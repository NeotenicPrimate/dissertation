PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Retsinas, G; Louloudis, G; Stamatopoulos, N; Gatos, B				Retsinas, George; Louloudis, Georgios; Stamatopoulos, Nikolaos; Gatos, Basilis			Efficient Learning-Free Keyword Spotting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Keyword spotting; query by example; learning-free; gradient orientation descriptor; sequence matching	TEXT LINE; SEGMENTATION; RECOGNITION; COMPETITION; WORDS	In this article, a method for segmentation-based learning-free Query by Example (QbE) keyword spotting on handwritten documents is proposed. The method consists of three steps, namely preprocessing, feature extraction and matching, which address critical variations of text images (e.g., skew, translation, different writing styles). During the feature extraction step, a sequence of descriptors is generated using a combination of a zoning scheme and a novel appearance descriptor, referred as modified Projections of Oriented Gradients. The preprocessing step, which includes contrast normalization and main-zone detection, aims to overcome the shortcomings of the appearance descriptor. Moreover, an uneven zoning scheme is introduced by applying a denser zoning only on query images for a more detailed representation. This leads to a significant reduction in storage requirements of a document collection. The distance between the query and word sequences is efficiently computed by the proposed Selective Matching algorithm. This algorithm is further extended to handle an augmented set of images originating from a single query image. The efficiency of the proposed method is demonstrated by experimentation conducted on seven publicly available datasets. In these experiments, the proposed method significantly outperforms all state-of-the-art learning-free techniques.	[Retsinas, George; Louloudis, Georgios; Stamatopoulos, Nikolaos; Gatos, Basilis] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, GR-15310 Athens, Greece; [Retsinas, George] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece	National Centre of Scientific Research "Demokritos"; National Technical University of Athens	Retsinas, G (corresponding author), Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, GR-15310 Athens, Greece.	georgeretsi@iit.demokritos.gr; louloud@iit.demokritos.gr; nstam@iit.demokritos.gr; bgat@iit.demokritos.gr		Louloudis, Georgios/0000-0003-4127-3796	EU project READ (Horizon-2020 programme) [674943]	EU project READ (Horizon-2020 programme)	This work has been supported by the EU project READ (Horizon-2020 programme, grant Ref. 674943).	Aldavert D, 2015, INT J DOC ANAL RECOG, V18, P223, DOI 10.1007/s10032-015-0245-z; Almazan J, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.67; Almazan J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814; Almazan J, 2013, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2013.130; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Espana-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141; Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009; Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113; Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Toselli AH, 2013, PROC INT CONF DOC, P501, DOI 10.1109/ICDAR.2013.106; Howe NR, 2013, PROC INT CONF DOC, P582, DOI 10.1109/ICDAR.2013.121; Kovalchuk A, 2014, INT CONF FRONT HAND, P3, DOI 10.1109/ICFHR.2014.9; Krishnan P, 2016, INT CONF FRONT HAND, P289, DOI [10.1109/ICFHR.2016.57, 10.1109/ICFHR.2016.0062]; Krishnan P, 2016, LECT NOTES COMPUT SC, V9905, P766, DOI 10.1007/978-3-319-46448-0_46; Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016; Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150; Pastor-Pellicer J, 2015, PROC INT CONF DOC, P341, DOI 10.1109/ICDAR.2015.7333780; Pratikakis I, 2016, INT CONF FRONT HAND, P613, DOI [10.1109/ICFHR.2016.109, 10.1109/ICFHR.2016.0117]; Pratikakis I, 2014, INT CONF FRONT HAND, P814, DOI 10.1109/ICFHR.2014.142; Puigcerver J, 2015, PROC INT CONF DOC, P1176, DOI 10.1109/ICDAR.2015.7333946; Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8; Retsinas G, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P411, DOI 10.1109/DAS.2016.61; Retsinas G, 2015, PROC INT CONF DOC, P336, DOI 10.1109/ICDAR.2015.7333779; Rothacker L, 2015, PROC INT CONF DOC, P661, DOI 10.1109/ICDAR.2015.7333844; Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2; Sfikas G, 2016, INT CONF FRONT HAND, P283, DOI [10.1109/ICFHR.2016.56, 10.1109/ICFHR.2016.0061]; Sharma A, 2015, PROC INT CONF DOC, P986, DOI 10.1109/ICDAR.2015.7333909; Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.55, 10.1109/ICFHR.2016.0060]; Wang P, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P207, DOI 10.1109/DAS.2014.46; Zagoris K, 2017, IEEE T IMAGE PROCESS, V26, P4032, DOI 10.1109/TIP.2017.2700721; Zagoris K, 2014, INT CONF FRONT HAND, P9, DOI 10.1109/ICFHR.2014.10; Zagoris K, 2011, J VIS COMMUN IMAGE R, V22, P378, DOI 10.1016/j.jvcir.2011.03.002	34	13	13	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1587	1600		10.1109/TPAMI.2018.2845880	http://dx.doi.org/10.1109/TPAMI.2018.2845880			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994197				2022-12-18	WOS:000470972300005
J	Im, S; Ha, H; Choe, G; Jeon, HG; Joo, K; Kweon, IS				Im, Sunghoon; Ha, Hyowon; Choe, Gyeongmin; Jeon, Hae-Gon; Joo, Kyungdon; Kweon, In So			Accurate 3D Reconstruction from Small Motion Clip for Rolling Shutter Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; geometry; structure from motion; rolling shutter; bundle adjustment; plane sweeping algorithm		Structure from small motion has become an important topic in 3D computer vision as a method for estimating depth, since capturing the input is so user-friendly. However, major limitations exist with respect to the form of depth uncertainty, due to the narrow baseline and the rolling shutter effect. In this paper, we present a dense 3D reconstruction method from small motion clips using commercial hand-held cameras, which typically cause the undesired rolling shutter artifact. To address these problems, we introduce a novel small motion bundle adjustment that effectively compensates for the rolling shutter effect. Moreover, we propose a pipeline for a fine-scale dense 3D reconstruction that models the rolling shutter effect by utilizing both sparse 3D points and the camera trajectory from narrow-baseline images. In this reconstruction, the sparse 3D points are propagated to obtain an initial depth hypothesis using a geometry guidance term. Then, the depth information on each pixel is obtained by sweeping the plane around each depth search space near the hypothesis. The proposed framework shows accurate dense reconstruction results suitable for various sought-after applications. Both qualitative and quantitative evaluations show that our method consistently generates better depth maps compared to state-of-the-art methods.	[Im, Sunghoon; Ha, Hyowon; Choe, Gyeongmin; Joo, Kyungdon; Kweon, In So] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea; [Jeon, Hae-Gon] KEPCO KAIST AI Res Ctr, Daejeon 34141, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Kweon, IS (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.	dlarl8927@kaist.ac.kr; hwha@rcv.kaist.ac.kr; gmchoe08@gmail.com; earboll@kaist.ac.kr; kdjoo369@gmail.com; iskweon77@kaist.ac.kr	Jeon, Hae-Gon/W-5908-2019	Jeon, Hae-Gon/0000-0003-1105-1666	Technology Innovation Program - Ministry of Trade, Industry & Energy (MOTIE, Korea) [2017-10069072]; National Research Foundation of Korea (NRF) - Ministry of Education [NRF-2016907531, 2018R1A6A3A03012899]	Technology Innovation Program - Ministry of Trade, Industry & Energy (MOTIE, Korea); National Research Foundation of Korea (NRF) - Ministry of Education	This work was supported by the Technology Innovation Program (No. 2017-10069072) funded by the Ministry of Trade, Industry & Energy (MOTIE, Korea). Sunghoon Im was partially supported by Global Ph.D. Fellowship Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2016907531). Hae-Gon Jeon was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(2018R1A6A3A03012899).	Akbari A. A., 2006, 2006 WORLD AUTOMATIO, P1, DOI DOI 10.1109/3DPVT.2006.141; [Anonymous], 2012, THE LYTRO CAMERA; [Anonymous], 2014, HTC ONE M8; Barron JT, 2015, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2015.7299076; Boas M. L., 2006, MATH METHODS PHYS; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Forssen PE, 2010, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2010.5540173; Gallup D., 2008, 2008 IEEE C COMPUTER, P1, DOI 10.1109/CVPR.2008.4587671; Gallup D., 2007 IEEE C COMP VIS, P1; Ha H, 2016, PROC CVPR IEEE, P5413, DOI 10.1109/CVPR.2016.584; Harris C., 1988, COMBINED CORNER EDGE, V15, DOI DOI 10.5244/C; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hedborg J, 2012, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2012.6247831; Hernandez Carlos, 2014, LENS BLUR NEW GOOGLE; Im S, 2016, LECT NOTES COMPUT SC, V9907, P156, DOI 10.1007/978-3-319-46487-9_10; Im S, 2015, IEEE I CONF COMP VIS, P837, DOI 10.1109/ICCV.2015.102; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Joshi Neel, 2014, MSRTR201473, P8; Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10; Liang Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3033, DOI 10.1109/CVPR.2011.5995480; Magerand L, 2012, LECT NOTES COMPUT SC, V7572, P456, DOI 10.1007/978-3-642-33718-5_33; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Oth L, 2013, PROC CVPR IEEE, P1360, DOI 10.1109/CVPR.2013.179; Reynolds M, 2011, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2011.5995550; Sastry, 2005, COMPUTING RES REPOSI; Saurer O, 2016, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2016.363; Saurer O, 2013, IEEE I CONF COMP VIS, P465, DOI 10.1109/ICCV.2013.64; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Suwajanakorn S, 2015, PROC CVPR IEEE, P3497, DOI 10.1109/CVPR.2015.7298972; Tomasi C., 1991, DETECTION TRACKING P; Venkataraman K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508390; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Yu F, 2014, PROC CVPR IEEE, P3986, DOI 10.1109/CVPR.2014.509	36	13	13	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					775	787		10.1109/TPAMI.2018.2819679	http://dx.doi.org/10.1109/TPAMI.2018.2819679			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993773				2022-12-18	WOS:000460583500001
J	Park, CC; Kim, B; Kim, G				Park, Cesc Chunseong; Kim, Byeongchang; Kim, Gunhee			Towards Personalized Image Captioning via Multimodal Memory Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image captioning; personalization; memory networks; convolutional neural networks		We address personalized image captioning, which generates a descriptive sentence for a user's image, accounting for prior knowledge such as her active vocabulary or writing style in her previous documents. As applications of personalized image captioning, we solve two post automation tasks in social networks: hashtag prediction and post generation. The hashtag prediction predicts a list of hashtags for an image, while the post generation creates a natural text consisting of normal words, emojis, and even hashtags. We propose a novel personalized captioning model named Context Sequence Memory Network (CSMN). Its unique updates over existing memory networks include (i) exploiting memory as a repository for multiple types of context information, (ii) appending previously generated words into memory to capture long-term information, and (iii) adopting CNN memory structure to jointly represent nearby ordered memory slots for better context understanding. For evaluation, we collect a new dataset InstaPIC-1.1M, comprising 1.1M Instagram posts from 6.3 K users. We further use the benchmark YFCC100M dataset [1] to validate the generality of our approach. With quantitative evaluation and user studies via Amazon Mechanical Turk, we show that the three novel features of the CSMN help enhance the performance of personalized image captioning over state-of-the-art captioning models.	[Park, Cesc Chunseong] Lunit Inc, Seoul 135080, South Korea; [Kim, Byeongchang; Kim, Gunhee] Seoul Natl Univ, Dept Comp Sci & Engn, Seoul 08826, South Korea; [Kim, Byeongchang; Kim, Gunhee] Seoul Natl Univ, Ctr Superintelligence, Seoul 08826, South Korea	Seoul National University (SNU); Seoul National University (SNU)	Kim, G (corresponding author), Seoul Natl Univ, Dept Comp Sci & Engn, Seoul 08826, South Korea.; Kim, G (corresponding author), Seoul Natl Univ, Ctr Superintelligence, Seoul 08826, South Korea.	cspark@lunit.io; byeongchang.kim@vision.snu.ac.kr; gunlee@snu.ac.kr			National Research Foundation of Korea(NRF) - Ministry of Science, ICT & Future Planning [2017M3C7A1047860]	National Research Foundation of Korea(NRF) - Ministry of Science, ICT & Future Planning	This research is partially supported by Kakao, Kakao Brain and Brain Research Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Science, ICT & Future Planning (2017M3C7A1047860). The code and dataset are available at https://github.com/cesc-park/attend2u.	Almaev T, 2015, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2015.430; Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65; Bigham Jeffrey P, 2010, P 23 NUAL ACM S US I, P333, DOI [10.1145/1866029.1866080?casa_token=eqdciLsaAKsAAAAA:v_iSvCJKVqaa-xY5ls_4fwveOme0IVWxS0hy40kPYpp, DOI 10.1145/1866029.1866080]; Chenyou Fan, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P459, DOI 10.1007/978-3-319-46604-0_33; Dauphin YN, 2017, PR MACH LEARN RES, V70; Denton E, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1731, DOI 10.1145/2783258.2788576; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Gehring J, 2017, PR MACH LEARN RES, V70; Graves A, 2014, NEURAL TURING MACHIN; Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101; Guu K., 2017, GENERATING SENTENCES; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hsieh PL, 2015, PROC CVPR IEEE, P1675, DOI 10.1109/CVPR.2015.7298776; Huang Ting-Hao Kenneth, 2016, P 2016 C N AM CHAPT, P1233, DOI DOI 10.18653/V1/N16-1147; JasonWeston Sumit, 2015, P INT C LEARN REPR I; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kienzle W., 2006, P 23 INT C MACH LEAR, P457, DOI DOI 10.1145/1143844.1143902; Kim Y., 2014, P 2014 C EMP METH NA; Kim Y, 2016, AAAI CONF ARTIF INTE, P2741; Kingma D.P, P 3 INT C LEARNING R; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Kumar A, 2016, PR MACH LEARN RES, V48; Lai SW, 2015, AAAI CONF ARTIF INTE, P2267; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Miller A., 2016, ARXIV160603126, P1400; Mirkin Shachar, 2015, 2015 C EMP METH NAT, P1102; Nair V., 2010, ICML, P807; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Park Cesc C, 2015, NIPS; Park CC, 2017, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2017.681; Polozov O, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P381; Ramnath K, 2014, IEEE WINT CONF APPL, P1050, DOI 10.1109/WACV.2014.6835988; Ren Z., 2017, P IEEE C COMP VIS PA, P6432; Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1; Sukhbaatar S., 2015, P 28 INT C NEURAL IN, V28, P2440; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130; Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640; Vinyals Oriol, 2015, NIPS; Weston Jason, 2014, EMNLP ASS COMP LING, P1822, DOI [10.3115/v1/d14-1194, DOI 10.3115/V1/D14-1194]; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Young Peter, 2014, T ASSOC COMPUT LING, V2, P67; Zaremba W., 2014, LEARNING TO EXECUTE; Zhang S., 2018, PERSONALIZING DIALOG	53	13	13	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					999	1012		10.1109/TPAMI.2018.2824816	http://dx.doi.org/10.1109/TPAMI.2018.2824816			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993735				2022-12-18	WOS:000460583500016
J	Teixeira, RFS; Leite, NJ				Teixeira, Raoni F. S.; Leite, Neucimar J.			A New Framework for Quality Assessment of High-Resolution Fingerprint Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; fingerprint analysis; quality assessment; high-resolution images; pores	CENTROIDAL VORONOI TESSELLATIONS; ENHANCEMENT; PERFORMANCE; FEATURES	The quality assessment of sets of features extracted from patterns of epidermal ridges on our fingers is a biometric challenge problem with implications on questions concerning security, privacy and identity fraud. In this work, we introduced a new methodology to analyze the quality of high-resolution fingerprint images containing sets of fingerprint pores. Our approach takes into account the spatial interrelationship between the considered features and some basic transformations involving point process and anisotropic analysis. We proposed two new quality index algorithms following spatial and structural classes of analysis. These algorithms have proved to be effective as a performance predictor and as a filter excluding low-quality features in a recognition process. The experiments using error reject curves show that the proposed approaches outperform the state-of-the-art quality assessment algorithm for high-resolution fingerprint recognition, besides defining a new method for reconstructing their friction ridge phases in a very consistent way.	[Teixeira, Raoni F. S.] Univ Fed Mato Grosso, Sch Engn, BR-78068600 Varzea Grande, MT, Brazil; [Leite, Neucimar J.] Univ Estadual Campinas, Inst Comp, BR-13083970 Campinas, SP, Brazil	Universidade Federal de Mato Grosso; Universidade Estadual de Campinas	Teixeira, RFS (corresponding author), Univ Fed Mato Grosso, Sch Engn, BR-78068600 Varzea Grande, MT, Brazil.	raoniteixeira@gmail.com; neucimar@ic.unicamp.br			CAPES; CNPq; FAPESP	CAPES(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP))	The authors would like to thanks the Brazilian agencies CAPES, CNPq and FAPESP for their financial support to this project. Prof. Neucimar J. Leite died in October 2016 while we concluded this work.	Alonso-Fernandez F, 2007, IEEE T INF FOREN SEC, V2, P734, DOI 10.1109/TIFS.2007.908228; [Anonymous], 2006, INTRO RANDOM SETS; Ashbaugh D.R, 1999, CRC SER PR CRIM; Bazen A. M., 2000, P WORKSH CIRC SYST S, P205; Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34; Canas G. D., 2012, SOCG, P219; Cao K, 2014, IEEE T PATTERN ANAL, V36, P1847, DOI 10.1109/TPAMI.2014.2302450; Chavel I., 2006, RIEMANNIAN GEOMETRY; Chen TP, 2004, IEEE IMAGE PROC, P1253; Chen Y, 2005, LECT NOTES COMPUT SC, V3546, P160; Chen Y., 2009, P INT C BIOM ICB 09, P1630; Daley D., 2003, INTRO THEORY POINT P, V1; Daley DJ., 2008, INTRO THEORY POINT P, V2nd ed., DOI 10.1007/978-0-387-49835-5; Du Q, 2005, SIAM J SCI COMPUT, V26, P737, DOI 10.1137/S1064827503428527; Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836; Feng JJ, 2006, PATTERN RECOGN, V39, P2131, DOI 10.1016/j.patcog.2006.05.001; Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332; Galton Francis, 1892, FINGER PRINTS; Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019; HARA M, 2007, Patent No. 7295688; HIRSCH W, 1973, J MENT DEFIC RES, V17, P58; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; ISO/ IEC, 2010, 1SC37 ISOIEC JTC, V4, P2010; Jain AK, 2007, IEEE T PATTERN ANAL, V29, P15, DOI 10.1109/TPAMI.2007.250596; Jin Qi, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P543, DOI 10.1109/ICCIS.2008.4670941; Jirachaweng S, 2011, PATTERN RECOGN, V44, P431, DOI 10.1016/j.patcog.2010.08.019; Labelle F., 2003, P 19 ANN S COMP GEOM, P191, DOI DOI 10.1145/777792.777822; Lee S, 2008, IEEE T INF FOREN SEC, V3, P792, DOI 10.1109/TIFS.2008.2007245; Leibon Greg, 2000, P 16 ANN S COMPUTATI, P341; Lim E, 2004, IEEE IMAGE PROC, P1241; Lim E, 2002, IEEE IMAGE PROC, P469; Maltoni D., 2009, HDB FINGERPRINT RECO; Olsen Martin Aastrup, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P158, DOI 10.1109/ICB.2012.6199802; Olsen MA, 2016, IET BIOMETRICS, V5, P47, DOI 10.1049/iet-bmt.2014.0055; Olsen MA, 2013, IEEE COMPUT SOC CONF, P138, DOI 10.1109/CVPRW.2013.28; PENROSE LS, 1973, J MED GENET, V10, P201, DOI 10.1136/jmg.10.3.201; Roddy AR, 1997, P IEEE, V85, P1390, DOI 10.1109/5.628710; Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018; Shen L, 2001, LECT NOTES COMPUT SC, V2091, P266; Sutthiwichaiporn P, 2013, PATTERN RECOGN, V46, P2465, DOI 10.1016/j.patcog.2013.02.002; Tabassi E., 2005, IM PROC 2005 ICIP 20; Thebaud L. R., 1999, U. S. Patent, Patent No. [5909501 A, 5909501]; van Lieshout, 2000, MARKOV POINT PROCESS; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yun EK, 2006, IMAGE VISION COMPUT, V24, P101, DOI 10.1016/j.imavis.2005.09.017; Zhao QJ, 2010, IEEE IMAGE PROC, P3089, DOI 10.1109/ICIP.2010.5648800; Zhao QJ, 2010, PATTERN RECOGN, V43, P2833, DOI 10.1016/j.patcog.2010.02.016; Zhao QJ, 2009, LECT NOTES COMPUT SC, V5558, P597, DOI 10.1007/978-3-642-01793-3_61; Zhu Y, 2007, IEEE T INF FOREN SEC, V2, P391, DOI 10.1109/TIFS.2007.903846	49	13	13	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					1905	1917		10.1109/TPAMI.2016.2631529	http://dx.doi.org/10.1109/TPAMI.2016.2631529			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27893382				2022-12-18	WOS:000408807600001
J	Sigalas, M; Pateraki, M; Trahanias, P				Sigalas, Markos; Pateraki, Maria; Trahanias, Panos			Full-Body Pose Tracking-The Top View Reprojection Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human pose estimation; model-based; tracking; particle filtering	HUMAN MOTION ANALYSIS	Recent introduction of low-cost depth cameras triggered a number of interesting works, pushing forward the state-of-the-art in human body pose extraction and tracking. However, despite the remarkable progress, many of the contemporary methods cope inadequately with complex scenarios, involving multiple interacting users, under the presence of severe inter-and intra-occlusions. In this work, we present a model-based approach for markerless articulated full body pose extraction and tracking in RGB-D sequences. A cylinder-based model is employed to represent the human body. For each body part a set of hypotheses is generated and tracked over time by a Particle Filter. To evaluate each hypothesis, we employ a novel metric that considers the reprojected Top View of the corresponding body part. The latter, in conjunction with depth information, effectively copes with difficult and ambiguous cases, such as severe occlusions. For evaluation purposes, we conducted several series of experiments using data from a public human action database, as well as own-collected data involving varying number of interacting users. The performance of the proposed method has been further compared against that of the Microsoft's Kinect SDK and NiTE (TM) using ground truth information. The results obtained attest for the effectiveness of our approach.	[Sigalas, Markos; Pateraki, Maria] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, Computat Vis & Robot Lab, Iraklion, Greece; [Trahanias, Panos] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, Iraklion, Greece; [Sigalas, Markos; Pateraki, Maria; Trahanias, Panos] Univ Crete, Dept Comp Sci, Iraklion, Crete, Greece	University of Crete	Sigalas, M (corresponding author), Fdn Res & Technol Hellas FORTH, Inst Comp Sci, Computat Vis & Robot Lab, Iraklion, Greece.; Sigalas, M (corresponding author), Univ Crete, Dept Comp Sci, Iraklion, Crete, Greece.	msigalas@ics.forth.gr; pateraki@ics.forth.gr; trahania@ics.forth.gr	Pateraki, Maria/ABE-6843-2021; Pateraki, Maria/AAP-1108-2021	Pateraki, Maria/0000-0002-8943-4598				Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011; Baak A., 2013, DATA DRIVEN APPROACH, P71, DOI DOI 10.1007/978-1-4471-4640-7_5; Baltzakis H, 2012, MACH VISION APPL, V23, P1141, DOI 10.1007/s00138-012-0409-5; Baltzakis H, 2009, LECT NOTES COMPUT SC, V5876, P140, DOI 10.1007/978-3-642-10520-3_13; Charles J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1202, DOI 10.1109/ICCVW.2011.6130387; Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006; Churchill E., 1978, HDB ANTHROPOMETRIC D, V2; Di Stefano L., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P322, DOI 10.1109/ICIAP.1999.797615; Escalera S, 2012, LECT NOTES COMPUT SC, V7378, P282, DOI 10.1007/978-3-642-31567-1_28; GANAPATHI V, 2010, PROC CVPR IEEE, P755, DOI DOI 10.1109/CVPR.2010.5540141; Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270; Grest D, 2005, LECT NOTES COMPUT SC, V3663, P285; Hernandez-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742; Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839; Kean S., 2011, MEET KINECT, P151, DOI [10.1007/978-1-4302-3889-8_8, DOI 10.1007/978-1-4302-3889-8_8]; KIEFEL M, 2014, LECT NOTES COMPUT SC, P331; Koritnik T, 2010, ADVANCES IN ROBOT KINEMATICS: MOTION IN MAN AND MACHINE, P401, DOI 10.1007/978-90-481-9262-5_43; Microsoft Corporation, 2012, MICR KIN XBOX 360; Moeslund TB, 2011, VISUAL ANAL HUMANS L, V1st; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; NASA, 1995, MAN SYST INT STAND R; Nowozin S, 2011, IEEE I CONF COMP VIS, P1668, DOI 10.1109/ICCV.2011.6126429; Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999; Pateraki M, 2014, COMPUT VIS IMAGE UND, V120, P1, DOI 10.1016/j.cviu.2013.12.006; Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Ramakrishna V, 2014, LECT NOTES COMPUT SC, V8690, P33, DOI 10.1007/978-3-319-10605-2_3; Rubin D. B, 1988, BAYESIAN STATISTICS, V3, P395; Schwarz L. A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P700, DOI 10.1109/FG.2011.5771333; Shen W, 2012, PROC CVPR IEEE, P1784, DOI 10.1109/CVPR.2012.6247875; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Siddiqui M., 2010, 2010 IEEE COMP SOC C, P1, DOI [10.1109/cvprw.2010.5543618, DOI 10.1109/CVPRW.2010.5543618]; Sigalas M, 2014, IEEE INT C INT ROBOT, P4104, DOI 10.1109/IROS.2014.6943140; Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189; Structure Sensor, 2015, OPENNI; Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664; Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310; Zabulis X, 2013, MACH VISION APPL, V24, P319, DOI 10.1007/s00138-012-0408-6; Zhang C., 2014, COMPUTER VISION MACH, P47, DOI DOI 10.1007/978-3-319-08651-4_3; ZHU Y, 2007, LECT NOTES COMPUT SC, P408; Zhu YD, 2010, SENSORS-BASEL, V10, P5280, DOI 10.3390/s100505280	42	13	13	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1569	1582		10.1109/TPAMI.2015.2502582	http://dx.doi.org/10.1109/TPAMI.2015.2502582			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26599616				2022-12-18	WOS:000379926200007
J	Fu, Y; Lam, A; Sato, I; Okabe, T; Sato, Y				Fu, Ying; Lam, Antony; Sato, Imari; Okabe, Takahiro; Sato, Yoichi			Separating Reflective and Fluorescent Components Using High Frequency Illumination in the Spectral Domain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fluorescence absorption and emission spectra; reflectance spectra; high frequency illumination	COLOR; RECOVERY	Hyperspectral imaging is beneficial to many applications but most traditional methods do not consider fluorescent effects which are present in everyday items ranging from paper to even our food. Furthermore, everyday fluorescent items exhibit a mix of reflection and fluorescence so proper separation of these components is necessary for analyzing them. In recent years, effective imaging methods have been proposed but most require capturing the scene under multiple illuminants. In this paper, we demonstrate efficient separation and recovery of reflectance and fluorescence emission spectra through the use of two high frequency illuminations in the spectral domain. With the obtained fluorescence emission spectra from our high frequency illuminants, we then describe how to estimate the fluorescence absorption spectrum of a material given its emission spectrum. In addition, we provide an in depth analysis of our method and also show that filters can be used in conjunction with standard light sources to generate the required high frequency illuminants. We also test our method under ambient light and demonstrate an application of our method to synthetic relighting of real scenes.	[Fu, Ying; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo 1138654, Japan; [Lam, Antony] Saitama Univ, Grad Sch Sci & Engn, Tokyo, Japan; [Sato, Imari] Natl Inst Informat, Tokyo, Japan; [Okabe, Takahiro] Kyushu Inst Technol, Grad Sch Comp Sci & Syst Engn, Fukuoka, Japan	University of Tokyo; Saitama University; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; Kyushu Institute of Technology	Fu, Y; Sato, Y (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo 1138654, Japan.; Lam, A (corresponding author), Saitama Univ, Grad Sch Sci & Engn, Tokyo, Japan.; Sato, I (corresponding author), Natl Inst Informat, Tokyo, Japan.; Okabe, T (corresponding author), Kyushu Inst Technol, Grad Sch Comp Sci & Syst Engn, Fukuoka, Japan.	fuying@iis.u-tokyo.ac.jp; antonylam@cv.ics.saitama-u.ac.jp; imarik@nii.ac.jp; okabe@ai.kyutech.ac.jp; ysato@iis.u-tokyo.ac.jp			Ministry of Education, Science, Sports and Culture	Ministry of Education, Science, Sports and Culture(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT))	This research was supported in part by the Ministry of Education, Science, Sports and Culture Grant-in-Aid for Scientific Research on Innovative Areas.	Alterman M., 2010, PROC IEEE INT C COMP, P1; Balas C, 2003, J CULT HERIT, V4, p330S; Barnard K, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P257; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Chi C, 2010, INT J COMPUT VISION, V86, P140, DOI 10.1007/s11263-008-0176-y; DiCarlo JM, 2001, NINTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P27; Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Farid H., 1999, IEEE COMP SOC C COMP; Fu Y, 2014, PROC CVPR IEEE, P2171, DOI 10.1109/CVPR.2014.278; Fu Y, 2013, IEEE I CONF COMP VIS, P457, DOI 10.1109/ICCV.2013.63; Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686; Hullin MB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778834; Hunt RWG, 2011, WILEY-ISTE, P1, DOI 10.1002/9781119975595; Johnson GM, 1999, IEEE COMPUT GRAPH, V19, P47, DOI 10.1109/38.773963; Lam A, 2013, PROC CVPR IEEE, P1452, DOI 10.1109/CVPR.2013.191; Lee BK, 2001, OPT ENG, V40, P2069, DOI 10.1117/1.1399283; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; McNamara G, 2006, CYTOM PART A, V69A, P863, DOI 10.1002/cyto.a.20304; Nawab S.H., 1996, SIGNALS SYSTEMS, V2; Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872; Rost FW., 1992, FLUORESCENCE MICROSC; Sato I, 2012, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2012.6247685; Skoog D., 2007, PRINCIPLES INSTRUMEN; Springsteen A, 1999, ANAL CHIM ACTA, V380, P183, DOI 10.1016/S0003-2670(98)00578-9; Styles IB, 2006, MED IMAGE ANAL, V10, P578, DOI 10.1016/j.media.2006.05.007; Suo JL, 2014, OPT EXPRESS, V22, P1697, DOI 10.1364/OE.22.001697; Tominaga S, 1996, J OPT SOC AM A, V13, P2163, DOI 10.1364/JOSAA.13.002163; Tominaga S., 2011, P IS T SID COL IM C, P252; Treibitz T, 2012, LECT NOTES COMPUT SC, V7578, P292, DOI 10.1007/978-3-642-33786-4_22; Wilkie A., 2006, GRAPHITE 06 P 4 INT, P321, DOI [10.1145/1174429.1174484, DOI 10.1145/1174429.1174484]; Zhang C, 2013, IEEE T PATTERN ANAL, V35, P2866, DOI 10.1109/TPAMI.2012.255; Zhang C, 2011, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2011.5995704; Zheng YQ, 2014, LECT NOTES COMPUT SC, V8693, P188, DOI 10.1007/978-3-319-10602-1_13	36	13	13	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					965	978		10.1109/TPAMI.2015.2473839	http://dx.doi.org/10.1109/TPAMI.2015.2473839			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26336113				2022-12-18	WOS:000374164700010
J	Vo, M; Narasimhan, SG; Sheikh, Y				Vo, Minh; Narasimhan, Srinivasa G.; Sheikh, Yaser			Texture Illumination Separation for Single-Shot Structured Light Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Single-shot; decomposition; separation; illumination; texture; mixture	IMAGES; TRANSPARENT; PROJECTION	Active illumination based methods have a trade-off between acquisition time and resolution of the estimated 3D shapes. Multi-shot approaches can generate dense reconstructions but require stationary scenes. Single-shot methods are applicable to dynamic objects but can only estimate sparse reconstructions and are sensitive to surface texture. We present a single-shot approach to produce dense shape reconstructions of highly textured objects illuminated by one or more projectors. The key to our approach is an image decomposition scheme that can recover the illumination image of different projectors and the texture images of the scene from their mixed appearances. We focus on three cases of mixed appearances: the illumination from one projector onto textured surface, illumination from multiple projectors onto a textureless surface, or their combined effect. Our method can accurately compute per-pixel warps from the illumination patterns and the texture template to the observed image. The texture template is obtained by interleaving the projection sequence with an all-white pattern. The estimated warps are reliable even with infrequent interleaved projection and strong object deformation. Thus, we obtain detailed shape reconstruction and dense motion tracking of the textured surfaces. The proposed method, implemented using a one camera and two projectors system, is validated on synthetic and real data containing subtle non-rigid surface deformations.	[Vo, Minh; Narasimhan, Srinivasa G.; Sheikh, Yaser] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Vo, M; Narasimhan, SG; Sheikh, Y (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	mpvo@cs.cmu.edu; srinivas@cs.cmu.edu; yaser@cs.cmu.edu	Vo, Minh/F-4937-2012	Vo, Minh/0000-0002-4608-7696	ONR [N00014-11-1-0295]; US National Science Foundation (NSF) [IIS-1317749]; NSF [1353120]; Div Of Information & Intelligent Systems [1317749] Funding Source: National Science Foundation	ONR(Office of Naval Research); US National Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This research was supported in parts by an ONR Grant N00014-11-1-0295, the US National Science Foundation (NSF) Grant IIS-1317749, and an NSF Grant No. 1353120.	Achar S, 2014, LECT NOTES COMPUT SC, V8689, P205, DOI 10.1007/978-3-319-10590-1_14; Achar S, 2013, IEEE I CONF COMP VIS, P1481, DOI 10.1109/ICCV.2013.187; Atcheson B, 2009, EXP FLUIDS, V46, P467, DOI 10.1007/s00348-008-0572-7; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33; Butler Alex D, 2012, P SIGCHI C HUM FACT, P1933, DOI [DOI 10.1145/2208276.2208335, 10.1145/2208276.2208335.]; Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177; Cech J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3129, DOI 10.1109/CVPR.2011.5995442; Chen CH, 2007, IEEE C EVOL COMPUTAT, P1; Chen HJ, 2007, OPT EXPRESS, V15, P12318, DOI 10.1364/OE.15.012318; Chen T. H., 2008, P IEEE C COMP VIS PA, P1; Cichocki A., 2012, ADAPTIVE BLIND SIGNA, DOI DOI 10.1002/0470845899; Couture V, 2011, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2011.6126458; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Furukawa R., 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P107, DOI 10.1109/PSIVT.2010.25; Gai K, 2012, IEEE T PATTERN ANAL, V34, P19, DOI 10.1109/TPAMI.2011.87; Gu JW, 2011, IEEE I CONF COMP VIS, P691, DOI 10.1109/ICCV.2011.6126305; Gupta M, 2013, INT J COMPUT VISION, V102, P33, DOI 10.1007/s11263-012-0554-3; Gupta M, 2012, PROC CVPR IEEE, P813, DOI 10.1109/CVPR.2012.6247753; Gupta M, 2012, INT J COMPUT VISION, V98, P146, DOI 10.1007/s11263-011-0500-9; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; Kasuya N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P299, DOI 10.1109/ICCVW.2013.47; Kawasaki H., 2008, PROCEEDINGSOF IEEE C, P1; Konig Soren, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P434, DOI 10.1504/IJISTA.2008.021306; Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62; Koninckx TP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P293, DOI 10.1109/IM.2003.1240262; Lanman D, 2009, COMPUT VIS IMAGE UND, V113, P1107, DOI 10.1016/j.cviu.2009.03.016; Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346; Lin zhen, 2002, ENVIRON TECHNOL, V3, P1; Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379; Movania M., 2011, OPENCLOTH; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Sagawa R, 2014, IEEE T PATTERN ANAL, V36, P1733, DOI 10.1109/TPAMI.2014.2300490; Salvi J, 2010, PATTERN RECOGN, V43, P2666, DOI 10.1016/j.patcog.2010.03.004; Scharstein D, 2003, PROC CVPR IEEE, P195; Schechner YY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1061, DOI 10.1109/ICCV.1998.710848; Schechner YY, 2000, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.2000.855796; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185; Tian YD, 2012, INT J COMPUT VISION, V98, P279, DOI 10.1007/s11263-011-0509-0; Ulusoy Ali Osman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1786, DOI 10.1109/ICCVW.2009.5457499; Vo M, 2014, IEEE COMPUT SOC CONF, P433, DOI 10.1109/CVPRW.2014.70; Vo M, 2012, OPT EXPRESS, V20, P16926, DOI 10.1364/OE.20.016926; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weise T., 2007, IEEE C COMPUTER VISI, P1; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Yamazaki S, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.96; Yang Z, 2013, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2013.11; Ye GZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601135	51	13	14	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					390	404		10.1109/TPAMI.2015.2443775	http://dx.doi.org/10.1109/TPAMI.2015.2443775			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761742				2022-12-18	WOS:000369989600015
J	Lobel, H; Vidal, R; Soto, A				Lobel, Hans; Vidal, Rene; Soto, Alvaro			Learning Shared, Discriminative, and Compact Representations for Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image categorization; dictionary learning; max-margin learning; structural SVMs; group sparsity	SCENE RECOGNITION; SHARING FEATURES; OBJECT	Dictionary-based and part-based methods are among the most popular approaches to visual recognition. In both methods, a mid-level representation is built on top of low-level image descriptors and high-level classifiers are trained on top of the mid-level representation. While earlier methods built the mid-level representation without supervision, there is currently great interest in learning both representations jointly to make the mid-level representation more discriminative. In this work we propose a new approach to visual recognition that jointly learns a shared, discriminative, and compact mid-level representation and a compact high-level representation. By using a structured output learning framework, our approach directly handles the multiclass case at both levels of abstraction. Moreover, by using a group-sparse prior in the structured output learning framework, our approach encourages sharing of visual words and thus reduces the number of words used to represent each class. We test our proposed method on several popular benchmarks. Our results show that, by jointly learning mid-and high-level representations, and fostering the sharing of discriminative visual words among target classes, we are able to achieve state-of-the-art recognition performance using far less visual words than previous approaches.	[Lobel, Hans; Soto, Alvaro] Pontificia Univ Catolica Chile, Dept Comp Sci, Santiago, Chile; [Vidal, Rene] Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, Baltimore, MD 21218 USA	Pontificia Universidad Catolica de Chile; Johns Hopkins University	Lobel, H (corresponding author), Pontificia Univ Catolica Chile, Dept Comp Sci, Alameda 340, Santiago, Chile.	halobel@uc.cl; rvidal@cis.jhu.edu; asoto@ing.puc.cl	Lobel, Hans/N-2520-2016; Soto, Alvaro/D-1406-2014	Soto, Alvaro/0000-0001-9378-397X; Lobel, Hans/0000-0003-3514-9414	FONDECYT [1120720]; NSF [1218709, 1447822]; ONR [N000141310116]; Div Of Information & Intelligent Systems [1218709] Funding Source: National Science Foundation	FONDECYT(Comision Nacional de Investigacion Cientifica y Tecnologica (CONICYT)CONICYT FONDECYT); NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was partially funded by grants FONDECYT 1120720, NSF 1218709, NSF 1447822 and ONR N000141310116. Hans Lobel is the corresponding author.	Babenko B, 2009, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2009.5459264; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Chen DZ, 2013, IEEE I CONF COMP VIS, P409, DOI 10.1109/ICCV.2013.58; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Doersch Carl, 2013, NIPS; Espinace P, 2013, ROBOT AUTON SYST, V61, P932, DOI 10.1016/j.robot.2013.05.002; Felzenszwalb P., INT J COMPUT VIS, V61, P55; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hwang SJ, 2011, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2011.5995543; Jain A, 2012, LECT NOTES COMPUT SC, V7576, P718, DOI 10.1007/978-3-642-33715-4_52; Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Jurie F, 2005, IEEE I CONF COMP VIS, P604; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Li LJ, 2007, IEEE I CONF COMP VIS, P345; Lian XC, 2010, LECT NOTES COMPUT SC, V6314, P157, DOI 10.1007/978-3-642-15561-1_12; Lobel H., 2013, P PAC RIM S IM VID T, P87; Lobel H, 2013, IEEE I CONF COMP VIS, P1697, DOI 10.1109/ICCV.2013.213; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, ADV NEURAL INFORM PR, P1033; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Moosmann F., 2007, ADV NEURAL INF PROCE, V19, P985; Ott P, 2011, PROC CVPR IEEE, P1513, DOI 10.1109/CVPR.2011.5995357; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Shabou A, 2012, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2012.6248107; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422; Torralba A, 2004, PROC CVPR IEEE, P762; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; Tsochantaridis I., 2004, P INT C MACH LEARN, P104; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Yu J., 2008, P INT C MACH LEARN, P1145; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhou N, 2014, IEEE T PATTERN ANAL, V36, P715, DOI 10.1109/TPAMI.2013.189; Zhu J., 2010, P NEUR INF PROC SYST, P2365; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	58	13	15	0	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2218	2231		10.1109/TPAMI.2015.2408349	http://dx.doi.org/10.1109/TPAMI.2015.2408349			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440263	hybrid			2022-12-18	WOS:000362411000006
J	Ben Ayed, I; Punithakumar, K; Li, S				Ben Ayed, Ismail; Punithakumar, Kumaradevan; Li, Shuo			Distribution Matching with the Bhattacharyya Similarity: A Bound Optimization Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph cuts; bound optimization; auxiliary functions; Bhattacharyya measure	ACTIVE CONTOURS; ENERGY MINIMIZATION; IMAGE PAIRS; GRAPH CUTS; SEGMENTATION; ALGORITHMS; DRIVEN; SHAPE	We present efficient graph cut algorithms for three problems: (1) finding a region in an image, so that the histogram (or distribution) of an image feature within the region most closely matches a given model; (2) co-segmentation of image pairs and (3) interactive image segmentation with a user-provided bounding box. Each algorithm seeks the optimum of a global cost function based on the Bhattacharyya measure, a convenient alternative to other matching measures such as the Kullback-Leibler divergence. Our functionals are not directly amenable to graph cut optimization as they contain non-linear functions of fractional terms, which make the ensuing optimization problems challenging. We first derive a family of parametric bounds of the Bhattacharyya measure by introducing an auxiliary labeling. Then, we show that these bounds are auxiliary functions of the Bhattacharyya measure, a result which allows us to solve each problem efficiently via graph cuts. We show that the proposed optimization procedures converge within very few graph cut iterations. Comprehensive and various experiments, including quantitative and comparative evaluations over two databases, demonstrate the advantages of the proposed algorithms over related works in regard to optimality, computational load, accuracy and flexibility.	[Ben Ayed, Ismail; Li, Shuo] GE Healthcare, London, ON, Canada; [Ben Ayed, Ismail; Li, Shuo] Univ Western Ontario, London, ON, Canada; [Punithakumar, Kumaradevan] Univ Alberta, Edmonton, AB, Canada	General Electric; Western University (University of Western Ontario); University of Alberta	Ben Ayed, I (corresponding author), GE Healthcare, London, ON, Canada.	ismail.benayed@ge.com; punithak@ualberta.ca; shuo.li@ge.com	Li, Shuo/F-9736-2017; Li, Shuo/GXV-6545-2022; Li, Shuo/N-5364-2019; Punithakumar, Kumaradevan/U-3182-2017	Li, Shuo/0000-0002-5184-3230; Li, Shuo/0000-0002-5184-3230; Punithakumar, Kumaradevan/0000-0003-3835-1079				Adam A, 2009, IEEE T PATTERN ANAL, V31, P1708, DOI 10.1109/TPAMI.2009.21; AHERNE F, 1997, KYBERNETIKA, V32, P1; Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Ayed IB, 2009, IEEE T MED IMAGING, V28, P1902, DOI 10.1109/TMI.2009.2022087; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Ben Ayed I, 2011, LECT NOTES COMPUT SC, V6801, P221, DOI 10.1007/978-3-642-22092-0_19; Ben Ayed I, 2010, PROC CVPR IEEE, P3288, DOI 10.1109/CVPR.2010.5540045; Ben Ayed I, 2008, LECT NOTES COMPUT SC, V5241, P1025, DOI 10.1007/978-3-540-85988-8_122; Ben Ayed I, 2009, INT J COMPUT VISION, V85, P115, DOI 10.1007/s11263-009-0249-6; Benedek C, 2009, IEEE T IMAGE PROCESS, V18, P2303, DOI 10.1109/TIP.2009.2025808; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov Y., 2006, GRAPH CUTS VISION GR, P79; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bugeau A., 2007, P IEEE C COMP VIS PA, P1; Chen SQ, 2009, IEEE I CONF COMP VIS, P763, DOI 10.1109/ICCV.2009.5459290; Cho MS, 2008, LECT NOTES COMPUT SC, V5305, P144; Cui J., 2008, IEEE C COMP VIS PATT, P1; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445; Gallagher AC, 2008, PROC CVPR IEEE, P1073; Gorelick L, 2013, PROC CVPR IEEE, P1714, DOI 10.1109/CVPR.2013.224; Gorelick L, 2012, LECT NOTES COMPUT SC, V7572, P583, DOI 10.1007/978-3-642-33718-5_42; Hao Jiang, 2012, 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P678, DOI 10.1109/CVPR.2012.6247736; Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261; JOULIN A, 2010, PROC CVPR IEEE, P1943, DOI DOI 10.1109/CVPR.2010.5539868; Kim J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1033, DOI 10.1109/ICCV.2003.1238463; Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Lee D. D., 2000, NIPS, V13, P535; Lempitsky V., 2008, CVPR, P1; Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262; Malcolm J, 2007, IEEE I CONF COMP VIS, P2726; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Mignotte M, 2010, IEEE T IMAGE PROCESS, V19, P1610, DOI 10.1109/TIP.2010.2044965; Mitiche A, 2010, SPRINGER TOP SIGN PR, V5, P1; Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652; Ohta N, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P481, DOI 10.1109/ICCV.2001.937664; Punithakumar K, 2010, IEEE T INF TECHNOL B, V14, P1106, DOI 10.1109/TITB.2010.2050778; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Rother C, 2007, PROC CVPR IEEE, P1784; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222; Taniai T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.74; Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34; Vicente S, 2009, IEEE I CONF COMP VIS, P755, DOI 10.1109/ICCV.2009.5459287; Viet-Quoc Pham, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2113, DOI 10.1109/CVPR.2011.5995356	53	13	13	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1777	1791		10.1109/TPAMI.2014.2382104	http://dx.doi.org/10.1109/TPAMI.2014.2382104			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353126				2022-12-18	WOS:000359216600004
J	Zhang, Q; Li, BX				Zhang, Qiang; Li, Baoxin			Relative Hidden Markov Models for Video-Based Evaluation of Motion Skills in Surgical Training	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Relative hidden markov model; relative learning; temporal model; emotion recognition; surgical skill		A proper temporal model is essential to analysis tasks involving sequential data. In computer-assisted surgical training, which is the focus of this study, obtaining accurate temporal models is a key step towards automated skill-rating. Conventional learning approaches can have only limited success in this domain due to insufficient amount of data with accurate labels. We propose a novel formulation termed Relative Hidden Markov Model and develop algorithms for obtaining a solution under this formulation. The method requires only relative ranking between input pairs, which are readily available from training sessions in the target application, hence alleviating the requirement on data labeling. The proposed algorithm learns a model from the training data so that the attribute under consideration is linked to the likelihood of the input, hence supporting comparing new sequences. For evaluation, synthetic data are first used to assess the performance of the approach, and then we experiment with real videos from a widely-adopted surgical training platform. Experimental results suggest that the proposed approach provides a promising solution to video-based motion skill evaluation. To further illustrate the potential of generalizing the method to other applications of temporal analysis, we also report experiments on using our model on speech-based emotion recognition.	[Zhang, Qiang; Li, Baoxin] Arizona State Univ, Comp Sci & Engn, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe	Zhang, Q (corresponding author), Arizona State Univ, Comp Sci & Engn, Tempe, AZ 85287 USA.	qzhang53@asu.edu; baoxin.li@asu.edu			National Science Foundation (NSF) [0904778]	National Science Foundation (NSF)(National Science Foundation (NSF))	The work was supported in part by a grant (#0904778) from the National Science Foundation (NSF). Any opinions expressed in this material are those of the authors and do not necessarily reflect the views of the NSF.	Altun Y, 2003, P 20 INT C MACHINE L, P3; [Anonymous], 2007, NEURIPS 2007; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Bertsekas D. P, 2014, CONSTRAINED OPTIMIZA; Chang C.-C., 2011, ACM T INTELL SYST TE, V2, P27; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; Duan F, 2008, IEEE INT CON AUTO SC, P454, DOI 10.1109/COASE.2008.4626426; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fox E., 2009, THESIS MIT CAMBRIDGE; Gallagher AG, 2005, ANN SURG, V241, P364, DOI 10.1097/01.sla.0000151982.85062.80; Howells NR, 2008, ARTHROSCOPY, V24, P335, DOI 10.1016/j.arthro.2007.08.033; JUANG BH, 1990, IEEE T ACOUST SPEECH, V38, P1639, DOI 10.1109/29.60082; Jun S., 2012, P WORKSH PERF METR I, P198; Kadar I, 2012, PROC CVPR IEEE, P2711, DOI 10.1109/CVPR.2012.6247993; Kahol K., 2006, P 14 ANN ACM INT C M, V719-722; Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719; Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lin Henry C, 2006, Comput Aided Surg, V11, P220, DOI 10.3109/10929080600989189; MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2111, DOI 10.1109/78.134449; Mori H, 2008, LECT NOTES ARTIF INT, V5246, P427, DOI 10.1007/978-3-540-87391-4_55; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2; Parikh D., 2012, P AAAI C ART INT; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Rosen J, 2006, IEEE T BIO-MED ENG, V53, P399, DOI 10.1109/TBME.2005.869771; Rosen Jacob, 2002, Comput Aided Surg, V7, P49, DOI 10.1002/igs.10026; Satoshi S., 2010, J ROBOT, V2010; Schuller B, 2003, INT CONF ACOUST SPEE, P1; Schultz M, 2004, ADV NEUR IN, V16, P41; Shengbo Guo, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P106, DOI 10.1007/978-3-642-33460-3_12; Sloin A, 2008, IEEE T SIGNAL PROCES, V56, P172, DOI 10.1109/TSP.2007.906741; Suzuki S, 2004, IEEE IND ELEC, P641; Tarasov A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P841, DOI 10.1109/FG.2011.5771359; Wang G, 2010, PROC CVPR IEEE, P3525, DOI 10.1109/CVPR.2010.5539955; Watanabe K, 2006, IEEE T SYST MAN CY A, V36, P549, DOI 10.1109/TSMCA.2005.855777; WOODLAND PC, 1994, INT CONF ACOUST SPEE, P125; Zhang Q., 2013, P INT IS T SPIE EL I; Zhang Q., 2011, PROC INT ACM WORKSHO, P19, DOI DOI 10.1145/1964114.1964119; Zhang Q, 2013, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2013.77	41	13	13	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1206	1218		10.1109/TPAMI.2014.2361121	http://dx.doi.org/10.1109/TPAMI.2014.2361121			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357343	hybrid			2022-12-18	WOS:000354377100007
J	Meng, GF; Xiang, SM; Zheng, NN; Pan, CH				Meng, Gaofeng; Xiang, Shiming; Zheng, Nanning; Pan, Chunhong			Nonparametric Illumination Correction for Scanned Document Images via Convex Hulls	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Document image processing; illumination correction; scanning artifacts; dark border noise; convex hull	MARGINAL NOISE REMOVAL; SHADING CORRECTION; PRINTED MATERIALS; DISTORTION; ALGORITHM; POINTS; SHAPE	A scanned image of an opened book page often suffers from various scanning artifacts known as scanning shading and dark borders noises. These artifacts will degrade the qualities of the scanned images and cause many problems to the subsequent process of document image analysis. In this paper, we propose an effective method to rectify these scanning artifacts. Our method comes from two observations: that the shading surface of most scanned book pages is quasi-concave and that the document contents are usually printed on a sheet of plain and bright paper. Based on these observations, a shading image can be accurately extracted via convex hulls-based image reconstruction. The proposed method proves to be surprisingly effective for image shading correction and dark borders removal. It can restore a desired shading-free image and meanwhile yield an illumination surface of high quality. More importantly, the proposed method is nonparametric and thus does not involve any user interactions or parameter fine-tuning. This would make it very appealing to nonexpert users in applications. Extensive experiments based on synthetic and real-scanned document images demonstrate the efficiency of the proposed method.	[Meng, Gaofeng; Xiang, Shiming; Pan, Chunhong] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Xi'an Jiaotong University	Meng, GF (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Zhongguancun East Rd 95, Beijing 100190, Peoples R China.	gfmeng@nlpr.ia.ac.cn; smxiang@nlpr.ia.ac.cn; nnzheng@mail.xjtu.edu.cn; chpan@nlpr.ia.ac.cn			National Natural Science Foundation of China [61005036, 61175025, 61272331]; National Basic Research Program of China [2012CB316304]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China)	The authors would like to thank the anonymous reviewers and the associate editor for their valuable remarks and suggestions that improved the manuscript significantly. This work is supported by the Projects of the National Natural Science Foundation of China (Grant No. 61005036, 61175025, and 61272331), and the National Basic Research Program of China (Grant No. 2012CB316304).	ACKLAND BD, 1981, IEEE T COMPUT, V30, P41, DOI 10.1109/TC.1981.6312155; ANDREW AM, 1979, INFORM PROCESS LETT, V9, P216, DOI 10.1016/0020-0190(79)90072-3; Azmi MH, 2009, LECT NOTES COMPUT SC, V5857, P636, DOI 10.1007/978-3-642-05036-7_60; Brown MS, 2007, IEEE T PATTERN ANAL, V29, P1904, DOI 10.1109/TPAMI.2007.1118; Brown MS, 2006, IEEE T IMAGE PROCESS, V15, P1544, DOI 10.1109/TIP.2006.871082; BYKAT A, 1978, INFORM PROCESS LETT, V7, P296, DOI 10.1016/0020-0190(78)90021-2; Deans S., 1983, RADON TRANSFORM SOME; Eddy W. F., 1977, ACM Transactions on Mathematical Software, V3, P398, DOI 10.1145/355759.355766; Fan KC, 2002, PATTERN RECOGN, V35, P2593, DOI 10.1016/S0031-3203(01)00205-9; Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010; Gonzalez R.C., 2008, DIGITAL IMAGE PROCES; Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2; HOARE CAR, 1962, COMPUT J, V5, P10, DOI 10.1093/comjnl/5.1.10; Hsia SC, 2006, IEEE T IMAGE PROCESS, V15, P2719, DOI 10.1109/TIP.2006.877354; Jarvis R. A., 1973, Information Processing Letters, V2, P18, DOI 10.1016/0020-0190(73)90020-3; Jian Fan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P561, DOI 10.1109/ICDAR.2009.111; Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633; Knuth D.E., 1997, ART COMPUTER PROGRAM, V3rd ed; Koo HI, 2009, IEEE T IMAGE PROCESS, V18, P1551, DOI 10.1109/TIP.2009.2019301; Landon G., 2007, IEEE C COMP VIS PATT, P1; Lee JS, 2009, IEEE T CIRC SYST VID, V19, P898, DOI 10.1109/TCSVT.2009.2017314; Lins RD, 2010, LECT NOTES COMPUT SC, V6112, P355, DOI 10.1007/978-3-642-13775-4_36; Lu SJ, 2007, PROC INT CONF DOC, P312; Lu SJ, 2010, INT J DOC ANAL RECOG, V13, P303, DOI 10.1007/s10032-010-0130-8; Mariano E, 2011, PROC INT CONF DOC, P915, DOI 10.1109/ICDAR.2011.186; Meng GF, 2008, IEEE SIGNAL PROC LET, V15, P849, DOI 10.1109/LSP.2008.2002929; Oliveira D. M., 2009, INT WORKSH CAM BAS D, P3; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2; Shafait F, 2008, IEEE T PATTERN ANAL, V30, P941, DOI 10.1109/TPAMI.2007.70837; Shafait F, 2007, LECT NOTES COMPUT SC, V4522, P651; Shafait F, 2011, IEEE T PATTERN ANAL, V33, P846, DOI 10.1109/TPAMI.2010.194; Shafait F, 2009, IEEE T PATTERN ANAL, V31, P763, DOI 10.1109/TPAMI.2008.220; Shen L., 2008, P IEEE C COMPUTER VI, P1; Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40; Tappen M.F., 2006, 2006 IEEE COMPUTER S, V2, P1992; TOUSSAINT GT, 1985, PATTERN RECOGN LETT, V3, P21, DOI 10.1016/0167-8655(85)90038-8; Tsoi YC, 2004, PROC CVPR IEEE, P240; Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009; WADA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P66, DOI 10.1109/ICCV.1995.466805; ZHANG L, 2005, PROC CVPR IEEE, P337; Zhang L, 2009, PATTERN RECOGN, V42, P2961, DOI 10.1016/j.patcog.2009.03.025; Zhang WF, 2007, PR IEEE COMP DESIGN, P10	45	13	15	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1730	1743		10.1109/TPAMI.2012.251	http://dx.doi.org/10.1109/TPAMI.2012.251			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681999				2022-12-18	WOS:000319060600015
J	Randell, DA; Landini, G; Galton, A				Randell, David A.; Landini, Gabriel; Galton, Antony			Discrete Mereotopology for Spatial Reasoning in Automated Histological Image Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Life and medical sciences; knowledge representation formalisms and methods; morphological; modeling methodologies; representation languages		Discrete mereotopology (DM) is a first-order spatial logic that fuses together mereology (the theory of parthood relations) and topology to model discrete space. We show how a set of quasitopological functions defined within DM can be mapped to specific operators defined in mathematical morphology (MM) and easily implemented in scientific image processing programs. These functions provide the means to model topological properties of individual regions and spatial relations between them such as contact, overlap, and the relation of part to whole. DM not only extends the expressive power of image processing applications where mathematical morphology is used, but by functioning as a logic it also supplies the formal basis with which to prove the correctness of implemented algorithms as well as providing the computational basis to mechanically reason about segmented digital images using automated reasoning programs. In particular, we show how DM can supply a model-based and algorithmic context to the otherwise blind pixel-based image processing routines still dominating conventional imaging approaches. A number of worked examples drawn from the, histological domain are given, including segmentation of cells in culture, identifying basal cell layers from stratified epithelia sections, and cell sorting in blood smears.	[Randell, David A.; Landini, Gabriel] Univ Birmingham, Coll Med & Dent Sci, Sch Dent, Birmingham B4 6NN, W Midlands, England; [Galton, Antony] Univ Exeter, Coll Engn Math & Phys Sci, Exeter EC4 4QF, Devon, England	University of Birmingham; University of Exeter	Randell, DA (corresponding author), Univ Birmingham, Coll Med & Dent Sci, Sch Dent, Birmingham B4 6NN, W Midlands, England.	d.a.randell@bham.ac.uk; g.landini@bham.ac.uk; apgalton@ex.ac.uk		Landini, Gabriel/0000-0002-9689-0989	STFC [ST/F003404/1]	STFC(UK Research & Innovation (UKRI)Science & Technology Facilities Council (STFC))	David Randell and Gabriel Landini acknowledge the support of the STFC grant (ST/F003404/1). The authors would like to thank the anonymous reviewers for their useful comments.	Aiello M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P205; [Anonymous], 2007, HDB KNOWLEDGE REPRES; Bloch I, 2006, INT J APPROX REASON, V41, P77, DOI 10.1016/j.ijar.2005.06.011; Bloch I., 2007, HDB SPATIAL LOGICS, p[53, 80]; Bruns T., 1996, P 7 INT S SPAT DAT H, P31; Cech E., 1966, TOPOLOGICAL SPACES; CUI Z, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P679; FREKSA C, 1992, ARTIF INTELL, V54, P199, DOI 10.1016/0004-3702(92)90090-K; Galton A, 2003, THEOR COMPUT SCI, V305, P111, DOI 10.1016/S0304-3975(02)00701-6; Galton A, 1999, LECT NOTES COMPUT SC, V1661, P251; Galton A, 1995, LECT NOTES COMPUT SC, V988, P377; Galton A., MEREOTOPOLOGY UNPUB; Inglada J, 2009, IEEE T GEOSCI REMOTE, V47, P599, DOI 10.1109/TGRS.2008.2003435; Landini G, 2004, CYTOM PART A, V61A, P45, DOI 10.1002/cyto.a.20082; Landini G, 2003, J MICROSC-OXFORD, V209, P118, DOI 10.1046/j.1365-2818.2003.01113.x; Landini G., 2008, P 5 INT S FRACT BIOL, P129; Landini G., 2008, P WORKSH SHAP SIZ ME; Landini G., 2006, HEAD FACE MED, V2, P1; Li SJ, 2004, ARTIF INTELL, V160, P1, DOI 10.1016/j.artint.2004.05.012; Li SJ, 2003, ARTIF INTELL, V145, P121, DOI 10.1016/S0004-3702(02)00372-7; Maillot N, 2004, MACH VISION APPL, V16, P33, DOI 10.1007/s00138-004-0142-9; Papadias D., 1997, P 5 ACM WORKSH ADV G; PREWITT JMS, 1966, ANN NY ACAD SCI, V128, P1035; Randell D., 2008, P 2 IMAGEJ US DEV C, P151; RANDELL D, 2006, P 17 EUR C ART INT, V141, P432; Randell D. A., 1992, Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR '92), P165; Randell D.A., 2004, P 16 EUR C ART INT E, P63; Rasband W.S, 1997, IMAGEJ; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Serra J, 1988, IMAGE ANAL MATH MORP; Weidenbach C, 2009, LECT NOTES ARTIF INT, V5663, P140, DOI 10.1007/978-3-642-02959-2_10	31	13	14	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					568	581		10.1109/TPAMI.2012.128	http://dx.doi.org/10.1109/TPAMI.2012.128			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22665719				2022-12-18	WOS:000314792900005
J	Marin-Franch, I; Foster, DH				Marin-Franch, Ivan; Foster, David H.			Estimating Information from Image Colors: An Application to Digital Cameras and Natural Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color vision; color information; digital color cameras; color processing; information theory; natural scenes; kth-nearest-neighbor statistics; color constancy	INDEPENDENT COMPONENT ANALYSIS; MUTUAL INFORMATION; CONSTANCY; TRANSFORMATIONS; NUMBER; LIMITS	The colors present in an image of a scene provide information about its constituent elements. But the amount of information depends on the imaging conditions and on how information is calculated. This work had two aims. The first was to derive explicitly estimators of the information available and the information retrieved from the color values at each point in images of a scene under different illuminations. The second was to apply these estimators to simulations of images obtained with five sets of sensors used in digital cameras and with the cone photoreceptors of the human eye. Estimates were obtained for 50 hyperspectral images of natural scenes under daylight illuminants with correlated color temperatures 4,000, 6,500, and 25,000 K. Depending on the sensor set, the mean estimated information available across images with the largest illumination difference varied from 15.5 to 18.0 bits and the mean estimated information retrieved after optimal linear processing varied from 13.2 to 15.5 bits (each about 85 percent of the corresponding information available). With the best sensor set, 390 percent more points could be identified per scene than with the worst. Capturing scene information from image colors depends crucially on the choice of camera sensors.	[Marin-Franch, Ivan] Indiana Univ, Sch Optometry, Bloomington, IN 47405 USA; [Foster, David H.] Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England	Indiana University System; Indiana University Bloomington; University of Manchester	Marin-Franch, I (corresponding author), Indiana Univ, Sch Optometry, 800 E Atwater Ave, Bloomington, IN 47405 USA.	imarinfr@indiana.edu; d.h.foster@manchester.ac.uk	Foster, David H/A-1179-2011; Marín-Franch, Iván/AAF-4195-2021	Foster, David H/0000-0003-2428-715X; 	EPSRC [EP/B000257/1, EP/E056512/1]; Engineering and Physical Sciences Research Council [EP/B000257/1, EP/E056512/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors thank M.S. Mould, R. Petersen, K. Zychaluk, G. Feng, and R. Senatore for useful comments and for critically reading the manuscript; J. Worthey for advice on sources of spectral data for digital trichromatic cameras; and S.M.C. Nascimento and K. Amano for use of a set of hyperspectral images of natural scenes. This work was supported by EPSRC (grant nos. EP/B000257/1 and EP/E056512/1). I. Marin-Franch was with the School of Electrical and Electronic Engineering at the University of Manchester.	Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BUCHSBAUM G, 1983, PROC R SOC SER B-BIO, V220, P89, DOI 10.1098/rspb.1983.0090; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; CSISZAR I, 1995, IEEE T INFORM THEORY, V41, P35, DOI 10.1109/18.370120; De Valois RL, 2000, P NATL ACAD SCI USA, V97, P4997, DOI 10.1073/pnas.97.9.4997; DiCarlo JM, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P295; DUIN RPW, 1976, IEEE T COMPUT, V25, P1175, DOI 10.1109/TC.1976.1674577; DZUMRA M, 1994, J OPT SOC AM A, V11, P2389, DOI 10.1364/JOSAA.11.002389; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P3011, DOI 10.1364/JOSAA.11.003011; Foster D., 2010, ENCY EYE, P266; Foster David H., 2008, CGIV 2008/MCS'08. 4th European Conference on Colour in Graphics, Imaging and Vision. 10th International Symposium on Multispectral Colour Science, P41; Foster D.H., 2005, PERCEPTION, V34, P1001; Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359; Foster DH, 2009, J OPT SOC AM A, V26, pB14, DOI 10.1364/JOSAA.26.000B14; Foster DH, 2003, TRENDS COGN SCI, V7, P439, DOI 10.1016/j.tics.2003.08.002; Foster DH, 2004, VISUAL NEUROSCI, V21, P331, DOI 10.1017/S0952523804213335; FOSTER DH, 1994, P ROY SOC B-BIOL SCI, V257, P115, DOI 10.1098/rspb.1994.0103; Funt B, 2003, P SOC PHOTO-OPT INS, V5007, P182, DOI 10.1117/12.473897; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Good I.J., 1974, SINGULARITY PROBABIL, V376; Goria MN, 2005, J NONPARAMETR STAT, V17, P277, DOI 10.1080/104852504200026815; Grassberger P., 2008, ARXIVPHYSICS0307138V; Hyvarinen A., 1999, Neural Computing Surveys, V2; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; Kozachenko L. F., 1987, Problems of Information Transmission, V23, P95; Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LAND EH, 1986, VISION RES, V26, P7, DOI 10.1016/0042-6989(86)90067-2; Lapidoth A, 1996, IEEE T INFORM THEORY, V42, P1520, DOI 10.1109/18.532892; Lyon RF., 2002, COL IM C, V3, P349; Marin-Franch I., 2009, THESIS U MANCHESTER; Marin-Franch I, 2010, J VISION, V10, DOI 10.1167/10.9.9; MERHAV N, 1994, IEEE T INFORM THEORY, V40, P1953, DOI 10.1109/18.340469; Nascimento SMC, 2005, J OPT SOC AM A, V22, P1017, DOI 10.1364/JOSAA.22.001017; Nascimento SMC, 2002, J OPT SOC AM A, V19, P1484, DOI 10.1364/JOSAA.19.001484; Oxtoby EK, 2005, PERCEPTION, V34, P961, DOI 10.1068/p5186; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; SPERLING HC, 1971, SCIENCE, V172, P180, DOI 10.1126/science.172.3979.180; Steuer R, 2002, BIOINFORMATICS, V18, pS231, DOI 10.1093/bioinformatics/18.suppl_2.S231; Stockman A, 2000, VISION RES, V40, P1711, DOI 10.1016/S0042-6989(00)00021-3; Stogbauer H, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066123; Terstiege H., 1972, J COLOR APPEARANCE, V1, P40; Terstiege H., 1972, J COLOR APPEARANCE, V1, P19; TROOST JM, 1992, VISION RES, V32, P1987, DOI 10.1016/0042-6989(92)90058-Q; Victor JD, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.051903; Von Kries J., 1902, FESTSCHRIFT ALBRECHT, VVolume 32, P145; von Kries J., 1905, HDB PHYSL MENSCHEN, P211; WORTHEY JA, 1985, J OPT SOC AM A, V2, P1014, DOI 10.1364/JOSAA.2.001014; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd	59	13	13	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					78	91		10.1109/TPAMI.2012.78	http://dx.doi.org/10.1109/TPAMI.2012.78			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22450817	Green Published			2022-12-18	WOS:000311127700009
J	Wittek, P; Tan, CL				Wittek, Peter; Tan, Chew Lim			Compactly Supported Basis Functions as Support Vector Kernels for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Wavelet kernels; feature engineering; feature correlation; semantic kernels	OPERATORS; MACHINES	Wavelet kernels have been introduced for both support vector regression and classification. Most of these wavelet kernels do not use the inner product of the embedding space, but use wavelets in a similar fashion to radial basis function kernels. Wavelet analysis is typically carried out on data with a temporal or spatial relation between consecutive data points. We argue that it is possible to order the features of a general data set so that consecutive features are statistically related to each other, thus enabling us to interpret the vector representation of an object as a series of equally or randomly spaced observations of a hypothetical continuous signal. By approximating the signal with compactly supported basis functions and employing the inner product of the embedding L-2 space, we gain a new family of wavelet kernels. Empirical results show a clear advantage in favor of these kernels.	[Wittek, Peter] Univ Boras, Swedish Sch Lib & Informat Sci, S-50190 Boras, Sweden; [Tan, Chew Lim] Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117417, Singapore	University of Boras; National University of Singapore	Wittek, P (corresponding author), Univ Boras, Swedish Sch Lib & Informat Sci, Allegatan 1, S-50190 Boras, Sweden.	peterwittek@acm.org; tancl@comp.nus.edu.sg						Alexandrov T, 2009, BIOINFORMATICS, V25, P643, DOI 10.1093/bioinformatics/btn662; Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; [Anonymous], READINGS MULTIMEDIA; Asuncion A, 2007, UCI MACHINE LEARNING; Basili R., 2005, P 9 C COMP NAT LANG, P1; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741; Bloehdorn S., 2006, P 6 IEEE INT C DAT M; Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Cormen Thomas H, 2001, INTRO ALGORITHMS; Cristianini N, 2002, J INTELL INF SYST, V18, P127, DOI 10.1023/A:1013625426931; DAWSON A, 2008, REPOSITORY CASE HIST; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Fonseca ES, 2005, IEEE INT SYM MULTIM, P785; Fonseca ES, 2007, COMPUT BIOL MED, V37, P571, DOI 10.1016/j.compbiomed.2006.08.008; Gallant SI, 1991, NEURAL COMPUT, V3, P293, DOI 10.1162/neco.1991.3.3.293; GREFENSTETTE G, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P89; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Hoenkamp E, 2003, J AM SOC INF SCI TEC, V54, P314, DOI 10.1002/asi.10211; Hosseini Pegah T., 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2052, DOI 10.1109/ICBBE.2008.842; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, 1997 DIGEST OF TECHNICAL PAPERS, P94; KARLGREN J, 2001, P FDN REAL WORLD INT, P294; Kontostathis A, 2006, INFORM PROCESS MANAG, V42, P56, DOI 10.1016/j.ipm.2004.11.007; Kraskov A, 2005, EUROPHYS LETT, V70, P278, DOI 10.1209/epl/i2004-10483-y; Li T., 2002, ACM SIGKDD EXPLORATI, V4, P49, DOI [10.1145/772862.772870, DOI 10.1145/772862.772870]; Liu H, 2008, CH CRC DATA MIN KNOW, P3; LYONS J., 1977, SEMANTICS; Mavroeidis D, 2005, LECT NOTES ARTIF INT, V3721, P181; Mohammad S., 2005, DISTRIBUTIONAL UNPUB; NAZARETH D, 2007, P 40 ANN HAW INT C S, V40, P907; RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528; SCHLEIF F, 2009, COMPUTING VISUALIZAT, V12, P1; Schutze H, 1997, INFORM PROCESS MANAG, V33, P307, DOI 10.1016/S0306-4573(96)00068-4; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P428; SIOLAS G, 2000, P IEEE INT JOINT C N; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; SZU HH, 1992, OPT ENG, V31, P1907, DOI 10.1117/12.59918; TUNTISAK S, 2007, P C IEEE POW ENG SOC, P1540; Unser M, 1997, P SOC PHOTO-OPT INS, V3169, P422, DOI 10.1117/12.292801; UNSER M, 1993, WAVELET ANAL ITS APP, P91; WEAVER H, 1988, THEORY DISCRETE CONT; WILKINSON YA, 1990, MUTAGENESIS, V5, P99, DOI 10.1007/BF00393758; Wittek Peter, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P3373, DOI 10.1109/IJCNN.2009.5179022; WITTEK P, 2009, P 8 INT C COMP SEM J; Wittgenstein L., 1951, PHILOS INVESTIGATION; Yiming Yang, 1999, Information Retrieval, V1, P69, DOI 10.1023/A:1009982220290; Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113; Zhang L, 2005, INT J COMPUT INTELL, V5, P283, DOI 10.1142/S1469026805001489	53	13	13	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2039	2050		10.1109/TPAMI.2011.28	http://dx.doi.org/10.1109/TPAMI.2011.28			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	808HQ	21321366				2022-12-18	WOS:000293969000011
J	Fossati, A; Dimitrijevic, M; Lepetit, V; Fua, P				Fossati, Andrea; Dimitrijevic, Miodrag; Lepetit, Vincent; Fua, Pascal			From Canonical Poses to 3D Motion Capture Using a Single Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; motion; video analysis; 3D scene analysis; modeling and recovery of physical attributes; tracking	PEOPLE	We combine detection and tracking techniques to achieve robust 3D motion recovery of people seen from arbitrary viewpoints by a single and potentially moving camera. We rely on detecting key postures, which can be done reliably, using a motion model to infer 3D poses between consecutive detections, and finally refining them over the whole sequence using a generative model. We demonstrate our approach in the cases of golf motions filmed using a static camera and walking motions acquired using a potentially moving one. We will show that our approach, although monocular, is both metrically accurate because it integrates information over many frames and robust because it can recover from a few misdetections.	[Fossati, Andrea; Dimitrijevic, Miodrag; Lepetit, Vincent; Fua, Pascal] Ecole Polytech Fed Lausanne, EPFL IC ISIM CVLab, Comp Vis Lab, I&C Fac,Stn 14, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Fossati, A (corresponding author), Ecole Polytech Fed Lausanne, EPFL IC ISIM CVLab, Comp Vis Lab, I&C Fac,Stn 14, CH-1015 Lausanne, Switzerland.	andrea.fossati@epfl.ch; miodrag.dimitrijevic@epfl.ch; vincent.lepetit@epfl.ch; pascal.fua@epfl.ch	Fua, Pascal/H-3928-2011; Fossati, Andrea/AAN-3814-2020	Fossati, Andrea/0000-0001-9368-4058; Fua, Pascal/0000-0002-6702-9970				AGARWAL A, 2004, P EUR C COMP VIS MAY; Agarwal A., 2004, P IEEE C COMP VIS PA; Balan AO, 2008, LECT NOTES COMPUT SC, V5303, P15, DOI 10.1007/978-3-540-88688-4_2; Bo L., 2008, P IEEE C COMP VIS PA; BRUBAKER M, 2006, P NIPS WORKSH EV ART; BRUBAKER MA, 2007, P IEEE C COMP VIS PA; CHOO K, 2001, P INT C COMP VIS JUL; DAVISON AJ, 2001, P EUR WORKSH COMP AN; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; DIFRANCO D, 2001, P IEEE C COMP VIS PA; Dimitrijevic M, 2006, COMPUT VIS IMAGE UND, V104, P127, DOI 10.1016/j.cviu.2006.07.007; ELGAMMAL A, 2004, P IEEE C COMP VIS PA; FOSSATI A, 2008, P EUR C COMP VIS OCT; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; GIEBEL J, 2004, P EUR C COMP VIS; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; LEE CS, 2006, P NIPS WORKSH EV ART; LEIBE B, 2005, P IEEE C COMP VIS PA, V1; LI R, 2006, P NIPS WORKSH EV ART; LOY G, 2004, P EUR C COMP VIS; MIKOLAJCZYK K, 2001, P IEEE C COMP VIS PA; MORI G, 2004, P IEEE C COMP VIS PA; NAVARATNAM R, 2007, P INT C COMP VIS OCT; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; ORMONEIT D, 2001, P NEUR INF PROC SYST, P894; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Rosenhahn B., 2007, P IEEE C COMP VIS PA; SHAKHNAROVICH G, 2003, P INT C COMP VIS; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733; SIDENBLADH H, 2000, P EUR C COMP VIS JUN; SIDENBLADH H, 2002, P EUR C COMP VIS MAY; Sigal L., 2006, HUMANEVA SYNCHRONIZE; Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935; SMINCHISESCU C, 2005, P IEEE C COMP VIS PA; Sullivan J., 2002, P EUR C COMP VIS; TAYCHER L, 2006, P IEEE C COMP VIS PA; THAYANANTHAN A, 2003, P BRIT MACH VIS C, P589; Tomasi C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1441; Urtasun R., 2006, P IEEE C COMP VIS PA; Urtasun R, 2008, PROC CVPR IEEE, P149; Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006; WANG Q, 2003, P IEEE C COMP VIS PA; WU Y, 2003, P INT C COMP VIS	46	13	15	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1165	1181		10.1109/TPAMI.2009.108	http://dx.doi.org/10.1109/TPAMI.2009.108			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489222	Green Submitted			2022-12-18	WOS:000277649100002
J	Koppal, SJ; Narasimhan, SG				Koppal, Sanjeev J.; Narasimhan, Srinivasa G.			Appearance Derivatives for Isonormal Clustering of Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Appearance modeling; physics-based vision; scene reconstruction; active illumination; material invariants; relighting	PHOTOMETRIC STEREO	A new technique is proposed for scene analysis, called "appearance clustering." The key result of this approach is that the scene points can be clustered according to their surface normals, even when the geometry, material, and lighting are all unknown. This is achieved by analyzing an image sequence of a scene as it is illuminated by a smoothly moving distant light source. In such a scenario, the brightness measurements at each pixel form a "continuous appearance profile." When the source path follows an unstructured trajectory ( obtained, say, by smoothly hand-waving a light source), the locations of the extrema of the appearance profile provide a strong cue for the scene point's surface normal. Based on this observation, a simple transformation of the appearance profiles and a distance metric are introduced that, together, can be used with any unsupervised clustering algorithm to obtain isonormal clusters of a scene. We support our algorithm empirically with comprehensive simulations of the Torrance-Sparrow and Oren-Nayar analytic BRDFs, as well as experiments with 25 materials obtained from the MERL database of measured BRDFs. The method is also demonstrated on 45 examples from the CURET database, obtaining clusters on scenes with real textures such as artificial grass and ceramic tile, as well as anisotropic materials such as satin and velvet. The results of applying our algorithm to indoor and outdoor scenes containing a variety of complex geometry and materials are shown. As an example application, isonormal clusters are used for lighting-consistent texture transfer. Our algorithm is simple and does not require any complex lighting setup for data collection.	[Koppal, Sanjeev J.; Narasimhan, Srinivasa G.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Koppal, SJ (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	koppal@cs.cmu.edu; srinivas@cs.cmu.edu			US National Science Foundation Awards [CCF-0541230, CCF-0541307]; US Office of Naval Research Award [N00014-05-1-0188]	US National Science Foundation Awards(National Science Foundation (NSF)); US Office of Naval Research Award	This research was supported by US National Science Foundation Awards CCF-0541230 and CCF-0541307 and US Office of Naval Research Award N00014-05-1-0188. The authors thank Alexei Efros and Mohit Gupta for the technical discussions, Janice Brochetti for proofreading the paper, and Shree Nayar for providing the CURET textures [ 29].	BASRI R, 2006, INT J COMPUTER VISIO; COLEMAN E, 1982, P INT C COL GRAPH IM; DANA KJ, 1997, P IEEE C COMP VIS PA; DEBEVEC P, 2000, P ACM SIGGRAPH; DEYOUNG J, 1997, P GRAPH INT C; FOURNIER A, 1995, P EUR WORKSH REND TE; GEORGHIADES AS, 2003, P EUR WORKSH REND TE; GOLDMAN D, 2005, P 10 IEEE INT C COMP; HAYAKAWA H, 1994, J OPTICAL SOC AM; HEALEY G, 1997, P 10 SCAND C IM AN; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; KAUTZ J, 1999, P EUR WORKSH REND TE; KLINKER GJ, 1990, INT J COMPUTER VISIO; KOPPAL SJ, 2006, APPEARANCE CLUSTERIN; LENSCH HPA, 2003, ACM T GRAPHICS; MALLICK S, 2001, P 8 INT C COMP VIS; MALLICK S, 2005, P 10 IEEE INT C COMP; MARSCHNER SR, 1999, P EUR WORKSH REND TE; Matusik W., 2003, ACM T GRAPHICS, V4, P8; NARASIMHAN SG, 2002, P 7 EUR C COMP VIS; NARASIMHAN SG, 2003, P 9 INT C COMP VIS; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; NAYAR SK, 1990, IEEE T ROBOTICS AUTO; Oren M, 1995, INT J COMPUTER VISIO; Pharr M., 2004, PHYS BASED RENDERING; Ramamoorthi Ravi, 2001, P ACM SIGGRAPH; Rusinkiewicz S., 1998, P EUR WORKSH REND TE; Salton G., 1989, AUTOMATIC TEXT PROCE; SATO Y, 1997, P ACM SIGGRAPH; SHASHUA A, 1997, INT J COMPUTER VISIO; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; Torrance K. E., 1967, J OPTICAL SOC AM, V1; WOODHAM R, 1978, PHOTOMETRIC STEREO; Zhang L., 2003, P IEEE C COMP VIS PA	34	13	15	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1375	1385		10.1109/TPAMI.2008.148	http://dx.doi.org/10.1109/TPAMI.2008.148			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542573				2022-12-18	WOS:000267050600003
J	Zhu, J; Lyu, MR; Huang, TS				Zhu, Jianke; Lyu, Michael R.; Huang, Thomas S.			A Fast 2D Shape Recovery Approach by Fusing Features and Appearance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing and computer vision; nonrigid detection; real-time deformable registration; nonrigid augmented reality; medical image registration	FINITE NEWTON METHOD; MODELS; REGISTRATION; FLOW	In this paper, we present a fusion approach to solve the nonrigid shape recovery problem, which takes advantage of both the appearance information and the local features. We have two major contributions. First, we propose a novel progressive finite Newton optimization scheme for the feature-based nonrigid surface detection problem, which is reduced to only solving a set of linear equations. The key is to formulate the nonrigid surface detection as an unconstrained quadratic optimization problem that has a closed-form solution for a given set of observations. Second, we propose a deformable Lucas-Kanade algorithm that triangulates the template image into small patches and constrains the deformation through the second-order derivatives of the mesh vertices. We formulate it into a sparse regularized least squares problem, which is able to reduce the computational cost and the memory requirement. The inverse compositional algorithm is applied to efficiently solve the optimization problem. We have conducted extensive experiments for performance evaluation on various environments, whose promising results show that the proposed algorithm is both efficient and effective.	[Zhu, Jianke; Lyu, Michael R.] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; [Huang, Thomas S.] Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Chinese University of Hong Kong; University of Illinois System; University of Illinois Urbana-Champaign	Zhu, J (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	jkzhu@cse.cuhk.edu.hk; lyu@cse.cuhk.edu.hk; huang@ifp.uiuc.edu			Innovation and Technology Fund [ITS/084/07]; Research Grants Council Earmarked Grant [CUHK4150/07E]	Innovation and Technology Fund; Research Grants Council Earmarked Grant	The authors appreciate the reviewers for their extensive and informative comments for the improvement of this manuscript. Also, the authors would like to thank Dr. Guangyu Wang and Mr. Xiaopei Liu for their fruitful discussions on the GPU programming. The work was fully supported by two Hong Kong Government grants: the Innovation and Technology Fund (ITS/084/07) and the Research Grants Council Earmarked Grant (CUHK4150/07E). The short version of this paper appeared in our previous work published in the Proceedings of the 2007 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR).	Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BARTOLI A, 2006, P 17 BRIT MACH VIS C; BARTOLI A, 2004, P 15 BRIT MACH VIS C; Bartoli A, 2008, IEEE T PATTERN ANAL, V30, P2098, DOI 10.1109/TPAMI.2008.22; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BENHIMANE S, 2004, P IEEE RSJ INT C INT, P943; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Boyd S, 2004, CONVEX OPTIMIZATION; Brand M, 2001, PROC CVPR IEEE, P315; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; Fang H, 2004, ACM T GRAPHIC, V23, P354, DOI 10.1145/1015706.1015728; Fang H, 2006, IEEE T VIS COMPUT GR, V12, P1580, DOI 10.1109/TVCG.2006.102; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; GAYBELLILE V, 2007, P 18 BRIT MACH VIS C; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Ilic S, 2007, INT J COMPUT VISION, V72, P159, DOI 10.1007/s11263-006-8595-0; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Keerthi SS, 2005, J MACH LEARN RES, V6, P341; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lin WC, 2006, LECT NOTES COMPUT SC, V3952, P44; Ling HB, 2005, IEEE I CONF COMP VIS, P1466; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Mangasarian OL, 2002, OPTIM METHOD SOFTW, V17, P913, DOI 10.1080/1055678021000028375; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; MCNEILL G, 2007, ADV NEURAL INFORM PR, V19, P969; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Periaswamy S, 2006, MED IMAGE ANAL, V10, P452, DOI 10.1016/j.media.2005.03.006; Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Salzmann M, 2007, IEEE T PATTERN ANAL, V29, P1481, DOI 10.1109/TPAMI.2007.1080; Sclaroff S, 2003, COMPUT VIS IMAGE UND, V89, P197, DOI 10.1016/S1077-3142(03)00003-1; Torresani L, 2001, PROC CVPR IEEE, P493; Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007; WHITE R, 2006, P 9 EUR C COMP VIS, P70; WHITE R, 2006, COMPUTER VISION PATT, V2, P1809; Zhu Hui-ming, 2007, Sichuan Daxue Xuebao (Ziran Kexueban), V44, P1; Zhu JK, 2006, LECT NOTES COMPUT SC, V3951, P186	45	13	13	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1210	1224		10.1109/TPAMI.2008.151	http://dx.doi.org/10.1109/TPAMI.2008.151			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443920				2022-12-18	WOS:000266188900006
J	Cappelli, R; Maltoni, D				Cappelli, Raffaele; Maltoni, Davide			On the Spatial Distribution of Fingerprint Singularities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint singularities; expectation-maximization; location of singularities; probability density function estimation; singularity detection	ORIENTATION MODEL; POINTS; COMPUTATION; EXTRACTION; FIELDS	Fingerprint singularities play an important role in several fingerprint recognition and classification systems. Although some general relationships and constraints about the location of singularities in the different fingerprint classes are well known, to the best of our knowledge, no statistical models have been developed until now. This paper studies the spatial distributions of singularity locations in nature and derives, from a representative data set of labeled samples, the probability density functions of the four main fingerprint classes. The results obtained can be directly exploited to improve the accuracy of many techniques relying on the position of singularities, as confirmed by the results of two experiments on fingerprint classification and synthesis.	[Cappelli, Raffaele; Maltoni, Davide] Univ Bologna, DEIS, I-47023 Cesena, FC, Italy	University of Bologna	Cappelli, R (corresponding author), Univ Bologna, DEIS, Via Sacchi 3, I-47023 Cesena, FC, Italy.	cappelli@cse.unibo.it; maltoni@cse.unibo.it		Cappelli, Raffaele/0000-0003-3054-9363				Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; CANDELA GT, 1995, 5647 NIST NISTIR; Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20; Cappelli R, 2002, INT C PATT RECOG, P744, DOI 10.1109/ICPR.2002.1048096; Cappelli R, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P183, DOI 10.1007/0-387-21685-5_9; Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586; Cappelli R, 2003, HDB FINGERPRINT RECO; Cappelli R, 2007, IEEE T PATTERN ANAL, V29, P1489, DOI 10.1109/TPAMI.2007.1087; Cappuccio FP, 2000, J CARDIOVASC RISK, V7, P1; Chikkerur S, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P207, DOI 10.1109/AUTOID.2005.34; Duda R.O., 1973, J ROYAL STAT SOC SER; Figueiredo M. A. T., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P54; Gu JW, 2004, PATTERN RECOGN, V37, P543, DOI 10.1016/S0031-3203(03)00178-X; HANLEY JA, 1983, JAMA-J AM MED ASSOC, V249, P1743, DOI 10.1001/jama.249.13.1743; Henry ER., 1900, CLASSIFICATION USES; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; Li J, 2006, PATTERN RECOGN, V39, P102, DOI 10.1016/j.patcog.2005.08.010; MALTONI D, 2007, HDB BIOMETRICS; Mardia K.V., 1980, HDB STAT, VVolume 1, P279, DOI DOI 10.1016/S0169-7161(80)01011-5; Neuhaus M, 2005, LECT NOTES COMPUT SC, V3546, P191; Nilsson K, 2003, PATTERN RECOGN LETT, V24, P2135, DOI 10.1016/S0167-8655(03)00083-7; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Prabhakar S., 2003, HDB FINGERPRINT RECO; Ratha N.K., 2007, ADV BIOMETRICS SENSO; RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3; Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; TABASSI E, 2004, 7151 US NAT I STAND; Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9; Wang XC, 2007, PATTERN RECOGN, V40, P1804, DOI 10.1016/j.patcog.2006.10.012; Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003; Watson C. I., 1993, NIST SPECIAL DATABAS; WAYMAN JL, 2000, BIOMETRICS PERSONAL, P345; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608; [No title captured]	38	13	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					742	748		10.1109/TPAMI.2008.243	http://dx.doi.org/10.1109/TPAMI.2008.243			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229088				2022-12-18	WOS:000263396100013
J	Xiong, W; Chung, HS; Jia, JY				Xiong, Wei; Chung, Hin Shun; Jia, Jiaya			Fractional Stereo Matching Using Expectation-Maximization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; digital matting; Expectation-Maximization; alpha matte		In our fractional stereo matching problem, a foreground object with a fractional boundary is blended with a background scene using unknown transparencies. Due to the spatially varying disparities in different layers, one foreground pixel may be blended with different background pixels in stereo images, making the color constancy commonly assumed in traditional stereo matching not hold any more. To tackle this problem, in this paper, we introduce a probabilistic framework constraining the matching of pixel colors, disparities, and alpha values in different layers, and propose an automatic optimization method to solve a Maximizing a Posterior (MAP) problem using Expectation-Maximization (EM), given only a short-baseline stereo input image pair. Our method encodes the effect of background occlusion by layer blending without requiring a special detection process. The alpha computation process in our unified framework can be regarded as a new approach by natural image matting, which handles appropriately the situation when the background color is similar to that of the foreground object. We demonstrate the efficacy of our method by experimenting with challenging stereo images and making comparisons with state-of-the-art methods.	[Xiong, Wei; Chung, Hin Shun; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Xiong, W (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	wayne.xiong@hotmail.com; hschung@cse.cuhk.edu.hk; leojia@cse.cuhk.edu.hk	Jia, Jiaya/I-3251-2012		Research Grants Council of the Hong Kong Special Administrative Region, China [412307]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	The authors would like to thank the associate editor and all the reviewers for their constructive comments to improve the manuscript. This work was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China ( Project No. 412307).	Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chuang YY, 2001, PROC CVPR IEEE, P264; Criminisi A, 2004, PROC CVPR IEEE, P342; Deng Y, 2005, IEEE I CONF COMP VIS, P1316; FELZENSZWALB PF, 2004, P IEEE INT C COMP VI, V70, P261; Hasinoff SW, 2006, COMPUT VIS IMAGE UND, V103, P22, DOI 10.1016/j.cviu.2006.02.005; Hong L, 2004, PROC CVPR IEEE, P74; Joshi N, 2006, ACM T GRAPHIC, V25, P779, DOI 10.1145/1141911.1141955; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; LEVIN A, 2007, P IEEE INT C COMP VI; LEVIN A, 2006, P IEEE CVPR 2006, P61; Minka T, 1998, EXPECTATION MAXIMIZA; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SMITH AR, 1996, P SIGGRAPH 96, P259; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954; Sun Y, 2004, WIREL COMMUN MOB COM, V4, P315, DOI 10.1002/wcm.215; TRUCCO E, 1997, P BRIT MACH VIS C BM; Tsin Y, 2003, PROC CVPR IEEE, P702; Wang J, 2005, IEEE I CONF COMP VIS, P936; WEXLER Y, 2002, P ECCV, V3, P487; XIONG W, 2007, P IEEE INT C COMP VI; YANG Q, 2006, CVPR, P2347; Zhang XS, 2005, LECT NOTES OPER RES, V5, P288; Zitnick CL, 2005, IEEE I CONF COMP VIS, P1308; Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766	28	13	15	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					428	443		10.1109/TPAMI.2008.98	http://dx.doi.org/10.1109/TPAMI.2008.98			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147873	Green Submitted			2022-12-18	WOS:000262480200004
J	Breckon, TP; Fisher, RB				Breckon, Toby P.; Fisher, Robert B.			Three-Dimensional Surface Relief Completion via Nonparametric Techniques	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing; occlusion; range data; surface fitting; texture	REPAIR	Common 3D acquisition techniques, such as laser scanning and stereo capture, are realistically only 2.5D in nature, Here, we consider the automated completion of hidden or missing portions in 3D scenes originally acquired from 2.5D (or 3D) capture. We propose an approach based on the nonparametric propagation of available scene knowledge from the known (visible) scene areas to these unknown (invisible) 3D regions in conjunction with an initial underlying geometric surface completion.	[Breckon, Toby P.] Cranfield Univ, Sch Engn, Appl Math & Comp Grp, Cranfield MK43 0AL, Beds, England; [Fisher, Robert B.] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Cranfield University; University of Edinburgh	Breckon, TP (corresponding author), Cranfield Univ, Sch Engn, Appl Math & Comp Grp, Whittle Bldg, Cranfield MK43 0AL, Beds, England.	toby.breckon@cranfield.ac.uk; rbf@inf.ed.ac.uk	Breckon, Toby/ABD-1451-2020	Breckon, Toby/0000-0003-1666-7590				Bhat Pravin, 2004, P 2004 EUR ACM SIGGR, P41; Borer P., 2005, P 6 INT S VIRT REAL, P41; Breckon T.P., 2006, THESIS U EDINBURGH; Breckon TP, 2005, COMPUT VIS IMAGE UND, V99, P499, DOI 10.1016/j.cviu.2005.05.002; Castellani U, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P672, DOI 10.1109/TDPVT.2002.1024138; CHALMOVIANSKY P, 2003, MATH SURFACES, V10, P196; Davis J., 2002, P 1 INT S 3D DAT PRO; Dell'Acqua F, 2002, IEEE T PATTERN ANAL, V24, P569, DOI 10.1109/34.993564; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Ju T, 2004, ACM T GRAPHIC, V23, P888, DOI 10.1145/1015706.1015815; [Краевский В.В. Kraevsky V.V.], 2005, [Педагогика, Pedagogika], P13; LAI YK, 2005, ACM SOLID PHYS MODEL, P15; Liepa P., 2003, Symposium on Geometry Processing, P200; Masuda T, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1003; Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006; PAULY M, 2005, P EUR S GEOM PROC; Sharf A, 2004, ACM T GRAPHIC, V23, P878, DOI 10.1145/1015706.1015814; Stulp F, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P232, DOI 10.1109/IM.2001.924442; TEKUMALLA L, 2004, UUCS04019 SCH COMPT; Verdera J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P903; Wang DN, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P11; Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298	22	13	14	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2249	2255		10.1109/TPAMI.2008.153	http://dx.doi.org/10.1109/TPAMI.2008.153			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988957	Green Submitted			2022-12-18	WOS:000260033900015
J	McAuley, JJ; Caetano, TS; Barbosa, MS				McAuley, Julian J.; Caetano, Tiberio S.; Barbosa, Marconi S.			Graph rigidity, cyclic belief propagation, and point pattern matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						point pattern matching; graph matching; graphical models; belief propagation; global rigidity; chordal graphs		A recent paper [1] proposed a provably optimal polynomial time method for performing near-isometric point pattern matching by means of exact probabilistic inference in a chordal graphical model. Its fundamental result is that the chordal graph in question is shown to be globally rigid, implying that exact inference provides the same matching solution as exact inference in a complete graphical model. This implies that the algorithm is optimal when there is no noise in the point patterns. In this paper, we present a new graph that is also globally rigid but has an advantage over the graph proposed in [1]: Its maximal clique size is smaller, rendering inference significantly more efficient. However, this graph is not chordal, and thus, standard Junction Tree algorithms cannot be directly applied. Nevertheless, we show that loopy belief propagation in such a graph converges to the optimal solution. This allows us to retain the optimality guarantee in the noiseless case, while substantially reducing both memory requirements and processing time. Our experimental results show that the accuracy of the proposed solution is indistinguishable from that in [1] when there is noise in the point patterns.	[McAuley, Julian J.] NICTA, Stat Machine Learning Grp, Canberra, ACT 2601, Australia; Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT 0200, Australia	Australian National University; Australian National University	McAuley, JJ (corresponding author), NICTA, Stat Machine Learning Grp, Locked Bag 8001, Canberra, ACT 2601, Australia.	julian.mcauley@nicta.com.au; Tiberio.Caetano@nicta.com.au; marconi@ifsc.usp.br						Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bishop C.M., 2014, ANTIMICROB AGENTS CH, V58, P7250; Caetano TS, 2006, INT C PATT RECOG, P121; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; CARCASSONI M, 2000, COMPUTER VISION PATT, V1, P1649; Connelly R, 2005, DISCRETE COMPUT GEOM, V33, P549, DOI 10.1007/s00454-004-1124-4; Crandall D, 2005, PROC CVPR IEEE, P10; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; IHLER AT, 2005, ADV NEURAL INFORM PR, P609; Lauritzen S., 1996, OXFORD STAT SCI SERI; Rangarajan A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P671; Robles-Kelly A, 2006, LECT NOTES COMPUT SC, V4109, P459; Weismer G, 2000, CLIN LINGUIST PHONET, V14, P1, DOI 10.1080/026992000298904; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; Yedidia JS, 2000, ADV NEURAL INFORM PR, V13, P689	17	13	19	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					2047	2054		10.1109/TPAMI.2008.124	http://dx.doi.org/10.1109/TPAMI.2008.124			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787251	Green Submitted			2022-12-18	WOS:000259110000016
J	Liao, M; Yang, RG; Zhang, ZY				Liao, Miao; Yang, Ruigang; Zhang, Zhengyou			Robust and accurate visual echo cancellation in a full-duplex projector-camera system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		visual echo cancellation; projector-camera system; geometric calibration; photometric calibration; whiteboard-camera system; teleconferencing; collaboration		In this paper, we study the problem of "visual echo" in a full-duplex projector-camera system for telecollaboration applications. Visual echo is defined as the appearance of projected contents observed by the camera. It can potentially saturate the projected contents, similar to audio echo in telephone conversation. Our approach to visual echo cancellation includes an offline calibration procedure that records the geometric and photometric transfer between the projector and the camera in a lookup table. During runtime, projected contents in the captured video are identified using the calibration information and suppressed, therefore achieving the goal of canceling visual echo. Our approach can accurately handle full-color images under the arbitrary reflectance of display surfaces and the photometric response of the projector or camera. It is robust to geometric registration errors and quantization effects and is therefore particularly effective for high-frequency contents such as texts and hand drawings. We demonstrate the effectiveness of our approach with a variety of real images in a full-duplex projector-camera system.	[Liao, Miao; Yang, Ruigang] Univ Kentucky, Dept Comp Sci, Lexington, KY 40507 USA; [Zhang, Zhengyou] Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA	University of Kentucky; Microsoft	Liao, M (corresponding author), Univ Kentucky, Dept Comp Sci, 1 Qual St,Suite 800, Lexington, KY 40507 USA.	miao.liao@cs.uky.edy; ryang@cs.uky.edy; zhang@microsoft.com	zhang, zheng/HCH-9684-2022					Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27; CHAM TJ, 2003, P IEEE COMP VIS PATT; Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; FLAGG M, 2005, P IEEE INT WORKSH PR; Fujii K, 2005, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.2005.41; HALL D, 1999, P 7 INT S INT ROB SY; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Jaynes C, 2004, IEEE T VIS COMPUT GR, V10, P290, DOI 10.1109/TVCG.2004.1272728; JAYNES C, 2003, P 7 INT WORKSH IMM P; MAJUMDER A, 2003, IEEE T VISUALIZATION, V10; MAJUMDER A, 2003, P IEEE INT WORKSH PR; Mynatt Elizabeth D., 1999, P SIGCHI C HUM FACT, P346, DOI [10.1145/302979.303108, DOI 10.1145/302979.303108]; PINHANEZ CS, 2001, P 3 INT C UB COMP UB; Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883; RASKAR R, 2003, P ACM SIGGR 03; RASKAR R, 1998, COMPUTER GRAPHICS, V32, P179; SATO Y, 2000, P 4 IEEE INT C AUT F; Stone MC, 2001, IEEE COMPUT GRAPH, V21, P58, DOI 10.1109/38.946632; SURATI R, 1998, THESIS MIT; Takao N, 2003, INT J COMPUT VISION, V53, P115, DOI 10.1023/A:1023084706295; TAKAO N, 2003, P IEEE INT WORKSH PR; TAKAO N, 2002, CMURITR0210; Wellner Pierre, 1993, COMMUN ACM, V36, P87, DOI 10.1145/159544.159630; Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508; Yoon KJ, 2005, PROC CVPR IEEE, P924; Zhang ZY, 2006, COMPUTER VISION FOR INTERACTIVE AND INTELLIGENT ENVIRONMENTS, P109; Zhou HN, 2004, IEEE IMAGE PROC, P2885	28	13	13	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1831	1840		10.1109/TPAMI.2007.70828	http://dx.doi.org/10.1109/TPAMI.2007.70828			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703834				2022-12-18	WOS:000258344900012
J	Niethammer, M; Vela, PA; Tannenbaum, A				Niethammer, Marc; Vela, Patricio A.; Tannenbaum, Allen			Geometric observers for dynamically evolving curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric observer; level set method; curve evolution; visual tracking	ACTIVE CONTOURS; TRACKING; FLOWS; MOTION	This paper proposes a deterministic observer design for visual tracking based on nonparametric implicit (level-set) curve descriptions. The observer is continuous discrete with continuous-time system dynamics and discrete-time measurements. Its state-space consists of an estimated curve position augmented by additional states (e.g., velocities) associated with every point on the estimated curve. Multiple simulation models are proposed for state prediction. Measurements are performed through standard static segmentation algorithms and optical-flow computations. Special emphasis is given to the geometric formulation of the overall dynamical system. The discrete-time measurements lead to the problem of geometric curve interpolation and the discrete-time filtering of quantities propagated along with the estimated curve. Interpolation and filtering are intimately linked to the correspondence problem between curves. Correspondences are established by a Laplace-equation approach. The proposed scheme is implemented completely implicitly (by Eulerian numerical solutions of transport equations) and thus naturally allows for topological changes and subpixel accuracy on the computational grid.	[Niethammer, Marc] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA; [Vela, Patricio A.; Tannenbaum, Allen] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	University of North Carolina; University of North Carolina Chapel Hill; University System of Georgia; Georgia Institute of Technology	Niethammer, M (corresponding author), Univ N Carolina, Dept Comp Sci, Campus Box 3175,Sitterson Hall, Chapel Hill, NC 27599 USA.	mn@cs.unc.edu; partricio.vela@ece.gatech.edu; allen.tannenbaum@ece.gatech.edu		Vela, Patricio/0000-0002-6888-7002	NCRR NIH HHS [P41 RR-13218, P41 RR013218] Funding Source: Medline; NIBIB NIH HHS [U54 EB005149, U54 EB005149-040003] Funding Source: Medline; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB005149] Funding Source: NIH RePORTER	NCRR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NIBIB NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		Abraham R., 2012, MANIFOLDS TENSOR ANA, V75; Angenent S, 2003, SIAM J MATH ANAL, V35, P61, DOI 10.1137/S0036141002410927; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; CASELLES V, 1997, INT J COMPUT VISION, V13, P5; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; CHARPIAT G, 2004, FDN COMPUTATIONAL MA, pOF1; COHEN I, 1991, 1595 INRIA; CREMERS D, 2003, P 2 IEEE WORKSH VAR, P169; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; Dong G, 2005, IEEE T MED IMAGING, V24, P910, DOI 10.1109/TMI.2005.846856; Dornaika F, 2006, IEEE T CIRC SYST VID, V16, P1107, DOI 10.1109/TCSVT.2006.881200; Doucet A., 2001, SEQUENTIAL MONTE CAR; Duci A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P656; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; Evans LC, 1998, GRAD STUD MATH; Gelb A., 1999, APPL OPTIMAL ESTIMAT; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JACKSON J, 2004, P C DEC CONTR; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KAO CY, 2003, 0375 U CAL; Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Li J, 2005, BIOPHYS J, V88, P3707, DOI 10.1529/biophysj.104.047332; LOTOTSKY S, 1996, THESIS U SO CALIFORN; LUENBERGER DG, 1971, IEEE T AUTOMAT CONTR, VAC16, P596, DOI 10.1109/TAC.1971.1099826; Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621; MICHOR PW, 2008, RIEMANNIAN GEOMETRIE; Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514; Miller RN, 1999, TELLUS A, V51, P167, DOI 10.1034/j.1600-0870.1999.t01-2-00002.x; Mitter SK, 1996, IEEE CONTR SYST MAG, V16, P67, DOI 10.1109/37.506400; Niethammer M, 2006, IEEE T AUTOMAT CONTR, V51, P562, DOI 10.1109/TAC.2006.872837; Osher S., 2003, APPL MATH SCI, V153; PAPADAKIS N, 2007, P INT C COMP VIS; Peterfreund N, 1999, IEEE T PATTERN ANAL, V21, P564, DOI 10.1109/34.771328; PICHON E, 1944, UNPUB LAPLACE EQUATI; Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081; Rathi Y, 2007, IEEE T IMAGE PROCESS, V16, P1370, DOI 10.1109/TIP.2007.894244; Rousson M., 2002, P IEEE WORKSH MOT VI; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; SETHIAN JA, 1999, LEVEL SETS METHODS F; SURESH S, 2005, ACTA BIOMATER, V1, P1630; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; Tagare HD, 2002, J MATH IMAGING VIS, V16, P57, DOI 10.1023/A:1013938519103; Tseng Y, 2004, J CELL SCI, V117, P2159, DOI 10.1242/jcs.01073; Vaswani N, 2006, IEEE DECIS CONTR P, P1668; VELA PA, 2007, IN PRESS IEEE T CONT; WOUWER AV, 2001, CONTROL SYSTEMS ROBO; Yezzi A, 2005, IEEE I CONF COMP VIS, P913; Yezzi A, 2001, PROC CVPR IEEE, P87; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042; Yilmaz A., 2004, OBJECT CONTOUR TRACK; Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	57	13	13	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1093	1108		10.1109/TPAMI.2008.28	http://dx.doi.org/10.1109/TPAMI.2008.28			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421113	Green Accepted, Green Submitted			2022-12-18	WOS:000254872500013
J	Angiulli, F				Angiulli, Fabrizio			Condensed nearest neighbor data domain description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; data domain description; data condensation; nearest neighbor rule; novelty detection		A simple yet effective unsupervised classification rule to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors' distances in a reference data set, assumed to model normal behavior, lie within a certain threshold. This work investigates the effect of using a subset of the original data set as the reference set of the classifier. With this aim, the concept of a reference-consistent subset is introduced and it is shown that finding the minimum-cardinality reference-consistent subset is intractable. Then, the Condensed Nearest Neighbor Domain Description (CNNDD) algorithm is described, which computes a reference-consistent subset with only two reference set passes. Experimental results revealed the advantages of condensing the data set and confirmed the effectiveness of the proposed approach. A thorough comparison with related methods was accomplished, pointing out the strengths and weaknesses of one-class nearest-neighbor-based training-set-consistent condensation.	Univ Calabria, Dipartimento Elettron Informat & Sistemist, I-87036 Arcavacata Di Rende, Italy	University of Calabria	Angiulli, F (corresponding author), Univ Calabria, Dipartimento Elettron Informat & Sistemist, Via P Bucci 41C, I-87036 Arcavacata Di Rende, Italy.	f.angiulli@deis.unical.it		Angiulli, Fabrizio/0000-0002-9860-7569				Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431), P15; Angiulli F., 2005, INT C MACH LEARN, P7; Breunig M., 2000, P ACM INT C MAN DAT; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CC, 2001, LIBSVM LIB SUPORT VE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75, DOI 10.1109/TPAMI.1981.4767052; Eskin E., 2002, ADV INF SECUR, V6, P77; FIX E, 1951, 4 SCH AV MED US AIR; Floyd S, 1995, MACH LEARN, V21, P269; Garey M., 1979, GUIDE NP COMPLETENES; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392; LITTLESTONE N, 1986, RELATING DATA COMPRE; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Ramaswamy S, 2000, P 2000 ACM SIGMOD IN, P427; Ritter G, 1997, PATTERN RECOGN LETT, V18, P525, DOI 10.1016/S0167-8655(97)00049-4; SCHOLKOPF B, 1999, 87 MICR RES REDM WAS; Scholkopf B., 1995, P INT C KNOWL DISC D, P251; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Tax DMJ, 2000, INT C PATT RECOG, P672, DOI 10.1109/ICPR.2000.906164; TAX DMJ, 1999, P EUR S ART NEUR NET, P251; TAX DMJ, 2001, THESIS U TECHN DELFT; TOUSSAINT G, 2002, SOCS025 MCG U SCH CO; YPMA A, 1998, P INT CORP ASS NAM N	28	13	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1746	1758		10.1109/TPAMI.2007.1086	http://dx.doi.org/10.1109/TPAMI.2007.1086			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699920	Green Submitted			2022-12-18	WOS:000248696100005
J	Wang, L; Yang, RG; Davis, JE				Wang, Liang; Yang, Ruigang; Davis, James E.			BRDF invariant stereo using light transport constancy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo; BRDF; rank constraint; light transport constancy; non-Lambertian	DEPTH	Nearly all existing methods for stereo reconstruction assume that scene reflectance is Lambertian and make use of brightness constancy as a matching invariant. We introduce a new invariant for stereo reconstruction called light transport constancy (LTC), which allows completely arbitrary scene reflectance (bidirectional reflectance distribution functions (BRDFs)). This invariant can be used to formulate a rank constraint on multiview stereo matching when the scene is observed by several lighting configurations in which only the lighting intensity varies. In addition, we show that this multiview constraint can be used with as few as two cameras and two lighting configurations. Unlike previous methods for BRDF invariant stereo, LTC does not require precisely configured or calibrated light sources or calibration objects in the scene. Importantly, the new constraint can be used to provide BRDF invariance to any existing stereo method whenever appropriate lighting variation is available.	Univ Kentucky, Dept Comp Sci, Lexington, KY 40507 USA; Univ Calif Santa Cruz, Dept Comp Sci, Santa Cruz, CA 95064 USA	University of Kentucky; University of California System; University of California Santa Cruz	Wang, L (corresponding author), Univ Kentucky, Dept Comp Sci, 1 Qual St,Suite 800, Lexington, KY 40507 USA.	lwangd@cs.uky.edu; ryang@cs.uky.edu; davis@cs.ucsc.edu		Yang, Ruigang/0000-0001-5296-6307				BHAT DN, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1087; BLAKE A, 1985, P 9 INT JOINT C ART, V2, P973; BRELSTAFF G, 1988, P IEEE INT C COMP VI, P297; CARRIHILL B, 1985, COMPUT VISION GRAPH, V32, P337, DOI 10.1016/0734-189X(85)90056-8; CURLESS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P987, DOI 10.1109/ICCV.1995.466772; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Fujii K, 2005, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.2005.41; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; JALKIO JA, 1985, OPT ENG, V24, P966, DOI 10.1117/12.7973609; Jin HL, 2003, PROC CVPR IEEE, P171; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; KOLMOGOROV V, 2003, IMPLEMENTATION GRAPH; Li YZ, 2002, INT C PATT RECOG, P573, DOI 10.1109/ICPR.2002.1048004; LIN S, 2002, P EUR C COMP VIS, P210; MAGDA S, 2001, P INT C COMP VIS, P297; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; MITSUNAGA T, 1999, P IEEE COMP VIS PATT, V1, P380; MIYASAKA T, 2001, P MACH VIS 3 DIM I 2; Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280; Scharfetter H, 2002, PHYSIOL MEAS, V23, P195, DOI 10.1088/0967-3334/23/1/320; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Treuille A, 2004, LECT NOTES COMPUT SC, V3022, P457; WOLFF LB, 1994, J OPT SOC AM A, V11, P3069, DOI 10.1364/JOSAA.11.003069; Yang RG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P576, DOI 10.1109/ICCV.2003.1238399; Zhang XW, 2003, LEUKEMIA RES, V27, P367, DOI 10.1016/S0145-2126(02)00175-3; Zickler T, 2002, LECT NOTES COMPUT SC, V2352, P869; Zickler TE, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1411; Zickler TE, 2003, PROC CVPR IEEE, P548	29	13	14	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1616	1626		10.1109/TPAMI.2007.1171	http://dx.doi.org/10.1109/TPAMI.2007.1171			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627048				2022-12-18	WOS:000247965600010
J	Chesi, G; Hung, YS				Chesi, Graziano; Hung, Y. S.			Image noise induced errors in camera positioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual servoing; image noise; positioning accuracy; convex optimization		The problem of evaluating worst-case camera positioning error induced by unknown-but-bounded (UBB) image noise for a given object-camera configuration is considered. Specifically, it is shown that upper bounds to the rotation and translation worst-case error for a certain image noise intensity can be obtained through convex optimizations. These upper bounds, contrary to lower bounds provided by standard optimization tools, allow one to design robust visual servo systems.	Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China	University of Hong Kong	Chesi, G (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Peoples R China.	chesi@eee.hku.hk; yshung@eee.hku.hk	Chesi, Graziano/C-1575-2009; Hung, Yeung Sam/C-1852-2009	Chesi, Graziano/0000-0003-4214-4224; 				Boyd S., 1994, SIAM; Chesi G, 2004, IEEE T ROBOTIC AUTOM, V20, P724, DOI 10.1109/TRO.2004.829465; Chesi G, 2003, IEEE T AUTOMAT CONTR, V48, P200, DOI 10.1109/TAC.2002.808465; Chesi G., 1999, P 5 EUR CONTR C; Corke PI, 2001, IEEE T ROBOTIC AUTOM, V17, P507, DOI 10.1109/70.954764; Cowan NJ, 2002, IEEE T ROBOTIC AUTOM, V18, P521, DOI 10.1109/TRA.2002.802202; Deguchi K, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P705, DOI 10.1109/IROS.1998.727274; Hashimoto K, 2003, ADV ROBOTICS, V17, P969, DOI 10.1163/156855303322554373; Kyrki V, 2004, IEEE INT CONF ROBOT, P1861, DOI 10.1109/ROBOT.2004.1308095; Malis E, 2004, IEEE T ROBOTIC AUTOM, V20, P72, DOI 10.1109/TRA.2003.820847; Malis E, 1999, IEEE T ROBOTIC AUTOM, V15, P238, DOI 10.1109/70.760345; Mezouar Y, 2002, IEEE T ROBOTIC AUTOM, V18, P534, DOI 10.1109/TRA.2002.802218; MURRAY RM, 1994, MATHINTRO ROBOTIC MA; Oh PY, 2001, IEEE T ROBOTIC AUTOM, V17, P1, DOI 10.1109/70.917078; Tahri O, 2004, IEEE INT CONF ROBOT, P1185, DOI 10.1109/ROBOT.2004.1307985; Taylor C. J., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2734, DOI 10.1109/ROBOT.2000.846441; WEISS LE, 1987, IEEE T ROBOTIC AUTOM, V3, P404, DOI 10.1109/JRA.1987.1087115; Zhang H, 2002, IEEE T ROBOTIC AUTOM, V18, P199, DOI 10.1109/TRA.2002.999648	18	13	13	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1476	1480		10.1109/TPAMI.2007.70723	http://dx.doi.org/10.1109/TPAMI.2007.70723			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568150				2022-12-18	WOS:000247186500015
J	Shang, LM; Jasiobedzki, P; Greenspan, M				Shang, Limin; Jasiobedzki, Piotr; Greenspan, Michael			Model-based tracking by classification in a tiny discrete pose space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; registration; motion; 3D/stereo scene analysis	SEARCH	A method is presented for tracking 3D objects as they transform rigidly in space within a sparse range image sequence. The method operates in discrete space and exploits the coherence across image frames that results from the relationship between known bounds on the object's velocity and the sensor frame rate. These motion bounds allow the interframe transformation space to be reduced to a reasonable and indeed tiny size, comprising only tens or hundreds of possible states. The tracking problem is in this way cast into a classification framework, effectively trading off localization precision for runtime efficiency and robustness. The method has been implemented and tested extensively on a variety of freeform objects within a sparse range data stream comprising only a few hundred points per image. It has been shown to compare favorably against continuous domain Iterative Closest Point (ICP) tracking methods, performing both more efficiently and more robustly. A hybrid method has also been implemented that executes a small number of ICP iterations following the initial discrete classification phase. This hybrid method is both more efficient than the ICP alone and more robust than either the discrete classification method or the ICP separately.	Queens Univ, Dept Elect & Comp Engn, Comp Vis & Robot Res Lab, Kingston, ON K7L 3N6, Canada; MDA Space Missions, Brampton, ON L6S 4J3, Canada	Queens University - Canada	Shang, LM (corresponding author), Queens Univ, Dept Elect & Comp Engn, Comp Vis & Robot Res Lab, Rm 518,Walter Light Hall,19 Union St, Kingston, ON K7L 3N6, Canada.	2ls2@qlink.queensu.ca; piotr.jasiobedzki@mdacorporation.com; michael.greenspan@queensu.ca						Abraham M., 2001, P 6 INT S ART INT RO; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Benjemaa R, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P113, DOI 10.1109/IM.1997.603856; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blais F, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P251, DOI 10.1109/IM.2003.1240257; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; DAUCHER N, 1993, P BRIT MACH VIS C, P249; Dornaika F, 2004, IEEE T SYST MAN CY B, V34, P1838, DOI 10.1109/TSMCB.2004.829135; Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620; Greenspan M, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P161, DOI 10.1109/IM.2001.924426; GREENSPAN M, 2004, P IEEE CS C COMP VIS, V1; Greenspan MA, 2002, IEEE T PATTERN ANAL, V24, P495, DOI 10.1109/34.993557; Gu YH, 1999, IEEE T SYST MAN CY A, V29, P358, DOI 10.1109/3468.769754; Jasiobedzki P., 1999, Proceedings 1999 International Conference on Information Intelligence and Systems (Cat. No.PR00446), P211, DOI 10.1109/ICIIS.1999.810263; JASIOBEDZKI P, 2000, P INT S ROB; JASIOBEDZKI P, 2001, P 6 INT S ART INT RO; Jost T, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427, DOI 10.1109/IM.2003.1240278; KOLLNIG H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P569, DOI 10.1109/ICCV.1995.466888; Langis C, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P195, DOI 10.1109/IM.2001.924434; LENG J, 2004, P 8 INT C CONTR AUT; Li BH, 2004, IEEE T SYST MAN CY B, V34, P1412, DOI 10.1109/TSMCB.2004.825914; Lowe D. G., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P436, DOI 10.1109/ICCV.1990.139566; Marchand E, 2001, IMAGE VISION COMPUT, V19, P941, DOI 10.1016/S0262-8856(01)00054-3; Morency LP, 2002, INT C PATT RECOG, P367, DOI 10.1109/ICPR.2002.1047472; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Shang LM, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P523; SIMON DA, 1994, IEEE INT CONF ROBOT, P2235, DOI 10.1109/ROBOT.1994.350953; Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53; THOMPSON D, 1987, P IEEE INT C ROB AUT, V4, P208; ULITSKY A, 2004, P WORKSH ON SERV SPA; Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92; Weik S, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P93, DOI 10.1109/IM.1997.603853; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Wunsch P, 1997, IEEE INT CONF ROBOT, P2868, DOI 10.1109/ROBOT.1997.606722	36	13	13	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					976	989		10.1109/TPAMI.2007.1088	http://dx.doi.org/10.1109/TPAMI.2007.1088			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431297				2022-12-18	WOS:000245600800005
J	Poh, N; Martin, A; Bengio, S				Poh, Norman; Martin, Alvin; Bengio, Samy			Performance generalization in biometric authentication using joint user-specific and sample bootstraps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometric authentication assessment; DET; ROC; bootstrap subset		Biometric authentication performance is often depicted by a detection error trade-off (DET) curve. We show that this curve is dependent on the choice of samples available, the demographic composition and the number of users specific to a database. We propose a two- step bootstrap procedure to take into account the three mentioned sources of variability. This is an extension to the Bolle et al.' s bootstrap subset technique. Preliminary experiments on the NIST2005 and XM2VTS benchmark databases are encouraging, e.g., the average result across all 24 systems evaluated on NIST2005 indicates that one can predict, with more than 75 percent of DET coverage, an unseen DET curve with eight times more users. Furthermore, our finding suggests that with more data available, the confidence intervals become smaller and, hence, more useful.	IDIAP Res Inst, CH-1920 Martigny, Switzerland; NIST, Gaithersburg, MD 20899 USA	National Institute of Standards & Technology (NIST) - USA	Poh, N (corresponding author), IDIAP Res Inst, Rue Simplon 4, CH-1920 Martigny, Switzerland.	norman@idiap.ch; alvin.martin@nist.gov; bengio@idiap.ch	Poh, Norman/Y-8261-2019					ADLER A, 2005, P 5 INT AUD VID BAS, P860; Bengio S., 2004, P SPEAK LANG REC WOR, P279; Bolle RM, 2004, COMPUT VIS IMAGE UND, V93, P1, DOI 10.1016/j.cviu.2003.08.002; CAMPBELL G, 1994, STAT MED, V13, P499, DOI 10.1002/sim.4780130513; Dass SC, 2005, PROC SPIE, V5779, P226, DOI 10.1117/12.603441; Doddington G., 1998, P INT C SPOK LANG PR; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; James L., 2005, BIOMETRIC SYSTEMS TE; MA G, 1993, MED DECIS MAKING, P191; Maass W., 1999, PULSED NEURAL NETWOR, DOI [10.7551/mitpress/5704.001.0001, DOI 10.7551/MITPRESS/5704.001.0001]; Macskassy S, 2004, P 1 WORKSH ROC AN AI, P61; MACSKASSY S, 2005, P 22 INT C MACH LEAR; MARTIN A, 1997, P EUROSPEECH, P1895; *NIST, 2005, 2005 NIST SPEAK REC; Poh N, 2006, PATTERN RECOGN, V39, P223, DOI 10.1016/j.patcog.2005.06.011; POH N, 2004, IN PRESS P INT C AC; WORKING H, 1929, STAT MED, V24	17	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					492	498		10.1109/TPAMI.2007.55	http://dx.doi.org/10.1109/TPAMI.2007.55			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224618	Green Submitted			2022-12-18	WOS:000243420500010
J	Berengolts, A; Lindenbaum, M				Berengolts, Alexander; Lindenbaum, Michael			On the distribution of saliency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						saliency networks; grouping; perceptual organization; figure-from-ground	PERCEPTUAL ORGANIZATION; VISUAL-ATTENTION; CONTOURS; CURVES	Detecting salient structures is a basic task in perceptual organization. Saliency algorithms typically mark edge-points with some saliency measure, which grows with the length and smoothness of the curve on which these edge-points lie. Here, we propose a modified saliency estimation mechanism that is based on probabilistically specified grouping cues and on curve length distributions. In this framework, the Shashua and Ullman saliency mechanism may be interpreted as a process for detecting the curve with maximal expected length. Generalized types of saliency naturally follow. We propose several specific generalizations (e.g., gray-level-based saliency) and rigorously derive the limitations on generalized saliency types. We then carry out a probabilistic analysis of expected length saliencies. Using ergodicity and asymptotic analysis, we derive the saliency distributions associated with the main curves and with the rest of the image. We then extend this analysis to finite-length curves. Using the derived distributions, we derive the optimal threshold on the saliency for discriminating between figure and background and bound the saliency-based figure-from-ground performance.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Berengolts, A (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	aer@cs.technion.ac.il						Alter T, 1998, INT J COMPUT VISION, V27, P51, DOI 10.1023/A:1007953729443; Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; Amir A, 1999, COMPUT VIS IMAGE UND, V76, P7, DOI 10.1006/cviu.1999.0786; [Anonymous], 1985, PERCEPTUAL ORG VISUA; Berengolts A, 2001, INT J COMPUT VISION, V41, P195, DOI 10.1023/A:1011108121495; BERENGOLTS A, 2004, CIS200403 TECHN; BERENGOLTS A, 2004, P C COMPUTER VISION, V2, P543; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHARLIER C, 1931, TRAITE; Dubuc B, 2001, INT J COMPUT VISION, V42, P83, DOI 10.1023/A:1011141618114; ELDER JH, 1996, P 4 EUR C COMP VIS, V1, P399; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GOLUBCHYCK R, 2006, MSC200607 TECHN; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1992, P EUR C COMP VIS ECC, P58; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; KOCH C, 1985, HUM NEUROBIOL, V4, P219; LINDENBAUM M, 2000, P ECCV, P257; Marr D., 1982, VISION COMPUTATIONAL; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; Neisser U., 1967, COGNITIVE PSYCHOL; Palmer S.E., 1999, VISION SCI PHOTONS P; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; REN X, 2005, P 10 IEEE INT C COMP, V2, P1214; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; SARKAR S, 1993, IEEE T SYST MAN CYB, V23, P382, DOI 10.1109/21.229452; Saund E, 1999, COMPUT VIS IMAGE UND, V76, P70, DOI 10.1006/cviu.1999.0789; SHAASHUA A, 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Sharon E, 2000, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2000.855801; Shen J., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P109; STUART A, 2003, KENDALLS ADV THEORY, V1; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; WILLIAMS L, 1998, P ECCV, P432; WILLIAMS LR, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P408, DOI 10.1109/ICCV.1995.466910; [No title captured]	40	13	13	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					1973	1990		10.1109/TPAMI.2006.249	http://dx.doi.org/10.1109/TPAMI.2006.249			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108371				2022-12-18	WOS:000241195700007
J	Kadyrov, A; Petrou, M				Kadyrov, Alexander; Petrou, Maria			The "invaders" algorithm: Range of values modulation for accelerated correlation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image correlation; image filtering; template matching; accelerated; correlation		In this paper, we present an algorithm that allows the simultaneous calculation of several cross correlations. The algorithm works by shifting the range of values of different images/signals to occupy different orders of magnitude and then combining them to form a single composite image/signal. Because additional signals are placed in the space usually occupied by a single signal, we call this the "invaders algorithm," to imply that extra signals invade the space that normally belongs to a single signal. After correlation is performed, the individual results are recovered by performing the inverse operation. The limitations of the algorithm are imposed by the finite length of the mantissa of the hardware used, the precision of the algorithm that performs the cross correlation ( e. g., the precision of the fast Fourier transform (FFT)) and by the actual values of the images/signals that are to be combined. The algorithm does not require any special hardware or special FFT algorithm. For typical 256 x 256 images, an acceleration by a factor of at least two in the calculation of their cross correlations is guaranteed using an ordinary PC or a laptop. As for smaller sized templates, tenfold accelerations may be achieved.	Univ London Imperial Coll Sci & Technol, Dept Elect & Elect Engn, London SW7 2AZ, England	Imperial College London	Kadyrov, A (corresponding author), Univ London Imperial Coll Sci & Technol, Dept Elect & Elect Engn, Exhibit Rd, London SW7 2AZ, England.	a.kadyrov@imperial.ac.uk; maria.petrou@imperial.ac.uk		Anam, Mohammad Ashraful/0000-0001-7349-3772				BAILEY DH, 2005, IEEE COMPUTING SCI E, P54; CHICHEVA M, 2005, P 4 INT S IM SIGN PR, P15; Fitch AJ, 2005, IEEE T IMAGE PROCESS, V14, P1063, DOI 10.1109/TIP.2005.849767; FITCH AJ, 2002, P BMVC, V1, P133; GUPTA A, 1993, IEEE T PARALL DISTR, V4, P922, DOI 10.1109/71.238626; Kadyrov A, 2003, IMAGE VISION COMPUT, V21, P1135, DOI 10.1016/j.imavis.2003.08.013; Kadyrov A, 2004, ELECTRON LETT, V40, P663, DOI 10.1049/el:20040370; Vanwormhoudt MC, 1998, SIGNAL PROCESS, V67, P189, DOI 10.1016/S0165-1684(98)00036-X	8	13	15	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1882	1886		10.1109/TPAMI.2006.234	http://dx.doi.org/10.1109/TPAMI.2006.234			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063693				2022-12-18	WOS:000240443400016
J	Hua, G; Liu, ZC; Zhang, ZY; Wu, Y				Hua, Gang; Liu, Zicheng; Zhang, Zhengyou; Wu, Ying			Iterative local-global energy minimization for automatic extraction of objects of interest	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variational energy; level set; semisupervised learning	SNAKES	We propose a novel global-local variational energy to automatically extract objects of interest from images. Previous formulations only incorporate local region potentials, which are sensitive to incorrectly classified pixels during iteration. We introduce a global likelihood potential to achieve better estimation of the foreground and background models and, thus, better extraction results. Extensive experiments demonstrate its efficacy.	Microsoft Live Labs, Redmond, WA 98052 USA; Microsoft Res, Multimedia Collaborat Grp, Redmond, WA 98052 USA; Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Microsoft; Microsoft; Northwestern University	Hua, G (corresponding author), Microsoft Live Labs, 1 Microsoft Way, Redmond, WA 98052 USA.	ganghua@microsoft.com; zliu@microsoft.com; zhang@microsoft.com; yingwu@ece.northwestern.edu	Wu, Ying/B-7283-2009; zhang, zheng/HCH-9684-2022					Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CORDUNEANU A, 2002, P UNC ART INT UAI, P111; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Jehan-Besson S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P408; Jehan-Besson S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P353, DOI 10.1109/ICCV.2001.937540; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442; Lawrence N. D., 2001, P 18 INT C MACH LEAR, P306; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Paragios N, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P67, DOI 10.1109/ICCV.2001.937500; PARAGIOS N, 1999, P IEEE C COMP VIS PA, V1, P1034; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rousson M, 2003, PROC CVPR IEEE, P699; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Tsai A, 2000, PROC CVPR IEEE, P119, DOI 10.1109/CVPR.2000.855808; YEZZI JA, 1999, P IEEE INT C COMP VI, P898; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZHU X, 2000, P 4 INT C AUT FAC GE, P446	26	13	17	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1701	1706		10.1109/TPAMI.2006.209	http://dx.doi.org/10.1109/TPAMI.2006.209			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986550				2022-12-18	WOS:000239605500013
J	Heidemann, G				Heidemann, G			The principal components of natural images revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical image representation; feature measurement; feature representation; texture; color scene analysis; shape; computer vision; computational models of vision; connectionism and neural nets	RECEPTIVE-FIELDS; VISUAL-CORTEX; COLOR INFORMATION; FILTERS; SCENES; CELLS; MODEL	This paper investigates the principal components (PCs) of natural gray and color images. A horizontal and vertical typology of PCs is found which leads to the identification of groups of basis functions for steerable bandpass filters. Using this system, the contribution of spatio-chromatic structure to the total variance can be quantified for selected spatial frequencies.	Florida State Univ, Florida A&M Univ, Dept Elect & Comp Engn, Tallahassee, FL 32310 USA	State University System of Florida; Florida A&M University; Florida State University	Heidemann, G (corresponding author), Florida State Univ, Florida A&M Univ, Dept Elect & Comp Engn, 2525 Pottsdamer St, Tallahassee, FL 32310 USA.	gh@eng.fsu.edu						Barlow H., 1961, SENSORY COMMUNICATIO, P217; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; BUCHSBAUM G, 1983, PROC R SOC SER B-BIO, V220, P89, DOI 10.1098/rspb.1983.0090; DEVALOIS RL, 1982, VISION RES, V22, P545, DOI 10.1016/0042-6989(82)90113-4; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gegenfurtner K, 2001, NAT NEUROSCI, V4, P339, DOI 10.1038/85963; Hall D., 2000, Machine Graphics & Vision, V9, P341; HANCOCK PJB, 1992, NETWORK-COMP NEURAL, V3, P61, DOI 10.1088/0954-898X/3/1/008; Heidemann G, 2004, COMPUT VIS IMAGE UND, V94, P234, DOI 10.1016/j.cviu.2003.10.009; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Johnson EN, 2001, NAT NEUROSCI, V4, P409, DOI 10.1038/86061; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; MacKay DJC, 1990, NETWORK-COMP NEURAL, V1, P257, DOI 10.1088/0954-898X/1/3/001; Marr D., 1982, VISION COMPUTATIONAL; *NOV DEV CORP, 2002, ART EXPL PHOT GALL; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; Petkov N, 1997, BIOL CYBERN, V76, P83, DOI 10.1007/s004220050323; Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Tailor DR, 2000, VISION RES, V40, P2671, DOI 10.1016/S0042-6989(00)00105-X; TOLHURST DJ, 1992, OPHTHAL PHYSL OPT, V12, P229, DOI 10.1111/j.1475-1313.1992.tb00296.x; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wachtler T, 2001, J OPT SOC AM A, V18, P65, DOI 10.1364/JOSAA.18.000065	25	13	13	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					822	826		10.1109/TPAMI.2006.107	http://dx.doi.org/10.1109/TPAMI.2006.107			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640267				2022-12-18	WOS:000235885700013
J	Soldea, O; Elber, G; Rivlin, E				Soldea, O; Elber, G; Rivlin, E			Global segmentation and curvature analysis of volumetric data sets using trivariate B-spline functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian and mean curvature; symbolic computation; global analysis; segmentation		This paper presents a method to globally segment volumetric images into regions that contain convex or concave (elliptic) iso-surfaces, planar or cylindrical (parabolic) iso-surfaces, and volumetric regions with saddle-like (hyperbolic) iso-surfaces, regardless of the value of the iso-surface level. The proposed scheme relies on a novel approach to globally compute, bound, and analyze the Gaussian and mean curvatures of an entire volumetric data set, using a trivariate B-spline volumetric representation. This scheme derives a new differential scalar field for a given volumetric scalar field, which could easily be adapted to other differential properties. Moreover, this scheme can set the basis for more precise and accurate segmentation of data sets targeting the identification of primitive parts. Since the proposed scheme employs piecewise continuous functions, it is precise and insensitive to aliasing.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Soldea, O (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	octavian@cs.technion.ac.il; gershon@cs.technion.ac.il; ehudr@cs.technion.ac.il						BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Bracewell R., 1986, FOURIER TRANSFORM IT; CORLESS RM, 1974, ESSENTIAL MAPLE 7 IN; Dahlquist G., 1974, NUMERICAL METHODS; Dell'Acqua F, 2002, IEEE T PATTERN ANAL, V24, P569, DOI 10.1109/34.993564; Dickinson SJ, 1997, IEEE T PATTERN ANAL, V19, P259, DOI 10.1109/34.584104; ELBER G, 2006, IRIT VERSION 9 0; ELBER G, 2001, P 6 ACM S SOL MOD CO, P171; Far G, 1996, CURVES SURFACES COMP; FITZGIBBON AW, 1997, COMPUTER AIDED DESIG, V29; FLYNN PJ, 1989, IEEE P C COMP VIS PA; GOLUB GH, 1996, MATRIX COMPUTATIONS, P180; Groller E., 2000, P SPRING C COMP GRAP, P58; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; HOFFMANN CM, 2005, COMPUTER AIDED DESIG, V2; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; HORN RA, 1985, MATRIX ANAL, P336; Interrante V., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P109, DOI 10.1145/258734.258796; Itoh T, 1995, IEEE T VIS COMPUT GR, V1, P319, DOI 10.1109/2945.485619; KAUFMAN I, 1999, IEEE T AUTOMATIC CON, V14; KINDLMANN G, 2003, IEEE VISUALIZATI OCT; Klette R., 2004, DIGITAL GEOMETRY GEO; Lakare S, 2000, IEEE VISUAL, P39; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883; MCINERNEY T, 1995, COMPUTERIZED MED IMA, V19; Spivak M., 1970, COMPREHENSIVE INTRO, V1; Sutton M, 1998, IMAGE VISION COMPUT, V16, P745, DOI 10.1016/S0262-8856(98)00069-9; Tang CK, 2002, IEEE T PATTERN ANAL, V24, P858, DOI 10.1109/TPAMI.2002.1008395; TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840; THIRION JP, 1995, COMPUT VIS IMAGE UND, V61, P190, DOI 10.1006/cviu.1995.1015; THIRION JP, 1992, 1672 UN RECH INR ROC; TRUCCO E, 1995, IEEE T PATTERN ANAL, V17, P177, DOI 10.1109/34.368172; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131; WEINKAUF T, 2002, J INT C CENTR EUR CO, P507; WEINSHALL D, 1991, IEEE T PATTERN ANAL, V13, P1236, DOI 10.1109/34.106997; WERTZ HJ, 1965, IEEE T AUTOMATIC CON, V10; Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806; Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0; [No title captured]; 2006, MAPLE C CODE GAUSSIA	43	13	15	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					265	278		10.1109/TPAMI.2006.36	http://dx.doi.org/10.1109/TPAMI.2006.36			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468622	Green Submitted			2022-12-18	WOS:000233824500008
J	Balakrishnan, N; Hariharakrishnan, K; Schonfeld, D				Balakrishnan, N; Hariharakrishnan, K; Schonfeld, D			A new image representation algorithm inspired by image submodality models, redundancy reduction, and learning in biological vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; feature representation; statistical models; clustering algorithms; machine learning; color	NATURAL IMAGES; LIGHTNESS	We develop a new biologically motivated algorithm for representing natural images using successive projections into complementary subspaces. An image is first projected into an edge subspace spanned using an ICA basis adapted to natural images which captures the sharp features of an image like edges and curves. The residual image obtained after extraction of the sharp image features is approximated using a mixture of probabilistic principal component analyzers (MPPCA) model. The model is consistent with cellular, functional, information theoretic, and learning paradigms in visual pathway modeling. We demonstrate the efficiency of our model for representing different attributes of natural images like color and luminance. We compare the performance of our model in terms of quality of representation against commonly used basis, like the discrete cosine transform (DCT), independent component analysis ( ICA), and principal components analysis (PCA), based on their entropies. Chrominance and luminance components of images are represented using codes having lower entropy than DCT, ICA, or PCA for similar visual quality. The model attains considerable simplification for learning from images by using a sparse independent code for representing edges and explicitly evaluating probabilities in the residual subspace.	Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA; Motorola India Elect Ltd, Bangalore 560093, Karnataka, India; Univ Illinois, Dept Elect & Comp Engn, Chicago, IL 60607 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Balakrishnan, N (corresponding author), Univ Illinois, Dept Bioengn, 851 S Morgan St,Room 218,M-C 063, Chicago, IL 60607 USA.	nikhilbalakrishnan@gmail.com; coonoor@gmail.com; ds@ece.uic.edu						Abbott L.F., 1999, NEURAL CODES DISTRIB; BALLARD DH, 1999, INTRO NATURAL COMPUT, P46; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow H., 1961, SENSORY COMMUNICATIO, P217; Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295; Cover T., 1991, ELEMENTS INFORM THEO, V1, P12, DOI DOI 10.1002/0471200611.CH2; DAUGMAN J, 2003, HDB BRAIN THEORY NEU, P457; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; GONZALEZ RC, 1993, DIGITAL IMAGE PROCEW; GROSSBERG S, 1988, PERCEPT PSYCHOPHYS, V43, P241, DOI 10.3758/BF03207869; HURLBERT A, 1986, J OPT SOC AM A, V3, P1684, DOI 10.1364/JOSAA.3.001684; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Hyvarinen A, 2001, NEURAL COMPUT, V13, P1527, DOI 10.1162/089976601750264992; Hyvarinen A., FASTICA MATLAB PACKA; Kentridge R, 2003, HDB BRAIN THEORY NEU, P230; Kruger N, 1998, NEURAL PROCESS LETT, V8, P117, DOI 10.1023/A:1009688428205; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; McArthur JA, 1999, VISION RES, V39, P1199, DOI 10.1016/S0042-6989(98)00216-8; NABNEY I, 2003, NETLAB NEURAL NETWOR; NEUMANN H, 2003, HDB BRAIN THEORY NEU, P271; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PARADISO MA, 1991, VISION RES, V31, P1221, DOI 10.1016/0042-6989(91)90047-9; SNELL RS, 1997, CLIN NEUROANATOMY ME, P702; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728	25	13	13	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1367	1378		10.1109/TPAMI.2005.170	http://dx.doi.org/10.1109/TPAMI.2005.170			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173182				2022-12-18	WOS:000230463300002
J	Regentova, E; Latifi, S; Deng, S; Yao, DS				Regentova, E; Latifi, S; Deng, S; Yao, DS			An algorithm with reduced operations for connected components detection in ITU-T group 3/4 coded images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image; CCITT (ITU) Group 3/4 compression; MH/MR/MMR; connected components	CLASSIFICATION	An algorithm, which performs connected components detection in the course of decoding ITU-T (former CCITT) facsimile Group 3/4, i.e., MH/MR/MMR compressed images is presented. New definitions of mode color and a new transition element are introduced that allow MR/MMR codes to analyze and derive information about connection of black runs in two adjacent scan lines in the course of decoding. The experiments on the standard set of eight CCITT documents have shown that, on the average, the complexity of direct processing of MR/MMR codes is lower by a factor of 20 and 2.5 than that for raster images and MH codes processing respectively. Data structures for image vector description are discussed.	Univ Nevada, Dept Elect & Comp Engn, Las Vegas, NV 89154 USA; Motorola Inc, Schaumburg, IL 60196 USA	Nevada System of Higher Education (NSHE); University of Nevada Las Vegas	Regentova, E (corresponding author), Univ Nevada, Dept Elect & Comp Engn, 4505 Maryland Pkwy, Las Vegas, NV 89154 USA.							AKIYAMA T, 1990, PATTERN RECOGN, V23, P1141, DOI 10.1016/0031-3203(90)90112-X; *CSC, CCITT STAND FAX IM; HINDS SC, 1990, P 10 INT C PATT REC, V1, P464; Hull JJ, 1997, PROC INT CONF DOC, P308, DOI 10.1109/ICDAR.1997.619862; Kanai J., 1998, International Journal on Document Analysis and Recognition, V1, P43; MAA CY, 1994, CVGIP-GRAPH MODEL IM, V56, P352, DOI 10.1006/cgip.1994.1032; Nagy G., 1988, P ACM C DOC PROC SYS, P169; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; RONSE C, 1984, RES STUDIES; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Shima Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P655, DOI 10.1109/ICPR.1990.118183; Shima Y., 1989, Systems and Computers in Japan, V20, P91, DOI 10.1002/scj.4690200610; Spitz A. L., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval, P303; SPITZ AL, 1992, P 1 S DOC AN INF RET, P11; *TERM EQ PROT TEL, 1985, CCITT REC T 6 FACS C, V7; *TERM EQ PROT TEL, 1985, CCITT REC T 4 STAND, V7; Toyoda J., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1113; TSUIKI T, 1982, P C REC GLOBECOM 82; WANG D, 1989, COMPUT VISION GRAPH, V47, P327, DOI 10.1016/0734-189X(89)90116-3	21	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1039	1047		10.1109/TPAMI.2002.1023801	http://dx.doi.org/10.1109/TPAMI.2002.1023801			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100003
J	Govindaraju, V; Slavik, P; Xue, HH				Govindaraju, V; Slavik, P; Xue, HH			Use of lexicon density in evaluating word recognizers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier combination; handwritten word recognizer; lexicon density; performance prediction; edit distances	RECOGNITION	We have developed the notion of lexicon density as a metric to measure the expected accuracy of handwritten word recognizers. Thus far, researchers have used the size of the lexicon as a gauge for the difficulty of the handwritten word recognition task. For example, the literature mentions recognizers with accuracy for lexicons of sizes 10, 100, 1,000, and so forth, implying that the difficulty of the task increases (and, hence, recognition accuracy decreases) with increasing lexicon sizes across recognizers. Lexicon density is an alternate measure which is quite dependent on the recognizer. There are many applications such as address interpretation where such a recognizer dependent measure can be useful. We have conducted experiments with two different types of recognizers. A segmentation-based and a grapheme-based recognizer have been selected to show how the measure of lexicon density can be developed in general for any recognizer. Experimental results show that the lexicon density measure described is more suitable than lexicon size or a simple string edit distance.	SUNY Buffalo, Dept Comp Sci & Engn, CEDAR, Amherst, NY 14228 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Govindaraju, V (corresponding author), SUNY Buffalo, Dept Comp Sci & Engn, CEDAR, Amherst, NY 14228 USA.							BAHL LR, 1983, IEEE T PATTERN ANAL, V5; HAMMING R, 1982, CODING INFORMATION T; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; Seni G, 1996, PATTERN RECOGN, V29, P405, DOI 10.1016/0031-3203(95)00102-6; STEPEHEN G, 2000, STRING SEARCHING ALG; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; XUE H, 2001, P INT C DOC AN REC	8	13	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					789	800		10.1109/TPAMI.2002.1008385	http://dx.doi.org/10.1109/TPAMI.2002.1008385			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300007
J	Lee, MS; Medioni, G; Mordohai, P				Lee, MS; Medioni, G; Mordohai, P			Inference of segmented overlapping surfaces from binocular stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						binocular stereo; tensor voting; perceptual grouping; surface inference	CURVES; SPARSE	We present an integrated approach to the derivation of scene descriptions from a pair of stereo images, where the steps of feature correspondence and surface reconstruction are addressed within the same framework, Special attention is given to the development of a methodology with general applicability. In order to handle the issues of noise, lack of image features, surface discontinuities, and regions visible in one image only, we adopt a tensor representation for the data and introduce a robust computational technique called tensor voting for information propagation. The key contributions of this paper are twofold: First, we introduce "saliency" instead of correlation scores as the criterion to determine the correctness of matches and the integration of feature matching and structure extraction. Second, our tensor representation and voting as a tool enables us to perform the complex computations associated with the formulation of the stereo problem in three dimensions at a reasonable computational cost, We illustrate the steps on an example, then provide results on both random dot stereograms and real stereo pairs, all processed with the same parameter set.	Philips Elect N Amer Corp, Philps Res, Briarcliff Manor, NY 10510 USA; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA; Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA	Philips; Philips Research; University of Southern California; University of Southern California	Lee, MS (corresponding author), Philips Elect N Amer Corp, Philps Res, 345 Scarborough Rd, Briarcliff Manor, NY 10510 USA.	Mi-Suen.Lee@Philips.com; medioni@iris.usc.edu; mordohai@iris.usc.edu	Mordohai, Philippos/B-8480-2008					BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; BURT P, 1980, PERCEPTION, V9, P671, DOI 10.1068/p090671; CHEN Q, 1999, P COMP VIS PATT REC, V1, P29; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Fua P, 1997, INT J COMPUT VISION, V24, P19, DOI 10.1023/A:1007918123901; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; GRANLUND GH, 1995, SINGAL PROCESSING CO; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ISHIKAWA H, 1998, P EUR C COMP VIS, P232; JULESZ B, 1960, AT&T TECH J, V39, P1125, DOI 10.1002/j.1538-7305.1960.tb03954.x; Julesz B., 1995, DIALOGUES PERCEPTION; KUNTSSON H, 1989, P 6 SCAND C IM AN, P244; Lee MS, 1998, PROC CVPR IEEE, P346, DOI 10.1109/CVPR.1998.698629; Lee MS, 1999, COMPUT VIS IMAGE UND, V76, P54, DOI 10.1006/cviu.1999.0787; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Marr D., 1982, VISION COMPUTATIONAL; Medioni G., 2000, COMPUTATIONAL FRAMEW; NALWA S, 1993, GUIDED TOUR COMPUTER; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; OLSEN SI, 1990, IEEE T PATTERN ANAL, V12, P309, DOI 10.1109/34.49055; ROBERT L, 1996, P EUR C COMP VIS, P439; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Sara R, 1997, PROC CVPR IEEE, P852, DOI 10.1109/CVPR.1997.609427; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Tang CK, 1998, IEEE T PATTERN ANAL, V20, P1206, DOI 10.1109/34.730555; TANG CK, IN PRESS IEEE T PATT; Wei GQ, 1998, IEEE T PATTERN ANAL, V20, P1143, DOI 10.1109/34.730551; WESTIN CF, 1994, THESIS LINKOEPING U; YUILLE AL, 1984, 77 AI MIT; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	40	13	13	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					824	837		10.1109/TPAMI.2002.1008388	http://dx.doi.org/10.1109/TPAMI.2002.1008388			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300010
J	Murua, A				Murua, A			Upper bounds for error rates of linear combinations of classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						exponential bounds; weakly dependent classifiers; classification trees; machine learning	EMPIRICAL PROCESSES; INEQUALITIES; TREES	A useful notion of weak dependence between many classifiers constructed with the same training data is introduced. It is shown that if both this weak dependence is low and the expected margins are large, then decison rules based on linear Combinations of these classifiers can achieve error rates that decrease exponentially fast. Empirical results with randomized trees and trees constructed via boosting and bagging show that weak dependence is present in these type of trees. Furthermore, these results also suggest that there is a trade-off between weak dependence and expected margins, in the sense that to compensate for low expected margins, there should be low mutual dependence between the classifiers involved in the linear combination.	Insightful Corp, Seattle, WA 98109 USA		Murua, A (corresponding author), Insightful Corp, 1700 Westlake Ave N,Suite 500, Seattle, WA 98109 USA.	amurua@insightful.com						ALEXANDER KS, 1984, ANN PROBAB, V12, P1041, DOI 10.1214/aop/1176993141; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; AMIT Y, 2001, COMMUNICATION; AMIT Y, 2000, IEEE T SPEECH AUDIO; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Breiman L, 1999, 547 U CAL BERK DEP S; Breiman L., 1996, 460 U CAL BERK DEP S; Drucker H, 1996, ADV NEUR IN, V8, P479; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FRIEDMAN J, 2000, ANN STAT; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T.J., 1990, GEN ADDITIVE MODELS, V43; MITCHELL TOM M., 1997, MACH LEARN, P2; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Ripley BD., 1996; ROUSSAS GG, 1987, STOCH ANAL APPL, V5, P61; ROUSSAS GG, 1997, FESTSCHRIFT LUCIEN L, P337; Schapire R.E., 1997, MACH LEARN P 14 INT; TALAGRAND M, 1994, ANN PROBAB, V22, P28, DOI 10.1214/aop/1176988847; Tibshirani R., 1996, BIAS VARIANCE PREDIC; *UCI, 2000, UCI MACHINE LEARNING; Van Der VaartJon A., 1996, WEAK CONVERGENCE EMP	27	13	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					591	602		10.1109/34.1000235	http://dx.doi.org/10.1109/34.1000235			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU					2022-12-18	WOS:000175187800003
J	Greenspan, MA				Greenspan, MA			Geometric probing of dense range data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose determination; object recognition; geometric probing; decision tree; template matching; range image	RECOGNIZING 3-D OBJECTS; DECISION TREES; RECOGNITION; ORIENTATION; REPRESENTATION; SYSTEM; VISION; IMAGE	A new method is presented for the efficient and reliable pose determination of 3D objects in dense range image data. The method is based upon a minimalistic Geometric Probing strategy that hypothesizes the intersection of the object with some selected image point, and searches for additional surface data at locations relative to that point. The strategy is implemented in the discrete domain as a binary decision tree classifier. The tree leaf nodes represent individual voxel templates of the model, with one template per distinct model pose. The internal nodes represent the union of the templates of their descendant leaf nodes. The union of all leaf node templates is the complete template set of the model over its discrete pose space. Each internal node also encodes a single voxel which is the most common element of its child node templates. Traversing the tree is equivalent to efficiently matching the large set of templates at a selected image seed location. The method was implemented and extensive experiments were conducted for a variety of combinations of tree designs and traversals under isolated, cluttered, and occluded scene conditions. The results demonstrated a tradeoff between efficiency and reliability. It was concluded that there exist combinations of tree design and traversal which are both highly efficient and reliable.	Queens Univ, Dept Elect & Comp Engn, Kingston, ON K7L 3N6, Canada	Queens University - Canada	Greenspan, MA (corresponding author), Queens Univ, Dept Elect & Comp Engn, 99 Univ Ave, Kingston, ON K7L 3N6, Canada.	michael.greenspan@ece.queensu.ca						Arkin EM, 1998, INT J COMPUT GEOM AP, V8, P343, DOI 10.1142/S0218195998000175; Barequet G., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P610, DOI 10.1109/ICPR.1994.577055; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BOWYER KW, 1990, P SOC PHOTO-OPT INS, V1395, P200; BROU P, 1984, INT J ROBOT RES, V3, P89, DOI 10.1177/027836498400300406; CHEN CH, 1989, IEEE T SYST MAN CYB, V19, P1535, DOI 10.1109/21.44070; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; COHEN L, 1994, INTERACTION, V12, P1; COLEMAN KG, 1987, GENE DEV, V1, P19, DOI 10.1101/gad.1.1.19; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; Garey M. R., 1974, Acta Informatica, V3, P347, DOI 10.1007/BF00263588; Greenspan M., 1998, Proceedings. Vision Interfaces '98, P181; Greenspan M, 1998, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.1998.698691; GREENSPAN M, 1999, ODIM99 3D IMAGING MO, P230; GREENSPAN M, 1999, THESIS CARLETON U; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; HENDERSON TC, 1984, PATTERN RECOGN LETT, V2, P235, DOI 10.1016/0167-8655(84)90030-8; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; IKEUCHI K, 1987, INT J COMPUT VISION, V1, P145, DOI 10.1007/BF00123163; Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P121, DOI 10.1109/IM.1997.603857; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; KRISHNAPURAM R, 1989, IEEE T PATTERN ANAL, V11, P1158, DOI 10.1109/34.42854; MORET BME, 1982, COMPUT SURV, V14, P593, DOI 10.1145/356893.356898; MORET BME, 1980, THESIS U TENNESSEE; MULLER Y, 1984, P 7 INT C PATT REC, P1101; RAMAPRIYAN HK, 1976, IEEE T COMPUT, V25, P66, DOI 10.1109/TC.1976.5009206; ROTH G, 1995, P 1995 ROB KNOWL BAS, P349; SHIRAI Y, 1972, PATTERN RECOGN, V4, P243, DOI 10.1016/0031-3203(72)90003-9; SKIENA SS, 1992, P IEEE, V80, P1364, DOI 10.1109/5.163406	35	13	13	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					495	508		10.1109/34.993557	http://dx.doi.org/10.1109/34.993557			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100006
J	Tang, YY; Yang, F; Liu, JM				Tang, YY; Yang, F; Liu, JM			Basic processes of Chinese character based on cubic B-spline wavelet transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						wavelet; cubic B-spline; character processing; compression; type zooming-in; typeface composition		In this paper, a novel approach based on cubic B-spline wavelet transform is proposed to process Chinese character including character compression, type zooming-in, and typeface composition. The basic idea is that a Chinese character is described by its contours which are represented by cubic B-spline functions, and each contour is decomposed into the details or the control points (wavelet coefficients) at different resolution levels. For character compression, there are two methods, one directly treats the details of wavelet coefficients and the other considers the subcurves piecing together at the different resolution levels. In the type zooming-in, the wavelet reconstruction is used to scale the Chinese character with arbitrary size and the wavelet filter is used to improve the quality of the enlarged type. For typeface composition, the new style typefaces of Chinese character are obtained by editing and modifying the details at different resolution levels. The concrete algorithms are also given in this paper as well as the experimental results.	Hong Kong Baptist Univ, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China; S Med Univ, Affiliated Hosp 2, Guangzhou 510282, Guangdon, Peoples R China	Hong Kong Baptist University; Southern Medical University - China	Tang, YY (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.	yytang@comp.hkbu.edu.hk						*AD SYST INC, 1991, AD TYP 1 FONT FORM; [Anonymous], [No title captured]; Barnett S, 1990, MATRICES METHODS APP; CAVANAUGH S, 1995, DIGITAL TYPE DESIGN; Chui CK, 1992, INTRO WAVELETS; HARALAMBOUS Y, 1998, P 7 INT C EL PUBL EP, P126; *MICR CORP, 1995, TRUETYPE 1 0 FONT FI; MOHANTY SK, 1998, P 7 INT C EL PUBL EP, P157; NAMANE A, 1990, IEEE T PATTERN ANAL, V12, P600, DOI 10.1109/34.56197; Pratt W. K., 1978, DIGITAL IMAGE PROCES; SCHNEIDER U, 1998, P 7 INT C EL PUBL EP, P109; SHAMIR A, 1998, P 7 INT C EL PUBL EP, P93; Stamm B., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P77, DOI 10.1007/BFb0053264; TANG YY, 1994, IEEE T IMAGE PROCESS, V3, P355, DOI 10.1109/83.298392; ULICHNEY RA, 1982, IEEE T PATTERN ANAL, V4, P331, DOI 10.1109/TPAMI.1982.4767254; Wright T, 1998, IEEE ANN HIST COMPUT, V20, P30, DOI 10.1109/85.667294	16	13	15	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1443	1448		10.1109/34.977567	http://dx.doi.org/10.1109/34.977567			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700009
J	Liang, JS; Phillips, IT; Haralick, RM				Liang, JS; Phillips, IT; Haralick, RM			An optimization methodology for document structure extraction on Latin character documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; statistical pattern analysis; text line extraction; performance evaluation	SEGMENTATION	In this paper, we give a formal definition of a document image structure representation and we formulate document image structure extraction as a partitioning problem: Finding an optimal solution partitioning the set of glyphs of an input document image into a hierarchical tree structure where entities within the hierarchy at each level have similar physical properties and compatable semantic labels. We present a unified methodology that is applicable to construction of document structures at different hierarchical levels. An iterative, relaxation-like method is used to find a partitioning solution that maximizes the probability of the extracted structure. All the probabilities used in the partioning process are estimated from an extensive training set of various kinds of measurements among the entities within the hierarchy. The off line probabilities estimated in the training then drive all decisions in the online document structure extraction. We have implemented a text line extraction algorithm using this framework. The algorithm was evaluated on the UW-III database of some 1,600 scanned document image pages. An area-overlap measure is used to find the correspondence between the detected entities and the ground-truth. For a total of 105,020 text lines, the text line extraction algorithm identifies and segments 104,773 correctly. an accuracy of 99.76 percent. The detail of the algorithm is presented in this paper.	Insightful Corp, Seattle, WA 98109 USA; CUNY Queens Coll, Dept Comp Sci, Flushing, NY 11367 USA; CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10016 USA	City University of New York (CUNY) System; Queens College NY (CUNY); City University of New York (CUNY) System	Liang, JS (corresponding author), Insightful Corp, 1700 Westlake Ave N,Suite 500, Seattle, WA 98109 USA.	jliang@insightful.com; yun@image.cs.qc.edu; haralick@gc.cuny.edu	Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				CHEN S, 1995, THESIS U WASHINGTON; CHEN S, 1995, P INT C DOC AN REC, P1153; Dengel A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P587, DOI 10.1109/ICDAR.1995.601965; Esposito F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P650, DOI 10.1109/ICDAR.1993.395653; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; GARRIS MD, 1995, P INT C IM PROC OCT, V3, P304; HA J, 1995, P DOC REC, V2, P140; Haralick R.M., 1992, COMPUTER ROBOT VISIO, V1; HARALICK RM, 1994, P IEEE COMP SOC C CO, P3852; Ittner D. J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P336, DOI 10.1109/ICDAR.1993.395720; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; Jensen F.V., 1996, INTRO BAYESIAN NETWO; KANAI J, 1995, IEEE T PATTERN ANAL, V17, P86, DOI 10.1109/34.368146; Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684; Liang J., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P278, DOI 10.1109/ACV.1996.572074; *MATHS, 1997, S PLUS GUID STAT; NAGY G, 1984, P 7 INT C PATT REC M, P347; PALUMBO PW, 1992, COMPUTER, V25, P34, DOI 10.1109/2.144438; Phillips I. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P478, DOI 10.1109/ICDAR.1993.395691; Phillips I. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P484, DOI 10.1109/ICDAR.1993.395690; PHILLIPS IT, 1996, USERS REFERENCE MANU, V3; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RANDRIAMASY S, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/CVPR.1994.323859; WANG SY, 1995, P 3 INT C DOC AN REC, P128	24	13	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2001	23	7					719	734		10.1109/34.935846	http://dx.doi.org/10.1109/34.935846			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	449TV					2022-12-18	WOS:000169704000003
J	Chang, CC; Tsai, WH				Chang, CC; Tsai, WH			Reliable determination of object pose from line features by hypothesis testing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D-to-2D; line features; object poses; hypothesis testing; reject option; reliable estimated poses	CORRESPONDENCES; ORIENTATION; POINT; 2-D	To develop a reliable computer vision system, the employed algorithm must guarantee good output quality. In this study, to ensure the quality of the pose estimated from line features, two simple test functions based on statistical hypothesis testing are defined. First, an error function based on the relation between the line features and some quality thresholds is defined. By using the first test function defined by a lower bound of the error function, poor input can be detected before estimating the pose. After pose estimation, the second test function can be used to decide if the estimated result is sufficiently accurate. Experimental results show that the first test function can detect input with low qualities or erroneous line correspondences and that the overall proposed method yields reliable estimated results.	Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan	National Yang Ming Chiao Tung University	Chang, CC (corresponding author), Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan.							CHEN SY, 1990, PATTERN RECOGN, V23, P859, DOI 10.1016/0031-3203(90)90132-5; Cho K, 1997, IEEE T PATTERN ANAL, V19, P1185, DOI 10.1109/34.632979; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; Horn R. A., 1986, MATRIX ANAL; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; KANATANI K, 1996, GEOMETRIC COMPUTATIO; KUMAR R, 1994, CVGIP-IMAG UNDERSTAN, V60, P313, DOI 10.1006/ciun.1994.1060; Lee CN, 1996, IMAGE VISION COMPUT, V14, P379, DOI 10.1016/0262-8856(95)01058-0; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; PHONG TQ, 1995, INT J COMPUT VISION, V15, P225, DOI 10.1007/BF01451742; Roussas GG., 1997, COURSE MATH STAT, V2; Taylor JR., 1982, INTRO ERROR ANAL, V2nd edition; YI SK, 1994, MACH VISION APPL, V7, P93, DOI 10.1007/BF01215805	16	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1235	1241		10.1109/34.809118	http://dx.doi.org/10.1109/34.809118			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100014
J	Syeda-Mahmood, T				Syeda-Mahmood, T			Indexing of technical line drawing databases	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image databases; technical line drawings; line-labeling; region selection; grouping; recognition; search	SCENES	Image indexing, namely, the problem of retrieving content information from images in response to queries, is a key problem underlying the operations in image databases. In this paper we present a method of indexing for 3D object queries in a database of a class of images called technical line drawings. Indexing is achieved as a combination of query-specific region selection and object recognition. The selection phase isolates relevant images and the regions in these images that are likely to contain the queried object. This is done using text information in the query and a grouping mechanism that is guaranteed to isolate single-object containing regions for the class of technical line drawing images. The grouping mechanism is an adaptation of Waltz relaxation to an extended junction set derived by analyzing the physically plausible ways in which interpretation lines interact with object contours. Model-based object recognition then confirms the presence of the part at the selected location using geometrical description of the queried 3D object. Results are shown that indicate that query-specific selection is very effective for reducing the search during indexing while lowering the chance of false positives and negatives.	IBM Corp, Almaden Res Ctr, San Jose, CA 95114 USA	International Business Machines (IBM)	Syeda-Mahmood, T (corresponding author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95114 USA.							Ah-Soon C., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P331, DOI 10.1109/ICDAR.1995.599006; BASRI R, 1991, AIMEMO1333 MIT; CHAKRAVARTY I, 1979, IEEE T PATTERN ANAL, V1, P202, DOI 10.1109/TPAMI.1979.4766906; Chandran S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P516, DOI 10.1109/ICDAR.1993.395683; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Das A. K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P347, DOI 10.1109/ICDAR.1995.599010; Dori D., 1993, Machine Vision and Applications, V6, P69, DOI 10.1007/BF01211932; FALK G, 1972, ARTIF INTELL, V3, P101, DOI 10.1016/0004-3702(72)90044-6; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; Green E., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P214, DOI 10.1109/ICDAR.1995.598979; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GUZMAN A, 1968, MACTR59 MIT; HARALICK RM, 1982, COMPUT VISION GRAPH, V20, P244, DOI 10.1016/0146-664X(82)90083-1; Hori O., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P218, DOI 10.1109/ICDAR.1995.598980; Hori O., 1993, Machine Vision and Applications, V6, P100, DOI 10.1007/BF01211934; HUFFMAN DA, 1977, MACH INTELL, V8, P493; KARVE A, 1994, LAN MAGAZINE     AUG, V9, P176; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P987; LAI CP, 1994, IEEE T PATTERN ANAL, V16, P848, DOI 10.1109/34.308483; Lee I., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P886, DOI 10.1109/ICDAR.1993.395595; LORENZ O, 1994, 3 ANN S DOC AN INF R, P461; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; ROBERTS LG, 1966, OPTICAL ELECTRO OPTI, P159; STRAFORINI M, 1992, IEEE T PATTERN ANAL, V14, P298, DOI 10.1109/34.121797; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Waltz D.L, 1972, AITR271 MIT; Watanabe T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P510, DOI 10.1109/ICDAR.1993.395684; Weiss M., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P335, DOI 10.1109/ICDAR.1995.599007; Winston P. H., 1984, ARTIFICIAL INTELLIGE; Yu B, 1995, P 3 INT C DOC AN REC, P803; ZURIER S, 1994, GOVT COMPUTER NEWS, V13, P6; 1994, SEYBOLD REPORT P MAY; 1994, WORKGROUP COMPUT AUG; 1994, DBMS             JAN	35	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					737	751		10.1109/34.784287	http://dx.doi.org/10.1109/34.784287			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000005
J	Descombes, X; Kruggel, F				Descombes, X; Kruggel, F			A Markov pixon information approach for low-level image description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						information; pixon; Markov random fields; image restoration; fMRI analysis	GIBBS RANDOM-FIELDS; MAXIMUM-ENTROPY; PARAMETER-ESTIMATION; RECONSTRUCTION; SEGMENTATION; RESTORATION	The problem of extracting information from an image which corresponds to early stage processing in vision is addressed. We propose a new approach (the MPI approach) which simultaneously provides a restored image, a segmented image and a map which reflects the local scale for representing the information. Embedded in a Bayesian framework, this approach is based on an information prior, a pixon model and two Markovian priors. This model based approach is oriented to detect and analyze small parabolic patches in a noisy environment. The number of clusters and their parameters are not required for the segmentation process. The MPI approach is applied to the analysis of Statistical Parametric Maps obtained from fMRI experiments.	Max Planck Inst Cognit Neurosci, Image Proc Grp, D-04103 Leipzig, Germany; Max Planck Inst Cognit Neurosci, Image Proc Grp, D-04103 Leipzig, Germany	Max Planck Society; Max Planck Society	Descombes, X (corresponding author), INRIA, 2004 Route Lucioles BP 93, F-06902 Sophia Antipolis, France.	xavier.descombes@sophia.inria.fr; kruggel@cns.mpg.de	Kruggel, Frithjof/M-9201-2016	Kruggel, Frithjof/0000-0003-3507-5662				BESAG J, 1974, ACAD ROYAL STAT SOC, V36, P721; Bullmore E, 1996, MAGN RESON MED, V35, P261, DOI 10.1002/mrm.1910350219; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Descombes X, 1998, IEEE T MED IMAGING, V17, P1028, DOI 10.1109/42.746636; Descombes X., 1997, Traitement du Signal, V14, P373; Descombes X., 1995, P 9 SCIA 95 UPPS SWE, V1, P349; DESCOMBES X, IN PRESS IEEE T IMAG; FRIEDEN BR, 1972, J OPT SOC AM, V62, P511, DOI 10.1364/JOSA.62.000511; Friston K J, 1994, Hum Brain Mapp, V1, P210, DOI 10.1002/hbm.460010306; FRISTON KJ, 1995, NEUROIMAGE, V2, P45, DOI 10.1006/nimg.1995.1007; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GULL SF, 1984, IEE PROC-F, V131, P646, DOI 10.1049/ip-f-1.1984.0099; KHINCHIN AI, 1957, MATH FDN INFORMATION; KRUGGEL F, 1998, IEEE WORKSH BIOM IM; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; Lange N, 1996, STAT MED, V15, P389, DOI 10.1002/(SICI)1097-0258(19960229)15:4<389::AID-SIM285>3.0.CO;2-J; LIANG ZR, 1994, IEEE T MED IMAGING, V13, P441, DOI 10.1109/42.310875; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; Metcalf TR, 1996, ASTROPHYS J, V466, P585, DOI 10.1086/177533; PINA RK, 1993, PUBL ASTRON SOC PAC, V105, P630, DOI 10.1086/133207; PUETTER RC, 1993, P SOC PHOTO-OPT INS, V1946, P405, DOI 10.1117/12.158693; Puetter RC, 1995, INT J IMAG SYST TECH, V6, P314, DOI 10.1002/ima.1850060405; Rabe-Hesketh S, 1997, Stat Methods Med Res, V6, P215, DOI 10.1191/096228097671764060; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; THOMPSON AM, 1991, IEEE T PATTERN ANAL, V13, P326, DOI 10.1109/34.88568; WON CS, 1992, COMPUT VIS GRAPH IMA, V4, P308; WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351; WORSLEY KJ, 1995, NEUROIMAGE, V2, P173, DOI 10.1006/nimg.1995.1023; WORSLEY KJ, 1992, J CEREBR BLOOD F MET, V12, P900, DOI 10.1038/jcbfm.1992.127	30	13	14	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					482	494		10.1109/34.771311	http://dx.doi.org/10.1109/34.771311			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD					2022-12-18	WOS:000080819100001
J	Csurka, G; Faugeras, O				Csurka, G; Faugeras, O			Algebraic and geometric tools to compute projective and permutation invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						uncalibrated stereo; projective and permutation invariants; indexation; projective reconstruction; cross ratio; Grassmann-Cayley algebra		This paper studies the computation of projective invariants in pairs of images from uncalibrated cameras and presents a detailed study of the projective and permutation invariants for configurations of points and/or lines. Two basic computational approaches are given, one algebraic and one geometric. In each case, invariants are computed in projective space or directly from image measurements. Finally, we develop combinations of those projective invariants which are insensitive to permutations of the geometric primitives of each of the basic configurations.	Univ Geneva, CUI, CH-1211 Geneva 4, Switzerland; INRIA Sophia Antipolis, F-06902 Sophia Antipois, France	University of Geneva	Csurka, G (corresponding author), Univ Geneva, CUI, 24 Rue Gen Dufour, CH-1211 Geneva 4, Switzerland.	Gabriela.Csurka@cui.unige.ch; faugeras@sophia.inria.fr						ASTROM K, 1995, P 9 SCAND C IM AN, P1053; CARLSSON S, 1994, LECT NOTES COMPUTER, V825, P145; Csurka G, 1998, IMAGE VISION COMPUT, V16, P3, DOI 10.1016/S0262-8856(97)00045-0; CSURKA G, 1997, LNCS, V1315, P207; CSURKA G, 1996, THESIS U NICE SOPHIA; DEVERNAY F, 1996, P C COMP VIS PATT RE; DOUBILET P, 1974, STUD APPL MATH, V53, P87; HARTLEY R, 1993, P DARPA IM UND WORKS, P737; HESTENES D, 1991, ACTA APPL MATH, V23, P25, DOI 10.1007/BF00046919; Horaud R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96, DOI 10.1109/ICCV.1998.710706; Horaud R, 1998, IEEE T ROBOTIC AUTOM, V14, P525, DOI 10.1109/70.704214; LASENBY J, 1996, P INT C PATT REC VIE; Meer P, 1998, INT J COMPUT VISION, V26, P137, DOI 10.1023/A:1007944826230; MORIN L, 1993, THESIS NATL POLYTECH; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; UENOHARA U, 1996, P IEEE INT C INT ROB, V2, P785; ZELLER C, 1994, P 12 INT C PATT REC; ZISSERMAN A, 1995, WORKSH REPR VIS SCEN, P93; [No title captured]	19	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					58	65		10.1109/34.745735	http://dx.doi.org/10.1109/34.745735			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900008
J	Bober, M; Petrou, M; Kittler, J				Bober, M; Petrou, M; Kittler, J			Nonlinear motion estimation using the supercoupling approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; motion segmentation; supercoupling approach; Markov random fields; stochastic relaxation		This paper presents the application of a very efficient multiresolution transformation, which is related to the renormalization group approach of physics, to the problem of motion segmentation. The proposed approach is much faster and yields much better results than the full resolution approach. The problem is formulated as one of global optimization where a cost function is constructed to combine the information obtained by various processors as well as the constraints we impose to the problem. The cost function is optimized using the supercoupling multiresolution approach.	Univ Surrey, Sch Elect Engn Informat Technol & Math, Guildford GU2 5XH, Surrey, England	University of Surrey	Bober, M (corresponding author), Univ Surrey, Sch Elect Engn Informat Technol & Math, Guildford GU2 5XH, Surrey, England.	m.bober@ee.surrey.ac.uk						BOBER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P947, DOI 10.1109/CVPR.1994.323931; GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HEITZ F, 1994, CVGIP-IMAG UNDERSTAN, V59, P125, DOI 10.1006/ciun.1994.1008; KONRAD J, 1990, IMAGE VISION COMPUT, V8, P304, DOI 10.1016/0262-8856(90)80007-G; MITICHE A, 1988, IEEE T PATTERN ANAL, V10, P943, DOI 10.1109/34.9116; NICHOLLS G, 1994, INT C PATT RECOG, P63, DOI 10.1109/ICPR.1994.577123; PEREZ P, 1992, P 17 IEE C AC SPEECH; PETROU M, 1993, COMPLEX STOCHASTIC S, P105; SCHROETER P, 1994, P EUR C COMP VIS, V2, P316; SINGH A, 1992, OPTIC FLOW COMPUTATI	11	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					550	555		10.1109/34.682185	http://dx.doi.org/10.1109/34.682185			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600011
J	Nguyen, TB; Oommen, BJ				Nguyen, TB; Oommen, BJ			Moment-preserving piecewise linear approximations of signals and images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						signal processing; image processing; sampling; approximation; moment-preserving approximations		Approximation techniques are an important aspect of digital signal and image processing. Many lossy signal compression procedures such as the Fourier transform and discrete cosine transform are based on the idea that a signal can be represented by a small number of transformed coefficients which are an approximation of the original. Existing approximation techniques approach this problem in either a time/spatial domain or transform domain, but not both. This paper briefly reviews various existing approximation techniques. Subsequently, we present a new strategy to obtain an approximation (f) over cap(x) of f(x) in such a way that it is reasonably close to the original function in the domain of the variable x, and exactly preserves some properties of the transformed domain. In this particular case, the properties of the transformed values that are preserved are geometric moments of the original function. The proposed technique has been applied to single-variable functions, two-dimensional planar curves, and two-dimensional images, and the results obtained are demonstrative.			Nguyen, TB (corresponding author), CARLETON UNIV,SCH COMP SCI,OTTAWA,ON K1S 5B6,CANADA.		Rohlf, F J/A-8710-2008; Oommen, B. John/P-6323-2017	Oommen, B. John/0000-0002-5105-1575				AHMED H, 1985, DISCRETE COSINE TRAN, P9; Akhiezer N.I, 1965, CLASSICAL MOMENT PRO; COSGRIF RL, 1960, 82011 ASTIA OH STAT; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; GLUSS B, 1962, INFORM CONTROL, V5, P261, DOI 10.1016/S0019-9958(62)90599-5; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; Henry Stone, 1961, MATH COMPUT, V15, P40, DOI DOI 10.1090/S0025-5718-1961-0119390-6; HIKLEBRAND FB, 1987, INTRO NUMERICAL ANAL; KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; NGUYEN TB, 1994, THESIS CARLETON U OT; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PHILLIPS GM, 1968, COMPUT J, V11, P211, DOI 10.1093/comjnl/11.2.211; PRUSINKIEWICZ P, 1985, VISUAL COMPUTER, P185; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; ROSIN PL, 1991, PATTERN RECOGN, V24, P643; TANIMOTO SL, 1979, COMPUT VISION GRAPH, V9, P72, DOI 10.1016/0146-664X(79)90083-2; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	21	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					84	91		10.1109/34.566816	http://dx.doi.org/10.1109/34.566816			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800011
J	Hull, JJ				Hull, JJ			Incorporating language syntax in visual text recognition with a statistical model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						text recognition; OCR; document recognition; document analysis; syntax; language syntax; HMM; hidden Markov model; character recognition	SPEECH RECOGNITION	The use of a statistical language model to improve the performance of an algorithm for recognizing digital images of handwritten or machine-printed text is discussed. A word recognition algorithm first determines a set of words (called a neighborhood) from a lexicon that are visually similar to each input word image. Syntactic classifications for the words and the transition probabilities between those classifications are input to the Viterbi algorithm. The Viterbi algorithm determines the sequence of syntactic classes (the states of an underlying Markov process) for each sentence that have the maximum a posteriori probability, given the observed neighborhoods. The performance of the word recognition algorithm is improved by removing words from neighborhoods with classes that are not included on the estimated state sequence. An experimental application is demonstrated with a neighborhood generation algorithm that produces a number of guesses about the identity of each word in a running text. The use of zero, first and second order transition probabilities and different levels of noise in estimating the neighborhood are explored.			Hull, JJ (corresponding author), RICOH CALIF RES CTR,2882 SAND HILL RD,MENLO PK,CA 94025, USA.							BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; Carroll JohnB., 1967, COMPUTATIONAL ANAL P; DESILVA G, 1994, PATTERN RECOGN, P311; Francis W., 1982, FREQUENCY ANAL ENGLI; Good IJ., 1965, ESTIMATION PROBABILI; HO TK, 1992, MACH VISION APPL, P157; HULL JJ, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P124, DOI 10.1109/ICPR.1992.201736; HULL JJ, 1986, IEEE CS C COMP VIS P, P156; HULL JJ, 1986, P C CAN SOC COMP STU, P134; HULL JJ, 1986, IEEE EXPERT, V1, P6370; Jelinek F., 1990, READINGS SPEECH RECO, P450, DOI [DOI 10.1016/B978-0-08-051584-7.50045-0, 10.1016/B978-0-08-051584-7.50045-0]; SCHWARTZ R, 1990, P IEEE INT C AC SPEE, P81; SESHADRI N, 1989, P IEEE GLOBAL TELECO, P1534; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184, DOI 10.1109/TPAMI.1979.4766904	15	13	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1251	1256		10.1109/34.546261	http://dx.doi.org/10.1109/34.546261			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000010
J	Kim, IY; Yang, HS				Kim, IY; Yang, HS			An integration scheme for image segmentation and labeling based on Markov random field model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						region clustering; region labeling; Markov random field; energy function; optimization		This paper presents a unified approach for the image understanding problem based on the MRF models. In the proposed scheme, the image segmentation and interpretation processes cooperate in the simultaneous optimization process so that the erroneous segmentation and misinterpretation can be compensately recovered by continuous estimation of the unified energy function.	KOREA ADV INST SCI & TECHNOL,DEPT COMP SCI,YUSUNG KU,TAEJON 305701,SOUTH KOREA	Korea Advanced Institute of Science & Technology (KAIST)	Kim, IY (corresponding author), SAMSUNG ELECTR CO LTD,MICRO DEVICES BUSINESS,WONMI KU,82-3 DODANG DONG,KYONGGI DO 421130,SOUTH KOREA.		Yang, Hyun Seung/C-1984-2011					GAMBLE EB, 1989, IEEE T SYST MAN CYB, V19, P1576, DOI 10.1109/21.44072; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; KIM IY, 1994, PATTERN RECOGN LETT, V15, P969, DOI 10.1016/0167-8655(94)90028-0; KIM IY, 1993, PATTERN RECOGN, V26, P1695, DOI 10.1016/0031-3203(93)90024-Q; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552; OHTA Y, 1985, KNOWLEDGE BASED INTE; SUK M, 1983, PATTERN RECOGN, V16, P469, DOI 10.1016/0031-3203(83)90051-1; TENENBAUM JM, 1977, ARTIF INTELL, V8, P241, DOI 10.1016/0004-3702(77)90031-5; YAKIMOVSKY Y, 1973, P IJCAI, V3, P580	10	13	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					69	73		10.1109/34.476014	http://dx.doi.org/10.1109/34.476014			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500009
J	CHIEN, S; GRATCH, J; BURL, M				CHIEN, S; GRATCH, J; BURL, M			ON THE EFFICIENT ALLOCATION OF RESOURCES FOR HYPOTHESIS EVALUATION - A STATISTICAL APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MACHINE LEARNING; THE UTILITY PROBLEM; PLANNING AND SCHEDULING; PARAMETER ESTIMATION; ADAPTIVE PROBLEM-SOLVING		This paper considers the decision-making problem of selecting a strategy from a set of alternatives on the basis of incomplete information (e.g., a finite number of observations). At any time the system can adopt a particular strategy or decide to gather additional information at some cost. Balancing the expected utility of the new information against the cost of acquiring the information is the central problem we address. In our approach, the cost and utility of applying a particular strategy to a given problem are represented as random variables from a parametric distribution. By observing the performance of each strategy on a randomly selected sample of problems, we can use parameter estimation techniques to infer statistical models of performance on the general population of problems. These models can then be used to estimate: 1) the utility and cost of acquiring additional information and 2) the desirability of selecting a particular strategy from a set of choices. Empirical results are presented that demonstrate the effectiveness of the hypothesis evaluation techniques for tuning system parameters in a NASA antenna scheduling application.	UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90089; UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801	University of Southern California; University of Illinois System; University of Illinois Urbana-Champaign	CHIEN, S (corresponding author), CALTECH,JET PROP LAB,ADV INFORMAT SYST SECT,ARTIFICIAL INTELLIGENCE GRP,4800 OAK GROVE DR,PASADENA,CA 91109, USA.							BECHHOFER RE, 1954, ANN MATH STAT, V25, P16, DOI 10.1214/aoms/1177728845; BURINGER H, 1980, NONPARAMETRIC SEQUEN; CHIEN S, 1994, 2ND P INT C AI PLANN, P213; FAYYAD U, 1990, 10TH P NATL C ART IN, P104; GRATCH J, 1993, IUUCDCSR931806 U ILL; GRATCH J, 1992, P 10 NAT C ART INT, P235; GRATCH J, 1993, 10TH P INT C MACH LE, P135; GRATCH J, 1994, 12TH P NATL C ART IN, P576; GREINER R, 1992, P AAAI 92 SAN JOS CA, P241; HASEEB RM, 1985, MODERN STATISTICAL S; HOGG RV, 1978, INTRO MATH STATISTIC; IWAMOTO M, 1994, 2ND P INT C AI PLANN, P281; KREYSIG E, 1970, INTRO MATH STATISTIC; MARON O, 1994, ADV NEURAL INFORMATI; Moore Andrew W., 1994, MACH LEARN P 11 INT, P190; MUSICK R, 1993, 10 INT C MACH LEARN, P212; PAULSON E, 1964, ANN MATH STAT, V35, P174, DOI 10.1214/aoms/1177703739; PEREZ MA, 1994, 2ND P INT C AI PLANN, P323; RUSSELL S, 1989, 11TH P INT JOINT C A, P334; Russell S.J., 1991, DO RIGHT THING STUDI; Santner T.J., 1984, DESIGN EXPT RANKING; TURNBULL, 1984, DESIGN EXPT RANKING; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; YANG WN, 1991, OPER RES, V39, P583, DOI 10.1287/opre.39.4.583	24	13	13	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					652	665		10.1109/34.391408	http://dx.doi.org/10.1109/34.391408			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400002
J	DHOND, UR; AGGARWAL, JK				DHOND, UR; AGGARWAL, JK			STEREO MATCHING IN THE PRESENCE OF NARROW OCCLUDING OBJECTS USING DYNAMIC DISPARITY SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						STEREO; MATCHING; CORRESPONDENCE; IMAGE ANALYSIS; BINOCULAR; OCCLUSION; SHADOW REGION; DISPARITY POOL; 3D STRUCTURE; TRIANGULATION; DYNAMIC DISPARITY SEARCH	IMAGES	Most contemporary stereo correspondence algorithms impose global consistency among candidate match-points using Spatial Hierarchy Mechanism- (SHM) based techniques that rely on either the local support within a 2D neighborhood in the image plane and/or cooperative processes between multiple levels of a pixel-resolution or structural-description hierarchy. We analyze the stereo matching failures in SHM-based techniques in the presence of narrow occluding objects and propose the Dynamic Disparity Search (DDS) framework to reduce false-positive matches. Experiments with indoor and outdoor scenes demonstrate a significant reduction in the false-positive match rates of a DDS-based stereo algorithm as compared to those of two existing algorithms.	UNIV TEXAS, DEPT ELECT & COMP ENGN, COMP & VIS RES CTR, AUSTIN, TX 78712 USA	University of Texas System; University of Texas Austin	DHOND, UR (corresponding author), SCHLUMBERGER AUSTIN SYST CTR, 8311 N FM 620 RD, AUSTIN, TX 78726 USA.							AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BOULT TE, 1988, 1988 P IEEE C COMP V, P177; CHUNG RCK, 1991, JUN P IEEE C COMP VI; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; DHOND UR, 1992, THESIS U TEXAS AUSTI; EASTMAN RD, 1987, COMPUT VISION GRAPH, V39, P73, DOI 10.1016/S0734-189X(87)80203-7; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; Hoff W., 1989, IEEE T PATTERN ANAL; IYENGAR SS, 1991, AUTONOMOUS MOBILEROB, V1, P25; KIM YC, 1987, IEEE T ROBOTIC AUTOM, V3, P599; KIM YC, 1987, IEEE J ROBOT AUTOM, V3, P361; LIM HS, 1987, FEB P DARPA IM UND W, P234; LITTLE JJ, 1990, IMAGE VISION COMPUT, V8, P328, DOI 10.1016/0262-8856(90)80009-I; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI GG, 1980, COMP GRAPHICS IMG P, V13, P257; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; TANADE T, 1992, JAN P DARPA IMG UND	20	13	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					719	724		10.1109/34.391415	http://dx.doi.org/10.1109/34.391415			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400008
J	YI, JH; CHELBERG, DM				YI, JH; CHELBERG, DM			DISCONTINUITY-PRESERVING AND VIEWPOINT INVARIANT RECONSTRUCTION OF VISIBLE SURFACES USING A FIRST-ORDER REGULARIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						SURFACE RECONSTRUCTION; REGULARIZATION; INVARIANCE; PRESERVATION OF DISCONTINUITIES; ROBUSTNESS; INVARIANT MEASURE		This paper describes the application of a first order regularization technique to the problem of reconstruction of visible surfaces. Our approach is a computationally efficient first order method that simultaneously achieves approximate invariance and preservation of discontinuities. Our reconstruction method is also robust with respect to the smoothing parameter lambda. The robustness property to lambda allows a free choice of the smoothing parameter lambda without struggling to determine an optimal lambda that provides the best reconstruction. A new approximately invariant first order stabilizing function for surface reconstruction is obtained by employing a first order Taylor expansion of a nonconvex invariant stabilizing function that is expanded at the estimated value of the squared gradient instead of at zero. The data compatibility measure used is the squared perpendicular distance between the reconstructed surface and the constraint surface. This combination of stabilizing function and data compatibility measure is necessary to achieve invariance with respect to rotations and translations of the surfaces being reconstructed. Sharp preservation of discontinuities is achieved by a weighted sum of adjacent pixels such that the adjacent pixels that are more likely to be in different regions are less weighted. The results indicate that the proposed methods for surface reconstruction perform well on sparse noisy range data. In addition, the volume between two surfaces normalized by the surface area (interpreted as average distance between two surfaces) is proposed as an invariant measure for the comparison of reconstruction results.	PURDUE UNIV, SCH ELECT ENGN, GEOMETR MODELING & PERCEPTUAL PROC LAB, W LAFAYETTE, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus	YI, JH (corresponding author), UNIV CALIF RIVERSIDE, VISUALIZAT & INTELLIGENT SYST LAB, RIVERSIDE, CA 92521 USA.							BLAKE A, 1986, JUN P IEEE INT C COM, P22; BLAKE A, 1987, VISUAL RECONSTRUCTIO, P93; CHELBERG DM, 1991, NOV P SPIE INT C INT, P336; IKEUCHI K, 1987, P DARPA IMAGE UNDERS, P697; MUMFORD D, 1985, P IEEE INT C COMPUTE; STEVENSON RL, 1992, IEEE T PATTERN ANAL, V14, P897, DOI 10.1109/34.161349; Taubin G., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P658, DOI 10.1109/ICCV.1993.378149; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; YI J, 1993, TR9330 PURD U SCH EL; YI J, 1993, TR9331 PURD U SCH EL	10	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					624	629		10.1109/34.387510	http://dx.doi.org/10.1109/34.387510			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000008
J	TONG, F; LI, ZN				TONG, F; LI, ZN			RECIPROCAL-WEDGE TRANSFORM FOR SPACE-VARIANT SENSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ACTIVE VISION; EGO MOTION; MOTION STEREO; NAVIGATION; RECIPROCAL-WEDGE TRANSFORM; SPACE-VARIANT SENSING	ACTIVE VISION; STEREO; NAVIGATION; VERGENCE; MOTION; FOCUS; ROAD	The Reciprocal-Wedge Transform (RWT) is presented as an alternative to the log-polar transform which has been a popular model for space-variant sensing in computer vision, The log-polar transform provides efficient data reduction, It simplifies the centric rotational and scaling image transformations, However, it adversely complicates the linear features and translational transformations. The RWT facilitates an anisotropic variable resolution, Unlike the log-polar, its variable resolution is predominantly in one dimension, Consequently, the RWT preserves linearity of lines and translations in the original image, In this paper, a concise matrix representation of the RWT is presented, Its properties in geometrical transformations and data reduction are described, A projective model for the transform and a potential hardware RWT camera design are also illustrated. As examples of initial applications, the RWT is used for finding road directions in navigation, and for recovering depth in motion stereo, Two types of motion stereo are presented, namely the longitudinal and lateral motion stereo, In all cases, the RWT images offer much reduced and adequate data owing to the variable resolution, In road navigation, perspective distortion of the road image is readily corrected by the variable resolution of the RWT, In cases of the motion stereo, the correspondence problem in the RWT domain is reduced to a simpler problem of extracting collinear points in the epipolar plane, Preliminary experimental results from test images of road-vehicle navigation and moving objects on a miniature assembly line are demonstrated.	SIMON FRASER UNIV,SCH COMP SCI,BURNABY,BC V5A 1S6,CANADA	Simon Fraser University	TONG, F (corresponding author), UNIV COLL FRASER VALLEY,FAC COMP INFORMAT SYST,BURNABY,BC,CANADA.							AHUJA N, 1993, IEEE T PATTERN ANAL, V15, P1007, DOI 10.1109/34.254059; Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971; Carpenter RHS, 1977, MOVEMENTS EYES; DICKMANNS ED, 1992, IEEE T PATTERN ANAL, V14, P199, DOI 10.1109/34.121789; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FERMULLER C, 1993, INT J COMPUT VISION, V11, P165, DOI 10.1007/BF01469227; IKEUCHI K, 1994, INT J COMPUTER VISIO, V12, P137; KREIDER G, 1990, SPIE, V1381; KROTKOV E, 1993, INT J COMPUT VISION, V11, P187, DOI 10.1007/BF01469228; KUTULAKOS KN, 1994, INT J COMPUT VISION, V12, P113, DOI 10.1007/BF01421200; LOTUFO RA, 1990, ELECTRON COMMUN ENG, V2, P35, DOI 10.1049/ecej:19900010; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; ROJER AS, 1990, 10TH INT C PATT REC, V2, P278; SANDINI, 1990, 5TH P INT S ROB RES, P75; SANDINI G, 1980, COMPUTER GRAPHICS IM, P365; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SWAIN MJ, 1993, INT J COMPUT VISION, V11, P109, DOI 10.1007/BF01469224; THORPE C, 1988, IEEE T PATTERN ANAL, V10, P362, DOI 10.1109/34.3900; TISTARELLI M, 1993, IEEE T PATTERN ANAL, V15, P401, DOI 10.1109/34.206959; TONG F, 1994, IEEE INT CONF ROBOT, P1060, DOI 10.1109/ROBOT.1994.351217; TONG F, 1994, UNPUB IMAGE VISION C; TONG F, 1993, P INT C COMP VIS ICC, P330; TSOTSOS JK, 1992, INT J COMPUT VISION, V7, P127, DOI 10.1007/BF00128132; VANDERSPIEGEL J, 1989, VLSI IMPLEMENTATION, P189; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171	32	13	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					500	511		10.1109/34.391393	http://dx.doi.org/10.1109/34.391393			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394		Green Submitted			2022-12-18	WOS:A1995QW39400005
J	WU, YY; IYENGAR, SS; JAIN, R; BOSE, S				WU, YY; IYENGAR, SS; JAIN, R; BOSE, S			A NEW GENERALIZED COMPUTATIONAL FRAMEWORK FOR FINDING OBJECT ORIENTATION USING PERSPECTIVE TRIHEDRAL ANGLE CONSTRAINT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE FROM ANGLE; SHAPE FROM PERSPECTIVE PROJECTION; POSE ESTIMATION; EXTRINSIC CAMERA CALIBRATION; 3-D OBJECT RECOGNITION	3-D OBJECTS; VIEW	This paper investigates a fundamental problem of determing the position and orientation of a three-dimensional (3-D) object using single perspective image view. The technique is focused on the interpretation of trihedral angle constraint information. A new closed from solution based on Kanatani's formulation is proposed. The main distinguishing feature of our method over the original Kanatani's formulation is that our approach gives an effective closed form solution for general trihedral angle constraint. The method also provides a general analytic technique for dealing with a class of problem of shape from inverse perspective projection by using ''Angle to Angle Correspondence Information.'' A detailed implementation of our technique is presented. Different trihedral angle configurations were generated using synthetic data for testing our approach of finding object orientation by angle to angle constraint. We performed simulation experiments by adding some noise to the synthetic data for evaluating the effectiveness of our method in real situation. It has been found that our method worked effectively in a noisy environment which confirms that the method is robust in practical application.	UNIV CALIF SAN DIEGO,DEPT ELECT & COMP ENGN,LA JOLLA,CA 92093	University of California System; University of California San Diego	WU, YY (corresponding author), LOUISIANA STATE UNIV,DEPT COMP SCI,BATON ROUGE,LA 70803, USA.							BARNARD ST, 1985, COMPUT VISION GRAPH, V29, P87, DOI 10.1016/S0734-189X(85)90152-5; CHEN HH, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P374; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Haralick R. M., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P370, DOI 10.1109/CVPR.1989.37874; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANATANI K, 1988, COMPUT VISION GRAPH, V41, P28, DOI 10.1016/0734-189X(88)90115-6; Kanatani K., 1993, GEOMETRIC COMPUTATIO; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MULGAONKAR PG, 1989, CVGIP, V36, P298; Shakunaga T., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P671, DOI 10.1109/CCV.1988.590049; Wu Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P261, DOI 10.1109/CVPR.1993.340980	16	13	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					961	975		10.1109/34.329012	http://dx.doi.org/10.1109/34.329012			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700001
J	JONES, R; SVALBE, I				JONES, R; SVALBE, I			ALGORITHMS FOR THE DECOMPOSITION OF GRAY-SCALE MORPHOLOGICAL OPERATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						GRAY-SCALE MORPHOLOGY; MATHEMATICAL MORPHOLOGY; MORPHOLOGIC BASIS DECOMPOSITION	MULTIPLE STRUCTURING ELEMENTS; MATHEMATICAL MORPHOLOGY; ALGEBRAIC BASIS; FILTERS; OPENINGS; CLOSINGS; DESIGN	Te choice and detailed design of structuring elements plays a pivotal role in the morphologic processing of images. A broad class of morphological operations can be expressed as and equivalent supremum of erosions by a minimal set of basis filters. Diverse morphological operations can then be expressed in a single, comparable framework. The set of basis filters are data-like structures, each filter representing one type of local change possible under that operation. The data-level description of the basis set is a natural starting point for the design of morphological filters. This paper promotes the use of the basis decomposition of gray-scale morphological operations to design and apply morphological filters. A constructive proof is given for the basis decomposition of general gray-scale morphological operations, as are practical algorithms to find all of the basis set members for these operations. Examples are given to illustrate the algorithms presented.			JONES, R (corresponding author), MONASH UNIV, FAC SCI, DEPT PHYS, CLAYTON, VIC 3168, AUSTRALIA.							BANON GJF, MAY P INT WORKSH MAT, V51; Dougherty E., 1992, MATH MORPHOLOGY IMAG, DOI [10.2307/3618604, DOI 10.2307/3618604]; GADER PD, 1991, CVGIP-IMAG UNDERSTAN, V53, P288, DOI 10.1016/1049-9660(91)90016-I; Giardina C., 1988, MORPHOLOGICAL METHOD; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O; HEIJMANS HJAM, 1991, IEEE T PATTERN ANAL, V13, P568, DOI 10.1109/34.87343; JONES R, 1994, IEEE T PATTERN ANAL, V16, P438, DOI 10.1109/34.277599; JONES R, 1992, PATTERN RECOGN LETT, V13, P175, DOI 10.1016/0167-8655(92)90057-7; KHOSRAVI M, 1993, MAY P INT WORKSH MAT; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1153, DOI 10.1109/TASSP.1987.1165259; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; Matheron G., 1975, RANDOM SETS INTEGRAL; RONSE C, 1991, CVGIP-IMAG UNDERSTAN, V54, P74, DOI 10.1016/1049-9660(91)90076-2; Serra J, 1988, IMAGE ANAL MATH MORP; SHIH FYC, 1991, PATTERN RECOGN, V24, P195, DOI 10.1016/0031-3203(91)90061-9; SONG JS, 1990, COMPUT VISION GRAPH, V50, P308, DOI 10.1016/0734-189X(90)90150-T; STEVENSON RL, 1987, IEEE T CIRCUITS SYST, V34, P1292, DOI 10.1109/TCS.1987.1086067; SVALBE I, 1992, PATTERN RECOGN LETT, V13, P123, DOI 10.1016/0167-8655(92)90043-Y; SVALBE ID, 1991, IEEE T PATTERN ANAL, V13, P1214	20	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					581	588		10.1109/34.295903	http://dx.doi.org/10.1109/34.295903			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200003
J	LIANG, P; TAUBES, CH				LIANG, P; TAUBES, CH			ORIENTATION-BASED DIFFERENTIAL GEOMETRIC REPRESENTATIONS FOR COMPUTER VISION APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								Orientation-based representations (OBR's) have many advantages. Three orientation-based differential geometric representations in computer vision literature are critically examined. The three representations are the extended Gaussian image (EGI), the support-function-based representation (SFBR), and the generalized Gaussian image (GGI). The scope of unique representation, invariant properties from matching considerations, computation and storage requirements, and relations between the three representations are analyzed. A constructive proof of the uniqueness of the SFBR for smooth surfaces is given. It is shown that an OBR using any combination of locally defined descriptors is insufficient to uniquely characterize a surface. It must contain either global descriptors or ordering information to uniquely characterize a surface. The GGI as it was originally introduced in requires the recording of one principle vector. It is shown in this paper that this is unnecessary. This reduces the storage requirement of a GGI, therefore making it a more attractive representation. The key ideas of the GGI are to represent the multiple folds of a Gaussian image separately; the use of linked data structures to preserve ordering at all levels and between the folds; and the indexing of the data structures by the unit normal. It extends the EGI approach to a much wider range of applications.	HARVARD UNIV,DEPT MATH,CAMBRIDGE,MA 02138	Harvard University	LIANG, P (corresponding author), UNIV CALIF RIVERSIDE,COLL ENGN,RIVERSIDE,CA 92521, USA.							BESL PJ, 1988, SURFACES RANGE IMAGE; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; Koenderink J., 1990, SOLID SHAPE; Marr D., 1982, VISION; Nalwa V. S., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P40, DOI 10.1109/CCV.1988.589970; NALWA VS, 1989, INT J COMPUT VISION, V3, P131, DOI 10.1007/BF00126429; ONeill B., 1966, ELEMENTARY DIFFERENT; Ping Liang, 1990, Computer Vision, Graphics, and Image Processing, V52, P78, DOI 10.1016/0734-189X(90)90124-E; POGORELOV AV, 1978, MATH MONOGRAPHS, V35; SPIVAK M., 1979, COMPREHENSIVE INTRO, VI; Spivak M., 1979, COMPREHENSIVE INTRO, VIII; Spivak M., 1979, COMPREHENSIVE INTRO, VII; [No title captured]	13	13	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					249	258		10.1109/34.276124	http://dx.doi.org/10.1109/34.276124			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400005
J	WU, JX; CHAN, C				WU, JX; CHAN, C			ISOLATED WORD RECOGNITION BY NEURAL-NETWORK MODELS WITH CROSS-CORRELATION COEFFICIENTS FOR SPEECH DYNAMICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ARTIFICIAL NEURAL NETWORKS; AUTOMATIC SPEECH RECOGNITION; DENSITY ESTIMATION; DYNAMICS REPRESENTATION; GENERALIZED DELTA RULE; MAXIMUM LIKELIHOOD ESTIMATION		This paper presents an artificial neural network (ANN) for the purpose of speaker-independent isolated word speech recognition. The network consists of three subnets in concatenation. The static information within one frame of speech signal is processed in the probabilistic mapping subnet that converts an input vector of acoustic features into a probability vector whose components are estimated probabilities of the feature vector belonging to the phonetic classes that constitute the words in the vocabulary. The dynamics capturing subnet computes the first-order cross correlation between the components of the probability vectors to serve as the discriminative feature derived from the interframe temporal information of the speech signal. These dynamic features are passed for decisionmaking to the classification subnet, which is a multilayer perceptron (MLP). The architecture of these three subnets are described, and the associated adaptive learning algorithms are derived. Recognition results for a subset of the DARPA TIMIT speech database is reported. The correct recognition rate of the proposed ANN system is 95.5%, whereas that of the best of continuous hidden Markov model (HMM)-based systems is only 91.0%.	SHANGHAI JIAO TONG UNIV,INST IMAGE PROC & PATTERN RECOGNIT,SHANGHAI,PEOPLES R CHINA	Shanghai Jiao Tong University	WU, JX (corresponding author), UNIV HONG KONG,DEPT COMP SCI,HONG KONG,HONG KONG.							ALMEIDA LB, 1987, 1ST P IEEE INT C NEU, V2, P609; Anderson S., 1988, 258 IND U DEP LING D; BAHL LR, 1988, P ICASSP 88 NEW YORK, P493; BOURLAND H, 1988, M21 PHILL RES LAB TE; BROOMHEAD D, 1988, RSRE4148 ROYAL SIGN; BROWN PF, 1987, THESIS CARNEGIE MELL; CHAN C, 1992, MAR P INT C AC SPEEC; DEMICHELIS P, 1989, P ICASSP 89, P314; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 1973, J ROYAL STAT SOC SER; FALLSIDE F, 1990, APR P IEEE INT C AC, P445; GAO YQ, 1990, P IEEE INT C ACOUSTI, P501; ISO K, 1990, P INT C AC SPEECH SI, P441; Iwamida H., 1990, Journal of the Acoustical Society of Japan (E), V11, P277, DOI 10.1250/ast.11.277; Jian-xiong Wu, 1991, International Journal of Neural Systems, V2, P211, DOI 10.1142/S0129065791000194; JUANG BH, 1985, AT&T TECH J, V64, P1235, DOI 10.1002/j.1538-7305.1985.tb00273.x; KOHONEN T, 1988, JUL P IEEE ANN INT C; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; LEE S, 1991, NEURAL NETWORKS, V4, P207, DOI 10.1016/0893-6080(91)90005-P; Lippmann RP, 1989, NEURAL COMPUT, V1, P1, DOI 10.1162/neco.1989.1.1.1; Prager R. W., 1986, COMPUTER SPEECH LANG, V1, P2; ROBINSON AJ, 1988, NEURAL INFORMATION P, P632; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; SUTTON RS, 1981, PSYCHOL REV, V88, P135, DOI 10.1037/0033-295X.88.2.135; TEBELSKIS J, 1990, P IEEE INT C ACOUSTI, P437; TRAVEN HGC, 1991, IEEE T NEURAL NETWOR, V2, P366, DOI 10.1109/72.97913; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; WATROUS RL, 1987, 1ST P IEEE INT C NEU, P381; WU JX, 1991, PATTERN RECOGN, V22, P1085; ZWICKER E, 1961, J ACOUST SOC AM, V22, P2248	31	13	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1993	15	11					1174	1185		10.1109/34.244678	http://dx.doi.org/10.1109/34.244678			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MH083					2022-12-18	WOS:A1993MH08300006
J	VEMURI, BC; MALLADI, R				VEMURI, BC; MALLADI, R			CONSTRUCTING INTRINSIC PARAMETERS WITH ACTIVE MODELS FOR INVARIANT SURFACE RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DEFORMABLE MODEL; INVARIANCE; LINES OF CURVATURE; REPARAMETERIZATION; SURFACE RECONSTRUCTION; THIN-PLATE-MEMBRANE SPLINES; VARIATIONAL PRINCIPLE	REPRESENTATION; OBJECTS	Three-dimensional viewpoint invariance is an important requirement on the representation of surfaces for recognition tasks. Parameterized surfaces possess this desirable property. In general, the parameters in a parametric surface representation can be arbitrarily defined. A canonical, intrinsic parameterization provides us with a consistent, invariant form for describing surfaces. Our goal here is to define and construct such a parameterization. In this paper, we present two new techniques within the framework of active modeling [29] to achieve this goal. Canonical parameterization of a surface in these techniques is defined by the surface lines of curvature. The problem is formulated as a variational principle with the associated energy expression consisting of a parameterized stabilizer term and a penalty term. In the first method, we use a static instance of the controlled continuity spline for the stabilizer and show how to modify it to reflect a change of parameters to the lines of curvature. In the second method, we use the dynamic instance of the controlled continuity spline called the deformable model. A force field defined in terms of the principal vectors is synthesized and applied to the parameter curves of the deformable model to coerce them along the lines of curvature. In essence, any transformation of parameters requires a modification of the stabilizer in the first method, whereas in the second method, it is tantamount to synthesizing a new force field. We present experimental results with real and synthetic range data.			VEMURI, BC (corresponding author), UNIV FLORIDA,DEPT COMP & INFORMAT SCI,GAINESVILLE,FL 32611, USA.							BARR AH, 1981, IEEE COMPUTER GR JAN, P11; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BLAKE A, 1984, P NAT C ARTIFICIAL I, P23; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; Boothby W., 1986, INTRO DIFFERENTIABLE; BOULT TE, 1986, JUN P IEEE C COMP VI, P68; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; Clarke F.H, 1990, CANADIAN MATH SOC SE, V2; Dahlquist G., 1974, NUMERICAL METHODS; DELINGETTE H, 1991, JUN P IEEE C COMP VI; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; DUCHON J, 1976, REV FRANCAISE AUTOMA, V5; Hughes T.J.R., 1987, FINITE ELEMENT METHO; HUREWICZ W, 1958, LECTURES ORDINARY DI; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LEE D, 1986, IEEE T PATTERN ANAL, V10, P822; MALLADI R, 1991, THESIS U FLORIDA GAI; MARROQUIN JL, 1987, J AM STAT ASS, V82; Meinguet J., 1979, J APPL MATH PHYS, V30, P292; POTMESIL M, 1983, AUG P IEEE INT JOINT; Rockafellar R. T., 1981, THEORY SUBGRADIENTS; SANDER PT, 1990, IEEE T PATTERN ANAL, V12, P833, DOI 10.1109/34.57680; Schumaker LL, 1976, APPROXIMATION THEORY, VII, P203; SINHA SS, 1990, MAY P IEEE INT C ROB, P7; STEVENSON R, 1989, NOV P IEEE WORKSH IN; SZELISKI R, 1989, BAYESIAN MODELING UN; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Terzopoulos D., 1987, TECHNICAL DIGEST SER, V12, P164; THOMPSON J. F., 1985, NUMERICAL GRID GENER; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; VEMURI BC, 1987, IEEE T CIRCUITS SYST, V34, P1351, DOI 10.1109/TCS.1987.1086070; VEMURI BC, 1991, JUN P IEEE C COMP VI, P724; VEMURI BC, 1990, AUG P IEEE INT WORKS, P361; VEMURI BC, 1989, NOV P SPIE S ADV INT, V119, P75; WANG YF, 1990, DEC P IEEE INT C COM, P300; YOUNG DM, 1971, ITERATIVE SOLUTION L	38	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					668	681		10.1109/34.221168	http://dx.doi.org/10.1109/34.221168			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185					2022-12-18	WOS:A1993LM18500002
J	CALIFANO, A; BOLLE, RM				CALIFANO, A; BOLLE, RM			THE MULTIPLE WINDOW PARAMETER TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							HOUGH TRANSFORM; RECOGNITION; SPACE; CURVES	This paper presents the multiwindow transform, which is an extension of parameter transform techniques that increases performance and scope. This is achieved by exploiting the long-range correlated information contained in multiple portions of an image. Traditional local parameter transforms, which are used for the detection and reconstruction of features, have been successfully employed to find, for example, lines and circles in edge maps. However, as shown by many examples in the literature, there is a steep tradeoff between accuracy and computational complexity when dealing with more complicated (i.e., high-dimensional) geometric features. Multiple window transforms allow for the extraction of high-dimensional features with improvement in accuracy over conventional techniques while keeping linear to low-order polynomial computational and space requirements with respect to image size and dimensionality of the features. Using correlated information provides a direct link between extracted features and supporting regions in the image. This, coupled with evidence integration techniques, is used to suppress noisy or nonexistent feature hypotheses. Parameter spaces are implemented as constraint satisfaction networks, where feature hypotheses with overlapping support in the image compete. After an iterative relaxation phase, surviving hypotheses have disjoint support, forming a segmentation of the image. Examples that show the performance and provide insight in the behavior are given. Complex, high-dimensional, parametric features such as surfaces and surface-intersection curves can be reconstructed from range data.			CALIFANO, A (corresponding author), IBM CORP,THOMAS J WATSON RES CTR,EXPLORATORY COMP VIS GRP,YORKTOWN HTS,NY 10598, USA.			Califano, Andrea/0000-0003-4742-3679				BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BALLARD DH, 1981, 7TH P INT JOINT C AR, P1068; BERGEN JR, PROBABILISTIC ALGORI; BOLLE RM, 1992, IEEE T PATTERN ANAL, V14, P534, DOI 10.1109/34.134058; BOLLE RM, 1986, DEC P INT AUT SYST, P142; BOLLE RM, 1986, IBM RC12002 TECH REP; BOLLE RM, 1987, JAN SPIE C OPT DIG P, P117; BOLLE RM, 1987, NOV P IEEE WORKSH CO, P324; BOLLE RM, 1989, JUN P IEEE C COMP VI, P625; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BOWN CM, 1983, IEEE T PATTERN ANAL, V5, P493; CALIFANO A, 1988, 7TH P NAT C ART INT, P831; CALIFANO A, 1989, JUN P IEEE C COMP VI, P192; CALIFANO A, 1990, 10TH P INT C PATT RE, P1; CALIFANO A, 1990, SHAPE ACQUISITION RE; DANE C, 1981, AUG P IEEE C PATT RE, P54; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FELDMAN JA, 1982, COGNITIVE SCI, V6, P205, DOI 10.1207/s15516709cog0603_1; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; HANAHARA K, 1988, IEEE T PATTERN ANAL, V10, P121, DOI 10.1109/34.3876; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; ITTNER DJ, 1985, JUN P COMP VIS PATT, P119; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KENDER JR, 1990, IBM RC16576 TECH REP; KENDER JR, 1990, IBM RC16577 TECH REP; KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677; KULTANEN P, 1990, 10TH P ICPR, P631; KUSHNIR M, 1985, PATTERN RECOGN, V18, P103, DOI 10.1016/0031-3203(85)90033-0; Lamperti J., 1977, STOCHASTIC PROCESSES; MOHAN R, 1990, PROGR NEURAL NETWORK; NETER J, 1974, APPLIED LINEAR STATI; PAO D, 1990, 10TH P INT C PATT RE, P620; ROSENFELD A, 1969, PICTURE PROCESSING C; SABBAH D, 1985, COGNITIVE SCI, V9, P25, DOI 10.1207/s15516709cog0901_3; SHAPIRO SD, 1978, PATTERN RECOGN, V10, P129, DOI 10.1016/0031-3203(78)90022-5; SHAPIRO SD, 1978, COMPUT VISION GRAPH, V8, P219, DOI 10.1016/0146-664X(78)90050-3; SLANSKY J, 1978, IEEE T COMPUT, V27, P923; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TAYLOR RW, 1990, 10TH P INT C PATT RE, P613; [No title captured]	43	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1157	1170		10.1109/34.177381	http://dx.doi.org/10.1109/34.177381			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300002
J	WILSON, R; BHALERAO, AH				WILSON, R; BHALERAO, AH			KERNEL DESIGNS FOR EFFICIENT MULTIRESOLUTION EDGE-DETECTION AND ORIENTATION ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDGE DETECTION; FILTER DESIGN; MULTIRESOLUTION; ORIENTATION; PYRAMID	IMAGE; SEGMENTATION; 2-D	This paper deals with the design of filter kernels having specified radial and angular frequency responses based on combined optimization and frequency sampling. This is used to generate small-radius, low-pass, and edge-detection kernesl for multiresolution pyramids. The performance of the new kernels in estimating orientation is shown to be significantly better than that of other commonly used pyramid kernels.			WILSON, R (corresponding author), UNIV WARWICK,DEPT COMP SCI,COVENTRY CV4 7AL,W MIDLANDS,ENGLAND.							BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BHALERAO A, 1989, RR154 U WARW DEP COM; BIGUN J, 1988, THESIS U LINKOPING S; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; Calway A., 1989, Third International Conference on Image Processing and its Applications (Conf. Publ. No.307), P651; CHAPMAN R, 1984, P ICASSP 84 SAN DIEG; CLIPPINGDALE SC, 1989, P ICASSP IEEE, P1409; DANIELSSON PE, 1990, COMPUT VISION GRAPH, V49, P198, DOI 10.1016/0734-189X(90)90137-K; DANIELSSON PE, 1980, 5TH P ICPR, P1171; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; HUANG TS, 1972, IEEE T ACOUST SPEECH, VAU20, P88, DOI 10.1109/TAU.1972.1162331; KNUTSSON H, 1983, P 2 SPECTR EST WORKS, P234; KNUTSSON H, 1982, THESIS U LINKOPING S; LENZ R, 1987, PATTERN RECOGN, V20, P163, DOI 10.1016/0031-3203(87)90050-1; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; RABINER L, 1975, THEORY APPLICATIONS; Schrift A., 1988, Proceedings of IAPR Workshop on Computer Vision: Special Hardware and Industrial Applications, P340; SPANN M, 1985, PATTERN RECOGN, V18, P257, DOI 10.1016/0031-3203(85)90051-2; TODD M, 1989, P ICASSP 89 GLASGOW, P1969; Watson G. N., 1958, THEORY BESSEL FUNCTI; WILSON R, 1988, IEEE T PATTERN ANAL, V10, P193, DOI 10.1109/34.3882; WILSON R, 1990, 5TH P SPIE C VIS COM	26	13	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1992	14	3					384	390		10.1109/34.120332	http://dx.doi.org/10.1109/34.120332			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HF732		Green Published			2022-12-18	WOS:A1992HF73200007
J	CARDILLO, J; SIDAHMED, MA				CARDILLO, J; SIDAHMED, MA			3-D POSITION SENSING USING A PASSIVE MONOCULAR VISION SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAMERA CALIBRATION; COMPUTER VISION; DEPTH RECOVERY; FOCUS BLUR; IMAGE ANALYSIS; ROBOT VISION SYSTEM		Passive monocular 3-D position sensing is made possible by a new calibration scheme that relates depth to focus blur through a composite lens and aperture model. A geometric model of the camera's position and orientation in space is used to transform the camera's imaging coordinates into world coordinates. Position accuracies comparable to those in stereo based vision systems are possible without the need for solving the difficult point of correspondence problem.			CARDILLO, J (corresponding author), UNIV WINDSOR,DEPT ELECT ENGN,WINDSOR N9B 3P4,ONTARIO,CANADA.							Born M., 1968, PRINCIPLES OPTICS; CARDILLO J, 1988, THESIS U WINDSOR WIN; KIM YC, 1987, IEEE J ROBOT AUTOM, V3, P361; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; RAY SF, 1976, LENS ACTION; Subbarao M., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P149, DOI 10.1109/CCV.1988.589986	7	13	20	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					809	813		10.1109/34.85671	http://dx.doi.org/10.1109/34.85671			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200006
J	ALNUWEIRI, HM; KUMAR, VKP				ALNUWEIRI, HM; KUMAR, VKP			FAST IMAGE LABELING USING LOCAL OPERATORS ON MESH-CONNECTED COMPUTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						IMAGE LABELING; IMAGE PROCESSING; LOCAL IMAGE OPERATORS; MESH-CONNECTED COMPUTERS; PARALLEL ALGORITHMS; SPACE-TIME TRADEOFFS		Mesh-connected computers are well suited to local computations that exploit the nearest-neighbour interconnections of the mesh. In this correspondence, a new parallel algorithm is proposed for fast image labeling using local operators on image pixels. The algorithm can be implemented on an n x n mesh-connected computer such that, for any integer k in the range [1, log(2n)], the algorithm requires THETA(kn(l/k)bits of local memory per processor and takes THETA(kn) time. Bit-serial processors and communication links can be used without affecting the asymptotic time complexity of the algorithm. The time complexity of the algorithm has very small leading constant factors, which makes it superior to previous mesh computer labeling algorithms for most practical image sizes (e.g., up to 4096 x 4096 images). Furthermore, our algorithm is based on using stacks that can be realized using very fast shift registers within each PE.	UNIV SO CALIF,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089	University of Southern California	ALNUWEIRI, HM (corresponding author), KING FAHD UNIV PETR & MINERALS,DEPT COMP ENGN,DHAHRAN 31261,SAUDI ARABIA.		Alnuweiri, Hussein/AAE-1470-2020					ALNUWEIRI HM, IN PRESS PARALLEL AR; ALNUWEIRI HM, 1988, P IEEE C COMPUT VISI; ALNUWEIRI HM, 1989, IEEE T CIRCUITS  OCT; BATCHER K, 1980, IEEE T COMPUT, V29; CYPHER R, 1990, IEEE T COMPUT, V39; DYER CR, 1981, IEEE T PATTERN ANAL, V3; FOUNTAIN T, 1987, PROCESSOR ARRAYS ARC; GRAY SB, 1971, IEEE T COMPUT, V20; LEVIALDI S, 1972, COMMUN ACM       JAN; NASSIMI D, 1980, SIAM J COMPUT, V9; ROSENFELD A, 1966, J ACM, V4; ROSENFELD A, 1970, J ACM            JAN	12	13	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					202	207		10.1109/34.67649	http://dx.doi.org/10.1109/34.67649			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900009
J	PELEG, S; RON, G				PELEG, S; RON, G			NONLINEAR MULTIRESOLUTION - A SHAPE-FROM-SHADING EXAMPLE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									DAVID SARNOFF RES CTR,PRINCETON,NJ	Sarnoff Corporation	PELEG, S (corresponding author), HEBREW UNIV JERUSALEM,DEPT COMP SCI,IL-91904 JERUSALEM,ISRAEL.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				BROOKS MJ, 1985, AUG P INT JOINT C AR, P932; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Simchony T., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P580, DOI 10.1109/CCV.1988.590038; SZELISKI R, 1990, 1ST P EUR C COMP VIS, P359; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TERZOPOULOS D, 1984, 4TH P NAT C ART INT, P314	9	13	14	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1206	1210		10.1109/34.62611	http://dx.doi.org/10.1109/34.62611			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000010
J	POLZLEITNER, W; WECHSLER, H				POLZLEITNER, W; WECHSLER, H			SELECTIVE AND FOCUSED INVARIANT RECOGNITION USING DISTRIBUTED ASSOCIATIVE MEMORIES (DAM)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									GEORGE MASON UNIV,DEPT COMP SCI,FAIRFAX,VA 22030	George Mason University	POLZLEITNER, W (corresponding author), JOANNEUM RES,WASTIANGASSE 6,A-8010 GRAZ,AUSTRIA.							HEBB DO, 1949, ORG BEHAVIOR; Kohonen T., 1988, SELF ORG ASS MEMORY; MASSONE L, 1985, COMPUT VISION GRAPH, V30, P169, DOI 10.1016/0734-189X(85)90095-7; MESSNER RA, 1985, COMPUT VISION GRAPH, V31, P50, DOI 10.1016/S0734-189X(85)80075-X; MURAKAMI K, 1987, IEEE T SYST MAN CYB, V17, P699, DOI 10.1109/TSMC.1987.289364; POLZLEITNER W, 1990, DIBAG48 TECH REP; POLZLEITNER W, 1986, 8TH P INT C PATT REC, P262; SCHURMANN J, 1977, POLYNOMKLASSIFIKATOR; WECHSLER H, 1989, IEEE T PATTERN ANAL, V11, P814, DOI 10.1109/34.31444; WECHSLER H, 1988, IEEE T PATTERN ANAL, V10, P811, DOI 10.1109/34.9104; WEISBERG S, 1985, APPLIED LINEAR REGRE	11	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1990	12	8					809	814		10.1109/34.57670	http://dx.doi.org/10.1109/34.57670			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DQ388					2022-12-18	WOS:A1990DQ38800006
J	ANG, CH; SAMET, H; SHAFFER, CA				ANG, CH; SAMET, H; SHAFFER, CA			A NEW REGION EXPANSION FOR QUADTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742; UNIV MARYLAND,INST ADV COMP STUDIES,COLLEGE PK,MD 20742; UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742; VIRGINIA POLYTECH INST & STATE UNIV,DEPT COMP SCI,BLACKSBURG,VA 24061	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; Virginia Polytechnic Institute & State University	ANG, CH (corresponding author), NATL UNIV SINGAPORE,DEPT COMP SCI,SINGAPORE 0511,SINGAPORE.							ABEL DJ, 1983, COMPUT VISION GRAPH, V24, P1, DOI 10.1016/0734-189X(83)90017-8; ANG CH, 1989, TR2255 U MAR COLL PA; GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741; HUNTER GM, 1978, THESIS PRINCETON U P; KLINGER A, 1971, OPTIMIZING METHODS S, P303; MASON DC, 1987, IMAGE VISION COMPUT, V5, P11, DOI 10.1016/0262-8856(87)90072-2; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Samet H., 1990, DESIGN ANAL SPATIAL, V85; SAMET H, 1984, TR1457 U MAR COLL PA; SAMET H, 1990, APPLICATIONS SPATIAL; SHAFFER CA, 1988, IMAGE VISION COMPUT, V6, P162, DOI 10.1016/0262-8856(88)90022-4; SHAFFER CA, 1987, TR1885 U MAR DEP COM	12	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					682	686		10.1109/34.56221	http://dx.doi.org/10.1109/34.56221			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400008
J	PARENT, P; ZUCKER, SW				PARENT, P; ZUCKER, SW			RADIAL PROJECTION - AN EFFICIENT UPDATE RULE FOR RELAXATION LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PARENT, P (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,MCGILL RES CTR INTELLIGENT MACHINES,COMP VIS & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA.							Faugeras O., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P318; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; MOHAMMED JL, 1983, IEEE T PATTERN ANAL, V5, P330, DOI 10.1109/TPAMI.1983.4767394; PARENT P, 1985, TR8512R MCG U COMP V; PARENT P, 1985, IEEE PATT A, V11, P823	5	13	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					886	889		10.1109/34.31449	http://dx.doi.org/10.1109/34.31449			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079					2022-12-18	WOS:A1989AH07900008
J	GARCIA, P; VIDAL, E; CASACUBERTA, F				GARCIA, P; VIDAL, E; CASACUBERTA, F			LOCAL LANGUAGES, THE SUCCESSOR METHOD, AND A STEP TOWARDS A GENERAL METHODOLOGY FOR THE INFERENCE OF REGULAR GRAMMARS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											GARCIA, P (corresponding author), UNIV POLITECN VALENCIA,FAC INFORMAT,DEPT SISTEMAS INFOMAT & COMPUTAC,E-46071 VALENCIA,SPAIN.							ANGLUIN D, 1983, COMPUT SURVEYS, V15; CHIRATHAMJAREE C, 1980, INT J MAN MACH STUD, V12, P379, DOI 10.1016/S0020-7373(80)80022-8; Eilemberg S, 1974, AUTOMATA LANGUAGES M; FELDMAN J, 1972, INFORM CONTROL, V20, P244, DOI 10.1016/S0019-9958(72)90424-X; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1982, SYNTACTIC PATTERN RE; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; GROSS M, 1971, INTRO FORMAL GRAMMAR; ITOGA SY, 1981, IEEE T PATTERN ANAL, V3; MICLET L, 1980, IEEE T SYST MAN CYB, V10, P737, DOI 10.1109/TSMC.1980.4308394; RICHETIN M, 1984, PATTERN RECOGN, V17, P245, DOI 10.1016/0031-3203(84)90063-3; RULOT H, 1987, PATTERN RECOGN, P451; SOLOMAA A, 1981, JEWELS FORMAL LANGUA; THOMASON MG, 1986, PATTERN RECOGN, V19, P343, DOI 10.1016/0031-3203(86)90001-4; VERNADAT F, 1984, P IEEE ICPR 84, P1370; WANG PSP, 1986, P IEEE INT C PATTERN, P129	16	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					841	845		10.1109/TPAMI.1987.4767991	http://dx.doi.org/10.1109/TPAMI.1987.4767991			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	K6735	21869446				2022-12-18	WOS:A1987K673500012
J	WILSON, R				WILSON, R			FINITE PROLATE SPHEROIDAL SEQUENCES AND THEIR APPLICATIONS .1. GENERATION AND PROPERTIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WILSON, R (corresponding author), UNIV WARWICK, DEPT COMP SCI, COVENTRY CV4 7AL, W MIDLANDS, ENGLAND.							Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; JACOBSON L, 1982, 6TH P INT C PATT REC; KNUTSSON H, 1983, P IEEE CAPAIDM WORKS; KNUTSSON H, 1982, THESIS LINKOPING U; KNUTSSON H, 1983, P IEEE WORKSHOP SPEC; LANDAU HJ, 1962, BELL SYST TECH J, V41, P1295, DOI 10.1002/j.1538-7305.1962.tb03279.x; LANDAU HJ, 1961, BELL SYST TECH J, V40, P65, DOI 10.1002/j.1538-7305.1961.tb03977.x; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; Nering E., 1970, LINEAR ALGEBRA MATRI; PAPOULIS A, 1972, IEEE T CIRCUITS SYST, VCT19, P674, DOI 10.1109/TCT.1972.1083556; POLLEN DA, 1983, IEEE T SYST MAN CYB, V13, P907, DOI 10.1109/TSMC.1983.6313086; RABINER LR, 1975, THEORY APPLICATION D; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SLEPIAN D, 1964, BELL SYST TECH J, V43, P3009, DOI 10.1002/j.1538-7305.1964.tb01037.x; SLEPIAN D, 1976, P IEEE, V64, P292, DOI 10.1109/PROC.1976.10110; SLEPIAN D, 1961, BELL SYST TECH J, V40, P43, DOI 10.1002/j.1538-7305.1961.tb03976.x; SLEPIAN D, 1978, BELL SYST TECH J, V57, P1317; THOMSON DJ, 1982, P IEEE, V70, P1055, DOI 10.1109/PROC.1982.12433; TUFTS DW, 1970, IEEE T ACOUST SPEECH, VAU18, P487, DOI 10.1109/TAU.1970.1162148; Wilkinson JH., 1965, ALGEBRAIC EIGENVALUE; WILSON R, 1984, IEEE T PATTERN ANAL, V6, P758, DOI 10.1109/TPAMI.1984.4767599; WILSON R, 1983, IEEE T COMMUN, V31, P398, DOI 10.1109/TCOM.1983.1095831; WILSON R, 1984, P IEEE ICASSP 84 SAN; WILSON R, 1983, LITHISYI0579 LINK U	25	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					787	795		10.1109/TPAMI.1987.4767985	http://dx.doi.org/10.1109/TPAMI.1987.4767985			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869440				2022-12-18	WOS:A1987K673500006
J	KOPLOWITZ, J; RAJ, APS				KOPLOWITZ, J; RAJ, APS			A ROBUST FILTERING ALGORITHM FOR SUBPIXEL RECONSTRUCTION OF CHAIN CODED LINE DRAWINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KOPLOWITZ, J (corresponding author), CLARKSON UNIV,DEPT ELECT & COMP ENGN,POTSDAM,NY 13676, USA.							BERNSTEIN C, 1985, JUN INT S INF THEOR, P43; BRONS R, 1974, COMPUT GRAPHICS IMAG, V3, P48; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1984, IEEE T PATTERN ANAL, V6, P632, DOI 10.1109/TPAMI.1984.4767577; FREEMAN H, 1969, IEEE T SYST SCI CYB, VSSC5, P70, DOI 10.1109/TSSC.1969.300247; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2; HUNG SHY, 1985, IEEE T PATTERN ANAL, V7, P203, DOI 10.1109/TPAMI.1985.4767644; KIM CE, 1983, IEEE T PATTERN ANAL, V5, P231, DOI 10.1109/TPAMI.1983.4767379; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P618, DOI 10.1109/TPAMI.1982.4767315; KIM CE, 1982, COMPUT VISION GRAPH, V18, P369, DOI 10.1016/0146-664X(82)90005-3; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; KOPLOWITZ J, 1978, INFORM PROCESS LETT, V7, P56, DOI 10.1016/0020-0190(78)90042-X; KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075; KOPLOWITZ J, 1985, JUN INT S INF THEOR, P169; KOPLOWITZ J, 1984, MAR P C INF SCI SYST, P531; NEUHOFF DL, 1985, IEEE T INFORM THEORY, V31, P53, DOI 10.1109/TIT.1985.1056998; OROURKE J, 1981, COMMUN ACM, V24, P574, DOI 10.1145/358746.358758; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; SCHWARTZ JT, 1981, INFORM PROCESS LETT, V13, P168, DOI 10.1016/0020-0190(81)90051-X; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502; WU LD, 1982, IEEE T PATTERN ANAL, V4, P347, DOI 10.1109/TPAMI.1982.4767258	24	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					451	457		10.1109/TPAMI.1987.4767927	http://dx.doi.org/10.1109/TPAMI.1987.4767927			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516638				2022-12-18	WOS:A1987H076800010
J	NALWA, VS				NALWA, VS			EDGE-DETECTOR RESOLUTION IMPROVEMENT BY IMAGE INTERPOLATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NALWA, VS (corresponding author), STANFORD UNIV,ARTIFICIAL INTELLIGENCE LAB,STANFORD,CA 94305, USA.							Atkinson KE., 1978, INTRO NUMERICAL ANAL; BARLOW HB, 1979, NATURE, V279, P189, DOI 10.1038/279189a0; BRACEWELL RN, 1978, FOURIER TRANSFORM IT; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; CANNY FJ, 1983, MIT AITR720 AI LAB T; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; Pratt W. K., 1978, DIGITAL IMAGE PROCES; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	11	13	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					446	451		10.1109/TPAMI.1987.4767926	http://dx.doi.org/10.1109/TPAMI.1987.4767926			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516637				2022-12-18	WOS:A1987H076800009
J	DERIN, H				DERIN, H			ESTIMATING COMPONENTS OF UNIVARIATE GAUSSIAN MIXTURES USING PRONYS METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											DERIN, H (corresponding author), UNIV MASSACHUSETTS,DEPT ELECT & COMP ENGN,AMHERST,MA 01003, USA.							BHATTACHARYA CG, 1967, BIOMETRICS, V23, P115, DOI 10.2307/2528285; COHEN AC, 1967, TECHNOMETRICS, V9, P15, DOI 10.2307/1266315; COOPER DB, 1964, INFORM CONTROL, V7, P416, DOI 10.1016/S0019-9958(64)90502-9; DAY NE, 1969, BIOMETRIKA, V56, P463, DOI 10.1093/biomet/56.3.463; EVERITT BS, 1981, MONOGR APPL PROB STA; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P410, DOI 10.1109/TPAMI.1983.4767410; HILDEBRAND FB, 1956, INTRO NUMERICAL ANAL, P378; KATOPIS A, 1972, P MODELLING SIMULATI, P473; KAZAKOS D, 1980, IEEE T INFORM THEORY, V26, P113, DOI 10.1109/TIT.1980.1056124; KAZAKOS D, 1977, IEEE T INFORM THEORY, V23, P203, DOI 10.1109/TIT.1977.1055693; Pearson K., 1894, Philosophical Transactions, V185a, P71, DOI 10.1098/rsta.1894.0003; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163, DOI 10.1109/TPAMI.1981.4767074; Prony G.R.B., 1795, J ECOLE POLYTECHNIQE, V1, P24; YOUNG TY, 1970, IEEE T INFORM THEORY, V16, P258, DOI 10.1109/TIT.1970.1054454	14	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					142	148		10.1109/TPAMI.1987.4767880	http://dx.doi.org/10.1109/TPAMI.1987.4767880			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869385				2022-12-18	WOS:A1987F378500013
J	KOSKO, B				KOSKO, B			COUNTING WITH FUZZY-SETS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											KOSKO, B (corresponding author), VERAC INC,9605 SCRANTON RD,SAN DIEGO,CA 92121, USA.							ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; ZADEH LA, 1981, 247 AI CTR SRI INT T; ZADEH LA, 1981, EMPIRICAL SEMANTICS, P281	3	13	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					556	557		10.1109/TPAMI.1986.4767822	http://dx.doi.org/10.1109/TPAMI.1986.4767822			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000017
J	OZEKI, O; NAKANO, T; YAMAMOTO, S				OZEKI, O; NAKANO, T; YAMAMOTO, S			REAL-TIME RANGE MEASUREMENT DEVICE FOR 3-DIMENSIONAL OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											OZEKI, O (corresponding author), TOYOTA CENT RES & DEV LABS INC,41-1 AZA YOKOMICHI,NAGAKUTE,AICHI 48011,JAPAN.							DOI Y, 1972, T SICE, V10, P18; GENNERY DB, 1979, 6TH P INT JOINT C AR, P320; HOLLAND S, 1980, SAE800378 PAP; Holland S. W., 1979, Computer Vision and Sensor-based Robots, P81; ISHII M, 1974, T SICE, V10, P79; KANADE T, 1981, P SOC PHOTO-OPT INST, V283, P48; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; OSHIMA M, 1981, 8TH P INT JOINT C AR, P601; OZEKI O, 1984, IECE TGPRL8425 TECH, P19; SATO Y, 1982, IEEE T PATTERN ANAL, V4; SHIRAI Y, 1972, PATTERN RECOGN, V4, P243, DOI 10.1016/0031-3203(72)90003-9; Yagi, 1973, COMPUT VISION GRAPH, V2, P131	12	13	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					550	554		10.1109/TPAMI.1986.4767820	http://dx.doi.org/10.1109/TPAMI.1986.4767820			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000015
J	HARALICK, RM				HARALICK, RM			DIGITAL STEP EDGES FROM ZERO CROSSINGS OF 2ND DIRECTIONAL-DERIVATIVES - REPLY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											HARALICK, RM (corresponding author), MACHINE VIS INT,ANN ARBOR,MI 48104, USA.		Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; CANNY J, 1983, MIT AITR720 ART INT; GRIMSON WEL, UNPUB IEEE T PATTERN; HASHIMOTO M, 1983, JUN P IEEE C COMP VI, P318; Leclerc Y., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P46	5	13	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					127	129		10.1109/TPAMI.1985.4767629	http://dx.doi.org/10.1109/TPAMI.1985.4767629			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869251				2022-12-18	WOS:A1985ABF0900016
J	CERNUSCHIFRIAS, B; COOPER, DB				CERNUSCHIFRIAS, B; COOPER, DB			3-D SPACE LOCATION AND ORIENTATION PARAMETER-ESTIMATION OF LAMBERTIAN SPHERES AND CYLINDERS FROM A SINGLE 2-D IMAGE BY FITTING LINES AND ELLIPSES TO THRESHOLDED DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									BROWN UNIV,DIV ENGN,ENGN MAN MACHINE SYST LAB,PROVIDENCE,RI 02912	Brown University	CERNUSCHIFRIAS, B (corresponding author), UNIV BUENOS AIRES,FAC INGN,BUENOS AIRES,ARGENTINA.		Cernuschi-Frias, Bruno/G-9177-2012	Cernuschi-Frias, Bruno/0000-0001-5335-9402				BOLLE RM, 1984, IEEE T PATTERN ANAL, V6, P418, DOI 10.1109/TPAMI.1984.4767547; BOLLE RM, 1982, JUN P C PATT REC IM, P611; BOLLE RM, 1981, LEMS1 BROWN U DIV EN; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; CERNUSCHIFRIAS B, 1983, THESIS BROWN U PROVI; CERNUSCHIFRIAS B, 1982, JUN P C PATT REC IM, P605; CERNUSCHIFRIAS B, 1981, LEMS2 BROWN U DIV EN; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; Duda R.O., 1973, J ROYAL STAT SOC SER; HAKALA DG, 1981, AUG SIGGRAPH 81 SEM; SEARS FW, 1958, OPTICS, P322; TENENBAUM JM, 1981, IMAGE MODELING, P371	12	13	14	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					430	441		10.1109/TPAMI.1984.4767548	http://dx.doi.org/10.1109/TPAMI.1984.4767548			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869211				2022-12-18	WOS:A1984SY28900004
J	SCHOLTEN, DK; WILSON, SG				SCHOLTEN, DK; WILSON, SG			CHAIN CODING WITH A HEXAGONAL LATTICE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV VIRGINIA,DEPT ELECT ENGN,CHARLOTTESVILLE,VA 22901	University of Virginia								FREEMAN H, 1980, COMPUT VISION GRAPH, V12, P203, DOI 10.1016/0146-664X(80)90012-X; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FREEMAN H, 1962, 3RD P INT C CYB NAM; KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075; NEUHOFF DL, 1981, AUG P IEEE COMP SOC; SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3, P533, DOI 10.1109/TPAMI.1981.4767146; Santal LA., 1953, INTRO INTEGRAL GEOME, V1198	7	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					526	533		10.1109/TPAMI.1983.4767432	http://dx.doi.org/10.1109/TPAMI.1983.4767432			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869138				2022-12-18	WOS:A1983RM11800009
J	WANG, PSP				WANG, PSP			HIERARCHICAL STRUCTURES AND COMPLEXITIES OF PARALLEL ISOMETRIC LANGUAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WANG, PSP (corresponding author), WANG LABS,LOWELL,MA 01851, USA.							BLUM M, 1967, 8 IEEE S SWITCH AUT, P155; COOK CR, 1978, COMPUT VISION GRAPH, V8, P144, DOI 10.1016/S0146-664X(78)80022-7; DACEY MF, 1970, PATTERN RECOGN, V2, P11, DOI 10.1016/0031-3203(70)90038-5; DACEY MF, 1971, PATTERN RECOGN, V3, P197, DOI 10.1016/0031-3203(71)90040-9; FISCHER MJ, 1969, 10TH IEEE C ANN S SW, P149; Fu K.S., 1974, MATH SCI ENG; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; Harrison M. A., 1978, INTRO FORMAL LANGUAG; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; KIRSCH RA, 1964, IEEE T COMPUT, VEC13, P363, DOI 10.1109/PGEC.1964.263816; MERCER A, 1973, COMMUN ACM, V16, P299, DOI 10.1145/362041.362198; MILLER WF, 1968, P AFIPS FJCC 1, V3, P279; MYLOPOULOS J, 1972, PATTERN RECOGN, V4, P37, DOI 10.1016/0031-3203(72)90018-0; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1976, INFORM CONTROL, V31, P177, DOI 10.1016/S0019-9958(76)80006-X; ROSENFELD A, 1973, INFORM CONTROL, V23, P173, DOI 10.1016/S0019-9958(73)90659-1; Rosenfeld A., 1979, PICTURE LANGUAGES; Rosenfeld A., 1971, MACH INTELL, VVI, P281; Salomaa A., 1973, FORMAL LANGUAGES; SIROMONEY R, 1974, INFORM CONTROL, V24, P155, DOI 10.1016/S0019-9958(74)80054-9; SKYUM S, 1974, INFORM CONTROL, V26, P280, DOI 10.1016/S0019-9958(74)91399-0; SMITH AR, 1971, 12 ANN S SWITCH AUT, P144; Wang P. S., 1975, Journal of Cybernetics, V5, P19, DOI 10.1080/01969727508545918; WANG PSP, 1981, COMPUT VISION GRAPH, V15, P296, DOI 10.1016/0146-664X(81)90062-9; WANG PSP, 1977, P ASS COMPUT MACH SE, P484; WANG PSP, 1982, INFORM PROCESSING LE	27	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					92	99		10.1109/TPAMI.1983.4767351	http://dx.doi.org/10.1109/TPAMI.1983.4767351			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869090				2022-12-18	WOS:A1983PZ84400014
J	AGUI, T; NAKAJIMA, M; ARAI, Y				AGUI, T; NAKAJIMA, M; ARAI, Y			AN ALGEBRAIC APPROACH TO THE GENERATION AND DESCRIPTION OF BINARY PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											AGUI, T (corresponding author), TOKYO INST TECHNOL,IMAGING SCI & ENGN LAB,4259 NAGATSUDA CHO,MIDORI KU,YOKOHAMA,KANAGAWA 227,JAPAN.							Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; FU KS, 1978, COMPUT GRAPHICS IMAG, V7, P303; Jury E., 1958, SAMPLED DATA CONTROL; LOUGHEED RM, 1980, AUG P IEEE WORKSH PI, P281; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SHAPIRO LG, 1980, IEEE T PATTERN ANAL, V2, P111, DOI 10.1109/TPAMI.1980.4766989; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598	7	13	13	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					635	641		10.1109/TPAMI.1982.4767317	http://dx.doi.org/10.1109/TPAMI.1982.4767317			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499638				2022-12-18	WOS:A1982PS23700009
J	CARBONELL, JG; CULLINGFORD, RE; GERSHMAN, AV				CARBONELL, JG; CULLINGFORD, RE; GERSHMAN, AV			STEPS TOWARD KNOWLEDGE-BASED MACHINE TRANSLATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									YALE UNIV,DEPT COMP SCI,ARTIFICIAL INTELLIGENCE PROJECT,NEW HAVEN,CT 06520	Yale University								Bar-Hillel Y., 1960, ADV COMPUT, V1, P91, DOI DOI 10.1016/S0065-2458(08)60607-5; BOBROW DG, 1977, COGNITIVE SCI, V1; BOITET C, 1976, 6TH P INT C COMP LIN; BRACHMAN RJ, 1978, 3878 BOLT BER NEWM I; BROWN JS, 1975, REPRESENTATION UNDER; CARBONEL.JR, 1970, IEEE T MAN MACHINE, VMM11, P190, DOI 10.1109/TMMS.1970.299942; CARBONELL JG, 1978, COGNITIVE SCI, V2; CARBONELL JG, 1979, 150 YALE U COMP SCI; CARBONELL JG, 1978, 7TH P INT C COMP LIN; CASTILLO C, 1972, U CHICAGO SPANISH DI; CHARNIAK E, 1972, MIT AITR266; CHARNIAK E, 1978, COGNITIVE SCI, V2; Colby K. M., 1973, COMPUTER MODELS THOU; Collins A.M., 1972, ORG MEMORY; CULLINGFORD RE, 1979, DISCOURSE PROCESSES, V2; CULLINGFORD RE, 1978, 116 YALE U COMP SCI; DEJONG GF, 1979, 158 YALE U COMP SCI; GERSHMAN A, 1977, 110 YALE U COMP SCI; GERSHMAN A, 1979, 156 YALE U COMP SCI; GINSPARG J, 1978, AIM316 STANF U STANF; GOLDMAN N, 1975, CONCEPTUAL INFORMATI; GOLDSTEIN IP, 1977, 5TH P INT C ART INT; HENDRIX GG, 1975, 4TH P INT JOINT C AR; HOFFMAN T, 1976, 6TH P INT C COMP LIN; JOSSELSON HH, 1970, ADV COMPUT, V10, P1; KITTREDGE R, 1976, 6TH P INT C COMP LIN; LEHNERT W, 1977, 88 YALE U DEP COMP S; LOCKE WN, 1957, MACHINE TRANSLATION; MARCUS M, 1977, THESIS MIT CAMBRIDGE; MCDONALD DD, 1977, 5TH P INT C ART INT; Minsky M., 2019, FRAMEWORK REPRESENTI; NEDOBEJKINE N, 1976, 6TH P INT C COMP LIN; QUILLIAN MR, 1968, SEMANTIC INFORMATION; RIEGER C, 1975, P THEORETICAL ISSUES; RIEGER CJ, 1975, CONCEPTUAL INFORMATI; RIESBECK C, 1975, CONCEPTUAL INFORMATI; RIESBECK CK, 1978, PATTERN DIRECTED INF; Schank R., 1977, SCRIPTS PLANS GOALS; SCHANK RC, 1974, 6 INST STUD SEM COGN; SCHANK RC, 1975, CONCEPTUAL INFORMATI; SIMMONS R, 1972, COMMUN ASS COMPUT MA, V15; STUTZMAN WJ, 1976, 6TH P INT C COMP LIN; WILENSKY R, 1976, P ANN C ACM; Wilks Y., 1976, AM J COMPUTATIONAL L; WILKS Y, 1976, ARTIFICIAL INTELL, V6; WILKS Y, 1973, COMPUTER MODELS THOU; Winograd Terry, 1972, UNDERSTANDING NATURA; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773; WOODS WA, 1972, 2378 BOLT BER NEWM R	49	13	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					376	392		10.1109/TPAMI.1981.4767124	http://dx.doi.org/10.1109/TPAMI.1981.4767124			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868959				2022-12-18	WOS:A1981MQ35700003
J	LEVINE, B				LEVINE, B			DERIVATIVES OF TREE SETS WITH APPLICATIONS TO GRAMMATICAL INFERENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LEVINE, B (corresponding author), UNIV OREGON,DEPT COMP & INFORMAT SCI,EUGENE,OR 97403, USA.			Levine, Barry/0000-0003-3018-7040				ARBIB MA, 1968, INFORM CONTROL, V12, P331, DOI 10.1016/S0019-9958(68)90374-4; BHARGAVA BK, 1973, IEEE T COMPUT, V22, P1087; BIERMANN AW, 1972, IEEE T COMPUT, VC 21, P592, DOI 10.1109/TC.1972.5009015; BOOTH TL, 1975, IEEE T SYST MAN CYB, V5, P409; BOOTH TL, 1975, IEEE T SYST MAN CYB, V5, P95; BRAINERD WS, 1969, INFORM CONTROL, V14, P217, DOI 10.1016/S0019-9958(69)90065-5; BRAINERD WS, 1968, INFORM CONTROL, V13, P484, DOI 10.1016/S0019-9958(68)90917-0; BRAYER JM, 1977, IEEE T SYST MAN CYB, V7, P293; BRZOZOWSKI JA, 1964, J ACM, V11, P481, DOI 10.1145/321239.321249; CRESPIREGHIZZI S, 1971, P IFIP C; Doner J., 1970, J COMPUT SYST SCI, V4, P406, DOI [10.1016/S0022-0000(70)80041-1, DOI 10.1016/S0022-0000(70)80041-1]; EDWARDS JJ, 1976, INT J COMPUT INFORM, V5; EVANS TG, 1971, SOFTWARE ENG, V2; Hopcroft J.E., 1969, FORMAL LANGUAGES THE; JOSHI AK, 1978, INFORM CONTR, V39, P192; LEVINE BA, 1979, THESIS OREGON STATE; Salomaa A., 1973, FORMAL LANGUAGES; THATCHER JW, 1973, CURRENTS THEORY COMP	18	13	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					285	293		10.1109/TPAMI.1981.4767101	http://dx.doi.org/10.1109/TPAMI.1981.4767101			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN969	21868949				2022-12-18	WOS:A1981MN96900005
J	Chen, TS; Pu, T; Wu, HF; Xie, Y; Liu, LB; Lin, L				Chen, Tianshui; Pu, Tao; Wu, Hefeng; Xie, Yuan; Liu, Lingbo; Lin, Liang			Cross-Domain Facial Expression Recognition: A Unified Evaluation Benchmark and Adversarial Graph Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Benchmark testing; Adversarial machine learning; Face recognition; Task analysis; Protocols; Faces; Facial expression recognition; domain adaptation; graph representation learning; adversarial learning; fair evaluation	EMOTION RECOGNITION	Facial expression recognition (FER) has received significant attention in the past decade with witnessed progress, but data inconsistencies among different FER datasets greatly hinder the generalization ability of the models learned on one dataset to another. Recently, a series of cross-domain FER algorithms (CD-FERs) have been extensively developed to address this issue. Although each declares to achieve superior performance, comprehensive and fair comparisons are lacking due to inconsistent choices of the source/target datasets and feature extractors. In this work, we first propose to construct a unified CD-FER evaluation benchmark, in which we re-implement the well-performing CD-FER and recently published general domain adaptation algorithms and ensure that all these algorithms adopt the same source/target datasets and feature extractors for fair CD-FER evaluations. Based on the analysis, we find that most of the current state-of-the-art algorithms use adversarial learning mechanisms that aim to learn holistic domain-invariant features to mitigate domain shifts. However, these algorithms ignore local features, which are more transferable across different datasets and carry more detailed content for fine-grained adaptation. Therefore, we develop a novel adversarial graph representation adaptation (AGRA) framework that integrates graph representation propagation with adversarial learning to realize effective cross-domain holistic-local feature co-adaptation. Specifically, our framework first builds two graphs to correlate holistic and local regions within each domain and across different domains, respectively. Then, it extracts holistic-local features from the input image and uses learnable per-class statistical distributions to initialize the corresponding graph nodes. Finally, two stacked graph convolution networks (GCNs) are adopted to propagate holistic-local features within each domain to explore their interaction and across different domains for holistic-local feature co-adaptation. In this way, the AGRA framework can adaptively learn fine-grained domain-invariant features and thus facilitate cross-domain expression recognition. We conduct extensive and fair comparisons on the unified evaluation benchmark and show that the proposed AGRA framework outperforms previous state-of-the-art methods.	[Chen, Tianshui] Guangdong Univ Technol, Guangzhou 510006, Guangdong, Peoples R China; [Pu, Tao; Wu, Hefeng; Xie, Yuan; Lin, Liang] Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China; [Liu, Lingbo] Hong Kong Polytech Univ, Hong Kong, Peoples R China	Guangdong University of Technology; Sun Yat Sen University; Hong Kong Polytechnic University	Wu, HF (corresponding author), Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China.	tianshuichen@gmail.com; putao3@mail2.sysu.edu.cn; wuhefeng@mail.sysu.edu.cn; phoenixsysu@gmail.com; lingbo.liu@polyu.edu.hk; linliang@ieee.org		Liu, Lingbo/0000-0001-8179-6685; Chen, Tianshui/0000-0002-5848-5624; Liang, Lin/0000-0003-2248-3755	National Natural Science Foundation of China (NSFC) [61876045, 61836012, 62002069]; Natural Science Foundation of Guangdong Province [2017A030312006]; Guangdong Provincial Basic Research Program [102020369]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); Guangdong Provincial Basic Research Program	This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grants 61876045, 61836012, and 62002069, in part by the Natural Science Foundation of Guangdong Province under Grant 2017A030312006, and in part by Guangdong Provincial Basic Research Program under Grant 102020369.	Chen RQ, 2020, AAAI CONF ARTIF INTE, V34, P10575; Chen TS, 2022, IEEE T PATTERN ANAL, V44, P1371, DOI 10.1109/TPAMI.2020.3025814; Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061; Chen TS, 2019, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2019.00632; Chen TS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P627; Chen TS, 2018, AAAI CONF ARTIF INTE, P6730; Chen TS, 2018, IEEE T IMAGE PROCESS, V27, P5827, DOI 10.1109/TIP.2018.2859025; Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664; Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532; Chu WS, 2017, IEEE T PATTERN ANAL, V39, P529, DOI 10.1109/TPAMI.2016.2547397; Clavel C, 2008, SPEECH COMMUN, V50, P487, DOI 10.1016/j.specom.2008.03.012; Dhall A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2106, DOI 10.1109/ICCVW.2011.6130508; Edwards J, 2002, CLIN PSYCHOL REV, V22, P789, DOI 10.1016/S0272-7358(02)00130-7; Fatras K, 2021, PR MACH LEARN RES, V139; Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006; Friesen E., 1978, CONSULTING PSYCHOL P, V3, P1; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005; Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282; Hasani B, 2017, IEEE INT CONF AUTOMA, P790, DOI 10.1109/FG.2017.99; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037; Jiang CH, 2018, ADV NEUR IN, V31; Junguang Jiang M. L., 2020, TRANSFER LEARNING LI; Kingma D.P, P 3 INT C LEARNING R; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808; Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053; Li S, 2022, IEEE T AFFECT COMPUT, V13, P881, DOI 10.1109/TAFFC.2020.2973158; Li S, 2018, INT C PATT RECOG, P3092, DOI 10.1109/ICPR.2018.8545284; Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382; Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277; Li Y., 2016, PROC INT C LEARN REP; Liu LB, 2022, Arxiv, DOI arXiv:2107.00946; Liu LB, 2022, IEEE T INTELL TRANSP, V23, P3377, DOI 10.1109/TITS.2020.3036057; Liu LB, 2019, IEEE T MULTIMEDIA, V21, P2248, DOI 10.1109/TMM.2019.2902096; Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011; Long MS, 2018, ADV NEUR IN, V31; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949; da Silva FAM, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023015; Mengxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13933, DOI 10.1109/CVPR42600.2020.01395; Miao YQ, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P326, DOI 10.1109/ICMLA.2012.178; Mollahosseini A, 2016, IEEE WINT CONF APPL; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Sangineto E, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P357, DOI 10.1145/2647868.2654916; Saste ST, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P701; Simonyan K., 2015, VERY DEEP CONVOLUTIO; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Valstar M., 2010, P 3 INT WORKSH EMOTI, P65; Wang JD, 2018, INT CONF PERVAS COMP, P115; Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083; Wang XQ, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7208794; Wang ZX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1021; Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58; Wei XF, 2018, IEEE INT CONF AUTOMA, P31, DOI 10.1109/FG.2018.00015; Wen J, 2019, AAAI CONF ARTIF INTE, P5401; Xie Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1255, DOI 10.1145/3394171.3413822; Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151; Yan HB, 2016, NEUROCOMPUTING, V208, P165, DOI 10.1016/j.neucom.2015.11.113; Yan KY, 2019, IEEE ACCESS, V7, P108906, DOI 10.1109/ACCESS.2019.2930359; Yan KY, 2016, LECT NOTES COMPUT SC, V9948, P427, DOI 10.1007/978-3-319-46672-9_48; Yang W., 2019, PROC INT C LEARN REP; Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60; Zeng JB, 2018, LECT NOTES COMPUT SC, V11217, P227, DOI 10.1007/978-3-030-01261-8_14; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1; Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414; Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002; Zhao J, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4397; Zheng WM, 2018, IEEE T AFFECT COMPUT, V9, P21, DOI 10.1109/TAFFC.2016.2563432; Zhu RH, 2016, INT CONF BIOMETR; Zong Y, 2018, IEEE T IMAGE PROCESS, V27, P2484, DOI 10.1109/TIP.2018.2797479	77	12	12	3	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9887	9903		10.1109/TPAMI.2021.3131222	http://dx.doi.org/10.1109/TPAMI.2021.3131222			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34847019	Green Submitted			2022-12-18	WOS:000880661400095
J	Rao, HC; Wang, SQ; Hu, XP; Tan, MK; Guo, Y; Cheng, J; Liu, XW; Hu, B				Rao, Haocong; Wang, Siqi; Hu, Xiping; Tan, Mingkui; Guo, Yi; Cheng, Jun; Liu, Xinwang; Hu, Bin			A Self-Supervised Gait Encoding Approach With Locality-Awareness for 3D Skeleton Based Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Skeleton; Three-dimensional displays; Encoding; Task analysis; Computational modeling; Solid modeling; Feature extraction; Skeleton based person re-identification; gait; self-supervised deep learning; locality-aware attention; contrastive learning	RECOGNITION; BIOMETRICS; ANGLE	Person re-identification (Re-ID) via gait features within 3D skeleton sequences is a newly-emerging topic with several advantages. Existing solutions either rely on hand-crafted descriptors or supervised gait representation learning. This paper proposes a self-supervised gait encoding approach that can leverage unlabeled skeleton data to learn gait representations for person Re-ID. Specifically, we first create self-supervision by learning to reconstruct unlabeled skeleton sequences reversely, which involves richer high-level semantics to obtain better gait representations. Other pretext tasks are also explored to further improve self-supervised learning. Second, inspired by the fact that motion's continuity endows adjacent skeletons in one skeleton sequence and temporally consecutive skeleton sequences with higher correlations (referred as locality in 3D skeleton data), we propose a locality-aware attention mechanism and a locality-aware contrastive learning scheme, which aim to preserve locality-awareness on intra-sequence level and inter-sequence level respectively during self-supervised learning. Last, with context vectors learned by our locality-aware attention mechanism and contrastive learning scheme, a novel feature named Constrastive Attention-based Gait Encodings (CAGEs) is designed to represent gait effectively. Empirical evaluations show that our approach significantly outperforms skeleton-based counterparts by 15-40 percent Rank-1 accuracy, and it even achieves superior performance to numerous multi-modal methods with extra RGB or depth information. Our codes are available at https://github.com/Kali-Hac/Locality-Awareness-SGE.	[Rao, Haocong; Hu, Xiping; Cheng, Jun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China; [Wang, Siqi; Liu, Xinwang] Natl Univ Def Technol, Changsha 410073, Peoples R China; [Hu, Xiping; Hu, Bin] Lanzhou Univ, Lanzhou 730000, Gansu, Peoples R China; [Tan, Mingkui] South China Univ Technol, Guangzhou 510006, Peoples R China; [Guo, Yi] Jinan Univ, Clin Med Coll 2, Shenzhen 518055, Peoples R China; [Hu, Bin] Beijing Inst Technol, Beijing 100081, Peoples R China	Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; National University of Defense Technology - China; Lanzhou University; South China University of Technology; Jinan University; Beijing Institute of Technology	Hu, XP (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.; Hu, B (corresponding author), Beijing Inst Technol, Beijing 100081, Peoples R China.	haocongrao@gmail.com; wangsiqi10c@nudt.edu.cn; xp.hu@siat.ac.cn; mingkuitan@scut.edu.cn; xuanyi_guo@163.com; jun.cheng@siat.ac.cn; xinwangliu@nudt.edu.cn; bh@bit.edu.cn	Rao, Haocong/ABF-7884-2021; Hu, Xiping/GSE-5065-2022; , CH/AAT-2453-2021	Rao, Haocong/0000-0002-9576-2379; Hu, Xiping/0000-0002-4952-699X; 	National Key Research and Development Program of China [2019YFA0706200]; National Natural Science Foundation of China [61632014, 61627808, 62006236, 62072190]; Hunan Provincial Natural Science Foundation [2020JJ5673]; NUDT Research Project [ZK20-10]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hunan Provincial Natural Science Foundation(Natural Science Foundation of Hunan Province); NUDT Research Project	This work was supported in part by the National Key Research and Development Program of China under Grant 2019YFA0706200, in part by the National Natural Science Foundation of China under Grants 61632014, 61627808, 62006236, and 62072190, in part by Hunan Provincial Natural Science Foundation under Grant 2020JJ5673, and in part by NUDT Research Project under Grant ZK20-10. Haocong Rao and Siqi Wang contributed equally to this work.	Aaron van den Oord, 2019, Arxiv, DOI arXiv:1807.03748; Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Andersson VO, 2015, AAAI CONF ARTIF INTE, P425; Antoine Bordes, 2015, Arxiv, DOI arXiv:1410.3916; Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI [DOI 10.1109/IJCB.2011.6117582, 10.1109/IJCB.2011.6117582]; Baltieri D, 2011, LECT NOTES COMPUT SC, V6978, P197, DOI 10.1007/978-3-642-24085-0_21; Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43; Battistone F, 2019, PATTERN RECOGN LETT, V126, P132, DOI 10.1016/j.patrec.2018.05.004; Boureau Y.-L., 2010, ICML, P111, DOI DOI 10.5555/3104322.3104338; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610; Chen T., 2020, ADV NEUR IN, V33; Chen T, 2020, PR MACH LEARN RES, V119; Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805; Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007; CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021; Dilip Krishnan, 2020, Arxiv, DOI arXiv:1906.05849; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V27, P766, DOI [DOI 10.1109/TPAMI.2015.2496141, 10.48550/arXiv.1406.6909]; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766; Gutmann M., 2010, AISTATS, V9, P297, DOI DOI 10.1145/3292500.3330651; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011; Haque A, 2016, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2016.138; Hasan M., 2016, PROC IEEE ELECT POWE, P1; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Ji X, 2019, IEEE I CONF COMP VIS, P9864, DOI 10.1109/ICCV.2019.00996; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Karianakis N, 2018, LECT NOTES COMPUT SC, V11209, P737, DOI 10.1007/978-3-030-01228-1_44; Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058; Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069; Lin Chunli, 2010, 2010 2nd International Conference on Networking and Digital Society (ICNDS 2010), P589, DOI 10.1109/ICNDS.2010.5479416; Liu Z, 2015, NEUROCOMPUTING, V168, P1144, DOI 10.1016/j.neucom.2015.05.008; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122; Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5; Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674; Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8; Munaro M, 2014, IEEE INT CONF ROBOT, P5644, DOI 10.1109/ICRA.2014.6907689; Munaro M, 2014, IEEE INT CONF ROBOT, P4512, DOI 10.1109/ICRA.2014.6907518; MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009; Nambiar A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3243043; Nambiar A, 2017, IEEE INT CONF AUTOMA, P973, DOI 10.1109/FG.2017.121; Pala P, 2019, COMPUT GRAPH-UK, V79, P69, DOI 10.1016/j.cag.2019.01.003; Qian XL, 2020, IEEE T PATTERN ANAL, V42, P371, DOI 10.1109/TPAMI.2019.2928294; Rao HC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P898; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sivapriya SV, 2011, INDIAN GEOTECHNICAL, P1, DOI [DOI 10.1109/IJCB.2011.6117504, 10.1155/2011/375897]; Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002; Tanawongsuwan R, 2001, PROC CVPR IEEE, P726; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596; Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260; Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637; Yoo J.-H., 2002, PROC BMVA S ADV BIOM, P596; Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878; Yu SQ, 2006, INT C PATT RECOG, P441; Zhang YQ, 2019, PATTERN RECOGN, V93, P228, DOI 10.1016/j.patcog.2019.04.023; Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310; Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147; Zhuang CX, 2019, IEEE I CONF COMP VIS, P6001, DOI 10.1109/ICCV.2019.00610	69	12	12	9	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6649	6666		10.1109/TPAMI.2021.3092833	http://dx.doi.org/10.1109/TPAMI.2021.3092833			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34181534	Green Submitted			2022-12-18	WOS:000853875300060
J	Zhang, XC				Zhang, Xingchen			Deep Learning-Based Multi-Focus Image Fusion: A Survey and a Comparative Study	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image fusion; Deep learning; Frequency modulation; Transforms; Generative adversarial networks; Visualization; Task analysis; Multi-focus image fusion; image fusion; deep learning; image processing	GENERATIVE ADVERSARIAL NETWORK; CONVOLUTIONAL NEURAL-NETWORK; INFORMATION MEASURE; QUALITY ASSESSMENT; INFRARED IMAGES; PERFORMANCE; CONSTRAINTS; ALGORITHM; FRAMEWORK; ENSEMBLE	Multi-focus image fusion (MFIF) is an important area in image processing. Since 2017, deep learning has been introduced to the field of MFIF and various methods have been proposed. However, there is a lack of survey papers that discuss deep learning-based MFIF methods in detail. In this study, we fill this gap by giving a detailed survey on deep learning-based MFIF algorithms, including methods, datasets and evaluation metrics. To the best of our knowledge, this is the first survey paper that focuses on deep learning-based approaches in the field of MFIF. Besides, extensive experiments have been conducted to compare the performance of deep learning-based MFIF algorithms with conventional MFIF approaches. By analyzing qualitative and quantitative results, we give some observations on the current status of MFIF and discuss some future prospects of this field.	[Zhang, Xingchen] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England	Imperial College London	Zhang, XC (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England.	xingchen.zhang@imperial.ac.uk	Zhang, Xingchen/GYJ-2323-2022					Ali Aghagolzadeh, 2017, Arxiv, DOI arXiv:1710.06511; Amin-Naji M., 2018, J AI DATA MIN, V6, P233, DOI [10.22044/JADM.2017.5169.1624, DOI 10.22044/JADM.2017.5169.1624]; Amin-Naji M, 2020, J AMB INTEL HUM COMP, V11, P1749, DOI 10.1007/s12652-019-01199-0; Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003; Amin-Naji M, 2017, IRAN CONF MACH, P45, DOI 10.1109/IranianMVIP.2017.8342367; Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7; Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003; Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z; Bouzos O, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922097; Bulanon DM, 2009, BIOSYST ENG, V103, P12, DOI 10.1016/j.biosystemseng.2009.02.009; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Canagarajah N., 2006, INT J SIGNAL PROCESS, V2, P178; Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001; Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002; Chen ZY, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1688, DOI 10.1109/IAEAC.2017.8054302; Chunxia Zhang, 2020, Arxiv, DOI arXiv:2002.04780; Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032; Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693; De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007; Deshmukh V, 2018, SMART INNOV SYST TEC, V83, P233, DOI 10.1007/978-3-319-63673-3_28; Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019; Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Gai D, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107681; Gang Xiao, 2020, Arxiv, DOI arXiv:2002.03322; Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003; Guo X., 2018, PROC 7 INT C INFORM, P236; Guo XP, 2020, IET IMAGE PROCESS, V14, P1339, DOI 10.1049/iet-ipr.2019.0883; Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292; Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098; Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012; Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Hong X., 2019, P INT C WAV AN PATT, P1; Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754; Huang J, 2020, NEURAL COMPUT APPL, V32, P15119, DOI 10.1007/s00521-020-04863-1; Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019; James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002; Jiang Zhi-guo, 2004, Proceedings. Third International Conference on Image and Graphics, P176; Jung H, 2020, IEEE T IMAGE PROCESS, V29, P3845, DOI 10.1109/TIP.2020.2966075; Kou L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191085; Lahoud F., 2019, ARXIV; Lai R, 2019, IEEE ACCESS, V7, P114385, DOI 10.1109/ACCESS.2019.2935006; Li H, 2021, PATTERN RECOGN LETT, V141, P45, DOI 10.1016/j.patrec.2020.11.014; Li HG, 2019, IEEE SENS J, V19, P9755, DOI 10.1109/JSEN.2019.2928818; Li HG, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON ALGORITHMS, COMPUTING AND SYSTEMS (ICACS 2018), P148, DOI 10.1145/3242840.3242863; Li H, 2015, OPT COMMUN, V342, P1, DOI 10.1016/j.optcom.2014.12.048; Li JJ, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4179397; Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190; Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004; Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222; Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu SQ, 2019, IEEE ACCESS, V7, P56367, DOI 10.1109/ACCESS.2019.2900376; Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311; Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007; Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001; Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776; Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004; Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004; [刘羽 Liu Yu], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1435; Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109; Ma BY, 2021, NEURAL COMPUT APPL, V33, P5793, DOI 10.1007/s00521-020-05358-9; Ma HY, 2020, IEEE T IMAGE PROCESS, V29, P8668, DOI 10.1109/TIP.2020.3018261; Ma HY, 2019, IEEE INT CON MULTI, P1150, DOI 10.1109/ICME.2019.00201; Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004; Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048; Ma JL, 2017, CHIN CONTR CONF, P5464, DOI 10.23919/ChiCC.2017.8028223; Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010; Murugan A., 2021, Intelligent Computing and Applications. Proceedings of ICICA 2019. Advances in Intelligent Systems and Computing (AISC 1172), P559, DOI 10.1007/978-981-15-5566-4_50; Mustafa HT, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115864; Mustafa HT, 2019, LECT NOTES ARTIF INT, V11508, P153, DOI 10.1007/978-3-030-20912-4_15; Mustafa HT, 2019, IMAGE VISION COMPUT, V85, P26, DOI 10.1016/j.imavis.2019.03.001; Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004; Nian ZC, 2019, IEEE IMAGE PROC, P1044, DOI 10.1109/ICIP.2019.8803065; Pan T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143901; Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231; Pe~na F. A. G., 2019, ARXIV; Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173; Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004; Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212; Rajalingam B., 2018, INT J ENG SCIINVENTI, V2, P52; Rao YJ, 1997, MEAS SCI TECHNOL, V8, P355, DOI 10.1088/0957-0233/8/4/002; Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Savic S., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P604; Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9; Song X, 2019, LECT NOTES ARTIF INT, V11377, P1, DOI 10.1007/978-3-030-20984-1_1; Song Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P401, DOI 10.1109/ROBIO.2006.340210; Sujatha K, 2018, MULTIMED TOOLS APPL, V77, P1735, DOI 10.1007/s11042-016-4312-3; Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043; Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085; Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520; Vincent O. R., 2009, P INF SCI IT ED C, V40, P97; Wang C, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106253; Wang HM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204225; Wang M, 2019, IMAGE VISION COMPUT, V86, P1, DOI 10.1016/j.imavis.2019.02.011; Wang Q, 2005, PHYSICA D, V200, P287, DOI 10.1016/j.physd.2004.11.001; Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang ZY, 2019, MULTIMED TOOLS APPL, V78, P34483, DOI 10.1007/s11042-019-08070-6; Wen Y, 2020, MULTIMED TOOLS APPL, V79, P34531, DOI 10.1007/s11042-020-08945-z; Xiao B, 2021, IEEE T IMAGE PROCESS, V30, P163, DOI 10.1109/TIP.2020.3033158; Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484; Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548; Xu H, 2020, IEEE T IMAGE PROCESS, V29, P7203, DOI 10.1109/TIP.2020.2999855; Xu H, 2020, IEEE ACCESS, V8, P26316, DOI 10.1109/ACCESS.2020.2971137; Xu KP, 2018, KSII T INTERNET INF, V12, P2253, DOI 10.3837/tiis.2018.05.019; Xu S, 2020, IEEE T COMPUT IMAG, V6, P1561, DOI 10.1109/TCI.2020.3039564; Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267; Yan X, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226647; Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001; Yang Y, 2019, IEEE T COMPUT IMAG, V5, P262, DOI 10.1109/TCI.2018.2889959; Yang Y, 2018, IEEE ACCESS, V6, P20138, DOI 10.1109/ACCESS.2018.2822688; Zeng WH, 2019, INT CONF ACOUST SPEE, P1762, DOI 10.1109/ICASSP.2019.8683312; Zhai H, 2020, APPL OPTICS, V59, P1684, DOI 10.1364/AO.381082; Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022; Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797; Zhang JC, 2020, PATTERN RECOGN LETT, V138, P370, DOI 10.1016/j.patrec.2020.08.002; Zhang Q., 2020, PATTERN RECOGN, V113; Zhang Q, 2018, PATTERN RECOGN, V83, P299, DOI 10.1016/j.patcog.2018.06.003; Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006; Zhang XC, 2021, INFORM FUSION, V74, P111, DOI 10.1016/j.inffus.2021.02.005; Zhang XC, 2020, IEEE COMPUT SOC CONF, P468, DOI 10.1109/CVPRW50498.2020.00060; Zhang XC, 2020, INFORM FUSION, V63, P166, DOI 10.1016/j.inffus.2020.05.002; Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011; Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006; Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433; Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177; Zhou JC, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2950949; Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005	131	12	12	35	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4819	4838		10.1109/TPAMI.2021.3078906	http://dx.doi.org/10.1109/TPAMI.2021.3078906			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33974542				2022-12-18	WOS:000836666600027
J	Pan, LY; Hartley, R; Scheerlinck, C; Liu, MM; Yu, X; Dai, YC				Pan, Liyuan; Hartley, Richard; Scheerlinck, Cedric; Liu, Miaomiao; Yu, Xin; Dai, Yuchao			High Frame Rate Video Reconstruction Based on an Event Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Cameras; Image resolution; Data models; Optimization; Image restoration; Lighting; Event camera (DAVIS); motion blur; high temporal resolution reconstruction; mEDI model; fibonacci sequence		Event-based cameras measure intensity changes (called 'events') with microsecond accuracy under high-speed motion and challenging lighting conditions. With the 'active pixel sensor' (APS), the 'Dynamic and Active-pixel Vision Sensor' (DAVIS) allows the simultaneous output of intensity frames and events. However, the output images are captured at a relatively low frame rate and often suffer from motion blur. A blurred image can be regarded as the integral of a sequence of latent images, while events indicate changes between the latent images. Thus, we are able to model the blur-generation process by associating event data to a latent sharp image. Based on the abundant event data alongside a low frame rate, easily blurred images, we propose a simple yet effective approach to reconstruct high-quality and high frame rate sharp videos. Starting with a single blurred frame and its event data from DAVIS, we propose the Event-based Double Integral (EDI) model and solve it by adding regularization terms. Then, we extend it to multiple Event-based Double Integral (mEDI) model to get more smooth results based on multiple images and their events. Furthermore, we provide a new and more efficient solver to minimize the proposed energy model. By optimizing the energy function, we achieve significant improvements in removing blur and the reconstruction of a high temporal resolution video. The video generation is based on solving a simple non-convex optimization problem in a single scalar variable. Experimental results on both synthetic and real datasets demonstrate the superiority of our mEDI model and optimization method compared to the state-of-the-art.	[Pan, Liyuan; Hartley, Richard; Scheerlinck, Cedric; Liu, Miaomiao] Australian Natl Univ, Res Sch Engn, Canberra, ACT, Australia; [Pan, Liyuan; Hartley, Richard; Scheerlinck, Cedric; Liu, Miaomiao] Australian Ctr Robot Vis, Brisbane, Qld 4000, Australia; [Yu, Xin] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia; [Dai, Yuchao] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China	Australian National University; Australian Centre for Robotic Vision; University of Technology Sydney; Northwestern Polytechnical University	Pan, LY (corresponding author), Australian Natl Univ, Res Sch Engn, Canberra, ACT, Australia.; Pan, LY (corresponding author), Australian Ctr Robot Vis, Brisbane, Qld 4000, Australia.	liyuan.pan@anu.edu.au; richard.hartley@anu.edu.au; cedric.scheerlinck@anu.edu.au; miaomiaoliu@anu.edu.au; xin.yu@uts.edu.au; daiyuchao@gmail.com		Yu, Xin/0000-0002-0269-5649	Australian Research Council through the "Australian Centre of Excellence for Robotic Vision" [CE140100016]; Natural Science Foundation of China [61871325, 61420106007, 61671387, 61603303]; National Key Research and Development Program of China [2018AAA0102803]; Australian Research Council (ARC) [DE140100180, DE180100628, DP200102274]	Australian Research Council through the "Australian Centre of Excellence for Robotic Vision"(Australian Research Council); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; Australian Research Council (ARC)(Australian Research Council)	This work was supported in part by the Australian Research Council through the "Australian Centre of Excellence for Robotic Vision" CE140100016, the Natural Science Foundation of China grants (61871325, 61420106007, 61671387, and 61603303), National Key Research and Development Program of China under Grant 2018AAA0102803 and the Australian Research Council (ARC) grants (DE140100180, DE180100628, andDP200102274).	Bardow P, 2016, PROC CVPR IEEE, P884, DOI 10.1109/CVPR.2016.102; Barua S., 2016, P IEEE REAL TIM SYST, P1; Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715; Brandli C, 2014, IEEE INT SYMP CIRC S, P686, DOI 10.1109/ISCAS.2014.6865228; Cook M, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P770, DOI 10.1109/IJCNN.2011.6033299; Delbruck T., 2020, V2E VIDEO FRAMES REA; Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413; Gallego G, 2018, IEEE T PATTERN ANAL, V40, P2402, DOI 10.1109/TPAMI.2017.2769655; Gehrig D, 2018, LECT NOTES COMPUT SC, V11216, P766, DOI 10.1007/978-3-030-01258-8_46; Gehrig D, 2019, IEEE I CONF COMP VIS, P5632, DOI 10.1109/ICCV.2019.00573; Gong Dong, 2017, P IEEE C COMP VIS PA, P2319; Jin MG, 2018, PROC CVPR IEEE, P6334, DOI 10.1109/CVPR.2018.00663; KIEFER J, 1953, P AM MATH SOC, V4, P502, DOI 10.2307/2032161; Kim H, 2016, LECT NOTES COMPUT SC, V9910, P349, DOI 10.1007/978-3-319-46466-4_21; Kim Hanme, 2014, BRIT MACH VIS C BMVC, DOI [10.5244/C.28.26, DOI 10.5244/C.28.26]; Kim TH, 2015, PROC CVPR IEEE, P5426, DOI 10.1109/CVPR.2015.7299181; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Kueng B, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P16, DOI 10.1109/IROS.2016.7758089; Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601; Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337; Liu HC, 2017, VISUAL COMPUT, V33, P749, DOI 10.1007/s00371-017-1372-y; Liu L, 2019, IEEE I CONF COMP VIS, P2570, DOI 10.1109/ICCV.2019.00266; Liu L, 2017, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2017.260; Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804; Pan L., 2020, P IEEE CVF C COMP VI, P1672; Pan LY, 2019, PROC CVPR IEEE, P6027, DOI 10.1109/CVPR.2019.00619; Pan LY, 2019, PROC CVPR IEEE, P6813, DOI 10.1109/CVPR.2019.00698; Pan LY, 2020, IEEE T IMAGE PROCESS, V29, P1748, DOI 10.1109/TIP.2019.2945867; Pan LY, 2018, IEEE WINT CONF APPL, P1377, DOI 10.1109/WACV.2018.00155; Pan LY, 2017, PROC CVPR IEEE, P6987, DOI 10.1109/CVPR.2017.739; Posch Christoph, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P400, DOI 10.1109/ISSCC.2010.5433973; Press W. H., 1988, NUMERICAL RECIPES C, V1, P3; Purohit K, 2019, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2019.00699; Rebecq H, 2019, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2019.00398; Rebecq H, 2021, IEEE T PATTERN ANAL, V43, P1964, DOI 10.1109/TPAMI.2019.2963386; Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143; Rebecq Henri, 2018, C ROB LEARN, P2; Reinbrecht C., 2016, PROC 29 S INTEGR CIR, P1; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Scheerlinck C, 2020, IEEE WINT CONF APPL, P156, DOI 10.1109/WACV45572.2020.9093366; Scheerlinck C, 2019, IEEE COMPUT SOC CONF, P1684, DOI 10.1109/CVPRW.2019.00215; Scheerlinck C, 2019, LECT NOTES COMPUT SC, V11365, P308, DOI 10.1007/978-3-030-20873-8_20; Scheerlinck C, 2019, IEEE ROBOT AUTOM LET, V4, P816, DOI 10.1109/LRA.2019.2893427; Sellent A, 2016, LECT NOTES COMPUT SC, V9906, P558, DOI 10.1007/978-3-319-46475-6_35; Shedligeri PA, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.6.063012; Stoffregen T, 2020, P EUR C COMP VIS, P1; Stoffregen T, 2019, IEEE I CONF COMP VIS, P7243, DOI 10.1109/ICCV.2019.00734; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun L, 2013, IEEE INT C COMPUTATI, P1, DOI 10.1109/ICCPhot.2013.6528301; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Vidal AR, 2018, IEEE ROBOT AUTOM LET, V3, P994, DOI 10.1109/LRA.2018.2793357; Wang L, 2019, PROC CVPR IEEE, P10073, DOI 10.1109/CVPR.2019.01032; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738; Yu X, 2014, IEEE T MULTIMEDIA, V16, P1510, DOI 10.1109/TMM.2014.2321734; Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267; Zhou Y, 2018, LECT NOTES COMPUT SC, V11205, P242, DOI 10.1007/978-3-030-01246-5_15; Zhu AZ, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Zhu AZH, 2017, PROC CVPR IEEE, P5816, DOI 10.1109/CVPR.2017.616	63	12	12	9	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2519	2533		10.1109/TPAMI.2020.3036667	http://dx.doi.org/10.1109/TPAMI.2020.3036667			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33166250	Green Submitted			2022-12-18	WOS:000792921400023
J	Chen, SZ; He, ZB; Sun, CJ; Yang, J; Huang, XL				Chen, Sizhe; He, Zhengbao; Sun, Chengjin; Yang, Jie; Huang, Xiaolin			Universal Adversarial Attack on Attention and the Resulting Dataset DAmageNet	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heating systems; Training; Neural networks; Perturbation methods; Semantics; Visualization; Error analysis; Adversarial attack; attention; transferability; black-box attack; DAmageNet		Adversarial attacks on deep neural networks (DNNs) have been found for several years. However, the existing adversarial attacks have high success rates only when the information of the victim DNN is well-known or could be estimated by the structure similarity or massive queries. In this paper, we propose to Attack on Attention (AoA), a semantic property commonly shared by DNNs. AoA enjoys a significant increase in transferability when the traditional cross entropy loss is replaced with the attention loss. Since AoA alters the loss function only, it could be easily combined with other transferability-enhancement techniques and then achieve SOTA performance. We apply AoA to generate 50000 adversarial samples from ImageNet validation set to defeat many neural networks, and thus name the dataset as DAmageNet. 13 well-trained DNNs are tested on DAmageNet, and all of them have an error rate over 85 percent. Even with defenses or adversarial training, most models still maintain an error rate over 70 percent on DAmageNet. DAmageNet is the first universal adversarial dataset. It could be downloaded freely and serve as a benchmark for robustness testing and adversarial training.	[Chen, Sizhe; He, Zhengbao; Sun, Chengjin; Yang, Jie; Huang, Xiaolin] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China; [Chen, Sizhe; He, Zhengbao; Sun, Chengjin; Yang, Jie; Huang, Xiaolin] Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China; [Chen, Sizhe; He, Zhengbao; Sun, Chengjin; Yang, Jie; Huang, Xiaolin] MOE Key Lab Syst Control & Informat Proc, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University	Huang, XL (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.; Huang, XL (corresponding author), Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China.; Huang, XL (corresponding author), MOE Key Lab Syst Control & Informat Proc, Shanghai 200240, Peoples R China.	sizhe.chen@sjtu.edu.cn; lstefanie@sjtu.edu.cn; sunchengjin@sjtu.edu.cn; jieyang@sjtu.edu.cn; xiaolinhuang@sjtu.edu.cn			National Key Research Development Project [2018AAA0100702, 2019YFB1311503]; National Natural Science Foundation of China [61977046, 61876107, U1803261]	National Key Research Development Project; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was partially supported by National Key Research Development Project (No. 2018AAA0100702, 2019YFB1311503) and National Natural Science Foundation of China (No. 61977046, 61876107, U1803261). The authors are grateful to the anonymous reviewers for their insightful comments.	Abadi M, 2015, P 12 USENIX S OPERAT; Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Baluja S., 2017, ARXIV170309387; Barbu A, 2019, ADV NEUR IN, V32; Brendel W., 2018, PROC 6 INT C LEARN R; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Cheng S., 2019, P 32 ADV NEUR INF PR; Chollet F., 2015, KERAS; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Cohen J, 2019, PR MACH LEARN RES, V97; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong YP, 2019, PROC CVPR IEEE, P4307, DOI 10.1109/CVPR.2019.00444; Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957; Du J., 2019, P 8 INT C LEARN REPR; Ganin Y, 2016, J MACH LEARN RES, V17; Goodfellow I. J., 2015, P INT C LEARN REPR; Gu JD, 2019, LECT NOTES COMPUT SC, V11363, P119, DOI 10.1007/978-3-030-20893-6_8; Guo Chuan, 2018, ICLR; Guo Y., 2019, P ADV NEURAL INFORM, P3820; Han JF, 2019, IEEE I CONF COMP VIS, P5157, DOI 10.1109/ICCV.2019.00526; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendrycks D., 2019, ICLR, P1; Hendrycks Dan, 2019, ARXIV190707174; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ilyas A., 2019, P 7 INT C LEARN REPR; Ilyas A, 2018, PR MACH LEARN RES, V80; Iwana BK, 2019, IEEE INT CONF COMP V, P4176, DOI 10.1109/ICCVW.2019.00513; Kurakin A, 2018, ICLR, P99, DOI DOI 10.1201/9781351251389-8; Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191; Lin J., 2020, P 8 INT C LEARN REPR; Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8; Liu ZH, 2019, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2019.00095; Madry A., 2018, P ICLR VANC BC CAN; Meunier L., 2019, ARXIV191002244; Miyato Takeru, 2017, INT C LEARN REPR ICL; Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Mustafa A, 2020, IEEE T IMAGE PROCESS, V29, P1711, DOI 10.1109/TIP.2019.2940533; Papernot N, 2016, ARXIV160507277, DOI 10.48550/arXiv.1605.07277; Prakash A, 2018, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR.2018.00894; Ru B., 2020, P ICLR; Samek W., 2019, LNAI, V11700; Sankaranarayanan S, 2018, AAAI CONF ARTIF INTE, P4008; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Simonyan Karen, 2013, DEEP INSIDE CONVOLUT, P2; Sinha A., 2018, P INT C LEARN REPR; Song Y, 2018, ADV NEUR IN, V31; Springenberg J. T, 2015, ARXIV PREPRINT ARXIV; Su D, 2018, LECT NOTES COMPUT SC, V11216, P644, DOI 10.1007/978-3-030-01258-8_39; Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858; Szegedy C, 2014, P 2 INT C LERAN REPR; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tang SL, 2021, IEEE T PATTERN ANAL, V43, P1100, DOI 10.1109/TPAMI.2019.2936378; Tramonti F, 2019, PSYCHOL HEALTH MED, V24, P27, DOI 10.1080/13548506.2018.1510131; Vaswani A, 2017, ADV NEUR IN, V30; Wu D, 2019, 7 INT C LEARN REPR; Xie C., 2018, P 6 INT C LEARN REPR; Xie CH, 2019, PROC CVPR IEEE, P2725, DOI 10.1109/CVPR.2019.00284; Xie CH, 2019, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2019.00059; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang DH, 2019, ADV NEUR IN, V32; Zhang TY, 2019, PR MACH LEARN RES, V97; Zhou B., 2015, P 3 INT C LEARN REPR; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou J, 2015, NAT METHODS, V12, P931, DOI [10.1038/nmeth.3547, 10.1038/NMETH.3547]; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	71	12	12	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2188	2197		10.1109/TPAMI.2020.3033291	http://dx.doi.org/10.1109/TPAMI.2020.3033291			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33095710	Green Submitted			2022-12-18	WOS:000764815300038
J	Geng, X; Qian, X; Huo, ZW; Zhang, Y				Geng, Xin; Qian, Xin; Huo, Zengwei; Zhang, Yu			Head Pose Estimation Based on Multivariate Label Distribution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Magnetic heads; Pose estimation; Faces; Solid modeling; Three-dimensional displays; Training; Head pose estimation; multivariate label distribution; machine learning; label noise	OBJECT POSE; NETWORK; FORESTS; MODEL; AGE	Accurate ground-truth pose is essential to the training of most existing head pose estimation methods. However, in many cases, the "ground truth" pose is obtained in rather subjective ways, such as asking the subjects to stare at different markers on the wall. Thus it is better to use soft labels rather than explicit hard labels to indicate the pose of a face image. This paper proposes to associate a multivariate label distribution (MLD) to each image. An MLD covers a neighborhood around the original pose. Labeling the images with MLD can not only alleviate the problem of inaccurate pose labels, but also boost the training examples associated to each pose without actually increasing the total amount of training examples. Four algorithms are proposed to learn from MLD. Furthermore, an extension of MLD with the hierarchical structure is proposed to deal with fine-grained head pose estimation, which is named hierarchical multivariate label distribution (HMLD). Experimental results show that the MLD-based methods perform significantly better than the compared state-of-the-art head pose estimation algorithms. Moreover, the MLD-based methods appear much more robust against the label noise in the training set than the compared baseline methods.	[Geng, Xin; Qian, Xin; Huo, Zengwei; Zhang, Yu] Southeast Univ, Minist Educ, Sch Comp Sci & Engn, Nanjing 211189, Peoples R China; [Geng, Xin; Qian, Xin; Huo, Zengwei; Zhang, Yu] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing 211189, Peoples R China	Southeast University - China; Southeast University - China	Geng, X (corresponding author), Southeast Univ, Minist Educ, Sch Comp Sci & Engn, Nanjing 211189, Peoples R China.; Geng, X (corresponding author), Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing 211189, Peoples R China.	xgeng@seu.edu.cn; xqian@seu.edu.cn; huozw@seu.edu.cn; zhang_yu@seu.edu.cn		Qian, Xin/0000-0001-6711-8749	National Key Research and Development Plan of China [2017YFB1002801]; National Science Foundation of China [62076063, 61702095]; Collaborative Innovation Center of Novel Software Technology and Industrialization; Collaborative Innovation Center of Wireless Communications Technology	National Key Research and Development Plan of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Collaborative Innovation Center of Novel Software Technology and Industrialization; Collaborative Innovation Center of Wireless Communications Technology	This work was supported by the National Key Research and Development Plan of China (No. 2017YFB1002801), the National Science Foundation of China (62076063, 61702095), the Collaborative Innovation Center of Novel Software Technology and Industrialization, and the Collaborative Innovation Center of Wireless Communications Technology.	Ahn B, 2015, LECT NOTES COMPUT SC, V9005, P82, DOI 10.1007/978-3-319-16811-1_6; Al Haj M, 2012, PROC CVPR IEEE, P2602, DOI 10.1109/CVPR.2012.6247979; Baltrusaitis T, 2016, IEEE WINT CONF APPL; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; Barra P, 2020, IEEE T IMAGE PROCESS, V29, P5457, DOI 10.1109/TIP.2020.2984373; Borghi G, 2020, IEEE T PATTERN ANAL, V42, P596, DOI 10.1109/TPAMI.2018.2885472; Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583; Cha S.H, 2007, CITY, V1, P300, DOI DOI 10.1007/S00167-009-0884-Z; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; Drouard V, 2015, IEEE IMAGE PROC, P4624, DOI 10.1109/ICIP.2015.7351683; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fenzi M, 2013, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2013.103; Foytik J, 2013, INT J COMPUT VISION, V101, P270, DOI 10.1007/s11263-012-0567-y; Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658; Geng X, 2014, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2014.237; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Geng X, 2010, AAAI CONF ARTIF INTE, P451; Gourier N., 2006, Multimodal Technologies for Perception of Humans. First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR 2006. Revised Selected Papers (Lecture Notes in Computer Science Vol.4122), P270; Gourier N., 2004, PROC ICPR INT WORKSH, P1; Gu JW, 2017, PROC CVPR IEEE, P1531, DOI 10.1109/CVPR.2017.167; Guo G., 2008, 2008 19 INT C PATTER, P1; Gurbuz S, 2012, PATTERN RECOGN, V45, P33, DOI 10.1016/j.patcog.2011.06.007; Hara K, 2017, INT J COMPUT VISION, V122, P292, DOI 10.1007/s11263-016-0942-1; He K, 2014, LECT NOTES COMPUT SC, V8692, P450, DOI 10.1007/978-3-319-10593-2_30; Hsu HW, 2019, IEEE T MULTIMEDIA, V21, P1035, DOI 10.1109/TMM.2018.2866770; Huang B, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.11.005; Huang D, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995683; Ho HT, 2012, IEEE IMAGE PROC, P153, DOI 10.1109/ICIP.2012.6466818; Jilin Tu, 2006, Multimodal Technologies for Perception of Humans. First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR 2006. Revised Selected Papers (Lecture Notes in Computer Science Vol.4122), P281; Kostinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375; Lathuiliere S, 2017, PROC CVPR IEEE, P7149, DOI 10.1109/CVPR.2017.756; Lee D, 2015, IEEE I CONF COMP VIS, P1958, DOI 10.1109/ICCV.2015.227; Li CL, 2018, MULTIMED TOOLS APPL, V77, P14605, DOI 10.1007/s11042-017-5050-x; Li Z, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1810; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Liu XB, 2016, IEEE IMAGE PROC, P1289, DOI 10.1109/ICIP.2016.7532566; Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727; Ma BP, 2013, NEUROCOMPUTING, V115, P1, DOI 10.1016/j.neucom.2012.11.005; Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Papazov C, 2015, PROC CVPR IEEE, P4722, DOI 10.1109/CVPR.2015.7299104; Patacchiola M, 2017, PATTERN RECOGN, V71, P132, DOI 10.1016/j.patcog.2017.06.009; Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281; Saeed A, 2015, IEEE IMAGE PROC, P1752, DOI 10.1109/ICIP.2015.7351101; Sherrah J, 2001, IMAGE VISION COMPUT, V19, P807, DOI 10.1016/S0262-8856(00)00096-2; Stiefelhagen R., 2004, P POINT WORKSH VIS O, V1, P21; Sundararajan Kalaivani, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P50, DOI 10.1109/CVPRW.2015.7301354; Tsoumakas G., 2007, INT J DATA WAREHOUSI, V3, P1; Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740; Venturelli M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P194, DOI 10.5220/0006104501940201; Voit M, 2007, LECT NOTES COMPUT SC, V4122, P291; Wang Jie, 2017, [Computational Visual Media, 计算可视媒体], V3, P229; Wang YJ, 2019, PATTERN RECOGN, V94, P196, DOI 10.1016/j.patcog.2019.05.026; Xu LH, 2019, NEUROCOMPUTING, V337, P339, DOI 10.1016/j.neucom.2018.12.074; Yang JL, 2012, INT C PATT RECOG, P2492; Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118; Yin B., 2009, J COMPUT RES DEV, V6; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhao HD, 2016, AAAI CONF ARTIF INTE, P1422; Zhen X, 2015, PROC CVPR IEEE, P1211, DOI 10.1109/CVPR.2015.7298725; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	64	12	12	10	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1974	1991		10.1109/TPAMI.2020.3029585	http://dx.doi.org/10.1109/TPAMI.2020.3029585			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33031033				2022-12-18	WOS:000764815300024
J	Qi, GJ; Zhang, LH; Lin, F; Wang, X				Qi, Guo-Jun; Zhang, Liheng; Lin, Feng; Wang, Xiao			Learning Generalized Transformation Equivariant Representations Via AutoEncoding Transformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Training; Decoding; Data models; Mutual information; Image reconstruction; Gallium nitride; Generalized transformation equivariant representations (GTER); autoencoding transformations (AET); autoencoding variational transformations (AVT); unsupervised learning; semi-supervised learning		Transformation equivariant representations (TERs) aim to capture the intrinsic visual structures that equivary to various transformations by expanding the notion of translation equivariance underlying the success of convolutional neural networks (CNNs). For this purpose, we present both deterministic AutoEncoding Transformations (AET) and probabilistic AutoEncoding Variational Transformations (AVT) models to learn visual representations from generic groups of transformations. While the AET is trained by directly decoding the transformations from the learned representations, the AVT is trained by maximizing the joint mutual information between the learned representation and transformations. This results in generalized TERs (GTERs) equivariant against transformations in a more general fashion by capturing complex patterns of visual structures beyond the conventional linear equivariance under a transformation group. The presented approach can be extended to (semi-)supervised models by jointly maximizing the mutual information of the learned representation with both labels and transformations. Experiments demonstrate the proposed models outperform the state-of-the-art models in both unsupervised and (semi-)supervised tasks. Moreover, we show that the unsupervised representation can even surpass the fully supervised representation pretrained on ImageNet when they are fine-tuned for the object detection task.	[Qi, Guo-Jun] Futurewei Seattle Cloud Lab, Seattle, WA 98006 USA; [Zhang, Liheng] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA; [Lin, Feng] Univ Sci & Technol China, Dept Elect Informat Engn, Hefei, Anhui, Peoples R China; [Wang, Xiao] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47906 USA	State University System of Florida; University of Central Florida; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Qi, GJ (corresponding author), Futurewei Seattle Cloud Lab, Seattle, WA 98006 USA.	guojunq@gmail.com; lihengzhang1993@knights.ucf.edu; lin1993@mail.ustc.edu.cn; wang3702@purdue.edu		Wang, Xiao/0000-0003-4435-7098; Lin, Feng/0000-0001-8541-7400				Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Arjovsky M, 2017, PR MACH LEARN RES, V70; Barber D, 2004, ADV NEUR IN, V16, P201; Bojanowski P, 2017, PR MACH LEARN RES, V70; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Chang SY, 2014, IEEE DATA MINING, P60, DOI 10.1109/ICDM.2014.115; Chen T, 2020, PR MACH LEARN RES, V119; Chen XC, 2020, IEEE IJCNN; Cohen TS, 2016, PR MACH LEARN RES, V48; Cohen Taco S, 2016, ARXIV161208498; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Donahue J., 2016, ARXIV160509782; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V27, P766, DOI [DOI 10.1109/TPAMI.2015.2496141, 10.48550/arXiv.1406.6909]; Dumoulin Vincent, 2016, ARXIV E PRINTS; Edraki M, 2018, LECT NOTES COMPUT SC, V11209, P90, DOI 10.1007/978-3-030-01228-1_6; Gidaris Spyros, 2018, ARXIV180307728; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Higgins I., 2017, P INT C LEARN REPR T; Hinton G, 1994, ADV NEURAL INFORM PR, V6, DOI DOI 10.1021/jp906511z; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hinton Geoffrey E., 2018, INT C LEARN REPR; Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691; Kingma D.P., 2013, P 2 INT C LEARN REPR; Krahenbuhl P., 2015, ARXIV151106856; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Laine Samuli, 2016, ARXIV161002242; Lenssen Jan Eric, 2018, ARXIV180605086; Li RH, 2018, IEEE INT CONF ROBOT, P7286; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Netzer Y., 2011, READING DIGITS NATUR; Noroozi M, 2017, IEEE I CONF COMP VIS, P5899, DOI 10.1109/ICCV.2017.628; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Oyallon E, 2017, IEEE I CONF COMP VIS, P5619, DOI 10.1109/ICCV.2017.599; Oyallon E, 2015, PROC CVPR IEEE, P2865, DOI 10.1109/CVPR.2015.7298904; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053; Qi G.-J., 2009, P 17 ACM INT C MULT, P243; Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2; Qi GJ, 2018, PROC CVPR IEEE, P1517, DOI 10.1109/CVPR.2018.00164; Qi GJ, 2016, PROC CVPR IEEE, P2267, DOI 10.1109/CVPR.2016.249; Qi GJ, 2013, PROC INT CONF DATA, P793, DOI 10.1109/ICDE.2013.6544875; Qi GJ, 2010, IEEE T MULTIMEDIA, V12, P278, DOI 10.1109/TMM.2010.2046270; Qi Guo-Jun, 2017, ARXIV170106264; Radford A., 2015, ARXIV PREPR ARXIV151; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rifai S., 2011, PROC INT C MACH LEAR; Sabour Sara, 2017, PROC 31 INT C NEURAL; Salimans T, 2016, ADV NEUR IN, V29; Shu XB, 2018, IEEE T CIRC SYST VID, V28, P454, DOI 10.1109/TCSVT.2016.2607345; Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216; Tang ., 2008, P ACM C MULT, P631; Tang J., 2007, P 15 ACM INT C MULT, P297, DOI 10.1145/1291233.1291296.; Tarvainen Antti, 2017, CORR, Vabs/1703; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang B, 2018, LECT NOTES COMPUT SC, V11071, P759, DOI 10.1007/978-3-030-00934-2_84; Wang Xiao, 2019, ARXIV191109265; Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Xu H., 2019, ARXIV191212674; Zhang LH, 2019, PROC CVPR IEEE, P2542, DOI 10.1109/CVPR.2019.00265; Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhao YR, 2018, LECT NOTES COMPUT SC, V11213, P508, DOI 10.1007/978-3-030-01240-3_31; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhuang CX, 2019, IEEE I CONF COMP VIS, P6001, DOI 10.1109/ICCV.2019.00610	71	12	12	6	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2045	2057		10.1109/TPAMI.2020.3029801	http://dx.doi.org/10.1109/TPAMI.2020.3029801			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33035159	Green Submitted			2022-12-18	WOS:000764815300029
J	Sun, J; Chen, TY; Giannakis, GB; Yang, QM; Yang, ZY				Sun, Jun; Chen, Tianyi; Giannakis, Georgios B.; Yang, Qinmin; Yang, Zaiyue			Lazily Aggregated Quantized Gradient Innovation for Communication-Efficient Federated Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Quantization (signal); Servers; Technological innovation; Convergence; Frequency modulation; Distributed databases; Collaborative work; Federated learning; communication-efficient; gradient innovation; quantization		This paper focuses on communication-efficient federated learning problem, and develops a novel distributed quantized gradient approach, which is characterized by adaptive communications of the quantized gradients. Specifically, the federated learning builds upon the server-worker infrastructure, where the workers calculate local gradients and upload them to the server; then the server obtain the global gradient by aggregating all the local gradients and utilizes it to update the model parameter. The key idea to save communications from the worker to the server is to quantize gradients as well as skip less informative quantized gradient communications by reusing previous gradients. Quantizing and skipping result in 'lazy' worker-server communications, which justifies the term Lazily Aggregated Quantized (LAQ) gradient. Theoretically, the LAQ algorithm achieves the same linear convergence as the gradient descent in the strongly convex case, while effecting major savings in the communication in terms of transmitted bits and communication rounds. Empirically, extensive experiments using realistic data corroborate a significant communication reduction compared with state-of-the-art gradient- and stochastic gradient-based algorithms.	[Sun, Jun; Yang, Qinmin] Zhejiang Univ, Coll Control Sci & Engn, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China; [Chen, Tianyi] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; [Giannakis, Georgios B.] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA; [Giannakis, Georgios B.] Univ Minnesota, Digital Technol Ctr, Minneapolis, MN 55455 USA; [Yang, Zaiyue] Southern Univ Sci & Technol, Dept Mech & Energy Engn, Shenzhen 518055, Peoples R China	Zhejiang University; Rensselaer Polytechnic Institute; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; Southern University of Science & Technology	Yang, QM (corresponding author), Zhejiang Univ, Coll Control Sci & Engn, State Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.; Yang, ZY (corresponding author), Southern Univ Sci & Technol, Dept Mech & Energy Engn, Shenzhen 518055, Peoples R China.	sunjun16sj@gmail.com; chent18@rpi.edu; georgios@umn.edu; qmyang@zju.edu.cn; yangzy3@sustech.edu.cn	Yang, Zaiyue/AHB-2796-2022		NSFC [61873118]; Shenzhen Committee on Science and Innovations [GJHZ20180411143603361]; Department of Science and Technology of Guangdong Province [2018A050506003]; China Scholarship Council; Key-Area Research and Development Program of Guangdong Province [2018B010107002]; National Natural Science Foundation of China [61751205]; NSF [1901134]	NSFC(National Natural Science Foundation of China (NSFC)); Shenzhen Committee on Science and Innovations; Department of Science and Technology of Guangdong Province; China Scholarship Council(China Scholarship Council); Key-Area Research and Development Program of Guangdong Province; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); NSF(National Science Foundation (NSF))	The work of Jun Sun and Zaiyue Yang was supported in part by the NSFC Grant 61873118, in part by the Shenzhen Committee on Science and Innovations under Grant GJHZ20180411143603361, and in part by the Department of Science and Technology of Guangdong Province under Grant 2018A050506003. The work by Jun Sun was also supported by China Scholarship Council. The work of Qinmin Yang was supported in part by the Key-Area Research and Development Program of Guangdong Province (No. 2018B010107002), and in part by the National Natural Science Foundation of China (61751205). The work of Georgios Giannakis is supported partially by NSF 1901134. Part of the results in this paper has been presented in Proc. of Neural Information Processing, Vancouver, Canada, December 8-14, 2019 [1].	Aji A.F., 2017, P 2017 C EMP METH NA, DOI [10.18653/v1/D17-1045, DOI 10.18653/V1/D17-1045]; Alistarh D, 2018, ADV NEUR IN, V31; Alistarh D, 2017, ADV NEUR IN, V30; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arjevani Y., 2015, ADV NEURAL INFORM PR, V28, P1756; Basar T., 2018, ARXIV181203239; Bernstein J, 2018, PR MACH LEARN RES, V80; Chen TL, 2020, ANN OPER RES, V290, P813, DOI 10.1007/s10479-018-2969-x; Gurbuzbalaban M, 2017, SIAM J OPTIMIZ, V27, P1035, DOI 10.1137/15M1049695; Jiang P, 2018, ADV NEUR IN, V31; Jordan MI, 2019, J AM STAT ASSOC, V114, P668, DOI 10.1080/01621459.2018.1429274; Karimireddy SP, 2019, PR MACH LEARN RES, V97; Kingma D.P, P 3 INT C LEARNING R; Konecn J., 2016, ARXIV161005492; Konecny J., 2018, FRONT APPL MATH STAT, V4, P62; LeCun Y., 2010, MNIST HANDWRITTEN DI; Li Mu, 2014, ADV NEURAL INFORM PR, V27, P19; Lin YL, 2018, INT CONF SYST SCI EN; Magnusson S., 2019, ARXIV190211163; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Mishchenko Konstantin, 2019, ARXIV190109269; Msechu EJ, 2012, IEEE T SIGNAL PROCES, V60, P400, DOI 10.1109/TSP.2011.2171686; Peterson L. L., 2007, COMPUTER NETWORKS SY; Seide F, 2014, INTERSPEECH, P1058; Shamir O, 2014, PR MACH LEARN RES, V32, P1000; Stich SU, 2018, ADV NEUR IN, V31; Strom N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1488; Sun J., 2019, P ADV NEUR INF PROC, V32, P3370; Wang HY, 2018, ADV NEUR IN, V31; Wang J., 2018, ARXIV180807576; Wangni J., 2018, ADV NEURAL INFORM PR, P1299; Wen W., 2017, ADV NEURAL INFORM PR, P1, DOI DOI 10.1109/ICC.2017.7997306; Wu JX, 2018, PR MACH LEARN RES, V80; Yu D, 2019, ARXIV191111363; Yu H, 2019, PR MACH LEARN RES, V97; Zhang HT, 2017, PR MACH LEARN RES, V70; Zhang S., 2015, P ADV NEURAL INFORM, P685, DOI DOI 10.1145/3207677.3277958; Zheng SX, 2017, PR MACH LEARN RES, V70; Zhu L., P INT C NEUR INF PRO, p14 774	40	12	12	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2031	2044		10.1109/TPAMI.2020.3033286	http://dx.doi.org/10.1109/TPAMI.2020.3033286			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33095709				2022-12-18	WOS:000764815300028
J	Eberle, O; Buttner, J; Krautli, F; Muller, KR; Valleriani, M; Montavon, G				Eberle, Oliver; Buettner, Jochen; Kraeutli, Florian; Mueller, Klaus-Robert; Valleriani, Matteo; Montavon, Gregoire			Building and Interpreting Deep Similarity Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; Data models; Robustness; Neural networks; Taylor series; Feature extraction; Deep learning; Similarity; layer-wise relevance propagation; deep neural networks; explainable machine learning; digital humanities	KERNEL; REPRESENTATION; SUPPORT	Many learning algorithms such as kernel machines, nearest neighbors, clustering, or anomaly detection, are based on distances or similarities. Before similarities are used for training an actual machine learning model, we would like to verify that they are bound to meaningful patterns in the data. In this paper, we propose to make similarities interpretable by augmenting them with an explanation. We develop BiLRP, a scalable and theoretically founded method to systematically decompose the output of an already trained deep similarity model on pairs of input features. Our method can be expressed as a composition of LRP explanations, which were shown in previous works to scale to highly nonlinear models. Through an extensive set of experiments, we demonstrate that BiLRP robustly explains complex similarity models, e.g., built on VGG-16 deep neural network features. Additionally, we apply our method to an open problem in digital humanities: detailed assessment of similarity between historical documents, such as astronomical tables. Here again, BiLRP provides insight and brings verifiability into a highly engineered and problem-specific similarity model.	[Eberle, Oliver; Mueller, Klaus-Robert; Montavon, Gregoire] TU Berlin, Berlin Inst Technol, D-10587 Berlin, Germany; [Buettner, Jochen; Kraeutli, Florian; Valleriani, Matteo] Max Planck Inst Hist Sci, D-14159 Berlin, Germany; [Mueller, Klaus-Robert] Korea Univ, Dept Artificial Intelligence, Seoul 136713, South Korea; [Mueller, Klaus-Robert] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Technical University of Berlin; Max Planck Society; Korea University; Max Planck Society	Muller, KR; Montavon, G (corresponding author), TU Berlin, Berlin Inst Technol, D-10587 Berlin, Germany.	oliver.eberle@campus.tu-berlin.de; buettner@mpiwg-berlin.mpg.de; fkraeutli@mpiwg-berlin.mpg.de; klaus-robert.mueller@tu-berlin.de; valleriani@mpiwg-berlin.mpg.de; gregoire.montavon@tu-berlin.de	Mueller, Klaus-Robert/Y-3547-2019	Mueller, Klaus-Robert/0000-0002-3861-7685; Eberle, Oliver/0000-0002-6967-9950	German Ministry for Education and Research [01IS18025A, 01IS18037A]; German Research Foundation (DFG) as Math+: Berlin Mathematics Research Center [390685689]; Institute for Information & Communications Technology Planning & Evaluation (IITP) - Korea Government [2019-0-00079]	German Ministry for Education and Research(Federal Ministry of Education & Research (BMBF)); German Research Foundation (DFG) as Math+: Berlin Mathematics Research Center(German Research Foundation (DFG)); Institute for Information & Communications Technology Planning & Evaluation (IITP) - Korea Government(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea)	This work was supported by the German Ministry for Education and Research as BIFOLD -Berlin Institute for the Foundations of Learning and Data (Ref. 01IS18025A and Ref. 01IS18037A), and the German Research Foundation (DFG) as Math+: Berlin Mathematics Research Center (EXC 2046/1, Project-ID: 390685689). This work was also supported in part by the Institute for Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government (No. 2019-0-00079, Artificial Intelligence Graduate School Program, KoreaUniversity).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2014, P INT C LEARN REPR; [Anonymous], 2014, COMPUTER VISION SPOR, DOI DOI 10.1007/978-3-319-09396-3_9; Anselmi F, 2016, INF INFERENCE, V5, P134, DOI 10.1093/imaiai/iaw009; Bach F.R., 2004, P 21 INT C MACH LEAR, P6, DOI DOI 10.1145/1015330.1015424; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Baehrens D, 2010, J MACH LEARN RES, V11, P1803; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bishop C.M, 2006, PATTERN RECOGN; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613; Chmiela S, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06169-2; Chmiela S, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1603015; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Cui T., 2019, RECOVERING PAIRWISE; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363; Gartner T., 2003, ACM SIGKDD EXPLORATI, V5, P49; Glorot X., 2011, P 14 INT C ART INT S, P315; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646, DOI DOI 10.5555/2984093.2984166; He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Huang G.B., 2008, WORKSHOP FACESREAL L; Husson Matthieu, 2014, SUHAYL, V13, P103; Janizek J. D., 2020, EXPLAINING EXPLANATI; Kauffmann J, 2019, FROM CLUSTERING CLUS; Kauffmann J, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107198; Krautli F, 2018, DIGIT SCHOLARSH HUM, V33, P336, DOI 10.1093/llc/fqx047; Lapuschkin S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08987-4; Lapuschkin S, 2017, IEEE INT CONF COMP V, P1629, DOI 10.1109/ICCVW.2017.191; Lenc L, 2015, LECT NOTES ARTIF INT, V9414, P349, DOI 10.1007/978-3-319-27101-9_26; Leupold S, 2017, THESIS TU BERLIN BER; Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Lundberg SM, 2017, ADV NEUR IN, V30; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Micenkova B, 2013, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2013.132; Mikolov T., 2013, ARXIV; Montavon Gr<prime>egoire, 2019, EXPLAINABLE AI INTER, P193, DOI DOI 10.1007/978-3-030-28954-6_10; Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011; Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008; Nierman A., 2002, 5 ACM SIGMOD INT WOR, P61; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Pampalk E., 2005, P 6 INT C MUS INF RE, P628; Peters J, 2017, ADAPT COMPUT MACH LE; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Samek W., 2019, EXPLAINABLE INTERPRE, V11700; Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Schreiber S, 2017, PROC INT CONF DOC, P1162, DOI 10.1109/ICDAR.2017.192; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Simon M, 2020, IEEE T PATTERN ANAL, V42, P749, DOI 10.1109/TPAMI.2018.2885764; Smilkov D, 2017, ARXIV; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tsang M., 2018, P INT C LEARN REPR; Tsuda K, 2002, NEURAL COMPUT, V14, P2397, DOI 10.1162/08997660260293274; Tzompanaki K, 2012, P MUS WEB INT C CULT; Valleriani M, 2019, SPHAERA JOHANNES SAC, P1; Valleriani M., 2019, J HIST NETW RES, V3, P50, DOI [10.25517/jhnr.v3i1.63, DOI 10.25517/JHNR.V3I1.63]; van der Maaten L, 2012, MACH LEARN, V87, P33, DOI 10.1007/s10994-011-5273-4; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Watkins C, 2000, ADV NEUR IN, P39; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613; Zhang WL, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1475, DOI 10.1145/2783258.2783304; Zheng M., 2019, LEARNING SIMILARITY; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; Zintgraf Luisa M., 2017, P ICLR	86	12	13	8	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1149	1161		10.1109/TPAMI.2020.3020738	http://dx.doi.org/10.1109/TPAMI.2020.3020738			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32870784	Green Submitted, hybrid			2022-12-18	WOS:000752018000007
J	Zhang, L; He, ZW; Yang, Y; Wang, L; Gao, XB				Zhang, Lei; He, Zhenwei; Yang, Yi; Wang, Liang; Gao, X-B			Tasks Integrated Networks: Joint Detection and Retrieval for Image Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image search; object detection; re-identification; retrieval; deep learning	RECOGNITION	The traditional object (person) retrieval (re-identification) task aims to learn a discriminative feature representation with intra-similarity and inter-dissimilarity, which supposes that the objects in an image are manually or automatically pre-cropped exactly. However, in many real-world searching scenarios (e.g., video surveillance), the objects (e.g., persons, vehicles, etc.) are seldom accurately detected or annotated. Therefore, object-level retrieval becomes intractable without bounding-box annotation, which leads to a new but challenging topic, i.e., image-level search with multi-task integration of joint detection and retrieval. In this paper, to address the image search issue, we first introduce an end-to-end Integrated Net (I-Net), which has three merits: 1) A Siamese architecture and an on-line pairing strategy for similar and dissimilar objects in the given images are designed. Benefited by the Siamese structure, I-Net learns the shared feature representation, because, on which, both object detection and classification tasks are handled. 2) A novel on-line pairing (OLP) loss is introduced with a dynamic feature dictionary, which alleviates the multi-task training stagnation problem, by automatically generating a number of negative pairs to restrict the positives. 3) A hard example priority (HEP) based softmax loss is proposed to improve the robustness of classification task by selecting hard categories. The shared feature representation of I-Net may restrict the task-specific flexibility and learning capability between detection and retrieval tasks. Therefore, with the philosophy of divide and conquer, we further propose an improved I-Net, called DC-I-Net, which makes two new contributions: 1) two modules are tailored to handle different tasks separately in the integrated framework, such that the task specification is guaranteed. 2) A class-center guided HEP loss (C2HEP) by exploiting the stored class centers is proposed, such that the intra-similarity and inter-dissimilarity can be captured for ultimate retrieval. Extensive experiments on famous image-level search oriented benchmark datasets, such as CUHK-SYSU dataset andPRWdataset for person search and the large-scaleWebTattoo dataset for tattoo search, demonstrate that the proposed DC-I-Net outperforms the state-of-the-art tasks-integrated and tasks-separated image search models.	[Zhang, Lei; He, Zhenwei] Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China; [Yang, Yi] Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia; [Wang, Liang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Gao, X-B] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China	Chongqing University; University of Technology Sydney; Chinese Academy of Sciences; Institute of Automation, CAS; Chongqing University of Posts & Telecommunications	Zhang, L (corresponding author), Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.	leizhang@cqu.edu.cn; hzw@cqu.edu.cn; yi.yang@uts.edu.au; wangliang@nlpr.ia.ac.cn; gaoxb@cqupt.edu.cn	Yang, Yi/B-9273-2017; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; Zhang, Lei/0000-0002-5305-8543	National Science Fund of China [61771079]; Chongqing Youth Talent Program	National Science Fund of China(National Natural Science Foundation of China (NSFC)); Chongqing Youth Talent Program	The authors would like to thank Dr. Wanli Ouyang from the University of Sydney for his help in revising the paper and proposing constructive suggestions. Lei Zhang was supported by the National Science Fund of China under Grants (61771079) and the Chongqing Youth Talent Program.	Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Cao C, 2017, IEEE WINT CONF APPL, P91, DOI 10.1109/WACV.2017.18; Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6; Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45; Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929; Chen WH, 2017, AAAI CONF ARTIF INTE, P3988; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110; Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Han CC, 2019, IEEE I CONF COMP VIS, P9813, DOI 10.1109/ICCV.2019.00991; Han H, 2019, IEEE T PATTERN ANAL, V41, P2333, DOI 10.1109/TPAMI.2019.2891584; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Z., 2018, P AS C COMP VSI, P349; Hrkac T., 2016, P OAGM ARW JOINT WOR, P131; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461; Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu FY, 2019, IEEE I CONF COMP VIS, P6638, DOI 10.1109/ICCV.2019.00674; Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61; Liu Jiawei, 2016, ACM MM, P192, DOI [10.1145/2964284.2967209, DOI 10.1145/2964284.2967209]; Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443; Nam W, 2014, ADV NEUR IN, V27; Ngan M., 2015, 8078 NIST, P1; Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shen YH, 2018, IEEE T NEUR NET LEAR, V29, P5960, DOI 10.1109/TNNLS.2018.2816021; Sohn K, 2016, ADV NEUR IN, V29; Song B, 2010, IEEE T IMAGE PROCESS, V19, P2564, DOI 10.1109/TIP.2010.2052823; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Song HM, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P146, DOI 10.1109/BigMM.2017.17; Sun YF, 2021, IEEE T PATTERN ANAL, V43, P902, DOI 10.1109/TPAMI.2019.2938523; Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Xiao JM, 2019, PATTERN RECOGN, V87, P332, DOI 10.1016/j.patcog.2018.10.028; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xiao Tong, 2016, ARXIV160401850; Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226; Xu Q., 2016, IEEE T IND ELECTRON, P1; Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113; Zemel, 2017, P IEEE 30 INT C TOOL, P260; Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28; Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; ZHENG L, 2016, PROC IEEE C COMPUT V, P1367; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531; Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389	68	12	12	13	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					456	473		10.1109/TPAMI.2020.3009758	http://dx.doi.org/10.1109/TPAMI.2020.3009758			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750818	Green Submitted			2022-12-18	WOS:000728561300033
J	Karim, F; Majumdar, S; Darabi, H				Karim, Fazle; Majumdar, Somshubra; Darabi, Houshang			Adversarial Attacks on Time Series	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series analysis; Computational modeling; Data models; Neural networks; Machine learning; Training; Computer vision; Time series classification; adversarial machine learning; perturbation methods; deep learning	CLASSIFICATION	Time series classification models have been garnering significant importance in the research community. However, not much research has been done on generating adversarial samples for these models. These adversarial samples can become a security concern. In this paper, we propose utilizing an adversarial transformation network (ATN) on a distilled model to attack various time series classification models. The proposed attack on the classification model utilizes a distilled model as a surrogate that mimics the behavior of the attacked classical time series classification models. Our proposed methodology is applied onto 1-nearest neighbor dynamic time warping (1-NN DTW) and a fully convolutional network (FCN), all of which are trained on 42 University of California Riverside (UCR) datasets. In this paper, we show both models were susceptible to attacks on all 42 datasets. When compared to Fast Gradient Sign Method, the proposed attack generates a larger faction of successful adversarial black-box attacks. A simple defense mechanism is successfully devised to reduce the fraction of successful adversarial samples. Finally, we recommend future researchers that develop time series classification models to incorporating adversarial data samples into their training data sets to improve resilience on adversarial samples.	[Karim, Fazle; Darabi, Houshang] Univ Illinois, Mech & Ind Engn, Chicago, IL 60607 USA; [Majumdar, Somshubra] Univ Illinois, Comp Sci, Chicago, IL 60607 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Darabi, H (corresponding author), Univ Illinois, Mech & Ind Engn, Chicago, IL 60607 USA.	karim1@uic.edu; smajum6@uic.edu; hdarabi@uic.edu		Majumdar, Somshubra/0000-0001-5635-4893				Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385; Alzantot Moustafa, 2018, EMNLP; Bagnall A, 2015, IEEE T KNOWL DATA EN, V27, P2522, DOI 10.1109/TKDE.2015.2416723; Baluja S., 2017, ARXIV170309387; Boyan J., 1996, PROC AAAI WORKSHOP I, P1; Bucilua Cristian, 2006, P 12 ACM SIGKDD INT, P535, DOI [10.1145/1150402.1150464, DOI 10.1145/1150402.1150464]; Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009; Dau H. A., 2018, UCR TIME SERIES CLAS; Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1; Hinton G., 2015, ARXIV150302531; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jia Robin, 2017, P 2017 C EMP METH NA, P2021, DOI DOI 10.18653/V1/D17-1215; Kampouraki A, 2009, IEEE T INF TECHNOL B, V13, P512, DOI 10.1109/TITB.2008.2003323; Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014; Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939; Kate RJ, 2016, DATA MIN KNOWL DISC, V30, P283, DOI 10.1007/s10618-015-0418-x; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; LeCun Y., 2015, LENET 5 CONVOLUTIONA, P14; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Madry Aleksander, 2017, ARXIV; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Oregi I, 2018, STUD COMPUT INTELL, V798, P26, DOI 10.1007/978-3-319-99626-4_3; Papernot N, 2016, ARXIV160507277, DOI 10.48550/arXiv.1605.07277; Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325; Rakthanmanon T., 2013, P 2013 SIAM INT C DA, P668, DOI [10.1137/1.9781611972832.74, DOI 10.1137/1.9781611972832.74]; Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P56, DOI 10.1109/JBHI.2016.2633287; Schafer P, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P637, DOI 10.1145/3132847.3132980; Schafer P, 2015, DATA MIN KNOWL DISC, V29, P1505, DOI 10.1007/s10618-014-0377-7; Sharabiani A, 2018, KNOWL INF SYST, V57, P359, DOI 10.1007/s10115-018-1163-4; Sharabiani A, 2017, IEEE T SYST MAN CY-S, V47, P2688, DOI 10.1109/TSMC.2017.2699333; Sirisambhand K, 2019, ADV INTELL SYST, V797, P717, DOI 10.1007/978-981-13-1165-9_65; Song C, 2018, IEEE COMP SOC ANN, P476, DOI 10.1109/ISVLSI.2018.00092; Spinoulas L, 2015, IEEE COMPUT SOC CONF; Tramer F., 2017, ARXIV170507204; Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039; Xi X., 2006, P 23 INT C MACHINE L, P1033, DOI 10.1145/1143844.1143974; Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017; Zhang MM, 2019, IEEE T PATTERN ANAL, V41, P1783, DOI 10.1109/TPAMI.2018.2871688	39	12	12	4	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3309	3320		10.1109/TPAMI.2020.2986319	http://dx.doi.org/10.1109/TPAMI.2020.2986319			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32286957	Green Submitted			2022-12-18	WOS:000692232400007
J	Li, M; Zuo, WM; Gu, SH; You, J; Zhang, D				Li, Mu; Zuo, Wangmeng; Gu, Shuhang; You, Jane; Zhang, David			Learning Content-Weighted Deep Image Compression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image coding; Entropy; Context modeling; Adaptation models; Decoding; Quantization (signal); Bit rate; Lossy image compression; convolutional networks; arithmetic codings		Learning-based lossy image compression usually involves the joint optimization of rate-distortion performance, and requires to cope with the spatial variation of image content and contextual dependence among learned codes. Traditional entropy models can spatially adapt the local bit rate based on the image content, but usually are limited in exploiting context in code space. On the other hand, most deep context models are computationally very expensive and cannot efficiently perform decoding over the symbols in parallel. In this paper, we present a content-weighted encoder-decoder model, where the channel-wise multi-valued quantization is deployed for the discretization of the encoder features, and an importance map subnet is introduced to generate the importance masks for spatially varying code pruning. Consequently, the summation of importance masks can serve as an upper bound of the length of bitstream. Furthermore, the quantized representations of the learned code and importance map are still spatially dependent, which can be losslessly compressed using arithmetic coding. To compress the codes effectively and efficiently, we propose an upper-triangular masked convolutional network (triuMCN) for large context modeling. Experiments show that the proposed method can produce visually much better results, and performs favorably against deep and traditional lossy image compression approaches.	[Li, Mu; You, Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China; [Zuo, Wangmeng] Peng Cheng Lab, Shenzhen 518066, Guangdong, Peoples R China; [Gu, Shuhang] Univ Sydney, Sch EIE, Darlington, NSW 2006, Australia; [Zhang, David] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen, Peoples R China; [Zhang, David] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen Res Inst Big Data, Shenzhen 518172, Guangdong, Peoples R China	Hong Kong Polytechnic University; Harbin Institute of Technology; Peng Cheng Laboratory; University of Sydney; Chinese University of Hong Kong, Shenzhen	Zuo, WM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.	csmuli@comp.polyu.edu.hk; cswmzuo@gmail.com; shuhanggu@gmail.com; csyjia@comp.polyu.edu.hk; davidzhang@cuhk.edu.cn	Li, Mu/GLU-3868-2022	Li, Mu/0000-0002-7327-3304	NSFC Fund [61671182, 61906162, U19A2073]; Shenzhen Research Institute of Big Data, Shenzhen Institute of Artificial Intelligence and Robotics for Society; China Postdoctoral Science Foundation [2019TQ0316, 2019M662198]; NVIDIA Corporation	NSFC Fund(National Natural Science Foundation of China (NSFC)); Shenzhen Research Institute of Big Data, Shenzhen Institute of Artificial Intelligence and Robotics for Society; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); NVIDIA Corporation	This work was supported in part by the NSFC Fund (No. 61671182, 61906162, U19A2073), Shenzhen Research Institute of Big Data, Shenzhen Institute of Artificial Intelligence and Robotics for Society, and China Postdoctoral Science Foundation (2019TQ0316, 2019M662198). The authors would like to thank the support from NVIDIA Corporation for donating the TITAN Xp GPU used in this work.	Agustsson E., 2018, P IEEE CVF C COMP VI, P2587; Agustsson E, 2017, ADV NEUR IN, V30; Asuni N, 2014, SMART TOOLS APPS GRA, P8, DOI [10.2312/STAG.20141242, DOI 10.2312/STAG.20141242]; Asuni N., 2013, J GRAPH TOOLS, V17, P113, DOI DOI 10.1080/2165347X.2015.1024298; Ball Johannes, 2018, INT C LEARN REPR ICL; Balle J., 2017, P INT C LEARN REPR; Bellard F, 2019, BPG IMAGE FORMAT; Courbariaux Matthieu, 2016, BINARIZED NEURAL NET; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang GL, 2017, IEEE ICC; Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461; Kingma D.P., 2015, INT C LEARN REPR ICL; Li M., 2018, INTRO MATH MODELING; Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173; Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Minnen D., 2018, P 31 INT C NEUR INF, p10 794; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Rippel O, 2017, PR MACH LEARN RES, V70; Said A, 2004, HPL200476, P64; Samuelsson J, 2018, P IEEE C COMP VIS PA, P2595; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804; Sukthankar R., 2015, ARXIV PREPRINT ARXIV; Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191; Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194; Tang Z., 2018, P IEEE C COMP VIS PA, P2567; Theis Lucas, 2017, INT C LEARN REPR; Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577; van den Oord A, 2016, ADV NEUR IN, V29; van den Oord A, 2016, PR MACH LEARN RES, V48; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Wang Z, 2003, CONF REC ASILOMAR C, P1398; WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771; Xie J., 2012, ADV NEURAL INFORM PR, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605; Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhou L., 2018, P IEEE C COMPUTER VI, P2617; Zhou Shuchang, 2016, P IEEE C COMP VIS PA	45	12	12	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3446	3461		10.1109/TPAMI.2020.2983926	http://dx.doi.org/10.1109/TPAMI.2020.2983926			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32248094	Green Submitted			2022-12-18	WOS:000692232400015
J	Zhang, F; Wang, JJ; Wang, WD; Xu, C				Zhang, Feng; Wang, Jianjun; Wang, Wendong; Xu, Chen			Low-Tubal-Rank Plus Sparse Tensor Recovery With Prior Subspace Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensile stress; Robustness; Principal component analysis; Convex functions; Face; Data models; Singular value decomposition; Tensor robust principal component analysis; tensor singular value decomposition; tensor principal components pursuit; prior subspace information; ADMM	FACTORIZATION; COMPLETION; APPROXIMATION; ALGORITHM; MODELS; IMAGE	Tensor principal component pursuit (TPCP) is a powerful approach in the tensor robust principal component analysis (TRPCA), where the goal is to decompose a data tensor to a low-tubal-rank part plus a sparse residual. TPCP is shown to be effective under certain tensor incoherence conditions, which can be restrictive in practice. In this paper, we propose a Modified-TPCP, which incorporates the prior subspace information in the analysis. With the aid of prior info, the proposed method is able to recover the low-tubal-rank and the sparse components under a significantly weaker incoherence assumption. We further design an efficient algorithm to implement Modified-TPCP based upon the alternating direction method of multipliers (ADMM). The promising performance of the proposed method is supported by simulations and real data applications.	[Zhang, Feng; Wang, Wendong] Southwest Univ, Sch Math & Stat, Chongqing 400715, Peoples R China; [Wang, Jianjun] Southwest Univ, Coll Artificial Intelligence, Chongqing 400715, Peoples R China; [Xu, Chen] Univ Ottawa, Dept Math & Stat, Ottawa, ON K1N 6N5, Canada	Southwest University - China; Southwest University - China; University of Ottawa	Wang, JJ (corresponding author), Southwest Univ, Coll Artificial Intelligence, Chongqing 400715, Peoples R China.	zhangf@email.swu.edu.cn; wdwang@swu.edu.cn; wjj@swu.edu.cn; cx3@uottawa.ca		Zhang, Feng/0000-0003-1000-8877; Wang, Jianjun/0000-0002-5344-4460; Wang, Wendong/0000-0002-9041-1721	National Natural Science Foundation of China [61673015, 61273020, 11690014]; Fundamental Research Funds for the Central Universities [XDJK2018C076, SWU1809002]; China Postdoctoral Science Foundation [2018M643390]; Graduate Student Scientific Research Innovation Projects in Chongqing [CYB19083]; Natural Sciences and Engineering Research Council of Canada [RGPIN-2016-05024]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Graduate Student Scientific Research Innovation Projects in Chongqing; Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	work was supported by the National Natural Science Foundation of China (Grants 61673015, 61273020, and 11690014), Fundamental Research Funds for the Central Universities (Grants XDJK2018C076 and SWU1809002), China Postdoctoral Science Foundation (Grant 2018M643390), Graduate Student Scientific Research Innovation Projects in Chongqing (Grant CYB19083) and Natural Sciences and Engineering Research Council of Canada (Grant RGPIN-2016-05024).	Bengua JA, 2017, IEEE T IMAGE PROCESS, V26, P2466, DOI 10.1109/TIP.2017.2672439; Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Cao WF, 2018, IEEE J-STARS, V11, P3863, DOI 10.1109/JSTARS.2018.2866815; Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262; Chen WG, 2019, APPL COMPUT HARMON A, V46, P417, DOI 10.1016/j.acha.2018.02.003; Chen YY, 2018, IEEE J-STSP, V12, P1364, DOI 10.1109/JSTSP.2018.2873148; Chen YD, 2015, IEEE T INFORM THEORY, V61, P2909, DOI 10.1109/TIT.2015.2415195; Chiang KY, 2016, PR MACH LEARN RES, V48; Dian RW, 2019, IEEE T NEUR NET LEAR, V30, P2672, DOI 10.1109/TNNLS.2018.2885616; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204; Eftekhari A, 2018, IEEE T INFORM THEORY, V64, P4044, DOI 10.1109/TIT.2018.2816685; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329; Jiang T., 2017, ARXIV171205870; Jiang TX, 2019, IEEE T IMAGE PROCESS, V28, P2089, DOI 10.1109/TIP.2018.2880512; Jiang TX, 2018, INFORM SCIENCES, V436, P403, DOI 10.1016/j.ins.2018.01.035; Karatzoglou A, 2010, P 4 ACM C REC SYST, P79, DOI DOI 10.1145/1864708.1864727; Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I; Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; Kong H, 2018, IEEE J-STSP, V12, P1405, DOI 10.1109/JSTSP.2018.2879185; Kreimer N, 2013, INT CONF ACOUST SPEE, P4275, DOI 10.1109/ICASSP.2013.6638466; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin Z., 2010, ARXIV10095055, DOI DOI 10.1016/J.JSB.2012.10.010; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760; Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4595, DOI 10.1109/TSP.2010.2051150; Wang JJ, 2019, SIGNAL PROCESS, V158, P116, DOI 10.1016/j.sigpro.2019.01.001; Wang Y, 2018, IEEE J-STARS, V11, P1227, DOI 10.1109/JSTARS.2017.2779539; Wang Y, 2017, IEEE GEOSCI REMOTE S, V14, P2457, DOI 10.1109/LGRS.2017.2771212; Wang Y, 2014, SIGNAL PROCESS, V104, P188, DOI 10.1016/j.sigpro.2014.03.040; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xia D, 2019, FOUND COMPUT MATH, V19, P1265, DOI 10.1007/s10208-018-09408-6; Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888; Xue NN, 2019, IEEE T PATTERN ANAL, V41, P2349, DOI 10.1109/TPAMI.2019.2902556; Yuan M, 2017, IEEE T INFORM THEORY, V63, P6753, DOI 10.1109/TIT.2017.2724549; Yuan M, 2016, FOUND COMPUT MATH, V16, P1031, DOI 10.1007/s10208-015-9269-5; Zhan JC, 2015, IEEE T SIGNAL PROCES, V63, P3332, DOI 10.1109/TSP.2015.2421485; Zhang CH, 2017, STAT OPTIMAL C UNPUB; Zhang X., 2013, ADV NEURAL INF PROCE, V26, P1637; Zhang XQ, 2021, IEEE T PATTERN ANAL, V43, P238, DOI 10.1109/TPAMI.2019.2929043; Zhang XQ, 2014, AAAI CONF ARTIF INTE, P1362; Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466; Zhou P, 2017, PROC CVPR IEEE, P3938, DOI 10.1109/CVPR.2017.419	54	12	12	7	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3492	3507		10.1109/TPAMI.2020.2986773	http://dx.doi.org/10.1109/TPAMI.2020.2986773			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32305896				2022-12-18	WOS:000692232400018
J	Liao, QF; Sun, D; Andreasson, H				Liao, Qianfang; Sun, Da; Andreasson, Henrik			Point Set Registration for 3D Range Scans Using Fuzzy Cluster-Based Metric and Efficient Global Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Measurement; Optimization; Three-dimensional displays; Iterative closest point algorithm; Quality assessment; Robustness; Convergence; Point set registration; fuzzy clusters; registration quality assessment; 3D range scans; branch-and-bound	ROBUST; SYSTEM; ICP	This study presents a new point set registration method to align 3D range scans. In our method, fuzzy clusters are utilized to represent a scan, and the registration of two given scans is realized by minimizing a fuzzy weighted sum of the distances between their fuzzy cluster centers. This fuzzy cluster-based metric has a broad basin of convergence and is robust to noise. Moreover, this metric provides analytic gradients, allowing standard gradient-based algorithms to be applied for optimization. Based on this metric, the outlier issues are addressed. In addition, for the first time in rigid point set registration, a registration quality assessment in the absence of ground truth is provided. Furthermore, given specified rotation and translation spaces, we derive the upper and lower bounds of the fuzzy cluster-based metric and develop a branch-and-bound (BnB)-based optimization scheme, which can globally minimize the metric regardless of the initialization. This optimization scheme is performed in an efficient coarse-to-fine fashion: First, fuzzy clustering is applied to describe each of the two given scans by a small number of fuzzy clusters. Then, a global search, which integrates BnB and gradient-based algorithms, is implemented to achieve a coarse alignment for the two scans. During the global search, the registration quality assessment offers a beneficial stop criterion to detect whether a good result is obtained. Afterwards, a relatively large number of points of the two scans are directly taken as the fuzzy cluster centers, and then, the coarse solution is refined to be an exact alignment using the gradient-based local convergence. Compared to existing counterparts, this optimization scheme makes a large improvement in terms of robustness and efficiency by virtue of the fuzzy cluster-based metric and the registration quality assessment. In the experiments, the registration results of several 3D range scan pairs demonstrate the accuracy and effectiveness of the proposed method, as well as its superiority to state-of-the-art registration approaches.	[Liao, Qianfang; Sun, Da; Andreasson, Henrik] Orebro Univ, Ctr Appl Autonomous Sensor Syst AASS, S-70281 Orebro, Sweden	Orebro University	Sun, D (corresponding author), Orebro Univ, Ctr Appl Autonomous Sensor Syst AASS, S-70281 Orebro, Sweden.	Qianfang.Liao@oru.se; Da.Sun@oru.se; Henrik.Andreasson@oru.se		Sun, Da/0000-0002-0334-2554; Andreasson, Henrik/0000-0002-2953-1564	Semantic Robots Research Profile - Swedish Knowledge Foundation (KKS)	Semantic Robots Research Profile - Swedish Knowledge Foundation (KKS)	This work was supported by the Semantic Robots Research Profile, funded by the Swedish Knowledge Foundation (KKS). The authors would like to thank the anonymous reviewers for their valuable comments and suggestions.	Andreasson H., 2007, P EUR C MOB ROB ECMR, P192; [Anonymous], 2011, ROBOTIC 3D SCAN REPO; Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178; Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Elbaz G, 2017, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2017.265; Evangelidis GD, 2018, IEEE T PATTERN ANAL, V40, P1397, DOI 10.1109/TPAMI.2017.2717829; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; Fletcher R., 2013, PRACTICAL METHODS OP; Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507; Giraldo LGS, 2017, PROC CVPR IEEE, P2454, DOI 10.1109/CVPR.2017.263; Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Liao QF, 2018, IEEE T FUZZY SYST, V26, P2510, DOI 10.1109/TFUZZ.2018.2791929; Liao QF, 2021, IEEE T CYBERNETICS, V51, P947, DOI 10.1109/TCYB.2019.2896530; Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160; Magnusson M, 2007, J FIELD ROBOT, V24, P803, DOI 10.1002/rob.20204; Maiseli B, 2017, J VIS COMMUN IMAGE R, V46, P95, DOI 10.1016/j.jvcir.2017.03.012; Medan G, 2017, IEEE T MED IMAGING, V36, P497, DOI 10.1109/TMI.2016.2615653; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Nuchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Papazov C, 2011, COMPUT VIS IMAGE UND, V115, P1598, DOI 10.1016/j.cviu.2011.05.008; Pitiot A, 2007, INT J COMPUT VISION, V71, P71, DOI 10.1007/s11263-006-8114-3; Rangarajan A, 1997, Med Image Anal, V1, P379; Robertson C, 2002, COMPUT VIS IMAGE UND, V87, P39, DOI 10.1006/cviu.2002.0981; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012; Sandhu R, 2010, IEEE T PATTERN ANAL, V32, P1459, DOI 10.1109/TPAMI.2009.142; Segal A. V., 2009, P ROBOT SCI SYST, V2; Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108; Stanford Computer Graphics Laboratory, 2005, STANF 3D SCANN REP STANF 3D SCANN REP; Stoyanov T, 2013, IEEE INT C INT ROBOT, P4702, DOI 10.1109/IROS.2013.6697033; Stoyanov T, 2012, INT J ROBOT RES, V31, P1377, DOI 10.1177/0278364912460895; Sun D, 2020, IEEE T ROBOT, V36, P1022, DOI 10.1109/TRO.2020.2973099; Sun D, 2020, IEEE T HUM-MACH SYST, V50, P55, DOI 10.1109/THMS.2019.2960676; Sun D, 2019, AUTOMATICA, V106, P358, DOI 10.1016/j.automatica.2019.04.033; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Turk G., 1998, LARGE GEOMETRIC MODE; Tustison NJ, 2011, IEEE T MED IMAGING, V30, P451, DOI 10.1109/TMI.2010.2086065; Wachowiak MP, 2004, IEEE T EVOLUT COMPUT, V8, P289, DOI [10.1109/TEVC.2004.826068, 10.1109/tevc.2004.826068]; Wu SH, 2018, IEEE T PATTERN ANAL, V40, P2529, DOI 10.1109/TPAMI.2017.2754254; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; Zhang JS, 2003, IEEE T SYST MAN CY B, V33, P983, DOI 10.1109/TSMCB.2003.816993	53	12	12	3	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3229	3246		10.1109/TPAMI.2020.2978477	http://dx.doi.org/10.1109/TPAMI.2020.2978477			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32149624	Green Submitted			2022-12-18	WOS:000681124300028
J	Xu, YH; Xie, LX; Dai, WR; Zhang, XP; Chen, X; Qi, GJ; Xiong, HK; Tian, Q				Xu, Yuhui; Xie, Lingxi; Dai, Wenrui; Zhang, Xiaopeng; Chen, Xin; Qi, Guo-Jun; Xiong, Hongkai; Tian, Qi			Partially-Connected Neural Architecture Search for Reduced Computational Redundancy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Redundancy; Network architecture; Stability analysis; Microprocessors; Space exploration; Convolution; Neural architecture search; differentiable architecture search; regularization; normalization	NETWORKS	Differentiable architecture search (DARTS) enables effective neural architecture search (NAS) using gradient descent, but suffers from high memory and computational costs. In this paper, we propose a novel approach, namely Partially-Connected DARTS (PC-DARTS), to achieve efficient and stable neural architecture search by reducing the channel and spatial redundancies of the super-network. In the channel level, partial channel connection is presented to randomly sample a small subset of channels for operation selection to accelerate the search process and suppress the over-fitting of the super-network. Side operation is introduced for bypassing (non-sampled) channels to guarantee the performance of searched architectures under extremely low sampling rates. In the spatial level, input features are down-sampled to eliminate spatial redundancy and enhance the efficiency of the mixed computation for operation selection. Furthermore, edge normalization is developed to maintain the consistency of edge selection based on channel sampling with the architectural parameters for edges. Theoretical analysis shows that partial channel connection and parameterized side operation are equivalent to regularizing the super-network on the weights and architectural parameters during bilevel optimization. Experimental results demonstrate that the proposed approach achieves higher search speed and training stability than DARTS. PC-DARTS obtains a top-1 error rate of 2.55 percent on CIFAR-10 with 0.07 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.1 percent on ImageNet (under the mobile setting) within 2.8 GPU-days.	[Xu, Yuhui; Xiong, Hongkai] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China; [Xie, Lingxi; Zhang, Xiaopeng; Chen, Xin; Tian, Qi] Huawei Inc, Shenzhen 518129, Guangdong, Peoples R China; [Dai, Wenrui] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China; [Qi, Guo-Jun] Hangzhou Dianzi Univ, Sch Artificial Intelligence, Hangzhou 310018, Zhejiang, Peoples R China	Shanghai Jiao Tong University; Huawei Technologies; Shanghai Jiao Tong University; Hangzhou Dianzi University	Dai, WR (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.	yuhuixu@sjtu.edu.cn; 198808xc@gmail.com; daiwenrui@sjtu.edu.cn; zxphistory@gmail.com; chenxin061@gmail.com; guojunq@gmail.com; xionghongkai@sjtu.edu.cn; tian.qi1@huawei.com	Xu, Yuhui/AAW-6061-2021	Xiong, Hongkai/0000-0003-4552-0029; Xu, Yuhui/0000-0002-7109-7140	National Natural Science Foundation of China [61971285, 61720106001, 61932022]; Program of Shanghai Academic Research Leader [17XD1401900]; Program of Shanghai Science and Technology Innovation Project [20511100100]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Program of Shanghai Academic Research Leader; Program of Shanghai Science and Technology Innovation Project	This work was supported in part by the National Natural Science Foundation of China under Grant 61971285, Grant 61720106001, and Grant 61932022, in part by the Program of Shanghai Academic Research Leader under Grant 17XD1401900, and in part by the Program of Shanghai Science and Technology Innovation Project under Grant 20511100100.	Baker Bowen, 2017, ICLR; Bender Gabriel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14311, DOI 10.1109/CVPR42600.2020.01433; Brock A., 2018, ICLR, P1; Cai H, 2018, AAAI CONF ARTIF INTE, P2787; Cai Han, 2019, INT C LEARN REPR; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen X, 2019, IEEE I CONF COMP VIS, P1294, DOI 10.1109/ICCV.2019.00138; Chen YK, 2019, ADV NEUR IN, V32; Chu Xiangxiang, 2021, ARXIV190701845, P12239; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DeVries T., 2017, P 2017 COMPUTER VISI; Dong XY, 2022, IEEE T PATTERN ANAL, V44, P3634, DOI 10.1109/TPAMI.2021.3054824; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Elsken Thomas, 2019, INT C LEARN REPR; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Ha David, 2017, ICLR; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Howard A. G., 2017, MOBILENETS EFFICIENT; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Larsson G., 2017, INT C LEARN REPR ICL; Le Q. V., 2019, P BMVC, P74; Li Liam, 2019, ABS190207638 CORR; Liang H., ARXIV190906035; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu Hanxiao, 2018, ICLR; Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Luo RQ, 2018, ADV NEUR IN, V31; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Mei Jieru, 2020, ICLR; Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3; Nayman N, 2019, ADV NEUR IN, V32; Peng J., 2018, ARXIV180902601; Pham H, 2018, PR MACH LEARN RES, V80; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Simonyan K, 2015, 3 INT C LEARN REPR I; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan M., 2020, P IEEE ICVF C COMOP, P10781; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Wang RJ, 2018, ADV NEUR IN, V31; Wu J., 2020, ARXIV200408423; Xie Sirui, 2019, INT C LEARN REPR; Xu Y, 2020, ICLR; Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18; Ying C, 2019, PR MACH LEARN RES, V97; Yu Kaicheng, 2020, ICLR; Zela A., 2020, P INT C NEUR INF PRO; Zela A., 2020, INT C LEARN REPRESEN; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541; Zhou HP, 2019, PR MACH LEARN RES, V97; Zhu ZT, 2019, INT CONF 3D VISION, P240, DOI 10.1109/3DV.2019.00035; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	70	12	12	4	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					2953	2970		10.1109/TPAMI.2021.3059510	http://dx.doi.org/10.1109/TPAMI.2021.3059510			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	33591909				2022-12-18	WOS:000681124300010
J	Lin, JX; Chen, ZB; Xia, YC; Liu, S; Qin, T; Luo, JB				Lin, Jianxin; Chen, Zhibo; Xia, Yingce; Liu, Sen; Qin, Tao; Luo, Jiebo			Exploring Explicit Domain Supervision for Latent Space Disentanglement in Unpaired Image-to-Image Translation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Task analysis; Gallium nitride; Generative adversarial networks; Generators; Data mining; Image synthesis; Image-to-image translation; explicit domain supervision; generative adversarial networks		Image-to-image translation tasks have been widely investigated with Generative Adversarial Networks (GANs). However, existing approaches are mostly designed in an unsupervised manner, while little attention has been paid to domain information within unpaired data. In this article, we treat domain information as explicit supervision and design an unpaired image-to-image translation framework, Domain-supervised GAN (DosGAN), which takes the first step towards the exploration of explicit domain supervision. In contrast to representing domain characteristics using different generators or domain codes, we pre-train a classification network to explicitly classify the domain of an image. After pre-training, this network is used to extract the domain-specific features of each image. Such features, together with the domain-independent features extracted by another encoder (shared across different domains), are used to generate image in target domain. Extensive experiments on multiple facial attribute translation, multiple identity translation, multiple season translation and conditional edges-to-shoes/handbags demonstrate the effectiveness of our method. In addition, we can transfer the domain-specific feature extractor obtained on the Facescrub dataset with domain supervision information to unseen domains, such as faces in the CelebA dataset. We also succeed in achieving conditional translation with any two images in CelebA, while previous models like StarGAN cannot handle this task.	[Lin, Jianxin; Chen, Zhibo; Liu, Sen] Univ Sci & Technol China, Hefei 230026, Anhui, Peoples R China; [Xia, Yingce; Qin, Tao] Microsoft Res Asia, Beijing 100080, Peoples R China; [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Microsoft; Microsoft Research Asia; University of Rochester	Chen, ZB (corresponding author), Univ Sci & Technol China, Hefei 230026, Anhui, Peoples R China.	linjx@mail.ustc.edu.cn; chenzhibo@ustc.edu.cn; yingce.xia@microsoft.com; elsen@iat.ustc.edu.cn; taoqin@microsoft.com; jiebo.luo@gmail.com		Luo, Jiebo/0000-0002-4516-9729; Qin, Tao/0000-0002-9095-0776	NSFC [61571413, 61632001]	NSFC(National Natural Science Foundation of China (NSFC))	This work was supported in part by NSFC under Grants 61571413 and 61632001.	Chen XY, 2018, LECT NOTES COMPUT SC, V11206, P167, DOI 10.1007/978-3-030-01216-8_11; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Denton Emily L, 2015, NEURIPS, V2, P4; Donahue Jeff, 2017, INT C LEARN REPR ICL; Dumoulin Vincent, 2017, ICLR; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He Di, 2016, NEURAL INFORM PROCES, P2; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heusel M., 2017, ADV NEURAL INFORM PR, P6626, DOI DOI 10.5555/3295222.3295408; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Kim Taeksoo, 2017, P 34 INT C MACH LEAR, P1857, DOI [10.5555/3305381.3305573, DOI 10.5555/3305381.3305573]; Kingma D.P, P 3 INT C LEARNING R; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; Lempitsky V., 2016, ARXIV160708022V3; Lin JX, 2018, PROC CVPR IEEE, P5524, DOI 10.1109/CVPR.2018.00579; Liu AH, 2018, ADV NEUR IN, V31; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Ma S, 2018, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2018.00593; Mejjati YA, 2018, ADV NEUR IN, V31; Nair V, 2010, P 27 INT C MACHINE L, P807; Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068; Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50; Radford A., 2015, ARXIV PREPR ARXIV151; Simonyan Karen, 2015, VERY DEEP CONVOLUTIO; Smolensky P, 1986, 315 COL U DEP COMP S; Taigman Yaniv, 2017, 5 INT C LEARN REPR I; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36	41	12	12	5	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1254	1266		10.1109/TPAMI.2019.2950198	http://dx.doi.org/10.1109/TPAMI.2019.2950198			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31675317	Green Submitted			2022-12-18	WOS:000626525300011
J	Hu, YY; Yang, WH; Ma, Z; Liu, JY				Hu, Yueyu; Yang, Wenhan; Ma, Zhan; Liu, Jiaying			Learning End-to-End Lossy Image Compression: A Benchmark	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image coding; Benchmark testing; Entropy; Rate-distortion; Codecs; Transforms; Transform coding; Machine learning; image compression; neural networks; transform coding		Image compression is one of the most fundamental techniques and commonly used applications in the image and video processing field. Earlier methods built a well-designed pipeline, and efforts were made to improve all modules of the pipeline by handcrafted tuning. Later, tremendous contributions were made, especially when data-driven methods revitalized the domain with their excellent modeling capacities and flexibility in incorporating newly designed modules and constraints. Despite great progress, a systematic benchmark and comprehensive analysis of end-to-end learned image compression methods are lacking. In this paper, we first conduct a comprehensive literature survey of learned image compression methods. The literature is organized based on several aspects to jointly optimize the rate-distortion performance with a neural network, i.e., network architecture, entropy model and rate control. We describe milestones in cutting-edge learned image-compression methods, review a broad range of existing works, and provide insights into their historical development routes. With this survey, the main challenges of image compression methods are revealed, along with opportunities to address the related issues with recent advanced learning methods. This analysis provides an opportunity to take a further step towards higher-efficiency image compression. By introducing a coarse-to-fine hyperprior model for entropy estimation and signal reconstruction, we achieve improved rate-distortion performance, especially on high-resolution images. Extensive benchmark experiments demonstrate the superiority of our model in rate-distortion performance and time complexity on multi-core CPUs and GPUs.	[Hu, Yueyu; Yang, Wenhan; Liu, Jiaying] Peking Univ, Wangxuan Inst Comp Technol, Beijing 100080, Peoples R China; [Ma, Zhan] Nanjing Univ, Elect Sci & Engn Sch, Nanjing 210093, Jiangsu, Peoples R China	Peking University; Nanjing University	Liu, JY (corresponding author), Peking Univ, Wangxuan Inst Comp Technol, Beijing 100080, Peoples R China.	huyy@pku.edu.cn; yangwenhan@pku.edu.cn; mazhan@nju.edu.cn; liujiaying@pku.edu.cn			National Key Research and Development Program of China [2018AAA0102702]; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China [61772043, 62022038]; Key Laboratory of Science, Techonology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology)	National Key Research and Development Program of China; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Laboratory of Science, Techonology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology)	This work was supported by the National Key Research and Development Program of China under Grant 2018AAA0102702, the Fundamental Research Funds for the Central Universities, and the National Natural Science Foundation of China under Contract No. 61772043 and No. 62022038. This is a research achievement of Key Laboratory of Science, Techonology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology).	Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031; Agustsson E, 2017, ADV NEUR IN, V30; Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; Asuni N, 2014, SMART TOOLS APPS GRA, P8, DOI [10.2312/STAG.20141242, DOI 10.2312/STAG.20141242]; Baig MH, 2017, ADV NEUR IN, V30; Balle J., 2018, PROC INT C LEARN REP; Balle J, 2016, PICT COD SYMP, DOI 10.1109/pcs.2016.7906310; Balle J, 2018, PICT COD SYMP, P248; Balle Johannes, 2016, P 4 INT C LEARN REPR; Balle Johannes, 2017, 5 INT C LEARN REPR I; Bellard Fabrice, BPG IMAGE FORMAT; Bjontegarrd Gisle, 2001, VCEGM33; Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; Cai JR, 2018, IEEE IMAGE PROC, P450, DOI 10.1109/ICIP.2018.8451411; Chen J., 2020, DOCUMENT JVET Q20002; Chen T, 2021, IEEE T IMAGE PROCESS, V30, P3179, DOI 10.1109/TIP.2021.3058615; Cheng ZX, 2019, PROC CVPR IEEE, P10063, DOI 10.1109/CVPR.2019.01031; Covell M., 2017, ARXIV 170506687; Cover T.M., 2012, ELEMENTS INFORM THEO, DOI DOI 10.1002/047174882X; Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485; Dumas T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1188; Gersho A., 1991, VECTOR QUANTIZATION; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hu YY, 2020, AAAI CONF ARTIF INTE, V34, P11013; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461; Kingma D. P., 2013, AUTO ENCODING VARIAT; Klopp J., 2018, PROC BRIT MACH VIS C; Kodak E., KODAK LOSSLESS TRUE; Lee J., 2019, PROC IEEE C COMPUT V; Lee Jooyoung, 2018, ARXIV180910452; Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695; Liu D., 2019, PROC INT C NEURAL IN; Liu JY, 2020, IEEE T IMAGE PROCESS, V29, P7845, DOI 10.1109/TIP.2020.3007828; Ma HC, 2022, IEEE T PATTERN ANAL, V44, P1247, DOI 10.1109/TPAMI.2020.3026003; Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192; MARCELLIN MW, 1990, IEEE T COMMUN, V38, P82, DOI 10.1109/26.46532; Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173; Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462; Mentzer Fabian, 2020, ARXIV200609965; Minnen D, 2017, IEEE IMAGE PROC, P2796; Minnen D, 2018, ADV NEUR IN, V31; Minnen D, 2018, IEEE IMAGE PROC, P430, DOI 10.1109/ICIP.2018.8451502; Mirza M., 2014, ARXIV; Nakanishi KM, 2019, LECT NOTES COMPUT SC, V11366, P718, DOI 10.1007/978-3-030-20876-9_45; Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8; Rippel O, 2017, PR MACH LEARN RES, V70; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Santurkar S, 2018, PICT COD SYMP, P258; Simonyan K., 2014, 3 INT C LEARN REPR I; Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Theis Lucas, 2017, INT C LEARN REPR; Toderici G., 2016, 4 INT C LEARN REPR I, P2; Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577; Tschannen M, 2018, ADV NEUR IN, V31; van den Oord A, 2016, PR MACH LEARN RES, V48; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771; Yang Y., 2020, ARXIV200604240, V33, P573; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796; Zhou J., 2019, PROC IEEE C COMPUT V; Zhou L., 2019, PROC IEEE C COMPUT V	67	12	12	4	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 11	2021	44	8					4194	4211		10.1109/TPAMI.2021.3065339	http://dx.doi.org/10.1109/TPAMI.2021.3065339			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HX	33705308	Green Submitted			2022-12-18	WOS:000820522700001
J	Luo, YW; Liu, P; Zheng, L; Guan, T; Yu, JQ; Yang, Y				Luo, Yawei; Liu, Ping; Zheng, Liang; Guan, Tao; Yu, Junqing; Yang, Yi			Category-Level Adversarial Adaptation for Semantic Segmentation Using Purified Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised domain adaptation; semantic segmentation; domain-adaptive segmentation; transfer learning; information bottleneck		We target the problem named unsupervised domain adaptive semantic segmentation. A key in this campaign consists in reducing the domain shift, so that a classifier based on labeled data from one domain can generalize well to other domains. With the advancement of adversarial learning method, recent works prefer the strategy of aligning the marginal distribution in the feature spaces for minimizing the domain discrepancy. However, based on the observance in experiments, only focusing on aligning global marginal distribution but ignoring the local joint distribution alignment fails to be the optimal choice. Other than that, the noisy factors existing in the feature spaces, which are not relevant to the target task, entangle with the domain invariant factors improperly and make the domain distribution alignment more difficult. To address those problems, we introduce two new modules, Significance-aware Information Bottleneck (SIB) and Category-level alignment (CLA), to construct a purified embedding-based category-level adversarial network. As the name suggests, our designed network, CLAN, can not only disentangle the noisy factors and suppress their influences for target tasks but also utilize those purified features to conduct a more delicate level domain calibration, i.e., global marginal distribution and local joint distribution alignment simultaneously. In three domain adaptation tasks, i.e., GTA5 -> Cityscapes, SYNTHIA -> Cityscapes and Cross Season, we validate that our proposed method matches the state of the art in segmentation accuracy.	[Luo, Yawei; Guan, Tao; Yu, Junqing] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China; [Luo, Yawei] Zhejiang Univ, CCAI, Hangzhou 310007, Zhejiang, Peoples R China; [Liu, Ping] Agcy Sci Technol & Res, Inst High Performance Comp, Singapore 138632, Singapore; [Yang, Yi] Univ Technol Sydney, AAII, ReLER, Ultimo, NSW 2007, Australia; [Zheng, Liang] Australian Natl Univ, Res Sch Comp Sci, Canberra, ACT 0200, Australia	Huazhong University of Science & Technology; Zhejiang University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); University of Technology Sydney; Australian National University	Guan, T (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.	yaweiluo329@gmail.com; pino.pingliu@gmail.com; liangzheng06@gmail.com; qd_gt@hust.edu.cn; yjqing@hust.edu.cn; yee.i.yang@gmail.com	Yang, Yi/B-9273-2017; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; 	National Key R&D Program of China [2020AAA0108800]; National Key RD program [2016YFB1000204]; CCFBaidu Open Fund [CCF-BAIDU OF2020016]	National Key R&D Program of China; National Key RD program; CCFBaidu Open Fund	This work was supported by the National Key R&D Program of China under Grant No. 2020AAA0108800 and National Key R&D program under Grant No. 2016YFB1000204. This work was also supported by CCFBaidu Open Fund under Grant No. CCF-BAIDU OF2020016.	Akhilesh G., 2019, PROC INT C LEARN REP; Alemi A. A., 2017, PROC INT C LEARN REP; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen M., 2011, ADV NEURAL INFORM PR, P2456, DOI DOI 10.1016/B978-012545025-6/50150-7; Chen YH, 2017, IEEE I CONF COMP VIS, P2011, DOI 10.1109/ICCV.2017.220; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gulrajani I, 2017, P NIPS 2017; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffman J, 2018, PR MACH LEARN RES, V80; Hoffmann Johannes, 2016, 2016 Conference on Precision Electromagnetic Measurements (CPEM), P1, DOI 10.1109/CPEM.2016.7540615; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Kim T, 2017, PR MACH LEARN RES, V70; Kingma D.P., 2013, P 2 INT C LEARN REPR; Kingma D. P.., 2013, PROC INT C LEARN REP; Li P., 2018, ARXIV 180101726; Liu Ming-Yu, 2016, ADV NEURAL INFORM PR, P2; Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI 10.1109/CVPR.2015.7298965; Long MS, 2015, PR MACH LEARN RES, V37, P97; Luo Y., 2020, PROC ANN C NEURAL IN, p20 612; Luo YW, 2019, IEEE I CONF COMP VIS, P6777, DOI 10.1109/ICCV.2019.00688; Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261; Luo YW, 2018, LECT NOTES COMPUT SC, V11213, P424, DOI 10.1007/978-3-030-01240-3_26; Maas A. L., 2013, P ICML; Peng X. B., 2019, PROC INT C LEARN REP; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Saito K, 2017, PR MACH LEARN RES, V70; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Sener Ozan, 2016, ADV NEURAL INFORM PR, P2; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Slonim N., 2002, THESIS EBREW U JERU; Solomon J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766963; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Tishby Naftali, 1999, ALL C COMM CONTR COM; Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Zhang H, 2019, PR MACH LEARN RES, V97; Zhang JT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3001; Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223; Zhang YH, 2018, PROC CVPR IEEE, P6810, DOI 10.1109/CVPR.2018.00712; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	59	12	12	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 8	2021	44	8					3940	3956		10.1109/TPAMI.2021.3064379	http://dx.doi.org/10.1109/TPAMI.2021.3064379			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HT	33684034				2022-12-18	WOS:000820522300001
J	Cao, QX; Liang, XD; Li, BL; Lin, L				Cao, Qingxing; Liang, Xiaodan; Li, Bailin; Lin, Liang			Interpretable Visual Question Answering by Reasoning on Dependency Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cognition; Visualization; Layout; Logic gates; Task analysis; Knowledge discovery; Image coding; Visual question answering; image and language parsing; deep reasoning; attention model		Collaborative reasoning for understanding image-question pairs is a very critical but underexplored topic in interpretable visual question answering systems. Although very recent studies have attempted to use explicit compositional processes to assemble multiple subtasks embedded in questions, their models heavily rely on annotations or handcrafted rules to obtain valid reasoning processes, which leads to either heavy workloads or poor performance on compositional reasoning. In this paper, to better align image and language domains in diverse and unrestricted cases, we propose a novel neural network model that performs global reasoning on a dependency tree parsed from the question; thus, our model is called a parse-tree-guided reasoning network (PTGRN). This network consists of three collaborative modules: i) an attention module that exploits the local visual evidence of each word parsed from the question, ii) a gated residual composition module that composes the previously mined evidence, and iii) a parse-tree-guided propagation module that passes the mined evidence along the parse tree. Thus, PTGRN is capable of building an interpretable visual question answering (VQA) system that gradually derives image cues following question-driven parse-tree reasoning. Experiments on relational datasets demonstrate the superiority of PTGRN over current state-of-the-art VQA methods, and the visualization results highlight the explainable capability of our reasoning system.	[Cao, Qingxing; Liang, Xiaodan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510275, Guangdong, Peoples R China; [Li, Bailin; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China; [Li, Bailin; Lin, Liang] Minist Educ, Engn Res Ctr Adv Comp Engn Software, Guangzhou 510275, Guangdong, Peoples R China	Sun Yat Sen University; Sun Yat Sen University	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.	icqx0icqx@gmail.com; xdliang328@gmail.com; liblin3@mail2.sysu.edu.cn; linliang@ieee.org		Liang, Lin/0000-0003-2248-3755; Cao, Qingxing/0000-0001-7042-6726	State Key Development Program [2018YFC0830103]; National High Level Talents Special Support Plan (Ten Thousand Talents Program); National Natural Science Foundation of China [U1811463, 61836012]	State Key Development Program; National High Level Talents Special Support Plan (Ten Thousand Talents Program); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the State Key Development Program under Grant 2018YFC0830103, in part by National High Level Talents Special Support Plan (Ten Thousand Talents Program), in part by the National Natural Science Foundation of China under Grant No.U1811463 and No.61836012.	Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Andreas Jacob, 2016, ARXIV160101705, P1545, DOI [DOI 10.18653/V1/N16-1181, 10.18653/v1/N16-1181]; [Anonymous], 2018, P INT C LEARN REPR; [Anonymous], 2016, 2016 IEEE C COMPUTER, DOI [DOI 10.1109/CVPR.2016.90, 10.1109/CVPR.2016.90]; [Anonymous], 2017, ARXIV171007300; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285; Chattopadhyay P, 2017, PROC CVPR IEEE, P4428, DOI 10.1109/CVPR.2017.471; Chen D., 2014, P 2014 C EMPIRICAL M, P740, DOI DOI 10.3115/V1/D14-1082; Chung J., 2014, DEEP LEARN WORKSH C; Fukui Akira, 2016, ARXIV160601847; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Hu RH, 2018, LECT NOTES COMPUT SC, V11211, P55, DOI 10.1007/978-3-030-01234-2_4; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Hudson D. A., 2018, P INT C LEARN REPR; Ilievski I., ABS160401485; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Kim J.-H., 2016, P INT C LEARN REPR; Kim JH, 2018, ADV NEUR IN, V31; Kingma D.P., 2015, ICLR, P1; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kumar A, 2016, PR MACH LEARN RES, V48; Lempitsky V., 2010, NIPS, V23, P1324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lu JS, 2016, ADV NEUR IN, V29; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Mascharka D, 2018, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2018.00519; Onoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38; Perez E, 2018, AAAI CONF ARTIF INTE, P3942; Santoro A., 2017, ARXIV170601427; Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499; Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556; Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444; Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344; Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yi K., 2018, ADV NEURAL INFORM PR, V31, P1031; Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202; Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684; Zhang JM, 2017, INT J COMPUT VISION, V124, P169, DOI 10.1007/s11263-017-1011-0; Zhang Y., 2018, P INT C LEARN REPR; Zhu C, 2017, IEEE I CONF COMP VIS, P1300, DOI 10.1109/ICCV.2017.145; Zhu YK, 2017, PROC CVPR IEEE, P6146, DOI 10.1109/CVPR.2017.651; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	49	12	13	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					887	901		10.1109/TPAMI.2019.2943456	http://dx.doi.org/10.1109/TPAMI.2019.2943456			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31562071	Green Submitted			2022-12-18	WOS:000616309900010
J	Song, GL; Wang, SH; Huang, QM; Tian, Q				Song, Guoli; Wang, Shuhui; Huang, Qingming; Tian, Qi			Harmonized Multimodal Learning with Gaussian Process Latent Variable Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal learning; Gaussian process; latent variable modeling; cross-modal retrieval	MULTIVIEW; IMAGES	Multimodal learning aims to discover the relationship between multiple modalities. It has become an important research topic due to extensive multimodal applications such as cross-modal retrieval. This paper attempts to address the modality heterogeneity problem based on Gaussian process latent variable models (GPLVMs) to represent multimodal data in a common space. Previous multimodal GPLVM extensions generally adopt individual learning schemes on latent representations and kernel hyperparameters, which ignore their intrinsic relationship. To exploit strong complementarity among different modalities and GPLVM components, we develop a novel learning scheme called Harmonization, where latent representations and kernel hyperparameters are jointly learned from each other. Beyond the correlation fitting or intra-modal structure preservation paradigms widely used in existing studies, the harmonization is derived in a model-driven manner to encourage the agreement between modality-specific GP kernels and the similarity of latent representations. We present a range of multimodal learning models by incorporating the harmonization mechanism into several representative GPLVM-based approaches. Experimental results on four benchmark datasets show that the proposed models outperform the strong baselines for cross-modal retrieval tasks, and that the harmonized multimodal learning method is superior in discovering semantically consistent latent representation.	[Song, Guoli; Huang, Qingming] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 101408, Peoples R China; [Song, Guoli; Wang, Shuhui; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Song, Guoli; Huang, Qingming] Peng Cheng Lab, Shenzhen 518066, Peoples R China; [Tian, Qi] Huawei Noahs Ark Lab, Shenzhen 518129, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Peng Cheng Laboratory; Huawei Technologies	Wang, SH (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	guoli.song@vipl.ict.ac.cn; wangshuhui@ict.ac.cn; qmhuang@ucas.ac.cn; tian.qi1@huawei.com		Song, Guoli/0000-0002-5452-3697	National Basic Research Program of China (973 Program) [2015CB351802]; National Natural Science Foundation of China [61672497, 61931008, 61620106009, U1636214, 61836002]; Key Research Programof Frontier Sciences of CAS [QYZDJ-SSW-SYS013]; China Postdoctoral Science Foundation [119103S291]	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research Programof Frontier Sciences of CAS; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	The authors would like to thank the associate editor and the reviewers for their time and effort provided to review the manuscript. This work was supported in part by by National Basic Research Program of China (973 Program) under Grant 2015CB351802, in part by National Natural Science Foundation of China under Grants 61672497, 61931008, 61620106009, U1636214, and 61836002, in part by Key Research Programof Frontier Sciences of CAS under Grant QYZDJ-SSW-SYS013, and in part by the Project funded by China Postdoctoral Science Foundation under Grant 119103S291.	Andrew Galen, 2013, ICML; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Damianou Andreas, 2013, ARTIF INTELL, P207, DOI DOI 10.1002/NME.1296; Damianou AC, 2016, J MACH LEARN RES, V17, P1; Damianou Andreas C, 2012, P INT C MACH LEARN, P145; Ek CH, 2008, LECT NOTES COMPUT SC, V5237, P62, DOI 10.1007/978-3-540-85853-9_6; Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634; Forstner W, 2003, GEODESY THE CHALLENG, P299, DOI DOI 10.1007/978-3-662-05296-9_31; Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P227, DOI 10.1145/2964284.2967216; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348; Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499; Khan I., 2009, PROC WORKSHOP AUSTRI, P213; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lawrence N., 2015, ARXIV PREPRINT ARXIV; Lawrence N.D, 2006, P 23 INT C MACH LEAR, V148, P513, DOI DOI 10.1145/1143844.1143909; Li JX, 2018, IEEE T NEUR NET LEAR, V29, P4272, DOI 10.1109/TNNLS.2017.2761401; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu H, 2017, PROC CVPR IEEE, P6345, DOI 10.1109/CVPR.2017.672; Long MS, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P579, DOI 10.1145/2911451.2911493; Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301; Mandal D, 2016, IEEE T IMAGE PROCESS, V25, P3826, DOI 10.1109/TIP.2016.2577885; Mao J, 2016, P 26 INT C NEUR INF, V29, P442; Matthews AGD, 2017, J MACH LEARN RES, V18, P1; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7; Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704; Pereira JC, 2012, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2012.6248041; Quadrianto N., 2011, P 28 INT C MACHINE L; Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Salzmann Mathieu, 2010, P 13 INT C ART INT S, P701; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Shon A.P., 2005, P ADV NEUR INF PROC, P1233; Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112; Song GL, 2017, IEEE I CONF COMP VIS, P5039, DOI 10.1109/ICCV.2017.538; Song GL, 2017, IEEE T IMAGE PROCESS, V26, P4168, DOI 10.1109/TIP.2017.2713045; Song GL, 2015, IEEE I CONF COMP VIS, P4050, DOI 10.1109/ICCV.2015.461; Srivastava N, 2014, J MACH LEARN RES, V15, P2949; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Titsias M. K., 2013, P INT C NEUR INF PRO, P279; Urtasun R., 2008, P 25 INT C MACHINE L, P1080; Urtasun R., 2007, P 24 INT C MACH LEAR, P927; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Wang SH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1398, DOI 10.1145/3240508.3240535; Wang SH, 2012, PROC CVPR IEEE, P2240, DOI 10.1109/CVPR.2012.6247933; Wang WR, 2015, PR MACH LEARN RES, V37, P1083; Wilson A., 2013, INT C MACH LEARN, P1067; Xie P., 2013, PROC INT JOINT C ART, P1806; Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966; Yang XT, 2017, PROC CVPR IEEE, P5066, DOI 10.1109/CVPR.2017.538; Zhai X., 2013, P AAAI C ART INT AAA; Zhen Y., 2012, PA CM SIGKDD INT C K, P940, DOI DOI 10.1145/2339530.2339678; Zhuang Yueting, 2013, 27 AAAI C ART INT, P1070	67	12	14	4	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					858	872		10.1109/TPAMI.2019.2942028	http://dx.doi.org/10.1109/TPAMI.2019.2942028			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31545710	Green Submitted			2022-12-18	WOS:000616309900008
J	Rioux, G; Scarvelis, C; Choksi, R; Hoheisel, T; Marechal, P				Rioux, Gabriel; Scarvelis, Christopher; Choksi, Rustum; Hoheisel, Tim; Marechal, Pierre			Blind Deblurring of Barcodes via Kullback-Leibler Divergence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Blind deblurring; denoising; symbology; QR barcode; UPC barcode; maximum entropy on the mean; Kullback-Leibler divergence; Fenchel-Rockafellar duality; L-BFGS	INFORMATION-THEORY; BAR; ALGORITHM; DECONVOLUTION; ENTROPY; MAXIMUM	Barcode encoding schemes impose symbolic constraints which fix certain segments of the image. We present, implement, and assess a method for blind deblurring and denoising based entirely on Kullback-Leibler divergence. The method is designed to incorporate and exploit the full strength of barcode symbologies. Via both standard barcode reading software and smartphone apps, we demonstrate the remarkable ability of our method to blindly recover simulated images of highly blurred and noisy barcodes. As proof of concept, we present one application on a real-life out of focus camera image.	[Rioux, Gabriel; Scarvelis, Christopher; Choksi, Rustum; Hoheisel, Tim] McGill Univ, Dept Math & Stat, Montreal, PQ H3A 0G4, Canada; [Marechal, Pierre] Univ Paul Sabatier, Inst Math Toulouse, F-31062 Toulouse, France	McGill University; Universite de Toulouse; Universite Toulouse III - Paul Sabatier	Rioux, G (corresponding author), McGill Univ, Dept Math & Stat, Montreal, PQ H3A 0G4, Canada.	gabriel.rioux@mail.mcgill.ca; christopher.scarvelis@mail.mcgill.ca; rustum.choksi@mcgill.ca; tim.hoheisel@mcgill.ca; pierre.marechal@math.univ-toulouse.fr			McGill SURA; NSERC USRA; NSERC (Canada)	McGill SURA; NSERC USRA(Natural Sciences and Engineering Research Council of Canada (NSERC)); NSERC (Canada)(Natural Sciences and Engineering Research Council of Canada (NSERC))	Gabriel Rioux and Christopher Scarvelis would like to acknowledge funding they received from the McGill SURA and NSERC USRA respectively which permitted their contribution to this research. Rustum Choksi and Tim Hoheisel were partially supported by NSERC (Canada) Discovery Grants. The authors would like to thank Jerome Gilles for helpful comments on a previous draft as well as the anonymous reviewers for their useful feedback. Gabriel Rioux and Christopher Scarvelis Fan are co-first authors. Rioux and Scarvelis equally share the role of first author.	[Anonymous], 2011, ZBAR BAR CODE READER; [Anonymous], 2017, PYTHON SPEED; Bercher JF, 1996, FUND THEOR, V70, P223; BORWEIN JM, 1992, MATH PROGRAM, V57, P49, DOI 10.1007/BF01581073; BORWEIN JM, 1992, MATH PROGRAM, V57, P15, DOI 10.1007/BF01581072; Chen LT, 2013, PROCEEDINGS OF THE 2013 ASIA-PACIFIC COMPUTATIONAL INTELLIGENCE AND INFORMATION TECHNOLOGY CONFERENCE, P524; Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38; Cho S, 2009, ALGEBR GEOM TOPOL, V9, P1, DOI 10.2140/agt.2009.9.1; Choksi R, 2011, INVERSE PROBL IMAG, V5, P591, DOI 10.3934/ipi.2011.5.591; Chu C. H., 2007, P 15 INT C MULT, P697; Claerbout J. F., 2004, EARTH SOUNDINGSANALY; DACUNHACASTELLE D, 1990, ANN I H POINCARE-PR, V26, P567; Dodangeh M, 2018, IET IMAGE PROCESS, V12, P948, DOI 10.1049/iet-ipr.2017.0302; Esedoglu S, 2004, INVERSE PROBL, V20, P121, DOI 10.1088/0266-5611/20/1/007; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Hansen P. C, 2006, DEBLURRING IMAGES; Iwen MA, 2013, SIAM J IMAGING SCI, V6, P56, DOI 10.1137/110834378; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; JAYNES ET, 1957, PHYS REV, V108, P171, DOI 10.1103/PhysRev.108.171; JOSEPH E, 1994, IEEE T PATTERN ANAL, V16, P630, DOI 10.1109/34.295907; Joseph E, 1993, IEEE T IMAGE PROCESS, V2, P223, DOI 10.1109/83.217225; Joshi N., 2008, CVPR, P1; Kato H, 2007, IEEE PERVAS COMPUT, V6, P76, DOI 10.1109/MPRV.2007.80; Kim J, 2007, OPT EXPRESS, V15, P14817, DOI 10.1364/OE.15.014817; Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8; Kresic-Juric S, 2006, PATTERN RECOGN LETT, V27, P1665, DOI 10.1016/j.patrec.2006.03.014; Kresic-Juric S, 2005, PATTERN RECOGN, V38, P2483, DOI 10.1016/j.patcog.2005.04.009; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li SR, 2018, IET IMAGE PROCESS, V12, P546, DOI 10.1049/iet-ipr.2017.0677; Liu NZ, 2018, PATTERN RECOGN LETT, V111, P117, DOI 10.1016/j.patrec.2018.04.036; Liu NZ, 2013, PATTERN RECOGN LETT, V34, P124, DOI 10.1016/j.patrec.2012.09.006; Marechal P, 1997, INVERSE PROBL, V13, P135, DOI 10.1088/0266-5611/13/1/011; Marechal P, 2001, APPROXIMATION, OPTIMIZATION AND MATHEMATICAL ECONOMICS, P205; Ohbuchi E, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P260, DOI 10.1109/CW.2004.23; Palmer RC, 2007, BAR CODE BOOK COMPRE; Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371; Parikh D., 2008, IEEE WORKSH APPL COM, P1, DOI DOI 10.1109/WACV.2008.4544033; Pu HT, 2019, MULTIMED TOOLS APPL, V78, P897, DOI 10.1007/s11042-018-5802-2; Rajagopalan A.N., 2014, MOTION DEBLURRING AL; Rockafellar R. T., 1974, CONJUGATE DUALITY OP; Rockafellar RT., 1998, VARIATIONAL ANAL, DOI 10.1007/978-3-642-02431-3; Rockafellar RT, 1972, CONVEX ANAL; Rohatgi V., 2001, INTRO PROBABILITY ST, V2nd; Soros G, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P117, DOI 10.1145/2802083.2808390; Sun L, 2013, IEEE INT C COMPUTATI, P1, DOI 10.1109/ICCPhot.2013.6528301; Thielemann J. T., 2004, P IEEE INT C COMP VI, P1; Turin W, 1998, IEEE T SIGNAL PROCES, V46, P354, DOI 10.1109/78.655421; van Gennip Yves, 2015, IEEE Trans Image Process, V24, P2864, DOI 10.1109/TIP.2015.2432675; Wang WN, 2018, J SCI COMPUT, V76, P1078, DOI 10.1007/s10915-018-0650-9; Xu W, 2011, P IEEE WORKSH APPL C, P159; Yang HJ, 2012, IEEE T IMAGE PROCESS, V21, P418, DOI 10.1109/TIP.2011.2155074; Zhang JJ, 2012, IEEE T IMAGE PROCESS, V21, P883, DOI 10.1109/TIP.2011.2162426; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	54	12	12	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					77	88		10.1109/TPAMI.2019.2927311	http://dx.doi.org/10.1109/TPAMI.2019.2927311			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31295104				2022-12-18	WOS:000597206900006
J	Cavallari, T; Golodetz, S; Lord, NA; Valentin, J; Prisacariu, VA; Di Stefano, L; Torr, PHS				Cavallari, Tommaso; Golodetz, Stuart; Lord, Nicholas A.; Valentin, Julien; Prisacariu, Victor A.; Di Stefano, Luigi; Torr, Philip H. S.			Real-Time RGB-D Camera Pose Estimation in Novel Scenes Using a Relocalisation Cascade	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Forestry; Three-dimensional displays; Real-time systems; Pose estimation; Impedance matching; Training; Camera pose estimation; relocalisation; RGB-D; online adaptation; cascade	SLAM	Camera pose estimation is an important problem in computer vision, with applications as diverse as simultaneous localisation and mapping, virtual/augmented reality and navigation. Common techniques match the current image against keyframes with known poses coming from a tracker, directly regress the pose, or establish correspondences between keypoints in the current image and points in the scene in order to estimate the pose. In recent years, regression forests have become a popular alternative to establish such correspondences. They achieve accurate results, but have traditionally needed to be trained offline on the target scene, preventing relocalisation in new environments. Recently, we showed how to circumvent this limitation by adapting a pre-trained forest to a new scene on the fly. The adapted forests achieved relocalisation performance that was on par with that of offline forests, and our approach was able to estimate the camera pose in close to real time, which made it desirable for systems that require online relocalisation. In this paper, we present an extension of this work that achieves significantly better relocalisation performance whilst running fully in real time. To achieve this, we make several changes to the original approach: (i) instead of simply accepting the camera pose hypothesis produced by RANSAC without question, we make it possible to score the final few hypotheses it considers using a geometric approach and select the most promising one; (ii) we chain several instantiations of our relocaliser (with different parameter settings) together in a cascade, allowing us to try faster but less accurate relocalisation first, only falling back to slower, more accurate relocalisation as necessary; and (iii) we tune the parameters of our cascade, and the individual relocalisers it contains, to achieve effective overall performance. Taken together, these changes allow us to significantly improve upon the performance our original state-of-the-art method was able to achieve on the well-known 7-Scenes and Stanford 4 Scenes benchmarks. As additional contributions, we present a novel way of visualising the internal behaviour of our forests, and use the insights gleaned from this to show how to entirely circumvent the need to pre-train a forest on a generic scene.	[Cavallari, Tommaso; Golodetz, Stuart; Lord, Nicholas A.] FiveAI Ltd, Oxford OX1 1ST, England; [Valentin, Julien] Google Inc, Mountain View, CA 94043 USA; [Prisacariu, Victor A.; Torr, Philip H. S.] Univ Oxford, Oxford OX1 2JD, England; [Di Stefano, Luigi] Univ Bologna, I-40126 Bologna, Italy	Google Incorporated; University of Oxford; University of Bologna	Golodetz, S (corresponding author), FiveAI Ltd, Oxford OX1 1ST, England.	tommaso.cavallari@five.ai; Stuart@five.ai; nick@five.ai; julienvalentin@google.com; victor@robots.ox.ac.uk; luigi.distefano@unibo.it; philip.torr@eng.ox.ac.uk	Golodetz, Stuart/ABE-4971-2020	Golodetz, Stuart/0000-0001-7363-9612; Cavallari, Tommaso/0000-0003-2490-5341; Di Stefano, Luigi/0000-0001-6014-6421	FiveAI Ltd.; Innovate UK/CCAV project [103700]; EPSRC; ERC grant ERC-2012-AdG HELIOS [321162]; EPSRC grant Seebibyte [EP/M013774/1]; EPSRC/MURI grant [EP/N019474/1]; EC grant [732158]; EPSRC [EP/N019474/1] Funding Source: UKRI	FiveAI Ltd.; Innovate UK/CCAV project(UK Research & Innovation (UKRI)Innovate UK); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ERC grant ERC-2012-AdG HELIOS; EPSRC grant Seebibyte(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC/MURI grant(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EC grant; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by FiveAI Ltd., Innovate UK/CCAV project 103700 (StreetWise), the EPSRC, ERC grant ERC-2012-AdG 321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1, EPSRC/MURI grant EP/N019474/1 and EC grant 732158 (MoveCare). Tommaso Cavallari, Stuart Golodetz, Nicholas A. Lord and Julien Valentin assert joint first authorship.	Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Balntas V, 2018, LECT NOTES COMPUT SC, V11218, P782, DOI 10.1007/978-3-030-01264-9_46; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577; Cavallari T, 2017, PROC CVPR IEEE, P218, DOI 10.1109/CVPR.2017.31; Chen MC, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS, MANAGEMENT ENGINEERING AND INDUSTRIAL APPLICATION (IMEIA 2016), P1, DOI 10.1109/PLASMA.2016.7534032; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284; Deng L, 2016, NEUROCOMPUTING, V208, P315, DOI 10.1016/j.neucom.2015.11.117; Fioraio N, 2015, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2015.7299077; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fulkerson B., 2010, TRENDS TOPICS COMP 2, P350; Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158; Galvez-Lopez D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525; Gee AP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.113; Glocker B, 2015, IEEE T VIS COMPUT GR, V21, P571, DOI 10.1109/TVCG.2014.2360403; Golodetz S., 2015, P ACM SIGGRAPHEM ERG; Golodetz S, 2018, IEEE T VIS COMPUT GR, V24, P2895, DOI 10.1109/TVCG.2018.2868533; Guzman-Rivera A, 2014, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2014.146; Hartley R., 2004, ROBOTICA; KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873; Kacete A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P20, DOI 10.1109/ISMAR-Adjunct.2017.23; Kahler O, 2016, LECT NOTES COMPUT SC, V9912, P500, DOI 10.1007/978-3-319-46484-8_30; Kahler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Laskar Z, 2017, IEEE INT CONF COMP V, P920, DOI 10.1109/ICCVW.2017.113; Lee YH, 2016, COMPUT VIS IMAGE UND, V149, P3, DOI 10.1016/j.cviu.2016.03.019; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Li S, 2015, IEEE INT CONF ROBOT, P6374, DOI 10.1109/ICRA.2015.7140094; Li XT, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Li XC, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12334; Lu GY, 2015, IEEE I CONF COMP VIS, P2434, DOI 10.1109/ICCV.2015.280; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Massiceti Daniela, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5118, DOI 10.1109/ICRA.2017.7989598; Melekhov I, 2017, IEEE INT CONF COMP V, P870, DOI 10.1109/ICCVW.2017.107; Meng LL, 2018, IEEE INT C INT ROBOT, P6827, DOI 10.1109/IROS.2018.8593505; Meng LL, 2017, IEEE INT C INT ROBOT, P6886; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Paucher R., 2010, 2010 IEEE COMP SOC C, P9; Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013; Prisacariu Victor Adrian, 2017, ARXIV170800783; Radwan N, 2018, IEEE ROBOT AUTOM LET, V3, P4407, DOI 10.1109/LRA.2018.2869640; Rodas NL, 2015, LECT NOTES COMPUT SC, V9349, P463, DOI 10.1007/978-3-319-24553-9_57; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Schmidt T, 2017, IEEE ROBOT AUTOM LET, V2, P420, DOI 10.1109/LRA.2016.2634089; Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721; Sharp T, 2008, LECT NOTES COMPUT SC, V5305, P595, DOI 10.1007/978-3-540-88693-8_44; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Strasdat H., 2012, THESIS; Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752; Valada A, 2018, IEEE INT CONF ROBOT, P6939; Valentin J, 2016, INT CONF 3D VISION, P323, DOI 10.1109/3DV.2016.41; Valentin J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751556; Valentin J, 2015, PROC CVPR IEEE, P4400, DOI 10.1109/CVPR.2015.7299069; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75; Wang QZ, 2016, ELECTRON COMMER RES, V16, P1, DOI 10.1007/s10660-015-9209-0; Wang SL, 2016, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2016.21; Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237; Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41	68	12	12	3	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2465	2477		10.1109/TPAMI.2019.2915068	http://dx.doi.org/10.1109/TPAMI.2019.2915068			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31059430	Green Submitted			2022-12-18	WOS:000567471300011
J	Kim, D; Woo, S; Lee, JY; Kweon, IS				Kim, Dahun; Woo, Sanghyun; Lee, Joon-Young; Kweon, In So			Recurrent Temporal Aggregation Framework for Deep Video Inpainting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video inpainting; video completion; video object removal; video caption removal; video decaptioning; video editing		Video inpainting aims to fill in spatio-temporal holes in videos with plausible content. Despite tremendous progress on deep learning-based inpainting of a single image, it is still challenging to extend these methods to video domain due to the additional time dimension. In this paper, we propose a recurrent temporal aggregation framework for fast deep video inpainting. In particular, we construct an encoder-decoder model, where the encoder takes multiple reference frames which can provide visible pixels revealed from the scene dynamics. These hints are aggregated and fed into the decoder. We apply a recurrent feedback in an auto-regressive manner to enforce temporal consistency in the video results. We propose two architectural designs based on this framework. Our first model is a blind video decaptioning network (BVDNet) that is designed to automatically remove and inpaint text overlays in videos without any mask information. Our BVDNet wins the first place in the ECCV Chalearn 2018 LAP Inpainting Competition Track 2: Video Decaptioning. Second, we propose a network for more general video inpainting (VINet) to deal with more arbitrary and larger holes. Video results demonstrate the advantage of our framework compared to state-of-the-art methods both qualitatively and quantitatively. The codes are available at https://github.com/mcahny/Deep-Video-Inpainting, and https://github.com/shwoo93/video_decaptioning.	[Kim, Dahun; Woo, Sanghyun; Kweon, In So] Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea; [Lee, Joon-Young] Adobe Res, San Jose, CA 95110 USA	Korea Advanced Institute of Science & Technology (KAIST); Adobe Systems Inc.	Kim, D (corresponding author), Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea.	mcahny@kaist.ac.kr; shwoo93@kaist.ac.kr; jolee@adobe.com; iskweon77@kaist.ac.kr		Woo, Sanghyun/0000-0002-9789-7103; Kim, Dahun/0000-0003-1776-6195	Fellowship Program through the National Research Foundation of Korea (NRF) - Ministry of Education [NRF2018H1A2A1062075]	Fellowship Program through the National Research Foundation of Korea (NRF) - Ministry of Education	Dahun Kim and Sanghyun Woo contributed equally to this work. Dahun Kim was supported by Global Ph.D. Fellowship Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF2018H1A2A1062075).	[Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], 2018, P 32 C NEUR INF PROC; [Anonymous], [No title captured]; Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chang YL, 2019, IEEE I CONF COMP VIS, P9065, DOI 10.1109/ICCV.2019.00916; Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126; Cheng Y., 2018, ARXIV180402047; Di Lin, 2016, Arxiv, DOI arXiv:1604.05144; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Granados M, 2012, COMPUT GRAPH FORUM, V31, P219, DOI 10.1111/j.1467-8659.2012.03000.x; Granados M, 2012, LECT NOTES COMPUT SC, V7572, P682, DOI 10.1007/978-3-642-33718-5_49; Huang HZ, 2017, PROC CVPR IEEE, P7044, DOI 10.1109/CVPR.2017.745; Huang JB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982398; Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Lai WS, 2018, LECT NOTES COMPUT SC, V11219, P179, DOI 10.1007/978-3-030-01267-0_11; Lee D, 2018, ADV NEUR IN, V31; Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6; Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141; Newson A, 2014, SIAM J IMAGING SCI, V7, P1993, DOI 10.1137/140954933; Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Pont-Tuset J., 2017, ARXIV170400675; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3; Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693; Shiratori T., 2006, P IEEE C COMP VIS PA, V1, P411, DOI DOI 10.1109/CVPR.2006.330; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479; Wang C., 2018, ARXIV180608482; Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316; Wang TC, 2018, ADV NEUR IN, V31; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wexler Y, 2004, PROC CVPR IEEE, P120; Xiao FY, 2017, PROC CVPR IEEE, P5253, DOI 10.1109/CVPR.2017.558; Xu N, 2018, LECT NOTES COMPUT SC, V11209, P603, DOI 10.1007/978-3-030-01228-1_36; Xu R, 2019, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2019.00384; Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434; Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728; Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142	50	12	12	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1038	1052		10.1109/TPAMI.2019.2958083	http://dx.doi.org/10.1109/TPAMI.2019.2958083			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	31831407				2022-12-18	WOS:000523685800003
J	Punnappurath, A; Brown, MS				Punnappurath, Abhijith; Brown, Michael S.			Learning Raw Image Reconstruction-Aware Deep Image Compressors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Image coding; Table lookup; Compressors; Transform coding; Cameras; Calibration; Image compression; radiometric calibration; raw image reconstruction; deep learning-based image compression	VISION	Deep learning-based image compressors are actively being explored in an effort to supersede conventional image compression algorithms, such as JPEG. Conventional and deep learning-based compression algorithms focus on minimizing image fidelity errors in the nonlinear standard RGB (sRGB) color space. However, for many computer vision tasks, the sensor's linear raw-RGB image is desirable. Recent work has shown that the original raw-RGB image can be reconstructed using only small amounts of metadata embedded inside the JPEG image [1]. However, [1] relied on the conventional JPEG encoding that is unaware of the raw-RGB reconstruction task. In this paper, we examine the ability of deep image compressors to be "aware" of the additional objective of raw reconstruction. Towards this goal, we describe a general framework that enables deep networks targeting image compression to jointly consider both image fidelity errors and raw reconstruction errors. We describe this approach in two scenarios: (1) the network is trained from scratch using our proposed joint loss, and (2) a network originally trained only for sRGB fidelity loss is later fine-tuned to incorporate our raw reconstruction loss. When compared to sRGB fidelity-only compression, our combined loss leads to appreciable improvements in PSNR of the raw reconstruction with only minor impact on sRGB fidelity as measured by MS-SSIM.	[Punnappurath, Abhijith; Brown, Michael S.] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada	York University - Canada	Punnappurath, A (corresponding author), York Univ, Dept Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada.	pabhijith@eecs.yorku.ca; mbrown@eecs.yorku.ca			Canada First Research Excellence Fund for the Vision: Science to Applications (VISTA) programme; NSERC	Canada First Research Excellence Fund for the Vision: Science to Applications (VISTA) programme; NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This study was funded in part by the Canada First Research Excellence Fund for the Vision: Science to Applications (VISTA) programme and an NSERC Discovery Grant.	[Anonymous], 2017, P INT C LEARN REPR I; [Anonymous], 2017, ICLR; [Anonymous], CORR; [Anonymous], [No title captured]; [Anonymous], 2018, P INT C LEARN REPR; [Anonymous], [No title captured]; Bellard Fabrice, BPG IMAGE FORMAT; Chakrabarti A, 2009, PRODUCT RESEARCH: THE ART AND SCIENCE BEHIND SUCCESSFUL PRODUCT LAUNCHES, P17, DOI 10.1007/978-90-481-2860-0_2; Chakrabarti A, 2014, IEEE T PATTERN ANAL, V36, P2185, DOI 10.1109/TPAMI.2014.2318713; Cheng DL, 2016, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2016.57; Cheng DL, 2015, IEEE I CONF COMP VIS, P298, DOI 10.1109/ICCV.2015.42; Debevec P. E., 2008, ACM SIGGRAPH 2008 CL, P1; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; Karaimer HC, 2018, PROC CVPR IEEE, P6440, DOI 10.1109/CVPR.2018.00674; Karaimer HC, 2016, LECT NOTES COMPUT SC, V9905, P429, DOI 10.1007/978-3-319-46448-0_26; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; King DB, 2015, ACS SYM SER, V1214, P1; Kodak E., KODAK LOSSLESS TRUE; Lin HT, 2012, LECT NOTES COMPUT SC, V7572, P556, DOI 10.1007/978-3-642-33718-5_40; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Nam S, 2017, IEEE I CONF COMP VIS, P1726, DOI 10.1109/ICCV.2017.190; Nguyen RMH, 2016, PROC CVPR IEEE, P1655, DOI 10.1109/CVPR.2016.183; Rippel O, 2017, PR MACH LEARN RES, V70; TAUBMAN DS, 2000, JPEG 2000 IMAGE COMP; Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577; Toderici George, 2015, CORR; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wierstra, 2016, ADV NEURAL INFORM PR, P3556; Yuan L, 2011, IEEE I CONF COMP VIS, P2158, DOI 10.1109/ICCV.2011.6126492	32	12	12	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					1013	1019		10.1109/TPAMI.2019.2903062	http://dx.doi.org/10.1109/TPAMI.2019.2903062			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30843804				2022-12-18	WOS:000526541100016
J	Smith, WAP; Ramamoorthi, R; Tozza, S				Smith, William A. P.; Ramamoorthi, Ravi; Tozza, Silvia			Height-from-Polarisation with Unknown Lighting or Albedo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lighting; Light sources; Shape; Refractive index; Surface reconstruction; Azimuth; Estimation; Polarisation; shape-from-x; bas-relief ambiguity; illumination estimation; albedo estimation	RECONSTRUCTION; SHAPE	We present a method for estimating surface height directly from a single polarisation image simply by solving a large, sparse system of linear equations. To do so, we show how to express polarisation constraints as equations that are linear in the unknown height. The local ambiguity in the surface normal azimuth angle is resolved globally when the optimal surface height is reconstructed. Our method is applicable to dielectric objects exhibiting diffuse and specular reflectance, though lighting and albedo must be known. We relax this requirement by showing that either spatially varying albedo or illumination can be estimated from the polarisation image alone using nonlinear methods. In the case of illumination, the estimate can only be made up to a binary ambiguity which we show is a generalised Bas-relief transformation corresponding to the convex/concave ambiguity. We believe that our method is the first passive, monocular shape-from-x technique that enables well-posed height estimation with only a single, uncalibrated illumination condition. We present results on real world data, including in uncontrolled, outdoor illumination.	[Smith, William A. P.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England; [Ramamoorthi, Ravi] Univ Calif San Diego, CSE Dept, La Jolla, CA 92093 USA; [Tozza, Silvia] Sapienza Univ Roma, Ist Nazl Alta Matemat, Res Unit, Dept Math, I-00185 Rome, Italy	University of York - UK; University of California System; University of California San Diego; Sapienza University Rome	Smith, WAP (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	william.smith@york.ac.uk; ravir@cs.ucsd.edu; tozza@mat.uniroma1.it	Smith, William/AAK-9101-2020	Smith, William/0000-0002-6047-0413	EPSRC [EP/N028481/1]; ONR [N000141512013, N000 141712687]; GNCS-INdAM; UC San Diego Center for Visual Computing	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ONR(Office of Naval Research); GNCS-INdAM(Istituto Nazionale di Alta Matematica (INDAM)); UC San Diego Center for Visual Computing	This work was supported in part by EPSRC grant EP/N028481/1, ONR grants N000141512013 and N000 141712687, GNCS-INdAM and the UC San Diego Center for Visual Computing. We thank Zak Murez and Dizhong Zhu for assistance with data collection.	Atkinson GA, 2007, IEEE T PATTERN ANAL, V29, P2001, DOI 10.1109/TPAMI.2007.1099; Atkinson GA, 2007, LECT NOTES COMPUT SC, V4673, P466; Atkinson GA, 2006, IEEE T IMAGE PROCESS, V15, P1653, DOI 10.1109/TIP.2006.871114; Atkinson GA, 2017, COMPUT VIS IMAGE UND, V160, P158, DOI 10.1016/j.cviu.2017.04.014; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Blinn James F., 1977, COMPUT GRAPHICS-US, V11, P192, DOI [DOI 10.1145/965141.563893, 10.1145/965141, DOI 10.1145/965141]; Carpinteri A., 1997, STRUCTURAL MECH; Cui Z., 2017, P IEEE C COMP VIS PA, P1558; Drbohlav O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P581, DOI 10.1109/ICCV.2001.937570; Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P147, DOI 10.5201/ipol.2012.g-tvi; Ghosh A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024163; Grant M, 2006, NONCON OPTIM ITS APP, V84, P155; Herrera SEM, 2013, I S BIOMED IMAGING, P1412; Huynh CP, 2013, INT J COMPUT VISION, V101, P64, DOI 10.1007/s11263-012-0546-3; Huynh CP, 2010, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2010.5539828; Kadambi A, 2017, INT J COMPUT VISION, V125, P34, DOI 10.1007/s11263-017-1025-7; Kadambi A, 2015, IEEE I CONF COMP VIS, P3370, DOI 10.1109/ICCV.2015.385; Mahmoud AH, 2012, IEEE IMAGE PROC, P1769, DOI 10.1109/ICIP.2012.6467223; Miyazaki D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P982; Miyazaki D, 2004, IEEE T PATTERN ANAL, V26, P73, DOI 10.1109/TPAMI.2004.1261080; Miyazaki D, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.4.041303; Miyazaki D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P104, DOI 10.1109/3DIMPVT.2012.14; Morel O, 2005, PROC SPIE, V5679, P178, DOI 10.1117/12.586815; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Rahmann S., 2001, P IEEE COMP SOC C CO, pI; Robles-Kelly A., 2013, IMAGING SPECTROSCOPY; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Schechner Y. Y., 2015, 2015 IEEE INT C COMP, P1; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Smith WAP, 2016, LECT NOTES COMPUT SC, V9912, P109, DOI 10.1007/978-3-319-46484-8_7; Tozza S, 2016, J MATH IMAGING VIS, V56, P57, DOI 10.1007/s10851-016-0633-0; Ngo TT, 2015, PROC CVPR IEEE, P2310, DOI 10.1109/CVPR.2015.7298844; Tuchin V.V., 2006, OPTICAL POLARIZATION, DOI [10.1016/j.jqsrt.2007.08.004, DOI 10.1016/J.JQSRT.2007.08.004]; WOLFF LB, 1994, J OPT SOC AM A, V11, P2956, DOI 10.1364/JOSAA.11.002956; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; Wolff LB, 1997, IMAGE VISION COMPUT, V15, P81, DOI 10.1016/S0262-8856(96)01123-7	36	12	13	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2875	2888		10.1109/TPAMI.2018.2868065	http://dx.doi.org/10.1109/TPAMI.2018.2868065			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30188812	hybrid, Green Accepted			2022-12-18	WOS:000498677600007
J	Xu, HJ; Das, A; Saenko, K				Xu, Huijuan; Das, Abir; Saenko, Kate			Two-Stream Region Convolutional 3D Network for Temporal Activity Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Temporal activity detection; two-stream architecture; hard mining		We address the problem of temporal activity detection in continuous, untrimmed video streams. This is a difficult task that requires extracting meaningful spatio-temporal features to capture activities, accurately localizing the start and end times of each activity. We introduce a new model, Region Convolutional 3D Network (R-C3D), which encodes the video streams using a three-dimensional fully convolutional network, then generates candidate temporal regions containing activities and finally classifies selected regions into specific activities. Computation is saved due to the sharing of convolutional features between the proposal and the classification pipelines. We further improve the detection performance by efficiently integrating an optical flow based motion stream with the original RGB stream. The two-stream network is jointly optimized by fusing the flow and RGB feature maps at different levels. Additionally, the training stage incorporates an online hard example mining strategy to address the extreme foreground-background imbalance typically observed in any detection pipeline. Instead of heuristically sampling the candidate segments for the final activity classification stage, we rank them according to their performance and only select the worst performers to update the model. This improves the model without heavy hyper-parameter tuning. Extensive experiments on three benchmark datasets are carried out to show superior performance over existing temporal activity detection methods. Our model achieves state-of-the-art results on the THUMOS'14 and Charades datasets. We further demonstrate that our model is a general temporal activity detection framework that does not rely on assumptions about particular dataset properties by evaluating our approach on the ActivityNet dataset.	[Xu, Huijuan] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Das, Abir] IIT Kharagpur, Comp Sci & Engn Dept, Kharagpur 721302, W Bengal, India; [Saenko, Kate] Boston Univ, Comp Sci, Boston, MA 02215 USA	University of California System; University of California Berkeley; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kharagpur; Boston University	Xu, HJ (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.	huijuan@eecs.berkeley.edu; abir@cse.iitkgp.ac.in; saenko@bu.edu	Xu, Huijuan/AGU-2919-2022	Saenko, Kate/0000-0002-7564-7218; Xu, Huijuan/0000-0002-4778-5584	NSF; DARPA	NSF(National Science Foundation (NSF)); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work is supported in part by the NSF and DARPA. We would thank Lu He for the meaningful discussions.	Abu-El-Haija S, 2016, YOUTUBE 8M LARGE SCA; Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Buch Shyamal, 2017, BMVC, P2; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Diba A., 2016, P EUR C COMP VIS WOR; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47; Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211; HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698; Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang Y.-G., 2014, THUMOS CHALLENGE ACT; Karaman  S., 2014, 2014 IEEE 27 CAN C E, V1, P1, DOI DOI 10.1109/CCECE.2014.6901151; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Loshchilov I., 2015, ARXIV151106343; MA SG, 2016, PROC CVPR IEEE, P1942, DOI DOI 10.1109/CVPR.2016.214; Montes Alberto, 2016, ARXIV160808128; Oneata  D., 2014, THUMOS ACTION RECOGN, P1; Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341; Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155; Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Sigurdsson GA, 2017, PROC CVPR IEEE, P5650, DOI 10.1109/CVPR.2017.599; Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31; Simo-Serra E., 2014, ARXIV PREPRINT ARXIV; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216; Singh G., 2016, UNTRIMMED VIDEO CLAS; Sung K.-K., 1996, THESIS; Szegedy C, 2013, ADV NEURAL INFORM PR, P2553; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678; Wang LM, 2014, LECT NOTES COMPUT SC, V8693, P565, DOI 10.1007/978-3-319-10602-1_37; Wang L, 2014, SPAT COGN COMPUT, V14, P1, DOI 10.1080/13875868.2013.784768; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362; Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617; Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293; Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735; Yuan J, 2016, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2016.337; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297; Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317; Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242	60	12	13	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2319	2332		10.1109/TPAMI.2019.2921539	http://dx.doi.org/10.1109/TPAMI.2019.2921539			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	31180838	Green Submitted			2022-12-18	WOS:000489763000004
J	Jayaraman, D; Grauman, K				Jayaraman, Dinesh; Grauman, Kristen			End-to-End Policy Learning for Active Visual Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active vision; active perception; active categorization; reinforcement learning; panoramic images	OBJECT RECOGNITION	Visual recognition systems mounted on autonomous moving agents face the challenge of unconstrained data, but simultaneously have the opportunity to improve their performance by moving to acquire new views at test time. In this work, we first show how a recurrent neural network-based system may be trained to perform end-to-end learning of motion policies suited for this "active recognition" setting. Further, we hypothesize that active vision requires an agent to have the capacity to reason about the effects of its motions on its view of the world. To verify this hypothesis, we attempt to induce this capacity in our active recognition pipeline, by simultaneously learning to forecast the effects of the agent's motions on its internal representation of the environment conditional on all past views. Results across three challenging datasets confirm both that our end-to-end system successfully learns meaningful policies for active category recognition, and that "learning to look ahead" further boosts recognition performance.	[Jayaraman, Dinesh] Univ Texas Austin, Austin, TX 78712 USA; [Jayaraman, Dinesh] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Grauman, Kristen] Univ Texas Austin, Comp Sci Dept, Austin, TX 78712 USA	University of Texas System; University of Texas Austin; University of California System; University of California Berkeley; University of Texas System; University of Texas Austin	Jayaraman, D (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.; Jayaraman, D (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.	dineshj@cs.utexas.edu; grauman@cs.utexas.edu	Jayaraman, Dinesh/AAI-2527-2021	Jayaraman, Dinesh/0000-0002-6888-3095	ONR PECASE Award [N00014-15-1-2291]; Google Faculty Research Award; DARPA Lifelong Learning Machines Award; Samsung Fellowship	ONR PECASE Award; Google Faculty Research Award(Google Incorporated); DARPA Lifelong Learning Machines Award; Samsung Fellowship(Samsung)	This research was supported in part by ONR PECASE Award N00014-15-1-2291, a Google Faculty Research Award, a DARPA Lifelong Learning Machines Award, and a Samsung Fellowship. We thank TACC for computing facilities, and Mohsen Malmir and Jianxiong Xiao for their assistance sharing GERMS and SUN360 data respectively.	Agrawal P., 2016, P 30 INT C NEUR INF, P5092; Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005; Andreopoulos A, 2009, IEEE I CONF COMP VIS, P903, DOI 10.1109/ICCV.2009.5459332; Ba J., 2015, P INT C LEARN REPR; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Bazzani L, 2011, P 28 INT C MACH LEAR, P937; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Borotschnig H., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P629; Bowling M., 2005, P 22 INT C MACHINE L, P65, DOI [10.1145/1102351.1102360, DOI 10.1145/1102351.1102360]; Brentano F., 1874, PSYCHOL EMPIRICAL ST, DOI DOI 10.4324/9781315747446; Butko Nicholas J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2751, DOI 10.1109/CVPRW.2009.5206540; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Callari FG, 2001, INT J COMPUT VISION, V43, P189, DOI 10.1023/A:1011135513777; Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI [10.1109/ICCV.2015.104, 10.1109/ICCV.2015.312]; Cohen T., 2015, ICLR; Denzler J, 2002, IEEE T PATTERN ANAL, V24, P145, DOI 10.1109/34.982896; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; Ding W., 2014, P INT C NEUR INF PRO; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Garcia A. G., 2015, P IEEE C COMP VIS PA, P3022; Gupta S, 2017, PROC CVPR IEEE, P7272, DOI 10.1109/CVPR.2017.769; Helmer S., 2009, P 21 INT JOINT C ART; Jayaraman D., 2018, P EUR C COMPUT VIS; Jayaraman D, 2016, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2016.418; Jayaraman D, 2016, LECT NOTES COMPUT SC, V9909, P489, DOI 10.1007/978-3-319-46454-1_30; Jayaraman D, 2015, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2015.166; Jayaraman Dinesh, 2018, P IEEE C COMP VIS PA; Johns E, 2016, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2016.414; Karayev S., 2012, P INT C NEUR INF PRO; Kulkarni TD, 2015, ADV NEUR IN, V28; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Levine S, 2016, J MACH LEARN RES, V17; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Malmir M., 2015, P BRIT MACH VIS C; Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316; Mishra A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3133, DOI 10.1109/IROS.2009.5354325; Mnih V., 2014, NEURAL INFORM PROCES, DOI DOI 10.48550/ARXIV.1406.6247; Oh J., 2015, P ADV NEUR INF PROC, P2863; Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2; Ramanathan V, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P235; Ranzato MarcAurelio, 2014, ARXIV14126604; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schiele B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P249, DOI 10.1109/ICCV.1998.710726; Sermanet P., 2014, ATTENTION FINE GRAIN; Simonyan Karen, 2015, INT C LEARN REPR; Soatto S, 2009, IEEE I CONF COMP VIS, P2138, DOI 10.1109/ICCV.2009.5459468; Stober J., 2011, P 1 INT C DEV LEARN; Sutton Richard S, 1998, INTRO REINFORCEMENT, V2; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Walker J, 2015, IEEE I CONF COMP VIS, P2443, DOI 10.1109/ICCV.2015.281; Watter Manuel, 2015, ADV NEURAL INFORM PR, V2, P2746; Wilkes D., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P136, DOI 10.1109/CVPR.1992.223215; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991; Xu K, 2015, INT C MACH LEARN, P2048; Yu XD, 2011, IEEE I CONF COMP VIS, P810, DOI 10.1109/ICCV.2011.6126320; Zhu Y., 2017, P INT C ROB AUT	63	12	13	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1601	1614		10.1109/TPAMI.2018.2840991	http://dx.doi.org/10.1109/TPAMI.2018.2840991			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29993712				2022-12-18	WOS:000470972300006
J	Das, A; Kottur, S; Gupta, K; Singh, A; Yadav, D; Lee, S; Moura, JMF; Parikh, D; Batra, D				Das, Abhishek; Kottur, Satwik; Gupta, Khushi; Singh, Avi; Yadav, Deshraj; Lee, Stefan; Moura, Jose M. F.; Parikh, Devi; Batra, Dhruv			Visual Dialog	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual dialog; computer vision; natural language processing; machine learning	GAME; GO	We introduce the task of Visual Dialog, which requires an Al agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in image, infer context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being sufficiently grounded in vision to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person real-time chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial v0.9 has been released and consists of similar to 1.2M dialog question-answer pairs from 10-round, human-human dialogs grounded in similar to 120k images from the COCO dataset. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders-Late Fusion, Hierarchical Recurrent Encoder and Memory Network (optionally with attention over image features)-and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the Al agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank and recall@k of human response. We quantify the gap between machine and human performance on the Visual Dialog task via human studies. Putting it all together, we demonstrate the first 'visual chatbot'! Our dataset, code, pretrained models and visual chatbot are available on https://visualdialog.org.	[Das, Abhishek; Yadav, Deshraj; Lee, Stefan; Parikh, Devi; Batra, Dhruv] Georgia Tech, Atlanta, GA 30332 USA; [Kottur, Satwik; Gupta, Khushi; Moura, Jose M. F.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Singh, Avi] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Parikh, Devi; Batra, Dhruv] Facebook AI Res, Menlo Pk, CA USA	University System of Georgia; Georgia Institute of Technology; Carnegie Mellon University; University of California System; University of California Berkeley; Facebook Inc	Das, A (corresponding author), Georgia Tech, Atlanta, GA 30332 USA.	abhshkdz@gatech.edu; skottur@andrew.cmu.edu; khushig@andrew.cmu.edu; avisingh@cs.berkeley.edu; deshraj@gatech.edu; steflee@gatech.edu; moura@andrew.cmu.edu; parikh@gatech.edu; dbatra@gatech.edu	Das, Abhishek/AAE-3060-2021	Moura, Jose/0000-0002-9822-8294; Lee, Stefan/0000-0001-5953-1963	NSF CAREER awards; ONR YIP awards; ONR [N00014-12-1-0903, N00014-14-1-0679]; Sloan Fellowship; ARO YIP awards; Paul G. Allen Family Foundation; ICTAS Junior Faculty awards; Google Faculty Research Awards; Amazon Academic Research Awards; AWS in Education Research grant	NSF CAREER awards(National Science Foundation (NSF)); ONR YIP awards; ONR(Office of Naval Research); Sloan Fellowship(Alfred P. Sloan Foundation); ARO YIP awards; Paul G. Allen Family Foundation; ICTAS Junior Faculty awards; Google Faculty Research Awards(Google Incorporated); Amazon Academic Research Awards; AWS in Education Research grant	We thank Harsh Agrawal, Jiasen Lu for help with AMT data collection; Xiao Lin, Latha Pemula for model discussions; Marco Baroni, Antoine Bordes, Mike Lewis, Marc'Aurelio Ranzato for helpful discussions. We are grateful to the developers of Torch [2] for building an excellent framework. This work was funded in part by NSF CAREER awards to DB and DP, ONR YIP awards to DP and DB, ONR Grant N00014-14-1-0679 to DB, a Sloan Fellowship to DP, ARO YIP awards to DB and DP, an Allen Distinguished Investigator award to DP from the Paul G. Allen Family Foundation, ICTAS Junior Faculty awards to DB and DP, Google Faculty Research Awards to DP and DB, Amazon Academic Research Awards to DP and DB, AWS in Education Research grant to DB, and NVIDIA GPU donations to DB. SK was supported by ONR Grant N00014-12-1-0903. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the U.S. Government, or any sponsor.	Agrawal A., 2016, P C EMP METH NAT LAN; Agrawal H., 2016, P C EMP METH NAT LAN; Andreas J., 2016, P N AM ASS COMP LING; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; [Anonymous], 2015, P INT C MACH LEARN; [Anonymous], 2017, IJCNLP; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bigham Jeffrey P, 2010, P 23 NUAL ACM S US I, P333, DOI [10.1145/1866029.1866080?casa_token=eqdciLsaAKsAAAAA:v_iSvCJKVqaa-xY5ls_4fwveOme0IVWxS0hy40kPYpp, DOI 10.1145/1866029.1866080]; Bordes A., 2015, CORR; Bordes Antoine, 2017, ICLR; Chattopadhyay P., 2017, P 5 AAAI C HUM COMP; Christie G., 2016, P C EMP METH NAT LAN; Danescu-Niculescu-Mizil Cristian, 2011, P 2 WORKSH COGN MOD, P76; Das A., 2016, P C EMP METH NAT LAN; Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321; de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475; Dodge J., 2016, P INT C LEARN REPR; Donahue Jeffrey, 2015, P IEEE C COMP VIS PA; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hermann KM, 2015, ADV NEUR IN, V28; Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7; Huang T.-H., 2016, P C N AM ASS COMP LI; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Jang Y., 2017, P IEEE C COMP VIS PA; Kannan A., 2016, P C KNOWL DISC DAT M; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kingma D.P, P 3 INT C LEARNING R; Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455; Lemon Oliver, 2006, P 11 C EUR CHAPT ASS, P119; Li J., 2016, P C EMP METH NAT LAN; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Chia-Wei, 2016, P C EMP METH NAT LAN; Lowe R., 2015, P 16 ANN SIGDIAL M D; Lu J., 2017, P C NEUR INF PROC SY; Lu J., 2015, DEEPER LSTM NORMALIZ, V6, P1; Lu JS, 2016, ADV NEUR IN, V29; Mahendru A., 2017, P C EMP METH NAT LAN; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Massiceti Daniela, 2018, P IEEE C COMP VIS PA; Mei Hongyuan, 2016, P AAAI C ART INT; Microsoft, BING SPELL CHECK API; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Paek Tim, 2001, P WORKSH EV LANG DIA; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Rajpurkar P., 2016, EMNLP; Ramanathan V, 2014, LECT NOTES COMPUT SC, V8689, P95, DOI 10.1007/978-3-319-10590-1_7; Ray Arijit, 2016, ARXIV160606622; Ren M., 2015, P 28 INT C NEUR INF, V2, P2953, DOI [10.5555/2969442.2969570, DOI 10.5555/2969442.2969570]; Rohrbach A., 2016, P EUR C COMPUT VIS; Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940; Seo P. H., 2017, P C NEUR INF PROC SY; Serban I. V., 2016, P ANN M ASS COMP LIN; Serban IV, 2017, AAAI CONF ARTIF INTE, P3295; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Simonyan K, 2015, 3 INT C LEARN REPR I; Strub F., 2017, P INT JOINT C ART IN; Sutskever Q. V. L. Ilya, 2014, P C NEUR INF PROC SY; Tapaswi M., 2016, P IEEE C COMP VIS PA; Venugopalan S., 2015, P N AM ASS COMP LING; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang LM, 2017, IEEE T IMAGE PROCESS, V26, P2055, DOI 10.1109/TIP.2017.2675339; Weizenbaum J., ELIZA; Weston J., 2016, P INT C LEARN REPR; Wu Q., 2018, P C COMP VIS PATT RE; Wu S., 2016, USING ARTIFICIAL INT; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542; Zhou K, 2016, DESTECH TRANS COMP; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	78	12	13	3	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1242	1256		10.1109/TPAMI.2018.2828437	http://dx.doi.org/10.1109/TPAMI.2018.2828437			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993628	hybrid			2022-12-18	WOS:000463607400016
J	Li, E; Mo, HL; Xu, D; Li, H				Li, Erbo; Mo, Hanlin; Xu, Dong; Li, Hua			Image Projective Invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2D projective transformation; relative projective differential invariant; projective weighted moment invariant; planar object recognition	MOMENT INVARIANTS; PATTERN-RECOGNITION	In this paper, we have proved the existence of projective moment invariants of images using finite combinations of weighted moments, with relative projective differential invariants as weight functions. We have given some instances constructed in that way, and analyzed possible issues could affect the performance. Some procedures are taken to estimate partial derivatives of discrete images, and a new method is designed to normalize the number of pixels for discrete images to minimize the changes before and after the projective transformation. We have carried out experiments using popular image databases and real images to test the performance. And the results show that the invariants proposed in this paper have better stability and discriminability than other previously used moment invariants in image retrieval and classification. Users can directly extract invariant features of images for a given planar object from different viewpoints without knowing the parameters of the 2D projective transformations. Therefore, the projective moment invariant could be potentially useful for planar object recognition, image description and classification.	[Li, Erbo] EON Real Inc, Irvine, CA 92618 USA; [Mo, Hanlin; Li, Hua] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Mo, Hanlin; Li, Hua] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Xu, Dong] Ambry Genet, Aliso Viejo, CA 92656 USA	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Mo, HL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	sophialiuli@gmail.com; mohanlin@ict.ac.cn; xudong0614@hotmail.com; lihua@ict.ac.cn		Li, Erbo/0000-0003-3882-5262; Li, Hua/0000-0003-4982-6455	National Natural Science Foundation of China [60873164, 61227802, 61379082]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work has partly been funded by the National Natural Science Foundation of China (Grant No. 60873164, 61227802 and 61379082). We would like to thank the reviewers for their valuable comments, and thank Dr. Huang, Yazhou for his assistance in the revisions. Erbo Li and Hanlin Mo contributed equally to this work.	Balmashnova E, 2008, J MATH IMAGING VIS, V31, P121, DOI 10.1007/s10851-008-0079-0; Csurka G, 1999, IEEE T PATTERN ANAL, V21, P58, DOI 10.1109/34.745735; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Gong M, 2017, COMPUT VIS IMAGE UND, V162, P46, DOI 10.1016/j.cviu.2017.07.003; Guggenheimer H.W., 1963, DIFFERENTIAL GEOMETR; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Kadlec M., 2011, P S GIS OSTR; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; Li E. B., 2017, ISOMORPHISM DIFFEREN; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011; Mo HL, 2017, COMM COM INF SC, V772, P183, DOI 10.1007/978-981-10-7302-1_16; Mo HL, 2017, COMM COM INF SC, V773, P551, DOI 10.1007/978-981-10-7305-2_47; Mundy L., 1992, GEOMETRIC INVARIANTS; Olver PJ, 1999, ACTA APPL MATH, V59, P45, DOI 10.1023/A:1006295328209; OLVER PJ, 1995, INVARIANTS SYMMETRY; RIVLIN E, 1995, IEEE T PATTERN ANAL, V17, P226, DOI 10.1109/34.368188; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Siebert A., 2000, COMPUT SCI; Suk T, 2004, IEEE T PATTERN ANAL, V26, P1364, DOI 10.1109/TPAMI.2004.89; Suk T, 2011, PATTERN RECOGN, V44, P2047, DOI 10.1016/j.patcog.2010.05.015; VANGOOL L, 1995, IMAGE VISION COMPUT, V13, P259, DOI 10.1016/0262-8856(95)99715-D; Voss K., 1995, ADAPTIVE MODELS INVA; Wang Y., 2013, J APPL MATH, V2013, P211; Wang YB, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL II, P13, DOI 10.1109/ICMTMA.2009.41; Wang YB, 2015, J MATH IMAGING VIS, V51, P248, DOI 10.1007/s10851-014-0518-z; Wang YB, 2010, PATTERN RECOGN, V43, P3233, DOI 10.1016/j.patcog.2010.05.004; Wang YB, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P249, DOI 10.1109/ISISE.2008.246; Weiss I., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P291, DOI 10.1109/CVPR.1988.196251; Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120; Wu YH, 2005, IEEE I CONF COMP VIS, P1547; Xu D., 2007, J INF COMPUT SCI, V4, P1364; Xu D, 2008, PATTERN RECOGN, V41, P240, DOI 10.1016/j.patcog.2007.05.001; Yang B, 2011, PATTERN RECOGN LETT, V32, P1283, DOI 10.1016/j.patrec.2011.03.012; Zunic J, 2010, PATTERN RECOGN, V43, P47, DOI 10.1016/j.patcog.2009.06.017	36	12	13	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1144	1157		10.1109/TPAMI.2018.2832060	http://dx.doi.org/10.1109/TPAMI.2018.2832060			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29994044	Green Submitted			2022-12-18	WOS:000463607400009
J	Ye, HJ; Zhan, DC; Jiang, Y; Zhou, ZH				Ye, Han-Jia; Zhan, De-Chuan; Jiang, Yuan; Zhou, Zhi-Hua			What Makes Objects Similar: A Unified Multi-Metric Learning Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Distance metric learning; multi-metric learning; similarity measures; semantic		Linkages are essentially determined by similarity measures that may be derived from multiple perspectives. For example, spatial linkages are usually generated based on localities of heterogeneous data. Semantic linkages, however, can come from even more properties, such as different physical meanings behind social relations. Many existing metric learning models focus on spatial linkages but leave the rich semantic factors unconsidered. We propose a Unified Multi-Metric Learning ((UML)-L-2) framework to exploit multiple types of metrics with respect to overdetermined similarities between linkages. In (UML)-L-2, types of combination operators are introduced for distance characterization from multiple perspectives, and thus can introduce flexibilities for representing and utilizing both spatial and semantic linkages. Besides, we propose a uniform solver for (UML)-L-2, and the theoretical analysis reflects the generalization ability of (UML)-L-2 as well. Extensive experiments on diverse applications exhibit the superior classification performance and comprehensibility of (UML)-L-2. Visualization results also validate its ability to physical meanings discovery.	[Ye, Han-Jia; Zhan, De-Chuan; Jiang, Yuan; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China	Nanjing University	Ye, HJ (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	yehj@lamda.nju.edu.cn; zhandc@lamda.nju.edu.cn; jiangy@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn	jiang, anyi/GPT-0379-2022		NSFC [61673201, 61751306, 61773198]; Huawei Fund	NSFC(National Natural Science Foundation of China (NSFC)); Huawei Fund(Huawei Technologies)	This research was supported by NSFC (61673201, 61751306, 61773198) and Huawei Funding.	Amid E, 2015, PR MACH LEARN RES, V37, P1472; [Anonymous], 2007, P 11 INT C ART INT S; [Anonymous], 2013, 30 INT C MACH LEARN; [Anonymous], PROC CVPR IEEE; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bellet A., 2015, METRIC LEARNING; Cao Q, 2016, MACH LEARN, V102, P115, DOI 10.1007/s10994-015-5499-7; Chakrabarti D, 2014, PR MACH LEARN RES, V32, P874; Changpinyo S, 2013, ADV NEURAL INFORM PR, P1511; Chechik G, 2010, J MACH LEARN RES, V11, P1109; Clemencon S, 2008, ANN STAT, V36, P844, DOI 10.1214/009052607000000910; Cook JA., 2007, P 11 INT C ART INT S, Vvol 2, P67; Do H., 2012, INT C ART INT STAT, P308; Fetaya E, 2015, PR MACH LEARN RES, V37, P162; Frank M, 2012, J MACH LEARN RES, V13, P459; Hsieh CK, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P193, DOI 10.1145/3038912.3052639; Hu JH, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2700405; Huang KZ, 2009, IEEE DATA MINING, P189, DOI 10.1109/ICDM.2009.22; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019; Law M. T, 2016, INT J COMPUT VISION, V121, P1; Leskovec J., 2012, P 25 INT C NEUR INF, P539, DOI DOI 10.1109/ICDM.2012.159; Li N., 2014, P NIPS, P1502; McDiarmid C., 1989, SURVEYS COMBINATORIC, V141, P148, DOI DOI 10.1017/CBO9781107359949.008; McFee B., 2010, P 27 INT C MACHINE L, P775; McFee B, 2011, J MACH LEARN RES, V12, P491; Nesterov Y., 2018, APPL OPTIMIZATION; Noh YK, 2018, IEEE T PATTERN ANAL, V40, P106, DOI 10.1109/TPAMI.2017.2666151; Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995; Schultz M, 2004, ADV NEUR IN, V16, P41; Shi Y, 2014, AAAI CONF ARTIF INTE, P2078; Sohn Kihyuk, 2016, NEURIPS, DOI DOI 10.5555/3157096.3157304; Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; van der Maaten L, 2012, MACH LEARN, V87, P33, DOI 10.1007/s10994-011-5273-4; Wang B, 2012, PROC CVPR IEEE, P2997, DOI 10.1109/CVPR.2012.6248029; Wang J, 2012, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE 2012, PVP 2012, VOL 9, P223; Wang Jun, 2012, ADV NEURAL INF PROCE, V25, P1601; Wang W., 2010, PROC 27 INT C MACH L, P1135; Wang XY, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9057-8; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Xing E., 2002, ADV NEURAL INFORM PR, V15, P505, DOI DOI 10.5555/2968618.2968683; Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273; Ye HJ, 2016, AAAI CONF ARTIF INTE, P2272; Ying YM, 2012, J MACH LEARN RES, V13, P1; Zhan D. C., 2009, P 26 INT C MACH LEAR, P1225, DOI DOI 10.1145/1553374.1553530; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495; Zhou Z.-H, 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106; Zhou ZH, 2016, FRONT COMPUT SCI-CHI, V10, P589, DOI 10.1007/s11704-016-6906-3; Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002	57	12	13	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1257	1270		10.1109/TPAMI.2018.2829192	http://dx.doi.org/10.1109/TPAMI.2018.2829192			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993879				2022-12-18	WOS:000463607400017
J	Huang, CT				Huang, Chao-Tsung			Empirical Bayesian Light-Field Stereo Matching by Robust Pseudo Random Field Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; light field; Markov random field; empirical Bayesian method		Light-field stereo matching problems are commonly modeled by Markov Random Fields MRFs) for statistical inference of depth maps. Nevertheless, most previous approaches did not adapt to image statistics but instead adopted fixed model parameters. They explored explicit vision cues, such as depth consistency and occlusion, to provide local adaptability and enhance depth quality. However, such additional assumptions could end up confining their applicability, e.g. algorithms designed for dense view sampling are not suitable for sparse one. In this paper, we get back to MRF fundamentals and develop an empirical Bayesian framework-Robust Pseudo Random Field-to explore intrinsic statistical cues for broad applicability. Based on pseudo-likelihoods with hidden soft-decision priors, we apply soft expectation-maximization EM) for good model fitting and perform hard EM for robust depth estimation. We introduce novel pixel difference models to enable such adaptability and robustness simultaneously. Accordingly, we devise a stereo matching algorithm to employ this framework on dense, sparse, and even denoised light fields. It can be applied to both true-color and grey-scale pixels. Experimental results show that it estimates scene-dependent parameters robustly and converges quickly. In terms of depth accuracy and computation speed, it also outperforms state-of-the-art algorithms constantly.	[Huang, Chao-Tsung] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan	National Tsing Hua University	Huang, CT (corresponding author), Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan.	chaotsung@ee.nthu.edu.tw			Ministry of Science and Technology, Taiwan [MOST 103-2218-E-007-008-MY3]	Ministry of Science and Technology, Taiwan(Ministry of Science and Technology, TaiwanMinistry of Science, ICT & Future Planning, Republic of Korea)	The author acknowledges support from the Ministry of Science and Technology, Taiwan, under Grant MOST 103-2218-E-007-008-MY3.	[Anonymous], 1997, P UNC ART INT AUG; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Heber S, 2017, IEEE I CONF COMP VIS, P2271, DOI 10.1109/ICCV.2017.247; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Huang CT, 2017, IEEE I CONF COMP VIS, P11, DOI 10.1109/ICCV.2017.11; Huang CT, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2517668; Huang CT, 2015, IEEE T IMAGE PROCESS, V24, P4299, DOI 10.1109/TIP.2015.2463220; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johannsen O, 2016, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2016.355; Kim C., 2013, ACM T GRAPHIC, V73, P1; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10; Kumar S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1150, DOI 10.1109/ICCV.2003.1238478; Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394; Liu Y, 2011, IEEE T IMAGE PROCESS, V20, P2515, DOI 10.1109/TIP.2011.2118223; Mei Xing, 2011, IEEE INT C COMP VIS, P467, DOI DOI 10.1109/ICCVW.2011.6130280; Rerabek M., 2016, PROC 8 INT C QUALITY, P1; Sheng H, 2015, IEEE IMAGE PROC, P852, DOI 10.1109/ICIP.2015.7350920; Si L., 2016, P AS C COMP VIS, P83; Su CC, 2013, IEEE T IMAGE PROCESS, V22, P2259, DOI 10.1109/TIP.2013.2249075; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wanner S., 2013, P VIS MOD VIS, P145; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Williem, 2018, IEEE T PATTERN ANAL, V40, P2484, DOI 10.1109/TPAMI.2017.2746858; Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347; Zhang L, 2007, IEEE T PATTERN ANAL, V29, P331, DOI 10.1109/TPAMI.2007.36; Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007	35	12	12	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					552	565		10.1109/TPAMI.2018.2809502	http://dx.doi.org/10.1109/TPAMI.2018.2809502			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994438				2022-12-18	WOS:000458168800003
J	Wang, YL; Tang, YY; Li, LQ; Chen, H; Pan, JJ				Wang, Yulong; Tang, Yuan Yan; Li, Luoqing; Chen, Hong; Pan, Jianjia			Atomic Representation-Based Classification: Theory, Algorithm, and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Atomic representation; representation-based classification; atomic classification condition	SPARSE REPRESENTATION; ROBUST	Representation-based classification (RC) methods such as sparse RC (SRC) have attracted great interest in pattern recognition recently. Despite their empirical success, few theoretical results are reported to justify their effectiveness. In this paper, we establish the theoretical guarantees for a general unified framework termed as atomic representation-based classification (ARC), which includes most RC methods as special cases. We introduce a new condition called atomic classification condition (ACC), which reveals important geometric insights for the theory of ARC. We show that under such condition ARC is provably effective in correctly recognizing any new test sample, even corrupted with noise. Our theoretical analysis significantly broadens the range of conditions under which RC methods succeed for classification in the following two aspects: (1) prior theoretical advances of RC are mainly concerned with the single SRC method while our theory can apply to the general unified ARC framework, including SRC and many other RC methods; and (2) previous works are confined to the analysis of noiseless test data while we provide theoretical guarantees for ARC using both noiseless and noisy test data. Numerical results are provided to validate and complement our theoretical analysis of ARC and its important special cases for both noiseless and noisy test data.	[Wang, Yulong] Chengdu Univ, Sch Informat Sci & Engn, Chengdu 610106, Sichuan, Peoples R China; [Tang, Yuan Yan; Pan, Jianjia] Univ Macau, Fac Sci & Technol, Macau 999078, Peoples R China; [Li, Luoqing] Hubei Univ, Fac Math & Stat, Wuhan 430062, Hubei, Peoples R China; [Chen, Hong] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA	Chengdu University; University of Macau; Hubei University; University of Texas System; University of Texas Arlington	Li, LQ (corresponding author), Hubei Univ, Fac Math & Stat, Wuhan 430062, Hubei, Peoples R China.	wangyulong6251@gmail.com; yytang@umac.mo; lilq@hubu.edu.cn; chenh@mail.hzau.edu.cn; jianjiapan@gmail.com		Wang, Yulong/0000-0002-1033-9281	National Natural Science Foundation of China [61702057, 61273244, 11771130, 11671161]; Macau-China [008-2014-AMJ]; Research Grants of University of Macau [MYRG2015-00049-FST, MYRG2015-00050-FST, RDG009/FST-TYY/2012]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Macau-China; Research Grants of University of Macau	The authors would like to thank the editor, the associate editor, and anonymous reviewers for their constructive comments in helping improve our work. This work was supported by the National Natural Science Foundation of China under Grant Nos. 61702057, 61273244, 11771130, and 11671161, the Macau-China join Project No. 008-2014-AMJ, and the Research Grants of University of Macau under Grant Nos. MYRG2015-00049-FST, MYRG2015-00050-FST, and RDG009/FST-TYY/2012.	Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595; Chi YJ, 2014, IEEE T PATTERN ANAL, V36, P1519, DOI 10.1109/TPAMI.2013.236; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Dyer EL, 2013, J MACH LEARN RES, V14, P2487; Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Elhamifar E., 2014, ARXIV14127260; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Elhamifar E, 2010, INT CONF ACOUST SPEE, P1926, DOI 10.1109/ICASSP.2010.5495317; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109; Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199; Soltanolkotabi M, 2012, ANN STAT, V40, P2195, DOI 10.1214/12-AOS1034; Tang YY, 2015, IEEE T CYBERNETICS, V45, P2905, DOI 10.1109/TCYB.2015.2389232; Wang Y, 2013, INT CONF MACH LEARN, P136; Wang YL, 2016, INT C PATT RECOG, P3685, DOI 10.1109/ICPR.2016.7900207; Wang YL, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2492819; Wang YL, 2015, IEEE T SIGNAL PROCES, V63, P4010, DOI 10.1109/TSP.2015.2425803; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892; Yang J., 2011, P IEEE INT C MULT EX, P1; Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849; Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393; You C., 2015, ARXIV150701307; You C, 2016, PROC CVPR IEEE, P3918, DOI 10.1109/CVPR.2016.425; You C, 2015, PR MACH LEARN RES, V37, P1585; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277	35	12	13	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					6	19		10.1109/TPAMI.2017.2780094	http://dx.doi.org/10.1109/TPAMI.2017.2780094			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990233				2022-12-18	WOS:000452434800002
J	Lin, CH; Kumar, A				Lin, Chenhao; Kumar, Ajay			Tetrahedron Based Fast 3D Fingerprint Identification Using Colored LEDs Illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; 3D fingerprint matching; 3D minutiae tetrahedron; hierarchical tetrahedron	REPRESENTATION; ALGORITHM; SHAPE	Emerging 3D fingerprint recognition technologies have attracted growing attention in addressing the limitations from contact-based fingerprint acquisition and improve recognition accuracy. However, the complex 3D imaging setups employed in these systems typically require structured lighting with scanners or multiple cameras which are bulky with higher cost. This paper presents a more accurate and efficient 3D fingerprint identification approach using a single 2D camera with multiple colored LED illumination. A 3D minutiae tetrahedron based algorithm is developed to more efficiently match recovered minutiae features in 3D space and address the limitations of 3D minutiae matching approach in the literature. This algorithm significantly improves the matching time to about 15 times than the state-of-art in the reference. A hierarchical tetrahedron matching scheme is also developed to further improve the matching accuracy with faster speed. The 2D images acquired to reconstruct the 3D fingerprints are also used to recover 2D minutiae and further improve matching performance for 3D fingerprints. A new two-session database acquiring from 300 different clients consists of 2760 3D fingerprints reconstructed from 5520 colored 2D fingerprints is also developed and shared in public domain to further advance much needed research in this area. Extensive experimental results presented in this paper validate our approach and demonstrate the effectiveness of proposed algorithms.	[Lin, Chenhao; Kumar, Ajay] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Hong Kong Polytechnic University	Kumar, A (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.	csclin@comp.polyu.edu.hk; Ajay.Kumar@polyu.edu.hk		Kumar, Ajay/0000-0002-3761-2436	General Research Fund from Research Grant Council of Hong Kong [PolyU 516913]	General Research Fund from Research Grant Council of Hong Kong	Authors wish to thank all reviewers and associate editor whose suggestions have helped to improve this paper. This work is supported by General Research Fund from Research Grant Council of Hong Kong, project number PolyU 516913.	Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578; AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; [Anonymous], 2011, 1979422011 ISOIEC; Arora S. S., 2014, P INT C PATT REC; Belyaev A., 2006, MPIINFMPGDE, P1; Chen YJ, 2006, LECT NOTES COMPUT SC, V4270, P1; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; FANG TP, 1995, IEEE COMPUT GRAPH, V15, P62; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Iula A, 2011, MICROELECTRON ENG, V88, P2278, DOI 10.1016/j.mee.2010.11.030; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Johnson MK, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964941; Johnson MK, 2009, PROC CVPR IEEE, P1070, DOI 10.1109/CVPRW.2009.5206534; Komarinski P, 2005, AUTOMATED FINGERPRIN; Koteshwara K. K., 1923, U.S. Patent, Patent No. [9,424,456, 9424456]; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; Krishnasamy P., 2011, P 2011 INT JOINT C B, P1; Kumar A., 2011, P C COMP VIS PATT RE, P114; Kumar A., 2018, CONTACTLESS 3D FINGE, V1; Kumar A, 2015, IEEE T PATTERN ANAL, V37, P681, DOI 10.1109/TPAMI.2014.2339818; Kumar A, 2013, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2013.441; Lalonde J.-F., 2006, TECH REP; Lamberti N, 2011, SENSOR ACTUAT A-PHYS, V172, P561, DOI 10.1016/j.sna.2011.09.038; Lee C, 2006, LECT NOTES COMPUT SC, V4109, P358; Maev RG, 2008, ACOUST IMAG, V29, P279, DOI 10.1007/978-1-4020-8823-0_39; Mallick SP, 2006, LECT NOTES COMPUT SC, V3951, P550; Maltoni D., 2009, HDB FINGERPRINT RECO; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Parziale G, 2006, LECT NOTES COMPUT SC, V3832, P244; Parziale G, 2004, LECT NOTES COMPUT SC, V3072, P241; Parziale G, 2009, ADV PATTERN RECOGNIT, P83, DOI 10.1007/978-1-84882-385-3_4; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; Savoia A., 2010, 2010 International Ultrasonics Symposium, P1877, DOI 10.1109/ULTSYM.2010.0475; Schneider J. K., 2013, U.S. Patent No, Patent No. [8,601,876, 8601876]; SRINIVASAN V, 1984, APPL OPTICS, V23, P3105, DOI 10.1364/AO.23.003105; Uz T., 2007, 2007 1 IEEE INT C BI; Wang YC, 2010, IEEE T INF FOREN SEC, V5, P750, DOI 10.1109/TIFS.2010.2062177; Watson C. I., 2007, 7392 NISTIR; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Xiong Y, 2015, IEEE T PATTERN ANAL, V37, P67, DOI 10.1109/TPAMI.2014.2343211	42	12	13	4	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					3022	3033		10.1109/TPAMI.2017.2771292	http://dx.doi.org/10.1109/TPAMI.2017.2771292			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990166				2022-12-18	WOS:000449355500017
J	Ren, SG; Huang, S; Ye, JP; Qian, XN				Ren, Shaogang; Huang, Shuai; Ye, Jieping; Qian, Xiaoning			Safe Feature Screening for Generalized LASSO	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generalized LASSO; structured sparsity; sparse learning; feature selection; feature screening	RULES	Solving Generalized LASSO (GL) problems is challenging, particularly when analyzing many features with a complex interacting structure. Recent developments have found effective ways to identify inactive features so that they can be removed or aggregated to reduce the problem size before applying optimization solvers for learning. However, existing methods are mostly devoted to special cases of GL problems with special structures for feature interactions, such as chains or trees. Developing screening rules, particularly, safe screening rules to remove or aggregate features with general interaction structures, calls for a very different screening approach for GL problems. To tackle this challenge, we formulate the GL screening problem as a bound estimation problem in a large linear inequality system when solving them in the dual space. We propose a novel bound propagation algorithm for efficient safe screening for general GL problems, which can be further enhanced by developing novel transformation methods that can effectively decouple interactions among features. The proposed propagation and transformation methods are applicable with dynamic screening that can easily initiate the screening process while existing screening methods require the knowledge of the solution under a desirable regularization parameter. Experiments on both synthetic and real-world data demonstrate the effectiveness of the proposed screening method.	[Ren, Shaogang; Qian, Xiaoning] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77840 USA; [Huang, Shuai] Univ Washington, Dept Ind & Syst Engn, Seattle, WA 98195 USA; [Ye, Jieping] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA; [Ye, Jieping] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Texas A&M University System; Texas A&M University College Station; University of Washington; University of Washington Seattle; University of Michigan System; University of Michigan; University of Michigan System; University of Michigan	Ren, SG (corresponding author), Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77840 USA.	shaogangren@email.tamu.edu; shuaih@uw.edu; jpye@umich.edu; xqian@ece.tamu.edu		Qian, Xiaoning/0000-0002-4347-2476; Ren, Shaogang/0000-0002-2961-1636	US National Science Foundation (NSF) [1553281]; Juvenile Diabetes Research Foundation (JDRF) [1-PNF-2014-151-A-V]	US National Science Foundation (NSF)(National Science Foundation (NSF)); Juvenile Diabetes Research Foundation (JDRF)(Juvenile Diabetes Research Foundation)	The authors would like to thank anonymous reviewers for their constructive suggestions to help improve the manuscript. XQ has been partially supported by Award #1553281 from US National Science Foundation (NSF). SH and XQ were partially supported by Grant 1-PNF-2014-151-A-V from Juvenile Diabetes Research Foundation (JDRF).	[Anonymous], 2006, ALZHEIMERS DIS NEURO; Arnold TB, 2016, J COMPUT GRAPH STAT, V25, P1, DOI 10.1080/10618600.2015.1008638; Bonnefoy A, 2015, IEEE T SIGNAL PROCES, V63, P5121, DOI 10.1109/TSP.2015.2447503; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Chuang HY, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100180; El Ghaoui L, 2012, PAC J OPTIM, V8, P667; Fan JQ, 2008, J R STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; Fercoq O, 2015, PR MACH LEARN RES, V37, P333; Grant Michael, 2014, CVX MATLAB SOFTWARE; Huang S., 2009, ADV NEURAL INFORM PR, V22, P808; IBMCPLEX Optimizer, 2012, IBM CPLEX OPTIMIZER; Korovin K, 2011, LECT NOTES ARTIF INT, V6803, P369, DOI 10.1007/978-3-642-22438-6_28; Liu J., 2014, P INT C MACH LEARN, P1556; Liu J., 2014, ADV NEURAL INFORM PR, V27, P1053; MALSAR: Multi-task Learning via Structural Regularization, 2012, MALSAR MULTITASK LEA; Ndiaye E, 2015, ADV NEUR IN, V28; Ren SG, 2015, JMLR WORKSH CONF PRO, V38, P781; Shaogang Ren, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2828, DOI 10.1109/ICASSP.2014.6854116; SLEP: Sparse Learning with Efficient Projections, 2011, SLEP SPARSE LEARNING; Tibshirani R, 2005, J R STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tibshirani R, 2012, J R STAT SOC B, V74, P245, DOI 10.1111/j.1467-9868.2011.01004.x; Tibshirani RJ, 2011, ANN STAT, V39, P1335, DOI 10.1214/11-AOS878; Wang J., 2014, ADV NEURAL INFORM PR, P2132; Wang J., 2015, ADV NEURAL INFORM PR, P1279; Wang J, 2015, J MACH LEARN RES, V16, P1063; Wang J, 2015, IEEE T PATTERN ANAL, V37, P1806, DOI 10.1109/TPAMI.2014.2388203; Xiang Z. J., 2012, P IEEE INT C AC SPEE; Xin B., 2014, P AAAI, P2163; Yang Sen, 2012, KDD, P922	30	12	12	3	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2992	3006		10.1109/TPAMI.2017.2776267	http://dx.doi.org/10.1109/TPAMI.2017.2776267			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990186	hybrid			2022-12-18	WOS:000449355500015
J	Wu, SH; Bertholet, P; Huang, H; Cohen-Or, D; Gong, ML; Zwicker, M				Wu, Shihao; Bertholet, Peter; Huang, Hui; Cohen-Or, Daniel; Gong, Minglun; Zwicker, Matthias			Structure-Aware Data Consolidation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data consolidation; filtering; clustering; dimensionality reduction; manifold denoising	DIMENSIONALITY REDUCTION	We present a structure-aware technique to consolidate noisy data, which we use as a pre-process for standard clustering and dimensionality reduction. Our technique is related to mean shift, but instead of seeking density modes, it reveals and consolidates continuous high density structures such as curves and surface sheets in the underlying data while ignoring noise and outliers. We provide a theoretical analysis under a Gaussian noise model, and show that our approach significantly improves the performance of many non-linear dimensionality reduction and clustering algorithms in challenging scenarios.	[Wu, Shihao; Bertholet, Peter] Univ Bern, Inst Informat, Neubruckstr 10, CH-3012 Bern, Switzerland; [Huang, Hui] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China; [Cohen-Or, Daniel] Tel Aviv Univ, Comp Sci Dept, IL-69778 Tel Aviv, Israel; [Gong, Minglun] Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1C 5S7, Canada; [Zwicker, Matthias] Univ Maryland, Coll Comp Math & Nat Sci, Comp Sci Dept, College Pk, MD 20742 USA	University of Bern; Shenzhen University; Tel Aviv University; Memorial University Newfoundland; University System of Maryland; University of Maryland College Park	Huang, H (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.	shihao.wu312@gmail.com; peter_bertholet@hotmail.com; hhzhiyan@gmail.com; cohenor@gmail.com; gongml@gmail.com; zwicker@inf.unibe.ch		Huang, Hui/0000-0003-3212-0544; Gong, Minglun/0000-0001-5820-5381	Swiss National Science Foundation [169151]; National Science Foundation of China [61522213, 61379090]; NSFC-ISF Joint Research Program [61761146002, 2472/17]; Natural Sciences and Engineering Research Council of Canada [2017-06086]; Guangdong Science and Technology Program [2015A030312015]; Natural Science Foundation of Shenzhen University [827-000196]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); National Science Foundation of China(National Natural Science Foundation of China (NSFC)); NSFC-ISF Joint Research Program; Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Guangdong Science and Technology Program; Natural Science Foundation of Shenzhen University	We thank the anonymous reviewers for their constructive comments. This work was supported in part by Swiss National Science Foundation (169151), National Science Foundation of China (61522213, 61379090), NSFC-ISF Joint Research Program (61761146002, 2472/17), Natural Sciences and Engineering Research Council of Canada (2017-06086), Guangdong Science and Technology Program (2015A030312015), and Natural Science Foundation of Shenzhen University (827-000196). Hui Huang (hhzhiyan@gmail.com) is the corresponding author of this paper.	Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Borg I., 2005, MODERN MULTIDIMENSIO, DOI 10.18637/jss.v014.b04; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Charikar M, 2002, J COMPUT SYST SCI, V65, P129, DOI 10.1006/jcss.2002.1882; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Deutsch S, 2016, INT CONF ACOUST SPEE, P4673, DOI 10.1109/ICASSP.2016.7472563; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Franti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gong Dian, 2010, J Mach Learn Res, V2010, P265; Hastie T, 2009, ELEMENTS STAT LEARNI; Hein Matthias, 2007, ADV NEURAL INFORM PR, P561; Huang H., 2013, ACM T GRAPHIC, V32, DOI DOI 10.1145/2461912.2461913; Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645; Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Lindsay B. G, 1995, NSF CBMS REGIONAL C, pI, DOI DOI 10.1214/CBMS/1462106013; Lipman Y., 2007, ACM T GRAPHIC, V26; Murtagh F, 2014, J CLASSIF, V31, P274, DOI 10.1007/s00357-014-9161-z; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tian Zhang, 1996, SIGMOD Record, V25, P103, DOI 10.1145/235968.233324; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang B, 2013, PROC CVPR IEEE, P468, DOI 10.1109/CVPR.2013.67; Wang WR, 2010, PROC CVPR IEEE, P1759, DOI 10.1109/CVPR.2010.5539845; Wang Y, 2015, AER ADV ENG RES, V21, P1422; Wang Y, 2011, IEEE T NEURAL NETWOR, V22, P1149, DOI 10.1109/TNN.2011.2147798; Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361	39	12	13	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2529	2537		10.1109/TPAMI.2017.2754254	http://dx.doi.org/10.1109/TPAMI.2017.2754254			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28945589				2022-12-18	WOS:000443875500019
J	Li, ZW; Cheong, LF; Yang, S; Toh, KC				Li, Zhuwen; Cheong, Loong-Fah; Yang, Shuoguang; Toh, Kim-Chuan			Simultaneous Clustering and Model Selection: Algorithm, Theory and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; segmentation; model selection; multi-structure fitting	IMAGE SEGMENTATION; VALIDATION; GEOMETRY	While clustering has been well studied in the past decade, model selection has drawn much less attention due to the difficulty of the problem. In this paper, we address both problems in a joint manner by recovering an ideal affinity tensor from an imperfect input. By taking into account the relationship of the affinities induced by the cluster structures, we are able to significantly improve the affinity input, such as repairing those entries corrupted by gross outliers. More importantly, the recovered ideal affinity tensor also directly indicates the number of clusters and their membership, thus solving the model selection and clustering jointly. To enforce the requisite global consistency in the affinities demanded by the cluster structure, we impose a number of constraints, specifically, among others, the tensor should be low rank and sparse, and it should obey what we call the rank-1 sum constraint. To solve this highly non-smooth and non-convex problem, we exploit the mathematical structures, and express the original problem in an equivalent form amenable for numerical optimization and convergence analysis. To scale to large problem sizes, we also propose an alternative formulation, so that those problems can be efficiently solved via stochastic optimization in an online fashion. We evaluate our algorithm with different applications to demonstrate its superiority, and show it can adapt to a large variety of settings.	[Li, Zhuwen; Cheong, Loong-Fah] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Yang, Shuoguang] Columbia Univ, Dept Ind Engn & Operat Res, New York, NY 10027 USA; [Toh, Kim-Chuan] Natl Univ Singapore, Dept Math, Singapore 119077, Singapore	National University of Singapore; Columbia University; National University of Singapore	Li, ZW (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore.	elelizh@nus.edu.sg; eleclf@nus.edu.sg; sy2614@columbia.edu; mattohkc@nus.edu.sg	Toh, Kim-Chuan/A-6068-2010		Singapore PSF [1521200082]	Singapore PSF	This work was partially supported by the Singapore PSF grant 1521200082. Shuoguang Yang worked on this project as a research engineer in the Department of Mathematics, National University of Singapore, Singapore.	Agarwal S, 2005, PROC CVPR IEEE, P838; Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Alzate C, 2010, IEEE T PATTERN ANAL, V32, P335, DOI 10.1109/TPAMI.2008.292; Bagon S., 2011, CORR; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; Barmpoutis A, 2012, SIAM J IMAGING SCI, V5, P434, DOI 10.1137/100801664; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Ben-Hur Asa, 2002, Pac Symp Biocomput, P6; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Bulo SR, 2013, IEEE T PATTERN ANAL, V35, P1312, DOI 10.1109/TPAMI.2012.226; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Chen YD, 2014, J MACH LEARN RES, V15, P2213; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z; Demaine ED, 2003, LECT NOTES COMPUT SC, V2764, P1; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Kanatani K, 1998, INT J COMPUT VISION, V26, P171, DOI 10.1023/A:1007948927139; Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095; Kolda T.G, 2006, SAND20062081; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Lange T, 2004, NEURAL COMPUT, V16, P1299, DOI 10.1162/089976604773717621; Leordeanu M., 2012, P 15 INT C ART INT S, P676; Li GY, 2015, SIAM J OPTIMIZ, V25, P2434, DOI 10.1137/140998135; Li ZW, 2016, PROC CVPR IEEE, P5347, DOI 10.1109/CVPR.2016.577; Li ZW, 2014, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2014.41; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu H., 2010, ADV NEURAL INFORM PR, P1414; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; Miettinen P., 2009, THESIS; Miettinen P, 2008, IEEE T KNOWL DATA EN, V20, P1348, DOI 10.1109/TKDE.2008.53; Ng AY, 2002, ADV NEUR IN, V14, P849; Ouyang Hua, 2013, P 30 INT C MACH LEAR, P80; Purkait P, 2014, LECT NOTES COMPUT SC, V8692, P672, DOI 10.1007/978-3-319-10593-2_44; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Shashua A, 2006, LECT NOTES COMPUT SC, V3954, P595; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Soltanolkotabi M, 2012, ANN STAT, V40, P2195, DOI 10.1214/12-AOS1034; Still S, 2004, NEURAL COMPUT, V16, P2483, DOI 10.1162/0899766042321751; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Tsuda K., 2005, P 22 INT C MACH LEAR, P920; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Vitaladevuni SN, 2010, PROC CVPR IEEE, P2203, DOI 10.1109/CVPR.2010.5539901; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang B, 2012, PROC CVPR IEEE, P2312, DOI 10.1109/CVPR.2012.6247942; Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350; Yuzhao Ni, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P1179, DOI 10.1109/ICDMW.2010.64; Zhang A., 2012, P 28 C UNCERTAINTY A, P944; Zhang T, 2012, INT J COMPUT VISION, V100, P217, DOI 10.1007/s11263-012-0535-6; Zhou D, 2006, P 2006 C ADV NEURAL, V19, DOI 10.7551/mitpress/7503.003.0205; Zien JY, 1999, IEEE T COMPUT AID D, V18, P1389, DOI 10.1109/43.784130	63	12	12	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1964	1978		10.1109/TPAMI.2017.2739147	http://dx.doi.org/10.1109/TPAMI.2017.2739147			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28809676				2022-12-18	WOS:000437271100013
J	Vasconcelos, F; Barreto, JP; Boyer, E				Vasconcelos, Francisco; Barreto, Joao P.; Boyer, Edmond			Automatic Camera Calibration Using Multiple Sets of Pairwise Correspondences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera calibration; camera networks; minimal algorithms; RANSAC		We propose a new method to add an uncalibrated node into a network of calibrated cameras using only pairwise point correspondences. While previous methods perform this task using triple correspondences, these are often difficult to establish when there is limited overlap between different views. In such challenging cases we must rely on pairwise correspondences and our solution becomes more advantageous. Our method includes an 11-point minimal solution for the intrinsic and extrinsic calibration of a camera from pairwise correspondences with other two calibrated cameras, and a new inlier selection framework that extends the traditional RANSAC family of algorithms to sampling across multiple datasets. Our method is validated on different application scenarios where a lack of triple correspondences might occur: addition of a new node to a camera network; calibration and motion estimation of a moving camera inside a camera network; and addition of views with limited overlap to a Structure-from-Motion model.	[Vasconcelos, Francisco] UCL, London WC1E 6BT, England; [Barreto, Joao P.] Univ Coimbra, Inst Syst & Robot, P-3000001 Coimbra, Portugal; [Boyer, Edmond] INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, France	University of London; University College London; Universidade de Coimbra	Vasconcelos, F (corresponding author), UCL, London WC1E 6BT, England.	f.vasconcelos@ucl.ac.uk; jpbar@isr.uc.pt; edmond.boyer@inria.fr	Barreto, Joao P/I-2845-2012	Barreto, Joao P/0000-0001-5220-9170	Portuguese Science Foundation [SFRH/BD/72323/2010]; French National Research Agency; project MORPHEO	Portuguese Science Foundation(Portuguese Foundation for Science and Technology); French National Research Agency(French National Research Agency (ANR)); project MORPHEO	The authors acknowledge support of the Portuguese Science Foundation (grant SFRH/BD/72323/2010), the French National Research Agency, and the project MORPHEO.	Allard J., 2006, P IEEE INT C COMP VI, P46; [Anonymous], 2017, 4D REPOSITORY; Barreto J., 2004, P P 5 WORKSH OMN VIS, V63, P64; Barreto J. P. d.A, 2004, THESIS; Barreto JP, 2005, IEEE I CONF COMP VIS, P625; Clipp B, 2009, IEEE I CONF COMP VIS, P1725, DOI 10.1109/ICCV.2009.5459387; Courchay J, 2012, INT J COMPUT VISION, V97, P71, DOI 10.1007/s11263-011-0483-6; Devarajan D., 2006, ACM T SENSOR NETWORK, V2, P380, DOI DOI 10.1145/1167935.1167939; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2001, PROC CVPR IEEE, P125; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Jacobs N., 2009, P 17 ACM SIGSPATIAL, P111, DOI DOI 10.1145/1653771.1653789; Josephson K., 2007, IEEE C COMP VIS PATT, P1; Kim JH, 2010, IEEE T PATTERN ANAL, V32, P1044, DOI 10.1109/TPAMI.2009.82; Kumar R., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587676; Levi N, 2003, PROC CVPR IEEE, P518; Longuet-Higgins HC, 1987, READINGS COMPUTER VI; Ma Y., 2004, INVITATION 3 D VISIO; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Pottmann Helmut, 2001, MATH VISUAL, V2; Puwein J., 2011, P IEEE WORKSH APPL C, P321; Raposo C, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.114; Raposo C, 2014, LECT NOTES COMPUT SC, V8690, P48, DOI 10.1007/978-3-319-10605-2_4; Rodrigues R, 2010, LECT NOTES COMPUT SC, V6314, P382, DOI 10.1007/978-3-642-15561-1_28; Shen E, 2011, IEEE SENS J, V11, DOI 10.1109/JSEN.2011.2123884; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; Stewenius H., 2005, P WORKSH OMN VIS; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; Sturm P, 2010, FOUND TRENDS COMPUT, V6, P1, DOI 10.1561/0600000023; Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325; Thomas G, 2007, J REAL-TIME IMAGE PR, V2, P117, DOI 10.1007/s11554-007-0041-1; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Vasconcelos F, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.124; Vasconcelos F, 2012, LECT NOTES COMPUT SC, V7577, P724, DOI 10.1007/978-3-642-33783-3_52; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Zaharescu A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P504; Zhao ZJ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1197, DOI 10.1109/ICME.2008.4607655	41	12	13	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					791	803		10.1109/TPAMI.2017.2699648	http://dx.doi.org/10.1109/TPAMI.2017.2699648			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28463187	Green Submitted			2022-12-18	WOS:000426687100002
J	Wu, CX; Zhang, JM; Sener, O; Selman, B; Savarese, S; Saxena, A				Wu, Chenxia; Zhang, Jiemi; Sener, Ozan; Selman, Bart; Savarese, Silvio; Saxena, Ashutosh			Watch-n-Patch: Unsupervised Learning of Actions and Relations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised learning; activity discovery; robot application	ACTION RECOGNITION; EVENT; MODEL	There is a large variation in the activities that humans perform in their everyday lives. We consider modeling these composite human activities which comprises multiple basic level actions in a completely unsupervised setting. Our model learns high-level co-occurrence and temporal relations between the actions. We consider the video as a sequence of short-term action clips, which contains human-words and object-words. An activity is about a set of action-topics and object-topics indicating which actions are present and which objects are interacting with. We then propose a new probabilistic model relating the words and the topics. It allows us to model long-range action relations that commonly exist in the composite activities, which is challenging in previous works. We apply our model to the unsupervised action segmentation and clustering, and to a novel application that detects forgotten actions, which we call action patching. For evaluation, we contribute a new challenging RGB-D activity video dataset recorded by the new Kinect v2, which contains several human daily activities as compositions of multiple actions interacting with different objects. Moreover, we develop a robotic system that watches and reminds people using our action patching algorithm. Our robotic setup can be easily deployed on any assistive robots.	[Wu, Chenxia; Sener, Ozan; Selman, Bart] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; [Zhang, Jiemi] Didi Chuxing, Beijing 100193, Peoples R China; [Savarese, Silvio] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Saxena, Ashutosh] Brain Things Inc, Redwood City, CA 94062 USA	Cornell University; Stanford University	Wu, CX (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	chenxiawu@cs.cornell.edu; jmzhang10@gmail.com; ozan@cs.cornell.edu; selman@cs.cornell.edu; ssilvio@cs.stanford.edu; asaxena@cs.stanford.edu	Sener, Ozan/ABF-9436-2020					Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; [Anonymous], 2009, DAILY TELEGRAPH; [Anonymous], [No title captured]; Assari SM, 2014, PROC CVPR IEEE, P2529, DOI 10.1109/CVPR.2014.324; Bhattacharya S., 2014, P CVPR, P2235; Blei D. M., 2009, TEXT MINING CLASSIFI, V10, P71, DOI DOI 10.1145/1141844.1143859; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41; Chen G, 2014, IEEE INT CONF ROBOT, P4520, DOI 10.1109/ICRA.2014.6907519; Chenxia Wu, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4362, DOI 10.1109/CVPR.2015.7299065; Chrungoo A, 2014, LECT NOTES ARTIF INT, V8755, P84, DOI 10.1007/978-3-319-11973-1_9; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Emonet Remi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3233, DOI 10.1109/CVPR.2011.5995572; Faruquie TA, 2009, P BRIT MACH VIS C, P1; Gelman A., 2013, TEXTS STAT SCI SERIE, Vthird, DOI 10.1201/b16018; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172; Hu N., 2014, P ROB SCI SYST; Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Jones S, 2014, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2014.84; Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332; Ke Y, 2007, IEEE I CONF COMP VIS, P1424; Klaser A., 2012, P EUR C COMP VIS, V6553, P219; Koppula H., 2013, INT C MACHINE LEARNI, P792, DOI DOI 10.1177/0278364913478446; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; KOPPULA HS, 2013, P IEEE RSJ INT C INT, P2071; Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105; Laptev I, 2007, IEEE I CONF COMP VIS, P2165; Lillo I, 2014, PROC CVPR IEEE, P812, DOI 10.1109/CVPR.2014.109; Lin YY, 2014, PROC CVPR IEEE, P2617, DOI 10.1109/CVPR.2014.335; Losch M., 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P1022; Ma S, 2015, PROC INT CONF RECON; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Narayan S, 2014, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2014.337; Nguyen H, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P787, DOI 10.1109/IROS.2008.4651216; Ni BB, 2014, PROC CVPR IEEE, P756, DOI 10.1109/CVPR.2014.102; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Pei MT, 2013, COMPUT VIS IMAGE UND, V117, P1369, DOI 10.1016/j.cviu.2012.12.003; Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85; Piyathilaka L, 2015, SPRINGER TRAC ADV RO, V105, P395, DOI 10.1007/978-3-319-07488-7_27; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0; Souza F, 2015, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2015.7298727; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341; Varadarajan J, 2013, INT J COMPUT VISION, V103, P100, DOI 10.1007/s11263-012-0596-6; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vo NN, 2014, PROC CVPR IEEE, P2641, DOI 10.1109/CVPR.2014.338; Wang X., 2006, P 12 ACM SIGKDD INT, P424; Wang XY, 2014, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2014.328; Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406; Wu C, 2014, P ROB SCI SYST; Wu CX, 2016, IEEE INT CONF ROBOT, P2479, DOI 10.1109/ICRA.2016.7487401; Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98; Yang S, 2015, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2015.7298769; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253; Yang YZ, 2015, AAAI CONF ARTIF INTE, P3686	66	12	12	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					467	481		10.1109/TPAMI.2017.2679054	http://dx.doi.org/10.1109/TPAMI.2017.2679054			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28287959	Green Submitted			2022-12-18	WOS:000422706000015
J	Xu, D; Duan, Q; Zheng, JM; Zhang, JY; Cai, JF; Cham, TJ				Xu, Di; Duan, Qi; Zheng, Jianmin; Zhang, Juyong; Cai, Jianfei; Cham, Tat-Jen			Shading-Based Surface Detail Recovery Under General Unknown Illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape from shading; 3D reconstruction; shape refinement; general unknown illumination; spatially varying albedo	HIGH-QUALITY SHAPE; PHOTOMETRIC STEREO; MULTIVIEW STEREO; RECONSTRUCTION; SILHOUETTE; IMAGES	Reconstructing the shape of a 3D object from multi-view images under unknown, general illumination is a fundamental problem in computer vision. High quality reconstruction is usually challenging especially when fine detail is needed and the albedo of the object is non-uniform. This paper introduces vertex overall illumination vectors to model the illumination effect and presents a total variation (TV) based approach for recovering surface details using shading and multi-view stereo (MVS). Behind the approach are the two important observations: (1) the illumination over the surface of an object often appears to be piecewise smooth and (2) the recovery of surface orientation is not sufficient for reconstructing the surface, which was often overlooked previously. Thus we propose to use TV to regularize the overall illumination vectors and use visual hull to constrain partial vertices. The reconstruction is formulated as a constrained TV-minimization problem that simultaneously treats the shape and illumination vectors as unknowns. An augmented Lagrangian method is proposed to quickly solve the TV-minimization problem. As a result, our approach is robust, stable and is able to efficiently recover high-quality surface details even when starting with a coarse model obtained using MVS. These advantages are demonstrated by extensive experiments on the state-of-the-art MVS database, which includes challenging objects with varying albedo.	[Xu, Di; Duan, Qi] Nanyang Technol Univ, 50 Nanyang Ave, Singapore 639798, Singapore; [Zheng, Jianmin; Cham, Tat-Jen] Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave, Singapore 639798, Singapore; [Cai, Jianfei] Nanyang Technol Univ, Sch Comp Engn, Visual & Interact Comp Div, 50 Nanyang Ave, Singapore 639798, Singapore; [Cai, Jianfei] Nanyang Technol Univ, Sch Comp Engn, Comp Commun Div, 50 Nanyang Ave, Singapore 639798, Singapore; [Zhang, Juyong] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chinese Academy of Sciences; University of Science & Technology of China, CAS	Xu, D (corresponding author), Nanyang Technol Univ, 50 Nanyang Ave, Singapore 639798, Singapore.	xudi@ntu.edu.sg; duan0013@ntu.edu.sg; asjmzheng@ntu.edu.sg; juyong@ustc.edu.cn; asjfcai@ntu.edu.sg; astjcham@ntu.edu.sg	Zheng, Jianmin/A-3717-2011; Cai, Jianfei/A-3691-2011	Zheng, Jianmin/0000-0002-5062-6226; Cham, Tat-Jen/0000-0001-5264-2572; Cai, Jianfei/0000-0002-9444-3763	Singapore MoE AcRF [RG138/14, RG26/15]; BeingTogether Centre; National Research Foundation, Prime Minister's Office, Singapore under its International Research Centres in Singapore Funding Initiative	Singapore MoE AcRF(Ministry of Education, Singapore); BeingTogether Centre; National Research Foundation, Prime Minister's Office, Singapore under its International Research Centres in Singapore Funding Initiative(National Research Foundation, Singapore)	This research is partially supported by Singapore MoE AcRF Tier-1 Grants RG138/14, RG26/15, and the BeingTogether Centre, a collaboration between Nanyang Technological University (NTU) Singapore and University of North Carolina (UNC) at Chapel Hill. The BeingTogether Centre is supported by the National Research Foundation, Prime Minister's Office, Singapore under its International Research Centres in Singapore Funding Initiative. We would also like to thank Dr. Chenglei Wu for providing some data of [11]. This work was presented in part in IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2014 [1]. Qi Duan and Jianfei Cai are with the corresponding authors.	Alldrin N, 2008, PROC CVPR IEEE, P2447; [Anonymous], 2006, MIDDLEBURY MULTIVIEW; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777; Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970; Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58; Choe GM, 2014, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2014.501; Debevec P., 2008, P ACM SIGGRAPH; Di Xu, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P476, DOI 10.1007/978-3-642-34778-8_44; DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Y, 2009, INT J COMPUT VISION, V81, P53, DOI 10.1007/s11263-008-0134-8; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102; Habbecke M, 2007, PROC CVPR IEEE, P1720; Han Y, 2013, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2013.204; Haque SM, 2014, PROC CVPR IEEE, P2283, DOI 10.1109/CVPR.2014.292; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Ihrke I, 2010, COMPUT GRAPH FORUM, V29, P2400, DOI 10.1111/j.1467-8659.2010.01753.x; Jancosek M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3121, DOI 10.1109/CVPR.2011.5995693; Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59; Jin HL, 2008, INT J COMPUT VISION, V76, P245, DOI 10.1007/s11263-007-0055-y; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Joshi N, 2007, IEEE I CONF COMP VIS, P1501; Kajiya J.T., 1986, SIGGRAPH, P143, DOI [DOI 10.1145/15922.15902, 10.1145/15886.15902, DOI 10.1145/15886.15902]; Kolev K, 2008, LECT NOTES COMPUT SC, V5302, P752, DOI 10.1007/978-3-540-88682-2_57; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Merrell P, 2007, IEEE I CONF COMP VIS, P1221; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Park J, 2013, IEEE I CONF COMP VIS, P1161, DOI 10.1109/ICCV.2013.148; Paul D., 1998, P SIGGRAPH 98, P189, DOI [10.1145/280814.280864, DOI 10.1145/280814.280864]; Richter SR, 2015, PROC CVPR IEEE, P1128, DOI 10.1109/CVPR.2015.7298716; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; Sinha S, 2007, ASIA S PACIF DES AUT, P1; Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612; Song P, 2010, VISUAL COMPUT, V26, P1435, DOI 10.1007/s00371-010-0429-y; Sorkine O., 2005, EUROGRAPHICS STARS, V29; Sun J, 2007, IMAGE VISION COMPUT, V25, P1050, DOI 10.1016/j.imavis.2006.04.025; TYLECEK R, 2010, INT J VIRTUAL REALIT, V9, P45, DOI DOI 10.20870/IJVR.2010.9.1.2761; Valgaerts L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366206; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Woodham R. J., 1989, SHAPE SHADING, P513; Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232; Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388; Wu CL, 2011, IEEE T VIS COMPUT GR, V17, P1082, DOI [10.1109/TVCG.2010.224, 10.1109/TPDS.2010.224]; Wu CL, 2012, J SCI COMPUT, V50, P145, DOI 10.1007/s10915-011-9477-3; Wu CL, 2009, SIAM J IMAGING SCI, V2, P670, DOI 10.1137/080722758; Xiong SY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661263; Xu D, 2014, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2014.198; Yoon KJ, 2010, INT J COMPUT VISION, V86, P192, DOI 10.1007/s11263-009-0222-4; Yoshiyasu Y, 2011, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2011.5995576; Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	59	12	12	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					423	436		10.1109/TPAMI.2017.2671458	http://dx.doi.org/10.1109/TPAMI.2017.2671458			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28221993				2022-12-18	WOS:000422706000012
J	Simon, T; Valmadre, J; Matthews, I; Sheikh, Y				Simon, Tomas; Valmadre, Jack; Matthews, Iain; Sheikh, Yaser			Kronecker-Markov Prior for Dynamic 3D Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Matrix normal distribution; Kronecker; trace-norm; spatiotemporal; missing data; generalized trace-norm	STRUCTURE-FROM-MOTION; PROCRUSTEAN NORMAL-DISTRIBUTION; NONRIGID MOTION; SHAPE; MODELS; FACTORIZATION; RECOVERY	Recovering dynamic 3D structures from 2D image observations is highly under-constrained because of projection andmissing data, motivating the use of strong priors to constrain shape deformation. In this paper, we empirically show that the spatiotemporal covariance of natural deformations is dominated by a Kronecker pattern. We demonstrate that this pattern arises as the limit of a spatiotemporal autoregressive process, and derive a Kronecker Markov Random Field as a prior distribution over dynamic structures. This distribution unifies shape and trajectory models of prior art and has the individual models as its marginals. The key assumption of the Kronecker MRF is that the spatiotemporal covariance is separable into the product of a temporal and a shape covariance, and can therefore bemodeled using thematrix normal distribution. Analysis on motion capture data validates that this distribution is an accurate approximation with significantly fewer free parameters. Using the trace-norm, we present a convex method to estimate missing data from a single sequence when the marginal shape distribution is unknown. The Kronecker-Markov distribution, fit to a single sequence, outperforms state-of-the-art methods at inferring missing 3D data, and additionally provides covariance estimates of the uncertainty.	[Simon, Tomas; Matthews, Iain; Sheikh, Yaser] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Valmadre, Jack] Univ Oxford, Oxford OX1 3PA, England	Carnegie Mellon University; University of Oxford	Simon, T (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	tsimon@cs.cmu.edu; jack.valmadre@gmail.com; iainm@cs.cmu.edu; yaser@cs.cmu.edu		Valmadre, Jack/0000-0003-1004-2784	ONR grant [N00014-15-1-2358]	ONR grant	This research was supported in part using an ONR grant N00014-15-1-2358.	Agarwal S., CERES SOLVER; Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202; AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; Akhter I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159523; Akhter Ijaz, 2008, ADV NEURAL INFORM PR, P41; Allen GI, 2010, ANN APPL STAT, V4, P764, DOI 10.1214/09-AOAS314; Angst R, 2012, LECT NOTES COMPUT SC, V7577, P682, DOI 10.1007/978-3-642-33783-3_49; Angst R, 2011, IEEE I CONF COMP VIS, P2502, DOI 10.1109/ICCV.2011.6126536; [Anonymous], [No title captured]; BARTOLI A, 2008, IEEE CVPR, V1, P1; BLANZ V, 1999, P 26 ANN C COMP GRAP, P187, DOI DOI 10.1145/311535.311556; Boyd S., 2011, FDN TRENDS MACHINE L, V3, P1, DOI DOI 10.1561/2200000016; Brand M, 2005, PROC CVPR IEEE, P122; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Bue A., 2005, ANAL MODELLING FACE; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Cho J, 2016, INT J COMPUT VISION, V117, P226, DOI 10.1007/s11263-015-0860-7; Dai Y., 2002, P IEEE C COMP VIS PA, P2018; De la Torre F., 2015, P 11 IEEE INT C WORK, P1; Dutilleul P, 1999, J STAT COMPUT SIM, V64, P105, DOI 10.1080/00949659908811970; Fayad J., 2009, P BRIT MACH VIS C, p110 1; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; Joo H, 2014, PROC CVPR IEEE, P1122, DOI 10.1109/CVPR.2014.147; Laub A. J., 2004, MATRIX ANAL SCIENTIS; Lee M, 2014, PROC CVPR IEEE, P1550, DOI 10.1109/CVPR.2014.201; Lee M, 2013, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR.2013.169; Mazumder R, 2010, J MACH LEARN RES, V11, P2287; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Olsen SI, 2008, J MATH IMAGING VIS, V31, P233, DOI 10.1007/s10851-007-0060-3; Park HS, 2010, LECT NOTES COMPUT SC, V6313, P158; Park S, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION 2007, VOL 5, P1, DOI 10.1145/13606121360695; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Rao C. R, 1973, LINEAR STAT INFERENC; Rue H, 2005, MG STAT PRO, V104; Salzmann M, 2011, IEEE I CONF COMP VIS, P2064, DOI 10.1109/ICCV.2011.6126480; Sidenbladh H., 2000, LNCS, V2, P702; Simon T, 2014, LECT NOTES COMPUT SC, V8691, P204, DOI 10.1007/978-3-319-10578-9_14; Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745; TAYLOR J, 2010, PROC CVPR IEEE, P2761, DOI DOI 10.1109/CVPR.2010.5540002; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Valmadre J, 2012, PROC CVPR IEEE, P1394, DOI 10.1109/CVPR.2012.6247826; Vidal R, 2006, LECT NOTES COMPUT SC, V3952, P205; Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573; Yan JY, 2005, PROC CVPR IEEE, P815	48	12	12	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2201	2214		10.1109/TPAMI.2016.2638904	http://dx.doi.org/10.1109/TPAMI.2016.2638904			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	27992328				2022-12-18	WOS:000412028600007
J	Hu, NH; Englebienne, G; Lou, ZY; Krsoe, B				Hu, Ninghang; Englebienne, Gwenn; Lou, Zhongyu; Krsoe, Ben			Learning to Recognize Human Activities Using Soft Labels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RGB-D perception; human activity recognition; max-margin learning		Human activity recognition system is of great importance in robot-care scenarios. Typically, training such a system requires activity labels to be both completely and accurately annotated. In this paper, we go beyond such restriction and propose a learning method that allow labels to be incomplete and uncertain. We introduce the idea of soft labels which allows annotators to assign multiple, and weighted labels to data segments. This is very useful in many situations, e.g., when the labels are uncertain, when part of the labels are missing, or when multiple annotators assign inconsistent labels. We formulate the activity recognition task as a sequential labeling problem. Latent variables are embedded in the model in order to exploit sub-level semantics for better estimation. We propose a max-margin framework which incorporate soft labels for learning the model parameters. The model is evaluated on two challenging datasets. To simulate the uncertainty in data annotation, we randomly change the labels for transition segments. The results show significant improvement over the state-of-the-art approach.	[Hu, Ninghang; Englebienne, Gwenn; Lou, Zhongyu; Krsoe, Ben] Univ Amsterdam, NL-1012 WX Amsterdam, Netherlands	University of Amsterdam	Hu, NH (corresponding author), Univ Amsterdam, NL-1012 WX Amsterdam, Netherlands.	huninghang@gmail.com; G.Englebienne@uva.nl; zyulou@gmail.com; b.j.a.krose@uva.nl			European project ACCOMPANY [287624]; European project MONARCH [601033]	European project ACCOMPANY; European project MONARCH	The research is funded by the European project ACCOMPANY (grant agreement No. 287624) and the European project MONARCH (grant agreement No. 601033).	Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ganchev K, 2010, J MACH LEARN RES, V11, P2001; Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7; Hu NH, 2014, IEEE INT CONF ROBOT, P1048, DOI 10.1109/ICRA.2014.6906983; Hu NH, 2014, IEEE ROMAN, P243, DOI 10.1109/ROMAN.2014.6926260; Jiang Y., 2013, MATH PROBL ENG, V2013, P1, DOI DOI 10.1109/ITEC.2013.6573487; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Koppula H., 2013, INT C MACHINE LEARNI, P792, DOI DOI 10.1177/0278364913478446; Koppula HS, 2013, IEEE INT C INT ROBOT, P2071, DOI 10.1109/IROS.2013.6696634; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Lou X, 2012, P 29 INT C MACH LEAR, P1519; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Mooij JM, 2010, J MACH LEARN RES, V11, P2169; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Tsochantaridis I., 2004, P 21 INT C MACH LEAR; Vahdat A, 2013, IEEE I CONF COMP VIS, P737, DOI 10.1109/ICCV.2013.462; Vail D. L., 2007, P 6 INT JOINT C AUT, P1, DOI DOI 10.1145/1329125.1329409; van Kasteren T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P1, DOI 10.1145/1409635.1409637; Wang S. B., 2006, PROC IEEE COMPUT SOC, P1521, DOI DOI 10.1109/CVPR.2006.132; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709; Wyatt D., 2005, P 20 NAT C ART INT, P21, DOI DOI 10.1038/JP.2012.20; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Yuille AL, 2002, ADV NEUR IN, V14, P1033	25	12	12	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					1973	1984		10.1109/TPAMI.2016.2621761	http://dx.doi.org/10.1109/TPAMI.2016.2621761			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	28113744				2022-12-18	WOS:000408807600006
J	Peng, B; Zhang, L; Mou, XQ; Yang, MH				Peng, Bo; Zhang, Lei; Mou, Xuanqin; Yang, Ming-Hsuan			Evaluation of Segmentation Quality via Adaptive Composition of Reference Segmentations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation evaluation; segmentation quality; image segmentation dataset	IMAGE SEGMENTATION; QUANTITATIVE-EVALUATION	Evaluating image segmentation quality is a critical step for generating desirable segmented output and comparing performance of algorithms, among others. However, automatic evaluation of segmented results is inherently challenging since image segmentation is an ill-posed problem. This paper presents a framework to evaluate segmentation quality using multiple labeled segmentations which are considered as references. For a segmentation to be evaluated, we adaptively compose a reference segmentation using multiple labeled segmentations, which locally matches the input segments while preserving structural consistency. The quality of a given segmentation is then measured by its distance to the composed reference. A new dataset of 200 images, where each one has 6 to 15 labeled segmentations, is developed for performance evaluation of image segmentation. Furthermore, to quantitatively compare the proposed segmentation evaluation algorithm with the state-of-the-art methods, a benchmark segmentation evaluation dataset is proposed. Extensive experiments are carried out to validate the proposed segmentation evaluation framework.	[Peng, Bo] Southwest Jiaotong Univ, Dept Software Engn, Chengdu 611756, Sichuan, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China; [Mou, Xuanqin] Xi An Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Xian 710049, Shaanxi, Peoples R China; [Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA 95344 USA	Southwest Jiaotong University; Hong Kong Polytechnic University; Xi'an Jiaotong University; University of California System; University of California Merced	Peng, B (corresponding author), Southwest Jiaotong Univ, Dept Software Engn, Chengdu 611756, Sichuan, Peoples R China.	bpeng@swjtu.edu.cn; cslzhang@comp.polyu.edu.hk; xqmou@mail.xjtu.edu.cn; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Mou, Xuanqin/0000-0003-1381-5260	HK RGC GRF [PolyU 5315/12E]; NSFC [61202190, 61571359]; National Key Basic Research Program [2016YFA0202003]; US National Science Foundation CAREER [1149783]	HK RGC GRF(Hong Kong Research Grants Council); NSFC(National Natural Science Foundation of China (NSFC)); National Key Basic Research Program(National Basic Research Program of China); US National Science Foundation CAREER(National Science Foundation (NSF))	This work was supported by the HK RGC GRF Grant (No. PolyU 5315/12E), the NSFC (Nos. 61202190, 61571359), the National Key Basic Research Program (2016YFA0202003) and US National Science Foundation CAREER Grant (No. 1149783).	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Alpert R. B. S., 2007, P IEEE C COMP VIS PA, V0, P1, DOI [DOI 10.1109/CVPR.2007.383017, 10.1109/CVPR.2007.383017]; [Anonymous], 2002, THESIS U CALIFORNIA; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Boiman O., 2006, ADV NEURAL INFORM PR, V19, P177; Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Christensen H., 2002, EMPIRICAL EVAL METHO; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Estrada FJ, 2005, PROC CVPR IEEE, P1132; Everingham M, 2002, LECT NOTES COMPUT SC, V2353, P34; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117; Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Goldluecke B, 2011, IEEE I CONF COMP VIS, P1267, DOI 10.1109/ICCV.2011.6126378; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Huang Q, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC53; Ion A, 2011, IEEE I CONF COMP VIS, P2110, DOI 10.1109/ICCV.2011.6126486; Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; Odet C, 2002, IEEE IMAGE PROC, P785; Peng B., 2008, P BRIT MACH VIS C, P153; Peng B, 2012, LECT NOTES COMPUT SC, V7574, P287, DOI 10.1007/978-3-642-33712-3_21; Pont-Tuset J, 2013, PROC CVPR IEEE, P2131, DOI 10.1109/CVPR.2013.277; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rao SS, 2009, PRODUCT RESEARCH: THE ART AND SCIENCE BEHIND SUCCESSFUL PRODUCT LAUNCHES, P135, DOI 10.1007/978-90-481-2860-0_7; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Russell Bryan, 2009, NIPS; Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923; Schoenemann T, 2012, INT J COMPUT VISION, V99, P53, DOI 10.1007/s11263-012-0518-7; Shin MC, 2001, COMPUT VIS IMAGE UND, V84, P160, DOI 10.1006/cviu.2001.0932; Stuhmer J, 2013, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2013.290; Unnikrishnan R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P394; Unnikrishnan R., 2005, P IEEE COMP SOC C CO, P34, DOI DOI 10.1109/CVPR.2005.390; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; van Dongen S., 2002, INSR0012; Vicente S., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587440; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang Z., 2006, MODERN IMAGE QUALITY; Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005; Zhang H, 2005, PROC SPIE, V5809, P420, DOI 10.1117/12.604213; Zhang H, 2004, P SOC PHOTO-OPT INS, V5307, P38	54	12	12	25	96	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					1929	1941		10.1109/TPAMI.2016.2622703	http://dx.doi.org/10.1109/TPAMI.2016.2622703			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27810800	hybrid			2022-12-18	WOS:000408807600003
J	Lee, M; Cho, J; Oh, S				Lee, Minsik; Cho, Jungchan; Oh, Songhwai			Procrustean Normal Distribution for Non-Rigid Structure from Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Procrustean normal distribution; non-rigid structure from motion; structure from motion; statistical shape model	SHAPE; RECOVERY; MODELS	A well-defined deformation model can be vital for non-rigid structure from motion (NRSfM). Most existing methods restrict the deformation space by assuming a fixed rank or smooth deformation, which are not exactly true in the real world, and they require the degree of deformation to be predetermined, which is impractical. Meanwhile, the errors in rotation estimation can have severe effects on the performance, i.e., these errors can make a rigid motion be misinterpreted as a deformation. In this paper, we propose an alternative to resolve these issues, motivated by an observation that non-rigid deformations, excluding rigid changes, can be concisely represented in a linear subspace without imposing any strong constraints, such as smoothness or low-rank. This observation is embedded in our new prior distribution, the Procrustean normal distribution (PND), which is a shape distribution exclusively for non-rigid deformations. Because of this unique characteristic of the PND, rigid and non-rigid changes can be strictly separated, which leads to better performance. The proposed algorithm, EM-PND, fits a PND to given 2D observations to solve NRSfM without any user-determined parameters. The experimental results show that EM-PND gives the state-of-the-art performance for the benchmark data sets, confirming the adequacy of the new deformation model.	[Lee, Minsik] Hanyang Univ, Div Elect Engn, Ansan 15588, Kyeonggi Do, South Korea; [Cho, Jungchan; Oh, Songhwai] Seoul Natl Univ, Dept Elect & Comp Engn, ASRI, Seoul 25354, South Korea	Hanyang University; Seoul National University (SNU)	Lee, M (corresponding author), Hanyang Univ, Div Elect Engn, Ansan 15588, Kyeonggi Do, South Korea.	mleepaper@hanyang.ac.kr	Lee, Minsik/S-7959-2017	Lee, Minsik/0000-0003-4941-4311	Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning [NRF-2014R1A1A1006269]	Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning	This work was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT & Future Planning, under Grant NRF-2014R1A1A1006269. Minsik Lee is the corresponding author.	Agudo A., 2014, BRIT MACH VIS C, P1; Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Akhter I, 2009, PROC CVPR IEEE, P1534, DOI 10.1109/CVPRW.2009.5206620; [Anonymous], 1980, TENSOR ANAL MANIFOLD; Bartoli A, 2013, INT J COMPUT VISION, V101, P227, DOI 10.1007/s11263-012-0565-0; C. M. U. G. Lab, 2002, CMU MOCAP DAT; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Cho J, 2016, INT J COMPUT VISION, V117, P226, DOI 10.1007/s11263-015-0860-7; Cho J, 2013, COMPUT VIS IMAGE UND, V117, P1549, DOI 10.1016/j.cviu.2013.07.009; Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905; Del Bue A, 2006, P IEEE C COMP VIS PA, V1, P1191; Fayad J, 2010, LECT NOTES COMPUT SC, V6314, P297, DOI 10.1007/978-3-642-15561-1_22; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; Gotardo P. F. U., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3065, DOI 10.1109/CVPR.2011.5995560; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Hartley R., 2004, ROBOTICA; KOSCHAT MA, 1991, PSYCHOMETRIKA, V56, P229, DOI 10.1007/BF02294460; Lee M, 2014, PROC CVPR IEEE, P1550, DOI 10.1109/CVPR.2014.201; Lee M, 2013, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR.2013.169; Llado X, 2010, IMAGE VISION COMPUT, V28, P1339, DOI 10.1016/j.imavis.2010.01.014; Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2; Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425; Mitteroecker P, 2009, EVOL BIOL, V36, P235, DOI 10.1007/s11692-009-9055-x; Nocedal J, 2006, SPRINGER SER OPER RE, P135; Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602; Paladini M, 2012, INT J COMPUT VISION, V96, P252, DOI 10.1007/s11263-011-0468-5; Phillips PJ, 2005, PROC CVPR IEEE, P947; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L., 2003, P NEUR INF PROC SYST, P1; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tron R., 2008, P IEEE C COMP VIS PA, P1; Valmadre J., 2012, P IEEE C COMP VIS PA, P16; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Xiao J.F., 2005, THESIS; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Zelditch M. L., 2004, GEOMETRIC MORPHOMETR, DOI DOI 10.1016/B978-0-12-778460-1.X5000-5	41	12	12	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1388	1400		10.1109/TPAMI.2016.2596720	http://dx.doi.org/10.1109/TPAMI.2016.2596720			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27529867				2022-12-18	WOS:000402744400009
J	Zhang, WZ; Zhang, LJ; Jin, ZM; Jin, R; Cai, D; Li, XL; Liang, RH; He, XF				Zhang, Weizhong; Zhang, Lijun; Jin, Zhongming; Jin, Rong; Cai, Deng; Li, Xuelong; Liang, Ronghua; He, Xiaofei			Sparse Learning with Stochastic Composite Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse learning; stochastic optimization; stochastic composite optimization	ONLINE; ALGORITHMS	In this paper, we study Stochastic Composite Optimization (SCO) for sparse learning that aims to learn a sparse solution from a composite function. Most of the recent SCO algorithms have already reached the optimal expected convergence rate O(1/lambda T), but they often fail to deliver sparse solutions at the end either due to the limited sparsity regularization during stochastic optimization (SO) or due to the limitation in online-to-batch conversion. Even when the objective function is strongly convex, their high probability bounds can only attain O(root log(1/delta)/T with delta is the failure probability, which is much worse than the expected convergence rate. To address these limitations, we propose a simple yet effective two-phase Stochastic Composite Optimization scheme by adding a novel powerful sparse online-to-batch conversion to the general Stochastic Optimization algorithms. We further develop three concrete algorithms, OptimalSL, LastSL and AverageSL, directly under our scheme to prove the effectiveness of the proposed scheme. Both the theoretical analysis and the experiment results show that our methods can really outperform the existing methods at the ability of sparse learning and at the meantime we can improve the high probability bound to approximately O(log (log (T)/delta)/lambda T).	[Zhang, Weizhong; Jin, Zhongming; Cai, Deng; He, Xiaofei] Zhejiang Univ, Coll Comp Sci, State Key Lab CAD&CG, 388 Yuhang Tang Rd, Hangzhou 310058, Zhejiang, Peoples R China; [Zhang, Lijun] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Jin, Rong] Alibaba Grp, Seattle, WA 98057 USA; [Li, Xuelong] Chinese Acad Sci, State Key Lab Transicent Opt & Photon, Xian Inst Opt & Precis Mech, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710119, Shaanxi, Peoples R China; [Liang, Ronghua] Zhejiang Univ Technol, Coll Informat Engn, 288 Liuhe Rd, Hangzhou 310058, Zhejiang, Peoples R China	Zhejiang University; Nanjing University; Alibaba Group; Chinese Academy of Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; Zhejiang University of Technology	Zhang, WZ (corresponding author), Zhejiang Univ, Coll Comp Sci, State Key Lab CAD&CG, 388 Yuhang Tang Rd, Hangzhou 310058, Zhejiang, Peoples R China.	zhangweizhongzju@gmail.com; zhanglj@lamda.nju.edu.cn; jinzhongming888@gmail.com; jinrong.jr@alibaba-inc.com; dengcai@cad.zju.edu.cn; xuelong_li@opt.ac.cn; rhliang@zjut.edu.cn; xiaofeihe@cad.zju.edu.cn	li, xiang/GWM-6319-2022; Li, Xuelong/ABF-3381-2020; Li, Xuelong/Z-3785-2019	Li, Xuelong/0000-0002-0019-4197	National Basic Research Program of China (973 Program) [2013CB336500]; National Natural Science Foundation of China [61233011]; National Youth Topnotch Talent Support Program	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Youth Topnotch Talent Support Program	This work was supported by the National Basic Research Program of China (973 Program) under Grant 2013CB336500, National Natural Science Foundation of China under Grant 61233011, and National Youth Topnotch Talent Support Program.	Agarwal A., 2012, P ADV NEUR INF PROC, P1538, DOI DOI 10.1109/CISS.2014.6814157; [Anonymous], 2011, JMLR WORKSHOP C P; Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498; Chen X., 2012, ADV NEURAL INFORM PR, P395; Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303; Dekel O., 2005, P ADV NEUR INF PROC, P267; Duchi J, 2009, J MACH LEARN RES, V10, P2899; Duchi JC, 2012, SIAM J OPTIMIZ, V22, P674, DOI 10.1137/110831659; Hu C., 2009, ADV NEURAL INF PROCE, P781; Langford J, 2009, J MACH LEARN RES, V10, P777; Lin Q., 2011, SPARSITY PRESE UNPUB, V15213; Littlestone N., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory, P269; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Nesterov Y., 2004, APPL OPTIM; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; Nesterov Yu., 2007, GRADIENT METHODS MIN; Nesterov Y, 2009, MATH PROGRAM, V120, P221, DOI 10.1007/s10107-007-0149-x; Oiwa H, 2011, LECT NOTES ARTIF INT, V6912, P533, DOI 10.1007/978-3-642-23783-6_34; RAKHLIN A., 2012, P INT C MACH LEARN, P1571; Smale S, 2009, CONSTR APPROX, V30, P311, DOI 10.1007/s00365-009-9070-2; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tropp JA, 2011, ELECTRON COMMUN PROB, V16, P262, DOI 10.1214/ECP.v16-1624; Xiao L, 2010, J MACH LEARN RES, V11, P2543; Zhang L., 2013, ADV NEURAL INFORM PR, P980; Zhang W., 2014, P 28 ASS ADV ART INT	29	12	13	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1223	1236		10.1109/TPAMI.2016.2578323	http://dx.doi.org/10.1109/TPAMI.2016.2578323			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27295652				2022-12-18	WOS:000401091200013
J	Valera, I; Ruiz, FJR; Perez-Cruz, F				Valera, Isabel; Ruiz, Francisco J. R.; Perez-Cruz, Fernando			Infinite Factorial Unbounded-State Hidden Markov Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series; Bayesian nonparametrics; hidden Markov models; Gibbs sampling; slice sampling; variational inference; reversible jump Markov chain Monte Carlo	INFERENCE	There are many scenarios in artificial intelligence, signal processing or medicine, in which a temporal sequence consists of several unknown overlapping independent causes, and we are interested in accurately recovering those canonical causes. Factorial hidden Markov models (FHMMs) present the versatility to provide a good fit to these scenarios. However, in some scenarios, the number of causes or the number of states of the FHMM cannot be known or limited a priori. In this paper, we propose an infinite factorial unbounded-state hidden Markov model (IFUHMM), in which the number of parallel hidden Markov models (HMMs) and states in each HMM are potentially unbounded. We rely on a Bayesian nonparametric (BNP) prior over integer-valued matrices, in which the columns represent the Markov chains, the rows the time indexes, and the integers the state for each chain and time instant. First, we extend the existent infinite factorial binary-state HMM to allow for any number of states. Then, we modify this model to allow for an unbounded number of states and derive an MCMC-based inference algorithm that properly deals with the trade-off between the unbounded number of states and chains. We illustrate the performance of our proposed models in the power disaggregation problem.	[Valera, Isabel] Max Planck Inst Software Syst, Kaiserslautern, Germany; [Valera, Isabel; Ruiz, Francisco J. R.; Perez-Cruz, Fernando] Univ Carlos III Madrid, Dept Signal Proc & Commun, Madrid, Spain; [Ruiz, Francisco J. R.] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Perez-Cruz, Fernando] Alcatel Lucent, Bell Labs, Murray Hill, NJ USA	Max Planck Society; Universidad Carlos III de Madrid; Columbia University; Alcatel-Lucent; AT&T	Valera, I (corresponding author), Max Planck Inst Software Syst, Kaiserslautern, Germany.; Valera, I (corresponding author), Univ Carlos III Madrid, Dept Signal Proc & Commun, Madrid, Spain.	ivalera@mpi-sws.org; f.ruiz@columbia.edu; Fernando.Perez-Cruz@Alcatel-Lucent.com		perez-cruz, fernando/0000-0001-8996-5076	Humboldt research fellowship for postdoctoral researchers program; Plan Regional-Programas I+D of Comunidad de Madrid [AGES-CM S2010/BMD-2422]; FPU fellowship from the Spanish Ministry of Education [AP2010-5333]; Ministerio de Economia of Spain (project COMPREHENSION) [TEC2012-38883-C02-01]; Ministerio de Economia of Spain (project ALCIT) [TEC2012-38800-C03-01]; Comunidad de Madrid (project CASI-CAM-CM) [S2013/ICE-2845]; Office of Naval Research [ONR N00014-11-1-0651]; European Union 7th Framework Programme through Marie Curie Initial Training Network 'Machine Learning for Personalized Medicine' (MLPM) [316861]	Humboldt research fellowship for postdoctoral researchers program; Plan Regional-Programas I+D of Comunidad de Madrid; FPU fellowship from the Spanish Ministry of Education(German Research Foundation (DFG)); Ministerio de Economia of Spain (project COMPREHENSION); Ministerio de Economia of Spain (project ALCIT); Comunidad de Madrid (project CASI-CAM-CM)(Comunidad de Madrid); Office of Naval Research(Office of Naval Research); European Union 7th Framework Programme through Marie Curie Initial Training Network 'Machine Learning for Personalized Medicine' (MLPM)	I. Valera is currently supported by the Humboldt research fellowship for postdoctoral researchers program and acknowledges the support of Plan Regional-Programas I+D of Comunidad de Madrid (AGES-CM S2010/BMD-2422). F.J.R. Ruiz is supported by an FPU fellowship from the Spanish Ministry of Education (AP2010-5333). This work is also partially supported by Ministerio de Economia of Spain (projects COMPREHENSION, id. TEC2012-38883-C02-01, and ALCIT, id. TEC2012-38800-C03-01), by Comunidad de Madrid (project CASI-CAM-CM, id. S2013/ICE-2845), by the Office of Naval Research (ONR N00014-11-1-0651), and by the European Union 7th Framework Programme through the Marie Curie Initial Training Network 'Machine Learning for Personalized Medicine' (MLPM2012, Grant No. 316861). Isabel Valera and Francisco J. R. Ruiz contributed equally in this paper.	[Anonymous], 2007, AISTATS; BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Darby S., 2006, ORTHOD FR, V86, P221, DOI [10.1051/orthodfr/2015025, DOI 10.1051/ORTHODFR/2015025]; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Ding N, 2010, INT CONF ACOUST SPEE, P2098, DOI 10.1109/ICASSP.2010.5495125; Fox EB, 2011, ANN APPL STAT, V5, P1020, DOI 10.1214/10-AOAS395; GILKS WR, 1992, J R STAT SOC C-APPL, V41, P337; Green P.J., 1995, ANN STAT, V82, P711, DOI DOI 10.1093/BI0MET/82.4.711; Griffiths TL, 2011, J MACH LEARN RES, V12, P1185; Heller K. A., 2009, P 12 INT C ART INT S, V12, P224; Jain S, 2004, J COMPUT GRAPH STAT, V13, P158, DOI 10.1198/1061860043001; Johnson MJ, 2013, J MACH LEARN RES, V14, P673; Jordan M. I., 2010, HIERARCHICAL MODELS; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Keralapura Mallika, 2011, IAENG International Journal of Computer Science, V38, P38; Kim H., 2011, P SIAM C DAT MIN MES, DOI [10.1137/1.9781611972818.64, 10.1137/1, DOI 10.1137/1]; Kupiec J., 1992, Computer Speech and Language, V6, P225, DOI 10.1016/0885-2308(92)90019-Z; Makonin S, 2013, 2013 IEEE ELECTRICAL POWER & ENERGY CONFERENCE (EPEC), DOI 10.1109/EPEC.2013.6802949; Nag R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P2071; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Neenan B., 2009, 1016844 EL POW RES I; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Robert CP, 2000, J R STAT SOC B, V62, P57, DOI 10.1111/1467-9868.00219; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Scott SL, 2002, J AM STAT ASSOC, V97, P337, DOI 10.1198/016214502753479464; Teh Y. W., 2010, BAYESIAN NONPARAMETR; Titsias M., 2007, NIPS, V19, P1513; Van Gael J., 2008, PROC 25 INT C MACHIN, V25, P1088; Van Gael J., 2009, ADV NEURAL INFORM PR, V21, P1697; Zico Kolter J, 2011, WORKSH DAT MIN APPL, V25, P59	34	12	13	3	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1816	1828		10.1109/TPAMI.2015.2498931	http://dx.doi.org/10.1109/TPAMI.2015.2498931			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26571511				2022-12-18	WOS:000381432700008
J	Swoboda, P; Shekhovtsov, A; Kappes, JH; Schnorr, C; Savchynskyy, B				Swoboda, Paul; Shekhovtsov, Alexander; Kappes, Joerg Hendrik; Schnoerr, Christoph; Savchynskyy, Bogdan			Partial Optimality by Pruning for MAP-Inference with General Graphical Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		MAP-inference; Markov random fields; energy minimization; persistency; partial optimality; local polytope	MINIMIZATION	We consider the energy minimization problem for undirected graphical models, also known as MAP-inference problem for Markov random fields which is NP-hard in general. We propose a novel polynomial time algorithm to obtain a part of its optimal non-relaxed integral solution. Our algorithm is initialized with variables taking integral values in the solution of a convex relaxation of the MAP-inference problem and iteratively prunes those, which do not satisfy our criterion for partial optimality. We show that our pruning strategy is in a certain sense theoretically optimal. Also empirically our method outperforms previous approaches in terms of the number of persistently labelled variables. The method is very general, as it is applicable to models with arbitrary factors of an arbitrary order and can employ any solver for the considered relaxed problem. Our method's runtime is determined by the runtime of the convex relaxation solver for the MAP-inference problem.	[Swoboda, Paul; Kappes, Joerg Hendrik; Schnoerr, Christoph] Heidelberg Univ, Image & Pattern Anal Grp IPA, Speyerer Str 6, D-69115 Heidelberg, Germany; [Shekhovtsov, Alexander] Graz Univ Technol, Inst Comp Graph & Vis ICG, Inffeldgasse 16, A-8010 Graz, Austria; [Schnoerr, Christoph; Savchynskyy, Bogdan] Heidelberg Univ, Heidelberg Collaboratory Image Proc HCI, Speyerer Str 6, D-69115 Heidelberg, Germany	Ruprecht Karls University Heidelberg; Graz University of Technology; Ruprecht Karls University Heidelberg	Swoboda, P (corresponding author), Heidelberg Univ, Image & Pattern Anal Grp IPA, Speyerer Str 6, D-69115 Heidelberg, Germany.	swoboda@math.uni-heidelberg.de; shekhovtsov@icg.tugraz.at; kappes@math.uni-heidelberg.de; schnoerr@math.uni-heidelberg.de; bogdan.savchynskyy@iwr.uni-heidelberg.de	Shekhovtsov, Alexander/A-7436-2013	Shekhovtsov, Alexander/0000-0003-0678-8954				[Anonymous], 2011, PROBABILISTIC INFERE; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; DESMET J, 1992, NATURE, V356, P539, DOI 10.1038/356539a0; Fix A, 2011, IEEE I CONF COMP VIS, P1020, DOI 10.1109/ICCV.2011.6126347; Globerson Amir, 2008, ADV NEURAL INFORM PR, P553; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Hazan T, 2010, IEEE T INFORM THEORY, V56, P6294, DOI 10.1109/TIT.2010.2079014; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; ILOG Inc., 2014, ILOG CPLEX HIGH PERF; Ishikawa H, 2011, IEEE T PATTERN ANAL, V33, P1234, DOI 10.1109/TPAMI.2010.91; Kahl F, 2012, DISCRETE APPL MATH, V160, P2419, DOI 10.1016/j.dam.2012.06.009; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Kappes JH, 2013, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2013.229; Kappes JH, 2012, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2012.6247863; Kausler BX, 2012, LECT NOTES COMPUT SC, V7574, P144, DOI 10.1007/978-3-642-33712-3_11; Kohli P., 2008, P 25 INT C MACH LEAR, P480, DOI DOI 10.1145/1390156.1390217; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Kovtun I, 2003, LECT NOTES COMPUT SC, V2781, P402; KOVTUN I, 2011, CONTROL SYST COMPUT, V2, P35; NEMHAUSER GL, 1975, MATH PROGRAM, V8, P232, DOI 10.1007/BF01580444; Rother C., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383203; Savchynskyy Bogdan, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1817, DOI 10.1109/CVPR.2011.5995652; Savchynskyy B., 2012, UAI P, P746; Savchynskyy B., 2013, P NIPS 2013, P1950; Schlesinger M. I., 1976, CYBERNET SYST, P113; Schmidt Stefan, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P89, DOI 10.1007/978-3-642-23094-3_7; Shekhovtsov A, 2014, PROC CVPR IEEE, P1162, DOI 10.1109/CVPR.2014.152; Sontag D., 2012, UAI, P795; Sontag D. A., 2010, THESIS; Strandmark P., GEN ROOF DUALITY; Swoboda P., 2013, P 4 INT C SCAL SPAC, P477, DOI DOI 10.1007/978-3-642-38267-3_40; Swoboda P, 2014, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2014.153; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Weiss Y., 2008, P UAI, P503; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Windheuser T, 2012, LECT NOTES COMPUT SC, V7577, P400, DOI 10.1007/978-3-642-33783-3_29; Yanover C, 2008, J COMPUT BIOL, V15, P899, DOI 10.1089/cmb.2007.0158	41	12	12	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1370	10.1109/TPAMI.2015.2484327	http://dx.doi.org/10.1109/TPAMI.2015.2484327			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26468978	Green Submitted			2022-12-18	WOS:000377897100008
J	Kooij, JFP; Englebienne, G; Gavrila, DM				Kooij, Julian F. P.; Englebienne, Gwenn; Gavrila, Dariu M.			Mixture of Switching Linear Dynamics to Discover Behavior Patterns in Object Tracks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human behavior analysis; hierarchical non-parametric graphical model; switching linear dynamical systems		We present a novel non-parametric Bayesian model to jointly discover the dynamics of low-level actions and high-level behaviors of tracked objects. In our approach, actions capture both linear, low-level object dynamics, and an additional spatial distribution on where the dynamic occurs. Furthermore, behavior classes capture high-level temporal motion dependencies in Markov chains of actions, thus each learned behavior is a switching linear dynamical system. The number of actions and behaviors is discovered from the data itself using Dirichlet Processes. We are especially interested in cases where tracks can exhibit large kinematic and spatial variations, e.g. person tracks in open environments, as found in the visual surveillance and intelligent vehicle domains. The model handles real-valued features directly, so no information is lost by quantizing measurements into 'visual words', and variations in standing, walking and running can be discovered without discrete thresholds. We describe inference using Markov Chain Monte Carlo sampling and validate our approach on several artificial and real-world pedestrian track datasets from the surveillance and intelligent vehicle domain. We show that our model can distinguish between relevant behavior patterns that an existing state-of-the-art hierarchical model for clustering and simpler model variants cannot. The software and the artificial and surveillance datasets are made publicly available for benchmarking purposes.	[Kooij, Julian F. P.; Englebienne, Gwenn; Gavrila, Dariu M.] Univ Amsterdam, Intelligent Syst Lab, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands; [Gavrila, Dariu M.] Daimler R&D, Environm Percept Dept, Ulm, Germany	University of Amsterdam; Daimler AG	Kooij, JFP; Englebienne, G; Gavrila, DM (corresponding author), Univ Amsterdam, Intelligent Syst Lab, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.; Gavrila, DM (corresponding author), Daimler R&D, Environm Percept Dept, Ulm, Germany.	julian.kooij@gmail.com; G.Englebienne@uva.nl; dariu@gavrila.net		Kooij, Julian/0000-0001-9919-0710				Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0; Beal MJ, 2002, ADV NEUR IN, V14, P577; Bishop CM, 2006, PATTERN RECOGNITION, V1; Blackman S. S., 1999, DESIGN ANAL MODERN T; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boyen X., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P33; Chang J., 2013, ADV NEURAL INFORM PR, P620; Chen Z, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P316, DOI 10.1109/ITSC.2008.4732644; Dahl D. B., 2005, SEQUENTIALLY ALLOCA; Emonet R., 2011, P 8 IEEE INT C ADV V, P6; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Fernyhough J. H., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P475; Fox E., 2009, THESIS MIT CAMBRIDGE; Fu ZY, 2005, IEEE IMAGE PROC, P2029; Geronimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122; Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342; Hughes M. C., 2012, NIPS, P1304; Joseph J, 2011, AUTON ROBOT, V31, P383, DOI 10.1007/s10514-011-9248-x; Keller CG, 2014, IEEE T INTELL TRANSP, V15, P494, DOI 10.1109/TITS.2013.2280766; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P285, DOI 10.1145/347090.347153; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kooij JFP, 2014, IEEE INT VEH SYM, P1445, DOI 10.1109/IVS.2014.6856505; Kooij JFP, 2012, LECT NOTES COMPUT SC, V7577, P270, DOI 10.1007/978-3-642-33783-3_20; Kooij JFP, 2014, LECT NOTES COMPUT SC, V8694, P618, DOI 10.1007/978-3-319-10599-4_40; Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; Liem Martijn, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P173, DOI 10.1007/978-3-642-23123-0_18; Liem M., 2009, BRIT MACH VIS C, P199; Lin DH, 2009, PROC CVPR IEEE, P747, DOI 10.1109/CVPRW.2009.5206660; Makris D, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P183, DOI 10.1109/AVSS.2003.1217920; Minka T.P., 2001, P 17 C UNC ART INT, P362; Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z; PAVLOVIC V., 2000, ADV NEURAL INFORM PR, V13, P981; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; RAUCH HE, 1965, AIAA J, V3, P1445, DOI 10.2514/3.3166; Romero-Cano V, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P104, DOI 10.1109/IVWorkshops.2013.6615234; Rosti AVI, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P809; Schneider N, 2013, LECT NOTES COMPUT SC, V8142, P174, DOI 10.1007/978-3-642-40602-7_18; Scovanner P, 2009, IEEE I CONF COMP VIS, P381, DOI 10.1109/ICCV.2009.5459224; Tao Junli, 2012, Journal of Information and Communication Convergence Engineering, V10, P307, DOI 10.6109/jicce.2012.10.3.307; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Varadarajan J., 2010, P BRIT MACH VIS C; Wang X., 2008, IEEE INT C COMP VIS; Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9; Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013	46	12	12	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					322	334		10.1109/TPAMI.2015.2443801	http://dx.doi.org/10.1109/TPAMI.2015.2443801			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761737				2022-12-18	WOS:000369989600010
J	Archambeau, C; Lakshminarayanan, B; Bouchard, G				Archambeau, Cedric; Lakshminarayanan, Balaji; Bouchard, Guillaume			Latent IBP Compound Dirichlet Allocation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; power-law distribution; sparse modelling; topic modelling; clustering; bag-of-words representation; Gibbs sampling		We introduce the four-parameter IBP compound Dirichlet process (ICDP), a stochastic process that generates sparse non-negative vectors with potentially an unbounded number of entries. If we repeatedly sample from the ICDP we can generate sparse matrices with an infinite number of columns and power-law characteristics. We apply the four-parameter ICDP to sparse nonparametric topic modelling to account for the very large number of topics present in large text corpora and the power-law distribution of the vocabulary of natural languages. The model, which we call latent IBP compound Dirichlet allocation (LIDA), allows for power-law distributions, both, in the number of topics summarising the documents and in the number of words defining each topic. It can be interpreted as a sparse variant of the hierarchical Pitman-Yor process when applied to topic modelling. We derive an efficient and simple collapsed Gibbs sampler closely related to the collapsed Gibbs sampler of latent Dirichlet allocation (LDA), making the model applicable in a wide range of domains. Our nonparametric Bayesian topic model compares favourably to the widely used hierarchical Dirichlet process and its heavy tailed version, the hierarchical Pitman-Yor process, on benchmark corpora. Experiments demonstrate that accounting for the power-distribution of real data is beneficial and that sparsity provides more interpretable results.	[Archambeau, Cedric] Amazon Berlin, Berlin, Germany; [Bouchard, Guillaume] Xerox Res Ctr Europe, Meylan, France; [Lakshminarayanan, Balaji] UCL, CSML, Gatsby Computat Neurosci Unit, London, England	Xerox; University of London; University College London	Archambeau, C (corresponding author), Amazon Berlin, Berlin, Germany.	cedric.p.archambeau@gmail.com; balaji@gatsby.ucl.ac.uk; guillaume.bouchard@xrce.xerox.com	Lakshminarayanan, Balaji/J-1566-2016	Lakshminarayanan, Balaji/0000-0002-5888-7252				Aldous D. J., 2010, ARXIV09094339V2; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Broderick T, 2012, BAYESIAN ANAL, V7, P439, DOI 10.1214/12-BA715; Buntine W, 2002, LECT NOTES ARTIF INT, V2430, P23; Chang J., 2009, ADV NEURAL INFORM PR, P22; Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Friedman N, 1999, ADV NEUR IN, V11, P417; Ghahramani Z., 2007, BAYESIAN STAT, V8; Griffiths T, 2002, P ADV NEUR INF PROC, P11; Griffiths T.L., 2005, ADV NEURAL INFORM PR; Griffiths TL, 2011, J MACH LEARN RES, V12, P1185; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Kim Y, 2001, ANN STAT, V29, P666; KINGMAN JFC, 1967, PAC J MATH, V21, P59, DOI 10.2140/pjm.1967.21.59; KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394; Liu B, 2010, BIOINFORMATICS, V26, P3105, DOI 10.1093/bioinformatics/btq576; Lukins SK, 2008, WORK CONF REVERSE EN, P155, DOI 10.1109/WCRE.2008.33; McCallum A, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P786; Pitman J, 1997, ANN PROBAB, V25, P855; Robert C, 2004, MONTE CARLO STAT MET, DOI DOI 10.1007/978-1-4757-4145-2; Sato I., 2010, P 16 ACM SIGKDD INT, DOI DOI 10.1145/1835804.1835890; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Teh Y. W., 2009, P ADV NEUR INF PROC, V22, P1838; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; Thibaux Romain, 2007, INT C ART INT STAT, P564; Titov Ivan, 2008, P ANN M ASS COMP LIN, P308; Wang C., 2011, P 14 INT C ART INT S, V15, P752, DOI DOI 10.1007/978-3-642-25832-9; Wang C., 2008, P INT C UNC ART INT; Wang C., 2009, P INT C COMP VIS PAT; Wang C., 2010, P ADV NEUR INF PROC, P1982; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Williamson S., 2010, ICML; Wood F, 2011, COMMUN ACM, V54, P91, DOI 10.1145/1897816.1897842; Zipf George Kingsley, 1935, PSYCHOBIOLOGY LANGUA	40	12	12	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					321	333		10.1109/TPAMI.2014.2313122	http://dx.doi.org/10.1109/TPAMI.2014.2313122			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353244	Green Submitted			2022-12-18	WOS:000349625500009
J	Chen, CY; Buntine, W; Ding, N; Xie, LX; Du, L				Chen, Changyou; Buntine, Wray; Ding, Nan; Xie, Lexing; Du, Lan			Differential Topic Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Differential topic model; transformed Pitman-Yor process; MCMC; data augmentation		In applications we may want to compare different document collections: they could have shared content but also different and unique aspects in particular collections. This task has been called comparative text mining or cross-collection modeling. We present a differential topic model for this application that models both topic differences and similarities. For this we use hierarchical Bayesian nonparametric models. Moreover, we found it was important to properly model power-law phenomena in topic-word distributions and thus we used the full Pitman-Yor process rather than just a Dirichlet process. Furthermore, we propose the transformed Pitman-Yor process (TPYP) to incorporate prior knowledge such as vocabulary variations in different collections into the model. To deal with the non-conjugate issue between model prior and likelihood in the TPYP, we thus propose an efficient sampling algorithm using a data augmentation technique based on the multinomial theorem. Experimental results show the model discovers interesting aspects of different collections. We also show the proposed MCMC based algorithm achieves a dramatically reduced test perplexity compared to some existing topic models. Finally, we show our model outperforms the state-of-the-art for document classification/ideology prediction on a number of text collections.	[Chen, Changyou; Buntine, Wray; Xie, Lexing] Australian Natl Univ, Canberra, ACT 0200, Australia; [Chen, Changyou; Buntine, Wray; Xie, Lexing] Natl ICT, Sydney, NSW, Australia; [Ding, Nan] Google Inc, Los Angeles, CA USA; [Du, Lan] Macquarie Univ, Dept Comp, Sydney, NSW 2109, Australia	Australian National University; Google Incorporated; Macquarie University	Chen, CY (corresponding author), Australian Natl Univ, Canberra, ACT 0200, Australia.	Changyou.Chen@NICTA.com.au; Wray.Buntine@NICTA.com.au; dingnan@google.com; Lexing.Xie@NICTA.com.au; dulan520@gmail.com	Du, Lan/AAY-1249-2021	Buntine, Wray/0000-0001-9292-1015; Du, Lan/0000-0002-9925-0223; Xie, Lexing/0000-0001-8319-0118	Australian Government; Australian Research Council through the ICT Center of Excellence program; Australian Research Council [DP110102506, DP110102593]	Australian Government(Australian GovernmentCGIAR); Australian Research Council through the ICT Center of Excellence program(Australian Research Council); Australian Research Council(Australian Research Council)	NICTA was funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Center of Excellence program. Lan Du was supported under Australian Research Council's Discovery Projects funding Scheme (DP110102506 and DP110102593).	Ahmed A., 2010, P 2010 C EMPIRICAL M, P1140; Aldous D., 1983, LECT NOTES MATH, V1117, P1, DOI [10.1007/BFb0099420, DOI 10.1007/BFB0099421.1072]; Andrzejewski David, 2009, Proc Int Conf Mach Learn, V382, P25; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chang C.-C., 2013, LIBSVM LIB SUPPORT V; Chen CY, 2011, LECT NOTES ARTIF INT, V6911, P296, DOI 10.1007/978-3-642-23780-5_29; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Du Lan, 2009, Adv Neural Inf Process Syst, V2009, P486; Du L, 2012, KNOWL INF SYST, V31, P475, DOI 10.1007/s10115-011-0425-1; Du L, 2010, MACH LEARN, V81, P5, DOI 10.1007/s10994-010-5197-4; Du Lan, 2012, P 2012 JOINT C EMP M, P535; Eisenstein Jacob, 2011, P 28 INT C MACH LEAR, P1041; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Frigyik B. A., 2010, P ADV NEUR INF PROC, V23, P613; Goldwater S, 2011, J MACH LEARN RES, V12, P2335; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Hut- ter Marcus, 2012, ARXIV10070296; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Li W., 2006, P 23 INT C MACH LEAR, P577, DOI DOI 10.1145/1143844.1143917; Lin Wei-Hao, 2006, P 10 C COMP NAT LANG, P109; Mimno D., 2008, P NIPS WORKSH AN GRA, V61, P1; Minka TP, 2000, ESTIMATING DIRICHLET; Newman D., 2011, ADV NEURAL INFORM PR, V24, P496, DOI DOI 10.5555/2986459.2986515; Orbanz P, 2008, INT J COMPUT VISION, V77, P25, DOI 10.1007/s11263-007-0061-0; Paisley J, 2012, BAYESIAN ANAL, V7, P997, DOI 10.1214/12-BA734; Paul M., 2009, P C EMP METH NAT LAN, V3, P1408; Paul M., 2012, P ADV NEUR INF PROC, P2591; Paul M., 2009, THESIS U ILLINOIS UR; Paul M, 2010, AAAI CONF ARTIF INTE, P545; Paul Michael, 2010, P 2010 C EMP METH NA, P66; Petterson J., 2010, ADV NEURAL INFORM PR, P1921; Robert C, 2004, MONTE CARLO STAT MET, DOI DOI 10.1007/978-1-4757-4145-2; Rosen-Zvi Michal, 2012, ARXIV12074169; Sato I., 2010, P 16 ACM SIGKDD INT; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sudderth E., 2005, ADV NEURAL INFORM PR, P1299; Teh Y. W., 2006, TRA206 NAT U SING; Teh Y. W., 2010, HIERARCHICAL BAYESIA; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; Wan, 2012, P 15 INT C ART INT S, V12, P1287; Wang C., 2009, ADV NEURAL INFORM PR, V22, P1982; Wang C., 2009, P 12 INT C ART INT S, P583; Wood F., 2009, P 26 ANN INT C MACH, P1129, DOI DOI 10.1145/1553374.1553518; XU Z., 2006, P 22 C ANN C UNC ART, P544; Yano T., 2009, PREDICTING RESPONSE, P477, DOI [DOI 10.3115/1620754.1620824, 10.3115/1620754.1620824]; Zhai ChengXiang, 2004, P 10 ACM SIGKDD KDD, P743, DOI DOI 10.1145/1014052.1014150	51	12	13	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					230	242		10.1109/TPAMI.2014.2313127	http://dx.doi.org/10.1109/TPAMI.2014.2313127			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353238	Green Submitted, Green Accepted			2022-12-18	WOS:000349625500003
J	Anvar, SMH; Yau, WY; Teoh, EK				Anvar, Seyed Mohammad Hassan; Yau, Wei-Yun; Teoh, Eam Khwang			Multiview Face Detection and Registration Requiring Minimal Manual Intervention	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiview; image registration; face constellation; simultaneous face detection and localization	IMAGE REGISTRATION; RECOGNITION; SCALE	Most face recognition systems require faces to be detected and localized a priori. In this paper, an approach to simultaneously detect and localize multiple faces having arbitrary views and different scales is proposed. The main contribution of this paper is the introduction of a face constellation, which enables multiview face detection and localization. In contrast to other multiview approaches that require many manually labeled images for training, the proposed face constellation requires only a single reference image of a face containing two manually indicated reference points for initialization. Subsequent training face images from arbitrary views are automatically added to the constellation (registered to the reference image) based on finding the correspondences between distinctive local features. Thus, the key advantage of the proposed scheme is the minimal manual intervention required to train the face constellation. We also propose an approach to identify distinctive correspondence points between pairs of face images in the presence of a large amount of false matches. To detect and localize multiple faces with arbitrary views, we then propose a probabilistic classifier-based formulation to evaluate whether a local feature cluster corresponds to a face. Experimental results conducted on the FERET, CMU, and FDDB datasets show that our proposed approach has better performance compared to the state-of-the-art approaches for detecting faces with arbitrary pose.	[Anvar, Seyed Mohammad Hassan] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Yau, Wei-Yun] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore; [Teoh, Eam Khwang] Nanyang Technol Univ, Sch Elect & Elect Engn, Div Control & Instrumentat, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Anvar, SMH (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	seye0005@e.ntu.edu.sg; wyyau@i2r.a-star.edu.sg; eekteoh@ntu.edu.sg		Yau, Wei-Yun/0000-0001-5709-9169	A*STAR; Institute for Infocomm Research, Singapore	A*STAR(Agency for Science Technology & Research (A*STAR)); Institute for Infocomm Research, Singapore	This research was supported by A*STAR and the Institute for Infocomm Research, Singapore. The authors would also like to thank Karthik Nandakumar, Jessica Ng, Mark David Rice, and Chuohao Yeo for their assistance in improving the paper.	Ashraf A.B., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587754; Batur AU, 2005, IEEE T IMAGE PROCESS, V14, P1707, DOI 10.1109/TIP.2005.854473; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Chen JC, 2009, IMAGE VISION COMPUT, V27, P1252, DOI 10.1016/j.imavis.2008.11.004; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32; Dedeoglu G, 2007, IEEE T PATTERN ANAL, V29, P807, DOI 10.1109/TPAMI.2007.1054; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEE A, 1994, IMAGE VISION COMPUT, V12, P639, DOI 10.1016/0262-8856(94)90039-6; GOSHTASBY A, 1985, IEEE T SYST MAN CYB, V15, P631, DOI 10.1109/TSMC.1985.6313439; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; Huang G.B., 2008, WORKSHOP FACESREAL L; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317; Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518; Jianke Z., 2009, P IEEE INT C COMP VI, P1265; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Meytlis M, 2007, IEEE T PATTERN ANAL, V29, P1262, DOI 10.1109/TPAMI.2007.1033; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Schneiderman H., 2011, CMU PROFILE FACE IMA; Thomas SJ, 2011, LECT NOTES COMPUT SC, V6493, P334; Toews M, 2007, IEEE T MED IMAGING, V26, P757, DOI 10.1109/TMI.2006.895907; Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233; Vedaldi A., 2011, SIFT IMPLEMENTATION; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wallach H.M., 2006, TECHNICAL REPORT; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiaoming L., 2007, P IEEE C COMP VIS PA, P1; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	46	12	12	1	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2484	2497		10.1109/TPAMI.2013.37	http://dx.doi.org/10.1109/TPAMI.2013.37			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969391				2022-12-18	WOS:000323175200013
J	Moreno-Noguer, F; Fua, P				Moreno-Noguer, Francesc; Fua, Pascal			Stochastic Exploration of Ambiguities for Nonrigid Shape Recovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deformable surfaces; monocular shape estimation	STRUCTURE-FROM-MOTION; RECONSTRUCTION; ILLUMINATION; SURFACES; MODELS	Recovering the 3D shape of deformable surfaces from single images is known to be a highly ambiguous problem because many different shapes may have very similar projections. This is commonly addressed by restricting the set of possible shapes to linear combinations of deformation modes and by imposing additional geometric constraints. Unfortunately, because image measurements are noisy, such constraints do not always guarantee that the correct shape will be recovered. To overcome this limitation, we introduce a stochastic sampling approach to efficiently explore the set of solutions of an objective function based on point correspondences. This allows us to propose a small set of ambiguous candidate 3D shapes and then use additional image information to choose the best one. As a proof of concept, we use either motion or shading cues to this end and show that we can handle a complex objective function without having to solve a difficult nonlinear minimization problem. The advantages of our method are demonstrated on a variety of problems including both real and synthetic data.	[Moreno-Noguer, Francesc] UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Spain; [Fua, Pascal] Ecole Polytech Fed Lausanne, BC IC CVLab 310, Comp Vis Lab, Stn 14, CH-1015 Lausanne, Switzerland	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Moreno-Noguer, F (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Llorens & Artigas 4-6, Barcelona 08028, Spain.	fmoreno@iri.upc.edu; pascal.fua@epfl.ch	Moreno-Noguer, Francesc/G-3915-2014	Moreno-Noguer, Francesc/0000-0002-8640-684X; Fua, Pascal/0000-0002-6702-9970	Spanish Ministry of Science and Innovation under CICYT project [PAU+ DPI2011-27510]; MIPRCV Consolider Ingenio [CSD2007-00018]; EU project GARNISC [FP7-247947]; Swiss National Science Foundation	Spanish Ministry of Science and Innovation under CICYT project; MIPRCV Consolider Ingenio; EU project GARNISC; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work has been partially funded by the Spanish Ministry of Science and Innovation under CICYT project PAU+ DPI2011-27510, by MIPRCV Consolider Ingenio 2010 CSD2007-00018, by the EU project GARNISC FP7-247947, and by the Swiss National Science Foundation. The authors would like to thank Josep M. Porta and Mathieu Salzmann for insightful comments and suggestions on a preliminary version of this work. They would also like to thank Aaron Hertzmann for bringing the CMA algorithm to their attention.	Balan AO, 2007, IEEE I CONF COMP VIS, P1379; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Brand M., 2001, P IEEE C COMP VIS PA; BREGLER C, 2000, P IEEE C COMP VIS PA; Chiuso A, 2000, INT J COMPUT VISION, V39, P195, DOI 10.1023/A:1026563712076; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; CRIMINISI A, 2001, DISTINGUISHED DISSER, P1; Delaney Martin, 2008, Proj Inf Perspect, P1; Ecker A, 2008, LECT NOTES COMPUT SC, V5302, P127, DOI 10.1007/978-3-540-88682-2_11; Gumerov N, 2004, LECT NOTES COMPUT SC, V3023, P482; Hamerly G., 2003, NEURAL INFORM PROCES, V17; Hansen N, 2006, STUD FUZZ SOFT COMP, V192, P75; Hansen N., 2007, CMA EVOLUTION STRATE; Hara K, 2005, IEEE T PATTERN ANAL, V27, P493, DOI 10.1109/TPAMI.2005.82; John M., 2000, LECT NOTES COMPUTER, P3, DOI DOI 10.1007/3-540-45053-X1; Liang J, 2005, PROC CVPR IEEE, P338; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McInerney T., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P518, DOI 10.1109/ICCV.1993.378169; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Moreno-Noguer F., 2010, P EUR C COMP VIS, P361; Moreno-Noguer F, 2009, PROC CVPR IEEE, P1842, DOI 10.1109/CVPRW.2009.5206758; Paladini M., 2011, INT J COMPUT VISION, P1; Perriollat M., 2008, P BRIT MACH VIS C; Qian G, 2004, INT J COMPUT VISION, V59, P5, DOI 10.1023/B:VISI.0000020669.68126.4b; Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Sanchez-Riera J, 2010, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2010.5539831; Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007; WHITE R, 2006, COMPUTER VISION PATT, V2, P1809; Xiao J, 2005, IEEE I CONF COMP VIS, P1075; Yu YZ, 1999, COMP GRAPH, P215; Zhu JK, 2008, LECT NOTES COMPUT SC, V5304, P766	37	12	12	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					463	475		10.1109/TPAMI.2012.102	http://dx.doi.org/10.1109/TPAMI.2012.102			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22547426	Green Submitted			2022-12-18	WOS:000312560600017
J	Koehl, P				Koehl, Patrice			Fast Recursive Computation of 3D Geometric Moments from Surface Meshes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D geometric moments; exact algorithm; discrete convolution	IMAGE-ANALYSIS; SPHERICAL-HARMONICS	A new exact algorithm is proposed to compute the 3D geometric moments of a homogeneous shape defined by an unstructured triangulation of its surface. This algorithm relies on the analytical integration of the moments on tetrahedra defined by the surface triangles and a central point and on a set of recurrent relationships between the corresponding integrals, and achieves linear running time complexities with respect to the number of triangles in the surface mesh and with respect to the number of moments that are computed. This effectively reduces the complexity for computing moments up to order N from N-6 to N-3 with respect to the fastest previously proposed exact algorithm.	[Koehl, Patrice] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Koehl, Patrice] Univ Calif Davis, Genome Ctr, Davis, CA 95616 USA	University of California System; University of California Davis; University of California System; University of California Davis	Koehl, P (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.	koehl@cs.ucdavis.edu	Koehl, Patrice/K-5708-2013	Koehl, Patrice/0000-0002-0908-068X	US National Institutes of Health	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	The author acknowledges support from the US National Institutes of Health.	BEST GC, 1964, MATH COMPUT, V18, P310, DOI 10.2307/2003308; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Khairy K, 2008, MED IMAGE ANAL, V12, P217, DOI 10.1016/j.media.2007.10.005; Koehl P., 2006, REV COMPUTATIONAL CH, V22; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; LIEN SL, 1984, IEEE COMPUT GRAPH, V4, P35, DOI 10.1109/MCG.1984.6429334; Pozo JM, 2011, IEEE T PATTERN ANAL, V33, P471, DOI 10.1109/TPAMI.2010.139; MAX NL, 1988, IEEE COMPUT GRAPH, V8, P42, DOI 10.1109/38.7748; Peng HC, 2008, BIOINFORMATICS, V24, P1827, DOI 10.1093/bioinformatics/btn346; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; Putz J., 1986, COLL MATH J, V17, P144, DOI DOI 10.2307/2686833; Shamir L, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000974; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Toomre D, 2010, ANNU REV CELL DEV BI, V26, P285, DOI 10.1146/annurev-cellbio-100109-104048; Venkatraman V, 2009, CELL BIOCHEM BIOPHYS, V54, P23, DOI 10.1007/s12013-009-9051-x; Yang L, 1997, GRAPH MODEL IM PROC, V59, P97, DOI 10.1006/gmip.1997.0418	17	12	12	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2158	2163		10.1109/TPAMI.2012.23	http://dx.doi.org/10.1109/TPAMI.2012.23			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22997126				2022-12-18	WOS:000308755000008
J	Weinshall, D; Zweig, A; Hermansky, H; Kombrink, S; Ohl, FW; Anemuller, J; Bach, JH; Van Gool, L; Nater, F; Pajdla, T; Havlena, M; Pavel, M				Weinshall, Daphna; Zweig, Alon; Hermansky, Hynek; Kombrink, Stefan; Ohl, Frank W.; Anemueller, Joern; Bach, Joerg-Hendrik; Van Gool, Luc; Nater, Fabian; Pajdla, Tomas; Havlena, Michal; Pavel, Misha			Beyond Novelty Detection: Incongruent Events, When General and Specific Classifiers Disagree	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Novelty detection; categorization; object recognition; out-of-vocabulary words	CORTICAL ACTIVITY	Unexpected stimuli are a challenge to any machine learning algorithm. Here, we identify distinct types of unexpected events when general-level and specific-level classifiers give conflicting predictions. We define a formal framework for the representation and processing of incongruent events: Starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels in the label hierarchy. An incongruent event is an event where the probability computed based on some more specific level is much smaller than the probability computed based on some more general level, leading to conflicting predictions. Algorithms are derived to detect incongruent events from different types of hierarchies, different applications, and a variety of data types. We present promising results for the detection of novel visual and audio objects, and new patterns of motion in video. We also discuss the detection of Out-Of-Vocabulary words in speech recognition, and the detection of incongruent events in a multimodal audiovisual scenario.	[Weinshall, Daphna; Zweig, Alon] Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel; [Hermansky, Hynek] Johns Hopkins Univ, Ctr Language & Speech Proc, Baltimore, MD 21218 USA; [Kombrink, Stefan] BUT, DCGM, Fac Informat Technol, Brno 61266, Czech Republic; [Ohl, Frank W.] LIN, Dept Syst Physiol Learning, D-39118 Magdeburg, Germany; [Anemueller, Joern; Bach, Joerg-Hendrik] Carl von Ossietzky Univ Oldenburg, Dept Phys, D-26111 Oldenburg, Germany; [Van Gool, Luc; Nater, Fabian] ETH Zentrum, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Pajdla, Tomas; Havlena, Michal] FEE CTU, Ctr Machine Percept, Dept Cybernet, Prague 16627 6, Czech Republic; [Pavel, Misha] Oregon Hlth & Sci Univ, Dept Biomed Engn, Portland, OR 97239 USA; [Pavel, Misha] Oregon Hlth & Sci Univ, Dept Comp Sci & Elect Engn, Portland, OR 97239 USA	Hebrew University of Jerusalem; Johns Hopkins University; Brno University of Technology; Leibniz Institut fur Neurobiologie (LIN); Carl von Ossietzky Universitat Oldenburg; Swiss Federal Institutes of Technology Domain; ETH Zurich; Czech Technical University Prague; Oregon Health & Science University; Oregon Health & Science University	Weinshall, D (corresponding author), Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel.	daphna@cs.huji.ac.il; alon.zweig@mail.huji.ac.il; hynek@jhu.edu; kombrink@fit.vutbr.cz; frank.ohl@lin-magdeburg.de; joern.anemueller@uni-oldenburg.de; j.bach@uni-oldenburg.de; vangool@vision.ee.ethz.ch; fnater@vision.ee.ethz.ch; pajdla@cmp.felk.cvut.cz; havlem1@cmp.felk.cvut.cz; pavel@bme.ogi.edu	Anemüller, Jörn/A-8090-2009; Pajdla, Tomas/K-7954-2013	Pajdla, Tomas/0000-0001-6325-0072; Bach, Jorg-Hendrik/0000-0001-5205-2193	European Union [IST-027787]	European Union(European Commission)	This study was supported by the European Union under the DIRAC integrated project IST-027787.	Anemuller J., 2008, P INT C SPOK LANG PR; [Anonymous], 2005, P IEEE C COMP VIS PA; Bach J.-H., 2010, P INT C SPOK LANG PR; Bar-Hillel A., 2005, P IEEE INT C COMP VI; Bar-Hillel A., 2006, P ADV NEUR INF PROC, V19; Berns GS, 1997, SCIENCE, V276, P1272, DOI 10.1126/science.276.5316.1272; Bishop C. M., 2006, J ELECT IMAG, V16, P140; BRADSKI GR, 1998, INTEL TECHNOLOGY J, V2, P12; Burget L, 2008, INT CONF ACOUST SPEE, P4081, DOI 10.1109/ICASSP.2008.4518551; Deliano M, 2009, J NEUROSCI, V29, P15898, DOI 10.1523/JNEUROSCI.1949-09.2009; DIEHL C, 2002, P IEEE INT JOINT C N; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Garofolo JS, 1993, TIMIT ACOUSTIC PHONE; Griffin G., 2007, UCBCSD041366 CALTECH; Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616; Ketabdar H., 2007, P EUR C SPEECH COMM; Kombrink S., 2009, P INTERSPEECH, P80; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; Marszalek M., 2008, P 10 EUR C COMP VIS; Marszalek M., 2007, P IEEE C COMP VIS PA; Matas J., 2000, P INT C PATT REC; Nater F., 2009, P IEEE INT C COMP VI; Ohl FW, 2001, NATURE, V412, P733, DOI 10.1038/35089076; Ohl FW, 1997, P NATL ACAD SCI USA, V94, P9440, DOI 10.1073/pnas.94.17.9440; Pajdla T., 2008, CMP200828 K13133 FEE; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Rokers B, 2002, BEHAV NEUROSCI, V116, P48, DOI 10.1037//0735-7044.116.1.48; Scholkopf B., 2000, ADV NEUR INF PROC SY; Sivic J., 2008, P IEEE C COMP VIS PA; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Ulanovsky N, 2004, J NEUROSCI, V24, P10440, DOI 10.1523/JNEUROSCI.1905-04.2004; Yeung D., 2002, P INT C PATT REC; Zweig A., 2007, P IEEE INT C COMP VI	36	12	13	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1886	1901		10.1109/TPAMI.2011.279	http://dx.doi.org/10.1109/TPAMI.2011.279			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22213766	Green Submitted			2022-12-18	WOS:000307522700002
J	Bart, E; Welling, M; Perona, P				Bart, Evgeniy; Welling, Max; Perona, Pietro			Unsupervised Organization of Image Collections: Taxonomies and Beyond	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Taxonomy; hierarchy; clustering		We introduce a nonparametric Bayesian model, called TAX, which can organize image collections into a tree-shaped taxonomy without supervision. The model is inspired by the Nested Chinese Restaurant Process (NCRP) and associates each image with a path through the taxonomy. Similar images share initial segments of their paths and thus share some aspects of their representation. Each internal node in the taxonomy represents information that is common to multiple images. We explore the properties of the taxonomy through experiments on a large (similar to 10(4)) image collection with a number of users trying to locate quickly a given image. We find that the main benefits are easier navigation through image collections and reduced description length. A natural question is whether a taxonomy is the optimal form of organization for natural images. Our experiments indicate that although taxonomies can organize images in a useful manner, more elaborate structures may be even better suited for this task.	[Bart, Evgeniy] Palo Alto Res Ctr, Palo Alto, CA 94304 USA; [Welling, Max] Univ Calif Irvine, Donald Bren Sch Informat & Comp Sci, Irvine, CA 92697 USA; [Perona, Pietro] CALTECH, Vis Lab Pietro Perona, Pasadena, CA 91125 USA	University of California System; University of California Irvine; California Institute of Technology	Bart, E (corresponding author), Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	bart@parc.com; welling@ics.uci.edu; perona@caltech.edu			US National Science Foundation [0447903,, 0535278, IIS-0535292]; US Office of Naval Research [00014-06-1-0734]	US National Science Foundation(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research)	This material is based upon work supported by the US National Science Foundation under Grant Nos. 0447903, 0535278 and IIS-0535292, and by US Office of Naval Research MURI grant 00014-06-1-0734. An early version of this paper appeared in [18]. The authors would like to thank Marco Andreetto for useful suggestions.	Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; ANDREETTO M, 2007, P IEEE 11 INT C COMP; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BART E, 2005, P IEEE CS C COMP VIS; BART E, 2009, P NIPS WORKSH APPL T; BART E, 2008, P IEEE C VIS PATT RE; BIEDERMAN I, 1995, INVITATION COGNITIVE, V2, P121; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BLEI DM, 2004, P NEUR INF PROC SYST; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Fei-Fei L., 2003, P IEEE 9 INT C COMP; FEIFEI L, 2005, P IEEE CS C COMP VIS; Fink M., 2006, P 23 INT C MACH LEAR; Griffin G., 2008, P IEEE C COMP VIS PA; Grunwald P.D., 2005, ADV MINIMUM DESCRIPT; HE X, 2008, P IEEE C COMP VIS PA; Lazebnik S., 2006, P IEEE CS C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; NISTER D, 2006, P IEEE CS C COMP VIS; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Sivic J., 2008, P IEEE C COMP VIS PA; Sudderth E. B., 2005, P NEUR INF PROC SYST; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Torralba A., 2004, P IEEE CS C COMP VIS; ZWEIG A, 2007, P IEEE 11 INT C COMP	27	12	12	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2302	2315		10.1109/TPAMI.2011.79	http://dx.doi.org/10.1109/TPAMI.2011.79			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21519098				2022-12-18	WOS:000294910000014
J	Gardner, RJ; Kiderlen, M				Gardner, Richard J.; Kiderlen, Markus			A New Algorithm for 3D Reconstruction from Support Functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Support function; convex body; geometric tomography; algorithm	LINE MEASUREMENTS; CONVEX-BODIES; LOCALIZATION; RECOGNITION; ATTENTION; FOCUS; SETS	We introduce a new algorithm for reconstructing an unknown shape from a finite number of noisy measurements of its support function. The algorithm, based on a least squares procedure, is very easy to program in standard software such as Matlab and it works for both 2D and 3D reconstructions ( in fact, in principle, in any dimension). Reconstructions may be obtained without any pre- or postprocessing steps and with no restriction on the sets of measurement directions except their number, a limitation dictated only by computing time. An algorithm due to Prince and Willsky was implemented earlier for 2D reconstructions and we compare the performance of their algorithm and ours. But, our algorithm is the first that works for 3D reconstructions with the freedom stated in the previous paragraph. Moreover, under mild conditions, theory guarantees that outputs of the new algorithm will converge to the input shape as the number of measurements increases. In addition, we offer a linear program version of the new algorithm that is much faster and better, or at least comparable, in performance at low levels of noise and reasonably small numbers of measurements. Another modification of the algorithm, suitable for use in a "focus of attention" scheme, is also described.	[Gardner, Richard J.] Western Washington Univ, Dept Math, Bellingham, WA 98225 USA; [Kiderlen, Markus] Univ Aarhus, Dept Math Sci, DK-8000 Aarhus C, Denmark	Western Washington University; Aarhus University	Gardner, RJ (corresponding author), Western Washington Univ, Dept Math, Bellingham, WA 98225 USA.	Richard.Gardner@wwu.edu; kiderlen@imf.au.dk		Kiderlen, Markus/0000-0003-2858-6659	US National Science Foundation [DMS-0603307]; Carlsberg Foundation; Danish Council for Strategic Research	US National Science Foundation(National Science Foundation (NSF)); Carlsberg Foundation(Carlsberg Foundation); Danish Council for Strategic Research(Danske Strategiske Forskningsrad (DSF))	The authors would like to thank a team of Western Washington University undergraduate students-Mark Lockwood, LeRoy Miller, Greg Richardson, Holly Rutledge, and Michael Taron-for writing the programs. This work was supported in part by US National Science Foundation Grant DMS-0603307, by the Carlsberg Foundation, and by the Danish Council for Strategic Research.	Fisher NI, 1997, J AM STAT ASSOC, V92, P84, DOI 10.2307/2291452; Gardner R., 2006, GEOMETRIC TOMOGRAPHY, VSecond; Gardner RJ, 2006, ANN STAT, V34, P1331, DOI 10.1214/009053606000000335; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; Ghosh PK, 1998, COMPUT VIS IMAGE UND, V72, P379, DOI 10.1006/cviu.1998.0674; Gregor J, 2002, INT J IMAG SYST TECH, V12, P229, DOI 10.1002/ima.10027; Gregor J, 2002, INT J IMAG SYST TECH, V12, P43, DOI 10.1002/ima.10007; Gregor J, 1997, IEEE T MED IMAGING, V16, P218, DOI 10.1109/42.563667; Groemer H., 1996, GEOMETRIC APPL FOURI; Hall P, 1999, IEEE T PATTERN ANAL, V21, P225, DOI 10.1109/34.754588; Ikehata M, 2002, INVERSE PROBL, V18, P111, DOI 10.1088/0266-5611/18/1/308; LELE AS, 1992, J OPT SOC AM A, V9, P1693, DOI 10.1364/JOSAA.9.001693; LINDENBAUM M, 1994, IEEE T ROBOTIC AUTOM, V10, P517, DOI 10.1109/70.313101; Mammen E, 2001, STAT SCI, V16, P232; Poonawala A, 2006, J MATH IMAGING VIS, V24, P229, DOI 10.1007/s10851-005-3625-z; PRINCE JL, 1990, IEEE T PATTERN ANAL, V12, P377, DOI 10.1109/34.50623; Schneider R., 1993, CONVEX BODIES BRUNN; SCHNEITER JL, 1990, IEEE T PATTERN ANAL, V12, P775, DOI 10.1109/34.57668; SERRELL B, 1995, VISITOR BEHAV, V10, P6	19	12	13	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					556	562		10.1109/TPAMI.2008.190	http://dx.doi.org/10.1109/TPAMI.2008.190			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147881	Green Submitted			2022-12-18	WOS:000262480200012
J	Geng, X; Zhou, ZH; Smith-Miles, K				Geng, Xin; Zhou, Zhi-Hua; Smith-Miles, Kate			Automatic age estimation based on facial aging patterns (vol 29, pg 2234, 2007)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									[Geng, Xin; Smith-Miles, Kate] Deakin Univ, Sch Engn & Informat Technol, Geelong, Vic 3215, Australia; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Deakin University; Nanjing University	Geng, X (corresponding author), Deakin Univ, Sch Engn & Informat Technol, Geelong, Vic 3215, Australia.	xge@deakin.edu.au; zhouzh@nju.edu.cn; katesm@deakin.edu.au	Smith-Miles, Kate/Q-9004-2019; Smith-Miles, Kate/B-7493-2008; Geng, Xin/A-5290-2008	Smith-Miles, Kate/0000-0003-2718-7680; Smith-Miles, Kate/0000-0003-2718-7680; 				Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733	1	12	12	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					368	368		10.1109/TPAMI.2008.8	http://dx.doi.org/10.1109/TPAMI.2008.8			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC					2022-12-18	WOS:000251580300015
J	Liang, C; Wong, KYK				Liang, Chen; Wong, Kwan-Yee K.			Robust recovery of shapes with unknown topology from the dual space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reconstruction; duality principle; tangent envelope; epipolar parameterization; surface extraction	3D OBJECTS; SURFACE; RECONSTRUCTION; CONSTRUCTION	In this paper, we address the problem of reconstructing an object surface from silhouettes. Previous works by other authors have shown that, based on the principle of duality, surface points can be recovered, theoretically, as the dual to the tangent plane space of the object. In practice, however, the identification of tangent basis in the tangent plane space is not trivial given a set of discretely sampled data. This problem is further complicated by the existence of bitangents to the object surface. The key contribution of this paper is the introduction of epipolar parameterization in identifying a well- defined local tangent basis. This extends the applicability of existing dual space reconstruction methods to fairly complicated shapes without making any explicit assumption on the object topology. We verify our approach with both synthetic and real- world data and compare it both qualitatively and quantitatively with other popular reconstruction algorithms. Experimental results demonstrate that our proposed approach produces more accurate estimation while maintaining reasonable robustness toward shapes with complex topologies.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	University of Hong Kong	Liang, C (corresponding author), Univ Hong Kong, Dept Comp Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	cliang@cs.hku.hk; kykwong@cs.hku.hk	Wong, Kenneth Kwan Yee/C-1577-2009	Wong, Kenneth Kwan Yee/0000-0001-8560-9007				BAUMGART B, 1975, P AFIPS NAT COMP C; BOISSONNAT JD, 1988, COMPUT VISION GRAPH, V44, P1, DOI 10.1016/S0734-189X(88)80028-8; Boyer E., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P198; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; Boyer E, 2003, PROC CVPR IEEE, P695; BRAND M, 2004, COMPUTER VISION PATT, V1, P30; CHEUNG G, 2003, COMPUTER VISION PATT; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7; Cipolla R, 1997, INT J COMPUT VISION, V23, P115, DOI 10.1023/A:1007920028712; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; Cipolla R., 2000, VISUAL MOTION CURVES; FRANCO JS, 2003, P BRIT MACH VIS C, V1, P329; Garcia B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1067, DOI 10.1109/ICCV.1998.710849; GIBLIN P, 1978, P INT C COMP VIS, P136; KANG K, 2004, THESIS BROWN U; Kang KB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P198, DOI 10.1109/ICCV.2001.937518; KUTULAKOS KN, 1997, COMPUTER VISION PATT, P53; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LAZEBNIK S, 2002, THESIS U ILLINOIS UR; LAZEBNIK S, 2001, COMPUTER VISION PATT, V1, P156; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MATUSIK W, 2001, P EUR WORKSH REND; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; Sethi A, 2004, INT J COMPUT VISION, V58, P73, DOI 10.1023/B:VISI.0000016148.08046.fc; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; WEISS R, 1994, P INT NSF ARPA WORKS, P101; Wong KYK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P217, DOI 10.1109/ICCV.2001.937627; WONG KYK, 2001, THESIS U CAMBRIDGE	32	12	12	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2205	2216		10.1109/TPAMI.2007.1127	http://dx.doi.org/10.1109/TPAMI.2007.1127			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934229	Green Submitted			2022-12-18	WOS:000250087900012
J	Destrempes, F; Mignotte, M; Angers, JF				Destrempes, Francois; Mignotte, Max; Angers, Jean-Francois			Localization of shapes using statistical models and stochastic optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape localization; statistical model; stochastic optimization; Exploration/Selection (E/S) algorithm; Probabilistic Principal Component Analysis ( PPCA)	RANDOM-FIELD MODELS; BIPLANAR RECONSTRUCTION; SEGMENTATION; KNOWLEDGE; TRACKING; CLASSIFICATION; RECOGNITION; CONTOURS; COLOR; SPACE	In this paper, we present a new model for deformations of shapes. A pseudolikelihood is based on the statistical distribution of the gradient vector field of the gray level. The prior distribution is based on the Probabilistic Principal Component Analysis (PPCA). We also propose a new model based on mixtures of PPCA that is useful in the case of greater variability in the shape. A criterion of global or local object specificity based on a preliminary color segmentation of the image is included into the model. The localization of a shape in an image is then viewed as minimizing the corresponding Gibbs field. We use the Exploration/Selection (E/S) stochastic algorithm in order to find the optimal deformation. This yields a new unsupervised statistical method for localization of shapes. In order to estimate the statistical parameters for the gradient vector field of the gray level, we use an Iterative Conditional Estimation (ICE) procedure. The color segmentation of the image can be computed with an Exploration/Selection/Estimation (ESE) procedure.	Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada; Univ Montreal, Dept Math & Stat, Montreal, PQ H3C 3J7, Canada	Universite de Montreal; Universite de Montreal	Destrempes, F (corresponding author), Univ Montreal, Dept Informat & Rech Operat, Pavillon Andre Aisenstadt,CP 6128 Succursale Cent, Montreal, PQ H3C 3J7, Canada.	destremp@iro.umontreal.ca; mignotte@iro.umontreal.ca; angers@dms.umontreal.ca	Mignotte, Max/F-7014-2015					ANDERSON TW, 1971, INTRO MULTIVARIATE S; Benameur S, 2005, IEEE T BIO-MED ENG, V52, P2041, DOI 10.1109/TBME.2005.857665; Benameur S, 2005, IEEE T BIO-MED ENG, V52, P1713, DOI 10.1109/TBME.2005.855717; Berger J. O., 1985, STAT DECISION THEORY; BERGTHOLDT M, 2005, MATH MODELS COMPUTER; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; CHAKRABORTY A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P624; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z; Cremers D, 2003, IMAGE VISION COMPUT, V21, P77, DOI 10.1016/S0262-8856(02)00128-2; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; Crisan D, 2002, IEEE T SIGNAL PROCES, V50, P736, DOI 10.1109/78.984773; DEBRUIJNE M, 2004, P MED IMAGE COMPUTIN, V1, P168; Destrempes F, 2005, IEEE T IMAGE PROCESS, V14, P1096, DOI 10.1109/TIP.2005.851710; Destrempes F., 2002, Proceedings of the Fourth IASTED International Conference Signal and Image Processing, P60; Destrempes F., 2002, Proceedings of the Fourth IASTED International Conference Signal and Image Processing, P66; Destrempes F, 2004, IEEE T PATTERN ANAL, V26, P626, DOI 10.1109/TPAMI.2004.1273940; DESTREMPES F, 2006, THESIS U MONTREAL; DESTREMPES F, 2002, THESIS U MONTREAL; DESTREMPES F, 2002, P 3 IND C COMP VIS G, P411; Destrempes F, 2006, IEEE T IMAGE PROCESS, V15, P2920, DOI 10.1109/TIP.2006.877522; FIGUEIREDO M, 1992, IEEE T MED IMAGING, V11, P416; Francois O, 2002, ANN APPL PROBAB, V12, P248; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GRENANDER U, 1994, J R STAT SOC B, V56, P549; GRENANDER U, 1976, PATTERN SYNTHESIS LE; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293, DOI 10.1109/34.485557; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kervrann C, 1998, GRAPH MODEL IM PROC, V60, P173, DOI 10.1006/gmip.1998.0469; KOLMOGOROV K, 2002, P EUROPEAN C COMPUTE, V3, P65; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Luettin J, 1997, COMPUT VIS IMAGE UND, V65, P163, DOI 10.1006/cviu.1996.0570; MATLOFF NS, 1988, PROBABILITY MODELING; Mignotte M, 2000, IEEE T PATTERN ANAL, V22, P129, DOI 10.1109/34.825752; Mignotte M, 2001, PATTERN ANAL APPL, V4, P256, DOI 10.1007/PL00010988; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; MOSHFEGHI M, 1994, IEEE T PATTERN ANAL, V16, P128; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; PIECZYNSKI W, 1994, REV TRAITEMENT SIGNA, V11, P141; Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78; Rue H, 1999, BIOMETRIKA, V86, P649, DOI 10.1093/biomet/86.3.649; SALZENSTEIN F, 1995, P INT C ACOUSTICS SP, V4, P2411; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Zhong Y, 2000, PATTERN RECOGN, V33, P671, DOI 10.1016/S0031-3203(99)00079-5	57	12	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1603	1615		10.1109/TPAMI.2007.1157	http://dx.doi.org/10.1109/TPAMI.2007.1157			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627047				2022-12-18	WOS:000247965600009
J	Huxley, MN; Zunic, J				Huxley, Martin N.; Zunic, Jovisa			The number of N-point digital discs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digital disc; digitization; enumeration; digital geometry	IMAGE-ANALYSIS; MOMENTS; DISKS	A digital disc is the set of all integer points inside some given disc. Let DN be the number of different digital discs consisting of N points ( different up to translation). The upper bound D-N = O(N-2) was shown recently; no corresponding lower bound is known. In this paper, we refine the upper bound to D-N = O(N), which seems to be the true order of magnitude, and we show that the average (D) over bar (N) = (D-1 + D-2 + ... + D-N)/N has upper and lower bounds which are of polynomial growth in N.	Univ Cardiff Wales, Sch Math, Cardiff CF24 4AG, S Glam, Wales; Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England; Serbian Acad Arts & Sci, Math Inst, Belgrade, Serbia	Cardiff University; University of Exeter; Serbian Academy of Sciences & Arts	Huxley, MN (corresponding author), Univ Cardiff Wales, Sch Math, 23 Senghennydd Rd, Cardiff CF24 4AG, S Glam, Wales.	Huxley@cf.ac.uk; J.Zunic@ex.ac.uk						BERENSTEIN CA, 1988, IEEE T PATTERN ANAL, V10, P880, DOI 10.1109/34.9109; FISK S, 1986, IEEE T PATTERN ANAL, V8, P554, DOI 10.1109/TPAMI.1986.4767821; Huxley M. N., 1996, LONDON MATH SOC MONO, V13; Huxley MN, 2006, FOUND COMPUT MATH, V6, P255, DOI 10.1007/s10208-005-0177-y; Huxley MN, 2003, P LOND MATH SOC, V87, P591, DOI 10.1112/S0024611503014485; KENDALL DG, 1948, ANN MATH STAT, V19, P1, DOI 10.1214/aoms/1177730285; KIM CE, 1984, IEEE T PATTERN ANAL, V6, P372, DOI 10.1109/TPAMI.1984.4767531; Klette R, 2000, J MATH IMAGING VIS, V13, P173, DOI 10.1023/A:1011289414377; Klette R., 2004, DIGITAL GEOMETRY; KOPLOWITZ J, 1993, IEEE T INFORM THEORY, V15, P949; Kratzel E., 1988, LATTICE POINTS; Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809; Pawlak M, 2002, IEEE T INFORM THEORY, V48, P2736, DOI 10.1109/TIT.2002.802627; WORRING M, 1995, IEEE T PATTERN ANAL, V17, P587, DOI 10.1109/34.387505; Zunic J, 2004, J MATH IMAGING VIS, V21, P199, DOI 10.1023/B:JMIV.0000043736.15525.ed; Zunic J, 2000, IEEE T PATTERN ANAL, V22, P407, DOI 10.1109/34.845384	16	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					159	161		10.1109/TPAMI.2007.250606	http://dx.doi.org/10.1109/TPAMI.2007.250606			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108390				2022-12-18	WOS:000241988300012
J	Lehmann, S; Bradley, AP; Clarkson, IVL; Williams, J; Kootsookos, PJ				Lehmann, Stefan; Bradley, Andrew P.; Clarkson, I. Vaughan L.; Williams, John; Kootsookos, Peter J.			Correspondence-free determination of the affine fundamental matrix	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; epipolar geometry; fundamental matrix; robust estimation; projection; slice theorem; Radon transformation	GEOMETRY	Fundamental matrix estimation is a central problem in computer vision and forms the basis of tasks such as stereo imaging and structure from motion. Existing algorithms typically analyze the relative geometries of matched feature points identified in both projected views. Automated feature matching is itself a challenging problem. Results typically have a large number of false matches. Traditional fundamental matrix estimation methods are very sensitive to matching errors, which led naturally to the application of robust statistical estimation techniques to the problem. In this work, an entirely novel approach is proposed to the fundamental matrix estimation problem. Instead of analyzing the geometry of matched feature points, the problem is recast in the frequency domain through the use of Integral Projection, showing how this is a reasonable model for orthographic cameras. The problem now reduces to one of identifying matching lines in the frequency domain which, most importantly, requires no feature matching or correspondence information. Experimental results on both real and synthetic data are presented that demonstrate the algorithm is a practical technique for fundamental matrix estimation. The behavior of the proposed algorithm is additionally characterized with respect to input noise, feature counts, and other parameters of interest.	Univ Queensland, Sch ITEE, Brisbane, Qld 4072, Australia; UTC Fire & Secur, Farmington, CT 06032 USA	University of Queensland	Lehmann, S (corresponding author), Univ Queensland, Sch ITEE, Brisbane, Qld 4072, Australia.	lehmann@itee.uq.edu.au; bradley@itee.uq.edu.au; v.clarkson@itee.uq.edu.au; jwilliams@itee.uq.edu.au; p.kootsookos@ieee.org	Williams, John/AAD-4790-2020; Bradley, Andrew P./O-8516-2019; Bradley, Andrew P./C-5685-2009; Kootsookos, Peter James/AAB-2672-2022	Williams, John/0000-0002-2528-1502; Bradley, Andrew P./0000-0003-0109-6844; Bradley, Andrew P./0000-0003-0109-6844; Kootsookos, Peter/0000-0003-3575-6951				Antone M, 2002, INT J COMPUT VISION, V49, P143, DOI 10.1023/A:1020141505696; Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; BAKER P, 2004, P 8 EUR C COMP VIS, P229; BEARDSLEY P, 1996, P EUR C COMP VIS CAM, V2, P683; Bracewell RN., 1995, 2 DIMENSIONAL IMAGIN; Chai JX, 2000, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2000.854892; Deans S., 1983, RADON TRANSFORM SOME; Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916; Favaro P, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P250, DOI 10.1109/ICIAP.2001.957017; Fermuller C, 1997, PROC CVPR IEEE, P250, DOI 10.1109/CVPR.1997.609328; Fermuller C, 2002, P IEEE, V90, P1113, DOI 10.1109/JPROC.2002.801440; FERMULLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P245, DOI 10.1109/ICCV.1995.466779; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEYER C, 2004, P WORKSH OMN VIS; GRACIAS N, 1997, P 5 INT S INT ROB SY; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hutchison LAD, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P253, DOI 10.1109/DIAL.2004.1263254; Irani M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P626, DOI 10.1109/ICCV.1999.791283; Kak A. C., 2001, PRINCIPLES COMPUTERI; LANK GW, 1973, IEEE T AERO ELEC SYS, VAES9, P151, DOI 10.1109/TAES.1973.309762; Leclercq P, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P606, DOI 10.1109/ICIAP.2003.1234117; LEHMANN S, 2004, P 38 AS C SIGN SYST, V1, P2089; Makadia A, 2005, PROC CVPR IEEE, P796; Makadia A, 2004, INT C PATT RECOG, P590, DOI 10.1109/ICPR.2004.1334598; Makadia A, 2003, PROC CVPR IEEE, P217; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; NEGAHDARIPOUR S, 1989, COMPUT VISION GRAPH, V46, P303, DOI 10.1016/0734-189X(89)90035-2; ROY S, 1996, P IEEE INT C PATT RE, V1, P728; SEITZ SM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P330; Stein GP, 2000, IEEE T PATTERN ANAL, V22, P992, DOI 10.1109/34.877522; TAALEBINEZHAAD MA, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P626, DOI 10.1109/ROBOT.1991.131652; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr P.H., 2002, MSRTR200256; WATT DW, 1989, J OPT SOC AM A, V6, P44, DOI 10.1364/JOSAA.6.000044; Weldon E. J.  Jr., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P613, DOI 10.1109/CVPR.1991.139762; Yezzi AJ, 2003, PROC CVPR IEEE, P525; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	42	12	13	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					82	97		10.1109/TPAMI.2007.250601	http://dx.doi.org/10.1109/TPAMI.2007.250601			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108385				2022-12-18	WOS:000241988300007
J	Ostrouchov, G; Samatova, NF				Ostrouchov, G; Samatova, NF			On FastMap and the convex hull of multivariate data: Toward fast and robust dimension reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimension reduction; convex hull; FastMap; RobustMap; principal components; multidimensional scaling; robust statistics; Euclidean distance		FastMap is a dimension reduction technique that operates on distances between objects. Although only distances are used, implicitly the technique assumes that the objects are points in a p-dimensional Euclidean space. It selects a sequence of k <= p orthogonal axes defined by distant pairs of points ( called pivots) and computes the projection of the points onto the orthogonal axes. We show that FastMap uses only the outer envelope of a data set. Pivots are taken from the faces, usually vertices, of the convex hull of the data points in the original implicit Euclidean space. This provides a bridge to results in robust statistics, where the convex hull is used as a tool in multivariate outlier detection and in robust estimation methods. The connection sheds new light on the properties of FastMap, particularly its sensitivity to outliers, and provides an opportunity for a new class of dimension reduction algorithms, RobustMaps, that retain the speed of FastMap and exploit ideas in robust statistics.	Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN 37831 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory	Ostrouchov, G (corresponding author), Oak Ridge Natl Lab, Comp Sci & Math Div, POB 2008, Oak Ridge, TN 37831 USA.	ostrouchovg@ornl.gov; samatovan@ornl.gov						Abu-Khzam F. N., 2002, Proceedings of the 14th IASTED International Conference Parallel and Distributed Computing and Systems, P174; Donoho D., 1983, FESTSCHRIFT EL LEHMA, P157; Downing DJ, 2000, COMPUT STAT DATA AN, V32, P245, DOI 10.1016/S0167-9473(99)00079-1; Erickson J, 1999, SIAM J COMPUT, V28, P1198, DOI 10.1137/S0097539797315410; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163; GALLIER J, 2000, GEOMETRIC METHODS AP; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hjaltason GR, 2003, IEEE T PATTERN ANAL, V25, P530, DOI 10.1109/TPAMI.2003.1195989; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Huber P., 1981, ROBUST STAT; HUBER PJ, 1972, ANN MATH STAT, V43, P1041, DOI 10.1214/aoms/1177692459; Ruts I, 1996, COMPUT STAT DATA AN, V23, P153, DOI 10.1016/S0167-9473(96)00027-8; *US DOE OFF HLTH E, 1990, DOEER0441; Ziegler G. M., 1995, LECT POLYTOPES; 2004, R LANGUAGE ENV STAT	16	12	13	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1340	1343		10.1109/TPAMI.2005.164	http://dx.doi.org/10.1109/TPAMI.2005.164			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119272				2022-12-18	WOS:000229700900014
J	Bottino, A; Laurentini, A				Bottino, A; Laurentini, A			The visual hull of smooth curved objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; aspect; aspect graphs; silhouettes; visual hull; smooth curved objects	ASPECT GRAPHS; SINGULARITIES; SILHOUETTES; PROJECTIONS; GEOMETRY; SOLIDS; SPACE	The visual hull is a geometric entity that relates the shape of an object to its silhouettes or shadows. This paper develops the theory of the visual hull of generic smooth objects. We show that the visual hull can be constructed using surfaces which partition the viewpoint space of the aspect graph of the object. The surfaces are those generated by the visual events tangent crossing and triple point. An analysis based on the shape of the object at the tangency points of these surfaces allows pruning away many surfaces and patches not relevant to the construction. An algorithm for computing the visual hull is outlined.	Politecn Torino, Dipartimento Automat & Informat, I-10129 Turin, Italy	Polytechnic University of Turin	Bottino, A (corresponding author), Politecn Torino, Dipartimento Automat & Informat, Corso Duca Abruzzi 24, I-10129 Turin, Italy.	andrea.bottino@polito.it; aldo.laurentini@polito.it	Bottino, Andrea/F-4509-2012	Bottino, Andrea/0000-0002-8894-5089				AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; Arnold V.I., 1984, CATASTROPHE THEORY; BOWYER K, 1993, IEEE T PATTERN ANAL, V15, P605, DOI 10.1109/34.216731; Bowyer K. W., 1990, International Journal of Imaging Systems and Technology, V2, P315, DOI 10.1002/ima.1850020407; Callahan J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P240; CHIEN CH, 1989, IEEE T PATTERN ANAL, V11, P372, DOI 10.1109/34.19034; Durand F, 2002, ACM T GRAPHIC, V21, P176, DOI 10.1145/508357.508362; EGGERT D, 1993, IEEE T PATTERN ANAL, V15, P109, DOI 10.1109/34.192483; EGGERT DW, 1993, IEEE T PATTERN ANAL, V15, P1114, DOI 10.1109/34.244674; Forsyth DA, 1996, INT J COMPUT VISION, V18, P21, DOI 10.1007/BF00126138; GIBSON JJ, 1951, PSYCHOL REV, V58, P403, DOI 10.1037/h0055232; GIGUS Z, 1991, IEEE T PATTERN ANAL, V13, P542, DOI 10.1109/34.87341; KERGOSIEN YL, 1981, CR ACAD SCI I-MATH, V292, P929; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; Laurentini A, 1997, COMPUT VIS IMAGE UND, V67, P81, DOI 10.1006/cviu.1996.0508; LAURENTINI A, 1995, IEEE T PATTERN ANAL, V17, P188, DOI 10.1109/34.368170; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Laurentini A, 1999, PATTERN RECOGN, V32, P377, DOI 10.1016/S0031-3203(98)00098-3; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; ONEILL B, 1996, ELEMENTARY DIFFERENT; PETITJEAN S, 1992, INT J COMPUT VISION, V9, P231, DOI 10.1007/BF00133703; Petitjean S, 1996, INT J COMPUT VISION, V19, P261, DOI 10.1007/BF00055147; Petitjean S, 1998, INT J COMPUT GEOM AP, V8, P407, DOI 10.1142/S0218195998000229; PLATONOVA OA, 1984, RUSS MATH SURV+, V39, P177, DOI 10.1070/RM1984v039n01ABEH003080; Pocchiola M, 1996, INT J COMPUT GEOM AP, V6, P279, DOI 10.1142/S0218195996000204; RIEGER J, 1996, PHILOS T R SOC A, P899; RIEGER JH, 1987, IMAGE VISION COMPUT, V5, P91, DOI 10.1016/0262-8856(87)90033-3; Rieger JH, 1998, DISCRETE COMPUT GEOM, V20, P205, DOI 10.1007/PL00009383; RIEGER JH, 1990, ARTIF INTELL, V44, P1, DOI 10.1016/0004-3702(90)90097-J; Shimshoni I, 1997, IEEE T PATTERN ANAL, V19, P315, DOI 10.1109/34.588001; SRIPRADISVARAKU.T, 1989, P IEEE WORKSH INT 3D, P109; ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734; [No title captured]	37	12	13	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1622	1632		10.1109/TPAMI.2004.130	http://dx.doi.org/10.1109/TPAMI.2004.130			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573822				2022-12-18	WOS:000224388700007
J	Lee, DS				Lee, DS			Substitution deciphering based on HMMs with applications to compressed document processing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						substitution ciphers; HMM; symbolic compression	MODELS	It has been shown that simple substitution ciphers can be solved using statistical methods such as probabilistic relaxation. However, the utility of such solutions has been limited by their inability to cope with noise encountered in practical applications. In this paper, we propose a new solution to substitution deciphering based on hidden Markov models. We show that our algorithm is more accurate than relaxation and much more robust in the presence of noise, making it useful for applications in compressed document processing. Recovering character interpretations from the sequence of cluster identifiers in a symbolically compressed document can be treated as a cipher problem. Although a significant amount of noise is present in the cluster sequence, enough information can be recovered with a robust deciphering algorithm to accomplish certain document analysis tasks. The feasibility of this approach is demonstrated in a multilingual document duplicate detection system.	Ricoh Innovat Inc, Menlo Pk, CA 94025 USA		Lee, DS (corresponding author), Ricoh Innovat Inc, 2882 Sand Hill Rd,Suite 115, Menlo Pk, CA 94025 USA.							CASEY RG, 1968, IEEE T COMPUT, VC 17, P492, DOI 10.1109/TC.1968.226928; Doermann D, 1997, PROC INT CONF DOC, P314, DOI 10.1109/ICDAR.1997.619863; Ganesan R., 1993, Cryptologia, V17, P321, DOI 10.1080/0161-119391867980; Haffner P., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P625, DOI 10.1109/ICDAR.1999.791865; Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380; Hull JJ, 2001, COMPUTER, V34, P30, DOI 10.1109/2.910891; HUNTER DGN, 1983, COMPUT J, V26, P68, DOI 10.1093/comjnl/26.1.68; King J. C., 1992, Cryptologia, V16, P215, DOI 10.1080/0161-119291866892; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; LEE DS, 1999, P 5 INT C DOC AN REC, P305; NAGY G, 1987, IEEE T PATTERN ANAL, V9, P710, DOI 10.1109/TPAMI.1987.4767969; PELEG S, 1979, COMMUN ACM, V22, P598, DOI 10.1145/359168.359174; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Salton G., 1989, AUTOMATIC TEXT PROCE; Witten I.H., 1994, MANAGING GIGABYTES C	15	12	29	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1661	1666		10.1109/TPAMI.2002.1114860	http://dx.doi.org/10.1109/TPAMI.2002.1114860			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA					2022-12-18	WOS:000179444600011
J	Xue, HH; Govindaraju, V				Xue, HH; Govindaraju, V			On the dependence of handwritten word recognizers on lexicons	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting recognition; word recognition; performance prediction; performance model; multiple regression	RECOGNITION; SEGMENTATION; DISTANCE	The performance of any word recognizer depends on the lexicon presented. Usually, large lexicons or lexicons containing similar entries pose difficulty for recognizers. However, the literature lacks any quantitative methodology of capturing the precise dependence between word recognizers and lexicons. This paper presents a performance model that views word recognition as a function of character recognition and statistically "discovers" the relation between a word recognizer and the lexicon. It uses model parameters that capture a recognizer's ability of distinguishing characters (of the alphabet) and its sensitivity to lexicon size. The se parameters are determined by a multiple regression model which is derived from the performance model. Such a model is very useful in comparing word recognizers by predicting their performance based on the lexicon presented. We demonstrate the performance model with extensive experiments on five different word recognizers, thousands of images, and tens of lexicons. The results show that the model is a good fit not only on the training data but also in predicting the recognizers' performance on testing data.	SUNY Buffalo, Ctr Excellence Document Anal & Recognit, Buffalo, NY 14260 USA; SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Xue, HH (corresponding author), SUNY Buffalo, Ctr Excellence Document Anal & Recognit, Buffalo, NY 14260 USA.	hxue@cedar.buffalo.edu; govind@cedar.buffalo.edu						ABRAMOWTIZ M, 1964, HDB MATH FUNCTIONS; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; Bahlmann C, 2001, PROC INT CONF DOC, P406, DOI 10.1109/ICDAR.2001.953822; BAIRD HS, 2000, IAPR WORKSH DOC AN S; Baird HS., 1992, STRUCTURED DOCUMENT, P546, DOI [10.1007/978-3-642-77281-8_26, DOI 10.1007/978-3-642-77281-8_26]; CHEN M, 1993, THESIS STATE U NY BU; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; Cole R., 1998, SURVEY STATE ART HUM; Dzuba G, 1998, P 6 INT WORKSH FRONT, P99; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; Favata J, 1996, P 5 INT WORKSH FRONT, P437; Govindaraju V, 2002, IEEE T PATTERN ANAL, V24, P789, DOI 10.1109/TPAMI.2002.1008385; Grandidier F., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P777, DOI 10.1109/ICDAR.1999.791903; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067, DOI 10.1109/34.625107; HO TK, 1995, P 3 INT C DOC AN REC, P278; JUANG BH, 1985, AT&T TECH J, V64, P391, DOI 10.1002/j.1538-7305.1985.tb00439.x; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; Marti UV, 2001, PROC INT CONF DOC, P260, DOI 10.1109/ICDAR.2001.953795; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; PARK J, 2000, IEEE C COMP VIS PATT; Seni G, 1996, PATTERN RECOGN, V29, P405, DOI 10.1016/0031-3203(95)00102-6; Slavik P, 2000, LECT NOTES COMPUT SC, V1857, P310; SLAVIK P, 2000, 09 STAT U NEW YORK B; XUE H, 2001, P 6 INT C DOC AN REC	26	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1553	1564		10.1109/TPAMI.2002.1114848	http://dx.doi.org/10.1109/TPAMI.2002.1114848			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA					2022-12-18	WOS:000179444600001
J	Boccignone, G; Ferraro, M; Caelli, T				Boccignone, G; Ferraro, M; Caelli, T			Generalized spatio-chromatic diffusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color images; scale-space; vector-valued diffusion	ANISOTROPIC DIFFUSION; SCALE-SPACE; COLOR; IMAGES; ENHANCEMENT; EDGE	In this paper, a framework for diffusion of color images is presented. The method is based on the theory of thermodynamics of irreversible transformations which provides a suitable basis for designing correlations between the different color channels. More precisely, we derive an equation for color evolution which comprises a purely spatial diffusive term and a nonlinear term that depends on the interactions among color channels over space. We apply the proposed equation to images represented in several color spaces, such as RGB, CIELAB, Opponent colors, and IHS.	Univ Salerno, Dipartimento Ingn Informat & Ingn Elettr, I-84084 Fisciano, SA, Italy; Univ Salerno, Natl Inst Phys Matter, I-84084 Fisciano, SA, Italy; Univ Turin, Inst Phys Matter, Dipartimento Fis Sperimentale, I-10125 Turin, Italy; Univ Turin, Inst Phys Matter, Natl Inst Phys Matter, I-10125 Turin, Italy; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2H1, Canada	University of Salerno; Consiglio Nazionale delle Ricerche (CNR); Istituto Nazionale per la Fisica della Materia (INFM-CNR); University of Salerno; University of Turin; Consiglio Nazionale delle Ricerche (CNR); Istituto Nazionale per la Fisica della Materia (INFM-CNR); University of Turin; University of Alberta	Boccignone, G (corresponding author), Univ Salerno, Dipartimento Ingn Informat & Ingn Elettr, Via Ponte Don Melillo 1, I-84084 Fisciano, SA, Italy.		Boccignone, Giuseppe/AAH-4459-2020; Boccignone, Giuseppe/G-7542-2012	Boccignone, Giuseppe/0000-0002-5572-0924; Boccignone, Giuseppe/0000-0002-5572-0924; Caelli, Terry/0000-0001-9281-2556				Ballard D.H., 1982, COMPUTER VISION; Boccignone G, 2001, IEEE T PATTERN ANAL, V23, P207, DOI 10.1109/34.908970; CAELLI T, 1993, PATTERN RECOGN, V26, P461, DOI 10.1016/0031-3203(93)90102-3; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CARRON T, 1994, P IEEE INT C IM PROC, V3, P977; de Groot S.R., 1984, NONEQUILIBRIUM THERM; Dresp B, 1999, VISION RES, V39, P3431, DOI 10.1016/S0042-6989(99)00026-7; Ferraro M, 1999, IEEE T PATTERN ANAL, V21, P1199, DOI 10.1109/34.809112; Florack L, 2001, J MATH IMAGING VIS, V15, P39, DOI 10.1023/A:1011221614364; Florack LMJ, 1997, IMAGE STRUCTURE; Grindrod P., 1991, PATTERNS WAVES; Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P573, DOI 10.1109/CVPR.1999.786996; LINDEBERG T, 1999, SCALE SPACE THEORY C; LINDEBERG T, 1994, P 3 EUR C COMP VIS S, V800, P389; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195; Pitas I., 2000, DIGITAL IMAGE PROCES; ROESMANS M, 1994, GEOMETRY DRIVEN DIFF; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563; Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; WEICKERT J, 1997, P 7 NAT S PATT REC I, V1, P239; Wendell B.A., 1995, FDN VISION; WHITAKER R, 1994, GOEMETRY DRIVEN DIFF; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	33	12	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1298	1309		10.1109/TPAMI.2002.1039202	http://dx.doi.org/10.1109/TPAMI.2002.1039202			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300001
J	Chau, T				Chau, T			Marginal maximum entropy partitioning yields asymptotically consistent probability density functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						marginal maximum entropy; recursive partitioning; pattern discovery; asymptotic optimal classification	CLASSIFICATION	The marginal maximum entropy criterion has been used to guide recursive partitioning of a continuous sample space. Although the criterion has been successfully applied in pattern discovery applications, its theoretical justification has not been clearly addressed. In this paper, it is shown that the basic marginal maximum entropy partitioning algorithm yields asymptotically consistent density estimates. This result supports the use of the marginal maximum entropy criterion in pattern discovery and implies that an optimal classifier can be constructed.	Univ Toronto, Bloorview MacMillan Ctr, Toronto, ON, Canada; Univ Toronto, Inst Biomat & Biomed Engn, Toronto, ON, Canada	University of Toronto; University Toronto Affiliates; Holland Bloorview Kids Rehabilitation Hospital; University of Toronto	Chau, T (corresponding author), Univ Toronto, Bloorview MacMillan Ctr, Toronto, ON, Canada.	ttkchau@ieee.org	Chau, Tom TK/C-8426-2009	Chau, Tom TK/0000-0002-7486-0316				Agresti A., 1990, CATEGORICAL DATA ANA, pXV; Chau T, 1999, IEEE T KNOWL DATA EN, V11, P833, DOI 10.1109/69.824592; Chiu D. K. Y., 1990, Journal of Experimental and Theoretical Artificial Intelligence, V2, P117, DOI 10.1080/09528139008953718; Christensen R., 1990, LOG LINEAR MODELS; Duda R.O., 1973, J ROYAL STAT SOC SER; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404, DOI 10.1109/TC.1977.1674849; GORDON L, 1978, ANN STAT, V6, P515, DOI 10.1214/aos/1176344197; HASKELL RE, 1991, LECT NOTES COMPUT SC, V507, P118; HENRICHON EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Lancaster H. O., 1969, CHI SQUARED DISTRIBU; LASCURAIN M, 1983, THESIS U WATERLOO WA; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; Melo A.C.G., 1991, IEE P C, V138; MURTHY SK, 1998, DATA MIN KNOWL DISC, P345; Papoulis A., 1991, COMMUNICATIONS SIGNA, V3; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; SONGQUIST JA, 1973, SEARCHING STRUCTURE; WONG AKC, 1987, KNOWLEDGE DISCOVERY, P125; [No title captured]	21	12	12	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					414	417		10.1109/34.917576	http://dx.doi.org/10.1109/34.917576			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900007
J	Oliensis, J; Govindu, V				Oliensis, J; Govindu, V			An experimental study of projective structure from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; projective geometry; calibration; experimental verification; multiframe structure from motion; optimization; local minima; Levenberg-Marquardt		We describe an essentially algorithm-independent experimental comparison of projective versus Euclidean reconstruction. The Euclidean approach is as accurate as the projective one, even with significant calibration error and for the pure projective structure. Projective optimization has less of a local-minima problem than its Euclidean equivalent. We describe techniques that enhance the convergence of optimization algorithms.	NEC Res Inst, Princeton, NJ 08540 USA; Univ Maryland, Dept Elect Engn, College Pk, MD 20742 USA; Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	NEC Corporation; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Oliensis, J (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.							Faugeras O., 1992, EUR C COMP VIS, P563; HARTLEY R, 1993, 2 WORKSH INV AZ, P187; Hartley R., 1995, ICCV, P1064; HARTLEY RI, 1992, ECCV, P579; KUMAR R, 1990, ICCV, P365; OLIENSIS J, 1997, 97028 NECI; OLIENSIS J, 1996, CVPR, P335; OLIENSIS J, 1997, 97112 NECI; OLIENSIS J, IN PRESS COMPUTER VI; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; TAYLOR CJ, 1991, WORKSH VIS MOT, P242	11	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					665	671		10.1109/34.777379	http://dx.doi.org/10.1109/34.777379			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT					2022-12-18	WOS:000081472600011
J	Borges, CF				Borges, CF			On the estimation of Markov random field parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; parameter estimation		We examine the histogram method proposed in [1] for estimating the parameters associated with a Markov random field. This method relies on the estimation of the local interaction sums from histogram data. We derive an estimator for these quantities that is optimal in a well-defined sense. Furthermore. we show that the final step of the histogram method, the solution of a least-squares problem. can be done substantially faster than one might expect it no equation culling is used. We also examine the use of weighted least-squares and see that this seems to lead to better estimates even with smalt amounts of data.	USN, Postgrad Sch, Monterey, CA 93943 USA	United States Department of Defense; United States Navy; Naval Postgraduate School	Borges, CF (corresponding author), USN, Postgrad Sch, Code MA-BC, Monterey, CA 93943 USA.		Borges, Carlos/E-3157-2010					BESAG J, 1974, J ROYAL STAT SOC B, V2; CALDER B, 1995, IEE E4 C MULTR IM PR; CROSS GR, 1983, IEEE T PATTERN ANAL, V5; DERIN H, 1987, IEEE T PATTERN ANAL, V9; Gauss C. F., 1995, CLASSICS APPL MATH; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GURELLI M, 1994, IEEE T PATTERN ANAL, V16	7	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					216	224		10.1109/34.754587	http://dx.doi.org/10.1109/34.754587			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD		Green Submitted			2022-12-18	WOS:000079296000003
J	Shimshoni, I; Basri, R; Rivlin, E				Shimshoni, I; Basri, R; Rivlin, E			A geometric interpretation of weak-perspective motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						weak-perspective projection; structure from motion	FACTORIZATION METHOD; RECOVERY; AFFINE; SHAPE	We present a geometric interpretation of the problem of motion recovery from three weak-perspective images. Our interpretation is based on reducing the problem of estimating the motion to a problem of finding triangles on a sphere whose angles are known. Using this geometric interpretation, a simple method to completely recover the motion parameters using three images is developed. The results of running the algorithm on real images are presented. In addition, we describe which of the various motion parameters can be recovered already from two images.	Technion Israel Inst Technol, Dept Ind Engn & Management, IL-32000 Haifa, Israel; Weizmann Inst Sci, Dept Appl Math, IL-76100 Rehovot, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology; Weizmann Institute of Science; Technion Israel Institute of Technology	Shimshoni, I (corresponding author), Technion Israel Inst Technol, Dept Ind Engn & Management, IL-32000 Haifa, Israel.							ALOIMONOS JY, 1990, IMAGE VISION COMPUT, V8, P179, DOI 10.1016/0262-8856(90)90064-C; Basri R, 1996, INT J COMPUT VISION, V19, P169, DOI 10.1007/BF00055803; Costeira J., 1995, ICCV, P1071; DEBRUNNER C, 1992, P 2 EUR C COMP VIS, P217; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEAR WC, 1994, IEEE WORKSH NONR ART; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; Koenderink J., 1990, SOLID SHAPE; KONTSEVICH LL, 1993, J OPT SOC AM A, V10, P1129, DOI 10.1364/JOSAA.10.001129; LEE CH, 1990, COMPUT VISION GRAPH, V52, P309, DOI 10.1016/0734-189X(90)90078-A; OHTA Y, 1991, P INT JOINT C ART IN, P746; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULMANN S, 1991, T PATTERN ANAL MACHI, V13, P992	16	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					252	257		10.1109/34.754615	http://dx.doi.org/10.1109/34.754615			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD		Green Published			2022-12-18	WOS:000079296000007
J	Chen, WT; Gader, P; Shi, HC				Chen, WT; Gader, P; Shi, HC			Lexicon-driven handwritten word recognition using optimal linear combinations of order statistics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						lexicon-driven; handwritten word recognition; linear combination of order statistics; dynamic programming; normalized edit distance; fuzzy integrals		In the standard segmentation-based approach to handwritten word recognition, individual character-class confidence scores are combined via averaging to estimate confidences in the hypothesized identities for a word. We describe a methodology for generating optimal Linear Combination of Order Statistics operators for combining character class confidence scores. Experimental results are provided on over 1,000 word images.	Univ Missouri, Dept Comp Engn & Comp Sci, Columbia, MO 65211 USA; Univ Missouri, Dept Elect Engn, Columbia, MO 65211 USA	University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia	Chen, WT (corresponding author), Univ Missouri, Dept Comp Engn & Comp Sci, 201 Engn Bldg W, Columbia, MO 65211 USA.	wchen@ece.missouri.edu; gader@cecs.missouri.edu; shi@cecs.missouri.edu						Bovik A., 1983, IEEE T ACOUSTICS SPE, V31; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; Chiang JH, 1997, IEEE T FUZZY SYST, V5, P497, DOI 10.1109/91.649901; COTE M, 1998, P INT C DOC AN REC U; DZUBA G, 1997, P INT C DOC AN REC U; El-Yacoubi A, 1998, INT C PATT RECOG, P1521, DOI 10.1109/ICPR.1998.711997; FAVATA J, 1977, P INT C DOC AN REC U; Gadea PM, 1996, INDIAN J PURE AP MAT, V27, P1; GADER P, 1995, IEEE T FUZZY SYST, V3, P357, DOI 10.1109/91.413223; GADER P, 1995, MACH VISION APPL, V8, P31, DOI 10.1007/BF01213636; Gader PD, 1996, PATTERN RECOGN LETT, V17, P577, DOI 10.1016/0167-8655(96)00021-9; Gader PD, 1997, COMPUTER, V30, P79, DOI 10.1109/2.566164; Gader PD, 1996, J ELECTRON IMAGING, V5, P15, DOI 10.1117/12.228053; GADER PD, 1994, DIGITAL IMAGE PROCES, P223; GILLIES AM, 1993, HANDWRITTEN ADDRESS; GOVINDARAJU V, 1995, P IEEE C SMC VANC BC, P2347; GRABISCH M, 1994, FUZZY SET SYST, V65, P255, DOI 10.1016/0165-0114(94)90023-X; Guillevic D, 1998, INT C PATT RECOG, P1526, DOI 10.1109/ICPR.1998.711998; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; KIM G, 1995, P 3 INT C DOC AN REC, P24; KIMURA F, 1993, P 3 INT WORKSH FRONT, P122; Knerr S, 1998, INT C PATT RECOG, P1518, DOI 10.1109/ICPR.1998.711996; Lecolinet E., 1991, P 1 INT C DOC AN REC, P740; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; Nemhauser G.L., 1988, INTEGER COMBINATORIA; PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071; PLESSIS B, 1992, P US POST SERV ADV T, P579; SHI H, 1996, P IEEE C SYST MAN CY, P412; SHRIDHAR M, 1995, P IEEE C SYST MAN CY; SHRIDHAR M, 1997, P INT C DOC AN REC U; Sinha P, 1998, INT C PATT RECOG, P436, DOI 10.1109/ICPR.1998.711174	31	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					77	82		10.1109/34.745738	http://dx.doi.org/10.1109/34.745738			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900011
J	Lee, EW; Chae, SI				Lee, EW; Chae, SI			Fast design of reduced-complexity nearest-neighbor classifiers using triangular inequality	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest-neighbor classifier; triangular inequality; computational complexity; NIST database; fast design	VECTOR QUANTIZATION; ALGORITHM	In this paper, we propose a method of designing a reduced complexity nearest-neighbor (RCNN) classifier with near-minimal computational complexity from a given nearest-neighbor classifier that has high input dimensionality and a large number of class vectors. We applied our method to the classification problem of handwritten numerals in the NLST database, if the complexity of the RCNN classifier is normalized to that of the given classifier, the complexity of the derived classifier is 62 percent, 2 percent higher than that of the optimal classifier. This was found using the exhaustive search.	Seoul Natl Univ, Sch Elect Engn, Seoul 151742, South Korea	Seoul National University (SNU)	Lee, EW (corresponding author), Seoul Natl Univ, Sch Elect Engn, San 56-1, Seoul 151742, South Korea.		Lee, Ealwan/E-8550-2017	Lee, Ealwan/0000-0001-6199-9020				Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Duda R.O., 1973, J ROYAL STAT SOC SER; FISHER FP, 1970, P NATL EL C DEC, V26, P481; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GERSHO A, 1992, VECTOR QUANTIZER SIG; Huang CM, 1992, IEEE T IMAGE PROCESS, V1, P413, DOI 10.1109/83.148613; LI WH, 1995, IEEE T CIRC SYST VID, V5, P119, DOI 10.1109/76.388060; *NIST, 221A323 NIST; POGGI G, 1993, ELECTRON LETT, V29, P1141, DOI 10.1049/el:19930761; Pratt W, 1991, DIGITAL IMAGE PROCES; RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335	11	12	13	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					562	566		10.1109/34.682187	http://dx.doi.org/10.1109/34.682187			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600013
J	Kam, AC; Kopec, GE				Kam, AC; Kopec, GE			Document image decoding by heuristic search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image decoding; Markov models; heuristic search; dynamic programming	MODELS	This correspondence describes an approach to reducing the computational cost of document image decoding by viewing it as a heuristic search problem. The kernel of the approach is a modified dynamic programming (DP) algorithm, called the iterated complete path (ICP) algorithm, that is intended for use with separable source models. A set of heuristic functions are presented for decoding formatted text with ICP. Speedups of 3-25 over DP have been observed when decoding text columns and telephone yellow pages using ICP and the proposed heuristics.	MIT,CAMBRIDGE,MA 02139; XEROX CORP,PALO ALTO RES CTR,PALO ALTO,CA 94304	Massachusetts Institute of Technology (MIT); Xerox								CHEN F, 1995, P SOC PHOTO-OPT INS, V2, P256; KAM A, 1995, P SOC PHOTO-OPT INS, V2, P84; KAM A, 1993, THESIS; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; *PAC BELL, SMART YELL PAG; Pearl J., 1984, INTELLIGENT SEARCH S	7	12	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					945	950		10.1109/34.537350	http://dx.doi.org/10.1109/34.537350			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900010
J	Nadabar, SG; Jain, AK				Nadabar, SG; Jain, AK			Parameter estimation in Markov random field contextual models using geometric models of objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; line process; clique potentials; parameter estimation; edge detection; CAD models; range mage	GIBBS RANDOM-FIELDS; SPATIAL-INTERACTION; IMAGES; SEGMENTATION	We present a new scheme for the estimation of Markov random field line process parameters which uses geometric CAD models of the objects in the scene. the models:are used to generate synthetic images of the objects from random viewpoints. the edge maps computed from the synthesized images are used as training samples to estimate the line process parameters using a least squares method. We show that this parameter estimation method is useful for detecting edges in range as well as intensity edges. The main contributions of the paper are: i) use of CAD models to obtain true edge labels which are otherwise not available, and ii) use of canonical MRF representation ttl reduce the number-of parameters.	MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University	Nadabar, SG (corresponding author), INNOVIS CORP,8017 EXELSIOR DR,MADISON,WI 53717, USA.							BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Griffeath D., 1976, DENUMERABLE MARKOV C; JAIN AK, 1990, P 3 IEEE INT C COMP, P677; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; NADABAR SG, 1992, THESIS MICHIGAN STAT	13	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					326	329		10.1109/34.485560	http://dx.doi.org/10.1109/34.485560			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500009
J	Chen, JL; Stockman, GC				Chen, JL; Stockman, GC			Determining pose of 3D objects with curved surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose determination; 3D objects; object tracking; object modeling; image matching; recognition by alignment	IMAGES	A method is presented for computing the pose of rigid 3D objects with arbitrary curved surfaces. Given an input image and a candidate object model and aspect, the method will verify whether or not the object is present acid if so, report pose parameters. The curvature method of Basri and Ullman is used to model points on the object rim, while stereo matching is used for internal edge points. The model allows an object edgemap to be predicted from pose parameters. Pose is computed via an iterative search for the best pose parameters. Heuristics are used so that matching can succeed in the presence of occlusion and artifact and without resorting to use of corresponding salient feature points. Bench tests and simulations show that the method almost always converges to ground truth pose parameters for a variety of objects and for a broad set of starting parameters in the same aspect.			Chen, JL (corresponding author), MICHIGAN STATE UNIV,PATTERN RECOGNIT & IMAGE PROC LAB,E LANSING,MI 48824, USA.							BAJCSY R, 1987, 1ST P INT C COMP VIS, P231; Basri R., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P482, DOI 10.1109/CCV.1988.590027; BOWYER K, 1989, MAY P IM UND WORKSH, P831; CHEN JL, 1993, JUN P IEEE C COMP VI, P233; GOAD C, 1983, P DARPA IMAGE UNDERS; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; GUPTA A, 1991, THESIS U PENNSYLVANI; HIGUCHI K, 1994, 2ND P IEEE CAD BAS V, P124; KEREN D, 1991, IEEE T PATTERN ANAL, V16, P38; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; PENTLAND A, 1994, JUN P IEEE C COMP VI, P84; PONCE J, 1994, JUN P IEEE C COMP VI, P147; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; ULLMAN S, 1986, MIT931 AI LAB TECHN	17	12	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					52	57		10.1109/34.476010	http://dx.doi.org/10.1109/34.476010			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500005
J	ASTROM, K				ASTROM, K			FUNDAMENTAL LIMITATIONS ON PROJECTIVE INVARIANTS OF PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						PROJECTIVE AND AFFINE INVARIANTS; RECOGNITION; HAUSDORFF METRIC		In this paper, some fundamental limitations of projective invariants of non-algebraic planar curves are discussed. It is shown that all curves within a large class can be mapped arbitrarily close to a circle by projective transformations. It is also shown that arbitrarily close to each of a finite number of closed planar curves there is one member of a set of projectively equivalent curves. Thus a continuous projective invariant on closed curves is constant. This also limits the possibility of finding so called projective normalisation schemes for closed planar curves.			ASTROM, K (corresponding author), LUND UNIV, DEPT MATH, S-22100 LUND, SWEDEN.		Åström, Kalle/C-2836-2009; Astrom, Kalle/AAT-9538-2020	Åström, Kalle/0000-0002-8689-7810; Astrom, Kalle/0000-0002-8689-7810				ASTROM K, 1993, 8TH P SCAND C IM AN, P769; ASTROM K, 1994, 3RD P ECCV STOCKH, V2, P439; ASTROM K, 1992, P S IM AN SWED, P141; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BLAKE A, 1994, IEEE PAMI, V16, P769; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BURNS JB, 1992, GEOMETRICAL INVARIAN; Carlsson S., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P471, DOI 10.1109/ICCV.1993.378178; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Mundy J., 1992, GEOMETRIC INVARIANCE; ROTHWELL C, 1992, 2ND P EUR C COMP VIS, P757	11	12	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					77	81		10.1109/34.368148	http://dx.doi.org/10.1109/34.368148			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400010
J	BELLEGARDA, EJ; BELLEGARDA, JR; NAHAMOO, D; NATHAN, KS				BELLEGARDA, EJ; BELLEGARDA, JR; NAHAMOO, D; NATHAN, KS			A FAST STATISTICAL MIXTURE ALGORITHM FOR ONLINE HANDWRITING RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ONLINE HANDWRITING RECOGNITION; STATISTICAL MODELING; FRAME-BASED PROCESSING; MIXTURE OUTPUT DISTRIBUTIONS	SPEECH RECOGNITION	The automatic recognition of on-line handwriting is considered From an information theoretic viewpoint. Emphasis is placed on the recognition of unconstrained handwriting, a general combination of cursively written word fragments and discretely written characters. Existing recognition algorithms, such as elastic matching, are severely challenged by the variability inherent to unconstrained handwriting. This motivates the development of a probabilistic: framework suitable to the derivation of a fast statistical mixture algorithm. This algorithm exhibits about the same degree of complexity as elastic matching, while being more flexible and potentially more robust. The approach relies on a novel front-end processor that, unlike conventional character or stroke-based processing, articulates around a small elementary unit of handwriting called a frame. The algorithm is based on 1) producing feature vectors representing each frame in one (or several) feature spaces, 2) Gaussian ii-means clustering in these spaces, and 3) mixture modeling taking into account the contributions of all relevant clusters in each space. The approach is illustrated on a simple task involving a 81-character alphabet. Both writer-dependent and writer-independent recognition results are found to be competitive with their elastic matching counterparts.			BELLEGARDA, EJ (corresponding author), IBM CORP,THOMAS J WATSON RES CTR,YORKTOWN HTS,NY 10598, USA.							BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Baum LE, 1972, INEQUALITIES, V3, P1; Bellegarda EJ, 1993, 3RD P INT WORKSH FRO, P225; BELLEGARDA JR, 1990, IEEE T ACOUST SPEECH, V38, P2033, DOI 10.1109/29.61531; FUJISAKI T, 1993, 3RD P INT WORKSH FRO, P235; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Jelinek F., 1969, IBM Journal of Research and Development, V13, P675, DOI 10.1147/rd.136.0675; MORASSO P, 1990, 1990 P INT NEUR NETW, P141; Nilsson N.J., 1971, PROBLEM SOLVING METH; Tappert C. C., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P79, DOI 10.1142/S0218001491000077; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TEULINGS HL, 1991, 2ND P INT WORKSH FRO, P45	13	12	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1227	1233		10.1109/34.387484	http://dx.doi.org/10.1109/34.387484			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500008
J	TANAKA, E				TANAKA, E			A METRIC BETWEEN UNROOTED AND UNORDERED TREES ACID ITS BOTTOM-UP COMPUTING METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DISTANCE; DYNAMIC PROGRAMMING; PATTERN MATCHING; PATTERN RECOGNITION; SIMILAR STRUCTURE SEARCH; SIMILARITY; TREE	EDITING DISTANCE; ALGORITHM	This correspondence proposes a distance between unrooted and unordered trees based on the strongly structure preserving mapping (SSPM). SSPM can make correspondences between the vertices of similar substructures of given structures more strictly than the already proposed mappings. The time complexity of computing the distance between trees Ta and Tb is O-T(m(b)(3)NaNb), where Na(Nb) and m(a)(m(b)) are the number of vertices in tree Ta(Tb) and the maximum degree of a vertex in Ta(Tb), respectively, and m(a) less than or equal to m(b) is assumed. The space complexity of the method is O-S(NaNb).			TANAKA, E (corresponding author), KOBE UNIV,FAC ENGN,DEPT ELECT & ELECTR ENGN,NADA KU,KOBE 657,JAPAN.							HICKS MG, 1990, J CHEM INF COMP SCI, V30, P191, DOI 10.1021/ci00066a018; Johnson MA, 1989, J MATH CHEM, V3, P117, DOI 10.1007/BF01166045; Lawler E. L., 2001, COMBINATORIAL OPTIMI; LU SY, 1979, IEEE T PATTERN ANAL, V1, P219, DOI 10.1109/TPAMI.1979.6786615; LU SY, 1984, IEEE T PATTERN ANAL, V6, P249, DOI 10.1109/TPAMI.1984.4767511; MUGURUMA T, 1994, T IEICE E, V77, P555; SELKOW SM, 1977, INFORM PROCESS LETT, V6, P184, DOI 10.1016/0020-0190(77)90064-3; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHASHA D, 1990, J ALGORITHM, V11, P581, DOI 10.1016/0196-6774(90)90011-3; SUSSENGUTH EH, 1965, J CHEM DOC, V5, P36, DOI 10.1021/c160016a007; TAI KC, 1979, J ACM, V26, P422, DOI 10.1145/322139.322143; TAKAHASHI Y, 1987, ANAL SCI, V3, P23; Tanaka E., 1984, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ67D, P722; TANAKA E, 1982, T IECE J, V65, P511; TANAKA E, 1993, T IEICE DI, V76, P635; TSAI WH, 1979, IEEE T SYST MAN CYB, V12, P757; Willett P., 1987, SIMILARITY CLUSTERIN; WONG AKC, 1990, IEEE T SYST MAN CYB, V20, P628, DOI 10.1109/21.57275; ZHANG KZ, 1992, INFORM PROCESS LETT, V42, P133, DOI 10.1016/0020-0190(92)90136-J	19	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1233	1238		10.1109/34.387483	http://dx.doi.org/10.1109/34.387483			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500009
J	KOTTKE, DP; SUN, Y				KOTTKE, DP; SUN, Y			MOTION ESTIMATION VIA CLUSTER MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DISPLACEMENT ESTIMATION; CLUSTER MATCHING; AFFINE MOTION MODEL; CLUSTERING; VARIABLE OBJECT BRIGHTNESS	FLOW	A new method for estimating displacements in computer imagery through cluster matching is presented. Without reliance on any object model, the algorithm clusters two successive frames of an image sequence based on position and intensity. After clustering, displacement estimates are obtained by matching the cluster centers between the two frames using cluster features such as position, intensity, shape and average gray-scale difference. The performance of the algorithm was compared to that of a gradient method and a block matching method. The cluster matching approach showed the best performance over a broad range of motion, illumination change and object deformation.	UNIV RHODE ISL,DEPT ELECT ENGN,KINGSTON,RI 02881	University of Rhode Island								AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Bandopadhay A., 1990, International Journal of Imaging Systems and Technology, V2, P345, DOI 10.1002/ima.1850020409; FU CS, 1991, OPTICAL ENG, V30, P881; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; Tou JT, 1974, PATTERN RECOGN; VERRI A, 1990, J OPT SOC AM A, V7, P912, DOI 10.1364/JOSAA.7.000912	6	12	40	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1128	1132		10.1109/34.334394	http://dx.doi.org/10.1109/34.334394			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100008
J	ZHUANG, XH; HUANG, Y				ZHUANG, XH; HUANG, Y			ROBUST 3-D 3-D POSE ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						MULTIPLE POSE ESTIMATION; GENERAL REGRESSION; CONTAMINATED GAUSSIAN DISTRIBUTION; CONTAMINATED GAUSSIAN MIXTURE DISTRIBUTION	IMAGES	The correspondence focuses on the robust 3-D-3-D pose estimation, especially, multiple pose, estimation. The robust 3-D-3-D multiple pose estimation problem is formulated as a series of general regressions which involve a successively size-decreasing data set, with each regression relating to one particular pose of interest. Since the first few regressions may carry a severely contaminated Gaussian error noise model, the MF-estimator (Zhuang et al., 1992) is used to solve each regression for each pose of interest. Extensive computer experiments with both real imagery and simulated data are conducted and results are promising. Three distinctive features of the MF-estimator are theoretically discussed and experimentally demonstrated: 1) It is highly robust in the sense that it is not much affected by a possible large portion of outliers or incorrect matches as long as the minimum number of inliers necessary to give a unique solution are provided; 2) It is made virtually independent of initial guesses; 3) It is computationally reasonable and admits an efficient parallel implementation.			ZHUANG, XH (corresponding author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65211, USA.							BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; HAMPEL FR, 1986, ROBUST STATISTICS AP; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HUANG TS, 1985, IEEE C COMPUTER VISI, P518; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; RUBINSTEIN RY, 1986, MONTO CARLO OPTIMIZA; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853; WENG J, 1990, OCT P IEEE INT WORKS, P367; WENG J, 1989, 2ND P INT C COMP VIS, P64; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666; ZHUANG X, 1990, 10TH P INT C PATT RE, V1, P545; ZHUANG XH, 1992, IEEE T PATTERN ANAL, V14, P19, DOI 10.1109/34.107011	12	12	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					818	824		10.1109/34.308478	http://dx.doi.org/10.1109/34.308478			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500008
J	GURELLI, MI; ONURAL, L				GURELLI, MI; ONURAL, L			ON A PARAMETER-ESTIMATION METHOD FOR GIBBS-MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						IMAGE MODELING; TEXTURE; GIBBS-MARKOV RANDOM FIELDS; PARAMETER ESTIMATION; PATTERN RECOGNITION	STATISTICAL-ANALYSIS; SPATIAL INTERACTION; SEGMENTATION; MODELS; IMAGES; DISTRIBUTIONS; RESTORATION; NOISY	This correspondence is about a Gibbs-Markov random field (GMRF) parameter estimation technique proposed by Derin and Elliott. We will refer to this technique as the histogramming (H) method. First, the relation of the H method to the (conditional) maximum likelihood (ML) method is considered. Second, a bias-reduction based modification of the H method is proposed to improve its performance, especially in the case of small amounts of image data.	BILKNET UNIV,DEPT ELECT & ELECTR ENGN,ANKARA 06533,TURKEY	Ihsan Dogramaci Bilkent University								ACUNA CO, 1992, CVGIP-GRAPH MODEL IM, V54, P210, DOI 10.1016/1049-9652(92)90052-Y; AHUJA N, 1981, IEEE T PATTERN ANAL, V3, P1, DOI 10.1109/TPAMI.1981.4767045; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; CHELLAPPA R, 1982, IEEE T ACOUST SPEECH, V30, P461, DOI 10.1109/TASSP.1982.1163911; COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P289; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DEGUCHI K, 1978, IEEE T COMPUT, V27, P739, DOI 10.1109/TC.1978.1675181; DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C	14	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					424	430		10.1109/34.277597	http://dx.doi.org/10.1109/34.277597			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607		Green Submitted			2022-12-18	WOS:A1994NH60700010
J	SAY, ACC; KURU, S				SAY, ACC; KURU, S			IMPROVED FILTERING FOR THE QSIM ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						ARTIFICIAL INTELLIGENCE; CONSTRAINT FILTERING; QUALITATIVE ARITHMETIC; QUALITATIVE REASONING; QUALITATIVE SIMULATION	SIMULATION	We have identified a source of spurious predictions inside Kuipers' qualitative simulation algorithm QSIM. Our proposed solution involves the use of interval corresponding values for filtering inconsistent states and does not require any additions or restrictions in the input set, unlike the other approaches to the spurious prediction elimination problem. The time and space complexities of the algorithm are not affected by the modification.			SAY, ACC (corresponding author), BOGAZICI UNIV,DEPT COMP ENGN,ISTANBUL,TURKEY.			Say, A. C. Cem/0000-0002-4374-8460				KUIPERS B, 1989, AUTOMATICA, V25, P571, DOI 10.1016/0005-1098(89)90099-X; KUIPERS B, 1986, ARTIF INTELL, V29, P289, DOI 10.1016/0004-3702(86)90073-1; KUIPERS B, 1987, 10TH P INT JOINT C A, P1079; KUIPERS B, 1989, AITR89117 U TEX AUST; LEE WW, 1988, 7TH P NAT C ART INT, P286; SAY ACC, 1992, THESIS BOGAZIC U IST	6	12	12	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					967	971		10.1109/34.232085	http://dx.doi.org/10.1109/34.232085			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600013
J	SPETSAKIS, ME; ALOIMONOS, Y				SPETSAKIS, ME; ALOIMONOS, Y			OPTIMAL VISUAL-MOTION ESTIMATION - A NOTE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CORRESPONDENCE; STRUCTURE FROM MOTION; 3-D MOTION ESTIMATION	3-DIMENSIONAL MOTION; RIGID OBJECTS	We analyze the problem of estimating 3-D motion in an optimal manner using correspondences of features in two views. The importance of having an optimal estimator is twofold: first, for the estimation itself and, second, for the bound it offers on how much sensitivity one can expect from a two-frame, point-based motion algorithm. The optimal estimator turns out to be nonlinear, and for that reason, we developed techniques that provide very good initial guesses for the iterative computation of the optimal estimator.	UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLL PK,MD 20742	University System of Maryland; University of Maryland College Park	SPETSAKIS, ME (corresponding author), YORK UNIV,DEPT COMP SCI,N YORK M3J 1P3,ONTARIO,CANADA.		Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				Adiv G., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P70; AISBETT J, 1991, IEEE T PATTERN ANAL, V12, P1092; Bottema O., 1979, THEORETICAL KINEMATI; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; FAUGERAS OD, 1989, MAR P IEEE WORKSH VI, P248; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HORN BKP, 1988, MIT AI994 MEM; HORN BKP, 1987, P IEEE ICCV; JERIAN C, 1988, 2ND P ICCV TARP SPRI; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; PHILIP J, 1991, IEEE T PATTERN ANAL, V13, P61, DOI 10.1109/34.67631; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P94; SPETSAKIS ME, 1988, DEC P INT C COMP VIS, P449; SPETSAKIS ME, 1988, CARTR389 U MAR COMP; SPETSAKIS ME, 1989, THESIS U MARYLAND CO; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TSAI RY, 1984, P DARPA IMAGE UNDERS; ULLMAN S, 1979, THESIS MIT; WAXMAN AM, 1987, ADV COMPUTER VISION; Weng Juyang, 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P355; 1991, INT J COMPUT VISION, V6, P245	22	12	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1992	14	9					959	964		10.1109/34.161355	http://dx.doi.org/10.1109/34.161355			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JL924					2022-12-18	WOS:A1992JL92400009
J	CHU, CC; AGGARWAL, JK				CHU, CC; AGGARWAL, JK			IMAGE INTERPRETATION USING MULTIPLE SENSING MODALITIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						IMAGE INTERPRETATION; KNOWLEDGE-BASED SYSTEMS; LASER RADAR; MULTISENSOR FUSION; THERMAL IMAGING	SEGMENTATION; REGION	This paper presents the automatic interpretation using multiple sensors (AIMS) system, which is an automatic image interpretation system using registered laser radar and thermal images. Its objective is to detect and recognize man-made objects at kilometer range in outdoor scenes. The multisensor fusion approach is applied to four sensing modalities (range, intensity, velocity, and thermal) to improve both image segmentation and interpretation. Low-level attributes of image segments (regions) are computed by the segmentation modules and then converted to the KEE format. The knowledge-based interpretation modules are constructed using KEE and Lisp. AIMS applies forward chaining in a bottom-up fashion to derive object-level interpretations from databases generated by the low-level processing modules. Segments are grouped into objects, and objects are classified into predefined categories using selected features. The efficiency of the interpretation process is enhanced by transferring nonsymbolic processing tasks to a concurrent service manager (program). A parallel implementation of the interpretation module on a multiple-input multiple-data (MIMD) machine is also reported. Experimental results using real data are presented.	UNIV TEXAS,DEPT ELECT & COMP ENGN,COMP & VIS RES CTR,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								Bachman C.G., 1979, LASER RADAR SYSTEMS; BELKNAP R, 1985, P DARPA IMAGE UNDERS, P279; BHANU B, 1990, IEEE T AERO ELEC SYS, V26, P2, DOI 10.1109/7.53409; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CHU C, 1991, J MACHINE VISION APP, P145; CHU CC, 1988, PATTERN RECOGN, V21, P303, DOI 10.1016/0031-3203(88)90043-X; CHU CC, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P117; CHU CC, 1990, PATTERN RECOGN, V23, P569, DOI 10.1016/0031-3203(90)90035-J; CHU CC, 1991, SEVENTH IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE APPLICATIONS, VOL 1, P190; CLANCEY WJ, 1985, ARTIF INTELL, V27, P289, DOI 10.1016/0004-3702(85)90016-5; DRAPER BA, 1987, P DARPA IMAGE UNDERS, P179; DUDGEON DE, 1989, P DARPA IMAGE UNDERS, P479; FAN TJ, 1988, P DARPA IMAGE UNDERS, P383; GUPTA A, 1988, 17TH P INT C PAR PRO, P271; HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867; Incropera F. P., 1981, FUNDAMENTALS HEAT TR; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; MULDER JA, 1988, IEEE T PATTERN ANAL, V10, P866, DOI 10.1109/34.9108; NANDHAKUMAR N, 1988, IEEE T PATTERN ANAL, V10, P469, DOI 10.1109/34.3911; OHTA Y, 1985, KNOWLEDGE BASED INTE; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; SHAW DE, 1987, PARALLEL COMPUTATION; Tong C. W., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V782, P10, DOI 10.1117/12.940553	24	12	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1992	14	8					840	847		10.1109/34.149595	http://dx.doi.org/10.1109/34.149595			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JG613					2022-12-18	WOS:A1992JG61300005
J	GUTFINGER, D; SKLANSKY, J				GUTFINGER, D; SKLANSKY, J			ROBUST CLASSIFIERS BY MIXED ADAPTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ADAPTATION; CLUSTER ANALYSIS; RELAXATION LABELING; SCENE INVARIANT; SUPERVISED TRAINING; UNSUPERVISED TRAINING	REGION	We show how to produce robust classifiers by combining supervised with unsupervised training. A supervised training phase exploits statistically scene invariant labeled data to produce an initial classifier. This is followed by an unsupervised training phase that exploits clustering properties of unlabeled data. We refer to this two-phase process as mixed adaptation. We present a probabilistic model supporting this technique. We present synthetic and real examples illustrating mixed adaptation. These examples include the detection of unspecified dotted curves in dotted noise and the detection and classification of vehicles in cinematic sequences of infrared imagery.	UNIV CALIF IRVINE,DEPT ELECT ENGN,IRVINE,CA 92717; UNIV CALIF IRVINE,DEPT ELECT & COMP ENGN,IRVINE,CA 92717	University of California System; University of California Irvine; University of California System; University of California Irvine	GUTFINGER, D (corresponding author), FORD AEROSP & COMMUN CORP,ENGN,NEWPORT BEACH,CA 92658, USA.							AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; BACKER E, 1981, IEEE T PATTERN ANAL, V3, P66, DOI 10.1109/TPAMI.1981.4767051; BHANU B, 1982, IEEE T PATTERN ANAL, V4; COOPER DB, 1964, INFORM CONTROL, V7, P416, DOI 10.1016/S0019-9958(64)90502-9; Duda R.O., 1973, J ROYAL STAT SOC SER; FORGY EW, 1965, ABSTRACTS BIOMETRICS, V21; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GUTFINGER D, 1990, TP905 U CAL TECH REP; GUTFINGER D, 1990, TP907 U CAL TECH REP; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KITCHEN L, 1984, PATTERN RECOGN, V17, P189, DOI 10.1016/0031-3203(84)90058-X; Narendra K.S., 1989, STABLE ADAPTIVE SYST; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; ROBERTS GA, 1989, MAR P SPIE AER PATT, V1098, P182; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SKLANSKY J, 1981, PATTERN CLASSIFIERS; TAKEN E, 1979, APPL OPT, V18; Tsypkin Y. Z., 1971, MATH SCI ENG, V73; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4	20	12	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					552	567		10.1109/34.87342	http://dx.doi.org/10.1109/34.87342			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200005
J	SCHNEITER, JL; SHERIDAN, TB				SCHNEITER, JL; SHERIDAN, TB			AN AUTOMATED TACTILE SENSING STRATEGY FOR PLANAR OBJECT RECOGNITION AND LOCALIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,DEPT MECH ENGN,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	SCHNEITER, JL (corresponding author), GE,CTR CORP RES & DEV,SCHENECTADY,NY 12301, USA.							AYACHE N, 1985, 1985 IEEE INT C ROB; BEJCZY AK, 1975 P IEEE INT C CY; BEJCZY AK, 1979, ELECTRO 79 NEW YORK; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6; BRIOT M, 1978, IEEE T SYST MAN CYBE, V8; BRIOT M, 1979, 9TH ISIR WASH; Devijver PA, 1982, PATTERN RECOGNITION; FAUGERAS O, 1983, 1983 IEEE C COMP VIS; FAUGERAS O, 1984, 1ST P INT S ROB RES; FAUX ID, 1980, COMPUTATIONAL GEOMET; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; GASTON P, 1984, IEEE T PATTERN ANAL, V6; GIBSON EJ, 1962, PSYCHOL READING, V69; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; GORDON G, 1978, ACTIVE TOUCH MECHANI; GRIMSON WEL, 1981, IMAGES SURFACES; GRIMSON WEL, 1983, MIT AI738 ART INT LA; GRIMSON WEL, 1985, MIT AI855 ART INT LA; HARMON L, 1982, INT J ROBOT RES, V1; HARMON L, 1980, SME MSR8003 TECH REP; HENDERSON T, 1983, IEEE T PATTERN ANAL, V5; HILLIS WD, 1981, MIT AI629 ART INT LA; HU MK, 1962, IRE T INFORM THEORY, V8; JACKINS C, 1980, COMPUT GRAPHICS IMAG, V14; KINOSHITA G, 1975, PATTERN RECOGNITION, V7; MARIK V, 1981, 7TH INT JOINT C ART; NEVATIA R, 1973, 3RD P IJCAI STANF; OVERTON K, 1981, 7TH INT JOINT C ART; PAGE C, 1976, 6TH U NOTT NOTT; PERSOON E, 1977, IEEE T SYST MAN CYBE, V7; REQUICHA AAG, 1980, COMPUT SURVEYS, V12; SADJADI F, 1980, IEEE T PATTERN ANAL, V2; SCHNEITER JL, 1986, THESIS MIT CAMBRIDGE; TAKEDA S, 1974, 4TH ISIR; TOGAI M, 1984, IEEE CH2008184000003; WILSON D, 1981, THESIS MIT CAMBRIDGE; [No title captured]	37	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1990	12	8					775	786		10.1109/34.57668	http://dx.doi.org/10.1109/34.57668			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DQ388					2022-12-18	WOS:A1990DQ38800004
J	WONG, SKM; POON, FCS				WONG, SKM; POON, FCS			COMMENTS ON APPROXIMATING DISCRETE PROBABILITY-DISTRIBUTIONS WITH DEPENDENCE TREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WONG, SKM (corresponding author), UNIV REGINA,DEPT COMP SCI,REGINA S4S 0A2,SASKATCHEWAN,CANADA.							CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Lewis PM., 1959, INF CONTROL, V2, P214, DOI 10.1016/S0019-9958(59)90207-4; WANG CC, 1979, IEEE T AUTOMAT CONTR, V24, P434; WONG AKC, 1977, 7TH P INT C CYB SOC, P19	6	12	12	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					333	335		10.1109/34.21803	http://dx.doi.org/10.1109/34.21803			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000014
J	MITICHE, A; GRISELL, R; AGGARWAL, JK				MITICHE, A; GRISELL, R; AGGARWAL, JK			ON SMOOTHNESS OF A VECTOR FIELD - APPLICATION TO OPTICAL-FLOW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV TEXAS, IMAGE & SIGNAL ANAL LAB, AUSTIN, TX 78712 USA	University of Texas System; University of Texas Austin	MITICHE, A (corresponding author), INST NATL RECH SCI TELECOMMUN, 3 PL COMMERCE, VERDUN H3E 1H6, QUEBEC, CANADA.							BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P313, DOI 10.1016/0734-189X(83)90029-4; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; GRIMSON WEL, 1980, MIT AI565 MEM; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HILDRETH ED, 1982, MIT AI699 MEM; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JERIAN C, 1984, IEEE T PATTERN ANAL, V6, P523, DOI 10.1109/TPAMI.1984.4767558; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARR D, P ROY SOC LONDON B, V204; Mitiche A., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P156; MITICHE A, 1984, APR P WORKSH COMP VI; Nagel HH, 1982, PATTERN RECOGN LETT, V1, P55, DOI 10.1016/0167-8655(82)90052-6; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; PAQUIN R, 1983, COMPUT VISION GRAPH, V24, P205; POGGIO T, MIT AI773 MEM; POTTER JL, 1972, COMPUT GRAPHICS IMAG, V6, P558; PRAZDNY K, 1983, COMPUT VISION GRAPH, V22, P239, DOI 10.1016/0734-189X(83)90067-1; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; Tikhonov A., 1977, SOLUTIONS ILL POSED; VEMURI B, 1985, JUL P SIAM C GEOM MO; WAXMAN A, 1985, INT J ROBOT RES, V5, P95; WAXMAN A, 1984, CARTR58 U MAR CTR AU; WOHN K, 1983, P IMAGE UNDERSTANDIN, P61	26	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					943	949		10.1109/34.9116	http://dx.doi.org/10.1109/34.9116			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100016
J	LONGSTAFF, ID				LONGSTAFF, ID			ON EXTENSIONS TO FISHERS LINEAR DISCRIMINANT FUNCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									ROYAL SIGNALS & RADAR ESTAB,MALVERN WR14 3PS,WORCS,ENGLAND									Duda R., 1973, PATTERN CLASSIFICATI, p[114, 221]; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FOLEY D, 1975, IEEE T C, V26, P281; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; MALINA W, 1981, IEEE T PATTERN ANAL, V3, P611, DOI 10.1109/TPAMI.1981.4767154	5	12	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					321	325		10.1109/TPAMI.1987.4767906	http://dx.doi.org/10.1109/TPAMI.1987.4767906			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869402				2022-12-18	WOS:A1987G163300013
J	MCVEY, ES; DRAKE, KC; INIGO, RM				MCVEY, ES; DRAKE, KC; INIGO, RM			RANGE MEASUREMENTS BY A MOBILE ROBOT USING A NAVIGATION LINE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MCVEY, ES (corresponding author), UNIV VIRGINIA,SCH ENGN & APPL SCI,CHARLOTTESVILLE,VA 22901, USA.							BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; COOKE RA, 1983, 13TH P INT S IND ROB, V2; DRAKE KC, 1985, IEEE T PATTERN ANAL, V7; DUDA RO, 1973, PATTERN CLASSIFICATI, P386; JOHNSTON AR, 1979, IEEE T VEH TECHNOL, V28, P95, DOI 10.1109/T-VT.1979.23775; JULLIERE M, 1983, 13TH P INT S IND ROB, V2; LARCOMBE MHE, 1981, 1ST P INT C AUT GUID, P137; MILGRAM DL, 1979, WESCON TECH PAPERS, V23; SCHMIDT RA, 1971, THESIS STANFORD U ST	9	12	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					105	109		10.1109/TPAMI.1986.4767757	http://dx.doi.org/10.1109/TPAMI.1986.4767757			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869328				2022-12-18	WOS:A1986AWT8600012
J	MARK, DM; ABEL, DJ				MARK, DM; ABEL, DJ			LINEAR QUADTREES FROM VECTOR REPRESENTATIONS OF POLYGONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter																		ABEL DJ, 1984, COMPUT VISION GRAPH, V27, P19, DOI 10.1016/0734-189X(84)90079-3; ABEL DJ, 1983, COMPUT VISION GRAPH, V24, P1, DOI 10.1016/0734-189X(83)90017-8; COMEAU MA, 1981, CANADA LAND DATA SYS, V3; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741; KAWAGUCHI E, 1983, IEEE T PATTERN ANAL, V5, P373, DOI 10.1109/TPAMI.1983.4767407; KLINGER A, 1971, OPTIMIZING METHODS S, P303; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; LAUZON JP, UNPUB COMPUT VISION; LAUZON JP, 1983, THESIS STATE U NEW Y; MARK DM, CSIRONET18 TECH REP; MARK DM, 1984, AUG P INT S SPAT DAT, V2, P412; MORTON G, 1966, UNPUB COMPUTER ORIEN; SAMET H, 1981, IEEE T PATTERN ANAL, V3, P683, DOI 10.1109/TPAMI.1981.4767171; SAMET H, 1980, COMPUT VISION GRAPH, V13, P88, DOI 10.1016/0146-664X(80)90118-5; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SAMET H, 1984, AUG P INT S SPAT DAT, V2, P392	17	12	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					344	349		10.1109/TPAMI.1985.4767664	http://dx.doi.org/10.1109/TPAMI.1985.4767664			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869270				2022-12-18	WOS:A1985AFM4400010
J	NAKAMURA, A; AIZAWA, K				NAKAMURA, A; AIZAWA, K			ON THE RECOGNITION OF PROPERTIES OF 3-DIMENSIONAL PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NAKAMURA, A (corresponding author), HIROSHIMA UNIV,DEPT APPL MATH,HIROSHIMA 724,JAPAN.							INOUE K, 1979, INFORM CONTROL, V41, P305, DOI 10.1016/S0019-9958(79)90604-1; Morgenthaler D.G., 1981, TR1005 U MAR COMP SC; MORGENTHALER DG, 1981, INFORM CONTROL, V51, P227, DOI 10.1016/S0019-9958(81)90290-4; MORGENTHALER DG, 1980, TR980 U MAR COMP SCI; Park C., 1971, TR156 U MAR COMP SCI; ROSENFELD A, 1981, INFORM CONTROL, V50, P119, DOI 10.1016/S0019-9958(81)90177-7; Rosenfeld A., 1979, PICTURE LANGUAGES; ROSENFELD A, 1980, TR942 U MAR COMP SCI; SELKOW SM, 1972, J ACM, V19, P283, DOI 10.1145/321694.321701; [No title captured]	10	12	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					708	713		10.1109/TPAMI.1985.4767727	http://dx.doi.org/10.1109/TPAMI.1985.4767727			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869309				2022-12-18	WOS:A1985ATG0500009
J	SHAHRARAY, B; ANDERSON, DJ				SHAHRARAY, B; ANDERSON, DJ			UNIFORM RESAMPLING OF DIGITIZED CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MICHIGAN,GRAD PROGRAM BIOENGN,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan	SHAHRARAY, B (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48109, USA.							FREEMAN H, 1980, COMPUT VISION GRAPH, V12, P203, DOI 10.1016/0146-664X(80)90012-X; GROEN FCA, 1978, COMPUT GRAPH IMAGE P, P394; HO CS, 1983, IEEE T PATTERN ANAL, V5, P593, DOI 10.1109/TPAMI.1983.4767448; KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; NEUHOFF DL, 1981, AUG IEEE COMP SOC C, P237; PAVLIDIS T, 1978, 4TH P INT JOINT C PA; ROSENFELD A, 1973, IEEE T COMPUT    SEP, P875; SCHOLTEN DK, 1983, IEEE T PATTERN ANAL, V5, P526, DOI 10.1109/TPAMI.1983.4767432	9	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					674	681		10.1109/TPAMI.1985.4767723	http://dx.doi.org/10.1109/TPAMI.1985.4767723			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869305				2022-12-18	WOS:A1985ATG0500005
J	DUNN, SM; HARWOOD, D; DAVIS, LS				DUNN, SM; HARWOOD, D; DAVIS, LS			LOCAL ESTIMATION OF THE UNIFORM ERROR THRESHOLD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DUNN, SM (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							Dunn S, 1983, PATTERN RECOGN LETT, V1, P169, DOI 10.1016/0167-8655(83)90058-2; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8	2	12	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					742	747		10.1109/TPAMI.1984.4767597	http://dx.doi.org/10.1109/TPAMI.1984.4767597			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499654				2022-12-18	WOS:A1984TX36100007
J	WANG, ZD				WANG, ZD			NEW ALGORITHM FOR THE SLANT TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WANG, ZD (corresponding author), UNIV ARIZONA,DEPT ELECT ENGN,TUCSON,AZ 85721, USA.							AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; Ahmed N., 1975, ORTHOGONAL TRANSFORM, P86; ENOMOTO H, 1971, IEEE T ELECTROMAGN C, VEM13, P11, DOI 10.1109/TEMC.1971.303101; FINO BJ, 1974, P IEEE, V62, P653, DOI 10.1109/PROC.1974.9500; FINO BJ, 1977, SIAM J COMPUT, V6, P700, DOI 10.1137/0206051; JONES HW, 1978, NOV INT TEL C; MANZ JW, 1972, IEEE T ACOUST SPEECH, VAU20, P204, DOI 10.1109/TAU.1972.1162377; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PRATT WK, 1974, IEEE T COMMUN, VCO22, P1075, DOI 10.1109/TCOM.1974.1092335; PRATT WK, 1972, MAR P S APPL WALSH F	10	12	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					551	555		10.1109/TPAMI.1982.4767301	http://dx.doi.org/10.1109/TPAMI.1982.4767301			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PG894	21869076				2022-12-18	WOS:A1982PG89400013
J	SNYDER, WE; TANG, DA				SNYDER, WE; TANG, DA			FINDING THE EXTREMA OF A REGION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SNYDER, WE (corresponding author), N CAROLINA STATE UNIV,DEPT ELECT ENGN,IMAGE ANAL GRP,RALEIGH,NC 27607, USA.							BRICE C, 1970, SCENE ANAL USING REG; CHIEN RT, 1976, 4TH P INT JOINT C AR; DUDA R, 1975, EXPLORATORY RES ADV; Duda R.O., 1973, J ROYAL STAT SOC SER; GRAHAM R, 1972, INFORM PROCESSING LE, V1; HARMON LD, 1972, P IEEE, V60, P1165, DOI 10.1109/PROC.1972.8878; JARVIS RA, 1973, INFORM PROCESSING LE, V2; MUNSON J, 1968, FAL P JOINT COMP C; Pavlidis T., 1977, STRUCTURAL PATTERN R; PAVLIDIS T, 1978, COMPUT GRAPHICS IMAG, V7; SHAMOS MI, 1975, 7TH P ACM S THEOR CO; YAKIMOVSKY Y, 1973, 3RD P INT JOINT C AR	12	12	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	3					266	269		10.1109/TPAMI.1980.4767016	http://dx.doi.org/10.1109/TPAMI.1980.4767016			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR843	21868902				2022-12-18	WOS:A1980JR84300009
J	KASHYAP, RL				KASHYAP, RL			SYNTACTIC DECISION RULES FOR RECOGNITION OF SPOKEN WORDS AND PHRASES USING A STOCHASTIC AUTOMATON	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KASHYAP, RL (corresponding author), PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907, USA.							JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; KASHYAP RL, 1978, IEEE T COMPUT, V27, P442, DOI 10.1109/TC.1978.1675124; KASHYAP RL, 1976, TREE7628 PURD U SCH; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; RISEMAN EM, 1974, IEEE T COMPUT, V23, P490; SANKOFF D, 1972, P NATL ACAD SCI USA, V69, P4, DOI 10.1073/pnas.69.1.4; Sellers P. H., 1974, Journal of Combinatorial Theory, Series A, V16, P253, DOI 10.1016/0097-3165(74)90050-8; SILVERMAN HF, 1975, IEEE T ACOUST SPEECH, V23, P87; THOMASON MG, 1974, IEEE T COMPUT, VC 23, P597, DOI 10.1109/T-C.1974.224000; TOUSSAINT GT, 1977, 1977 P IEEE COMP SOC, P1; WHITE GM, 1976, IEEE T ACOUST SPEECH, V24, P183, DOI 10.1109/TASSP.1976.1162779; WOODS W, 1976, BBN3438 REP, V2	13	12	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					154	163		10.1109/TPAMI.1979.4766901	http://dx.doi.org/10.1109/TPAMI.1979.4766901			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868844				2022-12-18	WOS:A1979HA30400005
J	SANKAR, PV; ROSENFELD, A				SANKAR, PV; ROSENFELD, A			HIERARCHICAL REPRESENTATION OF WAVEFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SANKAR, PV (corresponding author), UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742, USA.							DAVIS LS, 1977, IEEE T COMPUT, V26, P1053, DOI 10.1109/TC.1977.1674746; DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812; DAVIS LS, 1977, TR568 U MAR COMP SCI; EHRICH RW, 1976, IEEE T COMPUT, V25, P725, DOI 10.1109/TC.1976.1674681; EHRICH RW, COMPUT GRAPHICS IMAG; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; HOROWITZ SL, 1974, 2ND P INT JOINT C PA, P465; JOHNSTON E, 1973, IEEE T COMPUT, V22, P875; LOZANOPEREZ T, 1975, AI329 MIT MEM; MCCLURE DE, 1975, J MATH ANAL APPL, V51, P326, DOI 10.1016/0022-247X(75)90125-0; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; PAVLIDIS T, 1971, SOFTWARE ENGINEERING, V2, P203; ROSENBERG D, 1972, COMPUT GRAPHICS IMAG, V1, P183; ROSENFELD A, 1977, TR573 U MAR COMP SCI; Stockman G. C., 1973, 1st International Joint Conference on Pattern Recognition, P236; STOCKMAN GC, 1977, TR531 U MAR COMP SCI; YOUNG IT, 1974, INFORM CONTROL, V25, P357, DOI 10.1016/S0019-9958(74)91038-9	18	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					73	80		10.1109/TPAMI.1979.4766877	http://dx.doi.org/10.1109/TPAMI.1979.4766877			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868832				2022-12-18	WOS:A1979HA30300008
J	WONG, RY; HALL, EL				WONG, RY; HALL, EL			PERFORMANCE COMPARISON OF SCENE MATCHING TECHNIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV TENNESSEE,DEPT ELECT ENGN,KNOXVILLE,TN 37916	University of Tennessee System; University of Tennessee Knoxville	WONG, RY (corresponding author), CALIF STATE UNIV NORTHRIDGE,DEPT ELECT ENGN,NORTHRIDGE,CA 91330, USA.			Hall, Ernest/0000-0003-4361-8647				BARNEA DI, 1972, IEEE T COMPUT, V21; FU KS, 1977, JUN P IEEE C PATT RE; GREEN GS, 1976, IEEE T SYST MAN CYBE, V6; PAVLIDIS T, 1978, COMPUTER GRAPHICS IM, V7; PAVLIDIS T, 1977, JUN P IEEE C PATT RE; PERSOON E, 1977, IEEE T SYST MAN CYBE, V7; ROSENFELD A, 1977, IEEE T SYST MAN CYBE, V7; WONG RY, 1978, IEEE T COMPUT, V27; WONG RY, 1978, COMPUTER GRAPHICS IM, V8; WONG RY, 1977, IEEE T SYST MAN CYBE, V7; WONG RY, 1978, IEEE T AEROSP ELECTR, V14	11	12	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					325	330		10.1109/TPAMI.1979.4766931	http://dx.doi.org/10.1109/TPAMI.1979.4766931			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868866				2022-12-18	WOS:A1979HC30100013
J	Yan, CX; Chang, XJ; Li, ZH; Guan, WL; Ge, ZY; Zhu, L; Zheng, QH				Yan, Caixia; Chang, Xiaojun; Li, Zhihui; Guan, Weili; Ge, Zongyuan; Zhu, Lei; Zheng, Qinghua			ZeroNAS: Differentiable Generative Adversarial Networks Search for Zero-Shot Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generative adversarial networks; Computer architecture; Training; Generators; Task analysis; Testing; Optimization; Differentiable architecture search; generative adversarial networks; zero-shot learning		In recent years, remarkable progress in zero-shot learning (ZSL) has been achieved by generative adversarial networks (GAN). To compensate for the lack of training samples in ZSL, a surge of GAN architectures have been developed by human experts through trial-and-error testing. Despite their efficacy, however, there is still no guarantee that these hand-crafted models can consistently achieve good performance across diversified datasets or scenarios. Accordingly, in this paper, we turn to neural architecture search (NAS) and make the first attempt to bring NAS techniques into the ZSL realm. Specifically, we propose a differentiable GAN architecture search method over a specifically designed search space for zero-shot learning, referred to as ZeroNAS. Considering the relevance and balance of the generator and discriminator, ZeroNAS jointly searches their architectures in a min-max player game via adversarial training. Extensive experiments conducted on four widely used benchmark datasets demonstrate that ZeroNAS is capable of discovering desirable architectures that perform favorably against state-of-the-art ZSL and generalized zero-shot learning (GZSL) approaches. Source code is at https://github.com/caixiay/ZeroNAS.	[Yan, Caixia; Zheng, Qinghua] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Peoples R China; [Chang, Xiaojun] RMIT Univ, Sch Comp Technol, Melbourne, Vic 3000, Australia; [Li, Zhihui] Qilu Univ Technol, Shandong Acad Sci, Shandong Artificial Intelligence Inst, Jinan 250353, Peoples R China; [Guan, Weili; Ge, Zongyuan] Monash Univ, Fac Informat Technol, Melbourne, Vic 3800, Australia; [Zhu, Lei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China	Xi'an Jiaotong University; Royal Melbourne Institute of Technology (RMIT); Qilu University of Technology; Monash University; Shandong Normal University	Chang, XJ (corresponding author), RMIT Univ, Sch Comp Technol, Melbourne, Vic 3000, Australia.	yancaixia@stu.xjtu.edu.cn; cxj273@gmail.com; zhihuilics@gmail.com; honeyguan@gmail.com; Zongyuan.Ge@monash.edu; leizhu0608@gmail.com; qhzheng@mail.xjtu.edu.cn	; Chang, Xiaojun/A-2055-2015	Zhu, Lei/0000-0002-2993-7142; Chang, Xiaojun/0000-0002-7778-8807; Ge, Zongyuan/0000-0002-5880-8673	National Key Research and Development Program of China [2018AAA0101400]; National Nature Science Foundation of China [62137002, 61872287, 62050194, 61906109]; Innovative Research Group of the National Natural Science Foundation of China [61721002]; Innovation Research Team of Ministry of Education [IRT_17R86]; Project of China Knowledge Center for Engineering Science and Technology; Consulting Research Project of Chinese Academy of Engineering "The Online and Offline Mixed Educational Service System for The Belt and Road" Training in MOOC China; Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA) [DE190100626]	National Key Research and Development Program of China; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Innovative Research Group of the National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Innovation Research Team of Ministry of Education; Project of China Knowledge Center for Engineering Science and Technology; Consulting Research Project of Chinese Academy of Engineering "The Online and Offline Mixed Educational Service System for The Belt and Road" Training in MOOC China; Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA)(Australian Research Council)	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101400, in part by the National Nature Science Foundation of China under Grants 62137002, 61872287, 62050194, and 61906109, in part by the Innovative Research Group of the National Natural Science Foundation of China under Grant 61721002, in part by the Innovation Research Team of Ministry of Education under Grant IRT_17R86, in part by the Project of China Knowledge Center for Engineering Science and Technology and The Consulting Research Project of Chinese Academy of Engineering "The Online and Offline Mixed Educational Service System for The Belt and Road" Training in MOOC China, and in part by the Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA) under Grant DE190100626.	Andrew Hundt, 2019, Arxiv, DOI arXiv:1903.09900; Arjovsky M, 2017, PR MACH LEARN RES, V70; Chen Y., 2019, P NIPS, P1884; Cheng X., 2020, P NEURIPS; Deng J., 2009, P 2009 IEEE C COMP V, P248, DOI DOI 10.1109/CVPR.2009.5206848; Denton Emily L, 2015, NEURIPS, V2, P4; Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hanchao Wang, 2019, Arxiv, DOI arXiv:1906.11080; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Huang H, 2019, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2019.00089; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Li C., 2021, ARXIV; Li JJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1587, DOI 10.1145/3343031.3350901; Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022; Miao Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7806, DOI 10.1109/CVPR42600.2020.00783; Narayan Sanath, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P479, DOI 10.1007/978-3-030-58542-6_29; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Giryes R, 2020, Arxiv, DOI arXiv:1912.00606; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Verma VK, 2020, AAAI CONF ARTIF INTE, V34, P6062; Wah C., 2011, TECH REP; Wei X., 2018, P ICLR; Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052; Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581; Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328; Yao QM, 2020, AAAI CONF ARTIF INTE, V34, P6664; Zhang HF, 2019, NEUROCOMPUTING, V329, P12, DOI 10.1016/j.neucom.2018.10.043; Zhang M., 2020, PROC NEURIPS; Zhang M, 2021, IEEE T PATTERN ANAL, V43, P2921, DOI 10.1109/TPAMI.2020.3035351; Zhu YZ, 2019, IEEE I CONF COMP VIS, P9843, DOI 10.1109/ICCV.2019.00994; Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	46	11	11	3	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9733	9740		10.1109/TPAMI.2021.3127346	http://dx.doi.org/10.1109/TPAMI.2021.3127346			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34762584				2022-12-18	WOS:000880661400084
J	Liu, WW; Wang, HB; Shen, XB; Tsang, IW				Liu, Weiwei; Wang, Haobo; Shen, Xiaobo; Tsang, Ivor W.			The Emerging Trends of Multi-Label Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; Task analysis; Market research; Training; Testing; Noise measurement; Correlation; Extreme multi-label learning; multi-label learning with limited supervision; deep learning for multi-label learning; online multi-label learning; statistical multi-label learning; new applications	MISSING LABELS; VARIABLE SELECTION; CLASSIFICATION; NETWORKS; LASSO	Exabytes of data are generated daily by humans, leading to the growing needs for new efforts in dealing with the grand challenges for multi-label learning brought by big data. For example, extreme multi-label classification is an active and rapidly growing research area that deals with classification tasks with extremely large number of classes or labels; utilizing massive data with limited supervision to build a multi-label classification model becomes valuable for practical applications, etc. Besides these, there are tremendous efforts on how to harvest the strong learning capability of deep learning to better capture the label dependencies in multi-label learning, which is the key for deep learning to address real-world classification tasks. However, it is noted that there have been a lack of systemic studies that focus explicitly on analyzing the emerging trends and new challenges of multi-label learning in the era of big data. It is imperative to call for a comprehensive survey to fulfil this mission and delineate future research directions and new applications.	[Liu, Weiwei] Wuhan Univ, Sch Comp Sci, Wuhan 430079, Peoples R China; [Wang, Haobo] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China; [Shen, Xiaobo] Nanjing Univ Sci & Technol, Sch Comp & Engn, Nanjing 210094, Peoples R China; [Tsang, Ivor W.] Univ Technol Sydney, Ctr Artificial Intelligence, FEIT, Ultimo, NSW 2007, Australia	Wuhan University; Zhejiang University; Nanjing University of Science & Technology; University of Technology Sydney	Liu, WW (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.	liuweiwei863@gmail.com; wanghaobo@zju.edu.cn; njust.shenxiaobo@gmail.com; ivor.tsang@uts.edu.au	; Tsang, Ivor/E-8653-2011	Shen, Xiaobo/0000-0001-8494-4532; Tsang, Ivor/0000-0003-2211-8176	National Natural Science Foundation of China [61976161, 62176126, 61906091]; Natural Science Foundation of Jiangsu Province, China (Youth Fund Project) [BK20190440]; Fundamental Research Funds for the Central Universities [30921011210]; ARC [DP180100106, DP200101328]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province, China (Youth Fund Project); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); ARC(Australian Research Council)	This work was supported by the National Natural Science Foundation of China under Grants 61976161, 62176126, and 61906091, the Natural Science Foundation of Jiangsu Province, China (Youth Fund Project) under Grant BK20190440, the Fundamental Research Funds for the Central Universities under Grants 30921011210, the ARC under Grants DP180100106 and DP200101328.	Agrawal R., 2013, WWW, P13, DOI DOI 10.1145/2488388.2488391; Akbarnejad AH, 2019, IEEE T KNOWL DATA EN, V31, P229, DOI 10.1109/TKDE.2018.2833850; Alfassy A, 2019, PROC CVPR IEEE, P6541, DOI 10.1109/CVPR.2019.00671; Babbar R, 2019, MACH LEARN, V108, P1329, DOI 10.1007/s10994-019-05791-5; Babbar R, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P721, DOI 10.1145/3018661.3018741; Ben Messaoud M, 2019, LECT NOTES ARTIF INT, V11775, P805, DOI 10.1007/978-3-030-29551-6_71; Bhatia Kush, 2015, ADV NEURAL INFORM PR, P730, DOI DOI 10.5555/2969239.2969321; BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692; Boulmrharj S, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART ENERGY SYSTEMS AND TECHNOLOGIES (SEST); Bucak S. S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2801, DOI 10.1109/CVPR.2011.5995734; Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6314; Chang H, 2007, IEEE I CONF COMP VIS, P267, DOI 10.1142/9789812709677_0038; Chang WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3163, DOI 10.1145/3394486.3403368; Chen C, 2019, AAAI CONF ARTIF INTE, P3304; Chen G., 2018, P 2008 SIAM INT C DA, P410; Chen Minmin, 2013, P 30 INT C MACH LEAR, P1274; Chen SF, 2018, AAAI CONF ARTIF INTE, P6714; Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061; Chen T, 2020, PR MACH LEARN RES, V119; Chen Y.N., 2012, P ADV NEUR INF PROC, P1529; Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532; Chu HM, 2019, MACH LEARN, V108, P1193, DOI 10.1007/s10994-018-5773-6; Chu HM, 2018, LECT NOTES COMPUT SC, V11206, P409, DOI 10.1007/978-3-030-01216-8_25; Cisse M, 2016, PR MACH LEARN RES, V48; Cui ZJ, 2020, AAAI CONF ARTIF INTE, V34, P3693; Dahiya K, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P31, DOI 10.1145/3437963.3441810; Dembczynski K., 2012, PROC 29 INT C MACH L; Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z; Dong H., 2019, P 2019 C N AM CHAPTE, V1, P1348; Dong HC, 2018, AAAI CONF ARTIF INTE, P2926; Durand T, 2019, PROC CVPR IEEE, P647, DOI 10.1109/CVPR.2019.00074; Er MJ, 2016, IEEE SYS MAN CYBERN, P3701, DOI 10.1109/SMC.2016.7844809; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Farnadi G, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P171, DOI 10.1145/3159652.3159691; Fei H, 2020, AAAI CONF ARTIF INTE, V34, P7692; Fei Wu, 2015, IEEE Transactions on Big Data, V1, P109, DOI 10.1109/TBDATA.2015.2497270; Feng L, 2019, AAAI CONF ARTIF INTE, P3550; Gallinari P, 2013, ADV NEURAL INFORM PR, P1851; Gao W, 2013, ARTIF INTELL, V199, P22, DOI 10.1016/j.artint.2013.03.001; Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658; Gong C, 2016, AAAI CONF ARTIF INTE, P1610; Gong X., 2021, PROC 30 INT JOINT C, P2432; Gong XW, 2022, IEEE T MULTIMEDIA, V24, P1055, DOI 10.1109/TMM.2021.3109438; Gong XW, 2022, IEEE T NEUR NET LEAR, V33, P6775, DOI 10.1109/TNNLS.2021.3083397; Gong XW, 2020, AAAI CONF ARTIF INTE, V34, P4012; Guo Chuan, 2019, ADV NEURAL INFORM PR; Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082; Guo L, 2016, IEEE ACCESS, V4, P3201, DOI 10.1109/ACCESS.2016.2578638; Gupta V, 2019, AAAI CONF ARTIF INTE, P3747; Han YF, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1494, DOI 10.1145/3219819.3220038; He JJ, 2012, INFORM SCIENCES, V190, P162, DOI 10.1016/j.ins.2011.12.015; He S, 2019, IEEE DATA MINING, P280, DOI 10.1109/ICDM.2019.00038; Hendrycks D., 2016, ARXIV161002136, DOI DOI 10.48550/ARXIV.1606.08415; Hsu D.J., 2009, NIPS, P772; Hu MY, 2019, PROC CVPR IEEE, P11509, DOI 10.1109/CVPR.2019.01178; Hu MY, 2019, LECT NOTES COMPUT SC, V11365, P404, DOI 10.1007/978-3-030-20873-8_26; Hua X.-S., 2008, MSRTR2008103; Huang J, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM); Huang SJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P946; Huynh Dat, 2020, PROC IEEECVF C COMPU, P9423; Ibrahim Karim M., 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P291, DOI 10.1145/3372278.3390728; Jain H, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P528, DOI 10.1145/3289600.3290979; Jain H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P935, DOI 10.1145/2939672.2939756; Jain V, 2017, PR MACH LEARN RES, V70; Jalan A, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2600; Jasinska K, 2016, PR MACH LEARN RES, V48; Ji Z, 2020, IEEE T IMAGE PROCESS, V29, P6549, DOI 10.1109/TIP.2020.2991527; Jing LP, 2015, PROC CVPR IEEE, P1483, DOI 10.1109/CVPR.2015.7298755; Khan ME, 2018, PR MACH LEARN RES, V80; Kong XN, 2013, IEEE T KNOWL DATA EN, V25, P704, DOI 10.1109/TKDE.2011.141; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170; Li PY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1359; Li SY, 2019, IEEE T KNOWL DATA EN, V31, P1369, DOI 10.1109/TKDE.2018.2857766; Li X, 2015, JMLR WORKSH CONF PRO, V38, P635; Li ZW, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2612; Liu JZ, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P115, DOI 10.1145/3077136.3080834; Liu W., 2019, PROC 33 INT C NEURAL, P6334; Liu WW, 2019, PR MACH LEARN RES, V97; Liu WW, 2017, J MACH LEARN RES, V18; Liu WW, 2019, IEEE T PATTERN ANAL, V41, P408, DOI 10.1109/TPAMI.2018.2794976; Liu WW, 2017, J MACH LEARN RES, V18; Liu Y., 2006, AAAI, P421; Liu Y, 2018, PATTERN RECOGN, V78, P307, DOI 10.1016/j.patcog.2018.01.022; Liu YC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P700, DOI 10.1145/3240508.3240567; Lv JQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3101; Ma JH, 2017, KNOWL-BASED SYST, V137, P65, DOI 10.1016/j.knosys.2017.09.005; McAuley J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2783258.2783381; Mencia EL, 2010, LECT NOTES ARTIF INT, V6036, P192, DOI 10.1007/978-3-642-12837-0_11; Menon A. K., 2019, PROC 33 INT C NEURAL, p10 599; Mittal A, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P49, DOI 10.1145/3437963.3441807; Mittal A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3721, DOI 10.1145/3442381.3449815; Nam Jinseok, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8725, P437, DOI 10.1007/978-3-662-44851-9_28; Nam J, 2019, PR MACH LEARN RES, V97; Nam J, 2017, ADV NEUR IN, V30; Niculescu-Mizil A, 2017, PR MACH LEARN RES, V54, P1448; Niu XS, 2019, ADV NEUR IN, V32; Noorizadeh N, 2020, MULTIMED TOOLS APPL, V79, P19411, DOI 10.1007/s11042-020-08749-1; Noorizadeh N, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101602; Park S, 2013, INT CONF ACOUST SPEE, P3322, DOI 10.1109/ICASSP.2013.6638273; Prabhu Y, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P993, DOI 10.1145/3178876.3185998; Prabhu Y, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P441, DOI 10.1145/3159652.3159660; Prabhu Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P263, DOI 10.1145/2623330.2623651; Qi Z., 2011, PROC 17 ACM SIGKDD I, P1199, DOI 10.1145/2020408.2020592.; Ratnarajah N, 2014, NEUROIMAGE, V102, P913, DOI 10.1016/j.neuroimage.2014.08.001; Read J, 2009, LECT NOTES ARTIF INT, V5782, P254, DOI 10.1007/978-3-642-04174-7_17; Saini D, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3733, DOI 10.1145/3442381.3449937; Sen R, 2021, PR MACH LEARN RES, V139; Shao RF, 2018, IEEE DATA MINING, P437, DOI 10.1109/ICDM.2018.00059; Shen XB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2675; Shen XB, 2018, IEEE T NEUR NET LEAR, V29, P4324, DOI 10.1109/TNNLS.2017.2763967; Shi W., 2019, PROC 36 INT C MACH L, P5769; Si S, 2017, PR MACH LEARN RES, V70; Siblini W, 2018, PR MACH LEARN RES, V80; Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212; Sun LJ, 2019, AAAI CONF ARTIF INTE, P5016; Sun LJ, 2019, LECT NOTES ARTIF INT, V11440, P269, DOI 10.1007/978-3-030-16145-3_21; Sun YY, 2010, AAAI CONF ARTIF INTE, P593; Tagami Y, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P455, DOI 10.1145/3097983.3097987; Tan QY, 2017, NEUROCOMPUTING, V260, P192, DOI 10.1016/j.neucom.2017.04.033; Tang PJ, 2020, AAAI CONF ARTIF INTE, V34, P9024; Tarvainen A, 2017, ADV NEUR IN, V30; Tsai CP, 2020, AAAI CONF ARTIF INTE, V34, P6038; Ubaru S, 2017, PR MACH LEARN RES, V70; Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696; Venkatesan R, 2017, EVOL SYST-GER, V8, P303, DOI 10.1007/s12530-016-9162-8; Wang B., 2019, PROC C N AM CHAPTER, P2820; Wang CY, 2020, INT CONF ACOUST SPEE, P1006, DOI 10.1109/ICASSP40776.2020.9054353; Wang H., 2020, PROC EUR C MACH LEAR, P455; Wang HB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2477; Wang HB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3691; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wang K, 2018, PROC 10 ASIAN C MACH, P1; Wang KX, 2019, IEEE INT CON MULTI, P982, DOI 10.1109/ICME.2019.00173; Wang LC, 2020, AAAI CONF ARTIF INTE, V34, P6227; Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083; Wang QW, 2020, AAAI CONF ARTIF INTE, V34, P6251; Wang QF, 2014, LECT NOTES COMPUT SC, V8690, P425, DOI 10.1007/978-3-319-10605-2_28; Wang Y, 2020, AAAI CONF ARTIF INTE, V34, P12265; Wang Z., 2019, ADV NEURAL INFORM PR, P5820; Wang Zhen, 2020, ICML, V119, P9963; Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58; Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410; Wen J, 2020, LECT NOTES COMPUT SC, V12139, P355, DOI 10.1007/978-3-030-50420-5_26; Wu BY, 2019, IEEE ACCESS, V7, P172683, DOI 10.1109/ACCESS.2019.2956775; Wu BY, 2018, INT J COMPUT VISION, V126, P875, DOI 10.1007/s11263-018-1085-3; Wu B, 2016, AAAI CONF ARTIF INTE, P2229; Wu BY, 2014, INT C PATT RECOG, P1964, DOI 10.1109/ICPR.2014.343; Wu BY, 2015, PATTERN RECOGN, V48, P2279, DOI 10.1016/j.patcog.2015.01.022; Wunder G, 2014, IEEE COMMUN MAG, V52, P97, DOI 10.1109/MCOM.2014.6736749; Wydmuch M., 2018, P 32 INT C NEURAL IN, P6358; Xiao C., 2018, ARXIV; Xie MK, 2020, AAAI CONF ARTIF INTE, V34, P6454; Xie MK, 2018, AAAI CONF ARTIF INTE, P4302; Xu C, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1275, DOI 10.1145/2939672.2939798; Xu D., 2019, ARXIV; Xu LL, 2014, IEEE DATA MINING, P1067, DOI 10.1109/ICDM.2014.125; Xu Miao, 2013, ADV NEURAL INFORM PR, P2301, DOI DOI 10.5555/2999792.2999869; Xu N., 2020, PROC 37 INT C MACH L, V119, P10597; Xu N, 2021, IEEE T KNOWL DATA EN, V33, P1632, DOI 10.1109/TKDE.2019.2947040; Xu N, 2020, AAAI CONF ARTIF INTE, V34, P6510; Yang BS, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P917; Yang H, 2017, PROC CVPR IEEE, P5996, DOI 10.1109/CVPR.2017.635; Yang H, 2016, LECT NOTES COMPUT SC, V9905, P835, DOI 10.1007/978-3-319-46448-0_50; Yang L, 2020, FRONT ARTIF INTEL AP, V325, P1634, DOI 10.3233/FAIA200274; Yazici Vacit Oguz, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13437, DOI 10.1109/CVPR42600.2020.01345; Yeh CK, 2017, AAAI CONF ARTIF INTE, P2838; Yen IEH, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P545, DOI 10.1145/3097983.3098083; Yen IEH, 2016, PR MACH LEARN RES, V48; You R., 2020, PROC AAAI C ARTIF IN, p12 709; Yu GX, 2018, IEEE DATA MINING, P1398, DOI 10.1109/ICDM.2018.00192; Yu HF, 2014, PR MACH LEARN RES, V32; Yu HF, 2017, AAAI CONF ARTIF INTE, P2845; Zhan W, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1305, DOI 10.1145/3097983.3098141; Zhang CQ, 2020, IEEE T CYBERNETICS, V50, P2837, DOI 10.1109/TCYB.2019.2894985; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338, DOI 10.1109/TKDE.2006.162; Zhang ML, 2021, IEEE T PATTERN ANAL, V43, P3587, DOI 10.1109/TPAMI.2020.2985210; Zhang XY, 2020, AAAI CONF ARTIF INTE, V34, P12886; Zhang Y., 2011, P 14 INT C ART INT S, P873; Zhang Y, 2016, PROC CVPR IEEE, P5985, DOI 10.1109/CVPR.2016.644; Zhao He, 2018, AISTATS, P1943; Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369; Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833; Zhe Chu, 2019, 2019 IEEE International Conference on Big Knowledge (ICBK), P58, DOI 10.1109/ICBK.2019.00016; Zhou J., 2020, OPEN, V1, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]; Zhou Mingyuan, 2012, AISTATS, P1462; Zhou ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3553; Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1; Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219; Zhu Y, 2018, IEEE T KNOWL DATA EN, V30, P1901, DOI 10.1109/TKDE.2018.2810872; Zhu Y, 2018, IEEE T KNOWL DATA EN, V30, P1081, DOI 10.1109/TKDE.2017.2785795; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735	197	11	11	10	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7955	7974		10.1109/TPAMI.2021.3119334	http://dx.doi.org/10.1109/TPAMI.2021.3119334			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34637378	Green Submitted			2022-12-18	WOS:000864325900050
J	Ma, J; Zhang, Y; Gu, S; Zhu, C; Ge, C; Zhang, YC; An, XL; Wang, CC; Wang, QY; Liu, X; Cao, SC; Zhang, Q; Liu, SQ; Wang, YP; Li, YH; He, J; Yang, XP				Ma, Jun; Zhang, Yao; Gu, Song; Zhu, Cheng; Ge, Cheng; Zhang, Yichi; An, Xingle; Wang, Congcong; Wang, Qiyuan; Liu, Xin; Cao, Shucheng; Zhang, Qi; Liu, Shangqing; Wang, Yunpeng; Li, Yuhui; He, Jian; Yang, Xiaoping			AbdomenCT-1K: Is Abdominal Organ Segmentation a Solved Problem?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Benchmark testing; Liver; Image segmentation; Biological systems; Pancreas; Computed tomography; Kidney; Multi-organ segmentation; generalization; semi-supervised learning; weakly supervised learning; continual learning	LIVER SEGMENTATION; MULTIORGAN SEGMENTATION; NEURAL-NETWORKS; CT; INFORMATION; ATLAS; MODEL; IMAGE	With the unprecedented developments in deep learning, automatic segmentation of main abdominal organs seems to be a solved problem as state-of-the-art (SOTA) methods have achieved comparable results with inter-rater variability on many benchmark datasets. However, most of the existing abdominal datasets only contain single-center, single-phase, single-vendor, or single-disease cases, and it is unclear whether the excellent performance can generalize on diverse datasets. This paper presents a large and diverse abdominal CT organ segmentation dataset, termed AbdomenCT-1K, with more than 1000 (1K) CT scans from 12 medical centers, including multi-phase, multi-vendor, and multi-disease cases. Furthermore, we conduct a large-scale study for liver, kidney, spleen, and pancreas segmentation and reveal the unsolved segmentation problems of the SOTA methods, such as the limited generalization ability on distinct medical centers, phases, and unseen diseases. To advance the unsolved problems, we further build four organ segmentation benchmarks for fully supervised, semi-supervised, weakly supervised, and continual learning, which are currently challenging and active research topics. Accordingly, we develop a simple and effective method for each benchmark, which can be used as out-of-the-box methods and strong baselines. We believe the AbdomenCT-1K dataset will promote future in-depth research towards clinical applicable abdominal organ segmentation methods.	[Ma, Jun] Nanjing Univ Sci & Technol, Dept Math, Nanjing 210094, Peoples R China; [Zhang, Yao] Chinese Acad Sci, Inst Comp Technol, Beijing 100864, Peoples R China; [Zhang, Yao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Gu, Song] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China; [Zhu, Cheng] Shenzhen Haichuang Med CO LTD, Shenzhen 518000, Peoples R China; [Ge, Cheng] Jiangsu Univ Technol, Inst Bioinformat & Med Engn, Changzhou 213001, Peoples R China; [Zhang, Yichi] Beihang Univ, Sch Biol Sci & Med Engn, Beijing 100191, Peoples R China; [An, Xingle] Beijing Infervis Technol CO LTD, Beijing 100089, Peoples R China; [Wang, Congcong] Tianjin Univ Technol, Sch Comp Sci & Engn, Tianjin 300222, Peoples R China; [Wang, Congcong] Norwegian Univ Sci & Technol, Dept Comp Sci, N-7491 Trondheim, Norway; [Wang, Qiyuan] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Peoples R China; [Liu, Xin] Suzhou LungCare Med Technol Co Ltd, Suzhou 215021, Peoples R China; [Cao, Shucheng] King Abdullah Univ Sci & Technol, Bioengn, Biol & Environm Sci & Engn Div, Thuwal 23955, Saudi Arabia; [Zhang, Qi] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Taipa 999078, Macau, Peoples R China; [Liu, Shangqing] Southern Med Univ, Sch Biomed Engn, Guangzhou 510515, Peoples R China; [Wang, Yunpeng] Fudan Univ, Inst Biomed Sci, Shanghai 200433, Peoples R China; [Li, Yuhui] Univ Southern Calif, Computat Biol, Los Angeles, CA 90007 USA; [He, Jian] Nanjing Drum Tower Hosp, Dept Nucl Med, Nanjing 210008, Peoples R China; [Yang, Xiaoping] Nanjing Univ, Dept Math, Nanjing 210023, Peoples R China	Nanjing University of Science & Technology; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Nanjing University of Information Science & Technology; Jiangsu University of Technology; Beihang University; Tianjin University of Technology; Norwegian University of Science & Technology (NTNU); Nanjing University; King Abdullah University of Science & Technology; University of Macau; Southern Medical University - China; Fudan University; University of Southern California; Nanjing University; Nanjing University	Yang, XP (corresponding author), Nanjing Univ, Dept Math, Nanjing 210023, Peoples R China.	junma@njust.edu.cn; zhangyao215@mails.ucas.ac.cn; gusong1996@gmail.com; zhuc@hcsd-med.com; 13851520957@163.com; cada1998@buaa.edu.cn; anxingle820@gmail.com; congcong.wang6@outlook.com; qyuanwang@gmail.com; wxliuxin163@163.com; shucheng.cao@kaust.edu.sa; mb85402@um.edu.mo; shang56118@smu.edu.cn; wangyunpengbio@gmail.com; yuhuili@usc.edu; hjxueren@163.com; xpyang@nju.edu.cn	Zhang, Yichi/GZM-1393-2022; Zhang, Yao/ABI-4071-2022	Zhang, Yichi/0000-0002-4292-6835; Zhang, Yao/0000-0002-8759-4811; Cao, Shucheng/0000-0002-9115-6259; Wang, Yunpeng/0000-0002-0183-8345; ma, jun/0000-0002-9739-0855; Gu, Song/0000-0001-9716-5052	China's Ministry of Science and Technology [2020YFA0713800]; National Natural Science Foundation of China [11971229, 12090023]	China's Ministry of Science and Technology(Ministry of Science and Technology, China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by China's Ministry of Science and Technology under Grant 2020YFA0713800 and National Natural Science Foundation of China under Grants 11971229, No. 12090023.	Alberto Montes, 2019, Arxiv, DOI arXiv:1905.00737; Amber L. Simpson, 2019, Arxiv, DOI arXiv:1902.09063; Bakas S., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1811.02629; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bilic P., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1901.04056; Camoriano Raffaello, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3207, DOI 10.1109/ICRA.2017.7989364; Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009; Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; DAVIS, DENSELY ANNOTATED VI; Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012; Gao MC, 2016, I S BIOMED IMAGING, P1265, DOI 10.1109/ISBI.2016.7493497; George K, 2017, LECT NOTES COMPUT SC, V10553, P195, DOI 10.1007/978-3-319-67558-9_23; Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309; Goodfellow I. J., 2014, PROC INT C LEARN REP; Guo DZ, 2020, PROC CVPR IEEE, P4222, DOI 10.1109/CVPR42600.2020.00428; Harrison AP, 2017, P INT C MED IM COMP, P621; He Y., 2021, PROC IEEE C COMPUT V, P5841; Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851; Heinrich MP, 2019, MED IMAGE ANAL, V54, P1, DOI 10.1016/j.media.2019.02.006; Heller N., 2020, AM SOC CLIN ONCOL, V38, P626; Heller N, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101821; Hu PJ, 2017, INT J COMPUT ASS RAD, V12, P399, DOI 10.1007/s11548-016-1501-5; Humpire-Mamani GE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190102; Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521; Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z; Ji ZHX, 2019, LECT NOTES COMPUT SC, V11766, P175, DOI 10.1007/978-3-030-32248-9_20; Jie Li, 2019, Arxiv, DOI arXiv:1906.07367; Jimenez-del-Toro O, 2016, IEEE T MED IMAGING, V35, P2459, DOI 10.1109/TMI.2016.2578680; Jin DK, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101909; Joskowicz L, 2019, EUR RADIOL, V29, P1391, DOI 10.1007/s00330-018-5695-5; Ma J, 2021, Arxiv, DOI arXiv:2101.00232; Kanavati F, 2017, LECT NOTES COMPUT SC, V10541, P79, DOI 10.1007/978-3-319-67389-9_10; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kavur AE, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101950; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Landman B., 2015, P MICCAI MULT LAB CR; Larsson M, 2018, APPL SOFT COMPUT, V70, P465, DOI 10.1016/j.asoc.2018.05.038; Lee D.-H., 2013, INT C MACH LEARN WOR, V3, P1; Lee H. H., 2020, MEDICAL IMAGING 2020, DOI 10.1117/12.2549033.short?SSO=1-tab=ArticleLink; Li GD, 2015, IEEE T IMAGE PROCESS, V24, P5315, DOI 10.1109/TIP.2015.2481326; Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081; Liang-Chieh Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P695, DOI 10.1007/978-3-030-58545-7_40; Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344; Liu Y, 2022, IEEE T PATTERN ANAL, V44, P1415, DOI 10.1109/TPAMI.2020.3023152; Lomonaco V., 2017, ARXIV170503550, V78, P17; Ma J, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102035; Ma J, 2021, IEEE T MED IMAGING, V40, P93, DOI 10.1109/TMI.2020.3022693; De Lange M, 2019, Arxiv, DOI arXiv:1909.08383; Meinzer HP, 2002, COMPUT GRAPH-UK, V26, P569, DOI 10.1016/S0097-8493(02)00102-4; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28; Ni ZK, 2021, SURG INNOV, V28, P71, DOI 10.1177/1553350620954581; Nikolov S., 2018, ARXIV; Norgeot B, 2020, NAT MED, V26, P1320, DOI 10.1038/s41591-020-1041-y; Okada T, 2015, MED IMAGE ANAL, V26, P1, DOI 10.1016/j.media.2015.06.009; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Peng JL, 2015, MED PHYS, V42, P6840, DOI 10.1118/1.4934834; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Roth Holger, 2016, TCIA, DOI [10.5281/ZENODO.6872386, 10.7937/K9/TCIA.2016.TNB1KQBU]; Pf_ulb B., 2019, PROC INT C LEARN REP; Pont-Tuset J., 2017, ARXIV; Qian R, 2019, AAAI CONF ARTIF INTE, P8843; Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070; Raju Ashwin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P448, DOI 10.1007/978-3-030-58592-1_27; Rister B, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00715-8; Ronneberger O., 2015, P MEDICAL IMAGE COMP, P234; Roth Holger R., 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P451, DOI 10.1007/978-3-319-46723-8_52; Roth HR, 2018, LECT NOTES COMPUT SC, V11073, P417, DOI 10.1007/978-3-030-00937-3_48; Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001; Roth HR, 2018, MED IMAGE ANAL, V45, P94, DOI 10.1016/j.media.2018.01.006; Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68; Zhou SK, 2021, Arxiv, DOI arXiv:2008.09104; Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320; Shi GL, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.101979; Siri SK, 2017, COMPUT METH PROG BIO, V151, P101, DOI 10.1016/j.cmpb.2017.08.020; Song CF, 2019, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2019.00325; Sykes J, 2014, J MED RADIAT SCI, V61, P131, DOI 10.1002/jmrs.65; Tajbakhsh N, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101693; van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6; van Ginneken B, 2011, RADIOLOGY, V261, P719, DOI 10.1148/radiol.11091710; Wang X, 2020, INT J COMPUT VISION, V128, P1736, DOI 10.1007/s11263-020-01293-3; Wang Y, 2019, MED IMAGE ANAL, V55, P88, DOI 10.1016/j.media.2019.04.005; Xia YD, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101766; Xie LX, 2020, IEEE T MED IMAGING, V39, P514, DOI 10.1109/TMI.2019.2930679; Xu ZB, 2015, MED IMAGE ANAL, V24, P18, DOI 10.1016/j.media.2015.05.009; Xue J, 2021, IEEE T CYBERNETICS, V51, P2153, DOI 10.1109/TCYB.2019.2955178; Yao JW, 2019, LECT NOTES COMPUT SC, V11768, P318, DOI 10.1007/978-3-030-32254-0_36; Zeng HR, 2019, IEEE INT C BIOINFORM, P1409, DOI 10.1109/BIBM47256.2019.8983127; Zhang L, 2020, IEEE T MED IMAGING, V39, P2782, DOI 10.1109/TMI.2020.2975347; Zhang X, 2010, IEEE T BIO-MED ENG, V57, P2622, DOI 10.1109/TBME.2010.2056369; Zhang Y, 2017, CHIN AUTOM CONGR, P3864; Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002; Zhou X, 2005, INT CONGR SER, V1281, P1169, DOI 10.1016/j.ics.2005.03.079; Zhou XR, 2016, LECT NOTES COMPUT SC, V10008, P111, DOI 10.1007/978-3-319-46976-8_12; Zhou Y., 2016, MICCAI, DOI 10.1007/978-3-319-66182-7; Zhou YY, 2019, IEEE I CONF COMP VIS, P10671, DOI [10.1109/ICCV.2019.01077, 10.1109/SDPC.2019.00126]; Zhou YY, 2019, IEEE WINT CONF APPL, P121, DOI 10.1109/WACV.2019.00020; Zhu ZT, 2019, INT CONF 3D VISION, P240, DOI 10.1109/3DV.2019.00035	105	11	11	14	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6695	6714		10.1109/TPAMI.2021.3100536	http://dx.doi.org/10.1109/TPAMI.2021.3100536			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34314356	Green Published, Green Submitted			2022-12-18	WOS:000853875300063
J	Brachmann, E; Rother, C				Brachmann, Eric; Rother, Carsten			Visual Camera Re-Localization From RGB and RGB-D Images Using DSAC	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Training; Three-dimensional displays; Visualization; Optimization; Neural networks; Solid modeling; Camera re-localization; pose estimation; differentiable RANSAC; DSAC; differentiable argmax; differentiable PnP		We describe a learning-based system that estimates the camera position and orientation from a single input image relative to a known environment. The system is flexible w.r.t. the amount of information available at test and at training time, catering to different applications. Input images can be RGB-D or RGB, and a 3D model of the environment can be utilized for training but is not necessary. In the minimal case, our system requires only RGB images and ground truth poses at training time, and it requires only a single RGB image at test time. The framework consists of a deep neural network and fully differentiable pose optimization. The neural network predicts so called scene coordinates, i.e., dense correspondences between the input image and 3D scene space of the environment. The pose optimization implements robust fitting of pose parameters using differentiable RANSAC (DSAC) to facilitate end-to-end training. The system, an extension of DSAC++ and referred to as DSAC*, achieves state-of-the-art accuracy on various public datasets for RGB-based re-localization, and competitive accuracy for RGB-D based re-localization.	[Brachmann, Eric] Niantic, San Francisco, CA 94104 USA; [Rother, Carsten] Heidelberg Univ, Visual Learning Lab, D-69117 Heidelberg, Germany	Ruprecht Karls University Heidelberg	Brachmann, E (corresponding author), Niantic, San Francisco, CA 94104 USA.	ebrachmann@nianticlabs.com; carsten.rother@iwr.uni-heidelberg.de			COVMAP: Intelligente Karten mittels gemeinsamer GPS-und Videodatenanalyse, DFG [RO 4804/2-1, RO 2497/12-2]; European Research Council (ERC) through the European Unions Horizon 2020 programme [647769]	COVMAP: Intelligente Karten mittels gemeinsamer GPS-und Videodatenanalyse, DFG(German Research Foundation (DFG)); European Research Council (ERC) through the European Unions Horizon 2020 programme(European Research Council (ERC))	The authors would like to thank Dehui Lin for implementing an efficient version of the differentiable Kabsch pose solver within the scope of his master's thesis. This work was supported in part by the COVMAP: Intelligente Karten mittels gemeinsamer GPS-und Videodatenanalyse, DFG, under Grants RO 4804/2-1 and RO 2497/12-2 and in part by European Research Council (ERC) through the European Unions Horizon 2020 programme under Grant 647769. The computations were performed on an HPC Cluster at the Center for Information Services and High Performance Computing (ZIH) at TU Dresden. This work was done while E. Brachmann was at the Visual Learning Lab, HeidelbergUniversity.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Avetisyan A, 2019, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2019.00264; Ba J., 2017, P 3 INT C LEARN REPR; Balntas V, 2018, LECT NOTES COMPUT SC, V11218, P782, DOI 10.1007/978-3-030-01264-9_46; Bhowmik A, 2020, PROC CVPR IEEE, P4947, DOI 10.1109/CVPR42600.2020.00500; Brachmann E, 2019, IEEE I CONF COMP VIS, P7524, DOI 10.1109/ICCV.2019.00762; Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442; Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Bradski G, 2000, DR DOBBS J, V25, P120; Brahmbhatt S, 2018, PROC CVPR IEEE, P2616, DOI 10.1109/CVPR.2018.00277; Camposeco F, 2019, PROC CVPR IEEE, P7645, DOI 10.1109/CVPR.2019.00784; Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96; Cavallari T, 2019, INT CONF 3D VISION, P564, DOI 10.1109/3DV.2019.00068; Cavallari T, 2020, IEEE T PATTERN ANAL, V42, P2465, DOI 10.1109/TPAMI.2019.2915068; Cavallari T, 2017, PROC CVPR IEEE, P218, DOI 10.1109/CVPR.2017.31; Chapelle O, 2010, INFORM RETRIEVAL, V13, P216, DOI 10.1007/s10791-009-9110-3; Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Ding MY, 2019, IEEE I CONF COMP VIS, P2871, DOI 10.1109/ICCV.2019.00296; Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forstner W, 2016, GEOM COMPUT, V11; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Guzman-Rivera A, 2014, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2014.146; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Jay Iorio, 2018, Arxiv, DOI arXiv:1804.08386; KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Lee J, 2019, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2019.00238; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Li X., 2018, EUR C COMP VIS, P229; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Lim H, 2012, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2012.6247782; Long J., 2015, P 2015 IEEE C COMP V, P3431, DOI [10.1109/CVPR.2015.7298965, DOI 10.1109/CVPR.2015.7298965]; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Massiceti Daniela, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5118, DOI 10.1109/ICRA.2017.7989598; Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009; Meng LL, 2018, IEEE INT C INT ROBOT, P6827, DOI 10.1109/IROS.2018.8593505; Meng LL, 2017, IEEE INT C INT ROBOT, P6886; Naseer T, 2017, IEEE INT C INT ROBOT, P1525; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Papadopoulo T, 2000, LECT NOTES COMPUT SC, V1842, P554; Paszke A., 2017, AUTOMATIC DIFFERENTI; Probst T, 2019, PROC CVPR IEEE, P929, DOI 10.1109/CVPR.2019.00102; Ranftl R, 2018, LECT NOTES COMPUT SC, V11205, P292, DOI 10.1007/978-3-030-01246-5_18; Revaud J, 2019, ADV NEUR IN, V32; Rocco I, 2018, ADV NEUR IN, V31; Saha Soham, 2018, P BRIT MACH VIS C; Sattler T, 2019, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR.2019.00342; Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Schmidt T, 2017, IEEE ROBOT AUTOM LET, V2, P420, DOI 10.1109/LRA.2016.2634089; Schonberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Schull J, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P1, DOI 10.1145/2700648.2809870; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331; Svarm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75; Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752; Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790; Valentin J, 2016, INT CONF 3D VISION, P323, DOI 10.1109/3DV.2016.41; Valentin J, 2015, PROC CVPR IEEE, P4400, DOI 10.1109/CVPR.2015.7299069; Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Xiaotian Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11980, DOI 10.1109/CVPR42600.2020.01200; Yang LW, 2019, IEEE I CONF COMP VIS, P42, DOI 10.1109/ICCV.2019.00013; Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282; Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28; Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594; Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80	84	11	11	7	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5847	5865		10.1109/TPAMI.2021.3070754	http://dx.doi.org/10.1109/TPAMI.2021.3070754			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33798073	Green Submitted, hybrid			2022-12-18	WOS:000836666600093
J	Xie, JY; Ma, ZY; Lei, JJ; Zhang, GQ; Xue, JH; Tan, ZH; Guo, J				Xie, Jiyang; Ma, Zhanyu; Lei, Jianjun; Zhang, Guoqiang; Xue, Jing-Hao; Tan, Zheng-Hua; Guo, Jun			Advanced Dropout: A Model-Free Methodology for Bayesian Dropout Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Bayes methods; Standards; Gaussian distribution; Adaptation models; Stochastic processes; Neural networks; Deep neural network; dropout; model-free distribution; Bayesian approximation; stochastic gradient variational Bayes	DEEP NEURAL-NETWORKS; REGULARIZATION	Due to lack of data, overfitting ubiquitously exists in real-world applications of deep neural networks (DNNs). We propose advanced dropout, a model-free methodology, to mitigate overfitting and improve the performance of DNNs. The advanced dropout technique applies a model-free and easily implemented distribution with parametric prior, and adaptively adjusts dropout rate. Specifically, the distribution parameters are optimized by stochastic gradient variational Bayes in order to carry out an end-to-end training. We evaluate the effectiveness of the advanced dropout against nine dropout techniques on seven computer vision datasets (five small-scale datasets and two large-scale datasets) with various base models. The advanced dropout outperforms all the referred techniques on all the datasets. We further compare the effectiveness ratios and find that advanced dropout achieves the highest one on most cases. Next, we conduct a set of analysis of dropout rate characteristics, including convergence of the adaptive dropout rate, the learned distributions of dropout masks, and a comparison with dropout rate generation without an explicit distribution. In addition, the ability of overfitting prevention is evaluated and confirmed. Finally, we extend the application of the advanced dropout to uncertainty inference, network pruning, text classification, and regression. The proposed advanced dropout is also superior to the corresponding referred methods. Codes are available at https://github.com/PRIS-CV/AdvancedDropout.	[Xie, Jiyang; Ma, Zhanyu; Guo, Jun] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China; [Lei, Jianjun] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China; [Zhang, Guoqiang] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW 2007, Australia; [Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England; [Tan, Zheng-Hua] Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark	Beijing University of Posts & Telecommunications; Tianjin University; University of Technology Sydney; University of London; University College London; Aalborg University	Ma, ZY (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China.	xiejiyang2013@bupt.edu.cn; mazhanyu@bupt.edu.cn; jjlei@tju.edu.cn; guoqiang.zhang@uts.edu.au; jinghao.xue@ucl.ac.uk; zt@es.aau.dk; guojun@bupt.edu.cn			National Key R&D Program of China [2019YFF0303300, 2019YFF0303302]; NationalNatural Science Foundation of China (NSFC) [61922015, 61773071, U19B2036]; Beijing Natural Science Foundation Project [Z200002]; Beijing Nova Programme Interdisciplinary Cooperation Project [Z191100001119140]	National Key R&D Program of China; NationalNatural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation Project(Beijing Natural Science Foundation); Beijing Nova Programme Interdisciplinary Cooperation Project	This work was supported in part by the National Key R&D Program of China under Grant 2019YFF0303300 and under Subject IINo. 2019YFF0303302, in part by the NationalNatural Science Foundation of China (NSFC) under Grant 61922015, 61773071, U19B2036, in part by Beijing Natural Science Foundation Project under Grant Z200002, and in part by the Beijing Nova Programme Interdisciplinary Cooperation Project under Grant Z191100001119140.	Achille A, 2018, IEEE T PATTERN ANAL, V40, P2897, DOI 10.1109/TPAMI.2017.2784440; Adeli E, 2019, IEEE T PATTERN ANAL, V41, P515, DOI 10.1109/TPAMI.2018.2794470; Alex Krizhevsky, 2012, Arxiv, DOI arXiv:1207.0580; Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Ba J., 2013, ADV NEURAL INFORM PR, P3084; Bai C, 2021, IEEE T MULTIMEDIA, V23, P2199, DOI 10.1109/TMM.2021.3065578; Bishop C.M, 2006, PATTERN RECOGN; Bulo SR, 2016, PR MACH LEARN RES, V48; Charles Blundell, 2017, Arxiv, DOI arXiv:1606.04080; Chen J, 2019, NEUROCOMPUTING, V361, P173, DOI 10.1016/j.neucom.2019.04.090; Dua D., 2017, UCI MACHINE LEARNING, DOI DOI 10.1002/JCC.23219; Frankle J., 2019, PROC INT C LEARN REP; Gal Y., 2017, ADV NEUR IN; Gal Y, 2016, PR MACH LEARN RES, V48; Gal Yarin, 2016, ADV NEURAL INFORM PR, P1019, DOI DOI 10.5555/3157096.3157211; Gao H, 2019, PROC INT C MACH LEAR, P2112; Gimpel K, 2017, P INT C LEARN REPR; Griffin G, 2006, CALTECH256 IMAGE DAT; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Khan SH, 2019, NEURAL NETWORKS, V110, P82, DOI 10.1016/j.neunet.2018.09.009; Kingma DP, 2015, ADV NEUR IN, V28; Kingma DP, 2 INT C LEARN REPR I, P1; Ko B, 2017, INT CONF BIG DATA, P358, DOI 10.1109/BIGCOMP.2017.7881693; Krizhevsky A., 2009, LEARNING MULTIPLE LA; LeCun Y, 2011, MNIST DATABASE HANDW, DOI DOI 10.1109/MSP.2012.2211477; Li SW, 2016, LECT NOTES COMPUT SC, V9905, P349, DOI 10.1007/978-3-319-46448-0_21; Li XX, 2019, IEEE T VEH TECHNOL, V68, P4204, DOI 10.1109/TVT.2019.2895651; Li XX, 2019, IEEE ACCESS, V7, P19572, DOI 10.1109/ACCESS.2019.2897692; Liu L, 2019, IEEE ACCESS, V7, P36140, DOI 10.1109/ACCESS.2019.2904881; Liu YH, 2019, PROC CVPR IEEE, P7117, DOI 10.1109/CVPR.2019.00729; Ma Kede, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P851, DOI 10.1109/TPAMI.2018.2889948; Ma X., 2017, ICLR 2017; Ma ZY, 2019, IEEE ACCESS, V7, P59728, DOI 10.1109/ACCESS.2019.2914455; Ma ZY, 2011, IEEE T PATTERN ANAL, V33, P2160, DOI 10.1109/TPAMI.2011.63; Maddison Chris J, 2017, ICLR; Maeda S.-i., 2014, ARXIV PREPRINT ARXIV; Malinin A, 2018, ADV NEUR IN, V31; Peng Xu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P19, DOI 10.1007/978-3-319-46604-0_2; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salehinejad H, 2019, INT CONF ACOUST SPEE, P3602, DOI 10.1109/ICASSP.2019.8682914; Shen X, 2018, IEEE T NEUR NET LEAR, V29, P3926, DOI 10.1109/TNNLS.2017.2750679; Simonyan Karen, 2015, VERY DEEP CONVOLUTIO; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; van den Oord A, 2016, PR MACH LEARN RES, V48; Wan L., 2013, P INT C MACHINE LEAR, P1058; Wang HT, 2019, NEUROCOMPUTING, V357, P177, DOI 10.1016/j.neucom.2019.05.008; Wang SJ, 2019, PR MACH LEARN RES, V97; Xie JY, 2019, IEEE INT WORKS MACH; Xu P, 2018, PROC CVPR IEEE, P8090, DOI 10.1109/CVPR.2018.00844; Xu P, 2018, NEUROCOMPUTING, V278, P75, DOI 10.1016/j.neucom.2017.05.099; Xu Z, 2018, IEEE T PATTERN ANAL, V40, P1100, DOI 10.1109/TPAMI.2016.2637331; Yao SC, 2018, INT CON DISTR COMP S, P334, DOI 10.1109/ICDCS.2018.00041; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhe L., 2016, ADV NEURAL INFORM PR, P2531; Zhu FY, 2019, NEUROCOMPUTING, V328, P182, DOI 10.1016/j.neucom.2018.02.099	59	11	11	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4605	4625		10.1109/TPAMI.2021.3083089	http://dx.doi.org/10.1109/TPAMI.2021.3083089			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	34029187	Green Submitted			2022-12-18	WOS:000836666600013
J	Peng, SD; Zhou, XW; Liu, Y; Lin, HT; Huang, QX; Bao, HJ				Peng, Sida; Zhou, Xiaowei; Liu, Yuan; Lin, Haotong; Huang, Qixing; Bao, Hujun			PVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose estimation; Three-dimensional displays; Two dimensional displays; Solid modeling; Prediction algorithms; Computational modeling; Uncertainty; Object pose estimation; pixel-wise voting networks; keypoint detection		This paper addresses the problem of instance-level 6DoF object pose estimation from a single RGB image. Many recent works have shown that a two-stage approach, which first detects keypoints and then solves a Perspective-n-Point (PnP) problem for pose estimation, achieves remarkable performance. However, most of these methods only localize a set of sparse keypoints by regressing their image coordinates or heatmaps, which are sensitive to occlusion and truncation. Instead, we introduce a Pixel-wise Voting Network (PVNet) to regress pixel-wise vectors pointing to the keypoints and use these vectors to vote for keypoint locations. This creates a flexible representation for localizing occluded or truncated keypoints. Another important feature of this representation is that it provides uncertainties of keypoint locations that can be further leveraged by the PnP solver. Experiments show that the proposed approach outperforms the state of the art on the LINEMOD, Occluded LINEMOD, YCB-Video, and Tless datasets, while being efficient for real-time pose estimation. We further create a Truncated LINEMOD dataset to validate the robustness of our approach against truncation. The code is available at https://github.com/zju3dv/pvnet.	[Peng, Sida; Zhou, Xiaowei; Lin, Haotong; Bao, Hujun] Zhejiang Univ, Coll Comp Sci, Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China; [Liu, Yuan] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Huang, Qixing] Univ Texas Austin, Coll Comp Sci, Austin, TX 78712 USA	Zhejiang University; University of Hong Kong; University of Texas System; University of Texas Austin	Bao, HJ (corresponding author), Zhejiang Univ, Coll Comp Sci, Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.	pengsida@zju.edu.cn; xwzhou@zju.edu.cn; yliupal@hku.hk; haotongl@zju.edu.cn; huangqx@cs.utexas.edu; bao@cad.zju.edu.cn		Peng, Sida/0000-0001-6546-4525; Bao, Hujun/0000-0002-2662-0334; Lin, Haotong/0000-0001-5862-3268	National Key Research and Development Program of China [2020AAA0108901]; NSFC [61806176]; ZJU-SenseTime Joint Lab of 3D Vision; NSF [HDR TRIPODS-1934932]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); ZJU-SenseTime Joint Lab of 3D Vision; NSF(National Science Foundation (NSF))	The authors from Zhejiang University would like to acknowledge the support from the National Key Research and Development Program of China (No. 2020AAA0108901), NSFC (No. 61806176), and ZJU-SenseTime Joint Lab of 3D Vision. The work of Q. Huang was supported by the NSF HDR TRIPODS-1934932. Sida Peng and Xiaowei Zhou contributed equally to this work.	Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35; Bui M, 2018, IEEE INT CONF ROBOT, P6140; Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Chen Wang, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10059, DOI 10.1109/ICRA40945.2020.9196679; Chen W, 2020, PROC CVPR IEEE, P4232, DOI 10.1109/CVPR42600.2020.00429; Dengsheng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11970, DOI 10.1109/CVPR42600.2020.01199; Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390; Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ferraz L., 2014, P BRIT MACH VIS C NO, DOI 10.5244/C.28.83; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379; Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206; Hinterstoisser Stefan, 2012, P AS C COMP VIS, P2, DOI DOI 10.1007/978-3-642-37331-2_42; Hodan Tomas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11700, DOI 10.1109/CVPR42600.2020.01172; Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2; Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103; Hodan T, 2016, LECT NOTES COMPUT SC, V9915, P606, DOI 10.1007/978-3-319-49409-8_52; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169; Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Labbe Yann, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P574, DOI 10.1007/978-3-030-58520-4_34; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI 10.1007/978-3-030-01231-1_42; Li ZG, 2019, IEEE I CONF COMP VIS, P7677, DOI 10.1109/ICCV.2019.00777; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Meng Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P530, DOI 10.1007/978-3-030-58589-1_32; Michel F, 2017, PROC CVPR IEEE, P115, DOI 10.1109/CVPR.2017.20; Najibi Mahyar, 2020, P IEEE CVF C COMP VI, P11913; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8; Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17; Park K, 2019, IEEE I CONF COMP VIS, P7667, DOI 10.1109/ICCV.2019.00776; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469; Pitteri G, 2019, INT CONF 3D VISION, P614, DOI 10.1109/3DV.2019.00073; Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937; Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Sun, 2020, 2020 IEEE CVF C COMP, P11629, DOI DOI 10.1109/CVPR42600.2020.01165; Sun M, 2010, LECT NOTES COMPUT SC, V6315, P658, DOI 10.1007/978-3-642-15555-0_48; Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43; Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038; Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758; Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346; Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xu Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P139, DOI 10.1007/978-3-030-58574-7_9; Yu F., 2016, P ICLR 2016; Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255; Yu X., 2020, CHINESE CENTRA 0527; Zakharov S, 2019, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2019.00203; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhou X., 2019, ARXIV; Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589; Zhu ML, 2014, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2014.6907430	75	11	11	19	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3212	3223		10.1109/TPAMI.2020.3047388	http://dx.doi.org/10.1109/TPAMI.2020.3047388			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33360984				2022-12-18	WOS:000803117500031
J	Simonelli, A; Bulo, SR; Porzi, L; Antequera, ML; Kontschieder, P				Simonelli, Andrea; Bulo, Samuel Rota; Porzi, Lorenzo; Antequera, Manuel Lopez; Kontschieder, Peter			Disentangling Monocular 3D Object Detection: From Single to Multi-Class Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Two dimensional displays; Measurement; Shape; Object detection; Feature extraction; Estimation; Computer vision; object recognition; vision and scene understanding; 3D; Stereo scene analysis; object detection		In this paper we introduce a method for multi-class, monocular 3D object detection from a single RGB image, which exploits a novel disentangling transformation and a novel, self-supervised confidence estimation method for predicted 3D bounding boxes. The proposed disentangling transformation isolates the contribution made by different groups of parameters to a given loss, without changing its nature. This brings two advantages: i) it simplifies the training dynamics in the presence of losses with complex interactions of parameters; and ii) it allows us to avoid the issue of balancing independent regression terms. We further apply this disentangling transformation to another novel, signed Intersection-over-Union criterion-driven loss for improving 2D detection results. We also critically review the AP metric used in KITTI3D and resolve a flaw which affected and biased all previously published results on monocular 3D detection. Our improved metric is now used as official KITTI3D metric. We provide extensive experimental evaluations and ablation studies on the KITTI3D and nuScenes datasets, setting new state-of-the-art results. We provide additional results on all the classes of KITTI3D as well as nuScenes datasets to further validate the robustness of our method, demonstrating its ability to generalize for different types of objects.	[Simonelli, Andrea] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy; [Simonelli, Andrea] Fdn Bruno Kessler, I-38123 Trento, Italy; [Bulo, Samuel Rota; Porzi, Lorenzo; Antequera, Manuel Lopez; Kontschieder, Peter] Facebook, CH-94025 Zurich, Switzerland	University of Trento; Fondazione Bruno Kessler; Facebook Inc	Simonelli, A (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy.	andrea.simonelli@unitn.it; rotabulo@fb.com; porzi@fb.com; mlop@fb.com; pkontschieder@fb.com		Simonelli, Andrea/0000-0001-9636-3751				[Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Barabanau I., 2019, ABS190505618; Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938; Caesar H., 2019, P IEEE CVF C COMP VI; Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198; Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691; Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236; Chen XZ, 2015, ADV NEUR IN, V28; DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; He T., 2019, ABS190103446; Jorgensen E., 2019, ARXIV190608070; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169; Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049; Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214; Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375; Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298; Law H., 2018, INT J COMPUT VISION, DOI DOI 10.1007/s11263-019-01204-1; Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111; Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783; Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Liu LJ, 2019, PROC CVPR IEEE, P1057, DOI 10.1109/CVPR.2019.00115; Ma XZ, 2019, IEEE I CONF COMP VIS, P6850, DOI 10.1109/ICCV.2019.00695; Manhardt F, 2019, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2019.00217; Meyer GP, 2019, PROC CVPR IEEE, P12669, DOI 10.1109/CVPR.2019.01296; Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597; Murthy J. Krishna, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P724, DOI 10.1109/ICRA.2017.7989089; Pillai S, 2019, IEEE INT CONF ROBOT, P9250, DOI 10.1109/ICRA.2019.8793621; Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102; Qin ZY, 2019, PROC CVPR IEEE, P7607, DOI 10.1109/CVPR.2019.00780; Qin Zengyi, 2018, ARXIV181110247; Reddy ND, 2019, PROC CVPR IEEE, P7318, DOI 10.1109/CVPR.2019.00750; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Roddick Thomas, 2018, ARXIV181108188; Shi S., 2019, ABS190703670; Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086; Shin K., 2018, ABS181103818; Simonelli A, 2019, IEEE I CONF COMP VIS, P1991, DOI 10.1109/ICCV.2019.00208; Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826; Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI 10.1109/IROS40897.2019.8968513; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108; Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800; Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249; Yang B., 2018, C ROBOT LEARNING; Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798; You Y., 2019, ABS190606310; Zia MZ, 2014, PROC CVPR IEEE, P3678, DOI 10.1109/CVPR.2014.470	57	11	12	9	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1219	1231		10.1109/TPAMI.2020.3025077	http://dx.doi.org/10.1109/TPAMI.2020.3025077			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32946384				2022-12-18	WOS:000752018000012
J	Sun, QR; Liu, YY; Chen, ZZ; Chua, TS; Schiele, B				Sun, Qianru; Liu, Yaoyao; Chen, Zhaozheng; Chua, Tat-Seng; Schiele, Bernt			Meta-Transfer Learning Through Hard Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Adaptation models; Training; Feature extraction; Training data; Data models; Measurement; Few-shot learning; transfer learning; meta learning; image classification		Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, typical meta-learning models use shallow neural networks, thus limiting its effectiveness. In order to achieve top performance, some recent works tried to use the DNNs pre-trained on large-scale datasets but mostly in straight-forward manners, e.g., (1) taking their weights as a warm start of meta-training, and (2) freezing their convolutional layers as the feature extractor of base-learners. In this paper, we propose a novel approach called meta-transfer learning (MTL), which learns to transfer the weights of a deep NN for few-shot learning tasks. Specifically, meta refers to training multiple tasks, and transfer is achieved by learning scaling and shifting functions of DNN weights (and biases) for each task. To further boost the learning efficiency of MTL, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum of few-shot classification tasks. We conduct experiments for five-class few-shot classification tasks on three challenging benchmarks, miniImageNet, tieredImageNet, and Fewshot-CIFAR100 (FC100), in both supervised and semi-supervised settings. Extensive comparisons to related works validate that our MTL approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.	[Sun, Qianru; Chen, Zhaozheng] Singapore Management Univ, Sch Informat Syst, Singapore 178902, Singapore; [Liu, Yaoyao; Schiele, Bernt] Max Planck Inst Informat, Dept Comp Vis & Machine Learning, D-66123 Saarbrucken, Germany; [Chua, Tat-Seng] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore	Singapore Management University; Max Planck Society; National University of Singapore	Sun, QR (corresponding author), Singapore Management Univ, Sch Informat Syst, Singapore 178902, Singapore.	qianrusun@smu.edu.sg; yaoyao.liu@mpi-inimpg.de; zhaozhengcc@gmail.com; chuats@comp.nus.edu.sg; schiele@mpi-inimpg.de	Liu, Yaoyao/AAV-1380-2021; Chen, Zhaozheng/GXV-5366-2022	Liu, Yaoyao/0000-0002-5316-3028; Chen, Zhaozheng/0000-0002-1260-5635	Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant; National Research Foundation, Singapore under its International Research Centres in Singapore Funding Initiative	Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant(Ministry of Education, Singapore); National Research Foundation, Singapore under its International Research Centres in Singapore Funding Initiative	This work was supported by the Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant. This research is as part of NExT++, a research is supported by the National Research Foundation, Singapore under its International Research Centres in Singapore Funding Initiative. Qianru Sun and Yaoyao Liu contributed equally to this work.	Antoniou A., 2019, PROC INT C LEARN REP; Bartunov Sergey, 2018, INT C ART INT STAT, P670; Bauer M., 2017, ARXIV170600326; Bengio Samy, 1992, C OPT ART BIOL NEUR, P6; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bertinetto L, 2019, PROC INT C LEARN REP; Canevet Olivier, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P5128, DOI 10.1109/CVPR.2016.554; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Clevert D., 2016, PROC INT C LEARN REP; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dvornik N, 2019, IEEE I CONF COMP VIS, P3722, DOI 10.1109/ICCV.2019.00382; Erhan D, 2010, J MACH LEARN RES, V11, P625; Finn C, 2017, PR MACH LEARN RES, V70; Finn Chelsea, 2018, ADV NEURAL INFORM PR, P9516; Franceschi L, 2018, PR MACH LEARN RES, V80; Grant E., 2018, PROC INT C LEARN REP; Graves A, 2017, PR MACH LEARN RES, V70; Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883; Harwood B, 2017, IEEE I CONF COMP VIS, P2840, DOI 10.1109/ICCV.2017.307; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G.E., 1987, P 9 ANN C COGNITIVE, P177; Hou RB, 2019, ADV NEUR IN, V32; Hu S. X, 2020, PROC INT C LEARN REP, P1; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Ioffe S., 2015, INT C MACH LEARN, P448, DOI [10.5555/3045118.3045167, DOI 10.5555/3045118.3045167]; Keshari R, 2018, PROC CVPR IEEE, P9349, DOI 10.1109/CVPR.2018.00974; Khoreva A, 2019, INT J COMPUT VISION, V127, P1175, DOI 10.1007/s11263-019-01164-6; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee K., 2019, PROC IEEECVF C COMPU, p10 657; Lee Y, 2018, PR MACH LEARN RES, V80; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li HY, 2019, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2019.00009; Li HY, 2019, PR MACH LEARN RES, V97; Li XZ, 2019, ADV NEUR IN, V32; Li Zhenguo, 2017, METASGD LEARNING LEA; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu Y., 2019, PROC INT C LEARN REP; Lopez-Paz D, 2017, ADV NEUR IN, V30; Lu J, 2018, PR MACH LEARN RES, V80; MCNAUGHTON BL, 1983, EXP BRAIN RES, V52, P41; Mehrotra Akshay, 2017, ARXIV170308033; Mishra N., 2018, PROC INT C LEARN REP; Munkhdalai T, 2018, PR MACH LEARN RES, V80; Munkhdalai T, 2017, PR MACH LEARN RES, V70; Naik D. K., 1992, IJCNN International Joint Conference on Neural Networks (Cat. No.92CH3114-6), P437, DOI 10.1109/IJCNN.1992.287172; Oreshkin BN, 2018, ADV NEUR IN, V31; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pentina A, 2015, PROC CVPR IEEE, P5492, DOI 10.1109/CVPR.2015.7299188; Perez E, 2018, AAAI CONF ARTIF INTE, P3942; Prol H., 2018, ARXIV181200273; Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755; Ravi S., 2017, P INT C LEARN REPR, P1; Ren C, 2010, EUR J INORG CHEM, P5545, DOI 10.1002/ejic.201000731; Ren M., 2018, PROC INT C LEARN REP; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Rusu A. A., 2019, PROC INT C LEARN REP; Santoro A, 2016, PR MACH LEARN RES, V48; Satorras V. G., 2018, PROC INT C LEARN REP; Schwartz E, 2018, ADV NEUR IN, V31; Scott TR, 2018, ADV NEUR IN, V31; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049; Sun QR, 2017, PROC CVPR IEEE, P435, DOI 10.1109/CVPR.2017.54; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Thrun S, 1998, LEARNING TO LEARN, P3; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760; Wei Y, 2018, PR MACH LEARN RES, V80; Weinshall D, 2018, PR MACH LEARN RES, V80; Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052; Yang J., 2007, 7 IEEE INT C DATA MI, P69, DOI DOI 10.1109/ICDMW.2007.37; Yaoyao Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12242, DOI 10.1109/CVPR42600.2020.01226; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zhang RX, 2018, ADV NEUR IN, V31	81	11	12	43	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1443	1456		10.1109/TPAMI.2020.3018506	http://dx.doi.org/10.1109/TPAMI.2020.3018506			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32822293	Green Submitted, Green Accepted			2022-12-18	WOS:000752018000027
J	Rocco, I; Cimpoi, M; Arandjelovic, R; Torii, A; Pajdla, T; Sivic, J				Rocco, Ignacio; Cimpoi, Mircea; Arandjelovic, Relja; Torii, Akihiko; Pajdla, Tomas; Sivic, Josef			NCNet: Neighbourhood Consensus Networks for Estimating Image Correspondences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Pattern matching; Task analysis; Convolutional neural networks; Electronic mail; Reliability; Benchmark testing; Neighbourhood consensus; geometric matching; image alignment; category-level matching		We address the problem of finding reliable dense correspondences between a pair of images. This is a challenging task due to strong appearance differences between the corresponding scene elements and ambiguities generated by repetitive patterns. The contributions of this work are threefold. First, inspired by the classic idea of disambiguating feature matches using semi-local constraints, we develop an end-to-end trainable convolutional neural network architecture that identifies sets of spatially consistent matches by analyzing neighbourhood consensus patterns in the 4D space of all possible correspondences between a pair of images without the need for a global geometric model. Second, we demonstrate that the model can be trained effectively from weak supervision in the form of matching and non-matching image pairs without the need for costly manual annotation of point to point correspondences. Third, we show the proposed neighbourhood consensus network can be applied to a range of matching tasks including both category- and instance-level matching, obtaining the state-of-the-art results on the PF, TSS, InLoc, and HPatches benchmarks.	[Rocco, Ignacio; Sivic, Josef] INRIA, F-75012 Paris, France; [Rocco, Ignacio; Sivic, Josef] PSL Res Univ, CNRS, Dept Informat, ENS, F-75005 Paris, France; [Cimpoi, Mircea; Pajdla, Tomas; Sivic, Josef] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16000, Czech Republic; [Cimpoi, Mircea] Oculus Zurich, Zurich, Switzerland; [Arandjelovic, Relja] DeepMind, London N1C, England; [Torii, Akihiko] Tokyo Inst Technol, Grad Sch Sci & Engn, Dept Mech & Control Engn, Tokyo 1528550, Japan	Inria; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite; Czech Technical University Prague; Tokyo Institute of Technology	Rocco, I (corresponding author), INRIA, F-75012 Paris, France.	ignacio.rocco@inria.fr; mircea.cimpoi@cvut.cz; relja@google.com; pajdla@cvut.cz; josef.sivic@inria.fr		Cimpoi, Mircea/0000-0002-5624-7593	JSPS KAKENHI [15H05313, 16KK0002]; EU-H2020 project LADIO [731970]; ERC [336845]; CIFAR Learning in Machines and Brains program; European Regional Development Fund under the project IMPACT [CZ.02.1.01/0.0/0.0/15 003/0000468]; NVIDIA Corporation	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); EU-H2020 project LADIO; ERC(European Research Council (ERC)European Commission); CIFAR Learning in Machines and Brains program; European Regional Development Fund under the project IMPACT; NVIDIA Corporation	This work was supported in part by JSPS KAKENHI Grant Numbers 15H05313, 16KK0002, EU-H2020 project LADIO No. 731970, ERC grant LEAP No. 336845, CIFAR Learning in Machines and Brains program and the European Regional Development Fund under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15 003/0000468). The authors gratefully acknowledge the support of NVIDIA Corporation with the donation of Quadro P6000 GPU.	Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410; Balntas Vassileios, 2016, ARXIV160105030; Balntas Vassileios, 2016, BMVC, V2, DOI DOI 10.5244/C.30.119; Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302; Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Choy CB, 2016, ADV NEUR IN, V29; Chum O, 2005, PROC CVPR IEEE, P772; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828; Fischer P, 2014, ARXIV14055769; Ham B, 2018, IEEE T PATTERN ANAL, V40, P1711, DOI 10.1109/TPAMI.2017.2724510; Han K, 2017, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2017.203; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jahrer M., 2008, P COMP VIS WINT WORK, P39; Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Kim Seungryong, 2018, ADV NEURAL INFORM PR, P6129; Kingma D.P, P 3 INT C LEARNING R; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Long J.L., 2014, P C NEUR INF PROC SY, V27, P1601; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI 10.1007/s11263-018-1117-z; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Mishchuk Anastasiya, 2017, ADV NEURAL INFORM PR; Mishkin D, 2018, LECT NOTES COMPUT SC, V11213, P287, DOI 10.1007/978-3-030-01240-3_18; Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374; Paszke A., 2019, ADV NEURAL INF PROCE, P8026, DOI [10.48550/arXiv.1912.01703, DOI 10.48550/ARXIV.1912.01703]; Rocco I, 2018, ADV NEUR IN, V31; Rocco I, 2018, PROC CVPR IEEE, P6917, DOI 10.1109/CVPR.2018.00723; Rocco I, 2019, IEEE T PATTERN ANAL, V41, P2553, DOI 10.1109/TPAMI.2018.2865351; Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Sattler T, 2009, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2009.5459459; Savinov N, 2017, ADV NEUR IN, V30; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2383, P186; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Schonberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752; Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Widya A.R., 2018, IPSJ T COMPUT VIS AP, V10, P6; Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	64	11	11	7	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					1020	1034		10.1109/TPAMI.2020.3016711	http://dx.doi.org/10.1109/TPAMI.2020.3016711			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32795965	Green Submitted			2022-12-18	WOS:000740006100034
J	Zhang, LH; Wang, L; Bai, ZJ; Li, RC				Zhang, Lei-Hong; Wang, Li; Bai, Zhaojun; Li, Ren-Cang			A Self-Consistent-Field Iteration for Orthogonal Canonical Correlation Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Correlation; Feature extraction; Eigenvalues and eigenfunctions; Manifolds; Data visualization; Electronic mail; Optimization methods; Canonical correlation analysis; self-consistent-field iteration; orthogonal multiset canonical correlation analysis	DISCRIMINANT-ANALYSIS; TRACE RATIO; CLASSIFICATION; ALGORITHMS; SCENE; SETS	We propose an efficient algorithm for solving orthogonal canonical correlation analysis (OCCA) in the form of trace-fractional structure and orthogonal linear projections. Even though orthogonality has been widely used and proved to be a useful criterion for visualization, pattern recognition and feature extraction, existing methods for solving OCCA problem are either numerically unstable by relying on a deflation scheme, or less efficient by directly using generic optimization methods. In this paper, we propose an alternating numerical scheme whose core is the sub-maximization problem in the trace-fractional form with an orthogonality constraint. A customized self-consistent-field (SCF) iteration for this sub-maximization problem is devised. It is proved that the SCF iteration is globally convergent to a KKT point and that the alternating numerical scheme always converges. We further formulate a new trace-fractional maximization problem for orthogonal multiset CCA and propose an efficient algorithm with an either Jacobi-style or Gauss-Seidel-style updating scheme based on the SCF iteration. Extensive experiments are conducted to evaluate the proposed algorithms against existing methods, including real-world applications of multi-label classification and multi-view feature extraction. Experimental results show that our methods not only perform competitively to or better than the existing methods but also are more efficient.	[Zhang, Lei-Hong] Soochow Univ, Sch Math Sci, Suzhou 215006, Jiangsu, Peoples R China; [Zhang, Lei-Hong] Soochow Univ, Inst Computat Sci, Suzhou 215006, Jiangsu, Peoples R China; [Zhang, Lei-Hong] Shanghai Univ Finance & Econ, Sch Math, Shanghai 200433, Peoples R China; [Wang, Li; Li, Ren-Cang] Univ Texas Arlington, Dept Math, Arlington, TX 76019 USA; [Wang, Li] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Bai, Zhaojun] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Bai, Zhaojun] Univ Calif Davis, Dept Math, Davis, CA 95616 USA	Soochow University - China; Soochow University - China; Shanghai University of Finance & Economics; University of Texas System; University of Texas Arlington; University of Texas System; University of Texas Arlington; University of California System; University of California Davis; University of California System; University of California Davis	Wang, L (corresponding author), Univ Texas Arlington, Dept Math, Arlington, TX 76019 USA.; Wang, L (corresponding author), Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.	longzlh@suda.edu.cn; li.wang@uta.edu; zbai@ucdavis.edu; rcli@uta.edu	Zhang, Leihong/AAB-8006-2022	LI, REN-CANG/0000-0002-4388-3398	National Natural Science Foundation of China [NSFC-11671246]; National Key R&D Program of China [2018YFB0204404]; 2018 Double Innovation Program of Jiangsu Province, China; NSF [DMS-2009689, DMS-1913364, DMS-1719620]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; 2018 Double Innovation Program of Jiangsu Province, China; NSF(National Science Foundation (NSF))	The authors would like to thank the anonymous referees for their valuable comments and suggestions to improve the presentation of this paper. The work of Lei-Hong Zhang was supported in part by the National Natural Science Foundation of China NSFC-11671246, National Key R&D Program of China (No. 2018YFB0204404) and 2018 Double Innovation Program of Jiangsu Province, China. The work of Li Wang was supported in part by the NSF DMS-2009689. The work of Zhaojun Bai was supported in part by the NSF DMS-1913364. The work of Ren-Cang Li was supported in part by the NSF DMS-1719620 and DMS-2009689.	Absil PA, 2007, FOUND COMPUT MATH, V7, P303, DOI 10.1007/s10208-005-0179-9; Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Anderson E., 1999, LAPACK USERS GUIDE S; Bai ZJ, 2018, SIAM J SCI COMPUT, V40, pA3495, DOI 10.1137/18M1167681; Bai Zhaojun, 2000, TEMPLATES SOLUTION A; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Cai D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P3, DOI 10.1145/1076034.1076039; Cai YF, 2018, SIAM J MATRIX ANAL A, V39, P1360, DOI 10.1137/17M115935X; Chu D., 2013, P INT MULTICONF ENG, P322; Cunningham JP, 2015, J MACH LEARN RES, V16, P2859; Demmel JW, 1997, APPL NUMERICAL LINEA, V56; Dua D., 2017, UCI MACHINE LEARNING, DOI DOI 10.1002/JCC.23219; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Horn R.A., 2013, TOPICS MATRIX ANAL, DOI DOI 10.1017/CBO9780511840371; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.1093/biomet/58.3.433; Knyazev AV, 2001, SIAM J SCI COMPUT, V23, P517, DOI 10.1137/S1064827500366124; Knyazev AV, 2003, ELECTRON T NUMER ANA, V15, P38; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li LM, 2019, IEEE T PATTERN ANAL, V41, P2724, DOI 10.1109/TPAMI.2018.2866846; Li RC, 2015, MATRIX FUNCTIONS AND MATRIX EQUATIONS, P76; Martin R.M., 2004, ELECT STRUCTURE BASI, V1st, DOI 10.1017/CBO9780511805769; Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rai P., 2009, ADV NEURAL INFORM PR, V22, P1518; Saad Y, 2010, SIAM REV, V52, P3, DOI 10.1137/060651653; Shen XB, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P151; Shen XB, 2015, NEURAL PROCESS LETT, V42, P301, DOI 10.1007/s11063-014-9358-5; Stewart G., 1990, MATRIX PERTURBATION; Sun J.G., 1987, MATRIX PERTURBATION; Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160; Tsoumakas G., 2007, INT J DATA WAREHOUSI, V3, P1; Uurtio V, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136624; Wang Z, 2015, NEURAL COMPUT APPL, V26, P589, DOI 10.1007/s00521-014-1768-9; Wu JN, 2008, PROC CVPR IEEE, P2221; Ye JP, 2005, J MACH LEARN RES, V6, P483; Yi Z., 2011, J MACHINE LEARNING R, V15, P873; Zhang LH, 2011, PATTERN RECOGN LETT, V32, P476, DOI 10.1016/j.patrec.2010.11.008; Zhang LH, 2010, SIAM J MATRIX ANAL A, V31, P1584, DOI 10.1137/080720863; Zhang LH, 2015, SCI CHINA MATH, V58, P1549, DOI 10.1007/s11425-014-4825-z; Zhang LH, 2014, SCI CHINA MATH, V57, P2495, DOI 10.1007/s11425-014-4824-0; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019	46	11	11	8	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					890	904		10.1109/TPAMI.2020.3012541	http://dx.doi.org/10.1109/TPAMI.2020.3012541			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32750837	Green Submitted			2022-12-18	WOS:000740006100026
J	Zhang, ZY; Tran, L; Liu, F; Liu, XM				Zhang, Ziyuan; Tran, Luan; Liu, Feng; Liu, Xiaoming			On Learning Disentangled Representations for Gait Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gait recognition; deep convolutional neural networks; disentangled representation learning; auto-encoder; LSTM; canonical representation; face recognition	RECOGNIZING GAITS; EXTRACTION; IMAGE; PERFORMANCE; FACE	Gait, the walking pattern of individuals, is one of the important biometrics modalities. Most of the existing gait recognition methods take silhouettes or articulated body models as gait features. These methods suffer from degraded recognition performance when handling confounding variables, such as clothing, carrying and viewing angle. To remedy this issue, we propose a novel AutoEncoder framework, GaitNet, to explicitly disentangle appearance, canonical and pose features from RGB imagery. The LSTM integrates pose features over time as a dynamic gait feature while canonical features are averaged as a static gait feature. Both of them are utilized as classification features. In addition, we collect a Frontal-View Gait (FVG) dataset to focus on gait recognition from frontal-view walking, which is a challenging problem since it contains minimal gait cues compared to other views. FVG also includes other important variations, e.g., walking speed, carrying, and clothing. With extensive experiments on CASIA-B, USF, and FVG datasets, our method demonstrates superior performance to the SOTA quantitatively, the ability of feature disentanglement qualitatively, and promising computational efficiency. We further compare our GaitNet with state-of-the-art face recognition to demonstrate the advantages of gait biometrics identification under certain scenarios, e.g., long-distance/lower resolutions, cross viewing angles. Source code is available at http://cvlab.cse.msu.edu/project-gaitnet.html	[Zhang, Ziyuan; Tran, Luan; Liu, Feng; Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Liu, XM (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	zhang835@msu.edu; tranluan@msu.edu; liufeng6@msu.edu; liuxm@cse.msu.edu			Ford-MSU Alliance program; Army Research Office [W911NF-18-1-0330]	Ford-MSU Alliance program; Army Research Office	This work was supported in part by the Ford-MSU Alliance program, and the Army Research Office under Grant Number W911NF-18-1-0330. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.	Aggarwal H, 2018, IEEE T COGN DEV SYST, V10, P397, DOI 10.1109/TCDS.2017.2658674; Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004; Ariyanto Gunawan, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P354, DOI 10.1109/ICB.2012.6199832; Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870; Bashir K., 2009, 3 INT C IMAGING CRIM, P1, DOI DOI 10.1049/IC.2009.0230; Bobick A. F., 2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, pI, DOI 10.1109/CVPR.2001.990506; Brazil G, 2019, PROC CVPR IEEE, P7224, DOI 10.1109/CVPR.2019.00740; Brazil G, 2017, IEEE I CONF COMP VIS, P4960, DOI 10.1109/ICCV.2017.530; Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114; Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010; Chellappa R., 2010, HUMAN IDENTIFICATION; Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061; Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264; Cheung K. M. G., 2003, Proceedings 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pI; Choi S, 2019, IEEE T INF FOREN SEC, V14, P2577, DOI 10.1109/TIFS.2019.2901823; Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]; Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Gong SX, 2019, IEEE INT CONF COMP V, P1027, DOI 10.1109/ICCVW.2019.00132; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819; Hofmann M, 2014, J VIS COMMUN IMAGE R, V25, P195, DOI 10.1016/j.jvcir.2013.02.006; Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020; Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640; Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605; Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253; Kale A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P901; Kingma D.P., 2015, 3 INT C LEARN REPR I, P1, DOI DOI 10.1007/S11390-017-1754-7; Kingma D.P, P 3 INT C LEARNING R; Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379; Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552; Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113; Liu F, 2018, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2018.00547; Liu XM, 2010, IMAGE VISION COMPUT, V28, P1162, DOI 10.1016/j.imavis.2009.09.016; Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767; Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/ipsjtcva.4.53; Makihara Y, 2018, IEEE COMPUT SOC CONF, P674, DOI 10.1109/CVPRW.2018.00098; Makihara Y, 2017, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR.2017.718; Middleton L, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P171, DOI 10.1109/AUTOID.2005.2; Nambiar A.M., 2012, P MULT SEC MMSEC 201, P145, DOI [10.1145/2361407.2361432, DOI 10.1145/2361407.2361432]; Presley A.B., 2006, CLOTH TEXT RES J, V24, P80, DOI DOI 10.1177/0887302X0602400203; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Seyfioglu MS, 2017, IEEE RAD CONF, P1125, DOI 10.1109/RADAR.2017.7944373; Shakhnarovich G., 2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, pI, DOI 10.1109/CVPR.2001.990508; Shiraga K, 2016, INT CONF BIOMETR; Shutler JD, 2004, ADV SOFT COMP, P339; Sivapriya SV, 2011, INDIAN GEOTECHNICAL, P1, DOI [DOI 10.1109/IJCB.2011.6117504, 10.1155/2011/375897]; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Tai Y, 2019, AAAI CONF ARTIF INTE, P8893; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122; Tran L, 2021, IEEE T PATTERN ANAL, V43, P157, DOI 10.1109/TPAMI.2019.2927975; Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Verlekar TT, 2017, IET BIOMETRICS, V6, P299, DOI 10.1049/iet-bmt.2016.0118; Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633; Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260; Wang W, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P363, DOI 10.1145/2971648.2971670; Wang YX, 2019, PROC CVPR IEEE, P6351, DOI 10.1109/CVPR.2019.00652; Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669; Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769; Yin X, 2018, REPRESENTATION LEARN; Yu SQ, 2006, INT C PATT RECOG, P441; Yu SQ, 2019, PATTERN RECOGN, V87, P179, DOI 10.1016/j.patcog.2018.10.019; Zhang KH, 2019, PROC CVPR IEEE, P4695, DOI 10.1109/CVPR.2019.00483; Zhang YQ, 2019, PATTERN RECOGN, V93, P228, DOI 10.1016/j.patcog.2019.04.023; Zhang YT, 2015, IEEE T CYBERNETICS, V45, P1864, DOI 10.1109/TCYB.2014.2361287; Zhang ZY, 2019, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR.2019.00484; Zhon XL, 2007, IEEE T SYST MAN CY B, V37, P1119, DOI 10.1109/TSMCB.2006.889612; Zou Q, 2018, IEEE T CYBERNETICS, V48, P1136, DOI 10.1109/TCYB.2017.2682280	81	11	12	24	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					345	360		10.1109/TPAMI.2020.2998790	http://dx.doi.org/10.1109/TPAMI.2020.2998790			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750777	Green Submitted			2022-12-18	WOS:000728561300025
J	Hung, ZS; Mallya, A; Lazebnik, S				Hung, Zih-Siou; Mallya, Arun; Lazebnik, Svetlana			Contextual Translation Embedding for Visual Relationship Detection and Scene Graph Generation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual relationship detection; scene graph generation; scene understanding		Relations amongst entities play a central role in image understanding. Due to the complexity of modeling (subject, predicate, object) relation triplets, it is crucial to develop a method that can not only recognize seen relations, but also generalize to unseen cases. Inspired by a previously proposed visual translation embedding model, or VTransE [1], we propose a context-augmented translation embedding model that can capture both common and rare relations. The previous VTransE model maps entities and predicates into a low-dimensional embedding vector space where the predicate is interpreted as a translation vector between the embedded features of the bounding box regions of the subject and the object. Our model additionally incorporates the contextual information captured by the bounding box of the union of the subject and the object, and learns the embeddings guided by the constraint predicate union (subject, object) - subject - object. In a comprehensive evaluation on multiple challenging benchmarks, our approach outperforms previous translation-based models and comes close to or exceeds the state of the art across a range of settings, from small-scale to large-scale datasets, from common to previously unseen relations. It also achieves promising results for the recently introduced task of scene graph generation.	[Hung, Zih-Siou; Lazebnik, Svetlana] Univ Illinois, Comp Sci Dept, Urbana, IL 61801 USA; [Mallya, Arun] Nvidia Res, Santa Clara, CA 95051 USA	University of Illinois System; University of Illinois Urbana-Champaign	Hung, ZS (corresponding author), Univ Illinois, Comp Sci Dept, Urbana, IL 61801 USA.	zhung2@illinois.edu; amallya2@illinois.edu; slazebni@illinois.edu			NSF [1563727]; Amazon; AWS Research Awards	NSF(National Science Foundation (NSF)); Amazon; AWS Research Awards	This work was supported in part by NSF Award 1563727, Amazon and AWS Research Awards.	Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352; Fukui Akira, 2016, ARXIV160601847; Galleguillos C., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587799; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x; Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142; Liang KM, 2018, AAAI CONF ARTIF INTE, P7098; Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51; Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3177, DOI 10.1109/CVPR.2011.5995631; Mallya A., 2016, LECT NOTES COMPUT SC, P414, DOI DOI 10.1007/978-3-319-46448-0_25; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Papazoglou A, 2016, IMAGE VISION COMPUT, V52, P206, DOI 10.1016/j.imavis.2016.04.014; Pennington J., 2014, P 2014 C EMPIRICAL M, P1532; Peyre J, 2017, IEEE I CONF COMP VIS, P5189, DOI 10.1109/ICCV.2017.554; Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213; Prabhu N, 2015, IEEE I CONF COMP VIS, P1071, DOI 10.1109/ICCV.2015.128; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234; Yin GJ, 2018, LECT NOTES COMPUT SC, V11207, P330, DOI 10.1007/978-3-030-01219-9_20; Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121; Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331; Zhang J, 2019, PROC CVPR IEEE, P11527, DOI 10.1109/CVPR.2019.01180; Zhang J, 2019, AAAI CONF ARTIF INTE, P9185; Zhuang BH, 2017, IEEE I CONF COMP VIS, P589, DOI 10.1109/ICCV.2017.71	49	11	12	6	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3820	3832		10.1109/TPAMI.2020.2992222	http://dx.doi.org/10.1109/TPAMI.2020.2992222			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32365020	Green Submitted			2022-12-18	WOS:000702649700010
J	Yi, R; Xia, MF; Liu, YJ; Lai, YK; Rosin, PL				Yi, Ran; Xia, Mengfei; Liu, Yong-Jin; Lai, Yu-Kun; Rosin, Paul L.			Line Drawings for Face Portraits From Photos Using Global and Local Structure Based GANs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Generative adversarial networks; Gallium nitride; Training; Facial features; Rendering (computer graphics); Hair; Face portrait; style transfer; image translation; generative adversarial network	DATABASE	Despite significant effort and notable success of neural style transfer, it remains challenging for highly abstract styles, in particular line drawings. In this paper, we propose APDrawingGAN++, a generative adversarial network (GAN) for transforming face photos to artistic portrait drawings (APDrawings), which addresses substantial challenges including highly abstract style, different drawing techniques for different facial features, and high perceptual sensitivity to artifacts. To address these, we propose a composite GAN architecture that consists of local networks (to learn effective representations for specific facial features) and a global network (to capture the overall content). We provide a theoretical explanation for the necessity of this composite GAN structure by proving that any GAN with a single generator cannot generate artistic styles like APDrawings. We further introduce a classification-and-synthesis approach for lips and hair where different drawing styles are used by artists, which applies suitable styles for a given input. To capture the highly abstract art form inherent in APDrawings, we address two challenging operations-(1) coping with lines with small misalignments while penalizing large discrepancy and (2) generating more continuous lines-by introducing two novel loss terms: one is a novel distance transform loss with nonlinear mapping and the other is a novel line continuity loss, both of which improve the line quality. We also develop dedicated data augmentation and pre-training to further improve results. Extensive experiments, including a user study, show that our method outperforms state-of-the-art methods, both qualitatively and quantitatively.	[Yi, Ran; Xia, Mengfei; Liu, Yong-Jin] Tsinghua Univ, MOE Key Lab Pervas Comp, BNRist, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [Lai, Yu-Kun; Rosin, Paul L.] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales	Tsinghua University; Cardiff University	Liu, YJ (corresponding author), Tsinghua Univ, MOE Key Lab Pervas Comp, BNRist, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	yr16@mails.tsinghua.edu.cn; xiamf16@mails.tsinghua.edu.cn; liuyongjin@tsinghua.edu.cn; laiy4@cardiff.ac.uk; rosinpl@cardiff.ac.uk	Yi, Ran/AAU-6636-2021; Liu, Yong/GWQ-6163-2022	Yi, Ran/0000-0003-1858-3358; Rosin, Paul/0000-0002-4965-3884	Natural Science Foundation of China [61725204, 61521002]; Royal Society-Newton Advanced Fellowship [NA150431]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Royal Society-Newton Advanced Fellowship	This work was supported by the Natural Science Foundation of China (61725204, 61521002) and Royal Society-Newton Advanced Fellowship (NA150431).	Amos B, 2016, CMU SCH COMPUTER SCI, V6; Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789; Ba J., 2017, P 3 INT C LEARN REPR; Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012; Chelnokova O, 2014, MOL PSYCHIATR, V19, P746, DOI 10.1038/mp.2014.1; Chen H., 2004, P INT S NONPH AN REN, P95, DOI DOI 10.1145/987; Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986; Courset R, 2018, INT REV SOC PSYCHOL, V31, DOI 10.5334/irsp.179; Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351; Fiser J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073660; Gatys LA, 2015, ADV NEUR IN, V28; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hogg RV., 1987, ENG STAT; Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160; Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272; Li YJ, 2019, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2019.00162; Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683; Ma DS, 2015, BEHAV RES METHODS, V47, P1122, DOI 10.3758/s13428-014-0532-5; Meng M., 2010, P INT C MULT, P931; Mirza M., 2014, ARXIV; Peer P, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/585139; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; Rosin P. L., 2015, P WORKSH COMP AESTH, P159; Rosin P. L., 2010, P NPAR 2010 ANN FRAN, P119; Rosin P. L, 2017, P S NONPH AN REND; Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968; Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814; Shih YC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601137; Simo-Serra E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132703; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Strohminger N, 2016, BEHAV RES METHODS, V48, P1197, DOI 10.3758/s13428-015-0641-9; Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005; Vieira TF, 2014, VISUAL COMPUT, V30, P1333, DOI 10.1007/s00371-013-0884-3; Walker M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193190; Wang TH, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.36; Yi R, 2019, PROC CVPR IEEE, P10735, DOI 10.1109/CVPR.2019.01100; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang Y, 2017, IEEE T IMAGE PROCESS, V26, P464, DOI 10.1109/TIP.2016.2628581; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhao M., 2011, P ACM SIGGRAPHEUROGR, P117; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	50	11	11	7	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3462	3475		10.1109/TPAMI.2020.2987931	http://dx.doi.org/10.1109/TPAMI.2020.2987931			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32310761	Green Accepted			2022-12-18	WOS:000692232400016
J	Wang, QL; Xie, JT; Zuo, WM; Zhang, L; Li, PH				Wang, Qilong; Xie, Jiangtao; Zuo, Wangmeng; Zhang, Lei; Li, Peihua			Deep CNNs Meet Global Covariance Pooling: Better Representation and Generalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Global covariance pooling; matrix power normalization; deep convolutional neural networks; visual recognition	SHRINKAGE	Compared with global average pooling in existing deep convolutional neural networks (CNNs), global covariance pooling can capture richer statistics of deep features, having potential for improving representation and generalization abilities of deep CNNs. However, integration of global covariance pooling into deep CNNs brings two challenges: (1) robust covariance estimation given deep features of high dimension and small sample size; (2) appropriate usage of geometry of covariances. To address these challenges, we propose a global Matrix Power Normalized COVariance (MPN-COV) Pooling. Our MPN-COV conforms to a robust covariance estimator, very suitable for scenario of high dimension and small sample size. It can also be regarded as Power-Euclidean metric between covariances, effectively exploiting their geometry. Furthermore, a global Gaussian embedding network is proposed to incorporate first-order statistics into MPN-COV. For fast training of MPN-COV networks, we implement an iterative matrix square root normalization, avoiding GPU unfriendly eigen-decomposition inherent in MPN-COV. Additionally, progressive 1 x 1 convolutions and group convolution are introduced to compress covariance representations. The proposed methods are highly modular, readily plugged into existing deep CNNs. Extensive experiments are conducted on large-scale object classification, scene categorization, fine-grained visual recognition and texture classification, showing our methods outperform the counterparts and obtain state-of-the-art performance.	[Wang, Qilong] Tianjin Univ, Tianjin Key Lab Machine Learning, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Wang, Qilong; Xie, Jiangtao; Li, Peihua] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China	Tianjin University; Dalian University of Technology; Harbin Institute of Technology; Hong Kong Polytechnic University	Li, PH (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.	qlwang@tju.edu.cn; jiangtaoxie@mail.dlut.edu.cn; cswmzuo@gmail.com; cslzhang@comp.polyu.edu.hk; peihuali@dlut.edu.cn			National Natural Science Foundation of China [61971086, 61806140, U19A2073, 61471082, 61671182, 61732011]; China Post-doctoral Programme Foundation for Innovative Talent	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Post-doctoral Programme Foundation for Innovative Talent	The work was supported by the National Natural Science Foundation of China (Grant No. 61971086, 61806140, U19A2073, 61471082, 61671182 and 61732011). Qilong Wang was supported by China Post-doctoral Programme Foundation for Innovative Talent. The work was done while Q. Wang was a PhD student at the School of Information and Communication Engineering, Dalian University of Technology, China.	Acharya D, 2018, IEEE COMPUT SOC CONF, P480, DOI 10.1109/CVPRW.2018.00077; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arsigny V, 2005, LECT NOTES COMPUT SC, V3749, P115; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63; CALVO M, 1990, J MULTIVARIATE ANAL, V35, P223, DOI 10.1016/0047-259X(90)90026-E; Carreira J, 2015, IEEE T PATTERN ANAL, V37, P1177, DOI 10.1109/TPAMI.2014.2361137; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325; Dai XY, 2017, PROC CVPR IEEE, P6100, DOI 10.1109/CVPR.2017.646; Daniels MJ, 2001, BIOMETRICS, V57, P1173, DOI 10.1111/j.0006-341X.2001.01173.x; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dixit M, 2016, ADV NEUR IN, V29; Donoho D, 2018, ANN STAT, V46, P1742, DOI 10.1214/17-AOS1601; Dryden IL, 2009, ANN APPL STAT, V3, P1102, DOI 10.1214/09-AOAS249; Eigen D., 2014, 6 INT C LEARN REPR I; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Higham N.J, 2008, FUNCTIONS MATRICES T; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang GL, 2017, IEEE ICC; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Ionescu C, 2015, IEEE I CONF COMP VIS, P2965, DOI 10.1109/ICCV.2015.339; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743; Koniusz P, 2017, IEEE T PATTERN ANAL, V39, P313, DOI 10.1109/TPAMI.2016.2545667; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ledoit O, 2004, J MULTIVARIATE ANAL, V88, P365, DOI 10.1016/S0047-259X(03)00096-4; Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105; Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228; Li PH, 2017, IEEE T PATTERN ANAL, V39, P803, DOI 10.1109/TPAMI.2016.2560816; Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229; Li YS, 2017, IEEE I CONF COMP VIS, P5757, DOI 10.1109/ICCV.2017.613; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liyu Gong, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2366, DOI 10.1109/CVPRW.2009.5206506; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lovric M, 2000, J MULTIVARIATE ANAL, V74, P36, DOI 10.1006/jmva.1999.1853; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji Subhransu, 2013, ARXIV13065151; Nakayama H, 2010, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2010.5539921; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Simonyan K., 2014, 3 INT C LEARN REPR I; Stein C., 1986, J SOV MATH, V34, P1373, DOI [10.1007/BF01085007, DOI 10.1007/BF01085007]; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tang P., 2019, IEEE T NEURAL NETW L, V30, P2244; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wah C., 2011, TECH REP; Wang QL, 2017, PROC CVPR IEEE, P6507, DOI 10.1109/CVPR.2017.689; Wang QL, 2016, PROC CVPR IEEE, P4433, DOI 10.1109/CVPR.2016.480; Wang QL, 2016, PATTERN RECOGN, V59, P63, DOI 10.1016/j.patcog.2016.03.004; Wang Y, 2017, IEEE I CONF COMP VIS, P1368, DOI 10.1109/ICCV.2017.152; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yang E., 2014, P 31 INT C INT C MAC; Yu KC, 2018, LECT NOTES COMPUT SC, V11211, P621, DOI 10.1007/978-3-030-01234-2_37; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang H, 2017, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR.2017.309; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009	69	11	11	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2582	2597		10.1109/TPAMI.2020.2974833	http://dx.doi.org/10.1109/TPAMI.2020.2974833			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32086198	Green Submitted			2022-12-18	WOS:000670578800005
J	Engelsma, JJ; Cao, K; Jain, AK				Engelsma, Joshua J.; Cao, Kai; Jain, Anil K.			Learning a Fixed-Length Fingerprint Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; NIST; Knowledge engineering; Databases; Encryption; Face recognition; Task analysis; Fingerprint matching; minutiae representation; fixed-length representation; representation learning; deep networks; large-scale search; domain knowledge in deep networks	FEATURES	We present DeepPrint, a deep network, which learns to extract fixed-length fingerprint representations of only 200 bytes. DeepPrint incorporates fingerprint domain knowledge, including alignment and minutiae detection, into the deep network architecture to maximize the discriminative power of its representation. The compact, DeepPrint representation has several advantages over the prevailing variable length minutiae representation which (i) requires computationally expensive graph matching techniques, (ii) is difficult to secure using strong encryption schemes (e.g., homomorphic encryption), and (iii) has low discriminative power in poor quality fingerprints where minutiae extraction is unreliable. We benchmark DeepPrint against two top performing COTS SDKs (Verifinger and Innovatrics) from the NIST and FVC evaluations. Coupled with a re-ranking scheme, the DeepPrint rank-1 search accuracy on the NIST SD4 dataset against a gallery of 1.1 million fingerprints is comparable to the top COTS matcher, but it is significantly faster (DeepPrint: 98.80% in 0.3 seconds vs. COTS A: 98.85% in 27 seconds). To the best of our knowledge, the DeepPrint representation is the most compact and discriminative fixed-length fingerprint representation reported in the academic literature.	[Engelsma, Joshua J.; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Cao, Kai] Goodix, San Diego, CA 92618 USA	Michigan State University	Engelsma, JJ (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	engelsm7@msu.edu; caokai0505@gmail.com; jain@cse.msu.edu						[Anonymous], EXPLAINABLE ARTIFICI; [Anonymous], 2016, OFFICE BIOMETRIC IDE; [Anonymous], 2010, **DROPPED REF**; Barni M., 2010, P 4 IEEE INT C BIOM, P1, DOI DOI 10.1109/WIFS.2010.5711460; Bhanu B, 2003, IEEE T PATTERN ANAL, V25, P616, DOI 10.1109/TPAMI.2003.1195995; Boddeti V. N., 2018, P IEEE 9 INT C BIOM, P1; Bringer J., 2010, P 4 IEEE INT C BIOM, P1; Cao K, 2020, IEEE T INF FOREN SEC, V15, P880, DOI 10.1109/TIFS.2019.2930487; Cao K, 2019, IEEE T PATTERN ANAL, V41, P788, DOI 10.1109/TPAMI.2018.2818162; Cao K, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P437; Cao K, 2015, INT CONF BIOMETR, P349, DOI 10.1109/ICB.2015.7139060; Cappelli R, 2011, IEEE T PATTERN ANAL, V33, P1051, DOI 10.1109/TPAMI.2010.228; Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Darlow LN, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P22; Nguyen DL, 2018, INT CONF BIOMETR, P9, DOI 10.1109/ICB2018.2018.00013; Dorizzi B, 2009, LECT NOTES COMPUT SC, V5558, P725, DOI 10.1007/978-3-642-01793-3_74; Nguyen DT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351021; Ezeobiejesi J, 2017, ADV COMPUT VIS PATT, P83, DOI 10.1007/978-3-319-61657-5_4; Fan J., 2012, CRYPTOLOGY EPRINT AR; Farooq Faisal, 2007, 2007 IEEE C COMP VIS, P1, DOI 10.1109/CVPR.2007.383382; Feng J, 2019, P IEEE INT C BIOM; Galton Francis, 1892, FINGER PRINTS; Jaderberg M, 2015, ADV NEUR IN, V28; Jain A. K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P187, DOI 10.1109/CVPR.1999.784628; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiang XD, 2006, IEEE T INF FOREN SEC, V1, P532, DOI 10.1109/TIFS.2006.885021; Jin Z, 2016, IEEE T SYST MAN CY-S, V46, P1415, DOI 10.1109/TSMC.2015.2499725; Lei Z., 2014, LEARNING FACE REPRES; Liu EY, 2012, FUTURE GENER COMP SY, V28, P236, DOI 10.1016/j.future.2011.01.001; Liu MH, 2012, PATTERN RECOGN, V45, P2532, DOI 10.1016/j.patcog.2012.01.014; Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1; Maltoni D., 2009, HDB FINGERPRINT RECO; Nagar A, 2010, INT CONF ACOUST SPEE, P1826, DOI 10.1109/ICASSP.2010.5495392; Nandakumar K, 2010, IEEE INT WORKS INFOR; Qu Z., 2018, P CHIN C IM GRAPH TE, P281; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Schuch P, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P185, DOI 10.1109/BTAS.2017.8272697; Song DH, 2019, PATTERN RECOGN, V88, P397, DOI 10.1016/j.patcog.2018.11.018; Song DH, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P200, DOI 10.1109/BTAS.2017.8272699; Su YJ, 2016, PATTERN RECOGN, V54, P1, DOI 10.1016/j.patcog.2016.01.006; Sutcu Y, 2008, IEEE INT SYMP INFO, P2297, DOI 10.1109/ISIT.2008.4595400; Sutcu Y, 2007, PROC SPIE, V6539, DOI 10.1117/12.721058; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P108, DOI 10.1109/BTAS.2017.8272688; Uludag U, 2005, LECT NOTES COMPUT SC, V3546, P310; Unique identification authority of India, DASHB SUMM; Upmanyu M, 2010, IEEE T INF FOREN SEC, V5, P255, DOI 10.1109/TIFS.2010.2043188; Upmanyu M, 2009, LECT NOTES COMPUT SC, V5558, P899, DOI 10.1007/978-3-642-01793-3_91; Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166; Watson C. I., 2015, 80342015 NIST, DOI [10.6028/NIST.IR.8034, DOI 10.6028/NIST.IR.8034, 10.6028/nist.ir.8034]; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Xiaowei Dai, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P324, DOI 10.1007/978-3-319-69923-3_35; Xu HY, 2009, IEEE T INF FOREN SEC, V4, P397, DOI 10.1109/TIFS.2009.2021692; Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830; Yoon S, 2015, P NATL ACAD SCI USA, V112, P8555, DOI 10.1073/pnas.1410272112; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhu YM, 2017, IEEE INT WORKS INFOR, DOI 10.1109/INTMAG.2017.8007607	61	11	11	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					1981	1997		10.1109/TPAMI.2019.2961349	http://dx.doi.org/10.1109/TPAMI.2019.2961349			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31870978	Green Submitted			2022-12-18	WOS:000649590200012
J	Hassan, T; Seuss, D; Wollenberg, J; Weitz, K; Kunz, M; Lautenbacher, S; Garbas, JU; Schmid, U				Hassan, Teena; Seuss, Dominik; Wollenberg, Johannes; Weitz, Katharina; Kunz, Miriam; Lautenbacher, Stefan; Garbas, Jens-Uwe; Schmid, Ute			Automatic Detection of Pain from Facial Expressions: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pain; Feature extraction; Task analysis; Imaging; Encoding; Observers; Machine learning; Automatic pain detection; facial expressions of pain; pain datasets; pain feature representation; facial expression analysis; machine learning; survey	OLDER-ADULTS; DEMENTIA; RECOGNITION; INTENSITY; CLASSIFICATION; HISTOGRAMS; COMPONENTS; EMOTIONS; PATTERNS; VALIDITY	Pain sensation is essential for survival, since it draws attention to physical threat to the body. Pain assessment is usually done through self-reports. However, self-assessment of pain is not available in the case of noncommunicative patients, and therefore, observer reports should be relied upon. Observer reports of pain could be prone to errors due to subjective biases of observers. Moreover, continuous monitoring by humans is impractical. Therefore, automatic pain detection technology could be deployed to assist human caregivers and complement their service, thereby improving the quality of pain management, especially for noncommunicative patients. Facial expressions are a reliable indicator of pain, and are used in all observer-based pain assessment tools. Following the advancements in automatic facial expression analysis, computer vision researchers have tried to use this technology for developing approaches for automatically detecting pain from facial expressions. This paper surveys the literature published in this field over the past decade, categorizes it, and identifies future research directions. The survey covers the pain datasets used in the reviewed literature, the learning tasks targeted by the approaches, the features extracted from images and image sequences to represent pain-related information, and finally, the machine learning methods used.	[Hassan, Teena] Bielefeld Univ, D-33615 Bielefeld, Germany; [Hassan, Teena; Seuss, Dominik; Wollenberg, Johannes; Garbas, Jens-Uwe] Fraunhofer IIS, Elect Imaging Dept, D-91058 Erlangen, Germany; [Weitz, Katharina] Univ Augsburg, Dept Comp Sci, D-86159 Augsburg, Germany; [Kunz, Miriam] Univ Augsburg, Fac Med Sci, D-86159 Augsburg, Germany; [Lautenbacher, Stefan] Univ Bamberg, Fac Human Sci & Educ, D-96047 Bamberg, Germany; [Schmid, Ute] Univ Bamberg, Fac Informat Syst & Appl Comp Sci, D-96047 Bamberg, Germany	University of Bielefeld; University of Erlangen Nuremberg; University of Augsburg; University of Augsburg; Otto Friedrich University Bamberg; Otto Friedrich University Bamberg	Hassan, T (corresponding author), Bielefeld Univ, D-33615 Bielefeld, Germany.	teena.c.hassan@gmail.com; dominik.seuss@iis.fraunhofer.de; jo.wobg@web.de; katharina.weitz@informatik.uni-augsburg.de; miriam.kunz@med.uni-augsburg.de; stefan.lautenbacher@uni-bamberg.de; jens.garbas@iis.fraunhofer.de; ute.schmid@uni-bamberg.de	Weitz, Katharina/AAV-6328-2020	Weitz, Katharina/0000-0003-1001-2278; Schmid, Ute/0000-0002-1301-0326; Garbas, Jens-Uwe/0000-0003-3473-0370; , Stefan/0000-0002-2829-347X; Hassan, Teena/0000-0002-6105-0752	TALENTA start programme of the Fraunhofer Society; DFG [GA 2485/3-1, LA 685/18, Schm 1239/15]	TALENTA start programme of the Fraunhofer Society; DFG(German Research Foundation (DFG))	This work was partially funded by the grant received by the first author under the TALENTA start programme of the Fraunhofer Society during the period from February 2015 to January 2017. This work was also partially supported by DFG grants GA 2485/3-1, LA 685/18, Schm 1239/15, "Video-based automated pain detection exploiting compositional and temporal characteristics of action unit." The contributions in this paper are part of T. Hassan's research at Fraunhofer IIS.	Achterberg WP, 2013, CLIN INTERV AGING, V8, P1471, DOI 10.2147/CIA.S36739; Alphonse A. S., 2018, COMPUTATIONAL INTELL, P91; Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007; Aung MSH, 2016, IEEE T AFFECT COMPUT, V7, P435, DOI 10.1109/TAFFC.2015.2462830; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Bartlett MS, 2014, CURR BIOL, V24, P738, DOI 10.1016/j.cub.2014.02.009; Bogduk N, 2012, PAIN TERMS CURRENT 3; Bosley BN, 2004, J AM GERIATR SOC, V52, P247, DOI 10.1111/j.1532-5415.2004.52063.x; Brahnam S, 2006, LECT NOTES ARTIF INT, V3849, P121; Brahnam S, 2006, ARTIF INTELL MED, V36, P211, DOI 10.1016/j.artmed.2004.12.003; Brahnam S., 2008, Proceedings of the 2008 International Conference on Image Processing, Computer Vision & Pattern Recognition. IPCV 2008, P352; Brahnam S, 2007, DECIS SUPPORT SYST, V43, P1242, DOI 10.1016/j.dss.2006.02.004; Bunk SF, 2018, SOMATOSENS MOT RES, V35, P192, DOI 10.1080/08990220.2018.1521790; Chen JX, 2012, IEEE IMAGE PROC, P2621, DOI 10.1109/ICIP.2012.6467436; Chen JK, 2015, INT CONF AFFECT, P250, DOI 10.1109/ACII.2015.7344579; Chen JunKai, 2014, P 16 INT C MULTIMODA, P508, DOI [DOI 10.1145/2663204.2666277, 10.1145/2663204.2666277]; Cipher DJ, 2004, INT J GERIATR PSYCH, V19, P741, DOI 10.1002/gps.1155; Craig K. D., 2001, HDB PAIN ASSESSMENT, P153; Dael N, 2012, J NONVERBAL BEHAV, V36, P97, DOI 10.1007/s10919-012-0130-0; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; de Wit R, 1999, PAIN, V79, P89, DOI 10.1016/S0304-3959(98)00158-4; Dehghani H, 2014, ARCH TRAUMA RES, V3, DOI 10.5812/atr.18608; DOWNIE WW, 1978, ANN RHEUM DIS, V37, P378, DOI 10.1136/ard.37.4.378; Druzhkov P. N., 2016, Pattern Recognition and Image Analysis, V26, P9, DOI 10.1134/S1054661816010065; Egede J. O., 2017, P 19 ACM INT C MULT, P146; Egede J, 2017, IEEE INT CONF AUTOMA, P689, DOI 10.1109/FG.2017.87; Ekman P., 2002, FACIAL ACTION CODING; Engle VF, 2001, J GERONTOL A-BIOL, V56, pM405, DOI 10.1093/gerona/56.7.M405; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Florea C, 2016, IMAGE VISION COMPUT, V56, P13, DOI 10.1016/j.imavis.2016.08.014; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Ghasemi A, 2014, 2014 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING (SSP), P61, DOI 10.1109/SSP.2014.6884575; Gholami B, 2010, IEEE T BIO-MED ENG, V57, P1457, DOI 10.1109/TBME.2009.2039214; Giron MST, 2002, J GERONTOL A-BIOL, V57, pM236, DOI 10.1093/gerona/57.4.M236; GRACELY RH, 1978, PAIN, V5, P5, DOI 10.1016/0304-3959(78)90020-9; Guanming Lu, 2008, 2008 International Conference on Neural Networks and Signal Processing, P456, DOI 10.1109/ICNNSP.2008.4590392; Hadjistavropoulos T, 2018, EUR J PAIN, V22, P915, DOI 10.1002/ejp.1177; Hammal Z, 2008, P INT C VIS COMP SCI, P191; Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688; Hammal Z, 2012, PATTERN RECOGN, V45, P1265, DOI 10.1016/j.patcog.2011.09.014; Hassan T. C., 2017, 042017 U APPL SCI HO; Herr K, 2006, J PAIN SYMPTOM MANAG, V31, P170, DOI 10.1016/j.jpainsymman.2005.07.001; Hess U., 2009, METHODS SOCIAL NEURO, P70; Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750; Husebo BS, 2011, BMJ-BRIT MED J, V343, P1; In't Veld EMJH, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00330; Irani Ramin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P88, DOI 10.1109/CVPRW.2015.7301341; Irani Ramin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P80, DOI 10.1109/CVPRW.2015.7301340; K_achele M., 2015, EANN, P275; Kaltwang S, 2016, IEEE T PATTERN ANAL, V38, P1748, DOI 10.1109/TPAMI.2015.2501824; Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36; Kannala J, 2012, INT C PATT RECOG, P1363; Kappesser J, 2002, PAIN, V99, P197, DOI 10.1016/S0304-3959(02)00101-X; Kappesser J, 2010, PAIN, V148, P184, DOI 10.1016/j.pain.2009.10.007; Khan RA, 2013, IEEE INT CON MULTI; Kharghanian R, 2016, IEEE ENG MED BIO, P419, DOI 10.1109/EMBC.2016.7590729; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kunz M, 2015, EUR J PAIN, V19, P1350, DOI 10.1002/ejp.666; Kunz M, 2014, EUR J PAIN, V18, P813, DOI 10.1002/j.1532-2149.2013.00421.x; Kunz M, 2008, PAIN, V140, P127, DOI 10.1016/j.pain.2008.07.019; Kunz M, 2007, PAIN, V133, P221, DOI 10.1016/j.pain.2007.09.007; Kunz M, 2019, PAIN, V160, P535, DOI 10.1097/j.pain.0000000000001424; Kunz M, 2017, BMC GERIATR, V17, DOI 10.1186/s12877-017-0427-2; Kunz M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083277; Kunz M, 2012, BIOL PSYCHOL, V89, P467, DOI 10.1016/j.biopsycho.2011.12.016; Kunz M, 2009, EUR J PAIN, V13, P317, DOI 10.1016/j.ejpain.2008.05.001; Lawrence J, 1993, Neonatal Netw, V12, P59; Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010; Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15; Liu D., 2017, J MACH LEARN RES, V66, P1; Lo Presti Liliana, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P26, DOI 10.1109/CVPRW.2015.7301351; Lo Presti L, 2017, COMPUT VIS IMAGE UND, V156, P19, DOI 10.1016/j.cviu.2016.10.007; Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462; Lucey Patrick, 2009, Int Conf Affect Comput Intell Interact Workshops, V2009, P1; Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003; Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525; Martinez DL, 2017, IEEE COMPUT SOC CONF, P2318, DOI 10.1109/CVPRW.2017.286; Matuszewski B. J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2128, DOI 10.1109/ICCVW.2011.6130511; MCCORMACK HM, 1988, PSYCHOL MED, V18, P1007, DOI 10.1017/S0033291700009934; Meawad F., 2017, P 19 ACM INT C MULT, P397; Meng HY, 2014, IEEE T CYBERNETICS, V44, P315, DOI 10.1109/TCYB.2013.2253768; Monwar MM, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P28, DOI 10.1109/ISSPIT.2006.270764; Monwar MM, 2009, PROC SPIE, V7246, DOI 10.1117/12.806143; Moriarty O, 2011, PROG NEUROBIOL, V93, P385, DOI 10.1016/j.pneurobio.2011.01.002; Muggleton SH, 2018, MACH LEARN, V107, P1119, DOI 10.1007/s10994-018-5707-3; Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048; Neshov N, 2015, INT WORKSH INT DATA, P251, DOI 10.1109/IDAACS.2015.7340738; Nickel MM, 2017, NEUROIMAGE, V148, P141, DOI 10.1016/j.neuroimage.2017.01.011; Niese R., 2009, INT J DIGIT CONTENT, V3, P2; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27; Pedersen H, 2015, LECT NOTES COMPUT SC, V9163, P128, DOI 10.1007/978-3-319-20904-3_12; Picard R, 2017, P NEUR INF PROC SYST; Prince M, 2013, ALZHEIMERS DEMENT, V9, P63, DOI 10.1016/j.jalz.2012.11.007; Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010; PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U; Rathee N, 2016, COMPUT VIS IMAGE UND, V147, P77, DOI 10.1016/j.cviu.2015.12.004; Regnard C., 2013, INT J PALLIATIVE NUR, V9, P173; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rodriguez P, 2022, IEEE T CYBERNETICS, V52, P3314, DOI 10.1109/TCYB.2017.2662199; Roy S., 2007, J VISION, V7, P944, DOI DOI 10.1167/7.9.944; Roy SD, 2016, PROCEDIA COMPUT SCI, V84, P99, DOI 10.1016/j.procs.2016.04.072; Rudovic O, 2013, LECT NOTES COMPUT SC, V8034, P234, DOI 10.1007/978-3-642-41939-3_23; Rupenga M, 2016, 2016 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH); Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Schmid U., 2012, P 11 INT C GRAMM INF, P183; Schmid U, 2018, P 7 WORKSH DYN KNOWL, V2194, P4; Shannon Kathleen, 2003, Intensive Crit Care Nurs, V19, P154, DOI 10.1016/S0964-3397(03)00027-2; Sheu E, 2011, CLIN J PAIN, V27, P593, DOI 10.1097/AJP.0b013e31820f52e1; Siebers M., 2009, P 4 WORKSH EM COMP C, P24; Siebers M, 2016, INFORM SCIENCES, V329, P866, DOI 10.1016/j.ins.2015.10.007; Sikka K., 2014, P 16 INT C MULT INT, P349; Sikka K, 2013, IEEE INT CONF AUTOMA; Sikka K, 2015, PEDIATRICS, V136, pE124, DOI 10.1542/peds.2015-0029; Sikka K, 2014, IMAGE VISION COMPUT, V32, P659, DOI 10.1016/j.imavis.2014.02.008; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Singh S. K., 2015, J BIOL ENG RES REV, V2; Tarassenko L, 2014, PHYSIOL MEAS, V35, P807, DOI 10.1088/0967-3334/35/5/807; Tavakolian M, 2018, INT C PATT RECOG, P350, DOI 10.1109/ICPR.2018.8545324; Tsai FS, 2016, INTERSPEECH, P92, DOI 10.21437/Interspeech.2016-408; United Nations Department of Economic and Social Affairs Population Division, 2017, ESAPWP248; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wager TD, 2013, NEW ENGL J MED, V368, P1388, DOI 10.1056/NEJMoa1204471; Wall P. D., 1999, TXB PAIN, P1; Walter S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF); Wang C, 2018, FRONT BIOENG BIOTECH, V6, DOI 10.3389/fbioe.2018.00033; Wang F, 2017, IEEE IMAGE PROC, P1087; Warden Victoria, 2003, J Am Med Dir Assoc, V4, P9, DOI 10.1097/00130535-200301000-00002; Watson P., 2013, 2013 10 IEEE INT C W, P1; Weitz K, 2019, TM-TECH MESS, V86, P404, DOI 10.1515/teme-2019-0024; Werner P, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.119; Werner P, 2017, IEEE T AFFECT COMPUT, V8, P286, DOI 10.1109/TAFFC.2016.2537327; Werner P, 2014, INT C PATT RECOG, P4582, DOI 10.1109/ICPR.2014.784; Werner P, 2012, IEEE IMAGE PROC, P2313, DOI 10.1109/ICIP.2012.6467359; Wilike Diana J, 1995, ANALGESIA, V1, P91; Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080; Xing Zhang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163107; Yang R., 2016, 2016 6 INT C IMAGE P, P1; Yuan L, 2008, PROC INT C TOOLS ART, P473, DOI 10.1109/ICTAI.2008.122; Zafar Z, 2014, INT C PATT RECOG, P4696, DOI 10.1109/ICPR.2014.803; Zhang W., 2011, INT J ENG MANUF, V1, P69; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao R, 2016, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2016.377; Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191	146	11	11	7	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					1815	1831		10.1109/TPAMI.2019.2958341	http://dx.doi.org/10.1109/TPAMI.2019.2958341			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SA8YQ	31825861	Green Accepted			2022-12-18	WOS:000649590200001
J	Yang, JQ; Xian, K; Wang, P; Zhang, YN				Yang, Jiaqi; Xian, Ke; Wang, Peng; Zhang, Yanning			A Performance Evaluation of Correspondence Grouping Methods for 3D Rigid Data Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Shape; Measurement; Detectors; Feature extraction; Object recognition; Clutter; Performance evaluation; correspondence grouping; 3D computer vision; 3D rigid data; shape matching	OBJECT RECOGNITION; PAIRWISE REGISTRATION; SURFACE; SEGMENTATION; STATISTICS; FEATURES; IMAGES	Seeking consistent point-to-point correspondences between 3D rigid data (point clouds, meshes, or depth maps) is a fundamental problem in 3D computer vision. While a number of correspondence selection methods have been proposed in recent years, their advantages and shortcomings remain unclear regarding different applications and perturbations. To fill this gap, this paper gives a comprehensive evaluation of nine state-of-the-art 3D correspondence grouping methods. A good correspondence grouping algorithm is expected to retrieve as many as inliers from initial feature matches, giving a rise in both precision and recall as well as facilitating accurate transformation estimation. Toward this rule, we deploy experiments on three benchmarks with different application contexts, including shape retrieval, 3D object recognition, and point cloud registration. We also investigate various perturbations such as noise, point density variation, clutter, occlusion, partial overlap, different scales of initial correspondences, and different combinations of keypoint detectors and descriptors. The rich variety of application scenarios and nuisances result in different spatial distributions and inlier ratios of initial feature correspondences, thus enabling a thorough evaluation. Based on the outcomes, we give a summary of the traits, merits, and demerits of evaluated approaches and indicate some potential future research directions.	[Yang, Jiaqi; Wang, Peng; Zhang, Yanning] Northwestern Polytech Univ, Natl Engn Lab Integrated Aerosp Ground Ocean Big, Sch Comp Sci, Xian 710129, Peoples R China; [Xian, Ke] Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multispectral Informat, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China	Northwestern Polytechnical University; Huazhong University of Science & Technology	Wang, P (corresponding author), Northwestern Polytech Univ, Natl Engn Lab Integrated Aerosp Ground Ocean Big, Sch Comp Sci, Xian 710129, Peoples R China.	jqyang@nwpu.edu.cn; kexian@hust.edu.cn; peng.wang@nwpu.edu.cn; ynzhang@nwpu.edu.cn	Xian, Ke/HCH-2921-2022	Xian, Ke/0000-0002-0884-5126	National Natural Science Foundation of China [61876152]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like thank Dr. Anders Glent Buch and Dr. Emanuele Rodola for sharing the code of their methods to us, and the developers of PCL for making many methods evaluated in this paper publicly available. They would also like to thank the Standford 3D Scanning Repository, the University of Western Australia, and the University of Bologna for freely providing their datasets. This work is supported in part by the National Natural Science Foundation of China (No. 61876152).	Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575; [Anonymous], 2011, P EUR WORKSH 3D OBJ; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bian J. W., 2018, ARXIV180802267; Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302; Bronstein A. M., 2010, P EUR WORKSH 3D OBJ; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Buch AG, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1906-1; Buch AG, 2014, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2014.266; Bustos AP, 2018, IEEE T PATTERN ANAL, V40, P2868, DOI 10.1109/TPAMI.2017.2773482; Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y; Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828; Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y; HANSCH R, 2014, ISPRS ANN PHOTOGRAMM, V2; Hough P.V.C, 1962, U.S. Patent, Patent No. [3069654, 3,069,654]; Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kim H, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P119, DOI 10.1109/3DV.2013.24; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI 10.1007/s11263-018-1117-z; Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570; Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Mian A.S., 2005, INT J SHAPE MODEL, V11, P253, DOI [10.1142/S0218654305000797, DOI 10.1142/S0218654305000797]; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0; Odense D., 2018, 3D MATCHING; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Petrelli A, 2016, COMPUT GRAPH FORUM, V35, P59, DOI 10.1111/cgf.12732; Petrelli A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P403, DOI 10.1109/3DIMPVT.2012.51; Petrelli A, 2011, IEEE I CONF COMP VIS, P2244, DOI 10.1109/ICCV.2011.6126503; Qi CR, 2017, ADV NEUR IN, V30; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257; Rodola E, 2013, IEEE I CONF COMP VIS, P1169, DOI 10.1109/ICCV.2013.149; Rodola E, 2013, INT J COMPUT VISION, V102, P129, DOI 10.1007/s11263-012-0568-x; Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967; Rusu RB, 2008, IAS-10: INTELLIGENT AUTONOMOUS SYSTEMS 10, P119, DOI 10.3233/978-1-58003-887-8-119; Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011; Salti S, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P424, DOI 10.1109/3DIMPVT.2012.10; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y; Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187; Sukno FM, 2012, LECT NOTES COMPUT SC, V7432, P92, DOI 10.1007/978-3-642-33191-6_10; Tateno K, 2016, IEEE INT CONF ROBOT, P2295, DOI 10.1109/ICRA.2016.7487378; Tombari Federico, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P349, DOI 10.1109/PSIVT.2010.65; Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Weibull J W, 1997, EVOLUTIONARY GAME TH; Yang JQ, 2019, PATTERN RECOGN LETT, V117, P1, DOI 10.1016/j.patrec.2018.11.018; Yang JQ, 2017, INT CONF 3D VISION, P467, DOI 10.1109/3DV.2017.00060; Yang JQ, 2018, IEEE T IMAGE PROCESS, V27, P3766, DOI 10.1109/TIP.2018.2827330; Yang JQ, 2017, COMPUT VIS IMAGE UND, V160, P133, DOI 10.1016/j.cviu.2017.02.004; Yang JQ, 2017, PATTERN RECOGN, V66, P375, DOI 10.1016/j.patcog.2017.01.017; Yang JQ, 2016, INFORM SCIENCES, V346, P163, DOI 10.1016/j.ins.2016.01.095; Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637	64	11	11	6	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					1859	1874		10.1109/TPAMI.2019.2960234	http://dx.doi.org/10.1109/TPAMI.2019.2960234			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31869781	Green Submitted			2022-12-18	WOS:000649590200004
J	Muratore, F; Gienger, M; Peters, J				Muratore, Fabio; Gienger, Michael; Peters, Jan			Assessing Transferability From Simulation to Reality for Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Robots; Training; Physics; Upper bound; Analytical models; Reinforcement learning; Reinforcement learning; domain randomization; sim-to-real transfer	SOLUTION QUALITY; GAP	Learning robot control policies from physics simulations is of great interest to the robotics community as it may render the learning process faster, cheaper, and safer by alleviating the need for expensive real-world experiments. However, the direct transfer of learned behavior from simulation to reality is a major challenge. Optimizing a policy on a slightly faulty simulator can easily lead to the maximization of the 'Simulation Optimization Bias' (SOB). In this case, the optimizer exploits modeling errors of the simulator such that the resulting behavior can potentially damage the robot. We tackle this challenge by applying domain randomization, i.e., randomizing the parameters of the physics simulations during learning. We propose an algorithm called Simulation-based Policy Optimization with Transferability Assessment (SPOTA) which uses an estimator of the SOB to formulate a stopping criterion for training. The introduced estimator quantifies the over-fitting to the set of domains experienced while training. Our experimental results on two different second order nonlinear systems show that the new simulation-based policy search algorithm is able to learn a control policy exclusively from a randomized simulator, which can be applied directly to real systems without any additional training.	[Muratore, Fabio; Peters, Jan] Tech Univ Darmstadt, Intelligent Autonomous Syst Grp, D-64289 Darmstadt, Germany; [Muratore, Fabio; Gienger, Michael] Honda Res Inst Europe, D-63073 Offenbach, Germany; [Peters, Jan] Max Planck Inst Intelligent Syst, D-72076 Tubingen, Germany	Technical University of Darmstadt; Honda Motor Company; Max Planck Society	Muratore, F (corresponding author), Tech Univ Darmstadt, Intelligent Autonomous Syst Grp, D-64289 Darmstadt, Germany.	fabio@robot-learning.de; michael.gienger@honda-ri.de; peters@ias.informatik.tu-darmstadt.de	Peters, Jan/P-6027-2019; Peters, Jan R/D-5068-2009	Peters, Jan/0000-0002-5266-8091; Peters, Jan R/0000-0002-5266-8091; Gienger, Michael/0000-0001-8036-2519	Honda Research Institute Europe; European Union [640554]	Honda Research Institute Europe; European Union(European Commission)	Fabio Muratore gratefully acknowledges the financial support from Honda Research Institute Europe. Jan Peters received funding from the European Unions Horizon 2020 research and innovation programme under Grant agreement No 640554.	Andrychowicz M., 2017, ADV NEURAL INFORM PR; Antonova R., 2017, ARXIV E PRINTS; Bastin F, 2006, MATH PROGRAM, V108, P207, DOI 10.1007/s10107-006-0708-6; Bayraksan G, 2006, MATH PROGRAM, V108, P495, DOI 10.1007/s10107-006-0720-x; Bongard J, 2006, SCIENCE, V314, P1118, DOI 10.1126/science.1133687; Bousmalis K, 2018, IEEE INT CONF ROBOT, P4243; Chebotar Y, 2019, IEEE INT CONF ROBOT, P8973, DOI 10.1109/ICRA.2019.8793789; Deisenroth MP, 2014, IEEE INT CONF ROBOT, P3876, DOI 10.1109/ICRA.2014.6907421; DiCiccio TJ, 1996, STAT SCI, V11, P189; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Hanna JP, 2017, AAAI CONF ARTIF INTE, P3834; HOBBS BF, 1989, WATER RESOUR RES, V25, P152, DOI 10.1029/WR025i002p00152; Isermann R, 2011, IDENTIFICATION OF DYNAMIC SYSTEMS: AN INTRODUCTION WITH APPLICATIONS, P1, DOI 10.1007/978-3-540-78879-9; Jakobi N, 1995, LECT NOTES ARTIF INT, V929, P704; Kim S, 2015, INT SER OPER RES MAN, V216, P207, DOI 10.1007/978-1-4939-1384-8_8; King DB, 2015, ACS SYM SER, V1214, P1; Koos S, 2013, IEEE T EVOLUT COMPUT, V17, P122, DOI 10.1109/TEVC.2012.2185849; Kurutach T., 2018, P INT C LEARN REPR; Lillicrap T. P., 2016, P 33 INT C MACH LEAR; Mak WK, 1999, OPER RES LETT, V24, P47, DOI 10.1016/S0167-6377(98)00054-6; Mandlekar A, 2017, IEEE INT C INT ROBOT, P3932; Matas Jan, 2018, C ROB LEARN; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Mordatch I, 2015, IEEE INT C INT ROBOT, P5307, DOI 10.1109/IROS.2015.7354126; Muratore F., 2018, C ROBOT LEARNING, P700; OpenAI, 2018, LEARN DEXT IN HAND M; Pasupathy R, 2009, ACM T MODEL COMPUT S, V19, DOI 10.1145/1502787.1502788; Peng XB, 2018, IEEE INT CONF ROBOT, P3803, DOI 10.1109/ICCABS.2018.8541936; Pinto L, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Pinto L, 2017, PR MACH LEARN RES, V70; Quanser, 2019, QUANS PLATF; Rajeswaran A., 2017, ADV NEURAL INFORM PR, P6553; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rusu A. A., 2017, C ROBOT LEARNING, P262; Sadeghi F, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII; Schulman J., 2017, ARXIV E PRINTS; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Tobin J, 2017, IEEE INT C INT ROBOT, P23; Wang JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778810; Yu WH, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII	40	11	11	5	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1172	1183		10.1109/TPAMI.2019.2952353	http://dx.doi.org/10.1109/TPAMI.2019.2952353			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31722475	Green Submitted			2022-12-18	WOS:000626525300005
J	Zhou, JTY; Zhang, H; Jin, D; Peng, X				Zhou, Joey Tianyi; Zhang, Hao; Jin, Di; Peng, Xi			Dual Adversarial Transfer for Sequence Labeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Labeling; Task analysis; Training; Feature extraction; Tagging; Natural language processing; Computer architecture; Sequence labeling; named entity recognition; chunking; part-of-speech tagging; transfer learning; natural language processing; adversarial training		We propose a new architecture for addressing sequence labeling, termed Dual Adversarial Transfer Network (DATNet). Specifically, the proposed DATNet includes two variants, i.e., DATNet-F and DATNet-P, which are proposed to explore effective feature fusion between high and low resource. To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD) and adopt adversarial training to boost model generalization. We investigate the effects of different components of DATNet across different domains and languages, and show that significant improvement can be obtained especially for low-resource data. Without augmenting any additional hand-crafted features, we achieve state-of-the-art performances on CoNLL, Twitter, PTB-WSJ, OntoNotes and Universal Dependencies with three popular sequence labeling tasks, i.e., Named entity recognition (NER), Part-of-Speech (POS) Tagging and Chunking.	[Zhou, Joey Tianyi] ASTAR, Inst High Performance Comp, Singapore 138632, Singapore; [Zhang, Hao] ASTAR, Artificial Intelligence Initiat, Singapore 138632, Singapore; [Jin, Di] MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Peng, Xi] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China	Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); Agency for Science Technology & Research (A*STAR); Massachusetts Institute of Technology (MIT); Sichuan University	Peng, X (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.	zhouty@ihpc.a-star.edu.sg; zhang_hao@scei.a-star.edu.sg; jindi15@tmit.edu; pengx.gm@gmail.com	Jin, Di/AAN-4152-2021; Hao, Zhang/ABE-3767-2021; Peng, Xi/B-9002-2012	Hao, Zhang/0000-0002-2725-6458; Peng, Xi/0000-0002-5727-2790; /0000-0002-9587-1698; Zhou, Joey Tianyi/0000-0002-4675-7055	Fundamental Research Funds for the Central Universities [YJ201949, 2018SCUH0070]; Singapore government's Research, Innovation and Enterprise 2020 plan (Advanced Manufacturing and Engineering domain) [A1687b0033, A18A1b0045]; NFSC [61806135, 61625204, 61836006]	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Singapore government's Research, Innovation and Enterprise 2020 plan (Advanced Manufacturing and Engineering domain); NFSC(National Natural Science Foundation of China (NSFC))	This work was supported by the Fundamental Research Funds for the Central Universities under Grant YJ201949 and 2018SCUH0070, by programmatic grant no. A1687b0033 and no. A18A1b0045 from the Singapore government's Research, Innovation and Enterprise 2020 plan (Advanced Manufacturing and Engineering domain), and by NFSC under Grant 61806135, 61625204, and 61836006. J. T. Zhou and H. Zhang contributed to this work equally.	Adams O, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P937; Aguilar Gustavo, 2018, P 2018 C N AM CHAPT, V1, P1401, DOI DOI 10.18653/V1/N18-1127; Aguilar Gustavo, 2017, P 3 WORKSH NOIS US G, P148, DOI DOI 10.18653/V1/W17-4419; Akbik Alan., 2018, P 27 INT C COMPUTATI, P1638; Al-Rfou R., 2015, P 2015 SIAM INT C DA, P586, DOI DOI 10.1137/1.9781611974010.66; Al-Rfou Rami, 2013, P 17 C COMP NAT LANG, P183, DOI DOI 10.1007/S10479-011-0841-3; [Anonymous], 2018, P AAAI C ART INT; [Anonymous], 2010, P ANN M ASS COMP LIN; [Anonymous], **DATA OBJECT**; Bahdanau D., 2015, ICLR; Berend Gabor, 2017, T ASSOC COMPUT LING, V5, P247; Bojanowski Piotr., 2017, TACL, V5, P135, DOI [10.1162/tacl_a_00051, DOI 10.1162/TACL_A_00051]; Chen X., 2018, T ASS COMPUTATIONAL, V6, P557, DOI DOI 10.1162/TACL_A_00039; Chiu J.P., 2016, T ASS COMPUTATIONAL, V4, P357, DOI DOI 10.1162/TACL_A_00104; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Cotterell  R., 2017, P 8 INT JOINT C NAT, V2, P91, DOI DOI 10.18653/V1/D17-1078; Devlin J., 2018, P 2019 C N AM CHAPT, DOI [DOI 10.18653/V1/N19-1423, 10.18653/v1/N19-1423]; Erik F., 2002, COLING 02 6 C NAT LA; Fang M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P587, DOI 10.18653/v1/P17-2093; Feng XC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4071; Gillick Dan, 2016, 2016 C N AM CHAPT AS; Goodfellow I.J., 2015, ARXIV PREPRINT ARXIV; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gui Tao, 2017, P 2017 C EMP METH NA, P2411; Hashimoto Kazuma, 2017, P C EMP METH NAT LAN, P1923; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404; Kim Joo-Kyung, 2017, P 2017 C EMP METH NA, P2832, DOI [10.18653/v1/D17-1302, DOI 10.18653/V1/D17-1302]; Kim Sang E.F.T., 2003, P 7 C NAT LANG LEARN; Kingma D.P, P 3 INT C LEARNING R; Lample G., 2016, C N AM CHAPTER ASS C, P260, DOI [10.18653/v1/N16-1030, 10.18653/v1/n16-1030, DOI 10.18653/V1/N16-1030]; Li Qi, 2012, P 21 ACM INT C INF K, P1727, DOI DOI 10.1145/2396761.2398506; Limsopatham N., 2016, PROC 2 WORKSHOP NOIS, P145; Lin B.Y., 2017, P 3 WORKSHOP NOISY U, P160; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P799; Lin Z., 2017, ICLR; Ling Wang, 2015, P 2015 C EMP METH NA, P1520, DOI DOI 10.18653/V1/D15-1176; Liu LY, 2018, AAAI CONF ARTIF INTE, P5253; Liu PJ, 2017, 2017 24TH SAINT PETERSBURG INTERNATIONAL CONFERENCE ON INTEGRATED NAVIGATION SYSTEMS (ICINS); Lopez, 2016, P WORKSH NOIS US GEN, P171; Luo Gang, 2015, P 2015 C EMP METH NA, P879, DOI DOI 10.18653/V1/D15-1104; Luong Minh-Thang, 2016, CORR; Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064; Marcus Mitchell, 1994, P WORKSH HUM LANG TE, P114, DOI [10.3115/1075812.1075835, DOI 10.3115/1075812.1075835]; Mayhew Stephen, 2017, P 2017 C EMP METH NA, P2536, DOI DOI 10.18653/V1/D17-1269; Miyato T., 2017, P INT C LERAN REPR; Nguyen D.Q., 2017, P CONLL 2017 SHARED, V4, P134, DOI [DOI 10.18653/V1/K17-3014, 10.18653/v1/k17-3014]; Ni J., 2016, PROC C EMPIR METHODS, P1275, DOI 10.18653/v1/D16- 1135.; Ni J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1470, DOI 10.18653/v1/P17-1135; Passos Alexandre, 2014, P 18 C COMP NAT LANG, P78; Peters Matthew, 2018, DEEP CONTEXTUALIZED, P2227, DOI [10.18653/v1/N18-1202, DOI 10.18653/V1/N18-1202]; Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161; Pires T., 2019, ARXIV PREPRINT ARXIV; Plank B, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P412; Pradhan SS, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P517, DOI 10.1109/ICSC.2007.83; Rei M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2121, DOI 10.18653/v1/P17-1194; Rei Marek, 2018, NAACL HLT, V1, P293; Reimers Nils, 2017, P 2017 C EMP METH NA, P338, DOI DOI 10.18653/V1/D17-1035; Sang Erik F. Tjong Kim, 2000, 4 C COMP NAT LANG LE; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; von Daniken Pius, 2017, P 3 WORKSH NOIS US G, V2017, P166, DOI DOI 10.18653/V1/W17-4422; Wang H., 2018, DEEP LEARNING GENOMI; Yang Z., 2016, ADV NEURAL INF PROCE, V29; Yang Zhilin, 2017, ICLR; Yarowsky David, 2001, P 1 INT C HUM LANG T; Yasunaga Michihiro, 2018, P 2018 C N AM CHAPT, V1, P976, DOI [10.18653/v1/N18-1089, DOI 10.18653/V1/N18-1089]; Zeman Daniel, 2017, P CONLL 2017 SHAR TA, P1, DOI DOI 10.18653/V1/K17-3001; Zhang B., 2016, P C N AM CHAPT ASS C; Zhou JT, 2018, IEEE T NEUR NET LEAR, V29, P6191, DOI 10.1109/TNNLS.2018.2827036; Zhou JTY, 2019, J MACH LEARN RES, V20; Zhou JT, 2020, IEEE T NEUR NET LEAR, V31, P2304, DOI 10.1109/TNNLS.2019.2911236; Zhou JT, 2019, IEEE T NEUR NET LEAR, V30, P2794, DOI 10.1109/TNNLS.2018.2885854; Zukov-Gregoric A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P69	81	11	11	4	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					434	446		10.1109/TPAMI.2019.2931569	http://dx.doi.org/10.1109/TPAMI.2019.2931569			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31369370				2022-12-18	WOS:000607383300005
J	Eriksson, A; Olsson, C; Kahl, F; Chin, TJ				Eriksson, Anders; Olsson, Carl; Kahl, Fredrik; Chin, Tat-Jun			Rotation Averaging with the Chordal Distance: Global Minimizers and Strong Duality	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Rotation averaging; structure from motion; lagrangian duality; graph laplacian; chordal distance		In this paper we explore the role of duality principles within the problem of rotation averaging, a fundamental task in a wide range of applications. In its conventional form, rotation averaging is stated as a minimization over multiple rotation constraints. As these constraints are non-convex, this problem is generally considered challenging to solve globally. We show how to circumvent this difficulty through the use of Lagrangian duality. While such an approach is well-known it is normally not guaranteed to provide a tight relaxation. Based on spectral graph theory, we analytically prove that in many cases there is no duality gap unless the noise levels are severe. This allows us to obtain certifiably global solutions to a class of important non-convex problems in polynomial time. We also propose an efficient, scalable algorithm that outperforms general purpose numerical solvers by a large margin and compares favourably to current state-of-the-art. Further, our approach is able to handle the large problem instances commonly occurring in structure from motion settings and it is trivially parallelizable. Experiments are presented for a number of different instances of both synthetic and real-world data.	[Eriksson, Anders] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia; [Olsson, Carl; Kahl, Fredrik] Chalmers Univ Technol, S-41296 Gothenburg, Sweden; [Olsson, Carl] Lund Univ, S-22100 Lund, Sweden; [Chin, Tat-Jun] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	University of Queensland; Chalmers University of Technology; Lund University; University of Adelaide	Eriksson, A (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.	a.eriksson@uq.edu.au; calle@maths.lth.se; fredrik.kahl@chalmers.se; tat-jun.chin@adelaide.edu.au		Eriksson, Anders/0000-0003-2652-7110	Australian Research Council [FT170100072]; Swedish Research Council [2016-04445, 2018-05375]; Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots); Vinnova/FFI [2017-01942]	Australian Research Council(Australian Research Council); Swedish Research Council(Swedish Research CouncilEuropean Commission); Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots); Vinnova/FFI	This work has been funded by the Australian Research Council through grant FT170100072, the Swedish Research Council (no. 2016-04445 and 2018-05375), the Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots) and Vinnova/FFI (Perceptron, no. 2017-01942).	Arie-Nachimson M, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P81, DOI 10.1109/3DIMPVT.2012.46; Arrigoni F., 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P491, DOI 10.1109/3DV.2014.48; Boumal N., 2015, ARXIV150600575; Boumal N, 2014, INF INFERENCE, V3, P1, DOI 10.1093/imaiai/iat006; Boyd S, 2004, CONVEX OPTIMIZATION; Briales J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4630, DOI 10.1109/IROS.2016.7759681; Carlone L., 2016, SE SYNC CERTIFIABLY; Carlone L, 2016, IEEE T ROBOT, V32, P545, DOI 10.1109/TRO.2016.2544304; Carlone L, 2015, IEEE INT CONF ROBOT, P4597, DOI 10.1109/ICRA.2015.7139836; Carlone L, 2015, IEEE INT CONF ROBOT, P4589, DOI 10.1109/ICRA.2015.7139835; Chatterjee A, 2013, IEEE I CONF COMP VIS, P521, DOI 10.1109/ICCV.2013.70; Enqvist O., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P264, DOI 10.1109/ICCVW.2011.6130252; Eriksson A, 2018, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2018.00021; FIEDLER M, 1973, CZECH MATH J, V23, P298; Fredriksson J., 2012, P AS C COMP VIS, P245; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Govindu VM, 2006, LECT NOTES COMPUT SC, V3852, P457; Govindu VM, 2001, PROC CVPR IEEE, P218; Hartley R., 2010, P 19 INT S MATH THEO, P2435; Hartley R., 2011, P IEEE C COMP VIS PA, P3041, DOI DOI 10.1109/CVPR.2011.5995745; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824; Martinec D., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383115; Moulon P, 2013, IEEE I CONF COMP VIS, P3248, DOI 10.1109/ICCV.2013.403; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Tron R., 2012, 51 IEEE C DECISION C, P2052, DOI [10.1109/CDC.2012.6426677, DOI 10.1109/CDC.2012.6426677]; Tron R, 2014, IEEE T AUTOMAT CONTR, V59, P3325, DOI 10.1109/TAC.2014.2351912; Wang L, 2009, 2009 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS, P1, DOI 10.1109/ReConFig.2009.13; Wilson K, 2016, LECT NOTES COMPUT SC, V9911, P255, DOI 10.1007/978-3-319-46478-7_16; Zhong Y., 2017, ARXIV170306605	32	11	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					256	268		10.1109/TPAMI.2019.2930051	http://dx.doi.org/10.1109/TPAMI.2019.2930051			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31352332				2022-12-18	WOS:000597206900017
J	Kanezaki, A; Matsushita, Y; Nishida, Y				Kanezaki, Asako; Matsushita, Yasuyuki; Nishida, Yoshifumi			RotationNet for Joint Object Categorization and Unsupervised Pose Estimation from Multi-View Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; 3D shape retrieval; viewpoint estimation; multi-task learning; convolutional neural network	RECOGNITION	We propose a Convolutional Neural Network (CNN)-based model "RotationNet," which takes multi-view images of an object as input and jointly estimates its pose and object category. Unlike previous approaches that use known viewpoint labels for training, our method treats the viewpoint labels as latent variables, which are learned in an unsupervised manner during the training using an unaligned object dataset. RotationNet uses only a partial set of multi-view images for inference, and this property makes it useful in practical scenarios where only partial views are available. Moreover, our pose alignment strategy enables one to obtain view-specific feature representations shared across classes, which is important to maintain high accuracy in both object categorization and pose estimation. Effectiveness of RotationNet is demonstrated by its superior performance to the state-of-the-art methods of 3D object classification on 10- and 40-class ModelNet datasets. We also show that RotationNet, even trained without known poses, achieves comparable performance to the state-of-the-art methods on an object pose estimation dataset. Furthermore, our object ranking method based on classification by RotationNet achieved the first prize in two tracks of the 3D Shape Retrieval Contest (SHREC) 2017. Finally, we demonstrate the performance of real-world applications of RotationNet trained with our newly created multi-view image dataset using a moving USB camera.	[Kanezaki, Asako; Nishida, Yoshifumi] Natl Inst Adv Ind Sci & Technol, Koto Ku, 2-4-7 Aomi, Tokyo 1350064, Japan; [Matsushita, Yasuyuki] Osaka Univ, 1-5 Yamadaoka, Suita, Osaka 5650871, Japan	National Institute of Advanced Industrial Science & Technology (AIST); Osaka University	Kanezaki, A (corresponding author), Natl Inst Adv Ind Sci & Technol, Koto Ku, 2-4-7 Aomi, Tokyo 1350064, Japan.	kanezaki.asako@aist.go.jp; yasumat@ist.osaka-u.ac.jp; y.nishidai@aist.go.jp	Kanezaki, Asako/A-8515-2017	Kanezaki, Asako/0000-0003-3217-1405; Matsushita, Yasuyui/0000-0002-1935-4752	New Energy and Industrial Technology Development Organization (NEDO)	New Energy and Industrial Technology Development Organization (NEDO)(New Energy and Industrial Technology Development Organization (NEDO))	This project is supported by the New Energy and Industrial Technology Development Organization (NEDO). The authors would like to thank Hiroki Matsuno for his support in developing theHoloLens application.	Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543; Bakry A, 2014, LECT NOTES COMPUT SC, V8692, P434, DOI 10.1007/978-3-319-10593-2_29; Borotschnig H, 2000, IMAGE VISION COMPUT, V18, P715, DOI 10.1016/S0262-8856(99)00075-X; Brock Andrew, 2016, ARXIV160804236; Chang Angel X., 2015, ARXIV151203012CSGR P; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen CY, 2014, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2014.258; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Elhoseiny M, 2016, PR MACH LEARN RES, V48; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371; GARCIAGARCIA A, 2016, IEEE IJCNN, P1578, DOI DOI 10.1109/IJCNN.2016.7727386; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hegde V., 2016, ARXIV PREPRINT ARXIV; Hua B.-S., 2017, P EUR WORKSH 3D OBJ, P25; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; Johns E, 2016, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2016.414; Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuznetsova A, 2016, AAAI CONF ARTIF INTE, P3523; Lai K., 2011, P AAAI C ART INT, P1474; Lai K, 2011, IEEE INT CONF ROBOT, P1817; Li YY, 2016, ADV NEUR IN, V29; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Novotny D, 2017, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2017.558; Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2; Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; Savva M, 2017, PROC EUROGR WORKSHOP, P39; Sedaghat N, 2017, P BRIT MACH VIS C; Sfikas K., 2017, P 3DOR, V8, P1, DOI DOI 10.2312/3DOR.20171045; Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Su H, 2015, IEEE I CONF COMP VIS, P2677, DOI 10.1109/ICCV.2015.307; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Su Jong-Chyi, 2018, P EUR C COMP VIS ECC; Wang C., 2017, P BRIT MACH VIS C; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Xu X, 2016, INT C PATT RECOG, P3506, DOI 10.1109/ICPR.2016.7900177; Zaheer M., 2017, ADV NEURAL INFORM PR, P3391; Zanuttigh P, 2017, IEEE IMAGE PROC, P3615; Zhang H., 2013, 27 AAAI C ART INT BE, V2, P1012; Zhi SF, 2018, COMPUT GRAPH-UK, V71, P199, DOI 10.1016/j.cag.2017.10.007; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhu Z., 2014, NIPS, P217	49	11	11	4	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					269	283		10.1109/TPAMI.2019.2922640	http://dx.doi.org/10.1109/TPAMI.2019.2922640			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31217093	Bronze			2022-12-18	WOS:000597206900018
J	Li, KP; Wu, ZY; Peng, KC; Ernst, J; Fu, Y				Li, Kunpeng; Wu, Ziyan; Peng, Kuan-Chuan; Ernst, Jan; Fu, Yun			Guided Attention Inference Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural networks; Semantics; Visualization; Image segmentation; Supervised learning; Training data; Convolutional neural networks; Convolutional neural network; semantic segmentation; network attention; weakly supervised learning; biased data		With only coarse labels, weakly supervised learning typically uses top-down attention maps generated by back-propagating gradients as priors for tasks such as object localization and semantic segmentation. While these attention maps are intuitive and informative explanations of deep neural network, there is no effective mechanism to manipulate the network attention during learning process. In this paper, we address three shortcomings of previous approaches in modeling such attention maps in one common framework. First, we make attention maps a natural and explicit component in the training pipeline such that they are end-to-end trainable. Moreover, we provide self-guidance directly on these maps by exploring supervision from the network itself to improve them towards specific target tasks. Lastly, we proposed a design to seamlessly bridge the gap between using weak and extra supervision if available. Despite its simplicity, experiments on the semantic segmentation task demonstrate the effectiveness of our methods. Besides, the proposed framework provides a way not only explaining the focus of the learner but also feeding back with direct guidance towards specific tasks. Under mild assumptions our method can also be understood as a plug-in to existing convolutional neural networks to improve their generalization performance.	[Li, Kunpeng; Fu, Yun] Northeastern Univ, Boston, MA 02115 USA; [Wu, Ziyan; Peng, Kuan-Chuan; Ernst, Jan] Siemens Corp Technol, Princeton, NJ 08540 USA	Northeastern University; Siemens AG	Li, KP (corresponding author), Northeastern Univ, Boston, MA 02115 USA.	kunpengli@ece.neu.edu; wuzy.buaa@gmail.com; kuanchuan.peng@siemens.com; jan.ernst@siemens.com; yunfu@ece.neu.edu	Li, Kunpeng/AAH-1164-2019	Li, Kunpeng/0000-0001-5805-793X; Ernst, Jan/0000-0002-6342-9213; Fu, Yun/0000-0002-5098-2853	NSF IIS Award [1651902]; U.S. Army ResearchOffice [W911NF-17-1-0367]	NSF IIS Award(National Science Foundation (NSF)); U.S. Army ResearchOffice	This paper is based primarily on the work done during Kunpeng Li's internship at Siemens Corporate Technology. This research is supported in part by the NSF IIS Award 1651902 andU.S. Army ResearchOffice AwardW911NF-17-1-0367.	Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.185; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bai Y, 2014, PROC INT CONF RECON; Bargal SA, 2018, PROC CVPR IEEE, P1440, DOI 10.1109/CVPR.2018.00156; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338; Chen L.-C., 2015, COMPUT SCI; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dhar P, 2019, PROC CVPR IEEE, P5133, DOI 10.1109/CVPR.2019.00528; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jia Y., 2014, P 22 ACM INT C MULT, P675; Kim D, 2017, IEEE I CONF COMP VIS, P3554, DOI 10.1109/ICCV.2017.382; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Lee N., 2018, P INT C LEARN REPR; Li K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1492, DOI 10.1145/3240508.3240674; Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960; Li KP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2166; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Paszke A., 2017, AUTOMATIC DIFFERENTI, DOI DOI 10.1016/J.COMPAG.2018.04.002; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6; Roy A, 2017, PROC CVPR IEEE, P7282, DOI 10.1109/CVPR.2017.770; Saleh F, 2016, LECT NOTES COMPUT SC, V9912, P413, DOI 10.1007/978-3-319-46484-8_25; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Simonyan K., 2014, WORKSH INT C LEARN R, P1; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Springenberg J.T., 2014, ARXIV14126806; Subramanya A., 2018, ARXIV181202843; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang J, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901336; Zhang W, 2018, IEEE CONF COMPUT; Zhang XL, 2018, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2018.00144; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhang ZZ, 2017, PROC CVPR IEEE, P3549, DOI 10.1109/CVPR.2017.378; Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou YZ, 2018, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2018.00399	60	11	11	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					2996	3010		10.1109/TPAMI.2019.2921543	http://dx.doi.org/10.1109/TPAMI.2019.2921543			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31180839	hybrid			2022-12-18	WOS:000587912800003
J	Lin, D; Huang, H				Lin, Di; Huang, Hui			Zig-Zag Network for Semantic Segmentation of RGB-D Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Semantics; Computer architecture; Decoding; Image resolution; Feature extraction; Correlation; RGB-D images; semantic segmentation; convolutional neural networks		Semantic segmentation of images requires an understanding of appearances of objects and their spatial relationships in scenes. The fully convolutional network (FCN) has been successfully applied to recognize objects' appearances, which are represented with RGB channels. Images augmented with depth channels provide more understanding of the geometric information of the scene in an image. In this paper, we present a multiple-branch neural network to utilize depth information to assist in the semantic segmentation of images. Our approach splits the image into layers according to the "scene-scale". We introduce the context-aware receptive field (CARF), which provides better control of the relevant context information of learned features. Each branch of the network is equipped with CARF to adaptively aggregate the context information of image regions, leading to a more focused domain that is easier to learn. Furthermore, we propose a new zig-zag architecture to exchange information between the feature maps at different levels, augmented by the CARFs of the backbone network and decoder network. With the flexible information propagation allowed by our zig-zag network, we enrich the context information of feature maps for the segmentation. We show that the zig-zag network achieves state-of-the-art performances on several public datasets.	[Lin, Di; Huang, Hui] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China	Shenzhen University	Huang, H (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.	ande.lin1988@gmail.com; hhzhiyan@gmail.com		Huang, Hui/0000-0003-3212-0544	NSFC [61702338]; National 973 Program [2015CB352501]; Guangdong Science and Technology Program [2015A0303 12015]; Shenzhen Innovation Program [KQJSCX201707271 01233642]; LHTD [20170003]; National Engineering Laboratory for Big Data System Computing Technology	NSFC(National Natural Science Foundation of China (NSFC)); National 973 Program(National Basic Research Program of China); Guangdong Science and Technology Program; Shenzhen Innovation Program; LHTD; National Engineering Laboratory for Big Data System Computing Technology	We thank the anonymous reviewers and editors for their constructive suggestions. This work was supported in parts by NSFC (61702338), National 973 Program (2015CB352501), Guangdong Science and Technology Program (2015A0303 12015), Shenzhen Innovation Program (KQJSCX201707271 01233642), LHTD (20170003), and the National Engineering Laboratory for Big Data System Computing Technology.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Badrinarayanan V., 2015, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615; CHEN L, 2018, CIKM18 P 27 ACM INT, P833, DOI DOI 10.1107/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Couprie C., 2013, ARXIV13013572, P1; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Du J, 2016, PROCEEDINGS OF 2016 IEEE ADVANCED INFORMATION MANAGEMENT, COMMUNICATES, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IMCEC 2016), P1217, DOI 10.1109/IMCEC.2016.7867405; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gadde R, 2016, LECT NOTES COMPUT SC, V9905, P597, DOI 10.1007/978-3-319-46448-0_36; Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He Y., 2016, CORR; Husain F, 2017, IEEE ROBOT AUTOM LET, V2, P49, DOI 10.1109/LRA.2016.2532927; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kendall Alex, 2017, ADV NEURAL INFORM PR, DOI DOI 10.5555/3295222.3295309; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lin D, 2018, LECT NOTES COMPUT SC, V11207, P622, DOI 10.1007/978-3-030-01219-9_37; Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147; Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344; LIN GS, 2016, PROC CVPR IEEE, P3194, DOI DOI 10.1109/CVPR.2016.348; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533; Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189; Qi X., 2017, P IEEE C COMP VIS PA, P5199; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409; Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40; Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9; Yu F., 2016, P ICLR 2016; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	50	11	12	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2642	2655		10.1109/TPAMI.2019.2923513	http://dx.doi.org/10.1109/TPAMI.2019.2923513			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31226067				2022-12-18	WOS:000567471300023
J	Yu, T; Zhao, JH; Zheng, ZR; Guo, KW; Dai, QH; Li, H; Pons-Moll, G; Liu, YB				Yu, Tao; Zhao, Jianhui; Zheng, Zerong; Guo, Kaiwen; Dai, Qionghai; Li, Hao; Pons-Moll, Gerard; Liu, Yebin			DoubleFusion: Real-Time Capture of Human Performances with Inner Body Shapes from a Single Depth Sensor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Surface reconstruction; Real-time systems; Tracking; Strain; Cameras; Skeleton; RGBD sensor; human performance capture; human shape reconstruction; real-time	MARKERLESS MOTION CAPTURE; INTERACTING CHARACTERS; OBJECTS; REGISTRATION; TRACKING	We propose DoubleFusion, a new real-time system that combines volumetric non-rigid reconstruction with data-driven template fitting to simultaneously reconstruct detailed surface geometry, large non-rigid motion and the optimized human body shape from a single depth camera. One of the key contributions of this method is a double-layer representation consisting of a complete parametric body model inside, and a gradually fused detailed surface outside. A pre-defined node graph on the body parameterizes the non-rigid deformations near the body, and a free-form dynamically changing graph parameterizes the outer surface layer far from the body, which allows more general reconstruction. We further propose a joint motion tracking method based on the double-layer representation to enable robust and fast motion tracking performance. Moreover, the inner parametric body is optimized online and forced to fit inside the outer surface layer as well as the live depth input. Overall, our method enables increasingly denoised, detailed and complete surface reconstructions, fast motion tracking performance and plausible inner body shape reconstruction in real-time. Experiments and comparisons show improved fast motion tracking and loop closure performance on more challenging scenarios. Two extended applications including body measurement and shape retargeting show the potential of our system in terms of practical use.	[Yu, Tao; Zhao, Jianhui] Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing 100191, Peoples R China; [Zheng, Zerong; Dai, Qionghai; Liu, Yebin] Tsinghua Univ, Dept Automat, Broadband Network & Digital Media Lab, Beijing 100084, Peoples R China; [Guo, Kaiwen] Google Inc, San Francisco, CA 94105 USA; [Li, Hao] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90007 USA; [Pons-Moll, Gerard] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Beihang University; Tsinghua University; Google Incorporated; University of Southern California; Max Planck Society	Liu, YB (corresponding author), Tsinghua Univ, Dept Automat, Broadband Network & Digital Media Lab, Beijing 100084, Peoples R China.	ytrock@buaa.edu.cn; zhaojianhui@buaa.edu.cn; zzr18@mails.tsinghua.edu.cn; guokaiwen_neu@126.com; qionghaidai@tsinghua.edu.cn; hao@hao-li.com; gpons@mpi-inf.mpg.de; liuyebin@tsinghua.edu.cn	Dai, Qionghai/ABD-5298-2021	Dai, Qionghai/0000-0001-7043-3061; Li, Hao/0000-0002-4019-3420; Zhao, Jianhui/0000-0002-5275-4846; Zheng, Zerong/0000-0003-1339-2480	National Natural Science Foundation of China [61827805, 61861166002, 61531014, 51574012]; Changjiang Scholars and Innovative Research Team in University of China [IRT_16R02]; Shenzhen Peacock Plan [KQTD20140630115140843]; Google Faculty Research Award; Okawa Foundation Research Grant; U.S. Army Research Laboratory [W911NF14-D-0005]; Deutsche Forschungsgemeinschaft(DFG. German Research Foundation) [409792180]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Changjiang Scholars and Innovative Research Team in University of China(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT)); Shenzhen Peacock Plan; Google Faculty Research Award(Google Incorporated); Okawa Foundation Research Grant; U.S. Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); Deutsche Forschungsgemeinschaft(DFG. German Research Foundation)(German Research Foundation (DFG))	This work is supported by the National Natural Science Foundation of China NO.61827805, NO.61861166002, NO.61531014 and NO.51574012; Changjiang Scholars and Innovative Research Team in University of China, NO.IRT_16R02; Shenzhen Peacock Plan KQTD20140630115140843; Google Faculty Research Award; The Okawa Foundation Research Grant; The U.S. Army Research Laboratory under contract W911NF14-D-0005. Gerard Pons-Moll is funded by the Deutsche Forschungsgemeinschaft(DFG. German Research Foundation) 409792180.	Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Bogo F, 2015, IEEE I CONF COMP VIS, P2300, DOI 10.1109/ICCV.2015.265; Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698; Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32; Chang W, 2009, COMPUT GRAPH FORUM, V28, P447, DOI 10.1111/j.1467-8659.2009.01384.x; Chang W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966405; Chen Y, 2016, IEEE T VIS COMPUT GR, V22, P2000, DOI 10.1109/TVCG.2015.2478779; Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125; Dibra E, 2017, PROC CVPR IEEE, P5504, DOI 10.1109/CVPR.2017.584; Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801; Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969; Dou MS, 2013, INT SYM MIX AUGMENT, P99, DOI 10.1109/ISMAR.2013.6671769; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Guo KW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083722; Guo KW, 2015, IEEE I CONF COMP VIS, P3083, DOI 10.1109/ICCV.2015.353; Innmann M, 2016, LECT NOTES COMPUT SC, V9912, P362, DOI 10.1007/978-3-319-46484-8_22; Lahner Z, 2018, LECT NOTES COMPUT SC, V11208, P698, DOI 10.1007/978-3-030-01225-0_41; Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500; Leroy V, 2017, IEEE I CONF COMP VIS, P3113, DOI 10.1109/ICCV.2017.336; Li C, 2018, LECT NOTES COMPUT SC, V11212, P324, DOI 10.1007/978-3-030-01237-3_20; Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x; Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407; Li H, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1618521, 10.1145/1618452.1618503]; Liao M, 2009, IEEE I CONF COMP VIS, P167, DOI 10.1109/ICCV.2009.5459161; Liu YB, 2013, IEEE T PATTERN ANAL, V35, P2720, DOI 10.1109/TPAMI.2013.47; Liu YB, 2011, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2011.5995424; Liu YB, 2010, IEEE T VIS COMPUT GR, V16, P407, DOI 10.1109/TVCG.2009.88; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422; Mitra N. J., 2007, SGP, P173; Mustafa A, 2015, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2015.109; Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Nguyen CV, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P524, DOI 10.1109/3DIMPVT.2012.84; Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062; Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055; Pekelny Y, 2008, COMPUT GRAPH FORUM, V27, P399, DOI 10.1111/j.1467-8659.2008.01137.x; Pons-Moll G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073711; Pons-Moll G, 2015, INT J COMPUT VISION, V113, P163, DOI 10.1007/s11263-015-0818-9; Sharf A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409063; Slavcheva M, 2018, PROC CVPR IEEE, P2646, DOI 10.1109/CVPR.2018.00280; Slavcheva M, 2017, PROC CVPR IEEE, P5474, DOI 10.1109/CVPR.2017.581; Sussmuth J, 2008, COMPUT GRAPH FORUM, V27, P1469, DOI 10.1111/j.1467-8659.2008.01287.x; Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531; Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664; Tevs A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159517; Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2; Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696; Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526; Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59; Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301; Yu T., 2019, P IEEE INT C COMP VI; Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761; Yu T, 2017, IEEE I CONF COMP VIS, P910, DOI 10.1109/ICCV.2017.104; Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582; Zheng ZR, 2018, LECT NOTES COMPUT SC, V11213, P389, DOI 10.1007/978-3-030-01240-3_24; Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783; Zollhofer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165	62	11	13	3	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2523	2539		10.1109/TPAMI.2019.2928296	http://dx.doi.org/10.1109/TPAMI.2019.2928296			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31329106	Green Submitted			2022-12-18	WOS:000567471300015
J	Yu, X; Shiri, F; Ghanem, B; Porikli, F				Yu, Xin; Shiri, Fatemeh; Ghanem, Bernard; Porikli, Fatih			Can We See More? Joint Frontalization and Hallucination of Unaligned Tiny Faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Spatial resolution; Neural networks; Training; Solid modeling; Feature extraction; Face; super-resolution; hallucination; face frontalization	SUPERRESOLUTION; MODEL	In popular TV programs (such as CSI), a very low-resolution face image of a person, who is not even looking at the camera in many cases, is digitally super-resolved to a degree that suddenly the person's identity is made visible and recognizable. Of course, we suspect that this is merely a cinematographic special effect and such a magical transformation of a single image is not technically possible. Or, is it? In this paper, we push the boundaries of super-resolving (hallucinating to be more accurate) a tiny, non-frontal face image to understand how much of this is possible by leveraging the availability of large datasets and deep networks. To this end, we introduce a novel Transformative Adversarial Neural Network (TANN) to jointly frontalize very-low resolution (i.e., 16 x 16 pixels) out-of-plane rotated face images (including profile views) and aggressively super-resolve them (8x), regardless of their original poses and without using any 3D information. TANN is composed of two components: a transformative upsampling network which embodies encoding, spatial transformation and deconvolutional layers, and a discriminative network that enforces the generated high-resolution frontal faces to lie on the same manifold as real frontal face images. We evaluate our method on a large set of synthesized non-frontal face images to assess its reconstruction performance. Extensive experiments demonstrate that TANN generates both qualitatively and quantitatively superior results achieving over 4 dB improvement over the state-of-the-art.	[Yu, Xin; Shiri, Fatemeh; Porikli, Fatih] Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia; [Ghanem, Bernard] King Abdullah Univ Sci & Technol, Dept Elect Engn, Thuwal 23955, Saudi Arabia	Australian National University; King Abdullah University of Science & Technology	Yu, X (corresponding author), Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia.	xin.yu@anu.edu.au; fatemeh.shiri@anu.edu.au; bernard.ghanem@kaust.edu.sa; fatih.porikli@anu.edu.au	; Ghanem, Bernard/J-7605-2017	Yu, Xin/0000-0002-0269-5649; Ghanem, Bernard/0000-0002-5534-587X	Australian Research Council [DP150104645]; Australian Research Council Centre of Excellence for Robotic Vision [CE140100016]; King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research	Australian Research Council(Australian Research Council); Australian Research Council Centre of Excellence for Robotic Vision(Australian Research Council); King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research(King Abdullah University of Science & Technology)	This work was supported by the Australian Research Council`s Discovery Projects funding scheme (project DP150104645), Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016) and King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2012, LECT NOTES COMPUT SC; [Anonymous], 2001, PROC CVPR IEEE; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.581; [Anonymous], 2016, ECCV, DOI DOI 10.1007/978-3-319-46454-1_20; [Anonymous], 2007, 2007 7 IEEE C NAN; Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336; Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019; Chang FJ, 2017, IEEE INT CONF COMP V, P1599, DOI 10.1109/ICCVW.2017.188; Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264; Cole F., 2017, P IEEE C COMP VIS PA, P3703; Dovgard R, 2004, LECT NOTES COMPUT SC, V3022, P99; Goncalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hassner T, 2015, PROC CVPR IEEE, P4295, DOI 10.1109/CVPR.2015.7299058; Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448; Hennings-Yeomans P. H., 2008, P IEEE COMP SOC C CO, P1; Hinton G., NEURAL NETWORKS MACH; Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187; Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jaderberg M, 2015, ADV NEUR IN, V28; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121; Ledig C., 2016, PHOTO REALISTIC SING; Li YC, 2014, PATTERN RECOGN, V47, P1261, DOI 10.1016/j.patcog.2013.09.012; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Radford A., 2015, ARXIV151106434; Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Tran L., 2017, P IEEE C COMP VIS PA; van den Oord A, 2016, PR MACH LEARN RES, V48; Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9; Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171; Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36; Yang CY, 2018, INT J COMPUT VISION, V126, P597, DOI 10.1007/s11263-017-1044-4; Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146; Yang F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964955; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667; Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430; Yu X, 2017, AAAI CONF ARTIF INTE, P4327; Yu X, 2018, IEEE T IMAGE PROCESS, V27, P2747, DOI 10.1109/TIP.2018.2808840; Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570; Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871; Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679; Zhu ZY, 2014, COMPUTER VISION PATT, V1404, P3543	63	11	11	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2148	2164		10.1109/TPAMI.2019.2914039	http://dx.doi.org/10.1109/TPAMI.2019.2914039			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MW9MI	31056489	Green Published			2022-12-18	WOS:000557354900006
J	Hua, Y; Nakamura, S; Asif, MS; Sankaranarayanan, AC				Hua, Yi; Nakamura, Shigeki; Asif, M. Salman; Sankaranarayanan, Aswin C.			SweepCam - Depth-Aware Lensless Imaging Using Programmable Masks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Cameras; Image resolution; Semiconductor device measurement; Inverse problems; Convolution; Lensless imaging; computational photography		Lensless cameras, while extremely useful for imaging in constrained scenarios, struggle with resolving scenes with large depth variations. To resolve this, we propose imaging with a set of mask patterns displayed on a programmable mask, and introduce a computational focusing operator that helps to resolve the depth of scene points. As a result, the proposed imager can resolve dense scenes with large depth variations, allowing for more practical applications of lensless cameras. We also present a fast reconstruction algorithm for scene at multiple depths that reduces reconstruction time by two orders of magnitude. Finally, we build a prototype to show the proposed method improves both image quality and depth resolution of lensless cameras.	[Hua, Yi; Sankaranarayanan, Aswin C.] Carnegie Mellon Univ, ECE Dept, Pittsburgh, PA 15213 USA; [Nakamura, Shigeki] Sony Semicond Solut Corp, Atsugi, Kanagawa 2430014, Japan; [Asif, M. Salman] Univ Calif Riverside, ECE Dept, Riverside, CA 92521 USA	Carnegie Mellon University; University of California System; University of California Riverside	Hua, Y (corresponding author), Carnegie Mellon Univ, ECE Dept, Pittsburgh, PA 15213 USA.	yhua1@andrew.cmu.edu; Shigeki.A.Nakamura@sony.com; sasif@ece.ucr.edu; saswin@andrew.cmu.edu	Hua, Yi/AAP-9889-2021	Sankaranarayanan, Aswin/0000-0003-0906-4046; Asif, Salman/0000-0001-5993-3903	US National Science Foundation [1730147, IIS-1618823]; Sony research contract	US National Science Foundation(National Science Foundation (NSF)); Sony research contract	The authors would like to thank Jen-Hao Rick Chang for helpful discussions, and Ashok Veeraraghavan for generously donating the transmissive SLM used in the prototype. This work was supported by a Sony research contract, the US National Science Foundation Award IIS-1618823, and the US National Science Foundation ExpeditionsAward 1730147.	Adams JK, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1701548; Antipa N, 2018, OPTICA, V5, P1, DOI 10.1364/OPTICA.5.000001; Asif MS, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6498; Asif MS, 2017, IEEE T COMPUT IMAG, V3, P384, DOI 10.1109/TCI.2016.2593662; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boominathan V, 2016, IEEE SIGNAL PROC MAG, V33, P23, DOI 10.1109/MSP.2016.2581921; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Dutre P., 2006, ADV GLOBAL ILLUMINAT; FENIMORE EE, 1978, APPL OPTICS, V17, P337, DOI 10.1364/AO.17.000337; Gill P. R., 2013, IMAGING APPL OPTICS; GOLOMB SW, 1967, SHIFT REGISTER SEQUE; GOTTESMAN SR, 1989, APPL OPTICS, V28, P4344, DOI 10.1364/AO.28.004344; HECHT EUGENE, 2017, OPTICS; Kajiya J.T., 1986, SIGGRAPH, P143, DOI [DOI 10.1145/15922.15902, 10.1145/15886.15902, DOI 10.1145/15886.15902]; Khan Salman Siddique, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P7859, DOI 10.1109/ICCV.2019.00795; Kittle D, 2010, APPL OPTICS, V49, P6824, DOI 10.1364/AO.49.006824; Llull P, 2013, OPT EXPRESS, V21, P10526, DOI 10.1364/OE.21.010526; Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Tan J, 2019, IEEE T COMPUT IMAG, V5, P180, DOI 10.1109/TCI.2018.2889933; Tanida J, 2001, APPL OPTICS, V40, P1806, DOI 10.1364/AO.40.001806; Canh TN, 2019, IEEE INT CONF COMP V, P3978, DOI 10.1109/ICCVW.2019.00492; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Zheng YC, 2019, 2019 IEEE 8TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP 2019), P91, DOI 10.1109/CAMSAP45676.2019.9022507; Zomet A., 2006, COMP VIS PATT REC 20, V1, P339	26	11	11	4	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1606	1617		10.1109/TPAMI.2020.2986784	http://dx.doi.org/10.1109/TPAMI.2020.2986784			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32305898	Green Submitted, hybrid			2022-12-18	WOS:000542967200007
J	Luo, GB; Zhu, YS; Weng, ZY; Li, ZT				Luo, Guibo; Zhu, Yuesheng; Weng, Zhenyu; Li, Zhaotian			A Disocclusion Inpainting Framework for Depth-Based View Synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Correlation; Reconstruction algorithms; Cameras; Three-dimensional displays; Motion compensation; Two dimensional displays; Depth image based rendering; disocclusion inpainting; foreground extraction; improved background reconstruction	IMAGE COMPLETION; RANDOM-WALKS; VIDEO	This paper proposes a disocclusion inpainting framework for depth-based view synthesis. It consists of four modules: foreground extraction, motion compensation, improved background reconstruction, and inpainting. The foreground extraction module detects the foreground objects and removes them from both depth map and rendered video; the motion compensation module guarantees the background reconstruction model to suit for moving camera scenarios; the improved background reconstruction module constructs a stable background video by exploiting the temporal correlation information in both 2D video and its corresponding depth map; and the constructed background video and inpainting module are used to eliminate the holes in the synthesized view. The analysis and experiment indicate that the proposed framework has good generality, scalability and effectiveness, which means most of the existing background reconstruction methods and image inpainting methods can be employed or extended as the modules in our framework. Our comparison results have demonstrated that the proposed framework achieves better synthesized quality, temporal consistency, and has lower running time compared to the other methods.	[Luo, Guibo; Zhu, Yuesheng; Weng, Zhenyu; Li, Zhaotian] Peking Univ, Commun & Informat Secur Lab, Shenzhen Grad Sch, Shenzhen 100871, Peoples R China	Peking University; University Town of Shenzhen	Zhu, YS (corresponding author), Peking Univ, Commun & Informat Secur Lab, Shenzhen Grad Sch, Shenzhen 100871, Peoples R China.	luoguibo@sz.pku.edu.cn; zhuys@pku.edu.cn; wzytumbler@pku.edu.cn; lizhaotian@pku.edu.cn		weng, zhenyu/0000-0001-7857-8687	Shenzhen Municipal Development and Reform Commission (Disciplinary Development Program for Data Science and Intelligent Computing); Shenzhen International cooperative research projects [GJHZ20170313150021171]; NSFC-Shenzhen Robot Jointed Founding [U1613215]	Shenzhen Municipal Development and Reform Commission (Disciplinary Development Program for Data Science and Intelligent Computing); Shenzhen International cooperative research projects; NSFC-Shenzhen Robot Jointed Founding	This work was supported in part by the Shenzhen Municipal Development and Reform Commission (Disciplinary Development Program for Data Science and Intelligent Computing), in part by Shenzhen International cooperative research projects GJHZ20170313150021171, and in part by NSFC-Shenzhen Robot Jointed Founding (U1613215). The authors express their gratitude to Dennis Zhu and Bairong Li for helpful suggestions on the writing.	Afifi M, 2014, I S INTELL SIG PROC, P200, DOI 10.1109/ISPACS.2014.7024452; Ahn I, 2013, IEEE T BROADCAST, V59, P614, DOI 10.1109/TBC.2013.2281658; Angot LJ, 2010, PROC SPIE, V7526, DOI 10.1117/12.838571; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Buyssens P, 2017, IEEE T IMAGE PROCESS, V26, P525, DOI 10.1109/TIP.2016.2619263; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Ceulemans B., 2016, P IEEE INT C MULTIME, P1; Chen WY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1315; Choi S, 2013, IEEE T IMAGE PROCESS, V22, P2429, DOI 10.1109/TIP.2013.2251646; Ciotta M, 2016, INT CONF ACOUST SPEE, P1199, DOI 10.1109/ICASSP.2016.7471866; Criminisi A, 2007, INT J COMPUT VISION, V71, P89, DOI 10.1007/s11263-006-8525-1; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578; Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110; Domanski M, 2013, IEEE T IMAGE PROCESS, V22, P3517, DOI 10.1109/TIP.2013.2266580; Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gao Y, 2016, IEEE T IMAGE PROCESS, V25, P134, DOI 10.1109/TIP.2015.2498400; Gautier J, 2011, 3DTV CONF; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Habigt J, 2013, IEEE IMAGE PROC, P2131, DOI 10.1109/ICIP.2013.6738439; Haque M, 2008, INT C PATT RECOG, P1001; He L, 2011, EVID-BASED COMPL ALT, V2011, P1, DOI 10.1093/ecam/nep095; Horng YR, 2010, IEEE INT SYMP CIRC S, P2650, DOI 10.1109/ISCAS.2010.5537052; Howard J, 2014, IEEE WINT CONF APPL, P9, DOI 10.1109/WACV.2014.6836124; Hsu HA, 2014, IEEE T CIRC SYST VID, V24, P74, DOI 10.1109/TCSVT.2013.2276699; Huang JB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982398; Huang JB, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2601097.2601205, 10.1145/2602141]; Huang YZ, 2008, PROC CVPR IEEE, P2000; KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135; Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013; Kim HG, 2015, IEEE IMAGE PROC, P3136, DOI 10.1109/ICIP.2015.7351381; Koppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102; Lee PJ, 2011, IEEE T MULTIMEDIA, V13, P246, DOI 10.1109/TMM.2010.2100372; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Lo BPL, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P158, DOI 10.1109/ISIMP.2001.925356; Luo GB, 2016, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2016.197; Morse B, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P555, DOI 10.1109/3DIMPVT.2012.59; Muller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148; Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862; Newson A, 2014, SIAM J IMAGING SCI, V7, P1993, DOI 10.1137/140954933; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Ruzic T., 2014, P 8 INT C SIGN PROC, P1; Solh M, 2012, IEEE J-STSP, V6, P495, DOI 10.1109/JSTSP.2012.2204723; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274; Sun WX, 2012, IEEE IMAGE PROC, P2721, DOI 10.1109/ICIP.2012.6467461; Tam WJ, 2004, PROC SPIE, V5599, P162, DOI 10.1117/12.583105; Ting H., 2007, P 15 INT C MULT, P517; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Wang L., 2008, 2008 IEEE C COMPUTER, P1; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60; Xu X., 2008, IEEE C COMP VIS PATT, P1; Yao C, 2014, IEEE T BROADCAST, V60, P394, DOI 10.1109/TBC.2014.2321671; Zhu C, 2016, IEEE T BROADCAST, V62, P82, DOI 10.1109/TBC.2015.2475697; Zinger S, 2010, J VIS COMMUN IMAGE R, V21, P533, DOI 10.1016/j.jvcir.2010.01.004; Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766; Zou F, 2014, IEEE T CIRC SYST VID, V24, P1696, DOI 10.1109/TCSVT.2014.2313891	71	11	12	5	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1289	1302		10.1109/TPAMI.2019.2899837	http://dx.doi.org/10.1109/TPAMI.2019.2899837			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30794166				2022-12-18	WOS:000535615700001
J	Simon, M; Rodner, E; Darrell, T; Denzler, J				Simon, Marcel; Rodner, Erik; Darrell, Trevor; Denzler, Joachim			The Whole Is More Than Its Parts? From Explicit to Implicit Pose Normalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fine-grained classification; object recognition; convolutional neural networks	IMAGE; KERNELS	Fine-grained classification describes the automated recognition of visually similar object categories like birds species. Previous works were usually based on explicit pose normalization, i.e., the detection and description of object parts. However, recent models based on a final global average or bilinear pooling have achieved a comparable accuracy without this concept. In this paper, we analyze the advantages of these approaches over generic CNNs and explicit pose normalization approaches. We also show how they can achieve an implicit normalization of the object pose. A novel visualization technique called activation flow is introduced to investigate limitations in pose handling in traditional CNNs like AlexNet and VGG. Afterward, we present and compare the explicit pose normalization approach neural activation constellations and a generalized framework for the final global average and bilinear pooling called alpha-pooling. We observe that the latter often achieves a higher accuracy improving common CNN models by up to 22.9 percent, but lacks the interpretability of the explicit approaches. We present a visualization approach for understanding and analyzing predictions of the model to address this issue. Furthermore, we show that our approaches for fine-grained recognition are beneficial for other fields like action recognition.	[Simon, Marcel; Denzler, Joachim] Friedrich Schiller Univ Jena, Comp Vis Grp, D-07743 Jena, Germany; [Rodner, Erik] Carl Zeiss Corp Res, D-07745 Jena, Germany; [Darrell, Trevor] Univ Calif Berkeley, CS Div, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Friedrich Schiller University of Jena; University of California System; University of California Berkeley	Simon, M (corresponding author), Friedrich Schiller Univ Jena, Comp Vis Grp, D-07743 Jena, Germany.	marcel.simon@uni-jena.de; Erik.Rodner@uni-jena.de; trevor@cs.berkeley.edu; joachim.denzler@uni-jena.de		Denzler, Joachim/0000-0002-3193-3300	German Research Foundation (DFG) [RO 5093/1-1]	German Research Foundation (DFG)(German Research Foundation (DFG))	Part of this research was supported by grant RO 5093/1-1 of the German Research Foundation (DFG). The authors thank Nvidia for GPU donations.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Argyriou A, 2009, J MACH LEARN RES, V10, P2507; Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Branson S, 2014, P BRIT MACH VIS C, DOI 10.5244/C.28.87; Branson S, 2010, LECT NOTES COMPUT SC, V6314, P438, DOI 10.1007/978-3-642-15561-1_32; Cai SJ, 2016, PROC CVPR IEEE, P2950, DOI 10.1109/CVPR.2016.322; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57; Crans D. C., 2007, P IEEE C COMP VIS PA, P1; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Denzler J., 2016, ARXIV161201452; Donahue J, 2014, PR MACH LEARN RES, V32; Erhan D., 2009, 1341 DIRO U MONTR; Fergus R, 2003, PROC CVPR IEEE, P264; Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215; Goring C, 2014, PROC CVPR IEEE, P2489, DOI 10.1109/CVPR.2014.319; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Huang C, 2017, IEEE T MULTIMEDIA, V19, P673, DOI 10.1109/TMM.2016.2631122; Jaderberg M, 2015, ADV NEUR IN, V28; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jost T, 2005, COMPUT VIS IMAGE UND, V100, P107, DOI 10.1016/j.cviu.2004.10.009; Khosla A., 2011, P CVPR WORKSH FIN GR; Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li ZC, 2017, IEEE INT CONF COMP V, P1199, DOI 10.1109/ICCVW.2017.145; Lin T.-Y., 2017, P BRIT MACH VIS C; Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400; Lin TY, 2016, PROC CVPR IEEE, P2791, DOI 10.1109/CVPR.2016.305; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13; Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2305, DOI 10.1109/TPAMI.2016.2637921; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mordvintsev A., 2015, INCEPTIONISM GOING D; Mordvintsev A., 2015, DEEPDREAM CODE EXAMP; Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Riabchenko E, 2014, INT C PATT RECOG, P2814, DOI 10.1109/ICPR.2014.485; Rosenfeld A., 2016, PROC ASIAN C COMP VI, P264; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Simon M, 2017, IEEE I CONF COMP VIS, P4970, DOI 10.1109/ICCV.2017.531; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Simon M, 2015, LECT NOTES COMPUT SC, V9004, P162, DOI 10.1007/978-3-319-16808-1_12; Simonyan K., 2014, WORKSH INT C LEARN R, P1; Sminchisescu C, 2009, NEURIPS, P135; Srivastava RK, 2015, ADV NEUR IN, V28; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276; Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xie GS, 2017, PATTERN RECOGN, V71, P118, DOI 10.1016/j.patcog.2017.06.002; Yang S., 2012, ADV NEURAL INFORM PR, P3122; Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Yosinski J., 2015, P INT C MACH LEARN D; Zagoruyko S, 2016, P BRIT MACH VIS C; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364; Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128; Zhang XP, 2016, IEEE T IMAGE PROCESS, V25, P878, DOI 10.1109/TIP.2015.2509425; Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zobel M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P2, DOI 10.1109/AFGR.2000.840604	83	11	11	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					749	763		10.1109/TPAMI.2018.2885764	http://dx.doi.org/10.1109/TPAMI.2018.2885764			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30575529	hybrid			2022-12-18	WOS:000525365300016
J	Bulat, A; Tzimiropoulos, G				Bulat, Adrian; Tzimiropoulos, Georgios			Hierarchical Binary CNNs for Landmark Localization with Limited Resources	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose estimation; Computer architecture; Face; Task analysis; Quantization (signal); Neural networks; Training; Binary convolutional neural networks; residual learning; landmark localization; human pose estimation; face alignment	POSE ESTIMATION; FACE ALIGNMENT	Our goal is to design architectures that retain the groundbreaking performance of Convolutional Neural Networks (CNNs) for landmark localization and at the same time are lightweight, compact and suitable for applications with limited computational resources. To this end, we make the following contributions: (a) we are the first to study the effect of neural network binarization on localization tasks, namely human pose estimation and face alignment. We exhaustively evaluate various design choices, identify performance bottlenecks, and more importantly propose multiple orthogonal ways to boost performance. (b) Based on our analysis, we propose a novel hierarchical, parallel and multi-scale residual architecture that yields large performance improvement over the standard bottleneck block while having the same number of parameters, thus bridging the gap between the original network and its binarized counterpart. (c) We perform a large number of ablation studies that shed light on the properties and the performance of the proposed block. (d) We present results for experiments on the most challenging datasets for human pose estimation and face alignment, reporting in many cases state-of-the-art performance. (e) We further provide additional results for the problem of facial part segmentation. Code can be downloaded from https://www.adrianbulat.com/binary-cnn-landmarks.	[Bulat, Adrian; Tzimiropoulos, Georgios] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England	University of Nottingham	Bulat, A (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.	adrian.bulat@nottingham.ac.uk; yorgos.tzimiropoulos@nottingham.ac.uk		Tzimiropoulos, Georgios/0000-0002-1803-5338	University of Nottingham; Engineering and Physical Sciences Research Council [EP/M02153X/1]; EPSRC [EP/M02153X/1] Funding Source: UKRI	University of Nottingham; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Adrian Bulat was funded by a PhD scholarship from the University of Nottingham. This work was supported by the Engineering and Physical Sciences Research Council [grant number EP/M02153X/1] Facial Deformable Models of Animals to Georgios Tzimiropoulos.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64; Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216; Buehler P, 2011, INT J COMPUT VISION, V95, P180, DOI 10.1007/s11263-011-0480-9; Bulat A., 2016, P BRIT MACH VIS C, P19; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400; Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Collobert R., 2011, P NIPS WORKSH; Courbariaux M., 2014, ARXIV PREPRINT ARXIV; Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.1109/TWC.2016.2633262; Courbariaux Matthieu, 2016, BINARIZED NEURAL NET; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Lin DD, 2016, PR MACH LEARN RES, V48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Merolla P., 2016, ARXIV160601981; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Soudry D., 2014, PROC 27 INT C NEURAL, P963, DOI DOI 10.5555/2968826.2968934; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wu Y., 2017, P IM VIS COMP, V73, P1; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang N, 2015, ARXIV151107063; Zhou S., 2016, ARXIV160606160; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23	51	11	12	3	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					343	356		10.1109/TPAMI.2018.2866051	http://dx.doi.org/10.1109/TPAMI.2018.2866051			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30136931	Green Submitted, hybrid			2022-12-18	WOS:000508386100008
J	Rhinehart, N; Kitani, KM				Rhinehart, Nicholas; Kitani, Kris M.			First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Forecasting; Task analysis; Predictive models; Trajectory; Cameras; Learning (artificial intelligence); Visualization; First-person vision; activity forecasting; inverse reinforcement learning; online learning	PREDICTION	We address the problem of incrementally modeling and forecasting long-term goals of a first-person camera wearer: what the user will do, where they will go, and what goal they seek. In contrast to prior work in trajectory forecasting, our algorithm, Darko, goes further to reason about semantic states (will I pick up an object?), and future goal states that are far in terms of both space and time. Darko learns and forecasts from first-person visual observations of the user's daily behaviors via an Online Inverse Reinforcement Learning (IRL) approach. Classical IRL discovers only the rewards in a batch setting, whereas Darko discovers the transitions, rewards, and goals of a user from streaming data. Among other results, we show Darko forecasts goals better than competing methods in both noisy and ideal settings, and our approach is theoretically and empirically no-regret.	[Rhinehart, Nicholas; Kitani, Kris M.] Carnegie Mellon Univ, Robot Inst, Sch Comp Sci, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Rhinehart, N (corresponding author), Carnegie Mellon Univ, Robot Inst, Sch Comp Sci, Pittsburgh, PA 15213 USA.	nrhineha@cs.cmu.edu; kkitani@cs.cmu.edu	Rhinehart, Nicholas/M-1311-2019	Rhinehart, Nicholas/0000-0003-4242-1236	NSF NRI [1227495]; JST CREST [JPMJCR14E1]	NSF NRI(National Science Foundation (NSF)); JST CREST(Japan Science & Technology Agency (JST)Core Research for Evolutional Science and Technology (CREST))	The authors acknowledge the support of NSF NRI Grant 1227495 and JST CREST Grant JPMJCR14E1. The authors thank J. Andrew Bagnell for technical discussion, and Katherine Lagree and Gunnar A. Sigurdsson for data collection assistance.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Abbeel P., 2004, P 21 INT C MACHINE L, P1; Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, P IEEE C COMP VIS PA; [Anonymous], 2015, CORR; [Anonymous], P 32 AAAI C ART INT; Cakir F, 2015, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2015.125; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; De Brabandere B, 2016, ADV NEUR IN, V29; Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269; Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802; Ji J, 2016, INT CONF ACOUST SPEE, P1971, DOI 10.1109/ICASSP.2016.7472021; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335; Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45; Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321; Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625; Luc P, 2017, IEEE I CONF COMP VIS, P648, DOI 10.1109/ICCV.2017.77; Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Park HS, 2016, PROC CVPR IEEE, P4697, DOI 10.1109/CVPR.2016.508; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010; Platt JC, 2000, ADV NEUR IN, P61; Ramachandran P, 2011, COMPUT SCI ENG, V13, P40, DOI 10.1109/MCSE.2011.35; Ratliff N. D., 2006, P 23 INT C MACH LEAR, P729, DOI DOI 10.1145/1143844.1143936; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Rhinehart N, 2017, IEEE I CONF COMP VIS, P3716, DOI 10.1109/ICCV.2017.399; Rhinehart N, 2016, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2016.69; Rhinehart N, 2015, IEEE INT CONF ROBOT, P5448; Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Shalev-Shwartz S, 2012, FOUND TRENDS MACH LE, V4, P107, DOI 10.1561/2200000018; Su S., 2016, CORR; Su YC, 2016, LECT NOTES COMPUT SC, V9909, P454, DOI 10.1007/978-3-319-46454-1_28; Venkatraman A, 2017, ADV NEUR IN, V30; Villegas R, 2017, PR MACH LEARN RES, V70; Vondrick C, 2017, PROC CVPR IEEE, P2992, DOI 10.1109/CVPR.2017.319; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361; Walker J, 2014, PROC CVPR IEEE, P3302, DOI 10.1109/CVPR.2014.416; Wei W. W.-S., 1994, TIME SERIES ANAL; Xie D, 2013, IEEE I CONF COMP VIS, P2224, DOI 10.1109/ICCV.2013.277; Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540; Zhou MM, 2014, INTERNATIONAL CONFERENCE ON EDUCATION AND SOCIAL SCIENCES (INTCESS14), VOLS I AND II, P487; Ziebart B. D., 2008, AAAI, V8, P1433; Ziebart B. D., 2010, THESIS; Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147	53	11	12	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					304	317		10.1109/TPAMI.2018.2873794	http://dx.doi.org/10.1109/TPAMI.2018.2873794			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30295615	hybrid			2022-12-18	WOS:000508386100005
J	Benitez-Quiroz, F; Srinivasan, R; Martinez, AM				Benitez-Quiroz, Fabian; Srinivasan, Ramprakash; Martinez, Aleix M.			Discriminant Functional Learning of Color Features for the Recognition of Facial Action Units and Their Intensities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image color analysis; Color; Gold; Video sequences; Videos; Transforms; Face recognition; Facial expressions of emotion; face recognition; face perception; facial color; compound emotions; Gabor transform; color vision; time invariant; recognition in video; recognition in still images	EXPRESSION RECOGNITION; FACE; 3D; EMOTION; MODEL	Color is a fundamental image feature of facial expressions. For example, when we furrow our eyebrows in anger, blood rushes in, turning some face areas red; or when one goes white in fear as a result of the drainage of blood from the face. Surprisingly, these image properties have not been exploited to recognize the facial action units (AUs) associated with these expressions. Herein, we present the first system to do recognition of AUs and their intensities using these functional color changes. These color features are shown to be robust to changes in identity, gender, race, ethnicity, and skin color. Specifically, we identify the chromaticity changes defining the transition of an AU from inactive to active and use an innovative Gabor transform-based algorithm to gain invariance to the timing of these changes. Because these image changes are given by functions rather than vectors, we use functional classifiers to identify the most discriminant color features of an AU and its intensities. We demonstrate that, using these discriminant color features, one can achieve results superior to those of the state-of-the-art. Finally, we define an algorithm that allows us to use the learned functional color representation in still images. This is done by learning the mapping between images and the identified functional color features in videos. Our algorithm works in realtime, i.e., $& x003E;$& x003E;30 frames/second/CPU thread.	[Benitez-Quiroz, Fabian; Srinivasan, Ramprakash; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43212 USA	University System of Ohio; Ohio State University	Martinez, AM (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43212 USA.	benitez-quiroz.1@osu.edu; srinivasan.134@buckeyemail.osu.edu; aleix@ece.osu.edu			National Institutes of Health [R01-DC-014498]; Human Frontier Science Program [RGP0036/2016]; OSU's Center for Cognitive and Brain Sciences summer fellowship; NATIONAL EYE INSTITUTE [R01EY020834] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC014498] Funding Source: NIH RePORTER	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Human Frontier Science Program(Human Frontier Science Program); OSU's Center for Cognitive and Brain Sciences summer fellowship; NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	This research was supported in part by the National Institutes of Health, grant R01-DC-014498, and the Human Frontier Science Program, grant RGP0036/2016. RS was partially supported by OSU's Center for Cognitive and Brain Sciences summer fellowship. The authors thank the reviewers for their constructive feedback.	Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606; Almaev T, 2015, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2015.430; Angelopoulou E, 2001, PROC CVPR IEEE, P635; [Anonymous], 2015, INT C AUTOMATIC FACE, DOI DOI 10.1109/FG.2015.7284871; Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597; BALTRUSAITIS T., 2015, 2015 11 IEEE INT C W, V06, P1, DOI [10.1109/FG.2015.7284869, DOI 10.1109/FG.2015.7284869]; Batista JC, 2017, IEEE INT CONF AUTOMA, P866, DOI 10.1109/FG.2017.111; Bellocchi A, 2015, EMOT REV, V7, P151, DOI 10.1177/1754073914554775; Benitez-Quiroz C. F., 2017, ARXIV170301210; Benitez-Quiroz CF, 2017, IEEE I CONF COMP VIS, P3990, DOI 10.1109/ICCV.2017.428; Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600; Benitez-Quiroz CF, 2016, COGNITION, V150, P77, DOI 10.1016/j.cognition.2016.02.004; Benitez-Quiroz CF, 2018, P NATL ACAD SCI USA, V115, P3581, DOI 10.1073/pnas.1716084115; Bingol D, 2014, IEEE IMAGE PROC, P1381, DOI 10.1109/ICIP.2014.7025276; Blanco S, 1996, PHYS REV E, V54, P6661, DOI 10.1103/PhysRevE.54.6661; Carmona R., 1998, PRACTICAL TIME FREQU, V9; Cassidy S, 2015, AUTISM RES, V8, P534, DOI 10.1002/aur.1468; Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293; Changizi MA, 2006, BIOL LETT-UK, V2, P217, DOI 10.1098/rsbl.2006.0440; Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014; Cohn J. F., 2014, OXFORD HDB AFFECTIVE, P131; Cohn J. F., 2009, AFF COMP INT INT WOR, P1, DOI DOI 10.1109/ACII.2009.5349358; Corneanu C. A., 2018, ARXIV180305873; Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111; Ekman P., 2015, WHAT FACE REVEALS BA; Ekman P., 1978, FACIAL ACTION CODING, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; Eleftheriadis S, 2015, IEEE I CONF COMP VIS, P3792, DOI 10.1109/ICCV.2015.432; Girard JM, 2015, BEHAV RES METHODS, V47, P1136, DOI 10.3758/s13428-014-0536-1; Huang Xiaohua, 2016, ARXIV161003640; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jaiswal Shashank, 2016, WACV; Lajevardi SM, 2012, IEEE T IMAGE PROCESS, V21, P3721, DOI 10.1109/TIP.2012.2197628; Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462; Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949; Martinez A, 2012, J MACH LEARN RES, V13, P1589; Martinez AM, 2017, CURR DIR PSYCHOL SCI, V26, P263, DOI 10.1177/0963721417698535; Martinez AM, 2003, VISION RES, V43, P1047, DOI 10.1016/S0042-6989(03)00079-8; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130; Nair V., 2010, ICML, P807; Nicolle J, 2015, 2015 11 IEEE INT C W, V6, P1, DOI DOI 10.1109/FG.2015.7284868; Niese R, 2012, IET COMPUT VIS, V6, P79, DOI 10.1049/iet-cvi.2011.0064; Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192; Skerry AE, 2015, CURR BIOL, V25, P1945, DOI 10.1016/j.cub.2015.06.009; Srinivasan R, 2016, J NEUROSCI, V36, P4434, DOI 10.1523/JNEUROSCI.1704-15.2016; Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159; Todorov A, 2015, ANNU REV PSYCHOL, V66, P519, DOI 10.1146/annurev-psych-113011-143831; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410; You D, 2014, IEEE T NEUR NET LEAR, V25, P1879, DOI 10.1109/TNNLS.2013.2297686; Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421; Zhang X, 2014, IEEE WINT CONF APPL, P1104, DOI 10.1109/WACV.2014.6835735; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002	54	11	11	6	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2835	2845		10.1109/TPAMI.2018.2868952	http://dx.doi.org/10.1109/TPAMI.2018.2868952			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JQ0XI	30188814	Green Accepted			2022-12-18	WOS:000498677600004
J	Xiong, B; Jain, SD; Grauman, K				Xiong, Bo; Jain, Suyog Dutt; Grauman, Kristen			Pixel Objectness: Learning to Segment Generic Objects Automatically in Images and Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; video segmentation; deep learning; foreground segmentation	SALIENCY DETECTION	We propose an end-to-end learning framework for segmenting generic objects in both images and videos. Given a novel image or video, our approach produces a pixel-level mask for all "object-like" regions-even for object categories never seen during training. We formulate the task as a structured prediction problem of assigning an object/background label to each pixel, implemented using a deep fully convolutional network. When applied to a video, our model further incorporates a motion stream, and the network learns to combine both appearance and motion and attempts to extract all prominent objects whether they are moving or not. Beyond the core model, a second contribution of our approach is how it leverages varying strengths of training annotations. Pixel-level annotations are quite difficult to obtain, yet crucial for training a deep network approach for segmentation. Thus we propose ways to exploit weakly labeled data for learning dense foreground segmentation. For images, we show the value in mixing object category examples with image-level labels together with relatively few images with boundary-level annotations. For video, we show how to bootstrap weakly annotated videos together with the network trained for image segmentation. Through experiments on multiple challenging image and video segmentation benchmarks, our method offers consistently strong results and improves the state-of-the-art for fully automatic segmentation of generic (unseen) objects. In addition, we demonstrate how our approach benefits image retrieval and image retargeting, both of which flourish when given our high-quality foreground maps. Code, models, and videos are at: http://vision.cs.utexas.edu/projects/pixelobjectness/	[Xiong, Bo; Jain, Suyog Dutt; Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Xiong, B (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	bxiong@cs.utexas.edu; suyog@cs.utexas.edu; grauman@cs.utexas.edu			ONR YIP [N00014-12-1-0754]; AWS Machine Learning Research Award; DARPA Lifelong Learning Machines	ONR YIP(Office of Naval Research); AWS Machine Learning Research Award; DARPA Lifelong Learning Machines	This research is supported in part by ONR YIP N00014-12-1-0754, an AWS Machine Learning Research Award, and DARPA Lifelong Learning Machines. The authors thank the reviewers for their valuable suggestions. Bo Xiong and Suyog Dutt Jain contributed equally to this work.	Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], P BRIT MACH VIS C; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Badrinarayanan V, 2010, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR.2010.5540054; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Bideau P, 2016, LECT NOTES COMPUT SC, V9912, P433, DOI 10.1007/978-3-319-46484-8_26; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Faktor A., 2014, P BMVC, V2, P8; Fathi A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.78; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Galasso F., 2013, P AS C COMP VIS ACCV, P760, DOI 10.1007/978-3-642-37331-2_57; Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Guillaumin M, 2014, INT J COMPUT VISION, V110, P328, DOI 10.1007/s11263-014-0713-9; Gurari D, 2018, INT J COMPUT VISION, V126, P714, DOI 10.1007/s11263-018-1065-7; Gurari D, 2016, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2016.48; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Jain S., 2017, ARXIV170105349; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jain SD, 2016, PROC CVPR IEEE, P2864, DOI 10.1109/CVPR.2016.313; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jain SD, 2013, IEEE I CONF COMP VIS, P1313, DOI 10.1109/ICCV.2013.166; Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209; JOULIN A, 2010, PROC CVPR IEEE, P1943, DOI DOI 10.1109/CVPR.2010.5539868; Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Kuettel D, 2012, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2012.6247721; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Ce, 2009, THESIS, P2; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Marki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87; Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847; Nagaraja NS, 2015, IEEE I CONF COMP VIS, P3235, DOI 10.1109/ICCV.2015.370; Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48; Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Pinheiro Pedro O., 2015, ADV NEURAL INFORM PR, V3, P5; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293; Ren X., 2007, P CVPR, P1, DOI DOI 10.1109/CVPR.2007.383177; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Stein A, 2007, IEEE I CONF COMP VIS, P110; Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364; Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Vijayanarasimhan S, 2012, LECT NOTES COMPUT SC, V7576, P496, DOI 10.1007/978-3-642-33715-4_36; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wu ZY, 2015, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2015.7299047; Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107; Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	94	11	12	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2677	2692		10.1109/TPAMI.2018.2865794	http://dx.doi.org/10.1109/TPAMI.2018.2865794			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30130176	Green Submitted			2022-12-18	WOS:000489838200009
J	Kim, S; Min, D; Ham, B; Lin, S; Sohn, K				Kim, Seungryong; Min, Dongbo; Ham, Bumsub; Lin, Stephen; Sohn, Kwanghoon			FCSS: Fully Convolutional Self-Similarity for Dense Semantic Correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dense semantic correspondence; convolutional neural networks; self-similarity; weakly-supervised learning	SCENES; FLOW	We present a descriptor, called fully convolutional self-similarity (FCSS), for dense semantic correspondence. Unlike traditional dense correspondence approaches for estimating depth or optical flow, semantic correspondence estimation poses additional challenges due to intra-class appearance and shape variations among different instances within the same object or scene category. To robustly match points across semantically similar images, we formulate FCSS using local self-similarity (LSS), which is inherently insensitive to intra-class appearance variations. LSS is incorporated through a proposed convolutional self-similarity (CSS) layer, where the sampling patterns and the self-similarity measure are jointly learned in an end-to-end and multi-scale manner. Furthermore, to address shape variations among different object instances, we propose a convolutional affine transformer (CAT) layer that estimates explicit affine transformation fields at each pixel to transform the sampling patterns and corresponding receptive fields. As training data for semantic correspondence is rather limited, we propose to leverage object candidate priors provided in most existing datasets and also correspondence consistency between object pairs to enable weakly-supervised learning. Experiments demonstrate that FCSS significantly outperforms conventional handcrafted descriptors and CNN-based descriptors on various benchmarks.	[Kim, Seungryong; Ham, Bumsub; Sohn, Kwanghoon] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Min, Dongbo] Ewha Womans Univ, Dept Comp Sci & Engn, Seoul 03760, South Korea; [Lin, Stephen] Microsoft Res, Beijing 100080, Peoples R China	Yonsei University; Ewha Womans University; Microsoft	Sohn, K (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.	srkim89@yonsei.ac.kr; dbmin99@gmail.com; mimo@yonsei.ac.kr; stevelin@microsoft.com; khsohn@yonsei.ac.kr		Min, Dongbo/0000-0003-4825-5240; HAM, BUMSUB/0000-0002-3443-8161	Next-Generation Information Computing Development Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT [NRF-2017M3C4A7069370]; National Research Foundation of Korea (NRF) - Korea government (MSIP) [2017R1C1B2005584]	Next-Generation Information Computing Development Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT; National Research Foundation of Korea (NRF) - Korea government (MSIP)	This research was supported by Next-Generation Information Computing Development Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT (NRF-2017M3C4A7069370). The work of B. Ham was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2017R1C1B2005584).	[Anonymous], 2011, TECH REP; [Anonymous], [No title captured]; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bristow Hilton, 2015, P IEEE INT C COMP VI; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222; Chatfield Ken, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P264, DOI 10.1109/ICCVW.2009.5457691; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Choy C. B., 2016, P INT C NEUR INF PRO; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Donahue J., 2014, P 31 INT C MACH LEAR; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fischer P, 2014, ARXIV14055769; Garcia V, 2010, IEEE IMAGE PROC, P3757, DOI 10.1109/ICIP.2010.5654017; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; Ham B., 2017, PATTERN ANAL MACH IN, DOI [10.1109/TPAMI.2724510, DOI 10.1109/TPAMI.2724510]; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hur J, 2015, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2015.7298745; Jaderberg M, 2015, ADV NEUR IN, V28; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kim S, 2017, IEEE I CONF COMP VIS, P4539, DOI 10.1109/ICCV.2017.485; Kim S, 2017, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2017.73; Kim S, 2016, LECT NOTES COMPUT SC, V9912, P679, DOI 10.1007/978-3-319-46484-8_41; Kim S, 2015, PROC CVPR IEEE, P2103, DOI 10.1109/CVPR.2015.7298822; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laptev D, 2016, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.2016.38; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin CH, 2017, PROC CVPR IEEE, P2252, DOI 10.1109/CVPR.2017.242; Lin WY, 2012, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2012.6247651; Lin YL, 2014, LECT NOTES COMPUT SC, V8692, P466, DOI 10.1007/978-3-319-10593-2_31; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Long J.L., 2014, P C NEUR INF PROC SY, V27, P1601; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Nair V., 2010, ICML, P807; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Qiu WC, 2014, IEEE WINT CONF APPL, P1112, DOI 10.1109/WACV.2014.6835734; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Saleem S, 2014, IEEE SIGNAL PROC LET, V21, P400, DOI 10.1109/LSP.2014.2304073; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Simonyan K, 2015, 3 INT C LEARN REPR I; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460; Tau M, 2016, IEEE T PATTERN ANAL, V38, P875, DOI 10.1109/TPAMI.2015.2474356; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Trulls E, 2013, PROC CVPR IEEE, P2890, DOI 10.1109/CVPR.2013.372; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2016, J MACH LEARN RES, V17; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20; Zhou TH, 2015, PROC CVPR IEEE, P1191, DOI 10.1109/CVPR.2015.7298723	74	11	11	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					581	595		10.1109/TPAMI.2018.2803169	http://dx.doi.org/10.1109/TPAMI.2018.2803169			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993476	Green Submitted			2022-12-18	WOS:000458168800005
J	Li, Y; Zhang, JE; Huang, KQ; Zhang, JG				Li, Yan; Zhang, Junge; Huang, Kaiqi; Zhang, Jianguo			Mixed Supervised Object Detection with Robust Objectness Transfer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised detection; mixed supervised detection; robust objectness transfer	LOCALIZATION	In this paper, we consider the problem of leveraging existing fully labeled categories to improve the weakly supervised detection (WSD) of new object categories, which we refer to as mixed supervised detection (MSD). Different from previous MSD methods that directly transfer the pre-trained object detectors from existing categories to new categories, we propose a more reasonable and robust objectness transfer approach for MSD. In our framework, we first learn domain-invariant objectness knowledge from the existing fully labeled categories. The knowledge is modeled based on invariant features that are robust to the distribution discrepancy between the existing categories and new categories; therefore the resulting knowledge would generalize well to new categories and could assist detection models to reject distractors (e.g., object parts) in weakly labeled images of new categories. Under the guidance of learned objectness knowledge, we utilize multiple instance learning (MIL) to model the concepts of both objects and distractors and to further improve the ability of rejecting distractors in weakly labeled images. Our robust objectness transfer approach outperforms the existing MSD methods, and achieves state-of-the-art results on the challenging ILSVRC2013 detection dataset and the PASCAL VOC datasets.	[Li, Yan; Zhang, Junge; Huang, Kaiqi] Chinese Acad Sci CASIA, Inst Automat, NLPR, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China; [Li, Yan; Zhang, Junge; Huang, Kaiqi] UCAS, Beijing 100049, Peoples R China; [Huang, Kaiqi] CAS Ctr Excellence Brain Sci & Intelligence Techn, Shanghai 200031, Peoples R China; [Zhang, Jianguo] Univ Dundee, Sch Sci & Engn, Comp, Dundee DD1 4HN, Scotland	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of Dundee	Huang, KQ (corresponding author), Chinese Acad Sci CASIA, Inst Automat, NLPR, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China.; Huang, KQ (corresponding author), UCAS, Beijing 100049, Peoples R China.	yan.li@cripac.ia.ac.cn; jgzhang@nlpr.ia.ac.cn; kqhuang@nlpr.ia.ac.cn; j.n.zhang@dundee.ac.uk		zhang, jianguo/0000-0001-9317-0268	National Key Research and Development Program of China [2016YFB1001004, 2016YFB1001005]; National Natural Science Foundation of China [61673375, 61721004, 61403383]; Projects of Chinese Academy of Sciences [QYZDB-SSW-JSC006, 173211KYSB20160008]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Projects of Chinese Academy of Sciences(Chinese Academy of Sciences)	This work is funded by the National Key Research and Development Program of China (Grant 2016YFB1001004 and Grant 2016YFB1001005), the National Natural Science Foundation of China (Grant 61673375, Grant 61721004 and Grant 61403383) and the Projects of Chinese Academy of Sciences (Grant QYZDB-SSW-JSC006 and Grant 173211KYSB20160008).	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bilen H, 2014, P BMVC 2014, P1997; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Chavali N, 2016, PROC CVPR IEEE, P835, DOI 10.1109/CVPR.2016.97; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Everingham M., 2005, PASCAL VISUAL OBJECT; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Yaroslav, 2015, ICML; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guillaumin M, 2012, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2012.6248055; Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906; Hoffman Judy, 2014, NIPS; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Kolesnikov Alexander, 2016, P BRIT MACH VIS C; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Misra I, 2015, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2015.7298982; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rochan M, 2015, PROC CVPR IEEE, P4315, DOI 10.1109/CVPR.2015.7299060; Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shi MJ, 2017, IEEE I CONF COMP VIS, P3401, DOI 10.1109/ICCV.2017.366; Shi ZY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.78; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Tang YX, 2016, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2016.233; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; Yang Y, 2013, PROC CVPR IEEE, P1650, DOI 10.1109/CVPR.2013.216; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	41	11	12	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					639	653		10.1109/TPAMI.2018.2810288	http://dx.doi.org/10.1109/TPAMI.2018.2810288			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994285	Green Submitted			2022-12-18	WOS:000458168800009
J	Wang, W; Yan, Y; Cui, Z; Feng, JS; Yan, SC; Sebe, N				Wang, Wei; Yan, Yan; Cui, Zhen; Feng, Jiashi; Yan, Shuicheng; Sebe, Nicu			Recurrent Face Aging with Hierarchical AutoRegressive Memory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face aging; face normalization; recurrent neural network; gated recurrent unit; autoencoder	NEURAL-NETWORK	Modeling the aging process of human faces is important for cross-age face verification and recognition. In this paper, we propose a Recurrent Face Aging (RFA) framework which takes as input a single image and automatically outputs a series of aged faces. The hidden units in the RFA are connected autoregressively allowing the framework to age the person by referring to the previous aged faces. Due to the lack of labeled face data of the same person captured in a long range of ages, traditional face aging models split the ages into discrete groups and learn a one-step face transformation for each pair of adjacent age groups. Since human face aging is a smooth progression, it is more appropriate to age the face by going through smooth transitional states. In this way, the intermediate aged faces between the age groups can be generated. Towards this target, we employ a recurrent neural network whose recurrent module is a hierarchical triple-layer gated recurrent unit which functions as an autoencoder. The bottom layer of the module encodes the input to a latent representation, and the top layer decodes the representation to a corresponding aged face. The experimental results demonstrate the effectiveness of our framework.	[Wang, Wei; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38123 Trento, Italy; [Yan, Yan] Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA; [Cui, Zhen] Nanjing Univ Sci & Technol, Dept Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Yan, Shuicheng] Qihoo 360 Co, Beijing 100015, Peoples R China	University of Trento; Texas State University System; Texas State University San Marcos; Nanjing University of Science & Technology; National University of Singapore	Wang, W (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38123 Trento, Italy.	wei.wang@unitn.it; tom_yan@txstate.edu; zhen.cui@njust.edu.cn; elefjia@nus.edu.sg; eleyans@nus.edu.sg; sebe@disi.unitn.it	Yan, Shuicheng/HCI-1431-2022; Wang, Wei/AAK-5521-2021; Feng, Jiashi/AGX-6209-2022	Wang, Wei/0000-0002-5477-1017; Sebe, Niculae/0000-0002-6597-7248				Bengio Y., 2014, ARXIV14061078; Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302; Golovinskiy A, 2006, ACM T GRAPHIC, V25, P1025, DOI 10.1145/1141911.1141988; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hou XX, 2017, IEEE WINT CONF APPL, P1133, DOI 10.1109/WACV.2017.131; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Huang Gary B., 2007, 0749 U MASS, P7; Im D., 2016, GENERATING IMAGES RE; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; Kawulok M., 2016, ADV FACE DETECTION F, P189, DOI DOI 10.1007/978-3-319-25958-1_8; Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439; KEMELMACHERSHLIZER, 2014, PROC CVPR IEEE, P3334, DOI DOI 10.1109/CVPR.2014.426; KEMELMACHERSHLIZER, 2012, PROC CVPR IEEE, P1792; Kingma D.P, P 3 INT C LEARNING R; Koutnik J., 2014, P 31 INT C MACH LEAR; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975; Liu Ce, 2009, THESIS, P3; Park U., 2008, 2008 8 IEEE INT C AU, P1, DOI 10.1109/AFGR.2008.4813408; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Ramanathan N., 2009, J VISUAL LANG COMPUT, V15, P3349; Ramanathan N, 2008, IEEE INT CONF AUTOMA, P1006; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26; Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x; Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22; Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tazoe Y., 2012, ACM SIGGRAPH 2012 PO, P1; Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630; TULYAKOV S, 2016, PROC CVPR IEEE, P2396, DOI DOI 10.1109/CVPR.2016.263; TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586; Wang W., 2016, P ACCV, P104; Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261; Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340; Xiao H., 2018, P AAAI C ART INT; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yao K., 2015, ARXIV150803790; Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153; Zhu LC, 2017, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2017.147; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	50	11	11	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					654	668		10.1109/TPAMI.2018.2803166	http://dx.doi.org/10.1109/TPAMI.2018.2803166			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994505				2022-12-18	WOS:000458168800010
J	Zhang, RM; Lin, L; Wang, GR; Wang, M; Zuo, WM				Zhang, Ruimao; Lin, Liang; Wang, Guangrun; Wang, Meng; Zuo, Wangmeng			Hierarchical Scene Parsing by Weakly Supervised Learning with Image Descriptions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene parsing; deep learning; cross-modal learning; high-level understanding; recursive structured prediction	SEGMENTATION; RECOGNITION; TEMPLATES	This paper investigates a fundamental problem of scene understanding: how to parse a scene image into a structured configuration (i.e., a semantic object hierarchy with object interaction relations). We propose a deep architecture consisting of two networks: i) a convolutional neural network (CNN) extracting the image representation for pixel-wise object labeling and ii) a recursive neural network (RsNN) discovering the hierarchical object structure and the inter-object relations. Rather than relying on elaborative annotations (e.g., manually labeled semantic maps and relations), we train our deep model in a weakly-supervised learning manner by leveraging the descriptive sentences of the training images. Specifically, we decompose each sentence into a semantic tree consisting of nouns and verb phrases, and apply these tree structures to discover the configurations of the training images. Once these scene configurations are determined, then the parameters of both the CNN and RsNN are updated accordingly by back propagation. The entire model training is accomplished through an Expectation-Maximization method. Extensive experiments show that our model is capable of producing meaningful scene configurations and achieving more favorable scene labeling results on two benchmarks (i.e., PASCAL VOC2012 and SYSU-Scenes) compared with other state-of-the-art weakly-supervised deep learning methods. In particular, SYSU-Scenes contains more than 5,000 scene images with their semantic sentence descriptions, which is created by us for advancing research on scene parsing.	[Zhang, Ruimao; Lin, Liang; Wang, Guangrun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China; [Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230000, Anhui, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci, Harbin 150001, Heilongjiang, Peoples R China	Sun Yat Sen University; Hefei University of Technology; Harbin Institute of Technology	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China.	ruimao.zhang@ieee.org; linliang@ieee.org; wanggrun@mail2.sysu.edu.cn; eric.mengwang@gmail.com; cswmzuo@gmail.com	Zuo, Wangmeng/B-3701-2008	Zuo, Wangmeng/0000-0002-3330-783X; Liang, Lin/0000-0003-2248-3755	State Key Development Program [2016YFB1001004]; National Natural Science Foundation of China [61622214]; Guangdong Natural Science Foundation Project for Research Teams [2017A030312006]	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Natural Science Foundation Project for Research Teams	This work was supported by State Key Development Program under Grant 2016YFB1001004, the National Natural Science Foundation of China under Grant 61622214, and the Guangdong Natural Science Foundation Project for Research Teams under Grant 2017A030312006.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Chen L.-C., 2014, ARXIV PREPRINT ARXIV; Collins A., 2017, REPRESENTATION UNDER; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Ferrari Vittorio, 2007, NIPS; Fulkerson B, 2009, IEEE I CONF COMP VIS, P670; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI 10.1109/TPAMI.2008.55; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Lempitsky V., 2011, NIPS, V24, P1485; Li YJ, 2014, PR MACH LEARN RES, V32, P1368; Lin L, 2016, PROC CVPR IEEE, P2276, DOI 10.1109/CVPR.2016.250; Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pathak D., ARXIV14127144; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; SHARMA A, 2015, PROC CVPR IEEE, P530, DOI DOI 10.1109/CVPR.2015.7298651; Sharma A., 2014, ADV NEURAL INFORM PR; Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Socher R., 2013, LONG PAPERS, V1, P455; Socher R., 2011, P 28 INT C INT C MAC, P129; Socher Richard, 2010, P NIPS 2010 DEEP LEA; Tarlow D., 2012, P 28 C UNC ART INT, P825; Tighe J, 2014, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2014.479; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Todorovic S, 2008, PROC CVPR IEEE, P195; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757; Wang S, 2015, IEEE T PATTERN ANAL, V37, P2478, DOI 10.1109/TPAMI.2015.2424880; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408; Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhu L, 2012, IEEE T PATTERN ANAL, V34, P359, DOI 10.1109/TPAMI.2011.160	53	11	12	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					596	610		10.1109/TPAMI.2018.2799846	http://dx.doi.org/10.1109/TPAMI.2018.2799846			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993474	Green Submitted			2022-12-18	WOS:000458168800006
J	Tulyakov, S; Jeni, LA; Cohn, JF; Sebe, N				Tulyakov, Sergey; Jeni, Laszlo A.; Cohn, Jeffrey F.; Sebe, Nicu			Viewpoint-Consistent 3D Face Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face alignment; 3D face shape; morphable model	ACTIVE APPEARANCE MODELS; HEAD TRACKING; REGRESSION; DATABASE	Most approaches to face alignment treat the face as a 2D object, which fails to represent depth variation and is vulnerable to loss of shape consistency when the face rotates along a 3D axis. Because faces commonly rotate three dimensionally, 2D approaches are vulnerable to significant error. 3D morphable models, employed as a second step in 2D+3D approaches are robust to face rotation but are computationally too expensive for many applications, yet their ability to maintain viewpoint consistency is unknown. We present an alternative approach that estimates 3D face landmarks in a single face image. The method uses a regression forest-based algorithm that adds a third dimension to the common cascade pipeline. 3D face landmarks are estimated directly, which avoids fitting a 3D morphable model. The proposed method achieves viewpoint consistency in a computationally efficient manner that is robust to 3D face rotation. To train and test our approach, we introduce the Multi-PIE Viewpoint Consistent database. In empirical tests, the proposed method achieved simple yet effective head pose estimation and viewpoint consistency on multiple measures relative to alternative approaches.	[Tulyakov, Sergey] Snapchat Res, Venice, CA 90291 USA; [Jeni, Laszlo A.; Cohn, Jeffrey F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Jeni, Laszlo A.; Cohn, Jeffrey F.] Univ Pittsburgh, Affect Anal Grp, Pittsburgh, PA 15260 USA; [Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, TN, Italy	Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of Trento	Tulyakov, S (corresponding author), Snapchat Res, Venice, CA 90291 USA.	sergey.tulyakov@unitn.it; laszlojeni@cmu.edu; jeffcohn@cs.cmu.edu; niculae.sebe@unitn.it		Jeni, Laszlo A./0000-0002-2830-700X; Sebe, Niculae/0000-0002-6597-7248				An KH, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P307, DOI 10.1109/IROS.2008.4650742; [Anonymous], 2014, ARXIV14101037; Ariz M, 2016, COMPUT VIS IMAGE UND, V148, P201, DOI 10.1016/j.cviu.2015.04.009; Asteriadis S., 2009, P INT WORKSH AFF AW; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1993, P BRIT MACH VIS C, P639; Cootes Timothy F, 1992, BMVC, DOI DOI 10.1007/978-1-4471-3201-1_28; Zavan FHD, 2016, LECT NOTES COMPUT SC, V9914, P581, DOI 10.1007/978-3-319-48881-3_40; Fanelli G, 2013, IEEE INT CONF AUTOMA; Gou C, 2016, LECT NOTES COMPUT SC, V9914, P604, DOI 10.1007/978-3-319-48881-3_42; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Gross R., 2008, P IEEE INT C AUT FAC, P1; Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]; Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448; Hsieh PL, 2015, PROC CVPR IEEE, P1675, DOI 10.1109/CVPR.2015.7298776; Huang C, 2012, COMPUT VIS IMAGE UND, V116, P777, DOI 10.1016/j.cviu.2012.02.007; Huang GB, 2007, 07 UMASS TR; Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142; Jeni LA, 2016, LECT NOTES COMPUT SC, V9914, P511, DOI 10.1007/978-3-319-48881-3_35; Jeni LA, 2017, IMAGE VISION COMPUT, V58, P13, DOI 10.1016/j.imavis.2016.05.009; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; King DE, 2009, J MACH LEARN RES, V10, P1755; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kumano S, 2009, INT J COMPUT VISION, V83, P178, DOI 10.1007/s11263-008-0185-x; La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Messer K., 1999, AUDIO VIDEO BASED BI, P72; Milborrow S., 2010, MUCT LAND MARKED FAC; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455; Roth J, 2015, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2015.7298876; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sangineto E, 2013, IEEE T PATTERN ANAL, V35, P624, DOI 10.1109/TPAMI.2012.87; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Thies Justus, 2016, CVPR, DOI DOI 10.1109/CVPR.2016.262; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; TULYAKOV S, 2016, PROC CVPR IEEE, P2396, DOI DOI 10.1109/CVPR.2016.263; Tulyakov S, 2015, IEEE I CONF COMP VIS, P3748, DOI 10.1109/ICCV.2015.427; Tulyakov S, 2014, INT C PATT RECOG, P2263, DOI 10.1109/ICPR.2014.393; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740; Vicente F, 2015, IEEE T INTELL TRANSP, V16, P2014, DOI 10.1109/TITS.2015.2396031; Weise T., 2011, P ACM SIGGRAPH 2011; Weise T., 2009, P 2009 ACM SIGGRAPH, P7, DOI [DOI 10.1145/1599470.1599472, 10.1145/1599470.1599472]; Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang H, 2013, IEEE I CONF COMP VIS, P1936, DOI 10.1109/ICCV.2013.243; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Yin LJ, 2008, IEEE INT CONF AUTOMA, P116; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Zhang J, 2016, PROC CVPR IEEE, P3428, DOI 10.1109/CVPR.2016.373; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; Zhao RQ, 2016, LECT NOTES COMPUT SC, V9914, P590, DOI 10.1007/978-3-319-48881-3_41; Zhou SK, 2007, LECT NOTES COMPUT SC, V4584, P13; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23	79	11	11	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2250	2264		10.1109/TPAMI.2017.2750687	http://dx.doi.org/10.1109/TPAMI.2017.2750687			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28910758				2022-12-18	WOS:000440868400016
J	Li, YQ; Liu, W; Huang, JZ				Li, Yeqing; Liu, Wei; Huang, Junzhou			Sub-Selective Quantization for Learning Binary Codes in Large-Scale Image Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature quantization; dimensionality reduction; image search; image retrieval; large-scale machine learning	APPROXIMATE NEAREST-NEIGHBOR; PRODUCT QUANTIZATION; SCENE	Recently with the explosive growth of visual content on the Internet, large-scale image search has attracted intensive attention. It has been shown that mapping high-dimensional image descriptors to compact binary codes can lead to considerable efficiency gains in both storage and performing similarity computation of images. However, most existing methods still suffer from expensive training devoted to large-scale binary code learning. To address this issue, we propose a sub-selection based matrix manipulation algorithm, which can significantly reduce the computational cost of code learning. As case studies, we apply the sub-selection algorithm to several popular quantization techniques including cases using linear and nonlinear mappings. Crucially, we can justify the resulting sub-selective quantization by proving its theoretic properties. Extensive experiments are carried out on three image benchmarks with up to one million samples, corroborating the efficacy of the sub-selective quantization method in terms of image retrieval.	[Li, Yeqing; Liu, Wei; Huang, Junzhou] Univ Texas Arlington, Arlington, TX 76019 USA; [Li, Yeqing; Liu, Wei; Huang, Junzhou] Tencent AI Lab, Shenzhen 518057, Peoples R China	University of Texas System; University of Texas Arlington; Tencent	Huang, JZ (corresponding author), Univ Texas Arlington, Arlington, TX 76019 USA.; Huang, JZ (corresponding author), Tencent AI Lab, Shenzhen 518057, Peoples R China.	yeqing.li@mavs.uta.edu; wliu@ee.columbia.edu; jzhuang@uta.edu	li, ye/GWN-2672-2022	Liu, Wei/0000-0002-3865-8145	US National Science Foundation [IIS-1423056, CMMI-1434401, CNS-1405985, IIS-1718853]; NSF CAREER grant [IIS-1553687]	US National Science Foundation(National Science Foundation (NSF)); NSF CAREER grant(National Science Foundation (NSF)NSF - Office of the Director (OD))	This work was partially supported by US National Science Foundation IIS-1423056, CMMI-1434401, CNS-1405985, IIS-1718853 and the NSF CAREER grant IIS-1553687.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bishop CM, 2006, PATTERN RECOGNITION; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gross D, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.150401; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Li W.-J., 2012, P ADV NEUR INF PROC, P1646; Li YQ, 2014, AAAI CONF ARTIF INTE, P2803; Li YQ, 2014, INT C PATT RECOG, P3738, DOI 10.1109/ICPR.2014.642; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu W., 2014, ADV NEURAL INFORM PR, V4, P3419; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Maji S, 2008, PROC CVPR IEEE, P2245; McDiarmid C., 1989, SURVEYS COMBINATORIC, V141, P148, DOI DOI 10.1017/CBO9781107359949.008; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Omohundro S. M., 1987, EFFICIENT ALGORITHMS; Ou MD, 2015, AAAI CONF ARTIF INTE, P2894; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A, 2008, PROC CVPR IEEE, P2269; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Weiss Y., 2008, NIPS, V21, P1753; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25; Woodruff DP, 2014, FOUND TRENDS THEOR C, V10, P1, DOI 10.1561/0400000060; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763	49	11	11	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1526	1532		10.1109/TPAMI.2017.2710186	http://dx.doi.org/10.1109/TPAMI.2017.2710186			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	29733272	hybrid			2022-12-18	WOS:000431524700020
J	Wang, B; Ou, ZJ; Tan, ZQ				Wang, Bin; Ou, Zhijian; Tan, Zhiqiang			Learning Trans-Dimensional Random Fields with Applications to Language Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Language modeling; random field; stochastic approximation; trans-dimensional sampling; undirected graphical modeling	STOCHASTIC-APPROXIMATION; ALGORITHMS; INFERENCE	To describe trans-dimensional observations in sample spaces of different dimensions, we propose a probabilistic model, called the trans-dimensional random field (TRF) by explicitly mixing a collection of random fields. In the framework of stochastic approximation (SA), we develop an effective training algorithm, called augmented SA, which jointly estimates the model parameters and normalizing constants while using trans-dimensional mixture sampling to generate observations of different dimensions. Furthermore, we introduce several statistical and computational techniques to improve the convergence of the training algorithm and reduce computational cost, which together enable us to successfully train TRF models on large datasets. The new model and training algorithm are thoroughly evaluated in a number of experiments. The word morphology experiment provides a benchmark test to study the convergence of the training algorithm and to compare with other algorithms, because log-likelihoods and gradients can be exactly calculated in this experiment. For language modeling, our experiments demonstrate the superiority of the TRF approach in being computationally more efficient in computing data probabilities by avoiding local normalization and being able to flexibly integrate a richer set of features, when compared with n-gram models and neural network models.	[Wang, Bin; Ou, Zhijian] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Tan, Zhiqiang] Rutgers State Univ, Dept Stat, Piscataway, NJ 08854 USA	Tsinghua University; Rutgers State University New Brunswick	Wang, B (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.	wb.th08@gmail.com; ozj@tsinghua.edu.cn; ztan@stat.rutgers.edu			Toshiba Corporation; NSFC [61473168]; Tsinghua Initiative [20121088069]	Toshiba Corporation; NSFC(National Natural Science Foundation of China (NSFC)); Tsinghua Initiative	This work is partly supported by NSFC grant 61473168, Tsinghua Initiative 20121088069 and Toshiba Corporation.	Amaya F, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P10; [Anonymous], 2003, COMP NUMERICAL OPTIM; [Anonymous], 2001, CONDITIONAL RANDOM F; Chen HF, 2002, STOCHASTIC APPROXIMA; Chen S. F., 2009, P HUMAN LANGUAGE TEC, P468; Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169; Goodman JT, 2001, COMPUT SPEECH LANG, V15, P403, DOI 10.1006/csla.2001.0174; Grave E., 2016, ARXIV160904309; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Gu MG, 2001, J ROY STAT SOC B, V63, P339, DOI 10.1111/1467-9868.00289; Khudanpur S, 2000, COMPUT SPEECH LANG, V14, P355, DOI 10.1006/csla.2000.0149; Kingma DP., 2015, INT C LEARN REPR ICL; Koller D., 2009, PROBABILISTIC GRAPHI; Liang FM, 2007, J AM STAT ASSOC, V102, P305, DOI 10.1198/016214506000001202; Malouf, 2002, P 6 C NAT LANG LEARN, V20, P1, DOI DOI 10.3115/1118853.1118871; Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9; Mikolov T.A., 2012, STAT LANGUAGE MODELS; Mikolov T, 2011, INT CONF ACOUST SPEE, P5528; Mnih A., 2013, ADV NEURAL INFORM PR, V26, P2265; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; POLYAK BT, 1992, SIAM J CONTROL OPTIM, V30, P838, DOI 10.1137/0330046; Roark B., 2004, P ACL, P47; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159; Ruokolainen T, 2010, FRONT ARTIF INTEL AP, V219, P73, DOI 10.3233/978-1-60750-641-6-73; Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003; Shazeer N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1428; Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194; Sutskever I., 2014, ARXIV; Tan ZQ, 2017, J COMPUT GRAPH STAT, V26, P54, DOI 10.1080/10618600.2015.1113975; Tieleman T., 2012, COURSERA NEURAL NETW; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Wang B, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P785; Wiesler S., 2011, ADV NEURAL INFORM PR, P657; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287	40	11	11	3	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					876	890		10.1109/TPAMI.2017.2696536	http://dx.doi.org/10.1109/TPAMI.2017.2696536			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28436847				2022-12-18	WOS:000426687100008
J	Elhoseiny, M; Elgammal, A; Saleh, B				Elhoseiny, Mohamed; Elgammal, Ahmed; Saleh, Babak			Write a Classifier: Predicting Visual Classifiers from Unstructured Text	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Language and vision; zero shot learning; unstructured text; noisy text	OBJECT; EXAMPLE	People typically learn through exposure to visual concepts associated with linguistic descriptions. For instance, teaching visual object categories to children is often accompanied by descriptions in text or speech. In a machine learning context, these observations motivates us to ask whether this learning process could be computationally modeled to learn visual classifiers. More specifically, the main question of this work is how to utilize purely textual description of visual classes with no training images, to learn explicit visual classifiers for them. We propose and investigate two baseline formulations, based on regression and domain transfer, that predict a linear classifier. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the parameters of a linear classifier. We also propose a generic kernelized models where a kernel classifier is predicted in the form defined by the representer theorem. The kernelized models allow defining and utilizing any two Reproducing Kernel Hilbert Space (RKHS) kernel functions in the visual space and text space, respectively. We finally propose a kernel function between unstructured text descriptions that builds on distributional semantics, which shows an advantage in our setting and could be useful for other applications. We applied all the studied models to predict visual classifiers on two fine-grained and challenging categorization datasets (CU Birds and Flower Datasets), and the results indicate successful predictions of our final model over several baselines that we designed.	[Elhoseiny, Mohamed] Facebook Inc, Facebook AI Res, Menlo Pk, CA 94025 USA; [Elgammal, Ahmed; Saleh, Babak] Rutgers State Univ, Comp Sci Dept, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA	Facebook Inc; Rutgers State University New Brunswick	Elhoseiny, M (corresponding author), Facebook Inc, Facebook AI Res, Menlo Pk, CA 94025 USA.	m.elhoseiny@cs.rutgers.edu; elgammal@cs.rutgers.edu; babaks@cs.rutgers.edu	Elhoseiny, Mohamed/X-6406-2019		US National Science Foundation [IIS-1409683, IIS-1218872]	US National Science Foundation(National Science Foundation (NSF))	This research was funded by US National Science Foundation award IIS-1409683 and IIS-1218872.	Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2007, P 15 ACM INT C MULTI; Barnard K, 2001, PROC CVPR IEEE, P434; Bart E, 2005, PROC CVPR IEEE, P672; Belongie S., 2016, ALL ABOUT BIRDS16; Bengio Y., 2014, ARXIV14061078; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bucak S., 2010, ADV NEURAL INFORM PR, P325; Censor Y., 1997, PARALLEL OPTIMIZATIO; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Donahue J, 2014, PR MACH LEARN RES, V32; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Elhoseiny M, 2016, AAAI CONF ARTIF INTE, P3478; Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321; EVANGELISTA PF, 2007, P 17 INT C ART NEUR, V4668, P269; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; Fergus R, 2010, LECT NOTES COMPUT SC, V6311, P762, DOI 10.1007/978-3-642-15549-9_55; Fink M, 2004, P NIPS, V17, P449; Fox D., 2010, ADV NEURAL INFORM PR, V23, P244; Frome Andrea, 2013, NEURIPS; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Griffin G, 2008, PROC CVPR IEEE, P533; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; Huang S, 2015, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2015.7298638; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Krishnamoorthy N., 2013, P WORKSHOP VISION NA, P10; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038; Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13; Maji S., 2013, TECH REP; Mao J, 2015, 3 INT C LEARN REPR I; Mikolov T., 2013, ARXIV; Mikolov T., 2013, EFFICIENT ESTIMATION, P1, DOI DOI 10.48550/ARXIV.1301.3781; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Norouzi Mohammad, 2014, ICLR; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451; Qiao RZ, 2016, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2016.247; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rohrbach M., 2010, P 11 EUR C TRENDS TO, P15; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Romera-Paredes Bernardino, 2015, ICML; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Socher Richard, 2013, NEURIPS; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Vendrov I., 2016, P INT C LEARN REPR; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wah C., 2011, TECH REP; Wang JQ, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 7, P1; Welinder P., 2010, CNSTR2010001 CALTECH; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zeimpekis D, 2005, SIAM PROC S, P631	70	11	12	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2539	2553		10.1109/TPAMI.2016.2643667	http://dx.doi.org/10.1109/TPAMI.2016.2643667			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28055848	hybrid, Green Submitted			2022-12-18	WOS:000414395400016
J	Pittaluga, F; Koppal, SJ				Pittaluga, Francesco; Koppal, Sanjeev Jagannatha			Pre-Capture Privacy for Small Vision Sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; privacy	RECOGNITION; CAMERA; ANONYMITY; DESIGN	The next wave of micro and nano devices will create a world with trillions of small networked cameras. This will lead to increased concerns about privacy and security. Most privacy preserving algorithms for computer vision are applied after image/video data has been captured. We propose to use privacy preserving optics that filter or block sensitive information directly from the incident light-field before sensor measurements are made, adding a new layer of privacy. In addition to balancing the privacy and utility of the captured data, we address trade-offs unique to miniature vision sensors, such as achieving high-quality field-of-view and resolution within the constraints of mass and volume. Our privacy preserving optics enable applications such as depth sensing, full-body motion tracking, people counting, blob detection and privacy preserving face recognition. While we demonstrate applications on macro-scale devices (smartphones, webcams, etc.) our theory has impact for smaller devices.	[Pittaluga, Francesco; Koppal, Sanjeev Jagannatha] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Pittaluga, F (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	f.pittaluga@ufl.edu; sjkoppal@ece.ufl.edu						Abdulghani AM, 2010, IEEE ENG MED BIO, P1127, DOI 10.1109/IEMBS.2010.5627119; Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551; [Anonymous], 2008, P 2008 IEEE C COMP V; Bascle B., 1996, COMPUTER VISION ECCV, P571; Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638; Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304; Boyle M., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P1, DOI 10.1145/358916.358935; Brajovic V, 1998, IEEE J SOLID-ST CIRC, V33, P1199, DOI 10.1109/4.705358; Browarek S., 2010, THESIS; Calhoun BH, 2005, IEEE T COMPUT, V54, P727, DOI 10.1109/TC.2005.98; Chandrakasan A., 2006, POWER, V30; Chattopadhyay A., 2007, 2007 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2007.383413, DOI 10.1109/CVPR.2007.383413]; Cossalter M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P436, DOI 10.1109/AVSS.2009.13; Davenport M. A., 2007, P SPIE EL IM; Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306; Driessen B, 2013, LECT NOTES COMPUT SC, V8099, P18; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Duchi J.C., 2012, ADV NEURAL INFORM PR, V25, P1430; Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225; Dufaux F, 2010, IEEE INT CON MULTI, P66, DOI 10.1109/ICME.2010.5583552; DYCKHOFF H, 1990, EUR J OPER RES, V44, P145, DOI 10.1016/0377-2217(90)90350-K; Ercan AO, 2006, LECT NOTES COMPUT SC, V4026, P389; Erdem UM, 2006, COMPUT VIS IMAGE UND, V103, P156, DOI 10.1016/j.cviu.2006.06.005; Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14; Fan H., 2014, CORR; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; FERGUS R, 2006, MITCSAILTR2006058; Fernandez-Berni J, 2016, IEEE T CIRCUITS-II, V63, P488, DOI 10.1109/TCSII.2015.2505263; Fernandez-Berni J, 2014, SENSORS-BASEL, V14, P15203, DOI 10.3390/s140815203; Gluckman J, 2001, INT J COMPUT VISION, V44, P65, DOI 10.1023/A:1011172403203; Goodman J. W., 1968, INTRO FOURIER OPTICS, V2; Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227; Guvensan MA, 2011, AD HOC NETW, V9, P1238, DOI 10.1016/j.adhoc.2011.02.003; Gyselinckx B, 2005, IEEE CUST INTEGR CIR, P13; Ji Dai, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P68, DOI 10.1109/CVPRW.2015.7301356; Kevenaar TAM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P21, DOI 10.1109/AUTOID.2005.24; Koppal SJ, 2013, IEEE T PATTERN ANAL, V35, P2982, DOI 10.1109/TPAMI.2013.22; Koppal SJ, 2011, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2011.5995338; Korf Richard E., 2010, Annals of Operations Research, V179, P261, DOI 10.1007/s10479-008-0463-6; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Li F, 2011, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2011.6126245; Lindeberg T., 1993, SCALE SPACE THEORY C; Loukides G, 2008, P 2008 INT WORKSH PR, P36; Martello S., 1990, KNAPSACK PROBLEMS AL; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; Mrityunjay M., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P192, DOI 10.1109/NCVPRIPG.2011.48; Nakashima S, 2010, PROCD SOC BEHV, V2, P213, DOI 10.1016/j.sbspro.2010.01.038; Nayar SK, 2006, INT J COMPUT VISION, V70, P7, DOI 10.1007/s11263-005-3102-6; Nelson GR, 2005, IEEE INT SYMP CIRC S, P5326, DOI 10.1109/ISCAS.2005.1465838; Neustaedter C., 2006, ACM Transactions on Computer-Human Interaction, V13, P1, DOI 10.1145/1143518.1143519; Newton E., 2003, CMUCS03119; Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32; Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256; Nishiyama M, 2011, IEEE T PATTERN ANAL, V33, P838, DOI 10.1109/TPAMI.2010.203; Nishiyama M, 2009, PROC CVPR IEEE, P1115, DOI 10.1109/CVPRW.2009.5206750; O'Toole M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185535; Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pittaluga F, 2016, IEEE INT CONF COMPUT, P103; Pittaluga F, 2015, PROC CVPR IEEE, P314, DOI 10.1109/CVPR.2015.7298628; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229; Sample AP, 2008, IEEE T INSTRUM MEAS, V57, P2608, DOI 10.1109/TIM.2008.925019; Soro S, 2005, 2ND INTERNATIONAL CONFERENCE ON BROADBAND NETWORKS (BROADNETS 2005), P9, DOI 10.1109/ICBN.2005.1589704; Steltz E, 2009, IEEE-ASME T MECH, V14, P1, DOI 10.1109/TMECH.2008.2005902; Streeter L, 2015, OPT LETT, V40, P5391, DOI 10.1364/OL.40.005391; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Thorpe C, 2013, IEEE T PATTERN ANAL, V35, P3066, DOI 10.1109/TPAMI.2013.161; Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577; Wilhelm A, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATIONS, VOLS 1-4, CONFERENCE PROCEEDINGS, P32; Winkler T., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P593, DOI 10.1109/AVSS.2010.38; Winkler T, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P159, DOI 10.1109/AVSS.2014.6918661; Wolf W, 2002, COMPUTER, V35, P48, DOI 10.1109/MC.2002.1033027; Yu F. T., 2008, OPTICAL PATTERN RECO, V1; Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315; Zhang YP, 2014, INT C PATT RECOG, P4170, DOI 10.1109/ICPR.2014.715; Zhou SH, 2009, IEEE T INFORM THEORY, V55, P846, DOI 10.1109/TIT.2008.2009605; Zomet A., 2006, COMP VIS PATT REC 20, V1, P339	81	11	11	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2215	2226		10.1109/TPAMI.2016.2637354	http://dx.doi.org/10.1109/TPAMI.2016.2637354			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	27959803				2022-12-18	WOS:000412028600008
J	Kumar, KCA; Jacques, L; De Vleeschouwer, C				Kumar, Amit K. C.; Jacques, Laurent; De Vleeschouwer, Christophe			Discriminative and Efficient Label Propagation on Complementary Graphs for Multi-Object Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; label propagation; sporadic features; multi-object tracking; graph labeling	SELECTION; PEOPLE	Given a set of detections, detected at each time instant independently, we investigate how to associate them across time. This is done by propagating labels on a set of graphs, each graph capturing how either the spatio-temporal or the appearance cues promote the assignment of identical or distinct labels to a pair of detections. The graph construction is motivated by a locally linear embedding of the detection features. Interestingly, the neighborhood of a node in appearance graph is defined to include all the nodes for which the appearance feature is available (even if they are temporally distant). This gives our framework the uncommon ability to exploit the appearance features that are available only sporadically. Once the graphs have been defined, multi-object tracking is formulated as the problem of finding a label assignment that is consistent with the constraints captured each graph, which results into a difference of convex (DC) program. We propose to decompose the global objective function into node-wise sub-problems. This not only allows a computationally efficient solution, but also supports an incremental and scalable construction of the graph, thereby making the framework applicable to large graphs and practical tracking scenarios. Moreover, it opens the possibility of parallel implementation.	[Kumar, Amit K. C.; Jacques, Laurent; De Vleeschouwer, Christophe] UCL, ISP Grp, ELEN Dept, ICTEAM Inst, B-1348 Louvain, Belgium	Universite Catholique Louvain	Kumar, KCA (corresponding author), UCL, ISP Grp, ELEN Dept, ICTEAM Inst, B-1348 Louvain, Belgium.	amit.kc@uclouvain.be; laurent.jacques@uclouvain.be; christophe.devleeschouwer@uclouvain.be	Jacques, Laurent/N-7820-2019	Jacques, Laurent/0000-0002-6261-0328	F.N.R.S.	F.N.R.S.(Fonds de la Recherche Scientifique - FNRS)	A. K. K. C., L. Jacques, and C. D. Vleeschouwer are funded by the F.N.R.S.	Amit K. K. C., 2012, P AS C COMP VIS DAEI, V2, P412; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; CALAMAI PH, 1987, MATH PROGRAM, V39, P93, DOI 10.1007/BF02592073; Chen AI, 2012, ANN ALLERTON CONF, P601, DOI 10.1109/Allerton.2012.6483273; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; De Vleeschouwer C., 2012, P BRIT MACH VIS C; Delannay D, 2009, 2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P15; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; Freund Y., 1997, J COMPUT SYS SCI, V55; Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102; Kumar KCA, 2013, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2013.250; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; Lanckriet G. R., 2009, P 22 INT C NEURAL IN, P1759; Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809; Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242; LU Z, 2007, P ADV NEUR INF PROC, P1705; Lu Zhengdong, 2007, J MACH LEARN RES, P59; Nesterov Y., 2004, INTRO LECT CONVEX OP, V87; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tong W., 2007, P NATL C ARTIF INTEL, P651; Verleysen C., 2012, P SPIE, V8305; Wang F., 2006, P 23 INT C MACH LEAR, P985, DOI DOI 10.1145/1143844.1143968; Zhu Xiaojin., 2003, P ICLR, P912; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	34	11	11	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					61	74		10.1109/TPAMI.2016.2533391	http://dx.doi.org/10.1109/TPAMI.2016.2533391			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26915115	Green Submitted			2022-12-18	WOS:000390421300007
J	Zeng, Y; Wang, CH; Gu, XF; Samaras, D; Paragios, N				Zeng, Yun; Wang, Chaohui; Gu, Xianfeng; Samaras, Dimitris; Paragios, Nikos			Higher-Order Graph Principles towards Non-Rigid Surface Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Surface registration; higher-order graph matching; conformal geometry; higher-order Markov random fields		This paper casts surface registration as the problem of finding a set of discrete correspondences through the minimization of an energy function, which is composed of geometric and appearance matching costs, as well as higher-order deformation priors. Two higher-order graph-based formulations are proposed under different deformation assumptions. The first formulation encodes isometric deformations using conformal geometry in a higher-order graph matching problem, which is solved through dual-decomposition and is able to handle partial matching. Despite the isometry assumption, this approach is able to robustly match sparse feature point sets on surfaces undergoing highly anisometric deformations. Nevertheless, its performance degrades significantly when addressing anisometric registration for a set of densely sampled points. This issue is rigorously addressed subsequently through a novel deformation model that is able to handle arbitrary diffeomorphisms between two surfaces. Such a deformation model is introduced into a higher-order Markov Random Field for dense surface registration, and is inferred using a new parallel and memory efficient algorithm. To deal with the prohibitive search space, we also design an efficient way to select a number of matching candidates for each point of the source surface based on the matching results of a sparse set of points. A series of experiments demonstrate the accuracy and the efficiency of the proposed framework, notably in challenging cases of large and/or anisometric deformations, or surfaces that are partially occluded.	[Zeng, Yun] Google Inc, Mountain View, CA 94043 USA; [Wang, Chaohui] Univ Paris Est, CNRS, UMR 8049, Lab Informat Gaspard Monge, F-77454 Marne La Vallee 2, France; [Gu, Xianfeng; Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Paragios, Nikos] Univ Paris Saclay, CentraleSupelec, Inria, Ctr Visual Comp, Paris, France	Google Incorporated; Universite Gustave-Eiffel; ESIEE Paris; Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; Inria; UDICE-French Research Universities; Universite Paris Saclay	Zeng, Y (corresponding author), Google Inc, Mountain View, CA 94043 USA.	xzeng@google.com; chaohui.wang@u-pem.fr; gu@cs.stonybrook.edu; samaras@cs.stonybrook.edu; nikos.paragios@ecp.fr		Gu, Xianfeng/0000-0001-8226-5851	European Research Council [ERC-STG-259112]; Digiteo SubSample University of Paris-Saclay grant; CNRS INS2I-JCJC-INVISANA; National Science Foundation [DMS-1418255, DMS-1221339]; AFOSR [FA9550-10-1-0294, FA9550-2614-1-0193]; National Natural Science Foundation of China [61328206]	European Research Council(European Research Council (ERC)European Commission); Digiteo SubSample University of Paris-Saclay grant; CNRS INS2I-JCJC-INVISANA; National Science Foundation(National Science Foundation (NSF)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research was partially supported by European Research Council Grant Diocles (ERC-STG-259112), the Digiteo SubSample University of Paris-Saclay grant (2011-2016), CNRS INS2I-JCJC-INVISANA, National Science Foundation (Grant Nos. DMS-1418255, DMS-1221339), AFOSR FA9550-10-1-0294, AFOSR FA9550-2614-1-0193, and National Natural Science Foundation of China (Grant No. 61328206). Chaohui Wang is the corresponding author of the article.	Ahlfors L.V., 2006, LECT QUASICONFORMAL; Ahuja R. K., 1993, NETWORK FLOWS THEORY; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Anguelov D., 2004, ADV NEURAL INFORM PR, P33; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boyd S, 2004, CONVEX OPTIMIZATION; Brenner S., 2007, MATH THEORY FINITE E; Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Brown BJ, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239472; Burkard R., 2009, ASSIGNMENT PROBLEMS; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Cho M, 2009, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2009.5459322; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T., 2007, P ADV NEURAL INFORM, P313; Do Carmo P.], 1992, RIEMANNIAN GEOMETRY; Dongmei Zhang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P524, DOI 10.1109/CVPR.1999.784731; Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619; Farkas H. M., 2004, RIEMANN SURFACES; Fix A, 2012, LECT NOTES COMPUT SC, V7572, P385, DOI 10.1007/978-3-642-33718-5_28; Frankel T., 2004, GEOMETRY PHYS INTRO; Glocker B, 2010, LECT NOTES COMPUT SC, V6313, P272; Haehnel D., 2003, P INT C ART INT IJCA, V3, P915; Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x; Huang XL, 2003, LECT NOTES COMPUT SC, V2879, P926; Ishikawa Hiroshi, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2993, DOI 10.1109/CVPRW.2009.5206689; Kim J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966403; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; LEORDEANU M, 2011, P 2011 IEEE INT C CO, P2274; Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378; Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526; Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; Shaji A, 2010, PROC CVPR IEEE, P1221, DOI 10.1109/CVPR.2010.5539827; Sharma A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2481, DOI 10.1109/CVPR.2011.5995455; Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011; Sorkine Olga, 2007, P EUROGRAPHICS ACM S, V4, P109, DOI 10.1145/1281991.1282006; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Tevs A, 2011, COMPUT GRAPH FORUM, V30, P543, DOI 10.1111/j.1467-8659.2011.01879.x; Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775; Thorstensen Nicolas, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P644; Torr P.H., 2003, P INT WORKSH ART INT, P292; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209; Wang C., 2011, P INT C SCAL SPAC VA, P580; WANG CH, 2011, P IEEE INT C COMP VI, P319; Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004; Wang CH, 2010, LECT NOTES COMPUT SC, V6363, P189; Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050; Wang Y, 2005, IEEE I CONF COMP VIS, P388; Werner T, 2010, IEEE T PATTERN ANAL, V32, P1474, DOI 10.1109/TPAMI.2009.134; Yin L., 2008, AUTOMATIC FACE GESTU, V08, P1, DOI DOI 10.1109/AFGR.2008.4813324; Zeng W, 2008, LECT NOTES COMPUT SC, V5304, P1, DOI 10.1007/978-3-540-88690-7_1; ZENG Y, 2013, P IEEE INT C COMP VI, P3360; Zeng Y, 2011, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2011.5995513; Zeng Y, 2010, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2010.5540189; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24	71	11	12	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2416	2429		10.1109/TPAMI.2016.2528240	http://dx.doi.org/10.1109/TPAMI.2016.2528240			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26886966	Green Submitted, hybrid			2022-12-18	WOS:000387984700006
J	Hong, Y; Kwitt, R; Singh, N; Vasconcelos, N; Niethammer, M				Hong, Yi; Kwitt, Roland; Singh, Nikhil; Vasconcelos, Nuno; Niethammer, Marc			Parametric Regression on the Grassmannian	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Parametric regression; Grassmann manifold; geodesic shooting; time-warping; cubic splines	RIEMANNIAN-MANIFOLDS; GEODESIC REGRESSION; SMOOTHING SPLINES; LEAST-SQUARES; GEOMETRY; GROWTH; VIEW	We address the problem of fitting parametric curves on the Grassmann manifold for the purpose of intrinsic parametric regression. We start from the energy minimization formulation of linear least-squares in Euclidean space and generalize this concept to general nonflat Riemannian manifolds, following an optimal-control point of view. We then specialize this idea to the Grassmann manifold and demonstrate that it yields a simple, extensible and easy-to-implement solution to the parametric regression problem. In fact, it allows us to extend the basic geodesic model to (1) a "time-warped" variant and (2) cubic splines. We demonstrate the utility of the proposed solution on different vision problems, such as shape regression as a function of age, traffic-speed estimation and crowd-counting from surveillance video clips. Most notably, these problems can be conveniently solved within the same framework without any specifically-tailored steps along the processing pipeline.	[Hong, Yi; Singh, Nikhil; Niethammer, Marc] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27514 USA; [Kwitt, Roland] Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria; [Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	University of North Carolina; University of North Carolina Chapel Hill; Salzburg University; University of California System; University of California San Diego	Hong, Y (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27514 USA.	yihong@cs.unc.edu; rkwitt@gmx.at; nsingh@cs.unc.edu; nvasconcelos@ucsd.edu; mn@cs.unc.edu	Kwitt, Roland/AFS-8639-2022; singh, Nikhil/AAX-5380-2020	Vasconcelos, Nuno/0000-0002-9024-4302	NSF [EECS-1148870, IIS-1208522]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [P41EB002025] Funding Source: NIH RePORTER	NSF(National Science Foundation (NSF)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	This work was supported by NSF grants EECS-1148870 and IIS-1208522.	Absil PA, 2004, ACTA APPL MATH, V80, P199, DOI 10.1023/B:ACAP.0000013855.14971.91; Ahlberg J.H., 1967, THEORY SPLINES THEIR; Batzies E, 2015, LINEAR ALGEBRA APPL, V466, P83, DOI 10.1016/j.laa.2014.10.003; Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Bookstein F. L., 1991, MORPHOMETRIC TOOLS L; Boothby W., 1986, INTRO DIFFERENTIABLE; Boumal Nicolas, 2013, Geometric Science of Information. First International Conference, GSI 2013. Proceedings. LNCS 8085, P345, DOI 10.1007/978-3-642-40020-9_37; Boumal N., 2011, IFAC P, V44, P2284, DOI [10.3182/20110828-6-it-1002.00542, DOI 10.3182/20110828-6-IT-1002.00542, 10.3182/20110828-6-IT-1002.00542]; Boumal N, 2011, INT CONF ACOUST SPEE, P4232; Camarinha M., 1995, IMA Journal of Mathematical Control and Information, V12, P399, DOI 10.1093/imamci/12.4.399; Cetingul HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806; Chan AB, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P771; Cheema M., 1998, STATISTICIAN, V41, P209; Crouch P., 1995, Journal of Dynamical and Control Systems, V1, P177, DOI 10.1007/BF02254638; Davis BC, 2010, INT J COMPUT VISION, V90, P255, DOI 10.1007/s11263-010-0367-1; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Durrleman S, 2013, INT J COMPUT VISION, V103, P22, DOI 10.1007/s11263-012-0592-x; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fekedulegn D, 1999, SILVA FENN, V33, P327, DOI 10.14214/sf.653; Fletcher PT, 2013, INT J COMPUT VISION, V105, P171, DOI 10.1007/s11263-012-0591-y; Gallivan KA, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P315; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Harandi MT, 2014, LECT NOTES COMPUT SC, V8695, P408, DOI 10.1007/978-3-319-10584-0_27; Hinkle J, 2014, J MATH IMAGING VIS, V50, P32, DOI 10.1007/s10851-013-0489-5; Hong Y, 2015, LECT NOTES COMPUT SC, V9351, P727, DOI 10.1007/978-3-319-24574-4_87; Hong Y, 2014, LECT NOTES COMPUT SC, V8674, P105, DOI 10.1007/978-3-319-10470-6_14; Hong Y, 2014, LECT NOTES COMPUT SC, V8690, P632, DOI 10.1007/978-3-319-10605-2_41; Hong Y, 2012, LECT NOTES COMPUT SC, V7512, P197, DOI 10.1007/978-3-642-33454-2_25; Hopper K D, 1994, Acad Radiol, V1, P243; HUGHES PCR, 1978, J ANAT, V127, P83; Jayasumana S, 2014, PROC CVPR IEEE, P3802, DOI 10.1109/CVPR.2014.480; JOHNSON SC, 1994, BRAIN RES BULL, V35, P373, DOI 10.1016/0361-9230(94)90116-3; LUI YM, 2009, P IEEE 3 INT C BIOM, P1; Lui YM, 2012, J MACH LEARN RES, V13, P3297; Machado L, 2010, J DYN CONTROL SYST, V16, P121, DOI 10.1007/s10883-010-9080-1; Mittal S, 2012, IMAGE VISION COMPUT, V30, P417, DOI 10.1016/j.imavis.2011.09.005; Niethammer M, 2011, LECT NOTES COMPUT SC, V6892, P655, DOI 10.1007/978-3-642-23629-7_80; NOAKES L, 1989, IMA J MATH CONTROL I, V6, P465, DOI 10.1093/imamci/6.4.465; Rentmeesters Q, 2011, IEEE DECIS CONTR P, P7141, DOI 10.1109/CDC.2011.6161280; Samir C, 2012, FOUND COMPUT MATH, V12, P49, DOI 10.1007/s10208-011-9091-7; Sepiashvili D, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P307; Singh N, 2014, LECT NOTES COMPUT SC, V8674, P121, DOI 10.1007/978-3-319-10470-6_16; Singh N, 2013, I S BIOMED IMAGING, P1219; Su J, 2012, IMAGE VISION COMPUT, V30, P428, DOI 10.1016/j.imavis.2011.09.006; Trouve A, 2012, Q APPL MATH, V70, P219, DOI 10.1090/S0033-569X-2012-01250-4; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Turaga P, 2010, INT CONF ACOUST SPEE, P946, DOI 10.1109/ICASSP.2010.5495292; Zheng JJ, 2012, INT C PATT RECOG, P2095	51	11	11	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2284	2297		10.1109/TPAMI.2016.2516533	http://dx.doi.org/10.1109/TPAMI.2016.2516533			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26766216	Green Submitted, hybrid			2022-12-18	WOS:000385945000011
J	Roudposhti, KK; Nunes, U; Dias, J				Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge			Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Social signal processing; social role; human movement analysis; frequency domain; Bayesian approach		Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading). The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.	[Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge] Univ Coimbra, Elect & Comp Engn Dept, Inst Syst & Robot, P-3000 Coimbra, Portugal; [Dias, Jorge] Khalifa Univ, Inst Robot, Abu Dhabi, U Arab Emirates	Universidade de Coimbra; Khalifa University of Science & Technology	Roudposhti, KK (corresponding author), Univ Coimbra, Elect & Comp Engn Dept, Inst Syst & Robot, P-3000 Coimbra, Portugal.	kamrad@isr.uc.pt; urbano@deec.uc.pt; jorge@isr.uc.pt	Nunes, Urbano J/G-1187-2011; Khoshhal roudposhti, Kamrad/J-5935-2012; Dias, Jorge Miranda/A-1842-2011; Roudposhti, Kamrad Khoshhal/AAN-5227-2021	Nunes, Urbano J/0000-0002-7750-5221; Khoshhal roudposhti, Kamrad/0000-0001-9633-3114; Dias, Jorge Miranda/0000-0002-2725-8867; Roudposhti, Kamrad Khoshhal/0000-0001-9633-3114				Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Alazrai R, 2012, IEEE INT CONF ROBOT, P1212, DOI 10.1109/ICRA.2012.6224702; Badler Norman I., 1993, SIMULATING HUMANS CO; Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71; Diard J., 2003, P 2 INT C COMP INT R; Dong W, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P271; Engleberg IN, 2006, WORKING GROUPS COMMU; Girard JM, 2015, BEHAV RES METHODS, V47, P1136, DOI 10.3758/s13428-014-0536-1; Hutchinson A., 1974, LABANOTATION; Jayagopi DB, 2009, IEEE T AUDIO SPEECH, V17, P501, DOI 10.1109/TASL.2008.2008238; Khoshhal K., 2011, P 12 INT WORKSH IM A; Khoshhal K., 2010, IND POS IND NAV IPIN, P1, DOI DOI 10.1109/IPIN.2010.5647576; Kleinsmith A, 2011, IEEE T SYST MAN CY B, V41, P1027, DOI 10.1109/TSMCB.2010.2103557; Lebeltel O, 2004, AUTON ROBOT, V16, P49, DOI 10.1023/B:AURO.0000008671.38949.43; Leite I, 2013, INT J HUM-COMPUT ST, V71, P250, DOI 10.1016/j.ijhcs.2012.09.005; Metallinou A, 2013, IMAGE VISION COMPUT, V31, P137, DOI 10.1016/j.imavis.2012.08.018; Mohammadi G, 2012, IEEE T AFFECT COMPUT, V3, P273, DOI 10.1109/T-AFFC.2012.5; PANTIC M, 2006, P 8 INT C MULT INT, P239, DOI DOI 10.1145/1180995.1181044; Perez-Sala X, 2014, SENSORS-BASEL, V14, P4189, DOI 10.3390/s140304189; Ponce-Lopez V, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P495, DOI 10.1145/2522848.2532594; Rett J, 2008, THESIS; Richmond V. P., 2011, NONVERBAL BEHAV INTE; Roudposhti K. K., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6239349; Roudposhti KK, 2013, IEEE SYS MAN CYBERN, P2899, DOI 10.1109/SMC.2013.494; Roudposhti KK, 2013, PATTERN RECOGN LETT, V34, P820, DOI 10.1016/j.patrec.2012.09.021; Ryoo MS, 2006, 2006 IEEE COMPUTER S, V2, P1709, DOI DOI 10.1109/CVPR.2006.242; Sandy) A. ( Pentland, 2008, HONEST SIGNALS THEY; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Therrien CW, 1992, DISCRETE RANDOM SIGN; Ullmann, 1966, CHOREUTICS; Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27; Xiaofan Sun, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P40, DOI 10.1109/CVPRW.2011.5981812; Zancanaro M., 2006, 2006 INT C MULTIMODA, V8, P28; Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002	34	11	11	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1679	1691		10.1109/TPAMI.2015.2496209	http://dx.doi.org/10.1109/TPAMI.2015.2496209			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26540675				2022-12-18	WOS:000379926200015
J	Chandraker, M				Chandraker, Manmohan			The Information Available to a Moving Observer on Shape with Unknown, Isotropic BRDFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Surface reconstruction; general BRDF; multiview stereo; differential theory	OPTICAL-FLOW; SPECULAR REFLECTIONS; REFLECTANCE; PERCEPTION	Psychophysical studies show motion cues inform about shape even with unknown reflectance. Recent works in computer vision have considered shape recovery for an object of unknown BRDF using light source or object motions. This paper proposes a theory that addresses the remaining problem of determining shape from the (small or differential) motion of the camera, for unknown isotropic BRDFs. Our theory derives a differential stereo relation that relates camera motion to surface depth, which generalizes traditional Lambertian assumptions. Under orthographic projection, we show differential stereo may not determine shape for general BRDFs, but suffices to yield an invariant for several restricted (still unknown) BRDFs exhibited by common materials. For the perspective case, we show that differential stereo yields the surface depth for unknown isotropic BRDF and unknown directional lighting, while additional constraints are obtained with restrictions on the BRDF or lighting. The limits imposed by our theory are intrinsic to the shape recovery problem and independent of choice of reconstruction method. We also illustrate trends shared by theories on shape from differential motion of light source, object or camera, to relate the hardness of surface reconstruction to the complexity of imaging setup.	[Chandraker, Manmohan] NEC Labs Amer, Cupertino, CA 95014 USA	NEC Corporation	Chandraker, M (corresponding author), NEC Labs Amer, Cupertino, CA 95014 USA.	manu@nec-labs.com	Chandraker, Manmohan/AAU-4762-2021					Alldrin N, 2008, PROC CVPR IEEE, P2447; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Ben-Artzi A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356686; Blake A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P394, DOI 10.1109/CCV.1988.590016; BLAKE A, 1990, NATURE, V343, P165, DOI 10.1038/343165a0; Blake A., 1985, IJCAI, P973; Bonfort T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P591; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Chandraker M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2505, DOI 10.1109/CVPR.2011.5995603; Chandraker M, 2014, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2014.279; Chandraker M, 2014, LECT NOTES COMPUT SC, V8695, P202, DOI 10.1007/978-3-319-10584-0_14; Chandraker M, 2013, PROC CVPR IEEE, P2523, DOI 10.1109/CVPR.2013.326; Chandraker M, 2011, IEEE I CONF COMP VIS, P1076, DOI 10.1109/ICCV.2011.6126354; Chen M, 2000, ACM T GRAPHIC, V19, P246, DOI 10.1145/380666.380670; Clark J. J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P29, DOI 10.1109/CVPR.1992.223231; Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102; Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; John F., 1981, APP MATH SCI; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Minnaert M, 1941, ASTROPHYS J, V93, P403, DOI 10.1086/144279; Muryy AA, 2013, P NATL ACAD SCI USA, V110, P2413, DOI 10.1073/pnas.1212417110; NAGEL HH, 1989, IEEE T PATTERN ANAL, V11, P13, DOI 10.1109/34.23110; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; Ngan A, 2005, EUR S REND, V2, P117, DOI DOI 10.2312/EGWR/EGSR05/117-126; Norman JF, 2004, PSYCHOL SCI, V15, P565, DOI 10.1111/j.0956-7976.2004.00720.x; Oxholm G, 2012, LECT NOTES COMPUT SC, V7572, P528, DOI 10.1007/978-3-642-33718-5_38; Sato I, 2007, IEEE I CONF COMP VIS, P1493; Seitz S., 2006, P INT C COMP VIS PAT, P519, DOI DOI 10.1109/CVPR.2006.19; Todd JT, 1997, PERCEPTION, V26, P807, DOI 10.1068/p260807; Treuille A, 2004, LECT NOTES COMPUT SC, V3022, P457; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; Vogiatzis G., 2010, COMPUTER VISION; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu CC, 2012, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2012.6247839; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513; ZISSERMAN A, 1989, IMAGE VISION COMPUT, V7, P38, DOI 10.1016/0262-8856(89)90018-8	43	11	14	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1283	10.1109/TPAMI.2015.2481415	http://dx.doi.org/10.1109/TPAMI.2015.2481415			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26415156				2022-12-18	WOS:000377897100002
J	Munoz-Gonzalez, L; Lazaro-Gredilla, M; Figueiras-Vidal, AR				Munoz-Gonzalez, Luis; Lazaro-Gredilla, Miguel; Figueiras-Vidal, Anibal R.			Laplace Approximation for Divisive Gaussian Processes for Nonstationary Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian processes; nonstationary regression; Laplace approximation; heteroscedastic regression		The standard Gaussian Process regression (GP) is usually formulated under stationary hypotheses: The noise power is considered constant throughout the input space and the covariance of the prior distribution is typically modeled as depending only on the difference between input samples. These assumptions can be too restrictive and unrealistic for many real-world problems. Although nonstationarity can be achieved using specific covariance functions, they require a prior knowledge of the kind of nonstationarity, not available for most applications. In this paper we propose to use the Laplace approximation to make inference in a divisive GP model to perform nonstationary regression, including heteroscedastic noise cases. The log-concavity of the likelihood ensures a unimodal posterior and makes that the Laplace approximation converges to a unique maximum. The characteristics of the likelihood also allow to obtain accurate posterior approximations when compared to the Expectation Propagation (EP) approximations and the asymptotically exact posterior provided by a Markov Chain Monte Carlo implementation with Elliptical Slice Sampling (ESS), but at a reduced computational load with respect to both, EP and ESS.	[Munoz-Gonzalez, Luis; Lazaro-Gredilla, Miguel; Figueiras-Vidal, Anibal R.] Univ Carlos III Madrid, Dept Signal Theory & Commun, E-28903 Getafe, Spain	Universidad Carlos III de Madrid	Munoz-Gonzalez, L; Lazaro-Gredilla, M; Figueiras-Vidal, AR (corresponding author), Univ Carlos III Madrid, Dept Signal Theory & Commun, E-28903 Getafe, Spain.	lmunoz@tsc.uc3m.es; miguel@tsc.uc3m.es; arfv@tsc.uc3m.es	Figueiras-Vidal, Anibal R./AAA-1995-2019	Munoz-Gonzalez, Luis/0000-0001-6093-5922; FIGUEIRAS, ANIBAL RAMON/0000-0001-7068-9884	Spanish Government [TIN 2011/24533]	Spanish Government(Spanish GovernmentEuropean Commission)	The authors would like to thank the reviewers for their valuable comments to improve the quality of the manuscript and for proposing some interesting extensions of this work that have been included in the conclusions. This work was supported by the Spanish Government under Project TIN 2011/24533.	Adams R.P., 2008, P 25 INT C MACH LEAR, P1; Bache K., 2015, UCI MACHINE LEARNING; Drucker H, 1997, ADV NEUR IN, V9, P155; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Goldberg PW, 1998, ADV NEUR IN, V10, P493; HINKLEY DV, 1969, BIOMETRIKA, V56, P635, DOI 10.1093/biomet/56.3.635; Kersting K., 2007, P 24 INT C MACH LEAR, P393, DOI DOI 10.1145/1273496.1273546; Lazaro-Gredilla M., 2011, P INT C MACH LEARN M, P841; Lazaro-Gredilla M, 2010, J MACH LEARN RES, V11, P1865; Le Q.V., 2005, P 22 INT C MACHINE L, P489, DOI [10.1145/1102351.1102413, DOI 10.1145/1102351.1102413]; Munoz-Gonzalez L., 2011, 2011 IEEE INT WORKSH, P1, DOI 10.1109/MLSP.2011.6064576; Munoz-Gonzalez L, 2014, IEEE T NEUR NET LEAR, V25, P1991, DOI 10.1109/TNNLS.2014.2301951; Murray I., 2010, JMLR W CP, V9, P541; Quadrianto N, 2009, IEEE DATA MINING, P938, DOI 10.1109/ICDM.2009.82; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Seeger MW, 2008, J MACH LEARN RES, V9, P759; Snelson Edward, 2006, ADV NEURAL INFORM PR, V3; Williams CKI, 1996, ADV NEUR IN, V8, P514; Yuan M, 2004, STAT PROBABIL LETT, V69, P11, DOI 10.1016/j.spl.2004.03.009	20	11	11	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					618	624		10.1109/TPAMI.2015.2452914	http://dx.doi.org/10.1109/TPAMI.2015.2452914			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	26890623	Green Submitted			2022-12-18	WOS:000370738900015
J	Mottaghi, R; Fidler, S; Yuille, A; Urtasun, R; Parikh, D				Mottaghi, Roozbeh; Fidler, Sanja; Yuille, Alan; Urtasun, Raquel; Parikh, Devi			Human-Machine CRFs for Identifying Bottlenecks in Scene Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; semantic segmentation; object detection; scene recognition; human-machine hybrid	CONTOURS	Recent trends in image understanding have pushed for scene understanding models that jointly reason about various tasks such as object detection, scene recognition, shape analysis, contextual reasoning, and local appearance based classifiers. In this work, we are interested in understanding the roles of these different tasks in improved scene understanding, in particular semantic segmentation, object detection and scene recognition. Towards this goal, we "plug-in" human subjects for each of the various components in a conditional random field model. Comparisons among various hybrid human-machine CRFs give us indications of how much "head room" there is to improve scene understanding by focusing research efforts on various individual tasks.	[Mottaghi, Roozbeh] Allen Inst Artificial Intelligence, Seattle, WA 98103 USA; [Yuille, Alan] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA USA; [Fidler, Sanja; Urtasun, Raquel] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Parikh, Devi] Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA USA	University of California System; University of California Los Angeles; University of Toronto; Virginia Polytechnic Institute & State University	Mottaghi, R (corresponding author), Allen Inst Artificial Intelligence, Seattle, WA 98103 USA.	roozbeh@cs.stanford.edu; fidler@cs.toronto.edu; yuille@stat.ucla.edu; rurtasun@ttic.edu; parikh@vt.edu		Yuille, Alan L./0000-0001-5207-9249	NSF [IIS-1115719]; ONR [N00014-12-1-0883]	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research)	This work was supported in part by NSF IIS-1115719. The first author was partly supported by ONR grant N00014-12-1-0883. The authors would also like to thank Jian Yao and Xianjie Chen for their help with some of the experiments.	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; BACHMANN T, 1991, European Journal of Cognitive Psychology, V3, P87, DOI 10.1080/09541449108406221; Barrow H. G., 1978, AITN157 STANF RES I; Boix X, 2012, INT J COMPUT VISION, V96, P83, DOI 10.1007/s11263-011-0449-8; Brox T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2225, DOI 10.1109/CVPR.2011.5995659; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fowlkes C. C., 2005, THESIS; Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048; Gould S., 2009, ADV NEURAL INFORM PR, V22, P655; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hazan T., 2010, ADV NEURAL INFORM PR, P838; Heitz G., 2009, ADV NEURAL INFORM PR, V21, P641; Hoiem D., 2008, 2008 IEEE C COMPUTER, P1, DOI DOI 10.1109/CVPR.2008.4587587; Kohli P., 2007, P IEEE C COMP VIS PA, P1; Kumar S, 2005, IEEE I CONF COMP VIS, P1284; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262; Li C., 2010, ADV NEURAL INFORM PR, V23, P1351; Li FF, 2002, P NATL ACAD SCI USA, V99, P9596, DOI 10.1073/pnas.092277599; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Mottaghi R, 2013, PROC CVPR IEEE, P3143, DOI 10.1109/CVPR.2013.404; Oliva A, 2000, COGNITIVE PSYCHOL, V41, P176, DOI 10.1006/cogp.1999.0728; Parikh D, 2011, IEEE I CONF COMP VIS, P519, DOI 10.1109/ICCV.2011.6126283; Parikh D, 2011, PROC CVPR IEEE, P1425, DOI 10.1109/CVPR.2011.5995450; Parikh D, 2010, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2010.5539920; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Rivest J, 1996, VISION RES, V36, P53, DOI 10.1016/0042-6989(95)00056-6; Schwing A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1833, DOI 10.1109/CVPR.2011.5995642; Shotton J, 2007, INT J COMPUT VISION, V81, P2, DOI DOI 10.1007/S11263-007-0109-1; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; Torralba A, 2009, VISUAL NEUROSCI, V26, P123, DOI 10.1017/S0952523808080930; Torralba Antonio, 2005, ADV NEURAL INFORM PR, P1401; Wojek C, 2008, LECT NOTES COMPUT SC, V5305, P733, DOI 10.1007/978-3-540-88693-8_54; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; YANG Y, 2011, CVPR, P1385; Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739; Zitnick CL, 2012, PROC CVPR IEEE, P622, DOI 10.1109/CVPR.2012.6247729	44	11	12	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					74	87		10.1109/TPAMI.2015.2437377	http://dx.doi.org/10.1109/TPAMI.2015.2437377			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656579				2022-12-18	WOS:000366669200006
J	Wang, J; Fan, W; Ye, JP				Wang, Jie; Fan, Wei; Ye, Jieping			Fused Lasso Screening Rules via the Monotonicity of Subdifferentials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fused lasso; screening; l(1)-regularization	CLASSIFICATION	Fused Lasso is a popular regression technique that encodes the smoothness of the data. It has been applied successfully to many applications with a smooth feature structure. However, the computational cost of the existing solvers for fused Lasso is prohibitive when the feature dimension is extremely large. In this paper, we propose novel screening rules that are able to quickly identity the adjacent features with the same coefficients. As a result, the number of variables to be estimated can be significantly reduced, leading to substantial savings in computational cost and memory usage. To the best of our knowledge, the proposed approach is the first attempt to develop screening methods for the fused Lasso problem with general data matrix. Our major contributions are: 1) we derive a new dual formulation of fused Lasso that comes with several desirable properties; 2) we show that the new dual formulation of fused Lasso is equivalent to that of the standard Lasso by two affine transformations; 3) we propose a novel framework for developing effective and efficient screening rules for fused Lasso via the monotonicity of the subdifferentials (FLAMS). Some appealing features of FLAMS are: 1) our methods are safe in the sense that the detected adjacent features are guaranteed to have the same coefficients; 2) the dataset needs to be scanned only once to run the screening, whose computational cost is negligible compared to that of solving the fused Lasso; (3) FLAMS is independent of the solvers and can be integrated with any existing solvers. We have evaluated the proposed FLAMS rules on both synthetic and real datasets. The experiments indicate that FLAMS is very effective in identifying the adjacent features with the same coefficients. The speedup gained by FLAMS can be orders of magnitude.	[Wang, Jie; Ye, Jieping] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA; [Wang, Jie; Ye, Jieping] Arizona State Univ, Ctr Evolutionary Med & Informat, Biodesign Inst, Tempe, AZ 85287 USA; [Fan, Wei] Huawei Noahs Ark Lab, Hong Kong, Hong Kong, Peoples R China	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe; Huawei Technologies	Wang, J (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.	jie.wang.ustc@asu.edu; david.fanwei@huawei.com; jieping.ye@asu.edu			NSF [IIS-0953662, IIS-1421057]; NIH 'Big Data to Knowledge' (BD2K) Center of Excellence - cross-NIH consortium [U54 EB020403]; NIBIB; NCI; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB020403] Funding Source: NIH RePORTER; NATIONAL LIBRARY OF MEDICINE [R01LM010730] Funding Source: NIH RePORTER	NSF(National Science Foundation (NSF)); NIH 'Big Data to Knowledge' (BD2K) Center of Excellence - cross-NIH consortium; NIBIB(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NCI(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL LIBRARY OF MEDICINE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM))	This work was supported in part by NSF grants (IIS-0953662 and IIS-1421057) and NIH 'Big Data to Knowledge' (BD2K) Center of Excellence grant U54 EB020403, funded by a cross-NIH consortium including NIBIB and NCI. Jieping Ye is the corresponding author of the article.	Ahmed A, 2009, P NATL ACAD SCI USA, V106, P11878, DOI 10.1073/pnas.0901910106; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bauschke HH, 2011, CMS BOOKS MATH, P1, DOI 10.1007/978-1-4419-9467-7; Baushke H., 2011, CONVEX ANAL MONOTONE; Condat L, 2013, IEEE SIGNAL PROC LET, V20, P1054, DOI 10.1109/LSP.2013.2278339; El Ghaoui L, 2012, PAC J OPTIM, V8, P667; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Guler O., 2010, FDN OPTIMIZATION; Liu J., 2009, SLEP SPARSE LEARNING; Liu J., 2010, PROC 16 ACM SIGKDD I, P323; Nutt CL, 2003, CANCER RES, V63, P1602; Ogawa K., 2013, P 30 INT C MACH LEAR, P1382; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Rapaport F, 2008, BIOINFORMATICS, V24, pI375, DOI 10.1093/bioinformatics/btn188; Rinaldo A, 2009, ANN STAT, V37, P2922, DOI 10.1214/08-AOS665; Rockafellar R., 1974, P SIAM C BOARD MATH; Rockafellar R. T., 1970, CONVEX ANAL; Ruszczynski A. P., 2006, NONLINEAR OPTIMIZATI; Tibshirani R, 2005, J R STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tibshirani R, 2008, BIOSTATISTICS, V9, P18, DOI 10.1093/biostatistics/kxm013; Tibshirani R, 2012, J R STAT SOC B, V74, P245, DOI 10.1111/j.1467-9868.2011.01004.x; Tibshirani RJ, 2011, ANN STAT, V39, P1335, DOI 10.1214/11-AOS878; Wang J., 2014, ADV NEURAL INFORM PR, P2132; Wang J., J MACH LEAR IN PRESS; Wang J, 2014, PR MACH LEARN RES, V32, P523; Wang Jie, 2013, ADV NEURAL INFORM PR; Xiang Z., 2011, ADV NEURAL INFORM PR, V24, P900; Yanai H, 2011, STAT SOC BEHAV SC, P1, DOI 10.1007/978-1-4419-9887-3	29	11	11	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1806	1820		10.1109/TPAMI.2014.2388203	http://dx.doi.org/10.1109/TPAMI.2014.2388203			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353128				2022-12-18	WOS:000359216600006
J	Blomstedt, P; Tang, J; Xiong, J; Granlund, C; Corander, J				Blomstedt, Paul; Tang, Jing; Xiong, Jie; Granlund, Christian; Corander, Jukka			A Bayesian Predictive Model for Clustering Data of Mixed Discrete and Continuous Type	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes methods; predictive models; unsupervised learning; mixed distributions	PARTITION MODELS; IDENTIFICATION	Advantages of model-based clustering methods over heuristic alternatives have been widely demonstrated in the literature. Most model-based clustering algorithms assume that the data are either discrete or continuous, possibly allowing both types to be present in separate features. In this paper, we introduce a model-based approach for clustering feature vectors of mixed type, allowing each feature to simultaneously take on both categorical and real values. Such data may be encountered, for instance, in chemical and biological analyses, in the analysis of survey data, as well as in image analysis. Our model is formulated within a Bayesian predictive framework, where clustering solutions correspond to random partitions of the data. Using conjugate analysis, the posterior probability for each possible partition can be determined analytically, enabling the utilization of efficient computational search strategies for finding the posterior optimal partition. The derived model is illustrated using several synthetic and real datasets.	[Blomstedt, Paul] Aalto Univ, HIIT, Dept Informat & Comp Sci, FI-00076 Espoo, Finland; [Blomstedt, Paul; Granlund, Christian; Corander, Jukka] Abo Akad Univ, Dept Math, FI-20500 Turku, Finland; [Tang, Jing] Univ Helsinki, Inst Mol Med Finland FIMM, FI-00014 Helsinki, Finland; [Xiong, Jie; Corander, Jukka] Univ Helsinki, Dept Math & Stat, FI-00014 Helsinki, Finland	Aalto University; Abo Akademi University; University of Helsinki; University of Helsinki	Blomstedt, P (corresponding author), Aalto Univ, HIIT, Dept Informat & Comp Sci, FI-00076 Espoo, Finland.	paul.blomstedt@aalto.fi; jing.tang@helsinki.fi; jie.xiong@helsinki.fi; cgranlun@gmail.com; jukka.corander@helsinki.fi	Tang, Jing/H-4084-2012; Tang, Jing/W-1764-2019; tang, jing/HHR-9815-2022	Tang, Jing/0000-0001-7480-7710; Tang, Jing/0000-0001-7480-7710; 	Academy of Finland [251170]; ERC [239784]	Academy of Finland(Academy of Finland); ERC(European Research Council (ERC)European Commission)	The authors would like to thank Pekka Marttinen and Jukka Kohonen for their helpful input on matters of implementation and the National Bureau of Investigation Forensic Laboratory, Finland (NBI) for providing the amphetamine data. Three anonymous referees are gratefully acknowledged for their insightful comments which helped to improve the manuscript. The research was funded by Academy of Finland grant no. 251170 and ERC grant no. 239784.	Abramowitz M., 1965, HDB MATH FUNCTIONS F; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; BARRY D, 1992, ANN STAT, V20, P260, DOI 10.1214/aos/1176348521; Bernardo J. M., 1994, BAYESIAN THEORY; Blomstedt P, 2014, J CHEMOMETR, V28, P52, DOI 10.1002/cem.2566; Bock HH, 1996, COMPUT STAT DATA AN, V23, P5, DOI 10.1016/0167-9473(96)88919-5; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV, ppp153; Chewapreecha C, 2014, NAT GENET, V46, P305, DOI 10.1038/ng.2895; Cole M.D., 2003, ANAL CONTROLLED SUBS; Corander Jukka, 2009, Advances in Data Analysis and Classification, V3, P3, DOI 10.1007/s11634-009-0036-9; Corander J, 2008, COMPUTATION STAT, V23, P111, DOI 10.1007/s00180-007-0072-x; Corander J, 2007, B MATH BIOL, V69, P797, DOI 10.1007/s11538-006-9161-1; Corander J, 2006, MOL ECOL, V15, P2833, DOI 10.1111/j.1365-294X.2006.02994.x; Corander J, 2013, STAT COMPUT, V23, P59, DOI 10.1007/s11222-011-9291-7; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Eilers PHC., 2005, BASELINE CORRECTION; FEUERVERGER A, 1979, BIOMETRIKA, V66, P655, DOI 10.1093/biomet/66.3.655; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Hanage WP, 2009, SCIENCE, V324, P1454, DOI 10.1126/science.1171908; Harris D. C., 2010, QUANTITATIVE CHEM AN; HARTIGAN JA, 1990, COMMUN STAT THEORY, V19, P2745, DOI 10.1080/03610929008830345; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Kaas R., 2009, MODERN ACTUARIAL RIS; KEDEM B, 1990, J GEOPHYS RES-ATMOS, V95, P1965, DOI 10.1029/JD095iD02p01965; Kohonen J., 2013, COMM STAT T IN PRESS; KOOPMANS LH, 1969, AM MATH MON, V76, P297, DOI 10.2307/2316383; Kumar S., 2004, MIXED TYPE DISTRIBUT; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Marttinen P, 2009, IEEE T PATTERN ANAL, V31, P74, DOI 10.1109/TPAMI.2008.53; Morlini I, 2012, ADV DATA ANAL CLASSI, V6, P5, DOI 10.1007/s11634-011-0101-z; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Pitman J., 2006, LECT NOTES MATH, V1875; Quintana FA, 2003, J ROY STAT SOC B, V65, P557, DOI 10.1111/1467-9868.00402; ROTA GC, 1964, AM MATH MON, V71, P498, DOI 10.2307/2312585; Schmidhuber J., 2012, MULTICOLUMN DEEP NEU; Tang J, 2007, STAT APPL GENET MOL, V6; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967	41	11	12	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					489	498		10.1109/TPAMI.2014.2359431	http://dx.doi.org/10.1109/TPAMI.2014.2359431			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353256				2022-12-18	WOS:000349626200001
J	Kim, K; Lee, J				Kim, Kyoungok; Lee, Jaewook			Nonlinear Dynamic Projection for Noise Reduction of Dispersed Manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifold learning; dimension reduction; dispersed manifold; dynamical system	DIMENSIONALITY REDUCTION; SUPPORT; CLASSIFICATION	The search for a low-dimensional structure in high-dimensional data is one of the fundamental tasks in machine learning and pattern recognition. Manifold learning algorithms have recently emerged as alternatives to traditional linear dimension reduction techniques. In this paper, we propose a novel projection method that can be combined with any manifold learning methods to improve their dimension reduction performance when applied to high-dimensional data with a high level of noise. The method first builds a dispersion function that describes the distribution of dispersed manifold where the data lie. It then projects the noisy data onto a region wrapping the true manifold sufficiently close to it by applying a dynamical projection system associated with the constructed dispersion function. The effectiveness of the proposed projection method is validated by applying it to some real-world data sets with promising results.	[Kim, Kyoungok] POST ECH, Dept Ind & Management Engn, Pohang 790784, Kyungbuk, South Korea; [Lee, Jaewook] Seoul Natl Univ, Dept Ind Engn, Seoul 151744, South Korea	Pohang University of Science & Technology (POSTECH); Seoul National University (SNU)	Kim, K (corresponding author), POST ECH, Dept Ind & Management Engn, Pohang 790784, Kyungbuk, South Korea.	foriness@postech.ac.kr; jaewook@snu.ac.kr	; Lee, Jaewook/A-7355-2013	Kim, Kyoungok/0000-0002-0196-3832; Lee, Jaewook/0000-0001-5720-8337	National Research Foundation of Korea (NRF) - Korean government (MEST) [2011-0017657]	National Research Foundation of Korea (NRF) - Korean government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaNational Research Foundation of KoreaKorean Government)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MEST) (No. 2011-0017657).	Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chang H, 2006, PATTERN RECOGN, V39, P1053, DOI 10.1016/j.patcog.2005.07.011; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Hastie T, 2009, ELEMENTS STAT LEARNI; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jung KH, 2013, INFORM SCIENCES, V247, P144, DOI 10.1016/j.ins.2013.05.001; Jung KH, 2010, PATTERN RECOGN, V43, P1975, DOI 10.1016/j.patcog.2009.12.010; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee D, 2007, PATTERN RECOGN, V40, P41, DOI 10.1016/j.patcog.2006.06.008; Lee D, 2010, IEEE T KNOWL DATA EN, V22, P900, DOI 10.1109/TKDE.2009.140; Lee J, 2005, IEEE T PATTERN ANAL, V27, P461, DOI 10.1109/TPAMI.2005.47; Lee J, 2002, IEEE T CIRCUITS-I, V49, P196, DOI 10.1109/81.983867; Lee J, 2006, IEEE T PATTERN ANAL, V28, P1869, DOI 10.1109/TPAMI.2006.225; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217; Nocedal J., 2006, NUMERICAL OPTIMIZATI; Park J, 2004, PROC CVPR IEEE, P452; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Sra S, 2012, OPTIMIZATION FOR MACHINE LEARNING, P1; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Tenenbaum JB, 1998, ADV NEUR IN, V10, P682; Yin JS, 2008, PATTERN RECOGN LETT, V29, P1613, DOI 10.1016/j.patrec.2008.04.002; Zhang Z., 2007, P ADV NEUR INF PROC, P1593; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154	27	11	11	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2303	2309		10.1109/TPAMI.2014.2318727	http://dx.doi.org/10.1109/TPAMI.2014.2318727			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353068				2022-12-18	WOS:000343702400014
J	Sizintsev, M; Wildes, RP				Sizintsev, Mikhail; Wildes, Richard P.			Spacetime Stereo and 3D Flow via Binocular Spatiotemporal Orientation Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; motion; spacetime; spatiotemporal oriented energy; scene flow; multilayer reconstruction; transparency; specular	DEPTH MAPS RECOVERY; SCENE FLOW; MOTION; DISPARITY; FRAMEWORK; RECOGNITION; INTEGRATION; FUSION	This paper presents a novel approach to recovering estimates of 3D structure and motion of a dynamic scene from a sequence of binocular stereo images. The approach is based on matching spatiotemporal orientation distributions between left and right temporal image streams, which encapsulates both local spatial and temporal structure for disparity estimation. By capturing spatial and temporal structure in this unified fashion, both sources of information combine to yield disparity estimates that are naturally temporal coherent, while helping to resolve matches that might be ambiguous when either source is considered alone. Further, by allowing subsets of the orientation measurements to support different disparity estimates, an approach to recovering multilayer disparity from spacetime stereo is realized. Similarly, the matched distributions allow for direct recovery of dense, robust estimates of 3D scene flow. The approach has been implemented with real-time performance on commodity GPUs using OpenCL. Empirical evaluation shows that the proposed approach yields qualitatively and quantitatively superior estimates in comparison to various alternative approaches, including the ability to provide accurate multilayer estimates in the presence of (semi)transparent and specular surfaces.	[Sizintsev, Mikhail] SRI Int Sarnoff, Princeton, NJ 08540 USA; [Wildes, Richard P.] York Univ, Dept Comp Sci & Engn, Toronto, ON M3J 2R7, Canada; [Wildes, Richard P.] York Univ, Ctr Vis Res, Toronto, ON M3J 2R7, Canada	SRI International; York University - Canada; York University - Canada	Sizintsev, M (corresponding author), SRI Int Sarnoff, Princeton, NJ 08540 USA.	wildes@cse.yorku.ca			CRD - NSERC; CRD - MDA	CRD - NSERC; CRD - MDA	This work was supported by a CRD grant to R. Wildes, as jointly funded by NSERC and MDA.	Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; Bigun J., 1998, VISION DIRECTION; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bleyer Michael, 2009, 2009 Proceedings of 6th International Symposium on Image and Signal Processing and Analysis, P383; Borga M., 1999, P 11 SCAN C IM AN; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Cannons KJ, 2014, IEEE T PATTERN ANAL, V36, P784, DOI 10.1109/TPAMI.2013.233; Chomat O, 2000, LECT NOTES COMPUT SC, V1842, P487; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; Demirdjian D, 2002, INT J COMPUT VISION, V47, P219, DOI 10.1023/A:1014502126337; Derpanis KG, 2013, IEEE T PATTERN ANAL, V35, P527, DOI 10.1109/TPAMI.2012.141; Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221; Derpanis KG, 2009, PROC CVPR IEEE, P232, DOI 10.1109/CVPRW.2009.5206817; Derpanis KG, 2010, IEEE T PATTERN ANAL, V32, P1310, DOI 10.1109/TPAMI.2010.64; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Franke U, 2005, LECT NOTES COMPUT SC, V3663, P216; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gong ML, 2006, LECT NOTES COMPUT SC, V3953, P564, DOI 10.1007/11744078_44; Granlund G., 1995, SIGNAL PROCESS COMPU; Hanna K. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P357, DOI 10.1109/ICCV.1993.378192; Horn B., 1986, ROBOT VISION, P1; Hough PVC, 1959, P INT C HIGH EN ACC, P5; Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000; Hung CH, 2013, INT J COMPUT VISION, V102, P271, DOI 10.1007/s11263-012-0559-y; Isard M, 2006, LECT NOTES COMPUT SC, V3852, P32; Jiang H., 2012, P 12 EUR C COMP VIS, P601; JONES DG, 1992, LECT NOTES COMPUT SC, V588, P395; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Larsen ES, 2007, IEEE I CONF COMP VIS, P1440; Lee S., 2010, INT WORKSH ADV IM TE, p[149, 1]; Lei C, 2009, IEEE I CONF COMP VIS, P1570, DOI 10.1109/ICCV.2009.5459357; Leung C, 2004, INT C PATT RECOG, P72, DOI 10.1109/ICPR.2004.1333708; Malassiotis S, 1997, COMPUT VIS IMAGE UND, V65, P79, DOI 10.1006/cviu.1996.0481; Mandelbaum R., 1999, P IEEE 7 INT C COMP, P544; Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429; Pearce P., 1979, POLYHEDRA PRIMER; Pons JP, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P597; Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510; Scharr H, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P220, DOI 10.1109/MOTION.2002.1182240; Scharr H., 2006, P VIS MOD VIS 06, P81; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Shizawa M., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P447, DOI 10.1109/ICCV.1993.378182; Sizintsev M, 2012, IEEE T PATTERN ANAL, V34, P1206, DOI 10.1109/TPAMI.2011.202; Sizintsev M, 2011, IEEE I CONF COMP VIS, P1140, DOI 10.1109/ICCV.2011.6126362; Sizintsev M, 2010, IMAGE VISION COMPUT, V28, P352, DOI 10.1016/j.imavis.2009.06.008; Stein GP, 1998, PROC CVPR IEEE, P211, DOI 10.1109/CVPR.1998.698611; Strang G., 1988, LINEAR ALGEBRA APPL, V3rd; Strecha C, 2002, LECT NOTES COMPUT SC, V2351, P170; SUDHIR G, 1995, J OPT SOC AM A, V12, P2564, DOI 10.1364/JOSAA.12.002564; Tsin YH, 2006, IEEE T PATTERN ANAL, V28, P290, DOI 10.1109/TPAMI.2006.42; VALGAERTS L, 2010, P 11 EUR C COMP VIS, V6314, P568; Wedel A, 2008, LECT NOTES COMPUT SC, V5302, P739, DOI 10.1007/978-3-540-88682-2_56; Williams O, 2005, PROC CVPR IEEE, P250; XIONG W, 2007, CVPR, P1; Yang M., 2010, P BRIT MACH VIS C, P671; Yang WZ, 2012, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2012.6247835; Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41; Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52; Zhang L, 2003, PROC CVPR IEEE, P367; Zhang Y, 2001, PROC CVPR IEEE, P778; Zhu JJ, 2009, PROC CVPR IEEE, P453, DOI 10.1109/CVPRW.2009.5206520	63	11	12	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2241	2254		10.1109/TPAMI.2014.2321373	http://dx.doi.org/10.1109/TPAMI.2014.2321373			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353064				2022-12-18	WOS:000343702400010
J	Puig, L; Guerrero, JJ; Daniilidis, K				Puig, Luis; Guerrero, Jose J.; Daniilidis, Kostas			Scale Space for Camera Invariant Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Central projection systems; image smoothing; linear diffusion equation; Laplace-Beltrami operator; scale space		In this paper we propose a new approach to compute the scale space of any central projection system, such as catadioptric, fisheye or conventional cameras. Since these systems can be explained using a unified model, the single parameter that defines each type of system is used to automatically compute the corresponding Riemannian metric. This metric, is combined with the partial differential equations framework on manifolds, allows us to compute the Laplace-Beltrami (LB) operator, enabling the computation of the scale space of any central projection system. Scale space is essential for the intrinsic scale selection and neighborhood description in features like SIFT. We perform experiments with synthetic and real images to validate the generalization of our approach to any central projection system. We compare our approach with the best-existing methods showing competitive results in all type of cameras: catadioptric, fisheye, and perspective.	[Puig, Luis; Daniilidis, Kostas] Univ Penn, Grasp Lab, Philadelphia, PA 19104 USA; [Guerrero, Jose J.] I3A Univ Zaragoza, Inst Invest Ingn Aragon, Dept Informat & Ingn Sistemas, Zaragoza, Spain; [Daniilidis, Kostas] Series IEEE Workshops Omnidirect Vis, Hiroshima, Japan; [Daniilidis, Kostas] Third Symposium 3D Data Proc Visualizat & Transmi, Freiburg, Germany; [Daniilidis, Kostas] 11th European Conf Comp Vis, Freiburg, Germany; [Daniilidis, Kostas] IEEE, New York, NY USA	University of Pennsylvania	Puig, L (corresponding author), Univ Penn, Grasp Lab, 3330 Walnut St,L402, Philadelphia, PA 19104 USA.	luispuig@seas.upenn.edu; jguerrer@unizar.es; kostas@cis.upenn.edu	Guerrero, Jose J/K-5435-2014	Guerrero, Jose J/0000-0001-5209-2267; Daniilidis, Kostas/0000-0003-0498-0758	FEDER funds; TAMA funds; DGA FSE;  [DPI2012-31781];  [NSF-OIA-1028009];  [ARL MAST-CTA W911NF-08-2-0004];  [NSF-DGE-0966142]	FEDER funds(European Commission); TAMA funds; DGA FSE; ; ; ; 	This work has been supported by project DPI2012-31781, including FEDER funds and and TAMA funds and by DGA FSE(group T04). Puig and Daniilidis gratefully acknowledge support by the following grants: NSF-OIA-1028009, ARL MAST-CTA W911NF-08-2-0004, and NSF-DGE-0966142.	Arican Z., 2010, TECHNICAL REPORT; Arican Z, 2012, IEEE T IMAGE PROCESS, V21, P2412, DOI 10.1109/TIP.2012.2185937; Baker S, 2001, MG COMP SCI, P39; Barreto JP, 2001, PROC CVPR IEEE, P422; Bertalmio M, 2001, J COMPUT PHYS, V174, P759, DOI 10.1006/jcph.2001.6937; Bogdanova I, 2007, IEEE T IMAGE PROCESS, V16, P1888, DOI 10.1109/TIP.2007.899008; Bulow T, 2004, IEEE T PATTERN ANAL, V26, P1650, DOI 10.1109/TPAMI.2004.129; Courbon J, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1689; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; Cruz-Mota J, 2012, INT J COMPUT VISION, V98, P217, DOI 10.1007/s11263-011-0505-4; Daniilidis K, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P3, DOI 10.1109/OMNVIS.2002.1044483; Fleck M., 1995, TECHNICAL REPORT; GEYER C, 2000, EUR C COMP VIS ECCV, V2, P445; Hansen P, 2007, IEEE I CONF COMP VIS, P512; Hansen P, 2010, INT J ROBOT RES, V29, P267, DOI 10.1177/0278364909356484; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lourenco M, 2012, IEEE INT CONF ROBOT, P2189, DOI 10.1109/ICRA.2012.6225134; Lourenco M, 2012, IEEE T ROBOT, V28, P752, DOI 10.1109/TRO.2012.2184952; Lourenco M, 2010, IEEE INT CONF ROBOT, P1028, DOI 10.1109/ROBOT.2010.5509282; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Micusik B, 2003, PROC CVPR IEEE, P485; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Puig L, 2011, IEEE I CONF COMP VIS, P1599, DOI 10.1109/ICCV.2011.6126420; Puig L, 2011, INT J COMPUT VISION, V93, P101, DOI 10.1007/s11263-010-0411-1; Vedaldi A., 2007, 070012 UCLA CSD; Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Ying XG, 2004, LECT NOTES COMPUT SC, V3021, P442	32	11	12	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1832	1846		10.1109/TPAMI.2014.2306421	http://dx.doi.org/10.1109/TPAMI.2014.2306421			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352235	Green Submitted			2022-12-18	WOS:000340210100010
J	Sun, M; Kim, BS; Kohli, P; Savarese, S				Sun, Min; Kim, Byung-soo; Kohli, Pushmeet; Savarese, Silvio			Relating Things and Stuff via Object Property Interactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; semantic labeling; segmentation; graph-cut		In the last few years, substantially different approaches have been adopted for segmenting and detecting "things" (object categories that have a well defined shape such as people and cars) and "stuff" (object categories which have an amorphous spatial extent such as grass and sky). While things have been typically detected by sliding window or Hough transform based methods, detection of stuff is generally formulated as a pixel or segment-wise classification problem. This paper proposes a framework for scene understanding that models both things and stuff using a common representation while preserving their distinct nature by using a property list. This representation allows us to enforce sophisticated geometric and semantic relationships between thing and stuff categories via property interactions in a single graphical model. We use the latest advances made in the field of discrete optimization to efficiently perform maximum a posteriori (MAP) inference in this model. We evaluate our method on the Stanford dataset by comparing it against state-of-the-art methods for object segmentation and detection. We also show that our method achieves competitive performances on the challenging PASCAL '09 segmentation dataset.	[Sun, Min] Univ Washington, Seattle, WA 98195 USA; [Kim, Byung-soo] Univ Michigan, Stanford, CA 94305 USA; [Kim, Byung-soo; Savarese, Silvio] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Kohli, Pushmeet] Microsoft Res, Cambridge CB1 2FB, England	University of Washington; University of Washington Seattle; University of Michigan System; University of Michigan; Stanford University; Microsoft	Sun, M (corresponding author), Univ Washington, AC101 Paul G Allen Ctr, Seattle, WA 98195 USA.	sunmin@cs.washington.edu; bsookim@umich.edu; pkohli@microsoft.com; ssilvio@stanford.edu			US National Science Foundation (NSF) CAREER [1054127]; ARO [W911NF-09-1-0310]; ONR [N00014-13-1-0761]	US National Science Foundation (NSF) CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); ARO; ONR(Office of Naval Research)	The authors would like to acknowledge the support of US National Science Foundation (NSF) CAREER grant (#1054127), ARO grant (W911NF-09-1-0310), and ONR grant (N00014-13-1-0761).	Bao S., 2010, P IEEE C COMP VIS PA; Bao S.Y., 2011, P IEEE C COMP VIS PA; BARINOVA O, 2010, P IEEE C COMP VIS PA; Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Bosch X.B., 2010, P IEEE C COMP VIS PA; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Desai C., 2009, P 11 IEEE C COMP VIS; Divvala S.K., 2009, P IEEE C COMP VIS PA; Everingham M., 2009, PASCAL VIS OBJ CLASS; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gall J., 2009, P IEEE C COMP VIS PA; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Gould S., 2009, P 11 IEEE C COMP VIS; Gould S., 2009, STAIR VISION LIB V2; Gould S., 2009, P 23 ANN C NEUR INF; Grauman K., 2005, P 10 IEEE INT C COMP; Gupta A., 2008, P EUR C COMP VIS ECC; He X., 2004, P IEEE C COMP VIS PA; Heitz G., 2008, P 10 EUR C COMP VI 1; Heitz G., 2008, P ANN C NEUR INF PRO; Hoiem D., 2008, P IEEE C COMP VIS PA; HOIEM D, 2006, P IEEE C COMP VIS PA; KOHLI P., 2008, P IEEE C COMP VIS PA; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Ladicky L., 2010, P EUR C COMP VIS ECC; Ladicky L., 2010, P 11 EUR C COMP VIS; LEE Y. J., 2010, P IEEE C COMP VIS PA; LEIBE B., 2004, P ECCV WORKSH STAT L; Li CC, 2012, IEEE T PATTERN ANAL, V34, P1394, DOI 10.1109/TPAMI.2011.232; Li FF, 2010, STUD COMPUT INTELL, V285, P157; Li Li-Jia, 2009, P IEEE C COMP VIS PA, P1; Maji S., 2009, P IEEE C COMP VIS PA; Munoz D., 2010, P EUR C COMP VIS ECC; Rabinovich A., 2007, P 11 IEEE C COMP VIS; Rother C., 2007, P IEEE C COMP VIS PA; Shotton J, 2008, P IEEE C COMP VIS PA; SHOTTON J., 2006, P EUR C COMP VIS ECC; Sun M., 2010, P 11 EUR C COMP VI 5; Sun M., 2009, P IEEE C COMP VIS PA; Sun M., 2010, P BRIT MACH VIS C BM; Tighe J., 2010, P EUR C COMP VIS ECC; Tsochantaridis I., 2004, P 21 INT C MACH LEAR; Winn J., 2006, P IEEE C COMP VIS PA; Xiang Y., 2012, P IEEE C COMP VIS PA; Yao Y., 2012, P IEEE C COMP VIS PA	47	11	15	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1370	1383		10.1109/TPAMI.2013.193	http://dx.doi.org/10.1109/TPAMI.2013.193			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353309	Green Submitted			2022-12-18	WOS:000338209900007
J	Zhang, C; Sato, I				Zhang, Cherry; Sato, Imari			Image-Based Separation of Reflective and Fluorescent Components Using Illumination Variant and Invariant Color	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Reflectance components separation; fluorescence emission; diffuse reflection; illumination	ALGORITHMS	Traditionally, researchers tend to exclude fluorescence from color appearance algorithms in computer vision and image processing because of its complexity. In reality, fluorescence is a very common phenomenon observed in many objects, from gems and corals, to different kinds of writing paper, and to our clothes. In this paper, we provide detailed theories of fluorescence phenomenon. In particular, we show that the color appearance of fluorescence is unaffected by illumination in which it differs from ordinary reflectance. Moreover, we show that the color appearance of objects with reflective and fluorescent components can be represented as a linear combination of the two components. A linear model allows us to separate the two components using images taken under unknown illuminants using independent component analysis (ICA). The effectiveness of the proposed method is demonstrated using digital images of various fluorescent objects.	[Zhang, Cherry] Natl Inst Informat, Tokyo 1018430, Japan	Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan		imarik@nii.ac.jp			Ministry of Education, Science, Sports, and Culture; Grants-in-Aid for Scientific Research [22135001, 22135002] Funding Source: KAKEN	Ministry of Education, Science, Sports, and Culture(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)); Grants-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This research was supported in part by the Ministry of Education, Science, Sports, and Culture Grant-in-Aid for Scientific Research on Innovative Areas. The authors are grateful to Dr. Shin'ya Nishida for helpful suggestions.	Agarwal V, 2006, J PATTERN RECOGNIT R, V1, P42, DOI 10.13176/11.9; Alterman M., 2010, PROC IEEE INT C COMP, P1; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Barnard K, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P257; Ebner M., 2007, COMPUTER VISION; Emmel P., 1998, P 6 IS T COL IM C; Farid H., 1999, COMPUTER VISION PATT, V1; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Fujine T, 2010, J SOC INF DISPLAY, V18, P535, DOI 10.1889/JSID18.8.535; Glassner A., 1994, P 5 EUR WORKSH REND, P57; Gobinet C., 2004, P EUSIPCO, P6; Hullin MB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778834; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Johnson GM, 1999, IEEE COMPUT GRAPH, V19, P47, DOI 10.1109/38.773963; Kaneishi H., 2002, MODELING ESTIMATION; Kittel C., 1966, INTRO SOLID STATE PH, P554; Nakajima T., 2010, P COL SCI ASS JAP; Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071; Neher R.A., 2009, BIOPHYS J, V96, P149; Springsteen A, 1999, ANAL CHIM ACTA, V380, P183, DOI 10.1016/S0003-2670(98)00578-9; Sun Y., 2000, THESIS S FRASER U VA; Tominaga S., 2011, P IS T SIDS 19 COL I; Tsumura N, 2003, ACM T GRAPHIC, V22, P770, DOI 10.1145/882262.882344; Wilkie A., 2006, GRAPHITE 06 P 4 INT, P321, DOI [10.1145/1174429.1174484, DOI 10.1145/1174429.1174484]	24	11	11	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2866	2877		10.1109/TPAMI.2012.255	http://dx.doi.org/10.1109/TPAMI.2012.255			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136427				2022-12-18	WOS:000326502200005
J	Cordero-Grande, L; Merino-Caviedes, S; Aja-Fernandez, S; Alberola-Lopez, C				Cordero-Grande, Lucilio; Merino-Caviedes, Susana; Aja-Fernandez, Santiago; Alberola-Lopez, Carlos			Groupwise Elastic Registration by a New Sparsity-Promoting Metric: Application to the Alignment of Cardiac Magnetic Resonance Perfusion Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Groupwise elastic registration; registration metric; sparseness; cardiac magnetic resonance; myocardial perfusion	MYOCARDIAL-PERFUSION; NONRIGID REGISTRATION; MUTUAL-INFORMATION; MOTION CORRECTION; MR-IMAGES; QUANTIFICATION	This paper proposes a methodology for the joint alignment of a sequence of images based on a groupwise registration procedure by using a new family of metrics that exploit the expected sparseness of the temporal intensity curves corresponding to the aligned points. Therefore, this methodology is able to tackle the alignment of temporal sequences of images in which the represented phenomenon varies in time. Specifically, we have applied it to the correction of motion in contrast-enhanced first-pass perfusion cardiac magnetic resonance images. The time sequence is elastically registered as a whole by using the aforementioned family of multi-image metrics and jointly optimizing the parameters of the transformations involved. The proposed metrics are able to cope with dynamic changes in the intensity content of corresponding points in the sequence guided by the assumption that these changes allow for a sparse representation in a properly selected frame. Results have shown the statistically significant improvement in the performance of the proposed metric with respect to previous groupwise registration metrics for the problem at hand, which is especially relevant to correct for elastic deformations.	[Cordero-Grande, Lucilio; Merino-Caviedes, Susana; Aja-Fernandez, Santiago; Alberola-Lopez, Carlos] Univ Valladolid, Lab Procesado Imagen, Dept Teoria Senal & Comunicac & Ingn Telemat, ETSI Telecomunicac, E-47011 Valladolid, Castilla Leon, Spain	Universidad de Valladolid	Cordero-Grande, L (corresponding author), Univ Valladolid, Lab Procesado Imagen, Dept Teoria Senal & Comunicac & Ingn Telemat, ETSI Telecomunicac, E-47011 Valladolid, Castilla Leon, Spain.	lcorgra@lpi.tel.uva.es; smercav@lpi.tel.uva.es; sanaja@tel.uva.es; caralb@tel.uva.es	Cordero-Grande, Lucilio/AFT-0705-2022; Aja-Fernández, Santiago/L-2490-2017; Merino-Caviedes, Susana/J-9339-2019; Alberola-López, Carlos/M-1582-2014	Cordero-Grande, Lucilio/0000-0003-1477-304X; Aja-Fernández, Santiago/0000-0002-5337-5071; Merino-Caviedes, Susana/0000-0002-4689-9766; Alberola-López, Carlos/0000-0003-3684-0055	Ministerio de Ciencia e Innovacion; Fondo Europeo de Desarrollo Regional [TEC2010-17982]; Centro para el Desarrollo Tecnologico Industrial under the cvREMOD project [CEN-20091044]; Instituto de Salud Carlos III [PI11-01492]; European Commission [FP7-223920]	Ministerio de Ciencia e Innovacion(Ministry of Science and Innovation, Spain (MICINN)Instituto de Salud Carlos IIISpanish Government); Fondo Europeo de Desarrollo Regional(European Commission); Centro para el Desarrollo Tecnologico Industrial under the cvREMOD project; Instituto de Salud Carlos III(Instituto de Salud Carlos IIIEuropean Commission); European Commission(European CommissionEuropean Commission Joint Research Centre)	This work was supported in part by the Ministerio de Ciencia e Innovacion and the Fondo Europeo de Desarrollo Regional under Research Grant TEC2010-17982, by the Centro para el Desarrollo Tecnologico Industrial under the cvREMOD project and Research Grant CEN-20091044, by the Instituto de Salud Carlos III under Research Grant PI11-01492. The authors also acknowledge Grant FP7-223920 from the European Commission. Finally, the authors would like to thank the Hospital Quiron Valencia, Spain, for the acquisition of the images.	Balci S. K., 2007, P INT C MED IM COMP, V10, P105; Bhatia KK, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P908; Bidaut LM, 2001, J MAGN RESON IMAGING, V13, P648, DOI 10.1002/jmri.1092; Cordero-Grande L, 2011, MED IMAGE ANAL, V15, P283, DOI 10.1016/j.media.2011.01.002; Dornier C, 2003, J MAGN RESON IMAGING, V18, P160, DOI 10.1002/jmri.10351; Gupta SN, 2003, MAGNET RESON MED, V49, P506, DOI 10.1002/mrm.10394; Gupta V, 2012, MED IMAGE ANAL, V16, P767, DOI 10.1016/j.media.2011.12.005; Hamrouni S, 2011, I S BIOMED IMAGING, P574, DOI 10.1109/ISBI.2011.5872472; Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Kreutz-Delgado K., 1997, UCSDCIE9771; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Li C, 2011, MED IMAGE ANAL, V15, P449, DOI 10.1016/j.media.2011.02.001; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; Melbourne A, 2007, PHYS MED BIOL, V52, P5147, DOI 10.1088/0031-9155/52/17/003; Milles J, 2008, IEEE T MED IMAGING, V27, P1611, DOI 10.1109/TMI.2008.928918; Myronenko A, 2010, IEEE T MED IMAGING, V29, P1882, DOI 10.1109/TMI.2010.2053043; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Scott AD, 2009, RADIOLOGY, V250, P331, DOI 10.1148/radiol.2502071998; Shin T, 2013, MAGN RESON MED, V69, P839, DOI 10.1002/mrm.24303; Sotiras A., 2012, 7971 INRIA; Tamburo R., 2011, VTK J; Wachinger C, 2013, IEEE T PATTERN ANAL, V35, P1221, DOI 10.1109/TPAMI.2012.196; Wachinger C, 2012, MED IMAGE ANAL, V16, P1, DOI 10.1016/j.media.2011.03.001; Wang H, 2012, IEEE T MED IMAGING, V31, P487, DOI 10.1109/TMI.2011.2171706; Wells W M 3rd, 1996, Med Image Anal, V1, P35; Wollny G, 2012, MED IMAGE ANAL, V16, P1015, DOI 10.1016/j.media.2012.02.004; Wollny G, 2010, IEEE T MED IMAGING, V29, P1516, DOI 10.1109/TMI.2010.2049270; Wong KK, 2008, J MAGN RESON IMAGING, V27, P529, DOI 10.1002/jmri.21254; Zollei L., 2006, THESIS MIT	31	11	11	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2638	2650		10.1109/TPAMI.2013.74	http://dx.doi.org/10.1109/TPAMI.2013.74			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051725				2022-12-18	WOS:000324830900006
J	Melacci, S; Gori, M				Melacci, Stefano; Gori, Marco			Learning with Box Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Box kernels; Green's functions; kernel machines; propositional rules; regularization operators	KNOWLEDGE; NETWORKS	Supervised examples and prior knowledge on regions of the input space have been profitably integrated in kernel machines to improve the performance of classifiers in different real-world contexts. The proposed solutions, which rely on the unified supervision of points and sets, have been mostly based on specific optimization schemes in which, as usual, the kernel function operates on points only. In this paper, arguments from variational calculus are used to support the choice of a special class of kernels, referred to as box kernels, which emerges directly from the choice of the kernel function associated with a regularization operator. It is proven that there is no need to search for kernels to incorporate the structure deriving from the supervision of regions of the input space, because the optimal kernel arises as a consequence of the chosen regularization operator. Although most of the given results hold for sets, we focus attention on boxes, whose labeling is associated with their propositional description. Based on different assumptions, some representer theorems are given that dictate the structure of the solution in terms of box kernel expansion. Successful results are given for problems of medical diagnosis, image, and text categorization.	[Melacci, Stefano; Gori, Marco] Univ Siena, Dept Informat Engn & Math Sci, I-53100 Siena, Italy	University of Siena	Melacci, S (corresponding author), Univ Siena, Dept Informat Engn & Math Sci, Via Roma 56, I-53100 Siena, Italy.	mela@dii.unisi.it; marco@dii.unisi.it		MELACCI, STEFANO/0000-0002-0415-0888	Learning Techniques in Relational Domains and Their Applications [PRIN 2009]	Learning Techniques in Relational Domains and Their Applications	This research has been supported under the grant PRIN 2009 "Learning Techniques in Relational Domains and Their Applications." The authors would like to thank Marcello Sanguineti, Giorgio Gnecco, and Paolo Frasconi for fruitful discussions on earlier versions of this paper.	Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chen Z, 2002, NEURAL COMPUT, V14, P2791, DOI 10.1162/089976602760805296; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Fasshauer G. E., 2010, REPROD KERNELS SOBOL; Fasshauer G. E., 2011, P 13 INT C APPR THEO; Fasshauer G. E., 2011, REPROD KERNELS GEN S; Frank A., 2010, UCI REPOSITORY; Fung G. M., 2002, P 15 INT C NEUR INF, P537; Fung GM, 2003, LECT NOTES ARTIF INT, V2777, P102, DOI 10.1007/978-3-540-45167-9_9; Gnecco G., 2011, TECHNICAL REPORT; Grtner T., 2002, P 19 INT C MACH LEAR, P179; Haussler D, 1999, TECHNICAL REPORT; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683; Kunapuli G, 2010, LECT NOTES ARTIF INT, V6322, P145, DOI 10.1007/978-3-642-15883-4_10; Le Q.V., 2006, P 23 INT C MACH LEAR, P521; Mangasarian O., 2009, STAT ANAL DATA MIN, V1, P215; Mangasarian OL, 2008, IEEE T NEURAL NETWOR, V19, P1826, DOI 10.1109/TNN.2008.2005188; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Poggio T., 1989, TECHNICAL REPORT; Schoelkopf B., 2002, LEARNING KERNELS; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Sriperumbudur BK, 2010, J MACH LEARN RES, V11, P1517; Taylor M., 1981, PSEUDO DIFFERENTIAL	25	11	11	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2680	2692		10.1109/TPAMI.2013.73	http://dx.doi.org/10.1109/TPAMI.2013.73			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051728				2022-12-18	WOS:000324830900009
J	Murray, N; Vanrell, M; Otazu, X; Parraga, CA				Murray, Naila; Vanrell, Maria; Otazu, Xavier; Alejandro Parraga, C.			Low-Level Spatiochromatic Grouping for Saliency Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational models of vision; color; hierarchical image representation	SUPPRESSION; CONTRAST	We propose a saliency model termed SIM (saliency by induction mechanisms), which is based on a low-level spatiochromatic model that has successfully predicted chromatic induction phenomena. In so doing, we hypothesize that the low-level visual mechanisms that enhance or suppress image detail are also responsible for making some image regions more salient. Moreover, SIM adds geometrical grouplets to enhance complex low-level features such as corners, and suppress relatively simpler features such as edges. Since our model has been fitted on psychophysical chromatic induction data, it is largely nonparametric. SIM outperforms state-of-the-art methods in predicting eye fixations on two datasets and using two metrics.	[Murray, Naila] Xerox Res Ctr Europe, F-38240 Meylan, France; [Vanrell, Maria; Otazu, Xavier; Alejandro Parraga, C.] Ctr Visio Computador, Barcelona 08193, Spain	Xerox; Centre de Visio per Computador (CVC)	Murray, N (corresponding author), Xerox Res Ctr Europe, 6 Chemin Maupertuis, F-38240 Meylan, France.	nmurray@cvc.uab.es; maria@cvc.uab.es; xotazu@cvc.uab.es; Alejandro.Parraga@cvc.uab.es	Otazu, Xavier/P-6940-2019; Otazu, Xavier/A-1208-2009; Vanrell, Maria/A-7694-2010; Parraga, C. Alejandro/D-2329-2011	Otazu, Xavier/0000-0002-4982-791X; Otazu, Xavier/0000-0002-4982-791X; Vanrell, Maria/0000-0002-1567-9293; Parraga, C. Alejandro/0000-0002-3809-241X	Spanish Ministry of Science [TIN2010-21771-C02-1, 2009-SGR-669, Consolider-Ingenio 2010-CSD2007-00018];  [RYC-2007-00484]	Spanish Ministry of Science(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); 	This work was supported by Projects TIN2010-21771-C02-1, 2009-SGR-669, and Consolider-Ingenio 2010-CSD2007-00018 from the Spanish Ministry of Science. C. Alejandro Parraga was funded by grant RYC-2007-00484.	[Anonymous], 2006, NIPS; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Blakeslee B, 1997, VISION RES, V37, P2849, DOI 10.1016/S0042-6989(97)00086-2; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2530, DOI 10.1152/jn.00692.2001; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X., 2008, NIPS, P681; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Judd T., 2009, P IEEE INT C COMP VI; Kienzle W., 2007, ADV NEURAL INFORM PR, V19; LI CY, 1994, VISION RES, V34, P2337, DOI 10.1016/0042-6989(94)90280-1; Mallat S, 2009, APPL COMPUT HARMON A, V26, P161, DOI 10.1016/j.acha.2008.03.004; MULLEN KT, 1985, J PHYSIOL-LONDON, V359, P381, DOI 10.1113/jphysiol.1985.sp015591; Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506; Otazu X, 2010, J VISION, V10, DOI 10.1167/10.12.5; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Shapley R, 2011, VISION RES, V51, P701, DOI 10.1016/j.visres.2011.02.012; Simoncelli EP, 1999, ADV NEUR IN, V11, P153; Smith AT, 2001, CEREB CORTEX, V11, P1182, DOI 10.1093/cercor/11.12.1182; Walker GA, 2000, VISUAL NEUROSCI, V17, P369, DOI 10.1017/S0952523800173055; ZEKI S, 1991, J NEUROSCI, V11, P641; ZETZSCHE C, 1998, COM ADAP SY, P120; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22	29	11	13	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2810	2816		10.1109/TPAMI.2013.108	http://dx.doi.org/10.1109/TPAMI.2013.108			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051738				2022-12-18	WOS:000324830900019
J	Brahmachari, AS; Sarkar, S				Brahmachari, Aveek S.; Sarkar, Sudeep			Hop-Diffusion Monte Carlo for Epipolar Geometry Estimation between Very Wide-Baseline Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Epipolar geometry; Markov Chain Monte Carlo (MCMC); Joint Feature Distribution (JFD)	ROBUST ESTIMATOR; MLESAC	We present a Monte Carlo approach for epipolar geometry estimation that efficiently searches for minimal sets of inter correspondences in the presence of many outliers in the putative correspondence set, a condition that is prevalent when we have wide baselines, significant scale changes, rotations in depth, occlusion, and repeated patterns. The proposed Monte Carlo algorithm uses Balanced LOcal and Global Search (BLOGS) to find the best minimal set of correspondences. The local search is a diffusion process using Joint Feature Distributions that captures the dependencies among the correspondences. And, the global search is a hopping search process across the minimal set space controlled by photometric properties. Using a novel experimental protocol that involves computing errors for manually marked ground truth points and images with outlier rates as high as 90 percent, we find that BLOGS is better than related approaches such as MAPSAC [1], NAPSAC [2], and BEEM [3]. BLOGS results, are of similar quality as other approaches, but BLOGS generate them in 10 times fewer iterations. The time per iteration for BLOGS is also the lowest among the ones we studied.	[Brahmachari, Aveek S.; Sarkar, Sudeep] Univ S Florida, Dept Comp Sci & Engn, Comp Vis & Pattern Recognit Grp, Tampa, FL 33620 USA	State University System of Florida; University of South Florida	Brahmachari, AS (corresponding author), Univ S Florida, Dept Comp Sci & Engn, Comp Vis & Pattern Recognit Grp, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.	abrahmac@mail.usf.edu; sarkar@cse.usf.edu	Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Armangue X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3; Brahmachari A., 2009, P IEEE INT C COMP VI; Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150; Choi S., 1997, P BRIT MACH VIS C, V24, P271; Chum O, 2005, PROC CVPR IEEE, P772; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Domke J., 2005, Dynamical Vision. ICCV 2005 and ECCV 2006 Workshops WDV 2005 and WDV 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4358), P232; Doucet A., 2001, SEQUENTIAL MONTE CAR; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P COMP VIS PATT REC, V1, P453, DOI DOI 10.1109/CVPR.2006.235; Goshen L, 2008, IEEE T PATTERN ANAL, V30, P1230, DOI 10.1109/TPAMI.2007.70768; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Han F, 2004, IEEE T PATTERN ANAL, V26, P1138, DOI 10.1109/TPAMI.2004.70; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Ke Y, 2004, PROC CVPR IEEE, P506; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458; Ni K, 2009, IEEE I CONF COMP VIS, P2193, DOI 10.1109/ICCV.2009.5459241; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Rozenfeld S, 2005, PROC CVPR IEEE, P1113; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098; Triggs B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P201, DOI 10.1109/ICCV.2001.937625; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; Zheng Y., 2011, P IEEE C COMP VIS PA	34	11	11	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					755	762		10.1109/TPAMI.2012.227	http://dx.doi.org/10.1109/TPAMI.2012.227			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	26353140				2022-12-18	WOS:000314792900018
J	Deselaers, T; Gass, T; Heigold, G; Ney, H				Deselaers, Thomas; Gass, Tobias; Heigold, Georg; Ney, Hermann			Latent Log-Linear Models for Handwritten Digit Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Log-linear models; latent variables; conditional random fields; OCR; image classification	RECOGNITION	We present latent log-linear models, an extension of log-linear models incorporating latent variables, and we propose two applications thereof: log-linear mixture models and image deformation-aware log-linear models. The resulting models are fully discriminative, can be trained efficiently, and the model complexity can be controlled. Log-linear mixture models offer additional flexibility within the log-linear modeling framework. Unlike previous approaches, the image deformation-aware model directly considers image deformations and allows for a discriminative training of the deformation parameters. Both are trained using alternating optimization. For certain variants, convergence to a stationary point is guaranteed and, in practice, even variants without this guarantee converge and find models that perform well. We tune the methods on the USPS data set and evaluate on the MNIST data set, demonstrating the generalization capabilities of our proposed models. Our models, although using significantly fewer parameters, are able to obtain competitive results with models proposed in the literature.	[Deselaers, Thomas] Google Switzerland, CH-8002 Zurich, Switzerland; [Gass, Tobias] ETH, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Heigold, Georg] Google Inc, Mountain View, CA 94043 USA; [Ney, Hermann] Rhein Westfal TH Aachen, Lehrstuhl Informat 6, D-52056 Aachen, Germany; [Deselaers, Thomas; Gass, Tobias; Heigold, Georg; Ney, Hermann] Univ Aachen, RWTH, Dept Comp Sci, Human Language Technol & Pattern Recognit Grp, Aachen, Germany	Google Incorporated; Swiss Federal Institutes of Technology Domain; ETH Zurich; Google Incorporated; RWTH Aachen University; RWTH Aachen University	Deselaers, T (corresponding author), Google Switzerland, Brandschenkestr 110, CH-8002 Zurich, Switzerland.	deselaers@gmail.com; gasst@vision.ee.ethz.ch; heigold_stadelmann@hotmail.com; ney@cs.rwth-aachen.de	Gass, Tobias/C-2244-2013					Anderson J. A., 1982, HDB STATISTICS, P169; [Anonymous], 2002, LEARNING KERNELS; BARNDORFFNIELSEN OE, 1989, ANN I STAT MATH, V41, P247, DOI 10.1007/BF00049394; Bender O., 2003, P 7 C NAT LANG LEARN, V4, P148; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gass T., 2009, P 31 DAGM S PATT REC; Gehler P., 2009, P IEEE C COMP VIS PA; Gunawardana A, 2005, J MACH LEARN RES, V6, P2049; Gunawardana A., 2005, P INTERSPEECH, P117; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Haasdonk B, 2002, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2002.1048439; Haasdonk B., 2005, THESIS ALBERT LUDWIG; Heigold G., 2008, P INT SEPT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jebara T., 2003, MACHINE LEARNING DIS; Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198; Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153; Kullback S., 1971, ESTIMATING TES UNPUB; Lafferty John, 2001, CONDITIONAL RANDOM F, P282; Landauer T. K., 2007, HDB LATENT SEMANTIC; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2011, MNIST DATABASE HANDW; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Memisevic R., 2007, P IEEE C COMP VIS PA; Minka T.P., 2003, COMP NUMERICAL OPTIM; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Saul LK, 2002, ADV NEUR IN, V14, P897; Scholkopf B., 2010, USPS DATA SET; Simard PY, 2003, PROC INT CONF DOC, P958; Uchida S, 2005, IEICE T INF SYST, VE88D, P1781, DOI 10.1093/ietisy/e88-d.8.1781; Weyand T., 2009, P BRIT MACH VIS C	38	11	12	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1105	1117		10.1109/TPAMI.2011.218	http://dx.doi.org/10.1109/TPAMI.2011.218			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22064798	Green Submitted			2022-12-18	WOS:000302916600006
J	Porway, J; Zhu, SC				Porway, Jake; Zhu, Song-Chun			C-4: Exploring Multiple Solutions in Graphical Models by Cluster Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; computer vision; graph labeling; probabilistic algorithms; constraint satisfaction; Monte Carlo	SWENDSEN-WANG; PROPAGATION; RELAXATION; ALGORITHM	This paper presents a novel Markov Chain Monte Carlo (MCMC) inference algorithm called C-4-Clustering with Cooperative and Competitive Constraints-for computing multiple solutions from posterior probabilities defined on graphical models, including Markov random fields (MRF), conditional random fields (CRF), and hierarchical models. The graphs may have both positive and negative edges for cooperative and competitive constraints. C-4 is a probabilistic clustering algorithm in the spirit of Swendsen-Wang [34]. By turning the positive edges on/off probabilistically, C-4 partitions the graph into a number of connected components (ccps) and each ccp is a coupled subsolution with nodes connected by positive edges. Then, by turning the negative edges on/off probabilistically, C-4 obtains composite ccps (called cccps) with competing ccps connected by negative edges. At each step, C-4 flips the labels of all nodes in a cccp so that nodes in each ccp keep the same label while different ccps are assigned different labels to observe both positive and negative constraints. Thus, the algorithm can jump between multiple competing solutions (or modes of the posterior probability) in a single or a few steps. It computes multiple distinct solutions to preserve the intrinsic ambiguities and avoids premature commitments to a single solution that may not be valid given later context. C-4 achieves a mixing rate faster than existing MCMC methods, such as various Gibbs samplers [15], [26] and Swendsen-Wang cuts [2], [34]. It is also more "dynamic" than common optimization methods such as ICM [3], LBP [21], [37], and graph cuts [4], [20]. We demonstrate the C4 algorithm in line drawing interpretation, scene labeling, and object recognition.	[Porway, Jake] New York Times Co, R&D Div, New York, NY USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90024 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA	New York Times; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Porway, J (corresponding author), New York Times Co, R&D Div, New York, NY USA.				US National Science Foundation (NSF) [1018751]; US Office of Naval Research MURI [N000141010933]; 863 grant [2009AA01Z331]; NSFC [90920009]	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Office of Naval Research MURI(MURIOffice of Naval Research); 863 grant(National High Technology Research and Development Program of China); NSFC(National Natural Science Foundation of China (NSFC))	This work was partially supported by US National Science Foundation (NSF) IIS grant 1018751 and US Office of Naval Research MURI grant N000141010933. The authors would also like to acknowledge the support of the LHI data set [38]. Work done at LHI was supported by 863 grant 2009AA01Z331 and NSFC 90920009. J. Porway was a PhD student with the Department of Statistics, University of California, Los Angeles (UCLA) when this paper was submitted.	Apt KR, 1999, THEOR COMPUT SCI, V221, P179, DOI 10.1016/S0304-3975(99)00032-8; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; BESAG J, 1986, J R STAT SOC B, V48, P259; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Braunstein A, 2005, RANDOM STRUCT ALGOR, V27, P201, DOI 10.1002/rsa.20057; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Cooper C, 1999, RANDOM STRUCT ALGOR, V15, P242, DOI 10.1002/(SICI)1098-2418(199910/12)15:3/4<242::AID-RSA4>3.0.CO;2-C; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Dellaert F, 2001, ADV NEUR IN, V13, P852; EDWARDS RG, 1988, PHYS REV D, V38, P2009, DOI 10.1103/PhysRevD.38.2009; Felzenszwalb P., 2007, P IEEE C COMP VIS PA; FERGUS R., 2005, P IEEE C COMP VIS PA; FLETCHER R, 1970, COMPUT J, V13, P317, DOI 10.1093/comjnl/13.3.317; GELMAN A, 2004, BAYESIAN DATA ANAL, pCH5; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GORE V, 1997, P 29 ACM S THEOR COM, P674; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Huffman D., 1971, MACH INTELL, V8, P475; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; KUMAR M, 2006, LECT NOTES COMPUTER; KUMAR S, 2003, P IEEE C COMP VIS PA; Lafferty J., 2001, CONDITIONAL RANDOM F; LIN L, 2009, P IEEE C COMP VIS PA; LIU JS, 1995, J ROY STAT SOC B MET, V57, P157; Liu JS., 2001, MONTE CARLO STRATEGI, DOI DOI 10.1007/978-0-387-76371-2; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; OH SM, 2005, P 10 IEE INT C COMP, V2, P1161; Pearl J., 1984, INTELLIGENT SEARCH S; Porway J, 2010, INT J COMPUT VISION, V88, P254, DOI 10.1007/s11263-009-0306-1; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Sugihara K., 1986, MACHINE INTERPRETATI; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; Torralba A., 2004, P IEEE C COMP VIS PA; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; WU TF, 2010, INT J COMPUTER VISIO; YAO B, 2007, P INT C EN MIN METH; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	40	11	11	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1713	1727		10.1109/TPAMI.2011.27	http://dx.doi.org/10.1109/TPAMI.2011.27			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21321365	Green Submitted			2022-12-18	WOS:000292740000002
J	Kumar, R; Barmpoutis, A; Banerjee, A; Vemuri, BC				Kumar, Ritwik; Barmpoutis, Angelos; Banerjee, Arunava; Vemuri, Baba C.			Non-Lambertian Reflectance Modeling and Shape Recovery of Faces Using Tensor Splines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor splines; non-Lambertian reflectance; face relighting; 3D shape recovery; facial image analysis	PHOTOMETRIC STEREO; RECOGNITION; ILLUMINATION; IMAGES; APPEARANCE; RADIANCE; OBJECTS; SET	Modeling illumination effects and pose variations of a face is of fundamental importance in the field of facial image analysis. Most of the conventional techniques that simultaneously address both of these problems work with the Lambertian assumption and thus fall short of accurately capturing the complex intensity variation that the facial images exhibit or recovering their 3D shape in the presence of specularities and cast shadows. In this paper, we present a novel Tensor-Spline-based framework for facial image analysis. We show that, using this framework, the facial apparent BRDF field can be accurately estimated while seamlessly accounting for cast shadows and specularities. Further, using local neighborhood information, the same framework can be exploited to recover the 3D shape of the face (to handle pose variation). We quantitatively validate the accuracy of the Tensor Spline model using a more general model based on the mixture of single-lobed spherical functions. We demonstrate the effectiveness of our technique by presenting extensive experimental results for face relighting, 3D shape recovery, and face recognition using the Extended Yale B and CMU PIE benchmark data sets.	[Kumar, Ritwik; Barmpoutis, Angelos; Banerjee, Arunava; Vemuri, Baba C.] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Kumar, R (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, CSE Bldg, Gainesville, FL 32611 USA.	rkkumar@cise.ufl.edu; abarmpou@cise.ufl.edu; arunava@cise.ufl.edu; vemuri@cise.ufl.edu		Barmpoutis, Angelos/0000-0003-3271-7965; Banerjee, Arunava/0000-0001-9381-4940	University of Florida Alumni	University of Florida Alumni(University of Florida)	A part of the work presented here on relighting appeared in the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition in 2008 [26]. This research was in part funded by University of Florida Alumni Fellowships to Ritwik Kumar and Angelos Barmpoutis.	ALLDRIN N, 2008, P IEEE CS C COMP VIS; ALLDRIN N, 2007, P IEEE INT C COMP VI; [Anonymous], 2005, P IEEE INT C COMP VI; BARMPOUTIS A, 2008, P IEEE CS C COMP VIS; Barmpoutis A, 2007, IEEE T MED IMAGING, V26, P1537, DOI 10.1109/TMI.2007.903195; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Batur AU, 2001, PROC CVPR IEEE, P296; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; BISWAS S, 2007, P IEEE INT C COMP VI; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Borshukov G., 2003, P ACM SIGGRAPH SKETC; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Chan H., 1965, MAN MACHINE FACIAL R; CHANDRAKER M, 2007, P IEEE CS C COMP VIS; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; DEBEVEC P, 2000, P ACM SIGGRAPH; Debevec P., 1998, P ACM SIGGRAPH; FOO SC, 1997, THESIS CORNELL U ITH; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GEORGHIADES AS, 1999, P IEEE WORKSH MULT M; GEORGHIAGES AS, 2003, P 14 EUR WORKSH REND; Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; HERTZMANN A, 2003, P IEEE CS C COMP VIS; Horn B., 1986, ROBOT VISION, P1; Jeffreys H., 1931, CARTESIAN TENSORS; KEMELMACHER I, 2006, P EUR C COMP VIS; KOUDELKA ML, 2001, P IEEE CS C COMP VIS; Lawson C. L., 1974, SOLVING LEAST SQUARE; Lee J., 2005, P IEEE INT C COMP VI; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; LEE KC, 2005, P IEEE INT WORKSH AN; Liu ZC, 2001, COMP GRAPH, P271; MAGDA S, 2001, P IEEE INT C COMP VI; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; OSHEA JP, 2008, P ACM S APPL PERC GR; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Sim T, 2001, CMURITR0102; Smith WAP, 2008, INT J COMPUT VISION, V76, P71, DOI 10.1007/s11263-007-0074-8; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Wen Z, 2003, PROC CVPR IEEE, P158; WEYRICH T, 2006, P ACM SIGGRAPH; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Yoon KJ, 2010, INT J COMPUT VISION, V86, P192, DOI 10.1007/s11263-009-0222-4; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247; Zhou SK, 2007, IEEE T PATTERN ANAL, V29, P230, DOI 10.1109/TPAMI.2007.25; Zickler T, 2006, IEEE T PATTERN ANAL, V28, P1287, DOI 10.1109/TPAMI.2006.170	57	11	12	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					553	567		10.1109/TPAMI.2010.67	http://dx.doi.org/10.1109/TPAMI.2010.67			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	21252399				2022-12-18	WOS:000286204700009
J	Kleiner, I; Keren, D; Newman, I; Ben-Zwi, O				Kleiner, Igor; Keren, Daniel; Newman, Ilan; Ben-Zwi, Oren			Applying Property Testing to an Image Partitioning Problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Property testing; image partitioning		Property testing is a rapidly growing field of research. Typically, a property testing algorithm proceeds by quickly determining whether an input can satisfy some condition, under the assumption that most inputs do not satisfy it. If the input is "far" from satisfying the condition, the algorithm is guaranteed to reject it with high probability. Applying this paradigm to image detection is desirable since images are large objects and a lot of time can be saved by quickly rejecting images which are "far" from satisfying a certain condition the user is interested in. Further, typically most inputs are, indeed, "far" from the sought images. We demonstrate this by analyzing the problem of deciding whether a binary image can be partitioned according to a template represented by a rectangular grid, and introduce a quick "rejector," which tests an image extracted from the input image, but whose size, as well as the time required to construct it, are constants which are independent of the input image size. With high probability, the rejector dismisses the inputs which are "far" from the template.	[Kleiner, Igor; Keren, Daniel; Newman, Ilan; Ben-Zwi, Oren] Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel	University of Haifa	Kleiner, I (corresponding author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.	dkeren@cs.haifa.ac.il			Israel Science Foundation [1011/06, 1220/04]; Israel Ministry of Science [3/3422]	Israel Science Foundation(Israel Science Foundation); Israel Ministry of Science(Ministry of Science, Technology and Space (MOST), Israel)	This paper greatly benefited from the comments and corrections of four anonymous reviewers. This research was supported by Israel Science Foundation grants 1011/06 and 1220/04, and Israel Ministry of Science grant 3/3422.	Alon N., 2004, PROBABILISTIC METHOD; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; FISCHER E, 2001, COMPUT COMPLEX, V75, P97; Goldreich O, 1998, J ACM, V45, P653, DOI 10.1145/285055.285060; HAGERUP T, 1990, INFORM PROCESS LETT, V33, P305, DOI 10.1016/0020-0190(90)90214-I; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078; Lindenbaum M, 1997, IEEE T PATTERN ANAL, V19, P1251, DOI 10.1109/34.632984; Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092; Raskhodnikova S, 2003, LECT NOTES COMPUT SC, V2764, P370; Ratsch M, 2008, IEEE T IMAGE PROCESS, V17, P2456, DOI 10.1109/TIP.2008.2001393; Romdhani S, 2004, P ROY SOC A-MATH PHY, V460, P3283, DOI 10.1098/rspa.2004.1333; Sahbi H, 2006, J MACH LEARN RES, V7, P2087; Sun J, 2004, PROC CVPR IEEE, P276; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1	19	11	11	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					256	265		10.1109/TPAMI.2010.165	http://dx.doi.org/10.1109/TPAMI.2010.165			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20733222				2022-12-18	WOS:000285313200004
J	Griffin, LD; Lillholm, M				Griffin, Lewis D.; Lillholm, Martin			Symmetry Sensitivities of Derivative-of-Gaussian Filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Group theory; invariance; pattern analysis	LOCAL-IMAGE-STRUCTURE; DIFFERENTIAL STRUCTURE; MIRROR SYMMETRY; PERCEPTION; MODEL; CLASSIFICATION; SHAPE	We consider the measurement of image structure using linear filters, in particular derivative-of-Gaussian (DtG) filters, which are an important model of V1 simple cells and widely used in computer vision, and whether such measurements can determine local image symmetry. We show that even a single linear filter can be sensitive to a symmetry, in the sense that specific responses of the filter can rule it out. We state and prove a necessary and sufficient, readily computable, criterion for filter symmetry-sensitivity. We use it to show that the six filters in a second order DtG family have patterns of joint sensitivity which are distinct for 12 different classes of symmetry. This rich symmetry-sensitivity adds to the properties that make DtG filters well-suited for probing local image structure, and provides a set of landmark responses suitable to be the foundation of a nonarbitrary system of feature categories.	[Griffin, Lewis D.; Lillholm, Martin] UCL, Dept Comp Sci, London WC1E 6BT, England	University of London; University College London	Griffin, LD (corresponding author), UCL, Dept Comp Sci, Malet Pl,Engn Bldg, London WC1E 6BT, England.	L.Griffin@cs.ucl.ac.uk; M.Lillholm@cs.ucl.ac.uk	Griffin, Lewis/C-2118-2008		EPSRC [EP/D030978/1]; Engineering and Physical Sciences Research Council [EP/C006631/1, EP/D030978/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the EPSRC-funded project "Basic Image Features" EP/D030978/1.	Auyang Sunny Y., 2000, MIND EVERYDAY LIFE C; Baylis GC, 2001, VIS COGN, V8, P163, DOI 10.1080/13506280042000126; Bieberbach L, 1911, MATH ANN, V70, P297, DOI 10.1007/BF01564500; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BONNEH Y, 1994, SPATIAL VISION, V8, P515, DOI 10.1163/156856894X00152; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; Braitenberg V., 1984, VEHICLES EXPT SYNTHE; CASSIRER E, 1944, PHILOS PHENOMENOLOGI, V5, P1; CHAM TJ, 1995, IMAGE VISION COMPUT, V13, P439, DOI 10.1016/0262-8856(95)99731-F; CHO KG, 1991, PATTERN RECOGN LETT, V12, P343, DOI 10.1016/S0167-8655(05)80003-0; CONWAY JH, 2001, CONTRIBUTIONS ALGEBR, V42, P475; DAKIN SC, 1994, SPATIAL VISION, V8, P393, DOI 10.1163/156856894X00071; Dakin SC, 1998, P ROY SOC B-BIOL SCI, V265, P659, DOI 10.1098/rspb.1998.0344; DEBNATH L, 1995, INTEGRAL TRANSFORMS; DEBNATH L, 1964, MATH VESNIK, V1, P285; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GEORGESON MA, 1994, HIGHER ORDER PROCESS, P147; Gr?nbaum B., 1987, TILINGS PATTERNS; Griffin LD, 2005, NETWORK-COMP NEURAL, V16, P301, DOI 10.1080/09548980500289874; Griffin LD, 2004, VISION RES, V44, P407, DOI 10.1016/j.visres.2003.09.025; Griffin LD, 2001, LECT NOTES COMPUT SC, V2106, P326; Griffin LD, 2002, PERCEPTION, V31, P377; GRIFFIN LD, 2002, J MATH IMAG IN PRESS; Griffin LD, 2008, J MATH IMAGING VIS, V31, P157, DOI 10.1007/s10851-008-0078-1; Griffin LD, 2007, IEEE T PATTERN ANAL, V29, P1355, DOI 10.1109/TPAMI.2007.1066; Griffin LD, 2006, INT J COMPUT VISION, V70, P213, DOI 10.1007/s11263-006-6355-9; HANSEN O, 1992, PATTERN RECOGN LETT, V13, P253, DOI 10.1016/0167-8655(92)90076-C; HOLSER WT, 1961, ACTA CRYSTALLOGR, V14, P1236, DOI 10.1107/S0365110X61003612; Klein F., 1893, B NEW YORK MATH SOC, V2, P215, DOI DOI 10.1090/S0002-9904-1893-00147-X; Koenderink J. J., 1997, Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC'97. Proceedings, P66, DOI 10.1007/BFb0017861; Koenderink J. J., 1992, Journal of Visual Communication and Image Representation, V3, P1, DOI 10.1016/1047-3203(92)90026-P; Koenderink J. J., 1993, J INTELLIGENT SYSTEM, V3, P49; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; Koenderink JJ, 2003, IEICE T INF SYST, VE86D, P1165; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; KOENDERINK JJ, 1996, ADV IMAGE UNDERSTAND, P113; KOENDERINK JJ, 2002, P EUR C COMP VIS; Levi DM, 2004, VISION RES, V44, P2475, DOI 10.1016/j.visres.2004.05.011; LEWIS D, 1983, PHILOS STUD, V44, P197, DOI 10.1007/BF00354100; LILLHOLM M, 2008, IMAGE VISION COMPUTI; Lindeberg T., 1994, GEOMETRY DRIVEN DIFF, P1; Liu XW, 2002, VISION RES, V42, P2617, DOI 10.1016/S0042-6989(02)00297-3; LIU Y, 2005, P ACM SIGGRAPH; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; LOEB AA, 1978, COLOR SYMMETRY; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Mancini S, 2005, VISION RES, V45, P2145, DOI 10.1016/j.visres.2005.02.004; MAROLA G, 1990, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, VOLS 1 AND 2, P699; Marr D., 1982, VISION; Mellor M, 2005, LECT NOTES COMPUT SC, V3459, P38; MILGRAM M, 2005, P C IM AN PROC, P1010; Oka S, 2007, VISION RES, V47, P2212, DOI 10.1016/j.visres.2007.03.020; Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639; Park M., P 2008 IEEE 19 INT S, P1, DOI [10.1109/PIMRC.2008.4699890, DOI 10.1109/PIMRC.2008.4699890]; Perrett DI, 1999, EVOL HUM BEHAV, V20, P295, DOI 10.1016/S1090-5138(99)00014-8; Pizer S. M., 1994, Journal of Mathematical Imaging and Vision, V4, P303, DOI 10.1007/BF01254105; PRASAD V, 2005, P INT C COMP VIS, P346; Rainville SJM, 2000, VISION RES, V40, P2621, DOI 10.1016/S0042-6989(00)00110-3; Romeny B. t. H., 2003, FRONT END VISION MUL; ROMENY BMT, 1994, IMAGE VISION COMPUT, V12, P317, DOI 10.1016/0262-8856(94)90056-6; Sally S, 2001, SPATIAL VISION, V14, P217, DOI 10.1163/156856801300202940; SCHATTSCHNEIDER D, 1990, MC ESCHER VISIONS SY; Scognamillo R, 2003, P ROY SOC B-BIOL SCI, V270, P1727, DOI 10.1098/rspb.2003.2434; Tagliati E, 2001, LECT NOTES COMPUT SC, V2106, P51; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Weickert J, 1997, COMP IMAG VIS, V8, P45; Weinstein A., 1996, NOT AM MATH SOC, V43, P744; Xu M, 1998, IEEE SYS MAN CYBERN, P4620, DOI 10.1109/ICSMC.1998.727580; Young RA, 2001, SPATIAL VISION, V14, P321, DOI 10.1163/156856801753253591; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110; Zhu X, 2005, J ARID ENVIRON, V62, P1, DOI 10.1016/j.jaridenv.2004.10.010	74	11	14	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1072	1083		10.1109/TPAMI.2009.91	http://dx.doi.org/10.1109/TPAMI.2009.91			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431132	Green Submitted			2022-12-18	WOS:000276671900009
J	Lohou, C; Dehos, J				Lohou, Christophe; Dehos, Julien			Automatic Correction of Ma and Sonka's Thinning Algorithm Using P-Simple Points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D thinning algorithm; curve skeleton; digital topology; topology preservation	3D DIGITAL IMAGES; AIRWAY TREE; SKELETONIZATION; TOPOLOGY; SURFACE	Ma and Sonka proposed a fully parallel 3D thinning algorithm which does not always preserve topology. We propose an algorithm based on P-simple points which automatically corrects Ma and Sonka's algorithm. As far as we know, our algorithm is the only fully parallel curve thinning algorithm which preserves topology.	[Lohou, Christophe] Univ Auvergne, Dept Informat, Inst Univ Technol, Lab Algorithm & Image Clermont, F-43006 Le Puy En Velay, France; [Dehos, Julien] Univ Littoral Cote dOpale, Dept Informat, Inst Univ Technol, Lab Informat Littoral, F-43006 Le Puy En Velay, France	Universite Clermont Auvergne (UCA); Universite du Littoral-Cote-d'Opale	Lohou, C (corresponding author), Univ Auvergne, Dept Informat, Inst Univ Technol, Lab Algorithm & Image Clermont, 8 Rue Jean Baptiste Fabre,BP 219, F-43006 Le Puy En Velay, France.	christophe.lohou@iut.u-clermont1.fr; julien.dehos@gmail.com	LOHOU, Christophe/C-8224-2018	LOHOU, Christophe/0000-0001-5352-8237				Bertrand G, 2008, J MATH IMAGING VIS, V31, P35, DOI 10.1007/s10851-007-0063-0; BERTRAND G, 1995, P SOC PHOTO-OPT INS, V2573, P52, DOI 10.1117/12.216440; BERTRAND G, 1995, CR ACAD SCI I-MATH, V321, P1077; BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P169, DOI 10.1016/0167-8655(94)90046-9; BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P1003, DOI 10.1016/0167-8655(94)90032-9; Bertrand G., 1995, P 5 INT C DISCR GEOM, P233; BERTRAND G, 1994, P SPIE C VISION GEOM, V2356, P113; Borgefors G, 1999, PATTERN RECOGN, V32, P1225, DOI 10.1016/S0031-3203(98)00082-X; Burguet J, 2003, DISCRETE APPL MATH, V125, P93, DOI 10.1016/S0166-218X(02)00226-3; Chaturvedi A, 2005, PHYS MED BIOL, V50, P1405, DOI 10.1088/0031-9155/50/7/005; De Berg M., 2008, COMPUTATIONAL GEOMET, Vthird; DEHOS J, ANAL ALGORITHM UNPUB; Gong W., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P188, DOI 10.1109/ICPR.1990.118087; Gonzalez-Diaz R, 2005, DISCRETE APPL MATH, V147, P245, DOI 10.1016/j.dam.2004.09.014; KONG TY, 1989, COMPUT GRAPH, V13, P159, DOI 10.1016/0097-8493(89)90058-7; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5; Lohou C, 2005, DISCRETE APPL MATH, V151, P198, DOI 10.1016/j.dam.2005.02.030; Lohou C, 2004, DISCRETE APPL MATH, V139, P171, DOI 10.1016/j.dam.2002.11.002; LOHOU C, 2001, THESIS U MARNE LA VA; Lohou C, 2007, PATTERN RECOGN, V40, P2301, DOI 10.1016/j.patcog.2006.12.032; MA C, 2002, IEEE T PATTERN ANAL, V24; Ma CM, 1996, COMPUT VIS IMAGE UND, V64, P420, DOI 10.1006/cviu.1996.0069; MA CM, 1995, PATTERN RECOGN LETT, V16, P83, DOI 10.1016/0167-8655(94)00063-9; MA CM, 1994, CVGIP-IMAG UNDERSTAN, V59, P328, DOI 10.1006/ciun.1994.1023; Malgouyres R, 1998, P SOC PHOTO-OPT INS, V3454, P16, DOI 10.1117/12.323247; Manzanera A, 1999, P SOC PHOTO-OPT INS, V3811, P57, DOI 10.1117/12.364113; Palagyi K, 1999, GRAPH MODEL IM PROC, V61, P199, DOI 10.1006/gmip.1999.0498; Palagyi K., 1998, Journal of Computing and Information Technology - CIT, V6, P149; Palagyi K, 1998, PATTERN RECOGN LETT, V19, P613, DOI 10.1016/S0167-8655(98)00031-2; Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680; ROLLAND F, 1991, P INT WORKSH VIS FOR, P443; Sauret V, 1999, PHYS MED BIOL, V44, P1625, DOI 10.1088/0031-9155/44/7/304; Serra J, 1982, IMAGE ANAL MATH MORP; Svensson S, 2002, PATTERN RECOGN LETT, V23, P1419, DOI 10.1016/S0167-8655(02)00102-2; TSAO YF, 1981, COMPUT VISION GRAPH, V17, P315, DOI 10.1016/0146-664X(81)90011-3; Wang T, 2007, PATTERN RECOGN LETT, V28, P501, DOI 10.1016/j.patrec.2006.09.004	37	11	12	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1148	1152		10.1109/TPAMI.2010.27	http://dx.doi.org/10.1109/TPAMI.2010.27			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431139	Green Submitted			2022-12-18	WOS:000276671900016
J	Raj, A; Wiggins, CH				Raj, Anil; Wiggins, Chris H.			An Information-Theoretic Derivation of Min-Cut-Based Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphs; clustering; information theory; min-cut; Information Bottleneck; graph diffusion		Min-cut clustering, based on minimizing one of two heuristic cost functions proposed by Shi and Malik nearly a decade ago, has spawned tremendous research, both analytic and algorithmic, in the graph partitioning and image segmentation communities over the last decade. It is, however, unclear if these heuristics can be derived from a more general principle, facilitating generalization to new problem settings. Motivated by an existing graph partitioning framework, we derive relationships between optimizing relevance information, as defined in the Information Bottleneck method, and the regularized cut in a K-partitioned graph. For fast-mixing graphs, we show that the cost functions introduced by Shi and Malik can be well approximated as the rate of loss of predictive information about the location of random walkers on the graph. For graphs drawn from a generative model designed to describe community structure, the optimal information-theoretic partition and the optimal min-cut partition are shown to be the same with high probability.	[Raj, Anil; Wiggins, Chris H.] Columbia Univ, Dept Appl Phys & Appl Math, New York, NY 10027 USA; [Wiggins, Chris H.] Columbia Univ, Ctr Computat Biol & Bioinformat, New York, NY 10027 USA	Columbia University; Columbia University	Raj, A (corresponding author), Columbia Univ, Dept Appl Phys & Appl Math, 200 SW Mudd Bldg,MC 4701,500 W 120th St, New York, NY 10027 USA.	ar2384@columbia.edu; chris.wiggins@columbia.edu		Raj, Anil/0000-0003-4412-0883	National Institutes of Health (NIH) [NIH 1U54CA121852-01A1, NIH 5PN2EY016586-03]; US National Science Foundation [IIS-0705580]; NATIONAL CANCER INSTITUTE [U54CA121852] Funding Source: NIH RePORTER; NATIONAL EYE INSTITUTE [PN2EY016586] Funding Source: NIH RePORTER	National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US National Science Foundation(National Science Foundation (NSF)); NATIONAL CANCER INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))	The work of Chris H. Wiggins was supported by the National Institutes of Health (NIH) under grants NIH 1U54CA121852-01A1 and NIH 5PN2EY016586-03, and by the US National Science Foundation under grant IIS-0705580.	Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; FIEDLER M, 1973, CZECH MATH J, V23, P298; HOLLAND PW, 1976, SOCIOL METHODOL, P1; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Meila Marina, 2001, P INT C AI STAT; NADLER B, 2005, ADV NEURAL INFORM PR, V18, P955; SHAN JH, 2001, CHEM J INTERNET, V3, P55; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Slonim N, 2002, THESIS HEBREW U JERU; Tishby N., 2001, ADV NEURAL INFORM PR; Tishby N., 2000, INF BOTTLE METHOD, DOI [10.48550/ARXIV.PHYSICS/0004057, DOI 10.48550/ARXIV.PHYSICS/0004057]; Wagner D., 1993, P 18 INT S MATH FDN, P744; Ziv E, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.046117	15	11	11	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					988	995		10.1109/TPAMI.2009.124	http://dx.doi.org/10.1109/TPAMI.2009.124			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431126	Green Submitted, Green Accepted			2022-12-18	WOS:000276671900003
J	Ko, AHR; Cavalin, PR; Sabourin, R; Britto, AD				Ko, Albert Hung-Ren; Cavalin, Paulo Rodrigo; Sabourin, Robert; Britto, Alceu de Souza, Jr.			Leave-One-Out-Training and Leave-One-Out-Testing Hidden Markov Models for a Handwritten Numeral Recognizer: The Implications of a Single Classifier and Multiple Classifications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov Models; ensemble of classifiers; sequence; noise; leave one out; pattern recognition		Hidden Markov Models (HMMs) have been shown to be useful in handwritten pattern recognition. However, owing to their fundamental structure, they have little resistance to unexpected noise among observation sequences. In other words, unexpected noise in a sequence might "break" the normal transmission of states for this sequence, making it unrecognizable to trained models. To resolve this problem, we propose a leave-one-out-training strategy, which will make the models more robust. We also propose a leave-one-out-testing method, which will compensate for some of the negative effects of this noise. The latter is actually an example of a system with a single classifier and multiple classifications. Compared with the 98.00 percent accuracy of the benchmark HMMs, the new system achieves a 98.88 percent accuracy rate on handwritten digits.	[Ko, Albert Hung-Ren] Univ Toronto, Joseph L Rotman Sch Management, Toronto, ON M5S 3E6, Canada; [Cavalin, Paulo Rodrigo] Lab LIVIA, Dept Genie Prod Automatisee, Montreal, PQ H3C 1K3, Canada; [Sabourin, Robert] Ecole Technol Super, Dept Genie Prod Automatisee, Montreal, PQ H3C 1K3, Canada; [Britto, Alceu de Souza, Jr.] PPGIa PUCPR, BR-80215901 Curitiba, Parana, Brazil	University of Toronto; University of Quebec; Ecole de Technologie Superieure - Canada; Pontificia Universidade Catolica do Parana	Ko, AHR (corresponding author), Univ Toronto, Joseph L Rotman Sch Management, 105 St George St, Toronto, ON M5S 3E6, Canada.	drinkblue@gmail.com; cavalin@livia.etsmtl.ca; robert.sabourin@etsmtl.ca; alceu@ppgia.pucpr.br	Sabourin, Robert/J-7642-2012; de Souza Britto Jr, Alceu/AAC-1155-2022	Sabourin, Robert/0000-0002-9098-1011; de Souza Britto Junior, Alceu/0000-0002-3064-3563	NSERC of Canada [OGP0106456]	NSERC of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC))	The authors thank anonymous reviewers for valuable comments. Special thanks to Dr. Daniel Lopresti, who provided insightful feedbacks on the structure of this paper. This work was supported in part by grant OGP0106456 to Robert Sabourin from the NSERC of Canada.	ARICA N, 2000, P 15 INT C PATT REC; Bandyopadhyay S, 2001, IEEE T SYST MAN CY C, V31, P120, DOI 10.1109/5326.923275; Bengio Y., 1999, Neural Computing Surveys, V2; BRITTO A, 2001, THESIS PONTIFICAL CA; BRITTO AS, 2003, INT J DOC ANAL RECOG, V5, P102; Brown MT, 2005, GEOCHEM GEOPHY GEOSY, V6, DOI 10.1029/2004GC000893; Dietterich T. G., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P15; Eppstein D, 1998, P 9 ACM SIAM S DISCR, P619; Gunter S., 2003, International Journal on Document Analysis and Recognition, V5, P224, DOI 10.1007/s10032-002-0088-2; Gunter S, 2002, INT C PATT RECOG, P332, DOI 10.1109/ICPR.2002.1048307; Gunter S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P183, DOI 10.1109/IWFHR.2002.1030906; GUNTER S, 2002, P 3 INT WORKSH MULT, P179; GUNTER S, 2003, P 11 C INT GRAPH SOC; Gunter S, 2003, P INT WORKSH MULTIPL, P326; Halkidi M, 2002, SIGMOD REC, V31, P19, DOI 10.1145/601858.601862; HALKIDI M, 2001, J INTELL INF SYST, V17, P2; KO A, 2007, P 7 INT WORKSH MULT, P52; Ko AHR, 2009, PATTERN ANAL APPL, V12, P21, DOI 10.1007/s10044-007-0094-6; Kuncheva L. I., 2002, Information Fusion, V3, P245, DOI 10.1016/S1566-2535(02)00093-3; MILGRAM J, 1906, P INT JOINT C NEUR N, P2005; Oliveira LS, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P39, DOI 10.1109/IWFHR.2004.99; Oliveira LS, 2002, IEEE T PATTERN ANAL, V24, P1438, DOI 10.1109/TPAMI.2002.1046154; Pakhira MK, 2004, PATTERN RECOGN, V37, P487, DOI 10.1016/j.patcog.2003.06.005; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RADTKE P, 2006, P IEEE WORLD C COMP; RUTA D, 2005, INT J INFORM FUSION, P63; Smyth P, 1997, NEURAL COMPUT, V9, P227, DOI 10.1162/neco.1997.9.2.227; WANG X, 1994, P I PHONETIC SCI, V18, P111; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677	30	11	12	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2168	2178		10.1109/TPAMI.2008.254	http://dx.doi.org/10.1109/TPAMI.2008.254			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834139				2022-12-18	WOS:000271140100006
J	Tao, QP; Scott, SD; Vinodchandran, NV; Osugi, TT; Mueller, B				Tao, Qingping; Scott, Stephen D.; Vinodchandran, N. V.; Osugi, Thomas Takeo; Mueller, Brandon			Kernels for Generalized Multiple-Instance Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernels; support vector machines; generalized multiple-instance learning; content-based image retrieval; biological sequence analysis; fully polynomial randomized approximation schemes	ENUMERATION; ALGORITHMS	The multiple-instance learning (MIL) model has been successful in numerous application areas. Recently, a generalization of this model and an algorithm for it have been introduced, showing significant advantages over the conventional MIL model on certain application areas. Unfortunately, that algorithm is not scalable to high dimensions. We adapt that algorithm to one that uses a support vector machine with our new kernel k(A). This reduces the time complexity from exponential in the dimension to polynomial. Computing our new kernel is equivalent to counting the number of boxes in a discrete bounded space that contain at least one point from each of two multisets. We first show that this problem is #P-complete and then present a fully polynomial randomized approximation scheme (FPRAS) for it. We then extend k(A) by enriching its representation into a new kernel k(min) and also consider a normalized version of k(A) that we call k(A/V) (which may or may not be a kernel but whose approximation yielded positive semidefinite Gram matrices in practice). We then empirically evaluate all three measures on data from content-based image retrieval, biological sequence analysis, and the Musk data sets. We found that our kernels performed well on all data sets relative to algorithms in the conventional MIL model.	[Tao, Qingping] GC Image LLC, Lincoln, NE 68505 USA; [Scott, Stephen D.; Vinodchandran, N. V.] Univ Nebraska, Dept Comp Sci, Lincoln, NE 68588 USA; [Osugi, Thomas Takeo] Sphere Commun, Lincolnshire, IL 60069 USA; [Mueller, Brandon] Gallup Inc, Omaha, NE 68102 USA	University of Nebraska System; University of Nebraska Lincoln	Tao, QP (corresponding author), GC Image LLC, 216 N 11th St,Suite 302, Lincoln, NE 68505 USA.	sscott@cse.unl.edu; vinod@cse.unl.edu			US National Science Foundation [CCR-0092761, CCF-0430991, EPS-0091900]; US National Institutes of Health [RR-P20 RR1765]; NATIONAL CENTER FOR RESEARCH RESOURCES [P20RR017675] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))	The authors thank Toni Dietterich for his Musk partitionings, Qi Zhang, Sally Goldman, and James Wang for the CBIR data (indirectly from Corel and websbots.com), Qi Zhaing for his EMDD/DD code, Ronald Ortner for his boosting-based MIL code, and the anonymous reviewers for their helpful comments. This research was funded in part by US National Science Foundation Grants CCR-0092761, CCF-0430991, and EPS-0091900. It was also Supported In part by US National Institutes of Health Grant RR-P20 RR1765. This work,vas completed in part utilizing the Research Computing Facility, University of Nebraska. Qingping Tao, Thomas Osugi, and Brandon Mueller did this work at the University of Nebraska.	Andrews S., 2002, NIPS, V2, P561; Auer P, 2004, LECT NOTES COMPUT SC, V3201, P63; Auer P., 1997, P 14 INT C MACHINE L, P21; Auer Peter, 1997, P 29 ANN ACM S THEOR, P314; Blockeel H., 2005, P 22 INT C MACH LEAR, P57, DOI DOI 10.1145/1102351.1102359; Blum A, 1998, MACH LEARN, V30, P23, DOI 10.1023/A:1007402410823; BROWN T, 1998, MOL BIOL LABFAX; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Chen YX, 2004, J MACH LEARN RES, V5, P913; Cristianini N., 2000, INTRO SUPPORT VECTOR; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; DERAEDT L, 1998, P 8 INT C IND LOG PR, P1; DIETEL P, 1897, NATURL PFLANZ, V1, P2; DOOLY DR, 2002, J MACHINE LEARNING R, V3, P651; Du D.Z., 2000, WIL INT S D; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.bb.15.060186.001541; Gartner T., 2002, ICML, P179; Goldschmidt R, 2001, FOCUS BIOTECHNOL, V1, P15; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; KARP RM, 1989, J ALGORITHM, V10, P429, DOI 10.1016/0196-6774(89)90038-2; Khardon R, 2005, J MACH LEARN RES, V6, P1405; Khardon R, 2005, J ARTIF INTELL RES, V24, P341, DOI 10.1613/jair.1655; Kim J, 2000, BIOINFORMATICS, V16, P767, DOI 10.1093/bioinformatics/16.9.767; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; LITTLESTONE N, 1991, PROCEEDINGS OF THE FOURTH ANNUAL WORKSHOP ON COMPUTATIONAL LEARNING THEORY, P147; Littlestone N., 1988, Machine Learning, V2, P285, DOI 10.1023/A:1022869011914; Long PM, 1998, MACH LEARN, V30, P7, DOI 10.1023/A:1007450326753; Maass W, 1998, INFORM COMPUT, V141, P66, DOI 10.1006/inco.1997.2686; Maron O, 1998, ADV NEUR IN, V10, P570; Maron O., 1998, P 15 INT C MACH LEAR, P341; Papadimitriou CH., 1993, COMPUT COMPLEX; RAMON J, 2000, P ICML WORKSH ATTR V; RAY S, 2001, P 18 INT C MACH LEAR, P425; Ray S, 2005, P 22 INT C MACHINE L, P697, DOI DOI 10.1145/1102351.1102439; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Scholkopf B, 2002, LECT NOTES ARTIF INT, V2430, P511; Scholkopf B., 2001, LEARNING KERNELS SUP; Scholkopf Bernhard, 1997, SUPPORT VECTOR LEARN; Scott W, 2005, CR-NEW CENTEN REV, V5, P35, DOI 10.1353/ncr.2005.0047; TAKIMOTO E, 2003, J MACHINE LEARNING R, V4, P773; TAO Q, 2004, P 17 INT FLOR ART IN, P530; Tao Q., 2004, P 21 INT C MACH LEAR, P799; Tao QP, 2004, PROC INT C TOOLS ART, P272; VALIANT LG, 1979, SIAM J COMPUT, V8, P410, DOI 10.1137/0208032; Vapnik V.N, 1998, STAT LEARNING THEORY; VONHEIJNE G, 1992, J MOL BIOL, V225, P487, DOI 10.1016/0022-2836(92)90934-C; WANG C, 2004, TRUNLCSE20043 U NEBR; Wang Jun, 2000, ICML, P1119; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; WARMUTH MK, 2005, P 18 ANN C LEARN THE, P366; Weidmann N, 2003, LECT NOTES ARTIF INT, V2837, P468; Yang C., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P233, DOI 10.1109/ICDE.2000.839416; Zhang Q, 2002, ADV NEUR IN, V14, P1073; ZHANG Q, 2002, P 19 INT C MACH LEAR, P682; ZHANG T, 2000, ADV NEURAL INFORM PR, P703; Zhou ZH, 2003, PROC INT C TOOLS ART, P565, DOI 10.1109/TAI.2003.1250242	59	11	11	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2084	2097		10.1109/TPAMI.2007.70846	http://dx.doi.org/10.1109/TPAMI.2007.70846			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988944				2022-12-18	WOS:000260033900002
J	Wang, JM; Fleet, DJ; Hertzmann, A				Wang, Jack M.; Fleet, David J.; Hertzmann, Aaron			Gaussian process dynamical models for human motion (vol 30, pg 283, 2008)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									[Wang, Jack M.; Fleet, David J.; Hertzmann, Aaron] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 2E4, Canada	University of Toronto	Wang, JM (corresponding author), Univ Toronto, Dept Comp Sci, 40 St George St, Toronto, ON M5S 2E4, Canada.	jmwang@dgp.toronto.edu; fleet@cs.toronto.edu; hertzman@dgp.toronto.edu						Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167	1	11	11	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1118	1118		10.1109/TPAMI.2008.91	http://dx.doi.org/10.1109/TPAMI.2008.91			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW					2022-12-18	WOS:000254872500017
J	Santos, JM; de Sa, JM; Alexandre, LA				Santos, Jorge M.; de Sa, Joaquim Marques; Alexandre, Luis A.			LEGClust - A clustering algorithm based on layered entropic subgraphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; entropy; graphs	DENSITY-FUNCTION; MEAN SHIFT	Hierarchical clustering is a stepwise clustering method usually based on proximity measures between objects or sets of objects from a given data set. The most common proximity measures are distance measures. The derived proximity matrices can be used to build graphs, which provide the basic structure for some clustering methods. We present here a new proximity matrix based on an entropic measure and also a clustering algorithm (LEGClust) that builds layers of subgraphs based on this matrix and uses them and a hierarchical agglomerative clustering technique to form the clusters. Our approach capitalizes on both a graph structure and a hierarchical construction. Moreover, by using entropy as a proximity measure, we are able, with no assumption about the cluster shapes, to capture the local structure of the data, forcing the clustering method to reflect this structure. We present several experiments on artificial and real data sets that provide evidence on the superior performance of this new algorithm when compared with competing ones.	ISEP Polytech, Sch Engn, Dept Math, P-4200072 Oporto, Portugal; INEB Biomed Engn Inst, Oporto, Portugal; FEUP Engn Univ, Dept Elect & Comp Engn, Oporto, Portugal; UBI Beira Interior Univ, Dept Informat, Covilha, Portugal; Networks & Multimedia Grp IT, Covilha, Portugal	Polytechnic Institute of Porto; Universidade do Porto; Universidade do Porto; Universidade da Beira Interior	Santos, JM (corresponding author), ISEP Polytech, Sch Engn, Dept Math, R Dr Antonio Bernardino Almeida 431, P-4200072 Oporto, Portugal.	jms@isep.ipp.pt; jmsa@fe.up.pt; lfbaa@di.ubi.pt	Alexandre, Luís/E-8770-2013	Alexandre, Luís/0000-0002-5133-5025; Santos, Jorge/0000-0002-2760-7756				Berkhin P., 2002, SURVEY CLUSTERING DA; Bowman A., 1997, APPL SMOOTHING TECHN; CHENG CH, 1999, P INT C KNOWL DISC D; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; Ding CHQ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P107, DOI 10.1109/ICDM.2001.989507; DUIN RP, 1998, DUTCH HANDWRITTEN NU; Ester M., 1996, P 2 INT C KNOWL DISC, P226; FIEDLER M, 1975, CZECH MATH J, V25, P619; Fischer B, 2001, LECT NOTES COMPUT SC, V2134, P235; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P513, DOI 10.1109/TPAMI.2003.1190577; FORINA M, 1982, ANN CHIM-ROME, V72, P127; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; Guha S., 1998, SIGMOD Record, V27, P73, DOI 10.1145/276305.276312; Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3; Hartuv E, 2000, INFORM PROCESS LETT, V76, P175, DOI 10.1016/S0020-0190(00)00142-3; Hartuv E, 1999, P 3 ANN INT C COMP M, P188, DOI [10.1145/299432.299483, DOI 10.1145/299432.299483]; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jain AK, 2004, INT C PATT RECOG, P260, DOI 10.1109/ICPR.2004.1334073; Jenssen R, 2004, IEEE IJCNN, P111, DOI 10.1109/IJCNN.2004.1379881; Jenssen R, 2003, IEEE IJCNN, P523; JOHNSON EL, 1993, MATH PROGRAM, V62, P133, DOI 10.1007/BF01585164; KAMVAR S, 2002, P 19 INT C MACH LEAR, P283; Kannan R, 2000, ANN IEEE SYMP FOUND, P367, DOI 10.1109/SFCS.2000.892125; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Karypis G., 2003, CLUTO CLUSTERING TOO; KARYPIS G, 1998, 98019 U MINN DEP COM; KARYPIS G, 2003, CLUTO SOFTWARE PACKA; Kaufman L., 2009, FINDING GROUPS DATA; Lee Y, 2004, IEEE IJCNN, P117, DOI 10.1109/IJCNN.2004.1379882; Lee YJ, 2005, PATTERN RECOGN LETT, V26, P1412, DOI 10.1016/j.patrec.2004.11.025; Li HF, 2004, 2004 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS, P142; MATULA DW, 1972, SIAM J APPL MATH, V22, P459, DOI 10.1137/0122040; MATULA DW, 1970, P LOUIS C COMB GRAPH, P199; Meila M., 2001, P INT C ART INT STAT, P177; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Ng AY, 2001, ADV NEURAL INFORM PR, V14; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Proenca H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119; RENYI A, 1976, SELECTED PAPERS, V2, P526; Sanguinetti G, 2005, 2005 IEEE Workshop on Machine Learning for Signal Processing (MLSP), P55, DOI 10.1109/MLSP.2005.1532874; SANTOS JM, 2005, P 6 WORLD SCI ENG AC; SANTOS JM, 2005, 1 INEB; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silverman B. W., 1986, DENSITY ESTIMATION S, V26; Vermorken Jan B, 2003, Expert Rev Anticancer Ther, V3, P1, DOI 10.1586/14737140.3.1.1; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; XU D, 1999, P INT JOINT C NEUR N, P1716; XU X, 1998, DBSCAN; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103; STANFORD NC160 CANC	61	11	15	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					62	75		10.1109/TPAMI.2007.1142	http://dx.doi.org/10.1109/TPAMI.2007.1142			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000325				2022-12-18	WOS:000250843500006
J	Sharp, GC; Lee, SW; Wehe, DK				Sharp, Gregory C.; Lee, Sang W.; Wehe, David K.			Maximum-likelihood registration of range images with missing data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						range data; registration; maximum-likelihood; pixel classification	MULTIVIEW REGISTRATION; OBJECT VIEWS; 3D; REPRESENTATION; RECOGNITION; INTEGRATION; ALGORITHM; ERROR; SETS	Missing data are common in range images, due to geometric occlusions, limitations in the sensor field of view, poor reflectivity, depth discontinuities, and cast shadows. Using registration to align these data often fails, because points without valid correspondences can be incorrectly matched. This paper presents a maximum-likelihood method for registration of scenes with unmatched or missing data. Using ray casting, correspondences are formed between valid and missing points in each view. These correspondences are used to classify points by their visibility properties, including occlusions, field of view, and shadow regions. The likelihood of each point match is then determined using statistical properties of the sensor, such as noise and outlier distributions. Experiments demonstrate high rates of convergence on complex scenes with varying degrees of overlap.	Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA; Sogang Univ, Dept Media Technol, Seoul 121742, South Korea; Univ Michigan, Ann Arbor, MI 48109 USA	Harvard University; Massachusetts General Hospital; Sogang University; University of Michigan System; University of Michigan	Sharp, GC (corresponding author), Massachusetts Gen Hosp, Dept Radiat Oncol, 55 Fruit St COX3, Boston, MA 02114 USA.	gcsharp@partners.org; slee@sogang.ac.kr; dkw@umich.edu		Sharp, Gregory/0000-0001-8575-9611				Benjemaa R, 1999, IMAGE VISION COMPUT, V17, P113, DOI 10.1016/S0262-8856(98)00115-2; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FUSIELLO A, 2002, P 6 EUR C COMP VIS, pR2; GODIN G, 1994, P SPIE VID 3, V2350; Huber DF, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P153, DOI 10.1109/IM.2001.924424; Johnson AE, 1999, IMAGE VISION COMPUT, V17, P135, DOI 10.1016/S0262-8856(98)00117-6; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Liu YH, 2002, J INTELL ROBOT SYST, V33, P409, DOI 10.1023/A:1015500622943; MASUDA T, 1995, COMPUT VIS IMAGE UND, V61, P295, DOI 10.1006/cviu.1995.1024; Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0; *OH STAT U, OSU MSU WSU RANG IMA; Olson CF, 2000, IEEE T ROBOTIC AUTOM, V16, P55, DOI 10.1109/70.833191; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Rey W.J.J., 1983, INTRO ROBUST QUASIRO; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sharp GC, 2004, IEEE T PATTERN ANAL, V26, P1037, DOI 10.1109/TPAMI.2004.49; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Trobina M., 1995, BIWITR164 COMM TECHN; Trucco E, 1999, PATTERN RECOGN LETT, V20, P889, DOI 10.1016/S0167-8655(99)00055-0; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Whitaker RT, 2002, IEEE T PATTERN ANAL, V24, P1372, DOI 10.1109/TPAMI.2002.1039208; Williams J, 2000, IEICE T INF SYST, VE83D, P1662; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	33	11	11	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					120	130		10.1109/TPAMI.2007.1130	http://dx.doi.org/10.1109/TPAMI.2007.1130			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000329				2022-12-18	WOS:000250843500010
J	Veeramachaneni, S; Nagy, G				Veeramachaneni, Sriharsha; Nagy, George			Analytical results on style-constrained Bayesian classification of pattern fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						style context; field classification; adaptive classification; Bayesian classification	RECOGNITION	We formalize the notion of style context, which accounts for the increased accuracy of the field classifiers reported in this journal recently. We argue that style context forms the basis of all order-independent field classification schemes. We distinguish between intraclass style, which underlies most adaptive classifiers, and interclass style, which is a manifestation of interpattern dependence between the features of the patterns of a field. We show how style-constrained classifiers can be optimized either for field error ( useful for short fields like zip codes) or for singlet error ( for long fields, like business letters). We derive bounds on the reduction of error rate with field length and show that the error rate of the optimal style-constrained field classifier converges asymptotically to the error rate of a style-aware Bayesian singlet classifier.	IRST, Automated Reasoning Syst Div, I-38050 Trento, Italy; Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Johnsson Engn Ctr 6020, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Veeramachaneni, S (corresponding author), IRST, Automated Reasoning Syst Div, Via Sommar 18, I-38050 Trento, Italy.	hveera@gmail.com; nagy@ecse.rpi.edu		Nagy, George/0000-0002-0521-1443				CASTELLI V, 1995, PATTERN RECOGN LETT, V16, P105, DOI 10.1016/0167-8655(94)00074-D; Castelli V, 1996, IEEE T INFORM THEORY, V42, P2102, DOI 10.1109/18.556600; HAUSSLER D, 1991, PROCEEDINGS OF THE FOURTH ANNUAL WORKSHOP ON COMPUTATIONAL LEARNING THEORY, P61; HEATH D, 1976, AM STAT, V30, P188, DOI 10.2307/2683760; Marosi I, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P108, DOI 10.1109/DIAL.2006.28; Nagy G, 2004, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2004.1333692; NAGY G, 1966, IEEE T INFORM THEORY, V12, P215, DOI 10.1109/TIT.1966.1053864; NAGY G, 1992, P 11 INT C PATT REC, V2, P225; Sarkar P., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P382, DOI 10.1109/ICDAR.1999.791804; Sarkar P, 2001, PROC INT CONF DOC, P1169, DOI 10.1109/ICDAR.2001.953969; Sarkar P, 2000, INT C PATT RECOG, P855, DOI 10.1109/ICPR.2000.906209; SARKAR P, 2005, IEEE T PAMI, V27, P14; Veeramachaneni S, 2003, PROC INT CONF DOC, P1060; Veeramachaneni S, 2002, INT C PATT RECOG, P72, DOI 10.1109/ICPR.2002.1048239; Veeramachaneni S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P41, DOI 10.1109/IWFHR.2002.1030882; VEERAMACHANENI S, 2002, P 5 INT WORKSH DOC A, P123; VEERAMACHANENI S, 2005, IEEE T PAMI, V27, P88; Veeramachaneni S., 2003, INT J DOC ANAL RECOG, V6, P154; VEERAMACHANENI S, 2005, P 5 INT INT C MOD US, P515	19	11	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1280	U1		10.1109/TPAMI.2007.1030	http://dx.doi.org/10.1109/TPAMI.2007.1030			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496385				2022-12-18	WOS:000246395300015
J	Papaodysseus, C; Fragoulis, DK; Panagopoulos, M; Panagopoulos, T; Rousopoulos, P; Exarhos, M; Skembris, A				Papaodysseus, Constantin; Fragoulis, Dimitrios K.; Panagopoulos, Mihalis; Panagopoulos, Thanasis; Rousopoulos, Panayiotis; Exarhos, Mihalis; Skembris, Angelos			Determination of the method of construction of 1650 BC wall paintings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image line pattern analysis; archaeological image edge analysis; archaeological object reconstruction; curve fitting; statistical pattern matching		In this paper, a methodology of general applicability is presented for answering the question if an artist used a number of archetypes to draw a painting or if he drew it freehand. In fact, the contour line parts of the drawn objects that potentially correspond to archetypes are initially spotted. Subsequently, the exact form of these archetypes and their appearance throughout the painting is determined. The method has been applied to celebrated Thera Late Bronze Age wall paintings with full success. It has been demonstrated that the artist or group of artists has used seven geometrical archetypes and seven corresponding well-constructed stencils (four hyperbolae, two ellipses, and one Archimedes' spiral) to draw the wall painting "Gathering of Crocus" in 1650 B. C. This method of drawing seems to be unique in the history of arts and of great importance for archaeology, and the history of mathematics and sciences, as well.	Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece	National Technical University of Athens	Papaodysseus, C (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, 9 Heroon Polytechneiou, GR-15773 Athens, Greece.	cpapaod@cs.ntua.gr; dfrag@mail.ntua.gr; mpanagop@central.ntua.gr; thpanag@cs.ece.ntua.gr; panrous@mail.ntua.gr; mexarhos@central.ntua.gr; saverios@mail.ntua.gr	Papaodysseus, Constantin/AAI-6900-2020; Exarhos, Mihalis/AAQ-4363-2021	Panagopoulos, Michail/0000-0003-4585-8185; Papaodysseus, Constantin/0000-0002-5238-5833				Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237; BIRTACHA K, 2000, P 1 INT S WALL PAINT, P159; CRAIG D, 1999, IEEE T PATTERN ANAL, V21, P31; DOUMAS C, 1990, THERA AEGEAN WORLD, V3, P24; Doumas C., 1999, WALL PAINTINGS THERA; EXARCHAKOS T, 1997, HIST MATH MATH BAB A; HEATH T, 1981, HIST GREEK MATH, V0002; Heath Thomas, 1981, HIST GREEK MATH, V1; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Kohonen T, 1984, SELF ORG ASS MEMORY; Lee D, 1997, IEEE SIGNAL PROC LET, V4, P2, DOI 10.1109/97.551685; LUCAS N, 1981, HIST ROOTS ELEMENTAR; Sarfraz M, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P633, DOI 10.1109/IV.2002.1028841; SPANDAGOS E, 2000, ANCIENT GREECE MATH; SZABO A, 1968, BEGINNINGS GREEK MAT; Voss K, 1997, IEEE T PATTERN ANAL, V19, P80, DOI 10.1109/34.566815; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P207, DOI 10.1109/34.368167	18	11	11	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1361	1371		10.1109/TPAMI.2006.183	http://dx.doi.org/10.1109/TPAMI.2006.183			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Engineering	062NC	16929724	Green Submitted			2022-12-18	WOS:000238950800001
J	Lin, SS; Bajcsy, R				Lin, SS; Bajcsy, R			Single-view-point omnidirectional catadioptric cone mirror imager	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						catadioptric camera; imaging geometry; image quality analysis; omnidirectional imaging; optical analysis; panoramic imaging	REFLECTIVE SURFACES	We present here a comprehensive imaging theory about cone mirrors in a single-view-point (SVP) configuration and show that an SVP cone mirror catadioptric system is not only practical but also has unique advantages for certain applications. We show its merits and weaknesses and how to build a workable system.	Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA; Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	University of Pennsylvania; University of California System; University of California Berkeley	Lin, SS (corresponding author), Univ Penn, Dept Elect & Syst Engn, 200 S 33rd St,Moore 203, Philadelphia, PA 19104 USA.	shschon@seas.upenn.edu; bajcsy@eecs.berkeley.edu						Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Basu A, 2001, MG COMP SCI, P123; Benosman R, 1998, INT C PATT RECOG, P767, DOI 10.1109/ICPR.1998.711259; BOGNER S, 1995, P IEEE SMC C, P3100; BORNSTEIN MH, 1984, PSYCHOL ITS ALLIED D, P1; CARATHEODORY C, 1926, MATH NATURWISSENSCHA, V2, P1; Chahl JS, 1997, APPL OPTICS, V36, P8275, DOI 10.1364/AO.36.008275; Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241; Hicks RA, 2001, PROC CVPR IEEE, P584; Hicks RA, 2001, IMAGE VISION COMPUT, V19, P773, DOI 10.1016/S0262-8856(00)00104-9; Hua H, 2001, PROC CVPR IEEE, P960; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; Ishiguro H, 2001, MG COMP SCI, P23; KANG SB, 1997, INT J COMPUTER VISIO, V25; Krishnan A, 1996, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.1996.517100; Lin SS, 2003, IEEE INT CONF ROBOT, P1694, DOI 10.1109/ROBOT.2003.1241838; Lin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P102, DOI 10.1109/ICCV.2001.937610; LIN SS, 2003, THESIS U PENNSYLVANI; MURRAY DW, 1995, COMPUT VIS IMAGE UND, V61, P285, DOI 10.1006/cviu.1995.1021; NAGAHARA H, 2002, P IEEE INT C ROB AUT, V1, P900; NALWA VS, 2001, Patent No. 6219090; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Rees D. W., 1970, US Patent, Patent No. 3505465; SMITH WJ, 2000, MODERN OPTICAL ENG D, P1; Southwell D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P378, DOI 10.1109/ICPR.1996.546053; Southwell D, 1996, IEEE INT CONF ROBOT, P3253, DOI 10.1109/ROBOT.1996.509208; SVOBODA T, 1998, P 5 EUR C COMP VIS, P218; Swaminathan R, 2003, PROC CVPR IEEE, P594; YAGI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P11, DOI 10.1109/70.285581; Yagi Y, 1999, IEICE T INF SYST, VE82D, P568; YAMAZAWA K, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1029, DOI 10.1109/IROS.1993.583287	31	11	14	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					840	845		10.1109/TPAMI.2006.106	http://dx.doi.org/10.1109/TPAMI.2006.106			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640270	Green Submitted			2022-12-18	WOS:000235885700016
J	Marola, G				Marola, G			A technique for finding the symmetry axes of implicit polynomial curves under perspective projection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symmetry axis; perspective projection; invariants; implicit polynomial representation		This paper presents an algebraic technique for detecting the symmetry axes of a perspectively projected plane curve. The procedure applies to implicit polynomials which has been fitted to 2D image data acquired by means of a photo camera or a TV set. The effectiveness of the proposed method has been demonstrated experimentally by using both synthetic and real images.	Univ Pisa, Dept Informat Engn, I-56122 Pisa, Italy	University of Pisa	Marola, G (corresponding author), Univ Pisa, Dept Informat Engn, Via Caruso, I-56122 Pisa, Italy.	giovanni.marola@iet.unipi.it						BLAKE A, 1993, P INT C PATT REC, P724; FRANCOIS ARJ, 2002, P 16 INT C PATT REC, V4; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; Keren D., 1994, IEEE T PATTERN ANAL, V16; Lei YW, 1999, PATTERN RECOGN, V32, P167, DOI 10.1016/S0031-3203(98)00135-6; OH WG, 1990, P INT C PATT REC, P328; PEI SC, 1992, PATTERN RECOGN, V25, P913, DOI 10.1016/0031-3203(92)90057-P; Press W. H., 1992, NUMERICAL RECIPES; Shen DG, 1999, IEEE T PATTERN ANAL, V21, P466, DOI 10.1109/34.765657; TASDIZEN T, 1999, P IEEE C COMP VIS PA; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; YIP RK, 1994, IEEE T PATTERN ANAL, V16	12	11	12	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					465	470		10.1109/TPAMI.2005.45	http://dx.doi.org/10.1109/TPAMI.2005.45			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747801				2022-12-18	WOS:000226300200015
J	Xiong, Y; Huo, Q; Chan, CK				Xiong, Y; Huo, Q; Chan, CK			A discrete contextual stochastic model for the off line recognition of handwritten Chinese characters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						offline recognition of handwritten Chinese characters; contextual stochastic model; discriminative training; Markov random field	HIDDEN MARKOV-MODELS; SPEECH RECOGNITION; STATISTICAL-ANALYSIS; CLASSIFICATION	We study a discrete contextual stochastic (CS) model for complex and variant patterns like handwritten Chinese characters. Three fundamental problems of using CS models for character recognition are discussed and several practical techniques for solving these problems are investigated. A formulation for discriminative training of CS model parameters is also introduced and its practical usage investigated. To illustrate the characteristics of the various algorithms, comparative experiments are performed on a recognition task with a vocabulary consisting of 50 pairs of highly similar handwritten Chinese characters. The experimental results confirm the effectiveness of the discriminative training for improving recognition performance.	Hewlett Packard Labs, Palo Alto, CA 94304 USA; Univ Hong Kong, Dept Comp Sci & Informat Syst, Hong Kong, Hong Kong, Peoples R China	Hewlett-Packard; University of Hong Kong	Xiong, Y (corresponding author), Hewlett Packard Labs, 1501 Page Mill Rd,MS 1L-15, Palo Alto, CA 94304 USA.	yan_xiong@hp.com; qhuo@csis.hku.hk						BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; Chellappa R, 1993, MARKOV RANDOM FIELDS; DEVIJVER PA, 1993, ADV APPL STAT STAT I, V1, P187; Duda R.O., 1973, J ROYAL STAT SOC SER; FU KS, 1980, STAT PATTERN CLASSIF; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HASLETT J, 1985, PATTERN RECOGN, V18, P287, DOI 10.1016/0031-3203(85)90054-8; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; Huo Q, 1996, COMPUT SPEECH LANG, V10, P95, DOI 10.1006/csla.1996.0006; HUO Q, 1993, SPEECH COMMUN, V13, P307, DOI 10.1016/0167-6393(93)90029-K; HUO Q, 1995, P EUR 95 MADR SPAIN, P101; HUO QA, 1995, PATTERN RECOGN, V28, P513, DOI 10.1016/0031-3203(94)00117-5; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257, DOI 10.1109/89.568732; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Kindermann R., 1980, MARKOV RANDOM FIELDS, DOI [10.1090/conm/001, DOI 10.1090/CONM/001]; KITTLER J, 1985, IEEE T GEOSCI REMOTE, V23, P855, DOI 10.1109/TGRS.1985.289471; Leung S.-L., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P432, DOI 10.1109/ICIP.1995.537664; Li S., 1995, MARKOV RANDOM FIELD, P1; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; Parker T, 1998, COMPUTER, V31, P12; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; SAON G, 1997, AUTOMATIC BANKCHECK, P309; Wong PK, 1998, IEEE T PATTERN ANAL, V20, P1016, DOI 10.1109/34.713366; XIONG Y, 1997, P INTL C DIG SIGN PR, P1095; XIONG Y, 1997, P 13 INTL C DIG SIGN, P1099; 1998, INTL J PATTERN REC 1, V12; 1996, IEICE T INFORMAT E D, V79; 1997, PATTERN RECOGNITION, V30; IEICE T INFORMAT E D, V77, P94; 1998, INTL J PATTERN REC 2, V12	32	11	11	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2001	23	7					774	782		10.1109/34.935851	http://dx.doi.org/10.1109/34.935851			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	449TV		Green Submitted			2022-12-18	WOS:000169704000008
J	Priebe, CE				Priebe, CE			Olfactory classification via interpoint distance analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ensemble classifiers; combining classifiers; nonparametric; nearest-neighbor; interpoint distance; rank statistic; subsample statistic; functional data; artificial nose; electronic nose; analytical chemistry; chemometrics		Detection of the presence of a single prespecified chemical analyte at low concentration in complex backgrounds is a difficult application for chemical sensors. This article considers a database of artificial nose observations designed specifically to allow for the investigation of chemical sensor data analysis performance on the problem of trichloroethylene (TCE) detection. We consider an approach to this application which uses an ensemble of subsample classifiers based on interpoint distances. Experimental results are presented indicating that our nonparametric methodology is a useful tool in olfactory classification.	Johns Hopkins Univ, Whiting Sch Engn, Dept Math Sci, Baltimore, MD 21218 USA	Johns Hopkins University	Priebe, CE (corresponding author), Johns Hopkins Univ, Whiting Sch Engn, Dept Math Sci, Baltimore, MD 21218 USA.	cep@jhu.edu	Priebe, Carey E./A-3305-2010					[Anonymous], 1999, ADV KERNEL METHODS S, DOI DOI 10.17877/DE290R-5098; Bickel P., 2015, MATH STAT BASIC IDEA; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2017, CLASSIFICATION REGRE; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; David H. A., 1981, ORDER STAT; Dickinson TA, 1996, NATURE, V382, P697, DOI 10.1038/382697a0; Dietterich TG, 1997, AI MAG, V18, P97; FRIEDMAN JH, 1996, UNPUB ANOTHER APPROA; GUITIERREZOSUNA R, 1998, IEEE SPECTRUM, V35; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T.J., 1990, GEN ADDITIVE MODELS; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Kaplan G, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.669973; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Maa JF, 1996, ANN STAT, V24, P1069; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Nagle HT, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.715180; Priebe CE, 1999, COMMUN STAT-THEOR M, V28, P2871, DOI 10.1080/03610929908832454; PRIEBE CE, 2000, P STAT COMP SECT AM; Ramsay J.O., 1997, FUNCTIONAL DATA ANAL, DOI 10.1007/978-1-4757-7107-7; Ripley BD., 1996; SKALAK D, 1997, THESIS U MASSACHUSET; Stern P, 1999, SCIENCE, V286, P703, DOI 10.1126/science.286.5440.703; Wand M.P., 1995, KERNEL SMOOTHING; White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Xie JD, 2000, J NONPARAMETR STAT, V12, P661, DOI 10.1080/10485250008832827; 1998, IEEE SPECTRUM, V35, P22	35	11	12	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					404	413		10.1109/34.917575	http://dx.doi.org/10.1109/34.917575			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900006
J	Dickinson, SJ; Wilkes, D; Tsotsos, JK				Dickinson, SJ; Wilkes, D; Tsotsos, JK			A computational model of view degeneracy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						view degeneracy; aspect graphs; object recognition	3-D OBJECT RECOGNITION; ASPECT GRAPH; IMAGE	We quantify the observation by Kender and Freudenstein [24] that degenerate Views occupy a significant fraction of the viewing sphere surrounding an object. For a perspective camera geometry, we introduce a computational model that can be used to estimate the probability that a view degeneracy will occur in a random view of a polyhedral object. For a typical recognition system parameterization, view degeneracies typically occur with probabilities of 20 percent and, depending on the parameterization, as high as 50 percent. We discuss the impact of view degeneracy on the problem of object recognition and, for a particular recognition framework, relate the cost of object disambiguation to the probability of view degeneracy. To reduce this cost, we incorporate our model of view degeneracy in an active focal length control paradigm that balances the probability of View degeneracy with the camera field of view. In order to validate both our view degeneracy model as well as our active focal length control model, a set of experiments are reported using a real recognition system operating on real images.	Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA; Rutgers State Univ, Ctr Cognit Sci, New Brunswick, NJ 08903 USA; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A4, Canada	Rutgers State University New Brunswick; Rutgers State University New Brunswick; University of Toronto	Dickinson, SJ (corresponding author), Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08903 USA.		Tsotsos, John K/G-3436-2011; Wilkes, David/ABD-5065-2021; Tsotsos, John/N-1131-2019	Wilkes, David/0000-0002-9259-7144; Tsotsos, John/0000-0002-8621-9147				[Anonymous], 1985, PERCEPTUAL ORG VISUA; BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BERG JL, 1993, COMP STAND INTER, V15, P1, DOI 10.1016/0920-5489(93)90022-J; BERGEVIN R, 1992, CVGIP-IMAG UNDERSTAN, V55, P73, DOI 10.1016/1049-9660(92)90007-P; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BRUNNSTROM K, 1991, KTHNAP9131SE ISRN CV; BURNS J, 1987, P INT JOINT C ART IN, P763; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; DICKINSON S, 1990, VISION CONVERGENCE D; DICKINSON S, 1994, P EUR C COMP VIS ECC; DICKINSON S, 1989, CARTR453 U MAR; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; EGGERT D, 1990, PATTERN RECOGN LETT, V11, P751, DOI 10.1016/0167-8655(90)90094-I; EGGERT DW, 1993, IEEE T PATTERN ANAL, V15, P1114, DOI 10.1109/34.244674; FAIRWOOD RC, 1991, IMAGE VISION COMPUT, V9, P113, DOI 10.1016/0262-8856(91)90021-G; Gigus Z., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P654, DOI 10.1109/CVPR.1988.196306; GIGUS Z, 1988, P 2 IEEE INT C COMP, P30; HUMMEL JE, 1992, PSYCHOL REV, V99, P480, DOI 10.1037/0033-295X.99.3.480; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KENDER J, 1987, P 10 INT JOINT C ART, P801; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; RAJA NS, 1992, IMAGE VISION COMPUT, V10, P179, DOI 10.1016/0262-8856(92)90069-F; RAJA NS, 1994, CVGIP-IMAG UNDERSTAN, V60, P44, DOI 10.1006/ciun.1994.1030; SALLAM M, 1991, PATTERN RECOGN LETT, V12, P171, DOI 10.1016/0167-8655(91)90046-O; Shimshoni I., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P140, DOI 10.1109/WQV.1993.262941; SRIPRADISVARAKU.T, 1989, P IEEE WORKSH INT 3D, P109; STEWMAN JH, 1990, COMPUT VISION GRAPH, V51, P20, DOI 10.1016/S0734-189X(05)80060-X; SWAIN M, 1988, P DARPA IMAGE UNDERS, P690; THOMPSON D, 1987, P DARPA IMAGE UNDERS, P93; Tsotsos J.K., 1993, SPATIAL VISION HUMAN; Weinshall D, 1997, IEEE T PATTERN ANAL, V19, P97, DOI 10.1109/34.574783; WILKES D, 1994, THESIS; WILKES D, 1995, P INT C COMP VIS CAM; WILKES D, 1992, P COMP VIS PATT REC; WILKES D, 1993, P 8 SCAND C IM AN U; Witkin A. P., 1983, HUMAN MACHINE VISION	43	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					673	689		10.1109/34.784283	http://dx.doi.org/10.1109/34.784283			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000001
J	Bowyer, K				Bowyer, K			Editorial	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					1	2						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900001
J	Amir, A; Lindenbaum, M				Amir, A; Lindenbaum, M			Grouping-based nonadditive verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hypothesis verification; object recognition; perceptual grouping; maximum likelihood; graph clustering; Kullback Leibler distance	RECOGNITION	Verification is the final decision stage in many object recognition processes. It is carried out by evaluating a score for every hypothesis and choosing the hypotheses associated with the highest score. This paper suggests a grouping-based verification paradigm, relying on the observation that a group of data features belonging to a hypothesized object instance should be a "good group." Therefore, it should support perceptual grouping information available from the image by grouping relations. The proposed score, which is the joint likelihood of these grouping cues, quantifies this observation in a probabilistic framework. Experiments with synthetic and real images show that the proposed method performs better in difficult cases.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	International Business Machines (IBM); Technion Israel Institute of Technology	Amir, A (corresponding author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.	arnon@almaden.ibm.com; mic@cs.technion.ac.il						Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; AMIR A, 1995, CIS9518 TECHN; AMIR A, 1996, ECCV 96 CAMBR, V1, P371; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BREUEL TM, 1993, 9302 IDIAP; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; GRIMSON WEL, 1990, T PATTERN ANAL MACHI, V13; GRIMSON WEL, 1991, T PATTERN ANAL MACHI, V14; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Lindenbaum M, 1997, IEEE T PATTERN ANAL, V19, P1251, DOI 10.1109/34.632984; LINDENBAUM M, 1995, IEEE T PATTERN ANAL, V17, P666, DOI 10.1109/34.391409; Mundy J., 1992, GEOMETRIC INVARIANCE; Mundy J. L., 1994, Image Understanding Workshop. Proceedings, P1393; Papoulis A., 1991, COMMUNICATIONS SIGNA, V3; ROTHWELL C, 1996, ECCV 96 CAMBR, V1, P599; SARACHIK KB, 1993, CVPR, P400; SARKAR S, 1993, IEEE T SYST MAN CYB, V23, P382, DOI 10.1109/21.229452; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; WOLFSON HJ, 1990, EUR C COMP VIS, P526	21	11	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					186	192		10.1109/34.659936	http://dx.doi.org/10.1109/34.659936			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800007
J	Weng, J; Cui, YT; Ahuja, N				Weng, J; Cui, YT; Ahuja, N			Transitory image sequences, asymptotic properties, and estimation of motion and structure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; struction from motion; image sequences; optimal estimation; Cramer-Rao bound; optical flow		A transitory image sequence is one in which no scene element is visible through the entire sequence. When a camera system scans a scene which cannot be covered by a single view, the image sequence is transitory. This article deals with some major theoretical and algorithmic issues associated with the task of estimating structure and motion from transitory image sequences. It is shown that integration with a transitory sequence has properties that are very different from those with a non-transitory one. Two representations, world-centered (WC) and camera-centered (CC), behave very differently with a transitory sequence. The asymptotic error rates derived in this article indicate that one representation is significantly superior to the other, depending on whether one needs camera-centered or world-centered estimates. To establish the tightness of these error rates, it has been shown that these reachable error rates are in fact the lowest possible given by a theoretical lower error bound, the Cramer-Rao error bound. Based on these results, we introduce an efficient ''cross-frame'' estimation technique for the CC representation. For the WC representation, our analysis indicates that a good technique should be based on camera global pose instead of interframe motions. In addition to testing with synthetic data, rigorous experiments were conducted with real-image sequences taken by a fully calibrated camera system. The comparison of the experimental results with the ground truth has demonstrated that a good accuracy can be obtained from transitory image sequences.	UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	Weng, J (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							[Anonymous], 1984, ESTIMATION CONTROL S; AYACHE N, 1987, 1ST P INT C COMP VIS, P73; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; CUI N, 1994, CVGIP-IMAG UNDERSTAN, V59, P154, DOI 10.1006/ciun.1994.1010; Luenberger D. G., 1969, OPTIMIZATION VECTOR; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; RAO CR, 1973, LINEAR STATISTICAL I; SHARIAT H, 1990, IEEE T PATTERN ANAL, V12, P417, DOI 10.1109/34.55102; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WENG J, IEEE T PATTERN ANAL, V14, P965; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592	12	11	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					451	464		10.1109/34.589205	http://dx.doi.org/10.1109/34.589205			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300004
J	Sato, Y; Moriyama, M; Hanayama, M; Naito, H; Tamura, S				Sato, Y; Moriyama, M; Hanayama, M; Naito, H; Tamura, S			Acquiring 3D models of non-rigid moving objects from time and viewpoint varying image sequences: A step toward left ventricle recovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D shape recovery; non-rigid object; left ventricle; angiographic image analysis; multiple view integration; time-viewpoint space	CONTOURS; SHAPE	This paper describes a method for the accurate recovery of time-varying 3D shapes with known cycle from images with different. viewpoints as well as times, aiming at the recovery of the left ventricular shapes. ur recovery method is based on the integration of apparent contours from different viewpoints. We perform direct fitting to a 4D closed surface model based on B-splines so as to deal with fragmented contours such as extracted from x-ray cineangiocardiograms. The method is quantitatively evaluated using synthesized and real image sequences.	OSAKA UNIV HOSP,DEPT RADIOL,OSAKA 553,JAPAN	Osaka University	Sato, Y (corresponding author), OSAKA UNIV,SCH MED,BIOMED RES CTR,DIV FUNCT DIAGNOST IMAGING,2-2 YAMADAOKA,SUITA,OSAKA 565,JAPAN.		Sato, Yoshinobu/C-9361-2009; naito, hiroyoshi/E-7083-2011	naito, hiroyoshi/0000-0002-8138-6077				CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; EIHO S, 1984, IEEE P COMPUTERS CAR, P63; GOSHTASBY A, 1995, IEEE T MED IMAGING, V14, P56, DOI 10.1109/42.370402; Huang T. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P361, DOI 10.1109/ICPR.1990.118129; KAIHORI H, 1995, 1995 KANS SECT JONT, pG352; MATHENY A, 1995, IEEE T PATTERN ANAL, V17, P967, DOI 10.1109/34.464561; Pentland A., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P288, DOI 10.1109/WVM.1991.212773; Prause G.P.M., 1994, IEEE P COMPUTER CARD, P193; Schudy, 1979, P 6 C COMP APPL RAD; SHEN X, 1994, P EUR C COMP VIS 94, P225; TARATORIN AM, 1995, IEEE T MED IMAGING, V12, P521; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; ZHAO C, 1994, P 3 EUR C COMP VIS S, P417; ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734	15	11	12	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					253	259		10.1109/34.584103	http://dx.doi.org/10.1109/34.584103			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200007
J	Earnshaw, AM; Blostein, SD				Earnshaw, AM; Blostein, SD			The performance of camera translation direction estimators from optical flow: Analysis, comparison, and theoretical limits	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						translation direction estimation; linear constraints; optical flow; error analysis; performance comparison	MOTION; VIEWS	A noniterative method using optical flow to recover the translation direction oi amoving camera has been previously proposed in [4]. We present a detailed explanation of the bias in this algorithm and compare methods for eliminating this bias, as well as presenting a comprehensive error analysis. This analysis includes a necessary modification to the Cramer-Rao lower bound (CRLB). We propose a simple iterative modification to the algorithm which produces unbiased translation direction estimates that approach the CRLB. Numerical results are used to compare the various techniques on synthetic and real image sequences.			Earnshaw, AM (corresponding author), QUEENS UNIV,DEPT ELECT & COMP ENGN,KINGSTON,ON K7L 3N6,CANADA.							BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; EARNSHAW AM, 1995, 9510 QUEENS U DEP EL; GORMAN JD, 1990, IEEE T INFORMATION T, V3, P1285; HEEGER DJ, 1992, INT J COMPUTER VISIO, V7, P85; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jepson A. D., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P124, DOI 10.1109/WVM.1991.212779; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; KANATANI K, 1993, IEEE T PATTERN ANAL, V15, P37, DOI 10.1109/34.184773; Kanatani K., 1993, P 4 INT C COMP VIS B, P599; MACLEAN WJ, 1994, COMMUNICATION; OTTE M, 1994, P 3 EUR C COMP VIS, V1, P61; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Wilkinson JH., 1965, ALGEBRAIC EIGENVALUE	15	11	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					927	932		10.1109/34.537346	http://dx.doi.org/10.1109/34.537346			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900006
J	Hurn, M; Jennison, C				Hurn, M; Jennison, C			An extension of Geman and Reynolds' approach to constrained restoration and the recovery of discontinuities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical image reconstruction; discontinuity recovery; parameter selection; Gibbs sampler; Metropolis algorithm; simulated annealing		Geman and Reynolds [7] present an approach to linear image restoration which provides for recovery of horizontal and vertical gray-level discontinuities from blurred and noisy observations. We extend their model and parameter selection method to include diagonal discontinuities. A hazard of this modeling approach is identified and addressed. We also comment on the truncated Gibbs sampler suggested in the paper [7].			Hurn, M (corresponding author), UNIV BATH,SCH MATH SCI,BATH BA2 7AY,AVON,ENGLAND.							BADDELEY A, 1993, STAT IMAGES; BESAG J, 1986, J R STAT SOC B, V48, P259; Besag J. E., 1989, J APPL STAT, V16, P395, DOI [10.1080/02664768900000049, DOI 10.1080/02664768900000049]; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN D, 1993, MARKOV RANDOM FIELDS; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Glasbey CA, 1995, IMAGE ANAL BIOL SCI; GRENANDER U, 1994, J R STAT SOC B, V56, P549; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HURN M, 1994, 9402 U BATH; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; YANG C, 1993, EFFICIENT STOCHASTIC	14	11	11	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					657	662		10.1109/34.506418	http://dx.doi.org/10.1109/34.506418			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400011
J	Deng, WA; Lyengar, SS				Deng, WA; Lyengar, SS			A new probabilistic relaxation scheme and its application to edge detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						probabilistic relaxation; dictionary scheme; MRF; edge detection	DISCRETE RELAXATION; ALGORITHM	This paper presents a new scheme for probabilistic relaxation labeling that consists of an update function and a dictionary construction method. The nonlinear update function is derived from Markov Random Field theory and Bayes' formula. The method combines evidence from neighboring label assignments and eliminates label ambiguity efficiently. This result is important for a variety of image processing tasks, such as image restoration, edge enhancement, edge detection, pixel classification, and image segmentation. We successfully applied this method to edge detection. The relaxation step of the proposed edge-detection algorithm greatly reduces noise effects, gets better edge localization such as line ends and corners, and plays a crucial role in refining edge outputs. The experiments show that our algorithm converges quickly and is robust in noisy environments.			Deng, WA (corresponding author), LOUISIANA STATE UNIV,DEPT COMP SCI,BATON ROUGE,LA 70803, USA.							CANNY J, 1986, IEEE T PATTERN ANAL, V8, P699; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P227, DOI 10.1016/0734-189X(83)90115-9; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GU J, 1987, IEEE T PATTERN ANAL, V9, P816, DOI 10.1109/TPAMI.1987.4767988; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12, P165, DOI 10.1109/34.44403; HANCOCK ER, 1990, PATTERN RECOGN, V23, P711, DOI 10.1016/0031-3203(90)90094-2; HANCOCK ER, 1990, IEEE 10 ICPR, V1, P523; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; Hilditch C.J., 1969, MACH INTELL, P403; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; Kittler J., 1989, International Journal of Pattern Recognition and Artificial Intelligence, V3, P29, DOI 10.1142/S021800148900005X; KITTLER J, 1984, P 7 ICPR MONTR; KITTLER J, 1986, COMPUTER VISION GRAP; PELKOWITZ L, 1990, IEEE T SYST MAN CYB, V20, P709, DOI 10.1109/21.57279; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHACHTER BJ, 1977, IEEE T SYST MAN CYB, V7, P813; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7	18	11	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					432	437		10.1109/34.491624	http://dx.doi.org/10.1109/34.491624			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500008
J	Anh, V; Shi, JY; Tsui, HT				Anh, V; Shi, JY; Tsui, HT			Scaling theorems for zero crossings of bandlimited signals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scaling theorems; zero crossings; Gaussian kernels; scale space; multiscale analysis; signal descriptions; bandlimited signals; Whittaker-Shannon sampling theorem; quadratic forms	EDGE-DETECTION; VISION	Scale-space filtering is the only known method which provides a hierarchic signal description method by extracting features across a continuum of scales. One of its important characteristics is that it demands the filtering involved does not create generic features as the scale increases. It has been shown in [4], [5], [6] that the Gaussian filter is unique in holding this remarkable property. This is in essence the so-called scaling theorem. In this paper, we propose two scaling theorems for band-limited signals. They are applicable to a broader class of signals and a bigger family of filtering kernels than in [4], [5], [6]. An in-depth discussion of our theorems and the previously published ones is also given.	SHANGHAI JIAO TONG UNIV, INST IMAGE PROC & PATTERN RECOGNIT, SHANGHAI 200030, PEOPLES R CHINA; CHINESE UNIV HONG KONG, DEPT ELECTR ENGN, SHA TIN, HONG KONG	Shanghai Jiao Tong University; Chinese University of Hong Kong	Anh, V (corresponding author), QUEENSLAND UNIV TECHNOL, SCH MATH, GARDENS POINT CAMPUS, GPO BOX 2434, BRISBANE, QLD 4001, AUSTRALIA.		Anh, Vo V/I-9590-2012	Anh, Vo V/0000-0003-2463-2099				BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Barenblatt G. I., 1979, SIMILARITY SELF SIMI; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Bracewell R., 1986, FOURIER TRANSFORM IT; Chandrasekharan K., 1989, CLASSICAL FOURIER TR; Clark J. J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P491; DAUGMAN JG, 1988, J OPT SOC AM A, V5, P1142, DOI 10.1364/JOSAA.5.001142; JERRI AJ, 1977, P IEEE, V65, P1565, DOI 10.1109/PROC.1977.10771; LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Shi J. Y., 1992, Proceedings of the IEEE-SP International Symposium Time-Frequency and Time-Scale Analysis (Cat.No.92TH0478-8), P563, DOI 10.1109/TFTSA.1992.274116; SLEPIAN D, 1976, P IEEE, V64, P292, DOI 10.1109/PROC.1976.10110; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WITKIN AP, 1984, IMAGE UNDERSTANDING; YUILLE AL, 1985, J OPT SOC AM A, V2, P683, DOI 10.1364/JOSAA.2.000683; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	20	11	11	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					309	320		10.1109/34.485558	http://dx.doi.org/10.1109/34.485558			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500007
J	Jacobs, DW				Jacobs, DW			The space requirements of indexing under perspective projections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						indexing; invariants; perspective projection; geometric hashing; 3-D objects; 2-D images; object recognition; space; complexity	OBJECT RECOGNITION	Object recognition systems can be made more efficient through the use of table lookup to match features. The cost of this indexing process depends on the space required to represent groups of model features in such a lookup table. We determine the space required to perform indexing of arbitrary sets of 3-D model points for lookup from a single 2-D image formed under perspective projection. We show that in this case. one must use a 3-D surface to represent model groups, and we provide an analytic description of such a surface. This is in contrast to the cases of scaled-orthographic or affine projection, in which only a 2-D surface is required to represent a group of model features [3], [10]. This demonstrates a fundamental way in which the recognition of objects under perspective projection is more complex than is recognition under other projection models.			Jacobs, DW (corresponding author), NEC RES INST,4 INDEPENDENCE WAY,PRINCETON,NJ 08540, USA.							BREUEL TM, 1993, 9308 IDIAP; Brian Burns J., 1992, GEOMETRIC INVARIANCE; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; CYGANSKI D, 1985, IEEE T PATTERN ANAL, V7, P662, DOI 10.1109/TPAMI.1985.4767722; FAUGERAS OD, 1992, 2 EUR C COMP VIS ECC, P563; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; JACOBS D, IN PRESS INT J COMPU; JACOBS D, 1992, TR1416 MIT AI; JACOBS D, 1992, IEEE C COMP VIS PATT, P439; JACOBS D, 1993, IEEE C COMP VIS PATT, P226; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P238, DOI 10.1109/CCV.1988.589995; MOSES Y, 1992, 2 EUR C COMP VIS, P820; ROTHWELL CA, 1993, P IEEE INT C COMPUTE, P573; SHASHUA A, 1993, P 2 WORKSH APPL INV, P87; Tuller A., 1967, MODERN INTRO GEOMETR; WALLACK A, 1994, IEEE C COMP VIS PATT, P259; WEISS I, 1988, DARPA IM UND WORKSH, P1125; WERMAN M, 1995, 957 HEBR U	19	11	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					330	333		10.1109/34.485561	http://dx.doi.org/10.1109/34.485561			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500010
J	Smith, PW; Nandhakumar, N				Smith, PW; Nandhakumar, N			An improved power cepstrum based stereo correspondence method for textured scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						cepstrum; image correspondence; stereopsis; depth estimation; foreshortening correction		This paper analyzes the performance of cepstral approaches for solving the stereo correspondence problem. A quantitative analysis of the effects of noise,foreshortening differences, and photometric variations on existing cepstral correspondence techniques is presented: A modified approach that Is less sensitive to these effects is developed for textured scenes, and analytical arguments for its robustness are developed. The results of a comparative study of the new cepstral technique, the original cepstral algorithm and the cross-correlation approach are shown and discussed. The performance of the new method is experimentally verified on textured surfaces.			Smith, PW (corresponding author), UNIV VIRGINIA,DEPT ELECT ENGN,CHARLOTTESVILLE,VA 22903, USA.							BANDARI E, 1993, 931 U BRIT COL DEP C; BANDARI E, 1993, P IEEE ICCV BERL, P220; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Horn B., 1986, ROBOT VISION, P1; Lee C.-Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P655, DOI 10.1109/CVPR.1993.341042; LUDWIG KO, 1994, IMAGE VISION COMPUT, V12, P16, DOI 10.1016/0262-8856(94)90052-3; MALLAT S, 1991, IEEE T INFORMATION T, V37; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; OLSON TJ, 1991, INT J COMPUT VISION, V7, P67, DOI 10.1007/BF00130490; Smith P. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P651, DOI 10.1109/CVPR.1993.341044; YESHURUN Y, 1989, IEEE T PATTERN ANAL, V11, P759, DOI 10.1109/34.192471	13	11	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					338	348		10.1109/34.485563	http://dx.doi.org/10.1109/34.485563			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500012
J	HOLT, RJ; NETRAVALI, AN				HOLT, RJ; NETRAVALI, AN			UNIQUENESS OF SOLUTIONS TO 3 PERSPECTIVE VIEWS OF 4 POINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MOTION ESTIMATION; COMPUTER VISION; POLYNOMIAL SYSTEMS; ALGEBRAIC GEOMETRY	MOTION; PROJECTIONS; ALGORITHM	We show that there is, in general, a unique solution for the relative orientation of three cameras simultaneously photographing four feature points on a fixed object. However, multiple solutions are possible, in rare cases, even when the four feature points are not coplanar.			HOLT, RJ (corresponding author), AT&T BELL LABS,600 MT AVE,ROOM 2B-238,MURRAY HILL,NJ 07974, USA.		Holt, Robert J/B-5460-2009					AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Buchberger B., 1979, LECT NOTES COMPUT SC, V72, P3; DEMAZURE M, 1988, INRIA882 TECHN REP; EMIRIS I, 1993, JUL P ACM INT S SYMB, P183; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HARTSHORNE R, 1977, ALGEBRAIC GEOMETRY; Holt R., 1993, Journal of Visual Communication and Image Representation, V4, P14, DOI 10.1006/jvci.1993.1002; HOLT RJ, 1990, AT T1125690070601TM; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; JERIAN C, 2ND P ICCV TARP SPRI; LIU Y, 1988, JUN P CVPR ANN ARB; LIU YC, 1988, COMPUT VISION GRAPH, V43, P37, DOI 10.1016/0734-189X(88)90041-2; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1992, IMAGE VISION COMPUT, V10, P266, DOI 10.1016/0262-8856(92)90040-A; MITICHE A, 1986, HDB PATTERN RECOGNIT, P311; MORGAN AP, 1989, APPL MATH COMPUT, V29, P123, DOI 10.1016/0096-3003(89)90099-4; Netravali A. N., 1989, International Journal of Imaging Systems and Technology, V1, P78, DOI 10.1002/ima.1850010110; Shafarevich IR., 1974, BASIC ALGEBRAIC GEOM, DOI 10.1007/978-3-642-96200-4; STILLMAN M, 1989, MACAULAY USERS MANUA; STURMFELS B, 1994, J ALGEBR COMB, V3, P207, DOI 10.1023/A:1022497624378; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30, P525, DOI 10.1109/TASSP.1982.1163931; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779	28	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					303	307		10.1109/34.368195	http://dx.doi.org/10.1109/34.368195			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000007
J	HELMAN, D; JAJA, J				HELMAN, D; JAJA, J			EFFICIENT IMAGE-PROCESSING ALGORITHMS ON THE SCAN LINE ARRAY PROCESSOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE PROCESSING; PARALLEL ALGORITHMS; SIMD ALGORITHMS; LINEAR ARRAY; SCAN LINE ARRAY PROCESSORS; VIDEO PROCESSOR		We develop efficient algorithms for low and intermediate level images processing on the scan line array processor, a SIMD machine consisting of a linear array of cells that processes images in a scan line fashion. For low level processing, we present algorithms for block DFT, block DCT, convolution, template matching, shrinking, and expanding which run in real-time. By real-time, we mean that, if the required processing is based on neighborhoods of size m x m, then the output lines are generated at a rate of O(m) operations per line and a latency of O(m) scan lines, which is the best that can be achieved on this model. We also develop an algorithm for median filtering which runs in almost real-time at a cost of O(m log m) time per scan line and a latency of [m/2] scan lines. For intermediate level processing, we present optimal algorithms for translation, histogram computation, scaling, and rotation. We also develop efficient algorithms for labelling the connected components and determining the convex hulls of multiple figures which run in O(nlog n) and O(n log(2)n) time, respectively. The latter algorithms are significantly simpler and easier to implement than those already reported in the literature for linear arrays.	UNIV MARYLAND,INST ADV COMP STUDIES,COLLEGE PK,MD 20742; UNIV MARYLAND,SYST RES INST,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park								ALNUWEIRI HM, 1991, DISTRIB COMPUT, P55; BATCHER KE, 1980, IEEE T COMPUT, P836; BAUDET G, 1978, IEEE T COMPUT, P84; CANTONI V, 1987, PARALLEL COMPUTER VI, P3; CHIN D, 1988, IEEE T CONSUMER  MAY, P285; CLOUD EL, 1988, 2ND P S FRONT MASS P, P373; CORMEN T, 1991, INTRO ALGORITHMS, P281; DOSHI K, 1987, IEEE T COMPUT, P460; FISHER AF, 1986, CONTACT DERMATITIS, P338; FISHER AI, 1985, IEEE COMPUTER SOC WO, P484; FOUNTAIN TJ, 1980, IEEE T PATTERN ANAL, P310; FUSHER AL, 1989, IEEE T PATTERN ANAL, P262; HELMAN DR, 1993, THESIS U MARYLAND MA; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Knight S., 1992, Proceedings of the International Conference on Application Specific Array Processors (Cat. No.92TH0453-1), P342, DOI 10.1109/ASAP.1992.218560; LEA RM, 1988, IEEE MICRO       OCT, P10; NICKOLLS JR, 1990, IEEE COMPCON, P25; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; RAMAKRISHNAN IV, 1984, IEEE T COMPUT, P952; REDDAWAY SF, 1973, 1ST ANN S COMP ARCH, P61; SCHAEFER DH, 1987, PARALLEL COMPUTER VI, P15; SHARMA M, 1985, WORKSHOP COMPUTER AR, P92; WEEMS CC, 1989, INT J COMPUT VISION, P251	23	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					47	56		10.1109/34.368153	http://dx.doi.org/10.1109/34.368153			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400005
J	FLYNN, PJ				FLYNN, PJ			3-D OBJECT RECOGNITION WITH SYMMETRICAL MODELS - SYMMETRY EXTRACTION AND ENCODING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note							ROBOT VISION SYSTEM; COMPUTER VISION	Object recognition systems which employ solid models and range data have been a topic of interest for several years. Model databases have the potential to become large in some environments. This paper proposes a pair of techniques for incorporating knowledge of the symmetries of object models into the recognition process. The effects of symmetric models on the speed of an object recognition system is examined in the context of an implemented system employing invariant feature indexing as a correspondence-building mechanism. Groups of model surfaces are enumerated and examined to yield a list of segment label permutations which summarize the model's symmetry. This symmetry extraction process is followed by a symmetry encoding procedure which replaces groups of features which are indistinguishable because of symmetry with a single prototype feature group. Experiments with a large model database demonstrate the utility of these symmetry extraction and encoding techniques.			FLYNN, PJ (corresponding author), WASHINGTON STATE UNIV,SCH ELECT ENGN & COMP SCI,PULLMAN,WA 99164, USA.		Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X				ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; ARMAN F, 1991, JUN IEEE WORKSH DIR, P124; ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; BOARDMAN AD, 1973, SYMMETRY ITS APPLICA; BURNS JB, 1988, 1988 P DARPA IM UND, P711; CHEN CH, 1989, IEEE T SYST MAN CYB, V19, P1535, DOI 10.1109/21.44070; DICKINSON SJ, 1991, P IEEE WORKSHOP DIRE, P85; FLYNN PJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P119, DOI 10.1016/1049-9660(92)90012-R; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; FLYNN PJ, 1992, JUN P IEEE COMP SOC, P322; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; JIANG XY, 1992, CVGIP-GRAPH MODEL IM, V54, P91, DOI 10.1016/1049-9652(92)90037-X; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; Stark L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P251, DOI 10.1109/CVPR.1991.139697; SWAIN M, 1988, P DARPA IMAGE UNDERS, P690; VAYDA AJ, 1991, CVGIP-IMAG UNDERSTAN, V54, P1, DOI 10.1016/1049-9660(91)90073-X; WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107	22	11	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					814	818		10.1109/34.308477	http://dx.doi.org/10.1109/34.308477			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500007
J	PELLEGRETTI, P; ROLI, F; SERPICO, SB; VERNAZZA, G				PELLEGRETTI, P; ROLI, F; SERPICO, SB; VERNAZZA, G			SUPERVISED LEARNING OF DESCRIPTIONS FOR IMAGE RECOGNITION PURPOSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						PATTERN RECOGNITION; MACHINE LEARNING; IMAGE CLASSIFICATION; FUZZY DESCRIPTIONS; TOMOGRAPHIC MEDICAL IMAGES		This study deals with a learning system for generation of descriptions of objects to be recognized in 2-D images. After proposing a framework for handling fuzzy and relational descriptions, we present the system obtained by making such a framework manage a well-known learning methodology. Satisfactory results and comparisons are reported.			PELLEGRETTI, P (corresponding author), UNIV GENOA,DEPT BIOPHYS & ELECTR ENGN,VIA OPERA PIA 11A,I-16145 GENOA,ITALY.			ROLI, FABIO/0000-0003-4103-9190				[Anonymous], 1975, FUZZY SETS THEIR APP, DOI DOI 10.1016/B978-0-12-775260-0.50021-9; BERGADANO F, 1988, IEEE T PATTERN ANAL, V10, P555, DOI 10.1109/34.3917; BERGADANO F, 1991, E HORWOOD SERIES ART, P103; CONNEL JH, 1987, ARTIF INTELL, P159; DELLEPIANE S, 1987, IEEE T CIRCUITS SYST, V34, P1399; HART PE, 1973, PATTER CLASSIFICATIO; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349, DOI 10.1109/TPAMI.1980.4767034; Nagao M., 1980, STRUCTURAL ANAL COMP; NIEMANN H, 1990, MACHINE VISION APPLI, P220; PELLEGRETTI P, 1992, DIBELR92 U GEN TECH; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; SEGEN J, P CVPR89, P597; SERPICO SB, 1991, 6TH P INT C IMAG AN, P438; TURKSEN JB, 1991, FUZZY SETS SYSTEMS, P5	14	11	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					92	98		10.1109/34.273712	http://dx.doi.org/10.1109/34.273712			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300010
J	KIM, MG; DINSTEIN, IH; SHAW, L				KIM, MG; DINSTEIN, IH; SHAW, L			A PROTOTYPE FILTER DESIGN APPROACH TO PYRAMID GENERATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FILTER GENERATING KERNELS; IMAGE SAMPLING PATTERNS; NONINTEGER REDUCTION FACTOR; POLYPHASE FILTERS; PYRAMID FILTER	IMAGE	This paper presents a technique for image pyramid generation, in which the reduction (expansion) factor between layers is any rational number M/L. The image pyramid generation is modeled as an interpolation and filtering followed by a decimation. The model enables frequency domain analysis of the image pyramid, as well as convenient design of the generating kernels. L(M) generating kernels are necessary to produce an image pyramid with reduction (expansion) factor M/L(L/M). A polyphase filter network scheme is used where the L(M) generating kernels can be produced by sampling one prototype low-pass filter with cutoff frequency at omega = pi/max[M,L]. Using these polyphase filters, the frequency content of pyramid image decompositions can be adjusted with great flexibility. A systematic procedure is presented here for specifying the relative positions of spatial samples in successive pyramid levels-a complication that arises when generalizing from integer reduction factors to rational factors. Two types of low-pass filters are employed in this work for the prototype filter design: a binomial filter and an FIR linear phase filter. Illustrative examples are presented.	BEN GURION UNIV NEGEV,DEPT ELECT & COMP ENGN,IL-84105 BEER SHEVA,ISRAEL; POLYTECH INST NEW YORK,DEPT ELECT ENGN,BROOKLYN,NY 11201	Ben Gurion University; New York University; New York University Tandon School of Engineering	KIM, MG (corresponding author), KOREA UNIV,DEPT BIOMED ELECTR,SEOUL,SOUTH KOREA.							Adelson E. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P50, DOI 10.1117/12.976485; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CROCHIERE RE, 1981, P IEEE, V69, P300, DOI 10.1109/PROC.1981.11969; DINSTEIN I, 1989, SPIE, V1153, P522; HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892; HADDAD RA, 1971, IEEE T ACOUST SPEECH, VAU19, P296, DOI 10.1109/TAU.1971.1162204; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P229, DOI 10.1109/TPAMI.1984.4767506; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P222, DOI 10.1109/TPAMI.1984.4767505; KIM MG, 1991, THESIS POLYTECHNIC U; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MCCLELLAN JH, 1973, IEEE T CIRCUITS SYST, VCT20, P697, DOI 10.1109/TCT.1973.1083764; MEER P, 1988, COMPUT VISION GRAPH, V44, P307, DOI 10.1016/0734-189X(88)90127-2; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; PELEG S, 1989, IEEE T PATTERN ANAL, V11, P739, DOI 10.1109/34.192468; ROSENFELD A, 1990, INFORM SCIENCES, V50, P23, DOI 10.1016/0020-0255(90)90003-S; ROSENFELD A, 1984, MULTIRESOLUTION IMAG	17	11	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1233	1240						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600002
J	BOWYER, K; SALLAM, M; EGGERT, D; STEWMAN, J				BOWYER, K; SALLAM, M; EGGERT, D; STEWMAN, J			COMPUTING THE GENERALIZED ASPECT GRAPH FOR OBJECTS WITH MOVING PARTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ARTICULATED OBJECTS; ASPECT GRAPH; GENERAL CONFIGURATION; VISUAL POTENTIAL	CURVED OBJECTS; RECOGNITION; MODELS; IMAGES; VISION	A number of researchers have described algorithms for computing the aspect graph representation, but this work has thus far been limited to entirely rigid objects. We generalize this concept to include a larger, more realistic domain of objects known as articulated assemblies: those objects composed of rigid parts with articulated connections allowed between parts. The generalization actually suggests two slightly different representations: one that directly summarizes the possible general views of the object and another (hierarchical) form summarizing the possible ''general configurations'' and their respective views. Algorithms are outlined for computing both representations. We also examine in more detail the generalized aspect graphs of assemblies formed using translational connections, supported by an example.			BOWYER, K (corresponding author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.			Bowyer, Kevin/0000-0002-7562-4390				BOYWER K, 1989, P IMAGE UNDERSTANDIN, P831; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; CHEN SS, 1990, INST PHYS CONF SER, V116, P77; EDELSBRUNNER H, 1986, SIAM J COMPUT, V15, P341, DOI 10.1137/0215024; EGGERT D, 1993, IEEE T PATTERN ANAL, V15, P109, DOI 10.1109/34.192483; EGGERT D, 1991, THESIS U S FLORIDA; Eggert D. W., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P335, DOI 10.1109/CVPR.1992.223254; EGGERT DW, 1992, 17TH P CONG INT SOC, V85, P633; FUCHS H, 1980, P 7 ANN C COMP GRAPH, P124; GIAD C, 1982, COMPUT GRAPH, V16, P167; GIGUS Z, 1991, IEEE T PATTERN ANAL, V13, P30; GRIMSON WEL, 1989, INT J COMPUT VISION, V2, P353, DOI 10.1007/BF00133555; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; IKEUCHI K, 1987, INT J COMPUT VISION, V1, P145, DOI 10.1007/BF00123163; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KORN MR, 1987, PATTERN RECOGN, V20, P91, DOI 10.1016/0031-3203(87)90020-3; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; Plantinga H., 1990, Proceedings. Graphics Interface '90, P9; PONCE J, 1992, 2ND P EUR C COMP VIS, P599; RIEGER JH, 1990, ARTIF INTELL, V44, P1, DOI 10.1016/0004-3702(90)90097-J; SALLAM M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P636; SEALES WB, 1990, P GRAPHICS INTERFACE, P176; SRIPRADISVARAKU.T, 1989, NOV P IEEE WORKSH IN, P109; STEWAMN JH, 1991, THESIS U S FLORIDA; Stewman J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P494, DOI 10.1109/CCV.1988.590029; WANG R, 1990, 10TH P INT C PATT RE, P8	30	11	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					605	610		10.1109/34.216731	http://dx.doi.org/10.1109/34.216731			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700010
J	FERTIG, KW; BREESE, JS				FERTIG, KW; BREESE, JS			PROBABILITY INTERVALS OVER INFLUENCE DIAGRAMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note							NETWORKS	This paper describes a mechanism for performing probabilistic reasoning in influence diagrams using interval rather than point-valued probabilities. Procedures for operations corresponding to conditional expectation and Bayesian conditioning in influence diagrams are derived where lower bounds on probabilities are stored at each node. The resulting bounds for the transformed diagram are shown to be the tightest possible within the class of constraints on probability distributions that can be expressed exclusively as lower bounds on the component probabilities of the diagram. Sequences of these operations can be performed to answer probabilistic queries with indeterminacies in the input and for performing sensitivity analysis on an influence diagram. The storage requirements and computational complexity of this approach are comparable to those for point-valued probabilistic inference mechanisms.			FERTIG, KW (corresponding author), ROCKWELL INT CORP,CTR SCI,PALO ALTO LAB,PALO ALTO,CA 94301, USA.							BREESE JS, 1990, 6TH P C UNC ART INT, P122; CHU P, 1988, ROBUST INTERACTIVE D; COOPER GF, 1984, STANCS8448 STANF U C; COOPER GF, 1984, HPP8448 STANF U COMP; FERTIG KW, 1990, 4 ROCKW INT SCI CTR; GINSBERG ML, 1985, 9TH P INT JOINT C AR, P447; GROSOF B, 1986, UNCERTAINTY ARTIFICI, P259; HADDAWY P, 1986, 5TH P AAAI 86 NAT C, P238; Howard R. A., 1981, READINGS PRINCIPLES, VII, P721; Kyburg H. E.  Jr., 1988, International Journal of Approximate Reasoning, V2, P195, DOI 10.1016/0888-613X(88)90116-8; KYBURG HE, 1987, ARTIF INTELL, V31, P271, DOI 10.1016/0004-3702(87)90068-3; Levi I., 1980, ENTERPRISE KNOWLEDGE; LOUI R, TR228 U ROCH DEP COM; LOUI RP, 1987, THESIS U ROCHESTER; Nau R. F., 1989, Annals of Operations Research, V19, P375, DOI 10.1007/BF02283530; NEAPOLITAN RE, 1988, 4TH P AM ASS ART INT; OLMSTED SM, 1983, THESIS STANFORD U; Pearl J., 1988, International Journal of Approximate Reasoning, V2, P211, DOI 10.1016/0888-613X(88)90117-X; SEIDENFELD T, 1987, 391 CARN MELL U DEP; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; SHACHTER RD, 1988, OPER RES, V36, P589, DOI 10.1287/opre.36.4.589; SNOW P, 1986, AUG P AM ASS ART INT, P233; VANDERGAAG L, 1990, 6TH P C UNC ART INT; WELLMAN MP, 1990, ARTIF INTELL, V44, P257, DOI 10.1016/0004-3702(90)90026-V; WHITE CC, 1986, IEEE T SYST MAN CYB, V16, P570, DOI 10.1109/TSMC.1986.289260	26	11	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					280	286		10.1109/34.204910	http://dx.doi.org/10.1109/34.204910			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800009
J	CHIN, F; CHOI, A; LUO, YH				CHIN, F; CHOI, A; LUO, YH			OPTIMAL GENERATING KERNELS FOR IMAGE PYRAMIDS BY PIECEWISE FITTING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CONVOLUTION KERNELS; CURVE FITTING; FAST FILTER TRANSFORMS; IMAGE PYRAMIDS; MEAN SQUARE ERROR; SPLINE CURVES		A novel class of generating kernels for image pyramids is introduced. When these kernels are convolved with intensity functions of images, continuous piecewise surfaces composed of polynomial tensor products are fitted to the intensity functions. The fittings are optimal in the sense that the mean square error between them and the original intensity functions is minimized. We introduce two members of the class and prove symmetry, normalization, unimodality, and equal contribution properties. These kernels possess attractive properties such as small window size, fast inverse transformation, and minimum error. Experiments show that they compare favorably with existing ones in terms of mean square error.			CHIN, F (corresponding author), UNIV HONG KONG,DEPT COMP SCI,HONG KONG,HONG KONG.							BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CANTONI V, 1986, PYRAMIDAL SYSTEMS CO; CASTAN S, 1985, JUN P CVPR 85 SAN FR, P420; CHAPMAN R, 1984, P ICASSP 84 SAN DIEG; CHIN F, 1989, 1989 P INT S COMP AR, P612; DANIELSSON PE, 1980, 5TH P ICPR, P1171; HAGER WH, 1988, APPLIED NUMERICAL LI; LUO Y, 1985, JUN IEEE P CVPR 85 S, P426; LUO Y, 1988, J COMMUN CHINA, V9, P43; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; WILSON R, 1988, IEEE T PATTERN ANAL, V10, P193, DOI 10.1109/34.3882	17	11	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1190	1198		10.1109/34.177384	http://dx.doi.org/10.1109/34.177384			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300005
J	MULGAONKAR, PG; COWAN, CK; DECURTINS, J				MULGAONKAR, PG; COWAN, CK; DECURTINS, J			UNDERSTANDING OBJECT CONFIGURATIONS USING RANGE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						RANGE IMAGES; SPATIAL REASONING; STABILITY		This paper describes techniques that generate multiple interpretations from dense range images of piles of unknown objects and methods that use physical law, such as object stability, to rank the interpretations. Each of the interpretations completely accounts for the observed range data, but the interpretations differ in the ways the visible portions of objects are extended into the occluded portions of the scene.			MULGAONKAR, PG (corresponding author), SRI INT,CTR ADV AUTOMAT TECHNOL,MENLO PK,CA 94025, USA.							BESL P, 1986, COMPUT SURV, V17, P75; BOULT TE, 1987, OCT P AAAI WORKSH SP; MULGAONKAR PG, 1991, ITAD8842TN916 SRI IN; PENTLAND AP, 1986, 406 SRI INT TECH REP; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401	5	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					303	307		10.1109/34.121798	http://dx.doi.org/10.1109/34.121798			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900017
J	CHAN, SC; WONG, AKC				CHAN, SC; WONG, AKC			SYNTHESIS AND RECOGNITION OF SEQUENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						HIERARCHICAL CLUSTERING; MULTIPLE SEQUENCE ALIGNMENT; SEQUENCES; STRINGS; SUPERVISED CLASSIFICATION; SYNTHESIS; UNSUPERVISED CLASSIFICATION	KNOWLEDGE; DISTANCE; TREES; SETS	A string or sequence is a linear array of symbols that come from an alphabet. Due to unknown substitutions, insertions, and deletions of symbols, a sequence cannot be treated like a vector or a tuple of a fixed number of variables. The synthesis of an ensemble of sequences is a "sequence" of random elements that specify the probabilities of occurrence of the different symbols at the corresponding sites of the sequences. The synthesis is determined by a hierarchical sequence synthesis procedure (HSSP), which returns not only the taxonomic hierarchy of the whole ensemble of sequences but also the alignment and the synthesis of a group (a subset of the ensemble) of the sequences at each level of the hierarchy. The HSSP does not require the ensemble of sequences to be presented in the form of a tabulated array of data, the hierarchical information of the data, or the assumption of a stochastic process. This correspondence presents the concept of sequence synthesis and the applicability of the HSSP as a supervised classification procedure as well as an unsupervised classification procedure.			CHAN, SC (corresponding author), UNIV WATERLOO, DEPT SYST DESIGN ENGN, WATERLOO N2L 3G1, ONTARIO, CANADA.							ANDERSON TW, 1957, ANN MATH STAT, V28, P89, DOI 10.1214/aoms/1177707039; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Baum LE, 1972, INEQUALITIES, V3, P1; BAUM LE, 1966, ANN MATH STAT, V37, P1559; BRADLEY DW, 1983, TIME WARPS STRING ED; Cavalli-Sforza Luigi., 1971, GENETICS HUMAN POPUL; CAVALLISFORZA LL, 1969, 12 P INT C GEN TOK, V3, P405; CHAN KCC, 1990, IN PRESS COMPUTATION; CHAN SC, 1991, IN PRESS B MATH BIOL; CHAN SC, 1990, THESIS U WATERLOO CA; CHIU DKY, 1986, IEEE T SYST MAN CYB, V16, P251, DOI 10.1109/TSMC.1986.4308945; Clifford H.T., 1975, INTRO NUMERICAL CLAS; DEMORI R, 1977, SYNTACTIC PATTERN RE; DEVIJER P, 1982, PATTERN RECOGNITION; DIDAY E, 1988, 9TH P INT C PATT REC; Duda R.O., 1973, J ROYAL STAT SOC SER; Dunn G., 1982, INTRO MATH TAXONOMY; ERICKSON BW, 1983, TIME WARPS STRING ED; Fu K.S., 1974, MATH SCI ENG; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FU KS, 1977, IEEE T SYST MAN CYB, V7, P734, DOI 10.1109/TSMC.1977.4309608; FU KS, 1977, SYNTACTIC PATTERN RE; FU KS, 1982, PATTERN RECOGNITION; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; GOWER JC, 1967, BIOMETRICS, V23, P623, DOI 10.2307/2528417; GRANUM E, 1989, IN PRESS CYTOMETRY; GROSJEAN H, 1982, BIOCHIMIE, V64, P387, DOI 10.1016/S0300-9084(82)80576-2; HOGEWEG P, 1984, J MOL EVOL, V20, P175, DOI 10.1007/BF02257378; Kruskal J.B., 1983, TIME WARPS STRING ED; LANCE GN, 1967, COMPUT J, V9, P373, DOI 10.1093/comjnl/9.4.373; LEVINSON SE, 1985, P IEEE, V73, P1625, DOI 10.1109/PROC.1985.13344; Miclet L., 1986, STRUCTURAL METHODS P; NEEDLEMAN SB, 1970, J MOL BIOL, V48, P444; NEI M, 1972, AM NAT, V106, P283, DOI 10.1086/282771; NEI M, 1983, J MOL EVOL, V19, P153, DOI 10.1007/BF02300753; Nei M, 1973, GENETIC STRUCTURE PO; Patrick EA., 1972, FUNDAMENTALS PATTERN; RULOT H, 1987, NATO ASI SERIES F, V30; SANKOFF D, 1982, NUCLEIC ACIDS RES, V10, P421, DOI 10.1093/nar/10.1.421; Sneath P.H.A., 1973, NUMERICAL TAXONOMY P; THOMASON MG, 1986, IEEE T PATTERN ANAL, V8, P491, DOI 10.1109/TPAMI.1986.4767813; Tou JT, 1974, PATTERN RECOGN; WANG DCC, 1979, IEEE T AUTOMAT CONTR, V24, P434, DOI 10.1109/TAC.1979.1102039; WATERMAN MS, 1984, B MATH BIOL, V46, P473, DOI 10.1007/BF02459498; WILLIAMS W T, 1971, Taxon, V20, P519, DOI 10.2307/1218253; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796, DOI 10.1109/TPAMI.1987.4767986; WONG AKC, 1979, IEEE T PATTERN ANAL, V1, P342, DOI 10.1109/TPAMI.1979.4766942; WONG AKC, 1990, SYNTACTIC STRUCTURAL; WONG AKC, 1990, IN PRESS ARTIFICIAL; WONG AKC, 1987, NATO ASI SERIES F, V30; YOU M, 7TH P INT C PATT REC; YOU M, 1983, THESIS U WATERLOO CA; [No title captured]; [No title captured]	57	11	12	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1991	13	12					1245	1255		10.1109/34.106998	http://dx.doi.org/10.1109/34.106998			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GT950					2022-12-18	WOS:A1991GT95000006
J	CORAZZA, A; DEMORI, R; GRETTER, R; SATTA, G				CORAZZA, A; DEMORI, R; GRETTER, R; SATTA, G			COMPUTATION OF PROBABILITIES FOR AN ISLAND-DRIVEN PARSER	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							SPEECH	Island-driven parsers have interesting potential applications in automatic speech understanding (ASU). Most of the recently developed ASU systems are based on an acoustic processor (AP) and a language processor (LP). AP computes the a priori probability of the acoustic data given a linguistic interpretation. LP computes the probability of the linguistic interpretation. This paper describes an effort to adapt island-driven parsers to handle stochastic context-free grammars. These grammars could be used as language models (LM's) by a LP to compute the probability of a linguistic interpretation. Island-driven parsers applied to ASU are based on the idea of growing islands of recognized words with an attempt to recognize new words at the edges of an island. As different island may compete for growth, it is important to compute the probability that LM generates a sentence containing islands and gaps between them. This probability can be used to score competing interpretation hypotheses. Algorithms for computing these probabilities are introduced in this paper. The complexity of these algorithms is analyzed both from theoretical and practical points of view. It is shown that the computation of probabilities in the presence of gaps of unknown length requires the impractical solution of a nonlinear system of equations, whereas the computation of probabilities for cases with gaps containing a known number of unknown words has polynomial time complexity and is practically feasible. The use in ASU systems of the results obtained is discussed.	MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2A7,QUEBEC,CANADA; CTR RECH INFORMAT MONTREAL INC,MONTREAL,QUEBEC,CANADA	McGill University	CORAZZA, A (corresponding author), IST RIC SCI & TECNOL,NAT LANGUAGE GRP,TRENT,ITALY.			CORAZZA, Anna/0000-0002-9156-5079; SATTA, GIORGIO/0000-0001-7742-6438				Aho A.V., 1972, THEORY PARSING TRANS; Aho AV, 1974, DESIGN ANAL COMPUTER; BAKER JK, 1979, SPR P C AC SOC AM; CHOW YL, 1989, P IEEE C ACOUSTICS S, P727; CORAZZA A, 1991, 11991 MCGILL U SPEEC; GIACHIN EP, 1989, 11TH P INT JOINT C A, P1537; GONZALES RC, 1978, SYNTACTIC PATTERN RE; Harrison M. A., 1978, INTRO FORMAL LANGUAG; JELFINEK F, 1990, COMPUTATION PROBABIL; JELFINEK F, 1990, BASIC METHOD PROBABI; JELINEK F, 1985, P IEEE, V73, P1616, DOI 10.1109/PROC.1985.13343; KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193; Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X; MOORE R, 1989, P SPEECH NATURAL LAN, P243; Stock O., 1989, Computer Speech and Language, V3, P219, DOI 10.1016/0885-2308(89)90019-3; WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829; Woods W. A., 1985, Computer speech processing, P305; WOODS WA, 1982, ARTIF INTELL, V18, P295, DOI 10.1016/0004-3702(82)90025-X	18	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					936	950		10.1109/34.93811	http://dx.doi.org/10.1109/34.93811			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180					2022-12-18	WOS:A1991GJ18000007
J	CASACUBERTA, F				CASACUBERTA, F			SOME RELATIONS AMONG STOCHASTIC FINITE STATE NETWORKS USED IN AUTOMATIC SPEECH RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											CASACUBERTA, F (corresponding author), UNIV POLITECN VALENCIA,DEPT SISTEMAS INFORMAT & COMP,E-46071 VALENCIA,SPAIN.							ABRAMSON N, 1966, INFORMATION THEORY C; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650; BROWN FP, 1987, RC12750 IBM RES CTR; CERFDANON H, 1987, PATTERN RECOGNITION; DEROUAULT AM, 1986, IEEE T PATTERN ANAL, V8, P742, DOI 10.1109/TPAMI.1986.4767855; FU KS, 1982, SYNTACTIC PATTERN RE; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; KASHYAP RL, 1979, IEEE T PATTERN ANAL, V1, P154, DOI 10.1109/TPAMI.1979.4766901; LEE KF, 1988, CMUCS88148 CARN U TE; LEVINSON SE, 1983, IEEE T ACOUST SPEECH, V31, P1549, DOI 10.1109/TASSP.1983.1164235; LEVINSON SE, 1985, P IEEE, V73, P1625, DOI 10.1109/PROC.1985.13344; LEVINSON SE, 1983, AT&T TECH J, V62, P1035; LEVINSON SE, 1985, COMPUTER SPEECH PROC; MERIALDO B, 1988, P IEEE INT C AC SPEE, P111; Miclet L., 1986, STRUCTURAL METHODS P; NAKAGAWA S, 1986, P ICASSP86; RABINER L, 1988, NATO ASI SERIES; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; RABINER LR, 1983, AT&T TECH J, V62, P1075; RULOT H, 1988, P NATO ADV RES WORKS; Salomaa A., 1973, FORMAL LANGUAGES; SANTOS ES, 1975, INFORM SCIENCES, V8, P39, DOI 10.1016/0020-0255(75)90004-3; SCHWARTH R, 1988, RECENT ADV SPEECH UN; WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829	26	11	12	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					691	695		10.1109/34.56212	http://dx.doi.org/10.1109/34.56212			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400010
J	SHVAYTSER, H				SHVAYTSER, H			LEARNABLE AND NONLEARNABLE VISUAL CONCEPTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CORNELL UNIV,DEPT COMP SCI,ITHACA,NY 14853	Cornell University								BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; BollobuYs B., 1978, EXTREMAL GRAPH THEOR; Duda R.O., 1973, J ROYAL STAT SOC SER; HAUSSLER D, 1988, 1988 P WORKSH COMP L, P42; KEARNS M, 1987, 19TH P ACM S THEOR C, P285; Marr D., 1982, VISION; Minsky M., 1969, PERCEPTRONS; Natarajan B. K, 1987, P 19 ANN ACM S THEOR, P296; PITT L, 1988, J ACM, V35, P965, DOI 10.1145/48014.63140; Rivest R. L., 1987, Machine Learning, V2, P229, DOI 10.1023/A:1022607331053; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SHVAYTSER H, 1990, MACH LEARN, V5, P101, DOI 10.1007/BF00115896; TSOTSOS JK, 1990, BEHAVIORAL BRAIN SCI, V12; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VALIANT LG, 1985, 9TH P IJCAI, P550	16	11	11	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1990	12	5					459	466		10.1109/34.55105	http://dx.doi.org/10.1109/34.55105			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DA035					2022-12-18	WOS:A1990DA03500004
J	KRUEGER, WM; PHILLIPS, K				KRUEGER, WM; PHILLIPS, K			THE GEOMETRY OF DIFFERENTIAL-OPERATORS WITH APPLICATION TO IMAGE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NEW MEXICO STATE UNIV,DEPT MATH SCI,LAS CRUCES,NM 88003	New Mexico State University	KRUEGER, WM (corresponding author), DEPAUL UNIV,DEPT COMP SCI & INFORMAT SYST,CHICAGO,IL 60640, USA.							BRADY M, 1985, MIT AI824 ART INT LA; Canny J., 1986, IEEE T PATTERN ANAL, V8, P769, DOI DOI 10.1109/TPAMI.1986.4767851; GENNERT M, 1986, 1986 P IEEE C COMP V, P552; MACHUCA R, 1983, IEEE T PATTERN ANAL, V5, P316, DOI 10.1109/TPAMI.1983.4767393; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Milnor J. W., 1963, ANN MATH STUD, V51; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; SPACEK L, 1986, IMAGE VISION COMPUT, V4; SPIVAK M, 1975, DIFFERENTIAL GEOMETR, V2; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	10	11	11	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1989	11	12					1252	1264		10.1109/34.41364	http://dx.doi.org/10.1109/34.41364			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB716					2022-12-18	WOS:A1989CB71600002
J	STROBACH, P				STROBACH, P			QUADTREE-STRUCTURED LINEAR PREDICTION MODELS FOR IMAGE SEQUENCE PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											STROBACH, P (corresponding author), SIEMENS AG,ZENTRALBEREICH FORSCHU & TECH,D-8000 MUNICH 83,FED REP GER.							BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; COHEN Y, 1983, IEEE T PATTERN ANAL, V7, P284; FRIEDLANDER B, 1982, P IEEE, V70, P829, DOI 10.1109/PROC.1982.12407; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950; KLINGER A, 1978, COMPUT GRAPH IMAGE P, V8, P43; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; LEE D, 1980, THESIS STANFORD U ST; Limb J. O., 1975, Computer Graphics and Image Processing, V4, P311, DOI 10.1016/0146-664X(75)90001-5; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARAGOS PA, 1984, IEEE T ACOUST SPEECH, V32, P1213, DOI 10.1109/TASSP.1984.1164463; MUSMANN HG, 1985, P IEEE, V73, P523, DOI 10.1109/PROC.1985.13183; Nagel H.-H., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1140; RADFORD CJ, 1986, PATTERN RECOGN LETT, V4, P293, DOI 10.1016/0167-8655(86)90011-5; RANAGATH S, 1985, IEEE T ACOUST SPEECH, V33, P280; SRINIVASAN R, 1987, IEEE T COMMUN, V35, P297, DOI 10.1109/TCOM.1987.1096766; STROBACH P, 1982, IEEE T ACOUST SPEECH, V34, P880; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; Van Trees H., 2013, DETECTION ESTIMATION; WILLSKY AS, 1976, IEEE T AUTOMAT CONTR, V21, P108, DOI 10.1109/TAC.1976.1101146; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981	23	11	18	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1989	11	7					742	748		10.1109/34.192469	http://dx.doi.org/10.1109/34.192469			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AB815					2022-12-18	WOS:A1989AB81500008
J	KANATANI, KI				KANATANI, KI			TRANSFORMATION OF OPTICAL-FLOW BY CAMERA ROTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	KANATANI, KI (corresponding author), GUNMA UNIV,DEPT COMP SCI,KIRYU,GUNMA 376,JAPAN.							[Anonymous], 1964, GROUP THEORY ITS APP; CHOU TC, 1987, 1ST P INT C COMP VIS, P534; Gelfand I M, 1963, REPRESENTATION ROTAT; KANATANI K, 1987, COMPUT VISION GRAPH, V38, P122, DOI 10.1016/S0734-189X(87)80133-0; KANATANI K, 1986, COMPUT VISION GRAPH, V35, P181, DOI 10.1016/0734-189X(86)90026-5; KANATANI K, 1985, COMPUT VISION GRAPH, V29, P13, DOI 10.1016/S0734-189X(85)90147-1; KANATANI K, 1985, DEC P DARPA IM UND W, P107; KANATANI K, 1987, 1ST P IEEE INT C COM, P55; KANATANI K, 1986, JUN P IEEE C COMP VI, P578; KANATANI K, IN PRESS COMPUT VISI; KANATANI KI, 1987, COMPUT VISION GRAPH, V39, P328, DOI 10.1016/S0734-189X(87)80185-8; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; SMITH GF, 1971, INT J ENG SCI, V9, P899, DOI 10.1016/0020-7225(71)90023-1; Spencer AJM., 1971, CONTINUUM PHYS, P239, DOI DOI 10.1016/B978-0-12-240801-4.50008-X; SUBBARAO M, 1986, COMPUT VISION GRAPHI, V35, P181; Wang C-C., 1970, ARCH RATION MECH AN, V43, P392, DOI [10.1007/BF00252004, DOI 10.1007/BF00252004]; WANG CC, 1970, ARCH RATION MECH AN, V36, P166, DOI 10.1007/BF00272241; WANG CC, 1970, ARCH RATION MECH AN, V36, P198, DOI 10.1007/BF00272242; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1987, 1ST P INT C COMP VIS, P12; WAXMAN AM, 1987, ADV COMPUTER VISION; WAXMAN AM, 1984, 2ND P IEEE WORKSH CO, P49; Weyl H., 1946, CLASSICAL GROUPS	24	11	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					131	143		10.1109/34.3879	http://dx.doi.org/10.1109/34.3879			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400001
J	RUEB, KD; WONG, AKC				RUEB, KD; WONG, AKC			STRUCTURING FREE SPACE AS A HYPERGRAPH FOR ROVING ROBOT PATH PLANNING AND NAVIGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											RUEB, KD (corresponding author), UNIV WATERLOO,DEPT SYST DESIGN ENGN,WATERLOO N2L 3G1,ONTARIO,CANADA.							Berge C., 1973, GRAPHS HYPERGRAPHS; BONDY JA, 1982, GRAPH THEORY APPLICA; BROOKS RA, 1983, IEEE T SYST MAN CYB, V13, P190, DOI 10.1109/TSMC.1983.6313112; Chazelle B., 1980, COMPUTATIONAL GEOMET; GIRALT G, 1984, 1ST P ROB RES INT S, P191; LEE DT, 1984, IEEE T COMPUT, V33, P1072, DOI 10.1109/TC.1984.1676388; LOZANOPEREZ T, 1979, COMMUN ACM, V22, P560, DOI 10.1145/359156.359164; Nilsson N., 1969, IJCAI 69 P 1 INT JOI, P509; Pavlidis T., 1977, STRUCTURAL PATTERN R; SCHACHTER B, 1978, IEEE T COMPUT, V27, P1078, DOI 10.1109/TC.1978.1675001; Swamy M. N. S., 1981, GRAPHS NETWORKS ALGO; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WONG AKC, 1983, IEEE CH19620, P197; YAP KC, 1983, ALGORITHMIC MOTION P	14	11	11	0	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					263	273		10.1109/TPAMI.1987.4767900	http://dx.doi.org/10.1109/TPAMI.1987.4767900			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869396				2022-12-18	WOS:A1987G163300007
J	DEMORI, R; LAFACE, P; MONG, Y				DEMORI, R; LAFACE, P; MONG, Y			PARALLEL ALGORITHMS FOR SYLLABLE RECOGNITION IN CONTINUOUS SPEECH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									POLITECN TORINO,CENS,DIPARTIMENTO AUTOMAT & INFORMAT,I-10129 TORINO,ITALY	Polytechnic University of Turin	DEMORI, R (corresponding author), CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA.			MONG, Yu/0000-0003-3261-5096				BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; COLE RA, 1983, ICASSP 84, P731; Delgutte B., 1982, REPRESENTATION SPEEC, P131; DEMICHELIS P, 1983, IEEE T ACOUST SPEECH, V31, P359, DOI 10.1109/TASSP.1983.1164067; DEMORI R, 1980, IEEE T PATTERN ANAL, V2, P136, DOI 10.1109/TPAMI.1980.4766991; DEMORI R, 1984, P CSCSI 84 LONDON, P103; DEMORI R, 1982, P NATIONAL C ARTIFIC, P107; DODDINGTON GR, 1981, IEEE SPECTRUM, V18, P26, DOI 10.1109/MSPEC.1981.6369809; ERMAN LD, 1980, COMPUT SURV, V12, P213, DOI 10.1145/356810.356816; HUTTENLOCHER DP, 1984, IEEE INT C ACOUST SP; Kopec G. E., 1984, ICASSP 84. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, p42.1/1; Minsky M., 2019, FRAMEWORK REPRESENTI; RABINER LR, 1984, IEEE T ACOUST SPEECH, V32, P272, DOI 10.1109/TASSP.1984.1164298; RABINER LR, 1984, AT&T TECH J, V63, P459, DOI 10.1002/j.1538-7305.1984.tb00015.x; RABINER LR, 1981, IEEE T COMMUN, V29, P621, DOI 10.1109/TCOM.1981.1095031; YOU KC, 1979, IEEE T SYST MAN CYB, V9, P334, DOI 10.1109/TSMC.1979.4310222	16	11	11	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					56	69		10.1109/TPAMI.1985.4767618	http://dx.doi.org/10.1109/TPAMI.1985.4767618			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869240				2022-12-18	WOS:A1985ABF0900005
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			THE 2-NN RULE FOR MORE ACCURATE NN RISK-ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FUKUNAGA, K (corresponding author), PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907, USA.							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver PA, 1982, PATTERN RECOGNITION; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314, DOI 10.1109/TPAMI.1984.4767523; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SHORT RD, 1980, 5TH INT C PATT REC M, P81	7	11	11	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					107	112		10.1109/TPAMI.1985.4767625	http://dx.doi.org/10.1109/TPAMI.1985.4767625			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869247				2022-12-18	WOS:A1985ABF0900012
J	SUZUKI, S; ABE, K				SUZUKI, S; ABE, K			NEW FUSION OPERATIONS FOR DIGITIZED BINARY IMAGES AND THEIR APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SHIZUOKA UNIV,DEPT COMP SCI,HAMAMATSU,SHIZUOKA 432,JAPAN	Shizuoka University								BAN T, 1980, T IECE D, V63, P311; FISHLER MA, 1980, COMPUT VISION GRAPH, V13, P334; KAMO H, 1982, T IECE D, V65, P621; Lantuejoul C., 1980, Issues in Digital Image Processing. Proceedings of the NATO Advanced Study Institute on Digital Image Processing and Analysis, P107; LEVIALDI S, 1972, COMMUN ACM, V15, P7, DOI 10.1145/361237.361240; MASE K, 1981, T IECE JAPAN D, V64, P1029; NAKAGAWA Y, 1978, IEEE T SYST MAN CYB, V8, P632; PERKINS WA, 1980, IEEE T PATTERN ANAL, V2, P8, DOI 10.1109/TPAMI.1980.4766965; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; ROSENFELD A, 1969, PRIC EAWSCON CONVENT, P264; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Serra J, 1982, IMAGE ANAL MATH MORP; SERRA J, 1974, LEITZ SCI TECH INF S, V1, P125; Suzuki S., 1984, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ67D, P973; SUZUKI S, 1982, 6TH P INT C PATT REC, P732; TAMURA H, 1978, 4TH P INT JOINT C PA, P715; YOKOI S, 1981, IEEE T PATTERN ANAL, V3, P424, DOI 10.1109/TPAMI.1981.4767128; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2; YOKOI S, 1980, T IECE JD, V63, P386; YOKOI S, 1976, PRL7611 IECE JAP TEC; YOKOI S, 1978, T IECE D, V61, P613	24	11	12	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					638	651		10.1109/TPAMI.1985.4767720	http://dx.doi.org/10.1109/TPAMI.1985.4767720			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869302				2022-12-18	WOS:A1985ATG0500002
J	CHIEN, RT; ZHANG, L; ZHANG, B				CHIEN, RT; ZHANG, L; ZHANG, B			PLANNING COLLISION-FREE PATHS FOR ROBOTIC ARM AMONG OBSTACLES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									ANQING TEACHERS COLL,DEPT MATH,ANJUI,PEOPLES R CHINA; TSINGHUA UNIV,DEPT COMP ENGN & SCI,BEIJING,PEOPLES R CHINA	Anqing Normal University; Tsinghua University	CHIEN, RT (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							AHUJA N, 1980, 1ST P NAT C ART INT, P44; BOYSE JW, 1979, COMMUN ACM, V22, P3, DOI 10.1145/359046.359048; LOZANOPEREZ T, 1979, COMMUN ACM, V22, P560, DOI 10.1145/359156.359164	3	11	14	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					91	96		10.1109/TPAMI.1984.4767480	http://dx.doi.org/10.1109/TPAMI.1984.4767480			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869170				2022-12-18	WOS:A1984SB21300011
J	HUDSON, DL; ESTRIN, T				HUDSON, DL; ESTRIN, T			EMERGE - A DATA-DRIVEN MEDICAL DECISION-MAKING AID	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV CALIF LOS ANGELES,DEPT COMP SCI,LOS ANGELES,CA 90024	University of California System; University of California Los Angeles	HUDSON, DL (corresponding author), UNIV CALIF FRESNO,FRESNO CENT SAN JOAQUIN VALLEY MED EDUC PROGRAM,SCH MED,FRESNO,CA 93703, USA.							BENBASSAT M, 1980, IEEE T PATTERN ANAL, V2, P148, DOI 10.1109/TPAMI.1980.4766992; Blum R. L., 1982, Proceedings of the Sixth Annual Symposium on Computer Applications in Medical Care, P712; BLUM RL, 1978, 2ND P ANN S COMP APP, P303; DUDA RO, 1981, BYTE             MAR, P238; ESTRIN T, 1981, P IEEE FRONTIERS COM, P5; GOLDMAN L, 1982, NEW ENGL J MED, V307, P588, DOI 10.1056/NEJM198209023071004; HALL P, 1980, APPROXIMATE STRING M, P381; HUDSON DL, 1981, 5TH P ANN S COMP APP, P976; HUDSON DL, 1981, THESIS U CALIFORNIA; MILLER RA, 1982, NEW ENGL J MED, V307, P468, DOI 10.1056/NEJM198208193070803; Pople H. E., 1975, 4TH P INT JOINT C AR, P848; Shortliffe E.H., 2012, COMPUTER BASED MED C; SHORTLIFFE EH, 1979, P IEEE, V67, P1207, DOI 10.1109/PROC.1979.11436; SHORTLIFFE EH, 1981, 7TH P INT JOINT C AR, P876; WATERMAN D, 1978, PATTERN DIRECTED INF; WEISS SM, 1981, 7TH P INT JOINT C AR, P853	16	11	11	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					87	91		10.1109/TPAMI.1984.4767479	http://dx.doi.org/10.1109/TPAMI.1984.4767479			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869169				2022-12-18	WOS:A1984SB21300010
J	NAGY, G				NAGY, G			CANDID PRACTICAL PRINCIPLES OF EXPERIMENTAL PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NAGY, G (corresponding author), UNIV NEBRASKA,DEPT COMP SCI,LINCOLN,NE 68588, USA.			Nagy, George/0000-0002-0521-1443					0	11	11	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					199	200		10.1109/TPAMI.1983.4767372	http://dx.doi.org/10.1109/TPAMI.1983.4767372			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869101	Green Published			2022-12-18	WOS:A1983QJ97400008
J	ELLIOTT, H; COOPER, DB; COHEN, FS; SYMOSEK, PF				ELLIOTT, H; COOPER, DB; COHEN, FS; SYMOSEK, PF			IMPLEMENTATION, INTERPRETATION, AND ANALYSIS OF A SUBOPTIMAL BOUNDARY FINDING ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									BROWN UNIV, DEPT ENGN, PROVIDENCE, RI 02912 USA	Brown University	ELLIOTT, H (corresponding author), COLORADO STATE UNIV, DEPT ELECT ENGN, FT COLLINS, CO 80523 USA.							ASHKAR GP, 1978, COMPUT VISION GRAPH, V7, P331, DOI 10.1016/S0146-664X(78)80002-1; COHEN F, 1980, APR P INT C ACOUST S; COHEN F, THESIS BROWN U PROVI; Cooper D. B., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P25; COOPER DB, 1980, COMPUT VISION GRAPH, V12, P326, DOI 10.1016/0146-664X(80)90018-0; COOPER DB, 1979, IEEE T PATTERN ANAL, V1, P372, DOI 10.1109/TPAMI.1979.4766946; ELLIOTT H, 1979, P IEEE COMPUT SOC C; ELLIOTT H, 1980, 19TH P C DEC CONTR A; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; HANSEN FR, THESIS COLORADO STAT; HUECKEL MH, 1973, J ASS COMPUT MACH, V20; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; NAHI NE, 1978, IEEE T AUTOMAT CONTR, V23, P834, DOI 10.1109/TAC.1978.1101841; NAHI NE, 1977, IEEE T COMPUT, V26, P772, DOI 10.1109/TC.1977.1674915; NILSSON N, 1971, PROBLEM SOLVING METH, P54; REISS L, 1979, NOV P C COMP SOFTW A; SCHARF LL, UNPUB IEEE T AUTOMAT; SCHARF LL, 1979, DEC79C COL STAT U TE; SYMOSEK P, THESIS BROWN U PROVI	20	11	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					167	182		10.1109/TPAMI.1982.4767224	http://dx.doi.org/10.1109/TPAMI.1982.4767224			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869023				2022-12-18	WOS:A1982NE95700013
J	BJORKLUND, CM; PAVLIDIS, T				BJORKLUND, CM; PAVLIDIS, T			GLOBAL SHAPE-ANALYSIS BY K-SYNTACTIC SIMILARITY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PRINCETON UNIV,DEPT ELECT ENGN & COMP SCI,PRINCETON,NJ 08544	Princeton University								Aho AV, 1974, DESIGN ANAL COMPUTER; Albano A., 1974, COMPUT VISION GRAPH, V3, P23, DOI [10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2CGIPBG0146-664X]; BJORKLUND C, 1977, 1977 P IEEE SYST MAN, P690; BJORKLUND CM, 1978, IEEE P PATTERN RECOG, P301; BJORKLUND CM, 1979, THESIS PRINCETON U; BJORKLUND CM, 1977, IEEE P PATTERN RECOG, P198; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DECHAMPEAUX D, 1977, J ACM, V24, P177; Duda R., 1973, PATTERN CLASSIFICATI; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; FU KS, 1977, SYNTACTIC PATTERN RE; Garey M. R., 1976, SIAM Journal on Computing, V5, P704, DOI 10.1137/0205049; HARALICK RM, 1977, IEEE P PATTERN RECOG, P112; JOHNSON DB, 1975, SIAM J COMPUT, V4, P75; Liu C. L., 1968, INTRO COMBINATORIAL; LU SY, 1977, IEEE T COMPUT, V26, P1268, DOI 10.1109/TC.1977.1674788; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; MUNDY JL, 1977, IEEE P PATTERN RECOG, P144; PAVLIDIS T, 1979, P IEEE, V67, P737, DOI 10.1109/PROC.1979.11323; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; Pavlidis T., 1977, STRUCTURAL PATTERN R; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P1; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHACHTER B, 1978, IEEE T COMPUT, V27, P1078, DOI 10.1109/TC.1978.1675001; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SHILLMAN RJ, 1977, IEEE P PATTERN RECOG, P327; Stallings W. W., 1972, COMPUT GRAPHICS IMAG, P47; TANIMOTO SL, 1977, COMMUN ACM, V20, P223, DOI 10.1145/359461.359468; Tenenbaum J. M., 1976, 3rd International Joint Conference on Pattern Recognition, P504; YOU KC, 1979, IEEE T SYST MAN CYB, V9, P334, DOI 10.1109/TSMC.1979.4310222; YOU KC, 1978, DEC P INT COMP S	33	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					144	155		10.1109/TPAMI.1981.4767072	http://dx.doi.org/10.1109/TPAMI.1981.4767072			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868929				2022-12-18	WOS:A1981MN96800004
J	DAVIS, LS; HENDERSON, TC				DAVIS, LS; HENDERSON, TC			HIERARCHICAL CONSTRAINT PROCESSES FOR SHAPE-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									GERMAN AEROSP RES ESTAB, INST COMMUN THEORY, OBERPFAFFENHOFEN, FED REP GER	Helmholtz Association; German Aerospace Centre (DLR)	DAVIS, LS (corresponding author), UNIV TEXAS, DEPT COMP SCI, AUSTIN, TX 78712 USA.							BARROW H, 1976, SRI AI121 TECH REP; DAVIS L, 1980, 123 U TEX DEP COMP S; DAVIS LS, 1978, COMPUTER VISION SYST, P101; FU KS, 1977, SYNTACTIC PATTERN RE, P1; GALLO V, 1975, 1975 P IJCAI TBIL, P628; GASCHNIG J, 1978, 2ND P NAT C CAN SOC, P268; Gries D., 1971, COMPILER CONSTRUCTIO; HARALICK R, 1979, 5TH INT JOINT C ART; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; Marr D., 1979, THEORY EDGE DETECTIO; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; STOCKMAN G, 1977, 538 U MAR TECH REP; TANG GY, 1979, IEEE T PATTERN ANAL, V1, P135, DOI 10.1109/TPAMI.1979.4766899; VAMOS T, 1973 P IJCPR WASH, P445; YOU K, 1977, IMAGE UNDERSTANDING, P72	18	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					265	277		10.1109/TPAMI.1981.4767099	http://dx.doi.org/10.1109/TPAMI.1981.4767099			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN969	21868947				2022-12-18	WOS:A1981MN96900003
J	EKLUNDH, JO; ROSENFELD, A				EKLUNDH, JO; ROSENFELD, A			IMAGE SMOOTHING BASED ON NEIGHBOR LINKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	EKLUNDH, JO (corresponding author), NATL DEF RES INST,LINKOPING,SWEDEN.							DAVENPORT JP, 1978, 689 U MAR COMP SCI C; DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; SCHER A, 1980, IEEE T SYST MAN CYB, V10, P153; Zucker S. W., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P410	5	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					679	683		10.1109/TPAMI.1981.4767170	http://dx.doi.org/10.1109/TPAMI.1981.4767170			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868989				2022-12-18	WOS:A1981MR99600009
J	RUTKOWSKI, WS; PELEG, S; ROSENFELD, A				RUTKOWSKI, WS; PELEG, S; ROSENFELD, A			SHAPE SEGMENTATION USING RELAXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											RUTKOWSKI, WS (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				DAVIS L, UNPUBLISHED; DAVIS LS, 1980, 851 U MAR COMP SCI T; DAVIS LS, 1978, COMPUTER VISION SYST, P101; KITCHEN L, 1979, IEEE T SYST MAN CYB, V9, P869; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PELEG S, 1979, COMPUT VISION GRAPH, V10, P235, DOI 10.1016/0146-664X(79)90003-0; PELEG S, 1979 P PAT REC IM PR, P337; RUTKOWSKI WS, 1979, COMPUT VISION GRAPH, V9, P89, DOI 10.1016/0146-664X(79)90086-8; RUTKOWSKI WS, 1978, 623 U MAR COMP SCI T; YOU KC, 1978, 8TH P ANN AUT IM PAT	11	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					368	375		10.1109/TPAMI.1981.4767123	http://dx.doi.org/10.1109/TPAMI.1981.4767123			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868958				2022-12-18	WOS:A1981MQ35700002
J	CASTLEMAN, KR; WHITE, BS				CASTLEMAN, KR; WHITE, BS			OPTIMIZING CERVICAL SPECIMEN CLASSIFIERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CASTLEMAN, KR (corresponding author), CALTECH,JET PROP LAB,PASADENA,CA 91103, USA.							BARTELS PH, 1978, ACTA CYTOL, V22, P253; BIBBO M, 1975, ACTA CYTOL, V19, P438; BIBBO M, 1976, ACTA CYTOL, V20, P565; BIBBO M, 1976, ACTA CYTOL, V20, P249; CASTLEMAN KR, 1979, DIGITAL IMAGE PROCES, pCH16; Duda R.O., 1973, J ROYAL STAT SOC SER; EVANS DMD, 1974, BRIT J PREVENTIVE SO, V31, P238; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; KOSS LG, 1968, DIAGNOSTIC CYTOLOGY, P12; LORDEN G, 1972, ANN MATH STAT, V43, P1412, DOI 10.1214/aoms/1177692374; PATTEN S, 1969, DIAGNOSTIC CYTOLOGY; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PRESSMAN N, 1979, AUTOMATION CANCER CY; Wald A., 1947, SEQUENTIAL ANAL	15	11	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					451	457		10.1109/TPAMI.1980.6592366	http://dx.doi.org/10.1109/TPAMI.1980.6592366			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500008
J	JACOBUS, CJ; CHIEN, RT; SELANDER, JM				JACOBUS, CJ; CHIEN, RT; SELANDER, JM			MOTION DETECTION AND ANALYSIS OF MATCHING GRAPHS OF INTERMEDIATE-LEVEL PRIMITIVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign								AGGARWAL J, 1974, 151 U TEX TECH REP; BAKER H, 1977, 5TH P INT JOINT C AR, P649; BAUMGART S, 1974, AIM249 STANF AI MEM; BURR D, 1977, THESIS U ILLINOIS; DUDANI S, 1976, NOV P S CURR MATH PR; Gennery D. B., 1977, P 5 INT JOINT C ART, V2, P576; JAIN R, 1977, 5TH P INT JOINT C AR, P612; MARR D, 1977, AI446 MIT MEM; MARR D, 1976, AI364 MIT MEM; MARR D, 1976, AI377 MIT MEM; POTTER JL, 1977, COMPUT VISION GRAPH, V6, P558, DOI 10.1016/S0146-664X(77)80016-6; UNDERWOOD SA, 1975, IEEE T COMPUT, VC 24, P651, DOI 10.1109/T-C.1975.224277	12	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					495	510		10.1109/TPAMI.1980.6447696	http://dx.doi.org/10.1109/TPAMI.1980.6447696			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200002
J	MIZOGUCHI, R; SHIMURA, M				MIZOGUCHI, R; SHIMURA, M			A NONPARAMETRIC ALGORITHM FOR DETECTING CLUSTERS USING HIERARCHICAL STRUCTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									TOKYO INST TECHNOL,DEPT COMP SCI,TOKYO 152,JAPAN	Tokyo Institute of Technology	MIZOGUCHI, R (corresponding author), OSAKA UNIV,INST SCI & IND RES,RES DEPT ELECTR,SUITA,OSAKA 565,JAPAN.							AUGUSTSO.JG, 1970, J ACM, V17, P571, DOI 10.1145/321607.321608; BALL GH, 1966, INT COMMUN C PHILADE; DIDAY E, 1974, PATTERN RECOGN, V6, P17, DOI 10.1016/0031-3203(74)90005-3; FRIEDMAN HP, 1967, J AM STAT ASSOC, V62, P1159, DOI 10.2307/2283767; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P917, DOI 10.1109/T-C.1970.222799; GITMAN I, 1973, IEEE T SYST MAN CYB, VSMC3, P66, DOI 10.1109/TSMC.1973.5408579; GITMAN I, 1970, IEEE T COMPUT, VC 19, P583, DOI 10.1109/T-C.1970.222992; HUBERT L, 1973, PSYCHOMETRIKA, V38, P63, DOI 10.1007/BF02291174; HUBERT L, 1973, PSYCHOMETRIKA, V38, P47, DOI 10.1007/BF02291173; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KITTLER J, 1976, PATTERN RECOGN, V8, P23, DOI 10.1016/0031-3203(76)90026-1; KOONTZ WLG, 1976, IEEE T COMPUT, V25, P936, DOI 10.1109/TC.1976.1674719; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171, DOI 10.1109/TC.1972.5008922; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; LING RF, 1973, J AM STAT ASSOC, V68, P159, DOI 10.2307/2284161; PATRICK EA, 1969, IEEE T COMPUT, VC 18, P987, DOI 10.1109/T-C.1969.222567; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P219, DOI 10.1007/BF02289621; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	24	11	12	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					292	300		10.1109/TPAMI.1980.4767028	http://dx.doi.org/10.1109/TPAMI.1980.4767028			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JZ206	21868905				2022-12-18	WOS:A1980JZ20600002
J	SHINGHAL, R; TOUSSAINT, GT				SHINGHAL, R; TOUSSAINT, GT			SENSITIVITY OF THE MODIFIED VITERBI ALGORITHM TO THE SOURCE STATISTICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									MCGILL UNIV, SCH COMP SCI, MONTREAL H3C 3G1, QUEBEC, CANADA	McGill University	SHINGHAL, R (corresponding author), CONCORDIA UNIV, DEPT COMP SCI, MONTREAL H3G 1M8, QUEBEC, CANADA.							ABRAMSON N, 1960, APR P S DEC THEOR AP; BAKER JK, 1975, SPEECH RECOGNITION, P521; CHUNG SS, 1975, THESIS MCGILL U; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; SHINGHAL R, 1977, THESIS MCGILL U; SHINGHAL R, 1978, APR IEEE COMP SOC WO; TOUSSAINT GT, 1978, MAY P IEEE COMP SOC, P164; TOUSSAINT GT, 1977, JUN P IEEE COMP SOC, P1; White G. M., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P413	10	11	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					181	185		10.1109/TPAMI.1980.4766998	http://dx.doi.org/10.1109/TPAMI.1980.4766998			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868891				2022-12-18	WOS:A1980JH80300012
J	Cheng, XH; Chen, ZZ				Cheng, Xianhang; Chen, Zhenzhong			Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interpolation; Kernel; Convolution; Optical imaging; Optical distortion; Estimation; Nonlinear optics; Multiple video frame interpolation; adaptive convolution; deformable convolution; separable convolution		Generating non-existing frames from a consecutive video sequence has been an interesting and challenging problem in the video processing field. Typical kernel-based interpolation methods predict pixels with a single convolution process that convolves source frames with spatially adaptive local kernels, which circumvents the time-consuming, explicit motion estimation in the form of optical flow. However, when scene motion is larger than the pre-defined kernel size, these methods are prone to yield less plausible results. In addition, they cannot directly generate a frame at an arbitrary temporal position because the learned kernels are tied to the midpoint in time between the input frames. In this paper, we try to solve these problems and propose a novel non-flow kernel-based approach that we refer to as enhanced deformable separable convolution (EDSC) to estimate not only adaptive kernels, but also offsets, masks and biases to make the network obtain information from non-local neighborhood. During the learning process, different intermediate time step can be involved as a control variable by means of an extension of coord-conv trick, allowing the estimated components to vary with different input temporal information. This makes our method capable to produce multiple in-between frames. Furthermore, we investigate the relationships between our method and other typical kernel- and flow-based methods. Experimental results show that our method performs favorably against the state-of-the-art methods across a broad range of datasets. Code will be publicly available on URL: https://github.com/Xianhang/EDSC-pytorch.	[Cheng, Xianhang; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China	Wuhan University	Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.	xianhang@whu.edu.cn; zzchen@whu.edu.cn						Amir Roshan Zamir, 2012, Arxiv, DOI arXiv:1212.0402; Bailer C, 2019, IEEE T PATTERN ANAL, V41, P1879, DOI 10.1109/TPAMI.2018.2859970; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382; Bao WB, 2021, IEEE T PATTERN ANAL, V43, P933, DOI 10.1109/TPAMI.2019.2941941; Bao WB, 2018, IEEE T IMAGE PROCESS, V27, P3813, DOI 10.1109/TIP.2018.2825100; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Castagno R, 1996, IEEE T CIRC SYST VID, V6, P436, DOI 10.1109/76.538926; CHARBONNIER P, 1994, IEEE IMAGE PROC, P168; Cheng XH, 2020, AAAI CONF ARTIF INTE, V34, P10607; Cheng XH, 2020, IEEE T CIRC SYST VID, V30, P3968, DOI 10.1109/TCSVT.2019.2939143; Choi M, 2020, AAAI CONF ARTIF INTE, V34, P10663; Choi Myungsub, 2020, P IEEE C COMP VIS PA, P9444, DOI DOI 10.1109/CVPR42600.2020.00946; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Fourure Damien, 2017, ARXIV170707958; Haris M, 2020, PROC CVPR IEEE, P2856, DOI 10.1109/CVPR42600.2020.00293; Haris M, 2019, PROC CVPR IEEE, P3892, DOI 10.1109/CVPR.2019.00402; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938; Kingma D, 2014, COMPUTER SCI; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; Lee H, 2020, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR42600.2020.00536; Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218; Liu Ce, 2009, THESIS, P2; Liu R, 2018, ADV NEUR IN, V31; Liu YL, 2019, AAAI CONF ARTIF INTE, P8794; Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI 10.1109/ICCV.2017.478; Meyer S, 2018, PROC CVPR IEEE, P498, DOI 10.1109/CVPR.2018.00059; Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Nair V., 2010, ICML, P807; Niklaus S, 2020, PROC CVPR IEEE, P5436, DOI 10.1109/CVPR42600.2020.00548; Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183; Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37; Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244; Paliwal A, 2020, IEEE T PATTERN ANAL, V42, P1557, DOI 10.1109/TPAMI.2020.2987316; Peleg T, 2019, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2019.00250; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Reda FA, 2019, IEEE I CONF COMP VIS, P892, DOI 10.1109/ICCV.2019.00098; Shen W, 2020, PROC CVPR IEEE, P5113, DOI 10.1109/CVPR42600.2020.00516; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Singh P, 2019, PROC CVPR IEEE, P4830, DOI 10.1109/CVPR.2019.00497; Sun DQ, 2020, IEEE T PATTERN ANAL, V42, P1408, DOI 10.1109/TPAMI.2019.2894353; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Szeto R, 2020, IEEE T PATTERN ANAL, V42, P1053, DOI 10.1109/TPAMI.2019.2951667; Wang XT, 2019, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2019.00179; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu JY, 2016, IEEE T WIREL COMMUN, V15, P2713, DOI 10.1109/TWC.2015.2509063; Xiang XY, 2020, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR42600.2020.00343; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu Xiangyu, 2019, NEURIPS, P2; Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2; Yu S, 2019, IEEE INT CONF COMP V, P3503, DOI 10.1109/ICCVW.2019.00434; Yuan LZ, 2019, PROC CVPR IEEE, P12175, DOI 10.1109/CVPR.2019.01246; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953	64	10	10	4	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					7029	7045		10.1109/TPAMI.2021.3100714	http://dx.doi.org/10.1109/TPAMI.2021.3100714			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34324423	Green Submitted			2022-12-18	WOS:000853875300083
J	Zhao, SC; Yao, XX; Yang, JF; Jia, GL; Ding, GG; Chua, TS; Schuller, BW; Keutzer, K				Zhao, Sicheng; Yao, Xingxu; Yang, Jufeng; Jia, Guoli; Ding, Guiguang; Chua, Tat-Seng; Schuller, Bjorn W.; Keutzer, Kurt			Affective Image Content Analysis: Two Decades Review and New Perspectives	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Feature extraction; Semantics; Emotion recognition; Affective computing; Physiology; Noise measurement; Visualization; Affective computing; image emotion; emotion feature extraction; machine learning; emotional intelligence	EMOTION; SENTIMENT; VALENCE; RECOGNITION; FEATURES; CLASSIFICATION; AROUSAL; SPACE	Images can convey rich semantics and induce various emotions in viewers. Recently, with the rapid advancement of emotional intelligence and the explosive growth of visual data, extensive research efforts have been dedicated to affective image content analysis (AICA). In this survey, we will comprehensively review the development of AICA in the recent two decades, especially focusing on the state-of-the-art methods with respect to three main challenges - the affective gap, perception subjectivity, and label noise and absence. We begin with an introduction to the key emotion representation models that have been widely employed in AICA and description of available datasets for performing evaluation with quantitative comparison of label noise and dataset bias. We then summarize and compare the representative approaches on (1) emotion feature extraction, including both handcrafted and deep features, (2) learning methods on dominant emotion recognition, personalized emotion prediction, emotion distribution learning, and learning from noisy data or few labels, and (3) AICA based applications. Finally, we discuss some challenges and promising research directions in the future, such as image content and context understanding, group emotion clustering, and viewer-image interaction.	[Zhao, Sicheng; Ding, Guiguang] Tsinghua Univ, BNRist, Beijing 100084, Peoples R China; [Yao, Xingxu; Yang, Jufeng; Jia, Guoli] Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China; [Chua, Tat-Seng] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore; [Schuller, Bjorn W.] Imperial Coll London, Dept Comp, London SW7 2BX, England; [Keutzer, Kurt] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Tsinghua University; Nankai University; National University of Singapore; Imperial College London; University of California System; University of California Berkeley	Yang, JF (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China.	schzhao@gmail.com; yxx_hbgd@163.com; yangjufeng@nankai.edu.cn; exped1230@gmail.com; dinggg@tsinghua.edu.cn; dcscts@nus.edu.sg; bjoern.schuller@imperial.ac.uk; keutzer@berkeley.edu			National Natural Science Foundation of China [61701273, 61876094, U1933114, 61925107, U1936202]; National Key Research and Development Program of China [2018AAA0100403]; Natural Science Foundation of Tianjin, China [20JCJQJC00020, 18JCYBJC15400, 18ZXZNGX00110]; Berkeley DeepDrive	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; Natural Science Foundation of Tianjin, China(Natural Science Foundation of Tianjin); Berkeley DeepDrive	This work was supported in part by the National Natural Science Foundation of China under Grants 61701273, 61876094, U1933114, 61925107, and U1936202, in part by the National Key Research and Development Program of China under Grant 2018AAA0100403, in part by the Natural Science Foundation of Tianjin, China, under Grants 20JCJQJC00020, 18JCYBJC15400, and 18ZXZNGX00110, and in part by Berkeley DeepDrive.	Ahmad H. A., 2012, PROC INT C KANSEI EN; Ahsan U, 2017, IEEE IJCNN, P1372, DOI 10.1109/IJCNN.2017.7966013; Alarcao SM, 2018, MULTIMED TOOLS APPL, V77, P17413, DOI 10.1007/s11042-017-5311-8; Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671; Ali AR, 2017, IEEE WINT CONF APPL, P679, DOI 10.1109/WACV.2017.81; Balouchian P, 2019, IEEE WINT CONF APPL, P1645, DOI 10.1109/WACV.2019.00180; Bao SR, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON BIOELECTRONICS AND BIOINFORMATICS (ISBB); Borth D., 2013, P 21 ACM INT C MULT, DOI DOI 10.1145/2502081.2502282; Cahn J.E., 1990, J AM VOICE I O SOC, V8, P1; Campos V, 2015, P 1 INT WORKSHOP AFF, P57; Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011; Can Xu, 2014, Arxiv, DOI arXiv:1411.5731; Chen FH, 2018, IEEE T MULTIMEDIA, V20, P997, DOI 10.1109/TMM.2017.2757769; Chen M, 2015, IEEE IMAGE PROC, P4491, DOI 10.1109/ICIP.2015.7351656; Chen T, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P367, DOI 10.1145/2647868.2654935; COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241; Compton Rebecca J, 2003, Behav Cogn Neurosci Rev, V2, P115, DOI 10.1177/1534582303002002003; Cordel MO, 2019, PROC CVPR IEEE, P4021, DOI 10.1109/CVPR.2019.00415; D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899; Damian Borth, 2014, Arxiv, DOI arXiv:1410.8586; Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1; Dhall A, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P653; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Fan SJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P217, DOI 10.1145/3123266.3123445; Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785; Feng YF, 2019, AAAI CONF ARTIF INTE, P3558; Garg N, 2007, J MARKETING, V71, P194, DOI 10.1509/jmkg.71.1.194; Gatys L. A., 2015, ADV NEURAL INFORM PR, V28, P262, DOI DOI 10.1016/0014-5793(76)80724-7; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gunes H.., 2017, SOCIAL SIGNAL PROCES, P213; Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016; Guntuku SC, 2019, P 13 INT C WEB SOCIA, P236; Guo X, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P635, DOI 10.1145/3242969.3264990; Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452; Hassan SZ, 2019, LECT NOTES COMPUT SC, V11752, P104, DOI 10.1007/978-3-030-30645-8_10; Hassan T, 2021, IEEE T PATTERN ANAL, V43, P1815, DOI 10.1109/TPAMI.2019.2958341; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He T, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P382, DOI 10.1145/3323873.3326593; He XH, 2019, IEEE IJCNN, DOI 10.1080/00207179.2019.1598581; He YW, 2020, NEURAL PROCESS LETT, V51, P2077, DOI 10.1007/s11063-019-10035-7; He Zhang, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P166, DOI 10.1007/978-3-642-42051-1_22; He ZY, 2011, ADV COMPUT ELECTR EN, P413, DOI [10.4018/978-1-60960-212-3.ch019, 10.1007/978-3-642-24800-9_38]; HELMES E, 1993, PSYCHOL BULL, V113, P453, DOI 10.1037/0033-2909.113.3.453; Holbrook M.B., 1984, PSYCHOL MARKET, V1, P45, DOI [https://doi.org/10.1002/mar.4220010206, DOI 10.1002/MAR.4220010206]; Hosany S, 2013, J BUS RES, V66, P730, DOI 10.1016/j.jbusres.2011.09.011; Hosany S, 2010, J TRAVEL RES, V49, P513, DOI 10.1177/0047287509349267; Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008; Jindal S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P447, DOI 10.1109/INFOP.2015.7489424; Joho H, 2011, MULTIMED TOOLS APPL, V51, P505, DOI 10.1007/s11042-010-0632-x; Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246; Katsurai M, 2016, INT CONF ACOUST SPEE, P2837, DOI 10.1109/ICASSP.2016.7472195; Keren G, 2017, IEEE INT CON MULTI, P985, DOI 10.1109/ICME.2017.8019533; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P381; Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002; Kosti R, 2020, IEEE T PATTERN ANAL, V42, P2755, DOI 10.1109/TPAMI.2019.2916866; Kosti R, 2017, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2017.212; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lang Peter J, 1997, NIMH CTR STUDY EMOTI, V1, P3, DOI DOI 10.1027/0269-8803/A000147; Lee J, 2011, IEEE T MULTIMEDIA, V13, P1031, DOI 10.1109/TMM.2011.2158530; Lin C, 2020, AAAI CONF ARTIF INTE, V34, P2661; Lin HJ, 2014, IEEE INT CON MULTI; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu A, 2018, J VIS COMMUN IMAGE R, V57, P243, DOI 10.1016/j.jvcir.2018.11.006; Liu AN, 2018, SIGNAL PROCESS, V152, P206, DOI 10.1016/j.sigpro.2018.06.001; Liu HY, 2016, IEEE T NEUR NET LEAR, V27, P1201, DOI 10.1109/TNNLS.2016.2553579; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Liu X, 2019, J VIS COMMUN IMAGE R, V58, P576, DOI 10.1016/j.jvcir.2018.12.032; Lu X, 2017, INT CONF AFFECT, P440, DOI 10.1109/ACII.2017.8273637; Lu Xin, 2012, Proc ACM Int Conf Multimed, V2012, P229, DOI 10.1145/2393347.2393384; Machajdik J., 2010, P ACM INT C MULTIMED, P83, DOI DOI 10.1145/1873951.1873965; Metze F, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P478; Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732; Minsky M.., 1986, SOC MIND; Muandet K., 2013, INT C MACH LEARN, P10; Munezero M, 2014, IEEE T AFFECT COMPUT, V5, P101, DOI 10.1109/TAFFC.2014.2317187; Pan S, 2014, TOURISM MANAGE, V40, P59, DOI 10.1016/j.tourman.2013.05.007; Panda R, 2018, LECT NOTES COMPUT SC, V11206, P594, DOI 10.1007/978-3-030-01216-8_36; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Parrott W Gerrod, 2001, EMOTIONS SOCIAL PSYC; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Peng KC, 2015, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2015.7298687; Picard Rosalind W., 1997, AFFECTIVE COMPUTING; Plutchik Robert, 1980, EMOTION PSYCHOEVOLUT; Poels K, 2006, J ADVERTISING RES, V46, P18, DOI 10.2501/S0021849906060041; Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003; Truong QT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1274, DOI 10.1145/3123266.3123374; Rao TR, 2020, NEURAL PROCESS LETT, V51, P2043, DOI 10.1007/s11063-019-10033-9; Rao TR, 2019, NEUROCOMPUTING, V333, P429, DOI 10.1016/j.neucom.2018.12.053; Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434; Rui T, 2017, NEUROCOMPUTING, V230, P66, DOI 10.1016/j.neucom.2016.11.054; Salovey P., 1990, IMAG COGN PERS, V9, P185, DOI [10.2190/DUGG-P24E-52WK-6CDG, DOI 10.2190/DUGG-P24E-52WK-6CDG]; Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Sartori A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P311, DOI 10.1145/2733373.2806250; Scherer K.R., 2001, SERIES AFFECTIVE SCI; SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Schuller B, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P745, DOI 10.1109/ICME.2002.1035889; Schuller B, 2012, INT CONF ACOUST SPEE, P341, DOI 10.1109/ICASSP.2012.6287886; Schuller B, 2010, J NEW MUSIC RES, V39, P13, DOI 10.1080/09298210903430475; Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340; Shan Li, 2018, Arxiv, DOI arXiv:1804.08348; She DY, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3326335; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003; Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25; Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104; Sun K, 2009, IEEE INT CON MULTI, P566, DOI 10.1109/ICME.2009.5202559; Sun M.., 2016, PROC IEEE INT C MULT, P1; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Tan ESH, 2008, MEDIA PSYCHOL, V11, P28, DOI 10.1080/15213260701853161; Tobin J, 2017, IEEE INT C INT ROBOT, P23; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Toyama M.., 2013, PROC TTRA INT C; Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45; Wang J, 2016, IJCAI, P3484; Wang L.., 2018, PROC IEEE INT C SYST, P1873; Wang L, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P121, DOI 10.1109/ACIIW.2019.8925021; Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791; Wang WN, 2004, IEEE SYS MAN CYBERN, P6407; Wang XH, 2015, IEEE T AFFECT COMPUT, V6, P286, DOI 10.1109/TAFFC.2015.2400917; Wang XH, 2013, IEEE IMAGE PROC, P3230, DOI 10.1109/ICIP.2013.6738665; Wang XH, 2013, VISUAL COMPUT, V29, P1121, DOI 10.1007/s00371-012-0755-3; Wang YL, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2378; Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x; Wei Z., 2020, PROC IEEE C COMPUT V, P13106; Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667; Williamson J. D.., 1979, U.S. Patent, Patent No. [4,142,067, 4142067]; Wu B., 2015, PROC IEEE INT C MULT, P1; Wu BY, 2017, IEEE T MULTIMEDIA, V19, P1670, DOI 10.1109/TMM.2017.2655881; Wu LF, 2020, NEURAL PROCESS LETT, V51, P2063, DOI 10.1007/s11063-019-10027-7; Wu LF, 2017, IEEE IMAGE PROC, P1322; Xin Lu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P48, DOI 10.1007/978-3-319-46604-0_4; Xing BX, 2015, NEUROCOMPUTING, V148, P619, DOI 10.1016/j.neucom.2014.08.007; Xiong HT, 2019, AAAI CONF ARTIF INTE, P363; Yang JF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3266; Yang JF, 2018, AAAI CONF ARTIF INTE, P491; Yang JF, 2018, PROC CVPR IEEE, P7584, DOI 10.1109/CVPR.2018.00791; Yang JF, 2017, AAAI CONF ARTIF INTE, P224; Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520; Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978; Yang Y., 2013, P 21 ACM INT C MULTI, P785, DOI [10.1145/2502081.2502204, DOI 10.1145/2502081.2502204]; Yang Y, 2014, AAAI CONF ARTIF INTE, P306; Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754; Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701; Yao XX, 2019, IEEE I CONF COMP VIS, P1140, DOI 10.1109/ICCV.2019.00123; Ye J, 2019, IEEE IMAGE PROC, P869, DOI 10.1109/ICIP.2019.8802992; You QZ, 2017, AAAI CONF ARTIF INTE, P231; You QZ, 2016, AAAI CONF ARTIF INTE, P308; You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288; You QZ, 2015, AAAI CONF ARTIF INTE, P381; Yu J, 2019, IEEE IMAGE PROC, P2526, DOI 10.1109/ICIP.2019.8803388; Yuan J., 2013, P ACM INT WORKSH ISS; Zhan C, 2019, IEEE I CONF COMP VIS, P1151, DOI 10.1109/ICCV.2019.00124; Zhang J, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105245; Zhang J, 2019, IEEE INT CON MULTI, P1126, DOI 10.1109/ICME.2019.00197; Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253; Zhang W, 2020, IEEE T MULTIMEDIA, V22, P515, DOI 10.1109/TMM.2019.2928998; Zhao SC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2945, DOI 10.1145/3394171.3413776; Zhao SC, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3363560; Zhao SC, 2021, INT J COMPUT VISION, V129, P2399, DOI 10.1007/s11263-021-01479-3; Zhao SC, 2022, IEEE T CYBERNETICS, V52, P10000, DOI 10.1109/TCYB.2021.3062750; Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5534; Zhao SC, 2022, IEEE T NEUR NET LEAR, V33, P473, DOI 10.1109/TNNLS.2020.3028503; Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P303; Zhao SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1319, DOI 10.1145/3240508.3240591; Zhao SC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P192, DOI 10.1145/3343031.3351062; Zhao SC, 2019, AAAI CONF ARTIF INTE, P2620; Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1660; Zhao SC, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3233184; Zhao SC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P369, DOI 10.1145/3123266.3130858; Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669; Zhao SC, 2018, IEEE T AFFECT COMPUT, V9, P526, DOI [10.1109/TAFFC.2016.2628787, 10.1109/TAFFC.2018.2818685]; Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741; Zhao SC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P879, DOI 10.1145/2733373.2806354; Zhao SC, 2015, IEEE IMAGE PROC, P2459, DOI 10.1109/ICIP.2015.7351244; Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930; Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035; Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042; Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289; Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu XG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3595	188	10	10	34	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6729	6751		10.1109/TPAMI.2021.3094362	http://dx.doi.org/10.1109/TPAMI.2021.3094362			23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34214034	Green Submitted			2022-12-18	WOS:000853875300065
J	Cai, L; Li, JD; Wang, J; Ji, SW				Cai, Lei; Li, Jundong; Wang, Jie; Ji, Shuiwang			Line Graph Neural Networks for Link Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Task analysis; Predictive models; Graph neural networks; Convolution; Deep learning; Topology; Deep learning; graph analysis; link prediction; graph neural networks; line graphs		We consider the graph link prediction task, which is a classic graph analytical problem with many real-world applications. With the advances of deep learning, current link prediction methods commonly compute features from subgraphs centered at two neighboring nodes and use the features to predict the label of the link between these two nodes. In this formalism, a link prediction problem is converted to a graph classification task. In order to extract fixed-size features for classification, graph pooling layers are necessary in the deep learning model, thereby incurring information loss. To overcome this key limitation, we propose to seek a radically different and novel path by making use of the line graphs in graph theory. In particular, each node in a line graph corresponds to a unique edge in the original graph. Therefore, link prediction problems in the original graph can be equivalently solved as a node classification problem in its corresponding line graph, instead of a graph classification task. Experimental results on fourteen datasets from different applications demonstrate that our proposed method consistently outperforms the state-of-the-art methods, while it has fewer parameters and high training efficiency.	[Cai, Lei] Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA; [Li, Jundong] Univ Virginia, Dept Elect & Comp Engn, Dept Comp Sci, Charlottesville, VA 22904 USA; [Li, Jundong] Univ Virginia, Sch Data Sci, Charlottesville, VA 22904 USA; [Wang, Jie] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Anhui, Peoples R China; [Ji, Shuiwang] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA	Washington State University; University of Virginia; University of Virginia; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Texas A&M University System; Texas A&M University College Station	Ji, SW (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	lei.cai@wsu.edu; jundong@virginia.edu; jiewangx@ustc.edu.cn; sji@tamu.edu			National Science Foundation [DBI-2028361]	National Science Foundation(National Science Foundation (NSF))	This work was supported by National Science Foundation under Grant DBI-2028361.	Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Al Hasan M, 2006, SDM06 WORKSH LINK AN; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Cai L, 2020, AAAI CONF ARTIF INTE, V34, P3308; Chen Zhengdao, 2019, 7 INT C LEARN REPR I; Gao HY, 2019, PR MACH LEARN RES, V97; Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Hamilton WL, 2017, ADV NEUR IN, V30; Hinton Geoffrey, 2002, ADV NEURAL INFORM PR, V15, P833, DOI DOI 10.1109/TSMCB.2011.2106208; Jeh G, 2002, P 8 ACM SIGKDD INT C, V02, P538; Katz L., 1953, PSYCHOMETRIKA, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026, DOI 10.1016/j.clinph.2016.12.016]; Kipf T, 2018, PR MACH LEARN RES, V80; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Kovacs IA, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09177-y; LEHOT PGH, 1974, J ACM, V21, P569, DOI 10.1145/321850.321853; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Lu LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027; Max Welling, 2016, Arxiv, DOI arXiv:1611.07308; Max Welling, 2017, Arxiv, DOI arXiv:1609.02907; Newman MEJ, 2001, P NATL ACAD SCI USA, V98, P404, DOI 10.1073/pnas.021544898; Ng AY, 2002, ADV NEUR IN, V14, P849; Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592; Niepert M, 2016, PR MACH LEARN RES, V48; Oyetunde T, 2017, BIOINFORMATICS, V33, P608, DOI 10.1093/bioinformatics/btw684; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Qiu JZ, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P459, DOI 10.1145/3159652.3159706; Roussopoulos N. D., 1973, Information Processing Letters, V2, P108, DOI 10.1016/0020-0190(73)90029-X; Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38; Subelj L, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P527; Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093; Wang HW, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P968, DOI 10.1145/3292500.3330836; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Ying R, 2018, ADV NEUR IN, V31; You JX, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2236, DOI 10.1145/3308558.3313747; Yuan H., 2020, PROC 8 INT C LEARN R; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhang MH, 2018, ADV NEUR IN, V31; Zhang M, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P575, DOI 10.1145/3097983.3097996; Zhou T, 2009, EUR PHYS J B, V71, P623, DOI 10.1140/epjb/e2009-00335-8	43	10	10	11	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5103	5113		10.1109/TPAMI.2021.3080635	http://dx.doi.org/10.1109/TPAMI.2021.3080635			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33989153	Green Submitted			2022-12-18	WOS:000836666600046
J	Wang, SP; Chen, ZL; Du, SD; Lin, ZC				Wang, Shiping; Chen, Zhaoliang; Du, Shide; Lin, Zhouchen			Learning Deep Sparse Regularizers With Applications to Multi-View Clustering and Semi-Supervised Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural networks; Optimization; Task analysis; Minimization; Deep learning; Compressed sensing; Backpropagation; Deep learning; sparse regularizer; parameterized activation function; proximal operator; multi-view learning	IMAGE; REGRESSION	Sparsity-constrained optimization problems are common in machine learning, such as sparse coding, low-rank minimization and compressive sensing. However, most of previous studies focused on constructing various hand-crafted sparse regularizers, while little work was devoted to learning adaptive sparse regularizers from given input data for specific tasks. In this paper, we propose a deep sparse regularizer learning model that learns data-driven sparse regularizers adaptively. Via the proximal gradient algorithm, we find that the sparse regularizer learning is equivalent to learning a parameterized activation function. This encourages us to learn sparse regularizers in the deep learning framework. Therefore, we build a neural network composed of multiple blocks, each being differentiable and reusable. All blocks contain learnable piecewise linear activation functions which correspond to the sparse regularizer to be learned. Furthermore, the proposed model is trained with back propagation, and all parameters in this model are learned end-to-end. We apply our framework to multi-view clustering and semi-supervised classification tasks to learn a latent compact representation. Experimental results demonstrate the superiority of the proposed framework over state-of-the-art multi-view learning models.	[Wang, Shiping; Chen, Zhaoliang; Du, Shide] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Peoples R China; [Wang, Shiping; Chen, Zhaoliang; Du, Shide] Fuzhou Univ, Key Lab Network Comp & Intelligent Informat Proc, Fuzhou 350108, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China; [Lin, Zhouchen] Pazhou Lab, Guangzhou 510330, Peoples R China	Fuzhou University; Fuzhou University; Peking University; Pazhou Lab	Lin, ZC (corresponding author), Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China.	shipingwangphd@163.com; chenzl23@outlook.com; dushidems@gmail.com; zlin@pku.edu.cn			NSF of China [U1705262]; NSF of Fujian Province [2020J01130193, 2018J07005]; NSF China [61625301, 61731018]; Major Scientific Research Project of Zhejiang Lab [2019KB0AC01, 2019KB0AB02]; Beijing Academy of Artificial Intelligence; Qualcomm	NSF of China(National Natural Science Foundation of China (NSFC)); NSF of Fujian Province(Natural Science Foundation of Fujian Province); NSF China(National Natural Science Foundation of China (NSFC)); Major Scientific Research Project of Zhejiang Lab; Beijing Academy of Artificial Intelligence; Qualcomm	The work of Shiping Wang was supported in part by the NSF of China under Grant U1705262, and in part by the NSF of Fujian Province under Grants 2020J01130193 and 2018J07005. The work of Zhouchen Lin was supported in part by the NSF China under Grants 61625301 and 61731018, in part by the Major Scientific Research Project of Zhejiang Lab under Grants 2019KB0AC01 and 2019KB0AB02, in part by the Beijing Academy of Artificial Intelligence, and in part by Qualcomm.	Agrawal A, 2019, ADV NEUR IN, V32; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertinetto L., 2019, PROC 7 INT C LEARN R; Bhowmik A., 2017, PROC 2 NEURAL INF PR; Bibi A., 2019, PROC 7 INT C LEARN R; Combettes PL, 2020, SET-VALUED VAR ANAL, V28, P491, DOI 10.1007/s11228-019-00526-z; Dan C., 2019, ADV NEURAL INFORM PR, P2537; Friedman JH, 2012, INT J FORECASTING, V28, P722, DOI 10.1016/j.ijforecast.2012.05.001; Gao C., 2011, PROC ASS ADV ARTIF I, P356; Gao HC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2128; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; Gregor K., 2010, P 27 INT C INT C MAC, P399, DOI DOI 10.5555/3104322.3104374; Kloft M, 2011, J MACH LEARN RES, V12, P953; Li J, 2019, AAAI CONF ARTIF INTE, P4181; Li YQ, 2018, IEEE T PATTERN ANAL, V40, P2151, DOI 10.1109/TPAMI.2017.2748125; Liu SW, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5190; Liu X, 2020, AAAI CONF ARTIF INTE, V34, P4900; Lu CY, 2015, AAAI CONF ARTIF INTE, P1805; Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526; Luo W, 2018, IEEE T NEUR NET LEAR, V29, P3289, DOI 10.1109/TNNLS.2017.2712793; Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45; Ma RR, 2019, NEURAL NETWORKS, V119, P286, DOI 10.1016/j.neunet.2019.08.015; Mahapatra D., 2017, ARXIV; Nie F., 2016, IJCAI, P1881; Nie FP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564; Nie FP, 2017, AAAI CONF ARTIF INTE, P2408; Papyan V, 2017, J MACH LEARN RES, V18, P1; Sprechmann P, 2015, IEEE T PATTERN ANAL, V37, P1821, DOI 10.1109/TPAMI.2015.2392779; Srinivas S, 2017, IEEE COMPUT SOC CONF, P455, DOI 10.1109/CVPRW.2017.61; Sun Fei, 2016, P 25 INT JOINT C ART, P2915; Tanaka G, 2020, IEEE T NEUR NET LEAR, V31, P24, DOI 10.1109/TNNLS.2019.2899344; Tartaglione E, 2018, ADV NEUR IN, V31; Tian PZ, 2020, AAAI CONF ARTIF INTE, V34, P12087; Trzasko J, 2009, IEEE T MED IMAGING, V28, P106, DOI 10.1109/TMI.2008.927346; Wang S., 2016, ADV NEURAL INFORM PR, V29, P865; Wang XB, 2019, PATTERN RECOGN, V88, P50, DOI 10.1016/j.patcog.2018.09.009; Wang ZY, 2016, AAAI CONF ARTIF INTE, P2194; Xie XY, 2019, PR MACH LEARN RES, V97; Xie Y, 2020, IEEE T CYBERNETICS, V50, P572, DOI 10.1109/TCYB.2018.2869789; Yang H., 2020, PROC 8 INT C LEARN R; Yang Y, 2016, ADV NEUR IN, V29; Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335; Zhang HM, 2019, IEEE T NEUR NET LEAR, V30, P2916, DOI 10.1109/TNNLS.2019.2900572; Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196; Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P509, DOI 10.1109/TIP.2019.2929433; Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335; Zou DQ, 2020, IEEE T PATTERN ANAL, V42, P1501, DOI 10.1109/TPAMI.2019.2895331	49	10	10	18	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5042	5055		10.1109/TPAMI.2021.3082632	http://dx.doi.org/10.1109/TPAMI.2021.3082632			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	34018930				2022-12-18	WOS:000836666600042
J	Ong, J; Vo, BT; Vo, BN; Kim, DY; Nordholm, S				Ong, Jonah; Ba-Tuong Vo; Ba-Ngu Vo; Kim, Du Yong; Nordholm, Sven			A Bayesian Filter for Multi-View 3D Multi-Object Tracking With Occlusion Handling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Cameras; Trajectory; Bayes methods; Detectors; Training; Visualization; Multi-view; multi-sensor; multi-object visual tracking; occlusion handling; generalized labeled multi-bernoulli	PERFORMANCE EVALUATION; MULTITARGET TRACKING; VISUAL TRACKING; CAMERAS	This paper proposes an online multi-camera multi-object tracker that only requires monocular detector training, independent of the multi-camera configurations, allowing seamless extension/deletion of cameras without retraining effort. The proposed algorithm has a linear complexity in the total number of detections across the cameras, and hence scales gracefully with the number of cameras. It operates in the 3D world frame, and provides 3D trajectory estimates of the objects. The key innovation is a high fidelity yet tractable 3D occlusion model, amenable to optimal Bayesian multi-view multi-object filtering, which seamlessly integrates, into a single Bayesian recursion, the sub-tasks of track management, state estimation, clutter rejection, and occlusion/misdetection handling. The proposed algorithm is evaluated on the latest WILDTRACKS dataset, and demonstrated to work in very crowded scenes on a new dataset.	[Ong, Jonah; Ba-Tuong Vo; Ba-Ngu Vo; Nordholm, Sven] Curtin Univ, Dept Elect & Comp Engn, Bentley, WA 6102, Australia; [Kim, Du Yong] RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia	Curtin University; Royal Melbourne Institute of Technology (RMIT)	Ong, J (corresponding author), Curtin Univ, Dept Elect & Comp Engn, Bentley, WA 6102, Australia.	j.ong1@curtin.edu.au; ba-tuong.vo@curtin.edu.au; ba-ngu.vo@curtin.edu.au; duyong.kim@rmit.edu.au; s.nordholm@curtin.edu.au	Nordholm, Sven/J-5247-2014	Nordholm, Sven/0000-0001-8942-5328; Vo, Ba-Ngu/0000-0003-4202-7722; Kim, Du Yong/0000-0001-6882-2324; Ong Soon Xuan, Jonah/0000-0002-8019-0099	Australian Research Council [DP170104854, DP160104662]	Australian Research Council(Australian Research Council)	This work was supported by the Australian Research Council under DP170104854 and DP160104662.	Alameda-Pineda X, 2016, IEEE T PATTERN ANAL, V38, P1707, DOI 10.1109/TPAMI.2015.2496269; Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriyenko A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1839, DOI 10.1109/ICCVW.2011.6130472; [Anonymous], 2019, ARXIV 190703961; Vo BN, 2019, IEEE T SIGNAL PROCES, V67, P5952, DOI 10.1109/TSP.2019.2946023; Vo BN, 2017, IEEE T SIGNAL PROCES, V65, P1975, DOI 10.1109/TSP.2016.2641392; Vo BT, 2013, IEEE T SIGNAL PROCES, V61, P3460, DOI 10.1109/TSP.2013.2259822; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Baque P, 2017, IEEE I CONF COMP VIS, P271, DOI 10.1109/ICCV.2017.38; Bar-Shalom Y., 1988, TRACKING DATA ASS; Beard M., IEEE T SIGNAL PROCES, V68, P2754; Beard M, 2015, IEEE T SIGNAL PROCES, V63, P1433, DOI 10.1109/TSP.2015.2393843; Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Blackman, 1999, DESIGN ANAL MODERN T; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Chavdarova T, 2018, PROC CVPR IEEE, P5030, DOI 10.1109/CVPR.2018.00528; Chavdarova T, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P848, DOI 10.1109/ICMLA.2017.00-50; Do CT, 2019, INT CONF CONTR AUTO; Dockstader SL, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P95, DOI 10.1109/MOT.2001.937987; Domke J, 2013, IEEE T PATTERN ANAL, V35, P2454, DOI 10.1109/TPAMI.2013.31; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hoseinnezhad R, 2012, PATTERN RECOGN, V45, P3625, DOI 10.1016/j.patcog.2012.04.004; Hu HN, 2019, IEEE I CONF COMP VIS, P5389, DOI 10.1109/ICCV.2019.00549; Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57; Kim DY, 2019, PATTERN RECOGN, V90, P377, DOI 10.1016/j.patcog.2019.02.004; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Leal-Taixe L., 2015, ARXIV; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Li P., 2020, P IEEE CVF C COMP VI, P6877; Maggio E, 2008, IEEE T CIRC SYST VID, V18, P1016, DOI 10.1109/TCSVT.2008.928221; Mahler R., 2014, ADV STAT MULTISOURCE; Mahler RPS, 2011, IEEE T SIGNAL PROCES, V59, P3497, DOI 10.1109/TSP.2011.2128316; Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Ming Liang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11550, DOI 10.1109/CVPR42600.2020.01157; Nguyen T. T. D., 2019, SENSORS-BASEL, V19; Osep A., 2017, P 2017 IEEE INT C RO, P1995, DOI [DOI 10.1109/ICRA.2017.7989230, 10.1109/icra.2017.7989230]; Otsuka K, 2004, P IEEE COMP SOC C CO, V1, pI; Pedersen M., 2020, P IEEE CVF C COMP VI, P2426; Peng PX, 2015, PATTERN RECOGN, V48, P1760, DOI 10.1016/j.patcog.2014.12.004; Poiesi F, 2013, COMPUT VIS IMAGE UND, V117, P1257, DOI 10.1016/j.cviu.2012.08.008; Punchihewa YG, 2018, IEEE T SIGNAL PROCES, V66, P3040, DOI 10.1109/TSP.2018.2821650; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Reuter S, 2014, IEEE T SIGNAL PROCES, V62, P3246, DOI 10.1109/TSP.2014.2323064; Rezatofighi H., 2020, ARXIV 200803533; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Ristic B., 2003, KALMAN FILTER PARTIC; Scheidegger S, 2018, IEEE INT VEH SYM, P433; Schneider P., 2002, GEOMETRIC TOOLS COMP; Schuhmacher D, 2008, IEEE T SIGNAL PROCES, V56, P3447, DOI 10.1109/TSP.2008.920469; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Vo BN, 2005, IEEE T AERO ELEC SYS, V41, P1224, DOI 10.1109/TAES.2005.1561884; Xu YL, 2016, PROC CVPR IEEE, P4256, DOI 10.1109/CVPR.2016.461; Zhang WW, 2019, IEEE I CONF COMP VIS, P2365, DOI 10.1109/ICCV.2019.00245; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhao X., INT J ADV ROBOT SYST, V15	69	10	10	13	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2246	2263		10.1109/TPAMI.2020.3034435	http://dx.doi.org/10.1109/TPAMI.2020.3034435			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33112741	hybrid, Green Submitted			2022-12-18	WOS:000792921400005
J	Jin, J; Hou, JH; Chen, J; Zeng, HQ; Kwong, S; Yu, JY				Jin, Jing; Hou, Junhui; Chen, Jie; Zeng, Huanqiang; Kwong, Sam; Yu, Jingyi			Deep Coarse-to-Fine Dense Light Field Reconstruction With Flexible Sampling and Geometry-Aware Fusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Geometry; Learning systems; Image resolution; Rendering (computer graphics); Estimation; Cameras; Light field; deep learning; depth estimation; super resolution; compression; image-based rendering	QUALITY ASSESSMENT	A densely-sampled light field (LF) is highly desirable in various applications, such as 3-D reconstruction, post-capture refocusing and virtual reality. However, it is costly to acquire such data. Although many computational methods have been proposed to reconstruct a densely-sampled LF from a sparsely-sampled one, they still suffer from either low reconstruction quality, low computational efficiency, or the restriction on the regularity of the sampling pattern. To this end, we propose a novel learning-based method, which accepts sparsely-sampled LFs with irregular structures, and produces densely-sampled LFs with arbitrary angular resolution accurately and efficiently. We also propose a simple yet effective method for optimizing the sampling pattern. Our proposed method, an end-to-end trainable network, reconstructs a densely-sampled LF in a coarse-to-fine manner. Specifically, the coarse sub-aperture image (SAI) synthesis module first explores the scene geometry from an unstructured sparsely-sampled LF and leverages it to independently synthesize novel SAIs, in which a confidence-based blending strategy is proposed to fuse the information from different input SAIs, giving an intermediate densely-sampled LF. Then, the efficient LF refinement module learns the angular relationship within the intermediate result to recover the LF parallax structure. Comprehensive experimental evaluations demonstrate the superiority of our method on both real-world and synthetic LF images when compared with state-of-the-art methods. In addition, we illustrate the benefits and advantages of the proposed approach when applied in various LF-based applications, including image-based rendering and depth estimation enhancement. The code is available at https://github.com/jingjin25/LFASR-FS-GAF.	[Jin, Jing; Hou, Junhui; Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Chen, Jie] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China; [Zeng, Huanqiang] Huaqiao Univ, Coll Engn, Quanzhou 362021, Peoples R China; [Yu, Jingyi] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China	City University of Hong Kong; Hong Kong Baptist University; Huaqiao University; ShanghaiTech University	Hou, JH (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.	jingjin25-c@my.cityu.edu.hk; jh.hou@cityu.edu.hk; chenjie@comp.hkbu.edu.hk; zeng0043@hqu.edu.cn; cssamk@cityu.edu.hk; yujingyi@shanghaitech.edu.cn	cai, jie/HHS-0606-2022; Kwong, Sam/C-9319-2012	Kwong, Sam/0000-0001-7484-7261; Hou, Junhui/0000-0003-3431-2021; JIN, Jing/0000-0002-6584-8438	Hong Kong RGC [9048123 (CityU 21211518), 9042820 (CityU 11219019)]; Natural Science Foundation of China [61871342, 61871434]; Basic Research General Program of Shenzhen Municipality [JCYJ20190808183003968]	Hong Kong RGC(Hong Kong Research Grants Council); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Basic Research General Program of Shenzhen Municipality	The authors would like to thank the authors of [45] for sharing their source codes. This work was supported in part by the Hong Kong RGC under Grant 9048123 (CityU 21211518) and Grant 9042820 (CityU 11219019), in part by the Natural Science Foundation of China under Grant 61871342 and Grant 61871434, and in part by the Basic Research General Program of Shenzhen Municipality under Grant JCYJ20190808183003968.	Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932; Chen J, 2018, IEEE T IMAGE PROCESS, V27, P4889, DOI 10.1109/TIP.2018.2839524; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Fiss J, 2014, IEEE INT CONF COMPUT; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Hou JH, 2019, IEEE T CIRC SYST VID, V29, P517, DOI 10.1109/TCSVT.2018.2802943; Hou JH, 2015, IEEE T VIS COMPUT GR, V21, P848, DOI 10.1109/TVCG.2015.2403328; Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Jin J., 2020, P AAAI C ART INT, P11; Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251; Kamal MH, 2016, COMPUT VIS IMAGE UND, V145, P172, DOI 10.1016/j.cviu.2015.11.004; Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]; Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P, P 3 INT C LEARNING R; Kiran Adhikarla V., 2017, P IEEE C COMP VIS PA, P58; Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Mitra K., 2012, IEEE C COMP VIS PATT, P22; Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37; Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031; Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82; Paudyal P, 2019, IEEE T BROADCAST, V65, P152, DOI 10.1109/TBC.2019.2892092; Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855; Raj A.S., STANFORD LYTRO LIGHT; Rigamonti R, 2013, PROC CVPR IEEE, P2754, DOI 10.1109/CVPR.2013.355; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246; Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20; Tian Y, 2020, IEEE T IMAGE PROCESS, V29, P7945, DOI 10.1109/TIP.2020.3008856; Tulsiani S, 2018, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2018.00039; Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30; Vagharshakyan S, 2018, IEEE T PATTERN ANAL, V40, P133, DOI 10.1109/TPAMI.2017.2653101; Vijayanarasimhan Sudheendra, 2017, ARXIV170407804; Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wang Y., 2018, P EUR C COMP VIS ECC; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Wu GC, 2019, IEEE T IMAGE PROCESS, V28, P3261, DOI 10.1109/TIP.2019.2895463; Wu GC, 2019, IEEE T PATTERN ANAL, V41, P1681, DOI 10.1109/TPAMI.2018.2845393; Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178; Yan LQ, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2816814; Yeung HWF, 2019, IEEE T IMAGE PROCESS, V28, P2319, DOI 10.1109/TIP.2018.2885236; Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9; Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17; Yu JY, 2017, IEEE MULTIMEDIA, V24, P104, DOI 10.1109/MMUL.2017.24; Zhang C, 2004, SIGNAL PROCESS-IMAGE, V19, P1, DOI 10.1016/j.image.2003.07.001; Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329; Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007; Zhang ZT, 2015, PROC CVPR IEEE, P3800, DOI 10.1109/CVPR.2015.7299004; Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323; Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18	63	10	10	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1819	1836		10.1109/TPAMI.2020.3026039	http://dx.doi.org/10.1109/TPAMI.2020.3026039			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32966211	Green Submitted			2022-12-18	WOS:000764815300014
J	Toft, C; Maddern, W; Torii, A; Hammarstrand, L; Stenborg, E; Safari, D; Okutomi, M; Pollefeys, M; Sivic, J; Pajdla, T; Kahl, F; Sattler, T				Toft, Carl; Maddern, Will; Torii, Akihiko; Hammarstrand, Lars; Stenborg, Erik; Safari, Daniel; Okutomi, Masatoshi; Pollefeys, Marc; Sivic, Josef; Pajdla, Tomas; Kahl, Fredrik; Sattler, Torsten			Long-Term Visual Localization Revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Benchmark testing; Visualization; Cameras; Three-dimensional displays; Robots; Solid modeling; Trajectory; Visual localization; relocalization; 6DOF pose estimation; benchmark; long-term localization	PROBABILISTIC LOCALIZATION; PLACE RECOGNITION; IMAGE; SLAM	Visual localization enables autonomous vehicles to navigate in their surroundings and augmented reality applications to link virtual to real worlds. Practical visual localization approaches need to be robust to a wide variety of viewing conditions, including day-night changes, as well as weather and seasonal variations, while providing highly accurate six degree-of-freedom (6DOF) camera pose estimates. In this paper, we extend three publicly available datasets containing images captured under a wide variety of viewing conditions, but lacking camera pose information, with ground truth pose information, making evaluation of the impact of various factors on 6DOF camera pose estimation accuracy possible. We also discuss the performance of state-of-the-art localization approaches on these datasets. Additionally, we release around half of the poses for all conditions, and keep the remaining half private as a test set, in the hopes that this will stimulate research on long-term visual localization, learned local image features, and related research areas. Our datasets are available at visuallocalization.net, where we are also hosting a benchmarking server for automatic evaluation of results on the test set. The presented state-of-the-art results are to a large degree based on submissions to our server.	[Toft, Carl; Hammarstrand, Lars; Stenborg, Erik; Kahl, Fredrik; Sattler, Torsten] Chalmers Univ Technol, S-41296 Gothenburg, Sweden; [Maddern, Will] Univ Nuro, Nuro Robot Inst, Nuro OX1 2JD, England; [Torii, Akihiko; Safari, Daniel; Okutomi, Masatoshi] Tokyo Inst Technol, Tokyo 1528550, Japan; [Safari, Daniel] Tech Univ Denmark, DK-2800 Lyngby, Denmark; [Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland; [Pollefeys, Marc] Microsoft, Redmond, WA 98052 USA; [Sivic, Josef] PSL Res Univ, Dept Informat, CNRS, Ecole Normale Super, F-75006 Paris, France; [Sivic, Josef; Pajdla, Tomas; Sattler, Torsten] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16636 6, Czech Republic	Chalmers University of Technology; Tokyo Institute of Technology; Technical University of Denmark; Swiss Federal Institutes of Technology Domain; ETH Zurich; Microsoft; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite; Czech Technical University Prague	Toft, C (corresponding author), Chalmers Univ Technol, S-41296 Gothenburg, Sweden.	carltoft@gmail.com; will@nuro.ai; torii@sc.e.titech.ac.jp; lars.hammarstrand@chalmers.se; erik.stenborg@chalmers.se; daniel.safari@yahoo.dk; mxo@ok.sc.e.titech.ac.jp; marc.pollefeys@inf.ethz.ch; josef.sivic@inria.fr; pajdla@cvut.cz; fredrik.kahl@chalmers.se; torsten.sattler@cvut.cz	Sattler, Torsten/AAM-3155-2021; /C-1291-2019	/0000-0001-5676-1392	European Regional Development Fund under the project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]; JSPS KAKENHI [15H05313]; EPSRC [EP/M019918/1]; Swedish Research Council [2016-04445]; Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots)	European Regional Development Fund under the project IMPACT; JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Swedish Research Council(Swedish Research CouncilEuropean Commission); Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots)	This work was supported in part by the European Regional Development Fund under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468), JSPS KAKENHI Grant Number 15H05313, EPSRC Programme Grant EP/M019918/1, the Swedish Research Council (grant no. 2016-04445), and the Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots).	Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Camposeco F, 2017, PROC CVPR IEEE, P6700, DOI 10.1109/CVPR.2017.709; Camposeco F, 2016, LECT NOTES COMPUT SC, V9909, P202, DOI 10.1007/978-3-319-46454-1_13; Cao S, 2014, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2014.66; Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96; Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Choudhary S, 2012, LECT NOTES COMPUT SC, V7576, P130, DOI 10.1007/978-3-642-33715-4_10; Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Donoser M, 2014, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2014.73; Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828; Enqvist O., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P264, DOI 10.1109/ICCVW.2011.6130252; Enqvist O, 2008, LECT NOTES COMPUT SC, V5302, P141, DOI 10.1007/978-3-540-88682-2_12; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Germain H, 2019, INT CONF 3D VISION, P513, DOI 10.1109/3DV.2019.00063; Gronat P, 2016, INT J COMPUT VISION, V118, P319, DOI 10.1007/s11263-015-0878-x; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/cvpr.2009.5206587; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jenicek T, 2019, IEEE I CONF COMP VIS, P9695, DOI 10.1109/ICCV.2019.00979; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Kneip L, 2011, PROC CVPR IEEE; Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54; Larsson M, 2019, IEEE I CONF COMP VIS, P31, DOI 10.1109/ICCV.2019.00012; Larsson M, 2019, PROC CVPR IEEE, P9524, DOI 10.1109/CVPR.2019.00976; Larsson V., 2016, P BRIT MACH VIS C; Lee GH, 2015, INT J ROBOT RES, V34, P837, DOI 10.1177/0278364914557969; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218; Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Liu L, 2017, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2017.260; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823; Lynen S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498; Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273; Melekhov I., 2018, ARXIV181008393; Milford Michael, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301395; Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305; Naseer T, 2014, AAAI CONF ARTIF INTE, P2564; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Radenovic F, 2016, PROC CVPR IEEE, P5488, DOI 10.1109/CVPR.2016.592; Revaud J., 2019, P ADV NEUR INF PROC, P405; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Sarlin Paul-Edouard, 2019, P IEEE C COMP VIS PA; Sattler T., 2016, P IEEE C COMP VIS PA, P2102; Sattler T., 2015, P IEEE INT C COMP VI; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76; Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Shi T., ARXIV190403803, V2019; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Simonyan K., 2015, INT C LEARN REPR ICL; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Stenborg E, 2018, IEEE INT CONF ROBOT, P6484; Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986; Sun X, 2017, PROC CVPR IEEE, P5641, DOI 10.1109/CVPR.2017.598; Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Sunderhauf Niko, 2013, IEEE INT C ROB AUT W; Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331; Svarm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75; Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752; Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8_24; Toft C, 2017, IEEE INT CONF COMP V, P650, DOI 10.1109/ICCVW.2017.83; Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790; Torii A, 2015, IEEE T PATTERN ANAL, V37, P2346, DOI 10.1109/TPAMI.2015.2409868; uhlfellner P. M_, 2016, J FIELD ROBOTICS, V35; Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165; Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75; Wang SL, 2017, IEEE I CONF COMP VIS, P3028, DOI 10.1109/ICCV.2017.327; Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3; Xin Z, 2019, IEEE INT CONF ROBOT, P5979, DOI 10.1109/ICRA.2019.8794383; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310; Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366; Zhou H., 2016, P EUR C COMP VIS WOR	95	10	10	21	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2074	2088		10.1109/TPAMI.2020.3032010	http://dx.doi.org/10.1109/TPAMI.2020.3032010			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33074802	Green Submitted, Green Published			2022-12-18	WOS:000764815300031
J	Zeng, H; Cai, JR; Li, LD; Cao, ZS; Zhang, L				Zeng, Hui; Cai, Jianrui; Li, Lida; Cao, Zisheng; Zhang, Lei			Learning Image-Adaptive 3D Lookup Tables for High Performance Photo Enhancement in Real-Time	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Table lookup; Three-dimensional displays; Image color analysis; Pipelines; Cameras; Tools; Photo enhancement; photo retouching; 3D lookup table; color enhancement; tone enhncement		Recent years have witnessed the increasing popularity of learning based methods to enhance the color and tone of photos. However, many existing photo enhancement methods either deliver unsatisfactory results or consume too much computational and memory resources, hindering their application to high-resolution images (usually with more than 12 megapixels) in practice. In this paper, we learn image-adaptive 3-dimensional lookup tables (3D LUTs) to achieve fast and robust photo enhancement. 3D LUTs are widely used for manipulating color and tone of photos, but they are usually manually tuned and fixed in camera imaging pipeline or photo editing tools. We, for the first time to our best knowledge, propose to learn 3D LUTs from annotated data using pairwise or unpaired learning. More importantly, our learned 3D LUT is image-adaptive for flexible photo enhancement. We learn multiple basis 3D LUTs and a small convolutional neural network (CNN) simultaneously in an end-to-end manner. The small CNN works on the down-sampled version of the input image to predict content-dependent weights to fuse the multiple basis 3D LUTs into an image-adaptive one, which is employed to transform the color and tone of source images efficiently. Our model contains less than 600K parameters and takes less than 2 ms to process an image of 4K resolution using one Titan RTX GPU. While being highly efficient, our model also outperforms the state-of-the-art photo enhancement methods by a large margin in terms of PSNR, SSIM and a color difference metric on two publically available benchmark datasets. Code will be released at https://github.com/HuiZeng/Image-Adaptive-3DLUT.	[Zeng, Hui; Cai, Jianrui; Li, Lida; Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China; [Cao, Zisheng] DJI Innovat Co Ltd, Camera Grp, Shenzhen 518057, Peoples R China	Hong Kong Polytechnic University	Zhang, L (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.	cshzeng@comp.polyu.edu.hk; csjcai@comp.polyu.edu.hk; cslli@comp.polyu.edu.hk; zisheng.cao@dji.com; cslzhang@comp.polyu.edu.hk	Zhang, Hui/HHN-8494-2022		Hong Kong RGC RIF Grant [R5001-18]	Hong Kong RGC RIF Grant	This work was supported by the Hong Kong RGC RIF Grant (R5001-18). The authors would like to thank Zhihao Zeng, Jing Li, and other engineers from the Camera Group of DJI for their valuable discussions and suggestions on this work.	Backhaus W.G., 2011, COLOR VISION PERSPEC; Bychkovsky V, 2011, PROC CVPR IEEE, P97; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660; Deng YB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P870, DOI 10.1145/3240508.3240531; Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Glorot X., 2010, PROC MACH LEARN RES, P249; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gulrajani I, 2017, P NIPS 2017; Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181974; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Hwang SJ, 2012, LECT NOTES COMPUT SC, V7572, P569, DOI 10.1007/978-3-642-33718-5_41; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Kang SB, 2010, PROC CVPR IEEE, P1799, DOI 10.1109/CVPR.2010.5539850; Karaimer HC, 2016, LECT NOTES COMPUT SC, V9905, P429, DOI 10.1007/978-3-319-46448-0_26; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378; King DB, 2015, ACS SYM SER, V1214, P1; Kosugi S, 2020, AAAI CONF ARTIF INTE, V34, P11296; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee JY, 2016, PROC CVPR IEEE, P2470, DOI 10.1109/CVPR.2016.271; Liang Z., 2019, ARXIV190801481; Lim S. H., 2015, US Patent., Patent No. [9,105,078, 9105078]; Liu YM, 2014, COMPUT GRAPH FORUM, V33, P21, DOI 10.1111/cgf.12409; Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740; Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667; Mukherjee J, 2008, IEEE T IMAGE PROCESS, V17, P1783, DOI 10.1109/TIP.2008.2002826; Nam S, 2017, IEEE I CONF COMP VIS, P1726, DOI 10.1109/ICCV.2017.190; Park J, 2018, PROC CVPR IEEE, P5928, DOI 10.1109/CVPR.2018.00621; Paszke A, 2019, ADV NEUR IN, V32; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Schwartz E, 2019, IEEE T IMAGE PROCESS, V28, P912, DOI 10.1109/TIP.2018.2872858; Selan J., USING LOOKUP TABLES; Takahashi Y., 1998, US Patent., Patent No. [5,748,287, 5748287]; Ulyanov D., 2016, ARXIV160708022; Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wikipedia contributors, COL BAND WIK FREE EN; Wikipedia contributors, CIE 1931 COL SPAC WI; Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093; Yan JZ, 2014, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2014.382; Yan ZC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2790296; Yuan L, 2012, LECT NOTES COMPUT SC, V7575, P771, DOI 10.1007/978-3-642-33765-9_55; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	52	10	10	14	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2058	2073		10.1109/TPAMI.2020.3026740	http://dx.doi.org/10.1109/TPAMI.2020.3026740			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32976094	Green Submitted			2022-12-18	WOS:000764815300030
J	Jiang, ZT; Wang, TZ; Yan, JC				Jiang, Zetian; Wang, Tianzhe; Yan, Junchi			Unifying Offline and Online Multi-Graph Matching via Finding Shortest Paths on Supergraph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern matching; Heuristic algorithms; Dynamic programming; Optimization; Shortest path problem; Computational modeling; Indexes; Graph matching; multiple graph matching; online graph matching; shortest path search	OPTIMIZATION	This paper addresses the problem of multiple graph matching (MGM) by considering both offline batch mode and online setting. We explore the concept of cycle-consistency over pairwise matchings and formulate the problem as finding optimal composition path on the supergraph, whose vertices refer to graphs and edge weights denote score function regarding consistency and affinity. By our theoretical study we show that the offline and online MGM on supergraph can be converted to finding all pairwise shortest paths and single-source shortest paths respectively. We adopt the Floyd algorithm [1] and shortest path faster algorithm (SPFA) [2] , [3] to effectively find the optimal path. Extensive experimental results show our methods surpass state-of-the-art MGM methods, including CAO [4] , MISM [5] , IMGM [6] , and many other recent methods in offline and online settings. Source code will be made publicly available.	[Jiang, Zetian; Wang, Tianzhe] Shanghai Jiao Tong Univ, Zhiyuan Coll, Shanghai 200240, Peoples R China; [Yan, Junchi] Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China; [Yan, Junchi] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University	Yan, JC (corresponding author), Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.; Yan, JC (corresponding author), Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.	maple_jzt@sjtu.edu.cn; usedtobe@sjtu.edu.cn; yanjunchi@sjtu.edu.cn		Yan, Junchi/0000-0001-9639-7679	China Major State Research Development Program [2018AAA0100704]; NSFC [61972250, U19B2035]; Open Project Program of the National Laboratory of Pattern Recognition (NLPR)	China Major State Research Development Program; NSFC(National Natural Science Foundation of China (NSFC)); Open Project Program of the National Laboratory of Pattern Recognition (NLPR)	The work was supported in part by China Major State Research Development Program (2018AAA0100704), NSFC (61972250, U19B2035) and the Open Project Program of the National Laboratory of Pattern Recognition (NLPR). The authors would like to thank the anonymous reviewers for their valuable comments for improving the paper. Zetian Jiang and Tianzhe Wang contributed equally to this work.	[Anonymous], 2012, INT J COMPUT VISION, DOI DOI 10.1007/s11263-011-0442-2; Bernard F, 2019, PATTERN RECOGN, V92, P146, DOI 10.1016/j.patcog.2019.03.021; Birdal T, 2019, PROC CVPR IEEE, P11097, DOI 10.1109/CVPR.2019.01136; Chakraborty A, 2016, IEEE T PATTERN ANAL, V38, P1859, DOI 10.1109/TPAMI.2015.2491922; Chen YX, 2014, PR MACH LEARN RES, V32, P100; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Duan F., 1994, J SW JIAOTONG U, V29; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Henzinger MR, 1997, J COMPUT SYST SCI, V55, P3, DOI 10.1006/jcss.1997.1493; Hu Nan, 2018, PROC CVPR IEEE, P2463, DOI DOI 10.1109/CVPR.2018.00261; Huang QX, 2013, COMPUT GRAPH FORUM, V32, P177, DOI 10.1111/cgf.12184; Kim VG, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185550; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Leonardos Spyridon, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2645, DOI 10.1109/ICRA.2017.7989308; Leonardos S, 2018, IEEE DECIS CONTR P, P89, DOI 10.1109/CDC.2018.8619511; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Li B, 2018, P EUR C COMP VIS, P139; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Liu ZY, 2014, INT J COMPUT VISION, V109, P169, DOI 10.1007/s11263-014-0707-7; Loiola EM, 2007, EUR J OPER RES, V176, P657, DOI 10.1016/j.ejor.2005.09.032; Moore E.F., 1959, P INT S THEOR SWITCH, P285; Pachauri D., 2013, ADV NEURAL INFORM PR, V26, P1860; Shi XC, 2016, PROC CVPR IEEE, P5062, DOI 10.1109/CVPR.2016.547; Swoboda P, 2019, PROC CVPR IEEE, P11148, DOI 10.1109/CVPR.2019.01141; Tron R, 2017, IEEE I CONF COMP VIS, P4077, DOI 10.1109/ICCV.2017.437; van Wyk BJ, 2004, IEEE T PATTERN ANAL, V26, P1526, DOI 10.1109/TPAMI.2004.95; Wang QQ, 2018, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2018.00078; Yan JC, 2016, INT C PATT RECOG, P3832, DOI 10.1109/ICPR.2016.7900232; Yan JC, 2013, IEEE I CONF COMP VIS, P1649, DOI 10.1109/ICCV.2013.207; Yan JC, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P167, DOI 10.1145/2911996.2912035; Yan JC, 2016, IEEE T PATTERN ANAL, V38, P1228, DOI 10.1109/TPAMI.2015.2477832; Yan JC, 2015, IEEE I CONF COMP VIS, P199, DOI 10.1109/ICCV.2015.31; Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759; Yan JC, 2015, IEEE T IMAGE PROCESS, V24, P994, DOI 10.1109/TIP.2014.2387386; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667; Zhou XW, 2015, IEEE I CONF COMP VIS, P4032, DOI 10.1109/ICCV.2015.459	44	10	10	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3648	3663		10.1109/TPAMI.2020.2989928	http://dx.doi.org/10.1109/TPAMI.2020.2989928			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32340936				2022-12-18	WOS:000692232400028
J	Wang, NY; Zhang, YD; Li, ZW; Fu, YW; Yu, H; Liu, W; Xue, XY; Jiang, YG				Wang, Nanyang; Zhang, Yinda; Li, Zhuwen; Fu, Yanwei; Yu, Hang; Liu, Wei; Xue, Xiangyang; Jiang, Yu-Gang			Pixel2Mesh: 3D Mesh Model Generation via Image Guided Deformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Shape; Adaptation models; Solid modeling; Geometry; Strain; Color; 3D shape generation; graph convolutional neural network; mesh reconstruction; coarse-to-fine; end-to-end framework		In this paper, we propose an end-to-end deep learning architecture that generates 3D triangular meshes from single color images. Restricted by the nature of prevalent deep learning techniques, the majority of previous works represent 3D shapes in volumes or point clouds. However, it is non-trivial to convert these representations to compact and ready-to-use mesh models. Unlike the existing methods, our network represents 3D shapes in meshes, which are essentially graphs and well suited for graph-based convolutional neural networks. Leveraging perceptual features extracted from an input image, our network produces the correct geometry by progressively deforming an ellipsoid. To make the whole deformation procedure stable, we adopt a coarse-to-fine strategy, and define various mesh/surface related losses to capture properties of various aspects, which benefits producing the visually appealing and physically accurate 3D geometry. In addition, our model by nature can be adapted to objects in specific domains, e.g., human faces, and be easily extended to learn per-vertex properties, e.g., color. Extensive experiments show that our method not only qualitatively produces the mesh model with better details, but also achieves the higher 3D shape estimation accuracy compared against the state-of-the-arts.	[Wang, Nanyang; Yu, Hang; Xue, Xiangyang; Jiang, Yu-Gang] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China; [Zhang, Yinda] Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA; [Li, Zhuwen] Nuro Inc, Mountain View, CA 94043 USA; [Fu, Yanwei] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China; [Fu, Yanwei] Fudan Univ, MOE Frontiers Ctr Brain Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China; [Liu, Wei] Tencent AI Lab, Comp Vis Ctr, Shenzhen 518057, Peoples R China	Fudan University; Princeton University; Fudan University; Fudan University; Tencent	Jiang, YG (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.	nywang16@fudan.edu.cn; yindaz@cs.princeton.edu; lzhuwen@gmail.com; yanweifu@fudan.edu.cn; sir.hangyu@gmail.com; wl2223@columbia.edu; xyxue@fudan.edu.cn; ygj@fudan.edu.cn		Xue, Xiangyang/0000-0002-4897-9209; Fu, Yanwei/0000-0002-6595-6893; Liu, Wei/0000-0002-3865-8145	NSFC [U1611461, 61702108]; Science and Technology Commission of Shanghai Municipality Projects [19511120700, 19ZR147 1800, 19511132000]; Shanghai Research and Innovation Functional Program [17DZ2260900]; Shanghai Municipal Science and Technology Major Project [2018SH ZDZX01];  [TP2017006]	NSFC(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality Projects(Science & Technology Commission of Shanghai Municipality (STCSM)); Shanghai Research and Innovation Functional Program; Shanghai Municipal Science and Technology Major Project; 	This work was supported in part by the NSFC Projects (U1611461, 61702108), Science and Technology Commission of Shanghai Municipality Projects (19511120700, 19ZR147 1800, 19511132000), Shanghai Research and Innovation Functional Program (17DZ2260900), and Shanghai Municipal Science and Technology Major Project (2018SH ZDZX01). The work of Dr. Yanwei Fu was supported by Eastern Scholar (TP2017006). Nanyang Wang, Yinda Zhang, Zhuwen Li, and Yanwei Fu contributed equally to this work.	Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Boscaini Davide, 2016, P 30 INT C NEUR INF, P2; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754; Chang Angel X., 2015, ARXIV151203012CSGR P; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Cignoni P., 2008, P EUR IT CHAPT C, P2; Defferrard M, 2016, ADV NEUR IN, V29; Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33; Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29; Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030; Hartley R., 2004, ROBOTICA; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Huang QX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766890; Huber P., 2016, P 11 INT JOINT C COM, P3; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411; Kipf T. N., 2016, P INT C LEARN REPR, P2; Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599; Lee YJ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-176; Li ZW, 2018, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2018.00067; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112; Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459; Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Pontes Jhony K., 2017, ARXIV171110669CSCV; Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Su H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601159; Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314; Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Waechter M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2999533; Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4; Wen C, 2019, IEEE I CONF COMP VIS, P1042, DOI 10.1109/ICCV.2019.00113; Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697; Zhou ZH, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9801-4; Zhu X., 2016, COMPUT VIS PATTERN R, V41, P146; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	54	10	10	9	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3600	3613		10.1109/TPAMI.2020.2984232	http://dx.doi.org/10.1109/TPAMI.2020.2984232			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32248097				2022-12-18	WOS:000692232400025
J	Wolf, S; Bailoni, A; Pape, C; Rahaman, N; Kreshuk, A; Kothe, U; Hamprecht, FA				Wolf, Steffen; Bailoni, Alberto; Pape, Constantin; Rahaman, Nasim; Kreshuk, Anna; Kothe, Ullrich; Hamprecht, Fred A.			The Mutex Watershed and its Objective: Efficient, Parameter-Free Graph Partitioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Partitioning algorithms; Image segmentation; Image edge detection; Merging; Correlation; Vegetation; Image segmentation; partitioning algorithms; greedy algorithms; optimization; integer linear programming; machine learning; convolutional neural networks	SEGMENTATION; ALGORITHMS	Image partitioning, or segmentation without semantics, is the task of decomposing an image into distinct segments, or equivalently to detect closed contours. Most prior work either requires seeds, one per segment; or a threshold; or formulates the task as multicut / correlation clustering, an NP-hard problem. Here, we propose an efficient algorithm for graph partitioning, the "Mutex Watershed". Unlike seeded watershed, the algorithm can accommodate not only attractive but also repulsive cues, allowing it to find a previously unspecified number of segments without the need for explicit seeds or a tunable threshold. We also prove that this simple algorithm solves to global optimality an objective function that is intimately related to the multicut / correlation clustering integer linear programming formulation. The algorithm is deterministic, very simple to implement, and has empirically linearithmic complexity. When presented with short-range attractive and long-range repulsive cues from a deep neural network, the Mutex Watershed gives the best results currently known for the competitive ISBI 2012 EM segmentation benchmark.	[Wolf, Steffen; Bailoni, Alberto; Rahaman, Nasim; Kothe, Ullrich; Hamprecht, Fred A.] Heidelberg Univ, HCI IWR, D-69120 Heidelberg, Germany; [Pape, Constantin; Kreshuk, Anna] EMBL, D-69117 Heidelberg, Germany	Ruprecht Karls University Heidelberg; European Molecular Biology Laboratory (EMBL)	Hamprecht, FA (corresponding author), Heidelberg Univ, HCI IWR, D-69120 Heidelberg, Germany.	steffen.wolf@iwr.uni-heidelberg.de; alberto.bailoni@iwr.uni-heidelberg.de; constantin.pape@embl.de; nasim.rahaman@iwr.uni-heidelberg.de; anna.kreshuk@embl.de; ullrich.koethe@iwr.uni-heidelberg.de; fred.hamprecht@iwr.uni-heidelberg.de		Koethe, Ullrich/0000-0001-6036-1287; Kreshuk, Anna/0000-0003-1334-6388; Bailoni, Alberto/0000-0002-0569-8044; Wolf, Steffen/0000-0002-9639-2509; Pape, Constantin/0000-0001-6562-7187	Deutsche Forschungsgemeinschft (DFG, German Research Foundation) [240245660 - SFB 1129]; Baden-Wurttemberg Stiftung Elite PostDoc Program	Deutsche Forschungsgemeinschft (DFG, German Research Foundation)(German Research Foundation (DFG)); Baden-Wurttemberg Stiftung Elite PostDoc Program	This work was partially funded by the Deutsche Forschungsgemeinschft (DFG, German Research Foundation) -Projektnummer 240245660 -SFB 1129 and the Baden-Wurttemberg Stiftung Elite PostDoc Program. Steffen Wolf and Alberto Bailoni contributed equally to thiswork.	Abdelsamea M., 2011, INT J BIOSCI BIOCH B, V1, P256; Al-Faris AQ, 2014, J DIGIT IMAGING, V27, P133, DOI 10.1007/s10278-013-9640-5; Al-Faris AQ., SOFT COMPUT IND APPL, V223, P49; Alattar MA, 2010, LECT NOTES COMPUT SC, V6112, P89, DOI 10.1007/978-3-642-13775-4_10; Andres B, 2012, LECT NOTES COMPUT SC, V7574, P778, DOI 10.1007/978-3-642-33712-3_56; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Arganda-Carreras I, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00142; Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305; Beier T, 2017, NAT METHODS, V14, P101, DOI 10.1038/nmeth.4151; Beier T, 2016, LECT NOTES COMPUT SC, V9906, P715, DOI 10.1007/978-3-319-46475-6_44; Beucher S, 1994, COMP IMAG VIS, V2, P69; Beucher S., 1979, INT WORK IMAGE PROCE; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; Braides A, 2006, HBK DIFF EQUAT STATI, V3, P101, DOI 10.1016/S1874-5733(06)80006-9; Cai Jinzheng, 2016, Med Image Comput Comput Assist Interv, V9901, P442, DOI 10.1007/978-3-319-46723-8_51; Ciresan Dan, 2012, ADV NEURAL INFORM PR, P2843, DOI DOI 10.5555/2999325.2999452; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Couprie C, 2011, IEEE T PATTERN ANAL, V33, P1384, DOI 10.1109/TPAMI.2010.200; Dal Maso G, 2012, INTRO G CONVERGENCE, V8; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Funke J, 2019, IEEE T PATTERN ANAL, V41, P1669, DOI 10.1109/TPAMI.2018.2835450; Grimaud M., 1992, P SOC PHOTO-OPT INS, P292, DOI DOI 10.1117/12.60650; Guigues L, 2006, INT J COMPUT VISION, V68, P289, DOI 10.1007/s11263-005-6299-0; Hornakova A, 2017, PR MACH LEARN RES, V70; Januszewski M, 2018, NAT METHODS, V15, P605, DOI 10.1038/s41592-018-0049-4; Kernighan B. W., 1970, Bell System Technical Journal, V49, P291; Keuper M, 2015, IEEE I CONF COMP VIS, P1751, DOI 10.1109/ICCV.2015.204; Keuper M., 2016, ARXIV160706317; King DB, 2015, ACS SYM SER, V1214, P1; Kiran BR, 2014, PATTERN RECOGN, V47, P12, DOI 10.1016/j.patcog.2013.05.012; Knowles-Barley S, 2016, ARXIV161106973; Kokkinos I., 2015, COMPUT VIS PATTERN R; Lange JH, 2018, PR MACH LEARN RES, V80; Lee K., 2017, SHIN KORI 5 6 PUBLIC; Levi Z, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661258; Levinkov E, 2017, LECT NOTES COMPUT SC, V10496, P103, DOI 10.1007/978-3-319-66709-6_9; Malmberg F, 2011, LECT NOTES COMPUT SC, V6688, P36, DOI 10.1007/978-3-642-21227-7_4; Meirovitch Y., 2016, ARXIV QUANTITATIVE M; Meyer F, 1999, PROCEEDINGS OF THE IEEE-EURASIP WORKSHOP ON NONLINEAR SIGNAL AND IMAGE PROCESSING (NSIP'99), P369; MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4; Meyer F, 1994, COMP IMAG VIS, V2, P77; Mubarak D. Muhammad Noorul, 2012, International Journal of Computer Science & Information Technology, V4, P61, DOI 10.5121/ijcsit.2012.4306; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Najman L, 2017, SIAM J IMAGING SCI, V10, P2275, DOI 10.1137/17M1118580; Najman L, 2011, J MATH IMAGING VIS, V40, P231, DOI 10.1007/s10851-011-0259-1; Nunez-Iglesias J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071715; Pape C, 2017, IEEE INT CONF COMP V, P1, DOI 10.1109/ICCVW.2017.7; Parag T, 2017, 170708935 ARXIV; Perret B, 2018, IEEE T IMAGE PROCESS, V27, P1676, DOI 10.1109/TIP.2017.2779604; Pohle R, 2001, PROC SPIE, V4322, P1337, DOI 10.1117/12.431013; Poonguzhali S, 2006, 2006 INTERNATIONAL CONFERENCE ON BIOMEDICAL AND PHARMACEUTICAL ENGINEERING, VOLS 1 AND 2, P88; Quan T.M., 2016, ARXIV161205360; Ronneberger O, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Schlegel P, 2017, CURR OPIN INSECT SCI, V24, P96, DOI 10.1016/j.cois.2017.09.011; Shan J, 2008, INT C PATT RECOG, P3990; Shen W, 2017, IEEE I CONF COMP VIS, P2410, DOI 10.1109/ICCV.2017.262; Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817; Sorensen T.A., 1948, KONG DANSK VIDENSK S, V5, P4, DOI DOI 10.1234/12345678; Turaga S., 2009, ADV NEURAL INFORM PR, P1865; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881; Uzunbas MG, 2014, LECT NOTES COMPUT SC, V8673, P97, DOI 10.1007/978-3-319-10404-1_13; Vachier C., 1995, IEEE WORKSH NONL SIG, P254; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wang S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURE, P1; Weiler M, 2018, PROC CVPR IEEE, P849, DOI 10.1109/CVPR.2018.00095; Wolf S, 2018, LECT NOTES COMPUT SC, V11208, P571, DOI 10.1007/978-3-030-01225-0_34; Wolf S, 2017, IEEE I CONF COMP VIS, P2030, DOI 10.1109/ICCV.2017.222; Wu J, 2008, INT CONF BIOMED, P263, DOI 10.1109/BMEI.2008.352; Xiao C, 2018, I S BIOMED IMAGING, P378; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yarkony J, 2012, LECT NOTES COMPUT SC, V7577, P568, DOI 10.1007/978-3-642-33783-3_41; Zhang C, 2014, LECT NOTES COMPUT SC, V8673, P9, DOI 10.1007/978-3-319-10404-1_2; Zlateski A., 2015, ARXIV150500249	77	10	10	4	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3724	3738		10.1109/TPAMI.2020.2980827	http://dx.doi.org/10.1109/TPAMI.2020.2980827			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32175858	Green Submitted			2022-12-18	WOS:000692232400033
J	Zhang, QS; Wang, X; Wu, YN; Zhou, HL; Zhu, SC				Zhang, Quanshi; Wang, Xin; Wu, Ying Nian; Zhou, Huilin; Zhu, Song-Chun			Interpretable CNNs for Object Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Semantics; Neural networks; Task analysis; Feature extraction; Annotations; Benchmark testing; Convolutional neural networks; interpretable deep learning	MODELS	This paper proposes a generic method to learn interpretable convolutional filters in a deep convolutional neural network (CNN) for object classification, where each interpretable filter encodes features of a specific object part. Our method does not require additional annotations of object parts or textures for supervision. Instead, we use the same training data as traditional CNNs. Our method automatically assigns each interpretable filter in a high conv-layer with an object part of a certain category during the learning process. Such explicit knowledge representations in conv-layers of the CNN help people clarify the logic encoded in the CNN, i.e., answering what patterns the CNN extracts from an input image and uses for prediction. We have tested our method using different benchmark CNNs with various architectures to demonstrate the broad applicability of our method. Experiments have shown that our interpretable filters are much more semantically meaningful than traditional filters.	[Zhang, Quanshi; Wang, Xin; Zhou, Huilin] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, John Hopcroft Ctr, Shanghai 200240, Peoples R China; [Wu, Ying Nian] Univ Calif Los Angeles, Los Angeles, CA 90095 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat & Comp Sci, Los Angeles, CA 90095 USA	Shanghai Jiao Tong University; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Zhang, QS (corresponding author), Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, John Hopcroft Ctr, Shanghai 200240, Peoples R China.	zqs1022@sjtu.edu.cn; xin.wang@sjtu.edu.cn; ywu@stat.ucla.edu; zhouhuilin116@sjtu.edu.cn; sczhu@stat.ucla.edu			National Natural Science Foundation of China [U19B2043, 61906120]; DARPA XAI Award [N66001-17-2-4029]; NSF [IIS 1423305]; ARO [W911NF1810296]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); DARPA XAI Award; NSF(National Science Foundation (NSF)); ARO	This work was supported in part by National Natural Science Foundation of China (U19B2043 and 61906120), DARPA XAI Award N66001-17-2-4029, NSF IIS 1423305, and ARO project W911NF1810296.	Aubry M, 2015, IEEE I CONF COMP VIS, P2875, DOI 10.1109/ICCV.2015.329; Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Chen RJ, 2019, IEEE I CONF COMP VIS, P9186, DOI 10.1109/ICCV.2019.00928; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Cheng X., 2020, CVPR, P12925; Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522; Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371; Goyal Yash, 2016, ARXIV160808974; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228; Ithapu VK, 2017, IEEE COMPUT SOC CONF, P1695, DOI 10.1109/CVPRW.2017.216; Koh PW, 2017, PR MACH LEARN RES, V70; Kolouri S, 2017, IEEE COMPUT SOC CONF, P1670, DOI 10.1109/CVPRW.2017.213; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar D, 2017, IEEE COMPUT SOC CONF, P1686, DOI 10.1109/CVPRW.2017.215; Lakkaraju H, 2017, AAAI CONF ARTIF INTE, P2124; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lengerich B. J., 2017, ICML WORKSH VIS DEEP; Lundberg SM, 2017, ADV NEUR IN, V30; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Olah C., 2017, DISTILL, V2; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Sabour S, 2017, ADV NEUR IN, V30; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Simon M, 2015, LECT NOTES COMPUT SC, V9004, P162, DOI 10.1007/978-3-319-16808-1_12; Simonyan K., 2015, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1409.1556; Simonyan Karen, 2013, DEEP INSIDE CONVOLUT, P2; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858; Szegedy Christian, 2014, P 2 INT C LEARNING R; Vaughan J., 2018, ARXIV180601933; Ventura C, 2017, IEEE COMPUT SOC CONF, P1705, DOI 10.1109/CVPRW.2017.217; Wah C., 2011, TECH REP; Wicaksana AS, 2017, IEEE COMPUT SOC CONF, P1664, DOI 10.1109/CVPRW.2017.212; Wolchover N., 2017, QUANTA MAGAZINE; Xie JW, 2014, PROC CVPR IEEE, P1035, DOI 10.1109/CVPR.2014.136; Yosinski J, 2014, ADV NEUR IN, V27; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang Q., 2017, ARXIV170801783; Zhang QS, 2018, FRONT INFORM TECH EL, V19, P27, DOI 10.1631/FITEE.1700808; Zhang QS, 2019, PROC CVPR IEEE, P6254, DOI 10.1109/CVPR.2019.00642; Zhang QS, 2017, AAAI CONF ARTIF INTE, P2898; Zhang QS, 2018, AAAI CONF ARTIF INTE, P4454; Zhang QS, 2018, AAAI CONF ARTIF INTE, P4464; Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920; Zhang QS, 2017, PROC CVPR IEEE, P3890, DOI 10.1109/CVPR.2017.414; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2	51	10	10	15	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3416	3431		10.1109/TPAMI.2020.2982882	http://dx.doi.org/10.1109/TPAMI.2020.2982882			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32224452	hybrid, Green Submitted			2022-12-18	WOS:000692232400013
J	Bai, L; Liang, JY; Cao, FY				Bai, Liang; Liang, JiYe; Cao, Fuyuan			Semi-Supervised Clustering With Constraints of Different Types From Multiple Information Sources	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Matrix converters; Machine learning algorithms; Optimization; Benchmark testing; Task analysis; Measurement; Cluster analysis; semi-supervised clustering; multi-source constraints; consensus of constraints	CUTS	Semi-supervised clustering is one of important research topics in cluster analysis, which uses pre-given knowledge as constraints to improve the clustering performance. While clustering a data set, people often get prior constraints from different information sources, which may have different representations and contents, to guide clustering process. However, most of existing semi-supervised clustering algorithms are based on single-source constraints and rarely consider to integrate multi-source constraints to enhance the clustering quality. To solve the problem, we analyze the relations among different types of constraints and propose an uniform representation for them. Based it, we propose a new semi-supervised clustering algorithm to find out a clustering that has good cluster structure and high consensus of all the sources of constraints. In the algorithm, we construct an optimization objective model and its solution method to achieve the aim. This algorithm can integrate multi-source constraints well to reduce the effect of incorrect constraints from single sources and find out a high-quality clustering. By the experimental studies on several benchmark data sets, we illustrate the effectiveness of the proposed algorithm, compared to other semi-supervised clustering algorithms.	[Bai, Liang; Liang, JiYe; Cao, Fuyuan] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China	Shanxi University	Liang, JY (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.	bailiang@sxu.edu.cn; ljy@sxu.edu.cn; cfy@sxu.edu.cn		Bai, Liang/0000-0002-0380-2995	National Natural Science Foundation of China [61773247, 61876103, 61976128, 61902227]; Technology Research Development Projects of Shanxi [201901D211192]; 1331 Engineering Project of Shanxi Province, China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Technology Research Development Projects of Shanxi; 1331 Engineering Project of Shanxi Province, China	The authors are very grateful to the editors and reviewers for their valuable comments and suggestions. This work was supported by the National Natural Science Foundation of China (Nos. 61773247, 61876103, 61976128, 61902227), the Technology Research Development Projects of Shanxi (No. 201901D211192) and the 1331 Engineering Project of Shanxi Province, China.	Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1; Ahn I, 2016, IEEE T MULTIMEDIA, V18, P1414, DOI 10.1109/TMM.2016.2551698; Anand S, 2014, IEEE T PATTERN ANAL, V36, P1201, DOI 10.1109/TPAMI.2013.190; Bache K., 2019, UCI MACHINE LEARNING; Basu S., 2004, P 10 ACM SIGKDD INT P INT C KNOWL DISC D, P59; Basu S., 2002, P 19 INT C MACH LEAR P 19 INT C MACH LEAR, P27; Bilenko M., 2004, P 21 INT C MACH LEAR P INT C MACH LEARN, P81; Cai D., 2019, CODES DATASETS FEATU; Davidson I, 2005, SIAM PROC S, P138; Davis J., 2007, P 24 INT C MACH LEAR, P20; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Ding C., 2004, P 21 INT C MACH LEAR P INT C MACH LEARN, DOI DOI 10.1145/1015330.1015408; Han J, 2001, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5; Huang RZ, 2009, DATA KNOWL ENG, V68, P49, DOI 10.1016/j.datak.2008.08.008; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Law MT, 2017, PR MACH LEARN RES, V70; Lee DD, 2001, ADV NEUR IN, V13, P556; Li ZG, 2009, PROC CVPR IEEE, P421, DOI 10.1109/CVPRW.2009.5206852; Liu HF, 2010, AAAI CONF ARTIF INTE, P506; Liu HF, 2018, IEEE T PATTERN ANAL, V40, P2469, DOI 10.1109/TPAMI.2017.2763945; Lu ZW, 2013, INT J COMPUT VISION, V103, P306, DOI 10.1007/s11263-012-0602-z; Lu ZW, 2010, IEEE T MULTIMEDIA, V12, P194, DOI 10.1109/TMM.2010.2041100; Luo YC, 2018, ADV NEUR IN, V31; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Ng AY, 2002, ADV NEUR IN, V14, P849; Pelleg D, 2007, LECT NOTES ARTIF INT, V4701, P674; Press W.H., 2007, CONDITIONAL ENTROPY; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shental N, 2004, ADV NEUR IN, V16, P465; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Van Craenendonck T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2871; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wagstaff K., 2000, P 17 INT C MACH LEAR, P1097; Wang F., 2006, P 23 INT C MACH LEAR P INT C MACH LEARN, P985, DOI DOI 10.1145/1143844.1143968; Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9; Witten I.H., 2005, P DATA MINING LAS VE, P4; Wu L, 2012, IEEE T KNOWL DATA EN, V24, P478, DOI 10.1109/TKDE.2010.215; Xing E., 2003, ADV NEURAL INFORM PR, P505; Xiong SC, 2014, IEEE T KNOWL DATA EN, V26, P43, DOI 10.1109/TKDE.2013.22; Yang L, 2015, IEEE T CYBERNETICS, V45, P2585, DOI 10.1109/TCYB.2014.2377154; Yu ZW, 2017, IEEE T KNOWL DATA EN, V29, P1577, DOI [10.1109/TKDE.2017.2695615, 10.1109/TCYB.2016.2611020]; Zeng H, 2012, IEEE T KNOWL DATA EN, V24, P926, DOI 10.1109/TKDE.2011.68; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu X, 2009, MORGAN CLAYPOOL, DOI DOI 10.1007/978-3-031-01548-9; Zoidi O, 2018, IEEE T CIRC SYST VID, V28, P342, DOI 10.1109/TCSVT.2016.2598671	46	10	10	4	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3247	3258		10.1109/TPAMI.2020.2979699	http://dx.doi.org/10.1109/TPAMI.2020.2979699			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32167885				2022-12-18	WOS:000681124300029
J	Mustafa, A; Khan, SH; Hayat, M; Goecke, R; Shen, JB; Shao, L				Mustafa, Aamir; Khan, Salman H.; Hayat, Munawar; Goecke, Roland; Shen, Jianbing; Shao, Ling			Deeply Supervised Discriminative Learning for Adversarial Defense	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robustness; Perturbation methods; Training; Linear programming; Optimization; Marine vehicles; Prototypes; Adversarial defense; adversarial robustness; white-box attack; distance metric learning; deep supervision		Deep neural networks can easily be fooled by an adversary with minuscule perturbations added to an input image. The existing defense techniques suffer greatly under white-box attack settings, where an adversary has full knowledge of the network and can iterate several times to find strong perturbations. We observe that the main reason for the existence of such vulnerabilities is the close proximity of different class samples in the learned feature space of deep models. This allows the model decisions to be completely changed by adding an imperceptible perturbation to the inputs. To counter this, we propose to class-wise disentangle the intermediate feature representations of deep networks, specifically forcing the features for each class to lie inside a convex polytope that is maximally separated from the polytopes of other classes. In this manner, the network is forced to learn distinct and distant decision regions for each class. We observe that this simple constraint on the features greatly enhances the robustness of learned models, even against the strongest white-box attacks, without degrading the classification performance on clean images. We report extensive evaluations in both black-box and white-box attack scenarios and show significant gains in comparison to state-of-the-art defenses.	[Mustafa, Aamir] Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England; [Khan, Salman H.; Hayat, Munawar; Shen, Jianbing; Shao, Ling] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Goecke, Roland] Univ Canberra, Affect Comp, Bruce, ACT 2617, Australia; [Goecke, Roland] Univ Canberra, Human Ctr Technol Res Ctr, Bruce, ACT 2617, Australia; [Goecke, Roland] Univ Canberra, Vis & Sensing Grp, Bruce, ACT 2617, Australia	University of Cambridge; University of Canberra; University of Canberra; University of Canberra	Mustafa, A (corresponding author), Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.	aamirmustafa2@gmail.com; salman.khan@anu.edu.au; munawar.hayat@canberra.edu.au; roland.goecke@canberra.edu.au; shenjianbingcg@gmail.com; ling.shao@ieee.org	Khan, Salman Hameed/M-4834-2016; Goecke, Roland/F-7499-2013	Khan, Salman Hameed/0000-0002-9502-1749; Goecke, Roland/0000-0003-2279-7041; Hayat, Munawar/0000-0002-2706-5985				Ackerman E, 2017, IEEE SPECTRUM MAGAZI, V1; Athalye A, 2018, PR MACH LEARN RES, V80; Buckman J., 2018, ARXIVE PRINTS; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Cisse M, 2017, PR MACH LEARN RES, V70; Das Nilaksh, 2017, ARXIV PREPRINT ARXIV; de Berg M, 1998, THEOR COMPUT SYST, V31, P613, DOI 10.1007/PL00005845; Dhillon G. S., 2018, P INT C LEARN REPR P INT C LEARN REPR; Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957; Gilmer Justin, 2018, ARXIV180706732; Goodfellow I.J., 2015, STATISTICAL, DOI DOI 10.48550/ARXIV.1412.6572; Guo C., 2018, P INT C LEARN REPR; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Hayat M, 2017, PROC CVPR IEEE, P1551, DOI 10.1109/CVPR.2017.169; Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jakubovitz D, 2018, EUR C COMP VIS; Kabkab M., 2018, P ICLR; Kannan Harini, 2018, ARXIV180306373; Khan S, 2018, GUIDE CONVOLUTIONAL, V8, P1, DOI [DOI 10.2200/S00822ED1V01Y201712COV015, 10.2200/S00822ED1V01Y201712COV015]; Kurakin A., 2016, ABS160702533 CORR; Kurakin A, 2016, INT C LEARN REPR SAN; Kurakin A, 2018, SPRING SER CHALLENGE, P195, DOI 10.1007/978-3-319-94042-7_11; Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191; LIN J, 2019, P INT C LEARN REPR; Luo Y., 2015, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1511.06292, DOI 10.48550/ARXIV.1511.06292]; Madry A., 2018, P ICLR VANC BC CAN; Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83; Miyato T., 2016, P INT C LEARN REPR; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Mustafa A, 2019, IEEE I CONF COMP VIS, P3384, DOI 10.1109/ICCV.2019.00348; Mustafa A, 2020, IEEE T IMAGE PROCESS, V29, P1711, DOI 10.1109/TIP.2019.2940533; Na T., 2018, P INT C LEARN REPR P INT C LEARN REPR; Naseer M, 2019, ADV NEUR IN, V32; Pang TY, 2019, PR MACH LEARN RES, V97; Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41; Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36; Ros AS, 2018, AAAI CONF ARTIF INTE, P1660; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Song C., 2019, INT C LEARN REPR; Szegedy Christian, 2014, P 2 INT C LEARNING R; Tramer F., 2018, P INT C LEARN REPR; Tramer F., 2017, ARXIV170403453; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Xie C., 2018, P INT C LEARN REPR; Xie CH, 2019, PROC CVPR IEEE, P2725, DOI 10.1109/CVPR.2019.00284; Yu F., 2019, INTERPRETING ADVERSA	47	10	10	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3154	3166		10.1109/TPAMI.2020.2978474	http://dx.doi.org/10.1109/TPAMI.2020.2978474			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32149623	Green Submitted			2022-12-18	WOS:000681124300023
J	Zhang, R; Zhang, HY; Li, XL				Zhang, Rui; Zhang, Hongyuan; Li, Xuelong			Robust Multi-Task Learning With Flexible Manifold Constraint	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-task learning; robust loss; flexible manifold constraint; regression		Multi-Task Learning attempts to explore and mine the sufficient information within multiple related tasks for the better solutions. However, the performance of the existing multi-task approaches would largely degenerate when dealing with the polluted data, i.e., outliers. In this paper, we propose a novel robust multi-task model by incorporating a flexible manifold constraint (FMC-MTL) and a robust loss. Specifically speaking, multi-task subspace is embedded with a relaxed and generalized Stiefel Manifold for considering point-wise correlation and preserving the data structure simultaneously. In addition, a robust loss function is developed to ensure the robustness to outliers by smoothly interpolating between l(2,1)-norm and squared Frobenius norm. Equipped with an efficient algorithm, FMC-MTL serves as a robust solution to tackling the severely polluted data. Moreover, extensive experiments are conducted to verify the superiority of our model. Compared to the state-of-the-art multi-task models, the proposed FMC-MTL model demonstrates remarkable robustness to the contaminated data.	[Zhang, Rui; Zhang, Hongyuan; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Zhang, Rui; Zhang, Hongyuan; Li, Xuelong] Northwestern Polytech Univ, Ctr Opt IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University	Li, XL (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.	ruizhang8633@gmail.com; hyzhang98@gmail.com; xuelong_li@nwpu.edu.cn	Zhang, Rui/U-4639-2017	Zhang, Rui/0000-0001-9418-0863; Zhang, Hongyuan/0000-0003-4274-7332	National Key Research and Development Program of China [2018YFB1107400]; National Natural Science Foundation of China [61871470, 61761130079, U1801262]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by The National Key Research and Development Program of China (Grant No. 2018YFB1107400) and the National Natural Science Foundation of China (Grant Nos. 61871470, 61761130079, and U1801262).	Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A., 2006, ADV NEURAL INFORM PR, P41; Chapelle O., 2010, P 16 ACM SIGKDD INT, P1189, DOI [10.1145/1835804.1835953, DOI 10.1145/1835804.1835953]; Chen D, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE OF MANAGEMENT SCIENCE AND INFORMATION SYSTEM, VOLS 1-4, P1375; Chen J., 2011, PROC 17 ACM SIGKDD I, P42; Crammer Koby, 2012, PROC 25 INT C NEURAL, P1475; Ghosn J, 1997, ADV NEUR IN, V9, P946; Gong PH, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P761, DOI 10.1145/2623330.2623641; Gong Pinghua, 2012, KDD, V2012, P895; He XF, 2004, ADV NEUR IN, V16, P153; Jacob L, 2008, ARXIV PREPRINT ARXIV; Jalali A., 2010, ADV NEURAL INF PROCE, V23, P964; Ji S., 2009, P 26 ANN INT C MACH, P457, DOI DOI 10.1145/1553374.1553434; Lee S., 2010, PROC INT C NEURAL IN, P1306; Liu Wei, 2010, ICML; Nie F, 2013, P 23 INT JOINT C ART, P1565; Nie FP, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9021-9; Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958; Pan Y, 2015, IEEE T NEUR NET LEAR, V26, P3163, DOI 10.1109/TNNLS.2015.2406759; Parameswaran S., 2010, ADV NEURAL INFORM PR, V23, P1867; Pong TK, 2010, SIAM J OPTIMIZ, V20, P3465, DOI 10.1137/090763184; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x; Wang H, 2011, IEEE I CONF COMP VIS, P557, DOI 10.1109/ICCV.2011.6126288; Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814; Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479; Yu Z., 2012, CONVEX FORMULATION L; Zhang K, 2010, BIOINFORMATICS, V26, pi97, DOI 10.1093/bioinformatics/btq181; Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342; Zhang Yu, 2017, ARXIV170708114, DOI DOI 10.1109/TKDE.2021.3070203; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhou J., 2011, MALSAR MULTITASK LEA	34	10	10	4	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2150	2157		10.1109/TPAMI.2020.3007637	http://dx.doi.org/10.1109/TPAMI.2020.3007637			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	32750806				2022-12-18	WOS:000649590200025
J	Zhang, ZZ; Chen, PJ; Shi, XS; Yang, L				Zhang, Zizhao; Chen, Pingjun; Shi, Xiaoshuang; Yang, Lin			Text-Guided Neural Network Training for Image Recognition in Natural Scenes and Medicine	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Training; Semantics; Medical diagnostic imaging; Neural networks; Task analysis; Multimodal neural networks; text-guided network training; attention mechanisms; vision recognition; medical images		Convolutional neural networks (CNNs) are widely recognized as the foundation for machine vision systems. The conventional rule of teaching CNNs to understand images requires training images with human annotated labels, without any additional instructions. In this article, we look into a new scope and explore the guidance from text for neural network training. We present two versions of attention mechanisms to facilitate interactions between visual and semantic information and encourage CNNs to effectively distill visual features by leveraging semantic features. In contrast to dedicated text-image joint embedding methods, our method realizes asynchronous training and inference behavior: a trained model can classify images, irrespective of the text availability. This characteristic substantially improves the model scalability to multiple (multimodal) vision tasks. We also apply the proposed method onto medical imaging, which learns from richer clinical knowledge and achieves attention-based interpretable decision-making. With comprehensive validation on two natural and two medical datasets, we demonstrate that our method can effectively make use of semantic knowledge to improve CNN performance. Our method performs substantial improvement on medical image datasets. Meanwhile, it achieves promising performance for multi-label image classification and caption-image retrieval as well as excellent performance for phrase-based and multi-object localization on public benchmarks.	[Zhang, Zizhao] Google AI, Sunnyvale, CA 94089 USA; [Chen, Pingjun; Shi, Xiaoshuang; Yang, Lin] Univ Florida, Dept Biomed Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Zhang, ZZ (corresponding author), Google AI, Sunnyvale, CA 94089 USA.	mr.zizhaozhang@gmail.com; pingjunchen@ufl.edu; xsshi2015@ufl.edu; lin.yang@bme.ufl.edu	Chen, Pingjun/AAU-6822-2020	Chen, Pingjun/0000-0003-0528-1713				[Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900; Demner-Fushman Dina, 2012, Journal of Computing Science and Engineering, V6, P168, DOI 10.5626/JCSE.2012.6.2.168; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Eisenschtat A, 2017, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2017.201; Faghri F., 2017, BMVC; Frome Andrea, 2013, NEURIPS; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775; Hinton, 2016, ARXIV PREPRINT ARXIV; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228; Ioffe S., 2014, ICLR, P1; Jin XX, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901353; Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; Karen Simonyan, 2014, ARXIV13126034CS, DOI DOI 10.1038/S41591-018-0335-9; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Koh PW, 2017, PR MACH LEARN RES, V70; Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar D, 2017, IEEE COMPUT SOC CONF, P1686, DOI 10.1109/CVPRW.2017.215; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin Z., 2017, ARXIV PREPRINT ARXIV; Lu JS, 2016, ADV NEUR IN, V29; Luong M., 2015, ARXIV150804025; Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232; Pascanu R., 2013, P 30 INT C INT C MAC, P1310; Ren Zhou, 2016, PROC 24 ACM INT C MU, P207; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274; Stone A, 2017, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2017.85; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; Vaswani A, 2017, ADV NEUR IN, V30; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943; Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226; Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58; Xiao FY, 2017, PROC CVPR IEEE, P5253, DOI 10.1109/CVPR.2017.558; Xiong C, 2017, 5 INT C LEARN REPR I; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920; Zhang Z, 2017, MEDICAL IMAGE COMPUT, P320; Zhang ZZ, 2019, NAT MACH INTELL, V1, P236, DOI 10.1038/s42256-019-0052-1; Zhang ZZ, 2018, PROC CVPR IEEE, P9242, DOI 10.1109/CVPR.2018.00963; Zhang ZZ, 2017, PROC CVPR IEEE, P3549, DOI 10.1109/CVPR.2017.378; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou Bolei, 2015, ARXIV151202167; Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219	67	10	10	6	59	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1733	1745		10.1109/TPAMI.2019.2955476	http://dx.doi.org/10.1109/TPAMI.2019.2955476			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31765305				2022-12-18	WOS:000637533800018
J	Zhang, L; Shi, ZL; Zhou, JTY; Cheng, MM; Liu, Y; Bian, JW; Zeng, Z; Shen, CH				Zhang, Le; Shi, Zenglin; Zhou, Joey Tianyi; Cheng, Ming-Ming; Liu, Yun; Bian, Jia-Wang; Zeng, Zeng; Shen, Chunhua			Ordered or Orderless: A Revisit for Video Based Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Feature extraction; Task analysis; Visualization; Video sequences; Aggregates; Bridges; Deep learning; ensemble learning; video based person re-identification		Is recurrent network really necessary for learning a good visual representation for video based person re-identification (VPRe-id)? In this paper, we first show that the common practice of employing recurrent neural networks (RNNs) to aggregate temporal-spatial features may not be optimal. Specifically, with a diagnostic analysis, we show that the recurrent structure may not be effective learn temporal dependencies than what we expected and implicitly yields an orderless representation. Based on this observation, we then present a simple yet surprisingly powerful approach for VPRe-id, where we treat VPRe-id as an efficient orderless ensemble of image based person re-identification problem. More specifically, we divide videos into individual images and re-identify person with ensemble of image based rankers. Under the i.i.d. assumption, we provide an error bound that sheds light upon how could we improve VPRe-id. Our work also presents a promising way to bridge the gap between video and image based person re-identification. Comprehensive experimental evaluations demonstrate that the proposed solution achieves state-of-the-art performances on multiple widely used datasets (iLIDS-VID, PRID 2011, and MARS).	[Zhang, Le; Zeng, Zeng] ASTAR, Inst Infocomm Res, Singapore, Singapore; [Shi, Zenglin] Univ Amsterdam, NL-1012 WX Amsterdam, Netherlands; [Zhou, Joey Tianyi] ASTAR, Inst High Performance Comp, Singapore, Singapore; [Cheng, Ming-Ming; Liu, Yun] Nankai Univ, Coll Comp Sci, TKLNDST, Nankai 300071, Peoples R China; [Bian, Jia-Wang; Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); University of Amsterdam; Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); Nankai University; University of Adelaide	Zhou, JTY (corresponding author), ASTAR, Inst High Performance Comp, Singapore, Singapore.	lzhang027@e.ntu.edu.sg; zenglin.shi@luva.nl; joey.tianyi.zhou@gmail.com; cmm@nankai.edu.cn; nk12csly@mail.nankai.edu.cn; jiawang.bian@gmail.com; zengz@i2r.a-star.edu.sg; chunhua.shen@adelaide.edu.au	Bian, Jia-Wang/AAP-2274-2020; Cheng, Ming-Ming/A-2527-2009; Bian, Jia-Wang/AAH-4463-2019	Bian, Jia-Wang/0000-0003-2046-3363; Cheng, Ming-Ming/0000-0001-5550-8758; Bian, Jia-Wang/0000-0003-2046-3363; Liu, Yun/0000-0001-6143-0264; Zhou, Joey Tianyi/0000-0002-4675-7055; Shen, Chunhua/0000-0002-8648-8718				Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bian J., 2019, P NEURAL INFORM PROC, P35; Boin JB, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P147, DOI 10.1109/MIPR.2019.00033; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128; Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902; Chen L, 2017, IEEE COMPUT SOC CONF, P1478, DOI 10.1109/CVPRW.2017.191; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9; Jong K, 2004, LECT NOTES ARTIF INT, V3202, P267; Karanam Srikrishna, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P33, DOI 10.1109/CVPRW.2015.7301392; Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513; Khan FM, 2017, IEEE WINT CONF APPL, P605, DOI 10.1109/WACV.2017.73; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Y., 2015, P BRIT MACHINE VISIO; Li YJ, 2017, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW.2017.188; Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499; Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434; Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499; Liu Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P864; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148; Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; Pihur V, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-62; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; SERFLING RJ, 1974, ANN STAT, V2, P39, DOI 10.1214/aos/1176342611; Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241; Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564; Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Su X., ARXIV180705799; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; van den Hengel, 2016, ARXIV160601609; WANG L, 2016, P EUR C COMP VIS; Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45; Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507; Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42; Zhang JF, 2018, PROC CVPR IEEE, P6781, DOI 10.1109/CVPR.2018.00709; Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188; Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349; Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52; Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717; Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219	65	10	10	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1460	1466		10.1109/TPAMI.2020.2976969	http://dx.doi.org/10.1109/TPAMI.2020.2976969			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	32142419	Green Submitted			2022-12-18	WOS:000626525300026
J	Zhang, LF; Bao, CL; Ma, KS				Zhang, Linfeng; Bao, Chenglong; Ma, Kaisheng			Self-Distillation: Towards Efficient and Compact Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural networks; Knowledge engineering; Training; Computational modeling; Acceleration; Computer architecture; Image coding; Knowledge distillation; model acceleration; model compression; dynamic neural networks; multi-exit neural networks; attention; image classification		Remarkable achievements have been obtained by deep neural networks in the last several years. However, the breakthrough in neural networks accuracy is always accompanied by explosive growth of computation and parameters, which leads to a severe limitation of model deployment. In this paper, we propose a novel knowledge distillation technique named self-distillation to address this problem. Self-distillation attaches several attention modules and shallow classifiers at different depths of neural networks and distills knowledge from the deepest classifier to the shallower classifiers. Different from the conventional knowledge distillation methods where the knowledge of the teacher model is transferred to another student model, self-distillation can be considered as knowledge transfer in the same model - from the deeper layers to the shallow layers. Moreover, the additional classifiers in self-distillation allow the neural network to work in a dynamic manner, which leads to a much higher acceleration. Experiments demonstrate that self-distillation has consistent and significant effectiveness on various neural networks and datasets. On average, 3.49 and 2.32 percent accuracy boost are observed on CIFAR100 and ImageNet. Besides, experiments show that self-distillation can be combined with other model compression methods, including knowledge distillation, pruning and lightweight model design.	[Zhang, Linfeng; Ma, Kaisheng] Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China; [Bao, Chenglong] Tsinghua Univ, Yanqi Lake Beijing Inst Math Sci & Applicat, Yau Math Sci Ctr, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University	Ma, KS (corresponding author), Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China.; Bao, CL (corresponding author), Tsinghua Univ, Yanqi Lake Beijing Inst Math Sci & Applicat, Yau Math Sci Ctr, Beijing 100084, Peoples R China.	zhang-lf19@mails.tsinghua.edu.cn; clbao@mail.tsinghua.edu.cn; merrydoudou@gmail.com		Ma, Kaisheng/0000-0001-9226-3366	National Natural Sciences Foundation of China [31970972, 11901338]; Tsinghua University Initiative Scientific Research Program	National Natural Sciences Foundation of China(National Natural Science Foundation of China (NSFC)); Tsinghua University Initiative Scientific Research Program	This work was supported in part by the IIISCT (Institute for interdisciplinary Information Core Technology), National Natural Sciences Foundation of China under Grants 31970972 and 11901338), and Tsinghua University Initiative Scientific Research Program.	[Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Bagherinezhad H., 2018, ARXIV; Bucilua Cristian, 2006, P 12 ACM SIGKDD INT, P535, DOI [10.1145/1150402.1150464, DOI 10.1145/1150402.1150464]; Chen XS, 2020, PR MACH LEARN RES, V119; Cho JH, 2019, IEEE I CONF COMP VIS, P4793, DOI 10.1109/ICCV.2019.00489; Courbariaux M, 2015, ADV NEUR IN, V28; Cubuk Ekin D., 2018, ARXIV180509501; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denton E, 2014, ADV NEUR IN, V27; Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194; Ge SM, 2019, IEEE T IMAGE PROCESS, V28, P2051, DOI 10.1109/TIP.2018.2883743; Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309; Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104; Han S, 2015, ADV NEUR IN, V28; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48; Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201; Hinton G. E., 2014, P INT C NEUR INF PRO, P1; Howard A.G., 2017, MOBILENETS EFFICIENT; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang Gao, 2018, ICLR; Iandola Forrest N., 2016, SQUEEZENET ALEXNET L; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Jang Y, 2019, PR MACH LEARN RES, V97; Jin X, 2019, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2019.00143; Kang M, 2020, AAAI CONF ARTIF INTE, V34, P4404; Kaya Y, 2019, PR MACH LEARN RES, V97; Ke ZH, 2019, IEEE I CONF COMP VIS, P6727, DOI 10.1109/ICCV.2019.00683; Keskar N.S., 2017, ICLR; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Yann, 1990, P ADV NEUR INF PROC, P598; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lee K, 2019, IEEE I CONF COMP VIS, P312, DOI 10.1109/ICCV.2019.00040; [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1; Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936; Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Liu P., 2020, 2020 INT JOINT C NEU, P1, DOI 10.1016/j.solener.2019.02.027; Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271; Liu Yu, 2020, P IEEE CVF C COMP VI, P7539; Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]; Liu Z, 2019, PATTERN ANAL APPL, V22, P1527, DOI 10.1007/s10044-019-00792-5; Lopez-Paz D., 2016, P INT C LEARN REPR, P1; Louizos Christos, 2018, INT C LEARN REPR; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191; Nagel M, 2019, IEEE I CONF COMP VIS, P1325, DOI 10.1109/ICCV.2019.00141; Park Jongchan, 2018, ARXIV180706514; Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409; Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Romero Adriana, 2015, ICLR; Ronneberger O., 2015, P INT C MED IMAG COM, P234, DOI [DOI 10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Stork D.G., 1993, ADV NEURAL INF PROCE, P164; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145; Vapnik V, 2015, J MACH LEARN RES, V16, P2023; Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Wu ZX, 2018, PROC CVPR IEEE, P8817, DOI 10.1109/CVPR.2018.00919; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yang TY, 2019, IEEE WIREL COMMUNN; Ye SK, 2019, IEEE I CONF COMP VIS, P111, DOI 10.1109/ICCV.2019.00020; Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754; Yu, 2019, ICLR, P1; Yu JH, 2019, IEEE I CONF COMP VIS, P1803, DOI 10.1109/ICCV.2019.00189; Yu LQ, 2017, AAAI CONF ARTIF INTE, P66; Zagoruyko S, 2016, P BRIT MACH VIS C BM, DOI [10.5244/C.30.87, DOI 10.5244/C.30.87]; Zagoruyko S., 2017, P INT C LEARN REPR, DOI DOI 10.1109/CVPR.2019.00271; Zhang Hang, 2022, 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P2735, DOI 10.1109/CVPRW56347.2022.00309; Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381; Zhang LF, 2019, ADV NEUR IN, V32; Zhang TY, 2018, LECT NOTES COMPUT SC, V11212, P191, DOI 10.1007/978-3-030-01237-3_12; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhou A, 2017, INCREMENTAL NETWORK	88	10	10	20	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 18	2021	44	8					4388	4403		10.1109/TPAMI.2021.3067100	http://dx.doi.org/10.1109/TPAMI.2021.3067100			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HU	33735074	hybrid			2022-12-18	WOS:000820522400001
J	Li, JY				Li, Jiayuan			A Practical O(N-2) Outlier Removal Method for Correspondence-Based Point Cloud Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point cloud registration; outlier removal; correspondence matrix; robust estimation; O(N-2) running time	OBJECT RECOGNITION; ROBUST; SURFACE; IMAGES; STATISTICS; HISTOGRAMS; MLESAC; GRAPH	Point cloud registration (PCR) is an important and fundamental problem in 3D computer vision, whose goal is to seek an optimal rigid model to register a point cloud pair. Correspondence-based PCR techniques do not require initial guesses and gain more attentions. However, 3D keypoint techniques are much more difficult than their 2D counterparts, which results in extremely high outlier rates. Current robust techniques suffer from very high computational cost. In this paper, we propose a polynomial time (O(N-2), where N is the number of correspondences.) outlier removal method. Its basic idea is to reduce the input set into a smaller one with a lower outlier rate based on bound principle. To seek tight lower and upper bounds, we originally define two concepts, i.e., correspondence matrix (CM) and augmented correspondence matrix (ACM). We propose a cost function to minimize the determinant of CM or ACM, where the cost of CM rises to a tight lower bound and the cost of ACM leads to a tight upper bound. Then, we propose a scale-adaptive Cauchy estimator (SA-Cauchy) for further optimization. Extensive experiments on simulated and real PCR datasets demonstrate that the proposed method is robust at outlier rates above 99 percent and 1 similar to 2 orders faster than its competitors. The source code will be made publicly available in https://ljy-rs.github.io/web/	[Li, Jiayuan] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China	Wuhan University	Li, JY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.	ljy_whu_2012@whu.edu.cn	li, jia/GVT-7587-2022	Li, Jiayuan/0000-0002-9850-1668	National Natural Science Foundation of China (NSFC) [41901398]; State Key Program of the National Natural Science Foundation of China [42030102]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); State Key Program of the National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The author would like to thank the reviewers for their constructive comments and Dr. Qingwu Hu for his suggestions in revisions. This work was supported by the National Natural Science Foundation of China (NSFC) under Grant 41901398 and State Key Program of the National Natural Science Foundation of China (No. 42030102).	Barath D, 2020, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR42600.2020.00138; Barath D, 2018, PROC CVPR IEEE, P6733, DOI 10.1109/CVPR.2018.00704; Bazin Jean-Charles, 2012, P AS C COMP VIS, P2; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Bustos AP, 2018, IEEE T PATTERN ANAL, V40, P2868, DOI 10.1109/TPAMI.2017.2773482; Bustos AP, 2016, IEEE T PATTERN ANAL, V38, P2227, DOI 10.1109/TPAMI.2016.2517636; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Enqvist O, 2015, INT J COMPUT VISION, V112, P115, DOI 10.1007/s11263-014-0760-2; Enqvist O, 2012, LECT NOTES COMPUT SC, V7572, P738, DOI 10.1007/978-3-642-33718-5_53; Enqvist O, 2009, IEEE I CONF COMP VIS, P1295, DOI 10.1109/ICCV.2009.5459319; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569; Golyanik V, 2019, IEEE I CONF COMP VIS, P2080, DOI 10.1109/ICCV.2019.00217; Golyanik V, 2016, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR.2016.625; Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y; Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Horst R., 2003, GLOBAL OPTIMIZATION; Jauer P, 2019, IEEE T PATTERN ANAL, V41, P1102, DOI 10.1109/TPAMI.2018.2831670; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Li JX, 2019, IEEE I CONF COMP VIS, P361, DOI 10.1109/ICCV.2019.00045; Li JY, 2020, IEEE T GEOSCI REMOTE, V58, P5908, DOI 10.1109/TGRS.2020.2972982; Li JY, 2020, ISPRS J PHOTOGRAMM, V160, P244, DOI 10.1016/j.isprsjprs.2019.12.008; Li JY, 2017, PHOTOGRAMM REC, V32, P317, DOI 10.1111/phor.12201; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Olsson C, 2008, PROC CVPR IEEE, P3230; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257; Rusu RB, 2009, IEEE INT CONF ROBOT, P1848; Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011; Suwajanakorn S, 2018, ADV NEUR IN, V31; Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4; Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Yang H., 2020, ARXIV200503190; Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695; Yang H, 2019, ROBOTICS: SCIENCE AND SYSTEMS XV; Yang H, 2020, IEEE ROBOT AUTOM LET, V5, P1127, DOI 10.1109/LRA.2020.2965893; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637; Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748; Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29; Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47	53	10	10	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 9	2021	44	8					3926	3939		10.1109/TPAMI.2021.3065021	http://dx.doi.org/10.1109/TPAMI.2021.3065021			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HO	33687838				2022-12-18	WOS:000820521800001
J	Nascimento, JC; Carneiro, G				Nascimento, Jacinto C.; Carneiro, Gustavo			One Shot Segmentation: Unifying Rigid Detection and Non-Rigid Segmentation Using Elastic Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Training; Complexity theory; Visualization; Solid modeling; Object segmentation; Deep learning; Deep learning; data augmentation; manifold learning; object segmentation	DEEP LEARNING ARCHITECTURES; SALIENT OBJECT DETECTION; LEVEL SET METHODS; LEFT-VENTRICLE; DRIVEN SEGMENTATION; TIME SEGMENTATION; ULTRASOUND IMAGES; SHAPE; TRACKING; ATLAS	This paper proposes a novel approach for the non-rigid segmentation of deformable objects in image sequences, which is based on one-shot segmentation that unifies rigid detection and non-rigid segmentation using elastic regularization. The domain of application is the segmentation of a visual object that temporally undergoes a rigid transformation (e.g., affine transformation) and a non-rigid transformation (i.e., contour deformation). The majority of segmentation approaches to solve this problem are generally based on two steps that run in sequence: a rigid detection, followed by a non-rigid segmentation. In this paper, we propose a new approach, where both the rigid and non-rigid segmentation are performed in a single shot using a sparse low-dimensional manifold that represents the visual object deformations. Given the multi-modality of these deformations, the manifold partitions the training data into several patches, where each patch provides a segmentation proposal during the inference process. These multiple segmentation proposals are merged using the classification results produced by deep belief networks (DBN) that compute the confidence on each segmentation proposal. Thus, an ensemble of DBN classifiers is used for estimating the final segmentation. Compared to current methods proposed in the field, our proposed approach is advantageous in four aspects: (i) it is a unified framework to produce rigid and non-rigid segmentations; (ii) it uses an ensemble classification process, which can help the segmentation robustness; (iii) it provides a significant reduction in terms of the number of dimensions of the rigid and non-rigid segmentations search spaces, compared to current approaches that divide these two problems; and (iv) this lower dimensionality of the search space can also reduce the need for large annotated training sets to be used for estimating the DBN models. Experiments on the problem of left ventricle endocardial segmentation from ultrasound images, and lip segmentation from frontal facial images using the extended Cohn-Kanade (CK+) database, demonstrate the potential of the methodology through qualitative and quantitative evaluations, and the ability to reduce the search and training complexities without a significant impact on the segmentation accuracy.	[Nascimento, Jacinto C.] Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal; [Carneiro, Gustavo] Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia	Universidade de Lisboa; Instituto Superior Tecnico; University of Adelaide	Nascimento, JC (corresponding author), Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal.	jan@isr.ist.utl.pt; gustavo.carneiro@adelaide.edu.au	Nascimento, Jacinto/B-6128-2009	Nascimento, Jacinto/0000-0001-7468-5127; Carneiro, Gustavo/0000-0002-5571-6220	FCT [UID/EEA/50009/2019]; Australian Research Council [DP180103 232, CE140100016]	FCT(Portuguese Foundation for Science and TechnologyEuropean Commission); Australian Research Council(Australian Research Council)	This work was supported by the FCT [UID/EEA/50009/2019] and by Australian Research Council grants (DP180103 232 and CE140100016).	Absil PA, 2004, ACTA APPL MATH, V80, P199, DOI 10.1023/B:ACAP.0000013855.14971.91; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andreopoulos A, 2008, MED IMAGE ANAL, V12, P335, DOI 10.1016/j.media.2007.12.003; Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44; Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Boyd S, 2004, CONVEX OPTIMIZATION; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cabezas M, 2011, COMPUT METH PROG BIO, V104, pE158, DOI 10.1016/j.cmpb.2011.07.015; Carneiro G, 2008, IEEE T MED IMAGING, V27, P1342, DOI 10.1109/TMI.2008.928917; Carneiro G, 2013, IEEE T PATTERN ANAL, V35, P2592, DOI 10.1109/TPAMI.2013.96; Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273; Carneiro G, 2010, I S BIOMED IMAGING, P1085, DOI 10.1109/ISBI.2010.5490181; Carneiro G, 2010, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2010.5540013; Chen T, 2000, LECT NOTES COMPUT SC, V1935, P256; Chen T, 2008, IEEE T MED IMAGING, V27, P1084, DOI 10.1109/TMI.2008.918327; Cobzas D, 2009, PROC CVPR IEEE, P328, DOI 10.1109/CVPRW.2009.5206812; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 1999, LECT NOTES COMPUT SC, V1613, P322; Corsi C, 2002, IEEE T MED IMAGING, V21, P1202, DOI 10.1109/TMI.2002.804418; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Davis MH, 1997, IEEE T MED IMAGING, V16, P317, DOI 10.1109/42.585766; Debreuve E, 2001, IEEE T MED IMAGING, V20, P643, DOI 10.1109/42.932748; Dhungel N, 2015, LECT NOTES COMPUT SC, V9349, P605, DOI 10.1007/978-3-319-24553-9_74; Donato G, 2002, LECT NOTES COMPUT SC, V2352, P21; Duan Q, 2010, COMPUT METH PROG BIO, V98, P223, DOI 10.1016/j.cmpb.2009.09.001; Duc AKH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070059; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Georgescu B, 2005, PROC CVPR IEEE, P429; Girshick R., 2013, ARXIV; Girshick R. B., 2015, CORR, Vabs/1504.08083; Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang R., 2004, P IEEE COMP SOC C CO, pII; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jacob G, 2002, IEEE T MED IMAGING, V21, P226, DOI 10.1109/42.996341; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kato Z, 2011, FOUND TRENDS SIGNAL, V5, P1, DOI 10.1561/2000000035; Kikinis R, 1996, IEEE T VIS COMPUT GR, V2, P232, DOI 10.1109/2945.537306; Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kotropoulos C, 2003, PATTERN RECOGN LETT, V24, P715, DOI 10.1016/S0167-8655(02)00177-0; Kumar S., 2003, NIPS, V16, P1531; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lee CH, 2005, LECT NOTES COMPUT SC, V3765, P469; Lim J, 2005, PROC CVPR IEEE, P1196; Lin N, 2003, MED IMAGE ANAL, V7, P529, DOI 10.1016/S1361-8415(03)00035-5; Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434; Lon J., 2015, P IEEE C COMP VIS PA; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Lynch M, 2008, IEEE T MED IMAGING, V27, P195, DOI 10.1109/TMI.2007.904681; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mignotte M, 2001, PATTERN ANAL APPL, V4, P256, DOI 10.1007/PL00010988; Nascimento JC, 2008, IEEE T IMAGE PROCESS, V17, P392, DOI 10.1109/TIP.2007.915552; Nascimento JC, 2017, IEEE T IMAGE PROCESS, V26, P4978, DOI 10.1109/TIP.2017.2725582; Nascimento JC, 2014, PROC CVPR IEEE, P288, DOI 10.1109/CVPR.2014.44; Nascimento JC, 2013, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2013.256; Nascimento JC, 2010, LECT NOTES COMPUT SC, V6313, P172; Noble JA, 2011, INTERFACE FOCUS, V1, P673, DOI 10.1098/rsfs.2011.0025; Oakden-Rayner L, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01931-w; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Poggio Tomaso, 2003, NOTICES AM MATH SOC, V50, P537; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rohlfing T, 2004, NEUROIMAGE, V21, P1428, DOI 10.1016/j.neuroimage.2003.11.010; Rohlfing T, 2005, TOP BIOMED ENGN, P435; Sarti A, 2005, IEEE T ULTRASON FERR, V52, P947, DOI 10.1109/TUFFC.2005.1504017; Schaffer K, 2004, HUMAN RIGHTS AND NARRATED LIVES: THE ETHICS OF RECOGNITION, P13; Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0; Sutton C, 2006, INTRO CONDITIONAL RA; Tsechpenakis G, 2007, PROC CVPR IEEE, P2016; Ngo TA, 2014, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2014.399; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354; Wolz R, 2010, NEUROIMAGE, V49, P1316, DOI 10.1016/j.neuroimage.2009.09.069; Wu MJ, 2007, NEUROIMAGE, V34, P1612, DOI 10.1016/j.neuroimage.2006.07.050; Yang L, 2008, I S BIOMED IMAGING, P221, DOI 10.1109/ISBI.2008.4540972; Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022; Yu ZW, 2011, IMAGE VISION COMPUT, V29, P29, DOI 10.1016/j.imavis.2010.08.003; Zagrodsky V, 2005, IEEE T MED IMAGING, V24, P1089, DOI 10.1109/TMI.2005.852057; Zandifar A, 2004, IEEE IMAGE PROC, P1683; Zheng YF, 2008, IEEE T MED IMAGING, V27, P1668, DOI 10.1109/TMI.2008.2004421; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115, DOI 10.1109/TPAMI.2005.3	95	10	11	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					3054	3070		10.1109/TPAMI.2019.2922959	http://dx.doi.org/10.1109/TPAMI.2019.2922959			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31217094				2022-12-18	WOS:000587912800007
J	Yang, YM; Wu, QMJ; Feng, XX; Akilan, T				Yang, Yimin; Wu, Q. M. Jonathan; Feng, Xiexing; Akilan, Thangarajah			Recomputation of the Dense Layers for Performance Improvement of DCNN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Mathematical model; Optimization; Neurons; Convolutional neural networks; Deep learning; Deep convolutional neural networks; non-iterative learning; image object recognition; deep learning	EXTREME LEARNING-MACHINE; SCENE; RECOGNITION; NETWORK; MODEL	Gradient descent optimization of learning has become a paradigm for training deep convolutional neural networks (DCNN). However, utilizing other learning strategies in the training process of the DCNN has rarely been explored by the deep learning (DL) community. This serves as the motivation to introduce a non-iterative learning strategy to retrain neurons at the top dense or fully connected (FC) layers of DCNN, resulting in, higher performance. The proposed method exploits the Moore-Penrose Inverse to pull back the current residual error to each FC layer, generating well-generalized features. Further, the weights of each FC layers are recomputed according to the Moore-Penrose Inverse. We evaluate the proposed approach on six most widely accepted object recognition benchmark datasets: Scene-15, CIFAR-10, CIFAR-100, SUN-397, Places365, and ImageNet. The experimental results show that the proposed method obtains improvements over 30 state-of-the-art methods. Interestingly, it also indicates that any DCNN with the proposed method can provide better performance than the same network with its original Backpropagation (BP)-based training.	[Yang, Yimin] Lakehead Univ, Comp Sci Dept, Thunder Bay, ON P7B 5E1, Canada; [Wu, Q. M. Jonathan; Feng, Xiexing; Akilan, Thangarajah] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada	Lakehead University; University of Windsor	Yang, YM (corresponding author), Lakehead Univ, Comp Sci Dept, Thunder Bay, ON P7B 5E1, Canada.	yyang48@lakeheadu.ca; jwu@uwindsor.ca; xiexing.feng@uwindsor.ca; thangara@uwindsor.ca	Yang, Yimin/A-3060-2019	Yang, Yimin/0000-0002-1131-2056; Wu, Q.M. Jonathan/0000-0002-5208-7975	Natural Sciences and Engineering Research Council of Canada	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	This work was supported by the Natural Sciences and Engineering Research Council of Canada.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Boureau Y.-L., 2010, ICML, P111, DOI DOI 10.5555/3104322.3104338; BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963; Carreira-Perpinan MA, 2014, JMLR WORKSH CONF PRO, V33, P10; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen M., 2015, J MACH LEARN RES, V22, P191; Choromanska A., 2018, ARXIV180609077 CORR; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Gens R., 2012, 26 ADV NEURAL INFORM, P3239; Goh H, 2014, IEEE T NEUR NET LEAR, V25, P2212, DOI 10.1109/TNNLS.2014.2307532; Han YN, 2014, IEEE T CYBERNETICS, V44, P137, DOI 10.1109/TCYB.2013.2248710; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang G.-B., 2004, 2004 INT JOINT C NEU; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lam D, 2017, IEEE T CYBERNETICS, V47, P224, DOI 10.1109/TCYB.2015.2511149; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee C., 2014, ARXIV14095185 CORR; Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003; SCHMIDT WF, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P1, DOI 10.1109/ICPR.1992.201708; SCHRAUDOLPH NN, 1993, ADV NEURAL INFORMATI, V5, P499; Springenberg J.T., 2014, ARXIV14126806; Stollenga M.F., 2014, ADV NEURAL INFORM PR, P3545; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Weng J., 1992, INT JOINT C NEUR NET, P576, DOI DOI 10.1109/IJCNN.1992.287150; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123; Yang YM, 2016, IEEE T CYBERNETICS, V46, P2570, DOI 10.1109/TCYB.2015.2481713; Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006; Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471; Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894; Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P365, DOI 10.1109/TNNLS.2011.2178124; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881	51	10	10	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2912	2925		10.1109/TPAMI.2019.2917685	http://dx.doi.org/10.1109/TPAMI.2019.2917685			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31107643				2022-12-18	WOS:000575381000013
J	Iglesias, F; Zseby, T; Zimek, A				Iglesias, Felix; Zseby, Tanja; Zimek, Arthur			Absolute Cluster Validity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Indexes; Benchmark testing; Task analysis; Proposals; Autonomous systems; Clustering; cluster validity	DENSITY-FUNCTION; INDEX; CONSISTENCY; VALIDATION; ALGORITHMS; SYSTEM	The application of clustering involves the interpretation of objects placed in multi-dimensional spaces. The task of clustering itself is inherently submitted to subjectivity, the optimal solution can be extremely costly to discover and sometimes even unreachable or nonexistent. This fact introduces a trade-off between accuracy and computational effort, moreover given that engineering applications usually work well with suboptimal solutions. In such applied scenarios, cluster validation is mandatory to refine algorithms and ensure that solutions are meaningful. Validity indices are commonly intended to benchmark diverse clustering setups, therefore they are coefficients with a relative nature, i.e., useful when compared to one another. In this paper, we propose a validation methodology that enables absolute evaluations of clustering results. Our method performs geometric measurements of the solution space and provides a coherent interpretation of the data structure by using indices based on inter- and intra-cluster distances, density, and multimodality within clusters. Conducted tests and comparisons with well-known indices show that our validation methodology improves the robustness of the clustering application for knowledge discovery. While clustering is often performed as a black box technique, our index is construable and therefore allows for the implementation of systems enriched with self-checking capabilities.	[Iglesias, Felix; Zseby, Tanja] Tech Univ Wien, Inst Telecommun, A-1040 Vienna, Austria; [Zimek, Arthur] Univ Southern Denmark SDU, Dept Math & Comp Sci IMADA, DK-5230 Odense, Denmark	Technische Universitat Wien; University of Southern Denmark	Iglesias, F (corresponding author), Tech Univ Wien, Inst Telecommun, A-1040 Vienna, Austria.	felix.iglesias@nt.tuwien.ac.at; tanja.zseby@tuwien.ac.at; zimek@imada.sdu.dk		Zimek, Arthur/0000-0001-7713-4208	Vienna Science and Technology Fund (WWTF) [ICT15129]	Vienna Science and Technology Fund (WWTF)	This research has been partially funded by the Vienna Science and Technology Fund (WWTF) through project ICT15129, "BigDAMA".	[Anonymous], **DATA OBJECT**; Arbelaitz O, 2013, PATTERN RECOGN, V46, P243, DOI 10.1016/j.patcog.2012.07.021; Bailey J, 2014, CH CRC DATA MIN KNOW, P535; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Campello RJGB, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2733381; Charytanowicz M, 2010, ADV INTEL SOFT COMPU, V69, P15; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; Doborjeh MG, 2018, EVOL SYST-GER, V9, P195, DOI 10.1007/s12530-017-9178-8; EAGLEN RH, 1985, AM J PHYS ANTHROPOL, V66, P307, DOI 10.1002/ajpa.1330660308; Farber I., 2010, P MULTICLUST 1 INT W; Francois D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037; Franti P., 2018, K MEANS PROPERTIES S; Franti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227; Franti P, 2014, PATTERN RECOGN, V47, P3034, DOI 10.1016/j.patcog.2014.03.017; GARDNER MJ, 1986, BMJ-BRIT MED J, V292, P746, DOI 10.1136/bmj.292.6522.746; Gu G., 2008, P SEC S SAN JOS CA U, P139; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hamerly G, 2004, ADV NEUR IN, V16, P281; Houle ME, 2015, IEEE T PATTERN ANAL, V37, P136, DOI 10.1109/TPAMI.2014.2343223; Houle ME, 2010, LECT NOTES COMPUT SC, V6187, P482, DOI 10.1007/978-3-642-13818-8_34; Iglesias F., 2011, P IEEE INT S IND EL, P1321; Iglesias F, 2014, IEEE T IND INFORM, V10, P697, DOI 10.1109/TII.2013.2275032; Jain A. K., 1988, ALGORITHM CLUSTERING; Jaskowiak PA, 2016, KNOWL INF SYST, V47, P329, DOI 10.1007/s10115-015-0851-6; JOE H, 1989, J AM STAT ASSOC, V84, P157, DOI 10.2307/2289859; Kalogeratos Argyris, 2012, ADV NEURAL INFORM PR, V25, P2393; Kriegel H., 2011, P 2 MULTICLUST WORKS, P55; Kriegel HP, 2011, WIRES DATA MIN KNOWL, V1, P231, DOI 10.1002/widm.30; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Martinez AM, 2001, IEEE T SYST MAN CY B, V31, P669, DOI 10.1109/3477.956029; Masulli F, 1999, ARTIF INTELL MED, V16, P129, DOI 10.1016/S0933-3657(98)00069-4; Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856; MILLIGAN GW, 1981, PSYCHOMETRIKA, V46, P187, DOI 10.1007/BF02293899; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; MOORE DS, 1977, ANN STAT, V5, P143, DOI 10.1214/aos/1176343747; Moulavi D., 2014, P SIAM INT C DAT MIN, P839; Pakhira MK, 2004, PATTERN RECOGN, V37, P487, DOI 10.1016/j.patcog.2003.06.005; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Raykar VC, 2010, J COMPUT GRAPH STAT, V19, P205, DOI 10.1198/jcgs.2010.09046; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Roweis S, 1998, ADV NEUR IN, V10, P626; SAW JG, 1984, AM STAT, V38, P130, DOI 10.2307/2683249; Selver MA, 2011, ROBOT CIM-INT MANUF, V27, P164, DOI 10.1016/j.rcim.2010.07.004; Silverman B. W., 1986, DENSITY ESTIMATION S; SILVERMAN BW, 1981, J ROY STAT SOC B MET, V43, P97; Thirey B., 2015, SAO NASA ADS ARXIV E, P1; TUWienCNGroup, 2016, DAT AN ALG GOI IND A; Vendramin Lucas, 2010, Statistical Analysis and Data Mining, V3, P209, DOI 10.1002/sam.10080; Von Luxburg U, 2012, J MACHINE LEARN RES, V27, P65; Wang WN, 2007, FUZZY SET SYST, V158, P2095, DOI 10.1016/j.fss.2007.03.004; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; Yang Z, 2014, ENERG BUILDINGS, V78, P113, DOI 10.1016/j.enbuild.2014.04.002; Zalik KR, 2011, PATTERN RECOGN LETT, V32, P221, DOI 10.1016/j.patrec.2010.08.007; Zimek Arthur, 2012, Statistical Analysis and Data Mining, V5, P363, DOI 10.1002/sam.11161; Zimek A, 2015, MACH LEARN, V98, P121, DOI 10.1007/s10994-013-5334-y	57	10	10	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2096	2112		10.1109/TPAMI.2019.2912970	http://dx.doi.org/10.1109/TPAMI.2019.2912970			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	31027043				2022-12-18	WOS:000557354900003
J	Averbuch-Elor, H; Bar, N; Cohen-Or, D				Averbuch-Elor, Hadar; Bar, Nadav; Cohen-Or, Daniel			Border-Peeling Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Clustering methods; Optics; Kernel; Data analysis; Manuals; Bandwidth; Clustering; non-parametric techniques		In this paper, we present a novel non-parametric clustering technique. Our technique is based on the notion that each latent cluster is comprised of layers that surround its core, where the external layers, or border points, implicitly separate the clusters. Unlike previous techniques, such as DBSCAN, where the cores of the clusters are defined directly by their densities, here the latent cores are revealed by a progressive peeling of the border points. Analyzing the density of the local neighborhoods allows identifying the border points and associating them with points of inner layers. We show that the peeling process adapts to the local densities and characteristics to successfully separate adjacent clusters (of possibly different densities). We extensively tested our technique on large sets of labeled data, including high-dimensional datasets of deep features that were trained by a convolutional neural network. We show that our technique is competitive to other state-of-the-art non-parametric methods using a fixed set of parameters throughout the experiments.	[Averbuch-Elor, Hadar; Bar, Nadav; Cohen-Or, Daniel] Tel Aviv Univ, IL-69978 Tel Aviv, Israel	Tel Aviv University	Averbuch-Elor, H (corresponding author), Tel Aviv Univ, IL-69978 Tel Aviv, Israel.	averbuch1@mail.tau.ac.il; nadavbar@mail.tau.ac.il; cohenor@gmail.com	Averbuch-Elor, Hadar/AAO-4246-2021					Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14; Carreira-Perpinan M. A., 2015, CRC HDB CLUSTER ANAL, P1; Cheng D., 2018, INT J MACH LEARN CYB, V10, P1; Cheng D, 2018, P INT COMP SOFTW APP, V1, P410, DOI [10.1109/COMPSAC.2018.00063, DOI 10.1109/COMPSAC.2018.00063]; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Ertoz L, 2003, SIAM PROC S, P47; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Fanti C, 2004, ADV NEUR IN, V16, P1603; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Fu LM, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-3; Gionis A., 2007, ACM T KNOWL DISCOV D, V1, DOI DOI 10.1145/1217299.1217303; Huang JL, 2017, MACH LEARN, V106, P337, DOI 10.1007/s10994-016-5608-2; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Karami A., 2014, INT J COMPUT APPL, V91, P1, DOI DOI 10.5120/15890-5059; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Korn F, 2000, SIGMOD REC, V29, P201, DOI 10.1145/335191.335415; LeCun Y., 2010, MNIST HANDWRITTEN DI; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Maier M, 2007, LECT NOTES ARTIF INT, V4754, P196; Ng AY, 2002, ADV NEUR IN, V14, P849; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Sawant K., 2014, INT J INNOVATIVE SCI, V1, P329; Shah SA, 2017, P NATL ACAD SCI USA, V114, P9814, DOI 10.1073/pnas.1700770114; Shimshoni I., 2006, NEAREST NEIGHBOR MET, P203; van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Veenman CJ, 2002, IEEE T PATTERN ANAL, V24, P1273, DOI 10.1109/TPAMI.2002.1033218; Vinh NX, 2010, J MACH LEARN RES, V11, P2837; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Xia CY, 2006, IEEE T KNOWL DATA EN, V18, P289, DOI 10.1109/TKDE.2006.38	33	10	11	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1791	1797		10.1109/TPAMI.2019.2924953	http://dx.doi.org/10.1109/TPAMI.2019.2924953			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	31251176	Green Submitted			2022-12-18	WOS:000542967200021
J	Paliwal, A; Kalantari, NK				Paliwal, Avinash; Kalantari, Nima Khademi			Deep Slow Motion Video Reconstruction With Hybrid Imaging System	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational photography; video frame interpolation; slow motion; deep learning; hybrid imaging	OPTICAL-FLOW ESTIMATION; CAMERA	Slow motion videos are becoming increasingly popular, but capturing high-resolution videos at extremely high frame rates requires professional high-speed cameras. To mitigate this problem, current techniques increase the frame rate of standard videos through frame interpolation by assuming linear object motion which is not valid in challenging cases. In this paper, we address this problem using two video streams as input; an auxiliary video with high frame rate and low spatial resolution, providing temporal information, in addition to the standard main video with low frame rate and high spatial resolution. We propose a two-stage deep learning system consisting of alignment and appearance estimation that reconstructs high resolution slow motion video from the hybrid video input. For alignment, we propose to compute flows between the missing frame and two existing frames of the main video by utilizing the content of the auxiliary video frames. For appearance estimation, we propose to combine the warped and auxiliary frames using a context and occlusion aware network. We train our model on synthetically generated hybrid videos and show high-quality results on a variety of test scenes. To demonstrate practicality, we show the performance of our system on two real dual camera setups with small baseline.	[Paliwal, Avinash; Kalantari, Nima Khademi] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA	Texas A&M University System; Texas A&M University College Station	Paliwal, A (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	avinashpaliwal@tamu.edu; nimak@tamu.edu		Paliwal, Avinash/0000-0002-9090-6142; Khademi Kalantari, Nima/0000-0002-2588-9219	TAMU T3 grant [246451]	TAMU T3 grant	The authors would like to thank the reviewers for their comments and suggestions. They would also like to thank Luke M. Schmidt for providing insight into designing the digital camera rig, and Deepankar Chanda for help with collection of videos. The JUGGLER and HORSE scenes are from YouTube channels Curtis Lahr and Sony India, respectively. This work was supported in part by TAMU T3 grant - 246451.	Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1; Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Bhat P., 2007, P EUROGRAPHICS S REN, P327, DOI 10.2312; Boominathan V., 2014, ICCP, P1; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128; Gupta AK, 2009, PHYSICS AND CHEMISTRY OF THE EARTHS INTERIOR: CRUST, MANTLE AND CORE, P1, DOI 10.1145/1654059.1654061; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Janai J, 2017, PROC CVPR IEEE, P1406, DOI 10.1109/CVPR.2017.154; Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938; Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kingma D.P, P 3 INT C LEARNING R; LeCun Y, 2016, P INT C LEARN REPR; Liu YL, 2019, AAAI CONF ARTIF INTE, P8794; Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI 10.1109/ICCV.2017.478; Long GC, 2016, LECT NOTES COMPUT SC, V9910, P434, DOI 10.1007/978-3-319-46466-4_26; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324; Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027; Meyer S, 2018, PROC CVPR IEEE, P498, DOI 10.1109/CVPR.2018.00059; Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747; Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183; Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37; Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244; Peers P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477929; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Ren Z, 2017, AAAI CONF ARTIF INTE, P1495; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sawhney HS, 2001, COMP GRAPH, P451, DOI 10.1145/383259.383312; Shechtman E, 2010, PROC CVPR IEEE, P615, DOI 10.1109/CVPR.2010.5540159; Simonyan K, 2015, 3 INT C LEARN REPR I; Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Wang TC, 2016, PROC CVPR IEEE, P3717, DOI 10.1109/CVPR.2016.404; Wang Y, 2018, PROC CVPR IEEE, P4884, DOI 10.1109/CVPR.2018.00513; Wang YW, 2017, IEEE T VIS COMPUT GR, V23, P2357, DOI 10.1109/TVCG.2016.2628743; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Watanabe K, 2006, LECT NOTES COMPUT SC, V3851, P480; Wedel A, 2009, IEEE I CONF COMP VIS, P1663, DOI 10.1109/ICCV.2009.5459375; Wenbo Bao, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3698, DOI 10.1109/CVPR.2019.00382; Xie K, 2019, INT CONF MANAGE DATA, P195, DOI 10.1145/3299869.3319856; Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212; Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068	49	10	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1557	1569		10.1109/TPAMI.2020.2987316	http://dx.doi.org/10.1109/TPAMI.2020.2987316			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32310760	Green Submitted			2022-12-18	WOS:000542967200003
J	Birdal, T; Busam, B; Navab, N; Ilic, S; Sturm, P				Birdal, Tolga; Busam, Benjamin; Navab, Nassir; Ilic, Slobodan; Sturm, Peter			Generic Primitive Detection in Point Clouds Using Novel Minimal Quadric Fits	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Quadrics; surface fitting; implicit surfaces; point clouds; 3D surface detection; primitive fitting; minimal problems	EFFICIENT RANSAC; SEGMENTATION; ROBUST; PLANAR; EXTRACTION; SURFACES; CURVES; SPACE	We present a novel and effective method for detecting 3D primitives in cluttered, unorganized point clouds, without axillary segmentation or type specification. We consider the quadric surfaces for encapsulating the basic building blocks of our environments - planes, spheres, ellipsoids, cones or cylinders, in a unified fashion. Moreover, quadrics allow us to model higher degree of freedom shapes, such as hyperboloids or paraboloids that could be used in non-rigid settings. We begin by contributing two novel quadric fits targeting 3D point sets that are endowed with tangent space information. Based upon the idea of aligning the quadric gradients with the surface normals, our first formulation is exact and requires as low as four oriented points. The second fit approximates the first, and reduces the computational effort. We theoretically analyze these fits with rigor, and give algebraic and geometric arguments. Next, by re-parameterizing the solution, we devise a new local Hough voting scheme on the null-space coefficients that is combined with RANSAC, reducing the complexity from $O(N<^>4)$O(N4) to $O(N<^>3)$O(N3) (three points). To the best of our knowledge, this is the first method capable of performing a generic cross-type multi-object primitive detection in difficult scenes without segmentation. Our extensive qualitative and quantitative results show that our method is efficient and flexible, as well as being accurate.	[Birdal, Tolga; Busam, Benjamin; Navab, Nassir; Ilic, Slobodan] Tech Univ Munich, Dept Informat, D-80333 Munich, Germany; [Birdal, Tolga; Ilic, Slobodan] Siemens AG, D-80333 Munich, Germany; [Busam, Benjamin] Framos GmbH, D-82024 Munich, Germany; [Sturm, Peter] INRIA, F-38330 Grenoble, France	Technical University of Munich; Siemens AG; Siemens Germany; Inria	Birdal, T (corresponding author), Tech Univ Munich, Dept Informat, D-80333 Munich, Germany.	tolga.birdal@tum.de; b.busam@framos.com; navab@cs.tum.de; slobodan.ilic@siemens.com; peter.sturm@inria.fr	Birdal, Tolga/H-9173-2019; Busam, Benjamin/ADC-5306-2022	Birdal, Tolga/0000-0001-7915-7964; Busam, Benjamin/0000-0002-0620-5774; Ilic, Slobodan/0000-0002-3413-1936				[Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], 2007, IEEE 11 INT C COMP V, DOI DOI 10.1109/ICCV.2007.4409163; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Beale D., 2016, COMPUTATIONAL VISUAL, V2, P107; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Birdal T, 2018, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2018.00372; Birdal T, 2017, IEEE INT C INT ROBOT, P6871; Birdal T, 2016, INT CONF 3D VISION, P556, DOI 10.1109/3DV.2016.65; Birdal T, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P527, DOI 10.1109/3DV.2015.65; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Borrmann D, 2011, 3D RES, V2, DOI 10.1007/3DRes.02(2011)3; Choi S., 2016, ARXIV160202481; Cross G, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P25, DOI 10.1109/ICCV.1998.710697; Czerniawski T, 2018, AUTOMAT CONSTR, V88, P44, DOI 10.1016/j.autcon.2017.12.029; Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37; Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028; Drost B, 2017, IEEE INT CONF COMP V, P2200, DOI 10.1109/ICCVW.2017.257; Drost B, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P398, DOI 10.1109/3DV.2015.52; Fang H, 2018, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2018.00313; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; Frahm J.-M., 2006, P COMP VIS PATT REC, V1, P453, DOI DOI 10.1109/CVPR.2006.235; Garcia-Garcia A, 2017, ARXIV170406857; Gay P, 2017, IEEE I CONF COMP VIS, P3094, DOI 10.1109/ICCV.2017.334; Gotardo PFU, 2004, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2004.1334099; Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; Ioannou Y, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P501, DOI 10.1109/3DIMPVT.2012.12; Kanatani K, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P2, DOI 10.1109/3DIM.2005.49; Kukelova Z, 2016, PROC CVPR IEEE, P1799, DOI 10.1109/CVPR.2016.199; Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947; Liu Y, 2016, SCI CHINA TECHNOL SC, V59, P1156, DOI 10.1007/s11431-016-6072-8; Lopez-Rubio E, 2017, J MATH IMAGING VIS, V58, P189, DOI 10.1007/s10851-016-0700-6; Makhal A, 2018, 2018 SECOND IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P292, DOI 10.1109/IRC.2018.00062; MILLER JR, 1988, IEEE COMPUT GRAPH, V8, P28, DOI 10.1109/38.488; Minto L, 2016, LECT NOTES COMPUT SC, V9915, P118, DOI 10.1007/978-3-319-49409-8_12; Morwald T, 2013, IEEE INT CONF ROBOT, P148, DOI 10.1109/ICRA.2013.6630569; Monszpart A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766995; Oesau S, 2016, COMPUT GRAPH FORUM, V35, P203, DOI 10.1111/cgf.12720; Papazov C, 2011, LECT NOTES COMPUT SC, V6492, P135, DOI 10.1007/978-3-642-19315-6_11; Petitjean S, 2002, ACM COMPUT SURV, V34, P211, DOI 10.1145/508352.508354; Qin Kaihuai, 1997, Journal of Computer Science and Technology (English Language Edition), V12, P210, DOI 10.1007/BF02948971; Qin KH, 1998, PACIFIC GRAPHICS '98, PROCEEDINGS, P210, DOI 10.1109/PCCGA.1998.732121; Qiu RQ, 2014, LECT NOTES COMPUT SC, V8691, P17, DOI 10.1007/978-3-319-10578-9_2; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x; Sveier A, 2017, ADV APPL CLIFFORD AL, V27, P1961, DOI 10.1007/s00006-017-0759-1; Tasdizen T., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P35, DOI 10.1109/CVPR.1999.784605; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Tran TT, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0076-1; Ulrich M, 2012, IEEE T PATTERN ANAL, V34, P1902, DOI 10.1109/TPAMI.2011.266; Uto S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1611, DOI 10.1109/ROBIO.2013.6739697; Vaskevicius N, 2010, IEEE INT CONF ROBOT, P3466, DOI 10.1109/ROBOT.2010.5509463; Yan DM, 2006, LECT NOTES COMPUT SC, V4077, P73; Yan DM, 2012, COMPUT AIDED DESIGN, V44, P1072, DOI 10.1016/j.cad.2012.04.005; You SD, 2017, NEUROCOMPUTING, V259, P119, DOI 10.1016/j.neucom.2016.06.086; Zhao HW, 2016, IEEE IMAGE PROC, P2589, DOI 10.1109/ICIP.2016.7532827; Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103	66	10	10	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1333	1347		10.1109/TPAMI.2019.2900309	http://dx.doi.org/10.1109/TPAMI.2019.2900309			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30794508	Green Submitted			2022-12-18	WOS:000535615700004
J	Gao, J; Wang, Q; Xing, JL; Ling, HB; Hu, WM; Maybank, S				Gao, Jin; Wang, Qiang; Xing, Junliang; Ling, Haibin; Hu, Weiming; Maybank, Stephen			Tracking-by-Fusion via Gaussian Process Regression Extended to Transfer Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Correlation; Target tracking; Probability distribution; Visualization; Collaboration; Visual tracking; Gaussian processes; correlation filters; transfer learning; tracking-by-fusion	VISUAL TRACKING; OBJECT TRACKING; NETWORKS	This paper presents a new Gaussian Processes (GPs)-based particle filter tracking framework. The framework non-trivially extends Gaussian process regression (GPR) to transfer learning, and, following the tracking-by-fusion strategy, integrates closely two tracking components, namely a GPs component and a CFs one. First, the GPs component analyzes and models the probability distribution of the object appearance by exploiting GPs. It categorizes the labeled samples into auxiliary and target ones, and explores unlabeled samples in transfer learning. The GPs component thus captures rich appearance information over object samples across time. On the other hand, to sample an initial particle set in regions of high likelihood through the direct simulation method in particle filtering, the powerful yet efficient correlation filters (CFs) are integrated, leading to the CFs component. In fact, the CFs component not only boosts the sampling quality, but also benefits from the GPs component, which provides re-weighted knowledge as latent variables for determining the impact of each correlation filter template from the auxiliary samples. In this way, the transfer learning based fusion enables effective interactions between the two components. Superior performance on four object tracking benchmarks (OTB-2015, Temple-Color, and VOT2015/2016), and in comparison with baselines and recent state-of-the-art trackers, has demonstrated clearly the effectiveness of the proposed framework.	[Gao, Jin; Wang, Qiang; Xing, Junliang; Hu, Weiming] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China; [Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Maybank, Stephen] Birkbeck Coll, Dept Comp Sci & Informat Syst, Malet St, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of London; Birkbeck University London	Hu, WM (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China.	jin.gao@nlpr.ia.ac.cn; qiang.wang@nlpr.ia.ac.cn; jlxing@nlpr.ia.ac.cn; hbling@temple.edu; wmhu@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk	Xing, Junliang/HGE-9630-2022; Gao, Jin/U-8481-2019	Xing, Junliang/0000-0001-6801-0510; Gao, Jin/0000-0002-8925-5215; Ling, Haibin/0000-0003-4094-8413	Natural Science Foundation of China [61602478, 61751212, 61472421]; Beijing Natural Science Foundation [L172051]; NSFC-general technology collaborative Fund for basic research [U1636218]; Key Research Program of Frontier Sciences, CAS [QYZDJ-SSW-JSC040]; CAS External cooperation key project; Research Project of ForwardX Robotics, Inc.; US NSF [1350521, 1618398, 1814745]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation); NSFC-general technology collaborative Fund for basic research; Key Research Program of Frontier Sciences, CAS; CAS External cooperation key project; Research Project of ForwardX Robotics, Inc.; US NSF(National Science Foundation (NSF))	The authors would like to thank the anonymous reviewers for their constructive comments and suggestions. This work is supported by Natural Science Foundation of China (Grant No. 61602478, 61751212 and 61472421), Beijing Natural Science Foundation (Grant No. L172051), the NSFC-general technology collaborative Fund for basic research (Grant No. U1636218), the Key Research Program of Frontier Sciences, CAS (GrantNo. QYZDJ-SSW-JSC040), the CAS External cooperation key project, and the Research Project of ForwardX Robotics, Inc. Prof. Ling is supported in part by US NSF Grants 1350521, 1618398 and 1814745.	Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bishop C.M, 2006, PATTERN RECOGN; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Chen DP, 2014, LECT NOTES COMPUT SC, V8689, P345, DOI 10.1007/978-3-319-10590-1_23; Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928; Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Fanti C, 2004, ADV NEUR IN, V16, P1603; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Herbrich R., 2001, LEARNING KERNEL CLAS; Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu WM, 2017, IEEE T PATTERN ANAL, V39, P172, DOI 10.1109/TPAMI.2016.2539944; Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42; Hurzeler M, 1998, J COMPUT GRAPH STAT, V7, P175, DOI 10.2307/1390812; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Kwon J, 2014, PROC CVPR IEEE, P3494, DOI 10.1109/CVPR.2014.447; Kwon J, 2013, PROC CVPR IEEE, P2355, DOI 10.1109/CVPR.2013.305; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156; Lee DY, 2015, PROC CVPR IEEE, P5088, DOI 10.1109/CVPR.2015.7299144; Li GR, 2011, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2011.6126297; Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313; Li X, 2011, IEEE I CONF COMP VIS, P1156, DOI 10.1109/ICCV.2011.6126364; Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18; Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905; Liu S, 2017, NEURAL INFORM PROCES; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Meshgi K, 2018, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2018.00506; Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152; Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ristic B., 2004, KALMAN FILTER PARTIC; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Steyvers M., 2011, COMPUTATIONAL STAT M; Sui Y, 2018, INT J COMPUT VISION, V126, P515, DOI 10.1007/s11263-017-1049-z; Sui Y, 2018, IEEE T IMAGE PROCESS, V27, P1282, DOI 10.1109/TIP.2017.2779275; Sui Y, 2016, LECT NOTES COMPUT SC, V9912, P662, DOI 10.1007/978-3-319-46484-8_40; Sui Y, 2015, IEEE I CONF COMP VIS, P3002, DOI 10.1109/ICCV.2015.344; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang N., 2013, P 26 INT C NEUR INF, P809; Wang N., 2015, CORR; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9; Zhang MD, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P595, DOI 10.1109/ICCVW.2015.81; Zhang Z, 2014, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2014.160; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108; Zhu X., 2003, CMUCS03175; Zhu Xiaojin., 2003, P ICLR, P912	71	10	10	3	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					939	955		10.1109/TPAMI.2018.2889070	http://dx.doi.org/10.1109/TPAMI.2018.2889070			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30582527	Green Accepted, hybrid			2022-12-18	WOS:000526541100011
J	Santa Cruz, R; Fernando, B; Cherian, A; Gould, S				Santa Cruz, Rodrigo; Fernando, Basura; Cherian, Anoop; Gould, Stephen			Visual Permutation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Task analysis; Machine learning; Image sequences; Computational modeling; Computer vision; Predictive models; Permutation learning; self-supervised learning; relative attributes; representation learning; learning-to-rank		We present a principled approach to uncover the structure of visual data by solving a deep learning task coined <italic>visual permutation learning</italic>. The goal of this task is to find the permutation that recovers the structure of data from shuffled versions of it. In the case of natural images, this task boils down to recovering the original image from patches shuffled by an unknown permutation matrix. Permutation matrices are discrete, thereby posing difficulties for gradient-based optimization methods. To this end, we resort to a continuous approximation using doubly-stochastic matrices and formulate a novel bi-level optimization problem on such matrices that learns to recover the permutation. Unfortunately, such a scheme leads to expensive gradient computations. We circumvent this issue by further proposing a computationally cheap scheme for generating doubly stochastic matrices based on Sinkhorn iterations. To implement our approach we propose <italic>DeepPermNet</italic>, an end-to-end CNN model for this task. The utility of DeepPermNet is demonstrated on three challenging computer vision problems, namely, relative attributes learning, supervised learning-to-rank, and self-supervised representation learning. Our results show state-of-the-art performance on the Public Figures and OSR benchmarks for relative attributes learning, chronological and interestingness image ranking for supervised learning-to-rank, and competitive results in the classification and segmentation tasks of the PASCAL VOC dataset for self-supervised representation learning.	[Santa Cruz, Rodrigo; Fernando, Basura; Cherian, Anoop; Gould, Stephen] Australian Natl Univ, Australian Ctr Robot Vis, Canberra, ACT 0200, Australia; [Fernando, Basura] ASTAR, Artificial Intelligence Initiat, Singapore 138632, Singapore; [Cherian, Anoop] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA	Australian Centre for Robotic Vision; Australian National University; Agency for Science Technology & Research (A*STAR)	Santa Cruz, R (corresponding author), Australian Natl Univ, Australian Ctr Robot Vis, Canberra, ACT 0200, Australia.	rodrigo.santacruz@anu.edu.au; basura.fernando@anu.edu.au; anoop.cherian@anu.edu.au; stephen.gould@anu.edu.au		Santa Cruz, Rodrigo/0000-0002-5273-7296; Fernando, Basura/0000-0002-6920-9916	Australian Research Council (ARC) through the Centre of Excellence for Robotic Vision [CE140100016]	Australian Research Council (ARC) through the Centre of Excellence for Robotic Vision(Australian Research Council)	This research was supported by the Australian Research Council (ARC) through the Centre of Excellence for Robotic Vision (CE140100016) and was undertaken with resources from the National Computational Infrastructure (NCI), at the Australian National University (ANU).	Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680; Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; [Anonymous], 2012, LNCS, DOI DOI 10.1007/978-3-642-37331-2_24; Birkhoff G., 1946, U NAC TACUMAN REV SE, V5, P147; Bojanowski P, 2017, PR MACH LEARN RES, V70; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Branson S, 2013, PROC CVPR IEEE, P1806, DOI 10.1109/CVPR.2013.236; Brown BJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360683; BRUALDI RA, 1988, LINEAR ALGEBRA APPL, V107, P77, DOI 10.1016/0024-3795(88)90239-X; Cao Z., 2007, P 24 INT C MACH LEAR, P129, DOI DOI 10.1145/1273496.1273513; Cho TS, 2010, IEEE T PATTERN ANAL, V32, P1489, DOI 10.1109/TPAMI.2009.133; COOPER WS, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P198; Cruz RS, 2017, PROC CVPR IEEE, P6044, DOI 10.1109/CVPR.2017.640; Diamond S, 2016, J MACH LEARN RES, V17; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Domke Justin, 2012, INT C ARTIFICIAL INT; Donahue Jeff, 2017, INT C LEARN REPR ICL; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fernando B, 2016, ICML; Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607; Fernando B, 2015, IEEE I CONF COMP VIS, P2785, DOI 10.1109/ICCV.2015.319; Gidaris Spyros, 2018, ARXIV180307728; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Glorot X., 2010, PROC MACH LEARN RES, P249; Gould Stephen, 2016, ARXIV160705447; Gygli M, 2013, IEEE I CONF COMP VIS, P1633, DOI 10.1109/ICCV.2013.205; HUANG C, 2016, PROC CVPR IEEE, P5175, DOI DOI 10.1109/CVPR.2016.559; Isola P., 2016, P INT C LEARN REPR W; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jenni S, 2018, PROC CVPR IEEE, P2733, DOI 10.1109/CVPR.2018.00289; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Jun Xu, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P391; Karen Simonyan, 2014, ARXIV13126034CS, DOI DOI 10.1038/S41591-018-0335-9; Kim D, 2018, IEEE WINT CONF APPL, P793, DOI 10.1109/WACV.2018.00092; Knight PA, 2008, SIAM J MATRIX ANAL A, V30, P261, DOI 10.1137/060659624; Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96; Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79; Lee YJ, 2013, IEEE I CONF COMP VIS, P1857, DOI 10.1109/ICCV.2013.233; Liang L, 2014, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2014.34; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Marande W, 2007, SCIENCE, V318, P415, DOI 10.1126/science.1148033; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32; Mundhenk TN, 2018, PROC CVPR IEEE, P9339, DOI 10.1109/CVPR.2018.00973; Noroozi M, 2017, IEEE I CONF COMP VIS, P5899, DOI 10.1109/ICCV.2017.628; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Ochs P., 2015, INT C SCAL SPAC VAR, V9087, P654, DOI DOI 10.1007/978-3-319-18461-6_52; Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Ren ZZ, 2018, PROC CVPR IEEE, P762, DOI [10.1109/CVPR.2018.00086, 10.1109/CVPR.2018.00104]; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Sculley D., 2009, P NIPS WORKSH ADV RA; Shankar S, 2015, PROC CVPR IEEE, P3403, DOI 10.1109/CVPR.2015.7298962; Sholomon D, 2013, PROC CVPR IEEE, P1767, DOI 10.1109/CVPR.2013.231; Singh KK, 2016, LECT NOTES COMPUT SC, V9910, P753, DOI 10.1007/978-3-319-46466-4_45; SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343; Souri Yaser, 2016, ACCV; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; VON NEUMANN J., 1953, CONTRIBUTIONS THEORY, V2, P5, DOI [10.1515/9781400881970-002, DOI 10.1515/9781400881970-002]; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wohlhart P., 2015, P COMP VIS WINT WORK, P37; Wu QA, 2010, INFORM RETRIEVAL, V13, P254, DOI 10.1007/s10791-009-9112-1; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32; Zemel R.P, 2011, ARXIV PREPRINT ARXIV; Zhang QL, 2008, CHEM COMMUN, P1199, DOI 10.1039/b716681h; Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40	81	10	10	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					3100	3114		10.1109/TPAMI.2018.2873701	http://dx.doi.org/10.1109/TPAMI.2018.2873701			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30295613				2022-12-18	WOS:000498677600021
J	Anwar, S; Huynh, CP; Porikli, F				Anwar, Saeed; Huynh, Cong Phuoc; Porikli, Fatih			Image Deblurring with a Class-Specific Prior	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image deblurring; blind deconvolution; image prior; class prior	KERNEL ESTIMATION	A fundamental problem in image deblurring is to recover reliably distinct spatial frequencies that have been suppressed by the blur kernel. To tackle this issue, existing image deblurring techniques often rely on generic image priors such as the sparsity of salient features including image gradients and edges. However, these priors only help recover part of the frequency spectrum, such as the frequencies near the high-end. To this end, we pose the following specific questions: (i) Does any image class information offer an advantage over existing generic priors for image quality restoration? (ii) If a class-specific prior exists, how should it be encoded into a deblurring framework to recover attenuated image frequencies? Throughout this work, we devise a class-specific prior based on the band-pass filter responses and incorporate it into a deblurring strategy. More specifically, we show that the subspace of band-pass filtered images and their intensity distributions serve as useful priors for recovering image frequencies that are difficult to recover by generic image priors. We demonstrate that our image deblurring framework, when equipped with the above priors, significantly outperforms many state-of-the-art methods using generic image priors or class-specific exemplars.	[Anwar, Saeed; Huynh, Cong Phuoc; Porikli, Fatih] Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia; [Anwar, Saeed; Huynh, Cong Phuoc; Porikli, Fatih] Data61 CSIRO, Canberra, ACT 2601, Australia	Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO)	Anwar, S (corresponding author), Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia.	saeed.anwar@anu.edu.au; cong.huynh@anu.edu.au; fatih.porikli@anu.edu.au			Australian Research Council [DP150104645]; Australian Government RTP Scholarship	Australian Research Council(Australian Research Council); Australian Government RTP Scholarship(Australian Government)	This research was supported under Australian Research Council's Discovery Projects funding scheme (project number DP150104645) and an Australian Government RTP Scholarship.	Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413; Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743; Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; HaCohen Y, 2013, IEEE I CONF COMP VIS, P2384, DOI 10.1109/ICCV.2013.296; HEWITT E, 1979, ARCH HIST EXACT SCI, V21, P129, DOI 10.1007/BF00330404; Joshi N., 2008, CVPR, P1; Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731050; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krishnan D., 2009, ADV NEURAL INFORM PR, V22, P1033; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A., 2007, ADV NEURAL INFORM PR, P841; Levin A., 2006, ADV NEURAL INFORM PR, V19, P841; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51; Mosleh A, 2014, LECT NOTES COMPUT SC, V8692, P247, DOI 10.1007/978-3-319-10593-2_17; Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Sun LB, 2014, LECT NOTES COMPUT SC, V8692, P231; Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43; Tai YW, 2013, IEEE T PATTERN ANAL, V35, P2498, DOI 10.1109/TPAMI.2013.40; Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005; Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302; TROTT T, 1960, PHOTOGRAMM ENG, V26, P819; VANGEMERT JC, 2006, C COMP VIS PATT REC, P105; Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3; Xu L, 2014, LECT NOTES COMPUT SC, V8693, P33, DOI 10.1007/978-3-319-10602-1_3; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452; Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315; Zhang WW, 2008, LECT NOTES COMPUT SC, V5305, P802, DOI 10.1007/978-3-540-88693-8_59; Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	48	10	10	4	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2112	2130		10.1109/TPAMI.2018.2855177	http://dx.doi.org/10.1109/TPAMI.2018.2855177			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	30004871				2022-12-18	WOS:000480343900006
J	Park, MG; Yoon, KJ				Park, Min-Gyu; Yoon, Kuk-Jin			Learning and Selecting Confidence Measures for Robust Stereo Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; confidence measures; random forests; feature selection		We present a robust approach for computing disparity maps with a supervised learning-based confidence prediction. This approach takes into consideration following features. First, we analyze the characteristics of various confidence measures in the random forest framework to select effective confidence measures depending on the characteristics of the training data and matching strategies, such as similarity measures and parameters. We then train a random forest using the selected confidence measures to improve the efficiency of confidence prediction and to build a better prediction model. Second, we present a confidence-based matching cost modulation scheme, based on predicted confidence values, to improve the robustness and accuracy of the (semi-) global stereo matching algorithms. Finally, we apply the proposed modulation scheme to popularly used algorithms to make them robust against unexpected difficulties that could occur in an uncontrolled environment using challenging outdoor datasets. The proposed confidence measure selection and cost modulation schemes are experimentally verified from various perspectives using the KITTI and Middlebury datasets.	[Park, Min-Gyu] KETI, Intelligent Image Proc Res Ctr, Seongnam Si 13509, Gyeonggi Do, South Korea; [Yoon, Kuk-Jin] Korea Adv Inst Sci & Technol, Dept Mech Engn, Daejeon 34141, South Korea	Korea Electronics Technology Institute (KETI); Korea Advanced Institute of Science & Technology (KAIST)	Yoon, KJ (corresponding author), Korea Adv Inst Sci & Technol, Dept Mech Engn, Daejeon 34141, South Korea.	mpark@keti.re.kr; kjyoon@kaist.ac.kr	Yoon, Kuk-Jin/F-4329-2018	Park, Min Gyu/0000-0003-1752-150X; yun, gugjin/0000-0002-1634-2756	Samsung Research Funding Center of Samsung Electronics [SRFC-TC1603-05]; Next-Generation Information Computing Development Program through the National Research Foundation of Korea(NRF) - Ministry of Science, ICT [NRF-2017M3C4A7069369]; 'The Cross-Ministry Giga KOREA Project' - Korea government(MSIT) [GK18P0200, GK18P0300]	Samsung Research Funding Center of Samsung Electronics(Samsung); Next-Generation Information Computing Development Program through the National Research Foundation of Korea(NRF) - Ministry of Science, ICT(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea); 'The Cross-Ministry Giga KOREA Project' - Korea government(MSIT)(Giga Korea Co.Ministry of Science & ICT (MSIT), Republic of Korea)	This work was supported by Samsung Research Funding Center of Samsung Electronics under Project Number SRFC-TC1603-05, Next-Generation Information Computing Development Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Science, ICT (NRF-2017M3C4A7069369), and 'The Cross-Ministry Giga KOREA Project' grant funded by the Korea government(MSIT) (No. GK18P0200, Development of 4D reconstruction and dynamic deformable action model based hyper-realistic service technology and No. GK18P0300, Real-time 4D reconstruction of dynamic objects for ultra-realistic service).	Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Boykov Y, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P79, DOI 10.1007/0-387-28831-7_5; Brandao M, 2016, IEEE T PATTERN ANAL, V38, P116, DOI 10.1109/TPAMI.2015.2437381; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117; Egnal G, 2004, IMAGE VISION COMPUT, V22, P943, DOI 10.1016/j.imavis.2004.03.018; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Einecke N, 2015, IEEE INT VEH SYM, P585, DOI 10.1109/IVS.2015.7225748; Gallup D., 2007, P BRIT MACH VIS C; Garcia F, 2010, IEEE IMAGE PROC, P2805, DOI 10.1109/ICIP.2010.5651112; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Gherardi R., 2008, PATT REC 2008 ICPR 2, P1; Gouveia R, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P180, DOI 10.1109/3DV.2015.28; Haeusler R, 2013, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2013.46; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46; Kong D., 2004, P BRIT MACH VIS C; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614; Manduchi R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P26, DOI 10.1109/ICIAP.1999.797566; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Mei X, 2011, PROC CVPR IEEE, P1257; Meister S, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.2.021107; Menze Moritz, 2015, CVPR; Merrell P, 2007, IEEE I CONF COMP VIS, P3012, DOI 10.1109/iccv.2007.4408984; Mordohai P, 2009, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2009.5459409; Mostegel C, 2016, PROC CVPR IEEE, P4067, DOI 10.1109/CVPR.2016.441; Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605; Pfeiffer D, 2013, PROC CVPR IEEE, P297, DOI 10.1109/CVPR.2013.45; Poggi M., 2016, P BRIT MACH VIS C; Poggi M, 2016, INT CONF 3D VISION, P509, DOI 10.1109/3DV.2016.61; Sabater N, 2012, IEEE T PATTERN ANAL, V34, P930, DOI 10.1109/TPAMI.2011.207; Sara R, 2002, LECT NOTES COMPUT SC, V2352, P900; Saygili G, 2016, IEEE T MED IMAGING, V35, P539, DOI 10.1109/TMI.2015.2481609; Saygili G, 2015, COMPUT VIS IMAGE UND, V135, P95, DOI 10.1016/j.cviu.2015.02.005; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Seki A., 2016, P BRIT MACH VIS C; Spyropoulos A, 2016, INT J COMPUT VISION, V118, P300, DOI 10.1007/s11263-015-0877-y; Spyropoulos A, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P73, DOI 10.1109/3DV.2015.16; Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210; Yoon KJ, 2008, COMPUT VIS IMAGE UND, V112, P173, DOI 10.1016/j.cviu.2008.02.003; Zbontar J, 2016, J MACH LEARN RES, V17; Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478	44	10	11	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1397	1411		10.1109/TPAMI.2018.2837760	http://dx.doi.org/10.1109/TPAMI.2018.2837760			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993568				2022-12-18	WOS:000467037000009
J	Agudo, A; Moreno-Noguer, F				Agudo, Antonio; Moreno-Noguer, Francesc			Robust Spatio-Temporal Clustering and Reconstruction of Multiple Deformable Bodies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-rigid structure from motion; union of subspaces; spatio-temporal clustering; augmented lagrange multipliers	STRUCTURE-FROM-MOTION; 3D RECONSTRUCTION; SHAPE; SEGMENTATION; ALGORITHM	In this paper we present an approach to reconstruct the 3D shape of multiple deforming objects from a collection of sparse, noisy and possibly incomplete 2D point tracks acquired by a single monocular camera. Additionally, the proposed solution estimates the camera motion and reasons about the spatial segmentation (i.e., identifies each of the deforming objects in every frame) and temporal clustering (i.e., splits the sequence into motion primitive actions). This advances competing work, which mainly tackled the problem for one single object and non-occluded tracks. In order to handle several objects at a time from partial observations, we model point trajectories as a union of spatial and temporal subspaces, and optimize the parameters of both modalities, the non-observed point tracks, the camera motion, and the time-varying 3D shape via augmented Lagrange multipliers. The algorithm is fully unsupervised and does not require any training data at all. We thoroughly validate the method on challenging scenarios with several human subjects performing different activities which involve complex motions and close interaction. We show our approach achieves state-of-the-art 3D reconstruction results, while it also provides spatial and temporal segmentation.	[Agudo, Antonio; Moreno-Noguer, Francesc] CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya	Agudo, A (corresponding author), CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain.	aagudo@iri.upc.edu; fmoreno@iri.upc.edu	Agudo, Antonio/J-1805-2016; Agudo, Antonio/C-5147-2017	Agudo, Antonio/0000-0001-9900-5677; Agudo, Antonio/0000-0001-6845-4998	Google Faculty Research Award; Spanish Ministry of Science and Innovation [HuMoUR TIN2017-90086-R]; Maria de Maeztu Seal of Excellence [MDM-2016-0656]	Google Faculty Research Award(Google Incorporated); Spanish Ministry of Science and Innovation(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); Maria de Maeztu Seal of Excellence	This work is supported in part by a Google Faculty Research Award, by the Spanish Ministry of Science and Innovation under projects HuMoUR TIN2017-90086-R, and Maria de Maeztu Seal of Excellence MDM-2016-0656. We thank the anonymous reviewers for their insightful comments and suggestions which helped to improve the work.	Agudo A., 2016, P IEEE WINT C APPL C, P1; Agudo A, 2018, IEEE T PATTERN ANAL, V40, P2137, DOI 10.1109/TPAMI.2017.2752710; Agudo A, 2017, PROC CVPR IEEE, P1513, DOI 10.1109/CVPR.2017.165; Agudo A, 2017, IEEE WINT CONF APPL, P264, DOI 10.1109/WACV.2017.36; Agudo A, 2017, INT J COMPUT VISION, V122, P371, DOI 10.1007/s11263-016-0972-8; Agudo A, 2017, J MATH IMAGING VIS, V57, P75, DOI 10.1007/s10851-016-0668-2; Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293; Akhter I, 2009, PROC CVPR IEEE, P1534, DOI 10.1109/CVPRW.2009.5206620; Akhter Ijaz, 2008, ADV NEURAL INFORM PR, P41; Bach F., 2008, HAL00345747 EC NORM; Boumal N, 2014, J MACH LEARN RES, V15, P1455; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chen WY, 2011, IEEE T PATTERN ANAL, V33, P568, DOI 10.1109/TPAMI.2010.88; Chen Y., 2011, PROC 28 INT C MACHIN, P873; Chhatkuli A, 2016, PROC CVPR IEEE, P1719, DOI 10.1109/CVPR.2016.190; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905; Del Bue A, 2006, P IEEE C COMP VIS PA, V1, P1191; Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fayad J, 2010, LECT NOTES COMPUT SC, V6314, P297, DOI 10.1007/978-3-642-15561-1_22; Fragkiadaki Katerina, 2014, ADV NEURAL INFORM PR, P55; Gao Y, 2016, LECT NOTES COMPUT SC, V9906, P408, DOI 10.1007/978-3-319-46475-6_26; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Golyanik V, 2017, IEEE WINT CONF APPL, P254, DOI 10.1109/WACV.2017.35; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; Irani M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P626, DOI 10.1109/ICCV.1999.791283; Kong C, 2016, PROC CVPR IEEE, P4123, DOI 10.1109/CVPR.2016.447; Kumar S, 2017, PATTERN RECOGN, V71, P428, DOI 10.1016/j.patcog.2017.05.014; Lee M, 2016, PROC CVPR IEEE, P4670, DOI 10.1109/CVPR.2016.505; Lee M, 2014, PROC CVPR IEEE, P1550, DOI 10.1109/CVPR.2014.201; Lee M, 2013, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR.2013.169; Li ZW, 2013, IEEE I CONF COMP VIS, P1369, DOI 10.1109/ICCV.2013.173; Lin Z., 2009, UILUENG092215; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Ozden KE, 2010, IEEE T PATTERN ANAL, V32, P1134, DOI 10.1109/TPAMI.2010.23; Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602; Parashar S, 2016, PROC CVPR IEEE, P4679, DOI 10.1109/CVPR.2016.506; Park HS, 2010, LECT NOTES COMPUT SC, V6313, P158; Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; RUSSELL C, 2014, P EUR C COMPUT VIS, V8695, P583; Sayd P., 2008, P IEEE C COMP VIS PA, P1; Simon T, 2014, LECT NOTES COMPUT SC, V8691, P204, DOI 10.1007/978-3-319-10578-9_14; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Valmadre J, 2012, PROC CVPR IEEE, P1394, DOI 10.1109/CVPR.2012.6247826; van der Aa N. P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1264, DOI 10.1109/ICCVW.2011.6130396; Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31; Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573; Zappella L, 2013, COMPUT VIS IMAGE UND, V117, P113, DOI 10.1016/j.cviu.2012.09.004; Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200; Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311	62	10	10	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					971	984		10.1109/TPAMI.2018.2823717	http://dx.doi.org/10.1109/TPAMI.2018.2823717			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993925	Green Submitted			2022-12-18	WOS:000460583500014
J	Lee, D; Yang, MH; Oh, S				Lee, Donghoon; Yang, Ming-Hsuan; Oh, Songhwai			Head and Body Orientation Estimation Using Convolutional Random Projection Forests	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Head pose estimation; body orientation estimation; random forests; convolutional neural network; compressive sensing	POSE ESTIMATION	In this paper, we consider the problem of estimating the head pose and body orientation of a person from a low-resolution image. Under this setting, it is difficult to reliably extract facial features or detect body parts. We propose a convolutional random projection forest (CRPforest) algorithm for these tasks. A convolutional random projection network (CRPnet) is used at each node of the forest. It maps an input image to a high-dimensional feature space using a rich filter bank. The filter bank is designed to generate sparse responses so that they can be efficiently computed by compressive sensing. A sparse random projection matrix can capture most essential information contained in the filter bank without using all the filters in it. Therefore, the CRPnet is fast, e.g., it requires 0.04 ms to process an image of 50 x 50 pixels, due to the small number of convolutions (e.g., 0.01 percent of a layer of a neural network) at the expense of less than 2 percent accuracy. The overall forest estimates head and body pose well on benchmark datasets, e.g., over 98 percent on the HIIT dataset, while requiring 3.8 ms without using a GPU. Extensive experiments on challenging datasets show that the proposed algorithm performs favorably against the state-of-the-art methods in low-resolution images with noise, occlusion, and motion blur.	[Lee, Donghoon; Oh, Songhwai] Seoul Natl Univ, Dept Elect & Comp Engn, 1 Gwanak Ro, Seoul 08826, South Korea; [Lee, Donghoon; Oh, Songhwai] Seoul Natl Univ, ASRI, 1 Gwanak Ro, Seoul 08826, South Korea; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Seoul National University (SNU); Seoul National University (SNU); University of California System; University of California Merced	Oh, S (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, 1 Gwanak Ro, Seoul 08826, South Korea.; Oh, S (corresponding author), Seoul Natl Univ, ASRI, 1 Gwanak Ro, Seoul 08826, South Korea.	donghoon.lee@cpslab.snu.ac.kr; mhyang@ucmerced.edu; songhwai@snu.ac.kr	Yang, Ming-Hsuan/AAE-7350-2019; Lee, Donghoon/AAX-8390-2020; Yang, Ming-Hsuan/T-9533-2019	Lee, Donghoon/0000-0001-6271-439X; Yang, Ming-Hsuan/0000-0003-4848-2304	Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning [NRF-2017R1A2B2006136]; 'The Cross-Ministry Giga KOREA Project' - Korea government (MSIT) [GK17P0300]; NSF CAREER [1149783]	Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea); 'The Cross-Ministry Giga KOREA Project' - Korea government (MSIT)(Giga Korea Co.Ministry of Science & ICT (MSIT), Republic of Korea); NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD))	The work of D. Lee and S. Oh is supported in part by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT & Future Planning (NRF-2017R1A2B2006136) and 'The Cross-Ministry Giga KOREA Project' grant funded by the Korea government (MSIT) (No. GK17P0300, Real-Time 4D Reconstruction of Dynamic Objects for Ultra-Realistic Services). Thework of M.-H. Yang is supported in part by the NSF CAREER grant #1149783, and gifts from Adobe and Nvidia.	Al Haj M, 2012, PROC CVPR IEEE, P2602, DOI 10.1109/CVPR.2012.6247979; Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336; Bansal A., 2015, CORR; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Dahmane A, 2015, SIGNAL IMAGE VIDEO P, V9, P1871, DOI 10.1007/s11760-014-0676-x; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Doersch C, 2014, LECT NOTES COMPUT SC, V8691, P362, DOI 10.1007/978-3-319-10578-9_24; Drouard V, 2015, IEEE IMAGE PROC, P4624, DOI 10.1109/ICIP.2015.7351683; Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Foytik J, 2013, INT J COMPUT VISION, V101, P270, DOI 10.1007/s11263-012-0567-y; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Han B, 2014, PATTERN RECOGN LETT, V45, P145, DOI 10.1016/j.patrec.2014.03.017; Hao Ji, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3617, DOI 10.1109/ICIP.2011.6116500; Huang D, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995683; Ho HT, 2012, IEEE IMAGE PROC, P153, DOI 10.1109/ICIP.2012.6466818; Jiang FJ, 2012, INT C PATT RECOG, P1578; Kontschieder P, 2015, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2015.172; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee D, 2015, IEEE I CONF COMP VIS, P1958, DOI 10.1109/ICCV.2015.227; Li P., 2006, P 12 ACM SIGKDD INT, P287, DOI DOI 10.1145/1150402.1150436; Li Y, 2015, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2015.7298699; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Little G, 2005, INT CONF ACOUST SPEE, P89; Ma BP, 2015, NEUROCOMPUTING, V148, P455, DOI 10.1016/j.neucom.2014.07.019; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Orozco J., 2009, P BMVC, V1, P120, DOI DOI 10.5244/C.23.120; Parkhi Omkar M., 2015, BRIT MACH VIS C; Peng X, 2014, INT C PATT RECOG, P1800, DOI 10.1109/ICPR.2014.316; Sakita K., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P846; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Siriteerakul T., 2012, INT J COMPUT SCI ISS, V9, P270; Smith K, 2008, IEEE T PATTERN ANAL, V30, P1212, DOI 10.1109/TPAMI.2007.70773; Sundararajan Kalaivani, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P50, DOI 10.1109/CVPRW.2015.7301354; Tao JL, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P230, DOI 10.1109/ICCVW.2013.38; Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007; Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808; Zhang ZQ, 2007, LECT NOTES COMPUT SC, V4122, P299	45	10	10	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					107	120		10.1109/TPAMI.2017.2784424	http://dx.doi.org/10.1109/TPAMI.2017.2784424			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990037	hybrid			2022-12-18	WOS:000452434800009
J	Hu, WM; Tian, GD; Kang, YX; Yuan, CF; Maybank, S				Hu, Weiming; Tian, Guodong; Kang, Yongxin; Yuan, Chunfeng; Maybank, Stephen			Dual Sticky Hierarchical Dirichlet Process Hidden Markov Model and Its Application to Natural Language Description of Motions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						HDP-HMM; sticky prior; motion pattern learning; natural language description	TRAJECTORY ANALYSIS; SAMPLING METHODS; VIDEO RETRIEVAL; RECOGNITION; PATTERNS; SYSTEM; PRIORS	In this paper, a new nonparametric Bayesian model called the dual sticky hierarchical Dirichlet process hidden Markov model (HDP-HMM) is proposed for mining activities from a collection of time series data such as trajectories. All the time series data are clustered. Each cluster of time series data, corresponding to a motion pattern, is modeled by an HMM. Our model postulates a set of HMMs that share a common set of states (topics in an analogy with topic models for document processing), but have unique transition distributions. The number of HMMs and the number of topics are both automatically determined. The sticky prior avoids redundant states and makes our HDP-HMM more effective to model multimodal observations. For the application to motion trajectory modeling, topics correspond to motion activities. The learnt topics are clustered into atomic activities which are assigned predicates. We propose a Bayesian inference method to decompose a given trajectory into a sequence of atomic activities. The sources and sinks in the scene are learnt by clustering endpoints (origins and destinations) of trajectories. The semantic motion regions are learnt using the points in trajectories. On combining the learnt sources and sinks, the learnt semantic motion regions, and the learnt sequence of atomic activities, the action represented by a trajectory can be described in natural language in as automatic a way as possible. The effectiveness of our dual sticky HDP-HMM is validated on several trajectory datasets. The effectiveness of the natural language descriptions for motions is demonstrated on the vehicle trajectories extracted from a traffic scene.	[Hu, Weiming; Tian, Guodong; Kang, Yongxin; Yuan, Chunfeng] Chinese Acad Sci, Univ Chinese Acad Sci, Inst Automat,Natl Lab Pattern Recognit, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China; [Maybank, Stephen] Birkbeck Coll, Dept Comp Sci & Informat Syst, Malet St, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; University of Chinese Academy of Sciences, CAS; University of London; Birkbeck University London	Hu, WM (corresponding author), Chinese Acad Sci, Univ Chinese Acad Sci, Inst Automat,Natl Lab Pattern Recognit, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China.	wmhu@nlpr.ia.ac.cn; guodong.tian@nlpr.ia.ac.cn; yongxin.kang@nlpr.ia.ac.cn; cfyuan@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk	ARSLAN, Okan/AAA-3232-2020	yuan, chun feng/0000-0003-2219-4961	973 basic research program of China [2014CB349303]; Natural Science Foundation of China [U1636218, 61472421]; Strategic Priority Research Program of the CAS [XDB02070003]; CAS External cooperation key project	973 basic research program of China(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of the CAS; CAS External cooperation key project	This work is partly supported by the 973 basic research program of China (Grant No. 2014CB349303), the Natural Science Foundation of China (Grant No. U1636218, 61472421) and the Strategic Priority Research Program of the CAS (Grant No. XDB02070003), and the CAS External cooperation key project.	Alvarez I., 2014, BAYESIAN INFERENCE C; [Anonymous], 2010, BAYESIAN NONPARAMETR; [Anonymous], C N AM ASS COMP LING; Atev S, 2010, IEEE T INTELL TRANSP, V11, P647, DOI 10.1109/TITS.2010.2048101; Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346; Bashir FI, 2007, IEEE T IMAGE PROCESS, V16, P1912, DOI 10.1109/TIP.2007.898960; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chen L., 2005, P 2005 ACM SIGMOD IN, P491, DOI DOI 10.1145/1066157.1066213; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Fox E. B., 2008, 25 INT C MACHINE LEA, P312; Fox EB, 2011, ANN APPL STAT, V5, P1020, DOI 10.1214/10-AOAS395; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; Ishwaran H, 2000, BIOMETRIKA, V87, P371, DOI 10.1093/biomet/87.2.371; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Ishwaran H, 2002, CAN J STAT, V30, P269, DOI 10.2307/3315951; Jung CR, 2008, IEEE T CIRC SYST VID, V18, P1565, DOI 10.1109/TCSVT.2008.2005600; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P285, DOI 10.1145/347090.347153; Kivinen J. J., 2007, P IEEE 11 INT C COMP, P1; Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608; Kollnig H., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P338, DOI 10.1007/BFb0028366; Krishnamoorthy N., 2013, P WORKSHOP VISION NA, P10; Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869; Laptev I, 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587756; Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281; Little JJ, 2001, P SOC PHOTO-OPT INS, V4315, P545, DOI 10.1117/12.410966; Lou JG, 2002, INT C PATT RECOG, P777, DOI 10.1109/ICPR.2002.1048115; Ma X, 2009, IEEE T CIRC SYST VID, V19, P397, DOI 10.1109/TCSVT.2009.2013510; Morris B, 2009, PROC CVPR IEEE, P312, DOI 10.1109/CVPRW.2009.5206559; Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Naftel A., 2006, P IEEE INT C COMP VI, P47; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Nguyen NT, 2005, PROC CVPR IEEE, P955; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Piotto N, 2009, IEEE T MULTIMEDIA, V11, P1266, DOI 10.1109/TMM.2009.2030746; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Remagnino P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P857, DOI 10.1109/ICCV.1998.710817; Saleemi I, 2009, IEEE T PATTERN ANAL, V31, P1472, DOI 10.1109/TPAMI.2008.175; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Shao ZP, 2016, IEEE T CYBERNETICS, V46, P511, DOI 10.1109/TCYB.2015.2404828; Sun J, 2005, IEEE I CONF COMP VIS, P717; Teh Y.W., 2004, NONPARAMETRIC BAYESI; Teh Y.W., 2010, ENCY MACHINE LEARNIN; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Thomason Jesse, 2014, P 25 INT C COMP LING, P1218; Tian GD, 2013, IEEE IMAGE PROC, P98, DOI 10.1109/ICIP.2013.6738021; Veeraraghavan H, 2009, IEEE T INTELL TRANSP, V10, P628, DOI 10.1109/TITS.2009.2026440; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9; Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6; Wang XG, 2010, IEEE T PATTERN ANAL, V32, P56, DOI 10.1109/TPAMI.2008.241; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Xu HT, 2015, IEEE I CONF COMP VIS, P4328, DOI 10.1109/ICCV.2015.492; Zhang Z, 2006, INT C PATT RECOG, P1135	57	10	10	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2355	2373		10.1109/TPAMI.2017.2756039	http://dx.doi.org/10.1109/TPAMI.2017.2756039			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28952936	Green Accepted			2022-12-18	WOS:000443875500006
J	Fan, SJ; Ng, TT; Koenig, BL; Herberg, JS; Jiang, M; Shen, ZQ; Zhao, Q				Fan, Shaojing; Ng, Tian-Tsong; Koenig, Bryan Lee; Herberg, Jonathan Samuel; Jiang, Ming; Shen, Zhiqi; Zhao, Qi			Image Visual Realism: From Human Perception to Machine Computation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual realism; human psychophysics; statistical modeling; convolutional neural network	FACE; OWN; BIAS	Visual realism is defined as the extent to which an image appears to people as a photo rather than computer generated. Assessing visual realism is important in applications like computer graphics rendering and photo retouching. However, current realism evaluation approaches use either labor-intensive human judgments or automated algorithms largely dependent on comparing renderings to reference images. We develop a reference-free computational framework for visual realism prediction to overcome these constraints. First, we construct a benchmark dataset of 2,520 images with comprehensive human annotated attributes. From statistical modeling on this data, we identify image attributes most relevant for visual realism. We propose both empirically-based (guided by our statistical modeling of human data) and deep convolutional neural network models to predict visual realism of images. Our framework has the following advantages: (1) it creates an interpretable and concise empirical model that characterizes human perception of visual realism; (2) it links computational features to latent factors of human image perception.	[Fan, Shaojing; Zhao, Qi] Natl Univ Singapore, Smart Syst Inst, Singapore 119613, Singapore; [Ng, Tian-Tsong] Inst Infocomm Res, Singapore 138632, Singapore; [Koenig, Bryan Lee] Southern Utah Univ, Dept Psychol, Cedar City, UT 84720 USA; [Herberg, Jonathan Samuel] Natl Univ Singapore, Dept Psychol, Singapore 117583, Singapore; [Herberg, Jonathan Samuel] Inst High Performance Comp, Singapore 138632, Singapore; [Jiang, Ming; Shen, Zhiqi] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Jiang, Ming; Shen, Zhiqi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore	National University of Singapore; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Utah System of Higher Education; Southern Utah University; National University of Singapore; Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); University of Minnesota System; University of Minnesota Twin Cities; National University of Singapore	Zhao, Q (corresponding author), Natl Univ Singapore, Smart Syst Inst, Singapore 119613, Singapore.	idmfs@nus.edu.sg; ttng@i2r.a-star.edu.sg; bryanleekoenig@gmail.com; jonathan.herberg@gmail.com; mjiang@umn.edu; idmshenz@nus.edu.sg; qzhao@cs.umn.edu	Fan, Shaojing/AAG-3168-2019; Jiang, Ming/I-1536-2016	Fan, Shaojing/0000-0002-7744-1133; Jiang, Ming/0000-0001-6439-5476; Shen, Zhiqi/0000-0003-4495-9697; Ng, Tian Tsong/0000-0002-6713-2310	National Research Foundation, Prime Minister's Office, Singapore under its International Research Centre in Singapore Funding Initiative; University of Minnesota Department of Computer Science and Engineering Start-up Fund	National Research Foundation, Prime Minister's Office, Singapore under its International Research Centre in Singapore Funding Initiative(National Research Foundation, Singapore); University of Minnesota Department of Computer Science and Engineering Start-up Fund	We thank Qi Shan and his colleagues from University of Washington for sharing their dataset. We thank following people for their contribution to this work in one way or another: Dr. Cheston Y.-C Tan, Mr. Karianto Leman, Mr. Zhang Fan, Dr. Chu Xinqi, Dr. Wang Hee Lin, Prof. Liu Zhen, and all the reviewers for our previous papers on this topic. This research is supported by the National Research Foundation, Prime Minister's Office, Singapore under its International Research Centre in Singapore Funding Initiative, and a University of Minnesota Department of Computer Science and Engineering Start-up Fund (QZ).	Abadi M, 2015, P 12 USENIX S OPERAT; [Anonymous], 2017, HUMAN PERCEPTION IMA; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Aydin TO, 2015, IEEE T VIS COMPUT GR, V21, P31, DOI 10.1109/TVCG.2014.2325047; Bailey R. A., 2008, DESIGN COMP EXPT, V25; Bainbridge WA, 2017, NEUROIMAGE, V149, P141, DOI 10.1016/j.neuroimage.2017.01.063; Barron C., 1998, P ACM SIGGRAPH C ABS; Bernstein MJ, 2007, PSYCHOL SCI, V18, P706, DOI 10.1111/j.1467-9280.2007.01964.x; Borth Damian, 2013, ACM MM; BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605; Bradley M.M., 2007, HDB EMOTION ELICITAT, P29; Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Bukach CM, 2006, TRENDS COGN SCI, V10, P159, DOI 10.1016/j.tics.2006.02.004; Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005; Cadik M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366166; Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cho TS, 2012, IEEE T PATTERN ANAL, V34, P683, DOI 10.1109/TPAMI.2011.166; Choi SY, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.031104; Chollet F., 2015, KERAS; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Debevec Paul., 2008, ACM SIGGRAPH 2008 CL, P1; Dirik E., 2007, P IEEE INT C IM PROC; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; Fan S., 2012, SIGGRAPH ASIA 2012 T, P17; Fan SJ, 2016, PROC CVPR IEEE, P5762, DOI 10.1109/CVPR.2016.621; Fan SJ, 2014, PROC CVPR IEEE, P4201, DOI 10.1109/CVPR.2014.535; Fan SJ, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2620030; Farid H, 2012, DIGIT INVEST, V8, P226, DOI 10.1016/j.diin.2011.06.003; Farid Hany, 2003, 2003 C COMPUTER VISI, V8, P94, DOI DOI 10.1109/CVPRW.2003.10093; Ferwerda JA, 2003, PROC SPIE, V5007, P290, DOI 10.1117/12.473899; Gauthier I, 1997, VISION RES, V37, P1673, DOI 10.1016/S0042-6989(96)00286-6; Giard F, 2010, COMPUT HUM BEHAV, V26, P1748, DOI 10.1016/j.chb.2010.07.001; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Gygli M, 2013, IEEE I CONF COMP VIS, P1633, DOI 10.1109/ICCV.2013.205; HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747; Haykin S., 2004, NEURAL NETWORKS, V2, P41, DOI DOI 10.5555/541500; Hu TM, 2003, PATTERN RECOGN LETT, V24, P3059, DOI 10.1016/S0167-8655(03)00165-X; Hung CH, 2015, IEEE WINT CONF APPL, P302, DOI 10.1109/WACV.2015.47; Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200; Jakob W, 2014, ACM T GRAPHIC, V33, P1; Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283; Kao YY, 2017, IEEE T IMAGE PROCESS, V26, P1482, DOI 10.1109/TIP.2017.2651399; Ke Yan, 2006, 2006 IEEE COMPUTER S, V1, P419, DOI DOI 10.1109/CVPR.2006.303; Kee E, 2011, P NATL ACAD SCI USA, V108, P19907, DOI 10.1073/pnas.1110747108; Khosla A, 2012, ADV NEURAL INFORM PR, P296; Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275; Kirk, 2013, CONTENT BASED IMAGE; Kline R.B., 2011, PRINCIPLES PRACTICE; Lalonde JF, 2007, IEEE I CONF COMP VIS, P2181; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109; Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896; Ma S., 2017, ARXIV170400248; Machajdik J., 2010, P ACM INT C MULTIMED, P83, DOI DOI 10.1145/1873951.1873965; Mader B, 2017, PERCEPTION, V46, P1062, DOI 10.1177/0301006617713633; Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151; McKeeff TJ, 2010, COGNITION, V117, P355, DOI 10.1016/j.cognition.2010.09.002; McNamara A., 2005, P 2 S APPL PERC GRAP, P123; Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3; MEYER GW, 1986, ACM T GRAPHIC, V5, P30, DOI 10.1145/7529.7920; Michel C, 2006, PSYCHOL SCI, V17, P608, DOI 10.1111/j.1467-9280.2006.01752.x; Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732; Moon B., 2014, ACM T GRAPHIC, V33, P5; Myers L., 2006, SPEARMAN CORRELATION; Natu V, 2011, NEUROIMAGE, V54, P2547, DOI 10.1016/j.neuroimage.2010.10.006; Ng T. -T., 2004, 20320043 COL U US; Ng T. -T., 2005, 20520045 COL U US; Ng T. -T., 2013, DIGITAL IMAGE FORENS; NG TT, 2005, P 13 ANN ACM INT C M, P239; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rademacher P, 2001, SPRING EUROGRAP, P235; Ramanarayanan G, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276472, 10.1145/1239451.1239527]; Rossion B, 2002, PSYCHOL SCI, V13, P250, DOI 10.1111/1467-9280.00446; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shan Q, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P25, DOI 10.1109/3DV.2013.12; Shechtman E, 2007, PROC CVPR IEEE, P1744; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; van de Weijer J, 2007, PROC CVPR IEEE, P1898; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang C., 2004, P EUR PAR GRAPH VIS, P23; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wickens T. D., 2001, ELEMENTARY SIGNAL DE; Zhu JY, 2015, IEEE I CONF COMP VIS, P3943, DOI 10.1109/ICCV.2015.449	91	10	11	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2180	2193		10.1109/TPAMI.2017.2747150	http://dx.doi.org/10.1109/TPAMI.2017.2747150			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	GP4UX	28866484				2022-12-18	WOS:000440868400011
J	Wang, Y; Wan, JW; Guo, J; Cheung, YM; Yuen, PC				Wang, Yi; Wan, Jianwu; Guo, Jun; Cheung, Yiu-Ming; Yuen, Pong C.			Inference-Based Similarity Search in Randomized Montgomery Domains for Privacy-Preserving Biometric Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometric identification; privacy protection; nearest neighbour search; hypothesis testing; multi-index hashing	NEAREST-NEIGHBOR; RECOGNITION; PROTECTION; ALGORITHMS	Similarity search is essential to many important applications and often involves searching at scale on high-dimensional data based on their similarity to a query. In biometric applications, recent vulnerability studies have shown that adversarial machine learning can compromise biometric recognition systems by exploiting the biometric similarity information. Existing methods for biometric privacy protection are in general based on pairwise matching of secured biometric templates and have inherent limitations in search efficiency and scalability. In this paper, we propose an inference-based framework for privacy-preserving similarity search in Hamming space. Our approach builds on an obfuscated distance measure that can conceal Hamming distance in a dynamic interval. Such a mechanism enables us to systematically design statistically reliable methods for retrieving most likely candidates without knowing the exact distance values. We further propose to apply Montgomery multiplication for generating search indexes that can withstand adversarial similarity analysis, and show that information leakage in randomized Montgomery domains can be made negligibly small. Our experiments on public biometric datasets demonstrate that the inference-based approach can achieve a search accuracy close to the best performance possible with secure computation methods, but the associated cost is reduced by orders of magnitude compared to cryptographic primitives.	[Wang, Yi; Guo, Jun] Dongguan Univ Technol, Sch Comp Sci & Network Secur, Dongguan 523808, Peoples R China; [Wan, Jianwu] Changzhou Univ, Dept Comp Sci, Changzhou 213164, Peoples R China; [Cheung, Yiu-Ming; Yuen, Pong C.] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Dongguan University of Technology; Changzhou University; Hong Kong Baptist University	Guo, J (corresponding author), Dongguan Univ Technol, Sch Comp Sci & Network Secur, Dongguan 523808, Peoples R China.	wangyi@dgut.edu.cn; jianwuwan@gmail.com; guojun@dgut.edu.cn; ymc@comp.hkbu.edu.hk; pcyuen@comp.hkbu.edu.hk	wan, jianwu/ABF-7445-2020; Cheung, Yiu-ming/E-2050-2015; Wang, Yi Alice/L-8254-2016	wan, jianwu/0000-0002-4637-1515; Cheung, Yiu-ming/0000-0001-7629-4648; Wang, Yi Alice/0000-0002-8448-8570; Yuen, Pong Chi/0000-0002-9343-2202	Research Grants Council of Hong Kong [HKBU12202214]; National Natural Science Foundation of China [61403324, 61502058]	Research Grants Council of Hong Kong(Hong Kong Research Grants Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors wish to thank the anonymous reviewers for their valuable comments that contributed to the improved quality of this paper. This work is supported by the Research Grants Council of Hong Kong (HKBU12202214) and the National Natural Science Foundation of China (61403324 and 61502058). Most of the work was done while Y. Wang was with Hong Kong Baptist University.	Aghasaryan A, 2014, BELL LABS TECH J, V18, P33, DOI 10.1002/bltj.21644; Aghasaryan A, 2013, IEEE INT CONF TRUST, P362, DOI 10.1109/TrustCom.2013.46; Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; [Anonymous], 2016, HLTHCARE IT NEWS; [Anonymous], 2016, INDIAN BANK INTRO AA; Bakken DE, 2004, IEEE SECUR PRIV, V2, P34, DOI 10.1109/MSP.2004.97; Barni M, 2015, IEEE SIGNAL PROC MAG, V32, P66, DOI 10.1109/MSP.2015.2438131; Biggio B, 2017, IEEE T PATTERN ANAL, V39, P561, DOI 10.1109/TPAMI.2016.2558154; Biggio B, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2015.2426728; Boult T. E., 2007, 2007 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2007.383110; Bringer J., 2015, BIOMETRIC SECURITY, P312; Bringer J, 2013, IEEE SIGNAL PROC MAG, V30, P42, DOI 10.1109/MSP.2012.2230218; Cavoukian A., 2014, PRIVACY DESIGN SOLUT; Cover TM, 2006, ELEMENTS INFORM THEO; Crandall R., 2001, PRIME NUMBERS COMPUT; Galbally J, 2010, PATTERN RECOGN, V43, P1027, DOI 10.1016/j.patcog.2009.08.022; Gertz M, 2008, HDB DATABASE SECURIT; Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025; Hromkovic J., 2005, DESIGN ANAL RANDOMIZ; Jimenez A., 2015, P 53 AER SCI M AIAA, P1; Kawulok M., 2016, ADV FACE DETECTION F, P189, DOI DOI 10.1007/978-3-319-25958-1_8; Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653; Lei Z., 2014, LEARNING FACE REPRES; Li M, 2012, IEEE INT WORKSH MULT, P1, DOI 10.1109/MMSP.2012.6343406; Lim MH, 2013, IEEE T PATTERN ANAL, V35, P300, DOI 10.1109/TPAMI.2012.122; Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359; Lu WJ, 2014, IEEE ACCESS, V2, P125, DOI 10.1109/ACCESS.2014.2307057; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849; Norouzi M, 2014, IEEE T PATTERN ANAL, V36, P1107, DOI 10.1109/TPAMI.2013.231; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Poor, 2013, INTRO SIGNAL DETECTI; Rane S, 2013, IEEE SIGNAL PROC MAG, V30, P51, DOI 10.1109/MSP.2013.2261691; Rane S, 2013, IEEE SIGNAL PROC MAG, V30, P18, DOI 10.1109/MSP.2012.2230221; Rice JA., 2007, MATH STAT METASTATIS; Rodrigues RN, 2009, J VISUAL LANG COMPUT, V20, P169, DOI 10.1016/j.jvlc.2009.01.010; Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166; Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003; Wang Y, 2015, IEEE T INF FOREN SEC, V10, P1603, DOI 10.1109/TIFS.2015.2421332; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P72, DOI 10.1109/TPAMI.2010.73; Weng L, 2016, IEEE T KNOWL DATA EN, V28, P2738, DOI 10.1109/TKDE.2016.2587258; Weng L, 2015, IEEE T INF FOREN SEC, V10, P152, DOI 10.1109/TIFS.2014.2365998; Wu X, 2015, ARXIV150704844	46	10	11	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1611	1624		10.1109/TPAMI.2017.2727048	http://dx.doi.org/10.1109/TPAMI.2017.2727048			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28715325	Green Submitted			2022-12-18	WOS:000434294800006
J	Liao, W; Worz, S; Kang, CK; Cho, ZH; Rohr, K				Liao, Wei; Woerz, Stefan; Kang, Chang-Ki; Cho, Zang-Hee; Rohr, Karl			Progressive Minimal Path Method for Segmentation of 2D and 3D Line Structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Minimal paths; fast marching; dynamic speed function; segmentation of line structures; object detection	OBJECT SEGMENTATION; VESSELS; QUANTIFICATION; EXTRACTION; IMAGES	We propose a novel minimal path method for the segmentation of 2D and 3D line structures. Minimal path methods perform propagation of a wavefront emanating from a start point at a speed derived from image features, followed by path extraction using backtracing. Usually, the computation of the speed and the propagation of the wave are two separate steps, and point features are used to compute a static speed. We introduce a new continuous minimal path method which steers the wave propagation progressively using dynamic speed based on path features. We present three instances of our method, using an appearance feature of the path, a geometric feature based on the curvature of the path, and a joint appearance and geometric feature based on the tangent of the wavefront. These features have not been used in previous continuous minimal path methods. We compute the features dynamically during the wave propagation, and also efficiently using a fast numerical scheme and a low-dimensional parameter space. Our method does not suffer from discretization or metrication errors. We performed qualitative and quantitative evaluations using 2D and 3D images from different application areas.	[Liao, Wei; Woerz, Stefan; Rohr, Karl] Heidelberg Univ, BIOQUANT, Biomed Comp Vis Grp, Dept Bioinformat & Funct Genom, D-69120 Heidelberg, Germany; [Liao, Wei; Woerz, Stefan; Rohr, Karl] Heidelberg Univ, IPMB, D-69120 Heidelberg, Germany; [Kang, Chang-Ki] Gachon Univ, Neurosci Res Inst, 1198 Kuwol Dong, Incheon 405760, South Korea; [Kang, Chang-Ki] Gachon Univ, Dept Radiol Sci, 1198 Kuwol Dong, Incheon 405760, South Korea; [Cho, Zang-Hee] Seoul Natl Univ, Adv Inst Convergence Technol, 864-1 Iui Dong, Suwon 443270, Gyeonggi Do, South Korea	Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Gachon University; Gachon University; Seoul National University (SNU)	Liao, W (corresponding author), Heidelberg Univ, BIOQUANT, Biomed Comp Vis Grp, Dept Bioinformat & Funct Genom, D-69120 Heidelberg, Germany.; Liao, W (corresponding author), Heidelberg Univ, IPMB, D-69120 Heidelberg, Germany.	liaowei.post@gmail.com; s.woerz@dkfz.de; changkik@gmail.com; zcho@gachon.ac.kr; k.rohr@dkfz.de			Deutsche Forschungsgemeinschaft (DFG) [RO 2471/6, RTG 1653]; Helmholtz Association (SMHB)	Deutsche Forschungsgemeinschaft (DFG)(German Research Foundation (DFG)); Helmholtz Association (SMHB)	Support of the Deutsche Forschungsgemeinschaft (DFG) (QuantVessel (RO 2471/6), RTG 1653) and the Helmholtz Association (SMHB) is gratefully acknowledged. We also thank Artjom Zern for discussions.	Benmansour F, 2011, INT J COMPUT VISION, V92, P192, DOI 10.1007/s11263-010-0331-0; Benmansour F, 2009, J MATH IMAGING VIS, V33, P209, DOI 10.1007/s10851-008-0131-0; Chen D, 2014, IEEE IMAGE PROC, P1570, DOI 10.1109/ICIP.2014.7025314; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Deschamps T., 2002, INT C PATT REC QUEB; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178; Jbabdi S, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/320195; Joshi VS, 2011, I S BIOMED IMAGING, P1416, DOI 10.1109/ISBI.2011.5872665; Kaul V, 2012, IEEE T PATTERN ANAL, V34, P1952, DOI 10.1109/TPAMI.2011.267; Krueger M, 2013, PATTERN RECOGN LETT, V34, P833, DOI 10.1016/j.patrec.2012.12.017; Law MWK, 2008, LECT NOTES COMPUT SC, V5305, P368, DOI 10.1007/978-3-540-88693-8_27; Li H, 2007, IEEE T MED IMAGING, V26, P1213, DOI 10.1109/TMI.2007.903696; Liao W., 2012, P 11 AS C COMP VIS N, P25; Liao W, 2016, IEEE T IMAGE PROCESS, V25, P400, DOI 10.1109/TIP.2015.2499085; Liao W, 2013, LECT NOTES COMPUT SC, V8149, P550, DOI 10.1007/978-3-642-40811-3_69; Liao W, 2012, PROC SPIE, V8314, DOI 10.1117/12.911483; Lin Q., 2003, THESIS; Lo P, 2010, I S BIOMED IMAGING, P680, DOI 10.1109/ISBI.2010.5490083; Mirebeau JM, 2014, SIAM J NUMER ANAL, V52, P1573, DOI 10.1137/120861667; Mirebeau JM, 2014, NUMER MATH, V126, P515, DOI 10.1007/s00211-013-0571-3; Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16; Parker GJM, 2002, IEEE T MED IMAGING, V21, P505, DOI 10.1109/TMI.2002.1009386; Pechaud M, 2009, PROC CVPR IEEE, P336, DOI 10.1109/CVPRW.2009.5206782; Poon K, 2007, LECT NOTES COMPUT SC, V4792, P444; Rempfler M, 2014, LECT NOTES COMPUT SC, V8674, P505, DOI 10.1007/978-3-319-10470-6_63; Sato Y, 1998, Med Image Anal, V2, P143, DOI 10.1016/S1361-8415(98)80009-1; Schoenemann T, 2011, IEEE T IMAGE PROCESS, V20, P2565, DOI 10.1109/TIP.2011.2118225; Sethian JA, 2000, P NATL ACAD SCI USA, V97, P5699, DOI 10.1073/pnas.090060097; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Sironi A, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2462363; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Stawiaski J, 2011, LECT NOTES COMPUT SC, V6671, P417, DOI 10.1007/978-3-642-21569-8_36; Stuhmer J, 2013, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2013.290; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; Turetken E, 2016, IEEE T PATTERN ANAL, V38, P2515, DOI 10.1109/TPAMI.2016.2519025; Ulen J, 2015, IEEE T PATTERN ANAL, V37, P2588, DOI 10.1109/TPAMI.2015.2409869; Worz S, 2007, IEEE T IMAGE PROCESS, V16, P1994, DOI 10.1109/TIP.2007.901204; Yatziv L, 2006, J COMPUT PHYS, V212, P393, DOI 10.1016/j.jcp.2005.08.005; [No title captured]	41	10	10	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					696	709		10.1109/TPAMI.2017.2691709	http://dx.doi.org/10.1109/TPAMI.2017.2691709			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28410097				2022-12-18	WOS:000424465900014
J	Moschini, U; Meijster, A; Wilkinson, MHF				Moschini, Ugo; Meijster, Arnold; Wilkinson, Michael H. F.			A Hybrid Shared-Memory Parallel Max-Tree Algorithm for Extreme Dynamic-Range Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Connected filters; hierarchical image representation; parallel algorithms	OPENINGS	Max-trees, or component trees, are graph structures that represent the connected components of an image in a hierarchical way. Nowadays, many application fields rely on images with high-dynamic range or floating point values. Efficient sequential algorithms exist to build trees and compute attributes for images of any bit depth. However, we show that the current parallel algorithms perform poorly already with integers at bit depths higher than 16 bits per pixel. We propose a parallel method combining the two worlds of flooding and merging max-tree algorithms. First, a pilot max-tree of a quantized version of the image is built in parallel using a flooding method. Later, this structure is used in a parallel leaf-to-root approach to compute efficiently the final max-tree and to drive the merging of the sub-trees computed by the threads. We present an analysis of the performance both on simulated and actual 2D images and 3D volumes. Execution times are about 20 x better than the fastest sequential algorithm and speed-up goes up to 30-40 on 64 threads.	[Moschini, Ugo; Meijster, Arnold; Wilkinson, Michael H. F.] Univ Groningen, Johann Bernoulli Inst, POB 407, NL-9700 AK Groningen, Netherlands	University of Groningen	Moschini, U (corresponding author), Univ Groningen, Johann Bernoulli Inst, POB 407, NL-9700 AK Groningen, Netherlands.	lu.moschini@rug.nl; a.meijstern@rug.nl; m.h.f.wilkinson@rug.nl	Moschini, Ugo/M-1725-2019; Moschini, Ugo/W-6648-2019; Wilkinson, Michael/Q-2847-2019; Wilkinson, Michael H.F./C-2386-2009; Wilkinson, Michael/AAA-8471-2020	Moschini, Ugo/0000-0002-8006-6039; Wilkinson, Michael/0000-0001-6258-1128; Wilkinson, Michael H.F./0000-0001-6258-1128; 	Netherlands Organisation for Scientific Research (NWO) [612.001.110]	Netherlands Organisation for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO))	This work was funded by the Netherlands Organisation for Scientific Research (NWO) under project number 612.001.110. The authors would like to thank Prof. A. Ger de Bruyn for making the LOFAR dataset available.	Amato N., 1998, 98029 TEX A M U COLL; Berger Ch, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P41; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Carlinet Edwin, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P73, DOI 10.1007/978-3-642-38294-9_7; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Ha L, 2009, COMPUT GRAPH FORUM, V28, P2368, DOI 10.1111/j.1467-8659.2009.01542.x; HERF M, 2001, RADIX TRICKS; Hesselink WH, 2003, INFORM PROCESS LETT, V88, P225, DOI 10.1016/j.ipl.2003.08.003; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; Lengyel E., 2011, GAME ENGINE GEMS, V2; Masias M, 2012, MON NOT R ASTRON SOC, V422, P1674, DOI 10.1111/j.1365-2966.2012.20742.x; Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556; Moschini U, 2014, P 2014 C BIG DAT SPA, P232; Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518; Ouzounis G., 2012, ALPHA TREE ALGORITHM; Ouzounis GK, 2007, IEEE T PATTERN ANAL, V29, P990, DOI 10.1109/TPAMI.2007.1045; Ouzounis GK, 2011, IEEE T PATTERN ANAL, V33, P224, DOI 10.1109/TPAMI.2010.74; Perret B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4089, DOI 10.1109/ICPR.2010.994; Pesaresi M, 2013, IEEE J-STARS, V6, P2102, DOI 10.1109/JSTARS.2013.2271445; Rashid L, 2010, J SUPERCOMPUT, V53, P293, DOI 10.1007/s11227-009-0294-5; Saito RK, 2012, ASTRON ASTROPHYS, V544, DOI 10.1051/0004-6361/201219448; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Serra P, 2012, PUBL ASTRON SOC AUST, V29, P296, DOI 10.1071/AS11065; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; Teeninga P, 2015, LECT NOTES COMPUT SC, V9082, P157, DOI 10.1007/978-3-319-18720-4_14; Terdiman P, 2000, RADIX SORT REVISITED; Urbach ER, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P305; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Westenberg MA, 2007, IEEE T IMAGE PROCESS, V16, P2943, DOI 10.1109/TIP.2007.909317; Wilkinson M. H. F., 2011, P 18 IEEE INT C IM P, P1041; Wilkinson M. H. F., 2012, P ESA EUSC JRC 8 C I, P21; Wilkinson MHF, 2008, IEEE T PATTERN ANAL, V30, P1800, DOI 10.1109/TPAMI.2007.70836; Wilkinson MHF, 2011, LECT NOTES COMPUT SC, V6671, P331, DOI 10.1007/978-3-642-21569-8_29; Xu YC, 2016, IEEE T PATTERN ANAL, V38, P1126, DOI 10.1109/TPAMI.2015.2441070	35	10	11	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					513	526		10.1109/TPAMI.2017.2689765	http://dx.doi.org/10.1109/TPAMI.2017.2689765			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28371773	Green Submitted			2022-12-18	WOS:000424465900001
J	Bekkers, EJ; Loog, M; Romeny, BMT; Duits, R				Bekkers, Erik Johannes; Loog, Marco; Romeny, Bart M. ter Haar; Duits, Remco			Template Matching via Densities on the Roto-Translation Group	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Template matching; multi-orientation; invertible orientation scores; optic nerve head; fovea; retina	DIGITAL FUNDUS IMAGES; OPTIC DISC DETECTION; RETINAL IMAGES; LOCALIZATION; REGRESSION; EYE; REGULARIZATION; SEGMENTATION; SIGNAL	We propose a template matching method for the detection of 2D image objects that are characterized by orientation patterns. Our method is based on data representations via orientation scores, which are functions on the space of positions and orientations, and which are obtained via a wavelet-type transform. This new representation allows us to detect orientation patterns in an intuitive and direct way, namely via cross-correlations. Additionally, we propose a generalized linear regression framework for the construction of suitable templates using smoothing splines. Here, it is important to recognize a curved geometry on the position-orientation domain, which we identify with the Lie group SE(2): the roto-translation group. Templates are then optimized in a B-spline basis, and smoothness is defined with respect to the curved geometry. We achieve state-of-the-art results on three different applications: detection of the optic nerve head in the retina (99.83 percent success rate on 1,737 images), of the fovea in the retina (99.32 percent success rate on 1,616 images), and of the pupil in regular camera images (95.86 percent on 1,521 images). The high performance is due to inclusion of both intensity and orientation features with effective geometric priors in the template matching. Moreover, our method is fast due to a cross-correlation based matching approach.	[Bekkers, Erik Johannes; Romeny, Bart M. ter Haar; Duits, Remco] Eindhoven Univ Technol, Dept Biomed Engn, NL-5612 AZ Eindhoven, Netherlands; [Loog, Marco] Delft Univ Technol, Pattern Recognit Lab, NL-2628 CD Delft, Netherlands; [Romeny, Bart M. ter Haar] Northeastern Univ, Dept Biomed & Informat Engn, Shenyang 110004, Liaoning, Peoples R China; [Duits, Remco] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands	Eindhoven University of Technology; Delft University of Technology; Northeastern University - China; Eindhoven University of Technology	Bekkers, EJ (corresponding author), Eindhoven Univ Technol, Dept Biomed Engn, NL-5612 AZ Eindhoven, Netherlands.	e.j.bekkers@tue.nl; m.loog@tudelft.nl; b.m.terhaarromeny@tue.nl; r.duits@tue.nl	Romenij, Bart M. ter Haar/A-5323-2013	ter Haar Romeny, Bart/0000-0003-3442-3207	European Research Council under the European Community's 7th Framework Programme/ERC [335555]; Netherlands Organisation for Scientific Research (NWO)	European Research Council under the European Community's 7th Framework Programme/ERC; Netherlands Organisation for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO))	The authors would like to thank: the groups that kindly made available the benchmark datasets and annotations; Gonzalo Sanguinetti (TU/e) for fruitful discussions and feedback on this manuscript; and the anonymous reviewers for their very valuable suggestions and comments. The research leading to the results of this article has received funding from the European Research Council under the European Community's 7th Framework Programme (FP7/2007-2014)/ERC grant agreement No. 335555. This work is also part of the He Programme of Innovation Cooperation, which is (partly) financed by the Netherlands Organisation for Scientific Research (NWO).	Abramoff M.D., 2014, TELEOPHTHALMOL PREV, P41; [Anonymous], 1993, NONPARAMETRIC REGRES; Aquino A., 2012, INT J BIOL LIFE SCI, V8, P87; Aquino A, 2014, COMPUT BIOL MED, V55, P61, DOI 10.1016/j.compbiomed.2014.10.007; Aquino A, 2010, IEEE T MED IMAGING, V29, P1860, DOI 10.1109/TMI.2010.2053042; Asteriadis S, 2009, PATTERN RECOGN, V42, P1388, DOI 10.1016/j.patcog.2009.01.009; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bekkers E, 2015, LECT NOTES COMPUT SC, V8932, P464, DOI 10.1007/978-3-319-14612-6_34; Bekkers E, 2014, LECT NOTES COMPUT SC, V8815, P293, DOI 10.1007/978-3-319-11755-3_33; Bekkers E, 2014, J MATH IMAGING VIS, V49, P583, DOI 10.1007/s10851-013-0488-6; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Campadelli P, 2009, INT J PATTERN RECOGN, V23, P359, DOI 10.1142/S0218001409007259; Citti G, 2006, J MATH IMAGING VIS, V24, P307, DOI 10.1007/s10851-005-3630-2; Craven P., 1979, Numerische Mathematik, V31, P377, DOI 10.1007/BF01404567; Cuingnet R, 2013, IEEE T PATTERN ANAL, V35, P682, DOI 10.1109/TPAMI.2012.142; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dashtbozorg B, 2015, COMPUT BIOL MED, V56, P1, DOI 10.1016/j.compbiomed.2014.10.009; De Boor C, 1978, MATH COMPUT; Dong XA, 1996, STAT SINICA, V6, P675; Duits R., 2007, Pattern Recognition and Image Analysis, V17, P42, DOI 10.1134/S1054661807010063; Duits R, 2007, LECT NOTES COMPUT SC, V4485, P300; Duits R, 2007, INT J COMPUT VISION, V72, P79, DOI 10.1007/s11263-006-8894-5; Duits R, 2010, Q APPL MATH, V68, P255, DOI 10.1090/S0033-569X-10-01172-0; Fletcher PT, 2013, INT J COMPUT VISION, V105, P171, DOI 10.1007/s11263-012-0591-y; Foracchia M, 2005, MED IMAGE ANAL, V9, P179, DOI 10.1016/j.media.2004.07.001; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Gegundez-Arias ME, 2013, COMPUT MED IMAG GRAP, V37, P386, DOI 10.1016/j.compmedimag.2013.06.002; Giachetti A, 2013, COMPUT MED IMAG GRAP, V37, P369, DOI 10.1016/j.compmedimag.2013.06.005; Gu C., 1992, J COMPUT GRAPH STAT, V1, P169, DOI [10.1080/10618600.1992.10477012, DOI 10.1080/10618600.1992.10477012, DOI 10.2307/1390840]; Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30; Hebiri M, 2011, ELECTRON J STAT, V5, P1184, DOI 10.1214/11-EJS638; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634; KROON B., 2008, P 2008 INT C CONT BA, P379; Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829; Li CY, 2008, BIOINFORMATICS, V24, P1175, DOI 10.1093/bioinformatics/btn081; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lu SJ, 2011, IEEE T MED IMAGING, V30, P2126, DOI 10.1109/TMI.2011.2164261; Lu SJ, 2011, IEEE T BIO-MED ENG, V58, P88, DOI 10.1109/TBME.2010.2086455; Marin D, 2015, COMPUT METH PROG BIO, V118, P173, DOI 10.1016/j.cmpb.2014.11.003; Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008; Miolane N., 2015, P INT MICCAI WORKSH, P155; Niemeijer M, 2009, MED IMAGE ANAL, V13, P859, DOI 10.1016/j.media.2009.08.003; OSULLIVAN F, 1986, J AM STAT ASSOC, V81, P96, DOI 10.2307/2287973; Patton N, 2006, PROG RETIN EYE RES, V25, P99, DOI 10.1016/j.preteyeres.2005.07.001; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Qazi AA, 2010, MED IMAGE ANAL, V14, P255, DOI 10.1016/j.media.2010.01.004; Ramakanth SA, 2014, COMPUT MED IMAG GRAP, V38, P49, DOI 10.1016/j.compmedimag.2013.10.007; Sekhar S, 2011, APPL OPTICS, V50, P3064, DOI 10.1364/AO.50.003064; Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125; Tuzel O., 2008, P IEEE C COMP VIS PA, P1; UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220; Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930; Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Xu H, 2009, J MACH LEARN RES, V10, P1485; Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]; Youssif AAHAR, 2008, IEEE T MED IMAGING, V27, P11, DOI 10.1109/TMI.2007.900326; Yu H, 2012, IEEE T INF TECHNOL B, V16, P644, DOI 10.1109/TITB.2012.2198668; Yu H, 2011, PROC SPIE, V7963, DOI 10.1117/12.878145; Zhang J, 2016, INT J OPHTHALMOL-CHI, V9, P1, DOI 10.18240/ijo.2016.01.01	62	10	10	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					452	466		10.1109/TPAMI.2017.2652452	http://dx.doi.org/10.1109/TPAMI.2017.2652452			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28252390	Green Submitted			2022-12-18	WOS:000422706000014
J	Clement, M; Poulenard, A; Kurtz, C; Wendling, L				Clement, Michael; Poulenard, Adrien; Kurtz, Camille; Wendling, Laurent			Directional Enlacement Histograms for the Description of Complex Spatial Configurations between Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Enlacement histograms; interlacement histograms; relative position descriptors; spatial relations; image understanding	BLOOD-VESSEL SEGMENTATION; RELATIVE POSITION; IMAGES; REPRESENTATION; RECOGNITION; DEFINITION; COLOR	The analysis of spatial relations between objects in digital images plays a crucial role in various application domains related to pattern recognition and computer vision. Classical models for the evaluation of such relations are usually sufficient for the handling of simple objects, but can lead to ambiguous results in more complex situations. In this article, we investigate the modeling of spatial configurations where the objects can be imbricated in each other. We formalize this notion with the term enlacement, from which we also derive the term interlacement, denoting a mutual enlacement of two objects. Our main contribution is the proposition of new relative position descriptors designed to capture the enlacement and interlacement between two-dimensional objects. These descriptors take the form of circular histograms allowing to characterize spatial configurations with directional granularity, and they highlight useful invariance properties for typical image understanding applications. We also show how these descriptors can be used to evaluate different complex spatial relations, such as the surrounding of objects. Experimental results obtained in the different application domains of medical imaging, document image analysis and remote sensing, confirm the genericity of this approach.	[Clement, Michael; Poulenard, Adrien; Kurtz, Camille; Wendling, Laurent] Univ Paris 05, LIPADE SIP, F-75006 Paris, France	UDICE-French Research Universities; Universite Paris Cite	Clement, M (corresponding author), Univ Paris 05, LIPADE SIP, F-75006 Paris, France.	michael.clement@parisdescartes.fr; dxp789@hotmail.fr; camille.kurtz@parisdescartes.fr; laurent.wendling@parisdescartes.fr		KURTZ, Camille/0000-0001-9254-7537				Abramoff MD, 2010, OPHTHALMOLOGY, V117, P1147, DOI 10.1016/j.ophtha.2010.03.046; ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Baatz M., 2000, MULTIRESOLUTION SEGM, VXII, P12, DOI DOI 10.1016/J.ISPRSJPRS.2003.10.002; Bloch I, 1999, IEEE T PATTERN ANAL, V21, P657, DOI 10.1109/34.777378; Bloch I, 2005, IMAGE VISION COMPUT, V23, P89, DOI 10.1016/j.imavis.2004.06.013; Bloch I, 2003, PATTERN RECOGN, V36, P1563, DOI 10.1016/S0031-3203(02)00263-7; Bloch I, 2006, IEEE T SYST MAN CY B, V36, P312, DOI 10.1109/TSMCB.2005.857095; Bloch I, 2015, FUZZY SET SYST, V281, P280, DOI 10.1016/j.fss.2015.06.017; Buck AR, 2013, IEEE T EVOLUT COMPUT, V17, P588, DOI 10.1109/TEVC.2012.2226889; Cesar R, 2002, INT C PATT RECOG, P465, DOI 10.1109/ICPR.2002.1048339; Clement Michael, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P427; Colliot O, 2006, PATTERN RECOGN, V39, P1401, DOI 10.1016/j.patcog.2006.02.022; Coustaty M, 2011, INT J DOC ANAL RECOG, V14, P243, DOI 10.1007/s10032-011-0152-x; Delaye A, 2014, INT J DATA MIN MODEL, V6, P127, DOI 10.1504/IJDMMM.2014.063194; DUBOIS D, 1988, FUZZY SET SYST, V28, P313, DOI 10.1016/0165-0114(88)90038-3; Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277; Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687; Freeman J., 1975, COMPUT VISION GRAPH, V4, P156, DOI [DOI 10.1016/S0146-664X(75)80007-4, 10.1016/S0146-664X(75)80007-4]; Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311; Kurtz C, 2012, PATTERN RECOGN, V45, P685, DOI 10.1016/j.patcog.2011.07.017; Lomenie N, 2012, PATTERN RECOGN, V45, P2894, DOI 10.1016/j.patcog.2012.01.021; Marr D., 1982, VISION COMPUTATIONAL; Matsakis P, 1999, IEEE T PATTERN ANAL, V21, P634, DOI 10.1109/34.777374; Matsakis P, 2004, IEEE T PATTERN ANAL, V26, P1, DOI 10.1109/TPAMI.2004.1261075; Matsakis P, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P1596, DOI 10.1109/FUZZ.2002.1006745; Matsakis P, 2001, IEEE T SYST MAN CY B, V31, P573, DOI 10.1109/3477.938261; Matsakis P., 2015, INT C PATT REC APPL, P87; Matsakis P, 2010, STUD FUZZ SOFT COMP, V256, P49; MCNAMARA TP, 1986, COGNITIVE PSYCHOL, V18, P87, DOI 10.1016/0010-0285(86)90016-2; MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3; Naeem M., 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P286; Ni JB, 2010, PATTERN RECOGN, V43, P1607, DOI 10.1016/j.patcog.2009.09.020; Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455; ROSENFELD A, 1985, PATTERN RECOGN, V18, P169, DOI 10.1016/0031-3203(85)90041-X; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Tabbone S, 2003, IMAGE VISION COMPUT, V21, P483, DOI 10.1016/S0262-8856(03)00016-7; Takemura CM, 2012, PATTERN RECOGN, V45, P757, DOI 10.1016/j.patcog.2011.06.016; Vanegas M.C., 2009, P IEEE INT GEOSC REM; Vanegas MC, 2013, IEEE T GEOSCI REMOTE, V51, P3542, DOI 10.1109/TGRS.2012.2225628; Vanegas MC, 2011, ADV INTEL SYS RES, P844; Wang ZH, 2016, IEEE T PATTERN ANAL, V38, P2198, DOI 10.1109/TPAMI.2015.2513396; Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X	42	10	10	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2366	2380		10.1109/TPAMI.2016.2645151	http://dx.doi.org/10.1109/TPAMI.2016.2645151			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28026752	Green Submitted			2022-12-18	WOS:000414395400004
J	Yuan, XT; Liu, QS				Yuan, Xiao-Tong; Liu, Qingshan			Newton-Type Greedy Selection Methods for l(0)-Constrained Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparsity; Newton methods; greedy selection; optimization; M-estimation	SIGNAL RECOVERY; SPARSITY; REPRESENTATIONS; APPROXIMATION; PURSUIT	We introduce a family of Newton-type greedy selection methods for l(0)-constrained minimization problems. The basic idea is to construct a quadratic function to approximate the original objective function around the current iterate and solve the constructed quadratic program over the cardinality constraint. The next iterate is then estimated via a line search operation between the current iterate and the solution of the sparse quadratic program. This iterative procedure can be interpreted as an extension of the constrained Newton methods from convex minimization to non-convex l(0)-constrained minimization. We show that the proposed algorithms converge asymptotically and the rate of local convergence is superlinear up to certain estimation error. Our methods compare favorably against several state-of-the-art greedy selection methods when applied to sparse logistic regression and sparse support vector machines.	[Yuan, Xiao-Tong; Liu, Qingshan] Nanjing Univ Informat Sci & Technol, Jiangsu Prov Key Lab Big Data Anal Technol, Nanjing 210044, Jiangsu, Peoples R China	Nanjing University of Information Science & Technology	Yuan, XT (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Prov Key Lab Big Data Anal Technol, Nanjing 210044, Jiangsu, Peoples R China.	xtyuan1980@gmail.com; qsliu@nuist.edu.cn	Liu, Qing/GWC-9222-2022; liu, qingqing/HHD-0360-2022		Natural Science Foundation of China (NSFC) [61402232, 61522308]; Natural Science Foundation of Jiangsu Province of China (NSFJPC) [BK20141003]; NSFC [61532009]; Foundation of Jiangsu Province of China (FJPC) [15KJA520001]	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province of China (NSFJPC)(Natural Science Foundation of Jiangsu Province); NSFC(National Natural Science Foundation of China (NSFC)); Foundation of Jiangsu Province of China (FJPC)	The authors would like to thank the two anonymous referees for their constructive comments which are extremely helpful for improving this work. Xiao-Tong Yuan is supported in part by Natural Science Foundation of China (NSFC) under Grant 61402232, Grant 61522308, and in part by Natural Science Foundation of Jiangsu Province of China (NSFJPC) under Grant BK20141003. Qingshan Liu is supported in part by NSFC under Grant 61532009, and in part by Foundation of Jiangsu Province of China (FJPC) under Grant 15KJA520001. A preliminary version of the this article has appeared in the Proceedings of 2014 IEEE International Conference on Computer Vision and Pattern Recognition (CVPR 2014).	[Anonymous], 2010, THESIS U BRIT COLUMB; Bahmani S, 2013, J MACH LEARN RES, V14, P807; Becker S., 2012, ADV NEURAL INFORM PR, V25, P2618; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Blumensath T, 2013, IEEE T INFORM THEORY, V59, P3466, DOI 10.1109/TIT.2013.2245716; Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002; Boyed S, 2004, CONVEX OPTIMIZATION; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; BYRD RH, 1994, MATH PROGRAM, V63, P129, DOI 10.1007/BF01582063; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006; DENNIS JE, 1974, MATH COMPUT, V28, P549, DOI 10.1090/S0025-5718-1974-0343581-1; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Hsieh C.-J., 2011, ADV NEURAL INFORM PR, P2330; Jalali A., 2011, ADV NEURAL INF PROCE, V24, P1935; Kar P., 2014, ADV NEURAL INFORM PR, P685; Keerthi SS, 2005, J MACH LEARN RES, V6, P341; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002; Oztoprak F., 2012, P 25 INT C NEUR INF, V25, P755; Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465; SCHMIDT M., 2009, ARTIF INTELL, P456; Schmidt M, 2012, OPTIMIZATION FOR MACHINE LEARNING, P305; Shalev-Shwartz S, 2010, SIAM J OPTIMIZ, V20, P2807, DOI 10.1137/090759574; Shen J., 2016, TIGHT BOUND HARD THR; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0; Yuan X., 2016, P 30 ANN C NEUR INF, P3558; Yuan XT, 2014, PR MACH LEARN RES, V32, P127; Yuan XT, 2014, PROC CVPR IEEE, P4122, DOI 10.1109/CVPR.2014.525; Yuan XT, 2013, IEEE T PATTERN ANAL, V35, P3025, DOI 10.1109/TPAMI.2013.85; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136; Zhang T., 2008, P C NEUR INF PROC SY, P1921	37	10	10	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2437	2450		10.1109/TPAMI.2017.2651813	http://dx.doi.org/10.1109/TPAMI.2017.2651813			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28092519				2022-12-18	WOS:000414395400009
J	Rengarajan, V; Rajagopalan, AN; Aravind, R; Seetharaman, G				Rengarajan, Vijay; Rajagopalan, Ambasamudram Narayanan; Aravind, Rangarajan; Seetharaman, Guna			Image Registration and Change Detection under Rolling Shutter Motion Blur	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Rolling shutter; motion blur; change detection; image registration; aerial imaging		In this paper, we address the problem of registering a distorted image and a reference image of the same scene by estimating the camera motion that had caused the distortion. We simultaneously detect the regions of changes between the two images. We attend to the coalesced effect of rolling shutter and motion blur that occurs frequently in moving CMOS cameras. We first model a general image formation framework for a 3D scene following a layered approach in the presence of rolling shutter and motion blur. We then develop an algorithm which performs layered registration to detect changes. This algorithm includes an optimisation problem that leverages the sparsity of the camera trajectory in the pose space and the sparsity of changes in the spatial domain. We create a synthetic dataset for change detection in the presence of motion blur and rolling shutter effect covering different types of camera motion for both planar and 3D scenes. We compare our method with existing registration methods and also show several real examples captured with CMOS cameras.	[Rengarajan, Vijay; Rajagopalan, Ambasamudram Narayanan; Aravind, Rangarajan] Indian Inst Technol Madras, Dept Elect Engn, Madras 600036, Tamil Nadu, India; [Seetharaman, Guna] Air Force Res Lab, Informat Directorate, Rome, NY 13441 USA	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras	Rengarajan, V (corresponding author), Indian Inst Technol Madras, Dept Elect Engn, Madras 600036, Tamil Nadu, India.	vijay.ap@ee.iitm.ac.in; raju@ee.iitm.ac.in; aravind@ee.iitm.ac.in; guna@ieee.org		aravind, r./0000-0002-0805-3305; Ambasamudram, Rajagopalan/0000-0002-0006-6961	Asian Office of Aerospace Research and Development (AOARD)	Asian Office of Aerospace Research and Development (AOARD)	We thank the reviewers and the associate editor for providing valuable comments and suggestions that have significantly improved the contents of the paper. The grant from the Asian Office of Aerospace Research and Development (AOARD) is gratefully acknowledged. The results and interpretations presented in this paper are that of the authors, and do not necessarily reflect the views or priorities of the sponsor or the US AFRL.	[Anonymous], 2016, LIST TALLEST BUILDIN; Anuta PE., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI [10.1109/tge.1970.271435, DOI 10.1109/TGE.1970.271435]; Baker S, 2010, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2010.5539932; Bhat P., 2006, P IEEE C COMP VIS PA, V2, P2491; Bradler D, 2009, 2009 6TH IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, VOLS 1 AND 2, P1, DOI 10.1109/CVPR.2009.5204340; Cho S, 2012, COMPUT GRAPH FORUM, V31, P2183, DOI 10.1111/j.1467-8659.2012.03211.x; Cole-Rhodes AA, 2003, IEEE T IMAGE PROCESS, V12, P1495, DOI 10.1109/TIP.2003.819237; Goyette N, 2014, IEEE T IMAGE PROCESS, V23, P4663, DOI 10.1109/TIP.2014.2346013; Grundmann M., 2012, 2012 IEEE INT C COMP, P1, DOI [10.1109/ICCPhot.2012.6215213, DOI 10.1109/ICCPHOT.2012.6215213]; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Hasinoff SW, 2007, IEEE I CONF COMP VIS, P550; Hu Z, 2014, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2014.370; Hu Z, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.136; Joshi N., 2010, ACM T GRAPHIC, V29, P30, DOI DOI 10.1145/1778765.1778767; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; Liang CK, 2008, IEEE T IMAGE PROCESS, V17, P1323, DOI 10.1109/TIP.2008.925384; Linger ME, 2015, IEEE T GEOSCI REMOTE, V53, P2137, DOI 10.1109/TGRS.2014.2356177; Liu J., 2009, SLEP SPARSE LEARNING; Liu XZ, 2009, PROCEEDINGS OF 2009 INTERNATIONAL WORKSHOP ON INFORMATION SECURITY AND APPLICATION, P214; Meilland M, 2013, IEEE I CONF COMP VIS, P2016, DOI 10.1109/ICCV.2013.252; Paramanand C, 2014, INT J COMPUT VISION, V107, P272, DOI 10.1007/s11263-013-0685-1; Patron-Perez A, 2015, INT J COMPUT VISION, V113, P208, DOI 10.1007/s11263-015-0811-3; PRATT WK, 1974, IEEE T AERO ELEC SYS, VAE10, P353, DOI 10.1109/TAES.1974.307828; Rengarajan V, 2014, LECT NOTES COMPUT SC, V8695, P123, DOI 10.1007/978-3-319-10584-0_9; Rengarajan V, 2014, IEEE COMPUT SOC CONF, P315, DOI 10.1109/CVPRW.2014.55; Ringaby E, 2012, INT J COMPUT VISION, V96, P335, DOI 10.1007/s11263-011-0465-8; Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6; Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882; Su SC, 2015, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2015.7298760; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wu Z, 2012, IEEE T IMAGE PROCESS, V21, P2464, DOI 10.1109/TIP.2012.2185941; Wulff J, 2014, LECT NOTES COMPUT SC, V8694, P236, DOI 10.1007/978-3-319-10599-4_16; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247; Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423; Zhang HC, 2014, PROC CVPR IEEE, P2925, DOI 10.1109/CVPR.2014.374; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	40	10	10	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					1959	1972		10.1109/TPAMI.2016.2630687	http://dx.doi.org/10.1109/TPAMI.2016.2630687			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27875216				2022-12-18	WOS:000408807600005
J	Cordts, M; Rehfeld, T; Enzweiler, M; Franke, U; Roth, S				Cordts, Marius; Rehfeld, Timo; Enzweiler, Markus; Franke, Uwe; Roth, Stefan			Tree-Structured Models for Efficient Multi-Cue Scene Labeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene labeling; automotive; decision forests; segmentation tree; depth cues; superpixels; stixels	VISION; LAYOUT; DEPTH	We propose a novel approach to semantic scene labeling in urban scenarios, which aims to combine excellent recognition performance with highest levels of computational efficiency. To that end, we exploit efficient tree-structured models on two levels: pixels and superpixels. At the pixel level, we propose to unify pixel labeling and the extraction of semantic texton features within a single architecture, so-called encode-and-classify trees. At the superpixel level, we put forward a multi-cue segmentation tree that groups superpixels at multiple granularities. Through learning, the segmentation tree effectively exploits and aggregates a wide range of complementary information present in the data. A tree-structured CRF is then used to jointly infer the labels of all regions across the tree. Finally, we introduce a novel object-centric evaluation method that specifically addresses the urban setting with its strongly varying object scales. Our experiments demonstrate competitive labeling performance compared to the state of the art, while achieving near real-time frame rates of up to 20 fps.	[Cordts, Marius; Rehfeld, Timo; Enzweiler, Markus; Franke, Uwe] Daimler AG, Dept Environm Percept, Boblingen, Germany; [Cordts, Marius; Rehfeld, Timo; Roth, Stefan] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany	Daimler AG; Technical University of Darmstadt	Cordts, M (corresponding author), Daimler AG, Dept Environm Percept, Boblingen, Germany.; Cordts, M (corresponding author), Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.	marius.cordts@daimler.com; timo.rehfeld@daimler.com; markus.enzweiler@daimler.com; uwe.franke@daimler.com; sroth@cs.tu-darmstadt.de		Roth, Stefan/0000-0001-9002-9832				[Anonymous], P 13 IAPR INT C MACH; Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Floros G, 2012, PROC CVPR IEEE, P2823, DOI 10.1109/CVPR.2012.6248007; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1; Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048; Gould S, 2012, J MACH LEARN RES, V13, P3533; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He H, 2013, IEEE INT C INT ROBOT, P3697, DOI 10.1109/IROS.2013.6696884; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Ion A, 2014, INT J COMPUT VISION, V107, P40, DOI 10.1007/s11263-013-0663-7; Kahler O, 2013, IEEE I CONF COMP VIS, P3064, DOI 10.1109/ICCV.2013.380; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Ladicky L., 2010, P BRIT MACH VIS C BM; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165; Lempitsky V., 2011, NIPS, V24, P1485; Lim JJ, 2009, IEEE I CONF COMP VIS, P1978, DOI 10.1109/ICCV.2009.5459436; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Micusik Branislav, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P625, DOI 10.1109/ICCVW.2009.5457645; Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822; Nowozin S, 2010, LECT NOTES COMPUT SC, V6316, P98, DOI 10.1007/978-3-642-15567-3_8; Pfeiffer D, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.51; Plath N., 2009, P 26 ANN INT C MACHI, P817, DOI [10.1145/1553374.1553479, DOI 10.1145/1553374.1553479]; Qixing Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1953, DOI 10.1109/CVPR.2011.5995571; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Reynolds J, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P175, DOI 10.1109/CRV.2007.32; Ros G, 2015, IEEE WINT CONF APPL, P231, DOI 10.1109/WACV.2015.38; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Scharwachter T, 2015, IEEE INT VEH SYM, P599, DOI 10.1109/IVS.2015.7225750; Scharwachter T, 2014, LECT NOTES COMPUT SC, V8693, P533, DOI 10.1007/978-3-319-10602-1_35; Sengupta S, 2013, IEEE INT CONF ROBOT, P580, DOI 10.1109/ICRA.2013.6630632; Sharma A, 2015, PROC CVPR IEEE, P530, DOI 10.1109/CVPR.2015.7298651; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; STOLLNITZ EJ, 1995, IEEE COMPUT GRAPH, V15, P76, DOI 10.1109/38.376616; Tomasi C, 1991, CMUCS91132; Veksler O., 2010, EUR C COMP VIS, DOI DOI 10.1007/978-3-642-15555-0_16; Verbeek J., 2007, ADV NEURAL INF PROCE, V20, P1553; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739; Zhang J, 2013, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2013.161	49	10	11	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1444	1454		10.1109/TPAMI.2016.2592911	http://dx.doi.org/10.1109/TPAMI.2016.2592911			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27448340				2022-12-18	WOS:000402744400013
J	Chen, CY; Grauman, K				Chen, Chao Yeh; Grauman, Kristen			Efficient Activity Detection in Untrimmed Video with Max-Subgraph Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Activity detection; action recognition; maximum weighted subgraph search		We propose an efficient approach for activity detection in video that unifies activity categorization with space-time localization. The main idea is to pose activity detection as a maximum-weight connected subgraph problem. Offline, we learn a binary classifier for an activity category using positive video exemplars that are "trimmed" in time to the activity of interest. Then, given a novel untrimmed video sequence, we decompose it into a 3D array of space-time nodes, which are weighted based on the extent to which their component features support the learned activity model. To perform detection, we then directly localize instances of the activity by solving for the maximum-weight connected subgraph in the test video's space-time graph. We show that this detection strategy permits an efficient branch-and-cut solution for the best-scoring-and possibly non-cubically shaped-portion of the video for a given activity classifier. The upshot is a fast method that can search a broader space of space-time region candidates than was previously practical, which we find often leads to more accurate detection. We demonstrate the proposed algorithm on four datasets, and we show its speed and accuracy advantages over multiple existing search strategies.	[Chen, Chao Yeh; Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Chen, CY (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	chaoyeh@cs.utexas.edu; grauman@cs.utexas.edu			ONR PECASE [N00014-151-2291]	ONR PECASE(Office of Naval Research)	We thank the anonymous reviewers for their feedback, and Sudheendra Vijayanarasimhan for helpful discussions. This research is supported in part by ONR PECASE N00014-151-2291.	[Anonymous], 2009, BMVC, DOI DOI 10.5244/C.23.124; Bandla S, 2013, IEEE I CONF COMP VIS, P1833, DOI 10.1109/ICCV.2013.230; Bentley J., 1984, Communications of the ACM, V27, P865, DOI 10.1145/358234.381162; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875; Chen CY, 2012, PROC CVPR IEEE, P1274, DOI 10.1109/CVPR.2012.6247811; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dittrich MT, 2008, BIOINFORMATICS, V24, pI223, DOI 10.1093/bioinformatics/btn161; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Fowlkes C., 2010, P IEEE COMP SOC C CO, P9; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Ideker Trey, 2002, Bioinformatics, V18 Suppl 1, pS233; Jiang Y.-G., 2014, ECCV WORKSH; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Klaser A., 2008, P BRIT MACH VIS C; Klaser A., 2012, P EUR C COMP VIS, V6553, P219; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Ljubic I, 2006, MATH PROGRAM, V105, P427, DOI 10.1007/s10107-005-0660-x; Mikolajczyk Krystian, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587628; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228; Oneata Dan, 2014, LEAR SUBMISSION THUM, P2; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Ramanan D, 2004, ADV NEUR IN, V16, P1547; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Satkin S, 2010, LECT NOTES COMPUT SC, V6311, P536, DOI 10.1007/978-3-642-15549-9_39; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Vedaldi A., 2010, IEEE C COMP VIS PATT, P480; Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2011.5995545; Willems G., 2009, P BRIT MACH VIS C; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yu G, 2011, PROC CVPR IEEE, P865, DOI 10.1109/CVPR.2011.5995488; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]	38	10	10	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					908	921		10.1109/TPAMI.2016.2564404	http://dx.doi.org/10.1109/TPAMI.2016.2564404			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113697	Green Submitted			2022-12-18	WOS:000399250000006
J	Shi, R; Zeng, W; Su, ZY; Jiang, J; Damasio, HN; Lu, ZL; Wang, YL; Yau, ST; Gu, XF				Shi, Rui; Zeng, Wei; Su, Zhengyu; Jiang, Jian; Damasio, Hanna; Lu, Zhonglin; Wang, Yalin; Yau, Shing-Tung; Gu, Xianfeng			Hyperbolic Harmonic Mapping for Surface Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Surface matching and registration; hyperbolic geometry; harmonic mapping	3D MODELS; SHAPE CORRESPONDENCE; PARAMETERIZATION	Automatic computation of surface correspondence via harmonic map is an active research field in computer vision, computer graphics and computational geometry. It may help document and understand physical and biological phenomena and also has broad applications in biometrics, medical imaging and motion capture industries. Although numerous studies have been devoted to harmonic map research, limited progress has been made to compute a diffeomorphic harmonic map on general topology surfaces with landmark constraints. This work conquers this problem by changing the Riemannian metric on the target surface to a hyperbolic metric so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints. The computational algorithms are based on Ricci flow and nonlinear heat diffusion methods. The approach is general and robust. We employ our algorithm to study the constrained surface registration problem which applies to both computer vision and medical imaging applications. Experimental results demonstrate that, by changing the Riemannian metric, the registrations are always diffeomorphic and achieve relatively high performance when evaluated with some popular surface registration evaluation standards.	[Shi, Rui; Su, Zhengyu; Jiang, Jian; Gu, Xianfeng] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Zeng, Wei] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA; [Damasio, Hanna] Univ Southern Calif, Neurosci Dept, Los Angeles, CA 90089 USA; [Lu, Zhonglin] Ohio State Univ, Dept Psychol, Columbus, OH 43210 USA; [Wang, Yalin] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA; [Yau, Shing-Tung] Harvard Univ, Math Dept, Cambridge, MA 02138 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; State University System of Florida; Florida International University; University of Southern California; University System of Ohio; Ohio State University; Arizona State University; Arizona State University-Tempe; Harvard University	Shi, R (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	rshi@cs.stonybrook.edu; wzeng@cs.fiu.edu; zhsu@cs.stonybrook.edu; jianjiang@cs.stonybrook.edu; hdamasio@college.usc.edu; lu.535@osu.edu; ylwang@asu.edu; yau@math.harvard.edu; gu@cs.stonybrook.edu	Zeng, Wei/J-6474-2014	Wang, Yalin/0000-0002-6241-735X; Gu, Xianfeng/0000-0001-8226-5851	NSF Nets [1016286]; NSF IIS [0916286]; NSF CCF [1081424, 1544267]; ONR [N000140910228]; NIH [R21AG043760]; NATIONAL INSTITUTE ON AGING [RF1AG051710, R21AG043760, R21AG049216] Funding Source: NIH RePORTER	NSF Nets(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE)); NSF IIS(National Science Foundation (NSF)); NSF CCF; ONR(Office of Naval Research); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This work was partially supported by NSF Nets 1016286, NSF IIS 0916286, NSF CCF 1081424, ONR N000140910228, NSF CCF 1544267, and NIH R21AG043760.	Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Angenent S, 1999, LECT NOTES COMPUT SC, V1679, P271; Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Boyer DM, 2011, P NATL ACAD SCI USA, V108, P18221, DOI 10.1073/pnas.1112822108; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein Michael M, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1065, DOI 10.1109/TPAMI.2010.210; Brown B. J., 2007, P ACM SIGGRAPH 2007; Davis TA, 2004, ACM T MATH SOFTWARE, V30, P165, DOI 10.1145/992200.992205; Dey TK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360644; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Dongmei Zhang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P524, DOI 10.1109/CVPR.1999.784731; Dubrovina A, 2011, ADV DATA SCI ADAPT, V3, P203, DOI 10.1142/S1793536911000829; Eck M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P173, DOI 10.1145/218380.218440; Edelsbrunner H., 2009, COMPUTATIONAL TOPOLO; Golovinskiy A, 2009, COMPUT GRAPH-UK, V33, P262, DOI 10.1016/j.cag.2009.03.010; Gu X. D., 2008, COMPUTATIONAL CONFOR, V3; Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226; Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x; Joshi AA, 2007, IEEE T MED IMAGING, V26, P1657, DOI 10.1109/TMI.2007.901432; Kim V. G., 2011, ACM SIGGRAPH; Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811; Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233; Litke N., 2005, S GEOM PROC, P207; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; Memoli Facundo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P256, DOI 10.1109/ICCVW.2009.5457690; Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x; Pantazis D, 2010, NEUROIMAGE, V49, P2479, DOI 10.1016/j.neuroimage.2009.09.027; PAULY M, 2005, P EUR S GEOM PROC; Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277; Schoen R., 1997, P C LECT NOT GEOM TO, VII; Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812; Sharma A, 2010, P NORDIA WORKSH CVPR, P29; Shi J, 2013, NEUROIMAGE, V78, P111, DOI 10.1016/j.neuroimage.2013.04.018; Shi R, 2013, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2013.327; Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775; Thompson P. M., 2004, NEUROIMAGE MATH BRAI, V23; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Varun J., 2007, INT J SHAPE MODELING, V13, P101, DOI DOI 10.1142/S0218654307000968; Wang Y., 2009, ICCV, P2365; Wang YL, 2013, NEUROIMAGE, V74, P209, DOI 10.1016/j.neuroimage.2013.02.011; Wang YL, 2012, IEEE T MED IMAGING, V31, P251, DOI 10.1109/TMI.2011.2168233; Wang YL, 2010, NEUROIMAGE, V49, P2141, DOI 10.1016/j.neuroimage.2009.10.086; Wang Y, 2008, INT J COMPUT VISION, V76, P283, DOI 10.1007/s11263-007-0063-y; Xianfeng Gu, 2003, Symposium on Geometry Processing, P127; Zeng W, 2010, IEEE T PATTERN ANAL, V32, P662, DOI 10.1109/TPAMI.2009.201; Zeng Y, 2010, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2010.5540189; [No title captured]	50	10	10	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					965	980		10.1109/TPAMI.2016.2567398	http://dx.doi.org/10.1109/TPAMI.2016.2567398			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	27187948	Green Accepted, hybrid			2022-12-18	WOS:000399250000010
J	Du, M; Chellappa, R				Du, Ming; Chellappa, Rama			Face Association for Videos Using Conditional Random Fields and Max-Margin Markov Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face association; tracking by detection; conditional random field; max-margin Markov networks; contextual features	TRACKING	We address the video-based face association problem, in which one attempts to extract the face tracks of multiple subjects while maintaining label consistency. Traditional tracking algorithms have difficulty in handling this task, especially when challenging nuisance factors like motion blur, low resolution or significant camera motions are present. We demonstrate that contextual features, in addition to face appearance itself, play an important role in this case. We propose principled methods to combine multiple features using Conditional Random Fields and Max-Margin Markov networks to infer labels for the detected faces. Different from many existing approaches, our algorithms work in online mode and hence have a wider range of applications. We address issues such as parameter learning, inference and handling false positves/negatives that arise in the proposed approach. Finally, we evaluate our approach on several public databases.	[Du, Ming; Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Du, M (corresponding author), Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.	mingdu@umiacs.umd.edu; rama@umiacs.umd.edu	Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020					Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Anguelov D., 2007, P IEEE C COMP VIS PA, P1, DOI [10.1109/CVPR.2007.383057, DOI 10.1109/CVPR.2007.383057]; Bauml M, 2013, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2013.462; Berg TL, 2004, PROC CVPR IEEE, P848; Bojanowski P, 2013, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2013.283; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278; Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107; Du M, 2012, LECT NOTES COMPUT SC, V7578, P167, DOI 10.1007/978-3-642-33786-4_13; Everingham M., 2006, P BRIT MACH VIS C BM, P899, DOI DOI 10.5244/C.20.92; Fitzgibbon A, 2002, LECT NOTES COMPUT SC, V2352, P304; Frey BJ, 1998, ADV NEUR IN, V10, P479; Gallagher A. C., 2007, P IEEE C COMP VIS PA, P1; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Jepson AD, 2001, PROC CVPR IEEE, P415; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; LIN D, 2010, LECT NOTES COMPUT SC, P243; Maggio E, 2007, INT CONF ACOUST SPEE, P1101; Ramanan D, 2007, IEEE I CONF COMP VIS, P1432; Saul L. K., 1999, MEAN FIELD LEARNING; Sivic J, 2005, LECT NOTES COMPUT SC, V3568, P226; Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513; Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44; Tapaswi M, 2012, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2012.6247986; Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745; Yang B, 2012, LECT NOTES COMPUT SC, V7572, P484, DOI 10.1007/978-3-642-33718-5_35; Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	34	10	10	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1762	1773		10.1109/TPAMI.2015.2497689	http://dx.doi.org/10.1109/TPAMI.2015.2497689			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26552075				2022-12-18	WOS:000381432700004
J	Carreira, J; Vicente, S; Agapito, L; Batista, J				Carreira, Joao; Vicente, Sara; Agapito, Lourdes; Batista, Jorge			Lifting Object Detection Datasets into 3D	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Object reconstruction; structure-from-motion; viewpoint estimation; visual hulls	IMAGE; SHAPE; RECOGNITION; ORGANIZATION; MODEL	While data has certainly taken the center stage in computer vision in recent years, it can still be difficult to obtain in certain scenarios. In particular, acquiring ground truth 3D shapes of objects pictured in 2D images remains a challenging feat and this has hampered progress in recognition-based object reconstruction from a single image. Here we propose to bypass previous solutions such as 3D scanning or manual design, that scale poorly, and instead populate object category detection datasets semi-automatically with dense, per-object 3D reconstructions, bootstrapped from:(i) class labels, (ii) ground truth figure-ground segmentations and (iii) a small set of keypoint annotations. Our proposed algorithm first estimates camera viewpoint using rigid structure-from-motion and then reconstructs object shapes by optimizing over visual hull proposals guided by loose within-class shape similarity assumptions. The visual hull sampling process attempts to intersect an object's projection cone with the cones of minimal subsets of other similar objects among those pictured from certain vantage points. We show that our method is able to produce convincing per-object 3D reconstructions and to accurately estimate cameras viewpoints on one of the most challenging existing object-category detection datasets, PASCAL VOC. We hope that our results will re-stimulate interest on joint object recognition and 3D reconstruction from a single image.	[Carreira, Joao] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Carreira, Joao; Batista, Jorge] Univ Coimbra, Inst Syst & Robot, Coimbra, Portugal; [Vicente, Sara] Anthrop Technol Ltd, London, England; [Agapito, Lourdes] UCL, London, England; [Batista, Jorge] Univ Coimbra, Dept Elect Engn & Comp, Coimbra, Portugal	University of California System; University of California Berkeley; Universidade de Coimbra; University of London; University College London; Universidade de Coimbra	Carreira, J (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.; Carreira, J (corresponding author), Univ Coimbra, Inst Syst & Robot, Coimbra, Portugal.	carreira@eecs.berkeley.edu; sara@anthropics.co.uk; l.agapito@cs.ucl.ac.uk; batista@isr.uc.pt	Batista, Jorge/A-4196-2011	Batista, Jorge/0000-0003-2387-5961				AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; [Anonymous], 2014, COMMUNICATION; Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879; Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167; Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693; Berthold K.P., 1970, TECHNICAL REPORT, P2; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brox T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2225, DOI 10.1109/CVPR.2011.5995659; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2012, INT J COMPUT VISION, V98, P243, DOI 10.1007/s11263-011-0507-2; Cashman TJ, 2013, IEEE T PATTERN ANAL, V35, P232, DOI 10.1109/TPAMI.2012.68; Cremers D, 2011, IEEE T PATTERN ANAL, V33, P1161, DOI 10.1109/TPAMI.2010.174; Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fragkiadaki A., 2014, P ADV NEUR INF PROC, P55; Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Hassner T., 2006, 2006 C COMP VIS PATT, P15, DOI DOI 10.1109/CVPRW.2006.76; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D., 2011, REPRESENTATIONS TECH, V15; Huttenlocher D. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P102; Karsch K, 2013, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2013.281; Kim J, 2012, LECT NOTES COMPUT SC, V7578, P444, DOI 10.1007/978-3-642-33786-4_33; Kim VG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461933; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Mitra NJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618502; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Mundy J. L., 2006, CATEGORY LEVEL OBJEC; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Oswald MR, 2014, LECT NOTES COMPUT SC, V8692, P32; Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602; Prasad M., 2006, IEEE COMP SOC C COMP, P1345; Prasad M, 2010, PROC CVPR IEEE, P1720, DOI 10.1109/CVPR.2010.5539840; Roberts Lawrence G, 1963, THESIS, P2; Russell Bryan C., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2711, DOI 10.1109/CVPRW.2009.5206643; Russell C, 2014, LECT NOTES COMPUT SC, V8695, P583, DOI 10.1007/978-3-319-10584-0_38; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Su H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601159; Sun M, 2009, PROC CVPR IEEE, P1247, DOI 10.1109/CVPRW.2009.5206723; Toeppe E, 2013, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2013.30; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Twarog N. R., 2012, P ACM S APPL PERC, P47; ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006; Vicente S, 2008, PROC CVPR IEEE, P767; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; Vicente S, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P223, DOI 10.1109/3DV.2013.37; Wu Z, 2014, ARXIV14065670, V2; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Zhu SQ, 2010, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2010.5540085; Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87	68	10	10	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1342	10.1109/TPAMI.2015.2435707	http://dx.doi.org/10.1109/TPAMI.2015.2435707			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	27295458	Green Submitted			2022-12-18	WOS:000377897100006
J	Demirkus, M; Precup, D; Clark, JJ; Arbel, T				Demirkus, Meltem; Precup, Doina; Clark, James J.; Arbel, Tal			Hierarchical Spatio-Temporal Probabilistic Graphical Model with Multiple Feature Fusion for Binary Facial Attribute Classification in Real-World Face Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local invariant features; probabilistic modelling; facial trait; gender classification; facial hair detection; attribute classification; face; occlusion; real-world environment; Bag-of-words; hierarchical graphical model; real-world face video; spatio-temporal model	GENDER RECOGNITION	Recent literature shows that facial attributes, i.e., contextual facial information, can be beneficial for improving the performance of real-world applications, such as face verification, face recognition, and image search. Examples of face attributes include gender, skin color, facial hair, etc. How to robustly obtain these facial attributes (traits) is still an open problem, especially in the presence of the challenges of real-world environments: non-uniform illumination conditions, arbitrary occlusions, motion blur and background clutter. What makes this problem even more difficult is the enormous variability presented by the same subject, due to arbitrary face scales, head poses, and facial expressions. In this paper, we focus on the problem of facial trait classification in real-world face videos. We have developed a fully automatic hierarchical and probabilistic framework that models the collective set of frame class distributions and feature spatial information over a video sequence. The experiments are conducted on a large real-world face video database that we have collected, labelled and made publicly available. The proposed method is flexible enough to be applied to any facial classification problem. Experiments on a large, real-world video database McGillFaces [1] of 18,000 video frames reveal that the proposed framework outperforms alternative approaches, by up to 16.96 and 10.13%, for the facial attributes of gender and facial hair, respectively.	[Demirkus, Meltem; Precup, Doina; Clark, James J.; Arbel, Tal] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	McGill University	Demirkus, M; Precup, D; Clark, JJ; Arbel, T (corresponding author), McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.	demirkus@cim.mcgill.ca; dprecup@cs.mcgill.ca; clark@cim.mcgill.ca; arbel@cim.mcgill.ca						Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; Aghajanian J, 2009, IEEE I CONF COMP VIS, P1125, DOI 10.1109/ICCV.2009.5459352; Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010; [Anonymous], 2004, CAVIAR DATABASE; [Anonymous], 2005, 2005 IEEE COMP SOC C; Arashloo SR, 2011, IEEE T PATTERN ANAL, V33, P1274, DOI 10.1109/TPAMI.2010.209; Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; Bekios-Calfa J, 2014, PATTERN RECOGN LETT, V36, P228, DOI 10.1016/j.patrec.2013.04.028; Berg AC, 2005, PROC CVPR IEEE, P26; Berg AC, 2001, PROC CVPR IEEE, P607; Berg TL, 2004, PROC CVPR IEEE, P848; Blanz V, 2005, PROC CVPR IEEE, P454; Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003; Campbell R, 1999, PERCEPTION, V28, P489, DOI 10.1068/p2784; Cao D., 2011, 2011 INT JOINT C BIO, P1; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen BC, 2013, IEEE T MULTIMEDIA, V15, P1163, DOI 10.1109/TMM.2013.2242460; Cherniavsky N., 2010, EUR C COMP VIS, P43; Cottrell GW, 1990, P ADV NEUR INF PROC, P564; Datta Ankur, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P36, DOI 10.1109/FG.2011.5771429; Demirkus M., 2012, CVPR WORKSH, P130; Demirkus M., 2010, 2010 IEEE COMP SOC C, P55, DOI DOI 10.1109/CVPRW.2010.5543829; Demirkus M, 2014, LECT NOTES COMPUT SC, V8689, P328, DOI 10.1007/978-3-319-10590-1_22; Demirkus M, 2014, MULTIMED TOOLS APPL, V70, P495, DOI 10.1007/s11042-012-1352-1; Demirkus M, 2011, IEEE IMAGE PROC, P573, DOI 10.1109/ICIP.2011.6116613; Du M, 2012, LECT NOTES COMPUT SC, V7578, P167, DOI 10.1007/978-3-642-33786-4_13; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Franco A, 2010, PATTERN RECOGN, V43, P2891, DOI 10.1016/j.patcog.2010.02.017; Golomb B. A., 1990, NIPS, V1, P572; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948; Hadid A, 2009, PATTERN RECOGN, V42, P2818, DOI 10.1016/j.patcog.2009.02.011; Huang Gary B., 2007, 0749 U MASS, P7; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kamgar-Parsi B, 2011, IEEE T PATTERN ANAL, V33, P1925, DOI 10.1109/TPAMI.2011.68; Kim J, 2011, PROC CVPR IEEE, P1553, DOI 10.1109/CVPR.2011.5995526; Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lapedriza A, 2006, INT C PATT RECOG, P834; Li XO, 2010, PROC CVPR IEEE, P2590, DOI 10.1109/CVPR.2010.5539969; Lievin M, 2004, IEEE T IMAGE PROCESS, V13, P63, DOI 10.1109/TIP.2003.818013; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554; Makinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800; Medioni G, 2009, IEEE T SYST MAN CY A, V39, P12, DOI 10.1109/TSMCA.2008.2007979; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Sigal L, 2010, LECT NOTES COMPUT SC, V6313, P243; Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513; Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Tuytelaars T., 2006, TUTORIAL AT ECCV; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weber M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P20, DOI 10.1109/AFGR.2000.840607; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Yampolskiy RV, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P40, DOI 10.1109/ICMLA.2012.16; Yang M, 2011, PROC CVPR IEEE, P505, DOI 10.1109/CVPR.2011.5995481; Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788; Zhou S. K., 2006, INT SERIES BIOMETRIC; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	65	10	12	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1185	1203		10.1109/TPAMI.2015.2481396	http://dx.doi.org/10.1109/TPAMI.2015.2481396			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26415152				2022-12-18	WOS:000375609000011
J	Hauagge, D; Wehrwein, S; Bala, K; Snavely, N				Hauagge, Daniel; Wehrwein, Scott; Bala, Kavita; Snavely, Noah			Photometric Ambient Occlusion for Intrinsic Image Decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ambient occlusion; intrinsic images; image stacks; pixel statistics	STEREO; SHAPE	We present a method for computing ambient occlusion (AO) for a stack of images of a Lambertian scene from a fixed viewpoint. Ambient occlusion, a concept common in computer graphics, characterizes the local visibility at a point: it approximates how much light can reach that point from different directions without getting blocked by other geometry. While AO has received surprisingly little attention in vision, we show that it can be approximated using simple, per-pixel statistics over image stacks, based on a simplified image formation model. We use our derived AO measure to compute reflectance and illumination for objects without relying on additional smoothness priors, and demonstrate state-of-the art performance on the MIT Intrinsic Images benchmark. We also demonstrate our method on several synthetic and real scenes, including 3D printed objects with known ground truth geometry.	[Hauagge, Daniel; Wehrwein, Scott; Bala, Kavita; Snavely, Noah] Cornell Univ, Comp Sci, New York, NY 14850 USA	Cornell University	Hauagge, D; Wehrwein, S; Bala, K; Snavely, N (corresponding author), Cornell Univ, Comp Sci, New York, NY 14850 USA.	hauagge@cs.cornell.edu; swehrwein@cs.cornell.edu; kb@cs.cornell.edu; snavely@cs.cornell.edu		Bala, Kavita/0000-0001-9761-6503	US National Science Foundation (NSF) [IIS-0963657, IIS-1149393, IIS-1111534]; Intel Science and Technology Visual Computing Center	US National Science Foundation (NSF)(National Science Foundation (NSF)); Intel Science and Technology Visual Computing Center	This work was supported in part by the US National Science Foundation (NSF) (IIS-0963657, IIS-1149393, and IIS-1111534) and the Intel Science and Technology Visual Computing Center. The authors also thank the following people for their help and advice: Wenzel Jakob, Sean Bell, Pramook Khungurn, Steve Marschner, and Albert Liu.	Ackermann J, 2012, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2012.6247684; Aldrian O, 2012, LECT NOTES COMPUT SC, V7574, P201, DOI 10.1007/978-3-642-33712-3_15; [Anonymous], 2002, SIGGRAPH COURSE NOTE; Barron J. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2521, DOI 10.1109/CVPR.2011.5995392; Barron J. T., 2013, UCBEECS2013117; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Beeler T, 2012, LECT NOTES COMPUT SC, V7572, P30, DOI 10.1007/978-3-642-33718-5_3; Chandraker M., 2007, P IEEE C COMPUTER VI, P1; Garg R, 2009, IEEE I CONF COMP VIS, P1917, DOI 10.1109/ICCV.2009.5459424; Grosse R., 2009, MIT INTRINSIC IMAGES; Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428; Hauagge D., 2014, P BRIT MACH VIS C, P1; Hauagge D, 2013, PROC CVPR IEEE, P2515, DOI 10.1109/CVPR.2013.325; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; Kontkanen Janne, 2005, I3D 05, P41; Laffont P.-Y., 2012, P SIGGRAPH AS; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LANGER MS, 1994, J OPT SOC AM A, V11, P467, DOI 10.1364/JOSAA.11.000467; Lee KC, 2005, EXTENDED YALE FACE D; Lee KJ, 2012, LECT NOTES COMPUT SC, V7577, P327, DOI 10.1007/978-3-642-33783-3_24; Pantaleoni J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778774; Pharr M., 2004, GPU GEMS, V1, P279; Prados E., 2009, P 2 INT C SCAL SPAC, P296; Shen JB, 2013, IEEE T CYBERNETICS, V43, P425, DOI 10.1109/TSMCB.2012.2208744; Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738; Sunkavalli K., 2007, P SIGGRAPH; Sunkavalli K, 2010, LECT NOTES COMPUT SC, V6312, P251, DOI 10.1007/978-3-642-15552-9_19; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; WOODHAM R, 1991, 9118 U BRIT COL; WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9; Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388; Wu TP, 2010, IEEE T PATTERN ANAL, V32, P546, DOI 10.1109/TPAMI.2009.15	34	10	10	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					639	651		10.1109/TPAMI.2015.2453959	http://dx.doi.org/10.1109/TPAMI.2015.2453959			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959670	hybrid			2022-12-18	WOS:000372549700003
J	Osadchy, M; Keren, D; Raviv, D				Osadchy, Margarita; Keren, Daniel; Raviv, Dolev			Recognition Using Hybrid Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; object detection; large scale learning	IMAGE; HISTOGRAMS; FEATURES; SUPPORT	A canonical problem in computer vision is category recognition (e.g., find all instances of human faces, cars etc., in an image). Typically, the input for training a binary classifier is a relatively small sample of positive examples, and a huge sample of negative examples, which can be very diverse, consisting of images from a large number of categories. The difficulty of the problem sharply increases with the dimension and size of the negative example set. We propose to alleviate this problem by applying a "hybrid" classifier, which replaces the negative samples by a prior, and then finds a hyperplane which separates the positive samples from this prior. The method is extended to kernel space and to an ensemble-based approach. The resulting binary classifiers achieve an identical or better classification rate than SVM, while requiring far smaller memory and lower computational complexity to train and apply.	[Osadchy, Margarita; Keren, Daniel; Raviv, Dolev] Univ Haifa, Dept Comp Sci, IL-31999 Haifa, Israel	University of Haifa	Osadchy, M; Keren, D; Raviv, D (corresponding author), Univ Haifa, Dept Comp Sci, IL-31999 Haifa, Israel.	rita@cs.haifa.ac.il; dkeren@cs.haifa.ac.il; dolev.raviv@gmail.com			Israel Science Foundation [839/12]	Israel Science Foundation(Israel Science Foundation)	This work has been supported by Israel Science Foundation 839/12.	Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7; [Anonymous], 2007, CNSTR2007001 CALTECH; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Asuncion A, 2007, UCI MACHINE LEARNING; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1; Downs T, 2002, J MACH LEARN RES, V2, P293, DOI 10.1162/15324430260185637; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; Franc V, 2003, LECT NOTES COMPUT SC, V2756, P426; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Grauman K, 2007, J MACH LEARN RES, V8, P725; Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33; Hastie T, 2009, ELEMENTS STAT LEARNI; Huang YZ, 2011, PROC CVPR IEEE, P1753, DOI 10.1109/CVPR.2011.5995682; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jia Y., 2013, CAFFE OPEN SOURCE CO; Joachims T, 2006, PROC 22 ACM SIGKDD I, P217, DOI DOI 10.1145/1150402.1150429; Joachims T, 2009, MACH LEARN, V76, P179, DOI 10.1007/s10994-009-5126-6; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Keerthi SS, 2006, J MACH LEARN RES, V7, P1493; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; Kotsiantis S., 2006, GESTS INT T COMPUT S, V30, P1; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ladicky L, 2011, P 28 INT C INT C MAC, P985; Lanckriet G. R. G., 2003, Journal of Machine Learning Research, V3, P555, DOI 10.1162/153244303321897726; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee Y. J., 2001, P SIAM INT C DAT MIN; Levy N, 2012, LECT NOTES COMPUT SC, V7577, P29, DOI 10.1007/978-3-642-33783-3_3; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji Subhransu, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Martinus David, 2002, ONE CLASS CLASSIFICA; Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092; Osadchy M., 2006, P IEEE C COMP VIS PA, P2095; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Roth S, 2005, PROC CVPR IEEE, P860; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Steinwart I, 2004, J MACH LEARN RES, V4, P1071, DOI 10.1162/1532443041827925; Tsai D, 2011, IEEE I CONF COMP VIS, P611, DOI 10.1109/ICCV.2011.6126295; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	56	10	10	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					759	771		10.1109/TPAMI.2015.2465910	http://dx.doi.org/10.1109/TPAMI.2015.2465910			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959677	Green Published			2022-12-18	WOS:000372549700012
J	Dong, J; Chen, Q; Huang, ZY; Yang, JC; Yan, SC				Dong, Jian; Chen, Qiang; Huang, Zhongyang; Yang, Jianchao; Yan, Shuicheng			Parsing Based on Parselets: A Unified Deformable Mixture Model for Human Parsing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human parsing; parselets; And Or graph; deformable model	PICTORIAL STRUCTURES; POSE ESTIMATION; SEGMENTATION; SUPERPIXELS; SEARCH	Human parsing, namely partitioning the human body into semantic regions, has drawn much attention recently for its wide applications in human-centric analysis. Previous works often consider solving the problem of human pose estimation as the prerequisite of human parsing. We argue that these approaches cannot obtain optimal pixel-level parsing due to the inconsistent targets between the different tasks. In this work, we directly address the problem of human parsing by using the novel Parselet representation as the building blocks of our parsing model. Parselets are a group of parsable segments which can generally be obtained by low-level over-segmentation algorithms and bear strong semantic meaning. We then build a deformable mixture parsing model (DMPM) for human parsing to simultaneously handle the deformation and multi-modalities of Parselets. The proposed model has two unique characteristics: (1) the possible numerous modalities of Parselet ensembles are exhibited as the "And-Or" structure of sub-trees; (2) to further solve the practical problem of Parselet occlusion or absence, we directly model the visibility property at some leaf nodes. The DMPM thus directly solves the problem of human parsing by searching for the best graph configuration from a pool of Parselet hypotheses without intermediate tasks. Fast rejection based on hierarchical filtering is employed to ensure the overall efficiency. Comprehensive evaluations on a new large-scale human parsing dataset, which is crawled from the Internet, with high resolution and thoroughly annotated semantic labels at pixel-level, and also a benchmark dataset demonstrate the encouraging performance of the proposed approach.	[Dong, Jian; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore; [Chen, Qiang] IBM Res Corp, Carlton, Vic, Australia; [Huang, Zhongyang] OmniVision Technol, Singapore, Singapore; [Yang, Jianchao] Adobe Res, San Jose, CA 95110 USA	National University of Singapore; Adobe Systems Inc.	Dong, J (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore.	a0068947@nus.edu.sg; qiangchen@au1.ibm.com; zhongyang.huang@ovt.com; jiayang@adobe.com; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022; Dong, Jian/AAR-8670-2021; chen, qiang/HGU-5418-2022					Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Carreira J, 2012, INT J COMPUT VISION, V98, P243, DOI 10.1007/s11263-011-0507-2; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dechter R, 2007, ARTIF INTELL, V171, P73, DOI 10.1016/j.artint.2006.11.003; Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; GALLAGHER AC, 2008, COMP VIS PATT REC 20, P1, DOI DOI 10.1109/CVPR.2008.4587481; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Huayan Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2433, DOI 10.1109/CVPR.2011.5995722; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6; Ladicky L, 2013, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2013.459; Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/ISRA.2012.6219309, 10.1109/CVPR.2012.6247750]; Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536; Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071; Liu Si, 2012, P 20 ACM MULT C MM 1, P619, DOI DOI 10.1145/2393347.2393433; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Rothrock B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P640, DOI 10.1109/ICCVW.2011.6130303; Rothrock B, 2013, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2013.413; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Srinivasan P., 2007, CVPR, P1; Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wang X., 2011, PROC ACM INT C MULTI, P1353; Wang Y, 2012, J MACH LEARN RES, V13, P3075; Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519; Weiss D, 2013, PROC CVPR IEEE, P2035, DOI 10.1109/CVPR.2013.265; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yihang Bo, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2265, DOI 10.1109/CVPR.2011.5995609; Zhu L., 2008, IEEE C COMP VIS PATT, P1; Zhu L, 2011, INT J COMPUT VISION, V93, P1, DOI 10.1007/s11263-010-0375-1; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018; Zhu X., 2012, P BRIT MACH VIS C, P801; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	62	10	10	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					88	101		10.1109/TPAMI.2015.2420563	http://dx.doi.org/10.1109/TPAMI.2015.2420563			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26670586				2022-12-18	WOS:000366669200007
J	Galimzianova, A; Pernus, F; Likar, B; Spiclin, Z				Galimzianova, Alfiia; Pernus, Franjo; Likar, Bostjan; Spiclin, Ziga			Robust Estimation of Unbalanced Mixture Models on Samples with Outliers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mixture model; robust estimation; trimmed likelihood estimation; outlier detection; expectation-maximization; magnetic resonance imaging (MRI); brain structure segmentation	CLASSIFICATION; LIKELIHOOD; SEGMENTATION; VALIDATION; ALGORITHM	Mixture models are often used to compactly represent samples from heterogeneous sources. However, in real world, the samples generally contain an unknown fraction of outliers and the sources generate different or unbalanced numbers of observations. Such unbalanced and contaminated samples may, for instance, be obtained by high density data sensors such as imaging devices. Estimation of unbalanced mixture models from samples with outliers requires robust estimation methods. In this paper, we propose a novel robust mixture estimator incorporating trimming of the outliers based on component-wise confidence level ordering of observations. The proposed method is validated and compared to the state-of-the-art FAST-TLE method on two data sets, one consisting of synthetic samples with a varying fraction of outliers and a varying balance between mixture weights, while the other data set contained structural magnetic resonance images of the brain with tumors of varying volumes. The results on both data sets clearly indicate that the proposed method is capable to robustly estimate unbalanced mixtures over a broad range of outlier fractions. As such, it is applicable to real-world samples, in which the outlier fraction cannot be estimated in advance.	[Galimzianova, Alfiia; Pernus, Franjo; Likar, Bostjan; Spiclin, Ziga] Univ Ljubljana, Fac Elect Engn, SI-1000 Ljubljana, Slovenia	University of Ljubljana	Galimzianova, A (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska 25, SI-1000 Ljubljana, Slovenia.	alfiia.galimzianova@fe.uni-lj.si; franjo.pernus@fe.uni-lj.si; bostjan.likar@fe.uni-lj.si; ziga.spiclin@fe.uni-lj.si	Spiclin, Ziga/AAL-3031-2020	Spiclin, Ziga/0000-0001-8300-0417; Galimzianova, Alfiia/0000-0002-2901-6423	Ministry of Education, Science and Sport, Republic of Slovenia [J2-5473, L2-5472, L2-4072]	Ministry of Education, Science and Sport, Republic of Slovenia	This research was supported by the Ministry of Education, Science and Sport, Republic of Slovenia, under grants J2-5473, L2-5472, and L2-4072. A. Galimzianova is the corresponding author.	Garcia-Escudero LA, 2010, ADV DATA ANAL CLASSI, V4, P89, DOI 10.1007/s11634-010-0064-5; Aubert-Broche B, 2006, IEEE T MED IMAGING, V25, P1410, DOI 10.1109/TMI.2006.883453; Bricq S., 2008, GRAND CHALLENGE WORK, P1; Browne RP, 2012, IEEE T PATTERN ANAL, V34, P814, DOI 10.1109/TPAMI.2011.199; Cuadra MB, 2005, IEEE T MED IMAGING, V24, P1548, DOI 10.1109/TMI.2005.857652; Cuesta-Albertos JA, 2008, J R STAT SOC B, V70, P779, DOI 10.1111/j.1467-9868.2008.00657.x; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Franczak BC, 2014, IEEE T PATTERN ANAL, V36, P1149, DOI 10.1109/TPAMI.2013.216; Galimzianova Alfiia, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P84, DOI 10.1007/978-3-319-05530-5_9; Gallegos M., 2009, SANKHYA, V71, P164; Gallegos MT, 2009, ADV DATA ANAL CLASSI, V3, P135, DOI 10.1007/s11634-009-0044-9; Gallegos MT, 2005, ANN STAT, V33, P347, DOI 10.1214/009053604000000940; Garcia-Escudero LA, 2008, ANN STAT, V36, P1324, DOI 10.1214/07-AOS515; Garcia-Lorenzo D, 2011, IEEE T MED IMAGING, V30, P1455, DOI 10.1109/TMI.2011.2114671; Garcia-Lorenzo D, 2009, LECT NOTES COMPUT SC, V5762, P584, DOI 10.1007/978-3-642-04271-3_71; GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618; Hadi AS, 1997, COMPUT STAT DATA AN, V25, P251, DOI 10.1016/S0167-9473(97)00011-X; Hyndman RJ, 1996, AM STAT, V50, P120, DOI 10.2307/2684423; Lee SX, 2013, STAT METHOD APPL-GER, V22, P427, DOI 10.1007/s10260-013-0237-4; Ma JW, 2005, PATTERN RECOGN, V38, P2602, DOI 10.1016/j.patcog.2005.03.010; Maronna R. A., 2006, ROBUST STAT THEORY M; McLachlan G, 2005, FINITE MIXTURE MODEL; McLachlan GJ, 2006, AUST J STAT, V35, P157; Naim I., 2012, P 29 INT COFERENCE I, P1427; Neykov N, 2007, COMPUT STAT DATA AN, V52, P299, DOI 10.1016/j.csda.2006.12.024; Neykov NM, 2012, COMPUT STAT DATA AN, V56, P34, DOI 10.1016/j.csda.2011.07.007; Neykov NM, 2003, DEVELOPMENTS IN ROBUST STATISTICS, P277; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Prastawa M, 2009, MED IMAGE ANAL, V13, P297, DOI 10.1016/j.media.2008.11.002; Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566; Tohka J, 2007, IEEE T MED IMAGING, V26, P696, DOI 10.1109/TMI.2007.895453; Tomas-Fernandez X, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1543, DOI 10.1109/ISBI.2012.6235867; Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; Yao WX, 2014, COMPUT STAT DATA AN, V71, P116, DOI 10.1016/j.csda.2013.07.019; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424	36	10	10	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2273	2285		10.1109/TPAMI.2015.2404835	http://dx.doi.org/10.1109/TPAMI.2015.2404835			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440267				2022-12-18	WOS:000362411000010
J	Liu, HR; Latecki, LJ; Yan, SC				Liu, Hairong; Latecki, Longin Jan; Yan, Shuicheng			Dense Subgraph Partition of Positive Hypergraphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph partition; dense subgraph; densest k-subgraph; mode seeking; image matching		In this paper, we present a novel partition framework, called dense subgraph partition (DSP), to automatically, precisely and efficiently decompose a positive hypergraph into dense subgraphs. A positive hypergraph is a graph or hypergraph whose edges, except self-loops, have positive weights. We first define the concepts of core subgraph, conditional core subgraph, and disjoint partition of a conditional core subgraph, then define DSP based on them. The result of DSP is an ordered list of dense subgraphs with decreasing densities, which uncovers all underlying clusters, as well as outliers. A divide-and-conquer algorithm, called min-partition evolution, is proposed to efficiently compute the partition. DSP has many appealing properties. First, it is a nonparametric partition and it reveals all meaningful clusters in a bottom-up way. Second, it has an exact and efficient solution, called min-partition evolution algorithm. The min-partition evolution algorithm is a divide-and-conquer algorithm, thus time-efficient and memory-friendly, and suitable for parallel processing. Third, it is a unified partition framework for a broad range of graphs and hypergraphs. We also establish its relationship with the densest k-subgraph problem (DkS), an NP-hard but fundamental problem in graph theory, and prove that DSP gives precise solutions to DkS for all k in a graph-dependent set, called critical k-set. To our best knowledge, this is a strong result which has not been reported before. Moreover, as our experimental results show, for sparse graphs, especially web graphs, the size of critical k-set is close to the number of vertices in the graph. We test the proposed partition framework on various tasks, and the experimental results clearly illustrate its advantages.	[Liu, Hairong] Purdue Univ, Dept Mech Engn, W Lafayette, IN 47907 USA; [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore	Purdue University System; Purdue University; Purdue University West Lafayette Campus; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; National University of Singapore	Liu, HR (corresponding author), Purdue Univ, Dept Mech Engn, W Lafayette, IN 47907 USA.	lhrbss@gmail.com; latecki@temple.edu; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022	Latecki, Longin Jan/0000-0002-5102-8244	National Science Foundation (NSF) [OIA-1027897, IIS-1302164]; Singapore Ministry of Education [MOE2010-T2-1-087]	National Science Foundation (NSF)(National Science Foundation (NSF)); Singapore Ministry of Education(Ministry of Education, Singapore)	This work was in part supported by National Science Foundation (NSF) under Grants OIA-1027897 and IIS-1302164, and also partially supported by Singapore Ministry of Education under research Grant MOE2010-T2-1-087.	Andreev K, 2006, THEOR COMPUT SYST, V39, P929, DOI 10.1007/s00224-006-1350-7; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; BOROS E, 1991, 171991 RRR; Bulo SR, 2013, IEEE T PATTERN ANAL, V35, P1312, DOI 10.1109/TPAMI.2012.226; Chen J, 2012, IEEE T KNOWL DATA EN, V24, P1216, DOI 10.1109/TKDE.2010.271; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; Emanuel D, 2003, LECT NOTES COMPUT SC, V2832, P208; Feige U, 2001, ALGORITHMICA, V29, P410, DOI 10.1007/s004530010050; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fiduccia CM, 1982, 19TH P DES AUT C, DOI DOI 10.1109/DAC.1982.1585498; Fjallstrom P., 1998, COMPUT INF SCI, V3, P143; Gibson D., 2005, P INT C VER LARG DAT, P721; Goldberg A.V., 1984, FINDING MAXIMUM DENS; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; HUANG DJH, 1995, EUR CONF DESIG AUTOM, P60, DOI 10.1109/EDTC.1995.470419; Ishikawa H, 2011, IEEE T PATTERN ANAL, V33, P1234, DOI 10.1109/TPAMI.2010.91; Kappes Jorg Hendrik, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P31, DOI 10.1007/978-3-642-23094-3_3; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Karypis G, 1997, DES AUT CON, P526, DOI 10.1145/266021.266273; Kernighan Brian W, 1970, BELL SYST TECH J, V49, P291, DOI DOI 10.1002/J.1538-7305.1970.TB01770.X; Khuller S, 2009, LECT NOTES COMPUT SC, V5555, P597, DOI 10.1007/978-3-642-02927-1_50; Kim Sungwoong, 2011, ADV NEURAL INFORM PR; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Kumar V., 1998, HMETIS HYPERGRAPH PA; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Lin F., 2010, P 27 INT C MACH LEAR, V10, P655; Liu H., 2010, ICML, P671; Liu HR, 2013, IEEE T PATTERN ANAL, V35, P2131, DOI 10.1109/TPAMI.2013.16; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Ng AY, 2002, ADV NEUR IN, V14, P849; Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI, VUnabridged edition; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Rodriguez JA, 2009, APPL MATH LETT, V22, P916, DOI 10.1016/j.aml.2008.07.020; Saha B, 2010, LECT N BIOINFORMAT, V6044, P456, DOI 10.1007/978-3-642-12683-3_30; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Yuan XT, 2013, J MACH LEARN RES, V14, P899; Zass R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587500; Zhou D., 2006, ADV NEURAL INF PROCE, V19, P1601	42	10	10	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					541	554		10.1109/TPAMI.2014.2346173	http://dx.doi.org/10.1109/TPAMI.2014.2346173			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353260				2022-12-18	WOS:000349626200005
J	Ben-Shahar, O; Ben-Yosef, G				Ben-Shahar, Ohad; Ben-Yosef, Guy			Tangent Bundle Elastica and Computer Vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual completion; curve completion; tangent bundle; elastica	INTRINSIC CONNECTIONS; SHAPE REPRESENTATION; VISUAL-CORTEX; FUNCTIONAL ARCHITECTURE; HORIZONTAL CONNECTIONS; CONTOUR INTERPOLATION; SUBJECTIVE CONTOURS; CURVATURE; COMPLETION; CURVE	Visual curve completion, an early visual process that completes the occluded parts between observed boundary fragments (a.k.a. inducers), is a major problem in perceptual organization and a critical step toward higher level visual tasks in both biological and machine vision. Most computational contributions to solving this problem suggest desired perceptual properties that the completed contour should satisfy in the image plane, and then seek the mathematical curves that provide them. Alternatively, few studies (including by the authors) have suggested to frame the problem not in the image plane but rather in the unit tangent bundle R-2 x S-1, the space that abstracts the primary visual cortex, where curve completion allegedly occurs. Combining both schools, here we propose and develop a biologically plausible theory of elastica in the tangent bundle that provides not only perceptually superior completion results but also a rigorous computational prediction that inducer curvatures greatly affects the shape of the completed curve, as indeed indicated by human perception.	[Ben-Shahar, Ohad; Ben-Yosef, Guy] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel	Ben Gurion University	Ben-Shahar, O (corresponding author), Ben Gurion Univ Negev, Dept Comp Sci, POB 653, IL-84105 Beer Sheva, Israel.	ben-shahar@cs.bgu.ac.il; guybeny@cs.bgu.ac.il	Ben-Shahar, Ohad/F-8918-2015	Ben-Shahar, Ohad/0000-0001-5346-152X	National Institute for Psychobiology in Israel [9-2012/2013]; Israel Science Foundation (ISF) [259/12]; Frankel Fund; ABC Robotics initiative at BGU; Zlotowski Center for Neuroscience at Ben-Gurion University	National Institute for Psychobiology in Israel; Israel Science Foundation (ISF)(Israel Science Foundation); Frankel Fund; ABC Robotics initiative at BGU; Zlotowski Center for Neuroscience at Ben-Gurion University	This work was supported in part by the National Institute for Psychobiology in Israel (grant no. 9-2012/2013) founded by the Charles E. Smith Family and the Israel Science Foundation (ISF grant no. 259/12). We also thank the Frankel Fund, the ABC Robotics initiative at BGU, and the Zlotowski Center for Neuroscience at Ben-Gurion University for their generous support. GB present address is the Faculty of Mathematics and Computer Science, The Weizmann Institute of Science, POB 26 Rehovot 76100, Israel.	August J, 2003, IEEE T PATTERN ANAL, V25, P387, DOI 10.1109/TPAMI.2003.1190567; Ben-Shahar O, 2004, NEURAL COMPUT, V16, P445, DOI 10.1162/089976604772744866; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Ben-Yosef G, 2012, NEURAL COMPUT, V24, P3277, DOI 10.1162/NECO_a_00365; Ben-Yosef G, 2012, IEEE T PATTERN ANAL, V34, P1263, DOI 10.1109/TPAMI.2011.262; Bosking WH, 1997, J NEUROSCI, V17, P2112; Brady M, 1980, AAAI, P15; BRUCKSTEIN AM, 1990, COMPUT VISION GRAPH, V49, P283, DOI 10.1016/0734-189X(90)90105-5; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chan TF, 2005, COMMUN PUR APPL MATH, V58, P579, DOI 10.1002/cpa.20075; Citti G, 2006, J MATH IMAGING VIS, V24, P307, DOI 10.1007/s10851-005-3630-2; DOBBINS A, 1987, NATURE, V329, P438, DOI 10.1038/329438a0; Dudek G, 1997, COMPUT VIS IMAGE UND, V68, P170, DOI 10.1006/cviu.1997.0533; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Fantoni C, 2003, J VISION, V3, P281, DOI 10.1167/3.4.4; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; Fukushima K, 2010, NEURAL NETWORKS, V23, P528, DOI 10.1016/j.neunet.2009.10.002; Fulvio JM, 2008, VISION RES, V48, P831, DOI 10.1016/j.visres.2007.12.018; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; Gerbino W, 2006, VISION RES, V46, P3142, DOI 10.1016/j.visres.2006.03.030; GILBERT CD, 1992, NEURON, V9, P1, DOI 10.1016/0896-6273(92)90215-Y; GILBERT CD, 1983, J NEUROSCI, V3, P1116; GROSOF DH, 1993, NATURE, V365, P550, DOI 10.1038/365550a0; Guttman SE, 2004, VISION RES, V44, P1799, DOI 10.1016/j.visres.2004.02.008; Heitger F, 1998, IMAGE VISION COMPUT, V16, P407, DOI 10.1016/S0262-8856(97)00083-8; HOFFMAN WC, 1989, APPL MATH COMPUT, V32, P137, DOI 10.1016/0096-3003(89)90091-X; HORN BKP, 1983, ACM T MATH SOFTWARE, V9, P441, DOI 10.1145/356056.356061; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; Kapadia MK, 2000, J NEUROPHYSIOL, V84, P2048, DOI 10.1152/jn.2000.84.4.2048; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kellman PJ, 2003, NEURAL NETWORKS, V16, P915, DOI 10.1016/S0893-6080(03)00101-1; KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D; Kimia BB, 2003, INT J COMPUT VISION, V54, P157, DOI 10.1023/A:1023713602895; Landau L.D., 1986, THEORY ELASTICITY, DOI 10.1016/C2009-0-25521-8; Lee TS, 2001, P NATL ACAD SCI USA, V98, P1907, DOI 10.1073/pnas.031579998; Love A.E.H, 2013, TREATISE MATH THEORY; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; Maertens M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.002.2008; MALACH R, 1993, P NATL ACAD SCI USA, V90, P10469, DOI 10.1073/pnas.90.22.10469; MITCHISON G, 1982, P NATL ACAD SCI-BIOL, V79, P3661, DOI 10.1073/pnas.79.11.3661; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MUMFORD D, 1994, ALGEBRIC GEOMETRY IT; ONeill B., 1966, ELEMENTARY DIFFERENT; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Petitot J., 2003, AXIOMATHES, V13, P347; ROCKLAND KS, 1982, SCIENCE, V215, P1532, DOI 10.1126/science.7063863; RUTKOWSKI WS, 1979, COMPUT VISION GRAPH, V9, P89, DOI 10.1016/0146-664X(79)90086-8; Sarti A, 2000, P NATL ACAD SCI USA, V97, P6258, DOI 10.1073/pnas.110135797; Sarti A, 2009, J PHYSIOL-PARIS, V103, P37, DOI 10.1016/j.jphysparis.2009.05.004; Saund E., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P624, DOI 10.1109/CVPR.1999.784988; Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792; Singh M, 2005, P NATL ACAD SCI USA, V102, P939, DOI 10.1073/pnas.0408444102; Singh M, 2004, PSYCHOL SCI, V15, P454, DOI 10.1111/j.0956-7976.2004.00701.x; Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P943, DOI 10.3758/BF03206908; Singh M, 2007, VISION RES, V47, P783, DOI 10.1016/j.visres.2006.11.022; TAKEICHI H, 1995, PERCEPTION, V24, P1011, DOI 10.1068/p241011; TAKEICHI H, 1995, PERCEPTION, V24, P373, DOI 10.1068/p240373; TSAI DM, 1994, PATTERN RECOGN, V27, P699, DOI 10.1016/0031-3203(94)90048-5; ULLMAN S, 1976, BIOL CYBERN, V25, P1; VERSAVEL M, 1990, VISION RES, V30, P235, DOI 10.1016/0042-6989(90)90039-N; VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501; WEISS I, 1988, COMPUT VISION GRAPH, V41, P80, DOI 10.1016/0734-189X(88)90118-1; WERTHEIMER M, 1955, SOURCE BOOK GESTALT, P71; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837	67	10	10	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					161	174		10.1109/TPAMI.2014.2343214	http://dx.doi.org/10.1109/TPAMI.2014.2343214			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353216				2022-12-18	WOS:000346970600014
J	Ait-Mohand, K; Paquet, T; Ragot, N				Ait-Mohand, Kamel; Paquet, Thierry; Ragot, Nicolas			Combining Structure and Parameter Adaptation of HMMs for Printed Text Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; structure adaptation; parameter adaptation; printed text recognition; historical documents	MODEL SELECTION; SPEAKER ADAPTATION; MARKOV-MODELS; TOPOLOGY; OPTIMIZATION; CRITERION; DESIGN	We present two algorithms that extend existing HMM parameter adaptation algorithms (MAP and MLLR) by adapting the HMM structure. This improvement relies on a smart combination of MAP and MLLR with a structure optimization procedure. Our algorithms are semi-supervised: to adapt a given HMM model on new data, they require little labeled data for parameter adaptation and a moderate amount of unlabeled data to estimate the criteria used for HMM structure optimization. Structure optimization is based on state splitting and state merging operations and proceeds so as to optimize either the likelihood or a heuristic criterion. Our algorithms are successfully applied to the recognition of printed characters by adapting the HMM character models of a polyfont printed text recognizer to new fonts. Our experiments involve a total of 1,120,000 real and 3,100,000 synthetic character images and concern a set of 89 HMM models. A comparison of our results with those of state-of-the-art adaptation algorithms (MAP and MLLR) shows a significant increase in the accuracy of character recognition.	[Ait-Mohand, Kamel; Paquet, Thierry] Univ Rouen, Lab Comp Sci Informat Proc & Syst LITIS, F-76800 St Etienne, Haute Normandie, France; [Ragot, Nicolas] Univ Tours, Lab Comp Sci LI, Polytech Tours Engn Sch, F-37200 Tours, France	Universite de Rouen Normandie; Universite de Tours	Ait-Mohand, K (corresponding author), Univ Rouen, Lab Comp Sci Informat Proc & Syst LITIS, Ave Univ, F-76800 St Etienne, Haute Normandie, France.	kamel.ait-mohand@univ-rouen.fr; Thierry.Paquet@univ-rouen.fr; Nicolas.Ragot@univ-tours.fr	RAGOT, Nicolas/P-3720-2019; RAGOT, Nicolas/I-3804-2016	RAGOT, Nicolas/0000-0003-2321-942X; RAGOT, Nicolas/0000-0003-2321-942X	French National Research Agency (Agence Nationale de la Recherche - ANR)	French National Research Agency (Agence Nationale de la Recherche - ANR)(French National Research Agency (ANR))	This work was carried out in the framework of the NAVIgation into DOcument MASSes (NaviDoMass) project funded by the French National Research Agency (Agence Nationale de la Recherche - ANR). The authors would like to thank Ms. Marie-Luce Demonet from the CESR, Ms. Marie-Elise Freon and Ms. Isabelle Dussert-Carbone from the BnF (where the principal author of this paper had a research associate status for the time of this work) for their collaboration on this work and for the data they provided.	Abou-Moustafa KT, 2004, PATTERN RECOGN LETT, V25, P923, DOI 10.1016/j.patrec.2004.02.005; Ahmed I., 2012, GUIDE OCR ARABIC SCR, P147; Baillie M, 2004, LECT NOTES COMPUT SC, V3115, P70; Baird H. S., 1991, P 1 INT C DOC AN REC, P332; BAIRD HS, 1994, P SOC PHOTO-OPT INS, V2181, P106, DOI 10.1117/12.171098; BAIRD HS, 1995, DOCUMENT IMAGE ANAL, P315; BAKIS R, 1976, J ACOUST SOC AM, V59, pS97, DOI 10.1121/1.2003011; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bicego M, 2003, PATTERN RECOGN LETT, V24, P1395, DOI 10.1016/S0167-8655(02)00380-X; Biem A, 2003, PROC INT CONF DOC, P104; Biem A, 2002, INT CONF ACOUST SPEE, P989; Binsztok H., 2005, ELECT LETT COMPUT VI, V5, P30; Biswas G, 2000, INT C MACH LEARN, P543; BRAND M, 1998, P NEUR INF PROC SYST, P723; Brants T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P893, DOI 10.1109/ICSLP.1996.607745; Breuel T.M., 2008, P SOC PHOTO-OPT INS, V6815; Chen S., 1999, P EUR, V3, P1087; De S. Britto A.  Jr., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P105; DIGALAKIS VV, 1995, IEEE T SPEECH AUDI P, V3, P357, DOI 10.1109/89.466659; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; Freitag D, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P584; Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004; Gales MJF, 1996, COMPUT SPEECH LANG, V10, P249, DOI 10.1006/csla.1996.0013; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Guyon I, 1998, IEEE T PATTERN ANAL, V20, P52, DOI 10.1109/34.655649; Hamdani M., 2011, 2011 5th International Symposium on Computational Intelligence and Intelligent Informatics (ISCIII), P19, DOI 10.1109/ISCIII.2011.6069735; Haralambous Yannis, 2007, FONTS ENCODINGS; Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913; Hewett A.J., 1989, THESIS CAMBRIDGE U; Ho T.K., 1995, P 4 ANN S DOC AN INF, P413; KENNY P, 1990, IEEE T PATTERN ANAL, V12, P917, DOI 10.1109/34.57686; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kwong S, 2001, PATTERN RECOGN, V34, P509, DOI 10.1016/S0031-3203(99)00226-5; Law MH, 2000, INT C PATT RECOG, P195, DOI 10.1109/ICPR.2000.906046; Lee JJ, 2001, INT J PATTERN RECOGN, V15, P107, DOI 10.1142/S0218001401000769; LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010; Li C., 2001, Advances in Intelligent Data Analysis. 4th International Conference, IDA 2001. Proceedings (Lecture Notes in Computer Science Vol.2189), P53; Li C, 1999, LECT NOTES COMPUT SC, V1642, P245; Li DF, 2001, INT CONF ACOUST SPEE, P1521, DOI 10.1109/ICASSP.2001.941221; Liu NJ, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P100; Marosi I, 2007, PROC SPIE, V6500, DOI 10.1117/12.713912; Mohand Kamel Ait, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2877, DOI 10.1109/ICPR.2010.705; Montacie C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P977; Mota S., 2003, COMP VIS PATT REC WO, P321, DOI [10.1109/ CVPRW.2003.10047, DOI 10.1109/CVPRW.2003.10047]; Nartker TA, 2005, P SOC PHOTO-OPT INS, V5676, P37, DOI 10.1117/12.587293; Nishida M, 2005, IEEE T SPEECH AUDI P, V13, P583, DOI 10.1109/TSA.2005.848890; NORMANDIN Y, 1995, INT CONF ACOUST SPEE, P449, DOI 10.1109/ICASSP.1995.479625; Olivier C, 1997, INT J PATTERN RECOGN, V11, P789, DOI 10.1142/S0218001497000354; Ostendorf M, 1997, COMPUT SPEECH LANG, V11, P17, DOI 10.1006/csla.1996.0021; Plotz T., 2009, INT J DOCUMENT ANAL, V12, P269; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Reyes-Gomez MJ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P73; Rodriguez-Serrano J.A., 2008, INT C FRONTIERS HAND, P7; Schambach MP, 2003, PROC INT CONF DOC, P109; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Seymore K., 1999, AAAI 99 WORKSHOP MAC, P37; Siddiqi S.M., 2007, ARTIF INTELL, P492; Stenger B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P294, DOI 10.1109/ICCV.2001.937532; Stolcke A., 1993, P ADV NEUR INF PROC, P11; Takami J., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P573, DOI 10.1109/ICASSP.1992.225855; Vasko RC, 1997, P ANN INT IEEE EMBS, V19, P1725, DOI 10.1109/IEMBS.1997.757055; WEST M, 1993, J ROY STAT SOC B MET, V55, P409; Xu YH, 1999, IEEE T PATTERN ANAL, V21, P1280, DOI 10.1109/34.817408; ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027; Zhang XY, 2013, IEEE T PATTERN ANAL, V35, P1773, DOI 10.1109/TPAMI.2012.239	65	10	13	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1716	1732		10.1109/TPAMI.2014.2306423	http://dx.doi.org/10.1109/TPAMI.2014.2306423			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352227				2022-12-18	WOS:000340210100002
J	Lui, LM; Zeng, W; Yau, ST; Gu, XF				Lui, Lok Ming; Zeng, Wei; Yau, Shing-Tung; Gu, Xianfeng			Shape Analysis of Planar Multiply-Connected Objects Using Conformal Welding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape analysis; shape signature; multiply-connected shapes; conformal welding; conformal modules; morphing	DIFFEOMORPHISMS; RECOGNITION; METRICS; SPACES	Shape analysis is a central problem in the field of computer vision. In 2D shape analysis, classification and recognition of objects from their observed silhouettes are extremely crucial but difficult. It usually involves an efficient representation of 2D shape space with a metric, so that its mathematical structure can be used for further analysis. Although the study of 2D simply-connected shapes has been subject to a corpus of literatures, the analysis of multiply-connected shapes is comparatively less studied. In this work, we propose a representation for general 2D multiply-connected domains with arbitrary topologies using conformal welding. A metric can be defined on the proposed representation space, which gives a metric to measure dissimilarities between objects. The main idea is to map the exterior and interior of the domain conformally to unit disks and circle domains (unit disk with several inner disks removed), using holomorphic 1-forms. A set of diffeomorphisms of the unit circle S-1 can be obtained, which together with the conformal modules are used to define the shape signature. A shape distance between shape signatures can be defined to measure dissimilarities between shapes. We prove theoretically that the proposed shape signature uniquely determines the multiply-connected objects under suitable normalization. We also introduce a reconstruction algorithm to obtain shapes from their signatures. This completes our framework and allows us to move back and forth between shapes and signatures. With that, a morphing algorithm between shapes can be developed through the interpolation of the Beltrami coefficients associated with the signatures. Experiments have been carried out on shapes extracted from real images. Results demonstrate the efficacy of our proposed algorithm as a stable shape representation scheme.	[Lui, Lok Ming] Chinese Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China; [Zeng, Wei] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA; [Yau, Shing-Tung] Harvard Univ, Dept Math, Cambridge, MA 02138 USA; [Gu, Xianfeng] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Chinese University of Hong Kong; State University System of Florida; Florida International University; Harvard University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Lui, LM (corresponding author), Chinese Univ Hong Kong, Dept Math, Hong Kong, Hong Kong, Peoples R China.	lmlui@math.cuhk.edu.hk; wzeng@cs.fiu.edu; yau@math.harvard.edu; gu@cs.sunysb.edu	Zeng, Wei/J-6474-2014	Lui, Lok Ming/0000-0002-9152-0743; Gu, Xianfeng/0000-0001-8226-5851	RGC GRF [401811]; CUHK Direct Grant [2060413]; NSF [Nets 1016286, IIS 0916286, CCF 1081424]; ONR [N000140910228]	RGC GRF(Hong Kong Research Grants Council); CUHK Direct Grant(Chinese University of Hong Kong); NSF(National Science Foundation (NSF)); ONR(Office of Naval Research)	L. Ming Lui is supported by RGC GRF (Project ID: 401811) and CUHK Direct Grant (Project ID: 2060413). Xianfeng Gu is supported in part of NSF Nets 1016286, NSF IIS 0916286, NSF CCF 1081424 and ONR N000140910228.	Ahlfors LV., 1953, COMPLEX ANAL; AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; Astala K., 2009, PRINCETON MATH SERIE, V48; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Dryden I.L., 1998, STAT SHAPE ANAL; Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326; Ericsson A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1142; Gardiner F. P., 1999, QUASICONFORMAL TEICH; Henrici P., 1988, APPL COMPUTATIONAL C, V1; Henrici P., 1993, APPL COMPUTATIONAL C, V3; Hildreth E., 1984, MEASUREMENT VISUAL M; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Lee S. M., 2006, P IEEE COMP SOC C CV, V2, P1940; Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378; Lui LM, 2010, LECT NOTES COMPUT SC, V6315, P672; Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI [DOI 10.1007/978-3-662-05105-4_2, 10.1007/978-3-662-05105-4_2]; Michor PW, 2007, APPL COMPUT HARMON A, V23, P74, DOI 10.1016/j.acha.2006.07.004; Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0; Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Sebastian TB, 2002, LECT NOTES COMPUT SC, V2352, P731; Sharon E, 2006, INT J COMPUT VISION, V70, P55, DOI 10.1007/s11263-006-6121-z; Trouve A, 2005, SIAM J MATH ANAL, V37, P17, DOI 10.1137/S0036141002404838; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; Tyng-Luh Liu, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P456, DOI 10.1109/ICCV.1999.791256; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Yang Q, 1999, PATTERN RECOGN, V32, P1039, DOI 10.1016/S0031-3203(98)00054-5; Younes L., 2010, SHAPES DIFFEOMORPHIS; Younes L, 2012, IMAGE VISION COMPUT, V30, P389, DOI 10.1016/j.imavis.2011.09.009; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; Zeng W., 2009, SIAM ACM JOINT C GEO, P89; Zeng W, 2008, LECT NOTES COMPUT SC, V5304, P1, DOI 10.1007/978-3-540-88690-7_1; Zeng W, 2012, NUMER MATH, V121, P671, DOI 10.1007/s00211-012-0446-z; Zeng W, 2008, METHODS APPL ANAL, V15, P539; Zeng W, 2010, IEEE T PATTERN ANAL, V32, P662, DOI 10.1109/TPAMI.2009.201; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	36	10	10	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1384	1401		10.1109/TPAMI.2013.215	http://dx.doi.org/10.1109/TPAMI.2013.215			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353310				2022-12-18	WOS:000338209900008
J	Koehl, P; Hass, J				Koehl, Patrice; Hass, Joel			Automatic Alignment of Genus-Zero Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Conformal mapping; mesh warping; Mobius transformation; nonrigid registration	LOCALIZATION; OPTIMIZATION; GEOMETRY; SYSTEM	A new algorithm is presented that provides a constructive way to conformally warp a triangular mesh of genus zero to a destination surface with minimal metric deformation, as well as a means to compute automatically a measure of the geometric difference between two surfaces of genus zero. The algorithm takes as input a pair of surfaces that are topological 2-spheres, each surface given by a distinct triangulation. The algorithm then constructs a map f between the two surfaces. First, each of the two triangular meshes is mapped to the unit sphere using a discrete conformal mapping algorithm. The two mappings are then composed with a Mobius transformation to generate the function f. The Mobius transformation is chosen by minimizing an energy that measures the distance of f from an isometry. We illustrate our approach using several "real life" data sets. We show first that the algorithm allows for accurate, automatic, and landmark-free nonrigid registration of brain surfaces. We then validate our approach by comparing shapes of proteins. We provide numerical experiments to demonstrate that the distances computed with our algorithm between low-resolution, surface-based representations of proteins are highly correlated with the corresponding distances computed between high-resolution, atomistic models for the same proteins.	[Koehl, Patrice] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Hass, Joel] Univ Calif Davis, Dept Math, Davis, CA 95616 USA	University of California System; University of California Davis; University of California System; University of California Davis	Koehl, P (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.	koehl@cs.ucdavis.edu; hass@math.ucdavis.edu			US National Institutes of Health; US National Science Foundation	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US National Science Foundation(National Science Foundation (NSF))	Patrice Koehl acknowledges support from the US National Institutes of Health. Joel Hass acknowledges support from the US National Science Foundation. The authors would like to thank Nina Amenta and Owen Carmichael for very useful discussions. They thank the authors of FreeSurfer and Spherical Demons for making their codes freely available.	Alliez P, 2002, ACM T GRAPHIC, V21, P347, DOI 10.1145/566570.566588; Angenent S, 1999, LECT NOTES COMPUT SC, V1679, P271; Bers L., 1972, B LOND MATH SOC, V4, P257, DOI [10.1112/blms/4.3.257, DOI 10.1112/BLMS/4.3.257]; Boyer DM, 2011, P NATL ACAD SCI USA, V108, P18221, DOI 10.1073/pnas.1112822108; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Cheng HL, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P399; Cheng HL, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P481, DOI 10.1109/VISUAL.2004.36; Chou JJ, 2001, NAT STRUCT BIOL, V8, P990, DOI 10.1038/nsb1101-990; Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395; Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021; DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361; Eck M., 1995, P ACM SIGGRAPH 95, P175; Edelsbrunner H, 1999, DISCRETE COMPUT GEOM, V21, P87, DOI 10.1007/PL00009412; Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4; Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396; Franklin J, 2007, NUCLEIC ACIDS RES, V35, pW477, DOI 10.1093/nar/gkm342; Gholipour A, 2007, IEEE T MED IMAGING, V26, P427, DOI 10.1109/TMI.2007.892508; Gray J., 1994, REND CIRC MAT PALERM, V2, P47; Gu X., 2003, EUR S GEOM PROC, P127; Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226; HUANG Q, 2008, COMPUT GRAPH FORUM, P1149; Hurdal MK, 1999, LECT NOTES COMPUT SC, V1679, P279; Joshi A., 2004, IEEE T MED IMAGING, V26, P1657; Koehl P., 2006, REV COMPUTATIONAL CH, V22, P1, DOI DOI 10.1002/0471780367.CH1; Kolodny R, 2006, CURR OPIN STRUC BIOL, V16, P393, DOI 10.1016/j.sbi.2006.04.007; Kotter R, 2005, PHILOS T R SOC B, V360, P751, DOI 10.1098/rstb.2005.1625; Lasowski R, 2009, IEEE I CONF COMP VIS, P963, DOI 10.1109/ICCV.2009.5459356; LEE B, 1971, J MOL BIOL, V55, P379, DOI 10.1016/0022-2836(71)90324-X; Lin CJ, 1999, SIAM J OPTIMIZ, V9, P1100, DOI 10.1137/S1052623498345075; Lipman Y, 2011, ADV MATH, V227, P1047, DOI 10.1016/j.aim.2011.01.020; Lipman Y., 2011, MATH COMPUTATION; Lipman Y., 2011, COMMUNICATIONS PURE; Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378; Lu HX, 2012, INT J IMAG SYST TECH, V22, P145, DOI 10.1002/ima.22015; MAX NL, 1988, IEEE COMPUT GRAPH, V8, P42, DOI 10.1109/38.7748; MEMOLI F., 2007, S POINT BAS GRAPH, P81, DOI DOI 10.2312/SPBG/SPBG07/081-090; Otte A, 2006, J PHYSIOL-PARIS, V99, P281, DOI 10.1016/j.jphysparis.2006.03.011; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Shi X., 2009, P INT C COMP GRAPH, P53; Springborn B., 2008, P SIGGRAPH AS, P79; Springborn BA, 2005, MATH Z, V249, P513, DOI 10.1007/s00209-004-0713-5; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Tosun D, 2004, MED IMAGE ANAL, V8, P295, DOI 10.1016/j.media.2004.06.020; Vaillant M, 2005, LECT NOTES COMPUT SC, V3565, P381; Venkatraman V, 2009, CELL BIOCHEM BIOPHYS, V54, P23, DOI 10.1007/s12013-009-9051-x; Wang YL, 2005, LECT NOTES COMPUT SC, V3750, P675, DOI 10.1007/11566489_83; Wu Y, 2005, LECT NOTES COMPUT SC, V3482, P1099; Yeo BTT, 2010, IEEE T MED IMAGING, V29, P650, DOI 10.1109/TMI.2009.2030797; Zelditch M. L., 2004, GEOMETRIC MORPHOMETR, DOI DOI 10.1016/B978-0-12-778460-1.X5000-5	49	10	10	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					466	478		10.1109/TPAMI.2013.139	http://dx.doi.org/10.1109/TPAMI.2013.139			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457504	Green Submitted			2022-12-18	WOS:000331450100006
J	Chatzis, SP; Demiris, Y				Chatzis, Sotirios P.; Demiris, Yiannis			The Infinite-Order Conditional Random Field Model for Sequential Data Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Conditional random field; sequential data; sequence memoizer; mean-field principle	EFFICIENT BELIEF PROPAGATION; ENERGY FUNCTIONS; EM PROCEDURES	Sequential data labeling is a fundamental task in machine learning applications, with speech and natural language processing, activity recognition in video sequences, and biomedical data analysis being characteristic examples, to name just a few. The conditional random field (CRF), a log-linear model representing the conditional distribution of the observation labels, is one of the most successful approaches for sequential data labeling and classification, and has lately received significant attention in machine learning as it achieves superb prediction performance in a variety of scenarios. Nevertheless, existing CRF formulations can capture only one-or few-timestep interactions and neglect higher order dependences, which are potentially useful in many real-life sequential data modeling applications. To resolve these issues, in this paper we introduce a novel CRF formulation, based on the postulation of an energy function which entails infinitely long time-dependences between the modeled data. Building blocks of our novel approach are: 1) the sequence memoizer (SM), a recently proposed nonparametric Bayesian approach for modeling label sequences with infinitely long time dependences, and 2) a mean-field-like approximation of the model marginal likelihood, which allows for the derivation of computationally efficient inference algorithms for our model. The efficacy of the so-obtained infinite-order CRF (CRF infinity) model is experimentally demonstrated.	[Chatzis, Sotirios P.] Cyprus Univ Technol, Dept Elect Engn Comp Engn & Informat, CY-3036 Limassol, Cyprus; [Demiris, Yiannis] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2BT, England	Cyprus University of Technology; Imperial College London	Chatzis, SP (corresponding author), Cyprus Univ Technol, Dept Elect Engn Comp Engn & Informat, 33 Saripolou Str, CY-3036 Limassol, Cyprus.	sotirios.chatzis@cut.ac.cy; y.demiris@imperial.ac.uk	Chatzis, Sotirios/H-1975-2014; Demiris, Yiannis/AAF-3917-2019	Chatzis, Sotirios/0000-0002-4956-4013; Demiris, Yiannis/0000-0003-4917-3343				[Anonymous], 2012, CMU MOCAP DATABASE; [Anonymous], 2006, INTRO STAT RELATIONA; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CARREIRA-PERPINAN M. A., 2004, P IEEE C COMP VIS PA, V2, P692; Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4; Chandler D., 1987, INTRO MODERN STAT ME; Chatzis SP, 2008, IEEE T FUZZY SYST, V16, P1351, DOI 10.1109/TFUZZ.2008.2005008; Chatzis SP, 2010, IEEE T NEURAL NETWOR, V21, P1004, DOI 10.1109/TNN.2010.2046910; Chatzis SP, 2009, IEEE T PATTERN ANAL, V31, P1657, DOI 10.1109/TPAMI.2008.215; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Gasthaus J., 2011, P C NEUR INF PROC SY; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Kohli P., 2007, P IEEE C COMP VIS PA, P1; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Lafferty John, 2001, CONDITIONAL RANDOM F, P282; Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269; Lawrence N., 2012, GAUSSIAN PROCESS SOF; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Marcus M., 2004, CORPUS LINGUISTICS R; McCallum Andrew, 2003, P 7 C NATURAL LANGUA, P188; McDonald R, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S6; Mclachlan G., 2000, WILEY SER PROB STAT; Peng Fuchun, 2004, P 20 INT C COMP LING, P562; Pitman J, 1997, ANN PROBAB, V25, P855; Potetz B, 2007, P IEEE C COMP VIS PA, P1; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rother C, 2009, PROC CVPR IEEE, P1382, DOI 10.1109/CVPRW.2009.5206739; Sen P, 2008, DATA MIN KNOWL DISC, V17, P136, DOI 10.1007/s10618-008-0090-5; Sha F, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P213; Taskar B., 2004, ADV NEURAL INFORM PR, V16; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; Wood F., 2009, P INT C MACH LEARN; Wood F, 2011, COMMUN ACM, V54, P91, DOI 10.1145/1897816.1897842; Ye N., 2009, P ADV NEUR INF PROC; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1; ZERUBIA J, 1990, INT CONF ACOUST SPEE, P2193, DOI 10.1109/ICASSP.1990.115992; Zhang JG, 2010, PATTERN RECOGN, V43, P197, DOI 10.1016/j.patcog.2009.05.015; Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863	45	10	10	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1523	1534		10.1109/TPAMI.2012.208	http://dx.doi.org/10.1109/TPAMI.2012.208			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599063				2022-12-18	WOS:000317857900019
J	MomayyezSiahkal, P; Siddiqi, K				MomayyezSiahkal, Parya; Siddiqi, Kaleem			3D Stochastic Completion Fields for Mapping Connectivity in Diffusion MRI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D directional random walk; Fokker-Planck equation; completion fields; diffusion MRI; probabilistic connectivity; spherical harmonics	BRAIN WHITE-MATTER; FIBER TRACKING; TENSOR; TRACTOGRAPHY; REGULARIZATION; COMPUTATION; VALIDATION; INFERENCE; GEODESICS; MODEL	The 2D stochastic completion field algorithm, introduced by Williams and Jacobs [1], [2], uses a directional random walk to model the prior probability of completion curves in the plane. This construct has had a powerful impact in computer vision, where it has been used to compute the shapes of likely completion curves between edge fragments in visual imagery. Motivated by these developments, we extend the algorithm to 3D, using a spherical harmonics basis to achieve a rotation invariant computational solution to the Fokker-Planck equation describing the evolution of the probability density function underlying the model. This provides a principled way to compute 3D completion patterns and to derive connectivity measures for orientation data in 3D, as arises in 3D tracking, motion capture, and medical imaging. We demonstrate the utility of the approach for the particular case of diffusion magnetic resonance imaging, where we derive connectivity maps for synthetic data, on a physical phantom and on an in vivo high angular resolution diffusion image of a human brain.	[MomayyezSiahkal, Parya; Siddiqi, Kaleem] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada; [MomayyezSiahkal, Parya; Siddiqi, Kaleem] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	McGill University; McGill University	MomayyezSiahkal, P (corresponding author), McGill Univ, Sch Comp Sci, 3480 Univ St, Montreal, PQ H3A 2A7, Canada.	parya.momayyezsiahkal@mail.mcgill.ca; siddiqi@cim.mcgill.ca		Siddiqi, Kaleem/0000-0002-7347-9716	NSERC; FQRNT Quebec	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); FQRNT Quebec(FQRNT)	The authors would like to thank Jennifer Campbell and Bruce Pike for many helpful discussions and for providing the fiber ODF data for our experiments. This work was supported by grants from NSERC and FQRNT Quebec.	Alexander DC, 2002, MAGN RESON MED, V48, P331, DOI 10.1002/mrm.10209; Anderson AW, 2005, MAGN RESON MED, V54, P1194, DOI 10.1002/mrm.20667; Anwander A, 2007, CEREB CORTEX, V17, P816, DOI 10.1093/cercor/bhk034; Basser PJ, 2000, MAGNET RESON MED, V44, P625, DOI 10.1002/1522-2594(200010)44:4<625::AID-MRM17>3.0.CO;2-O; BASSER PJ, 1994, BIOPHYS J, V66, P259, DOI 10.1016/S0006-3495(94)80775-1; Batchelor P. G., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P121; Behrens TEJ, 2003, MAGN RESON MED, V50, P1077, DOI 10.1002/mrm.10609; Bermnan JI, 2008, NEUROIMAGE, V39, P215, DOI 10.1016/j.neuroimage.2007.08.021; Campbell JSW, 2005, NEUROIMAGE, V27, P725, DOI 10.1016/j.neuroimage.2005.05.014; Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319; Catani M, 2002, NEUROIMAGE, V17, P77, DOI 10.1006/nimg.2002.1136; Ciccarelli O, 2003, NEUROIMAGE, V18, P348, DOI 10.1016/S1053-8119(02)00042-3; Descoteaux M, 2007, MAGN RESON MED, V58, P497, DOI 10.1002/mrm.21277; Fillard P, 2009, LECT NOTES COMPUT SC, V5761, P927, DOI 10.1007/978-3-642-04268-3_114; Fletcher PT, 2007, LECT NOTES COMPUT SC, V4584, P346; Fornberg B, 1997, GEOPHYS RES LETT, V24, P3245, DOI 10.1029/97GL03272; Frank T, 1996, FOKKER PLANCK EQUATI; Frey S, 2008, J NEUROSCI, V28, P11435, DOI 10.1523/JNEUROSCI.2388-08.2008; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; Hageman NS, 2009, IEEE T MED IMAGING, V28, P348, DOI 10.1109/TMI.2008.2004403; Jbabdi S, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/320195; Jeurissen B, 2011, HUM BRAIN MAPP, V32, P461, DOI 10.1002/hbm.21032; Jones DK, 2005, MAGNET RESON MED, V53, P1143, DOI 10.1002/mrm.20466; Jones DK, 1999, MAGN RESON MED, V42, P37, DOI 10.1002/(SICI)1522-2594(199907)42:1<37::AID-MRM7>3.0.CO;2-O; Kanizsa G., 1979, PRAEGER SPECIAL STUD; Kimia BB, 2003, INT J COMPUT VISION, V54, P157, DOI 10.1023/A:1023713602895; Koch MA, 2002, NEUROIMAGE, V16, P241, DOI 10.1006/nimg.2001.1052; LEBIHAN D, 1986, RADIOLOGY, V161, P401, DOI 10.1148/radiology.161.2.3763909; LEBIHAN D, 1993, NEUROREPORT, V4, P887; Malcolm JG, 2010, IEEE T MED IMAGING, V29, P1664, DOI 10.1109/TMI.2010.2048121; Momayyez Parya, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P178, DOI 10.1109/CVPR.2009.5204044; Momayyez P., 2011, P 22 INT C INF PROC; MomayyezSiahkal P., 2009, P MICCAI WORKSH DIFF, P81; Mori S, 1999, ANN NEUROL, V45, P265, DOI 10.1002/1531-8249(199902)45:2<265::AID-ANA21>3.0.CO;2-3; Mori S, 2002, NMR BIOMED, V15, P468, DOI 10.1002/nbm.781; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; O'Donnell L, 2002, LECT NOTES COMPUT SC, V2488, P459; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Parker GJM, 2002, IEEE T MED IMAGING, V21, P505, DOI 10.1109/TMI.2002.1009386; Pechaud M, 2009, LECT NOTES COMPUT SC, V5762, P482, DOI 10.1007/978-3-642-04271-3_59; Petry S., 1987, PERCEPTION ILLUSORY; Pichon E, 2005, LECT NOTES COMPUT SC, V3749, P180; Poupon C, 2000, NEUROIMAGE, V12, P184, DOI 10.1006/nimg.2000.0607; Poupon C, 2008, MAGN RESON MED, V60, P1276, DOI 10.1002/mrm.21789; Rushworth MFS, 2006, CEREB CORTEX, V16, P1418, DOI 10.1093/cercor/bhj079; Savadjiev P, 2006, MED IMAGE ANAL, V10, P799, DOI 10.1016/j.media.2006.06.009; Tournier JD, 2004, NEUROIMAGE, V23, P1176, DOI 10.1016/j.neuroimage.2004.07.037; Tuch DS, 2004, MAGN RESON MED, V52, P1358, DOI 10.1002/mrm.20279; ULLMAN S, 1976, BIOL CYBERN, V25, P1; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Venkataramani A, 2010, LECT NOTES COMPUT SC, V6361, P191; Williams LR, 1997, NEURAL COMPUT, V9, P859, DOI 10.1162/neco.1997.9.4.859; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Yo TS, 2009, LECT NOTES COMPUT SC, V5761, P886; Zweck J, 2004, J MATH IMAGING VIS, V21, P135, DOI 10.1023/B:JMIV.0000035179.47895.bc	55	10	10	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					983	995		10.1109/TPAMI.2012.184	http://dx.doi.org/10.1109/TPAMI.2012.184			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	23428434	Green Submitted			2022-12-18	WOS:000314931000016
J	Andreetto, M; Zelnik-Manor, L; Perona, P				Andreetto, Marco; Zelnik-Manor, Lihi; Perona, Pietro			Unsupervised Learning of Categorical Segments in Image Collections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; image segmentation; unsupervised object recognition; graphical models; density estimation; scene analysis	TEXTURE	Which one comes first: segmentation or recognition? We propose a unified framework for carrying out the two simultaneously and without supervision. The framework combines a flexible probabilistic model, for representing the shape and appearance of each segment, with the popular "bag of visual words" model for recognition. If applied to a collection of images, our framework can simultaneously discover the segments of each image and the correspondence between such segments, without supervision. Such recurring segments may be thought of as the "parts" of corresponding objects that appear multiple times in the image collection. Thus, the model may be used for learning new categories, detecting/classifying objects, and segmenting images, without using expensive human annotation.	[Andreetto, Marco] Google Los Angeles US LAX BIN, Venice, CA 90291 USA; [Zelnik-Manor, Lihi] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; [Perona, Pietro] CALTECH, Dept Elect Engn, Pasadena, CA 91125 USA	Google Incorporated; Technion Israel Institute of Technology; California Institute of Technology	Andreetto, M (corresponding author), Google Los Angeles US LAX BIN, 340 Main St, Venice, CA 90291 USA.	marco@vision.caltech.edu; lihi@ee.technion.ac.il; perona@caltech.edu			ONR-MURI [N00014-06-1-0734]; FP7-IRG [2009783]	ONR-MURI(MURIOffice of Naval Research); FP7-IRG	The authors would like to thank Greg Griffin and Kristin Branson for reviewing the manuscript and giving many important suggestions for improving it. Funding for this research was provided by ONR-MURI Grant N00014-06-1-0734. Lihi Zelnik-Manor is supported by FP7-IRG grant 2009783.	Ahuja N., 2007, P 11 IEEE INT C COMP; Andreetto M., 2007, P 11 IEEE INT C COMP; Andreetto M., 2011, THESIS CALTECH; [Anonymous], 2004, MICROSOFT RES CAMBRI; Bishop, 1995, NEURAL NETWORKS PATT; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Brox T, 2007, LECT NOTES COMPUT SC, V4814, P152; Cao L., 2007, P 11 IEEE INT C COMP; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; CASELLA R, 1999, MONTE CARLO STAT MET; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T, 2005, PROC CVPR IEEE, P1124; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Duda R.O., 2000, PATTERN CLASSIFICATI; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Everingham M., 2012, PASCAL VISUAL OBJECT; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fergus R., 2003, P IEEE C COMP VIS PA; Genovese CR, 2000, ANN STAT, V28, P1105; Jin R., 2005, P ADV NEUR INF PROC; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313; Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10; Lee A., 2001, INT J COMPUT VISION, V41, P7; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Marr D., 1982, VISION COMPUTATIONAL; Meila M, 2001, ADV NEUR IN, V13, P873; Ng A., 2001, P ADV NEURAL INFORM; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Orbanz P, 2008, INT J COMPUT VISION, V77, P25, DOI 10.1007/s11263-007-0061-0; Rabinovich A., 2007, P 11 IEEE INT C COMP; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Russell B. C., 2006, P IEEE C COMP VIS PA; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sivic J., 2005, P 10 IEEE INT C COMP; Sudderth E.B., 2008, P ADV NEUR INF PROC; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Verbeek J., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383098; Vidal-Naquet M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P281; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang X., 2007, P ADV NEUR INF PROC; Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18; WEI GCG, 1990, J AM STAT ASSOC, V85, P699, DOI 10.2307/2290005; Winn J., 2005, P 10 IEEE INT C COMP; Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179; Zass R, 2005, IEEE I CONF COMP VIS, P294; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601	57	10	10	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1842	1855		10.1109/TPAMI.2011.268	http://dx.doi.org/10.1109/TPAMI.2011.268			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22201050	Green Accepted			2022-12-18	WOS:000306409100015
J	Tung, T; Matsuyama, T				Tung, Tony; Matsuyama, Takashi			Topology Dictionary for 3D Video Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D video; dictionary; Reeb graph; topology matching; Markov model; editing; summarization; semantic description	DEFORMATION; COMPRESSION; CAPTURE	This paper presents a novel approach that achieves 3D video understanding. 3D video consists of a stream of 3D models of subjects in motion. The acquisition of long sequences requires large storage space (2 GB for 1 min). Moreover, it is tedious to browse data sets and extract meaningful information. We propose the topology dictionary to encode and describe 3D video content. The model consists of a topology-based shape descriptor dictionary which can be generated from either extracted patterns or training sequences. The model relies on 1) topology description and classification using Reeb graphs, and 2) a Markov motion graph to represent topology change states. We show that the use of Reeb graphs as the high-level topology descriptor is relevant. It allows the dictionary to automatically model complex sequences, whereas other strategies would require prior knowledge on the shape and topology of the captured subjects. Our approach serves to encode 3D video sequences, and can be applied for content-based description and summarization of 3D video sequences. Furthermore, topology class labeling during a learning process enables the system to perform content-based event recognition. Experiments were carried out on various 3D videos. We showcase an application for 3D video progressive summarization using the topology dictionary.	[Tung, Tony; Matsuyama, Takashi] Kyoto Univ, Dept Intelligence Sci & Technol, Matsuyama Lab, Grad Sch Informat,Sakyo Ku, Kyoto 6068501, Japan	Kyoto University	Tung, T (corresponding author), Kyoto Univ, Dept Intelligence Sci & Technol, Matsuyama Lab, Grad Sch Informat,Sakyo Ku, Kyoto 6068501, Japan.	tung@vision.kuee.kyoto-u.ac.jp; tm@i.kyoto-u.ac.jp			JST-CREST "Creation of Human-Harmonized Information Technology for Convivial Society"; Japan Society for the Promotion of Science [23700170]; Grants-in-Aid for Scientific Research [23700170] Funding Source: KAKEN	JST-CREST "Creation of Human-Harmonized Information Technology for Convivial Society"; Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); Grants-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work was supported in part by the JST-CREST project "Creation of Human-Harmonized Information Technology for Convivial Society," and the Japan Society for the Promotion of Science (Wakate-B No. 23700170). The authors thank Ms. Kinh Thang and Ms. Karine Tung for their support, as well as Ms. Bidda Camilla Solvang Poulsen for her graphic design work.	Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433; Allard J., 2007, P ACM SIGGR; Alliez P, 2005, MATH VIS, P3, DOI 10.1007/3-540-26808-1_1; Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606; Baran I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276467; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; Cheung KM, 2005, INT J COMPUT VISION, V63, P225, DOI 10.1007/s11263-005-6879-4; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Franco J.-S., 2004, P IEEE COMP SOC C CO, P31; Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15; Gray R. M., 1992, VECTOR QUANTIZATION; Habe H., 2004, P PICT COD S; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; Huang P., 2010, P INT S 3D DAT PROC; Huang P., 2009, P IEEE C COMP VIS PA; Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9; Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074; Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002; Kho Y, 2005, ACM T GRAPHIC, V24, P934, DOI 10.1145/1073204.1073291; Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605; Lee JH, 2002, ACM T GRAPHIC, V21, P491; Matsuyama T, 2004, COMPUT VIS IMAGE UND, V96, P393, DOI 10.1016/j.cviu.2004.03.012; Meyn S. P., 2008, MARKOV CHAINS STOCHA; Mizuguchi T., 2001, P EUR SHORT PRES; MOLINATANCO L, 2000, P IEEE WORKSH HUM MO; Muller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247; Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694; Palagyi K, 1999, GRAPH MODEL IM PROC, V61, P199, DOI 10.1006/gmip.1999.0498; Park SI, 2006, ACM T GRAPHIC, V25, P881, DOI 10.1145/1141911.1141970; Pascucci V, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239509; Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29; REEB G, 1946, CR HEBD ACAD SCI, V222, P847; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Sharf A, 2007, COMPUT GRAPH FORUM, V26, P323, DOI 10.1111/j.1467-8659.2007.01054.x; Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414; Sorkine O., 2007, P 5 EUR S GEOM PROC, V4, P109, DOI [DOI 10.2312/SGP/SGP07/109-116, 10.2312/SGP/SGP07/109-116]; Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; Sullivan J., 2002, P 7 EUR C COMP VIS; Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748; Tung T., 2009, P IEEE C COMP VIS PA; Tung T., 2009, P 13 IEEE INT C COMP; Tung T., 2008, P IEEE C COMP VIS PA; Tung T., 2007, P IEEE C COMP VIS PA; Tung T., 2012, SHAPE SIMILARITY COM; Weinland D., 2007, P 11 IEEE INT C COMP; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628; ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714	53	10	12	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1645	1657		10.1109/TPAMI.2011.258	http://dx.doi.org/10.1109/TPAMI.2011.258			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22745004	Green Published			2022-12-18	WOS:000305188500015
J	Castellani, U; Cristani, M; Murino, V				Castellani, Umberto; Cristani, Marco; Murino, Vittorio			Statistical 3D Shape Analysis by Local Generative Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D shape analysis; shape representation; Hidden Markov Models; generative modeling	REGISTRATION	In this paper, we propose a new approach for surface representation. Generative models are exploited for encoding the variations of local geometric properties of 3D shapes. Surfaces are locally modeled as a stochastic process which spans a neighborhood area through a set of circular geodesic pathways, captured by a modified version of a Hidden Markov Model (HMM) named multicircular HMM (MC-HMM). The approach proposed consists of two main phases: 1) local geometric feature collection and 2) MC-HMM parameter estimation. The effectiveness of our proposal is demonstrated by several applicative scenarios, all using well-known benchmark data sets, such as multiple view registration, matching of deformable shapes, and object recognition on cluttered scenes. The results achieved are very promising and open up the use of generative models as geometric descriptors in an extensive range of applications.	[Castellani, Umberto; Cristani, Marco; Murino, Vittorio] Univ Verona, Dipartimento Informat, I-37134 Verona, Italy; [Cristani, Marco; Murino, Vittorio] Ist Italiano Tecnol, I-16163 Genoa, Italy	University of Verona; Istituto Italiano di Tecnologia - IIT	Castellani, U (corresponding author), Univ Verona, Dipartimento Informat, Str Le Grazie 15, I-37134 Verona, Italy.	umberto.castellani@univr.it; marco.cristani@univr.it; vittorio.murino@univr.it	Cristani, Marco/I-5275-2012	Murino, Vittorio/0000-0002-8645-2328				Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein MM, 2011, IEEE T PATTERN ANAL, V33, P1065, DOI 10.1109/TPAMI.2010.210; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0; Novatnack J., 2007, INT C COMP VIS; Novatnack J., 2008, P 10 EUR C COMP VI 3; Petitjean S, 2002, ACM COMPUT SURV, V34, P211, DOI 10.1145/508352.508354; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Smyth P, 1997, ADV NEUR IN, V9, P648; Tangelder J. W., 2004, P INT C SHAP MOD APP; Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748; Zhang H., 2010, COMPUT GRAPH FORUM, P1; [No title captured]	21	10	14	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2555	2560		10.1109/TPAMI.2011.85	http://dx.doi.org/10.1109/TPAMI.2011.85			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21576733				2022-12-18	WOS:000295980000020
J	Felzenszwalb, PF; McAuley, JJ				Felzenszwalb, Pedro F.; McAuley, Julian J.			Fast Inference with Min-Sum Matrix Product	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphical models; MAP inference; min-sum matrix product	PATH; TIME; ALGORITHM	The MAP inference problem in many graphical models can be solved efficiently using a fast algorithm for computing min-sum products of n x n matrices. The class of models in question includes cyclic and skip-chain models that arise in many applications. Although the worst-case complexity of the min-sum product operation is not known to be much better than O(n(3)), an O(n(2.5)) expected time algorithm was recently given, subject to some constraints on the input matrices. In this paper, we give an algorithm that runs in O(n(2) log n) expected time, assuming that the entries in the input matrices are independent samples from a uniform distribution. We also show that two variants of our algorithm are quite fast for inputs that arise in several applications. This leads to significant performance gains over previous methods in applications within computer vision and natural language processing.	[Felzenszwalb, Pedro F.] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; [McAuley, Julian J.] NICTA, Canberra, ACT 2601, Australia; [McAuley, Julian J.] Australian Natl Univ, Canberra, ACT 2601, Australia	University of Chicago; Australian National University; Australian National University	Felzenszwalb, PF (corresponding author), Univ Chicago, Dept Comp Sci, 1100 E 58th St, Chicago, IL 60637 USA.	pff@cs.uchicago.edu; julian.mcauley@gmail.com						Aho AV, 1974, DESIGN ANAL COMPUTER; Aji SM, 2000, IEEE T INFORM THEORY, V46, P325, DOI 10.1109/18.825794; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; [Anonymous], 2006, INTRO STAT RELATIONA; Bertele U., 1972, NONSERIAL DYNAMIC PR; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y. Y., 2001, P IEEE INT C COMP VI; Chan TM, 2007, ACM S THEORY COMPUT, P590, DOI 10.1145/1250790.1250877; Coughlan J. M., 2002, P EUR C COMP VIS; Felzenszwalb PF, 2007, J ARTIF INTELL RES, V29, P153, DOI 10.1613/jair.2187; FRIEZE AM, 1985, DISCRETE APPL MATH, V10, P57, DOI 10.1016/0166-218X(85)90059-9; KARGER DR, 1993, SIAM J COMPUT, V22, P1199, DOI 10.1137/0222071; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KNUTH DE, 1977, INFORM PROCESS LETT, V6, P1, DOI 10.1016/0020-0190(77)90002-3; McAuley J. J., 2010, P AI STAT; McAuley JJ, 2008, IEEE T PATTERN ANAL, V30, P2047, DOI 10.1109/TPAMI.2008.124; MOFFAT A, 1987, SIAM J COMPUT, V16, P1023, DOI 10.1137/0216065; Paskin M.A., 2003, P INT JOINT C ART IN; Quasthoff U., 2006, P LANG RES EV; Sigal L., 2006, P C ART MOT DEF OBJ; STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411; VALIANT LG, 1975, J COMPUT SYST SCI, V10, P308, DOI 10.1016/S0022-0000(75)80046-8; YEDIDIA J, 2000, P NEUR INF PROC SYST	24	10	12	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2549	2554		10.1109/TPAMI.2011.121	http://dx.doi.org/10.1109/TPAMI.2011.121			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21670488	Green Submitted			2022-12-18	WOS:000295980000019
J	Chandraker, M; Bai, JM; Ng, TT; Ramamoorthi, R				Chandraker, Manmohan; Bai, Jiamin; Ng, Tian-Tsong; Ramamoorthi, Ravi			On the Duality of Forward and Inverse Light Transport	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light transport; rendering equation; inverse light transport; duality theory; interreflections; radiometric compensation	GLOBAL ILLUMINATION	Inverse light transport seeks to undo global illumination effects, such as interreflections, that pervade images of most scenes. This paper presents the theoretical and computational foundations for inverse light transport as a dual of forward rendering. Mathematically, this duality is established through the existence of underlying Neumann series expansions. Physically, it can be shown that each term of our inverse series cancels an interreflection bounce, just as the forward series adds them. While the convergence properties of the forward series are well known, we show that the oscillatory convergence of the inverse series leads to more interesting conditions on material reflectance. Conceptually, the inverse problem requires the inversion of a large light transport matrix, which is impractical for realistic resolutions using standard techniques. A natural consequence of our theoretical framework is a suite of fast computational algorithms for light transport inversion-analogous to finite element radiosity, Monte Carlo and wavelet-based methods in forward rendering-that rely at most on matrix-vector multiplications. We demonstrate two practical applications, namely, separation of individual bounces of the light transport and fast projector radiometric compensation, to display images free of global illumination artifacts in real-world environments.	[Chandraker, Manmohan; Bai, Jiamin; Ramamoorthi, Ravi] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Ng, Tian-Tsong] Inst Infocomm Res, Singapore 138632, Singapore	University of California System; University of California Berkeley; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)	Chandraker, M (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	manukc@eecs.berkeley.edu; bjiamin@eecs.berkeley.edu; ttng@i2r.a-star.edu.sg; ravir@eecs.berkeley.edu	Chandraker, Manmohan/AAU-4762-2021	Ng, Tian Tsong/0000-0002-6713-2310	US Office of Naval Research (ONR) YIP [N00014-10-1-0032]; ONR PECASE [N00014-09-1-0741]; A*STAR Graduate Academy of Singapore	US Office of Naval Research (ONR) YIP(Office of Naval Research); ONR PECASE(Office of Naval Research); A*STAR Graduate Academy of Singapore(Agency for Science Technology & Research (A*STAR))	This work was funded by US Office of Naval Research (ONR) YIP grant N00014-10-1-0032, ONR PECASE grant N00014-09-1-0741, a National Science Scholarship from the A*STAR Graduate Academy of Singapore, as well as generous support from Adobe, NVIDIA, Intel, and Pixar. The authors would like to thank Joo Hwee Lim and Zhiyong Huang for kind support at I<SUP>2</SUP>R and the anonymous reviewers of this paper and [11] for useful comments.	ARVO J, 1994, P ACM SIGGRAPH, P75; BAI J, 2010, UCBEECS2010101; Bai J., 2010, P EUR C COMP VIS; Bimber O, 2006, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2006.34; Christensen PH, 1996, ACM T GRAPHIC, V15, P37, DOI 10.1145/226150.226153; Cohen M.F., 1993, RADIOSITY REALISTIC; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Demmel JW, 1997, APPL NUMERICAL LINEA, V56; DING Y, 2009, P IEEE C COMP VIS PA; Forsythe G., 1950, MATH TABLES OTHER AI, V4, P127; FUJII K, 2005, P IEEE C COMP VIS PA; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GORTLER S, 1993, P SIGGRAPH, P221; HANRAHAN P, 1991, COMP GRAPH, V25, P197; Kajiya JamesT., 1986, P 13 ANN C COMP GRAP, P143, DOI DOI 10.1145/15922.15902; Liu S., 2010, P EUR C COMP VIS; Marschner S. R, 1998, THESIS CORNELL U; Masselus V, 2003, ACM T GRAPHIC, V22, P613, DOI 10.1145/882262.882315; MUKAIGAWA Y, 2006, P ACM S VIRT REAL SO, P265; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280; NG TT, 2009, P IEEE INT C COMP VI; OTOOLE M, 2010, P SIGGRAPH AS 2010; Peers P, 2006, ACM T GRAPHIC, V25, P746, DOI 10.1145/1141911.1141950; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; RASKAR R, 2001, P EUROGRAPHICS WORKS; Seitz SM, 2005, IEEE I CONF COMP VIS, P1440; Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257; VEACH E, 1998, THESIS STANFORD U; Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47; Yu YZ, 1999, COMP GRAPH, P215	31	10	11	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2122	2128		10.1109/TPAMI.2011.124	http://dx.doi.org/10.1109/TPAMI.2011.124			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21670483	Green Submitted			2022-12-18	WOS:000293969000018
J	Patras, I; Hancock, ER				Patras, Ioannis; Hancock, Edwin R.			Coupled Prediction Classification for Robust Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Regression; tracking; state estimation; relevance determination; probabilistic tracking	DENSITY PROPAGATION; MIXTURES; MODELS	This paper addresses the problem of robust template tracking in image sequences. Our work falls within the discriminative framework in which the observations at each frame yield direct probabilistic predictions of the state of the target. Our primary contribution is that we explicitly address the problem that the prediction accuracy for different observations varies, and in some cases, can be very low. To this end, we couple the predictor to a probabilistic classifier which, when trained, can determine the probability that a new observation can accurately predict the state of the target (that is, determine the "relevance" or "reliability" of the observation in question). In the particle filtering framework, we derive a recursive scheme for maintaining an approximation of the posterior probability of the state in which multiple observations can be used and their predictions moderated by their corresponding relevance. In this way, the predictions of the "relevant" observations are emphasized, while the predictions of the "irrelevant" observations are suppressed. We apply the algorithm to the problem of 2D template tracking and demonstrate that the proposed scheme outperforms classical methods for discriminative tracking both in the case of motions which are large in magnitude and also for partial occlusions.	[Patras, Ioannis] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England; [Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	University of London; Queen Mary University London; University of York - UK	Patras, I (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, Mile End Rd, London E1 4NS, England.	i.patras@elec.qmul.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028; Patras, Ioannis/0000-0003-3913-4738	Engineering and Physical Sciences Research Council [EP/G033935/1]; Royal Society; EU FET [213250]; EPSRC [EP/G033935/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Royal Society(Royal Society of London); EU FET; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The work of Ioannis Patras is partially supported by the Engineering and Physical Sciences Research Council, research grant EP/G033935/1. The work of Edwin Hancock was supported by a Royal Society Wolfson Research Merit Award and the EU FET project SIMBAD (213250).	Agarwal A, 2006, LECT NOTES COMPUT SC, V3851, P50; Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; BLACK MJ, 1996, P EUR C COMP VIS, P329; BUCHANAN AM, 2007, P IEEE C COMP VIS PA; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; DEUTSCHER J, 2001, P INT C COMP VIS PAT; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; OKUMA K, 2004, P EUR C COMP VIS, P28; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515; PATRAS I, 2007, P IEEE C COMP VIS PA; Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179; SIGAL L, 2004, P INT C COMP VIS PAT; SIMONCELLI EP, 1991, IEEE C COMP VIS PATT, P310, DOI 10.1109/CVPR.1991.139707; SMINCHISESCU C, 2005, P IEEE C COMP VIS PA; Sminchisescu C, 2007, IEEE T PATTERN ANAL, V29, P2030, DOI 10.1109/TPAMI.2007.1111; TIPPING M, 2000, ADV NEURAL INFORM PR; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; VLASSIS N, 2004, IASUVA0401 U AMST IN; Waterhouse S, 1996, ADV NEUR IN, V8, P351; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; Wu Y, 2003, PROC CVPR IEEE, P295; Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119	32	10	11	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1553	1567		10.1109/TPAMI.2009.175	http://dx.doi.org/10.1109/TPAMI.2009.175			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634552				2022-12-18	WOS:000279969000002
J	Peres, RT; Pedreira, CE				Peres, R. T.; Pedreira, C. E.			Generalized Risk Zone: Selecting Observations for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification; neural networks; observations selection; risk zone; support vector machine		In this paper, we extend the risk zone concept by creating the Generalized Risk Zone. The Generalized Risk Zone is a model-independent scheme to select key observations in a sample set. The observations belonging to the Generalized Risk Zone have shown comparable, in some experiments even better, classification performance when compared to the use of the whole sample. The main tool that allows this extension is the Cauchy-Schwartz divergence, used as a measure of dissimilarity between probability densities. To overcome the setback concerning pdf's estimation, we used the ideas provided by the Information Theoretic Learning, allowing the calculation to be performed on the available observations only. We used the proposed methodology with Learning Vector Quantization, feedforward Neural Networks, Support Vector Machines, and Nearest Neighbors.	[Peres, R. T.; Pedreira, C. E.] Univ Fed Rio de Janeiro, COPPE, PEE, Engn Grad Program, BR-21945 Rio De Janeiro, Brazil; [Peres, R. T.; Pedreira, C. E.] Univ Fed Rio de Janeiro, Sch Med, Rio De Janeiro, Brazil	Universidade Federal do Rio de Janeiro; Universidade Federal do Rio de Janeiro	Peres, RT (corresponding author), Univ Fed Rio de Janeiro, COPPE, PEE, Engn Grad Program, BR-21945 Rio De Janeiro, Brazil.	rperes@lps.ufrj.br; pedreira@ufrj.br	Pedreira, Carlos/I-5629-2013	Pedreira, Carlos/0000-0002-9312-4023	Brazilian National Research Council (CNPq); Rio de Janeiro Research Foundation (FAPERJ)	Brazilian National Research Council (CNPq)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); Rio de Janeiro Research Foundation (FAPERJ)(Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado do Rio De Janeiro (FAPERJ))	The work of C. E. Pedreira was partially supported by grants from the Brazilian National Research Council (CNPq) and the Rio de Janeiro Research Foundation (FAPERJ). The work of R. T. Peres was supported by a PhD scholarship from CNPq. The authors are also in debt to Professor Alexandre Pinto Alves da Silva and to Mr. Helio Pinto for allowing some of the experiments performed in their Lab (LASPOT-UFRJ).	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bouguila N, 2006, IEEE T IMAGE PROCESS, V15, P2657, DOI 10.1109/TIP.2006.877379; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; DETRANO R, 1989, AM J CARDIOL, V64, P304, DOI 10.1016/0002-9149(89)90524-9; Duda R. O., 2001, PATTERN CLASSIFICATI; FARAWAY JJ, 1990, P 22 S INT COMP SCI, P104; HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; HWANG JN, 1991, IEEE T NEURAL NETWOR, V2, P131, DOI 10.1109/72.80299; JENSEN R, 2005, THESIS U TROMSO; Kohonen T, 2001, SELF ORGANIZING MAPS; Li MK, 2006, IEEE T PATTERN ANAL, V28, P1251, DOI 10.1109/TPAMI.2006.156; Mitra P, 2004, IEEE T PATTERN ANAL, V26, P413, DOI 10.1109/TPAMI.2004.1262340; Olshen R., 1984, CLASSIFICATION REGRE; Pedreira CE, 2006, IEEE T PATTERN ANAL, V28, P157, DOI 10.1109/TPAMI.2006.14; PEDREIRA CE, 2005, P IEEE INT NEUR NETW; PLUTOWSKI M, 1993, IEEE T NEURAL NETWOR, V4, P305, DOI 10.1109/72.207618; PRINCIPE JC, 2000, UNSUPERVISED ADAPTIV; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; Tutz G, 2005, STAT COMPUT, V15, P155, DOI 10.1007/s11222-005-1305-x; Vapnik V.N, 1998, STAT LEARNING THEORY; Vinga S, 2004, J THEOR BIOL, V231, P377, DOI 10.1016/j.jtbi.2004.06.030; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; XU D, 1999, THESIS U FLORIDA	25	10	10	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1331	1337		10.1109/TPAMI.2008.269	http://dx.doi.org/10.1109/TPAMI.2008.269			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443929				2022-12-18	WOS:000266188900015
J	Marttinen, P; Tang, J; De Baets, B; Dawyndt, P; Corander, J				Marttinen, Pekka; Tang, Jing; De Baets, Bernard; Dawyndt, Peter; Corander, Jukka			Bayesian Clustering of Fuzzy Feature Vectors Using a Quasi-Likelihood Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian clustering; fuzzy modeling; quasi-likelihood; continuous data	MODEL SELECTION; IDENTIFICATION	Bayesian model-based classifiers, both unsupervised and supervised, have been studied extensively, and their value and versatility have been demonstrated on a wide spectrum of applications within science and engineering. A majority of the classifiers are built on the assumption of intrinsic discreteness of the considered data features or on their discretization prior to the modeling. On the other hand, Gaussian mixture classifiers have also been utilized to a large extent for continuous features in the Bayesian framework. Often, the primary reason for discretization in the classification context is the simplification of the analytical and numerical properties of the Bayesian models. However, the discretization can be problematic due to its ad hoc nature and the decreased statistical power to detect the correct classes ( or clusters) in the resulting procedure. Here, we introduce an unsupervised classification approach for fuzzy feature vectors that utilizes a discrete model structure while preserving the continuous characteristics of data. This goal is achieved by replacing the ordinary likelihood by a binomial quasi-likelihood to yield an analytical expression for the posterior probability of a given clustering solution. The resulting model can also be justified from an information-theoretic perspective. Our method is shown to yield highly accurate clusterings for challenging synthetic and empirical data sets and to perform favorably compared to some alternative approaches.	[Marttinen, Pekka; Tang, Jing] Univ Helsinki, Dept Math & Stat, FIN-00014 Helsinki, Finland; [De Baets, Bernard] Univ Ghent, Dept Appl Math Biometr & Proc Control, B-9000 Ghent, Belgium; [Dawyndt, Peter] Univ Ghent, Dept Appl Math & Comp Sci, B-9000 Ghent, Belgium; [Corander, Jukka] Abo Akad Univ, Dept Math, SF-20500 Turku, Finland	University of Helsinki; Ghent University; Ghent University; Abo Akademi University	Marttinen, P (corresponding author), Univ Helsinki, Dept Math & Stat, POB 68, FIN-00014 Helsinki, Finland.	pekka.marttinen@helsinki.fi; jing.tang@helsinki.fi; bernard.debaets@ugent.be; peter.dawyndt@ugent.be; jukka.corander@abo.fi	Tang, Jing/H-4084-2012; tang, jing/HHR-9815-2022; Tang, Jing/W-1764-2019; Marttinen, Pekka E/N-6234-2015; De Baets, Bernard/E-8877-2010; Dawyndt, Peter/A-1566-2013	Tang, Jing/0000-0001-7480-7710; Tang, Jing/0000-0001-7480-7710; Marttinen, Pekka E/0000-0001-7078-7927; De Baets, Bernard/0000-0002-3876-620X; Dawyndt, Peter/0000-0002-1623-9070	ComMIT graduate school; University of Helsinki [121301]; Academy of Finland	ComMIT graduate school; University of Helsinki; Academy of Finland(Academy of Finland)	This work was financially supported by the ComMIT graduate school, the research funds of the University of Helsinki, and Grant 121301 from the Academy of Finland. The authors thank Bram Slabbinck, Ghent University, for the Bacillus data set used in the illustrations.	Ashlock D, 2006, EVOLUTIONARY COMPUTA; Bernardo J. M., 1994, BAYESIAN THEORY; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV, ppp153; Corander J, 2007, B MATH BIOL, V69, P797, DOI 10.1007/s11538-006-9161-1; Corander J, 2006, FISH B-NOAA, V104, P550; Corander J, 2006, STAT COMPUT, V16, P355, DOI 10.1007/s11222-006-9391-y; Dawyndt P, 2006, J MICROBIOL METH, V66, P410, DOI 10.1016/j.mimet.2006.01.008; De Baets B, 2005, EUR J OPER RES, V160, P726, DOI 10.1016/j.ejor.2003.06.036; DEBAETS B, 2008, INT J APPRO IN PRESS; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1925, P CAMB PHILOS SOC, V22, P700, DOI 10.1017/S0305004100009580; Gelman A., 1996, BAYESIAN DATA ANAL; Gevers D, 2006, PHILOS T R SOC B, V361, P1911, DOI 10.1098/rstb.2006.1915; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x; Herbich R, 2001, J MACH LEARN RES, V1, P245, DOI 10.1162/153244301753683717; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jiang WX, 2004, J STAT PLAN INFER, V121, P265, DOI 10.1016/S0378-3758(03)00112-5; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; Kim HC, 2006, IEEE T PATTERN ANAL, V28, P1948, DOI 10.1109/TPAMI.2006.238; KOHAVI R, 1996, P 2 INT C KNOWL DISC, P114; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; Laskey KB, 2003, MACH LEARN, V50, P175, DOI 10.1023/A:1020206129842; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Marttinen P, 2006, BIOINFORMATICS, V22, P2466, DOI 10.1093/bioinformatics/btl411; Neal R. M, 1998, 9815 DEP STAT U TOR; Nelder JA, 2000, J APPL STAT, V27, P1007, DOI 10.1080/02664760050173328; NELDER JA, 1987, BIOMETRIKA, V74, P221, DOI 10.1093/biomet/74.2.221; Pan W, 2001, BIOMETRICS, V57, P529, DOI 10.1111/j.0006-341X.2001.00529.x; Ripley BD., 1996; Robert C. P., 2005, MONTE CARLO STAT MET; Sisson SA, 2005, J AM STAT ASSOC, V100, P1077, DOI 10.1198/016214505000000664; Slabbinck B, 2008, ANTON LEEUW INT J G, V94, P187, DOI 10.1007/s10482-008-9229-z; Upal M. A., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science, P342; WEDDERBURN RWM, 1974, BIOMETRIKA, V61, P439, DOI 10.1093/biomet/61.3.439; Zhou XB, 2003, MOL CANCER THER, V2, P679	35	10	12	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					74	85		10.1109/TPAMI.2008.53	http://dx.doi.org/10.1109/TPAMI.2008.53			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029547				2022-12-18	WOS:000260889700007
J	Wang, JZ; Geman, D; Luo, JB; Gray, RM				Wang, James Z.; Geman, Donald; Luo, Jiebo; Gray, Robert M.			Real-world image annotation and retrieval: An introduction to the special section	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									[Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16803 USA; [Geman, Donald] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; [Luo, Jiebo] Eastman Kodak Co, Kodak Res Labs, Rochester, NY 14650 USA; [Gray, Robert M.] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Johns Hopkins University; Eastman Kodak; Stanford University	Wang, JZ (corresponding author), Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16803 USA.	jwang@ist.psu.edu; geman@jhu.edu; jiebo.luo@kodak.com; rmgray@stanford.edu	Luo, Jiebo/AAI-7549-2020	Wang, James/0000-0003-4379-4173; Gray, Robert/0000-0002-6947-3637; Luo, Jiebo/0000-0002-4516-9729	Johns Hopkins University; Eastman Kodak Company; Stanford University	Johns Hopkins University(Johns Hopkins University); Eastman Kodak Company; Stanford University(Stanford University)	The hard work of more than 100 reviewers and all of the contributing authors is gratefully acknowledged. We would also like to thank the anonymous reviewers of our proposal and Editor-in-Chief David Kriegman for sharing our vision. The editorial staff of TPAMI, especially Elaine Stephenson, has been extremely responsive to our many inquiries. J.Z. Wang would like to thank Carnegie Mellon University, Takeo Kanade, and The Pennsylvania State University for being supportive of his work. Johns Hopkins University, Eastman Kodak Company, and Stanford University have supported the work of D. Geman, J. Luo, and R. M. Gray, respectively.	Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Geman D., 2007, 10 REASONS WHY C PAP; 2007, WALL STREET J   0403; 2007, REUTERS         1019	4	10	14	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1873	1876		10.1109/TPAMI.2008.231	http://dx.doi.org/10.1109/TPAMI.2008.231			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	19791313				2022-12-18	WOS:000259110000001
J	Feris, R; Raskar, R; Chen, L; Tan, KH; Turk, M				Feris, Rogerio; Raskar, Ramesh; Chen, Longbin; Tan, Kar-Han; Turk, Matthew			Multiflash stereopsis: Depth-edge-preserving stereo with small baseline illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo matching; multiflash imaging; depth discontinuities	SHAPE	Traditional stereo matching algorithms are limited in their ability to produce accurate results near depth discontinuities, due to partial occlusions and violation of smoothness constraints. In this paper, we use small baseline multiflash illumination to produce a rich set of feature maps that enable the acquisition of discontinuity preserving point correspondences. First, from a single multiflash camera, we formulate a qualitative depth map using a gradient domain method that encodes object relative distances. Then, in a multiview setup, we exploit shadows created by light sources to compute an occlusion map. Finally, we demonstrate the usefulness of these feature maps by incorporating them into two different dense stereo correspondence algorithms, the first based on local search and the second based on belief propagation. Experimental results show that our enhanced stereo algorithms are able to extract high-quality discontinuity preserving correspondence maps from scenes that are extremely challenging for conventional stereo methods. We also demonstrate that small baseline illumination can be useful to handle specular reflections in stereo imagery. Different from most existing active illumination techniques, our method is simple, inexpensive, and compact and requires no calibration of light sources.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA; Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA; Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA; Epson Res & Dev Inc, San Jose, CA 95131 USA	International Business Machines (IBM); University of California System; University of California Santa Barbara	Feris, R (corresponding author), IBM Corp, TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.	rsferis@us.ibm.com; raskar@merl.com; lbchen@cs.ucsb.edu; tan@erd.epson.com; mturk@cs.ucsb.edu		Tan, Kar Han/0000-0001-9294-2932				AGRAWAL A, P 32 INT C COMP GRAP, P5; AGRAWAL M, 2004, P IEEE CS C COMP VIS; Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143; Bell M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P670, DOI 10.1109/ICCV.2001.937585; Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296; BOUGUET J, 1998, P 6 IEEE INT C COMP; CHRISTOUDIAS C, 2002, P INT C PATT REC; Cipolla R., 2000, VISUAL MOTION CURVES; CRISPELL D, 2006, P INT S 3D DAT PROC; Daum M, 1998, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.1998.698646; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; FATTAL R, 2002, P 29 INT C COMP GRAP; FELZENSZWALB P, 2004, P IEEE CS C COMP VIS; FERIS R, 2004, P IEEE BRAZ S COMP G; FERIS R, 2004, P IEEE WORKSH REAL T; FERIS R, 2006, P IEEE BRAZ S COMP G; Hertzmann A, 2003, PROC CVPR IEEE, P533; Horn E, 1999, IMAGE VISION COMPUT, V17, P87, DOI 10.1016/S0262-8856(98)00113-9; INTILLE SS, 1994, P 3 EUR C COMP VIS, P179; ISHIKAWA H, 1998, P 5 EUR C COMP VIS J; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; KANG S, 2001, P IEEE CS C COMP VIS, V1, P102; Kolmogorov V., 2001, P 8 IEEE INT C COMP; KRIEGMAN D, 2001, J OPT SOC AM, P1804; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; Raskar R, 2004, P 31 INT C COMP GRAP; Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002; Sato I, 2001, PROC CVPR IEEE, P400; SAVARESE S, 2001, P 8 IEEE INT C COMP; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; SEITZ S, 2006, P IEEE CS C COMP VIS; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; SUN J, 2005, P IEEE CS C COMP VIS; Tajima J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P309, DOI 10.1109/ICPR.1990.118121; TAN K, 2004, P 7 INT C MED IM COM; TAPPEN M, 2003, P 9 IEEE INT C COMP; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; YANG DKM, 1996, THESIS COLUMBIA U; Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035; ZHANG L, 2004, P 31 INT C COMP GRAP; ZICKLER T, 2002, P 7 EUR C COMP VIS	44	10	13	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					147	159		10.1109/TPAMI.2007.1136	http://dx.doi.org/10.1109/TPAMI.2007.1136			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000331	Green Submitted			2022-12-18	WOS:000250843500012
J	Pock, T; Pock, M; Bischof, H				Pock, Thomas; Pock, Michael; Bischof, Horst			Algorithmic differentiation: Application to variational problems in computer vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						evaluating derivatives; algorithmic differentiation; variational methods; energy functional; optimization	EDGE-DETECTION; OPTICAL-FLOW; REGULARIZATION; MINIMIZATION; RECOVERY; ADJOINT; CODE	Many vision problems can be formulated as minimization of appropriate energy functionals. These energy functionals are usually minimized, based on the calculus of variations (Euler-Lagrange equation). Once the Euler-Lagrange equation has been determined, it needs to be discretized in order to implement it on a digital computer. This is not a trivial task and, is moreover, error-prone. In this paper, we propose a flexible alternative. We discretize the energy functional and, subsequently, apply the mathematical concept of algorithmic differentiation to directly derive algorithms that implement the energy functional's derivatives. This approach has several advantages: First, the computed derivatives are exact with respect to the implementation of the energy functional. Second, it is basically straightforward to compute second-order derivatives and, thus, the Hessian matrix of the energy functional. Third, algorithmic differentiation is a process which can be automated. We demonstrate this novel approach on three representative vision problems ( namely, denoising, segmentation, and stereo) and show that state-of-the-art results are obtained with little effort.	Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; Graz Univ, Wegener Ctr Climate & Global Change, A-8010 Graz, Austria	Graz University of Technology; University of Graz	Pock, T (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, Inffeldgasse 16, A-8010 Graz, Austria.	pock@icg.tugraz.at; michael.pock@uni-graz.at; bischof@icg.tugraz.at		Bischof, Horst/0000-0002-9096-6671				AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Bischof C, 1996, IEEE COMPUT SCI ENG, V3, P18, DOI 10.1109/99.537089; BISCHOF CH, 1995, NATO ADV SCI I SER C, V462, P59; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Brook A, 2003, J MATH IMAGING VIS, V18, P247, DOI 10.1023/A:1022895410391; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; CHAMBOLLE A, 2000, SPRINGER LECT NOTES; Chan T, 2005, HDB MATH MODELS COMP; Chan TF, 2003, SIAM J APPL MATH, V63, P564; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Courtier, 2002, METEOROLOGICAL TRAIN; DROSKE M, 2005, THESIS U DUISBURG ES; Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Giering R, 2005, FUTURE GENER COMP SY, V21, P1345, DOI 10.1016/j.future.2004.11.003; Giering R, 1998, ACM T MATH SOFTWARE, V24, P437, DOI 10.1145/293686.293695; GIERING R, 2006, P INT C COMP SCI, P591; GRIEWANK A, 1991, SIAM NEWS, V24, P8; GRIEWANK A, 1996, ACM T MATH SOFTWARE; Griewank A., 2000, FRONTIERS APPL MATH; Griewank A., 1989, MATH PROGRAMMING REC, V6, P83; GRIEWANK A, 1991, AUTOMATIC DIFFERENTI, P69; HADAMARD J, 2002, PRINCETON U B, V13; Hascoet L., 2005, COMPUTING ADJOINTS A; Hintermuller M, 2004, J MATH IMAGING VIS, V20, P19, DOI 10.1023/B:JMIV.0000011317.13643.3a; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huber P., 1981, ROBUST STAT; KAWOHL B, 2003, MATH METHODS APPL SC; Lefebure M, 2001, J MATH IMAGING VIS, V14, P131, DOI 10.1023/A:1011259231755; March R, 1997, IMAGE VISION COMPUT, V15, P705, DOI 10.1016/S0262-8856(97)00002-4; MOREL JM, 1995, VARIATIONAL MODELS I; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MUMFORD D, 1994, GEOMETRY DRIVEN DIFF, P141; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Nielsen M, 1997, J MATH IMAGING VIS, V7, P291, DOI 10.1023/A:1008282127190; Nocedal J., 1997, STATE ART NUMERICAL, P311; Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003; Shapira Y, 2006, COMPUT SCI ENG SER, V1; SHEN J, 2005, P INT C ADV CONCEPTS, P499; Shen JH, 2005, APPL MATH RES EXPRES, P143, DOI 10.1155/AMRX.2005.143; Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189; Tikhonov A.N., 1943, DOKL AKAD NAUK SSSR, V39, P195; Vanzella W, 2004, IEEE T PATTERN ANAL, V26, P804, DOI 10.1109/TPAMI.2004.15; Vemuri BC, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P86, DOI 10.1109/MMBIA.2000.852364; Vese L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P175, DOI 10.1007/0-387-21810-6_10; VOBBECK M, 2005, P WORKSH AUT DIFF; Zou X., 1997, NCARTN435STR; 2006, COLLECTION TOOLS PUB	60	10	11	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1180	1193		10.1109/TPAMI.2007.1044	http://dx.doi.org/10.1109/TPAMI.2007.1044			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496376				2022-12-18	WOS:000246395300006
J	Chi, YL; Leung, MKH				Chi, Yanling; Leung, Maylor K. H.			Part-based object retrieval in cluttered environment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape retrieval; cluttered scene; local structure; indexing	RECOGNITION	A novel local structural approach, which is a sequel to our previous work, is proposed in this paper for object retrieval in a cluttered and occluded environment without identifying the outlines of an object. It works by first extracting consistent and structurally unique local neighborhood from inputs or models and then voting on the optimal matches employing dynamic programming and a novel hypercube-based indexing structure. The proposed concepts have been tested on a database with thousands of images and compared with the six nearest-neighbors shape description with superior results.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Chi, YL (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	chiyanling@pmail.ntu.edu.sg; asmkleung@ntu.edu.sg	chi, yanling/GYD-6662-2022					ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058; BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; CHI Y, 2004, P INT C IM AN REC, P761; Chi YL, 2007, PATTERN RECOGN, V40, P244, DOI 10.1016/j.patcog.2006.06.009; Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Huet B, 1999, IEEE T PATTERN ANAL, V21, P1363, DOI 10.1109/34.817414; Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3; Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7; Koffka K., 1935, PRINCIPLES GESTALT P; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MANJUNATH B, 2002, INTRO MPEG7 MULTIMED; Mokhtarian F., 2002, CURVATURE SCALE SPAC; Smith-Gratto K., 1999, JEDUCATIONAL TECH NO, V27, P361; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zusne L., 1970, VISUAL PERCEPTION FO	18	10	12	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					890	895		10.1109/TPAMI.2007.1026	http://dx.doi.org/10.1109/TPAMI.2007.1026			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356207				2022-12-18	WOS:000244855700011
J	Cheng, L; Caelli, T; Sanchez-Azofeifa, A				Cheng, L; Caelli, T; Sanchez-Azofeifa, A			Component optimization for image understanding: A Bayesian approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; stereo; 3D fitting; scene analysis; image understanding; forestry inventory	EM ALGORITHM	In this paper, the optimizations of three fundamental components of image understanding: segmentation/annotation, 3D sensing (stereo) and 3D fitting, are posed and integrated within a Bayesian framework. This approach benefits from recent advances in statistical learning which have resulted in greatly improved flexibility and robustness. The first two components produce annotation (region labeling) and depth maps for the input images, while the third module integrates and resolves the inconsistencies between region labels and depth maps to fit most likely 3D models. To illustrate the application of these ideas, we have focused on the difficult problem of fitting individual tree models to tree stands which is a major challenge for vision-based forestry inventory systems.	Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada; Natl ICT Australia, Canberra Lab, Canberra, ACT 2601, Australia; Univ Alberta, Dept Earth & Atmospher Sci, Edmonton, AB T6G 2E3, Canada	University of Alberta; NICTA; University of Alberta	Cheng, L (corresponding author), Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.	licheng@cs.ualberta.ca; Terry.Caelli@nicta.com.au; arturo.sanchez@ualberta.ca	Cheng, Li/AAU-6734-2020; Sánchez, Arturo/L-3622-2019; Sanchez-Azofeifa, Arturo/F-4700-2014	Cheng, Li/0000-0003-3261-3533; Sánchez, Arturo/0000-0002-4946-1559; Sanchez-Azofeifa, Arturo/0000-0001-7768-6600; Caelli, Terry/0000-0001-9281-2556				BESAG J, 1986, J R STAT SOC B, V48, P259; Celeux G, 1996, J STAT COMPUT SIM, V55, P287, DOI 10.1080/00949659608811772; Cheng H, 2001, J ELECTRON IMAGING, V10, P460, DOI 10.1117/1.1344590; CHENG L, IN PRESS COMPUTER VI; CHENG L, 2002, P INT C PATT REC; Gelman A, 1997, BAYESIAN DATA ANAL; Gilks WR, 1996, MARKOV CHAIN MONTE C; Gillis MD, 1996, FOREST CHRON, V72, P138, DOI 10.5558/tfc72138-2; Gougeon F. A., 1995, CAN J REMOTE SENS, V21, P274, DOI [10.1080/07038992.1995.10874622, DOI 10.1080/07038992.1995.10874622]; Gray A., 1997, MODERN DIFFERENTIAL; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Larsen M, 1998, PATTERN RECOGN LETT, V19, P1153, DOI 10.1016/S0167-8655(98)00092-0; Nielsen SF, 2000, BERNOULLI, V6, P457, DOI 10.2307/3318671; PINZ AJ, 1991, NASA CONF P, V3099, P111; Pollock R, 1996, THESIS U BRIT COLUMB; Robert C.P., 2007, BAYESIAN CHOICE DECI, Vsecond; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; YEDIDA J. S., 2003, EXPLORING ARTIFICIAL, P236	19	10	10	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					684	693		10.1109/TPAMI.2006.92	http://dx.doi.org/10.1109/TPAMI.2006.92			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640256				2022-12-18	WOS:000235885700002
J	Hua, G; Wu, Y				Hua, G; Wu, Y			Variational maximum A posteriori by annealed mean field analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mean field variational analysis; deterministic annealing; maximum a posteriori estimation; graphical model; Markov network	GRADIENT PROJECTION METHOD	This paper proposes a novel probabilistic variational method with deterministic annealing for the maximum a posteriori (MAP) estimation of complex stochastic systems. Since the MAP estimation involves global optimization, in general, it is very difficult to achieve. Therefore, most probabilistic inference algorithms are only able to achieve either the exact or the approximate posterior distributions. Our method constrains the mean field variational distribution to be multivariate Gaussian. Then, a deterministic annealing scheme is nicely incorporated into the mean field fix-point iterations to obtain the optimal MAP estimate. This is based on the observation that when the covariance of the variational Gaussian distribution approaches to zero, the infimum point of the Kullback-Leibler (KL) divergence between the variational Gaussian and the real posterior will be the same as the supreme point of the real posterior. Although global optimality may not be guaranteed, our extensive synthetic and real experiments demonstrate the effectiveness and efficiency of the proposed method.	Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA	Northwestern University	Hua, G (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, 2145 Sheridan Rd, Evanston, IL 60208 USA.	ganghua@ece.northwestern.edu; yingwu@ece.northwestern.edu	Wu, Ying/B-7283-2009					Andrieu C, 1999, IEEE T SIGNAL PROCES, V47, P2667, DOI 10.1109/78.790649; BARBU A, 2003, P IEEE INT C COMP VI; Beal M.J., 2003, VARIATIONAL ALGORITH; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Deutscher J., 2000, P IEEE C COMP VIS PA; DOLL D, 1997, IMAGE VISION COMPUT, V15, P855; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; FREEMAN WT, 2003, P IEEE C COMP VIS PA; FREEMAN WT, 1999, MARKOV NETWORK LOW L; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hua G, 2004, PROC CVPR IEEE, P826; HUA G, 2004, P IEEE AS C COMP VIS; Isard M, 2003, PROC CVPR IEEE, P613; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS CAM, V1, P343; Jaakkola T., 2000, ADV MEAN FIELD METHO; Jordan M., 2002, HDB BRAIN THEORY NEU, P243; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Li SZ, 1996, PATTERN RECOGN, V29, P159, DOI 10.1016/0031-3203(95)00071-2; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Murphy K. P., 1999, P 15 C UNC ART INT; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; PAVLOVIC VI, 1999, THESIS U ILLINOIS UR; Puzicha J, 1999, COMPUT VIS IMAGE UND, V76, P213, DOI 10.1006/cviu.1999.0805; PUZICHA J, 1997, P 15 IMACS WORLD C S; Rao AV, 1999, IEEE T PATTERN ANAL, V21, P159, DOI 10.1109/34.748824; ROSEN JB, 1961, J SOC IND APPL MATH, V9, P514, DOI 10.1137/0109044; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; SIGAL L, 2004, ADV NEURAL INF PROCE, V16; Sudderth EB, 2003, PROC CVPR IEEE, P605; Thomas J. A, 1991, ELEMENTS INF THEORY; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Wang Y, 2003, PROC CVPR IEEE, P335; Winn J. M., 2003, THESIS U CAMBRIDGE; Wu Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1094, DOI 10.1109/ICCV.2003.1238471; Wu Y, 2003, PROC CVPR IEEE, P789; Wu Y, 2003, PROC CVPR IEEE, P295; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590; Yedidia J., 2003, EXPLORING ARTIFICIAL, V8, P236; YUILLE AL, 1994, NEURAL COMPUT, V6, P341, DOI 10.1162/neco.1994.6.3.341	40	10	10	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1747	1761						15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285374	Green Submitted			2022-12-18	WOS:000231826300006
J	Wendling, L; Tabbone, S				Wendling, L; Tabbone, S			A new way to detect arrows in line drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						arrow symbol recognition; geometric properties; criteria aggregation; Choquet integral	PATTERN-RECOGNITION	A new way of detecting arrows in line drawings is proposed in this paper. We provide a set of criteria which are aggregated using the Choquet integral. These criteria are defined from the geometric properties of an arrow. Experimental results on two kinds of line-drawing documents show the interest of our approach.	LORIA, F-54506 Vandoeuvre Les Nancy, France	Universite de Lorraine	Wendling, L (corresponding author), LORIA, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.	wendling@loria.fr; tabbone@loria.fr						Ah-Soon C, 2001, PATTERN RECOGN LETT, V22, P231, DOI 10.1016/S0167-8655(00)00091-X; BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z; BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025; CHAI I, 1992, P SPIE IS T S EL IM, P38; Cordella L. P., 2000, International Journal on Document Analysis and Recognition, V3, P73, DOI 10.1007/s100320000036; Dori D, 1998, COMPUT VIS IMAGE UND, V69, P196, DOI 10.1006/cviu.1997.0585; GHORBEL F, 1994, PATTERN RECOGN LETT, V15, P1043, DOI 10.1016/0167-8655(94)90037-X; Grabisch M, 1996, EUR J OPER RES, V89, P445, DOI 10.1016/0377-2217(95)00176-X; GRABISCH M, 1995, P FUZZ IEEE IFES 95, V1, P145; Lai C. P., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P606, DOI 10.1109/ICDAR.1993.395662; MAES M, 1991, PATTERN RECOGN, V24, P433, DOI 10.1016/0031-3203(91)90056-B; Marichal JL, 2000, EUR J OPER RES, V124, P641, DOI 10.1016/S0377-2217(99)00182-4; Messmer B. T., 1996, Graphics Recognition, Methods and Applications. First International Workshop. Selected Papers, P123; MUROFUSHI T, 1989, FUZZY SET SYST, V29, P201, DOI 10.1016/0165-0114(89)90194-2; MUROFUSHI T, 1993, P 9 FUZZ SYST S SAPP, P693; Priestnall G, 1996, PATTERN RECOGN LETT, V17, P277, DOI 10.1016/0167-8655(95)00117-4; Shapley L. S., 1953, CONTRIBUTIONS THEORY, V28, P307, DOI [10.3390/atmos10110723, DOI 10.1515/9781400881970-018]; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89102; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Valveny E, 2001, PROC INT CONF DOC, P455, DOI 10.1109/ICDAR.2001.953831; WEISSTEN EW, 1999, CRC CONCISE ENCY MAT; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0	22	10	10	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					935	U1		10.1109/TPAMI.2004.20	http://dx.doi.org/10.1109/TPAMI.2004.20			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579951				2022-12-18	WOS:000221323900010
J	Zoeter, O; Heskes, T				Zoeter, O; Heskes, T			Hierarchical visualization of time-series data using switching linear dynamical systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data visualization; time-series; latent variables; principal component analysis; switching linear dynamical systems; approximate inference	STATE-SPACE MODELS	We propose a novel visualization algorithm for high-dimensional time-series data. In contrast to most visualization techniques, we do not assume consecutive data points to be independent. The basic model is a linear dynamical system which can be seen as a dynamic extension of a probabilistic principal component model. A further extension to a particular switching linear dynamical system allows a representation of complex data onto multiple and even a hierarchy of plots. Using sensible approximations based on expectation propagation, the projections can be performed in essentially the same order of complexity as their static counterpart. We apply our method on a real-world data set with sensor readings from a paper machine.	Univ Nijmegen, SNN, NL-6525 EZ Nijmegen, Netherlands	Radboud University Nijmegen	Zoeter, O (corresponding author), Univ Nijmegen, SNN, Geert Grooteplein 21, NL-6525 EZ Nijmegen, Netherlands.		Heskes, Tom/A-1443-2010	Heskes, Tom/0000-0002-3398-5235				Alhoniemi E., 1999, INTEGRATED COMPUTER, V6; Bar-Shalom Y, 1993, ESTIMATION TRACKING; BEAL M, 2001, P ADV NEUR INF PROC; BISHOP CM, 1998, IEEE T PATTERN ANAL, V20; BISHOP CM, 1997, P IEE 5 INT C ART NE, P111; Carter CK, 1996, BIOMETRIKA, V83, P589, DOI 10.1093/biomet/83.3.589; DOUCET A, 2000, P 16 ANN C UNC ART I; Fruhwirth-Schnatter S, 2001, ANN I STAT MATH, V53, P31, DOI 10.1023/A:1017908219076; HARRISON PJ, 1976, J R STAT SOC B, V38, P205; HESKES T, 2003, P 9 INT WORKSH ART I; HESKES T, 2002, P 18 ANN C UNC ART I; Kim C.-J., 1999, STATE SPACE MODELS R; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LERNER U, 2001, P 17 ANN C UNC ART I; MINKA T, 2001, P 17 ANN C UNC ART I; Minka T., 2001, EP ENERGY FUNCTION M; ROWEIS S, 2001, P NEUR INF PROC SYST, V14; Roweis S., 1997, EM ALGORITHMS PCA SE; SHUMWAY RH, 1991, J AM STAT ASSOC, V86, P763, DOI 10.2307/2290410; TEH Y, 2002, P ADV NEUR INF PROC; Tino P, 2002, IEEE T PATTERN ANAL, V24, P639, DOI 10.1109/34.1000238; TIPPING ME, 1999, J ROYAL STAT SOC B, V61; Yedidia JS, 2001, ADV NEUR IN, V13, P689; [No title captured]	25	10	10	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1202	1214		10.1109/TPAMI.2003.1233895	http://dx.doi.org/10.1109/TPAMI.2003.1233895			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE		Green Submitted			2022-12-18	WOS:000185460800001
J	Raudys, S				Raudys, S			Experts' boasting in trainable fusion rules	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fusion rule; expert classifiers; generalization error; resubstitution error; complexity	CLASSIFIER FUSION	We consider the trainable fusion rule design problem when the expert classifiers provide crisp outputs and the behavior space knowledge method is used to fuse local experts' decisions. If the training set is utilized to design both the experts and the fusion rule, the experts' outputs become too self-assured. In small sample situations, "optimistically biased" experts' outputs bluffs the fusion rule designer. If the experts differ in complexity and in classification performance, then the experts' boasting effect and can severely degrade the performance of a multiple classification system. Theoretically-based and experimental procedures are suggested to reduce the experts' boasting effect.	Inst Math & Informat, LT-2021 Vilnius, Lithuania	Vilnius University	Raudys, S (corresponding author), Inst Math & Informat, Akademijos 4, LT-2021 Vilnius, Lithuania.	raudys@das.mii.lt						Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Duda R.O., 2000, PATTERN CLASSIFICATI; Duin R. P. W., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P5; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Ghosh J, 2002, LECT NOTES COMPUT SC, V2364, P1; GULER C, 1996, P 8 EUR SIGN PROC C; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; Janeliunas A, 2002, LECT NOTES COMPUT SC, V2364, P242; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kittler J, 1998, PATTERN ANAL APPL, V1, P18, DOI 10.1007/BF01238023; Kittler J, 2000, LECT NOTES COMPUT SC, V1876, P45; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KITTLER J, 2001, LECT NOTES COMPUTER, V2096; KITTLER J, 2000, LECT NOTES COMPUTER, V1857; KITTLER J, 2002, LECT NOTES COMPUTER, V2364; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; KUNCHEVA LI, 2001, LNCS, V2096, P228; LACHENBRUCH PA, 1979, BIOMETRICS, V5, P9; Raudys S, 2002, LECT NOTES COMPUT SC, V2364, P27; RAUDYS S, 2001, STAT NEURAL CLASSIFI, P312; Roli F, 2002, LECT NOTES COMPUT SC, V2364, P252; Roli F, 2002, LECT NOTES COMPUT SC, V2364, P232; Skurichina M, 2000, IEEE T NEURAL NETWOR, V11, P504, DOI 10.1109/72.839019; Tin Kam Ho, 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096), P53; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	29	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1178	1182		10.1109/TPAMI.2003.1227993	http://dx.doi.org/10.1109/TPAMI.2003.1227993			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX					2022-12-18	WOS:000184977300013
J	Titsias, MK; Likas, A				Titsias, MK; Likas, A			Class conditional density estimation using mixtures with constrained component sharing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mixture models; classification; density estimation; EM algorithm; component sharing	MAXIMUM-LIKELIHOOD	We propose a generative mixture model classifier that allows for the class conditional densities to be represented by mixtures having certain subsets of their components shared or common among classes. We argue that, when the total number of mixture components is kept fixed, the most efficient classification model is obtained by appropriately determining the sharing of components among class conditional densities. In order to discover such an efficient model, a training method is derived based on the EM algorithm that automatically adjusts component sharing. We provide experimental results with good classification performance.	Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece	University of Ioannina	Titsias, MK (corresponding author), Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.	mtitsias@cs.uoi.gr; arly@cs.uoi.gr						BAHL LR, 1996, P INT C AC SPEECH SI; Bishop, 1995, NEURAL NETWORKS PATT; BRAND M, 1998, NEURAL INFORMATION P, V11; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 1973, J ROYAL STAT SOC SER; Ghahramani Z., 1994, P ADV NEUR INF PROC, P120; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; JEBARA T, 1998, NEURAL INFORMATION P, V11; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Mclachlan G., 2000, WILEY SER PROB STAT; MILLER DJ, 1996, NEURAL INFORMATION P, V9; Newman C. B. D., 1998, UCI REPOSITORY MACHI; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Richardson T., 2001, P 8 INT WORKSH ART I, P233; SAUL LK, 2002, NEURAL INFORMATION P, V14; Titsias MK, 2001, IEEE T NEURAL NETWOR, V12, P987, DOI 10.1109/72.950129; Titterington DM, 1985, STAT ANAL FINITE MIX	17	10	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					924	928		10.1109/TPAMI.2003.1206521	http://dx.doi.org/10.1109/TPAMI.2003.1206521			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN					2022-12-18	WOS:000183667300014
J	Park, J				Park, J			An adaptive approach to offline handwritten word recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; handwritten word recognition; adaptive word recognition	CHARACTER-RECOGNITION; ADDRESSES; SYSTEM; MODEL; FORMS	An adaptive handwritten word recognition method is presented. The key ideas of adaptation are 1) to actively and successively select a subset of features for each word image which provides the minimum required classification accuracy to get a valid answer and 2) to derive a consistent decision metric which works in a multiresolution feature space and considers the interrelationships of a lexicon at the same time. A recursive architecture based on interaction between flexible character classification and deductive decision making is developed. The recognition process starts from the initial coarse level using a minimum number of features, then increases the discrimination power by adding other features adaptively and recursively until the result is accepted by the decision maker. For the computational aspect of a feasible solution, a unified decision metric, recognition confidence, is derived from two measurements: pattern confidence, evaluation of absolute confidence using shape features, and lexical confidence, evaluation of the relative string dissimilarity in the lexicon. Practical implementation and experimental results in reading the handwritten words of the address components of US mail pieces are provided. Up to a 4 percent improvement in recognition performance is achieved compared to a nonadaptive method. The experimental result shows that the proposed method has advantages in producing valid answers using the same number of features as conventional methods.	Motorola Inc, Lexicus Div, Palo Alto, CA 94304 USA		Park, J (corresponding author), Motorola Inc, Lexicus Div, 3145 Porter Dr, Palo Alto, CA 94304 USA.	JaehwaPark@motorola.com						Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Belaid Y., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P744, DOI 10.1109/ICDAR.1995.602009; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; COHEN E, 1994, IEEE T PATTERN ANAL, V16, P1049, DOI 10.1109/34.329003; Favata J, 1996, P 5 INT WORKSH FRONT, P437; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FU KS, 1986, IEEE T PATTERN ANAL, V8, P313, DOI 10.1109/TPAMI.1986.4767794; Gader PD, 1997, IEEE T SYST MAN CY B, V27, P158, DOI 10.1109/3477.552199; Goodrich MA, 1998, IEEE T SYST MAN CY A, V28, P763, DOI 10.1109/3468.725348; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Kaltenmeier A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P139, DOI 10.1109/ICDAR.1993.395764; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; KIM G, 1997, AUTOMATIC BANKCHECK, P195; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; Levi Isaac, 1984, DECISIONS REVISIONS; LIN CS, 1987, PATTERN RECOGN, V20, P535, DOI 10.1016/0031-3203(87)90080-X; MADHVANATH S, 1992, P US POSTAL SERVICE, P183; MADHVANATH S, 1993, P 3 INT WORKSH FRONT, P132; MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375; Miletzki U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P329, DOI 10.1109/ICDAR.1999.791791; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Park J, 2000, IEEE T PATTERN ANAL, V22, P400, DOI 10.1109/34.845383; Park J., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P605, DOI 10.1109/ICDAR.1999.791860; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; Simon J. C., 1994, P C DOC AN SYST KAIS, P135; SIMON JC, 1992, P IEEE, V80, P1150, DOI 10.1109/5.156476; Srihari SN, 1996, P IEEE, V84, P1038, DOI 10.1109/5.503302; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306, DOI 10.1109/TPAMI.1979.4766926; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	36	10	10	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					920	931		10.1109/TPAMI.2002.1017619	http://dx.doi.org/10.1109/TPAMI.2002.1017619			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF					2022-12-18	WOS:000176446100005
J	Ribeiro, E; Hancock, ER				Ribeiro, E; Hancock, ER			Shape from periodic texture using the eigenvectors of local affine distortion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape-from-texture; spectral analysis; affine distortion; eigen-analysis	SURFACE ORIENTATION; MOMENTS	This paper shows how the local slant and tilt angles of regularly textured curved surfaces can be estimated directly, without the need for iterative numerical optimization, We work in the frequency domain and measure texture distortion using the affine distortion of the pattern of spectral peaks. The key theoretical contribution is to show that the directions of the eigenvectors of the affine distortion matrices can be used to estimate local slant and tilt angles of tangent planes to curved surfaces. In particular, the leading eigenvector points in the tilt direction. Although not as geometrically transparent, the direction of the second eigenvector can be used to estimate the slant direction. The required affine distortion matrices are computed using the correspondences between spectral peaks, established on the basis of their energy ordering. We apply the method to a variety of real-world and synthetic imagery.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England; Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England	University of York - UK; University of York - UK	Ribeiro, E (corresponding author), Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England.	erh@cs.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				ALOIMONOS J, 1988, BIOL CYBERN, V58, P345, DOI 10.1007/BF00363944; Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BROWN LG, 1990, IEEE T PATTERN ANAL, V12, P584, DOI 10.1109/34.56194; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; GARDING J, 1992, J MATH IMAGING VIS, V2, P329; GARDING J, 1992, P EUR C COMP VIS IT, P630; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; Horn B., 1986, ROBOT VISION, P1; IKEUCHI K, 1984, ARTIF INTELL, V22, P49, DOI 10.1016/0004-3702(84)90025-0; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; JAU JY, 1990, COMPUT VISION GRAPH, V52, P248, DOI 10.1016/0734-189X(90)90057-3; KANATANI K, 1989, ARTIF INTELL, V38, P1, DOI 10.1016/0004-3702(89)90066-0; KAY SM, 1988, MDOERN SPECTRAL ESTI; KENDER JR, 1979, P 6 IJCAI, P475; KRUMM J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P121, DOI 10.1109/ICCV.1995.466797; Krumm J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P284, DOI 10.1109/CVPR.1992.223262; KRUMM J, 1990, P IEEE INT C COMP VI, P359; Kwon JS, 1996, PATTERN RECOGN, V29, P725, DOI 10.1016/0031-3203(95)00101-8; Malik J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P267, DOI 10.1109/CVPR.1993.340979; MALIK J, 1994, P EUR C COMP VIS 94, V800, P353; Marr D., 1982, VISION COMPUTATIONAL; ROSENFELD A, 1975, IEEE T COMPUT, V24, P988, DOI 10.1109/T-C.1975.224106; SAKAI K, 1994, P IEEE C VIS PATT RE, P527; STEVENS KA, 1981, BIOL CYBERN, V42, P95, DOI 10.1007/BF00336727; STEVENS KA, 1983, BIOL CYBERN, V46, P183, DOI 10.1007/BF00336800; SUPER BJ, 1995, PATTERN RECOGN, V28, P729, DOI 10.1016/0031-3203(94)00140-H; SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983; SUPER BJ, 1992, P SPIE C VIS COMM IM, P144; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406	31	10	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1459	1465		10.1109/34.977570	http://dx.doi.org/10.1109/34.977570			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY		Green Accepted, Green Submitted			2022-12-18	WOS:000172634700012
J	Slavik, P; Govindaraju, V				Slavik, P; Govindaraju, V			Equivalence of different methods for slant and skew corrections in word recognition applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image preprocessing; slant normalization; skew normalization; handwriting recognition		Normalization of slant and skew is often used in processing a word image before recognition. In this paper, we prove the theoretical equivalence of different methods for slant and skew corrections. In particular, we show that correcting first for skew by rotation and then for slant by a shear transformation in the horizontal direction is equivalent to first correcting for slant by a shear transformation in the horizontal direction and then for skew by a shear transformation in the vertical direction. Our proof can be easily modified to prove equivalence of other methods for correcting the slant and skew.	SUNY Buffalo, Dept Comp Sci & Engn, Ctr Excellence Document Anal & Recognit, Buffalo, NY 14260 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Slavik, P (corresponding author), SUNY Buffalo, Dept Comp Sci & Engn, Ctr Excellence Document Anal & Recognit, 226 Bell Hall, Buffalo, NY 14260 USA.							BROWN MK, 1983, PATTERN RECOGN, V16, P447, DOI 10.1016/0031-3203(83)90049-3; GADER P, 1995, MACH VISION APPL, V8, P31, DOI 10.1007/BF01213636; GUERFALI W, 1993, PATTERN RECOGN, V26, P419, DOI 10.1016/0031-3203(93)90169-W; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; KIM G, 1996, P SPIE S EL IM SCI T, P262; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; SENIOR A, 1992, 105 CUEDFINFENGTR; SLAVIK P, 1999, 200009 SUNY BUFF DEP; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2	9	10	13	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					323	326		10.1109/34.910885	http://dx.doi.org/10.1109/34.910885			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW		Green Submitted			2022-12-18	WOS:000167276200009
J	Quan, L				Quan, L			Two-way ambiguity in 2D projective reconstruction from three uncalibrated 1D images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						1D camera; vision geometry; ambiguity; reconstruction	CAMERA	We show that there is, in general, a two-way ambiguity for 2D projective reconstruction from three uncalibrated 1D views, independent of the number of point correspondences. The two distinct projective reconstructions are exactly related by a quadratic transformation with the three camera centers as fundamental points. Unique 2D reconstruction is possible only when the three camera centers are aligned. By Carlsson duality, there is a dual two-way ambiguity for 2D projective reconstruction from six point correspondences, independent of the number of 1D views. The theoretical results are demonstrated on numerical examples.	CNRS, INRIA, F-38330 Montbonnot St Martin, France	Centre National de la Recherche Scientifique (CNRS); Inria	Quan, L (corresponding author), CNRS, INRIA, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	Long.Quan@inrialpes.fr						Astrom K, 2000, J MATH IMAGING VIS, V12, P121, DOI 10.1023/A:1008362322190; ASTROM K, 1996, THESIS LUND U; BUCHANAN T, 1988, COMPUT VISION GRAPH, V42, P130, DOI 10.1016/0734-189X(88)90146-6; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; Carlsson S., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P85, DOI 10.1109/WVRS.1995.476856; FAUGERAS O, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P951, DOI 10.1109/ICCV.1995.466832; FAUGERAS O, 1998, P 5 EUR C COMP VIS F, P36; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P882, DOI 10.1109/ICCV.1995.466843; MAYBANK S, 1993, THEORY RECONSTRUCTIO; Maybank SJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P703, DOI 10.1109/ICCV.1998.710794; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285; Quan L, 1997, PROC CVPR IEEE, P60, DOI 10.1109/CVPR.1997.609298; QUAN L, 1999, P 7 INT C COMP VIS, P344; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; SPETSAKIS M, 1990, P DARPA IM UND WORKS, P271; TRIGGS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P338, DOI 10.1109/ICCV.1995.466920	19	10	11	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					212	216		10.1109/34.908971	http://dx.doi.org/10.1109/34.908971			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ		Green Submitted			2022-12-18	WOS:000166933500010
J	Xirouhakis, Y; Delopoulos, A				Xirouhakis, Y; Delopoulos, A			Least squares estimation of 3D shape and motion of rigid objects from their orthographic projections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D motion; 3D structure; structure from motion; orthography	FACTORIZATION METHOD; 3-DIMENSIONAL MOTION; DEPTH ESTIMATION; IMAGE STREAMS; ALGORITHM; RECOVERY	The extraction of motion and shape information of three-dimensional objects from their two-dimensional projections is a task that emerges in Various applications such as computer vision, biomedical engineering, and video coding and mining especially after the recent guidelines of the Motion Pictures Expert Group regarding MPEG-4 and MPEG-7 standards. Present work establishes a novel approach for extracting the motion and shape parameters of a rigid three-dimensional object on the basis of its orthographic projections and the associated motion field. Experimental results have been included to verify the theoretical analysis.	Natl Tech Univ Athens, Dept Elect & Comp Engn, Image Video & Multimedia Syst Lab, GR-15773 Athens, Greece	National Technical University of Athens	Xirouhakis, Y (corresponding author), Natl Tech Univ Athens, Dept Elect & Comp Engn, Image Video & Multimedia Syst Lab, 9 Iroon Polytechniou Str, GR-15773 Athens, Greece.		Delopoulos, Anastasios/B-2140-2013; Delopoulos, Anastasios/ABB-6127-2021					Aizawa K., 1989, Signal Processing: Image Communication, V1, P139, DOI 10.1016/0923-5965(89)90006-4; BOZDAGI G, 1994, IEEE T IMAGE PROCESS, V3, P711, DOI 10.1109/83.334971; BRIASSOULI A, 1999, P INT WORKSH SYNTH N; DELOPOULOS A, 1998, P IEEE IM MULT DIG S, P151; DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; Hung YS, 1999, IEEE T PATTERN ANAL, V21, P570, DOI 10.1109/34.771330; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289; Ostuni J, 1996, IEEE T PATTERN ANAL, V18, P64, DOI 10.1109/34.476013; PHILIP J, 1991, IEEE T PATTERN ANAL, V13, P61, DOI 10.1109/34.67631; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; Soatto S, 1998, IEEE T PATTERN ANAL, V20, P943, DOI 10.1109/34.713361; Tekalp M., 1995, DIGITAL VIDEO PROCES, V1; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; XIROUHAKIS Y, 1999, P 6 IEEE INT C EL CI; Xu G, 1999, IEEE T PATTERN ANAL, V21, P54, DOI 10.1109/34.745734	23	10	10	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					393	399		10.1109/34.845382	http://dx.doi.org/10.1109/34.845382			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500009
J	Jorgensen, TM; Linneberg, C				Jorgensen, TM; Linneberg, C			Theoretical analysis and improved decision criteria for the n-tuple classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						n-tuple classifier; maximum likelihood; Bayes; cross-validation; RAM-net		The anticipated behavior of the n-tuple classification system is that it gives the highest output score for the class to which the input example actually belongs. By performing a theoretical analysis of how the output scores are related to the underlying probability distributions of the data, this paper shows that this in general is not to be expected. The theoretical results are able to explain the behavior that is observed in experimental studies. The theoretical analysis also give valuable insight into how the n-tuple classifier can be improved to deal with skewed training priors, which until now have been a hard problem for the architecture to tackle. It is shown that by relating an output score to the probability that a given class generates the data makes it possible to design the n-tuple net to operate as a close approximation to the Bayes estimator. It is specifically illustrated that this approximation can be obtained by modifying the decision criteria. In real cases, the underlying example distributions are unknown and accordingly the optimum way to treat the output scores cannot be calculated theoretically. However, it is shown that the feasibility of performing leave-one-out cross-validation tests in n-tuple networks makes it possible to obtain proper processing of the scores in such cases.	Riso Natl Lab, DK-4000 Roskilde, Denmark; Intellix AS, DK-1879 Copenhagen, Denmark	Technical University of Denmark	Jorgensen, TM (corresponding author), Riso Natl Lab, POB 49, DK-4000 Roskilde, Denmark.	thomas.martini@riso.dk; cli@intellix.com	Jørgensen, Thomas Martini/AAE-2303-2019; MartiniJørgensen, Thomas/I-5995-2012	Jørgensen, Thomas Martini/0000-0003-2920-1343; MartiniJørgensen, Thomas/0000-0003-2920-1343				ALEKSANDER I, 1970, ELECTRON LETT, V6, P134, DOI 10.1049/el:19700092; ALEKSANDER I, 1984, SENSOR REV, P120; Aleksander I., 1990, INTRO NEURAL COMPUTI; ANDERSEN AW, 1994, P MACH VIS APPL ARCH, P163; [Anonymous], 1959, P E JOINT COMP C, DOI DOI 10.1145/1460299.1460326; AUSTIN J, 1998, RAM BASED NEURAL NET; BLEDSOE WW, 1961, IRE T ELECTRON COM, VEC10, P96; Jorgensen TM, 1997, INT J NEURAL SYST, V8, P17, DOI 10.1142/S0129065797000045; JORGENSEN TM, 1994, P SOC PHOTO-OPT INS, V2353, P328, DOI 10.1117/12.188904; JORGENSEN TM, 1998, RAM BASED NEURAL NET, P78; Jung DM, 1996, IEEE T PATTERN ANAL, V18, P734, DOI 10.1109/34.506795; KENNEDY JV, 1995, P IEEE INT C NEUR NE, V2, P1037, DOI DOI 10.1109/ICNN.1995.487564; Michie Donald, 1994, MACHINE LEARNING NEU, P2; MORCINIEC M, 1995, P WEIGHTL NEUR NETW, P93; *NAT I STAND TECHN, 1995, NIST SPEC DAT, V19; Rohwer R, 1998, NEURAL NETWORKS, V11, P1, DOI 10.1016/S0893-6080(97)00062-2; STONHAM TJ, 1977, ELECTRON LETT, V13, P155, DOI 10.1049/el:19770110; Wackerly D., 1996, MATH STAT APPL; WEHENKEL L, 1993, P IEEE PES 1993 WINT	19	10	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					336	347		10.1109/34.761264	http://dx.doi.org/10.1109/34.761264			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL					2022-12-18	WOS:000079781200005
J	Phillips, PJ; Bowyer, KW				Phillips, PJ; Bowyer, KW			Introduction to the special section on empirical evaluation of computer vision algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	National Institute of Standards & Technology (NIST) - USA; State University System of Florida; University of South Florida	Phillips, PJ (corresponding author), Natl Inst Stand & Technol, Bldg 225,Room A216,100 Bur Dr,Stop 8490, Gaithersburg, MD 20899 USA.	jonathon@nist.gov; kwb@bigpine.csee.usf.edu							0	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					289	290		10.1109/TPAMI.1999.761260	http://dx.doi.org/10.1109/TPAMI.1999.761260			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL					2022-12-18	WOS:000079781200001
J	Hall, P; Turlach, BA				Hall, P; Turlach, BA			On the estimation of a convex set with corners	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						circular data; diagnostic; kernel; laser radar; robotic vision; smoothing parameter; spline; support function	LOCALLY WEIGHTED REGRESSION; SUPPORT-LINE MEASUREMENTS; RECONSTRUCTION	In robotic Vision using laser-radar measurements, noisy data on convex sets with corners are derived in terms of the set's support function. The corners represent abutting edges of manufactured items, and convey important information about the items' shape. However, simple methods for set estimation, for example based on fitting random polygons or smooth sets, either add additional corners as an artifact of the algorithm, or approximate corners by smooth curves. It might be argued, however, that corners have special significance in the interpretation of a set, and should not be introduced as an artifact of the estimation procedure. In this paper we suggest a corner-diagnostic approach, in the form of a three-step algorithm which (a) identifies the number and positions of corners, (b) fits smooth curves between corners, and (c) splices together the smooth curves and the corners, to produce an over-all estimate of the convex set. The corner-finding step is parametric in character, and although it is based on detecting change points in high-order derivatives of the support function, it produces root-n consistent estimators of the locations of corners. On the other hand, the smooth-curve fitting step is entirely nonparametric. The splicing step marries these two disparate approaches into a single, practical method.	Australian Natl Univ, Sch Math Sci, Ctr Math & Its Applicat, Canberra, ACT 0200, Australia; CSIRO, Div Math & Stat, N Ryde, NSW 2113, Australia; Univ Adelaide, Dept Stat, Adelaide, SA 5005, Australia	Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); University of Adelaide	Hall, P (corresponding author), Australian Natl Univ, Sch Math Sci, Ctr Math & Its Applicat, Canberra, ACT 0200, Australia.	halpstat@pretty.anu.edu.au; bturlach@stats.adelaide.edu.au	Turlach, Berwin/A-4995-2008	Turlach, Berwin/0000-0001-8795-471X				BRESLER Y, 1984, P SOC PHOTO-OPT INST, V515, P251; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COOPER J, 1993, IEEE T PATTERN ANAL, V15, P823, DOI 10.1109/34.236246; FAN JQ, 1993, ANN STAT, V21, P196, DOI 10.1214/aos/1176349022; Fisher NI, 1997, J AM STAT ASSOC, V92, P84, DOI 10.2307/2291452; Grenander U., 1993, GEN PATTERN THEORY M; HALL P, 1996, 00596 SRR AUSTR NAT; HASTIE T, 1993, STAT SCI, V8, P120, DOI 10.1214/ss/1177011002; Herman G, 1980, IMAGE RECONSTRUCTION; Karl WC, 1996, J MATH IMAGING VIS, V6, P249, DOI 10.1007/BF00119842; KOROSTELEV AP, 1993, COMPUTER INTENSIVE M, P113; KOROSTELEV AP, 1993, SPRINGER LECT NOTES, V82; LELE AS, 1992, J OPT SOC AM A, V9, P1693, DOI 10.1364/JOSAA.9.001693; PRINCE JL, 1990, IEEE T PATTERN ANAL, V12, P377, DOI 10.1109/34.50623; ROSSI DJ, 1984, IEEE T ACOUST SPEECH, V32, P886, DOI 10.1109/TASSP.1984.1164405; Santal LA., 1953, INTRO INTEGRAL GEOME, V1198; SKIENA SS, 1991, J ALGORITHM, V12, P359, DOI 10.1016/0196-6774(91)90009-N; STARK H, 1988, J OPT SOC AM A, V5, P331, DOI 10.1364/JOSAA.5.000331	19	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					225	234		10.1109/34.754588	http://dx.doi.org/10.1109/34.754588			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000004
J	Rocha, J; Bernardino, R				Rocha, J; Bernardino, R			Singularities and regularities on line pictures via symmetrical trapezoids	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour trapezoid; maximal trapezoid set; regular region; singular region; skeleton		An algorithm that decomposes a line image into singular and regular regions is presented. We define a contour trapezoid as the building block of regular regions, and postulate a Maximal Trapezoid Set as the core of regular regions. Then, we describe an algorithm that calculates a Maximal Trapezoid Set of a polygon and show how to use it to find a skeleton of a polygonal approximation of a contour. Experiments are explained to show the behavior of the new concept on real images as compared to previous algorithms.	Univ Balearic Isl, Dept Matemat & Informat, Palma de Mallorca 07071, Spain	Universitat de les Illes Balears	Rocha, J (corresponding author), Univ Balearic Isl, Dept Matemat & Informat, Palma de Mallorca 07071, Spain.		Rocha, Jairo/K-9850-2014	Rocha, Jairo/0000-0002-8810-7376				BJORKLUND CM, 1981, IEEE T PATTERN ANAL, V3, P144, DOI 10.1109/TPAMI.1981.4767072; CHANG F, 1997, 4 ICDAR, P123; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; Pavlidis T., 1989, From Pixels to Features. Proceedings of a Workshop, P219; Plamondon R., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1247, DOI 10.1142/S0218001493000613; ROCHA J, 1996, LNCS, V1121, P361; Suzuki T., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1055, DOI 10.1142/S0218001493000534	7	10	10	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					391	395		10.1109/34.677264	http://dx.doi.org/10.1109/34.677264			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200004
J	Slater, D; Healey, G				Slater, D; Healey, G			The illumination-invariant matching of deterministic local structure in color images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; machine vision; color; color vision; color constancy; recognition; invariant recognition; local methods	RECOGNITION; OBJECTS	The availability of multiple spectral measurements at each pixel in an image provides important additional information for recognition. Spectral information is of particular importance for applications where spatial information is limited. Such applications include the recognition of small objects or the recognition of small features on partially occluded objects. We introduce a feature matrix representation for deterministic local structure in color images. Although feature matrices are useful for recognition, this representation depends on the spectral properties of the scene illumination. Using a linear model for surface spectral reflectance with the same number of parameters as the number of color bands, we show that changes in the spectral content of the illumination correspond to linear transformations of the feature matrices, and that image plane rotations correspond to circular shifts of the matrices. From these relationships, we derive an algorithm for the recognition of local surface structure which is invariant to these scene transformations. We demonstrate the algorithm with a series of experiments on images of real objects.			Slater, D (corresponding author), UNIV CALIF IRVINE,DEPT ELECT & COMP ENGN,IRVINE,CA 92697, USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; HEALEY G, 1995, J OPT SOC AM A, V12, P1877, DOI 10.1364/JOSAA.12.001877; HEALEY G, 1994, J OPT SOC AM A, V11, P3003, DOI 10.1364/JOSAA.11.003003; HU MK, 1961, P IRE            SEP; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Jain R., 1995, MACHINE VISION; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Silver W, 1980, THESIS MIT; Slater D, 1996, IEEE T PATTERN ANAL, V18, P206, DOI 10.1109/34.481544; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487	15	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1146	1151		10.1109/34.625119	http://dx.doi.org/10.1109/34.625119			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800010
J	Sussner, P; Ritter, GX				Sussner, P; Ritter, GX			Decomposition of gray-scale morphological templates using the rank method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						morphology; convolution; structuring element; morphological template; template decomposition; template rank	IMAGE ALGEBRA; CONVOLUTION	Convolutions are a fundamental tool in image processing. Classical examples of two dimensional linear convolutions include image correlation, the mean filter, the discrete Fourier transform, and a multitude of edge mask filters. Nonlinear convolutions are used in such operations as the median filter, the medial axis transform, and erosion and dilation as defined in mathematical morphology. For large convolution masks or structuring elements, the computation cost resulting from implementation can be prohibitive. However, in many instances, this cost can be significantly reduced by decomposing the templates representing the masks or structuring elements into a sequence of smaller templates. In addition, such decomposition can often be made architecture specific and, thus, resulting in optimal transform performance. In this paper we provide methods for decomposing morphological templates which are analogous to decomposition methods used in the linear domain. Specifically, we define the notion of the rank of a morphological template which categorizes separable morphological templates as templates of rank one. We establish a necessary and sufficient condition for the decomposability of rank one templates into 3 x 3 templates. We then use the invariance of the template rank under certain transformations in order to develop template decomposition techniques for templates of rank two.			Sussner, P (corresponding author), UNIV FLORIDA,GAINESVILLE,FL 32611, USA.		Sussner, Peter/C-8689-2013					Birkhoff G., 1970, J COMB THEORY, V8, P115, DOI DOI 10.1016/S0021-9800(70)80014-X; CROSBY FJ, 1995, THESIS U FLORIDA GAI; CUNNINGHAMEGREE.R, 1979, LECT NOTES EC MATH S, V166; Davidson J. L., 1992, Journal of Mathematical Imaging and Vision, V1, P169, DOI 10.1007/BF00122211; DAVIDSON JL, 1993, CVGIP-IMAG UNDERSTAN, V57, P283, DOI 10.1006/ciun.1993.1020; GADER P, 1980, SIAM J MATRIX ANAL A, P305; GADER PD, 1991, CVGIP-IMAG UNDERSTAN, V53, P288, DOI 10.1016/1049-9660(91)90016-I; LEE SY, 1987, IEEE T PATTERN ANAL, V9, P590, DOI 10.1109/TPAMI.1987.4767947; LI D, 1990, IMAGE ALGEBRA MORPHO, V1350, P408; MANSEUR ZZ, 1991, CVGIP-GRAPH MODEL IM, V53, P428, DOI 10.1016/1049-9652(91)90027-H; OLEARY DP, 1988, COMPUT VISION GRAPH, V41, P333, DOI 10.1016/0734-189X(88)90107-7; PARK H, 1994, IEEE T PATTERN ANAL, V16, P304, DOI 10.1109/34.276129; RITTER G, 1995, UNPUB IMAGE ALGEBRA; RITTER GX, 1987, J PARALLEL DISTR COM, V4, P7, DOI 10.1016/0743-7315(87)90007-4; RITTER GX, 1990, COMPUT VISION GRAPH, V49, P297, DOI 10.1016/0734-189X(90)90106-6; RITTER GX, 1991, ADV ELECTRON EL PHYS, V80, P243; STERNBERG SR, 1983, COMPUTER, V16; SUSSNER P, 1996, CCVR963 U FLOR CTR C; SUSSNER P, 1995, STATE ART GLOBAL OPT, P457; Takriti S., 1992, Journal of Mathematical Imaging and Vision, V2, P39, DOI 10.1007/BF00123880; XU J, 1991, IEEE T PATTERN ANAL, V13; ZHU HX, 1995, SIAM J MATRIX ANAL A, V16, P579, DOI 10.1137/S0895479893244493; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X; [No title captured]; [No title captured]	25	10	11	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					649	658		10.1109/34.601252	http://dx.doi.org/10.1109/34.601252			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200009
J	Trier, OD; Taxt, T; Jain, AK				Trier, OD; Taxt, T; Jain, AK			Recognition of digits in hydrographic maps: Binary versus topographic analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						binary analysis; topographic analysis; deconvolution; locally adaptive binarization; symbol recognition; data capture	CHARACTER-RECOGNITION; BINARIZATION METHODS; SEGMENTATION; FEATURES	This paper compares the performance of topographic analysis and binary analysis for recognition of digits in hydrographic maps. The performance of each method was measured by the correct classification rate of the final symbol recognition step when processing a complete hydrographic map of size 0.45 x 0.6 m(2) with about 35,000 digits. The experimental results indicated that binary analysis had a better performance than topographic analysis. Overall, the performance of the binary analysis was acceptable.	MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University	Trier, OD (corresponding author), UNIV OSLO,DEPT INFORMAT,POB 1080,N-0316 OSLO,NORWAY.							BOATTO L, 1992, COMPUTER, V25, P25, DOI 10.1109/2.144437; BROWN RM, 1988, PATTERN RECOGN, V21, P91, DOI 10.1016/0031-3203(88)90017-9; Duda R.O., 1973, J ROYAL STAT SOC SER; FUJISAWA H, 1992, P IEEE, V80, P1079, DOI 10.1109/5.156471; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HOLBAEKHANSSEN E, 1986, P 8 INT C PATT REC P, P144; Hori O., 1993, Machine Vision and Applications, V6, P100, DOI 10.1007/BF01211934; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; LEE HJ, 1992, PATTERN RECOGN, V25, P543, DOI 10.1016/0031-3203(92)90052-K; Lee S., 1991, P 1 INT C DOC AN REC, P260; MUSAVI MT, 1988, PATTERN RECOGN, V21, P319, DOI 10.1016/0031-3203(88)90045-3; Niblack W., 1986, INTRO DIGITAL IMAGE, P115; PAVLIDIS T, 1993, PATTERN RECOGN LETT, V14, P317, DOI 10.1016/0167-8655(93)90097-W; Pavlidis T., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P570; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; TAXT T, 1990, PATTERN RECOGN, V23, P1155, DOI 10.1016/0031-3203(90)90113-Y; TAXT T, 1994, P 12 IAPR INT C PATT, V2, P123; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; TRIER OD, 1996, 223 U OSL DEP INF; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; WESTALL JM, 1993, PATTERN RECOGN, V26, P1473, DOI 10.1016/0031-3203(93)90153-N; YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9	23	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					399	404		10.1109/34.588025	http://dx.doi.org/10.1109/34.588025			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200010
J	Madsen, CB; Christensen, HI				Madsen, CB; Christensen, HI			A viewpoint planning strategy for determining true angles on polyhedral objects by camera alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; viewpoint planning; camera alignment; angle	RECOGNITION	The paper presents a viewpoint planning strategy which automatically guides a movable camera from an arbitrary position io a position where the optical axis is perpendicular to a plane spanned by any two intersecting edges on a polyhedral object, i.e., a junction. In related work it is common to use the changing length of edge segments to control such alignment, but we demonstrate the use of the apparent angle between the edge segments oi the junction. By basing the control on the apparent angle we achieve robustness as well as independence of distance to the object. and focal length. The strategy is able to determine the true angle of a junction with an accuracy of approximately 1 degrees, and align with an accuracy of approximately 6 degrees.	ROYAL INST TECHNOL, CTR AUTONOMOUS SYST, S-10044 STOCKHOLM, SWEDEN	Royal Institute of Technology	Madsen, CB (corresponding author), UNIV AALBORG, LAB IMAGE ANAL, AALBORG, DENMARK.		Christensen, Henrik I/A-2261-2009	Madsen, Claus B./0000-0003-0762-3713				ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; BANIHASHEMI A, 1993, P IEEE C COMP VIS PA, P122; BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BRUNNSTROM K, 1992, LECT NOTES COMPUT SC, V588, P701; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; DICKINSON SJ, 1994, P EUR C COMP VIS ECC, P3; GREMBAN KD, 1994, INT J COMPUT VISION, V12, P137, DOI 10.1007/BF01421201; KUTULAKOS KN, 1994, INT J COMPUT VISION, V12, P113, DOI 10.1007/BF01421200; KUTULAKOS KN, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P331, DOI 10.1109/CVPR.1994.323848; MADSEN C, 1994, THESIS AALBORG U DEN; MADSEN CB, 1995, P 9 SCAND C IM AN JU, P1011; RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202; SHIMSHONI I, 1995, P INT C COMP VIS JUN; Wilkes D., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P136, DOI 10.1109/CVPR.1992.223215	14	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					158	163		10.1109/34.574798	http://dx.doi.org/10.1109/34.574798			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800010
J	Michel, J; Nandhakumar, N; Velten, V				Michel, J; Nandhakumar, N; Velten, V			Thermophysical algebraic invariants from infrared imagery for object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						invariance; thermal image; physics-based computer vision; image understanding; model-based vision		An important issue in developing a model-based vision system is the specification of features that are invariant to viewing and scene conditions and also specific, i.e., the feature must have different values for different classes of objects. We formulate a new approach for establishing invariant features. Our approach is unique in the field since it considers not just surface reflection and surface geometry in the specification of invariant features, but it also takes into account internal object composition and state which affect images sensed in the nonvisible spectrum. A new type of invariance called Thermophysical Invariance is defined. Features are defined such that they are functions of only the thermophysical properties of the imaged objects. The approach is based on a physics-based model that is derived from the principle of the conservation of energy applied at the surface of the imaged object.	ELECTROGLAS INC,SANTA CLARA,CA 95054; USAF,WRIGHT LAB ADV AVION,WRIGHT PATTERSON AFB,OH 45433	United States Department of Defense; United States Air Force; US Air Force Research Laboratory	Michel, J (corresponding author), ABTECH CORP,1575 STATE FARM BLVD,CHARLOTTESVILLE,VA 22911, USA.							BINFORD T, 1989, UNCERTAINTY AI, V3; BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X; BURNS JB, 1993, IEEE T PATTERN ANAL, V15; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13; FUKUNAGA K, INTRO STATISTICAL PA; GAUDER MJ, 1993, ATR SYST TECHN C; Gurevich G.B., 1964, FDN THEORY ALGEBRAIC; Healey G., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P355, DOI 10.1109/CVPR.1994.323851; IDSO SB, 1977, GEOPHYSICAL RES, V82; Incropera F. P., 1981, FUNDAMENTALS HEAT TR; Kapur D., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P97, DOI 10.1109/ISCV.1995.476984; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; Mahalanobis, 1936, P NATL I SCI INDIA, V2, P49; Mundy J., 1992, GEOMETRIC INVARIANCE; NANDHAKUMAR N, 1988, IEEE T PATTERN ANAL, V10, P469, DOI 10.1109/34.3911; Nandhakumar N., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P1306, DOI 10.1109/ROBOT.1988.12244; NANDHAKUMAR N, 1990, P IAPR TC7 WORKSH MU; NANDHAKUMAR N, IN PRESS J OPTICAL S; NAYAR SK, 1993, P IEEE ICCV; REISS T, 1993, LECT NOTES COMPUTER, V676; Rivlin E., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P697, DOI 10.1109/CVPR.1993.341022; Touloukian Y.S., 1972, THERMOPHYSICAL PROPE, V9; Touloukian YS., 1972, THERMOPHYSICAL PROPE, V8; Weinshall D., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P695, DOI 10.1109/CVPR.1993.341023; WEINSHALL D, 1991, IEEE T PATTERN ANAL, V13; WEISS I, 1993, IEEE T PATTERN ANAL, V15, P943, DOI 10.1109/34.232081; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705; WOLFF LB, 1994, P EUR C COMP VIS, P247; Zerroug M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P96, DOI 10.1109/CVPR.1993.340973	30	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					41	51		10.1109/34.566809	http://dx.doi.org/10.1109/34.566809			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800004
J	Parisse, C				Parisse, C			Global word shape processing in off-line recognition of handwriting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting; off-line; global recognition of word shape; contour; n-gram; large-size lexicon		Off-line recognition of handwriting may be achieved using simplified profiles of word shapes. These profiles consist of approximations of the word's upper and lower contour. Training and recognition are based on n-gram extraction and identification. The lexicons used extend to 16,000 words.			Parisse, C (corresponding author), HOP LA PITIE SALPETRIERE, INSERM, TLNP, PAVILLON CLAUDE BERNARD, 47 BD HOP, F-75651 PARIS 13, FRANCE.		Parisse, Christophe/N-4373-2018; Parisse, Christophe/E-1067-2019	Parisse, Christophe/0000-0002-0010-3363				Badie K., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P28; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; CHEN M, 1992, P US POST SERV ADV T, P563; CHERIET M, 1993, PATTERN RECOGNITION, V14; EARNEST LD, 1962, P IFIP C; FARAG RFH, 1979, IEEE T COMPUT, V28, P172, DOI 10.1109/TC.1979.1675310; Favata JT, 1992, P 5 USPS ADV TECHN C, P237; GILLIES AM, 1992, P USPS 5 ADV TECHN C; GILLOUX M, 1992, P USPS 5 ADV TECHN C, P545; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; HIGGINS CA, 1993, P 6 INT C HANDWR DRA, P111; HULL JJ, 1992, P INT C PATT REC, V2, P84; LECOLINET E, 1993, P 6 INT C HANDWR DRA, P89; MADHVANATH S, 1992, P US POSTAL SERVICE, P183; MERMELSTEIN P, 1964, P FALL JOINT COMP C, P333; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; SAYRE KM, 1973, PATTERN RECOGN, V5, P213, DOI 10.1016/0031-3203(73)90044-7; SUEN CY, 1992, P 2 PAC RIM INT C AR, P15; TOUSSAINT GT, 1970, IEEE T COMPUT, VC 19, P541, DOI 10.1109/T-C.1970.222972	20	10	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					460	464		10.1109/34.491629	http://dx.doi.org/10.1109/34.491629			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500013
J	HUANG, TS; BRUCKSTEIN, AM; HOLT, RJ; NETRAVALI, AN				HUANG, TS; BRUCKSTEIN, AM; HOLT, RJ; NETRAVALI, AN			UNIQUENESS OF 3D POSE UNDER WEAK PERSPECTIVE - A GEOMETRICAL PROOF	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						POSE DETERMINATION; WEAK PERSPECTIVE PROJECTION	IMAGE	We present a purely geometrical proof that under the weak perspective model, the 3D pose of a 3-point configuration is determined uniquely up to a reflection by its 2D projection.	AT&T BELL LABS,MURRAY HILL,NJ	AT&T; Nokia Corporation; Nokia Bell Labs	HUANG, TS (corresponding author), UNIV ILLINOIS,URBANA,IL 61801, USA.		Holt, Robert J/B-5460-2009					ALTER TD, 1994, IEEE T PATTERN ANAL, V16, P802, DOI 10.1109/34.308475; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; [No title captured]	4	10	19	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1220	1221		10.1109/34.476515	http://dx.doi.org/10.1109/34.476515			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500010
J	NISHIDA, H				NISHIDA, H			MODEL-BASED SHAPE-MATCHING WITH STRUCTURAL FEATURE GROUPING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CHARACTER RECOGNITION; HANDWRITING RECOGNITION; IMAGE MATCHING; SHAPE MATCHING; SHAPE DESCRIPTION; SHAPE ANALYSIS; STRUCTURAL DESCRIPTION	ONLINE HANDWRITING RECOGNITION	An essential problem in on-line handwriting recognition is the shape variation along with the variety of stroke number and stroke order. In this paper we present a clear and systematic approach to shape matching based on structural feature grouping. To cope with topological deformations caused by stroke connection and breaking, we incorporate some aspects of top-down approaches systematically into the shape matching algorithm. The grouping of local structural features into high level features is controlled by high-level knowledge as well as the simple geometric conditions. The shape matching algorithm has the following properties from the viewpoint of on-line character recognition: 1) stroke order, direction, and number are free, and 2) stroke connection and breaking are allowed.			NISHIDA, H (corresponding author), UNIV AIZU,SCH ENGN & COMP SCI,AIZU WAKAMATSU,FUKUSHIMA 96580,JAPAN.							COX CH, 1982, PATTERN RECOGN, V15, P11, DOI 10.1016/0031-3203(82)90056-5; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; Ishii K., 1989, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ72D-II, P669; Ishii K., 1983, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ66D, P1270; Nakagawa M., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1059; NISHIDA H, 1992, IEEE T PATTERN ANAL, V14, P516, DOI 10.1109/34.134057; NISHIDA H, 1993, IEEE T PATTERN ANAL, V15, P1298, DOI 10.1109/34.250847; NISHIDA H, 1995, COMPTUER VISION IMAG, V61; NISHIDA H, 1994, ASPECTS VISUAL FORM, P420; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; WAKAHARA T, 1992, P IEEE, V80, P1181, DOI 10.1109/5.156478	11	10	17	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					315	320		10.1109/34.368198	http://dx.doi.org/10.1109/34.368198			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000010
J	KULKARNI, SR; MITTER, SK; RICHARDSON, TJ; TSITSIKLIS, JN				KULKARNI, SR; MITTER, SK; RICHARDSON, TJ; TSITSIKLIS, JN			LOCAL VERSUS NONLOCAL COMPUTATION OF LENGTH OF DIGITIZED-CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						LOCAL; NONLOCAL; PARALLEL COMPUTATION; LENGTH; DIGITIZED CURVE	IMAGES	In this paper, we consider the problem of computing the length of a curve from digitized versions of the curve using parallel computation. Our aim is to study the inherent parallel computational complexity of this problem as a function of the digitization level. Precise formulations for the digitization, the parallel computation, and notions of local and nonlocal computations are given. We show that length cannot be computed locally from digitizations on rectangular tessellations. However, for a random tessellation and appropriate deterministic ones, we show that the length of straight line segments can be computed locally. Implications of our results for a method for image segmentation and a number of open problems are discussed.	MIT,INFORMAT & DECIS SYST LAB,CAMBRIDGE,MA 02139; AT&T BELL LABS,MATH SCI RES CTR,MURRAY HILL,NJ 07974	Massachusetts Institute of Technology (MIT); AT&T; Nokia Corporation; Nokia Bell Labs	KULKARNI, SR (corresponding author), PRINCETON UNIV,DEPT ELECT ENGN,PRINCETON,NJ 08544, USA.							Abelson H., 1978, Theoretical Computer Science, V6, P41, DOI 10.1016/0304-3975(78)90004-X; AMBARTZUMIAN RV, 1987, STOCHASTIC INTEGRAL; AMBROSIO L, 1988, CICSP63 MIT CTR INT; AMBROSIO L, 1988, CICSP86 MIT CONTR SY; ATTOUCH H, 1984, VARIATION CONVERGENC; BADDELEY AJ, 1986, CWI MONOGRAPHS; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; KONG TY, 1990, PATTERN RECOGN LETT, V11, P231, DOI 10.1016/0167-8655(90)90060-F; KOPLOWITZ J, 1989, IEEE T PATTERN ANAL, V11, P611, DOI 10.1109/34.24795; KOPLOWITZ J, 1988, SPIE, V1001, P756; KULKARNI SR, 1990, SIGNAL PROCESSING 1, V22, P189; KULKARNI SR, 1991, THESIS MIT; KULKARNI SR, 1994, SPIE NEURAL STOCHAST, V3, P2304; LEE CN, 1990, COMPUT VISION GRAPH, V51, P87, DOI 10.1016/S0734-189X(05)80064-7; MARROQUIN J, 1987, J AM STATIST SOC, V82, P77; Minsky M., 1969, PERCEPTRONS; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; MONTANARI U, 1970, COMMUN ACM, V13; MORAN PAP, 1966, BIOMETRIKA, V53, P359; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; MUMFORD D, UNPUB COMMUN PURE AP; RICHARDSON TJ, 1989, THESIS MIT; Santal LA., 1953, INTRO INTEGRAL GEOME, V1198; STEELE JM, 1981, ANN PROBAB, V9, P365, DOI 10.1214/aop/1176994411; STEINHAUS H., 1954, C MATH, VIII, P1, DOI DOI 10.4064/CM-3-1-1-13; Stoyan D., 1987, STOCHASTIC GEOMETRY	29	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					711	718		10.1109/34.297951	http://dx.doi.org/10.1109/34.297951			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134					2022-12-18	WOS:A1994NY13400004
J	LIN, JC; TSAI, WH				LIN, JC; TSAI, WH			FEATURE-PRESERVING CLUSTERING OF 2-D DATA FOR 2-CLASS PROBLEMS USING ANALYTICAL FORMULAS - AN AUTOMATIC AND FAST APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						2-CLASS CLUSTERING; CLUSTER REPRESENTATIVES; FEATURE-PRESERVING; ANALYTICAL FORMULAS; DECISION BOUNDARY; AUTOMATIC FAST CLUSTERING; K-MEANS; HIERARCHICAL METHODS		We propose in this correspondence a new method to perform two-class clustering of 2-D data in a quick and, automatic way by preserving certain features of the input data. The method is analytical, deterministic, unsupervised, automatic, and noniterative. The computation time is of order n if the data size is n, and hence much faster than any other method which requires the computation of an n-by-n dissimilarity matrix. Furthermore, the proposed method does not have the trouble of guessing initial values. This new approach is thus more suitable for fast automatic hierarchical clustering or any other fields requiring fast automatic two-class clustering of 2-D data. The method can be extended to cluster data in higher dimensional space. A 3-D example is included.			LIN, JC (corresponding author), NATL CHIAO TUNG UNIV,DEPT COMP & INFORMAT SCI,HSINCHU 30050,TAIWAN.							DEVIJVER PA, 1982, PATTERN RECOGN, P406; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; HATHAWAY RJ, 1988, J CLASSIF, V2, P29; Kaufman L., 2009, FINDING GROUPS DATA; Lecompte D, 1986, Acta Psychiatr Belg, V86, P324; LIN JC, 1993, PATTERN RECOGN, V26, P485, DOI 10.1016/0031-3203(93)90104-5; LIN JC, 1992, NSC810408E009589 NAT; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502; TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; 1989, INT MATH STATISTICAL	13	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					554	560						7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100014
J	SUN, Y; LIU, I; GRADY, JK				SUN, Y; LIU, I; GRADY, JK			RECONSTRUCTION OF 3-D BINARY TREE-LIKE STRUCTURES FROM 3 MUTUALLY ORTHOGONAL PROJECTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3-VIEW RECONSTRUCTION; ORTHOGONAL PROJECTIONS; 3-D TREE STRUCTURE; MORPHOLOGICAL FILTERING; ITERATIVE LEAST-SQUARES METHOD	IMAGE-RECONSTRUCTION; ALGORITHMS	A method is developed to generate the 3-D binary representation for a tree-like object from three mutually orthogonal projections. This is done by first backprojecting the binarized images from three directions and then iteratively removing artifacts in the backprojection. Three different algorithms have been developed: the Lagrange multiplier algorithm (LMA), the conjugate gradient algorithm (CGA), and the minimum-voxel representation algorithm (MRA). The performance of these algorithms under noise-free conditions is evaluated using mathematically projected images of a 3-D tree structure. While all three algorithms are capable of producing a relatively accurate reconstruction, the MRA is superior not only because it requires the least amount of computation but also because it uses binary instead of gray-scale information in the input images. Reconstruction of 3-D coronary arterial structures using MRA is further verified with x-ray images of a human chest phantom and shows a satisfactory performance. The result of this study should be valuable for 3-D imaging of blood vessels.	XRE CORP,LITTLETON,MA 01460		SUN, Y (corresponding author), UNIV RHODE ISL,COLL ENGN,FAC ELECT ENGN,DEPT ELECT ENGN,KINGSTON,RI 02881, USA.							CHUA LO, 1975, COMPUTER AIDED ANAL, P631; CRYPTON, 1985, SCI DIG, V93, P74; GONZALEZ RC, 1987, DIGITAL IMAGE PROCES, P351; GOTTFRIED BS, 1973, INTRO OPTIMIZATION T; Herman G T, 1976, Comput Biol Med, V6, P273, DOI 10.1016/0010-4825(76)90066-4; KATAWA S, 1985, IEEE T MED IMAGING, V4, P65; LIU IH, 1992, OPT ENG, V31, P2197, DOI 10.1117/12.59977; MEDOFF BP, 1983, J OPT SOC AM, V73, P1493, DOI 10.1364/JOSA.73.001493; PAPOULIS A, 1975, IEEE T CIRCUITS SYST, V22, P735, DOI 10.1109/TCS.1975.1084118; PENG H, 1989, IEEE T MED IMAGING, V8, P16, DOI 10.1109/42.20358; SARKAR TK, 1986, IEEE ANTENNAS PR AUG, P5; SOUMEKH M, 1988, P IEEE INT C ACOUSTI, P1281	12	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					241	248						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400004
J	CHEN, MH; CHIN, RT				CHEN, MH; CHIN, RT			PARTIAL SMOOTHING SPLINES FOR NOISY PLUS BOUNDARIES WITH CORNERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						PARTIAL SMOOTHING SPLINE; GENERALIZED CROSS-VALIDATION; SMOOTHING PARAMETER; BOUNDARY ESTIMATION; CORNER DETECTION	CROSS-VALIDATION; REGULARIZATION; DISCONTINUITIES; CURVE	We have investigated the estimation of 2-D boundary functions from sampled data sets where both noise and corners are present. The approach is based on the partial smoothing spline in which the estimated boundary function consists of an ordinary smoothing spline and a parametric function that describes the discontinuities (i.e., corners of the boundary). Prior knowledge about the boundary, such as the number of corners, their locations, noise levels, and the amount of smoothness, is not required for the boundary estimate. The smoothing parameter and the corner locations of the spline, which are parts of the estimate, are determined by the generalized cross-validation method whereby statistical properties are gathered from the input sampled data rather than specified a priori. This approach enables the smoothing of a noisy boundary while retaining an accurate description of the boundary corners. Extensive experiments were conducted to verify its ability to smooth noise while retaining a good representation of boundary corners, and do not rely on any prior information.			CHEN, MH (corresponding author), UNIV WISCONSIN, DEPT ELECT & COMP ENGN, 1415 JOHNSON DR, MADISON, WI 53706 USA.		Chin, Roland Tai Hong/E-9856-2010					ANSELONE PM, 1968, NUMER MATH, V12, P66, DOI 10.1007/BF02170998; Boult T. E., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P68; BUCK R, 1978, ADV CALCULUS; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; KASS M, 1987, 1ST P INT C COMP VIS, P259; KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; LEE D, 1988, IEEE T PATTERN ANAL, V10, P822, DOI 10.1109/34.9105; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; REINSCH CH, 1971, NUMER MATH, V16, P451, DOI 10.1007/BF02169154; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; SHIAU JH, 1985, THESIS U WISCONSIN M; SHIAU JJ, 1986, J ATMOSPHERIC OCEANI, V3, P74; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TIHONOV AN, 1963, SOV MATH DOKL, V4, P1624; WAHBA G, 1975, COMMUN STAT, V4, P1, DOI 10.1080/03610927508827223; Wahba G., 1990, SPLINE MODELS OBSERV	21	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1993	15	11					1208	1216						9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MH083					2022-12-18	WOS:A1993MH08300011
J	EDELMAN, S				EDELMAN, S			ON LEARNING TO RECOGNIZE 3-D OBJECTS FROM EXAMPLES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPLEXITY; LEARNING FROM EXAMPLES; OBJECT RECOGNITION; REPRESENTATION; VISION		Previous results on nonlearnability of visual concepts relied on the assumption that such concepts are represented as sets of pixels [1]. This correspondence uses an approach developed by Haussler [2] to show that under an alternative, feature-based representation, recognition is PAC learnable from a feasible number of examples in a distribution-free manner.			EDELMAN, S (corresponding author), WEIZMANN INST SCI,DEPT APPL MATH & COMP SCI,IL-76100 REHOVOT,ISRAEL.							BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Boff K.R., 1986, HDB PERCEPTION HUMAN; DODWELL PC, 1983, PERCEPT PSYCHOPHYS, V34, P1, DOI 10.3758/BF03205890; EDELMAN S, 1991, BIOL CYBERN, V64, P209, DOI 10.1007/BF00201981; EDELMAN S, 1991, CSTR10 WEIZM I SCI; EDELMAN S, 1992, ANN STAT, V6, P37; GOIROSI F, 1990, AI1164 MIT ART INT L; GRIMSON WEL, 1981, IMAGES SURFACES; HAUSSLER D, 1989, USCSCRL8930 U CAL; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; Marr D., 1982, VISION; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Pollard David, 1984, CONVERGENCE STOCHAST; RUSSELL B, 1921, ANALYSIS MIND; SHVAYTSER H, 1990, IEEE T PATTERN ANAL, V12, P459, DOI 10.1109/34.55105; SHVAYTSER H, 1990, 3RD P C COMP VIS TOK; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; TSAO T, 1987, TR1851 U MAR; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Ullman S., 1983, HUMAN MACHINE VISION; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; [No title captured]	25	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					833	837		10.1109/34.236244	http://dx.doi.org/10.1109/34.236244			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800010
J	QIAN, W; TITTERINGTON, DM				QIAN, W; TITTERINGTON, DM			BAYESIAN IMAGE-RESTORATION - AN APPLICATION TO EDGE-PRESERVING SURFACE RECOVERY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						AUTONORMAL; DISCONTINUITY; EDGE PRESERVATION; EM ALGORITHM; MARKOV RANDOM FIELD; REGULARIZATION; RESTORATION	STATISTICAL-ANALYSIS; RECONSTRUCTION; RELAXATION; VISION	Bayesian methods are used to recover a 2-D surface by assuming that there is a textural image that can be modeled by a Markov random field and that the original surface is composed of different surfaces, each of which is associated with one textural state. Both parametric and nonparametric methods are used to enforce smoothness of these surfaces. Iterative procedures are examined for simultaneous restoration of the textural image and estimation of underlying parameters. From the estimated textural image and the estimated parameters, an estimate for the original surface can be obtained. Some numerical examples are presented, including an illustration from electron microscopy.			QIAN, W (corresponding author), UNIV GLASGOW,DEPT STAT,GLASGOW G12 8QQ,SCOTLAND.							BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; BESAG J, 1986, J R STAT SOC B, V48, P259; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; BLAKE A, 1986, C COMPUTER VISION PA, P656; Blake A, 1983, PATTERN RECOGN LETT, V1, P393, DOI 10.1016/0167-8655(83)90077-6; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HALL P, 1992, TECHNOMETRICS, V34, P429, DOI 10.2307/1268942; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; LEE D, 1990, IEEE T PATTERN ANAL, V12, P321, DOI 10.1109/34.50620; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; QIAN W, 1991, PHILOS T ROY SOC A, V337, P407, DOI 10.1098/rsta.1991.0132; Qian W., 1992, J STATIST COMPUT SIM, V40, P55; QIAN W, 1989, J APPL STAT, V16, P267; RIPLEY BD, 1988, STATISTICAL INFERENC; SINHA SS, 1992, IEEE T PATTERN ANAL, V14, P36, DOI 10.1109/34.107012; TAN HL, 1992, IEEE T PATTERN ANAL, V14, P3, DOI 10.1109/34.107010; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; Tikhonov A., 1977, SOLUTIONS ILL POSED; VEIJANEN A, 1990, 74 U HELS DEP STAT R; WU JS, 1990, KERNEL TYPE ESTIMATI	29	10	11	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					748	752		10.1109/34.221174	http://dx.doi.org/10.1109/34.221174			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185					2022-12-18	WOS:A1993LM18500008
J	TALLURI, R; AGGARWAL, JK				TALLURI, R; AGGARWAL, JK			IMAGE MAP CORRESPONDENCE FOR MOBILE ROBOT SELF-LOCATION USING COMPUTER-GRAPHICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						AUTONOMOUS NAVIGATION; COMPUTER GRAPHICS; COMPUTER VISION; CONSTRAINED SEARCH; DIGITAL ELEVATION MAP; POSITION ESTIMATION	TERRAIN	This paper discusses the use of computer graphics in estimating the position of an autonomous mobile robot navigating in an outdoor, mountainous environment, which is fundamentally a computer vision task. A digital elevation map (DEM) of the area in which the robot is to navigate is given, and the robot is equipped with a camera that can be panned and tilted, a compass, and an altimeter. The position of the robot is estimated by establishing a correspondence between the images acquired by the camera on the robot (actual images) and the images generated from the DEM (predicted images) using computer graphics techniques. Features are extracted from the predicted images, and the actual images that are used in establishing the correspondence. The features used are the horizon line contours (HLC's) in the images. In order to reduce the search space (the set of possible robot locations) to be considered in generating the images, a constrained search paradigm is used. Geometric constraints help prune the search space significantly. The novel feature of this work is the collaboration between computer graphics and computer vision techniques to establish the position of the robot in its environment. The approach is tested using real terrain data of areas in Colorado and simulated images. The method is suitable for use in outdoor mobile robots and planetary rovers.	UNIV TEXAS,DEPT ELECT & COMP ENGN,COMP VIS RES CTR,AUSTIN,TX 78712	University of Texas System; University of Texas Austin	TALLURI, R (corresponding author), TEXAS INSTRUMENTS INC,CENT RES LABS,DALLAS,TX 75265, USA.							Bowyer K. W., 1990, International Journal of Imaging Systems and Technology, V2, P315, DOI 10.1002/ima.1850020407; GAGALOWICZ A, 1990, 4TH P ICCV OS, P733; GENNERY DB, 1989, JUN P C COMP VIS PAT, P483; KAK AC, 1990, UNCERTAINTY ARTIFICI, V5, P353; KUBERT B, 1968, J ACM, V15, P193, DOI 10.1145/321450.321453; RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P1138, DOI 10.1109/34.62603; TALLURI R, 1992, IEEE T ROBOTIC AUTOM, V8, P573, DOI 10.1109/70.163782; TALLURI R, 1990, JUL P IEEE WORKSH IN, P159; TALLURI R, 1990, NOV P AIAA NASA INT, P135; TSUBOUCHI T, 1987, MAR P IEEE INT C ROB, P1978; WILLIAMSON H, 1972, COMMUN ACM, V15, P100, DOI 10.1145/361254.361264; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108; WRIGHT TJ, 1973, IEEE T COMPUT, VC 22, P28, DOI 10.1109/T-C.1973.223597; YOKOYA N, 1989, COMPUT VISION GRAPH, V46, P284, DOI 10.1016/0734-189X(89)90034-0	15	10	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					597	601		10.1109/34.216729	http://dx.doi.org/10.1109/34.216729			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700008
J	RONSE, C				RONSE, C			ON IDEMPOTENCE AND RELATED REQUIREMENTS IN EDGE-DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDGE DETECTION; EDGE MAP; ENERGY FEATURE DETECTOR; FOURIER PHASE AND AMPLITUDE; IDEMPOTENCE; PROJECTION; QUADRATURE	ENERGY	Owens et al. [13] investigated an important desirable property for edge detection: The edge map E(I) of a grey-level image I is identical to its own edge map E(E(I)); in other words, the edge detection operation E is idempotent, or, a projection: E o E = E. Although they modeled the edge map of a figure by a Dirac distribution, this map can more generally be considered to be a line edge. Thus, an idempotent edge detector must be able to detect line edges, and this is why pure step edge detectors (e.g., gradient maximum, zero crossing of convolution by the Laplacian of a Gaussian, etc.) often fail to be idempotent. The energy feature detectors described in [13] are good candidates for idempotent edge detectors. However, some of them (in particular, the Gabor energy feature detector) suffer from an important defect that is absent in gradient-type operators: their sensitivity to grey-level shift in the original image. This leads to errors in the localization of step edges. The Fourier phase and amplitude conditions outlined by Morrone [10] for the class of energy feature detectors are interesting in this respect. First, when the convolution masks are taken in L1, these conditions guarantee a zero dc level; therefore, the resulting energy feature detector is invariant under grey-level shift in the original image. Second, the properties of the underlying edge model are invariant under a smoothing of the image by a Gaussian or any function in L1 having zero Fourier phase. In particular, such a smoothing does not deteriorate the idempotence of the edge detector, contrary to what is asserted in [13]. Some concrete examples of energy feature detectors satisfying the Morrone conditions are described. The mathematical properties of the model will be analyzed in great detail in a further paper [14].			RONSE, C (corresponding author), UNIV STRASBOURG 1,DEPT INFORMAT,F-67070 STRASBOURG,FRANCE.							ABRAMOWITZ M, 1964, NBS APPLIED MATH SER, V55; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; KLEIN SA, 1985, J OPT SOC AM A, V2, P1170, DOI 10.1364/JOSAA.2.001170; KUNDU A, 1990, PATTERN RECOGN, V23, P423, DOI 10.1016/0031-3203(90)90065-S; LACROIX V, 1991, 10TH P INT C PATT RE, V1, P903; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1982, PHIL T ROYAL SOC L B; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0; OWENS R, 1989, PATTERN RECOGN LETT, V9, P233, DOI 10.1016/0167-8655(89)90002-0; RONSE C, UNPUB1 DIMENSIONAL L; ROSS J, IN PRESS LEONARDO; Rudin W, 1970, REAL COMPLEX ANAL; SERRA J, 1987, J MICROSC-OXFORD, V145, P1, DOI 10.1111/j.1365-2818.1987.tb01312.x; Stein EM., 1971, FOURIER ANAL EUCLIDE; VENKATESH S, 1990, PATTERN RECOGN LETT, V11, P339, DOI 10.1016/0167-8655(90)90043-2	19	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					484	491		10.1109/34.211468	http://dx.doi.org/10.1109/34.211468			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000006
J	CORTELAZZO, G; BALANZA, M				CORTELAZZO, G; BALANZA, M			FREQUENCY-DOMAIN ANALYSIS OF TRANSLATIONS WITH PIECEWISE CUBIC TRAJECTORIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACCELERATION AND DERIVATIVES OF THE ACCELERATION; CUBIC SPLINE TRAJECTORIES; FREQUENCY DOMAIN ANALYSIS; MOTION ANALYSIS; SPECTRAL STRUCTURES OF MOVING SCENES		Translations with piecewise cubic trajectories are studied in the frequency domain. This class of motion has as an important subcase: cubic spline trajectories. Translations with trajectories depending on time with general polynomial law are preliminarily considered, and a general theorem concerning this type of motion is introduced. The application of this theorem to the case of cubic time dependence and the consideration of finite-duration effects lead to the solution of the piecewise cubic trajectory case. The results, which are remarkably different from those concerning constant velocity translations, clearly indicate the importance of the role of velocity and time duration. In this respect, they confirm the validity of constant velocity motion as a first-order model for frequency domain analysis of motion.	LAB RIC & SVILUPPO SELECO SPA,PORDENONE,ITALY		CORTELAZZO, G (corresponding author), UNIV PADUA,DIPARTIMENTO ELETTR & INFORMAT,I-35100 PADUA,ITALY.							ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; BALANZA M, 1989, 3RD P INT WORKSH HDT; DREWERY JO, 1975, BBC RD197531 TECH RE; Erdelyi A, 1954, TABLES INTEGRAL TRAN; FLEET DJ, 1989, IEEE T PATTERN ANAL, V11, P315, DOI 10.1109/34.21800; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HUANG TS, 1983, IMAGE SEQUENCE ANAL; PAPOULIS A, 1968, SYSTEMS TRANSFORMS A; WATSON AB, 1983, NASA84352 AM RES CTR	9	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1993	15	4					411	416		10.1109/34.206960	http://dx.doi.org/10.1109/34.206960			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU543					2022-12-18	WOS:A1993KU54300008
J	CHEN, LT; DAVIS, LS; KRUSKAL, CP				CHEN, LT; DAVIS, LS; KRUSKAL, CP			EFFICIENT PARALLEL PROCESSING OF IMAGE CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; CONNECTION MACHINE; HYPERCUBES; IMAGE CONTOUR ANALYSIS; LIST RANKING; PARALLEL PROCESSING; SCAN OPERATONS		This paper describes two parallel algorithms for ranking the pixels on a curve in O(log N) time using either a EREW or CREW PRAM model. The algorithms accomplish this with N processors for a square-root N x square-root N image. After applying such an algorithm to an image, we are able to move the pixels from a curve into processors having consecutive addresses. This is important because we can subsequently apply many algorithms to the curve (such as piecewise linear approximation algorithms (or point in polygon tests) using segmented scan operations (i.e., parallel prefix operations). Scan operations can be executed in logarithmic time on many interconnection networks, such as hypercube, tree, butterfly, and shuffle exchange machines as well as on the EREW PRAM. The algorithms were implemented on hypercube structured Connection Machine, and various performance tests were conducted.	UNIV MARYLAND,DEPT COMP SCI,COLL PK,MD 20742	University System of Maryland; University of Maryland College Park	CHEN, LT (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLL PK,MD 20742, USA.							AGRAWAL A, 1987, AUG P INT C PAR PROC, P783; ANDERSON RJ, 1988, 3RD P AWOC, P81; CHEN LT, 1990, SEP P DARPA IM UND W, P805; CHEN LT, 1990, CARTR501CSTR2458 CEN; CHEN LT, 1991, CARTR541CSTR2629 CEN; COLE R, 1988, SIAM J COMPUT, V17, P128, DOI 10.1137/0217009; Hillis W., 1985, CONNECTION MACHINE; HUNG Y, 1988, THESIS U MARYLAND CO; TARJAN RE, 1985, SIAM J COMPUT, V14, P862, DOI 10.1137/0214061; WEEMS CC, 1989, INT J COMPUT VISION, V2, P251, DOI 10.1007/BF00158166; WU AY, 1989, PATTERN RECOGN, V22, P165, DOI 10.1016/0031-3203(89)90063-0; [No title captured]	12	10	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1993	15	1					69	81		10.1109/34.184775	http://dx.doi.org/10.1109/34.184775			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KH085					2022-12-18	WOS:A1993KH08500005
J	KUHN, R; DEMORI, R				KUHN, R; DEMORI, R			A CACHE-BASED LANGUAGE MODEL FOR SPEECH RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KUHN, R (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2K6,QUEBEC,CANADA.							ESSEN U, 1991, FIRST QUANT LING C T; JELINEK F, 1991, 4TH P DARPA WORKSH S, P293; KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193	3	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					691	692						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600011
J	DUNCAN, JS; BIRKHOLZER, T				DUNCAN, JS; BIRKHOLZER, T			REINFORCEMENT OF LINEAR STRUCTURE USING PARAMETRIZED RELAXATION LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDGE REINFORCEMENT; EDGE REINFORCEMENT WITH THINNING; LINE ENHANCEMENT; OPTIMIZATION; NEURAL NETWORKS; NOISE SUPPRESSION; RELAXATION LABELING	EDGE-DETECTION	The problem of reinforcing local evidence of linear structure while suppressing unwanted information in noisy images is considered, using a new modified form of relaxation labeling. The methodology is based on parametrizing a continuous set of orientation labels via a single vector and using a sigmoidal thresholding function to bias neighborhood influence and ensure convergence to meaningful stable states. Label strength and label/no-label decisions are incorporated into a single functional. Optimal points of the functional represent the cases where as many pixels (objects) as possible have achieved the desirable linear-structure-reinforced and noise-suppressed labelings. Three different linear structure reinforcement tasks are considered within the general framework: edge reinforcement, edge reinforcement with thinning, and bar (line segment) reinforcement. Results are presented from several image data sets. The primary advantages to this approach are that it can directly handle continuous feature information (both magnitude and direction) from low-level image analysis operators (primarily edge and line detectors) and that the computational complexity of labeling is reduced due to the parametrization. Both of these improvements are of considerable practical utility.	YALE UNIV,DEPT DIAGNOST RADIOL,NEW HAVEN,CT 06510	Yale University	DUNCAN, JS (corresponding author), YALE UNIV,DEPT ELECT ENGN,NEW HAVEN,CT 06510, USA.							AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DUNCAN JS, 1989, PATTERN RECOGN LETT, V9, P27, DOI 10.1016/0167-8655(89)90025-1; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; LYVERS EP, 1988, IEEE T PATTERN ANAL, V10, P927, DOI 10.1109/34.9114; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHACHTER BJ, 1977, IEEE T SYST MAN CYB, V7, P813; Sha'ashua A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P321, DOI 10.1109/CCV.1988.590008; Zucker S. W., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P568, DOI 10.1109/CCV.1988.590037; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41	16	10	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1992	14	5					502	515		10.1109/34.134056	http://dx.doi.org/10.1109/34.134056			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HR650					2022-12-18	WOS:A1992HR65000001
J	ONURAL, L				ONURAL, L			GENERATING CONNECTED TEXTURED FRACTAL PATTERNS USING MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						FRACTAL GENERATION; FRACTALS; MARKOV RANDOM FIELDS; PATTERN MODELING; TEXTURES	DIFFUSION-LIMITED AGGREGATION; CLUSTER CLUSTER AGGREGATION; IMAGES; DIMENSION; SYSTEMS; MODEL; GIBBS; SEGMENTATION; ALGORITHMS; RELAXATION	A procedure that yields textured and connected binary fractals is presented. The texture is imposed by modeling the fractal as a Markov random field at every resolution level. The model size and the parameters specify the texture. The generation starts at a coarser level and continues at finer levels. Connectivity, which is a global property, is maintained by restricting the flow of the sample generating Markov chain within a limited subset of all possible outcomes of the Markov random field. Sample patterns are shown.			ONURAL, L (corresponding author), BILKENT UNIV,DEPT ELECT & ELECTR ENGN,ANKARA,TURKEY.							BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CLARK NN, 1986, POWDER TECHNOL, V46, P45, DOI 10.1016/0032-5910(86)80097-3; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; FLINN PA, 1974, J STAT PHYS, V10, P89, DOI 10.1007/BF01011718; FORREST SR, 1979, J PHYS A-MATH GEN, V12, pL109, DOI 10.1088/0305-4470/12/5/008; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HASSNER M, 1980, COMPUT VISION GRAPH, V12, P357, DOI 10.1016/0146-664X(80)90019-2; HONG DC, 1985, J PHYS A-MATH GEN, V18, P1103; ISHAM V, 1981, INT STAT REV, V49, P21, DOI 10.2307/1403035; JULLIEN R, 1986, J PHYS A-MATH GEN, V19, P2129, DOI 10.1088/0305-4470/19/11/022; KAYE BH, 1978, POWDER TECHNOL, V21, P1, DOI 10.1016/0032-5910(78)80103-X; KAYE BH, 1985, AM LAB           APR, P55; Kinderman R., 1980, MARKOV RANDOM FIELDS; KOLB M, 1986, J PHYS A-MATH GEN, V19, pL263, DOI 10.1088/0305-4470/19/5/009; LEWIS M, 1985, SCIENCE, V230, P1163, DOI 10.1126/science.4071040; MALZBENDER RM, 1985, J PHYS A-MATH GEN, V18, P1143; Mandelbrot, 1982, FRACTAL GEOMETRY NAT, P394; Mandelbrot B.B., 1977, FRACTALS FORM CHANCE; MARGOLINA A, 1985, J PHYS A-MATH GEN, V18, pL651, DOI 10.1088/0305-4470/18/11/004; MARTIN JE, 1985, J PHYS A-MATH GEN, V18, pL625, DOI 10.1088/0305-4470/18/10/012; MEAKIN P, 1984, J COLLOID INTERF SCI, V102, P491, DOI 10.1016/0021-9797(84)90252-2; MEAKIN P, 1986, J PHYS A-MATH GEN, V19, P2137, DOI 10.1088/0305-4470/19/11/023; MEAKIN P, 1983, PHYS REV A, V27, P1495, DOI 10.1103/PhysRevA.27.1495; MEAKIN P, 1985, J PHYS A-MATH GEN, V18, pL661, DOI 10.1088/0305-4470/18/11/006; MOUSSOUR.J, 1974, J STAT PHYS, V10, P11, DOI 10.1007/BF01011714; NORMAND MD, 1986, POWDER TECHNOL, V45, P271, DOI 10.1016/0032-5910(86)80121-8; ORBACH R, 1986, SCIENCE, V231, P814, DOI 10.1126/science.231.4740.814; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; PFEIFER P, 1983, J CHEM PHYS, V79, P3558, DOI 10.1063/1.446210; RIPLEY BD, 1986, CAN J STAT, V14, P83, DOI 10.2307/3314656; Rozanov Y. A., 1982, MARKOV RANDOM FIELDS; WITTEN TA, 1986, SCIENCE, V232, P1607, DOI 10.1126/science.232.4758.1607; WITTEN TA, 1981, PHYS REV LETT, V47, P1400, DOI 10.1103/PhysRevLett.47.1400; WITTEN TA, 1983, PHYS REV B, V27, P5686, DOI 10.1103/PhysRevB.27.5686	38	10	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					819	825		10.1109/34.85673	http://dx.doi.org/10.1109/34.85673			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642		Green Submitted			2022-12-18	WOS:A1991GC64200008
J	PARK, RH; CHOI, WY				PARK, RH; CHOI, WY			A 3-MODULE STRATEGY FOR EDGE-DETECTION - COMMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PARK, RH (corresponding author), SOGANG UNIV,DEPT ELECTR ENGN,CPO BOX 1142,SEOUL 100611,SOUTH KOREA.		Park, Rae-Hong/Q-7908-2019; Park, Rae-Hong/Q-7955-2019	Park, Rae-Hong/0000-0002-4792-2980				FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; GONZALEZ RC, 1977, DIGITAL IMAGE PROCES, P333	2	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					223	224						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282					2022-12-18	WOS:A1990CL28200011
J	YAMAMOTO, M				YAMAMOTO, M			A GENERAL APERTURE PROBLEM FOR DIRECT ESTIMATION OF 3-D MOTION PARAMETERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											YAMAMOTO, M (corresponding author), MINIST INT TRADE & IND,COMP VIS SECT,ELECTROTECH LAB,UMEZONO 1-1-4,TSUKUBA,IBARAKI 305,JAPAN.							CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; HORN BKP, 1987, 1ST P ICCV LOND, P2; HUANG TS, 1981, IMAGE SEQUENCE ANAL; Kanatani K. I., 1986, Transactions of the Information Processing Society of Japan, V27, P373; Limb J. O., 1975, Computer Graphics and Image Processing, V4, P311, DOI 10.1016/0146-664X(75)90001-5; LIMB JO, 1975, IEEE T COMMUN, VCO23, P474, DOI 10.1109/TCOM.1975.1092828; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MARUYAMA M, 1984, T I ELECTRON COMMU A, V67, P1147; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; OSHIMA M, 1968, GAKUZYUTUTOSHO SYUPP; SCALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Tsukune H., 1985, Bulletin of the Electrotechnical Laboratory, V49, P299; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Yamamoto M., 1986, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ69D, P785; Yamamoto M., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P562; YAMAMOTO M, 1984, Patent No. 197526; YAMAMOTO M, 1988, 893 EL LAB IB REP; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105	23	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					528	536		10.1109/34.24785	http://dx.doi.org/10.1109/34.24785			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400008
J	DEMANTARAS, RL; VALVERDE, L				DEMANTARAS, RL; VALVERDE, L			NEW RESULTS IN FUZZY CLUSTERING BASED ON THE CONCEPT OF INDISTINGUISHABILITY RELATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV POLITECH BARCELONA,FAC INFORMAT,BARCELONA 34,SPAIN; UNIV POLITECN BARCELONA,DEPT MATEMAT & ESTADIST,BARCELONA,SPAIN	Universitat Politecnica de Catalunya			de Mantaras, Ramon Lopez/C-6023-2009; Valverde, Llorenç/AAB-1328-2021	Valverde, Llorenç/0000-0002-9163-568X				Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BEZDEK JC, 1978, FUZZY SETS SYSTEMS, V1, P112; MENGER K, 1951, P NATL ACAD SCI USA, V37, P178, DOI 10.1073/pnas.37.3.178; OVCHINNIKOV SV, 1982, 2ND P WORLD C MATH S, P566; RUSPINI E, 1982, FUZZY SET POSSIBILIT, P133; TRILLAS E, 1982, ACT PRIM C CAT LOG M, P51; VALVERDE L, 1983, STRUCTURE F INDISTIN; VALVERDE L, 1982, THESIS U POLITECNICA; ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1; [No title captured]	10	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					754	757		10.1109/34.6788	http://dx.doi.org/10.1109/34.6788			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500019
J	BROWSE, RA				BROWSE, RA			FEATURE-BASED TACTILE OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									QUEENS UNIV, DEPT PSYCHOL, KINGSTON K7L 3N6, ONTARIO, CANADA	Queens University - Canada	BROWSE, RA (corresponding author), QUEENS UNIV, DEPT ELECT, KINGSTON K7L 3N6, ONTARIO, CANADA.							Bajcsy R., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P809; BAJCSY R, 1984, COGNITION BRAIN THEO, V2; BRADY M, 1985, ARTIF INTELL, V26, P79, DOI 10.1016/0004-3702(85)90013-X; BROWSE RA, UNPUB FEATURE EXTRAC; BROWSE RA, 1984, 85165 QUEENS U DEP C; BROWSE RA, 1983, 5TH P C COGN SCI SOC; CORCORAN DWJ, 1977, PERCEPTION, V6, P249, DOI 10.1068/p060247; DARIO P, 1985, IEEE SPECTRUM, V22, P46, DOI 10.1109/MSPEC.1985.6370785; ELLIS R, 1984, SPIE INTELL ROBOTS C, V521, P289; FEARING RS, 1985, INT J ROBOT RES, V4, P40, DOI 10.1177/027836498500400304; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; GIBSON JJ, 1962, PSYCHOL REV, V69, P477, DOI 10.1037/h0046962; Harmon L.D., 1982, INT J ROBOT RES, V1, P3, DOI DOI 10.1177/027836498200100201; HILLIS D, 1982, INT J ROBOT RES, V1, P33; KLATZKY RL, 1985, PERCEPT PSYCHOPHYS, V37, P299, DOI 10.3758/BF03211351; LEDERMAN SJ, IN PRESS SENSORS SEN; LOOMIS JM, 1984, HDB HUMAN PERCEPTION; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; OLDFIELD SR, 1983, PERCEPTION, V12, P615, DOI 10.1068/p120615; RODGER JC, 1986, MAY P CAN ART INT C	20	10	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					779	786		10.1109/TPAMI.1987.4767984	http://dx.doi.org/10.1109/TPAMI.1987.4767984			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869439				2022-12-18	WOS:A1987K673500005
J	LOIZOU, G; MAYBANK, SJ				LOIZOU, G; MAYBANK, SJ			THE NEAREST NEIGHBOR AND THE BAYES ERROR RATES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MARCONI COMMAND & CONTROL SYST,SURREY GU16 5PE,ENGLAND		LOIZOU, G (corresponding author), UNIV LONDON BIRKBECK COLL,DEPT COMP SCI,MALET ST,LONDON WC1E 7HX,ENGLAND.							ABRAMOWITZ M, 1964, APPLIED MATH SERIES, V55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P343; DEVIJVER PA, 1985, PATTERN RECOGN LETT, V3, P1, DOI 10.1016/0167-8655(85)90035-2; DEVIJVER PA, 1982, NATO ADV STUDY I C, P3; DEVIJVER PA, 1978, NATO ADV STUDY I E, P61; Devijver PA, 1982, PATTERN RECOGNITION; DEVIJVER PA, 1977, NATO ADV STUDY I E, P1; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154, DOI 10.1109/TPAMI.1982.4767222; DEVROYE L, 1985, NONPARAMETRIC DENSIT; Duda R.O., 1973, J ROYAL STAT SOC SER; Feustel CD, 1982, PATTERN RECOGN LETT, V1, P125, DOI 10.1016/0167-8655(82)90025-3; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314, DOI 10.1109/TPAMI.1984.4767523; Fukunaga K, 1982, PATTERN RECOGN LETT, V1, P3, DOI 10.1016/0167-8655(82)90043-5; GOIN JE, 1984, IEEE T PATTERN ANAL, V6, P379, DOI 10.1109/TPAMI.1984.4767533; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; LOIZOU G, UNPUB INCOMPLETE BET; Marshall Albert W., 1979, INEQUALITIES THEORY, V143; Maybank SJ, 1983, PATTERN RECOGN LETT, V1, P291, DOI 10.1016/0167-8655(83)90065-X; Miclet L, 1983, PATTERN RECOGN LETT, V1, P277, DOI 10.1016/0167-8655(83)90063-6; Mitrinovic, 1970, ANAL INEQUALITIES, V1; Ni L. M., 1984, VLSI PATTERN RECOGNI, P65; PALIWAL KK, 1983, IEEE T PATTERN ANAL, V5, P229, DOI 10.1109/TPAMI.1983.4767378; PAPADIMITRIOU CH, 1980, LECT NOTES COMPUTER, V85, P470; Shamos MI, 1978, THESIS YALE U NEW HA; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Tatsumi S., 1983, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part A, VJ66A, P807; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121, DOI 10.1109/TSMC.1976.5409182; TOUSSAINT GT, 1982, NATO ADV STUDY I C, P569; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Williamson J. H., 1962, LEBESGUE INTEGRATION	34	10	12	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					254	262		10.1109/TPAMI.1987.4767899	http://dx.doi.org/10.1109/TPAMI.1987.4767899			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869395				2022-12-18	WOS:A1987G163300006
J	XU, G; TSUJI, S; ASADA, M				XU, G; TSUJI, S; ASADA, M			A MOTION STEREO METHOD BASED ON COARSE-TO-FINE CONTROL STRATEGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											XU, G (corresponding author), OSAKA UNIV, DEPT CONTROL ENGN, TOYONAKA, OSAKA 560, JAPAN.							BOLLES RC, 1985, 3RD P ISRR, P192; BRIDWELL NJ, 1983, COMPUT VISION GRAPH, V21, P33, DOI 10.1016/S0734-189X(83)80028-0; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P121, DOI 10.1109/TPAMI.1985.4767628; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; GRIMSON WEL, 1981, IMAGES SURFACES COMP; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MORAVEC HP, 1983, P IEEE, V71, P872, DOI 10.1109/PROC.1983.12684; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; NEVATIA R, 1976, COMPUT GRAPHICS IMAG, V6, P619; NISHIHARA HK, 1983, 3RD P INT C ROB VIS, P121; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; XU G, 1985, 9TH P INT JOINT C AR, P892; Yagi, 1973, COMPUT VISION GRAPH, V2, P131	17	10	11	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					332	336		10.1109/TPAMI.1987.4767908	http://dx.doi.org/10.1109/TPAMI.1987.4767908			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869404				2022-12-18	WOS:A1987G163300015
J	FU, KS; CHIEN, YT; CARDILLO, GP				FU, KS; CHIEN, YT; CARDILLO, GP			A DYNAMIC-PROGRAMMING APPROACH TO SEQUENTIAL PATTERN-RECOGNITION (REPRINTED FROM IEEE TRANSACTIONS ON ELECTRONIC-COMPUTERS, VOL EC-16, 1967	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									AT&T BELL LABS, HOLMDEL, NJ 07733 USA; PURDUE UNIV, SCH ELECT ENGN, W LAFAYETTE, IN 47907 USA; GEN RES CORP, SANTA BARBARA, CA USA	AT&T; Nokia Corporation; Nokia Bell Labs; Purdue University System; Purdue University; Purdue University West Lafayette Campus								BELLMAN R, 1961, P NATL ACAD SCI USA, V47, P338, DOI 10.1073/pnas.47.3.338; Bellman RE, 1957, DYNAMIC PROGRAMMING; CHIEN YT, 1966, IEEE T INFORM THEORY, V12, P206, DOI 10.1109/TIT.1966.1053863; Chow C. K., 1962, IRE T ELECTRON COM, VEC-11, P683; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; DYNKIN EB, 1963, SOV MATH, V4, P627; FISHBURN PC, 1965, RACTP143 RES AN CORP; FU KS, 1967, IEEE T ELECTRONIC CO, V16; FU KS, 1967, TREE679 PURD U SCH E; Howard Ronald A., 1960, DYNAMIC PROGRAMMING; Lindley DV, 1961, APPLIED STATISTICS, V10, P39; MARILL T, 1960, IRE T ELECTRON COM, VEC9, P472	12	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					313	326		10.1109/TPAMI.1986.4767794	http://dx.doi.org/10.1109/TPAMI.1986.4767794			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C0841	21869350				2022-12-18	WOS:A1986C084100003
J	CHAUDHURI, BB				CHAUDHURI, BB			APPLICATIONS OF QUADTREE, OCTREE, AND BINARY-TREE DECOMPOSITION TECHNIQUES TO SHAPE-ANALYSIS AND PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CHAUDHURI, BB (corresponding author), INDIAN STAT INST,ELECTR & COMMUN SCI UNIT,CALCUTTA 700035,W BENGAL,INDIA.							ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; DATTA AK, 1982, IEEE T PATTERN ANAL, V4, P683, DOI 10.1109/TPAMI.1982.4767326; DYER CR, 1980, COMPUT VISION GRAPH, V13, P270, DOI 10.1016/0146-664X(80)90050-7; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; EDELSBRUNNER H, 1983, IEEE T INFORM THEORY, V29, P551, DOI 10.1109/TIT.1983.1056714; Fairfield J., 1979, Proceedings of the International Conference on Cybernetics and Society, P60; Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; JARVIS RA, 1977, JUN P IEEE COMP SOC, P231; KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; KLINGER A, 1972, OPTIMIZING METHODS S; KNOWLTON K, 1980, P IEEE, V68, P885, DOI 10.1109/PROC.1980.11754; LING RF, 1973, J AM STAT ASSOC, V68, P159, DOI 10.2307/2284161; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; RANADE R, 1980, TR878 U MAR DEP COMP; RANADE S, 1981, IEEE T SYST MAN CYB, V11, P373; RANADE S, 1981, IEEE T SYST MAN CYB, V11, P370; ROSENFELD A, 1982, TR1197 U MAR DEP COM; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1; SAMET H, 1983, COMMUN ACM, V26, P680, DOI 10.1145/358172.358409; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; Shamos MI, 1978, THESIS YALE U NEW HA; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; Wald A., 1947, SEQUENTIAL ANAL	28	10	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					652	661		10.1109/TPAMI.1985.4767721	http://dx.doi.org/10.1109/TPAMI.1985.4767721			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869303				2022-12-18	WOS:A1985ATG0500003
J	GU, WK; HUANG, TS				GU, WK; HUANG, TS			CONNECTED LINE DRAWING EXTRACTION FROM A PERSPECTIVE VIEW OF A POLYHEDRON	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									ZHEJIANG UNIV,DEPT RADIO ENGN,HANGZHOU,PEOPLES R CHINA	Zhejiang University	GU, WK (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							AKKERMANS M, 1983, P SOC PHOTOOPT INSTR, V449, P534; ASADA M, 1984, PATTERN RECOGN, V17, P57, DOI 10.1016/0031-3203(84)90035-9; CHENG JK, 1980, TREE8053 PURD U REP; FANG JQ, 1982, AUG AM ASS ART INT N; GRIFFITH AK, 1973, IEEE T COMPUT, VC 22, P371, DOI 10.1109/T-C.1973.223724; GU WK, 1984, 7TH INT C PATT REC; GU WK, 1984, T137 U ILL COMP SCI; KITCHEN L, 1980, IEEE T SYST MAN CYB, V10, P96; MARTELLI A, 1972, COMPUTER GRAPHICS IM, V1, P169, DOI DOI 10.1016/S0146-664X(72)80013-3; MODESTINO JW, 1976, JUN JOINT WORKSH PAT; NAGAO M, 1973, COMPUT GRAPHICS IMAG, V2, P272; OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627; OLSZTYN JT, 1974, UST INT JOINT C PATT; PINGLE KK, 1971, 2ND INT JOINT C ART; PRAGER JM, 1980, IEEE T PATTERN ANAL, V2, P16, DOI 10.1109/TPAMI.1980.4766966; Ramer Urs, 1975, COMPUTER GRAPHICS IM, V4, P81; REDDY VSN, 1972, COMPUTER GRAPHICS IM, V1, P386; UNDERWOOD SA, 1975, IEEE T COMPUT, VC 24, P651, DOI 10.1109/T-C.1975.224277; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848	20	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					422	430		10.1109/TPAMI.1985.4767681	http://dx.doi.org/10.1109/TPAMI.1985.4767681			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869280				2022-12-18	WOS:A1985ALB6900006
J	LI, XB; DUBES, RC				LI, XB; DUBES, RC			THE 1ST STAGE IN 2-STAGE TEMPLATE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University								ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; Cheng H. D., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P578; GOODMAN LA, 1972, J AM STAT ASSOC, V67, P415, DOI 10.2307/2284396; GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532; MUNTEANU C, 1981, PATTERN RECOGN, V13, P167, DOI 10.1016/0031-3203(81)90014-5; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; ROSENFELD A, 1970, PICTURE PROCESSING C; STALLINGS W, 1976, PATTERN RECOGN, V8, P87, DOI 10.1016/0031-3203(76)90037-6; SVEDLOW M, 1976, S MACHINE PROCESSING; TANIMOTO SL, 1981, COMPUT VISION GRAPH, V16, P356, DOI 10.1016/0146-664X(81)90046-0; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; WONG RY, 1978, IEEE T COMPUT, V27, P359, DOI 10.1109/TC.1978.1675108	13	10	11	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					700	707		10.1109/TPAMI.1985.4767726	http://dx.doi.org/10.1109/TPAMI.1985.4767726			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869308				2022-12-18	WOS:A1985ATG0500008
J	TAKIYAMA, R				TAKIYAMA, R			THE SEPARATING CAPACITY OF A MULTITHRESHOLD THRESHOLD ELEMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											TAKIYAMA, R (corresponding author), KYUSHU INST DESIGN,DEPT VISUAL COMMUN DESIGN,MINAMI KU,FUKUOKA 815,JAPAN.							BITNER JR, 1977, IEEE T COMPUT, V26, P1147, DOI 10.1109/TC.1977.1674763; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; HARING DR, 1966, IEEE TRANS ELECTRON, VEC15, P45, DOI 10.1109/PGEC.1966.264375; LIU CL, 1970, INTRO COMBINATORIAL; Muroga S., 1971, THRESHOLD LOGIC ITS; NILSSON NJ, 1965, LEARNING MACHINES F; OHERA L, 1969, KYBERNETIKA, V5, P420; PEARL J, 1979, IEEE T PATTERN ANAL, V1, P350, DOI 10.1109/TPAMI.1979.4766943; TAKIYAMA R, 1978, PATTERN RECOGN, V10, P27, DOI 10.1016/0031-3203(78)90045-6; WEAVER CS, 1975, IEEE T COMPUT, VC 24, P290, DOI 10.1109/T-C.1975.224209	10	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					112	116		10.1109/TPAMI.1985.4767626	http://dx.doi.org/10.1109/TPAMI.1985.4767626			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869248				2022-12-18	WOS:A1985ABF0900013
J	BENBASSAT, M; ZAIDENBERG, L				BENBASSAT, M; ZAIDENBERG, L			CONTEXTUAL TEMPLATE MATCHING - A DISTANCE MEASURE FOR PATTERNS WITH HIERARCHICALLY DEPENDENT FEATURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST CRIT CARE MED,LOS ANGELES,CA 90003	University of Southern California	BENBASSAT, M (corresponding author), TEL AVIV UNIV,FAC MANAGEMENT,IL-69978 TEL AVIV,ISRAEL.							AFIFI AA, 1969, J AM STAT ASSOC, V64, P359, DOI 10.2307/2283745; AFIFI AA, 1969, J AM STATIST ASS, V64, P377; AFIFI AA, 1972, STATISTICAL ANAL COM; ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; AZEN SP, 1972, COMPUT BIOMED RES, V5, P613, DOI 10.1016/0010-4809(72)90041-9; Diday E., 1976, Digital pattern recognition, P47; DIDAY E, 1974, 2ND P INT JOINT C PA; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; Fu K. S., 1976, Digital pattern recognition, P95; Fu K.S., 1974, MATH SCI ENG; HAND DJ, 1976, 3RD P INT JOINT C PA; KENDRICK, 1965, TAXON, V14, P141; MCNEILL, 1972, TAXON, V21, P771; Pavlidis T., 1977, STRUCTURAL PATTERN R; TVERSKY A, 1977, PSYCHOL REV, V84; WILLIAMS, 1969, TAXON, V18, P369; WILLIAMS, 1975, STATISTICAL METHODS	17	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					201	211		10.1109/TPAMI.1984.4767503	http://dx.doi.org/10.1109/TPAMI.1984.4767503			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869183				2022-12-18	WOS:A1984SF59100006
J	HERMAN, M; KANADE, T; KUROE, S				HERMAN, M; KANADE, T; KUROE, S			INCREMENTAL ACQUISITION OF A 3-DIMENSIONAL SCENE MODEL FROM IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University	HERMAN, M (corresponding author), CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213, USA.							BAER A, 1979, COMPUT AIDED DESIGN, V11, P253, DOI 10.1016/0010-4485(79)90071-X; BAKER HH, 1981, P 7 INT JOINT C ART, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARROW HG, 1977, AUG P IJCAI 77, P696; Devich R. N., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P322; DOLYE J, 1979, ARTIFICIAL INTELL, V12, P231; Duda R.O., 1973, J ROYAL STAT SOC SER; EASTMAN CM, 1982, JAN ISR C CAD; HANNAH MJ, 1974, AIM239 STANF U TECH; HENDERSON RL, 1979, P SOC PHOTO-OPT INST, V186, P240; LIEBES S, 1981, APR P IM UND WORKSH, P168; LUCAS BD, 1981, 81 P IJCAI, P674; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; RUBIN SM, 1980, COMPUT VISION GRAPH, V13, P298, DOI 10.1016/0146-664X(80)90031-3; SHAFER SA, 1982, CMUCS82100 CARN MELL	16	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					331	340		10.1109/TPAMI.1984.4767526	http://dx.doi.org/10.1109/TPAMI.1984.4767526			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SR542	21869200	Green Submitted			2022-12-18	WOS:A1984SR54200009
J	COOPER, DB; SUNG, FP				COOPER, DB; SUNG, FP			MULTIPLE-WINDOW PARALLEL ADAPTIVE BOUNDARY FINDING IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											COOPER, DB (corresponding author), BROWN UNIV,DIV ENGN,PROVIDENCE,RI 02912, USA.							Anderson B. D. O., 1979, OPTIMAL FILTERING; BLAKE IF, 1973, IEEE T INFORM THEORY, V19, P295, DOI 10.1109/TIT.1973.1055016; COHEN F, 1980, 1980 P IEEE INT C AC, P410; COHEN F, 1980, THESIS BROWN U PROVI; COOPER DB, 1979, IEEE T PATTERN ANAL, V1, P372, DOI 10.1109/TPAMI.1979.4766946; COOPER DB, 1980, 5TH P IAPR INT C PAT, P1278; COOPER DB, 1978, MAY P IEEE COMP SOC, P25; COOPER DB, 1980, COMPUT GRAPHICS  APR, P326; ELLIOTT H, 1982, IEEE T PATTERN ANAL, V4, P167, DOI 10.1109/TPAMI.1982.4767224; ELLIOTT H, 1979, AUG P IEEE COMP SOC, P122; MIDDLETON D, 1968, IEEE T INFORM THEORY, V14, P434, DOI 10.1109/TIT.1968.1054139; MOOD AM, 1950, INTRO THEORY STATIST, P316; NAGIN PA, 1979, COINS7915 U MASS TEC; NAHI NE, 1978, IEEE T AUTOMAT CONTR, V23, P834, DOI 10.1109/TAC.1978.1101841; PAPOULIS A, 1965, PROBABILITY RANDOM V, P481; REISS L, 1979, NOV P IEEE COMP SOC, P849; ROSENFELD A, 1981, IMAGE MODELING, P63; SCHARF LL, 1981, IEEE T AUTOMAT CONTR, V26, P1018, DOI 10.1109/TAC.1981.1102775; SCHENKER PS, 1980, 5TH P INT C PATT REC, P1308; SUNG F, 1981, THESIS BROWN U PROVI, P29; SYMOSEK PF, 1980, THESIS BROWN U PROVI, P63; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848	22	10	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					299	316		10.1109/TPAMI.1983.4767392	http://dx.doi.org/10.1109/TPAMI.1983.4767392			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QS785	21869113				2022-12-18	WOS:A1983QS78500005
J	GRITTON, CWK; PARRISH, EA				GRITTON, CWK; PARRISH, EA			BOUNDARY LOCATION FROM AN INITIAL PLAN - THE BEAD CHAIN ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV VIRGINIA,SCH ENGN & APPL SCI,DEPT ELECT ENGN,CHARLOTTESVILLE,VA 22901	University of Virginia								KELLY MD, 1970, AI130 STANF ART INT; MARTELLI A, 1976, COMMUN ASS COMPUT MA, V19; PARRISH EA, 1978, 2ND P ANN S COMP APP; PARRISH EA, 1980, APR P IEEE SOUTHEAST; PARRISH EA, 1978, OCT CHIN EL SOC PEK; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Weibel E R, 1969, Int Rev Cytol, V26, P235, DOI 10.1016/S0074-7696(08)61637-X; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; WIDROW B, 1973, J PATTERN RECOGNITIO, V5, P199; [No title captured]	10	10	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					8	13		10.1109/TPAMI.1983.4767339	http://dx.doi.org/10.1109/TPAMI.1983.4767339			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869078				2022-12-18	WOS:A1983PZ84400002
J	MOHR, R; BAJCSY, R				MOHR, R; BAJCSY, R			PACKING VOLUMES BY SPHERES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV PENN,DEPT COMP & INFORMAT SCI,PHILADELPHIA,PA 19104	University of Pennsylvania	MOHR, R (corresponding author), UNIV NANCY 1,UNITE ENSEIGNEMENT & RECH SCI MATH,F-54013 NANCY,FRANCE.							BADLER NI, 1979, P IEEE, V67, P1397, DOI 10.1109/PROC.1979.11475; BAJCSY R, 1980, 5TH P ICPR MIAM; BINFORD TA, 1980, 5TH P INT C PATT REC, P364; BINFORD TO, 1971, DEC IEEE C SYST CONT; BLUM H, 1979, MAY WORKSH REPR 3D O; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; FALK G, 1970, THESIS STANFORD U ST; GUZMAN A, 1968, FAL AFIPS P JOINT CO, V33, P291; Hilbert D., 1952, GEOMETRY IMAGINATION; LIEBERMAN LI, 1975, RC548923910 IBM RES; MOHR R, UNPUB IEEE T PATTERN; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; OROURKE J, 1979, IEEE T PATTERN ANAL, V1, P295, DOI 10.1109/TPAMI.1979.4766925; REQUICHA AAG, 1980, COMPUT SURVEYS, V12; Roberts L, 1965, MACHINE PERCEPTION 3; ROSENFEL.A, 1966, J ACM, V13, P471; SOROKA BI, 1979, THESIS U PENNSYLVANI; VOELKER HB, 1977, IEEE COMPUTER    DEC; VOELKER HB, 1981, SAE TECH PAPERS SER	20	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					111	116		10.1109/TPAMI.1983.4767354	http://dx.doi.org/10.1109/TPAMI.1983.4767354			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869093				2022-12-18	WOS:A1983PZ84400017
J	BOZINOVIC, R; SRIHARI, SN				BOZINOVIC, R; SRIHARI, SN			A STRING CORRECTION ALGORITHM FOR CURSIVE SCRIPT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BOZINOVIC, R (corresponding author), SUNY BUFFALO, DEPT COMP SCI, BUFFALO, NY 14226 USA.		Srihari, Sargur N/E-8100-2011					BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; DEWEY G, 1923, RELATIVE FREQUENCY S; EHRICH RW, 1975, IEEE T COMPUT, VC 24, P182, DOI 10.1109/T-C.1975.224184; FARAG RFH, 1979, IEEE T COMPUT, V28, P172, DOI 10.1109/TC.1979.1675310; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; Jelinek F., 1969, IBM Journal of Research and Development, V13, P675, DOI 10.1147/rd.136.0675; KASHYAP RL, 1981, INFORM SCIENCES, V23, P123, DOI 10.1016/0020-0255(81)90052-9; KASHYAP RL, 1981, INFORM SCIENCES, V23, P201, DOI 10.1016/0020-0255(81)90056-6; Knuth D., 1973, ART COMPUTER PROGRAM, V3; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; PETERSON JL, 1980, LECTURE NOTES COMPUT, V96; SHINGHAL R, 1979, INT J MAN MACH STUD, V11, P201, DOI 10.1016/S0020-7373(79)80017-6; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184, DOI 10.1109/TPAMI.1979.4766904; SRIHARI SN, 1978, MAY P IEEE COMP SOC, P173; SRIHARI SN, 1982, IEEE T PATTERN ANAL, V4, P520; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; WINSTON PH, 1977, ARTIF INTELL, P99	19	10	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					655	663		10.1109/TPAMI.1982.4767321	http://dx.doi.org/10.1109/TPAMI.1982.4767321			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499642				2022-12-18	WOS:A1982PS23700013
J	FERRIE, FP; LEVINE, MD; ZUCKER, SW				FERRIE, FP; LEVINE, MD; ZUCKER, SW			CELL TRACKING - A MODELING AND MINIMIZATION APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FERRIE, FP (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,COMP VIS & GRAPH LAB,MONTREAL H3C 3G1,QUEBEC,CANADA.							ARIKI Y, 1978, 4TH P IJCPR, P681; ARIKI Y, 1978, SYSTEM ANAL TIME VAR; BRACHMAN RJ, 1979, ASS NETWORKS; FERRIE FP, 1979, THESIS MCGILL U MONT; GREAVES JO, 1975, P IEEE, V63; Hamming R.W., 1973, NUMERICAL METHODS SC; LEVESQUE H, 1979, ASS NETWORKS; LEVINE MD, 1978, AUTOMATIC PICTURE PR; MILGRAM DL, 1977, TR539 U MAR COMP SCI; Minsky M., 2019, FRAMEWORK REPRESENTI; RILEY PA, 1979, CLONAL DIFFERENCES G; RILEY PA, 1972, CELL DIFFER, P288; TSOTOS JK, 1979, 792 U TOR DEP COMP S; TSOTSOS JK, 1980, IEEE T PATTERN ANAL, V2, P563, DOI 10.1109/TPAMI.1980.6447704; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; YACHIDA M, 1974, 4TH P INT JOINT C PA, P1; YOUNG IT, 1974, INFORM CONTROL, V25, P357, DOI 10.1016/S0019-9958(74)91038-9; YOUSSEF YM, 1977, THESIS MCGILL U MONT	18	10	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					277	291		10.1109/TPAMI.1982.4767244	http://dx.doi.org/10.1109/TPAMI.1982.4767244			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869034				2022-12-18	WOS:A1982NN06900005
J	SADJADI, FA				SADJADI, FA			PERFORMANCE EVALUATIONS OF CORRELATIONS OF DIGITAL IMAGES USING DIFFERENT SEPARABILITY MEASURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SADJADI, FA (corresponding author), UNIV TENNESSEE,DEPT ELECT ENGN,KNOXVILLE,TN 37916, USA.		Sadjadi, Firooz/AAX-3886-2021					Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; FUKUNAGA K, 1972, INTRO STATISTICAL PA; FUKUNAGA K, 1978, TREE7848 PURD U; SADJADI F, 1979, 23RD P SPIE INT S SA; SADJADI F, 1980, OPT ENG          MAY	6	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					436	441		10.1109/TPAMI.1982.4767277	http://dx.doi.org/10.1109/TPAMI.1982.4767277			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869060				2022-12-18	WOS:A1982NT73500012
J	SHINGHAL, R; SUEN, CY				SHINGHAL, R; SUEN, CY			A METHOD FOR SELECTING CONSTRAINED HAND-PRINTED CHARACTER SHAPES FOR MACHINE RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SHINGHAL, R (corresponding author), CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA.							Kwan C. C., 1979, Proceedings of the International Conference on Cybernetics and Society, P530; NEISSER V, 1960, INFORM CONTR, V3, P191; SPOONER MG, 1959, P INT C INFORM PROCE, P481; Suen C. Y., 1974, Canadian Datasystems, V6, P40; SUEN CY, 1975, VISIBLE LANG, V9, P145; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; SUEN CY, 1974, P INT C SYST MAN CYB, P253; SUEN CY, 1973, P INT C CYBERN SOC, P174; 1978, 243341M1978 CAN STAN; 1974, X345 AM NAT STAND I	10	10	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					74	78		10.1109/TPAMI.1982.4767199	http://dx.doi.org/10.1109/TPAMI.1982.4767199			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MY534	21869007				2022-12-18	WOS:A1982MY53400013
J	SLOAN, KR				SLOAN, KR			ANALYSIS OF DOT PRODUCT SPACE SHAPE DESCRIPTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627	University of Rochester								BROWN KQ, 1979, THESIS CARNEGIEMELLO; FIRSCHEIN O, 1979, AUG IEEE PRIP C, P109; FREEMAN H, 1975, COMM ASS COMPUT MACH, V18; MARUYAMA K, 1972, UIUCDCSR72533 U ILL; SLOAN K, 1977, THESIS U PENNSYLVANI; SLOAN KR, 1980, 5TH P IJCPR MIAM BEA; SLOAN KR, 1980, TR74 U ROCH DEP COMP; SNYDER WE, 1980, IEEE T PATTERN ANAL, V2	8	10	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					87	90		10.1109/TPAMI.1982.4767202	http://dx.doi.org/10.1109/TPAMI.1982.4767202			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869010	Green Submitted			2022-12-18	WOS:A1982MY53400016
J	HALL, EL; DAVIES, DL; CASEY, ME				HALL, EL; DAVIES, DL; CASEY, ME			THE SELECTION OF CRITICAL SUBSETS FOR SIGNAL, IMAGE, AND SCENE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PRATT & WHITNEY AIRCRAFT CO,IMAGE PROC LAB,E HARTFORD,CT 06118; ORTEC INC,OAK RIDGE,TN 37830	Raytheon Technologies; Pratt & Whitney	HALL, EL (corresponding author), UNIV TENNESSEE,DEPT ELECT ENGN,KNOXVILLE,TN 37916, USA.			Hall, Ernest/0000-0003-4361-8647				Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; Hall E. L., 1979, COMPUTER IMAGE PROCE; NACK ML, 1977, 1977 MACH PROC REM S, P12; RAMAPRIYAN HK, 1976, IEEE T COMPUT, V25, P66, DOI 10.1109/TC.1976.5009206; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; STEINER D, 1977, PHOTOGRAMMETRIA, V33, P41, DOI 10.1016/0031-8663(77)90015-1; TANIMOTO S, 1976, COMPUT GRAPH IMAGE P, V5, P68; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8; WONG RY, 1978, IEEE T COMPUT, V27, P359, DOI 10.1109/TC.1978.1675108; WONG RY, 1976, 1976 P IEEE C DEC CO	11	10	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					313	322		10.1109/TPAMI.1980.4767030	http://dx.doi.org/10.1109/TPAMI.1980.4767030			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JZ206	21868907				2022-12-18	WOS:A1980JZ20600004
J	Bond-Taylor, S; Leach, A; Long, Y; Willcocks, CG				Bond-Taylor, Sam; Leach, Adam; Long, Yang; Willcocks, Chris G.			Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Data models; Training; Computational modeling; Analytical models; Generative adversarial networks; Predictive models; Neurons; Deep learning; generative models; energy-based models; variational autoencoders; generative adversarial networks; autoregressive models; normalizing flows	ADVERSARIAL; NETWORKS	Deep generative models are a class of techniques that train deep neural networks to model the distribution of training samples. Research has fragmented into various interconnected approaches, each of which make trade-offs including run-time, diversity, and architectural restrictions. In particular, this compendium covers energy-based models, variational autoencoders, generative adversarial networks, autoregressive models, normalizing flows, in addition to numerous hybrid approaches. These techniques are compared and contrasted, explaining the premises behind each and how they are interrelated, while reviewing current state-of-the-art advances and implementations.	[Bond-Taylor, Sam; Leach, Adam; Long, Yang; Willcocks, Chris G.] Univ Durham, Dept Comp Sci, Durham DH1 3LE, England	Durham University	Bond-Taylor, S (corresponding author), Univ Durham, Dept Comp Sci, Durham DH1 3LE, England.	samuel.e.bond-taylor@durham.ac.uk; adam.leach@durham.ac.uk; yang.long@durham.ac.uk; christopher.g.willcocks@durham.ac.uk	; Willcocks, Chris/F-9253-2015	Long, Yang/0000-0002-2445-6112; Willcocks, Chris/0000-0001-6821-3924; Bond-Taylor, Sam/0000-0003-1538-7909	MRC Innovation Fellowship [MR/S003916/1]	MRC Innovation Fellowship	This work was supported by MRC Innovation Fellowship with ref MR/S003916/1.	Aaron Courville, 2017, Arxiv, DOI arXiv:1710.02248; Aaron Courville, 2019, Arxiv, DOI arXiv:1901.08508; Alain G, 2016, INF INFERENCE, V5, P210, DOI 10.1093/imaiai/iaw003; Alec Radford, 2019, Arxiv, DOI arXiv:1904.10509; Alemi AA, 2018, PR MACH LEARN RES, V80; Nichol A, 2021, Arxiv, DOI arXiv:2102.09672; Alex X. Lee, 2018, Arxiv, DOI arXiv:1804.01523; Alireza Makhzani, 2016, Arxiv, DOI arXiv:1511.05644; Andrew M. Dai, 2016, Arxiv, DOI arXiv:1511.06349; Vahdat A, 2021, Arxiv, DOI arXiv:2106.05931; Arbel M., 2021, PROC INT C LEARN REP; Arjovsky M., 2017, 5 INT C LEARN REPR; Arjovsky M, 2017, PR MACH LEARN RES, V70; Babaeizadeh Mohammad, 2018, ICLR; Bauer M, 2019, PR MACH LEARN RES, V89, P66; Behrmann J, 2019, PR MACH LEARN RES, V97; Belinda Z. Li, 2020, Arxiv, DOI arXiv:2006.04768; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Bengio Y., 2013, ARXIV; Bengio Y., 2013, P 26 INT C NEUR INF, P899; Bojanowski P, 2018, PR MACH LEARN RES, V80; Bond-Taylor S., 2021, PROC INT C LEARN REP; Brock A., 2018, PROC INT C LEARN REP; Brown T., 2020, P INT C NEUR INF PRO, V33; Burda Yuri, 2016, 4 INT C LEARN REPR I; Caffarelli L. A., 1999, MONGE AMPERE EQUATIO; Carreira-Perpinan M.A., 2005, P 10 INT WORKSH ART; Che T., 2020, PROC C NEURAL INF PR; Chen Jianfei, 2020, PROC 37 INT C MACH L, P1660; Chen RTQ, 2019, ADV NEUR IN, V32; Chen RTQ., 2018, NEURAL ORDINARY DIFF; Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243; Chen X, 2017, PROC 5 INT C LEARN R; Chen X, 2018, PR MACH LEARN RES, V80; Child R, 2021, PROC INT C LEARN REP; Cho-Jui Hsieh, 2020, Arxiv, DOI arXiv:2008.03364; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Choromanski K., 2021, INT C LEARN REPR; Chung Junyoung, 2014, ARXIV PREPRINT ARXIV; Cornish R, 2020, PR MACH LEARN RES, V119; Cremer C, 2018, PR MACH LEARN RES, V80; Dacheng Tao, 2020, Arxiv, DOI arXiv:2001.06937; Dai B., 2018, PROC INT C LEARN REP; Watson D, 2021, Arxiv, DOI arXiv:2106.03802; De Cao N, 2020, PR MACH LEARN RES, V115, P1263; Denton Emily L, 2015, NEURIPS, V2, P4; Devlin J., 2019, P 2019 C N AM CHAPTE, P4171, DOI [10.18653/v1/n19-1423, DOI 10.18653/V1/N19-1423]; Dinh L., 2019, PROC INT C LEARN REP; Dinh L., 2017, PROC 5 INT C LEARN R; Dinh Laurent, 2014, ARXIV14108516; Dosovitskiy Alexey, 2016, NEURIPS; Du Y., 2019, PROC INT C NEURAL IN, P3608; Dupont E, 2019, ADV NEUR IN, V32; Durkan C., 2019, ARXIV190602145; Durkan C, 2020, PR MACH LEARN RES, V119; Durkan C, 2019, ADV NEUR IN, V32; Dustin Tran, 2019, Arxiv, DOI arXiv:1903.03704; Dupont E, 2022, Arxiv, DOI arXiv:2102.04776; Nijkamp E, 2020, Arxiv, DOI arXiv:2006.06897; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; Finlay C, 2020, PR MACH LEARN RES, V119; Gao R., 2021, PROC INT C LEARN REP; Germain M, 2015, PR MACH LEARN RES, V37, P881; Ghosh P., 2020, 8 INT C LEARN REPR I; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gouk H, 2021, MACH LEARN, V110, P393, DOI 10.1007/s10994-020-05929-w; Goyal K., 2021, ARXIV; Grathwohl W., 2021, PROC INT C MACH LEAR, P3831; Grathwohl W., 2019, P INT C LEARN REPR; Grathwohl W. S., 2021, PROC INT C LEARN REP; Grathwohl W, 2020, PR MACH LEARN RES, V119; Grathwohl Will, 2019, ICLR; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Grnarova P, 2019, ADV NEUR IN, V32; Grover A, 2018, AAAI CONF ARTIF INTE, P3069; Gulrajani I., 2016, P INT C LEARN REPR; Gulrajani I., 2019, PROC 7 INT C LEARN R; Gutmann M., 2010, AISTATS, V9, P297, DOI DOI 10.1145/3292500.3330651; Ha D., 2018, PREPRINT; Hafner D., 2019, INT C LEARN REPR; Han T, 2017, AAAI CONF ARTIF INTE, P1976; Han Zhang, 2020, Arxiv, DOI arXiv:1907.12998; Hasenclever L., 2017, PROC WORKSHOP BAYESI; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hensel M, 2017, ADV NEUR IN, V30; Higgins I., 2016, INT C LEARNING REPRE; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P448; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Sasaki H, 2021, Arxiv, DOI arXiv:2104.05358; Ho J, 2020, ADV NEUR IN, P6840; Ho Jonathan, 2019, ICML; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hoffman M. D, 2016, PROC C NEURAL INF PR; Hoogeboom E., 2021, ARXIV; Hoogeboom E., 2020, PROC C NEURAL INF PR, P18249; Hoogeboom E, 2019, ADV NEUR IN, V32; Hoogeboom E, 2019, PR MACH LEARN RES, V97; Huang C.-W., 2020, WORKSHOP INTEGR DEEP; Huang CW, 2018, PR MACH LEARN RES, V80; Huang HB, 2018, ADV NEUR IN, V31; Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202; Huszar F, 2015, ARXIV; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Ioffe S., 2015, P 32 INT C MACH LEAR; Gulrajani I, 2017, ADV NEUR IN, V30; Jae Hyun Lim, 2017, Arxiv, DOI arXiv:1705.02894; Jaini P, 2019, PR MACH LEARN RES, V97; Jang E., 2016, ARXIV; Jiaming Song, 2017, Arxiv, DOI arXiv:1702.08658; Jiang Yifan, 2021, ARXIV; Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393; Jolicoeur-Martineau A., 2021, ARXIV; Jolicoeur-Martineau Alexia, 2018, ARXIV180700734; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Jun H, 2020, PR MACH LEARN RES, V119; Kaiser L, 2018, PR MACH LEARN RES, V80; Karami M, 2019, ADV NEUR IN, V32; Karnewar Animesh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7796, DOI 10.1109/CVPR42600.2020.00782; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Karras Tero, 2021, ARXIV; Karras Tero, 2020, ARXIV200606676, V33; Karras Timo Aila Samuli Laine Tero, 2018, PROC INT C LEARN REP, Patent No. [1710.10196, 171010196]; Katharopoulos A, 2020, PR MACH LEARN RES, V119; Kim H., 2021, PROC INT C MACH LEAR, P5562; Kim Y, 2018, PR MACH LEARN RES, V80; Kingma D.P., 2013, P 2 INT C LEARN REPR; Kingma DP, 2018, ADV NEUR IN, V31; Kingma DP., 2016, ADV NEURAL INFORM PR, V29, P4743; Kobyzev I, 2021, IEEE T PATTERN ANAL, V43, P3964, DOI 10.1109/TPAMI.2020.2992934; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Kumar K, 2019, ADV NEUR IN, V32; Kumar M, 2019, PROC INT C MACH LEAR; Larochelle H., 2011, INT C ART INT STAT; Larsen ABL, 2016, PR MACH LEARN RES, V48; LeCun Y., 2006, PREDICTING STRUCTURE; Lei Wang, 2018, Arxiv, DOI arXiv:1809.10188; Duan LL, 2019, Arxiv, DOI arXiv:1907.10448; Li ZY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030269; Lin J, 2021, PROC CVPR IEEE, P14981, DOI 10.1109/CVPR46437.2021.01474; Liu B., 2021, PROC INT C LEARN REP; Liu KL, 2019, IEEE I CONF COMP VIS, P6391, DOI 10.1109/ICCV.2019.00648; Liu MY, 2017, ADV NEUR IN, V30; Liu XQ, 2019, PROC CVPR IEEE, P11226, DOI 10.1109/CVPR.2019.01149; Loaiza-Ganem G., 2019, PROC C NEURAL INF PR, P13266; Lu C., 2021, PROC INT C LEARN REP, P13266; Lucic M, 2018, ADV NEUR IN, V31; Ma X., 2019, PROC INT C LEARN REP; Ma XZ, 2019, ADV NEUR IN, V32; Maaloe L, 2019, ADV NEUR IN, V32; Maddison Chris J, 2017, ICLR; Madry Aleksander, 2017, ARXIV; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Mehdi Mirza, 2014, Arxiv, DOI arXiv:1411.1784; Mehri S., 2017, P INT C LEARN REPR; Meng C., 2020, PROC C NEURAL INF PR, P6673; Meng C., 2021, PROC INT C LEARN REP; Menick J., 2019, P INT C LEARN REPR; Minkai Xu, 2020, Arxiv, DOI arXiv:2004.01704; Miyato T., 2018, INT C LEARN REPR, P2; Muller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156; Nash C., 2019, PROC INT C MACH LEAR, P1735; Neklyudov K., 2019, PROC 33 INT C NEURAL, P13955; Tran NT, 2019, ADV NEUR IN, V32; Ngxande M, 2019, 2019 SOUTHERN AFRICAN UNIVERSITIES POWER ENGINEERING CONFERENCE/ROBOTICS AND MECHATRONICS/PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA (SAUPEC/ROBMECH/PRASA), P111, DOI 10.1109/RoboMech.2019.8704766; Nie Weili, 2019, INT C LEARN REPR; Nielsen D., 2020, PROC NEURIPS, P12685; Nijkamp Erik, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P361, DOI 10.1007/978-3-030-58539-6_22; Nijkamp E, 2019, ADV NEUR IN, V32; Nijkamp E, 2020, AAAI CONF ARTIF INTE, V34, P5272; Norouzi Sajad, 2020, PROC C NEURAL INF PR, V33, P8753; Nowozin S, 2016, ADV NEUR IN, V29; Odena A, 2017, PR MACH LEARN RES, V70; Onken D, 2021, AAAI CONF ARTIF INTE, V35, P9223; Ostrovski G, 2018, PR MACH LEARN RES, V80; Oussidi A, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018); Pang B., 2020, PROC C NEURAL INF PR; Pang T., 2020, PROC INT C NEURAL IN, V34; Papamakarios G, 2017, ADV NEUR IN, V30; Papamakarios G, 2021, J MACH LEARN RES, V22; Parmar Niki, 2018, PR MACH LEARN RES, P4055; Grnarova P, 2021, Arxiv, DOI arXiv:2103.12685; Pontryagin L.S., 1962, MATH THEORY OPTIMAL; Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI 10.1109/ICASSP.2019.8683143; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ramesh A, 2021, PR MACH LEARN RES, V139; Razavi A, 2019, ADV NEUR IN, V32; Reed S, 2017, PR MACH LEARN RES, V70; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Roberts G.O., 1996, BERNOULLI, V2, P341, DOI DOI 10.2307/3318418; Ruiqi Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7515, DOI 10.1109/CVPR42600.2020.00754; Salimans T, 2016, ADV NEUR IN, V29; Salimans T, 2015, PR MACH LEARN RES, V37, P1218; Salimans Tim, 2017, ARXIV170105517; Saremi S., 2018, ARXIV; Schmidhuber J, 1990, FKI12690 TU MUENCH; Schmidhuber J, 2020, NEURAL NETWORKS, V127, P58, DOI 10.1016/j.neunet.2020.04.008; Shi JX, 2018, PR MACH LEARN RES, V80; Sinha Samarth, 2020, 37 INT C MACH LEARN, V119, P9005; Sitzmann Vincent, 2020, ARXIV200609661, V33, P7462; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Sonderby C.K., 2017, ICLR, P1; Sonderby CK, 2016, ADV NEUR IN, V29; Song J., 2021, PROC INT C LEARN REP; Song JM, 2017, ADV NEUR IN, V30; Song Y., 2021, PROC INT C LEARN REP; Song Y, 2020, PR MACH LEARN RES, V115, P574; Song Y, 2019, ADV NEUR IN, V32; Song Y, 2019, ADV NEUR IN, V32; Sutherland Danica J, 2018, ICLR; Sutskever I., 2010, PROC 13 INT C ARTIF, P789; Swersky K., 2011, PROC 28 INT C MACH L, P1201; Tancik M., 2020, NEURIPS; Thanh-Tung Hoang, 2020, 2020 INT JOINT C NEU, P1; Theis L, 2015, ADV NEURAL INFORM PR, P1927; Theis Lucas, 2016, ICLR; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Titsias MK, 2019, ADV NEUR IN, V32; Tolstikhin I., 2018, INT C LEARN REPRESEN; Tomczak JM, 2018, PR MACH LEARN RES, V84; Tran D, 2019, ADV NEUR IN, V32; Tran Dustin, 2016, INT C LEARN REPR, V5; Tran NT, 2021, IEEE T IMAGE PROCESS, V30, P1882, DOI 10.1109/TIP.2021.3049346; Turner R. E., 2011, BAYESIAN TIME SERIES, P104; Turner R, 2019, PR MACH LEARN RES, V97; Tzen B., 2019, C LEARNING THEORY, P3084; Uria Benigno, 2013, P 26 INT C NEURAL IN; Valvano G, 2021, IEEE T MED IMAGING, V40, P1990, DOI 10.1109/TMI.2021.3069634; van den Berg R., 2021, PROC INT C LEARN REP; van den Berg R, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P393; van den Oord A, 2016, ADV NEUR IN, V29; van den Oord A, 2017, ADV NEUR IN, V30; van den Oord A, 2018, PR MACH LEARN RES, V80; van den Oord A, 2016, PR MACH LEARN RES, V48; van den Oord Aaron, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1609.03499; Vaswani A, 2017, ADV NEUR IN, V30; Villani C., 2003, TOPICS OPTIMAL TRANS, V58; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142; Wang Alex, 2019, ARXIV190204094; Wang Y., 2020, PROC INT C LEARN REP; Wehenkel A, 2019, ADV NEUR IN, V32; Welling M., 2011, P 28 INT C INT C MAC, P681, DOI DOI 10.4310/CIS.2012.V12.N3.A3; Wu H., 2020, ADV NEURAL INF PROCE; Xiao Z., 2021, PROC INT C LEARN REP; Xie JW, 2020, IEEE T PATTERN ANAL, V42, P27, DOI 10.1109/TPAMI.2018.2879081; Xie JW, 2016, PR MACH LEARN RES, V48; Yang L, 2022, IEEE T NEUR NET LEAR, V33, P528, DOI 10.1109/TNNLS.2020.3028042; Song Y, 2021, Arxiv, DOI arXiv:2101.03288; Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552; Yu L., 2020, PROC 37 INT C MACH L, P10957; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zhang H, 2019, PR MACH LEARN RES, V97; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhao J, 2017, PROC INT C LEARN REP; Zhao S., 2020, ADV NEURAL INFORM PR, V33, P7559; Zhao SJ, 2017, PR MACH LEARN RES, V70; Zhao SJ, 2019, AAAI CONF ARTIF INTE, P5885; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Ziegler ZM, 2019, PR MACH LEARN RES, V97	265	9	9	29	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7327	7347		10.1109/TPAMI.2021.3116668	http://dx.doi.org/10.1109/TPAMI.2021.3116668			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34591756	Green Submitted, hybrid, Green Accepted			2022-12-18	WOS:000864325900010
J	Fan, AX; Ma, JY; Jiang, XY; Ling, HB				Fan, Aoxiang; Ma, Jiayi; Jiang, Xingyu; Ling, Haibin			Efficient Deterministic Search With Robust Loss Functions for Geometric Model Fitting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geometric model fitting; robust loss function; deterministic search; outlier; image matching	EPIPOLAR GEOMETRY; CONSENSUS	Geometric model fitting is a fundamental task in computer vision, which serves as the pre-requisite of many downstream applications. While the problem has a simple intrinsic structure where the solution can be parameterized within a few degrees of freedom, the ubiquitously existing outliers are the main challenge. In previous studies, random sampling techniques have been established as the practical choice, since optimization-based methods are usually too time-demanding. This prospective study is intended to design efficient algorithms that benefit from a general optimization-based view. In particular, two important types of loss functions are discussed, i.e., truncated and l(1) losses, and efficient solvers have been derived for both upon specific approximations. Based on this philosophy, a class of algorithms are introduced to perform deterministic search for the inliers or geometric model. Recommendations are made based on theoretical and experimental analyses. Compared with the existing solutions, the proposed methods are both simple in computation and robust to outliers. Extensive experiments are conducted on publicly available datasets for geometric estimation, which demonstrate the superiority of our methods compared with the state-of-the-art ones. Additionally, we apply our method to the recent benchmark for wide-baseline stereo evaluation, leading to a significant improvement of performance. Our code is publicly available at https://github.com/AoxiangFan/EifficientDeterministicSearch.	[Fan, Aoxiang; Ma, Jiayi; Jiang, Xingyu] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China; [Ling, Haibin] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Wuhan University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Ma, JY (corresponding author), Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.	fanaoxiang@whu.edu.cn; jyma2010@gmail.com; jiangx.y@whu.edu.cn; haibin.ling@stonybrook.edu			National Natural Science Foundation of China [61773295]; Natural Science Foundation of Hubei Province [2019CFA037]; Key Research and Development Program of Hubei Province [2020BAB113]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Hubei Province(Natural Science Foundation of Hubei Province); Key Research and Development Program of Hubei Province	This work was supported by the National Natural Science Foundation of China under Grant 61773295, the Natural Science Foundation of Hubei Province under Grant 2019CFA037, and the Key Research and Development Program of Hubei Province under Grant 2020BAB113.	Aftab K, 2015, IEEE WINT CONF APPL, P480, DOI 10.1109/WACV.2015.70; Aoxiang Fan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P462, DOI 10.1007/978-3-030-58542-6_28; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410; Barath D, 2020, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR42600.2020.00138; Barath D, 2019, PROC CVPR IEEE, P10189, DOI 10.1109/CVPR.2019.01044; Barath D, 2018, PROC CVPR IEEE, P6733, DOI 10.1109/CVPR.2018.00704; Bazin JC, 2013, IEEE T PATTERN ANAL, V35, P1565, DOI 10.1109/TPAMI.2012.264; Bian J.-W., 2019, PROC BRIT MACH VIS C; Bian JW, 2020, INT J COMPUT VISION, V128, P1580, DOI 10.1007/s11263-019-01280-3; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Cai ZP, 2018, LECT NOTES COMPUT SC, V11216, P699, DOI 10.1007/978-3-030-01258-8_42; Cai ZP, 2019, IEEE I CONF COMP VIS, P1637, DOI 10.1109/ICCV.2019.00172; Campbell D, 2017, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2017.10; Chin TJ, 2015, PROC CVPR IEEE, P2413, DOI 10.1109/CVPR.2015.7298855; Choy C., 2020, P IEEE CVF C COMP VI, P11227; Chum O, 2005, PROC CVPR IEEE, P772; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Ding T., 2020, PROC IEEECVF C COMPU, P6080; Ding Tianyu, 2019, P 36 INT C MACH LEAR, P1617; Enqvist O, 2012, LECT NOTES COMPUT SC, V7572, P738, DOI 10.1007/978-3-642-33718-5_53; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fragoso V, 2013, IEEE I CONF COMP VIS, P2472, DOI 10.1109/ICCV.2013.307; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Jin YH, 2021, INT J COMPUT VISION, V129, P517, DOI 10.1007/s11263-020-01385-0; Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599; Le H, 2021, IEEE T PATTERN ANAL, V43, P842, DOI 10.1109/TPAMI.2019.2939307; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Lerman G, 2018, INF INFERENCE, V7, P277, DOI 10.1093/imaiai/iax012; Lerman G, 2018, P IEEE, V106, P1380, DOI 10.1109/JPROC.2018.2853141; Lerman G, 2015, FOUND COMPUT MATH, V15, P363, DOI 10.1007/s10208-014-9221-0; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Lin WY, 2018, IEEE T PATTERN ANAL, V40, P34, DOI 10.1109/TPAMI.2017.2652468; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma JY, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01359-2; Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI 10.1007/s11263-018-1117-z; Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478; Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009; Maunu T, 2019, J MACH LEARN RES, V20; Mishchuk A., 2017, P INT C NEUR INF PRO, P4829; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458; Ni K, 2009, IEEE I CONF COMP VIS, P2193, DOI 10.1109/ICCV.2009.5459241; Olsson C, 2008, PROC CVPR IEEE, P3230; Purkait P, 2018, INT WORKSH EN MIN ME, P312; Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sun W., 2020, P IEEECVF C COMPUTER, P11286; Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Tsakiris MC, 2018, J MACH LEARN RES, V19; Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156; Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282; Yinqiang Zheng, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1825, DOI 10.1109/CVPR.2011.5995640; Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; Zhu ZH, 2018, ADV NEUR IN, V31	65	9	9	8	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8212	8229		10.1109/TPAMI.2021.3109784	http://dx.doi.org/10.1109/TPAMI.2021.3109784			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34473624				2022-12-18	WOS:000864325900067
J	Wu, GC; Liu, YB; Fang, L; Chai, TY				Wu, Gaochang; Liu, Yebin; Fang, Lu; Chai, Tianyou			Revisiting Light Field Rendering With Deep Anti-Aliasing Neural Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Rendering (computer graphics); Deep learning; Estimation; Shearing; Pipelines; Neural networks; Light field reconstruction; light field rendering; deep learning; view extrapolation		The light field (LF) reconstruction is mainly confronted with two challenges, large disparity and the non-Lambertian effect. Typical approaches either address the large disparity challenge using depth estimation followed by view synthesis or eschew explicit depth information to enable non-Lambertian rendering, but rarely solve both challenges in a unified framework. In this paper, we revisit the classic LF rendering framework to address both challenges by incorporating it with advanced deep learning techniques. First, we analytically show that the essential issue behind the large disparity and non-Lambertian challenges is the aliasing problem. Classic LF rendering approaches typically mitigate the aliasing with a reconstruction filter in the Fourier domain, which is, however, intractable to implement within a deep learning pipeline. Instead, we introduce an alternative framework to perform anti-aliasing reconstruction in the image domain and analytically show comparable efficacy on the aliasing issue. To explore the full potential, we then embed the anti-aliasing framework into a deep neural network through the design of an integrated architecture and trainable parameters. The network is trained through end-to-end optimization using a peculiar training set, including regular LFs and unstructured LFs. The proposed deep learning pipeline shows a substantial superiority in solving both the large disparity and the non-Lambertian challenges compared with other state-of-the-art approaches. In addition to the view interpolation for an LF, we also show that the proposed pipeline also benefits light field view extrapolation.	[Wu, Gaochang; Chai, Tianyou] Northeastern Univ, State Key Lab Synthet Automat Proc Ind, Shenyang 110819, Peoples R China; [Wu, Gaochang; Chai, Tianyou] Northeastern Univ, Inst Ind Artificial Intelligence, Shenyang 110819, Peoples R China; [Liu, Yebin] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Fang, Lu] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Fang, Lu] Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China	Northeastern University - China; Northeastern University - China; Tsinghua University; Tsinghua University	Chai, TY (corresponding author), Northeastern Univ, State Key Lab Synthet Automat Proc Ind, Shenyang 110819, Peoples R China.	wugc@mail.neu.edu.cn; liuyebin@mail.tsinghua.edu.cn; fanglu@tsinghua.edu.cn; tychai@mail.neu.edu.cn			Major Program of National Natural Science Foundation of China NSFC [61991400, 61991401, 61991404]; Science and Technology Major Projects of Liaoning Province [2020JH1/10100008]; NSFC [61827805, 61531014, 61861166002, 6181001011]; Fundamental Research Funds for the Central Universities [100802004]	Major Program of National Natural Science Foundation of China NSFC(National Natural Science Foundation of China (NSFC)); Science and Technology Major Projects of Liaoning Province; NSFC(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the Major Program of National Natural Science Foundation of China NSFC under Grants 61991400, 61991401, and 61991404, in part by the Science and Technology Major Projects of Liaoning Province under Grant 2020JH1/10100008, in part by the NSFC under Grants 61827805, 61531014, 61861166002, and 6181001011, and in part by the Fundamental Research Funds for the Central Universities under Grant 100802004.	Adhikarla VK, 2017, PROC CVPR IEEE, P3720, DOI 10.1109/CVPR.2017.396; Alperovich A, 2018, PROC CVPR IEEE, P9145, DOI 10.1109/CVPR.2018.00953; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2018, ICME 2018 GRAND CHAL; [Anonymous], STANFORD NEW LIGHT F; [Anonymous], STANFORD LYTRO LIGHT; Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168; Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932; Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238; Christian Szegedy, 2015, Arxiv, DOI arXiv:1502.03167; Dosovitskiy Alexey, 2016, NEURIPS; Farrugia RA, 2020, IEEE T PATTERN ANAL, V42, P1162, DOI 10.1109/TPAMI.2019.2893666; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Goodfellow I., 2015, TENSORFLOW LARGE SCA; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659; Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251; Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]; Kingma D.P., 2015, INT C LEARN REPR, P1; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lin X, 2015, BIOMED OPT EXPRESS, V6, P3179, DOI 10.1364/BOE.6.003179; Luo Wenjie, 2016, ADV NEUR IN, V29; Lytro, LYTRO; Ng R., 2005, COMPUT SCI TECH REP, V2, P1; Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031; Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855; Schilling H, 2018, PROC CVPR IEEE, P4530, DOI 10.1109/CVPR.2018.00476; Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541; Stewart J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P150; Sulc A., 2017, PROC INT WORKSHOP EN, P372; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Vagharshakyan S, 2018, IEEE T PATTERN ANAL, V40, P133, DOI 10.1109/TPAMI.2017.2653101; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wang YW, 2017, IEEE T VIS COMPUT GR, V23, P2357, DOI 10.1109/TVCG.2016.2628743; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Wu GC, 2019, IEEE T IMAGE PROCESS, V28, P3261, DOI 10.1109/TIP.2019.2895463; Wu GC, 2019, IEEE T PATTERN ANAL, V41, P1681, DOI 10.1109/TPAMI.2018.2845393; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126; Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9; Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17; Yucer K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2876504; Zhang ZT, 2015, PROC CVPR IEEE, P3800, DOI 10.1109/CVPR.2015.7299004; Zheng HT, 2018, LECT NOTES COMPUT SC, V11210, P87, DOI 10.1007/978-3-030-01231-1_6; Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323	53	9	9	7	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5430	5444		10.1109/TPAMI.2021.3073739	http://dx.doi.org/10.1109/TPAMI.2021.3073739			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33861692	Green Submitted			2022-12-18	WOS:000836666600066
J	Fu, Y; Zhang, T; Wang, LZ; Huang, H				Fu, Ying; Zhang, Tao; Wang, Lizhi; Huang, Hua			Coded Hyperspectral Image Reconstruction Using Deep External and Internal Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Hyperspectral imaging; Spatial resolution; Lenses; Cameras; Apertures; Testing; Compressive sensing; coded hyperspectral imaging; deep external learning; deep internal learning	SPECTROMETER; DESIGN; SYSTEM	To solve the low spatial and/or temporal resolution problem which the conventional hyperspectral cameras often suffer from, coded hyperspectral imaging systems have attracted more attention recently. Recovering a hyperspectral image (HSI) from its corresponding coded image is an ill-posed inverse problem, and learning accurate prior of HSI is essential to solve this inverse problem. In this paper, we present an effective convolutional neural network (CNN) based method for coded HSI reconstruction, which learns the deep prior from the external dataset as well as the internal information of input coded image with spatial-spectral constraint. Specifically, we first develop a CNN-based channel attention reconstruction network to effectively exploit the spatial-spectral correlation of the HSI. Then, the reconstruction network is learned by leveraging an arbitrary external hyperspectral dataset to exploit the general spatial-spectral correlation under adversarial loss. Finally, we customize the network by internal learning with spatial-spectral constraint and total variation regularization for each coded image, which can make use of the internal imaging model to learn specific prior for current desirable image and effectively avoids overfitting. Experimental results using both synthetic data and real images show that our method outperforms the state-of-the-art methods on several popular coded hyperspectral imaging systems under both comprehensive quantitative metrics and perceptive quality.	[Fu, Ying; Zhang, Tao; Wang, Lizhi; Huang, Hua] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China	Beijing Institute of Technology	Huang, H (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.	fuying@bit.edu.cn; tzhang@bit.edu.cn; lzwang@bit.edu.cn; huahuang@bit.edu.cn	张, 涛/GSD-3950-2022	张, 涛/0000-0002-7358-0603	National Natural Science Foundation of China [61827901, 62088101]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China under Grants 61827901 and 62088101.	Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986; [Anonymous], 2000, P 3 C FUS EARTH DAT, P99; Arad B, 2016, LECT NOTES COMPUT SC, V9911, P19, DOI 10.1007/978-3-319-46478-7_2; BASEDOW RW, 1995, P SOC PHOTO-OPT INS, V2480, P258, DOI 10.1117/12.210881; Bell-Kligler S, 2019, ADV NEUR IN, V32; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Bjorgan A, 2015, PROC SPIE, V9537, DOI 10.1117/12.2184155; Bora A, 2017, PR MACH LEARN RES, V70; Cao XY, 2018, IEEE T IMAGE PROCESS, V27, P2354, DOI 10.1109/TIP.2018.2799324; Cao X, 2011, IEEE T PATTERN ANAL, V33, P2423, DOI 10.1109/TPAMI.2011.80; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; Choi I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130810; DESCOUR M, 1995, APPL OPTICS, V34, P4817, DOI 10.1364/AO.34.004817; Dian RW, 2018, IEEE T NEUR NET LEAR, V29, P5345, DOI 10.1109/TNNLS.2018.2798162; Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360; Ford BK, 2001, OPT EXPRESS, V9, P444, DOI 10.1364/OE.9.000444; Fu Y, 2019, PROC CVPR IEEE, P11653, DOI 10.1109/CVPR.2019.01193; Fu Y, 2018, LECT NOTES COMPUT SC, V11207, P812, DOI 10.1007/978-3-030-01219-9_48; Fu Y, 2016, PROC CVPR IEEE, P3727, DOI 10.1109/CVPR.2016.405; Gao LA, 2010, OPT EXPRESS, V18, P14330, DOI 10.1364/OE.18.014330; Gat N, 2006, P SOC PHOTO-OPT INS, V6302, pM3020, DOI 10.1117/12.678082; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Glorot X., 2010, PROC MACH LEARN RES, P249; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457; Kingma D.P., 2015, INT C LEARN REPR ICL; Kittle D, 2010, APPL OPTICS, V49, P6824, DOI 10.1364/AO.49.006824; KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N; Kulkarni K, 2016, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2016.55; Li ST, 2018, IEEE T IMAGE PROCESS, V27, P4118, DOI 10.1109/TIP.2018.2836307; Liao XJ, 2014, SIAM J IMAGING SCI, V7, P797, DOI 10.1137/130936658; Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262; Lin X, 2014, OPT LETT, V39, P2044, DOI 10.1364/OL.39.002044; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P2990, DOI 10.1109/TPAMI.2018.2873587; Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901; Miao X, 2019, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2019.00416; Ojha L, 2015, NAT GEOSCI, V8, P829, DOI [10.1038/ngeo2546, 10.1038/NGEO2546]; OKAMOTO T, 1991, OPT LETT, V16, P1277, DOI 10.1364/OL.16.001277; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tan J, 2016, IEEE J-STSP, V10, P389, DOI 10.1109/JSTSP.2015.2500190; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wang LZ, 2020, PROC CVPR IEEE, P1658, DOI 10.1109/CVPR42600.2020.00173; Wang LZ, 2019, PROC CVPR IEEE, P8024, DOI 10.1109/CVPR.2019.00822; Wang LZ, 2019, IEEE T IMAGE PROCESS, V28, P2257, DOI 10.1109/TIP.2018.2884076; Wang LZ, 2017, IEEE T PATTERN ANAL, V39, P2104, DOI 10.1109/TPAMI.2016.2621050; Wang LZ, 2015, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2015.7299128; Wang LZ, 2015, APPL OPTICS, V54, P848, DOI 10.1364/AO.54.000848; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Watkins, 2007, REMOTE SENSING APPL, DOI [10.1201/9781420012606, DOI 10.1201/9781420012606]; Xie Q, 2019, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2019.00168; Xiong ZW, 2017, IEEE INT CONF COMP V, P518, DOI 10.1109/ICCVW.2017.68; Yamaguchi M, 2006, PROC SPIE, V6062, DOI 10.1117/12.649454; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Yuan X, 2016, IEEE IMAGE PROC, P2539, DOI 10.1109/ICIP.2016.7532817; Zhang SP, 2019, IEEE I CONF COMP VIS, P10182, DOI 10.1109/ICCV.2019.01028; Zhang T, 2019, IEEE I CONF COMP VIS, P8558, DOI 10.1109/ICCV.2019.00865; Zhang Yulun, 2018, P EUROPEAN C COMPUTE, P286; Ziyi Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P187, DOI 10.1007/978-3-030-58592-1_12	63	9	9	16	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3404	3420		10.1109/TPAMI.2021.3059911	http://dx.doi.org/10.1109/TPAMI.2021.3059911			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33596170				2022-12-18	WOS:000805820500007
J	Fu, CY; Wu, X; Hu, YB; Huang, HB; He, R				Fu, Chaoyou; Wu, Xiang; Hu, Yibo; Huang, Huaibo; He, Ran			DVG-Face: Dual Variational Generation for Heterogeneous Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; Learning systems; Databases; Generators; Gallium nitride; Image recognition; Training; Heterogeneous face recognition; cross-domain; dual generation; contrastive learning	SPECTRAL REGRESSION	Heterogeneous face recognition (HFR) refers to matching cross-domain faces and plays a crucial role in public security. Nevertheless, HFR is confronted with challenges from large domain discrepancy and insufficient heterogeneous data. In this paper, we formulate HFR as a dual generation problem, and tackle it via a novel dual variational generation (DVG-Face) framework. Specifically, a dual variational generator is elaborately designed to learn the joint distribution of paired heterogeneous images. However, the small-scale paired heterogeneous training data may limit the identity diversity of sampling. In order to break through the limitation, we propose to integrate abundant identity information of large-scale visible data into the joint distribution. Furthermore, a pairwise identity preserving loss is imposed on the generated paired heterogeneous images to ensure their identity consistency. As a consequence, massive new diverse paired heterogeneous images with the same identity can be generated from noises. The identity consistency and identity diversity properties allow us to employ these generated images to train the HFR network via a contrastive learning mechanism, yielding both domain-invariant and discriminative embedding features. Concretely, the generated paired heterogeneous images are regarded as positive pairs, and the images obtained from different samplings are considered as negative pairs. Our method achieves superior performances over state-of-the-art methods on seven challenging databases belonging to five HFR tasks, including NIR-VIS, Sketch-Photo, Profile-Frontal Photo, Thermal-VIS, and ID-Camera.	[Fu, Chaoyou; Wu, Xiang; Hu, Yibo; Huang, Huaibo; He, Ran] CASIA, Natl Lab Pattern Recognit, Ctr Res Intelligent Percept & Comp, Beijing 100190, Peoples R China; [Fu, Chaoyou; Wu, Xiang; Hu, Yibo; Huang, Huaibo; He, Ran] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing 100864, Peoples R China; [Fu, Chaoyou; Wu, Xiang; Hu, Yibo; Huang, Huaibo; He, Ran] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	He, R (corresponding author), CASIA, Natl Lab Pattern Recognit, Ctr Res Intelligent Percept & Comp, Beijing 100190, Peoples R China.; He, R (corresponding author), Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing 100864, Peoples R China.; He, R (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100190, Peoples R China.	chaoyou.fu@nlpr.ia.ac.cn; alfredxiangwu@gmail.com; huyibo871079699@gmail.com; huaibo.huang@cripac.ia.ac.cn; rhe@nlpr.ia.ac.cn		Huang, Huaibo/0000-0001-5866-2283; Wu, Xiang/0000-0001-5317-1338	Beijing Natural Science Foundation [JQ18017]; National Natural Science Foundation of China [61721004, U20A20223]; Youth Innovation PromotionAssociation CAS [Y201929]	Beijing Natural Science Foundation(Beijing Natural Science Foundation); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation PromotionAssociation CAS	The authors would like to thank the associate editor and the reviewers for their valuable comments and advice. This work was supported by Beijing Natural Science Foundation (Grant JQ18017), National Natural Science Foundation of China (Grants 61721004 and U20A20223), and Youth Innovation PromotionAssociation CAS (Grant Y201929).	Bachman P, 2019, ADV NEUR IN, V32; Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702; Bhatt H.S., 2010, 2010 4 IEEE INT C BI, P1, DOI [10.1109/btas.2010.5634507, DOI 10.1109/BTAS.2010.5634507]; Bhatt H.S., 2012, MEMETIC APPROACH MAT; Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877; Cao B, 2019, IEEE T NEUR NET LEAR, V30, P1731, DOI 10.1109/TNNLS.2018.2872675; Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155; Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520; Deng ZY, 2019, AAAI CONF ARTIF INTE, P8239; Deng ZY, 2019, IEEE T IMAGE PROCESS, V28, P3102, DOI 10.1109/TIP.2019.2894272; Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314; Dong Yi, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163093; Duan B., 2020, P IEEE CVF C COMP VI, P7930, DOI DOI 10.1109/CVPR42600.2020.00795; Fu CY, 2019, ADV NEUR IN, V32; Gong DH, 2017, IEEE T IMAGE PROCESS, V26, P2079, DOI 10.1109/TIP.2017.2651380; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770; Hensel M, 2017, ADV NEUR IN, V30; Hu GS, 2018, IEEE T IMAGE PROCESS, V27, P293, DOI 10.1109/TIP.2017.2756450; Hu YB, 2018, PROC CVPR IEEE, P8398, DOI 10.1109/CVPR.2018.00876; Huang D., 2012, IRIPTR12FR001 U BEIJ; Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310; Huang HB, 2018, ADV NEUR IN, V31; Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267; Huang XS, 2013, IEEE T IMAGE PROCESS, V22, P353, DOI 10.1109/TIP.2012.2215617; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Huo J, 2018, IEEE T CYBERNETICS, V48, P1814, DOI 10.1109/TCYB.2017.2715660; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35; Jin Y, 2015, IEEE T INF FOREN SEC, V10, P640, DOI 10.1109/TIFS.2015.2390414; Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kingma DP, 2018, ADV NEUR IN, V31; Kingma DP, 2 INT C LEARN REPR I, P1; Klare B, 2010, PROC SPIE, V7667, DOI 10.1117/12.849821; Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229; Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720; Li MY, 2020, PROC CVPR IEEE, P5283, DOI 10.1109/CVPR42600.2020.00533; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Liu M. -Y., 2016, ADV NEURAL INFORM PR, P469; Liu XX, 2016, INT CONF BIOMETR; Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001; Panetta Karen, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P509, DOI 10.1109/TPAMI.2018.2884458; Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244; Peng CL, 2019, PATTERN RECOGN, V90, P161, DOI 10.1016/j.patcog.2019.01.041; Peng CL, 2017, IEEE T CIRC SYST VID, V27, P288, DOI 10.1109/TCSVT.2015.2502861; Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681; Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47; Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40; Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467; Shao M, 2017, IEEE T NEUR NET LEAR, V28, P451, DOI 10.1109/TNNLS.2016.2517014; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319; Shu ZX, 2018, LECT NOTES COMPUT SC, V11214, P664, DOI 10.1007/978-3-030-01249-6_40; Song LX, 2018, AAAI CONF ARTIF INTE, P7355; Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414; van den Oord A, 2016, ADV NEUR IN, V29; van den Oord A, 2017, ADV NEUR IN, V30; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wu X, 2019, AAAI CONF ARTIF INTE, P9005; Wu X, 2018, AAAI CONF ARTIF INTE, P1679; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Yujun Shen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9240, DOI 10.1109/CVPR42600.2020.00926; Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821; Zhang H, 2019, INT J COMPUT VISION, V127, P845, DOI 10.1007/s11263-019-01175-3; Zhang MJ, 2020, IEEE T IMAGE PROCESS, V29, P1507, DOI 10.1109/TIP.2019.2942514; Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	78	9	10	13	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					2938	2952		10.1109/TPAMI.2021.3052549	http://dx.doi.org/10.1109/TPAMI.2021.3052549			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33460368	Green Submitted			2022-12-18	WOS:000803117500013
J	Gong, C; Yang, J; You, JN; Sugiyama, M				Gong, Chen; Yang, Jian; You, Jane; Sugiyama, Masashi			Centroid Estimation With Guaranteed Efficiency: A General Framework for Weakly Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Supervised learning; Fasteners; Training data; Support vector machines; Semisupervised learning; Safety; Weakly supervised learning; centroid estimation; unbiasedness; statistical efficiency	INSTANCE; REGULARIZATION	In this paper, we propose a general framework termed centroid estimation with guaranteed efficiency (CEGE) for weakly supervised learning (WSL) with incomplete, inexact, and inaccurate supervision. The core of our framework is to devise an unbiased and statistically efficient risk estimator that is applicable to various weak supervision. Specifically, by decomposing the loss function (e.g., the squared loss and hinge loss) into a label-independent term and a label-dependent term, we discover that only the latter is influenced by the weak supervision and is related to the centroid of the entire dataset. Therefore, by constructing two auxiliary pseudo-labeled datasets with synthesized labels, we derive unbiased estimates of centroid based on the two auxiliary datasets, respectively. These two estimates are further linearly combined with a properly decided coefficient which makes the final combined estimate not only unbiased but also statistically efficient. This is better than some existing methods that only care about the unbiasedness of estimation but ignore the statistical efficiency. The good statistical efficiency of the derived estimator is guaranteed as we theoretically prove that it acquires the minimum variance when estimating the centroid. As a result, intensive experimental results on a large number of benchmark datasets demonstrate that our CEGE generally obtains better performance than the existing approaches related to typical WSL problems including semi-supervised learning, positive-unlabeled learning, multiple instance learning, and label noise learning.	[Gong, Chen] Nanjing Univ Sci & Technol, Intelligent Percept, Key Lab Intelligent Percept & Syst High Dimens In, PCA Lab,Sch Comp Sci & Engn, Nanjing 210044, Jiangsu, Peoples R China; [Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, PCA Lab, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210044, Jiangsu, Peoples R China; [You, Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China; [Sugiyama, Masashi] RIKEN Ctr Adv Intelligence Project, Tokyo 1030027, Japan; [Sugiyama, Masashi] Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778574, Japan	Nanjing University of Science & Technology; Nanjing University of Science & Technology; Hong Kong Polytechnic University; RIKEN; University of Tokyo	Yang, J (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, PCA Lab, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210044, Jiangsu, Peoples R China.; You, JN (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.	chen.gong@njust.edu.cn; csjyang@njust.edu.cn; jane.you@polyu.edu.hk; sugi@k.u-tokyo.ac.jp		Sugiyama, Masashi/0000-0001-6658-6743; You, Jane/0000-0002-8181-4836	NSF of China [U1713208, 61973162]; Fundamental Research Funds for the Central Universities [30920032202]; CCF-Tencent Open Fund [RAGR20200101]; "Young Elite Scientists Sponsorship Program" by CAST [2018QNRC001]; Hong Kong Scholars Program [XJ2019036]; "111 Program" [AH92005MS]; Hong Kong Polytechnic University [YZ3K]; KAKENHI [20H04206]	NSF of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); CCF-Tencent Open Fund; "Young Elite Scientists Sponsorship Program" by CAST; Hong Kong Scholars Program; "111 Program"(Ministry of Education, China - 111 Project); Hong Kong Polytechnic University(Hong Kong Polytechnic University); KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	The work of C. Gong was supported by the NSF of China (No: 61973162), the Fundamental Research Funds for the Central Universities (No: 30920032202), CCF-Tencent Open Fund (No: RAGR20200101), the "Young Elite Scientists Sponsorship Program" by CAST (No: 2018QNRC001), and Hong Kong Scholars Program (No: XJ2019036). The work of J. Yang was supported by NSF of China (No: U1713208) and "111 Program" (No: AH92005MS). The work of J. You was supported by the Hong Kong Polytechnic University grants (Nos: YZ3K, UAJP/UAGK, and ZVRH). The work of M. Sugiyama was supported by KAKENHI (No: 20H04206).	Andrews S., 2002, SUPPORT VECTOR MACHI, P561; Bao H., 2018, P 35 INT C MACH LEAR, P452; Bekker J, 2018, AAAI CONF ARTIF INTE, P2712; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Berthelot D, 2019, ADV NEUR IN, V32; Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918; Brabham D., 2008, CONVERGENCE-US, V14, P75, DOI DOI 10.1177/1354856507084420; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131, DOI 10.1613/jair.606; Cour T, 2009, PROC CVPR IEEE, P919, DOI 10.1109/CVPRW.2009.5206667; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; du Plessis MC, 2014, ADV NEUR IN, V27; du Plessis MC, 2015, PR MACH LEARN RES, V37, P1386; Dua D., 2017, UCI MACHINE LEARNING; Elkan Charles, 2008, P 14 ACM SIGKDD INT, P213, DOI DOI 10.1145/1401890.1401920; Gao W, 2016, AAAI CONF ARTIF INTE, P1575; Gartner T., 2002, ICML, P179; Gong C, 2020, IEEE T CIRC SYST VID, V30, P1396, DOI 10.1109/TCSVT.2019.2903563; Gong C, 2021, IEEE T PATTERN ANAL, V43, P918, DOI 10.1109/TPAMI.2019.2941684; Gong C, 2019, IEEE T NEUR NET LEAR, V30, P3471, DOI 10.1109/TNNLS.2019.2892403; Gong C, 2018, IEEE T CYBERNETICS, V48, P967, DOI 10.1109/TCYB.2017.2669639; Gong C, 2017, IEEE T NEUR NET LEAR, V28, P1452, DOI 10.1109/TNNLS.2016.2514360; Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936; Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2148, DOI 10.1109/TNNLS.2014.2376963; Han B., 2016, PROC EUR C MACH LEAR, P665; Han B, 2020, PR MACH LEARN RES, V119; Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944; Ilse M, 2018, PR MACH LEARN RES, V80; Ishida T, 2018, ADV NEUR IN, V31; Ishida T, 2017, ADV NEUR IN, V30; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Kipf Thomas N., 2017, P ICLR; Kiryo R, 2017, ADV NEUR IN, V30; Kulis B, 2009, MACH LEARN, V74, P1, DOI 10.1007/s10994-008-5084-4; Laine S., 2017, P INT C LEARN REPR; Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571; Lee Wee Sun, 2003, ICML, P448, DOI DOI 10.1016/J.TCS.2005.09.007; Li Xiaoli, 2003, IJCAI 03 P 18 INT JO, P587; Li Y, 2009, P INT C MACH LEARN, P633, DOI DOI 10.1145/1553374.1553456; Li YF, 2021, IEEE T PATTERN ANAL, V43, P334, DOI 10.1109/TPAMI.2019.2922396; Li YF, 2013, J MACH LEARN RES, V14, P2151; Liu Bing, 2002, ICML, P387; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Lu J, 2018, PR MACH LEARN RES, V80; Lu N., 2019, P INT C LEARN REPR, P1; Luo Y, 2020, PHYTOTHER RES, V34, P2180, DOI 10.1002/ptr.6672; Lyu YF, 2020, SYMP VLSI CIRCUITS; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Natarajan Nagarajan, 2013, ADV NEURAL INFORM PR; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Patrini G, 2016, PR MACH LEARN RES, V48; Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240; Peng M., 2019, ARXIV 190512226; Peters J, 2017, ADAPT COMPUT MACH LE; Plessis du, 2015, P 7 AS C MACH LEARN, P221; Ramaswamy HG, 2016, PR MACH LEARN RES, V48; Sakai T, 2017, PR MACH LEARN RES, V70; Scott C., 2013, P 26 ANN C LEARN THE, P489; Settles B., 2009, ACTIVE LEARNING LIT; Shi H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2689; Tarvainen A, 2017, ADV NEUR IN, V30; van Rooyen B, 2015, ADV NEUR IN, V28; Wang JD, 2009, IEEE T PATTERN ANAL, V31, P1600, DOI 10.1109/TPAMI.2008.216; Wang JQ, 2001, APMC 2001: ASIA-PACIFIC MICROWAVE CONFERENCE, VOLS 1-3, PROCEEDINGS, P1119, DOI 10.1109/APMC.2001.985316; Wang XG, 2019, INFORM SCIENCES, V504, P578, DOI 10.1016/j.ins.2019.07.071; Wang XG, 2018, PATTERN RECOGN, V74, P15, DOI 10.1016/j.patcog.2017.08.026; Wei XS, 2017, IEEE T NEUR NET LEAR, V28, P975, DOI 10.1109/TNNLS.2016.2519102; Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968; Xia Xiaobo, 2019, NEURIPS, P1; Yarowsky David, 1995, ACL, P2, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]; Zhang C, 2020, PEER PEER NETW APPL, V13, P16, DOI [10.1007/s12083-018-0715-4, 10.1109/IRMMW-THz.2019.8874219]; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhou Z.-H., 2007, P 24 INT C MACHINE L, P1167; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106; Zhu X, 2003, ICML, P920; Zhu X, 2009, MORGAN CLAYPOOL, DOI DOI 10.1007/978-3-031-01548-9; Zhu Xiaojin., 2003, P ICLR, P912	80	9	9	11	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					2841	2855		10.1109/TPAMI.2020.3044997	http://dx.doi.org/10.1109/TPAMI.2020.3044997			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33320809				2022-12-18	WOS:000803117500007
J	Song, XY; Chai, L; Zhang, JX				Song, Xiaoying; Chai, Li; Zhang, Jingxin			Graph Signal Processing Approach to QSAR/QSPR Model Learning of Compounds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Compounds; Analytical models; Mathematical model; Biological system modeling; Chemicals; Predictive models; Indexes; QSAR; QSPR model learning; compounds; graph signal processing (GSP); multidimensional signal	PRODUCT-CONNECTIVITY INDEX; PREDICTION	Quantitative relationship between the activity/property and the structure of compound is critical in chemical applications. To learn this quantitative relationship, hundreds of molecular descriptors have been designed to describe the structure, mainly based on the properties of vertices and edges of molecular graph. However, many descriptors degenerate to the same values for different compounds with the same molecular graph, resulting in model failure. In this paper, we design a multidimensional signal for each vertex of the molecular graph to derive new descriptors with higher discriminability. We treat the new and traditional descriptors as the signals on the descriptor graph learned from the descriptor data, and enhance descriptor dissimilarity using the Laplacian filter derived from the descriptor graph. Combining these with model learning techniques, we propose a graph signal processing based approach to obtain reliable new models for learning the quantitative relationship and predicting the properties of compounds. We also provide insights from chemistry for the boiling point model. Several experiments are presented to demonstrate the validity, effectiveness and advantages of the proposed approach.	[Song, Xiaoying; Chai, Li] Wuhan Univ Sci & Technol, Engn Res Ctr Met Automat & Measurement Technol, Wuhan 430072, Peoples R China; [Zhang, Jingxin] Swinburne Univ Technol, Sch Software & Elect Engn, Melbourne, Vic 3122, Australia	Wuhan University of Science & Technology; Swinburne University of Technology	Chai, L (corresponding author), Wuhan Univ Sci & Technol, Engn Res Ctr Met Automat & Measurement Technol, Wuhan 430072, Peoples R China.	xiaoying811@wust.edu.cn; chaili@wust.edu.cn; jingxinzhang@swin.edu.au			National Natural Science Foundation of China [61625305, 61801338, 61801339]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China (Grants 61625305, 61801338, and 61801339).	Baghban A, 2019, CHINESE J CHEM ENG, V27, P620, DOI 10.1016/j.cjche.2018.08.026; Bahonar H, 2021, IEEE T PATTERN ANAL, V43, P473, DOI 10.1109/TPAMI.2019.2929519; Ben Ghanem O, 2017, CHEMOSPHERE, V170, P242, DOI 10.1016/j.chemosphere.2016.12.003; Brandes U., 2005, NETWWORK ANAL METHOL; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Burden FR, 2009, QSAR COMB SCI, V28, P645, DOI 10.1002/qsar.200810173; Cheng Z, 2008, SPECTROSC SPECT ANAL, V28, P860; Cooper A, 2010, DRUG METAB DISPOS, V38, P2218, DOI 10.1124/dmd.110.034462; Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527; Dehmer M, 2017, INFORM SCIENCES, V418, P575, DOI 10.1016/j.ins.2017.08.009; Dehmer M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031214; Dehmer M, 2012, MATCH-COMMUN MATH CO, V67, P147; Diudea MV, 2011, COMPLEXITY, V16, P32, DOI 10.1002/cplx.20363; Ferreira MMC, 2001, CHEMOSPHERE, V44, P125, DOI 10.1016/S0045-6535(00)00275-7; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Gomez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Gutman I, 2006, LINEAR ALGEBRA APPL, V414, P29, DOI 10.1016/j.laa.2005.09.008; Hayat S, 2022, POLYCYCL AROMAT COMP, V42, P1113, DOI 10.1080/10406638.2020.1768414; Hayat S, 2019, INT J QUANTUM CHEM, V119, DOI 10.1002/qua.26016; Hosamani S.M., 2017, APPL MATH NONLINEAR, V2, P131; Kheradmand A, 2014, IEEE T IMAGE PROCESS, V23, P5136, DOI 10.1109/TIP.2014.2362059; Le T, 2012, CHEM REV, V112, P2889, DOI 10.1021/cr200066h; Liu PX, 2009, INT J MOL SCI, V10, P1978, DOI 10.3390/ijms10051978; Lucic B, 2009, CHEM PHYS LETT, V475, P146, DOI 10.1016/j.cplett.2009.05.022; Lusci A, 2013, J CHEM INF MODEL, V53, P1563, DOI 10.1021/ci400187y; Mansouri K, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0263-1; Ribeiro FAD, 2003, J MOL STRUC-THEOCHEM, V663, P109, DOI 10.1016/j.theochem.2003.08.107; Sandryhaila A, 2014, IEEE T SIGNAL PROCES, V62, P3042, DOI 10.1109/TSP.2014.2321121; Sandryhaila A, 2013, IEEE T SIGNAL PROCES, V61, P1644, DOI 10.1109/TSP.2013.2238935; Santiago CB, 2018, CHEM SCI, V9, P2398, DOI 10.1039/c7sc04679k; Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192; Teixeira AL, 2013, J CHEMINFORMATICS, V5, DOI 10.1186/1758-2946-5-9; Todeschini R, 1997, QUANT STRUCT-ACT REL, V16, P120, DOI 10.1002/qsar.19970160204; Todeschini R., 2008, HDB MOL DESCRIPTORS, V11; Todeschini R, 2016, J CHEM INF MODEL, V56, P1905, DOI 10.1021/acs.jcim.6b00277; UNGER SH, 1973, J MED CHEM, V16, P745, DOI 10.1021/jm00265a001; van Dijk D, 2018, CELL, V174, P716, DOI 10.1016/j.cell.2018.05.061; Vukicevic D, 2010, CROAT CHEM ACTA, V83, P349; Vukicevic D, 2010, ACTA CHIM SLOV, V57, P524	40	9	9	10	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1963	1973		10.1109/TPAMI.2020.3032718	http://dx.doi.org/10.1109/TPAMI.2020.3032718			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33085613				2022-12-18	WOS:000764815300023
J	Pinckaers, H; van Ginneken, B; Litjens, G				Pinckaers, Hans; van Ginneken, Bram; Litjens, Geert			Streaming Convolutional Neural Networks for End-to-End Learning With Multi-Megapixel Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Memory management; Convolution; Convolutional neural networks; Backpropagation; Streaming media; Task analysis; Training; Deep learning; convolutional neural networks; image classification; high-resolution images		Due to memory constraints on current hardware, most convolution neural networks (CNN) are trained on sub-megapixel images. For example, most popular datasets in computer vision contain images much less than a megapixel in size (0.09MP for ImageNet and 0.001MP for CIFAR-10). In some domains such as medical imaging, multi-megapixel images are needed to identify the presence of disease accurately. We propose a novel method to directly train convolutional neural networks using any input image size end-to-end. This method exploits the locality of most operations in modern convolutional neural networks by performing the forward and backward pass on smaller tiles of the image. In this work, we show a proof of concept using images of up to 66-megapixels (8192x8192), saving approximately 50GB of memory per image. Using two public challenge datasets, we demonstrate that CNNs can learn to extract relevant information from these large images and benefit from increasing resolution. We improved the area under the receiver-operating characteristic curve from 0.580 (4MP) to 0.706 (66MP) for metastasis detection in breast cancer (CAMELYON17). We also obtained a Spearman correlation metric approaching state-of-the-art performance on the TUPAC16 dataset, from 0.485 (1MP) to 0.570 (16MP). Code to reproduce a subset of the experiments is available at https://github.com/DIAGNijmegen/StreamingCNN.	[Pinckaers, Hans; van Ginneken, Bram; Litjens, Geert] Radboud Univ Nijmegen, Med Ctr, Diagnost Image Anal Grp, Radboud Inst Hlth Sci, NL-6525 GA Nijmegen, Netherlands	Radboud University Nijmegen	Pinckaers, H (corresponding author), Radboud Univ Nijmegen, Med Ctr, Diagnost Image Anal Grp, Radboud Inst Hlth Sci, NL-6525 GA Nijmegen, Netherlands.	hans.pinckaers@radboudumc.nl; bram.vanginneken@radboudumc.nl; geert.litjens@radboudumc.nl	Pinckaers, Hans/T-6889-2017; Litjens, Geert JS/A-2319-2016	Pinckaers, Hans/0000-0002-7570-9300; Litjens, Geert JS/0000-0003-1554-1291	Dutch Cancer Society (KWF) [KUN 2015-797]	Dutch Cancer Society (KWF)(KWF Kankerbestrijding)	The authors would like to thank Erdi C alli for his help in proofreading the equations. This work was supported by the Dutch Cancer Society (KWF), grant number KUN 2015-797.	Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1; Chen Tianqi, 2016, TRAINING DEEP NETS S, V6, P6; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Courtiol Pierre, 2018, ARXIV180202212; Couture HD, 2018, LECT NOTES COMPUT SC, V11071, P254, DOI 10.1007/978-3-030-00934-2_29; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gomez Aidan N, 2017, ADV NEURAL INFORM PR, P2214; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266; Howard J., IMAGENETTE SMALLER S; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ianni JD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59985-2; Ilse M, 2018, PR MACH LEARN RES, V80; Ioffe S., 2015, INT C MACH LEARN, P448, DOI [10.5555/3045118.3045167, DOI 10.5555/3045118.3045167]; Katharopoulos A, 2019, PR MACH LEARN RES, V97; Kingma D.P., 2015, INT C LEARN REPR, P1; Kr_ahenb_uhl P., 2016, PROC INT C LEARN REP; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Litjens G, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy065; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015; Matas J, 2016, PROC INT C LEARN REP; Nielsen TO, 2010, CLIN CANCER RES, V16, P5222, DOI 10.1158/1078-0432.CCR-10-1282; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Paeng K, 2017, LECT NOTES COMPUT SC, V10553, P231, DOI 10.1007/978-3-319-67558-9_27; Quellec Gwenole, 2017, IEEE Rev Biomed Eng, V10, P213, DOI 10.1109/RBME.2017.2651164; Recasens A, 2018, LECT NOTES COMPUT SC, V11213, P52, DOI 10.1007/978-3-030-01240-3_4; Ronneberger O., 2015, INT C MED IM COMP CO, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.1007/978-3-319-24574-4_28]; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6; Santurkar S, 2018, ADV NEUR IN, V31; Simonyan Karen, 2013, DEEP INSIDE CONVOLUT, P2; Smilkov D., 2017, PROC INT C MACH LEAR; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PR MACH LEARN RES, V97; Tellez D, 2021, IEEE T PATTERN ANAL, V43, P567, DOI 10.1109/TPAMI.2019.2936841; Vanhoucke V., 2011, PROC DEEP LEARN UNSU; Veta M, 2019, MED IMAGE ANAL, V54, P111, DOI 10.1016/j.media.2019.02.012; Weinstein JN, 2013, NAT GENET, V45, P1113, DOI 10.1038/ng.2764; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang J., 2019, ARXIV 190306631	47	9	9	16	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1581	1590		10.1109/TPAMI.2020.3019563	http://dx.doi.org/10.1109/TPAMI.2020.3019563			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32845835	Green Submitted			2022-12-18	WOS:000752018000036
J	Liu, YY; Shang, FH; Liu, HY; Kong, L; Jiao, LC; Lin, ZC				Liu, Yuanyuan; Shang, Fanhua; Liu, Hongying; Kong, Lin; Jiao, Licheng; Lin, Zhouchen			Accelerated Variance Reduction Stochastic ADMM for Large-Scale Machine Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stochastic optimization; ADMM; variance reduction; momentum acceleration; strongly convex and non-strongly convex; smooth and non-smooth	ALTERNATING DIRECTION METHOD; DUAL COORDINATE ASCENT; CONVERGENCE; MULTIPLIERS; ALGORITHMS; DESCENT	Recently, many stochastic variance reduced alternating direction methods of multipliers (ADMMs) (e.g., SAG-ADMM and SVRG-ADMM) have made exciting progress such as linear convergence rate for strongly convex (SC) problems. However, their best-known convergence rate for non-strongly convex (non-SC) problems is O(1/T) as opposed to O(1/T-2) of accelerated deterministic algorithms, where T is the number of iterations. Thus, there remains a gap in the convergence rates of existing stochastic ADMM and deterministic algorithms. To bridge this gap, we introduce a new momentum acceleration trick into stochastic variance reduced ADMM, and propose a novel accelerated SVRG-ADMM method (called ASVRG-ADMM) for the machine learning problems with the constraint Ax + By = c. Then we design a linearized proximal update rule and a simple proximal one for the two classes of ADMM-style problems with B = tau I and B not equal tau I, respectively, where I is an identity matrix and tau is an arbitrary bounded constant. Note that our linearized proximal update rule can avoid solving sub-problems iteratively. Moreover, we prove that ASVRG-ADMM converges linearly for SC problems. In particular, ASVRG-ADMM improves the convergence rate from O(1/T) to O(1/T-2) for non-SC problems. Finally, we apply ASVRG-ADMM to various machine learning problems, e.g., graph-guided fused Lasso, graph-guided logistic regression, graph-guided SVM, generalized graph-guided fused Lasso and multi-task learning, and show that ASVRG-ADMM consistently converges faster than the state-of-the-art methods.	[Liu, Yuanyuan; Shang, Fanhua; Liu, Hongying; Kong, Lin; Jiao, Licheng] Xidian Univ, Sch Artificial Intelligence, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China; [Shang, Fanhua] Peng Cheng Lab, Shenzhen 518066, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China	Xidian University; Peng Cheng Laboratory; Peking University	Shang, FH; Liu, HY (corresponding author), Xidian Univ, Sch Artificial Intelligence, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.; Shang, FH (corresponding author), Peng Cheng Lab, Shenzhen 518066, Peoples R China.	yyliu@xidian.edu.cn; fhshang@xidian.edu.cn; hyliu@xidian.edu.cn; xdkonglin0511@163.com; lchjiao@mail.xidian.edu.cn; zlin@pku.edu.cn		Liu, Yuanyuan/0000-0001-8646-8533	National Natural Science Foundation of China [61876221, 61876220, 61976164, 61836009, U1701267, 61871310, 61801353]; Foundation for Innovative Research Groups of the National Natural Science Foundation of China [61621005]; Major Research Plan of the National Natural Science Foundation of China [91438201, 91438103]; Program for Cheung Kong Scholars and Innovative Research Team in University [IRT_15R53]; Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project) [B07048]; Science Foundation of Xidian University [10251180018, 10251180019]; National Science Basic Research Plan in Shaanxi Province of China [2019JQ-657, 2020JM-194]; NSF China [61625301, 61731018]; Major Scientific Research Project of Zhejiang Lab [2019KB0AC01, 2019KB0AB02]; Beijing Academy of Artificial Intelligence; Qualcomm	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Foundation for Innovative Research Groups of the National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Major Research Plan of the National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Program for Cheung Kong Scholars and Innovative Research Team in University(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT)); Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project)(Ministry of Education, China - 111 Project); Science Foundation of Xidian University; National Science Basic Research Plan in Shaanxi Province of China; NSF China(National Natural Science Foundation of China (NSFC)); Major Scientific Research Project of Zhejiang Lab; Beijing Academy of Artificial Intelligence; Qualcomm	The author would like to thank all the reviewers for their valuable comments. Thisworkwas supported by the National Natural Science Foundation of China (Nos. 61876221, 61876220, 61976164, 61836009, U1701267, 61871310, and 61801353), the Project supported the Foundation for Innovative Research Groups of the National Natural Science Foundation of China (No. 61621005), the Major Research Plan of the National Natural Science Foundation of China (Nos. 91438201, and 91438103), the Program for Cheung Kong Scholars and Innovative Research Team in University (No. IRT_15R53), the Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project) (No. B07048), the Science Foundation of Xidian University (Nos. 10251180018 and 10251180019), and the National Science Basic Research Plan in Shaanxi Province of China (Nos. 2019JQ-657 and 2020JM-194). Z. Lin was supported by NSF China (Grant nos. 61625301 and 61731018), Major Scientific Research Project of Zhejiang Lab (Grant nos. 2019KB0AC01 and 2019KB0AB02), Beijing Academy ofArtificial Intelligence, and Qualcomm.	Allen-Zhu Z, 2018, J MACH LEARN RES, V18; Allen-Zhu ZY, 2016, PR MACH LEARN RES, V48; [Anonymous], 2015, FOUND TRENDS MACH LE, V8, P232, DOI 10.1561/2200000050; Azadi S, 2014, PR MACH LEARN RES, V32; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Chen CH, 2016, MATH PROGRAM, V155, P57, DOI 10.1007/s10107-014-0826-5; Davis D, 2017, MATH OPER RES, V42, P783, DOI 10.1287/moor.2016.0827; Deng W, 2016, J SCI COMPUT, V66, P889, DOI 10.1007/s10915-015-0048-x; Eckstein J, 2015, PAC J OPTIM, V11, P619; Fang C., 2017, P INT C NEUR INF PRO, P4479; Franca G, 2018, PR MACH LEARN RES, V80; Goldstein T, 2014, SIAM J IMAGING SCI, V7, P1588, DOI 10.1137/120896219; Golub G. H., 2013, MATRIX COMPUTIONS; He BS, 2012, SIAM J IMAGING SCI, V5, P119, DOI 10.1137/100814494; Hien LTK, 2019, J OPTIMIZ THEORY APP, V181, P541, DOI 10.1007/s10957-018-01469-5; Hong MY, 2017, MATH PROGRAM, V162, P165, DOI 10.1007/s10107-016-1034-2; Hu C., 2009, ADV NEURAL INF PROCE, P781; Huang F., 2019, ARXIV180203284V3; Huang F, 2019, PR MACH LEARN RES, V97; Johnson R., 2013, ADV NEURAL INF PROCE, V26, P315, DOI DOI 10.5555/2999611.2999647; Kadkhodaie M, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P497, DOI 10.1145/2783258.2783400; Konecny J, 2016, IEEE J-STSP, V10, P242, DOI 10.1109/JSTSP.2015.2505682; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Li H, 2019, J SCI COMPUT, V79, P671, DOI 10.1007/s10915-018-0893-5; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Liu YY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3045; Liu YY, 2017, AAAI CONF ARTIF INTE, P2287; Lu CY, 2018, IEEE T PATTERN ANAL, V40, P527, DOI 10.1109/TPAMI.2017.2689021; Lu CY, 2016, AAAI CONF ARTIF INTE, P739; Mahoney MW, 2011, FOUND TRENDS MACH LE, V3, P123, DOI 10.1561/2200000035; NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543; Nesterov Y., 2018, APPL OPTIMIZATION; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; Nie FP, 2014, PR MACH LEARN RES, V32, P505; Nishihara R, 2015, PR MACH LEARN RES, V37, P343; Nitanda A., 2014, ADV NEURAL INFORM PR, P1574; Ouyang Hua, 2013, P 30 INT C MACH LEAR, P80; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Roux R. N., 2012, ADV NEURAL INFORM PR, P2663; Shang F., 2018, PROC 21 INT C ARTIF, P1027; Shang FH, 2020, IEEE T KNOWL DATA EN, V32, P188, DOI 10.1109/TKDE.2018.2878765; Shang FH, 2018, IEEE T PATTERN ANAL, V40, P2066, DOI 10.1109/TPAMI.2017.2748590; Suzuki T., 2013, P INT C MACH LEARN A; Suzuki T, 2014, PR MACH LEARN RES, V32; Tian WY, 2019, MATH COMPUT, V88, P1685, DOI 10.1090/mcom/3388; Tibshirani RJ, 2011, ANN STAT, V39, P1335, DOI 10.1214/11-AOS878; Tran-Dinh Q., 2018, P INT C NEUR INF PRO, P4816; Tseng P, 1998, SIAM J OPTIMIZ, V8, P506, DOI 10.1137/S1052623495294797; Tseng P, 2010, MATH PROGRAM, V125, P263, DOI 10.1007/s10107-010-0394-2; Wang H., 2012, P 29 INT C MACH LEAR, P1699; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiao L, 2014, SIAM J OPTIMIZ, V24, P2057, DOI 10.1137/140961791; Xu Y, 2017, ADV NEUR IN, V30; Yang Sen, 2012, KDD, P922; Yu Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3364; Zhang L., 2013, ADV NEURAL INFORM PR, P980; Zhang T., 2004, P 21 INT C MACH LEAR, P116, DOI 10.1145/1015330.1015332; Zhang WZ, 2017, IEEE T PATTERN ANAL, V39, P1223, DOI 10.1109/TPAMI.2016.2578323; Zhang XQ, 2011, J SCI COMPUT, V46, P20, DOI 10.1007/s10915-010-9408-8; Zhao SY, 2015, ARXIV150203529; Zheng S, 2016, P 25 INT JOINT C ART, P2407, DOI DOI 10.1007/978-3-662-48868-3_65; Zhong LW, 2014, PR MACH LEARN RES, V32; Zhou K., 2019, PROC 22 INT C ARTIF, P1602	70	9	9	4	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4242	4255		10.1109/TPAMI.2020.3000512	http://dx.doi.org/10.1109/TPAMI.2020.3000512			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750780				2022-12-18	WOS:000714203900009
J	Palazzo, S; Spampinato, C; Kavasidis, I; Giordano, D; Schmidt, J; Shah, M				Palazzo, Simone; Spampinato, Concetto; Kavasidis, Isaak; Giordano, Daniela; Schmidt, Joseph; Shah, Mubarak			Decoding Brain Representations by Multimodal Learning of Neural Activity and Visual Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Brain-visual embedding; multimodal learning; unsupervised learning	OSCILLATIONS; ATTENTION; MODEL	This work presents a novel method of exploring human brain-visual representations, with a view towards replicating these processes in machines. The core idea is to learn plausible computational and biological representations by correlating human neural activity and natural images. Thus, we first propose a model, EEG-ChannelNet, to learn a brain manifold for EEG classification. After verifying that visual information can be extracted from EEG data, we introduce a multimodal approach that uses deep image and EEG encoders, trained in a siamese configuration, for learning a joint manifold that maximizes a compatibility measure between visual features and brain representations. We then carry out image classification and saliency detection on the learned manifold. Performance analyses show that our approach satisfactorily decodes visual information from neural signals. This, in turn, can be used to effectively supervise the training of deep learning models, as demonstrated by the high performance of image classification and saliency detection on out-of-training classes. The obtained results show that the learned brain-visual features lead to improved performance and simultaneously bring deep models more in line with cognitive neuroscience work related to visual perception and attention.	[Palazzo, Simone; Spampinato, Concetto; Kavasidis, Isaak; Giordano, Daniela] Univ Catania, Dept Elect Elect & Comp Engn, Viale Andrea Doria 6, I-95125 Catania, Italy; [Spampinato, Concetto; Shah, Mubarak] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA; [Schmidt, Joseph] Univ Cent Florida, Dept Psychol, Orlando, FL 32816 USA	University of Catania; State University System of Florida; University of Central Florida; State University System of Florida; University of Central Florida	Palazzo, S (corresponding author), Univ Catania, Dept Elect Elect & Comp Engn, Viale Andrea Doria 6, I-95125 Catania, Italy.	palazzosim@dieei.unict.it; cspampin@dieei.unict.it; kavasidis@dieei.unict.it; dgiordan@dieei.unict.it; Joseph.Schmidt@ucf.edu; shah@crcv.ucf.edu	Schmidt, Joseph/ABG-6969-2020	Shah, Mubarak/0000-0001-6172-5572; Schmidt, Joseph/0000-0002-2446-821X; Spampinato, Concetto/0000-0001-6653-2577; Palazzo, Simone/0000-0002-2441-0982				[Anonymous], 2010, MIR 10 P 2010 ACM IN; Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73; Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Bullier J, 2001, BRAIN RES REV, V36, P96, DOI 10.1016/S0165-0173(01)00085-6; Cichy RM, 2016, SCI REP-UK, V6, DOI 10.1038/srep27755; Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477; Clayton MS, 2015, TRENDS COGN SCI, V19, P188, DOI 10.1016/j.tics.2015.02.004; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Fong RC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-23618-6; Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132; Horikawa T, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15037; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; Hung CP, 2005, SCIENCE, V310, P863, DOI 10.1126/science.1117593; Ilievski I, 2017, ADV NEUR IN, V30; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Jensen O, 2007, TRENDS NEUROSCI, V30, P317, DOI 10.1016/j.tins.2007.05.001; Kapoor A, 2008, PROC CVPR IEEE, P2150; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kavasidis I, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1809, DOI 10.1145/3123266.3127907; Kourtzi Z, 2011, ANNU REV NEUROSCI, V34, P45, DOI 10.1146/annurev-neuro-060909-153218; Kravitz DJ, 2011, NAT REV NEUROSCI, V12, P217, DOI 10.1038/nrn3008; Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008; Kuanar S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2576; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Lawhern VJ, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aace8c; Li YT, 2017, ADV NEUR IN, V30; Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1; Mansimov E., 2016, ICLR, P1; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Nishimoto S, 2011, CURR BIOL, V21, P1641, DOI 10.1016/j.cub.2011.08.031; Olah Chris, 2017, DISTILL, P4, DOI DOI 10.23915/DISTILL.00007; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7; Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48; Palazzo S, 2017, IEEE I CONF COMP VIS, P3430, DOI 10.1109/ICCV.2017.369; Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71; Peirce JW, 2015, J VISION, V15, DOI 10.1167/15.7.5; Proverbio AM, 2011, SCI REP-UK, V1, DOI 10.1038/srep00054; Reed S, 2016, PR MACH LEARN RES, V48; Robinson AK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16377-3; Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P1679, DOI 10.1109/TPAMI.2013.2297711; Seymour KJ, 2016, CEREB CORTEX, V26, P1997, DOI 10.1093/cercor/bhv021; Sohn K., 2014, P 27 INT C NEURAL IN, V2, P2141; Spampinato C, 2017, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2017.479; Srivastava N, 2014, J MACH LEARN RES, V15, P2949; Stansbury DE, 2013, NEURON, V79, P1025, DOI 10.1016/j.neuron.2013.06.034; Tallon-Baudry C, 1999, TRENDS COGN SCI, V3, P151, DOI 10.1016/S1364-6613(99)01299-1; Tang ZC, 2017, OPTIK, V130, P11, DOI 10.1016/j.ijleo.2016.10.117; Treue S, 2003, CURR OPIN NEUROBIOL, V13, P428, DOI 10.1016/S0959-4388(03)00105-3; Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130; Vidyaratne L, 2016, IEEE IJCNN, P1202, DOI 10.1109/IJCNN.2016.7727334; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wen HG, 2018, PR MACH LEARN RES, V80; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yamins D.L., 2013, ADV NEURAL INFORM PR, V26, P3093, DOI [DOI 10.5555/2999792.2999957, 10.5555/2999792.2999957]; Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111; Yan P., 2018, NEUROLOGY, V90; Yu F., 2016, ABS151107122 CORR; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang DL, 2018, AAAI CONF ARTIF INTE, P1703; Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081; Zhao H., 2018, LECT NOTES COMPUT SC, P570, DOI DOI 10.1007/978-3-030-01246-5_35	71	9	9	19	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3833	3849		10.1109/TPAMI.2020.2995909	http://dx.doi.org/10.1109/TPAMI.2020.2995909			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32750768	Green Submitted			2022-12-18	WOS:000702649700011
J	Zhang, ML; Fang, JP				Zhang, Min-Ling; Fang, Jun-Peng			Partial Multi-Label Learning via Credible Label Elicitation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Computational complexity; Sensitivity analysis; Benchmark testing; Standards; Machine learning; multi-label learning; partial label learning; candidate label set; credible label elicitation		Partial multi-label learning (PML) deals with the problem where each training example is associated with an overcomplete set of candidate labels, among which only some candidate labels are valid. The task of PML naturally arises in learning scenarios with inaccurate supervision, and the goal is to induce a multi-label predictor which can assign a set of proper labels for unseen instance. The PML training procedure is prone to be misled by false positive labels concealed in the candidate label set, which serves as the major modeling difficulty for partial multi-label learning. In this paper, a novel two-stage PML approach is proposed which works by eliciting credible labels from the candidate label set for model induction. In the first stage, the labeling confidence of candidate label for each PML training example is estimated via iterative label propagation. In the second stage, by utilizing credible labels with high labeling confidence, multi-label predictor is induced via pairwise label ranking coupled with virtual label splitting or maximum a posteriori (MAP) reasoning. Experimental studies show that the proposed approach can achieve highly competitive generalization performance by excluding most false positive labels from the training procedure via credible label elicitation.	[Zhang, Min-Ling; Fang, Jun-Peng] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China; [Zhang, Min-Ling; Fang, Jun-Peng] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Peoples R China	Southeast University - China; Southeast University - China	Zhang, ML (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China.	zhangml@seu.edu.cn; fangjp@seu.edu.cn		FANG, JUNPENG/0000-0002-2576-4723	National Key R&D Program of China [2018YFB1004300]; National Science Foundation of China [61573104]; Collaborative Innovation Center of Novel Software Technology and Industrialization	National Key R&D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Collaborative Innovation Center of Novel Software Technology and Industrialization	The authors would like to thank the associate editor and anonymous reviewers for their insightful comments and suggestions. They would also like to thank Dr. Guoxian Yu in helping share the yeastBP data set. This work was supported by the National Key R&D Program of China (2018YFB1004300), the National Science Foundation of China (61573104), and was also supported in part by the Collaborative Innovation Center of Novel Software Technology and Industrialization.	Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Burkhardt S, 2018, MACH LEARN, V107, P859, DOI 10.1007/s10994-017-5689-6; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Chen CH, 2018, IEEE T PATTERN ANAL, V40, P1653, DOI 10.1109/TPAMI.2017.2723401; Chen YC, 2014, IEEE T INF FOREN SEC, V9, P2076, DOI 10.1109/TIFS.2014.2359642; Chen ZS, 2020, AAAI CONF ARTIF INTE, V34, P3553; Cour T, 2011, J MACH LEARN RES, V12, P1501; Demsar J, 2006, J MACH LEARN RES, V7, P1; Fang J-P, 2019, 33 AAAI C ART INT; Furnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8; Gibaja E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2716262; Gong C, 2018, IEEE T CYBERNETICS, V48, P967, DOI 10.1109/TCYB.2017.2669639; He S, 2019, IEEE DATA MINING, P280, DOI 10.1109/ICDM.2019.00038; Huang SJ, 2020, J COMPUT SCI TECH-CH, V35, P234, DOI 10.1007/s11390-020-9994-3; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199; Liu L., 2012, ADV NEURAL INFORM PR, P548; Luo J., 2010, PROC NEURAL INF PROC, P1504; Pan XY, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9558-2; Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5; Sun L, 2019, FRONT COMPUT SCI-CHI, V13, P1243, DOI 10.1007/s11704-018-7452-y; Sun LJ, 2019, AAAI CONF ARTIF INTE, P5016; Sun YY, 2010, AAAI CONF ARTIF INTE, P593; Tan Q., 2018, P 2018 SIAM INT C DA, P450; Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164; Wang HB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3691; Wei T, 2018, MACH LEARN, V107, P703, DOI 10.1007/s10994-017-5675-z; Wu JH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P416, DOI 10.1145/3292500.3330901; Wu X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2868; Xie MK, 2018, AAAI CONF ARTIF INTE, P4302; Yu F, 2017, MACH LEARN, V106, P573, DOI 10.1007/s10994-016-5606-4; Yu GX, 2018, IEEE DATA MINING, P1398, DOI 10.1109/ICDM.2018.00192; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang ML, 2018, FRONT COMPUT SCI-CHI, V12, P191, DOI 10.1007/s11704-017-7031-7; Zhang ML, 2017, IEEE T KNOWL DATA EN, V29, P2155, DOI 10.1109/TKDE.2017.2721942; Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39; Zhou Z.-H., 2017, ENCY MACHINE LEARNIN; Zhou ZH, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9801-4; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106	40	9	9	7	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3587	3599		10.1109/TPAMI.2020.2985210	http://dx.doi.org/10.1109/TPAMI.2020.2985210			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32286956				2022-12-18	WOS:000692232400024
J	Sun, SL; Zong, DM				Sun, Shiliang; Zong, Daoming			LCBM: A Multi-View Probabilistic Model for Multi-Label Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Probabilistic logic; Task analysis; Prediction algorithms; Support vector machines; Kernel; Training; Semantics; Multi-view learning; multi-label classification; Bernoulli mixture; probabilistic model; variational autoencoder		Multi-label classification is an important research topic in machine learning, for which exploiting label dependencies is an effective modeling principle. Recently, probabilistic models have shown great potential in discovering dependencies among labels. In this paper, motivated by the recent success of multi-view learning to improve the generalization performance, we propose a novel multi-view probabilistic model named latent conditional Bernoulli mixture (LCBM) for multi-label classification. LCBM is a generative model taking features from different views as inputs, and conditional on the latent subspace shared by the views a Bernoulli mixture model is adopted to build label dependencies. Inside each component of the mixture, the labels have a weak correlation which facilitates computational convenience. The mean field variational inference framework is used to carry out approximate posterior inference in the probabilistic model, where we propose a Gaussian mixture variational autoencoder (GMVAE) for effective posterior approximation. We further develop a scalable stochastic training algorithm for efficiently optimizing the model parameters and variational parameters, and derive an efficient prediction procedure based on greedy search. Experimental results on multiple benchmark datasets show that our approach outperforms other state-of-the-art methods under various metrics.	[Sun, Shiliang; Zong, Daoming] East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China	East China Normal University	Sun, SL (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.	slsun@cs.ecnu.edu.cn; m15901768536@163.com		Sun, Shiliang/0000-0001-7069-3752	National Natural Science Foundation of China [61673179]; Shanghai Knowledge Service Platform Project [ZF1213]; Fundamental Research Funds for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Knowledge Service Platform Project; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported by the National Natural Science Foundation of China under Project 61673179, Shanghai Knowledge Service Platform Project (No. ZF1213), and the Fundamental Research Funds for the Central Universities.	Bach F. R., 2005, 688 U CAL DEPT STAT; Benites F, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P847, DOI 10.1109/ICDMW.2015.14; Bishop C.M, 2006, PATTERN RECOGN; Chen WJ, 2016, PATTERN RECOGN, V52, P61, DOI 10.1016/j.patcog.2015.10.008; Dembczynski K, 2012, MACH LEARN, V88, P5, DOI 10.1007/s10994-012-5285-8; Demsar J, 2006, J MACH LEARN RES, V7, P1; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Gibaja EL, 2016, PROG ARTIF INTELL, V5, P251, DOI 10.1007/s13748-016-0098-9; Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913; Jang Eric, 2017, P 5 INT C LEARN REPR; Jiang LX, 2019, IEEE T KNOWL DATA EN, V31, P201, DOI 10.1109/TKDE.2018.2836440; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P., 2013, AUTO ENCODING VARIAT; Kludas J, 2008, LECT NOTES COMPUT SC, V4918, P147, DOI 10.1007/978-3-540-79860-6_12; Li C., 2016, P 33 INT C MACH LEAR, P2482; Li Q, 2016, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2016.325; Li X, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P430; Liu M, 2015, AAAI CONF ARTIF INTE, P2778; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo Y, 2013, IEEE T NEUR NET LEAR, V24, P709, DOI 10.1109/TNNLS.2013.2238682; Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Paisley J., 2012, P 29 INT C MACH LEAR, P1363; Puyol-Anton E, 2019, IEEE T BIO-MED ENG, V66, P956, DOI 10.1109/TBME.2018.2865669; Quoc Le, 2014, P 31 INT C MACHINE L, V32, P1188; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Serban I. V., 2016, MULTIMODAL VARIATION, P1; Sohn Kihyuk, 2015, NEURAL INFORM PROCES; Sun SL, 2016, IEEE T CYBERNETICS, V46, P3272, DOI 10.1109/TCYB.2015.2502248; Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6; Sun SL, 2011, LECT NOTES ARTIF INT, V7121, P209; Szymanski P., 2017, SCIKIT BASED PYTHON, P1; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1; Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164; van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334; Von Ahn Luis, 2004, P SIGCHI C HUM FACT, P319, DOI DOI 10.1145/985692.985733; Xu JH, 2013, PATTERN RECOGN, V46, P885, DOI 10.1016/j.patcog.2012.09.003; Zhang J., 2012, PROC ACM SIGKDD INT, P543; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39; Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007; Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356; Zou FH, 2016, MULTIMED TOOLS APPL, V75, P12627, DOI 10.1007/s11042-014-2423-2	49	9	9	4	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2682	2696		10.1109/TPAMI.2020.2974203	http://dx.doi.org/10.1109/TPAMI.2020.2974203			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32078533				2022-12-18	WOS:000670578800012
J	Su, JS; Zeng, JL; Xie, J; Wen, HT; Yin, YJ; Liu, Y				Su, Jinsong; Zeng, Jiali; Xie, Jun; Wen, Huating; Yin, Yongjing; Liu, Yang			Exploring Discriminative Word-Level Domain Contexts for Multi-Domain Neural Machine Translation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Decoding; Adaptation models; Annotations; Context modeling; Semantics; Task analysis; Multi-domain neural machine translation; word-level context; adversarial training	SEQUENCE	Owing to its practical significance, multi-domain Neural Machine Translation (NMT) has attracted much attention recently. Recent studies mainly focus on constructing a unified NMT model with mixed-domain training corpora to switch translation between different domains. In these models, the words in the same sentence are not well distinguished, while intuitively, they are related to the sentence domain to varying degrees and thus should exert different effects on the multi-domain NMT model. In this article, we are committed to distinguishing and exploiting different word-level domain contexts for multi-domain NMT. For this purpose, we adopt multi-task learning to jointly model NMT and monolingual attention-based domain classification tasks, improving the NMT model in two ways: 1) One domain classifier and one adversarial domain classifier are introduced to conduct domain classifications of input sentences. During this process, two generated gating vectors are used to produce domain-specific and domain-shared annotations for decoder; 2) We equip decoder with an attentional domain classifier. Then, the derived attentional weights are utilized to refine the model training via word-level cost weighting, so that the impacts of target words can be discriminated by their relevance to sentence domain. Experimental results on several multi-domain translations demonstrate the effectiveness of our model.	[Su, Jinsong] Xiamen Univ, Xiamen 361005, Peoples R China; [Zeng, Jiali; Wen, Huating; Yin, Yongjing] Xiamen Univ, Software Sch, Xiamen 361005, Peoples R China; [Xie, Jun] Tecent Co, Beijing 100080, Peoples R China; [Liu, Yang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Xiamen University; Xiamen University; Tsinghua University	Liu, Y (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	jssu@xmu.edu.cn; lemon@stu.xmu.edu.cn; stiffxie@tencent.com; htwen@stu.xmu.edu.cn; yinyongjing@stu.xmu.edu.cn; liuyang2011@tsinghua.edu.cn		Liu, Yang/0000-0002-3087-242X	National Key R&D Program of China [2019QY1803]; Beijing Advanced Innovation Center for Language Resources [TYR17002]; National Natural Science Foundation of China [61672440, 61761166008]; China Scholarship Council [201806315048]; Fundamental Research Funds for the Central Universities [ZK1024]; Scientific Research Project of National Language Committee of China [YB135-49]	National Key R&D Program of China; Beijing Advanced Innovation Center for Language Resources; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Scholarship Council(China Scholarship Council); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Scientific Research Project of National Language Committee of China	The authors would like to thank anonymous reviewers for their insightful comments. They would also like to thank Yubin Ge for his help in paper writing. This work was supported by the National Key R&D Program of China (No. 2019QY1803), the Beijing Advanced Innovation Center for Language Resources (No. TYR17002), National Natural Science Foundation of China (Nos. 61672440 and 61761166008), the China Scholarship Council (No. 201806315048), the Fundamental Research Funds for the Central Universities (No. ZK1024), and the Scientific Research Project of National Language Committee of China (No. YB135-49). Jinsong Su and Jiali Zeng contributed equally to this work. Work done while Jiali Zeng was an intern at Tencent, Beijing, China.	Amin Farajian M., 2017, P 2 C MACH TRANSL, P127; Bahdanau D., 2015, P 3 ITN C LEARN REPR; Ballesteros M., 2015, P 2015 C EMP METH NA, P349, DOI DOI 10.18653/V1/D15-1041; Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Britz Denny, 2017, P 2 C MACH TRANSL, P118, DOI DOI 10.18653/V1/W17-4712; Cettolo Mauro, 2015, P INT WORKSH SPOK LA, P2; Chen B., 2017, P 1 WORKSHOP NEURAL, P40; Chen W., 2016, CORR; Chen XC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1193, DOI 10.18653/v1/P17-1110; Cho K., 2014, P 2014 C EMP METH NA, P1724; Chu C., 2018, P 27 INT C COMP LIGN, P1304; Chu CH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P385, DOI 10.18653/v1/P17-2061; Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723; Dyer C., 2012, P ASS MACH TRANSL AM; Freitag M., 2016, CORR; Gehring J, 2017, PR MACH LEARN RES, V70; Heusser AC, 2018, J MACH LEARN RES, V18; Hiroya S., 2013, EUR J OPER RES, V215, P832; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huck M., 2015, P 15 MACHINE TRANSLA, P240; Johnson M., 2017, T ASSOC COMPUT LING, DOI 10.1162/tacl_a_00065; Kalchbrenner Nal, 2013, P 2013 C EMP METH NA, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047; Kingma Diederik P., 2015, 3 INT C LEARN REPRES, V3; Kobus Catherine, 2017, P INT C REC ADV NAT, P372, DOI DOI 10.26615/978-954-452-049-6_049; Koehn Philipp, 2004, EMNLP; Li Jiwei, 2016, P NAACL, DOI DOI 10.18653/V1/N16-1082; Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001; Liu Y, 2016, AAAI CONF ARTIF INTE, P2750; Luong Minh-Thang, 2015, P INT WORKSH SPOK LA, P76; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Sajjad Hassan, 2017, CORR; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Servan C., 2016, CORR; Snover Matthew, 2006, P ASS MACH TRANSL AM, P223; Su J., 2012, P 50 ANN M ASS COMP, P459; Su JS, 2018, AAAI CONF ARTIF INTE, P5488; Su JS, 2018, IEEE-ACM T AUDIO SPE, V26, P623, DOI 10.1109/TASLP.2018.2789721; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Tars Sander, 2018, CORR; Tian L, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1837; Vaswani A, 2017, ADV NEUR IN, V30; Wang R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P560, DOI 10.18653/v1/P17-2089; Xiao X., 2012, P 50 ANN M ASS COMP, P750; Zeng J., 2018, P 2018 C EMPIRICAL M, P447; Zhang Biao, 2016, P 2016 C EMP METH NA, P521, DOI [DOI 10.18653/V1/D16-1050, 10.18653/v1/D16-1050]; Zhang J., 2016, P COLING, P1807; Zhao B., 2006, P COLING ACL MAIN C, P969; Zhou QY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1095, DOI 10.18653/v1/P17-1101; Zoph Barret, 2016, P 2016 C EMP METH NA, P1568, DOI [DOI 10.18653/V1/D16-1163, 10.18653/v1/D16-1163]	50	9	9	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1530	1545		10.1109/TPAMI.2019.2954406	http://dx.doi.org/10.1109/TPAMI.2019.2954406			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31751225				2022-12-18	WOS:000637533800005
J	Siarohin, A; Lathuiliere, S; Sangineto, E; Sebe, N				Siarohin, Aliaksandr; Lathuiliere, Stephane; Sangineto, Enver; Sebe, Nicu			Appearance and Pose-Conditioned Human Image Generation Using Deformable GANs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Generators; Strain; Gallium nitride; Training; Generative adversarial networks; Face; Conditional GAN; image generation; deformable objects; human pose		In this paper, we address the problem of generating person images conditioned on both pose and appearance information. Specifically, given an image x(a) of a person and a target pose P(x(b)), extracted from an image x(b), we synthesize a new image of that person in pose P(x(b)), while preserving the visual details in x(a). In order to deal with pixel-to-pixel misalignments caused by the pose differences between P(x(a)) and P(x(b)), we introduce deformable skip connections in the generator of our Generative Adversarial Network. Moreover, a nearest-neighbour loss is proposed instead of the common L-1 and L-2 losses in order to match the details of the generated image with the target image. Quantitative and qualitative results, using common datasets and protocols recently proposed for this task, show that our approach is competitive with respect to the state of the art. Moreover, we conduct an extensive evaluation using off-the-shell person re-identification (Re-ID) systems trained with person-generation based augmented data, which is one of themain important applications for this task. Our experiments show that our Deformable GANs can significantly boost the Re-ID accuracy and are even better than data-augmentation methods specifically trained using Re-ID losses.	[Siarohin, Aliaksandr; Sangineto, Enver; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38122 Trento, Italy; [Lathuiliere, Stephane] Inst Polytech Paris, Telecom Paris, LTCI, F-75013 Paris, France	University of Trento; IMT - Institut Mines-Telecom; Institut Polytechnique de Paris	Lathuiliere, S (corresponding author), Inst Polytech Paris, Telecom Paris, LTCI, F-75013 Paris, France.	aliaksandr.siarohin@disi.unitn.it; stephane.lathuiliere@telecom-paris.fr; enver.sangineto@disi.unitn.it; sebe@disi.unitn.it	Sangineto, Enver/AAS-9542-2020	Sebe, Niculae/0000-0002-6597-7248; Sangineto, Enver/0000-0002-5187-4133	European Research Council (ERC) [788793-BACKUP]	European Research Council (ERC)(European Research Council (ERC)European Commission)	We want to thank the NVIDIA Corporation for the donation of the GPUs used in this project. This project has received funding from the European Research Council (ERC) (Grant agreement No.788793-BACKUP).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Guler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762; Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jaderberg M, 2015, ADV NEUR IN, V28; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kingma D. P, 2014, ARXIV13126114; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Lassner C, 2017, IEEE I CONF COMP VIS, P853, DOI 10.1109/ICCV.2017.98; Lee H, 2018, IEEE INT CONF COMM; Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018; Ma Liqian, 2017, P NEUR INF PROC SYST, P405; Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Pouget-Abadie Jean, 2014, COMMUN ACM, V27, DOI DOI 10.1145/3422622; Salimans T, 2016, ADV NEUR IN, V29; Si CY, 2018, PROC CVPR IEEE, P118, DOI 10.1109/CVPR.2018.00020; Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359; Sun QR, 2018, PROC CVPR IEEE, P5050, DOI 10.1109/CVPR.2018.00530; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Ulyanov D., 2016, ARXIV160708022; Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361; Wang W, 2018, PROC CVPR IEEE, P7083, DOI 10.1109/CVPR.2018.00740; Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581; Zanfir M, 2018, PROC CVPR IEEE, P5391, DOI 10.1109/CVPR.2018.00565; Zhao B, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P383, DOI 10.1145/3240508.3240536; Zheng L., 2016, PERSON RE IDENTIFICA; Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405	42	9	9	4	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1156	1171		10.1109/TPAMI.2019.2947427	http://dx.doi.org/10.1109/TPAMI.2019.2947427			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31634122	Green Submitted			2022-12-18	WOS:000626525300004
J	Zhang, J; Chen, DD; Liao, J; Zhang, WM; Feng, HM; Hua, G; Yu, NH				Zhang, Jie; Chen, Dongdong; Liao, Jing; Zhang, Weiming; Feng, Huamin; Hua, Gang; Yu, Nenghai			Deep Model Intellectual Property Protection via Deep Watermarking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Watermarking; Computational modeling; Training; Task analysis; IP networks; Image processing; Media; Deep model IP protection; model watermarking; image processing	COPYRIGHT PROTECTION; IMAGES; ROBUST; NETWORKS; SCHEME	Despite the tremendous success, deep neural networks are exposed to serious IP infringement risks. Given a target deep model, if the attacker knows its full information, it can be easily stolen by fine-tuning. Even if only its output is accessible, a surrogate model can be trained through student-teacher learning by generating many input-output training pairs. Therefore, deep model IP protection is important and necessary. However, it is still seriously under-researched. In this work, we propose a new model watermarking framework for protecting deep networks trained for low-level computer vision or image processing tasks. Specifically, a special task-agnostic barrier is added after the target model, which embeds a unified and invisible watermark into its outputs. When the attacker trains one surrogate model by using the input-output pairs of the barrier target model, the hidden watermark will be learned and extracted afterwards. To enable watermarks from binary bits to high-resolution images, a deep invisible watermarking mechanism is designed. By jointly training the target model and watermark embedding, the extra barrier can even be absorbed into the target model. Through extensive experiments, we demonstrate the robustness of the proposed framework, which can resist attacks with different network structures and objective functions.	[Zhang, Jie; Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, Sch Cyber Sci & Secur, Hefei 230026, Anhui, Peoples R China; [Chen, Dongdong] Microsoft Res, Redmond, WA 98052 USA; [Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China; [Feng, Huamin] Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China; [Hua, Gang] Wormpex AI Res LLC, Bellevue, WA 98004 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Microsoft; City University of Hong Kong; Beijing Electronic Science & Technology Institute	Chen, DD (corresponding author), Microsoft Res, Redmond, WA 98052 USA.	zjzac@mail.ustc.edu.cn; cddlyf@gmail.com; fingliao@cityu.edu.hk; zhangwm@ustc.edu.cn; fenghm@besti.edu.cn; ganghua@gmail.com; ynh@ustc.edu.cn		Zhang, Jie/0000-0002-4230-1077; LIAO, Jing/0000-0001-7014-5377; Chen, Dongdong/0000-0002-4642-4373	NSFC [61629301, 62072421, 62002334]; Exploration Fund Project of University of Science and Technology of China [YD3480002001]; Fundamental Research Funds for the Central Universities [WK2100000011, WK5290000001]; ECS Grant from the Research Grants Council of the Hong Kong [CityU 21209119]; APRC Grant from CityU, Hong Kong [9610488]; National Key R&D Program of China [2018AAA0101400]	NSFC(National Natural Science Foundation of China (NSFC)); Exploration Fund Project of University of Science and Technology of China; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); ECS Grant from the Research Grants Council of the Hong Kong; APRC Grant from CityU, Hong Kong; National Key R&D Program of China	Y This work was supported in part by the NSFC under Grants 62072421 and 62002334, Exploration Fund Project of University of Science and Technology of China under Grant YD3480002001, and by Fundamental Research Funds for the Central Universities under Grant WK2100000011 and WK5290000001. The work of Jing Liao was supported in part by the ECS Grant from the Research Grants Council of the Hong Kong (Project No. CityU 21209119) and an APRC Grant from CityU, Hong Kong (Project No. 9610488). The work of Gang Hua was supported in part by the National Key R&D Program of China Grant 2018AAA0101400 and NSFC Grant 61629301. Jie Zhang and Dongdong Chen are co-first authors.	Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1615; [Anonymous], 2016, INTERSPEECH, DOI DOI 10.21437/Interspeech.2016-1446; [Anonymous], 2018, INT J MULTIMEDIA INF; Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570; Chen DD, 2020, IEEE T IMAGE PROCESS, V29, P8043, DOI 10.1109/TIP.2020.3009844; Chen DD, 2021, IEEE T PATTERN ANAL, V43, P2373, DOI 10.1109/TPAMI.2020.2964205; Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151; Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126; Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296; Chen H., 2019, ARXIV 190400344; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Deeba F., 2020, INT J MACH LEARN COM, V10, P277, DOI DOI 10.18178/IJMLC.2020.10.2.932; Deguillaume F, 2002, PROC SPIE, V4675, P313, DOI 10.1117/12.465289; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan LX, 2019, ADV NEUR IN, V32; Fan QN, 2017, IEEE I CONF COMP VIS, P3258, DOI 10.1109/ICCV.2017.351; Fang H, 2021, IEEE T CIRC SYST VID, V31, P1436, DOI 10.1109/TCSVT.2020.3009349; Fang H, 2019, IEEE T INF FOREN SEC, V14, P1403, DOI 10.1109/TIFS.2018.2878541; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Guo J, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240862; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hernandez JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598; Hinton G., 2015, ARXIV150302531; Hong SD, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/ab15a2; Hong SD, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.178-245; Hong SD, 2017, LECT NOTES COMPUT SC, V10367, P33, DOI 10.1007/978-3-319-63564-4_3; Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686; Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957; Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604; Kim T, 2017, PR MACH LEARN RES, V70; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kutter M, 1999, P SOC PHOTO-OPT INS, V3528, P423, DOI 10.1117/12.337432; Le Merrer E, 2020, NEURAL COMPUT APPL, V32, P9233, DOI 10.1007/s00521-019-04434-z; Lee CH, 1999, IEEE T CONSUM ELECTR, V45, P1005, DOI 10.1109/30.809176; Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003; Nikolaidis N, 1996, INT CONF ACOUST SPEE, P2168, DOI 10.1109/ICASSP.1996.545849; ORuanaidh JJK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P239, DOI 10.1109/ICIP.1996.560428; Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244; Ronneberger O., 2015, P INT C MED IMAG COM, P234, DOI [DOI 10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]; Rouhani BD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P485, DOI 10.1145/3297858.3304051; Sun YH, 2017, IEEE ICC; Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219; Uchida Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P274, DOI 10.1145/3078971.3078974; Vaswani A., 2017, P 31 INT C NEUR INF, P5998, DOI DOI 10.5555/3295222.3295349; Voloshynovskiy S, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P999, DOI 10.1109/ICIP.2001.958294; Voloshynovskiy S., 2000, 2000 10 EUR SIGN PRO, P1; Wang Sheng-Yu, 2020, P IEEECVF C COMPUTER, V8, P8695, DOI DOI 10.1109/CVPR42600.2020.00872; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Wu HZ, 2021, IEEE T CIRC SYST VID, V31, P2591, DOI 10.1109/TCSVT.2020.3030671; Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158; Yang W, 2017, MED IMAGE ANAL, V35, P421, DOI 10.1016/j.media.2016.08.004; Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71; Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079; Zhang J., 2020, ADV NEURAL INFORM PR, V33, P22619; Zhang J., 2017, DMBD, P326; Zhang JL, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P159, DOI 10.1145/3196494.3196550; Zhang J, 2020, AAAI CONF ARTIF INTE, V34, P12805; Zhao J., 1995, Intellectual Property Rights and New Technologies. Proceedings of the KnowRight'95 Conference, P242	68	9	9	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 9	2021	44	8					4005	4020		10.1109/TPAMI.2021.3064850	http://dx.doi.org/10.1109/TPAMI.2021.3064850			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HO	33687836	Green Submitted			2022-12-18	WOS:000820521800002
J	Yin, XF; Zhu, YM; Hu, JK				Yin, Xuefei; Zhu, Yanming; Hu, Jiankun			3D Fingerprint Recognition based on Ridge-Valley-Guided 3D Reconstruction and 3D Topology Polymer Feature Extraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Two dimensional displays; Image reconstruction; Cameras; Feature extraction; Topology; Fingerprint recognition; Biometrics; 3D fingerprint recognition; real-time 3D fingerprint reconstruction; 3D topology feature extraction	LOW-COST; SYSTEM; TAXONOMY	An automated fingerprint recognition system (AFRS) for 3D fingerprints is essential and highly promising for biometric security. Despite the progress in developing 3D AFRSs, achieving high-quality real-time reconstruction and high-accuracy recognition of 3D fingerprints remain two challenging issues. To address them, we propose a robust 3D AFRS based on ridge-valley (RV)-guided 3D fingerprint reconstruction and 3D topology polymer (TTP) feature extraction. The former considers the unique fingerprint characteristics of the RV and achieves real-time reconstruction. Unlike traditional triangulation-based methods that establish correspondences between points by cross-correlation-based searching, we propose to establish RV correspondences (RVCs) between ridges/valleys by defining and calculating a RVC matrix based on the topology of RV curves. To enhance depth reconstruction, curve-based smoothing is proposed to refine our novel RV disparity map. The TTP feature codes the 3D topology by projecting the 3D minutiae onto multiple planes and extracting their corresponding 2D topologies and has proven to be effective and efficient for 3D fingerprint recognition. Comprehensive experimental results demonstrate that our method outperforms the state-of-the-art methods in terms of both reconstruction and recognition accuracy. Also, due to its very short running time, it is appropriate for practical applications.	[Yin, Xuefei; Zhu, Yanming; Hu, Jiankun] Univ New South Wales, Sch Engn & Informat Technol, Canberra, ACT 2600, Australia	University of New South Wales Sydney	Hu, JK (corresponding author), Univ New South Wales, Sch Engn & Informat Technol, Canberra, ACT 2600, Australia.	xuefei.yin@student.unsw.edu.au; yanming.zhu@student.unsw.edu.au; J.Hu@adfa.edu.au		Hu, Jiankun/0000-0003-0230-1432; Zhu, Yanming/0000-0002-8238-8090; Yin, Xuefei/0000-0002-5784-7419	ARC Discovery Grant [IDDP190103660]; ARC Linkage Grant [LP180100663]	ARC Discovery Grant(Australian Research Council); ARC Linkage Grant(Australian Research Council)	This research is supported by ARC Discovery Grant (IDDP190103660) and ARC Linkage Grant (ID LP180100663).	[Anonymous], 2011, NEUROTECHNOLOGY VERI; Auksorius E, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.9.096002; Bouguet J.-Y., 2003, CAMERA CALIBRATION T; Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52; Cheng YZ, 2006, APPL OPTICS, V45, P9238, DOI 10.1364/AO.45.009238; Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036; FANG TP, 1995, IEEE COMPUT GRAPH, V15, P62; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Furman S. M., 2017, 8171 NAT I STAND TEC; Hariharan P., 2010, BASICS INTERFEROMETR; Hartley R., 2003, MULTIPLE VIEW GEOMET; Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468; Huang SJ, 2014, OPT LASER ENG, V52, P123, DOI 10.1016/j.optlaseng.2013.07.001; Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252; Jiang XY, 2017, MICROSYST NANOENG, V3, DOI 10.1038/micronano.2017.59; Kim S, 2018, BIOMED OPT EXPRESS, V9, P1232, DOI 10.1364/BOE.9.001232; Kumar A, 2015, IEEE T PATTERN ANAL, V37, P681, DOI 10.1109/TPAMI.2014.2339818; Labati RD, 2016, IEEE T SYST MAN CY-S, V46, P202, DOI 10.1109/TSMC.2015.2423252; Lalonde J.-F., 2006, CMURITR0621; Li B, 2013, IEEE INT C INT ROBOT, P1301, DOI 10.1109/IROS.2013.6696517; Li K. K. Bo, 2013, MULTIPLE CAMERA CALI; Lin CH, 2018, IEEE T PATTERN ANAL, V40, P3022, DOI 10.1109/TPAMI.2017.2771292; Liu F, 2015, NEUROCOMPUTING, V168, P599, DOI 10.1016/j.neucom.2015.05.065; Liu F, 2014, PATTERN RECOGN, V47, P178, DOI 10.1016/j.patcog.2013.06.009; Maev RG, 2012, PROC SPIE, V8546, DOI 10.1117/12.976344; Maltoni D., 2009, HDB FINGERPRINT RECO; Pang XF, 2013, IEEE COMPUT GRAPH, V33, P73, DOI 10.1109/MCG.2012.128; Parziale G, 2006, LECT NOTES COMPUT SC, V3832, P244; Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013; Ratha NK, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Sousedik C., 2013, BIOM SPEC INT GROUP, p[1, 1]; Tang HY, 2016, IEEE J SOLID-ST CIRC, V51, P2522, DOI 10.1109/JSSC.2016.2604291; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Wang YC, 2010, IEEE T INF FOREN SEC, V5, P750, DOI 10.1109/TIFS.2010.2062177; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Xie WY, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.10.103103; Yalla VG, 2005, P SOC PHOTO-OPT INS, V5798, P44, DOI 10.1117/12.603832; Yang WC, 2014, IEEE T INF FOREN SEC, V9, P1179, DOI 10.1109/TIFS.2014.2328095; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhu YM, 2017, IEEE INT WORKS INFOR, DOI 10.1109/INTMAG.2017.8007607	43	9	9	7	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1085	1091		10.1109/TPAMI.2019.2949299	http://dx.doi.org/10.1109/TPAMI.2019.2949299			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31675315	hybrid			2022-12-18	WOS:000616309900023
J	Zhang, Y; Tsang, IW; Luo, YW; Hu, CH; Lu, XB; Yu, X				Zhang, Yang; Tsang, Ivor W.; Luo, Yawei; Hu, Changhui; Lu, Xiaobo; Yu, Xin			Recursive Copy and Paste GAN: Face Hallucination From Shaded Thumbnails	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face hallucination; super-resolution; illumination normalization; generative adversarial network	NETWORK; IMAGES	Existing face hallucination methods based on convolutional neural networks (CNNs) have achieved impressive performance on low-resolution (LR) faces in a normal illumination condition. However, their performance degrades dramatically when LR faces are captured in non-uniform illumination conditions. This paper proposes a Recursive Copy and Paste Generative Adversarial Network (Re-CPGAN) to recover authentic high-resolution (HR) face images while compensating for non-uniform illumination. To this end, we develop two key components in our Re-CPGAN: internal and recursive external Copy and Paste networks (CPnets). Our internal CPnet exploits facial self-similarity information residing in the input image to enhance facial details; while our recursive external CPnet leverages an external guided face for illumination compensation. Specifically, our recursive external CPnet stacks multiple external Copy and Paste (EX-CP) units in a compact model to learn normal illumination and enhance facial details recursively. By doing so, our method offsets illumination and upsamples facial details progressively in a coarse-to-fine fashion, thus alleviating the ambiguity of correspondences between LR inputs and external guided inputs. Furthermore, a new illumination compensation loss is developed to capture illumination from the external guided face image effectively. Extensive experiments demonstrate that our method achieves authentic HR face images in a uniform illumination condition with a 16x magnification factor and outperforms state-of-the-art methods qualitatively and quantitatively.	[Zhang, Yang; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China; [Zhang, Yang; Tsang, Ivor W.; Yu, Xin] Univ Technol Sydney, Australian Inst Artificial Intelligence, Ultimo, NSW 2007, Australia; [Zhang, Yang; Lu, Xiaobo] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China; [Luo, Yawei] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310007, Peoples R China; [Hu, Changhui] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Peoples R China; [Hu, Changhui] Nanjing Univ Posts & Telecommun, Coll Artificial Intelligent, Nanjing 210023, Peoples R China	Southeast University - China; University of Technology Sydney; Zhejiang University; Nanjing University of Posts & Telecommunications; Nanjing University of Posts & Telecommunications	Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Lu, XB (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.	zhangyang201703@126.com; ivor.tsang@uts.edu.au; yaweiluo329@gmail.com; hchnjupt@126.com; xblu2013@126.com; xin.yu@uts.edu.au		Yu, Xin/0000-0002-0269-5649	National Natural Science Foundation of China [61871123, 61976017, 61802203]; Key Research and Development Program in Jiangsu Province [BE2016739]; Australian Research Council [DP180100106, DP200101328]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research and Development Program in Jiangsu Province; Australian Research Council(Australian Research Council)	This work was supported by the National Natural Science Foundation of China under Grants 61871123, 61976017, and 61802203 and the Key Research and Development Program in Jiangsu Province under Grant BE2016739. This work was supported in part by Australian Research Council under Grants DP180100106 and DP200101328.	Anokhin I., 2020, CVPR, P7488; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019; Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180; Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264; Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047; Farrugia RA, 2017, IEEE T IMAGE PROCESS, V26, P4562, DOI 10.1109/TIP.2017.2717181; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Huang HB, 2019, INT J COMPUT VISION, V127, P763, DOI 10.1007/s11263-019-01154-8; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Jaderberg M, 2015, ADV NEUR IN, V28; Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D. P., 2013, AUTO ENCODING VARIAT; Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853; Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065; Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212; Liu ZC, 2001, COMP GRAPH, P271; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019; Menon S, 2020, PROC CVPR IEEE, P2434, DOI 10.1109/CVPR42600.2020.00251; Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343; Phillips F, 2011, ISS ACCOUNT EDUC, V26, P593, DOI 10.2308/iace-50038; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Saito S, 2017, PROC CVPR IEEE, P2326, DOI 10.1109/CVPR.2017.250; Sengupta S, 2018, PROC CVPR IEEE, P6296, DOI 10.1109/CVPR.2018.00659; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; Shiri F, 2019, INT J COMPUT VISION, V127, P863, DOI 10.1007/s11263-019-01169-1; Shu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3095816; Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Socher R., 2012, ADV NEURAL INFORM PR, V1, P656; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tappen MF, 2012, LECT NOTES COMPUT SC, V7578, P236, DOI 10.1007/978-3-642-33786-4_18; Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350; van den Oord A, 2016, PR MACH LEARN RES, V48; Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244; Wang ZB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417824; Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36; Yang CY, 2018, INT J COMPUT VISION, V126, P597, DOI 10.1007/s11263-017-1044-4; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Yang Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7353, DOI 10.1109/CVPR42600.2020.00738; Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14; Yu X, 2020, INT J COMPUT VISION, V128, P500, DOI 10.1007/s11263-019-01254-5; Yu X, 2020, IEEE T PATTERN ANAL, V42, P2148, DOI 10.1109/TPAMI.2019.2914039; Yu X, 2018, PROC CVPR IEEE, P908, DOI 10.1109/CVPR.2018.00101; Yu X, 2017, AAAI CONF ARTIF INTE, P4327; Yu X, 2018, IEEE T IMAGE PROCESS, V27, P2747, DOI 10.1109/TIP.2018.2808840; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20; Yu X, 2014, IEEE T MULTIMEDIA, V16, P1510, DOI 10.1109/TMM.2014.2321734; Zhang W, 2018, IEEE CONF COMPUT; Zhang Y, 2019, J VIS COMMUN IMAGE R, V59, P501, DOI 10.1016/j.jvcir.2019.02.007; Zheng YP, 2022, IEEE T NEUR NET LEAR, V33, P1310, DOI 10.1109/TNNLS.2020.3041752; Zhou H, 2018, PROC CVPR IEEE, P6238, DOI 10.1109/CVPR.2018.00653; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	72	9	9	5	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 23	2021	44	8					4321	4338		10.1109/TPAMI.2021.3061312	http://dx.doi.org/10.1109/TPAMI.2021.3061312			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HN	33621168				2022-12-18	WOS:000820521700004
J	Xu, X; Cheong, LF; Li, ZW				Xu, Xun; Cheong, Loong-Fah; Li, Zhuwen			3D Rigid Motion Segmentation with Mixed and Unknown Number of Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spectral clustering; model selection; motion segmentation; multi-view learning	GENERATION; DEGENERATE; ALGORITHM	Many real-world video sequences cannot be conveniently categorized as general or degenerate; in such cases, imposing a false dichotomy in using the fundamental matrix or homography model for motion segmentation on video sequences would lead to difficulty. Even when we are confronted with a general scene-motion, the fundamental matrix approach as a model for motion segmentation still suffers from several defects, which we discuss in this paper. The full potential of the fundamental matrix approach could only be realized if we judiciously harness information from the simpler homography model. From these considerations, we propose a multi-model spectral clustering framework that synergistically combines multiple models (homography and fundamental matrix) together. We show that the performance can be substantially improved in this way. For general motion segmentation tasks, the number of independently moving objects is often unknown a priori and needs to be estimated from the observations. This is referred to as model selection and it is essentially still an open research problem. In this work, we propose a set of model selection criteria balancing data f idelity and model complexity. We perform extensive testing on existing motion segmentation datasets with both segmentation and model selection tasks, achieving state-of-the-art performance on all of them; we also put forth a more realistic and challenging dataset adapted from the KITTI benchmark, containing real-world effects such as strong perspectives and strong forward translations not seen in the traditional datasets.	[Xu, Xun; Cheong, Loong-Fah] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Xu, Xun] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore; [Li, Zhuwen] PonyAI, Fremont, CA 94538 USA	National University of Singapore; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)	Xu, X (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore.; Xu, X (corresponding author), ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.	alex.xun.xu@gmail.com; eleclf@nus.edu.sg; lzhuwen@gmail.com			Singapore PSF grant [1521200082]	Singapore PSF grant	This work was supported by the Singapore PSF grant 1521200082.	Bideau P., 2016, DETAILED RUBRIC MOTI; Bideau P, 2018, PROC CVPR IEEE, P508, DOI 10.1109/CVPR.2018.00060; Bideau P, 2016, LECT NOTES COMPUT SC, V9912, P433, DOI 10.1007/978-3-319-46484-8_26; Boult T. E., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P179, DOI 10.1109/WVM.1991.212809; Chen P, 2008, INT J COMPUT VISION, V80, P125, DOI 10.1007/s11263-008-0135-7; Chin T.-J., 2009, NIPS, V22, P333; Chin TJ, 2010, LECT NOTES COMPUT SC, V6315, P533, DOI 10.1007/978-3-642-15555-0_39; Chin TJ, 2010, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2010.5539931; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Dragon R, 2012, LECT NOTES COMPUT SC, V7573, P445, DOI 10.1007/978-3-642-33709-3_32; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Goh A, 2007, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2007.383235; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Goshen L, 2008, INT J COMPUT VISION, V80, P275, DOI 10.1007/s11263-008-0126-8; Gruber J, 2004, NBER CONF R, P1; Hartley R., 2003, MULTIPLE VIEW GEOMET; Horn R.A., 2013, MATRIX ANAL, P321; Hu H, 2015, IEEE T PATTERN ANAL, V37, P1542, DOI 10.1109/TPAMI.2014.2377740; Huang HC, 2012, PROC CVPR IEEE, P773, DOI 10.1109/CVPR.2012.6247748; Ji P, 2015, IEEE I CONF COMP VIS, P4687, DOI 10.1109/ICCV.2015.532; Jung H, 2014, PROC CVPR IEEE, P1210, DOI 10.1109/CVPR.2014.158; Keuper M, 2017, IEEE I CONF COMP VIS, P4252, DOI 10.1109/ICCV.2017.455; Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374; Kumar A., 2011, ADV NEURAL INFORM PR, P1413; Lai TT, 2017, IEEE T INTELL TRANSP, V18, P973, DOI 10.1109/TITS.2016.2596296; Lange T., 2006, ADV NEURAL INFORM PR, V18, P723; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; Lazic N, 2009, IEEE I CONF COMP VIS, P825, DOI 10.1109/ICCV.2009.5459302; Lee CM, 2013, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2013.200; Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624; Li ZW, 2018, IEEE T PATTERN ANAL, V40, P1964, DOI 10.1109/TPAMI.2017.2739147; Li ZW, 2014, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2014.41; Li ZW, 2013, IEEE I CONF COMP VIS, P1369, DOI 10.1109/ICCV.2013.173; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Magri L, 2014, PROC CVPR IEEE, P3954, DOI 10.1109/CVPR.2014.505; Narayana M., 2012, P BRIT MACH VIS C, V1, P5; Narayana M, 2012, PROC CVPR IEEE, P2104, DOI 10.1109/CVPR.2012.6247916; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Raj A, 2010, IEEE T PATTERN ANAL, V32, P988, DOI 10.1109/TPAMI.2009.124; Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Shi J., 2005, IEEE T PATTERN ANAL, V22, P888; Sugaya Y, 2004, LECT NOTES COMPUT SC, V3247, P13; Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Tishby N., 2001, P 13 INT C NEUR INF, P619; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Vidal R., 2004, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pII; Vidal R, 2008, INT J COMPUT VISION, V79, P85, DOI 10.1007/s11263-007-0099-z; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang H., 2014, P 30 INT C MACH LEAR, P352; Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9; Xu X, 2018, PROC CVPR IEEE, P2859, DOI 10.1109/CVPR.2018.00302; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Zamalieva D, 2014, COMPUT VIS IMAGE UND, V127, P73, DOI 10.1016/j.cviu.2014.06.007; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zhang T, 2012, INT J COMPUT VISION, V100, P217, DOI 10.1007/s11263-012-0535-6; Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007	63	9	10	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					1	16		10.1109/TPAMI.2019.2929146	http://dx.doi.org/10.1109/TPAMI.2019.2929146			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31331880	Green Submitted			2022-12-18	WOS:000597206900001
J	Chang, JL; Wang, LF; Meng, GF; Zhang, Q; Xiang, SM; Pan, CH				Chang, Jianlong; Wang, Lingfeng; Meng, Gaofeng; Zhang, Qi; Xiang, Shiming; Pan, Chunhong			Local-Aggregation Graph Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolution; Neural networks; Message passing; Laplace equations; Aggregates; Pattern recognition; Function approximation; Local-aggregation function; local-aggregation graph neural network; non-Euclidean structured signal		Convolutional neural networks (CNNs) provide a dramatically powerful class of models, but are subject to traditional convolution that can merely aggregate permutation-ordered and dimension-equal local inputs. It causes that CNNs are allowed to only manage signals on Euclidean or grid-like domains (e.g., images), not ones on non-Euclidean or graph domains (e.g., traffic networks). To eliminate this limitation, we develop a local-aggregation function, a sharable nonlinear operation, to aggregate permutation-unordered and dimension-unequal local inputs on non-Euclidean domains. In the context of the function approximation theory, the local-aggregation function is parameterized with a group of orthonormal polynomials in an effective and efficient manner. By replacing the traditional convolution in CNNs with the parameterized local-aggregation function, Local-Aggregation Graph Networks (LAGNs) are readily established, which enable to fit nonlinear functions without activation functions and can be expediently trained with the standard back-propagation. Extensive experiments on various datasets strongly demonstrate the effectiveness and efficiency of LAGNs, leading to superior performance on numerous pattern recognition and machine learning tasks, including text categorization, molecular activity detection, taxi flow prediction, and image classification.	[Chang, Jianlong; Wang, Lingfeng; Meng, Gaofeng; Zhang, Qi; Xiang, Shiming; Pan, Chunhong] Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Chang, Jianlong; Zhang, Qi; Xiang, Shiming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Meng, GF (corresponding author), Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	jianlong.chang@nlpr.ia.ac.cn; lfwang@nlpr.ia.ac.cn; gfmeng@nlpr.ia.ac.cn; qi.zhang2015@nlpr.ia.ac.cn; smxiang@nlpr.ia.ac.cn; chpan@nlpr.ia.ac.cn			National Natural Science Foundation of China [91646207, 61773377, 61573352]; Beijing Natural Science Foundation [L172053]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work was supported by the National Natural Science Foundation of China under Grants 91646207, 61773377, and 61573352, and the Beijing Natural Science Foundation under Grant L172053. Wewould like to thank Lele Yu, Jie Gu, Cheng Da, Xue Ye, and Tingzhao Yu for their discussions in shaping the early stage of thiswork. We furthermore thank the anonymous reviewers for their constructive comments earnestly.	Abadi M., 2015, TENSORFLOW LARGE SCA; Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146; [Anonymous], 2014, ICLR; Atwood J, 2016, C WORKSH NEUR INF PR, P1993; Battaglia P., 2018, CORR; Battaglia Peter W, 2016, ARXIV161200222; Boscaini Davide, 2016, P 30 INT C NEUR INF, P2; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Chang J., 2018, P C NEUR INF PROC SY, P11; Chang JL, 2020, IEEE T PATTERN ANAL, V42, P809, DOI 10.1109/TPAMI.2018.2889949; Chang JL, 2018, PATTERN RECOGN, V77, P438, DOI 10.1016/j.patcog.2017.10.022; Chang JL, 2017, IEEE I CONF COMP VIS, P5880, DOI 10.1109/ICCV.2017.626; Chen J., 2017, ARXIV171010568; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chollet F., 2015, KERAS; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Coates A., 2011, ADV NEURAL INFORM PR, P2528, DOI DOI 10.1016/J.PSYCHRES.2009.03.008; Defferrard M, 2016, ADV NEUR IN, V29; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Gilmer J, 2017, PR MACH LEARN RES, V70; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Glorot X., 2011, J MACH LEARN RES, V14, P315; Gomez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Gregor K., 2010, CORR; Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005; Henaff M., 2015, CORR; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Irsoy Ozan, 2014, ADV NEURAL INFORM PR, V27, P2096; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; Kreyszig E, 1989, INTRO FUNCTIONAL ANA, V1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624; Li RY, 2018, AAAI CONF ARTIF INTE, P3546; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112; Mnih V., 2013, ARXIV PREPRINT ARXIV; Mnih V, 2016, PR MACH LEARN RES, V48; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Qin J., 2017, ARXIV PREPRINT ARXIV; Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Schutt KT, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13890; Shaw Peter, 2018, P 2018 C N AM CHAPT, P464, DOI DOI 10.18653/V1/N18-2074; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; Sui YL, 2013, INT SYM CODE GENER, P1; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; van der Merwe R, 2019, ARCH REC, V40, P239, DOI 10.1080/23257962.2017.1388224; Velickovic P., 2017, STAT-US, V1050, P20; Verma Nitika, 2017, ABS170605206 CORR; Xu KYL, 2018, PR MACH LEARN RES, V80; Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890; You J., 2018, CORR; Zaheer M., 2017, ADV NEURAL INFORM PR, P3391; Zhang Q, 2018, INT C PATT RECOG, P1018, DOI 10.1109/ICPR.2018.8545106	60	9	9	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2874	2886		10.1109/TPAMI.2019.2915591	http://dx.doi.org/10.1109/TPAMI.2019.2915591			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31071020				2022-12-18	WOS:000575381000010
J	Haefner, B; Peng, SY; Verma, A; Queau, Y; Cremers, D				Haefner, Bjoern; Peng, Songyou; Verma, Alok; Queau, Yvain; Cremers, Daniel			Photometric Depth Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image resolution; Lighting; Shape; Training; Cameras; Color; Frequency measurement; RGB-D cameras; depth super-resolution; shape-from-shading; photometric stereo; variational methods; deep learning	VISCOSITY SOLUTIONS; SHAPE; IMAGE; STEREO; REFLECTANCE; CONSISTENT; RESOLUTION; AMBIGUITY; FRAMEWORK	This study explores the use of photometric techniques (shape-from-shading and uncalibrated photometric stereo) for upsampling the low-resolution depth map from an RGB-D sensor to the higher resolution of the companion RGB image. A single-shot variational approach is first put forward, which is effective as long as the target's reflectance is piecewise-constant. It is then shown that this dependency upon a specific reflectance model can be relaxed by focusing on a specific class of objects (e.g., faces), and delegate reflectance estimation to a deep neural network. A multi-shot strategy based on randomly varying lighting conditions is eventually discussed. It requires no training or prior on the reflectance, yet this comes at the price of a dedicated acquisition setup. Both quantitative and qualitative evaluations illustrate the effectiveness of the proposed methods on synthetic and real-world scenarios.	[Haefner, Bjoern; Verma, Alok; Cremers, Daniel] Tech Univ Munich, Dept Comp Sci, D-80333 Munich, Germany; [Peng, Songyou] Univ Illinois, Adv Digital Sci Ctr, Singapore 138602, Singapore; [Queau, Yvain] UMR CNRS, GREYC Lab, F-6072 Caen, France	Technical University of Munich; Centre National de la Recherche Scientifique (CNRS); Universite de Caen Normandie	Haefner, B (corresponding author), Tech Univ Munich, Dept Comp Sci, D-80333 Munich, Germany.	bjoern.haefner@tum.de; songyou.peng@adsc-create.edu.sg; alok.verma@tum.de; yvain.queau@ensicaen.fr; cremers@tum.de		Haefner, Bjoern/0000-0002-3178-3517				Adelson E. H., 1996, PERCEPTION BAYESIAN, P409, DOI DOI 10.1017/CBO9780511984037.014; Alldrin NG, 2007, PROC CVPR IEEE, P1822; Anderson R., 2011, MVA, P369; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Breuss M, 2012, SIAM J IMAGING SCI, V5, P311, DOI 10.1137/100815104; Chatterjee A, 2015, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2015.7298695; CHAUDHURI S, 2005, MOTION FREE SUPER RE; Choe G, 2017, INT J COMPUT VISION, V122, P1, DOI 10.1007/s11263-016-0937-y; Cristiani E, 2007, SIAM J NUMER ANAL, V45, P1979, DOI 10.1137/050637625; Diebel J., 2006, ADV NEURAL INFORM PR, P291; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204; Eigen D, 2014, ADV NEUR IN, V27; Falcone M., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P596; Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932; Ferstl D, 2015, IEEE I CONF COMP VIS, P513, DOI 10.1109/ICCV.2015.66; Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127; Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891; GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41; Goldlucke B, 2014, INT J COMPUT VISION, V106, P172, DOI 10.1007/s11263-013-0654-8; Graber G, 2015, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2015.7298649; Haefner B, 2018, PROC CVPR IEEE, P164, DOI 10.1109/CVPR.2018.00025; Han Y, 2013, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2013.204; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Horn B, 1970, THESIS; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; Hornacek M, 2013, PROC CVPR IEEE, P1123, DOI 10.1109/CVPR.2013.149; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang R, 2011, IEEE IMAGE PROC, P13, DOI 10.1109/ICIP.2011.6115701; Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22; Ikehata S, 2018, LECT NOTES COMPUT SC, V11219, P3, DOI 10.1007/978-3-030-01267-0_1; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Kim K, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P199, DOI 10.1109/ICCVW.2015.35; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Li BC, 2020, PATTERN RECOGN LETT, V130, P21, DOI 10.1016/j.patrec.2018.07.023; Li C, 2014, LECT NOTES COMPUT SC, V8693, P218, DOI 10.1007/978-3-319-10602-1_15; Li J, 2014, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2014.431; LIONS PL, 1993, NUMER MATH, V64, P323, DOI 10.1007/BF01388692; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Lu F, 2018, IEEE T PATTERN ANAL, V40, P221, DOI 10.1109/TPAMI.2017.2655525; Lu Z, 2013, INT J COMPUT VISION, V102, P18, DOI 10.1007/s11263-012-0589-5; Ma W.-C., 2007, PROC 18 EUR C RENDER, P183, DOI 10.2312/EGWR/EGSR07/183-194; Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6; Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338; Maier R, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P536, DOI 10.1109/3DV.2015.66; Mo ZP, 2018, PROC CVPR IEEE, P2936, DOI 10.1109/CVPR.2018.00310; MUMFORD D, 1994, GEOMETRY DRIVEN DIFF, P135; Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179; Or-Ell R, 2016, PROC CVPR IEEE, P4378, DOI 10.1109/CVPR.2016.474; Papadhimitri T, 2014, INT J COMPUT VISION, V107, P139, DOI 10.1007/s11263-013-0665-5; Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423; Peng SY, 2017, IEEE INT CONF COMP V, P2961, DOI 10.1109/ICCVW.2017.349; Queau Y., 2017, INT WORKSHOP ENERGY, P342; Queau Y, 2018, J MATH IMAGING VIS, V60, P576, DOI 10.1007/s10851-017-0773-x; Queau Y, 2017, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2017.45; Queau Y, 2015, J MATH IMAGING VIS, V52, P87, DOI 10.1007/s10851-014-0512-5; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Richter SR, 2015, PROC CVPR IEEE, P1128, DOI 10.1109/CVPR.2015.7298716; Riegler G, 2016, LECT NOTES COMPUT SC, V9907, P268, DOI 10.1007/978-3-319-46487-9_17; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053; Schmidt Mark, 2005, MINFUNC UNCONSTRAINE; Schuon S, 2009, PROC CVPR IEEE, P343, DOI 10.1109/CVPRW.2009.5206804; Sengupta S, 2018, PROC CVPR IEEE, P6296, DOI 10.1109/CVPR.2018.00659; Shen JB, 2011, PROC CVPR IEEE; Shi BX, 2019, IEEE T PATTERN ANAL, V41, P271, DOI 10.1109/TPAMI.2018.2799222; Shi J, 2017, PROC CVPR IEEE, P5844, DOI 10.1109/CVPR.2017.619; Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578; Strekalovskiy E, 2014, LECT NOTES COMPUT SC, V8690, P127, DOI 10.1007/978-3-319-10605-2_9; Tan P, 2008, IEEE T PATTERN ANAL, V30, P1460, DOI 10.1109/TPAMI.2007.70789; Trigeorgis G, 2017, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2017.44; Unger M, 2010, LECT NOTES COMPUT SC, V6376, P313; Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4; Werlberger M, 2009, P BRIT MACH VIS C; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Xie J, 2016, IEEE T IMAGE PROCESS, V25, P428, DOI 10.1109/TIP.2015.2501749; Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678; Xie L, 2019, VISUAL COMPUT, V35, P99, DOI 10.1007/s00371-018-1507-9; Yang M, 2017, AAAI CONF ARTIF INTE, P1626; Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhang YA, 2018, IEEE INT C COMPUT, P201, DOI 10.1109/CSE.2018.00035; Zollhofer M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766887	92	9	9	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2453	2464		10.1109/TPAMI.2019.2923621	http://dx.doi.org/10.1109/TPAMI.2019.2923621			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31226068	Green Submitted			2022-12-18	WOS:000567471300010
J	Lyu, X; Sun, WW; Wang, ZR; Liu, H; Yang, J; Cheng, G				Lyu, Xiang; Sun, Will Wei; Wang, Zhaoran; Liu, Han; Yang, Jian; Cheng, Guang			Tensor Graphical Model: Non-Convex Optimization and Statistical Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphical models; Estimation; Convergence; Testing; Sparse matrices; Covariance matrices; Asymptotic normality; hypothesis testing; optimality; rate of convergence	COVARIANCE ESTIMATION; CONFIDENCE-INTERVALS; VARIABLE SELECTION; ADAPTIVE LASSO; CONVERGENCE; LIKELIHOOD; TESTS; RATES; CONNECTIVITY; REGIONS	We consider the estimation and inference of graphical models that characterize the dependency structure of high-dimensional tensor-valued data. To facilitate the estimation of the precision matrix corresponding to each way of the tensor, we assume the data follow a tensor normal distribution whose covariance has a Kronecker product structure. A critical challenge in the estimation and inference of this model is the fact that its penalized maximum likelihood estimation involves minimizing a non-convex objective function. To address it, this paper makes two contributions: (i) In spite of the non-convexity of this estimation problem, we prove that an alternating minimization algorithm, which iteratively estimates each sparse precision matrix while fixing the others, attains an estimator with an optimal statistical rate of convergence. (ii) We propose a de-biased statistical inference procedure for testing hypotheses on the true support of the sparse precision matrices, and employ it for testing a growing number of hypothesis with false discovery rate (FDR) control. The asymptotic normality of our test statistic and the consistency of FDR control procedure are established. Our theoretical results are backed up by thorough numerical studies and our real applications on neuroimaging studies of Autism spectrum disorder and users' advertising click analysis bring new scientific findings and business insights. The proposed methods are encoded into a publicly available R package Tlasso.	[Lyu, Xiang] Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA; [Sun, Will Wei] Univ Miami, Dept Management Sci, Coral Gables, FL USA; [Wang, Zhaoran] Northwestern Univ, Dept Ind Engn & Management Sci, Evanston, IL 60208 USA; [Liu, Han] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA; [Liu, Han] Northwestern Univ, Dept Stat, Evanston, IL 60208 USA; [Yang, Jian] Yahoo Res, Sunnyvale, CA 94089 USA; [Cheng, Guang] Purdue Univ, Dept Stat, W Lafayette, IN 47906 USA	University of California System; University of California Berkeley; University of Miami; Northwestern University; Northwestern University; Northwestern University; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Lyu, X (corresponding author), Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA.	xianglyu@berkeley.edu; wsun@bus.miami.edu; zhaoranwang@gmail.com; hanliu@northwestern.edu; jianyang@oath.com; chengg@purdue.edu	Wang, Zhaoran/P-7113-2018		NSF CAREER Award [DMS1454377]; NSF [IIS1408910, IIS1332109, DMS-1712907, DMS-1811812, DMS-1821183]; NIH [R01MH102339, R01GM083084, R01HG06841]; Office of Naval Research [ONR N00014-18-2759]; Princeton ORFE Department	NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Office of Naval Research(Office of Naval Research); Princeton ORFE Department	Han Liu is grateful for the support of NSF CAREER Award DMS1454377, NSF IIS1408910, NSF IIS1332109, NIH R01MH102339, NIH R01GM083084, and NIH R01HG06841. Guang Cheng's research is sponsored by NSF DMS-1712907, DMS-1811812, DMS-1821183, and Office of Naval Research (ONR N00014-18-2759). Will Wei Sun was visiting Princeton and Guang Cheng was on sabbatical at Princeton while this work was carried out; Will Wei Sun and Guang Cheng would like to thank Princeton ORFE Department for their Hospitality and Support.	Agarwal A, 2016, SIAM J OPTIMIZ, V26, P2775, DOI 10.1137/140979861; [Anonymous], 2015, PROC C LEARN THEORY; ARORA S., 2014, ARXIV14010579; Arora S., 2014, C LEARNING THEORY, P779; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Bickel PJ, 2008, ANN STAT, V36, P2577, DOI 10.1214/08-AOS600; Cai TT, 2016, ANN STAT, V44, P455, DOI 10.1214/13-AOS1171; Chen XR, 2018, ARTIF CELL NANOMED B, V46, pS608, DOI 10.1080/21691401.2018.1431654; Chu P., 2016, STRUCTURE AWARE RANK, P413; Chu W., 2009, PROC 12 INT C ARTIF, V5, P89; Fan JQ, 2009, ANN APPL STAT, V3, P521, DOI 10.1214/08-AOAS215; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Ha S, 2015, EXP NEUROBIOL, V24, P273, DOI 10.5607/en.2015.24.4.273; Haeffele B, 2017, PROC IEEE C COMPUT V, P7331; Hardt M, 2014, ANN IEEE SYMP FOUND, P651, DOI 10.1109/FOCS.2014.75; Hardt Moritz, 2014, JMLR WORKSHOP C P, P703; He SY, 2014, J MULTIVARIATE ANAL, V128, P165, DOI 10.1016/j.jmva.2014.03.007; Hoff PD, 2016, BAYESIAN ANAL, V11, P627, DOI 10.1214/14-BA934; Hoff PD, 2011, BAYESIAN ANAL, V6, P179, DOI 10.1214/11-BA606; Hyde KL, 2010, HUM BRAIN MAPP, V31, P556, DOI 10.1002/hbm.20887; Jain P, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P665; Jankova J, 2015, ELECTRON J STAT, V9, P1205, DOI 10.1214/15-EJS1031; Jia JY, 2005, IEEE T PATTERN ANAL, V27, P36, DOI 10.1109/TPAMI.2005.20; Karatzoglou A, 2010, P 4 ACM C REC SYST, P79, DOI DOI 10.1145/1864708.1864727; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Lam C, 2009, ANN STAT, V37, P4254, DOI 10.1214/09-AOS720; Ledoux M, 2011, CLASS MATH, P1; Lee W, 2015, J MACH LEARN RES, V16, P1035; Leng CL, 2012, J AM STAT ASSOC, V107, P1187, DOI 10.1080/01621459.2012.706133; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Liu WD, 2014, ANN STAT, V42, P2003, DOI 10.1214/14-AOS1249; Liu WD, 2013, ANN STAT, V41, P2948, DOI 10.1214/13-AOS1169; Loh PL, 2017, ANN STAT, V45, P2455, DOI 10.1214/16-AOS1530; Nair A, 2013, BRAIN, V136, P1942, DOI 10.1093/brain/awt079; Netrapalli P., 2013, P ADV NEUR INF PROC, P2796; Rai P, 2014, PR MACH LEARN RES, V32, P1800; Ravikumar P, 2011, ELECTRON J STAT, V5, P935, DOI 10.1214/11-EJS631; Rendle Steffen, 2010, P 3 ACM INT C WEB SE, P81, DOI [DOI 10.1145/1718487.1718498, 10.1145/1718487.1718498]; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; Rudie JD, 2013, NEUROIMAGE-CLIN, V2, P79, DOI 10.1016/j.nicl.2012.11.006; Shen XT, 2012, J AM STAT ASSOC, V107, P223, DOI 10.1080/01621459.2011.645783; Shi R., 2015, ARXIV150406074; Sun J, 2015, 2015 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P407, DOI 10.1109/SAMPTA.2015.7148922; Sun Q., 2017, ARXIV170601158; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tsiligkaridis T, 2013, IEEE T SIGNAL PROCES, V61, P1743, DOI 10.1109/TSP.2013.2240157; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Van de Geer S, 2014, ANN STAT, V42, P1166, DOI 10.1214/14-AOS1221; Ventura J, 2012, CANADA AMONG NATION, P27; Wang YL, 2013, NEUROIMAGE, V74, P209, DOI 10.1016/j.neuroimage.2013.02.011; Wang ZR, 2014, ANN STAT, V42, P2164, DOI 10.1214/14-AOS1238; Xia Y, 2017, BIOMETRICS, V73, P780, DOI 10.1111/biom.12633; Xiong L., 2010, P SDM COL OH, P211; Xu ZH, 2012, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION APPLICATIONS (ICCIA 2012), P1678; Yi XY, 2014, PR MACH LEARN RES, V32, P613; Yin JX, 2012, J MULTIVARIATE ANAL, V107, P119, DOI 10.1016/j.jmva.2012.01.005; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Zahn JM, 2007, PLOS GENET, V3, P2326, DOI 10.1371/journal.pgen.0030201; Zhang CH, 2014, J R STAT SOC B, V76, P217, DOI 10.1111/rssb.12026; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhao QB, 2015, IEEE T PATTERN ANAL, V37, P1751, DOI 10.1109/TPAMI.2015.2392756; Zheng N, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P737; Zhou SH, 2014, ANN STAT, V42, P532, DOI 10.1214/13-AOS1187; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735	72	9	9	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					2024	2037		10.1109/TPAMI.2019.2907679	http://dx.doi.org/10.1109/TPAMI.2019.2907679			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30932830	hybrid, Green Submitted			2022-12-18	WOS:000545415400016
J	Tang, ZQ; Peng, X; Li, K; Metaxas, DN				Tang, Zhiqiang; Peng, Xi; Li, Kang; Metaxas, Dimitris N.			Towards Efficient U-Nets: A Coupled and Quantized Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stacked U-nets; dense connectivity; network quantization; efficient Al; human pose estimation; face alignment		In this paper, we propose to couple stacked U-Nets for efficient visual landmark localization. The key idea is to globally reuse features of the same semantic meanings across the stacked U-Nets. The feature reuse makes each U-Net light-weighted. Specially, we propose an order-K coupling design to trim off long-distance shortcuts, together with an iterative refinement and memory sharing mechanism. To further improve the efficiency, we quantize the parameters, intermediate features, and gradients of the coupled U-Nets to low bit-width numbers. We validate our approach in two tasks: human pose estimation and facial landmark localization. The results show that our approach achieves state-of-the-art localization accuracy but using similar to 70% fewer parameters, similar to 30% less inference time, similar to 98% less model size, and saving similar to 75% training memory compared with benchmark localizers.	[Tang, Zhiqiang; Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08901 USA; [Peng, Xi] SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA; [Li, Kang] Rutgers State Univ, Dept Orthopaed, New Jersey Med Sch, New Brunswick, NJ 08901 USA	Rutgers State University New Brunswick; State University of New York (SUNY) System; State University of New York (SUNY) Binghamton; Rutgers State University New Brunswick; Rutgers State University Medical Center	Peng, X (corresponding author), SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA.	zhiqiang.tang@rutgers.edu; xpeng@binghamton.edu; kl419@rutgers.edu; dnm@cs.rutgers.edu		Li, Kang/0000-0002-8136-9816	US National Science Foundation under grants: Cyber-Human Systems [1703883, 1763523]; INDUSTRY/UNIV COOP RES CENTERS CARTA [1747778]; Algorithms in the Field [1733843]; Multidisciplinary University Research Initiatives (MURI) [W911NF1610342]	US National Science Foundation under grants: Cyber-Human Systems; INDUSTRY/UNIV COOP RES CENTERS CARTA; Algorithms in the Field; Multidisciplinary University Research Initiatives (MURI)(MURI)	This work was partially supported by the US National Science Foundation under grants: Cyber-Human Systems (Grants #1703883 and #1763523), INDUSTRY/UNIV COOP RES CENTERS CARTA (Grant #1747778), Algorithms in the Field (Grant #1733843), and also partially funded by Multidisciplinary University Research Initiatives (MURI#W911NF1610342).	Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; [Anonymous], 2016, P 2016 BRIT MACH VIS; Begleiter R, 2004, J ARTIF INTELL RES, V22, P385, DOI 10.1613/jair.1491; Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64; Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400; Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen YH, 2017, AIP CONF PROC, V1812, DOI 10.1063/1.4975898; Chu Xiao, 2017, PROC CVPR IEEE, P1831, DOI DOI 10.1109/CVPR.2017.601; Courbariaux Matthieu, 2016, BINARIZED NEURAL NET; Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44; Glorot X., 2011, P 14 INT C ART INT S, P315; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hu PY, 2016, PROC CVPR IEEE, P5600, DOI 10.1109/CVPR.2016.604; Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156; Johnson Sam, 2010, BMVC, DOI [10.5244/C.24.12, DOI 10.5244/C.24.12]; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1; Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918; Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16; Liu F., 2018, IEEE TRAN PAGERN ANA; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Peng X, 2018, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2018.00237; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Pleiss G., 2017, ARXIV170706690; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Shi B., 2014, ARXIV14095230; Simonyan K., 2014, ARXIV170706990; Srivastava Rupesh Kumar, 2015, ADV NEURAL INFORM PR, P2377; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tang ZQ, 2018, LECT NOTES COMPUT SC, V11207, P348, DOI 10.1007/978-3-030-01219-9_21; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144; Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P52, DOI 10.1007/978-3-319-46454-1_4; Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P2116, DOI 10.1109/CVPRW.2017.263; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhang N, 2018, INT CONF INSTR MEAS, P403, DOI 10.1109/IMCCC.2018.00091; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou S., 2016, ARXIV160606160; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134	55	9	11	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					2038	2050		10.1109/TPAMI.2019.2907634	http://dx.doi.org/10.1109/TPAMI.2019.2907634			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30932829	hybrid			2022-12-18	WOS:000545415400017
J	Almatrafi, M; Baldwin, R; Aizawa, K; Hirakawa, K				Almatrafi, Mohammed; Baldwin, Raymond; Aizawa, Kiyoharu; Hirakawa, Keigo			Distance Surface for Event-Based Optical Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical imaging; Optical sensors; Cameras; Voltage control; Neuromorphics; Image edge detection; Surface treatment; Motion estimation; optical flow; dynamic vision sensor; neuromorphic camera	MOTION ESTIMATION	We propose DistSurf-OF, a novel optical flow method for neuromorphic cameras. Neuromorphic cameras (or event detection cameras) are an emerging sensor modality that makes use of dynamic vision sensors (DVS) to report asynchronously the log-intensity changes (called "events") exceeding a predefined threshold at each pixel. In absence of the intensity value at each pixel location, we introduce a notion of "distance surface"-the distance transform computed from the detected events-as a proxy for object texture. The distance surface is then used as an input to the intensity-based optical flow methods to recover the two dimensional pixel motion. Real sensor experiments verify that the proposed DistSurf-OF accurately estimates the angle and speed of each events.	[Almatrafi, Mohammed] Umm Al Qura Univ, Dept Elect & Commun Engn, Al Lith 28434, Saudi Arabia; [Baldwin, Raymond; Hirakawa, Keigo] Univ Dayton, Dept Elect & Comp Engn, Dayton, OH 45469 USA; [Aizawa, Kiyoharu] Univ Tokyo, Bunkyo City, Tokyo 1138656, Japan	Umm Al Qura University; University of Dayton; University of Tokyo	Almatrafi, M (corresponding author), Umm Al Qura Univ, Dept Elect & Commun Engn, Al Lith 28434, Saudi Arabia.	mmmatrafi@uqu.edu.sa; baldwinr2@udayton.edu; aizawa@hal.t.u-tokyo.ac.jp; khirakawa1@udayton.edu		Almatrafi, Mohammed/0000-0002-6701-4250	Ford University Research Program; Japan National Institute of Information and Communications Technology	Ford University Research Program; Japan National Institute of Information and Communications Technology	This work was supported in part by Ford University Research Program and the Japan National Institute of Information and Communications Technology.	Almatrafi M, 2020, IEEE T COMPUT IMAG, V6, P396, DOI 10.1109/TCI.2019.2948787; Alzugaray I, 2018, IEEE ROBOT AUTOM LET, V3, P3177, DOI 10.1109/LRA.2018.2849882; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1; Baldwin RW, 2019, LECT NOTES COMPUT SC, V11663, P395, DOI 10.1007/978-3-030-27272-2_35; Bao LC, 2014, PROC CVPR IEEE, P3534, DOI 10.1109/CVPR.2014.452; BARDOW P, 2016, PROC CVPR IEEE, P884, DOI DOI 10.1109/CVPR.2016.102; Barranco F, 2014, P IEEE, V102, P1537, DOI 10.1109/JPROC.2014.2347207; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Benosman R, 2014, IEEE T NEUR NET LEAR, V25, P407, DOI 10.1109/TNNLS.2013.2273537; Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715; Brosch T, 2015, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fnins.7015.00137, 10.3389/fnins.2015.00137]; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Chen HJ, 2020, IEEE T COMPUT IMAG, V6, P276, DOI 10.1109/TCI.2019.2948755; Clady X, 2017, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00594; Delbruck T, 2018, P S SEC LIF EL ADV E, P21; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844; Gallego G, 2019, PROC CVPR IEEE, P12272, DOI 10.1109/CVPR.2019.01256; Gallego G, 2018, PROC CVPR IEEE, P3867, DOI 10.1109/CVPR.2018.00407; Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944; Gehrig D, 2018, LECT NOTES COMPUT SC, V11216, P766, DOI 10.1007/978-3-030-01258-8_46; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Karam C, 2019, IEEE SIGNAL PROC LET, V26, P853, DOI 10.1109/LSP.2019.2910466; Kim Hanme, 2014, BRIT MACH VIS C BMVC, DOI [10.5244/C.28.26, DOI 10.5244/C.28.26]; Kroeger T, 2016, LECT NOTES COMPUT SC, V9908, P471, DOI 10.1007/978-3-319-46493-0_29; Lagorce X, 2017, IEEE T PATTERN ANAL, V39, P1346, DOI 10.1109/TPAMI.2016.2574707; Lee JH, 2012, IEEE IMAGE PROC, P1957, DOI 10.1109/ICIP.2012.6467270; Liu Min, 2018, ARXIV180503988; Liu MS, 2017, IEEE GLOBE WORK; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Meister S, 2018, AAAI CONF ARTIF INTE, P7251; Memin E, 2002, INT J COMPUT VISION, V46, P129, DOI 10.1023/A:1013539930159; Memin E, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P933, DOI 10.1109/ICCV.1998.710828; Mueggler E, 2018, IEEE T ROBOT, V34, P1425, DOI 10.1109/TRO.2018.2858287; Padala V, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00118; Paredes-Valles F, 2020, IEEE T PATTERN ANAL, V42, P2051, DOI 10.1109/TPAMI.2019.2903179; Rueckauer B., 2016, EVALUATION EVENT BAS; Rueckauer B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00176; Sironi A, 2018, PROC CVPR IEEE, P1731, DOI 10.1109/CVPR.2018.00186; Stoffregen T., 2017, P AUSTR C ROB AUT AC, P52; Stoffregen T, 2019, IEEE I CONF COMP VIS, P7243, DOI 10.1109/ICCV.2019.00734; Sun DQ, 2014, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2014.144; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Wedel A., 2008, 2008 23 INT C IM VIS, P1; Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2; Ye C., 2018, ARXIV180908625; Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1; Zhu AZ, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Zhu AZ, 2019, PROC CVPR IEEE, P989, DOI 10.1109/CVPR.2019.00108	55	9	9	4	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1547	1556		10.1109/TPAMI.2020.2986748	http://dx.doi.org/10.1109/TPAMI.2020.2986748			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32305894	Green Submitted			2022-12-18	WOS:000542967200002
J	Bhandari, A; Conde, MH; Loffeld, O				Bhandari, Ayush; Conde, Miguel Heredia; Loffeld, Otmar			One-Bit Time-Resolved Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Imaging; Time measurement; Image resolution; Sensors; Quantization (signal); Current measurement; Photonics; Computational imaging; inverse problems; one-bit sampling; sparse recovery and time-resolved imaging	SIGNALS	Spatial resolution is one of the fundamental bottlenecks in the area of time-resolved imaging. Since each pixel measures a scene-dependent time profile, there is a technological limit on the size of pixel arrays that can be simultaneously used to perform measurements. To overcome this barrier, in this paper, we propose a low-complexity, one-bit sensing scheme. On the data capture front, the time-resolved measurements are mapped to a sequence of +1 and -1. This leads to an extremely simple implementation and at the same time poses a new form of information loss. On the image recovery front, our one-bit time-resolved imaging scheme is complemented with a non-iterative recovery algorithm that can handle the case of single and multiple light paths. Extensive computer simulations and physical experiments benchmarked against conventional Time-of-Flight imaging data corroborate our theoretical framework. Thus, our low-complexity alternative to time-resolved imaging can indeed potentially lead to a new imaging methodology.	[Bhandari, Ayush; Conde, Miguel Heredia] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England; [Conde, Miguel Heredia; Loffeld, Otmar] Univ Siegen, Ctr Sensor Syst ZESS, D-57076 Siegen, Germany	Imperial College London; Universitat Siegen	Bhandari, A (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England.	ayush@alum.MIT.edu; heredia@zess.uni-siegen.de; loffeld@zess.uni-siegen.de	Bhandari, Ayush/GXF-5212-2022; Conde, Miguel Heredia/AAO-1497-2020; Dr. Loffeld, Otmar/A-2232-2009	Conde, Miguel Heredia/0000-0001-5218-0822; Bhandari, Ayush/0000-0002-4485-2569; Dr. Loffeld, Otmar/0000-0002-5413-6582	UK Research and Innovation council's Future Leaders Fellowship Program (MRC) [MR/S034897/1]; UKRI [MR/S034897/1] Funding Source: UKRI	UK Research and Innovation council's Future Leaders Fellowship Program (MRC); UKRI	The work of A. Bhandari was supported by the UK Research and Innovation council's Future Leaders Fellowship Program (MRC Fellowship Award no. MR/S034897/1). The work of M. Heredia Conde was performed in part and over several visits at Imperial College London, where he is a visiting researcher. He thanks the EEE department for hospitality.	Aziz PM, 1996, IEEE SIGNAL PROC MAG, V13, P61, DOI 10.1109/79.482138; Bamji CS, 2018, ISSCC DIG TECH PAP I, P94; Bhandari A, 2016, IEEE SIGNAL PROC MAG, V33, P45, DOI 10.1109/MSP.2016.2582218; Bhandari A, 2016, INT CONF ACOUST SPEE, P4009, DOI 10.1109/ICASSP.2016.7472430; Bhandari A, 2015, OPTICA, V2, P965, DOI 10.1364/OPTICA.2.000965; Bhandari A, 2014, OPT LETT, V39, P1705, DOI 10.1364/OL.39.001705; Conde Miguel Heredia, 2019, 2019 IEEE SENSORS, DOI 10.1109/SENSORS43011.2019.8956637; Conde M.H., 2017, COMPRESSIVE SENSING; Daubechies I, 2003, ANN MATH, V158, P679, DOI 10.4007/annals.2003.158.679; Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060; Gupta M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3152155; Gupta M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2735702; Hart A, 2009, IEEE J SOLID-ST CIRC, V44, P1401, DOI 10.1109/JSSC.2009.2015852; Heide F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766953; Heide F, 2014, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2014.418; Heide F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516974; Hernandez-Marin S, 2007, IEEE T PATTERN ANAL, V29, P2170, DOI 10.1109/TPAMI.2007.1122; HUA Y, 1990, IEEE T ACOUST SPEECH, V38, P814, DOI 10.1109/29.56027; Kadambi A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2836164; Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428; Kirmani A, 2014, SCIENCE, V343, P58, DOI 10.1126/science.1246775; Li L, 2000, ANN STAT, V28, P1279; Luh L, 2005, IEEE CUST INTEGR CIR, P387; Mo JH, 2015, IEEE T SIGNAL PROCES, V63, P5498, DOI 10.1109/TSP.2015.2455527; O'Toole M, 2017, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2017.246; O'Toole M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601103; Paveau M.-A., 2017, UNDERSTANDING DELTAS, V2nd; Satat G, 2018, IEEE INT CONF COMPUT; Tadano R, 2016, IEEE IMAGE PROC, P1564, DOI 10.1109/ICIP.2016.7532621; Velten A., 2012, NATURE COMMUNICATION, V3, P1; Vetterli M, 2002, IEEE T SIGNAL PROCES, V50, P1417, DOI 10.1109/TSP.2002.1003065	31	9	9	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1630	1641		10.1109/TPAMI.2020.2986950	http://dx.doi.org/10.1109/TPAMI.2020.2986950			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32305900				2022-12-18	WOS:000542967200009
J	Mosinska, A; Kozinski, M; Fua, P				Mosinska, Agata; Kozinski, Mateusz; Fua, Pascal			Joint Segmentation and Path Classification of Curvilinear Structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Image edge detection; Roads; Task analysis; Decoding; Feature extraction; Computer architecture; Deep convolutional neural networks; multi-task learning; segmentation; delineation; curvilinear structures; road detection; neuron tracing	CENTERLINE EXTRACTION; NETWORKS	Detection of curvilinear structures in images has long been of interest. One of the most challenging aspects of this problem is inferring the graph representation of the curvilinear network. Most existing delineation approaches first perform binary segmentation of the image and then refine it using either a set of hand-designed heuristics or a separate classifier that assigns likelihood to paths extracted from the pixel-wise prediction. In our work, we bridge the gap between segmentation and path classification by training a deep network that performs those two tasks simultaneously. We show that this approach is beneficial because it enforces consistency across the whole processing pipeline. We apply our approach on roads and neurons datasets.	[Mosinska, Agata; Kozinski, Mateusz; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Kozinski, M (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland.	agata.mosinska@epfl.ch; mateusz.kozinski@gmail.com; pascal.fua@epfl.ch		Kozinski, Mateusz/0000-0002-3187-518X	Swiss National Science Foundation; ERC project FastProof	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); ERC project FastProof	Agata Mosinska received support from the Swiss National Science Foundation. Mateusz Kozinski has been supported by the ERC project FastProof.	[Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], 2012, ICML 12 P 29 INT C I; [Anonymous], [No title captured]; Apostolova LG, 2012, ALZ DIS ASSOC DIS, V26, P17, DOI 10.1097/WAD.0b013e3182163b62; Arganda-Carreras I, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00142; Bastani F, 2018, PROC CVPR IEEE, P4720, DOI 10.1109/CVPR.2018.00496; Breitenreicher Dirk, 2013, Inf Process Med Imaging, V23, P328, DOI 10.1007/978-3-642-38868-2_28; Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36; Ghafoorian M, 2019, LECT NOTES COMPUT SC, V11129, P256, DOI 10.1007/978-3-030-11009-3_15; Huang X, 2009, INT J REMOTE SENS, V30, P1977, DOI 10.1080/01431160802546837; Law MWK, 2008, LECT NOTES COMPUT SC, V5305, P368, DOI 10.1007/978-3-540-88693-8_27; Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17; Mattyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372; Mnih V, 2013, MACHINE LEARNING AER; Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16; Montoya-Zegarra JA, 2014, LECT NOTES COMPUT SC, V8753, P212, DOI 10.1007/978-3-319-11752-2_17; Mosinska Agata, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P165, DOI 10.1007/978-3-319-66185-8_19; Mosinska A, 2018, PROC CVPR IEEE, P3136, DOI 10.1109/CVPR.2018.00331; Peng HC, 2011, BIOINFORMATICS, V27, pI239, DOI 10.1093/bioinformatics/btr237; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Simonyan K, 2015, 3 INT C LEARN REPR I; Sironi A, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2462363; Turetken E, 2013, IEEE I CONF COMP VIS, P1553, DOI 10.1109/ICCV.2013.196; Turetken E, 2012, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2012.6247722; Turetken E, 2016, IEEE T PATTERN ANAL, V38, P2515, DOI 10.1109/TPAMI.2016.2519025; Wegner JD, 2013, PROC CVPR IEEE, P1698, DOI 10.1109/CVPR.2013.222; Wegner JD, 2015, ISPRS J PHOTOGRAMM, V108, P128, DOI 10.1016/j.isprsjprs.2015.07.002; Wu DJ, 2012, PROC CVPR IEEE, P980, DOI 10.1109/CVPR.2012.6247774; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yang J, 2019, NEUROINFORMATICS, V17, P185, DOI 10.1007/s12021-018-9392-y; Zhou Zhi, 2018, Brain Inform, V5, P3, DOI 10.1186/s40708-018-0081-2	34	9	9	6	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1515	1521		10.1109/TPAMI.2019.2921327	http://dx.doi.org/10.1109/TPAMI.2019.2921327			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	31180837	Green Submitted			2022-12-18	WOS:000535615700016
J	Favreau, JD; Lafarge, F; Bousseau, A; Auvolat, A				Favreau, Jean-Dominique; Lafarge, Florent; Bousseau, Adrien; Auvolat, Alex			Extracting Geometric Structures in Images with Delaunay Point Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Perturbation methods; Markov processes; Task analysis; Image segmentation; Three-dimensional displays; Monte Carlo methods; Spatial point process; delaunay triangulation; geometric structures; line network extraction; object contouring; image compression	LINEAR SPLINES; RECONSTRUCTION; SCENES	We introduce Delaunay Point Processes, a framework for the extraction of geometric structures from images. Our approach simultaneously locates and groups geometric primitives (line segments, triangles) to form extended structures (line networks, polygons) for a variety of image analysis tasks. Similarly to traditional point processes, our approach uses Markov Chain Monte Carlo to minimize an energy that balances fidelity to the input image data with geometric priors on the output structures. However, while existing point processes struggle to model structures composed of inter-connected components, we propose to embed the point process into a Delaunay triangulation, which provides high-quality connectivity by construction. We further leverage key properties of the Delaunay triangulation to devise a fast Markov Chain Monte Carlo sampler. We demonstrate the flexibility of our approach on a variety of applications, including line network extraction, object contouring, and mesh-based image compression.	[Favreau, Jean-Dominique; Lafarge, Florent; Bousseau, Adrien; Auvolat, Alex] Inria Sophia Antipolis, F-06902 Valbonne, France		Lafarge, F (corresponding author), Inria Sophia Antipolis, F-06902 Valbonne, France.	jean-dominique.favreau@inria.fr; Florent.Lafarge@inria.fr; adrien.bousseau@inria.fr; alex.auvolat-bernstein@inria.fr		Favreau, Jean-Dominique/0000-0003-3768-3602	ERC [D3 (ERC-2016-STG 714221)]	ERC(European Research Council (ERC)European Commission)	This work was supported in part by the ERC starting grant D3 (ERC-2016-STG 714221) and by research and software donations from Adobe. Special thanks to Dengfeng Chai and Liuyun Duan for the fruitful discussions.	Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520; BADDELEY A, 1989, INT STAT REV, V57, P89, DOI 10.2307/1403381; Baddeley A.J., 1993, J APPL STAT, V20, P231, DOI [10.1080/02664769300000065, DOI 10.1080/02664769300000065]; Bertin E., 1999, STOCH MODELS, V15, P181; Bougleux S, 2009, IEEE I CONF COMP VIS, P2343, DOI 10.1109/ICCV.2009.5459425; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Castrejon L, 2017, PROC CVPR IEEE, P4485, DOI 10.1109/CVPR.2017.477; Chai DF, 2013, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2013.247; Daley D.J., 2008, INTRO THEORY POINT P, V2; de Goes F, 2011, COMPUT GRAPH FORUM, V30, P1593, DOI 10.1111/j.1467-8659.2011.02033.x; Demaret L, 2006, IEEE SIGNAL PROC LET, V13, P281, DOI 10.1109/LSP.2006.870358; Demaret L, 2006, SIGNAL PROCESS, V86, P1604, DOI 10.1016/j.sigpro.2005.09.003; Descombes X, 2011, STOCHASTIC GEOMETRY; Drot S, 2002, INT C PATT RECOG, P913, DOI 10.1109/ICPR.2002.1048453; Duan L, 2015, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2015.7298931; Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946; Gai M, 2016, VISUAL COMPUT, V32, P491, DOI 10.1007/s00371-015-1082-2; Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52; Kim B, 2018, COMPUT GRAPH FORUM, V37, P329, DOI 10.1111/cgf.13365; Kluszczynski R, 2007, ANN I STAT MATH, V59, P465, DOI 10.1007/s10463-006-0062-8; Labatut P, 2007, IEEE I CONF COMP VIS, P504; Lacoste C, 2005, IEEE T PATTERN ANAL, V27, P1568, DOI 10.1109/TPAMI.2005.206; Lafarge F, 2010, IEEE T PATTERN ANAL, V32, P1597, DOI 10.1109/TPAMI.2009.152; Levinshtein A, 2010, LECT NOTES COMPUT SC, V6312, P480, DOI 10.1007/978-3-642-15552-9_35; Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58; Liao PS, 2001, J INF SCI ENG, V17, P713; Liao ZC, 2012, IEEE T VIS COMPUT GR, V18, P1858, DOI 10.1109/TVCG.2012.76; Mallat S., 2008, WAVELET TOUR SIGNAL; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mattyus G, 2015, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2015.197; Mostegel C, 2017, PROC CVPR IEEE, P2501, DOI 10.1109/CVPR.2017.268; Noris G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421640; Ortner M, 2007, INT J COMPUT VISION, V72, P107, DOI 10.1007/s11263-005-5033-7; PESKUN PH, 1973, BIOMETRIKA, V60, P607; Pham TT, 2016, PROC CVPR IEEE, P2837, DOI 10.1109/CVPR.2016.310; Ren XF, 2005, IEEE I CONF COMP VIS, P1214; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; SALAMON P, 2002, SIAM MONOGRAPHS MATH; Sun KQ, 2007, LECT NOTES COMPUT SC, V4679, P467; Sun XL, 2014, LECT NOTES COMPUT SC, V8694, P317, DOI 10.1007/978-3-319-10599-4_21; The CGAL Project, 2017, CGAL USER REFERENCE, V4th; Turetken E, 2013, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2013.238; Utasi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3385, DOI 10.1109/CVPR.2011.5995699; VANLIESHOUT MNM, 1994, ADV APPL PROBAB, V26, P281, DOI 10.1017/S0001867800026197; Verdie Y, 2014, INT J COMPUT VISION, V106, P57, DOI 10.1007/s11263-013-0641-0; Wegner JD, 2013, PROC CVPR IEEE, P1698, DOI 10.1109/CVPR.2013.222; Wu ST, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P60, DOI 10.1109/SIBGRA.2003.1240992; Zhang ZQ, 2012, PROC CVPR IEEE, P3266, DOI 10.1109/CVPR.2012.6248063	50	9	9	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					837	850		10.1109/TPAMI.2018.2890586	http://dx.doi.org/10.1109/TPAMI.2018.2890586			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30605093	Green Submitted			2022-12-18	WOS:000526541100006
J	Liao, ZB; Drummond, T; Reid, I; Carneiro, G				Liao, Zhibin; Drummond, Tom; Reid, Ian; Carneiro, Gustavo			Approximate Fisher Information Matrix to Characterize the Training of Deep Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Machine learning; Neural networks; Computational modeling; Convergence; Linear programming; Testing; Machine learning; deep learning; neural networks; stochastic gradient descent; Fisher information matrix; neural network training characterisation	OPTIMIZATION METHODS	In this paper, we introduce a novel methodology for characterizing the performance of deep learning networks (ResNets and DenseNet) with respect to training convergence and generalization as a function of mini-batch size and learning rate for image classification. This methodology is based on novel measurements derived from the eigenvalues of the approximate Fisher information matrix, which can be efficiently computed even for high capacity deep models. Our proposed measurements can help practitioners to monitor and control the training process (by actively tuning the mini-batch size and learning rate) to allow for good training convergence and generalization. Furthermore, the proposed measurements also allow us to show that it is possible to optimize the training process with a new dynamic sampling training approach that continuously and automatically change the mini-batch size and learning rate during the training process. Finally, we show that the proposed dynamic sampling training approach has a faster training time and a competitive classification accuracy compared to the current state of the art.	[Liao, Zhibin; Reid, Ian; Carneiro, Gustavo] Univ Adelaide, Australian Ctr Robot Vis, Adelaide, SA 5005, Australia; [Drummond, Tom] Monash Univ, Australian Ctr Robot Vis, Clayton, Vic 3800, Australia	Australian Centre for Robotic Vision; University of Adelaide; Monash University	Liao, ZB (corresponding author), Univ Adelaide, Australian Ctr Robot Vis, Adelaide, SA 5005, Australia.	zhibin.liao@adelaide.edu.au; tom.drummond@monash.edu; ian.reid@adelaide.edu.au; gustavo.carneiro@adelaide.edu.au	; Drummond, Tom/A-4696-2011	Reid, Ian/0000-0001-7790-6423; Drummond, Tom/0000-0001-8204-5904; Carneiro, Gustavo/0000-0002-5571-6220	Australian Research Council [DP180103232, CE140100016, FL130100102]	Australian Research Council(Australian Research Council)	This work was partially edited while Zhibin Liao was a postdoctoral research fellow with the Robotics and Control Laboratory at the University of British Columbia. This work was support by the Australian Research Council through grants DP180103232, CE140100016, and FL130100102.	Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], 2017, ARXIV171011258; [Anonymous], P NIPS WORKSH DEEP L; Bertsekas DP, 1996, SIAM J OPTIMIZ, V6, P807, DOI 10.1137/S1052623494268522; Bottou L, 2018, SIAM REV, V60, P223, DOI 10.1137/16M1080173; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Byrd RH, 2012, MATH PROGRAM, V134, P127, DOI 10.1007/s10107-012-0572-5; Chaudhari Pratik, 2017, INT C LEARN REPR, P4; Collobert R., 2011, NIPS; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Fletcher R., 2013, PRACTICAL METHODS OP; Friedlander MP, 2012, SIAM J SCI COMPUT, V34, pA1380, DOI 10.1137/110830629; Goodfellow I. J., 2015, PROC INT C LEARN REP, P1; Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Huang GL, 2017, IEEE ICC; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jastrzebski S, 2018, LECT NOTES COMPUT SC, V11141, P392, DOI 10.1007/978-3-030-01424-7_39; Keskar N.S., 2017, ICLR; King DB, 2015, ACS SYM SER, V1214, P1; Kiros R, 2013, ARXIV13013641, P1; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee J. D., 2016, C LEARN THEOR, P1246; Martens J., 2010, P 27 INT C MACH LEAR, P735; Martens James, 2014, NEW INSIGHTS PERSPEC; Nair V., 2010, ICML, P807; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sagun L., 2018, P 6 INT C LEARN REPR; Sagun L, 2016, EIGENVALUES HESSIAN; Schraudolph NN, 2001, LECT NOTES COMPUT SC, V2130, P19; Smith S. L., 2018, ICLR 2018, P1; Soudry D., 2016, ARXIV PREPRINT ARXIV; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Wilkinson JH., 1965, ALGEBRAIC EIGENVALUE; Zeiler M.D., 2012, ADADELTA ADAPTIVE LE, DOI DOI 10.48550/ARXIV.1212.5701	44	9	9	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					15	26		10.1109/TPAMI.2018.2876413	http://dx.doi.org/10.1109/TPAMI.2018.2876413			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30334782				2022-12-18	WOS:000502294300002
J	Diaz, M; Ferrer, MA; Quintana, JJ				Diaz, Moises; Ferrer, Miguel A.; Quintana, Jose J.			Anthropomorphic Features for On-Line Signatures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Joints; Feature extraction; Bones; Elbow; Shoulder; Manipulators; Wrist; On-line signature verification; anthropomorphic features; biometrics; performance evaluation; virtual skeletal arm (VSA)	SCORE NORMALIZATION; DYNAMIC SIGNATURE; VERIFICATION; SYSTEM; RECOGNITION	Many features have been proposed in on-line signature verification. Generally, these features rely on the position of the on-line signature samples and their dynamic properties, as recorded by a tablet. This paper proposes a novel feature space to describe efficiently on-line signatures. Since producing a signature requires a skeletal arm system and its associated muscles, the new feature space is based on characterizing the movement of the shoulder, the elbow and the wrist joints when signing. As this motion is not directly obtained from a digital tablet, the new features are calculated by means of a virtual skeletal arm (VSA) model, which simulates the architecture of a real arm and forearm. Specifically, the VSA motion is described by its 3D joint position and its joint angles. These anthropomorphic features are worked out from both pen position and orientation through the VSA forward and direct kinematic model. The anthropomorphic features & x2019; robustness is proved by achieving state-of-the-art performance with several verifiers and multiple benchmarks on third party signature databases, which were collected with different devices and in different languages and scripts.	[Diaz, Moises] Univ Atlantico Medio, Las Palmas Gran Canaria 35017, Spain; [Ferrer, Miguel A.; Quintana, Jose J.] Univ Las Palmas Gran Canaria, Las Palmas Gran Canaria 35017, Spain	Universidad de Las Palmas de Gran Canaria	Diaz, M (corresponding author), Univ Atlantico Medio, Las Palmas Gran Canaria 35017, Spain.	moises.diaz@atlanticomedio.es; miguelangel.ferrer@ulpgc.es; josejuan.quintana@ulpgc.es	Diaz, Moises/L-3637-2013; Quintana, Jose J./AAA-6790-2019; Ferrer, Miguel/AFU-8286-2022; Ferrer, Miguel A A/L-3863-2013	Diaz, Moises/0000-0003-3878-3867; Quintana, Jose J./0000-0003-1166-6257; Ferrer, Miguel A A/0000-0002-2924-1225	Spanish government's MIMECO [TEC2016-77791-C4-1-R]; European Union FEDER program/funds	Spanish government's MIMECO; European Union FEDER program/funds	The authors would like to thank Jose Antonio Santana Segura, laboratory technician at Department of Automatic and Electronic Engineering at the Universidad de Las Palmas de Gran Canaria, for his support during the experiments with the ABB IRB 120 robot. This study was funded by the Spanish government's MIMECO TEC2016-77791-C4-1-R research project and European Union FEDER program/funds.	Ansari AQ, 2014, IET BIOMETRICS, V3, P113, DOI 10.1049/iet-bmt.2012.0048; Corke P., 2011, INROBOTICVISION; Craig J. J, 2005, INTRO ROBOTICS MECH, V3; Diaz M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3274658; Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419; Diaz M, 2015, PROC INT CONF DOC, P631, DOI 10.1109/ICDAR.2015.7333838; Ferrer MA, 2018, IEEE T CYBERNETICS, V48, P2896, DOI 10.1109/TCYB.2017.2751740; Ferrer MA, 2017, IEEE T PATTERN ANAL, V39, P1041, DOI 10.1109/TPAMI.2016.2582167; Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981; Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012; Fischer A, 2017, IEEE T HUM-MACH SYST, V47, P169, DOI 10.1109/THMS.2016.2634922; Fischer A, 2015, PROC INT CONF DOC, P241, DOI 10.1109/ICDAR.2015.7333760; Galbally J, 2015, PATTERN RECOGN, V48, P2921, DOI 10.1016/j.patcog.2015.03.019; Guru DS, 2017, EXPERT SYST APPL, V80, P232, DOI 10.1016/j.eswa.2017.03.024; Guru DS, 2009, IEEE T PATTERN ANAL, V31, P1059, DOI 10.1109/TPAMI.2008.302; Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013; Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x; Lei HS, 2005, PATTERN RECOGN LETT, V26, P2483, DOI 10.1016/j.patrec.2005.05.005; Liu YS, 2015, IEEE T CYBERNETICS, V45, P2498, DOI 10.1109/TCYB.2014.2375959; Mall G, 2001, FORENSIC SCI INT, V117, P23, DOI 10.1016/S0379-0738(00)00445-X; Martinez-Diaz M, 2014, IET BIOMETRICS, V3, P267, DOI 10.1049/iet-bmt.2013.0081; Muramatsu D, 2007, LECT NOTES COMPUT SC, V4642, P503; Netter F.H., 1989, ATLAS HUMAN ANATOMY; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; Pirlo G, 2015, IEEE T HUM-MACH SYST, V45, P805, DOI 10.1109/THMS.2015.2443050; Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472; Sharma A, 2018, IEEE T CYBERNETICS, V48, P611, DOI 10.1109/TCYB.2017.2647826; Sharma A, 2017, IEEE T INF FOREN SEC, V12, P705, DOI 10.1109/TIFS.2016.2632063; Sharma A, 2016, PATTERN RECOGN LETT, V84, P22, DOI 10.1016/j.patrec.2016.07.015; Uicker J.J., 1964, J APPL MECH, V31, P309, DOI [10.1115/1.3629602, DOI 10.1115/1.3629602]	32	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2807	2819		10.1109/TPAMI.2018.2869163	http://dx.doi.org/10.1109/TPAMI.2018.2869163			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30207948				2022-12-18	WOS:000498677600002
J	Tanaka, K; Mukaigawa, Y; Funatomi, T; Kubo, H; Matsushita, Y; Yagi, Y				Tanaka, Kenichiro; Mukaigawa, Yasuhiro; Funatomi, Takuya; Kubo, Hiruyuki; Matsushita, Yasuyuki; Yagi, Yasushi			Material Classification from Time-of-Flight Distortions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Distortion measurement; Distortion; Time-domain analysis; Optical distortion; Optical imaging; Frequency measurement; Alternative sensor; subsurface scattering; time-of-flight camera; temporal point spread functions		This paper presents a material classification method using an off-the-shelf Time-of-Flight (ToF) camera. The proposed method is built upon a key observation that the depth measurement by a ToF camera is distorted for objects with certain materials, especially with translucent materials. We show that this distortion is due to the variation of time domain impulse responses across materials and also due to the measurement mechanism of the ToF cameras. Specifically, we reveal that the amount of distortion varies according to the modulation frequency of the ToF camera, the object material, and the distance between the camera and object. Our method uses the depth distortion of ToF measurements as a feature for classification and achieves material classification of a scene. Effectiveness of the proposed method is demonstrated by numerical evaluations and real-world experiments, showing its capability of material classification, even for visually indistinguishable objects.	[Tanaka, Kenichiro; Mukaigawa, Yasuhiro; Funatomi, Takuya; Kubo, Hiruyuki] Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Nara 6300192, Japan; [Matsushita, Yasuyuki] Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan; [Yagi, Yasushi] Osaka Univ, Inst Sci & Ind Res, Suita, Osaka 5670047, Japan	Nara Institute of Science & Technology; Osaka University; Osaka University	Tanaka, K (corresponding author), Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Nara 6300192, Japan.	ktanaka@is.naist.jp; mukaigawa@is.naist.jp; funatomi@is.naist.jp; hkubo@is.naist.jp; yasumat@ist.osaka-u.ac.jp; yagi@am.sanken.osaka-u.ac.jp	Kubo, Hiroyuki/AAS-1487-2021; Funatomi, Takuya/K-5919-2018	Kubo, Hiroyuki/0000-0002-7061-7941; Funatomi, Takuya/0000-0001-5588-5932; Matsushita, Yasuyui/0000-0002-1935-4752	JSPS KAKEN [JP18H03265, JP18K19822]; JST CREST [JPMJCR1764]	JSPS KAKEN; JST CREST(Japan Science & Technology Agency (JST)Core Research for Evolutional Science and Technology (CREST))	We thank all anonymous reviewers who gave us various insightful and constructive comments. This work is partly supported by JSPS KAKEN JP18H03265, JP18K19822, and JST CREST JPMJCR1764.	ABRAMSON N, 1978, OPT LETT, V3, P121, DOI 10.1364/OL.3.000121; Bhandari Ayush, 2014, IEEE Sensors 2014. Proceedings, P614, DOI 10.1109/ICSENS.2014.6985073; Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54; Davis A, 2015, PROC CVPR IEEE, P5335, DOI 10.1109/CVPR.2015.7299171; Dorrington A. A., 2011, C 3 DIM IM INT MEAS, P2; Freeman D., 2014, PSYCHOL MED 1 VIEW; Fuchs Stefan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3583, DOI 10.1109/ICPR.2010.874; Gkioulekas I, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766928; Godbaz J. P., 2012, SPIE, V8296, P1; Godbaz J.P., 2013, TOF RANGE IMAGING CA, P91; Gupta M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2735702; HEIDE F, 2013, ACM T GRAPHIC, V32; Heide F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766953; Heide F, 2014, OPT EXPRESS, V22, P26338, DOI 10.1364/OE.22.026338; Heide F, 2014, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2014.418; Jarabo A, 2017, VIS INFORM, V1, P65, DOI 10.1016/j.visinf.2017.01.008; Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661251; Jimenez D, 2012, PROC CVPR IEEE, P893, DOI 10.1109/CVPR.2012.6247763; Kadambi A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2836164; Kadambi A, 2016, PROC CVPR IEEE, P893, DOI 10.1109/CVPR.2016.103; Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428; Kakue T, 2012, IEEE J SEL TOP QUANT, V18, P479, DOI 10.1109/JSTQE.2011.2147281; Kirmani A, 2013, IEEE INT CON MULTI; Kirmani A, 2011, INT J COMPUT VISION, V95, P13, DOI 10.1007/s11263-011-0470-y; Kitano K., 2017, IPSJ T COMPUT VIS AP, V9, P15, DOI [10.1186/s41074-017-0026-3, DOI 10.1186/S41074-017-0026-3]; Lee S, 2015, IMAGE VISION COMPUT, V43, P27, DOI 10.1016/j.imavis.2015.08.001; Lin JY, 2014, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2014.419; Liu C, 2010, PROC CVPR IEEE, P239, DOI 10.1109/ICCET.2010.5485248; Liu C, 2014, IEEE T PATTERN ANAL, V36, P86, DOI 10.1109/TPAMI.2013.110; Mannan MA, 2010, LECT NOTES COMPUT SC, V6454, P439, DOI 10.1007/978-3-642-17274-8_43; Naik N, 2015, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2015.7298602; Naik N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024205; O'Toole M, 2017, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2017.246; O'Toole M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601103; Peters C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818103; Qiao H, 2015, OPT LETT, V40, P918, DOI 10.1364/OL.40.000918; Saponaro P, 2015, PROC CVPR IEEE, P4649, DOI 10.1109/CVPR.2015.7299096; Sato M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2191, DOI 10.1145/2702123.2702169; Schwartz G, 2015, PROC CVPR IEEE, P3565, DOI 10.1109/CVPR.2015.7298979; Schwartz G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P883, DOI 10.1109/ICCVW.2013.121; Shim H, 2016, IEEE T CIRC SYST VID, V26, P841, DOI 10.1109/TCSVT.2015.2397231; Shrestha S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925928; SU SC, 2016, PROC CVPR IEEE, P3503, DOI DOI 10.1109/CVPR.2016.381; Tadano R, 2015, IEEE I CONF COMP VIS, P3595, DOI 10.1109/ICCV.2015.410; Tanaka K, 2017, PROC CVPR IEEE, P2740, DOI 10.1109/CVPR.2017.293; Tanaka K, 2016, PROC CVPR IEEE, P4387, DOI 10.1109/CVPR.2016.475; Tsai CY, 2017, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2017.251; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; Velten A, 2013, ACM T GRAPHIC, V32, P1, DOI DOI 10.1145/2461912.2461928; Velten A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1747; Wu D, 2014, INT J COMPUT VISION, V107, P123, DOI 10.1007/s11263-013-0668-2; Xu Z., 2013, US Patent, Patent No. [8,587,771, 8587771]; Zhang H, 2015, PROC CVPR IEEE, P3071, DOI 10.1109/CVPR.2015.7298926	54	9	9	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2906	2918		10.1109/TPAMI.2018.2869885	http://dx.doi.org/10.1109/TPAMI.2018.2869885			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30222552	Bronze			2022-12-18	WOS:000498677600009
J	Zhou, HY; Zhang, T; Jagadeesan, J				Zhou, Haoyin; Zhang, Tao; Jagadeesan, Jayender			Re-weighting and 1-Point RANSAC-Based P < inline-formula >< tex-math notation="LaTeX">$n$</tex-math >< alternatives >< mml:math >< mml:mi > n </mml:mi ></mml:math >< inline-graphic xlink:href="zhou-ieq1-2871832.gif"/></alternatives ></inline-formula > P Solution to Handle Outliers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Iterative methods; Linear programming; Time complexity; Robustness; Three-dimensional displays; Pose estimation; Perspective-< inline-formula xmlns:ali="http:; www; niso; org; schemas; ali; 1; 0; " xmlns:mml="http:; www; w3; org; 1998; Math; MathML" xmlns:xlink="http:; www; w3; org; 1999; xlink" xmlns:xsi="http:; www; w3; org; 2001; XMLSchema-instance"> < tex-math notation="LaTeX">$n$<; tex-math > < alternatives > < mml:math > < mml:mi > n <; mml:mi > <; mml:math > < inline-graphic xlink:href="zhou-ieq16-2871832; gif" xlink:type="simple"; > <; alternatives > <; inline-formula >-point; 1-point RANSAC; soft re-weighting; robustness to outliers	POSE ESTIMATION; OBJECT POSE; PERSPECTIVE; ACCURATE; OPTIMIZATION; EFFICIENT	The ability to handle outliers is essential for performing the perspective-$n$n-point (P$n$P) approach in practical applications, but conventional RANSAC+P3P or P4P methods have high time complexities. We propose a fast P$n$P solution named R1PP$n$P to handle outliers by utilizing a soft re-weighting mechanism and the 1-point RANSAC scheme. We first present a P$n$nP algorithm, which serves as the core of R1PP$n$nP, for solving the P$n$nP problem in outlier-free situations. The core algorithm is an optimal process minimizing an objective function conducted with a random control point. Then, to reduce the impact of outliers, we propose a reprojection error-based re-weighting method and integrate it into the core algorithm. Finally, we employ the 1-point RANSAC scheme to try different control points. Experiments with synthetic and real-world data demonstrate that R1PP$n$P is faster than RANSAC+P3P or P4P methods especially when the percentage of outliers is large, and is accurate. Besides, comparisons with outlier-free synthetic data show that R1PP$n$nP is among the most accurate and fast P$n$nP solutions, which usually serve as the final refinement step of RANSAC+P3P or P4P. Compared with REPP$n$nP, which is the state-of-the-art P$n$n. P algorithm with an explicit outliers-handling mechanism, R1PP$n$nP is slower but does not suffer from the percentage of outliers limitation as REPP$n$nP.	[Zhou, Haoyin; Jagadeesan, Jayender] Harvard Med Sch, Surg Planning Lab, Brigham & Womens Hosp, Boston, MA 02115 USA; [Zhang, Tao] Tsinghua Univ, Dept Automat, Sch Informat Sci & Technol, Beijing 100086, Peoples R China	Harvard University; Brigham & Women's Hospital; Harvard Medical School; Tsinghua University	Zhou, HY (corresponding author), Harvard Med Sch, Surg Planning Lab, Brigham & Womens Hosp, Boston, MA 02115 USA.	zhouhaoyin@bwh.harvard.edu; taozhang@tsinghua.edu.cn; jayender@bwh.harvard.edu		Zhang, Tao/0000-0002-2980-6281	National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health [R01EB025964, P41EB015898, P41RR019703]; Research Grant from Siemens-Healthineers USA; National Institutes of Health through an R01 grant [R01EB025964]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [P41EB015898, R01EB025964] Funding Source: NIH RePORTER	National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); Research Grant from Siemens-Healthineers USA; National Institutes of Health through an R01 grant(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	This work was supported by the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health through Grant Numbers R01EB025964, P41EB015898, P41RR019703, and a Research Grant from Siemens-Healthineers USA. H. Zhou and J. Hayender are also supported by the National Institutes of Health through an R01 grant (R01EB025964). Jayender Jagadeesan owns equity in Navigation Sciences, Inc. He is a co-inventor of a navigation device to assist surgeons in tumor excision that is licensed to Navigation Sciences. Dr. Jagadeesan's interests were reviewed and are managed by BWH and Partners HealthCase in accordance with their conflict of interest policies. The content of this paper is not related to this financial interest.	Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388; Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bujnak M., 2008, 2008 IEEE C COMPUTER, P1; David P, 2004, INT J COMPUT VISION, V59, P259, DOI 10.1023/B:VISI.0000025800.10423.1f; DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625; DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852; Ferraz L, 2014, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2014.71; Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Garro V, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P262, DOI 10.1109/3DIMPVT.2012.40; Hartley R., 2003, MULTIPLE VIEW GEOMET; Havlena M, 2010, LECT NOTES COMPUT SC, V6312, P100, DOI 10.1007/978-3-642-15552-9_8; Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; Horaud R, 1997, INT J COMPUT VISION, V22, P173, DOI 10.1023/A:1007940112931; Josephson K, 2009, PROC CVPR IEEE, P2411; Kahl F, 2008, INT J COMPUT VISION, V79, P271, DOI 10.1007/s11263-007-0117-1; Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083; Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464; Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9; Kneip L, 2013, IEEE INT CONF ROBOT, P3770, DOI 10.1109/ICRA.2013.6631107; Lee GH, 2015, INT J ROBOT RES, V34, P837, DOI 10.1177/0278364914557969; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Muller M, 2013, INT J COMPUT ASS RAD, V8, P663, DOI 10.1007/s11548-013-0828-4; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953; Nister D., 2004, P IEEE COMP SOC C CO, P67; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Schweighofer G, 2008, IEEE WORK APP COMP, P159; Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252; Simpson D. G., 1997, BREAKTHROUGHS STAT, P433; TRIGGS B, 1999, P INT C COMP VIS ICC, V7, P278; WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632; Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291; Zheng YQ, 2013, IEICE T INF SYST, VE96D, P1525, DOI 10.1587/transinf.E96.D.1525	44	9	10	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					3022	3033		10.1109/TPAMI.2018.2871832	http://dx.doi.org/10.1109/TPAMI.2018.2871832			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	31689179	Green Accepted			2022-12-18	WOS:000498677600017
J	Xue, NN; Deng, JK; Cheng, SY; Panagakis, Y; Zafeiriou, S				Xue, Niannan; Deng, Jiankang; Cheng, Shiyang; Panagakis, Yannis; Zafeiriou, Stefanos			Side Information for Face Completion: A Robust PCA Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RPCA; GAN; side information; UV completion; face recognition; in the wild	LOW-RANK MATRIX; REPRESENTATION; RECOGNITION; ALGORITHM	Robust principal component analysis (RPCA) is a powerful method for learning low-rank feature representation of various visual data. However, for certain types as well as significant amount of error corruption, it fails to yield satisfactory results; a drawback that can be alleviated by exploiting domain-dependent prior knowledge or information. In this paper, we propose two models for the RPCA that take into account such side information, even in the presence of missing values. We apply this framework to the task of UV completion which is widely used in pose-invariant face recognition. Moreover, we construct a generative adversarial network (GAN) to extract side information as well as subspaces. These subspaces not only assist in the recovery but also speed up the process in case of large-scale data. We quantitatively and qualitatively evaluate the proposed approaches through both synthetic data and eight real-world datasets to verify their effectiveness.	[Xue, Niannan; Deng, Jiankang; Cheng, Shiyang; Panagakis, Yannis; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London SW7 2AZ, England; [Deng, Jiankang; Zafeiriou, Stefanos] Facesoft, London W12 OBZ, England; [Zafeiriou, Stefanos] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland	Imperial College London; University of Oulu	Deng, JK (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.	n.xue15@imperial.ac.uk; j.deng16@imperial.ac.uk; shiyang.cheng11@imperial.ac.uk; i.panagakis@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Panagakis, Yannis/AAZ-8090-2020	Panagakis, Ioannis/0000-0003-0153-5210	EPSRC [EP/N007743/1, EP/S010203/1]; European Community Horizon 2020 [H2020/2014-2020] [688520]; Google Faculty Fellowship	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); European Community Horizon 2020 [H2020/2014-2020]; Google Faculty Fellowship(Google Incorporated)	This work was partially funded by the EPSRC project EP/N007743/1 (FACER2VM: Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management), the EPSRC project EP/S010203/1 (DEFORM: Large Scale Shape Analysis of Deformable Models of Humans), the European Community Horizon 2020 [H2020/2014-2020] under grant agreement no. 688520 (TeSLA), and a Google Faculty Fellowship to Dr. Zafeiriou. We thank the NVIDIA Corporation for donating several GPUs used in this work.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2019, P IEEE C COMP VIS PA; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.578; Aravkin A, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P32; Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Beveridge J. R., 2013, BIOM THEOR APPL SYST, P1, DOI DOI 10.1109/BTAS.2013.6712704; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bodla N, 2017, IEEE WINT CONF APPL, P586, DOI 10.1109/WACV.2017.71; Booth J, 2018, IEEE T PATTERN ANAL, V40, P2638, DOI 10.1109/TPAMI.2018.2832138; Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Booth J, 2014, IEEE IMAGE PROC, P4672, DOI 10.1109/ICIP.2014.7025947; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Candes EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793; CHANG FJ, 2017, IEEE INT CONF COMP V, P1599, DOI DOI 10.1109/ICCVW.2017.188; Chen CH, 2018, IEEE T PATTERN ANAL, V40, P1653, DOI 10.1109/TPAMI.2017.2723401; Chen J, 2017, IMAGE VISION COMPUT, V64, P34, DOI 10.1016/j.imavis.2017.05.006; Chiang K Y, 2015, ADV NEURAL INFORM PR, P3447; Chiang KY, 2016, PR MACH LEARN RES, V48; Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741; Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251; Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089; Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338; Du M, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2300812; Hintermuller M, 2015, J MATH IMAGING VIS, V51, P361, DOI 10.1007/s10851-014-0527-y; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jiao JT, 2015, IEEE T INFORM THEORY, V61, P5357, DOI 10.1109/TIT.2015.2462848; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243; Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434; Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803; Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052; Li C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P1, DOI 10.1109/CCET.2018.8542225; Lin Z., 2010, ARXIV10095055, DOI DOI 10.1016/J.JSB.2012.10.010; Liu G, 2017, ADV NEURAL INFORM PR, P785; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2017, IEEE T PATTERN ANAL, V39, P47, DOI 10.1109/TPAMI.2016.2539946; Liu GC, 2016, IEEE T SIGNAL PROCES, V64, P5623, DOI 10.1109/TSP.2016.2586753; Liu GC, 2016, IEEE T PATTERN ANAL, V38, P417, DOI 10.1109/TPAMI.2015.2453969; Liu Q, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P663, DOI 10.1109/IITSI.2010.40; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033; Mota JFC, 2017, IEEE T INFORM THEORY, V63, P4472, DOI 10.1109/TIT.2017.2695614; Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956; Patel A, 2009, PROC CVPR IEEE, P1327, DOI 10.1109/CVPRW.2009.5206522; Patel VM, 2012, IEEE T INF FOREN SEC, V7, P954, DOI 10.1109/TIFS.2012.2189205; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Ranjan R., 2018, ARXIV180907586; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; ROCKAFELLAR RT, 1976, SIAM J CONTROL, V14, P877, DOI 10.1137/0314056; Sagonas C, 2014, PROC CVPR IEEE, P1789, DOI 10.1109/CVPR.2014.231; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shabalin AA, 2013, J MULTIVARIATE ANAL, V118, P67, DOI 10.1016/j.jmva.2013.03.005; Shang F., 2014, P 23 ACM INT C C INF, P1149, DOI DOI 10.1145/2661829.2662083; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Shekhar S., 2017, ARXIV170702733; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sun HJ, 2016, J INEQUAL APPL, DOI 10.1186/s13660-016-1173-2; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Toh KC, 2010, PAC J OPTIM, V6, P615; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508; Xie WD, 2018, LECT NOTES COMPUT SC, V11215, P811, DOI 10.1007/978-3-030-01252-6_48; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156; Xu Miao, 2013, ADV NEURAL INFORM PR, P2301, DOI DOI 10.5555/2999792.2999869; Xue NN, 2017, IEEE I CONF COMP VIS, P4327, DOI 10.1109/ICCV.2017.463; Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zheng JJ, 2017, IEEE T PATTERN ANAL, V39, P2242, DOI 10.1109/TPAMI.2016.2636827	87	9	9	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2349	2364		10.1109/TPAMI.2019.2902556	http://dx.doi.org/10.1109/TPAMI.2019.2902556			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30843800	Green Submitted, Green Accepted			2022-12-18	WOS:000489763000006
J	Zhang, MM; Ma, KT; Lim, JH; Zhao, Q; Feng, JS				Zhang, Mengmi; Ma, Keng Teck; Lim, Joo Hwee; Zhao, Qi; Feng, Jiashi			Anticipating Where People will Look Using Adversarial Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Egocentric videos; gaze anticipation; generative adversarial network; saliency; visual attention	VISUAL-ATTENTION; PREDICT; MODEL	We introduce a new problem of gaze anticipation on future frames which extends the conventional gaze prediction problem to go beyond current frames. To solve this problem, we propose a new generative adversarial network based model, Deep Future Gaze (DFG), encompassing two pathways: DFG-P is to anticipate gaze prior maps conditioned on the input frame which provides task influences; DFG-G is to learn to model both semantic and motion information in future frame generation. DFG-P and DFG-G are then fused to anticipate future gazes. DFG-G consists of two networks: a generator and a discriminator. The generator uses a two-stream spatial-temporal convolution architecture (3D-CNN) for explicitly untangling the foreground and background to generate future frames. It then attaches another 3D-CNN for gaze anticipation based on these synthetic frames. The discriminator plays against the generator by distinguishing the synthetic frames of the generator from the real frames. Experimental results on the publicly available egocentric and third person video datasets show that DFG significantly outperforms all competitive baselines. We also demonstrate that DFG achieves better performance of gaze prediction on current frames in egocentric and third person videos than state-of-the-art methods.	[Zhang, Mengmi] Natl Univ Singapore, Singapore 119077, Singapore; [Zhang, Mengmi] ASTAR, Inst Infocomm Res I2R, Singapore 138632, Singapore; [Ma, Keng Teck; Lim, Joo Hwee] A AI, Singapore 138632, Singapore; [Ma, Keng Teck; Lim, Joo Hwee] ASTAR, I2R, Singapore 138632, Singapore; [Zhao, Qi] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Zhao, Qi] Natl Univ Singapore, ECE, Singapore 119077, Singapore; [Zhao, Qi] Natl Univ Singapore, Dept Ophthalmol, Singapore 119077, Singapore; [Feng, Jiashi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore	National University of Singapore; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); University of Minnesota System; University of Minnesota Twin Cities; National University of Singapore; National University of Singapore; National University of Singapore	Zhang, MM (corresponding author), Natl Univ Singapore, Singapore 119077, Singapore.	mengmi@u.nus.edu; makt@scei.a-star.edu.sg; joohwee@i2r.a-star.edu.sg; qzhao@cs.umn.edu; elefjia@nus.edu.sg	Feng, Jiashi/AGX-6209-2022		Reverse Engineering Visual Intelligence for cognitiVe Enhancement (REVIVE) programme - A*STAR, National University of Singapore startup grant [1335H00098, R-263-000-C08-133]; Ministry of Education of Singapore AcRF Tier One grant [R-263-000-C21-112]	Reverse Engineering Visual Intelligence for cognitiVe Enhancement (REVIVE) programme - A*STAR, National University of Singapore startup grant(National University of Singapore); Ministry of Education of Singapore AcRF Tier One grant(Ministry of Education, Singapore)	This work was supported by the Reverse Engineering Visual Intelligence for cognitiVe Enhancement (REVIVE) programme (1335H00098) funded by A*STAR, National University of Singapore startup grant R-263-000-C08-133 and Ministry of Education of Singapore AcRF Tier One grant R-263-000-C21-112. We also like to thank Yin Li, Sayed Hossein Khatoonabadi, and Victor Leboran for their help in replicating the experimental setups in [3], [33], [34].	Ba SO, 2011, IEEE T PATTERN ANAL, V33, P101, DOI 10.1109/TPAMI.2010.69; Bazzani Loris, 2016, ARXIV160308199; Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731; Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118; Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710; Borji Ali, 2012, CVPR; Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697; Bruce N., 2005, P 18 INT C NEUR INF, P155; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Buso V, 2015, SIGNAL PROCESS-IMAGE, V39, P418, DOI 10.1016/j.image.2015.05.006; Bylinskii Zoya, 2016, ARXIV160403605; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Davis JE, 2006, DEAF WAY II READER: PERSPECTIVES FROM THE SECOND INTERNATIONAL CONFERENCE ON DEAF CULTURE, P233; Denton Emily L, 2015, NEURIPS, V2, P4; Ding W., 2009, HCI INT, V1, P8055; Dollar P., 2005, P IEEE INT WORKSH VI, P65, DOI [DOI 10.1109/VSPETS.2005.1570899, 10.1109/VSPETS.2005.1570899]; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Huang CM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01049; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kalchbrenner N, 2016, ARXIV161000527; KHATOONABADI SH, 2015, PROC CVPR IEEE, P5501; Kingma D.P, P 3 INT C LEARNING R; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar M., 2007, GAZE ENHANCED USER I; Kummerer Matthias, 2014, ARXIV14111045; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343; Leboran V, 2017, IEEE T PATTERN ANAL, V39, P893, DOI 10.1109/TPAMI.2016.2567391; Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625; Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Lotter William, 2016, ARXIV160508104; Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Mathieu Michael, 2015, ARXIV151105440; Mirza M., 2014, ARXIV; Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32; Mobahi H., 2009, P 26 ANN INT C MACHI, P737, DOI DOI 10.1145/1553374.1553469; Multon F, 1999, J VISUAL COMP ANIMAT, V10, P39, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<39::AID-VIS195>3.0.CO;2-2; Ohme R., 2011, J INTERACTIVE ADVERT, V11, P60, DOI [10.1080/15252019.2011.10722185, DOI 10.1080/15252019.2011.10722185]; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ranzato MarcAurelio, 2014, ARXIV14126604; Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147; Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51; Walker J, 2014, PROC CVPR IEEE, P3302, DOI 10.1109/CVPR.2014.416; Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28; Xue Tianfan, 2016, ADV NEURAL INFORM PR, P2; Yamada K, 2011, LECT NOTES COMPUT SC, V7087, P277, DOI 10.1007/978-3-642-25367-6_25; Zeleznik R. C., 2005, CS05 BROWN U; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhang MM, 2017, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2017.377; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9; Zhou XF, 2014, INT CONF NANO MICRO, P28, DOI 10.1109/NEMS.2014.6908752; Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16	75	9	9	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1783	1796		10.1109/TPAMI.2018.2871688	http://dx.doi.org/10.1109/TPAMI.2018.2871688			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30273143				2022-12-18	WOS:000473598800001
J	Martinho-Corbishley, D; Nixon, MS; Carter, JN				Martinho-Corbishley, Daniel; Nixon, Mark S.; Carter, John N.			Super-Fine Attributes with Crowd Prototyping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Attribute-based pedestrian re-identification; soft biometrics; crowdsourcing; retrieval; perception; PETA dataset	LAW	Recognising human attributes from surveillance footage is widely studied for attribute-based re-identification. However, most works assume coarse, expertly-defined categories, ineffective in describing challenging images. Such brittle representations are limited in descriminitive power and hamper the efficacy of learnt estimators. We aim to discover more relevant and precise subject descriptions, improving image retrieval and closing the semantic gap. Inspired by fine-grained and relative attributes, we introduce super-fine attributes, which now describe multiple, integral concepts of a single trait as multi-dimensional perceptual coordinates. Crowd prototyping facilitates efficient crowdsourcing of super-fine labels by pre-discovering salient perceptual concepts for prototype matching. We re-annotate gender, age and ethnicity traits from PETA, a highly diverse (19K instances, 8.7K identities) amalgamation of 10 re-id datasets including VIPER, CUHK and TownCentre. Employing joint attribute regression with the ResNet-152 CNN, we demonstrate substantially improved ranked retrieval performance with super-fine attributes in comparison to conventional binary labels, reporting up to a 11.2 and 14.8 percent mAP improvement for gender and age, further surpassed by ethnicity. We also find our 3 super-fine traits to outperform 35 binary attributes by 6.5 percent mAP for subject retrieval in a challenging zero-shot identification scenario.	[Martinho-Corbishley, Daniel] Univ Southampton, Fac Phys Sci & Engn, Vis Learning & Control, Southampton SO17 1BJ, Hants, England; [Nixon, Mark S.] Univ Southampton, Elect & Comp Sci, Southampton SO17 1BJ, Hants, England; [Carter, John N.] Univ Southampton, Sch Elect & Comptuer Sci, Southampton SO17 1BJ, Hants, England	University of Southampton; University of Southampton; University of Southampton	Martinho-Corbishley, D (corresponding author), Univ Southampton, Fac Phys Sci & Engn, Vis Learning & Control, Southampton SO17 1BJ, Hants, England.	dmc@ecs.soton.ac.uk; msn@ecs.soton.ac.uk; jnc@ecs.soton.ac.uk		Nixon, Mark/0000-0002-9174-5934				Agarwal Sameer, 2007, J MACHINE LEARNING R, P11; Almudhahka N. Y., 2016, P IEEE INT C ID SEC, P1, DOI DOI 10.1109/BTAS.2016.7791206; [Anonymous], 2010, TRACTATUS LOGICO PHI; [Anonymous], 2011, TECH REP; Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332; Bekele E, 2017, IEEE INT CONF AUTOMA, P386, DOI 10.1109/FG.2017.55; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169; Chen X., 2016, ARXIV160307054; Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381; Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7; Deng Y., 2015, ARXIV150100901; Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966; Edelman S, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00045; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fox T., 2012, FREQUENCY RESPONSE S; Gardenfors P., 2004, CONCEPTUAL SPACES GE; Golomb B. A., 1990, NIPS, V1, P572; Gomes Ryan G, 2011, NEURAL INFORM PROCES, P558; Hall D, 2015, PROC CVPR IEEE, P5482, DOI 10.1109/CVPR.2015.7299187; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hill MQ, 2016, PSYCHOL SCI, V27, P1486, DOI 10.1177/0956797616663878; Jaha ES, 2016, IEEE T INF FOREN SEC, V11, P2377, DOI 10.1109/TIFS.2016.2584001; Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81; Kovashka A, 2015, INT J COMPUT VISION, V114, P56, DOI 10.1007/s11263-014-0798-1; Kovashka A, 2013, IEEE I CONF COMP VIS, P3432, DOI 10.1109/ICCV.2013.426; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5; Leibniz G.W., 1989, PHILOS PAPERS LETT, P303, DOI DOI 10.1007/978-94-010-1426-7_36; Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352; Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476; Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Martin D, 2016, BIOARCHAEOL SOC THEO, P1, DOI 10.1007/978-3-319-22554-8_1; Martinho-Corbishley D, 2016, INT C PATT RECOG, P3067, DOI 10.1109/ICPR.2016.7900105; Ng C.B., 2012, LECT NOTES COMPUTER, P335, DOI DOI 10.1007/978-3-642-32695-0; Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Patterson G, 2016, LECT NOTES COMPUT SC, V9910, P85, DOI 10.1007/978-3-319-46466-4_6; Qian BY, 2014, IEEE T IMAGE PROCESS, V23, P5573, DOI 10.1109/TIP.2014.2365952; Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219; Samangooei S., 2008, 2 IEEE INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2008.4699354; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046; Sudowe P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P329, DOI 10.1109/ICCVW.2015.51; Sun YL, 2018, IEEE T PATTERN ANAL, V40, P332, DOI 10.1109/TPAMI.2017.2669035; Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; Wah C, 2014, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2014.115; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Yu A, 2015, IEEE I CONF COMP VIS, P2416, DOI 10.1109/ICCV.2015.278; Zheng L., 2016, PERSON RE IDENTIFICA; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004; 1978, PSYCHOL REV, V85, P445; 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI DOI 10.1109/TVCG.2014.2346978	58	9	9	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1486	1500		10.1109/TPAMI.2018.2836900	http://dx.doi.org/10.1109/TPAMI.2018.2836900			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HW9UU	29994759	Green Accepted			2022-12-18	WOS:000467037000015
J	Hadfield, S; Lebeda, K; Bowden, R				Hadfield, Simon; Lebeda, Karel; Bowden, Richard			HARD-PnP: PnP Optimization Using a Hybrid Approximate Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PnP; perspective-n-point; camera resectioning; overparameterization; multiview geometry	POSE ESTIMATION; ACCURATE	This paper proposes a Hybrid Approximate Representation (HAR) based on unifying several efficient approximations of the generalized reprojection error (which is known as the gold standard for multiview geometry). The HAR is an over-parameterization scheme where the approximation is applied simultaneously in multiple parameter spaces. A joint minimization scheme "HAR-Descent" can then solve the PnP problem efficiently, while remaining robust to approximation errors and local minima. The technique is evaluated extensively, including numerous synthetic benchmark protocols and the real-world data evaluations used in previous works. The proposed technique was found to have runtime complexity comparable to the fastest Oonthorn techniques, and up to 10 times faster than current state of the art minimization approaches. In addition, the accuracy exceeds that of all 9 previous techniques tested, providing definitive state of the art performance on the benchmarks, across all 90 of the experiments in the paper and supplementary material, which can be found on the Computer Society Digital Library at http:w//doi.ieeecomputersociety.org/10.1109/TPAMI.2018.2806446.	[Hadfield, Simon; Bowden, Richard] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; [Lebeda, Karel] Synthesia Ltd, London E1 5JL, England	University of Surrey	Hadfield, S (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	S.Hadfield@surrey.ac.uk; karel@synthesia.io; R.Bowden@surrey.ac.uk	Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020; Hadfield, Simon/0000-0001-8637-5054	EPSRC [EP/I011811/1]; SNSF [CRSII2 160811]	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); SNSF(Swiss National Science Foundation (SNSF))	Supported by EPSRC project "Learning to recognise dynamic visual content" (EP/I011811/1) and the SNSF grant CRSII2 160811 "SMILE".	Abdel-Aziz Y., 1971, P S CLOSE RANGE PHOT, P1, DOI [10.14358/PERS.81.2.103, DOI 10.1080/10671188.1967.10616517]; Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3; Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552; Cox D. A., 2007, IDEALS VARIETIES ALG; Ferraz L, 2014, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2014.71; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Garro V., 2012, P 2 JOINT 3DIM 3DPVT, P262; Grimson WEL, 1996, IEEE T MED IMAGING, V15, P129, DOI 10.1109/42.491415; Hadfield S, 2014, LECT NOTES COMPUT SC, V8690, P758, DOI 10.1007/978-3-319-10605-2_49; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266; Jaggi M., 2013, P 30 INT C MACHINE L, P427; Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464; Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9; Kneip L, 2013, IEEE INT CONF ROBOT, P3770, DOI 10.1109/ICRA.2013.6631107; Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23; Lebeda K., 2014, P AS C COMP VIS, P642; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Malik S., 2002, VI 2002, P399; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Schwartz G, 2008, PUBLIC INVESTMENT AND PUBLIC-PRIVATE PARTNERSHIPS: ADDRESSING INFRASTRUCTURE CHALLENGES AND MANAGING FISCAL RISKS, P1; Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252; State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P429, DOI 10.1145/237170.237282; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005; Wu CC, 2015, PROC CVPR IEEE, P2440, DOI 10.1109/CVPR.2015.7298858; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291; Zheng YQ, 2013, IEICE T INF SYST, VE96D, P1525, DOI 10.1587/transinf.E96.D.1525	31	9	11	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					768	774		10.1109/TPAMI.2018.2806446	http://dx.doi.org/10.1109/TPAMI.2018.2806446			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994452	Green Published			2022-12-18	WOS:000458168800018
J	Hu, Z; Cho, S; Wang, J; Yang, MH				Hu, Zhe; Cho, Sunghyun; Wang, Jue; Yang, Ming-Hsuan			Deblurring Low-Light Images with Light Streaks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image deblurring; light streak; non-uniform blur	BLIND DECONVOLUTION; KERNEL ESTIMATION; MOTION; RESTORATION; SHAKEN	Images acquired in low-light conditions with handheld cameras are often blurry, so steady poses and long exposure time are required to alleviate this problem. Although significant advances have been made in image deblurring, state-of-the-art approaches often fail on low-light images, as a sufficient number of salient features cannot be extracted for blur kernel estimation. On the other hand, light streaks are common phenomena in low-light images that have not been extensively explored in existing approaches. In this work, we propose an algorithm that utilizes light streaks to facilitate deblurring low-light images. The light streaks, which commonly exist in the low-light blurry images, contain rich information regarding camera motion and blur kernels. A method is developed in this work to detect light streaks for kernel estimation. We introduce a non-linear blur model that explicitly takes light streaks and corresponding light sources into account, and pose them as constraints for estimating the blur kernel in an optimization framework. For practical applications, the proposed algorithm is extended to handle images undergoing non-uniform blur. Experimental results show that the proposed algorithm performs favorably against the state-of-the-art methods on deblurring real-world low-light images.	[Hu, Zhe] Hikvis Res Amer, Santa Clara, CA 95054 USA; [Cho, Sunghyun] DGIST, Daegu, South Korea; [Wang, Jue] Megvii Inc, Seattle, WA 98052 USA; [Yang, Ming-Hsuan] Univ Calif Merced, Merced, CA 95340 USA	Daegu Gyeongbuk Institute of Science & Technology (DGIST); University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif Merced, Merced, CA 95340 USA.	zhe.hu@hikvision.com; scho@dgist.ac.kr; wangjue@megvii.com; mhyang@ucmerced.edu	Yang, Ming-Hsuan/AAE-7350-2019; Hu, Zhe/AAE-7207-2021; Cho, Sunghyun/X-5508-2019; Wang, Jue/GVU-0480-2022; Yang, Ming-Hsuan/T-9533-2019	Cho, Sunghyun/0000-0001-7627-3513; Wang, Jue/0000-0002-3641-3136; Yang, Ming-Hsuan/0000-0003-4848-2304	National Science Foundation CAREER Grant [1149783]; STCSM Grant [16511101300]; Next-Generation Information Computing Development Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT [NRF-2017M3C4A7066316]	National Science Foundation CAREER Grant(National Science Foundation (NSF)); STCSM Grant; Next-Generation Information Computing Development Program through the National Research Foundation of Korea (NRF) - Ministry of Science, ICT	Z. Hu and M.-H. Yang are supported in part by the National Science Foundation CAREER Grant #1149783, and gifts from Adobe, NEC, Panasonic, Nvidia and STCSM Grant #16511101300. S. Cho is supported by Next-Generation Information Computing Development Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT (NRF-2017M3C4A7066316).	Bardsley J, 2006, OPT EXPRESS, V14, P1767, DOI 10.1364/OE.14.001767; BURTON GJ, 1987, APPL OPTICS, V26, P157, DOI 10.1364/AO.26.000157; Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413; Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743; Cho S, 2007, IEEE I CONF COMP VIS, P596; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479; Cho TS, 2010, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2010.5540214; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Harmeling S., 2010, ADV NEURAL INFORM PR, V23, P829; Harmeling S, 2010, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2010.5651650; Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276; Hu W, 2012, IEEE T IMAGE PROCESS, V21, P386, DOI 10.1109/TIP.2011.2160073; Hu Z, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.136; Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5; Hua BS, 2011, IEEE IMAGE PROC, P1553, DOI 10.1109/ICIP.2011.6115743; Joshi N., 2008, CVPR, P1; Joshi N., 2010, P ACM SIGGRAPH; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A., 2006, ADV NEURAL INFORM PR, V19, P841; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Shan Q, 2007, IEEE I CONF COMP VIS, P738; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Tai Y.-W., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587507; Tai Y. W., 2011, PAMI, V33, P1603; Tai YW, 2013, IEEE T PATTERN ANAL, V35, P2498, DOI 10.1109/TPAMI.2013.40; Whyte Oliver, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P745; Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512; Yuan L., 2007, 1 IEEE INT C BIOM TH, P1, DOI DOI 10.1145/1239451.1239452; Zhang HC, 2014, IEEE T PATTERN ANAL, V36, P1628, DOI 10.1109/TPAMI.2013.241	43	9	10	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2329	2341		10.1109/TPAMI.2017.2768365	http://dx.doi.org/10.1109/TPAMI.2017.2768365			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	29990078				2022-12-18	WOS:000443875500004
J	Soulard, R; Carre, P				Soulard, Raphael; Carre, Philippe			Characterization of Color Images with Multiscale Monogenic Maxima	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; image color analysis; image reconstruction; monogenic wavelets; wavelet maxima	WAVELET; TRANSFORMS; FRAMEWORK; SIGNALS	Can we build a feature-based analysis that fully characterizes images? The literature answers with edge-based reconstruction methods inspired by Marr's paradigm but limited to the greyscale case. This paper studies the color case. A new sparse representation is carried out with the monogenic concept and the Mallat-Zhong wavelet maxima method. Our monogenic maxima provide efficient contour shape and color characterization, as a sparse set of local features including amplitude, phase, orientation and ellipse parameters. This rich description takes the wavelet maxima representation further towards the wide topic of keypoint analysis. We propose a reconstruction process that retrieves the image from its monogenic maxima. While known works all rely on constrained optimization, implying an iterative use of the filterbank, we propose to interpolate the data in the feature domain by exploiting the visual knowledge from the feature-set. This direct retrieval is accurate enough so that no iteration is required. The main question is finally answered with comparative experiments. It is shown that a reasonably small amount of features is sufficiently informative for visually appealing image retrieval. The features appear numerically stable to rotation, and can be intuitively simplified to perform image regularization.	[Soulard, Raphael; Carre, Philippe] Univ Poitiers, CNRS, UMR 7252, XLIM SIC Dept, F-86000 Poitiers, France	Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite de Poitiers	Soulard, R (corresponding author), Univ Poitiers, CNRS, UMR 7252, XLIM SIC Dept, F-86000 Poitiers, France.	soulard.raphael@gmail.com; philippe.carre@univ-poitiers.fr						Bovik A., 2000, HDB IMAGE VIDEO PROC; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087; Chenouard N, 2012, IEEE T IMAGE PROCESS, V21, P4522, DOI 10.1109/TIP.2012.2206044; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; Felsberg M., 2002, THESIS; Fleischmann O, 2011, J MATH IMAGING VIS, V40, P305, DOI 10.1007/s10851-011-0263-5; Granlund G.H., 1995, SIGNAL PROCESSING CO; HAHN SL, 1992, P IEEE, V80, P1287, DOI 10.1109/5.158601; Haussecker H., 1996, P 3D IM AN SYNTH NOV, P18; Held S, 2010, IEEE T IMAGE PROCESS, V19, P653, DOI 10.1109/TIP.2009.2036713; Jahne B., 2005, DIGITAL IMAGE PROCES; Janssen BJ, 2009, INT J COMPUT VISION, V84, P205, DOI 10.1007/s11263-008-0156-2; Kothe U, 2005, LECT NOTES COMPUT SC, V3459, P179; Larkin KG, 2001, J OPT SOC AM A, V18, P1862, DOI 10.1364/JOSAA.18.001862; Lesinski K., 2017, SOURCE CODE COLOR MU; Lillholm M, 2003, INT J COMPUT VISION, V52, P73, DOI 10.1023/A:1022995822531; Lilly JM, 2011, IEEE T SIGNAL PROCES, V59, P5930, DOI 10.1109/TSP.2011.2164914; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1; Marr D., 1982, VISION; NABIGHIAN MN, 1984, GEOPHYSICS, V49, P780, DOI 10.1190/1.1441706; Pad P, 2016, IEEE T IMAGE PROCESS, V25, P2275, DOI 10.1109/TIP.2016.2545301; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Soulard R, 2016, IEEE T SIGNAL PROCES, V64, P1535, DOI 10.1109/TSP.2015.2505664; Thomas Bulow, 1999, HYPERCOMPLEX SPECTRA; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Unser M, 2013, SIAM J IMAGING SCI, V6, P102, DOI 10.1137/120866014; Unser M, 2009, IEEE T IMAGE PROCESS, V18, P2402, DOI 10.1109/TIP.2009.2027628; Van De Ville D, 2008, IEEE T IMAGE PROCESS, V17, P2063, DOI 10.1109/TIP.2008.2004797; Wietzke L, 2010, J MATH IMAGING VIS, V37, P132, DOI 10.1007/s10851-010-0197-3	32	9	9	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2289	2302		10.1109/TPAMI.2017.2760303	http://dx.doi.org/10.1109/TPAMI.2017.2760303			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28991734	Green Submitted			2022-12-18	WOS:000443875500001
J	Villamizar, M; Andrade-Cetto, J; Sanfeliu, A; Moreno-Noguer, F				Villamizar, Michael; Andrade-Cetto, Juan; Sanfeliu, Alberto; Moreno-Noguer, Francesc			Boosted Random Ferns for Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing and computer vision; object detection; random ferns; boosting; online-boosting	FEATURES; REGRESSION; FORESTS; IMAGE	In this paper we introduce the Boosted Random Ferns (BRFs) to rapidly build discriminative classifiers for learning and detecting object categories. At the core of our approach we use standard random ferns, but we introduce four main innovations that let us bring ferns from an instance to a category level, and still retain efficiency. First, we define binary features on the histogram of oriented gradients-domain (as opposed to intensity-), allowing for a better representation of intra-class variability. Second, both the positions where ferns are evaluated within the sliding window, and the location of the binary features for each fern are not chosen completely at random, but instead we use a boosting strategy to pick the most discriminative combination of them. This is further enhanced by our third contribution, that is to adapt the boosting strategy to enable sharing of binary features among different ferns, yielding high recognition rates at a low computational cost. And finally, we show that training can be performed online, for sequentially arriving images. Overall, the resulting classifier can be very efficiently trained, densely evaluated for all image locations in about 0.1 seconds, and provides detection rates similar to competing approaches that require expensive and significantly slower processing times. We demonstrate the effectiveness of our approach by thorough experimentation in publicly available datasets in which we compare against state-of-the-art, and for tasks of both 2D detection and 3D multi-view estimation.	[Villamizar, Michael; Andrade-Cetto, Juan; Sanfeliu, Alberto] CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain; [Moreno-Noguer, Francesc] Inst Robot & Informat Ind, Barcelona 08028, Spain	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII)	Villamizar, M (corresponding author), CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain.	villamizar@iri.upc.edu; cetto@iri.upc.edu; sanfeliu@iri.upc.edu; fmoreno@iri.upc.edu	Andrade-Cetto, Juan/F-2576-2013; Andrade-Cetto, Juan/AAA-4131-2020; Andrade Cetto, Juan/HCI-2418-2022	Andrade-Cetto, Juan/0000-0002-6354-8941; Andrade-Cetto, Juan/0000-0002-6354-8941; 	Catalan Agency for Management of University; Research Grants for the Consolidated Group VIS [2014 SGR 897]; Spanish Ministry of Economy, Industry and Competitiveness [DPI2016-78957-R, TIN2014-58178-R]; European Union project AEROARMS [H2020-ICT-2014-1-644271]; European Union project LOGIMATIC [H2020-Galileo-2015-1-687534]	Catalan Agency for Management of University; Research Grants for the Consolidated Group VIS; Spanish Ministry of Economy, Industry and Competitiveness; European Union project AEROARMS; European Union project LOGIMATIC	This work was partially supported by the Catalan Agency for Management of University and Research Grants for the Consolidated Group VIS (2014 SGR 897). A.S. acknowledges support also from project ColRobTransp (DPI2016-78957-R), and J.A. and F.M. from project RobInstruct (TIN2014-58178-R), both funded by the Spanish Ministry of Economy, Industry and Competitiveness. J.A., A.S., and F.M. were also partially supported by the European Union projects AEROARMS (H2020-ICT-2014-1-644271) and LOGIMATIC (H2020-Galileo-2015-1-687534).	Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113; Bao SY, 2012, LECT NOTES COMPUT SC, V7572, P86, DOI 10.1007/978-3-642-33718-5_7; Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Caruana R., 2006, P 23 INT C MACH LEAR, P161; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Fritz M, 2005, IEEE I CONF COMP VIS, P1363; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379; Grabner H, 2006, IEEE C COMP VIS PATT, P260; Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408; Hao S, 2009, IEEE I CONF COMP VIS, P213, DOI 10.1109/ICCV.2009.5459168; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kim T., 2008, ADV NEURAL INFORM PR, P841; Krupka E, 2014, PROC CVPR IEEE, P3670, DOI 10.1109/CVPR.2014.469; Laptev I, 2009, IMAGE VISION COMPUT, V27, P535, DOI 10.1016/j.imavis.2008.08.010; Lehmann AD, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.8; Leibe B., 2006, P BRIT MACH VIS C ED, P1169; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Liu K, 2012, PROC CVPR IEEE, P917, DOI 10.1109/CVPR.2012.6247766; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Mikolajczyk K., 2006, P CVPR, V1, P26, DOI DOI 10.1109/CVPR.2006.202]; Mita T, 2008, IEEE T PATTERN ANAL, V30, P1257, DOI 10.1109/TPAMI.2007.70767; Monroy Antonio, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3561, DOI 10.1109/ICIP.2011.6116485; Ozuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; Ozuysal M., 2007, 2007 IEEE C COMP VIS, P1; Riemenschneider H, 2010, LECT NOTES COMPUT SC, V6315, P29, DOI 10.1007/978-3-642-15555-0_3; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772; Stark M., 2010, P BRIT MACH VIS C, P1, DOI [10.5244/C.24.106, DOI 10.5244/C.24.106]; Tang D., 2012, P BRIT MACH VIS C, P1; Thomas A, 2007, IEEE I CONF COMP VIS, P23; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Toshev A, 2010, PROC CVPR IEEE, P950, DOI 10.1109/CVPR.2010.5540114; Villamizar M, 2014, IEEE INT CONF ROBOT, P4996, DOI 10.1109/ICRA.2014.6907591; Villamizar Michael, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P388, DOI 10.1109/ICPR.2010.103; Villamizar M, 2006, INT C PATT RECOG, P81; Villamizar M, 2016, COMPUT VIS IMAGE UND, V149, P51, DOI 10.1016/j.cviu.2016.03.010; Villamizar M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.20; Villamizar M, 2012, PATTERN RECOGN, V45, P3141, DOI 10.1016/j.patcog.2012.03.025; Villamizar M, 2010, PROC CVPR IEEE, P1038, DOI 10.1109/CVPR.2010.5540104; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Xiang Y, 2012, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2012.6248081; Yarlagadda P, 2010, LECT NOTES COMPUT SC, V6315, P197, DOI 10.1007/978-3-642-15555-0_15; Zhang JE, 2011, PROC CVPR IEEE, P1393, DOI 10.1109/CVPR.2011.5995678; Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411	64	9	11	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					272	288		10.1109/TPAMI.2017.2676778	http://dx.doi.org/10.1109/TPAMI.2017.2676778			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28278456	Green Submitted			2022-12-18	WOS:000422706000002
J	Freifeld, O; Hauberg, S; Batmanghelich, K; Fisher, JW				Freifeld, Oren; Hauberg, Soren; Batmanghelich, Kayhan; Fisher, Jonn W., III			Transformations Based on Continuous Piecewise-Affine Velocity Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spatial transformations; continuous piecewise-affine velocity fields; diffeomorphisms; tessellations; priors; MCMC	PRINCIPAL GEODESIC ANALYSIS; PARALLEL TRANSPORT; STATISTICS; DIFFEOMORPHISMS; FLOWS; SHAPE; DEFORMATIONS; REGRESSION; MODELS; SPACE	We propose novel finite-dimensional spaces of well-behaved R-n -> R-n transformations. The latter are obtained by (fast and highly-accurate) integration of continuous piecewise-affine velocity fields. The proposed method is simple yet highly expressive, effortlessly handles optional constraints (e.g., volume preservation and/or boundary conditions), and supports convenient modeling choices such as smoothing priors and coarse-to-fine analysis. Importantly, the proposed approach, partly due to its rapid likelihood evaluations and partly due to its other properties, facilitates tractable inference over rich transformation spaces, including using Markov-Chain Monte-Carlo methods. Its applications include, but are not limited to: monotonic regression (more generally, optimization over monotonic functions); modeling cumulative distribution functions or histograms; time-warping; image warping; image registration; real-time diffeomorphic image editing; data augmentation for image classifiers. Our GPU-based code is publicly available.	[Freifeld, Oren] Ben Gurion Univ Beer Sheva, Dept Comp Sci, IL-84105 Beer Sheva, Israel; [Batmanghelich, Kayhan; Fisher, Jonn W., III] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Hauberg, Soren] DTU Compute, Sect Cognit Syst, DK-2800 Lyngby, Denmark	Ben Gurion University; Massachusetts Institute of Technology (MIT); Technical University of Denmark	Freifeld, O (corresponding author), Ben Gurion Univ Beer Sheva, Dept Comp Sci, IL-84105 Beer Sheva, Israel.	orenfr@cs.bgu.ac.il; sohau@dtu.dk; kayhan@csail.mit.edu; Fisher@csail.mit.edu	; Hauberg, Soren/L-2104-2016	Freifeld, Oren/0000-0001-9816-9709; Hauberg, Soren/0000-0001-7223-877X	U.S. Office of Naval Research MURI [N000141110688]; U.S. ARO MURI [W911NF-11-1-0391]; Danish Council for Independent Research, Natural Sciences; VITALITE; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB005149] Funding Source: NIH RePORTER	U.S. Office of Naval Research MURI(MURIOffice of Naval Research); U.S. ARO MURI(MURI); Danish Council for Independent Research, Natural Sciences(Det Frie Forskningsrad (DFF)); VITALITE; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	O.F. and J.W.F. are partially supported by U.S. Office of Naval Research MURI program, award N000141110688, and VITALITE, which receives support from U.S. ARO MURI, award W911NF-11-1-0391. S.H. was funded by the Danish Council for Independent Research, Natural Sciences.	Al-Mohy AH, 2011, SIAM J SCI COMPUT, V33, P488, DOI 10.1137/100788860; Allassonniere S, 2015, SIAM J IMAGING SCI, V8, P1367, DOI 10.1137/140971762; Allassonniere S, 2010, BERNOULLI, V16, P641, DOI 10.3150/09-BEJ229; [Anonymous], 2010, PATTERN THEORY STOCH; ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015; Arsigny V, 2005, MED IMAGE ANAL, V9, P507, DOI 10.1016/j.media.2005.04.001; Arsigny V., 2006, BIOMEDICAL IMAGE REG; Arsigny V, 2006, LECT NOTES COMPUT SC, V4190, P924; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Censi A, 2013, IEEE INT CONF ROBOT, P2860, DOI 10.1109/ICRA.2013.6630973; Censi A, 2012, IEEE INT CONF ROBOT, P3657, DOI 10.1109/ICRA.2012.6225318; Chen TL, 2014, J APPL STAT, V41, P242, DOI 10.1080/02664763.2013.838667; Cootes T., 2005, 16 BRIT MACH VIS C, V2, P879; Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326; Durrleman S, 2013, INT J COMPUT VISION, V101, P161, DOI 10.1007/s11263-012-0556-1; Fawzi A., 2016, P BRIT MACH VIS C; Fletcher PT, 2013, INT J COMPUT VISION, V105, P171, DOI 10.1007/s11263-012-0591-y; Fletcher PT, 2003, PROC CVPR IEEE, P95; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Freifeld O., 2012, P 12 EUR C COMP VIS; Freifeld O, 2015, IEEE I CONF COMP VIS, P2911, DOI 10.1109/ICCV.2015.333; Freifeld O, 2014, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2014.179; Galun M, 2015, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2015.257; Gawlik ES, 2011, PHYSICA D, V240, P1724, DOI 10.1016/j.physd.2011.07.011; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Grenander U., 2007, PATTERN THEORY REPRE; Grenander U., 1993, GEN PATTERN THEORY M; Guo H., 2006, HDB MATH MODELS COMP; HARANDI MT, 2014, P EUR C COMPUT VIS, V8690, P17; Hauberg S., 2016, 19 INT C ART INT STA; Hinkle J, 2014, J MATH IMAGING VIS, V50, P32, DOI 10.1007/s10851-013-0489-5; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Jayasumana S, 2013, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2013.17; Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431; Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276457, 10.1145/1239451.1239515]; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Lin D., 2010, CHILD ISS LAWS PROGR, P1; Lin DH, 2009, PROC CVPR IEEE, P747, DOI 10.1109/CVPRW.2009.5206660; Liu C, 2001, PROC CVPR IEEE, P192; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lorenzi M., 2011, INFORM PROCESSING ME; Lorenzi M, 2013, INT J COMPUT VISION, V105, P111, DOI 10.1007/s11263-012-0598-4; Mansi T, 2011, INT J COMPUT VISION, V92, P92, DOI 10.1007/s11263-010-0405-z; Miller EG, 2003, PROC CVPR IEEE, P114; Moler C, 2003, SIAM REV, V45, P3, DOI 10.1137/S00361445024180; Nielsen M, 2008, J MATH IMAGING VIS, V31, P221, DOI 10.1007/s10851-008-0083-4; Nilsson Adam, 2013, 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2013), P1208, DOI 10.1109/IROS.2013.6696504; Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2; Pennec X, 1999, PROCEEDINGS OF THE IEEE-EURASIP WORKSHOP ON NONLINEAR SIGNAL AND IMAGE PROCESSING (NSIP'99), P194; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Sommer S, 2010, LECT NOTES COMPUT SC, V6316, P43, DOI 10.1007/978-3-642-15567-3_4; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Srivastava A., 2007, IEEE C COMP VIS PATT, P1; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Szeliski R., 2010, COMPUTER VISION ALGO, DOI DOI 10.1007/978-3-030-34372-9; Taheri S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P306, DOI 10.1109/FG.2011.5771415; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023; Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040; Weber O, 2012, COMPUT GRAPH FORUM, V31, P2409, DOI 10.1111/j.1467-8659.2012.03130.x; Wulff J, 2015, PROC CVPR IEEE, P120, DOI 10.1109/CVPR.2015.7298607; Xie Q, 2013, IEEE I CONF COMP VIS, P865, DOI 10.1109/ICCV.2013.112; Younes L, 2012, IMAGE VISION COMPUT, V30, P389, DOI 10.1016/j.imavis.2011.09.009; Zhang M., 2016, ALGORITHMIC ADV RIEM; Zhang Miaomiao, 2015, Inf Process Med Imaging, V24, P249, DOI 10.1007/978-3-319-19992-4_19	69	9	9	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2496	2509		10.1109/TPAMI.2016.2646685	http://dx.doi.org/10.1109/TPAMI.2016.2646685			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28092517	Green Accepted, Green Submitted			2022-12-18	WOS:000414395400013
J	Wu, TF; Lu, Y; Zhu, SC				Wu, Tianfu; Lu, Yang; Zhu, Song-Chun			Online Object Tracking, Learning and Parsing with And-Or Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; and-or graph; latent SVM; dynamic programming; intrackability	ROBUST VISUAL TRACKING; MODELS	This paper presents a method, called AOGTracker, for simultaneously tracking, learning and parsing (TLP) of unknown objects in video sequences with a hierarchical and compositional And-Or graph (AOG) representation. The TLP method is formulated in the Bayesian framework with a spatial and a temporal dynamic programming (DP) algorithms inferring object bounding boxes on-thefly. During online learning, the AOG is discriminatively learned using latent SVM [1] to account for appearance (e.g., lighting and partial occlusion) and structural (e.g., different poses and viewpoints) variations of a tracked object, as well as distractors (e.g., similar objects) in background. Three key issues in online inference and learning are addressed: (i) maintaining purity of positive and negative examples collected online, (ii) controling model complexity in latent structure learning, and (iii) identifying critical moments to re-learn the structure of AOG based on its intrackability. The intrackability measures uncertainty of an AOG based on its score maps in a frame. In experiments, our AOGTracker is tested on two popular tracking benchmarks with the same parameter setting: the TB-100/50/CVPR2013 benchmarks [2], [3], and the VOT benchmarks [4]-VOT 2013, 2014, 2015 and TIR2015 (thermal imagery tracking). In the former, our AOGTracker outperforms state-of-the-art tracking algorithms including two trackers based on deep convolutional network [5], [6]. In the latter, our AOGTracker outperforms all other trackers in VOT2013 and is comparable to the state-of-the-art methods in VOT2014, 2015 and TIR2015.	[Wu, Tianfu] Univ Calif Los Angeles, Los Angeles, CA 90095 USA; [Wu, Tianfu] North Carolina State Univ, Dept Elect & Comp Engn & Visual Narrat Cluster, Raleigh, NC 27695 USA; [Lu, Yang] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat & Comp Sci, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of North Carolina; North Carolina State University; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Wu, TF (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.; Wu, TF (corresponding author), North Carolina State Univ, Dept Elect & Comp Engn & Visual Narrat Cluster, Raleigh, NC 27695 USA.	tianfu_wu@ncsu.edu; yanglv@ucla.edu; sczhu@stat.ucla.edu		Wu, Tianfu/0000-0001-8911-5506	DARPA SIMPLEX Award [1010 N66001-15-C-4035]; ONR MURI grant [N00014-16-1-2007]; US National Science Foundation [IIS-1423305]; ECE at NCSU [201473-02119]; NVIDIA Corporation	DARPA SIMPLEX Award; ONR MURI grant; US National Science Foundation(National Science Foundation (NSF)); ECE at NCSU; NVIDIA Corporation	This work was supported by the DARPA SIMPLEX Award 1010 N66001-15-C-4035, the ONR MURI grant N00014-16-1-2007 and US National Science Foundation IIS-1423305. T. Wu was also supported by the ECE startup fund 201473-02119 at NCSU. We thank Steven Holtzen for proofreading this paper. We thank the two reviewers for their helpful comments on improving the presentation of this paper. We also gratefully acknowledge the support of NVIDIA Corporation with the donation of one GPU.	Adam A., 2006, IEEE C COMP VIS PATT; Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881; Batra D, 2012, LECT NOTES COMPUT SC, V7576, P1, DOI 10.1007/978-3-642-33715-4_1; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bischof H., 2006, BMVC, P47; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Carey S., 2011, ORIGIN CONCEPTS; Cehovin L., 2013, VISUAL OBJECT TRACKI; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733; Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22; Everingham M., PASCAL VISUAL OBJECT; Felzenszwalb P., 2010, TR201002 U CHIC DEP; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Goldberg AV, 1997, J ALGORITHM, V22, P1, DOI 10.1006/jagm.1995.0805; Gong HF, 2012, INT J COMPUT VISION, V97, P255, DOI 10.1007/s11263-011-0486-3; GRABNER H, 2008, P EUR C COMP VIS, V5302, P234; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; HONG S, 2014, PROC 13 EUR CONF, V8689, P1; Hong S, 2013, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2013.285; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kristan M., 2015, CORR; Kristan M., 2014, P INT C COMP VIS, P191; Kristan M., 2015, VISUAL OBJECT TRACKI; Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32; Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li X., 2013, CORR; Li X, 2013, IEEE T PATTERN ANAL, V35, P863, DOI 10.1109/TPAMI.2012.166; Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730; Lu Y, 2014, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2014.443; Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; NAM H, 2014, PROC 13 EUR CONF, V8693, P112; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Park D, 2011, IEEE I CONF COMP VIS, P2627, DOI 10.1109/ICCV.2011.6126552; Pei MT, 2013, COMPUT VIS IMAGE UND, V117, P1369, DOI 10.1016/j.cviu.2012.12.003; PEREZ P, 2002, P 7 EUR C COMP VIS, V2350, P661, DOI DOI 10.1007/3-540-47969-4_44; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Song X, 2013, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2013.421; Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445; Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308; Vojir T., 2011, P COMP VIS WINT WORK, P91; Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445; Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307; Wang N., 2015, CORR; Wu Y., 2013, P IEEE C COMP VIS PA, P241; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878; Xiao JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P137, DOI 10.1109/ICCVW.2013.24; Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhang K., 2015, CORR; Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; Zhao Y., 2011, ADV NEURAL INFORM PR, V24, P73; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	81	9	9	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2465	2480		10.1109/TPAMI.2016.2644963	http://dx.doi.org/10.1109/TPAMI.2016.2644963			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28026751	hybrid, Green Submitted			2022-12-18	WOS:000414395400011
J	Sun, M; Farhadi, A; Taskar, B; Seitz, S				Sun, Min; Farhadi, Ali; Taskar, Ben; Seitz, Steve			Summarizing Unconstrained Videos Using Salient Montages	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video summarization; video saliency detection	TRACKING; PREDICT; MODEL; GAZE	We present a novel method to summarize unconstrained videos using salient montages (i.e., a "melange" of frames in the video as shown in Fig. 1), by finding "montageable moments" and identifying the salient people and actions to depict in each montage. Our method aims at addressing the increasing need for generating concise visualizations from the large number of videos being captured from portable devices. Our main contributions are (1) the process of finding salient people and moments to form a montage, and (2) the application of this method to videos taken "in the wild" where the camera moves freely. As such, we demonstrate results on head-mounted cameras, where the camera moves constantly, as well as on videos downloaded from YouTube. In our experiments, we show that our method can reliably detect and track humans under significant action and camera motion. Moreover, the predicted salient people are more accurate than results from state-of-the-art video salieny method [1]. Finally, we demonstrate that a novel "montageability" score can be used to retrieve results with relatively high precision which allows us to present high quality montages to users.	[Sun, Min] Natl Tsing Hua Univ, Hsinchu 30013, Taiwan; [Farhadi, Ali; Taskar, Ben; Seitz, Steve] Univ Washington, Seattle, WA 98105 USA	National Tsing Hua University; University of Washington; University of Washington Seattle	Sun, M (corresponding author), Natl Tsing Hua Univ, Hsinchu 30013, Taiwan.	sunmin@ee.nthu.edu.tw; ali@cs.uw.edu; taskar@cs.washington.edu; seitz@cs.washington.edu			Microsoft; Google; Intel; TerraSwarm research center; US National Science Foundation [IIS-1338054, IIS-1218683]; ONR [N00014-13-1-0720, MURI N00014-10-1-0934]; MOST [103-2218-E-007-025]	Microsoft(Microsoft); Google(Google Incorporated); Intel(Intel Corporation); TerraSwarm research center; US National Science Foundation(National Science Foundation (NSF)); ONR(Office of Naval Research); MOST	We thank Microsoft, Google, Intel, the TerraSwarm research center, US National Science Foundation IIS-1338054, US National Science Foundation IIS-1218683, ONR N00014-13-1-0720, ONR MURI N00014-10-1-0934, and MOST 103-2218-E-007-025 for supporting this research.	Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Aner A, 2002, LECT NOTES COMPUT SC, V2353, P388; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Borgo R., 2011, EUROGRAPHICS 2011 ST; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Chen S, 2014, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2014.148; Cremonesi P., 2010, P 2010 ACM C RECOMME, P39, DOI [10.1145/1864708.1864721, DOI 10.1145/1864708.1864721]; Cui X, 2009, C P ACM INT C MULTIM, P617, DOI DOI 10.1145/1631272.1631370; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Felzenszwalb P.F., 2012, DISCRIMINATIVELY TRA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fragkiadaki K, 2012, LECT NOTES COMPUT SC, V7576, P552, DOI 10.1007/978-3-642-33715-4_40; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Goldman DB, 2006, ACM T GRAPHIC, V25, P862, DOI 10.1145/1141911.1141967; Gong B., 2014, ADV NEURAL INFORM PR, P2069; Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772; Guo C., 2008, P CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587715; Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; Joshi N, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P251; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348; Kolekar MH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1617, DOI 10.1109/ICME.2006.262856; Kopf J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601195; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31; Liu F., 2008, P 16 ACM INT C MULT, P329, DOI [10.1145/1459359.1459404, DOI 10.1145/1459359.1459404]; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350; Lucas B. D., 1981, IJCAI, P121, DOI DOI 10.5555/1623264.1623280; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Massey M, 1996, IBM SYST J, V35, P557, DOI 10.1147/sj.353.0557; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472; Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z; Nepal S., 2001, P 9 ACM INT C MULTIM, P261, DOI DOI 10.1145/500141.500181; Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; POTAPOV D, 2014, PROC 13 EUR CONF, V8694, P540; Pritch Y, 2007, IEEE I CONF COMP VIS, P833; Rav-Acha A., P 2006 IEEE COMP SOC, P435; Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Sun M., 2014, P EUR C COMPUT VIS, P472; Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51; Sunkavalli K, 2012, IEEE T VIS COMPUT GR, V18, P1868, DOI 10.1109/TVCG.2012.72; Tang H, 2011, IEEE INT CON MULTI; Vondrick C., 2011, INT J COMPUT VISION, V101, P1; Wang JH, 2004, Proceedings of the World Engineers' Convention 2004: Vol D, Environment Protection and Disaster Mitigation, P599; Xiong Z., 2005, 2005 IEEE International Conference on Multimedia and Expo; Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322	57	9	9	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2256	2269		10.1109/TPAMI.2016.2623699	http://dx.doi.org/10.1109/TPAMI.2016.2623699			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	27959796	hybrid			2022-12-18	WOS:000412028600011
J	Spampinato, C; Palazzo, S; Giordano, D				Spampinato, Concetto; Palazzo, Simone; Giordano, Daniela			Gamifying Video Object Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interactive video annotation; games with a purpose; human in the loop; spatio-temporal superpixel segmentation	EXTRACTION; TRACKING	Video object segmentation can be considered as one of the most challenging computer vision problems. Indeed, so far, no existing solution is able to effectively deal with the peculiarities of real-world videos, especially in cases of articulated motion and object occlusions; limitations that appear more evident when we compare the performance of automated methods with the human one. However, manually segmenting objects in videos is largely impractical as it requires a lot of time and concentration. To address this problem, in this paper we propose an interactive video object segmentation method, which exploits, on one hand, the capability of humans to identify correctly objects in visual scenes, and on the other hand, the collective human brainpower to solve challenging and large-scale tasks. In particular, our method relies on a game with a purpose to collect human inputs on object locations, followed by an accurate segmentation phase achieved by optimizing an energy function encoding spatial and temporal constraints between object regions as well as human-provided location priors. Performance analysis carried out on complex video benchmarks, and exploiting data provided by over 60 users, demonstrated that our method shows a better trade-off between annotation times and segmentation accuracy than interactive video annotation and automated video object segmentation approaches.	[Spampinato, Concetto; Palazzo, Simone; Giordano, Daniela] Univ Catania, Dept Elect Elect & Comp Engn, Pattern Recognit & Comp Vis Lab PeRCeiVe Lab, I-95124 Catania, Italy	University of Catania	Spampinato, C (corresponding author), Univ Catania, Dept Elect Elect & Comp Engn, Pattern Recognit & Comp Vis Lab PeRCeiVe Lab, I-95124 Catania, Italy.	cspampin@dieei.unict.it; palazzosim@dieei.unict.it; dgiordan@dieei.unict.it		Spampinato, Concetto/0000-0001-6653-2577; Palazzo, Simone/0000-0002-2441-0982				Achanta R., 2010, 149300 EPFL; Addis M., 2010, P 1 INT DIG PRES INT P 1 INT DIG PRES INT, P3; Badrinarayanan V, 2014, INT J COMPUT VISION, V110, P14, DOI 10.1007/s11263-013-0673-5; Badrinarayanan V, 2010, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR.2010.5540054; Bai X, 2010, LECT NOTES COMPUT SC, V6315, P617; Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Budvytis I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2257, DOI 10.1109/CVPR.2011.5995600; Donahue J, 2011, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2011.6126394; Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI DOI 10.1109/CVPR.2008.4587581; Fathi A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.78; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Galasso F, 2013, IEEE I CONF COMP VIS, P3527, DOI 10.1109/ICCV.2013.438; Giordano D, 2015, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2015.7299114; Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228; Gorelick L, 2013, PROC CVPR IEEE, P1714, DOI 10.1109/CVPR.2013.224; Hacker S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1207; Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243; Jain Aditya, 2015, Int J Appl Basic Med Res, V5, P124, DOI 10.4103/2229-516X.157168; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81; Kavasidis I, 2013, IEEE COMPUT SOC CONF, P694, DOI 10.1109/CVPRW.2013.105; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Li L., 2003, P 11 ACM INT C MULT, P2, DOI DOI 10.1145/957013.957017; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817; Lim J, 2014, LECT NOTES COMPUT SC, V8693, P173, DOI 10.1007/978-3-319-10602-1_12; Liu C., 2009, P 10 EUR C COMP VI 3, P28; McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008; MORRISON D, 2009, P ACM SIGKDD WORKSH, P44; Nagaraja NS, 2015, IEEE I CONF COMP VIS, P3235, DOI 10.1109/ICCV.2015.370; NAPPER GENEVIEVE A, VISION RES, V37, P1557, DOI [10.1016/S0042-6989(03, DOI 10.1016/S0042-6989(96)00269-6, 10.1016/s0042-6989(96)00269-6, DOI 10.1016/S0042-6989(99)00163-7]; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Oei AC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058546; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Salvo R. D., 2016, P IEEE WINT C APPL C, P1, DOI [10.1109/WACV.2016.7477718, DOI 10.1109/WACV.2016.7477718]; Siorpaes K, 2008, LECT NOTES COMPUT SC, V5021, P751; Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003; Spampinato C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1231, DOI 10.1145/2733373.2806324; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Vedaldi A, 2014, PROC CVPR IEEE, P3622, DOI 10.1109/CVPR.2014.463; von Ahn L., 2006, P SIGCHI C HUMAN FAC, P55, DOI DOI 10.1145/1124772.1124782; von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719; Von Ahn Luis, 2004, P SIGCHI C HUM FACT, P319, DOI DOI 10.1145/985692.985733; Von Ahn Luis., 2006, P SIGCHI C HUMAN FAC, P79; Zhang BC, 2011, IEEE T CIRC SYST VID, V21, P29, DOI 10.1109/TCSVT.2011.2105591; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhang Y, 2015, PROC CVPR IEEE, P3641, DOI 10.1109/CVPR.2015.7298987	54	9	10	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					1942	1958		10.1109/TPAMI.2016.2610973	http://dx.doi.org/10.1109/TPAMI.2016.2610973			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27662670	Green Submitted			2022-12-18	WOS:000408807600004
J	Hassner, T; Filosof, S; Mayzels, V; Zelnik-Manor, L				Hassner, Tal; Filosof, Shay; Mayzels, Viki; Zelnik-Manor, Lihi			SIFTing Through Scales	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vision and scene understanding; representations; data structures; and transforms		Scale invariant feature detectors often find stable scales in only a few image pixels. Consequently, methods for feature matching typically choose one of two extreme options: matching a sparse set of scale invariant features, or dense matching using arbitrary scales. In this paper, we turn our attention to the overwhelming majority of pixels, those where stable scales are not found by standard techniques. We ask, is scale- selection necessary for these pixels, when dense, scale- invariant matching is required and if so, how can it be achieved? We make the following contributions: (i) We show that features computed over different scales, even in low- contrast areas, can be different and selecting a single scale, arbitrarily or otherwise, may lead to poor matches when the images have different scales. (ii) We show that representing each pixel as a set of SIFTs, extracted at multiple scales, allows for far better matches than single- scale descriptors, but at a computational price. Finally, (iii) we demonstrate that each such set may be accurately represented by a low- dimensional, linear subspace. A subspace- to- point mapping may further be used to produce a novel descriptor representation, the Scale- Less SIFT (SLS), as an alternative to single- scale descriptors. These claims are verified by quantitative and qualitative tests, demonstrating significant improvements over existing methods. A preliminary version of this work appeared in [1].	[Hassner, Tal; Filosof, Shay] Open Univ Israel, Dept Math & Comp Sci, IL-4353701 Raanana, Israel; [Mayzels, Viki; Zelnik-Manor, Lihi] Technion, Dept Elect Engn, IL-3200003 Haifa, Israel	Open University Israel; Technion Israel Institute of Technology	Hassner, T (corresponding author), Open Univ Israel, Dept Math & Comp Sci, IL-4353701 Raanana, Israel.	hassner@openu.ac.il; shayfilosof@gmail.com; mviki@techunix.technion.ac.il; lihi@ee.technion.ac.il			Ollendorf foundation; Israel Ministry of Science; Israel Science Foundation [1179/11]	Ollendorf foundation; Israel Ministry of Science(Ministry of Science, Technology and Space (MOST), Israel); Israel Science Foundation(Israel Science Foundation)	Lihi Zelnik-Manor was supported in part by the Ollendorf foundation, the Israel Ministry of Science, and by the Israel Science Foundation under Grant 1179/11.	Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Basri Ronen, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P109, DOI 10.1109/ICCVW.2009.5457710; Basri R., 2007, COMPUTER VISION PATT, P1; Basri R, 2011, IEEE T PATTERN ANAL, V33, P266, DOI 10.1109/TPAMI.2010.110; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662; Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Hartley R., 2004, ROBOTICA; Hassner T., 2015, DENSE IMAGE CORRES C; Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Kannala J, 2008, PROC CVPR IEEE, P1006; Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56; Ke Y, 2004, PROC CVPR IEEE, P506; Knyazev Andrew V, 2012, ARXIV12090523; Kokkinos I., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587798; Levi G, 2016, P IEEE WINT C APPL C, P1, DOI DOI 10.1109/WACV.2016.7477723; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lindeberg T., 1999, HDB COMPUTER VISION, P239; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K., 2002, THESIS; Morel JM, 2011, INVERSE PROBL IMAG, V5, P115, DOI 10.3934/ipi.2011.5.115; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Qiu WC, 2014, IEEE WINT CONF APPL, P1112, DOI 10.1109/WACV.2014.6835734; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Saxena Ashutosh, 2005, ADV NEURAL INFORM PR; Simon I., 2007, CVPR, P1; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; Tau M, 2016, IEEE T PATTERN ANAL, V38, P875, DOI 10.1109/TPAMI.2015.2474356; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Trulls E, 2013, PROC CVPR IEEE, P2890, DOI 10.1109/CVPR.2013.372; Varma M., 2007, P IEEE INT C COMP VI, V1, P1, DOI DOI 10.1109/ICCV.2007.4408875; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Xu L, 2012, LECT NOTES COMPUT SC, V7573, P385, DOI 10.1007/978-3-642-33709-3_28; Yao J, 2006, SIGNAL PROCESS-IMAGE, V21, P506, DOI 10.1016/j.image.2006.03.005	45	9	9	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1431	1443		10.1109/TPAMI.2016.2592916	http://dx.doi.org/10.1109/TPAMI.2016.2592916			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27448341				2022-12-18	WOS:000402744400012
J	Collins, T; Bartoli, A				Collins, Toby; Bartoli, Adrien			Planar Structure-from-Motion with Affine Camera Models: Closed-Form Solutions, Ambiguities and Degeneracy Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structure-from-Motion; factorization; stratification; critical motion; degeneracy; ambiguity; plane; orthographic; weak-perspective; para-perspective	PROJECTIVE RECONSTRUCTION; SHAPE; POSE; PARAPERSPECTIVE	Planar Structure-from-Motion (SfM) is the problem of reconstructing a planar object or surface from a set of 2D images using motion information. The problemis well-understood with the perspective camera model and can be solved with Homography Decomposition (HD). However when the structure is small and/or viewed far from the camera the perspective effects diminish, and in the limit the projections become affine. In these situations HD fails because the problem itself becomes ill-posed. We propose a stable alternative using affine camera models. These have been used extensively to reconstruct non-planar structures, however a general, accurate and closed-form method for planar structures has been missing. The problemis fundamentally different with planar structures because the types of affine camera models one can use are more restricted and it is inherently more ambiguous and non-linear. We provide a closed-form method for the orthographic camera model that solves the general problem (three or more views with three or more correspondences and missing correspondences) and returns all metric structure solutions and corresponding camera poses. The method does not require initialisation, and optimises an objective function that is very similar to the reprojection error. In fact there is no clear benefit in refining its solutions with bundle adjustment, which is a remarkable result. We also present a new theoretical analysis that deepens our understanding of the problem. The main result is the necessary and sufficient geometric conditions for the problem to be degenerate with the orthographic camera. We also show there can exist up to two solutions for metric structure with four or more views (previously it was assumed to be unique), and we give the necessary and sufficient geometric conditions for disambiguation. Other theoretical results include showing that in the case of three images the optimal reconstruction (with respect to reprojection error) can usually be found in closed-form, and additional prior knowledge needed to solve with non-orthographic affine cameras.	[Collins, Toby; Bartoli, Adrien] Univ Auvergne, ALCoV ISIT CNRS, F-63000 Clermont Ferrand, France	Universite Clermont Auvergne (UCA)	Collins, T (corresponding author), Univ Auvergne, ALCoV ISIT CNRS, F-63000 Clermont Ferrand, France.	Toby.Collins@gmail.com; adrien.bartoli@gmail.com	Collins, Toby/Q-8967-2019		EU's FP7 ERC [307483 FLEXABLE]; Almerys Corporation	EU's FP7 ERC; Almerys Corporation	This research has received funding from the EU's FP7 ERC research grant 307483 FLEXABLE and Almerys Corporation.	Bartoli A, 2008, IEEE T PATTERN ANAL, V30, P2098, DOI 10.1109/TPAMI.2008.22; Bouguet J.-Y., 2016, CAMERA CALIBRATION T; Collins T., 2010, P INT WORKSHOP VISIO, P339; Collins T, 2014, INT J COMPUT VISION, V109, P252, DOI 10.1007/s11263-014-0725-5; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Hartley R., 2004, ROBOTICA; Hartley R, 2007, INT J COMPUT VISION, V71, P5, DOI 10.1007/s11263-005-4796-1; Henrion D, 2009, OPTIM METHOD SOFTW, V24, P761, DOI 10.1080/10556780802699201; HOFFMAN DD, 1986, BIOL CYBERN, V54, P71, DOI 10.1007/BF00320477; Horaud R, 1997, INT J COMPUT VISION, V22, P173, DOI 10.1023/A:1007940112931; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; Kanatani K, 2007, IEICE T INF SYST, VE90D, P851, DOI 10.1093/ietisy/e90-d.5.851; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Lobay A, 2006, INT J COMPUT VISION, V67, P71, DOI 10.1007/s11263-006-4068-8; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malis E., 2007, RR6303 INRIA; Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; Quan L, 1996, INT J COMPUT VISION, V19, P93, DOI 10.1007/BF00131149; Sturm P, 2000, IEEE T PATTERN ANAL, V22, P1199, DOI 10.1109/34.879804; Sturm P, 2000, PROC CVPR IEEE, P706, DOI 10.1109/CVPR.2000.855889; Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211; Taylor J, 2010, PROC CVPR IEEE, P2761, DOI 10.1109/CVPR.2010.5540002; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tresadern P, 2005, PROC CVPR IEEE, P1110; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Triggs B, 1997, IMAGE VISION COMPUT, V15, P617, DOI 10.1016/S0262-8856(97)00016-4; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Vedaldi A., 2016, VLFEAT OPEN PORTABLE; WEINSHALL D, 1995, IEEE T PATTERN ANAL, V17, P512, DOI 10.1109/34.391392; Zhang Z., 1996, P ARPA IM UND WORKSH, P6249	34	9	10	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1237	1255		10.1109/TPAMI.2016.2578333	http://dx.doi.org/10.1109/TPAMI.2016.2578333			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27295655				2022-12-18	WOS:000401091200014
J	Tward, D; Miller, M; Trouve, A; Younes, L				Tward, Daniel; Miller, Michael; Trouve, Alain; Younes, Laurent			Parametric Surface Diffeomorphometry for Low Dimensional Embeddings of Dense Segmentations and Imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational anatomy; diffeomorphometry; shape analysis; medical imaging; neuroimaging	ACTIVE CONTOURS; SHAPE; SNAKES; KNOWLEDGE; METRICS; DRIVEN; MAPS	In the field of Computational Anatomy, biological form (including our focus, neuroanatomy) is studied quantitatively through the action of the diffeomorphism group on example anatomies - a technique called diffeomorphometry. Here we design an algorithm within this framework to pass from dense objects common in neuromaging studies (binary segmentations, structural images) to a sparse representation defined on the surface boundaries of anatomical structures, and embedded into the low dimensional coordinates of a parametric model. Our main new contribution is to introduce an expanded group action to simultaneously deform surfaces through direct mapping of points, as well as images through functional composition with the inverse. This allows us to index the diffeomorphisms with respect to two-dimensional surface geometries like subcortical gray matter structures, but explicitly map onto cost functions determined by noisy 3-dimensional measurements. We consider models generated from empirical covariance of training data, as well as bandlimited (Laplace-Beltrami eigenfunction) models when no such data is available. We show applications to noisy or anomalous segmentations, and other typical problems in neuroimaging studies. We reproduce statistical results detecting changes in Alzheimer's disease, despite dimensionality reduction. Lastly we apply our algorithm to the common problem of segmenting subcortical structures from T1MR images.	[Tward, Daniel; Miller, Michael] Johns Hopkins Sch Med, Dept Biomed Engn, Baltimore, MD 21218 USA; [Trouve, Alain] Ecole Normale Super, Ctr Math & Leurs Applicat, F-94230 Paris, France; [Younes, Laurent] Johns Hopkins Univ, Dept Appl Math & Stat, Whiting Sch Engn, Baltimore, MD 21218 USA	Johns Hopkins University; Johns Hopkins Medicine; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Johns Hopkins University	Tward, D (corresponding author), Johns Hopkins Sch Med, Dept Biomed Engn, Baltimore, MD 21218 USA.	dtward@cis.jhu.edu; mim@cis.jhu.edu; trouve@cmla.ens-cachan.fr; laurent.younes@jhu.edu		Tward, Daniel/0000-0002-4607-6807; Younes, Laurent/0000-0003-2017-9565	US National Center for Research Resources; National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) [P41 EB015909]; NIH [U01 NS082085-01, U01 AG033655]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [P41EB015909, R01EB008171] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [U01NS082085] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON AGING [U01AG033655, U19AG033655] Funding Source: NIH RePORTER	US National Center for Research Resources(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This project was supported by the US National Center for Research Resources and the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) through Grant Number P41 EB015909. The PREDICT project was supported by NIH grant U01 NS082085-01. The BIOCARD project was supported by NIH grant U01 AG033655.	Alexandrov O, 2005, J COMPUT PHYS, V204, P121, DOI 10.1016/j.jcp.2004.10.005; Ardekani Siamak, 2012, Statistical Atlases and Computational Models of the Heart. Imaging and Modelling Challenges. Second International Workshop, STACOM 2011 Held in Conjunction with MICCAI 2011. Revised Selected Papers, P234, DOI 10.1007/978-3-642-28326-0_24; Ashburner J, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P49, DOI 10.1016/B978-012372560-8/50004-8; Ashburner J, 2009, MAGN RESON IMAGING, V27, P1163, DOI 10.1016/j.mri.2009.01.006; Bernal-Rusiel JL, 2013, NEUROIMAGE, V66, P249, DOI 10.1016/j.neuroimage.2012.10.065; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Ceritoglu C, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00151; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; Cremers D, 2007, PROC SPIE, V6512, DOI 10.1117/12.708609; Du J, 2011, NEUROIMAGE, V56, P162, DOI 10.1016/j.neuroimage.2011.01.067; Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326; Durrleman S, 2013, INT J COMPUT VISION, V101, P161, DOI 10.1007/s11263-012-0556-1; Durrleman S, 2012, LECT NOTES COMPUT SC, V7512, P223, DOI 10.1007/978-3-642-33454-2_28; Durrleman S, 2008, LECT NOTES COMPUT SC, V5242, P390, DOI 10.1007/978-3-540-85990-1_47; Glaunes J, 2008, INT J COMPUT VISION, V80, P317, DOI 10.1007/s11263-008-0141-9; Grenander M., 2007, PATTERN THEORY REPRE; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732; Grenander U., 1991, HANDS PATTERN THEORE; Gu LX, 2006, INT J COMPUT ASS RAD, V1, P23, DOI 10.1007/s11548-006-0001-4; Haller JW, 1997, RADIOLOGY, V202, P504, DOI 10.1148/radiology.202.2.9015081; Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Khan AR, 2008, NEUROIMAGE, V41, P735, DOI 10.1016/j.neuroimage.2008.03.024; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Le Guyader C, 2008, IEEE T IMAGE PROCESS, V17, P767, DOI 10.1109/TIP.2008.919951; Li X, 2012, MED PHYS, V39, P6550, DOI 10.1118/1.4754584; Ma J, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/974957; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Memoli F, 2004, NEUROIMAGE, V23, pS179, DOI 10.1016/j.neuroimage.2004.07.072; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Micheli M, 2013, IZV MATH+, V77, P541, DOI [10.4213/im7966, 10.1070/IM2013v077n03ABEH002648]; Michor PW, 2007, APPL COMPUT HARMON A, V23, P74, DOI 10.1016/j.acha.2006.07.004; Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0; Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733; Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514; Miller MI, 2004, NEUROIMAGE, V23, pS19, DOI 10.1016/j.neuroimage.2004.07.021; Miller MI, 2014, TECHNOLOGY, V2, P36, DOI 10.1142/S2339547814500010; Miller MI, 2013, NEUROIMAGE-CLIN, V3, P352, DOI 10.1016/j.nicl.2013.09.001; Nichols T, 2003, STAT METHODS MED RES, V12, P419, DOI 10.1191/0962280203sm341ra; Niethammer M, 2011, LECT NOTES COMPUT SC, V6892, P655, DOI 10.1007/978-3-642-23629-7_80; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; Pennec X, 2009, LECT NOTES COMPUT SC, V5416, P347; Qiu AQ, 2006, IEEE T MED IMAGING, V25, P1296, DOI 10.1109/TMI.2006.882143; Qiu AQ, 2012, IEEE T MED IMAGING, V31, P302, DOI 10.1109/TMI.2011.2168567; Qiu AQ, 2009, NEUROIMAGE, V45, P656, DOI 10.1016/j.neuroimage.2009.01.013; Qiu AQ, 2009, AM J PSYCHIAT, V166, P74, DOI 10.1176/appi.ajp.2008.08030426; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93; Schwarz T, 2007, COMPUT CARDIOL, V34, P741, DOI 10.1109/CIC.2007.4745592; Segars WP, 2013, MED PHYS, V40, DOI 10.1118/1.4794178; STANIFORTH A, 1991, MON WEATHER REV, V119, P2206, DOI 10.1175/1520-0493(1991)119<2206:SLISFA>2.0.CO;2; Sundaramoorthi G, 2007, IEEE T IMAGE PROCESS, V16, P803, DOI 10.1109/TIP.2007.891071; Thompson P. M., 2002, Computing and Visualization in Science, V5, P13, DOI 10.1007/s00791-002-0084-6; Toga AW, 2001, ANAT RECORD, V265, P37, DOI 10.1002/ar.1057; Trouve A., 1995, APPROACH PATTERN REC; Tward DJ, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/205494; Vaillant M, 2005, LECT NOTES COMPUT SC, V3565, P381; Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023; Vialard FX, 2012, INT J COMPUT VISION, V97, P229, DOI 10.1007/s11263-011-0481-8; Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665; Younes L., 2010, APPL MATH SCI SERIES, V171; Younes L, 2008, REND LINCEI-MAT APPL, V19, P25; Younes L, 2014, HUM BRAIN MAPP, V35, P792, DOI 10.1002/hbm.22214; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	71	9	9	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1195	1208		10.1109/TPAMI.2016.2578317	http://dx.doi.org/10.1109/TPAMI.2016.2578317			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27295651	Green Accepted			2022-12-18	WOS:000401091200011
J	Wang, LM; Chen, MH; Rodrigues, M; Wilcox, D; Calderbank, R; Carin, L				Wang, Liming; Chen, Minhua; Rodrigues, Miguel; Wilcox, David; Calderbank, Robert; Carin, Lawrence			Information-Theoretic Compressive Measurement Design	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Information-theoretic metric; information bottleneck; projection design; gradient of mutual information; compressive sensing	MUTUAL INFORMATION; FEATURE-EXTRACTION; GAUSSIAN CHANNELS; MATRIX; ERROR	An information-theoretic projection design framework is proposed, of interest for feature design and compressive measurements. Both Gaussian and Poisson measurement models are considered. The gradient of a proposed information-theoretic metric (ITM) is derived, and a gradient-descent algorithm is applied in design; connections are made to the information bottleneck. The fundamental solution structure of such design is revealed in the case of a Gaussian measurement model and arbitrary input statistics. This new theoretical result reveals how ITM parameter settings impact the number of needed projection measurements, with this verified experimentally. The ITM achieves promising results on real data, for both signal recovery and classification.	[Wang, Liming; Calderbank, Robert; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Chen, Minhua] Univ Chicago, Dept Comp Sci & Stat, Chicago, IL 60637 USA; [Wilcox, David] Purdue Univ, Dept Chem, W Lafayette, IN 47907 USA; [Rodrigues, Miguel] UCL, Dept Elect & Elect Engn, London WC1E 7JE, England	Duke University; University of Chicago; Purdue University System; Purdue University; Purdue University West Lafayette Campus; University of London; University College London	Wang, LM (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	liming.w@duke.edu; minhua@cs.uchicago.edu; m.rodrigues@ee.ucl.ac.uk; wilcoxd@purdue.edu; robert.calderbank@duke.edu; lcarin@duke.edu		Carin, Lawrence/0000-0001-6277-7948				[Anonymous], [No title captured]; Bishop CM, 2006, PATTERN RECOGNITION, V1; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Carson WR, 2012, SIAM J IMAGING SCI, V5, P1185, DOI 10.1137/120878380; Chen M., 2012, P 29 INT C MACH LEAR, P919; Chen MH, 2010, IEEE T SIGNAL PROCES, V58, P6140, DOI 10.1109/TSP.2010.2070796; Cover T.M., 2012, ELEMENTS INFORM THEO, DOI DOI 10.1002/047174882X; Creutzig F, 2008, NEURAL COMPUT, V20, P1026, DOI 10.1162/neco.2008.01-07-455; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Guo DN, 2005, IEEE T INFORM THEORY, V51, P1261, DOI 10.1109/TIT.2005.844072; Gut A., 1995, INTERMEDIATE COURSE, V1; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hild KE, 2006, IEEE T PATTERN ANAL, V28, P1385, DOI 10.1109/TPAMI.2006.186; Horn R.A., 2013, MATRIX ANAL, VSecond; Hsu W. H., 2006, P 14 ANN ACM INT C M, P35, DOI [10.1145/1180639.1180654, DOI 10.1145/1180639.1180654]; Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345; Kaski S., 2003, P 20 INT C MACH LEAR, P329; Nenadic Z, 2007, IEEE T PATTERN ANAL, V29, P1394, DOI 10.1109/TPAMI.2007.1156; Palomar DP, 2007, IEEE T INFORM THEORY, V53, P453, DOI 10.1109/TIT.2006.889728; Perez-Cruz F, 2010, IEEE T INFORM THEORY, V56, P1070, DOI 10.1109/TIT.2009.2039045; Prasad S., 2012, CERTAIN RELATIONS MU; Seeger M.W., 2008, P 25 INT C MACH LEAR, P912; Slonim N, 2006, NEURAL COMPUT, V18, P1739, DOI 10.1162/neco.2006.18.8.1739; Song L., 2008, P 20 INT C NEUR INF, P1385; Tang B, 2010, IEEE T SIGNAL PROCES, V58, P4684, DOI 10.1109/TSP.2010.2050885; Tishby N., 2000, ADV NEURAL INFORM PR, P640; Tishby Naftali, 1999, ALL C COMM CONTR COM; Torkkola K., 2003, Journal of Machine Learning Research, V3, P1415, DOI 10.1162/153244303322753742; Torkkola K., 2001, P ADV NEUR INF PROC, P969; Wang L., 2013, ADV NEURAL INF PROCE, P1142; Wang L., 2013, P IEEE INT S INF THE, P454; Wang LM, 2014, IEEE T INFORM THEORY, V60, P2611, DOI 10.1109/TIT.2014.2307068; Wilcox DS, 2012, ANAL CHIM ACTA, V755, P17, DOI 10.1016/j.aca.2012.10.005; Xiao CS, 2011, IEEE T SIGNAL PROCES, V59, P3301, DOI 10.1109/TSP.2011.2140112; Zheng LZ, 2002, IEEE T INFORM THEORY, V48, P359, DOI 10.1109/18.978730; Zhou Mingyuan, 2012, AISTATS, P1462	40	9	9	3	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1150	1164		10.1109/TPAMI.2016.2568189	http://dx.doi.org/10.1109/TPAMI.2016.2568189			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27187951	Green Published			2022-12-18	WOS:000401091200008
J	Mitra, A; Biswas, S; Bhattacharyya, C				Mitra, Adway; Biswas, Soma; Bhattacharyya, Chiranjib			Bayesian Modeling of Temporal Coherence in Videos for Entity Discovery and Summarization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; Chinese restaurant process; temporal coherence; temporal segmentation; tracklet clustering; entity discovery; entity-driven video summarization		A video is understood by users in terms of entities present in it. Entity Discovery is the task of building appearance model for each entity (e. g., a person), and finding all its occurrences in the video. We represent a video as a sequence of tracklets, each spanning 10-20 frames, and associated with one entity. We pose Entity Discovery as tracklet clustering, and approach it by leveraging Temporal Coherence (TC): the property that temporally neighboring tracklets are likely to be associated with the same entity. Our major contributions are the first Bayesian nonparametric models for TC at tracklet-level. We extend Chinese Restaurant Process (CRP) to TC-CRP, and further to Temporally Coherent Chinese Restaurant Franchise (TC-CRF) to jointly model entities and temporal segments using mixture components and sparse distributions. For discovering persons in TV serial videos without meta-data like scripts, these methods show considerable improvement over state-of-the-art approaches to tracklet clustering in terms of clustering accuracy, cluster purity and entity coverage. The proposed methods can perform online tracklet clustering on streaming videos unlike existing approaches, and can automatically reject false tracklets. Finally we discuss entity-driven video summarization-where temporal segments of the video are selected based on the discovered entities, to create a semantically meaningful summary.	[Mitra, Adway; Bhattacharyya, Chiranjib] Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; [Biswas, Soma] Indian Inst Sci, Elect Engn, Bangalore, Karnataka, India	Indian Institute of Science (IISC) - Bangalore; Indian Institute of Science (IISC) - Bangalore	Mitra, A (corresponding author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	adway.cse@gmail.com; soma.biswas@ee.iisc.ernet.in; chiranjib.bhattacharyya@gmail.com			Department of Science and Technology (Government of India)	Department of Science and Technology (Government of India)(Department of Science & Technology (India))	This research is partially supported by grants from Department of Science and Technology (Government of India).	Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Arandjelovic O., 2006, P IEEE C COMP VIS PA, V2, P1513; Babacan SD, 2012, IEEE T SIGNAL PROCES, V60, P3964, DOI 10.1109/TSP.2012.2197748; Blei DM, 2011, J MACH LEARN RES, V12, P2461; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chao Liang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3377, DOI 10.1109/CVPR.2011.5995681; Chiu WC, 2013, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2013.48; Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951; Ding XH, 2011, IEEE T IMAGE PROCESS, V20, P3419, DOI 10.1109/TIP.2011.2156801; Du L., 2013, P 2013 C N AM CHAPT, P190; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Fox E. B., 2008, 25 INT C MACHINE LEA, P312; Gorur D, 2010, J COMPUT SCI TECH-CH, V25, P653, DOI [10.1007/s11390-010-1051-1, 10.1007/s11390-010-9355-8]; Griffiths T.L., 2005, ADV NEURAL INFORM PR; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Kawale J., 2013, P 2013 SIAM INT C DA, P103; Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205; Lu Z, 2007, NEURAL COMPUT, V19, P1528, DOI 10.1162/neco.2007.19.6.1528; Mitra Adway, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P465, DOI 10.1007/978-3-642-40991-2_30; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35; Sang J., 2010, P 18 ACM INT C MULTI, P855, DOI DOI 10.1145/1873951.1874096; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Sharma P, 2013, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2013.418; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tang K., 2012, ADV NEURAL INFORM PR; Tapaswi M, 2012, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2012.6247986; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Tierney S, 2014, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2014.134; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wang X., DATA MINING KNOWL DI, V28, P1; Williamson S., 2010, ICML; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu BY, 2013, IEEE I CONF COMP VIS, P2856, DOI 10.1109/ICCV.2013.355; Wu BY, 2013, PROC CVPR IEEE, P3507, DOI 10.1109/CVPR.2013.450; Xiao SJ, 2014, LECT NOTES COMPUT SC, V8694, P123, DOI 10.1007/978-3-319-10599-4_9; Xu X., 2015, ARXIV150707458; Zhang YF, 2009, IEEE T MULTIMEDIA, V11, P1276, DOI 10.1109/TMM.2009.2030629	44	9	9	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					430	443		10.1109/TPAMI.2016.2557785	http://dx.doi.org/10.1109/TPAMI.2016.2557785			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	27116733				2022-12-18	WOS:000395555100002
J	Zhao, RQ; Martinez, AM				Zhao, Ruiqi; Martinez, Aleix M.			Labeled Graph Kernel for Behavior Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; kernel; classification; decoding; computational model; multimodal	RECOGNITION	Automatic behavior analysis from video is a major topic in many areas of research, including computer vision, multimedia, robotics, biology, cognitive science, social psychology, psychiatry, and linguistics. Two major problems are of interest when analyzing behavior. First, we wish to automatically categorize observed behaviors into a discrete set of classes (i.e., classification). For example, to determine word production from video sequences in sign language. Second, we wish to understand the relevance of each behavioral feature in achieving this classification (i.e., decoding). For instance, to know which behavior variables are used to discriminate between the words apple and onion in American Sign Language (ASL). The present paper proposes to model behavior using a labeled graph, where the nodes define behavioral features and the edges are labels specifying their order (e.g., before, overlaps, start). In this approach, classification reduces to a simple labeled graph matching. Unfortunately, the complexity of labeled graph matching grows exponentially with the number of categories we wish to represent. Here, we derive a graph kernel to quickly and accurately compute this graph similarity. This approach is very general and can be plugged into any kernel-based classifier. Specifically, we derive a Labeled Graph Support Vector Machine (LGSVM) and a Labeled Graph Logistic Regressor (LGLR) that can be readily employed to discriminate between many actions (e.g., sign language concepts). The derived approach can be readily used for decoding too, yielding invaluable information for the understanding of a problem (e.g., to know how to teach a sign language). The derived algorithms allow us to achieve higher accuracy results than those of state-of-the-art algorithms in a fraction of the time. We show experimental results on a variety of problems and datasets, including multimodal data.	[Zhao, Ruiqi; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43201 USA	University System of Ohio; Ohio State University	Zhao, RQ (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43201 USA.	zhao.823@osu.edu; aleix@ece.osu.edu			NATIONAL EYE INSTITUTE [R01EY020834] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC014498] Funding Source: NIH RePORTER; NEI NIH HHS [R01 EY020834] Funding Source: Medline; NIDCD NIH HHS [R01 DC014498] Funding Source: Medline	NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD)); NEI NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NIDCD NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))		Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0; Athitsos Vassilis, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563181; Benitez-Quiroz CF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086268; Bishop C.M, 2006, PATTERN RECOGN; Brentari D., 1998, PROSODIC MODEL SIGN; Chartrand G., 2006, INTRO GRAPH THEORY; Chen M., 2013, THESIS; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Cuturi M., 2011, P 28 INT C MACH LEAR, P929; DIESTEL R, 2005, GRAPH THEORY; Ding LY, 2009, IMAGE VISION COMPUT, V27, P1826, DOI 10.1016/j.imavis.2009.02.005; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7; Emmorey K., 2013, SIGNS LANGUAGE REVIS; Eyjolfsdottir E, 2014, LECT NOTES COMPUT SC, V8690, P772, DOI 10.1007/978-3-319-10605-2_50; Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597; FLEISCHMAN M, 2006, P 8 ACM INT WORKSH M, P183; Frank A., 2011, UCI MACHINE LEARNING, P22; Gartner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11; Girard JM, 2015, BEHAV RES METHODS, V47, P1136, DOI 10.3758/s13428-014-0536-1; Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049; Inokuchi A., 2003, INT C MACHINE LEARNI, P321; Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31; Jeni LA, 2014, LECT NOTES COMPUT SC, V8692, P135, DOI 10.1007/978-3-319-10593-2_10; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Mahe P, 2004, P 21 INT C MACH LEAR, DOI DOI 10.1145/1015330.1015446; Martinez A, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P35, DOI 10.1109/IVL.1999.781120; Nalin M., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P351, DOI 10.1109/ROMAN.2012.6343778; Natarajan P., 2007, P IEEE WORKSH MOT VI, P10, DOI DOI 10.1109/WMVC.2007.12; Nayak S, 2012, J MACH LEARN RES, V13, P2589; Ni BB, 2012, LECT NOTES COMPUT SC, V7573, P173, DOI 10.1007/978-3-642-33709-3_13; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Niedenthal P. M., 2006, PSYCHOL EMOTION INTE; Nowozin S, 2007, IEEE I CONF COMP VIS, P1727; Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Ong EJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.55; Ong EJ, 2012, PROC CVPR IEEE, P2200, DOI 10.1109/CVPR.2012.6247928; Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1; Pei J, 2001, PROC INT CONF DATA, P215; Pitsikalis V, 2011, CVPRW, P1, DOI DOI 10.1109/CVPRW.2011.5981681; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, P1357, DOI 10.1162/153244303322753706; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Su JY, 2014, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2014.86; Vapnik V, 1997, ADV NEUR IN, V9, P281; VONDERMALSBURG C, 1988, NEURAL NETWORKS, V1, P141, DOI 10.1016/0893-6080(88)90016-0; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333; Wang Xingxing, 2012, ASIAN C COMPUTER VIS, P572; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286	54	9	9	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1640	1650		10.1109/TPAMI.2015.2481404	http://dx.doi.org/10.1109/TPAMI.2015.2481404			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26415154	Green Accepted			2022-12-18	WOS:000379926200012
J	Martins, P; Henriques, JF; Caseiro, R; Batista, J				Martins, Pedro; Henriques, Joao F.; Caseiro, Rui; Batista, Jorge			Bayesian Constrained Local Models Revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-rigid face alignment; face registration; constrained local models (CLM); active shape models (ASM)	FACE ALIGNMENT; SHAPE MODEL; LOCALIZATION	This paper presents a novel Bayesian formulation for aligning faces in unseen images. Our approach revisits the Constrained Local Models (CLM) formulation where an ensemble of local feature detectors are constrained to lie within the subspace spanned by a Point Distribution Model (PDM). Fitting such a model to an image typically involves two main steps: a local search using a detector, obtaining response maps for each landmark (likelihood term) and a global optimization that finds the PDM parameters that jointly maximize all the detections at once. The so-called global optimization can be posed as a Bayesian inference problem, where the posterior distribution of the shape (and pose) parameters can be inferred in a maximum a posteriori (MAP) sense. This work introduces an extended Bayesian global optimization strategy that includes two novel additions: (1) to perform second order updates of the PDM parameters (accounting for their covariance) and (2) to model the underlying dynamics of the shape variations, encoded in the prior term, by using recursive Bayesian estimation. Extensive evaluations were performed against state-of-the-art methods on several standard datasets (IMM, BioID, XM2VTS, LFW and FGNET Talking Face). Results show that the proposed approach significantly increases the fitting performance.	[Martins, Pedro; Henriques, Joao F.; Caseiro, Rui; Batista, Jorge] Univ Coimbra, ISR, P-3000 Coimbra, Portugal	Universidade de Coimbra	Martins, P; Henriques, JF; Caseiro, R; Batista, J (corresponding author), Univ Coimbra, ISR, P-3000 Coimbra, Portugal.	pedromartins@isr.uc.pt; henriques@isr.uc.pt; ruicaseiro@isr.uc.pt; batista@isr.uc.pt	Batista, Jorge/A-4196-2011; Martins, Pedro/GWC-7702-2022	Batista, Jorge/0000-0003-2387-5961; Henriques, Joao F./0000-0002-2478-2102; Martins, Pedro/0000-0001-8984-4506	Portuguese Science Foundation (FCT) [PTDC/EIA-CCO/108791/2008, PTDC/EEA-CRO/122812/2010]; FCT [SFRH/BPD/90200/2012, SFRH/BD/75459/2010, SFRH/BD/74152/2010]	Portuguese Science Foundation (FCT)(Portuguese Foundation for Science and Technology); FCT(Portuguese Foundation for Science and TechnologyEuropean Commission)	This work was supported by the Portuguese Science Foundation (FCT) under the projects with grants: PTDC/EIA-CCO/108791/2008 and PTDC/EEA-CRO/122812/2010. P. Martins, J. Henriques and R. Caseiro also acknowledge the FCT through grants SFRH/BPD/90200/2012, SFRH/BD/75459/2010 and SFRH/BD/74152/2010, respectively.	Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bishop C.M, 2006, PATTERN RECOGN; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Cheng XL, 2013, 2013 IEEE MILITARY COMMUNICATIONS CONFERENCE (MILCOM 2013), P1, DOI 10.1109/MILCOM.2013.9; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cootes T. F., 2004, IMAG SCI BIOMED ENG; Cootes T. F., 2012, LECT NOTES COMPUT SC, P278, DOI DOI 10.1007/978-3-642-33786-4; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2003, P BRIT MACH VIS C; Cristinacce D., 2006, P BRIT MACH VIS C, V3, P929; Cristinacce D., 2007, P BMVC, P880; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Fanelli G, 2013, IEEE INT CONF AUTOMA; FGNet, 2004, TALK FAC VID; Gelman A., 2004, BAYESIAN DATA ANAL, V2nd, DOI DOI 10.1201/9780429258411; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Huang G.B., 2008, WORKSHOP FACESREAL L; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Martins P., 2012, P EUR C COMP VIS, P55; Martins P., 2012, P BRIT MACH VIS C; Martins P, 2014, IEEE IMAGE PROC, P303, DOI 10.1109/ICIP.2014.7025060; Martins P, 2014, PROC CVPR IEEE, P1797, DOI 10.1109/CVPR.2014.232; Martins P, 2013, COMPUT VIS IMAGE UND, V117, P250, DOI 10.1016/j.cviu.2012.11.010; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Nguyen MH, 2010, INT J COMPUT VISION, V88, P69, DOI 10.1007/s11263-009-0299-9; Nordstrom M., 2004, IMM200403160 DTU; Paquet U, 2009, PROC CVPR IEEE, P1193, DOI 10.1109/CVPRW.2009.5206751; Rapp V, 2013, IMAGE VISION COMPUT, V31, P542, DOI 10.1016/j.imavis.2013.04.006; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Saragih J, 2007, IEEE I CONF COMP VIS, P2173; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377; SARAGIH JM, 2009, P IEEE INT C COMP VI, P2248; Shen CH, 2007, IEEE T IMAGE PROCESS, V16, P1457, DOI 10.1109/TIP.2007.894233; Smith BM, 2012, LECT NOTES COMPUT SC, V7574, P43, DOI 10.1007/978-3-642-33712-3_4; Tresaderrn P., 2009, P BRIT MACH VIS C, P1; TZIMIROPOULOS G, 2012, AS C COMP VIS, P650; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang YL, 2008, PPAR RES, V2008, DOI 10.1155/2008/209629; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Xue Z, 2003, PATTERN RECOGN, V36, P2819, DOI 10.1016/S0031-3203(03)00181-X; Zhou Y, 2003, PROC CVPR IEEE, P109; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	53	9	9	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					704	716		10.1109/TPAMI.2015.2462343	http://dx.doi.org/10.1109/TPAMI.2015.2462343			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959675				2022-12-18	WOS:000372549700008
J	Ni, BB; Moulin, P; Yan, SC				Ni, Bingbing; Moulin, Pierre; Yan, Shuicheng			Order Preserving Sparse Coding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse coding; order preserving; time sequence classification; scene classification	SELECTION	In this paper, we investigate order-preserving sparse coding for classifying structured data whose atomic features possess ordering relationships. Examples include time sequences where individual frame-wise features are temporally ordered, as well as still images (landscape, street view, etc.) where different regions of the image are spatially ordered. Classification of these structured data is often tackled by first decomposing the input data into individual atomic features, then performing sparse coding or other processing for each atomic feature vector independently, and finally aggregating individual responses to classify the input data. However, this heuristic approach ignores the underlying order of the individual atomic features within the input data, and results in suboptimal discriminative capability. In this work, we introduce an order preserving regularizer which aims to preserve the ordering structure of the reconstruction coefficients within the sparse coding framework. An efficient Nesterov-type smooth approximation method is developed for optimization of the new regularization criterion, with theoretically guaranteed error bound. We perform extensive experiments for time series classification on a synthetic dataset, several machine learning benchmarks, and an RGB-D human activity dataset. We also report experiments for scene classification on a benchmark image dataset. The encoded representation is discriminative and robust, and our classifier outperforms state-of-the-art methods on these tasks.	[Ni, Bingbing] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Moulin, Pierre] Univ Illinois, Dept Elect & Comp Engn, Beckman Inst, Urbana, IL 61801 USA; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	University of Illinois System; University of Illinois Urbana-Champaign; National University of Singapore	Ni, BB (corresponding author), Adv Digital Sci Ctr, Singapore 138632, Singapore.	bingbing.ni@adsc.com.sg; moulin@ifp.uiuc.edu; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022		Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR)	Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR)(Agency for Science Technology & Research (A*STAR))	This study was supported by a research grant for the Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR). Part of this work was presented at ECCV 2012.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Balasubramanian K., 2013, P INT C MACH LEARN; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Cadieu C. F., 2008, ADV NEURAL INFORM PR, P209; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Hammami N, 2010, INT CONF COMP SCI, P521, DOI 10.1109/ICCSIT.2010.5563892; Hayashi A, 2005, LECT NOTES ARTIF INT, V3587, P356; Kadous MW, 2002, THESIS U NEW S WALES; Kim S, 2006, J MACH LEARN RES, V7, P945; Kim T., 2010, NIPS 10, P1117; Kobayashi T, 2013, PROC CVPR IEEE, P747, DOI 10.1109/CVPR.2013.102; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manning CD, 1999, FDN STAT NATURAL LAN; Megalooikonomou V, 2005, PROC INT CONF DATA, P668; MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x; Nanopoulos A, 2001, INFORMATION PROCESSING AND TECHNOLOGY, P49; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Rodriguez J. J., 2004, P 2004 ACM S APPL CO, P548; Sadeghi F, 2012, LECT NOTES COMPUT SC, V7576, P228, DOI 10.1007/978-3-642-33715-4_17; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Shen Y., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587755; Sung J., 2011, CORR; Tibshirani R, 2005, J R STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Tron R., 2008, P IEEE C COMP VIS PA, P1; Tseng P., 2008, SIAM J OPTIM; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wang ZT, 2012, RADIOCARBON, V54, P195, DOI 10.2458/azu_js_rc.v54i2.15869; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xi X., 2006, P 23 INT C MACHINE L, P1033, DOI 10.1145/1143844.1143974; Yan SY, 2012, LECT NOTES COMPUT SC, V7575, P473, DOI 10.1007/978-3-642-33765-9_34; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zhang J., 2006, CMULTI06006; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	38	9	9	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1615	1628		10.1109/TPAMI.2014.2362935	http://dx.doi.org/10.1109/TPAMI.2014.2362935			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26352999				2022-12-18	WOS:000357591900007
J	Shabat, G; Shmueli, Y; Bermanis, A; Averbuch, A				Shabat, Gil; Shmueli, Yaniv; Bermanis, Amit; Averbuch, Amir			Accelerating Particle Filter Using Randomized Multiscale and Fast Multipole Type Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Particle filter; multiscale methods; nonlinear tracking; fast multipole method	ALGORITHM; TRACKING	Particle filter is a powerful tool for state tracking using non-linear observations. We present a multiscale based method that accelerates the tracking computation by particle filters. Unlike the conventional way, which calculates weights over all particles in each cycle of the algorithm, we sample a small subset from the source particles using matrix decomposition methods. Then, we apply a function extension algorithm that uses a particle subset to recover the density function for all the rest of the particles not included in the chosen subset. The computational effort is substantial especially when multiple objects are tracked concurrently. The proposed algorithm significantly reduces the computational load. By using the Fast Gaussian Transform, the complexity of the particle selection step is reduced to a linear time in n and k, where n is the number of particles and k is the number of particles in the selected subset. We demonstrate our method on both simulated and on real data such as object tracking in video sequences.	[Shabat, Gil; Shmueli, Yaniv; Bermanis, Amit; Averbuch, Amir] Tel Aviv Univ, IL-69978 Tel Aviv, Israel	Tel Aviv University	Shabat, G (corresponding author), Tel Aviv Univ, IL-69978 Tel Aviv, Israel.				Israel Science Foundation [1041/10]; Israeli Ministry of Science Technology [3-9096, 3-10898]; US Israel Binational Science Foundation [BSF 2012282]; Jyvaskyla University	Israel Science Foundation(Israel Science Foundation); Israeli Ministry of Science Technology; US Israel Binational Science Foundation(US-Israel Binational Science Foundation); Jyvaskyla University	This research was partially supported by the Israel Science Foundation (Grant No. 1041/10), by the Israeli Ministry of Science & Technology (Grants No. 3-9096, 3-10898), by US Israel Binational Science Foundation (BSF 2012282) and by a Fellowship from Jyvaskyla University. G. Shabat is the corresponding author.	Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Baker C. T. H., 1977, NUMERICAL TREATMENT, V13; Bermanis A, 2013, APPL COMPUT HARMON A, V34, P15, DOI 10.1016/j.acha.2012.03.002; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Cham T.-J., 1999, P IEEE COMP SOC C CO, V2, P244, DOI DOI 10.1109/CVPR.1999.784636; Cheng H, 2005, SIAM J SCI COMPUT, V26, P1389, DOI 10.1137/030602678; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; DEUTSCHER J, 2000, P IEEE C COMP VIS PA, V2, P126, DOI DOI 10.1109/CVPR.2000.854758; Doucet A., 2009, HDB NONLINEAR FILTER, V12, P656; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Feder T., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, P434, DOI 10.1145/62212.62255; Flannery B.P., 1992, NUMERICAL RECIPES C; Golub G.H., 1996, MATRIX COMPUTATIONS, V3; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; GREENGARD L, 1987, J COMPUT PHYS, V73, P325, DOI 10.1016/0021-9991(87)90140-9; Gupta N, 2002, IETE J RES, V48, P237, DOI 10.1080/03772063.2002.11416282; Han B, 2009, IEEE T PATTERN ANAL, V31, P919, DOI 10.1109/TPAMI.2008.134; Han T.X., 2006, IEEE COMPUTER SOC C, V1, P214; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2602, DOI 10.1109/TSP.2003.816754; Martinsson PG, 2011, APPL COMPUT HARMON A, V30, P47, DOI 10.1016/j.acha.2010.02.003; Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Ristic B., 2004, KALMAN FILTER PARTIC; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Rui Y, 2001, PROC CVPR IEEE, P786; Sminchisescu C, 2003, PROC CVPR IEEE, P69; Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8; Urtasun R., 2006, 2006 IEEE COMP VIS P, P238, DOI DOI 10.1109/CVPR.2006.15; van der Merwe R, 2001, ADV NEUR IN, V13, P584; Wan E., 2000, CUEDFINFENGTR380; Wang FS, 2013, COMPUT J, V56, P1102, DOI 10.1093/comjnl/bxs141; Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464; Zhang XQ, 2010, LECT NOTES COMPUT SC, V5995, P236	36	9	9	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1396	1407		10.1109/TPAMI.2015.2392754	http://dx.doi.org/10.1109/TPAMI.2015.2392754			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352448	Green Submitted			2022-12-18	WOS:000355931100008
J	Hu, WZ; Zhu, SC				Hu, Wenze; Zhu, Song-Chun			Learning 3D Object Templates by Quantizing Geometry and Appearance Spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchical models; 3D object models; structure learning; And-Or Tree; object detection; pose estimation	REPRESENTATION	While 3D object-centered shape-based models are appealing in comparison with 2D viewer-centered appearance-based models for their lower model complexities and potentially better view generalizabilities, the learning and inference of 3D models has been much less studied in the recent literature due to two factors: i) the enormous complexities of 3D shapes in geometric space; and ii) the gap between 3D shapes and their appearances in images. This paper aims at tackling the two problems by studying an And-Or Tree (AoT) representation that consists of two parts: i) a geometry-AoT quantizing the geometry space, i.e. the possible compositions of 3D volumetric parts and 2D surfaces within the volumes; and ii) an appearance-AoT quantizing the appearance space, i.e. the appearance variations of those shapes in different views. In this AoT, an And-node decomposes an entity into constituent parts, and an Or-node represents alternative ways of decompositions. Thus it can express a combinatorial number of geometry and appearance configurations through small dictionaries of 3D shape primitives and 2D image primitives. In the quantized space, the problem of learning a 3D object template is transformed to a structure search problem which can be efficiently solved in a dynamic programming algorithm by maximizing the information gain. We focus on learning 3D car templates from the AoT and collect a new car dataset featuring more diverse views. The learned car templates integrate both the shape-based model and the appearance-based model to combine the benefits of both. In experiments, we show three aspects: 1) the AoT is more efficient than the frequently used octree method in space representation; 2) the learned 3D car template matches the state-of-the art performances on car detection and pose estimation in a public multi-view car dataset; and 3) in our new dataset, the learned 3D template solves the joint task of simultaneous object detection, pose/view estimation, and part localization. It can generalize over unseen views and performs better than the version 5 of the DPM model in terms of object detection and semantic part localization.	[Hu, Wenze; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Hu, WZ (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	wzhu@stat.ucla.edu; sczhu@stat.ucla.edu			NSF [IIS 1018751, DMS 1007889]; ONR MURI [N00014-10-1-0933]; DARPA MSEE [FA8650-11-1-7149]	NSF(National Science Foundation (NSF)); ONR MURI(MURIOffice of Naval Research); DARPA MSEE	This project was supported by NSF IIS 1018751, ONR MURI N00014-10-1-0933, DARPA MSEE grant FA8650-11-1-7149 and NSF DMS 1007889. The author would also like to thank Dr. Yingnian Wu, Tianfu Wu, and Brandon Rothrock for insightful suggestions.	Arie-Nachimson M, 2009, IEEE I CONF COMP VIS, P1341, DOI 10.1109/ICCV.2009.5459310; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BINFORD TO, 1971, IEEE C SYST CONTR DE; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S; Fidler S., 2007, 2007 IEEE C COMP VIS, P1, DOI [10.1109/CVPR.2007.383269, DOI 10.1109/CVPR.2007.383269]; Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379; Hao S, 2009, IEEE I CONF COMP VIS, P213, DOI 10.1109/ICCV.2009.5459168; Hejrati M., 2012, NIPS; Hsiao E, 2010, PROC CVPR IEEE, P2653, DOI 10.1109/CVPR.2010.5539981; Hu WZ, 2012, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2012.6247945; Hu WZ, 2011, IEEE I CONF COMP VIS, P1808, DOI 10.1109/ICCV.2011.6126447; Hu WZ, 2010, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2010.5539910; Huo XM, 2005, IEEE T IMAGE PROCESS, V14, P1665, DOI 10.1109/TIP.2005.857273; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; Kushner A, 2007, ENCYCLOP MATH APPL, V101, P1; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Leibe B, 2003, PROC CVPR IEEE, P409; Li B, 2013, IEEE I CONF COMP VIS, P2560, DOI 10.1109/ICCV.2013.318; Liebelt J., 2008, P 2008 IEEE C COMPUT, P1; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Lopez-Sastre RJ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130367; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Marr D., 1982, VISION COMPUTATIONAL; Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Rabbani M., 2002, J ELECTRON IMAGING, V11, P286, DOI DOI 10.1117/1.1469618; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35; Thomas A., 2006, P IEEE C COMP VIS PA, V2, P1589; Urtasun R., 2012, P ADV NEUR INF PROC, P620; Wang S., 2012, P AS C COMP VIS, P796; Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400; Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0; Xiang Y, 2012, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2012.6248081; Yan P., 2007, COMP VIS 2007 ICCV 2, P1; Zhu L, 2008, LECT NOTES COMPUT SC, V5303, P759; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018; Zia M. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P569, DOI 10.1109/ICCVW.2011.6130294	42	9	10	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1190	1205		10.1109/TPAMI.2014.2362141	http://dx.doi.org/10.1109/TPAMI.2014.2362141			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357342	hybrid			2022-12-18	WOS:000354377100006
J	Knowles, DA; Ghahramani, Z				Knowles, David A.; Ghahramani, Zoubin			Pitman Yor Diffusion Trees for Bayesian Hierarchical Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; unsupervised learning; clustering methods; phylogeny; density estimation; robust algorithm	COALESCENT	In this paper we introduce the Pitman Yor Diffusion Tree (PYDT), a Bayesian non-parametric prior over tree structures which generalises the Dirichlet Diffusion Tree [30] and removes the restriction to binary branching structure. The generative process is described and shown to result in an exchangeable distribution over data points. We prove some theoretical properties of the model including showing its construction as the continuum limit of a nested Chinese restaurant process model. We then present two alternative MCMC samplers which allow us to model uncertainty over tree structures, and a computationally efficient greedy Bayesian EM search algorithm. Both algorithms use message passing on the tree structure. The utility of the model and algorithms is demonstrated on synthetic and real world data, both continuous and binary.	[Knowles, David A.] Stanford Univ, Menlo Pk, CA 94025 USA; [Ghahramani, Zoubin] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Stanford University; University of Cambridge	Knowles, DA (corresponding author), Stanford Univ, Menlo Pk, CA 94025 USA.			Knowles, David/0000-0002-7408-146X	Wolfson College, Cambridge; Microsoft Research Cambridge through the Roger Needham Scholarship; EPSRC [EP/I036575/1, EP/H019472/1]; Google; Micrsoft; Engineering and Physical Sciences Research Council [EP/I036575/1, EP/H019472/1] Funding Source: researchfish	Wolfson College, Cambridge; Microsoft Research Cambridge through the Roger Needham Scholarship(Microsoft); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Google(Google Incorporated); Micrsoft; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	David A. Knowles would like to thank Wolfson College, Cambridge and Microsoft Research Cambridge for funding through the Roger Needham Scholarship. Zoubin Ghahramani would like to acknowledge EPSRC Grants EP/I036575/1 and EP/H019472/1 and support from Google and Micrsoft. The authors thank Peter Orbanz and anonymous reviewers for help improving the manuscript.	ALDOUS D, 1991, ANN PROBAB, V19, P1, DOI 10.1214/aop/1176990534; Aldous D., 1983, LECT NOTES MATH, V1117, P1, DOI [10.1007/BFb0099420, DOI 10.1007/BFB0099421.1072]; Aldous D., 1996, RANDOM DISCRETE STRU, P1, DOI [10.1007/978-1-4612-0719-1_1, DOI 10.1007/978-1-4612-0719-1_1]; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Barretina J, 2012, NATURE, V483, P603, DOI 10.1038/nature11003; Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056; Blei DM, 2004, ADV NEUR IN, V16, P17; Blundell C., 2010, UAI, P65; Colless DH., 1982, SYST ZOOL, V31, P100, DOI [10.2307/2413420, DOI 10.2307/2413420]; Daume H., 2008, ADV NEURAL INFORM PR, P1321; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Eldon B, 2006, GENETICS, V172, P2621, DOI 10.1534/genetics.105.052175; Geweke J, 2004, J AM STAT ASSOC, V99, P799, DOI 10.1198/016214504000001132; Ghahramani Z, 2010, ADV NEURAL INF PROCE, V2010, P19; Ghahramani Z., 2005, P 22 INT C MACH LEAR, P297, DOI DOI 10.1145/1102351.1102389; Guyon I., 2005, ADV NEURAL INFORM PR, V17, P545; Haas B, 2008, ANN PROBAB, V36, P1790, DOI 10.1214/07-AOP377; HEDGECOCK D, 1994, GENETICS AND EVOLUTION OF AQUATIC ORGANISMS, P122; Hewitt E., 1955, T AM MATH SOC, V80, P470, DOI DOI 10.1090/S0002-9947-1955-0076206-8; Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105; Kingman J. F. C., 1993, POISSON PROCESSES; Kingman JFC., 1982, STOCHASTIC PROCESS A, V13, P235, DOI [10.1016/0304-4149(82)90011-4, DOI 10.1016/0304-4149(82)90011-4]; KNOWLES DA, 2011, P UAI; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Mccullagh P, 2008, BERNOULLI, V14, P988, DOI 10.3150/08-BEJ134; Minka T, 2010, INFERNET 24 MICROSOF; Minka T.P., 2001, P 17 C UNC ART INT, P362; Murray I., 2008, ADV NEURAL INF PROCE, V21, P9; Neal RM, 2003, BAYESIAN STATISTICS 7, P619; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Pitman J, 1997, ANN PROBAB, V25, P855; Pitman J, 1999, ANN PROBAB, V27, P1870, DOI 10.1214/aop/1022677552; Platt J.C., 2008, ADV NEURAL INFORM PR, P1473; Rao V., 2011, P 27 C UNC ART INT, P619; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Rogers JS, 1996, SYST BIOL, V45, P99, DOI 10.2307/2413515; Sagitov S, 1999, J APPL PROBAB, V36, P1116, DOI 10.1239/jap/1032374759; Teh Yee W., 2011, ADV NEURAL INFORM PR, P819; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	46	9	9	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					271	289		10.1109/TPAMI.2014.2313115	http://dx.doi.org/10.1109/TPAMI.2014.2313115			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353241				2022-12-18	WOS:000349625500006
J	Dai, ZW; Lucke, J				Dai, Zhenwen; Luecke, Joerg			Autonomous Document Cleaning-A Generative Approach to Reconstruct Strongly Corrupted Scanned Texts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Probabilistic generative models; document cleaning; scanned text; unsupervised learning; expectation maximization; variational approximation; expectation truncation	SPARSE; RECOGNITION; VISION; SEGMENTATION; RESTORATION; APPEARANCE; OBJECTS; IMAGES; MODEL	We study the task of cleaning scanned text documents that are strongly corrupted by dirt such as manual line strokes, spilled ink, etc. We aim at autonomously removing such corruptions from a single letter-size page based only on the information the page contains. Our approach first learns character representations from document patches without supervision. For learning, we use a probabilistic generative model parameterizing pattern features, their planar arrangements and their variances. The model's latent variables describe pattern position and class, and feature occurrences. Model parameters are efficiently inferred using a truncated variational EM approach. Based on the learned representation, a clean document can be recovered by identifying, for each patch, pattern class and position while a quality measure allows for discrimination between character and non-character patterns. For a full Latin alphabet we found that a single page does not contain sufficiently many character examples. However, even if heavily corrupted by dirt, we show that a page containing a lower number of character types can efficiently and autonomously be cleaned solely based on the structural regularity of the characters it contains. In different example applications with different alphabets, we demonstrate and discuss the effectiveness, efficiency and generality of the approach.	[Dai, Zhenwen] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England; [Luecke, Joerg] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, D-26111 Oldenburg, Germany; [Luecke, Joerg] Carl von Ossietzky Univ Oldenburg, Sch Med & Hlth Sci, D-26111 Oldenburg, Germany; [Luecke, Joerg] Tech Univ Berlin, Dept Elect Engn & Comp Sci, Berlin, Germany	University of Sheffield; Carl von Ossietzky Universitat Oldenburg; Carl von Ossietzky Universitat Oldenburg; Technical University of Berlin	Dai, ZW (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.	z.dai@sheffield.ac.uk; joerg.luecke@uni-oldenburg.de			German Research Foundation (DFG) [LU 1196/4-2]; Frankfurt Institute for Advanced Studies of the Goethe-University Frankfurt, Germany	German Research Foundation (DFG)(German Research Foundation (DFG)); Frankfurt Institute for Advanced Studies of the Goethe-University Frankfurt, Germany	This work was funded by the German Research Foundation (DFG) under grant LU 1196/4-2. Large parts of the research under the grant were done at the Frankfurt Institute for Advanced Studies of the Goethe-University Frankfurt, Germany (the previous institution of the authors).	Banerjee J, 2009, PROC CVPR IEEE, P517, DOI 10.1109/CVPRW.2009.5206601; BEKER H., 1982, CIPHER SYSTEMS PROTE; Bern M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P582, DOI 10.1109/ICIP.2000.899497; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Dai ZW, 2012, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2012.6247953; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DAYAN P, 1995, NEURAL COMPUT, V7, P565, DOI 10.1162/neco.1995.7.3.565; Frey BJ, 2003, PROC CVPR IEEE, P45; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Grimes DB, 2005, NEURAL COMPUT, V17, P47, DOI 10.1162/0899766052530893; Jackson JD, 2008, INT J COMPUT VISION, V79, P71, DOI 10.1007/s11263-007-0097-1; Jojic N, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P34; Jojic N., 2001, P IEEE C COMP VIS PA, P517; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kannan A., 2005, P 10 INT WORKSH ART, P166; Kannan A, 2008, INT J COMPUT VISION, V77, P87, DOI 10.1007/s11263-007-0094-4; Kindermann R., 1980, MARKOV RANDOM FIELDS, DOI [10.1090/conm/001, DOI 10.1090/CONM/001]; Kopec GE, 1996, P SOC PHOTO-OPT INS, V2660, P14, DOI 10.1117/12.234712; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; Korner E, 1999, NEURAL NETWORKS, V12, P989, DOI 10.1016/S0893-6080(99)00049-0; Lamme VAF, 2000, TRENDS NEUROSCI, V23, P571, DOI 10.1016/S0166-2236(00)01657-X; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907; Lee H., 2007, ADV NEURAL INF PROCE, P801; Li S, 2009, MARKOV RANDOM FIELD; Likforman-Sulem L, 2011, IMAGE VISION COMPUT, V29, P351, DOI 10.1016/j.imavis.2011.01.001; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucke J, 2010, J MACH LEARN RES, V11, P2855; Madec S, 2012, J COGNITIVE NEUROSCI, V24, P1645, DOI 10.1162/jocn_a_00178; MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3; Moghaddam RF, 2011, PATTERN RECOGN, V44, P363, DOI 10.1016/j.patcog.2010.07.027; Ni K, 2009, IEEE T PATTERN ANAL, V31, P2158, DOI 10.1109/TPAMI.2009.165; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700; Puertas G., 2010, ADV NEURAL INF PROCE, V23, P1939; Raizada RDS, 2003, CEREB CORTEX, V13, P100, DOI 10.1093/cercor/13.1.100; Schmidt U, 2010, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2010.5539844; Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y; Sun DQ, 2012, PROC CVPR IEEE, P1768, DOI 10.1109/CVPR.2012.6247873; Titsias M., 2004, P C COMP VIS PATT RE, P179; Wang CH, 2009, IEEE I CONF COMP VIS, P747; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096; Winn J., 2004, ADVANCES NEURAL INFO, P1505; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002; Zheng QG, 2001, IEEE IMAGE PROC, P193, DOI 10.1109/ICIP.2001.958986	48	9	10	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					1950	1962		10.1109/TPAMI.2014.2313126	http://dx.doi.org/10.1109/TPAMI.2014.2313126			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352627	hybrid, Green Submitted			2022-12-18	WOS:000341981300004
J	Han, F; Liu, H				Han, Fang; Liu, Han			High Dimensional Semiparametric Scale-Invariant Principal Component Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						High dimensional statistics; principal component analysis; nonparanormal distribution; robust statistics	POWER METHOD; RELAXATIONS	We propose a new high dimensional semiparametric principal component analysis (PCA) method, named Copula Component Analysis (COCA). The semiparametric model assumes that, after unspecified marginally monotone transformations, the distributions are multivariate Gaussian. COCA improves upon PCA and sparse PCA in three aspects: (i) It is robust to modeling assumptions; (ii) It is robust to outliers and data contamination; (iii) It is scale-invariant and yields more interpretable results. We prove that the COCA estimators obtain fast estimation rates and are feature selection consistent when the dimension is nearly exponentially large relative to the sample size. Careful experiments confirm that COCA outperforms sparse PCA on both synthetic and real-world data sets.	[Han, Fang] Johns Hopkins Univ, Dept Biostat, Baltimore, MD 21205 USA; [Liu, Han] Princeton Univ, Dept Operat Res & Financial Engn, Princeton, NJ 08540 USA	Johns Hopkins University; Princeton University	Han, F (corresponding author), Johns Hopkins Univ, Dept Biostat, Baltimore, MD 21205 USA.	fhan@jhsph.edu; hanliu@princeton.edu			NSF [III-1116730, III-1332109]; NIH [R01MH102339, R01GM083084, R01HG06841]; FDA [HHSF223201000072C]; Google; NATIONAL HUMAN GENOME RESEARCH INSTITUTE [R01HG006841] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM083084] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTH [R01MH102339] Funding Source: NIH RePORTER	NSF(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); FDA(United States Department of Health & Human Services); Google(Google Incorporated); NATIONAL HUMAN GENOME RESEARCH INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Human Genome Research Institute (NHGRI)); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))	The authors thank the associate editor and two anonymous reviewers, who made numerous helpful suggestions for improvements to the paper. The authors are supported by NSF Grants III-1116730 and NSF III-1332109, NIH R01MH102339, NIH R01GM083084, and NIH R01HG06841, and FDA HHSF223201000072C. Fang is also supported by a fellowship from Google.	Amini AA, 2009, ANN STAT, V37, P2877, DOI 10.1214/08-AOS664; Balasubramanian M, 2002, SCIENCE, V295; Berthet Q, 2013, ANN STAT, V41, P1780, DOI 10.1214/13-AOS1127; Borgognone MG, 2001, FOOD QUAL PREFER, V12, P323, DOI 10.1016/S0950-3293(01)00017-9; Chatfield C., 1980, INTRO MULTIVARIATE A, V166; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Eloyan A, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00061; Flury B., 1997, 1 COURSE MULTIVARIAT; Han F, 2012, ADV NEURAL INFORM PR, P171; Han Fang, 2013, ARXIV13056916; Johnson RA, 2007, APPL MULTIVARIATE ST; Johnstone IM, 2009, J AM STAT ASSOC, V104, P682, DOI 10.1198/jasa.2009.0121; Journee M, 2010, J MACH LEARN RES, V11, P517; Klaassen CAJ, 1997, BERNOULLI, V3, P55, DOI 10.2307/3318652; Konishi S., 1979, HIROSHIMA MATH J, V9, P647; KRUSKAL WH, 1958, J AM STAT ASSOC, V53, P814, DOI 10.2307/2281954; Leek JT, 2007, PLOS GENET, V3, P1724, DOI 10.1371/journal.pgen.0030161; Liu H, 2012, ANN STAT, V40, P2293, DOI 10.1214/12-AOS1037; Liu H, 2009, J MACH LEARN RES, V10, P2295; Ma ZM, 2013, ANN STAT, V41, P772, DOI 10.1214/13-AOS1097; Mackey L., 2009, P ADV NEUR INF PROC, V21, P1017; Mathematicien E.-U, 1958, INTRO MULTIVARIATE S, V2; McCall MN, 2010, BIOSTATISTICS, V11, P242, DOI 10.1093/biostatistics/kxp059; NAGAO H, 1988, ANN I STAT MATH, V40, P477, DOI 10.1007/BF00053060; Paul D., 2012, ARXIV12021242; Power JD, 2011, NEURON, V72, P665, DOI 10.1016/j.neuron.2011.09.006; Raskutti G, 2011, IEEE T INFORM THEORY, V57, P6976, DOI 10.1109/TIT.2011.2165799; Shen HP, 2008, J MULTIVARIATE ANAL, V99, P1015, DOI 10.1016/j.jmva.2007.06.007; Van De Geer S., 2000, EMPIRICAL PROCESSES, V105; Vu V., 2012, INT C ARTIFICIAL INT, P1278; Wegkamp M., 2013, ARXIV13056526; Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008; Yuan XT, 2013, J MACH LEARN RES, V14, P899; Zhang YW, 2012, INT SER OPER RES MAN, V166, P915, DOI 10.1007/978-1-4614-0769-0_31; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	36	9	9	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2016	2032		10.1109/TPAMI.2014.2307886	http://dx.doi.org/10.1109/TPAMI.2014.2307886			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352632	Green Submitted, Green Accepted			2022-12-18	WOS:000341981300009
J	Li, YJ; Li, HJ; Cai, Z				Li, Yujian; Li, Houjun; Cai, Zhi			Fast Orthogonal Haar Transform Pattern Matching via Image Square Sum	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Square sum; strip sum; pattern matching; template matching; orthogonal Haar transform; full search equivalent algorithm	PERFORMANCE EVALUATION; MOTION ESTIMATION; RECOGNITION	Although using image strip sum, an orthogonal Haar transform (OHT) pattern matching algorithm may have good performance, it requires three subtractions to calculate each Haar projection value on the sliding windows. By establishing a solid mathematical foundation for OHT, this paper based on the concept of image square sum, proposes a novel fast orthogonal Haar transform (FOHT) pattern matching algorithm, from which a Haar projection value can be obtained by only one subtraction. Thus, higher speed-ups can be achieved, while producing the same results with the full search pattern matching. A large number of experiments show that the speed-ups of FOHT are very competitive with OHT in most cases of matching one single pattern, and generally higher than OHT in all cases of matching multiple patterns, exceeding other high-level full search equivalent algorithms.	[Li, Yujian; Li, Houjun; Cai, Zhi] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing, Peoples R China; [Li, Yujian] Chinese Acad Sci, Inst Biophys, Beijing 100864, Peoples R China; [Li, Yujian] Beijing Univ Posts & Telecommun, Beijing, Peoples R China	Beijing University of Technology; Chinese Academy of Sciences; Institute of Biophysics, CAS; Beijing University of Posts & Telecommunications	Li, YJ (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing, Peoples R China.	lihoujun@emails.bjut.edu.cn			National Natural Science Foundation of China [61175004, 60775010]; Natural Science Foundation of Beijing [4112009]; Beijing Municipal Education Commission Science and Technology Development Plan key project [KZ201210005007]; Research Fund for the Doctoral Program of Higher Education [20121103110029]; SRF for ROCS, SEM	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Beijing(Beijing Natural Science Foundation); Beijing Municipal Education Commission Science and Technology Development Plan key project; Research Fund for the Doctoral Program of Higher Education(Research Fund for the Doctoral Program of Higher Education of China (RFDP)); SRF for ROCS, SEM(Scientific Research Foundation for the Returned Overseas Chinese Scholars)	The authors wish to thank W. Ouyang et al. for providing the image data sets and the source codes in our comparative experiments. The authors would also like to all of the editors and the anonymous reviewers, whose comments were of great value. This work was supported in part by the National Natural Science Foundation of China under grant 61175004 and grant 60775010, the Natural Science Foundation of Beijing under grant 4112009, the Beijing Municipal Education Commission Science and Technology Development Plan key project under grant KZ201210005007, the Research Fund for the Doctoral Program of Higher Education under grant 20121103110029, and SRF for ROCS, SEM.	Aksoy MS, 2004, J INTELL MANUF, V15, P569, DOI 10.1023/B:JIMS.0000034120.86709.8c; Alon Y., 2006, PROC IEEE C COMPUT V, V1, P689; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Di Stefano L, 2003, IEEE IMAGE PROC, P269; Di Stefano L, 2003, MACH VISION APPL, V13, P213; Dufour RM, 2002, IEEE T IMAGE PROCESS, V11, P1385, DOI 10.1109/TIP.2002.806245; Efros A., 2001, P SIGGRAPH 01 LOS AN, P104; Gharavi-Alkhansari M, 2001, IEEE T IMAGE PROCESS, V10, P526, DOI 10.1109/83.913587; Heckbert P. S., 1986, Computer Graphics, V20, P315, DOI 10.1145/15886.15921; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lewis JP, 1994, PROC CANAD IMAG PROC, P120; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mak CM, 2008, IEEE T CIRC SYST VID, V18, P735, DOI 10.1109/TCSVT.2008.918790; Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Moshe Y, 2009, IEEE T IMAGE PROCESS, V18, P2243, DOI 10.1109/TIP.2009.2025559; Ouyang WL, 2012, IEEE T PATTERN ANAL, V34, P127, DOI 10.1109/TPAMI.2011.106; Ouyang WL, 2010, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2010.5540058; Ouyang WL, 2010, IEEE T PATTERN ANAL, V32, P165, DOI 10.1109/TPAMI.2009.104; Pan WH, 2008, LECT NOTES COMPUT SC, V5304, P468; Pele O, 2008, IEEE T PATTERN ANAL, V30, P1427, DOI 10.1109/TPAMI.2007.70794; Simard P., 2004, P C ADV NEUR INF PRO, V11, P571; Tang F, 2007, IEEE T PATTERN ANAL, V29, P2120, DOI 10.1109/TPAMI.2007.1123; Tombari F, 2009, IEEE T PATTERN ANAL, V31, P129, DOI 10.1109/TPAMI.2008.46; Wei SD, 2008, IEEE T IMAGE PROCESS, V17, P2227, DOI 10.1109/TIP.2008.2004615; WU X, 2005, THESIS U BRIT COLUMB; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	31	9	9	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1748	1760		10.1109/TPAMI.2014.2303082	http://dx.doi.org/10.1109/TPAMI.2014.2303082			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352229				2022-12-18	WOS:000340210100004
J	Wang, KK; Wang, XW; Pan, ZG; Liu, K				Wang, Kangkan; Wang, Xianwang; Pan, Zhigeng; Liu, Kai			A Two-Stage Framework for 3D Face Reconstruction from RGBD Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face reconstruction; sparse coding; surface modeling; statistical learning; deformation transfer; rigid registration; non-rigid registration; surface tracking	CAPTURE	This paper proposes a new approach for 3D face reconstruction with RGBD images from an inexpensive commodity sensor. The challenges we face are: 1) substantial random noise and corruption are present in low-resolution depth maps; and 2) there is high degree of variability in pose and face expression. We develop a novel two-stage algorithm that effectively maps low-quality depth maps to realistic face models. Each stage is targeted toward a certain type of noise. The first stage extracts sparse errors from depth patches through the data-driven local sparse coding, while the second stage smooths noise on the boundaries between patches and reconstructs the global shape by combining local shapes using our template-based surface refinement. Our approach does not require any markers or user interaction. We perform quantitative and qualitative evaluations on both synthetic and real test sets. Experimental results show that the proposed approach is able to produce high-resolution 3D face models with high accuracy, even if inputs are of low quality, and have large variations in viewpoint and face expression.	[Wang, Kangkan] Zhejiang Univ, Dept Comp Sci, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China; [Wang, Xianwang] Hewlett Packard Corp, Palo Alto, CA 94304 USA; [Pan, Zhigeng] Hangzhou Normal Univ, Cangqian St,Haishu Rd 58, Hangzhou 311121, Zhejiang, Peoples R China; [Liu, Kai] Sichuan Univ, Sch Elect Engn & Informat, Chengdu 610065, Sichuan, Peoples R China	Zhejiang University; Hewlett-Packard; Hangzhou Normal University; Sichuan University	Pan, ZG (corresponding author), Hangzhou Normal Univ, Cangqian St,Haishu Rd 58, Hangzhou 311121, Zhejiang, Peoples R China.	wangkangkan@gmail.com; xianwang.wang@hp.com; zgpan@hznu.edu.cn; kailiu@scu.edu.cn		Pan, Zhi-geng/0000-0003-0717-5850	NSFC [61332017, 61170318]	NSFC(National Natural Science Foundation of China (NSFC))	This research was supported by NSFC No. 61332017 and No. 61170318.	Amberg B, 2007, IEEE I CONF COMP VIS, P1326; Baltrusaitis T., 2012, P IEEE C COMP VIS PA; Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2007, IEEE I CONF COMP VIS, P1562; Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778; Brand M, 2001, PROC CVPR IEEE, P456; Breuer P, 2008, IEEE INT CONF AUTOMA, P1, DOI 10.1109/AFGR.2008.4813339; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; De la Torre F., 2011, P ACM SIGGRAPH; Ecker A, 2008, LECT NOTES COMPUT SC, V5302, P127, DOI 10.1007/978-3-540-88682-2_11; Kendall David G, 1989, STAT SCI, P6, DOI DOI 10.1214/SS/1177012582; Kim YS, 2010, IEEE IMAGE PROC, P1821, DOI 10.1109/ICIP.2010.5650893; Koh KM, 2007, J MACH LEARN RES, V8, P1519; Liu K, 2010, OPT EXPRESS, V18, P5229, DOI 10.1364/OE.18.005229; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; Mount D.M., 2014, ANN LIB APPROXIMATE; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Salzmann M., 2007, COMP VIS 2007 ICCV 2, P1; Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Thomas D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P33, DOI 10.1109/3DIMPVT.2012.15; Torresani L., 2003, P ADV NEUR INF PROC; Wang H, 2005, PHYS MED BIOL, V50, P2887, DOI 10.1088/0031-9155/50/12/011; Weise T., 2009, P 2009 ACM SIGGRAPH, P7, DOI [DOI 10.1145/1599470.1599472, 10.1145/1599470.1599472]; Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972; Weiss A., 2010, P IEEE 11 INT C COMP; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiao J, 2005, IEEE I CONF COMP VIS, P1075; Yin L., 2008, AUTOMATIC FACE GESTU, V08, P1, DOI DOI 10.1109/AFGR.2008.4813324; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; Zhu JK, 2008, LECT NOTES COMPUT SC, V5304, P766; Zollhofer M, 2011, COMPUT ANIMAT VIRT W, V22, P195, DOI 10.1002/cav.405	34	9	11	1	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1493	1504		10.1109/TPAMI.2013.235	http://dx.doi.org/10.1109/TPAMI.2013.235			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353333				2022-12-18	WOS:000340191900001
J	Wang, L; Zhou, LP; Shen, CH; Liu, LQ; Liu, H				Wang, Lei; Zhou, Luping; Shen, Chunhua; Liu, Lingqiao; Liu, Huan			A Hierarchical Word-Merging Algorithm with Class Separability Measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchical word merge; compact codebook; class separability; bag-of-features model; object recognition	OBJECT CATEGORIZATION; VOCABULARIES; FRAMEWORK; COMPACT; SPARSE	In image recognition with the bag-of-features model, a small-sized visual codebook is usually preferred to obtain a low-dimensional histogram representation and high computational efficiency. Such a visual codebook has to be discriminative enough to achieve excellent recognition performance. To create a compact and discriminative codebook, in this paper we propose to merge the visual words in a large-sized initial codebook by maximally preserving class separability. We first show that this results in a difficult optimization problem. To deal with this situation, we devise a suboptimal but very efficient hierarchical word-merging algorithm, which optimally merges two words at each level of the hierarchy. By exploiting the characteristics of the class separability measure and designing a novel indexing structure, the proposed algorithm can hierarchically merge 10,000 visual words down to two words in merely 90 seconds. Also, to show the properties of the proposed algorithm and reveal its advantages, we conduct detailed theoretical analysis to compare it with another hierarchical word-merging algorithm that maximally preserves mutual information, obtaining interesting findings. Experimental studies are conducted to verify the effectiveness of the proposed algorithm on multiple benchmark data sets. As shown, it can efficiently produce more compact and discriminative codebooks than the state-of-the-art hierarchical word-merging algorithms, especially when the size of the codebook is significantly reduced.	[Wang, Lei; Zhou, Luping; Liu, Lingqiao] Univ Wollongong, Sch Comp Sci & Software Engn, Wollongong, NSW 2500, Australia; [Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Liu, Huan] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA	University of Wollongong; University of Adelaide; Arizona State University; Arizona State University-Tempe	Wang, L (corresponding author), Univ Wollongong, Sch Comp Sci & Software Engn, Room 219,Bldg 3,Northfields Ave, Wollongong, NSW 2500, Australia.	leiw@uow.edu.au; lupingz@uow.edu.au; chhshen@gmail.com; liulq83@gmail.com; huan.liu@asu.edu	Liu, Hua Kun/G-1349-2012; Zhou, Luping/AAD-6045-2020; Wang, Lei/AAL-9684-2020; Wang, Lei/D-9079-2013	Liu, Hua Kun/0000-0002-0253-647X; Wang, Lei/0000-0002-0961-0441; liu, lingqiao/0000-0003-3584-795X				Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; [Anonymous], 2007, CNSTR2007001 CALTECH; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2010, P IEEE C COMP VIS PA; CSURKA G, 2004, P EUR C COMP VIS INT; Dinkelbach W., 1967, MANAGE SCI, V13, P492, DOI 10.1287/mnsc.13.7.492; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Everingham M., 2013, PASCAL VISUAL OBJECT; Farquhar J., 2005, TECHNICAL REPORT; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15; Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760; Jurie F, 2005, IEEE I CONF COMP VIS, P604; Larlus D, 2009, IMAGE VISION COMPUT, V27, P523, DOI 10.1016/j.imavis.2008.04.022; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138; Leibe B., 2003, BMVC, P759; Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845; Liu LQ, 2011, PROC CVPR IEEE, P1537, DOI 10.1109/CVPR.2011.5995628; Liu Q, 2008, IEEE IC COMP COM NET, P1; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Moosmann F., 2007, ADV NEURAL INF PROCE, V19, P985; Nie F., 2008, P 23 AAAI C ART INT, P671; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464; Quelhas P, 2005, IEEE I CONF COMP VIS, P883; Raina R., 2007, ICML; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shen CH, 2007, LECT NOTES COMPUT SC, V4844, P227; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Slonim N, 2000, ADV NEUR IN, V12, P617; Sophia T., 2005, THESIS J GUTENBERG U; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wang Hao, 2007, P IEEE C COMP VIS PA; Wang L, 2008, IEEE T PATTERN ANAL, V30, P1534, DOI 10.1109/TPAMI.2007.70799; Wang L, 2008, LECT NOTES COMPUT SC, V5305, P719, DOI 10.1007/978-3-540-88693-8_53; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang L., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/DYSPAN.2008.47; Yuan J, 2007, PROC CVPR IEEE, P1930, DOI 10.1109/CVPR.2007.383222; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	47	9	9	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					417	435		10.1109/TPAMI.2013.160	http://dx.doi.org/10.1109/TPAMI.2013.160			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457501				2022-12-18	WOS:000331450100003
J	Yuan, XT; Yan, SC				Yuan, Xiao-Tong; Yan, Shuicheng			Forward Basis Selection for Pursuing Sparse Representations over a Dictionary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Greedy selection; sparse representation; optimization; Gaussian graphical models; subspace segmentation	OPTIMIZATION PROBLEMS; APPROXIMATION; RECOVERY	The forward greedy selection algorithm of Frank and Wolfe [9] has recently been applied with success to coordinate-wise sparse learning problems, characterized by a tradeoff between sparsity and accuracy. In this paper, we generalize this method to the setup of pursuing sparse representations over a prefixed dictionary. Our proposed algorithm iteratively selects an atom from the dictionary and minimizes the objective function over the linear combinations of all the selected atoms. The rate of convergence of this greedy selection procedure is analyzed. Furthermore, we extend the algorithm to the setup of learning nonnegative and convex sparse representation over a dictionary. Applications of the proposed algorithms to sparse precision matrix estimation and low-rank subspace segmentation are investigated with efficiency and effectiveness validated on benchmark datasets.	[Yuan, Xiao-Tong] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, Nanjing 210044, Jiangsu, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Vis & Machine Learning Lab, Singapore 117583, Singapore; [Yuan, Xiao-Tong] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore	Nanjing University of Information Science & Technology; National University of Singapore; National University of Singapore	Yuan, XT (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Informat & Control, Nanjing 210044, Jiangsu, Peoples R China.	xtyuan1980@gmail.com; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022		Singapore National Research Foundation under its International Research Center @ Singapore Funding Initiative; Jiangsu Province, China [BK2012045]	Singapore National Research Foundation under its International Research Center @ Singapore Funding Initiative(National Research Foundation, Singapore); Jiangsu Province, China	The authors would like to thank the anonymous reviewers for their constructive comments on this paper. This research was partially supported by the Singapore National Research Foundation under its International Research Center @ Singapore Funding Initiative and administered by the IDM Programme Office, and partially supported by the Grant BK2012045, Jiangsu Province, China. This work was undertaken while Xiao-Tong Yuan was affiliated with the Department of Electrical and Computer Engineering, National University of Singapore.	Cai T, 2011, J AM STAT ASSOC, V106, P594, DOI 10.1198/jasa.2011.tm10155; Clarkson KL, 2008, PROCEEDINGS OF THE NINETEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P922; Dudik M., 2012, AISTATS, P327; DUNN JC, 1978, J MATH ANAL APPL, V62, P432, DOI 10.1016/0022-247X(78)90137-3; Edwards D., 2000, INTRODUCTION TO GRAP; Fan J., 1997, STAT METHOD APPL-GER, V6, P131; Fan JQ, 2009, ANN APPL STAT, V3, P521, DOI 10.1214/08-AOAS215; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Grubb Alexander, 2011, ICML, P1209; Hazan E, 2008, LECT NOTES COMPUT SC, V4957, P306, DOI 10.1007/978-3-540-78773-0_27; Hess KR, 2006, J CLIN ONCOL, V24, P4236, DOI 10.1200/JCO.2006.05.6861; Hiriart-Urruty J.-B., 1993, CONVEX ANALYSIS AND; Jaggi M., 2010, P 27 INT C MACHINE L; Jaggi Martin, 2011, THESIS; Johnson R., 2011, TECHNICAL REPORT; Kim Y., 2004, P 21 INT C MACHINE L, P60; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Lu ZS, 2009, SIAM J OPTIMIZ, V19, P1807, DOI 10.1137/070695915; Luss R., 2011, TECHNICAL REPORT; NESTEROV Y., 2004, INTRODUCTORY LECTURE; Ni Y., 2010, PROC WORKSHOP OPTIMI; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; ROCKFELLAR RT, 1970, CONVEX ANALYSIS; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; Schapire R., 2002, PROC MSRI WORKSHOP N; SCHMIDT M., 2009, ARTIF INTELL, P456; Shalev-Shwartz S., 2011, PROC 28TH INTL CONF; Shalev-Shwartz S, 2010, SIAM J OPTIMIZ, V20, P2807, DOI 10.1137/090759574; Tewari A., 2011, PROC ADVANCES IN NEU; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; TSENG P., 2008, SUBMITTED TO SIAM J; Wang CJ, 2010, SIAM J OPTIMIZ, V20, P2994, DOI 10.1137/090772514; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Yuan X., 2012, J SCIENTIFIC COMPUTI, V62, P432; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136; Zhang T, 2011, IEEE T INFORM THEORY, V57, P6215, DOI 10.1109/TIT.2011.2162263	41	9	10	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					3025	3036		10.1109/TPAMI.2013.85	http://dx.doi.org/10.1109/TPAMI.2013.85			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136438				2022-12-18	WOS:000326502200017
J	Censi, A; Scaramuzza, D				Censi, Andrea; Scaramuzza, Davide			Calibration by Correlation Using Metric Embedding from Nonmetric Similarities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Intrinsic camera calibration; metric embedding; catadioptric cameras; pin-hole cameras; fish-eye cameras	CAMERA CALIBRATION; SELF-CALIBRATION; PROXIMITIES; MODEL	This paper presents a new intrinsic calibration method that allows us to calibrate a generic single-view point camera just by waving it around. From the video sequence obtained while the camera undergoes random motion, we compute the pairwise time correlation of the luminance signal for a subset of the pixels. We show that if the camera undergoes a random uniform motion, then the pairwise correlation of any pixels pair is a function of the distance between the pixel directions on the visual sphere. This leads to formalizing calibration as a problem of metric embedding from nonmetric measurements: We want to find the disposition of pixels on the visual sphere from similarities that are an unknown function of the distances. This problem is a generalization of multidimensional scaling (MDS) that has so far resisted a comprehensive observability analysis (can we reconstruct a metrically accurate embedding?) and a solid generic solution (how do we do so?). We show that the observability depends both on the local geometric properties (curvature) as well as on the global topological properties (connectedness) of the target manifold. We show that, in contrast to the euclidean case, on the sphere we can recover the scale of the points distribution, therefore obtaining a metrically accurate solution from nonmetric measurements. We describe an algorithm that is robust across manifolds and can recover a metrically accurate solution when the metric information is observable. We demonstrate the performance of the algorithm for several cameras (pin-hole, fish-eye, omnidirectional), and we obtain results comparable to calibration using classical methods. Additional synthetic benchmarks show that the algorithm performs as theoretically predicted for all corner cases of the observability analysis.	[Censi, Andrea] CALTECH, Control & Dynam Syst Dept, Pasadena, CA 91125 USA; [Scaramuzza, Davide] Univ Zurich, Dept Informat, AI Lab, CH-8050 Zurich, Switzerland	California Institute of Technology; University of Zurich	Censi, A (corresponding author), CALTECH, Control & Dynam Syst Dept, 1200 E Calif Blvd,MC 107-81, Pasadena, CA 91125 USA.	andrea@cds.caltech.edu; davide.scaramuzza@ieee.org		Censi, Andrea/0000-0001-5162-0398	US National Science Foundation (NRI program) [12018687]; US Defense Advanced Research Projects Agency (MSEE program) [FA8650-11-1-7156]; Swiss National Science Foundation [200021-143607]; National Centre of Competence in Research Robotics	US National Science Foundation (NRI program)(National Science Foundation (NSF)); US Defense Advanced Research Projects Agency (MSEE program); Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); National Centre of Competence in Research Robotics	A. Censi was supported by the US National Science Foundation (NRI program, grant #12018687) and US Defense Advanced Research Projects Agency (MSEE program, grant #FA8650-11-1-7156). D. Scaramuzza was suppported by the Swiss National Science Foundation through project #200021-143607 and the National Centre of Competence in Research Robotics.	Agarwal S., 2007, P 11 INT C ART INT S; Antonelli G., 2010, P INT C ROB AUT, DOI [10.1109/ROBOT.2010.5509954, DOI 10.1109/R0B0T.2010.5509954]; Barreto J., 2013, OMNIDIRECTIONAL CAME; Barreto J. P., 2009, PROCEDINGS BRIT MACH; Boerlin M, 2009, NEURAL COMPUT, V21, P216, DOI [10.1162/neco.2009.06-07-554, 10.1162/neco.2008.06-07-554]; Chandraker M.K., 2007, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2007.383067, DOI 10.1109/CVPR.2007.383067]; Clarke TA, 1998, PHOTOGRAMM REC, V16, P51, DOI 10.1111/0031-868X.00113; Cox T. F., 2011, MULTIDIMENSIONAL SCA; Espuny F., 2008, P 8 WORKSH OMN VIS C; France SL, 2011, IEEE T SYST MAN CY C, V41, P644, DOI 10.1109/TSMCC.2010.2078502; Gennery DB, 2006, INT J COMPUT VISION, V68, P239, DOI 10.1007/s11263-006-5168-1; Gower J. C, 2004, OXFORD STAT SCI SERI, V30; Grossberg MD, 2005, INT J COMPUT VISION, V61, P119, DOI 10.1023/B:VISI.0000043754.56350.10; Grossmann E, 2010, COMPUT VIS IMAGE UND, V114, P198, DOI 10.1016/j.cviu.2009.03.009; Hartley R. I., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P471; Kahl F, 1998, INT C PATT RECOG, P56, DOI 10.1109/ICPR.1998.711078; Kannala J., 2013, CAMERA CALIBRATION T; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; LEE RCT, 1977, IEEE T COMPUT, V26, P288, DOI 10.1109/TC.1977.1674822; Li HD, 2006, LECT NOTES COMPUT SC, V3851, P21; Martinez-Finkelshtein A, 2006, INT MATH RES NOTICES, V2006, DOI 10.1155/IMRN/2006/91426; Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084; Modayil J., 2010, P INT C DEV LEARN IC, DOI DOI 10.1109/DEVLRN.2010.557885; Pierce D, 1997, ARTIF INTELL, V92, P169, DOI 10.1016/S0004-3702(96)00051-3; Platt J. C., 2005, P 10 INT WORKSH ART, P261; Puig L, 2012, COMPUT VIS IMAGE UND, V116, P120, DOI 10.1016/j.cviu.2011.08.003; Ramalingam S, 2010, COMPUT VIS IMAGE UND, V114, P210, DOI 10.1016/j.cviu.2009.07.007; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Rufli M, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3121, DOI 10.1109/IROS.2008.4650703; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scaramuzza D., 2007, VISION SYSTEMS APPL; Scaramuzza D., 2013, OCAMCALIB OMNIDIRECT; Scaramuzza D., 2006, IEEE INT C COMP VIS, P45, DOI DOI 10.1109/ICVS.2006.3; Scaramuzza D., 2006, P 7 AS C COMP VIS, DOI [10.1109/ IROS. 2006.282372, DOI 10.1109/IR0S.2006.282372]; Shang Y, 2004, IEEE T PARALL DISTR, V15, P961, DOI 10.1109/TPDS.2004.67; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P219, DOI 10.1007/BF02289621; Stober J., 2009, P AAAI FALL S MAN LE; Sturm P, 2010, FOUND TRENDS COMPUT, V6, P1, DOI 10.1561/0600000023; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	41	9	9	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2357	2370		10.1109/TPAMI.2013.34	http://dx.doi.org/10.1109/TPAMI.2013.34			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969382	Green Accepted, Green Submitted			2022-12-18	WOS:000323175200004
J	Leichter, I; Krupka, E				Leichter, Ido; Krupka, Eyal			Monotonicity and Error Type Differentiability in Performance Measures for Target Detection and Tracking in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Performance evaluation; tracking; multiple targets	FACE	There exists an abundance of systems and algorithms for multiple target detection and tracking in video, and many measures for evaluating the quality of their output have been proposed. The contribution of this paper lies in the following: first, it argues that such performance measures should have two fundamental properties-monotonicity and error type differentiability; second, it shows that the recently proposed measures do not have either of these properties and are, thus, less usable; third, it composes a set of simple measures, partly built on common practice, that does have these properties. The informativeness of the proposed set of performance measures is demonstrated through their application on face detection and tracking results.	[Leichter, Ido; Krupka, Eyal] Microsoft Res, Microsoft R&D Ctr, Adv Technol Labs Israel, IL-31905 Haifa, Israel		Leichter, I (corresponding author), Microsoft Res, Microsoft R&D Ctr, Adv Technol Labs Israel, Bldg 23,Matam Park, IL-31905 Haifa, Israel.	idol@microsoft.com; eyalk@microsoft.com						Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Classification of Events Activities and Relationships (CLEAR), 2013, EV WORKSH 2006 2007; Collins R., 2005, IEEE INT WORKSH PERF, V2; Fischer M., 2013, PERSON REIDENTIFICAT; Kao EK, 2009, IEEE I CONF COMP VIS, P1523, DOI 10.1109/ICCV.2009.5459275; Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57; Leichter I., 2012, MSRTR201223; Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yin F., 2007, P 10 IEEE INT WORKSH, P17; Yuen J, 2009, IEEE I CONF COMP VIS, P1451, DOI 10.1109/ICCV.2009.5459289	11	9	9	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2553	2560		10.1109/TPAMI.2013.70	http://dx.doi.org/10.1109/TPAMI.2013.70			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969397				2022-12-18	WOS:000323175200019
J	Bellala, G; Stanley, J; Bhavnani, SK; Scott, C				Bellala, Gowtham; Stanley, Jason; Bhavnani, Suresh K.; Scott, Clayton			A Rank-Based Approach to Active Diagnosis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active diagnosis; active learning; Bayesian network; persistent noise; area under the ROC curve	INFERENCE	The problem of active diagnosis arises in several applications such as disease diagnosis and fault diagnosis in computer networks, where the goal is to rapidly identify the binary states of a set of objects (e.g., faulty or working) by sequentially selecting, and observing, potentially noisy responses to binary valued queries. Previous work in this area chooses queries sequentially based on Information gain, and the object states are inferred by maximum a posteriori (MAP) estimation. In this work, rather than MAP estimation, we aim to rank objects according to their posterior fault probability. We propose a greedy algorithm to choose queries sequentially by maximizing the area under the ROC curve associated with the ranked list. The proposed algorithm overcomes limitations of existing work. When multiple faults may be present, the proposed algorithm does not rely on belief propagation, making it feasible for large scale networks with little loss in performance. When a single fault is present, the proposed algorithm can be implemented without knowledge of the underlying query noise distribution, making it robust to any misspecification of these noise parameters. We demonstrate the performance of the proposed algorithm through experiments on computer networks, a toxic chemical database, and synthetic datasets.	[Bellala, Gowtham] Hewlett Packard Labs, Palo Alto, CA 94304 USA; [Stanley, Jason] Citadel Investment Grp, Chicago, IL 60603 USA; [Bhavnani, Suresh K.] Univ Texas Med Branch, Inst Translat Sci, Galveston, TX 77555 USA; [Scott, Clayton] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Hewlett-Packard; University of Texas System; University of Texas Medical Branch Galveston; University of Michigan System; University of Michigan	Bellala, G (corresponding author), Hewlett Packard Labs, 1501 Page Mill Rd,Bldg 1U,Mail Stop 1143, Palo Alto, CA 94304 USA.	gowtham.bellala@hp.com; jasonsta@umich.edu; skbhavnani@gmail.com; clayscot@umich.edu			US National Science Foundation (NSF) [0830490, 0953135]; CDC/NIOSH [R21 OH009441-01A]; NATIONAL INSTITUTE FOR OCCUPATIONAL SAFETY AND HEALTH [R21OH009441] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); CDC/NIOSH(United States Department of Health & Human ServicesCenters for Disease Control & Prevention - USANational Institute for Occupational Safety & Health (NIOSH)); NATIONAL INSTITUTE FOR OCCUPATIONAL SAFETY AND HEALTH(United States Department of Health & Human ServicesCenters for Disease Control & Prevention - USANational Institute for Occupational Safety & Health (NIOSH))	This work was supported in part by US National Science Foundation (NSF) Awards No. 0830490 and 0953135, and CDC/NIOSH Grant No. R21 OH009441-01A.	[Anonymous], 2012, SUPPLEMENTARY MAT; Ataman K, 2006, IEEE IJCNN, P123; Bellala G., 2011, P 27 INT C UNC ART I; Bellala G., 2011, P 14 INT C ART INT S; Bellala G, 2012, IEEE T INFORM THEORY, V58, P459, DOI 10.1109/TIT.2011.2169296; Bhavnani S. K., 2007, P AM MED INF ASS ANN; Cheng L., 2010, P IEEE INFOCOM; Cortes C., 2003, P ADV NEUR INF PROC, V15; Culver M., 2006, P 6 INT C DAT MIN; Dasgupta S., 2004, P ADV NEUR INF PROC; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; Golovin D., 2010, P ADV NEUR INF PROC, V23; GUILLAUME JL, 2004, BIPARTITE GRAPHS MOD; Gupta A., 2010, P 37 INT C C AUT LAN; Hanneke S., 2007, P 20 C LEARN THEOR; Hyafil L., 1976, Information Processing Letters, V5, P15, DOI 10.1016/0020-0190(76)90095-8; Jaakkola TS, 1999, J ARTIF INTELL RES, V10, P291, DOI 10.1613/jair.583; Kaariainen M., 2006, P 17 INT C ALG LEARN, P63; KANDULA S, 2005, P ACM SIGCOMM MINENE; Kim JC, 2000, STAT PROBABIL LETT, V46, P391, DOI 10.1016/S0167-7152(99)00128-5; Kosaraju S. R., 1999, P 6 INT WORKSH ALG D, P11; Le T, 2007, IEEE T SYST MAN CY B, V37, P1607, DOI 10.1109/TSMCB.2007.906977; Long P.M., 2007, P ADV NEUR INF PROC, V19; LOVELAND DW, 1985, ACTA INFORM, V22, P101, DOI 10.1007/BF00290148; Medina A, 2001, P 9 INT S MOD AN SIM; Mooij JM, 2010, J MACH LEARN RES, V11, P2169; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Nowak R., 2009, P ADV NEUR INF PROC, V21; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Renyi A., 1961, MTA MATEMATIKAI KUTA, V6, P505; Rish I, 2005, IEEE T NEURAL NETWOR, V16, P1088, DOI 10.1109/TNN.2005.853423; Santoso N. I., 1999, 1999 IEEE Power Engineering Society Summer Meeting. Conference Proceedings (Cat. No. 99CH36364), P714, DOI 10.1109/PESS.1999.787405; Winick J., 2002, CSETR45602 U MICH; Zheng A. X., 2005, P INT C UNC ART INT; Zhu YL, 2006, IEEE T POWER DELIVER, V21, P634, DOI 10.1109/TPWRD.2005.858774	35	9	10	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2078	2090		10.1109/TPAMI.2013.30	http://dx.doi.org/10.1109/TPAMI.2013.30			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868771	Green Submitted			2022-12-18	WOS:000322029000003
J	Ghosh, P; Manjunath, BS				Ghosh, Pratim; Manjunath, B. S.			Robust Simultaneous Registration and Segmentation with Sparse Error Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; registration; tracking; optimization	SHAPE PRIORS; ALGORITHMS; MODEL	We introduce a fast and efficient variational framework for Simultaneous Registration and Segmentation (SRS) applicable to a wide variety of image sequences. We demonstrate that a dense correspondence map (between consecutive frames) can be reconstructed correctly even in the presence of partial occlusion, shading, and reflections. The errors are efficiently handled by exploiting their sparse nature. In addition, the segmentation functional is reformulated using a dual Rudin-Osher-Fatemi (ROF) model for fast implementation. Moreover, nonparametric shape prior terms that are suited for this dual-ROF model are proposed. The efficacy of the proposed method is validated with extensive experiments on both indoor, outdoor natural and biological image sequences, demonstrating the higher accuracy and efficiency compared to various state-of-the-art methods.	[Ghosh, Pratim] Microsoft Corp, Redmond, WA 98052 USA; [Manjunath, B. S.] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA	Microsoft; University of California System; University of California Santa Barbara	Ghosh, P (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	pratim@ece.ucsb.edu; manj@ece.ucsb.edu	Manjunath, B S/AAM-8190-2020	Manjunath, B S/0000-0003-2804-3611	Center for Bioimage Informatics [NSF-III 0808772, NSF-OIA 0941717]; Div Of Information & Intelligent Systems [0808772] Funding Source: National Science Foundation	Center for Bioimage Informatics; Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work is supported by the Center for Bioimage Informatics under grants NSF-III 0808772 and NSF-OIA 0941717.	An JH, 2005, LECT NOTES COMPUT SC, V3749, P286; Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z; Avidan S., 2005, PROC IEEE INTL CONF; Babenko B., 2009, IEEE PATTERN ANALYSI, V32, P1153; Baker S., 2007, PROC IEEE INTL CONF; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Bresson X, 2006, INT J COMPUT VISION, V68, P145, DOI 10.1007/s11263-006-6658-x; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Cremers D., 2003, IEEE 2 INT WORKSH VA, P169; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; Ehrhardt J., 2007, PROC IEEE INTL CONF, P1; Ghosh P., 2009, PROC 12TH IEEE INTL; Ghosh P., 2010, PROC IEEE INTL CONF; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ishikawa H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P509, DOI 10.1109/ICCV.2001.937559; Leventon M., 2002, PROC FIFTH IEEE EMBS; Mei X., 2009, P INT C COMP VIS; Mei Xue, 2011, P IEEE C COMP VIS PA; Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; SADDI K, 2007, P IEEE 11 INT C COMP, P1; Schoenemann T, 2008, P IEEE C COMP VIS PA, P1; Schoenemann T., 2008, PROC IEEE INTL CONF; Schoenemann T, 2010, IEEE T PATTERN ANAL, V32, P1153, DOI 10.1109/TPAMI.2009.79; Sun D., 2010, PROC IEEE INTL CONF; Taron M, 2009, IEEE T PATTERN ANAL, V31, P99, DOI 10.1109/TPAMI.2008.36; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; Unal G, 2005, PROC CVPR IEEE, P168; Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2; Zhu Y., 2008, COMP VIS PATT REC IE, P1	39	9	9	0	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					425	436		10.1109/TPAMI.2012.103	http://dx.doi.org/10.1109/TPAMI.2012.103			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22547427	Green Submitted			2022-12-18	WOS:000312560600014
J	Holzer, S; Ilic, S; Navab, N				Holzer, Stefan; Ilic, Slobodan; Navab, Nassir			Multilayer Adaptive Linear Predictors for Real-Time Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Template tracking; linear predictors		Enlarging or reducing the template size by adding new parts or removing parts of the template according to their suitability for tracking requires the ability to deal with the variation of the template size. For instance, real-time template tracking using linear predictors, although fast and reliable, requires using templates of a fixed size and does not allow online modification of the predictor. To solve this problem, we propose the Adaptive Linear Predictors (ALPs), which enable fast online modifications of prelearned linear predictors. Instead of applying a full matrix inversion for every modification of the template shape, as standard approaches to learning linear predictors do, we just perform a fast update of this inverse. This allows us to learn the ALPs in a much shorter time than standard learning approaches while performing equally well. Additionally, we propose a multilayer approach to detect occlusions and use ALPs to effectively handle them. This allows us to track large templates and modify them according to the present occlusions. We performed an exhaustive evaluation of our approach and compared it to standard linear predictors and other state-of-the-art approaches.	[Holzer, Stefan; Ilic, Slobodan; Navab, Nassir] TUM, Dept Comp Sci, D-85748 Garching, Germany	Technical University of Munich	Holzer, S (corresponding author), TUM, Dept Comp Sci, Boltzmannstr 3, D-85748 Garching, Germany.	holzers@in.tum.de; slobodan.ilic@in.tum.de; navab@cs.tum.edu	Peters, Terry M/K-6853-2013	Peters, Terry M/0000-0003-1440-7488; Ilic, Slobodan/0000-0002-3413-1936	Bayerische Forschungsstiftung	Bayerische Forschungsstiftung	This project was partially funded by the Bayerische Forschungsstiftung.	Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BAKER S, 2003, CMURITR0301; Baker SA, 2001, P SOC PHOTO-OPT INS, V4308, P1, DOI 10.1117/12.424997; Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252; Benhimane S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P943; CASCIA ML, 2000, IEEE T PATTERN ANAL, V22, P322; Dellaert F., 1999, ICCV WORKSH FRAM RAT, P1; Grassl C, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P51, DOI 10.1109/IAI.2004.1300943; Grassl C, 2003, LECT NOTES COMPUT SC, V2781, P273; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HENDERSON HV, 1981, SIAM REV, V23, P53, DOI 10.1137/1023004; HINTERSTOISSER S, 2008, P IEEE C COMP VIS PA, P1; Holzer S, 2010, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2010.5539851; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; Jurie F., 2002, P BRIT MACHINE VISIO, V2002, P123, DOI [10.5244/C.16.10, DOI 10.5244/C.16.10]; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Malis E, 2004, IEEE INT CONF ROBOT, P1843, DOI 10.1109/ROBOT.2004.1308092; Matas J, 2006, LECT NOTES COMPUT SC, V4338, P445; Mayol WW, 2008, MACH VISION APPL, V19, P65, DOI 10.1007/s00138-007-0087-x; Parisot Pascaline, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P891, DOI 10.1109/SITIS.2007.83; Patras I., 2007, P 8 INT WORKSH IM AN, P15; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119	23	9	11	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					105	117		10.1109/TPAMI.2012.86	http://dx.doi.org/10.1109/TPAMI.2012.86			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22487980				2022-12-18	WOS:000311127700011
J	Ying, XH; Yang, L; Zha, HB				Ying, Xianghua; Yang, Li; Zha, Hongbin			A Fast Algorithm for Multidimensional Ellipsoid-Specific Fitting by Minimizing a New Defined Vector Norm of Residuals Using Semidefinite Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multidimensional ellipsoid; ellipsoid-specific fitting; semidefinite programming; new defined vector norm	SURFACES; CURVES	A quadratic surface in n-dimensional space is defined as the locus of zeros of a quadratic polynomial. The quadratic polynomial may be compactly written in notation by an (n + 1)-vector and a real symmetric matrix of order n + 1, where the vector represents homogenous coordinates of an n-D point, and the symmetric matrix is constructed from the quadratic coefficients. If an n-D quadratic surface is an n-D ellipsoid, the leading n x n principal submatrix of the symmetric matrix would be positive or opposite definite. As we know, to impose a matrix being positive or opposite definite, perhaps the best choice may be to employ semidefinite programming (SDP). From such straightforward and intuitive knowledge, in the literature until 2002, Calafiore first proposed a feasible method for multidimensional ellipsoid-specific fitting using SDP, which minimizes the 2-norm of the algebraic residual vector. However, the runtime of the method is significantly long and memory is often out when the number of fitted points is greater than several thousand. In this paper, we propose a fast and easily implemented algorithm for multidimensional ellipsoid-specific fitting by minimizing a new defined vector norm of the algebraic residual vector using SDP, which drastically decreases the size of the SDP problem while preserving accuracy. The proposed fast method can handle several million fitted points without any difficulty.	[Ying, Xianghua; Yang, Li; Zha, Hongbin] Peking Univ, Sch Elect Engn & Comp Sci, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China	Peking University	Ying, XH (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China.	xhying@cis.pku.edu.cn; yangli@cis.pku.edu.cn; zha@cis.pku.edu.cn			NKBPRC [2011CB302202]; NNSFC [61075034, 91120004]; NHTRDP [2009AA01Z329]	NKBPRC; NNSFC(National Natural Science Foundation of China (NSFC)); NHTRDP	This work was supported in part by the NKBPRC 973 Grant No. 2011CB302202, the NNSFC Grant No. 61075034, the NNSFC Grant No. 91120004, and the NHTRDP 863 Grant No. 2009AA01Z329.	Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Calafiore G, 2002, IEEE T SYST MAN CY A, V32, P269, DOI 10.1109/TSMCA.2002.1021114; CAO X, 1991, P IEEE INT C SYST MA, P123, DOI DOI 10.1109/ICSMC.1991.169672; Chen YH, 1999, COMPUT AIDED DESIGN, V31, P101, DOI 10.1016/S0010-4485(98)00083-9; Cross G, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P25, DOI 10.1109/ICCV.1998.710697; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Golub G. H., 1996, MATRIX COMPUTATIONS, P52; Gotardo PFU, 2004, IEEE T SYST MAN CY B, V34, P2303, DOI 10.1109/TSMCB.2004.835082; Helzer A, 2004, IEEE T PATTERN ANAL, V26, P1283, DOI 10.1109/TPAMI.2004.91; Lee PY, 2004, CONF REC ASILOMAR C, P131; Sappa AD, 2009, IEEE IMAGE PROC, P3521, DOI 10.1109/ICIP.2009.5414072; Sturm P, 2007, LECT NOTES COMPUT SC, V4844, P784; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; van Kaick OM, 2002, IEEE IMAGE PROC, P493; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003	17	9	9	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1856	1863		10.1109/TPAMI.2012.109	http://dx.doi.org/10.1109/TPAMI.2012.109			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22585099				2022-12-18	WOS:000306409100016
J	Joshi, N; Kadir, T; Brady, M				Joshi, Niranjan; Kadir, Timor; Brady, Michael			Simplified Computation for Nonparametric Windows Method of Probability Density Function Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Probability density function; nonparametric estimation; signals and images; image registration; image segmentation	IMAGE REGISTRATION; SEGMENTATION	Recently, Kadir and Brady [8], [10] proposed a method for estimating probability density functions (PDFs) for digital signals which they call the Nonparametric (NP) Windows method. The method involves constructing a continuous space representation of the discrete space and sampled signal by using a suitable interpolation method. NP Windows requires only a small number of observed signal samples to estimate the PDF and is completely data driven. In this short paper, we first develop analytical formulae to obtain the NP Windows PDF estimates for 1D, 2D, and 3D signals, for different interpolation methods. We then show that the original procedure to calculate the PDF estimate can be significantly simplified and made computationally more efficient by a judicious choice of the frame of reference. We have also outlined specific algorithmic details of the procedures enabling quick implementation. Our reformulation of the original concept has directly demonstrated a close link between the NP Windows method and the Kernel Density Estimator.	[Joshi, Niranjan; Brady, Michael] Univ Oxford, Dept Radiat Oncol & Biol, Oxford OX3 7DQ, England; [Kadir, Timor] Mirada Med, Oxford OX1 0JX, England	University of Oxford	Joshi, N (corresponding author), Univ Oxford, Dept Radiat Oncol & Biol, Old Rd Campus Res Bldg,Off Roosevelt Dr, Oxford OX3 7DQ, England.	njoshi@robots.ox.ac.uk; timork@theiet.org; jmb@robots.ox.ac.uk	Dowson, Nicholas/B-7621-2017	Dowson, Nicholas/0000-0003-4694-5459	Microsoft Research, United Kingdom; EPSRC/MRC	Microsoft Research, United Kingdom; EPSRC/MRC(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)Engineering & Physical Sciences Research Council (EPSRC))	The authors (N. Joshi and M. Brady) thank EPSRC/MRC, and Microsoft Research, United Kingdom, for funding this research work.	[Anonymous], 2004, NONPARAMETRIC SEMIPA, DOI DOI 10.1007/978-3-642-17146-8; Cover TM, 2006, ELEMENTS INFORM THEO; Dowson N, 2008, IEEE T PATTERN ANAL, V30, P1841, DOI 10.1109/TPAMI.2007.70832; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; JOSHI N, 2007, THESIS U OXFORD; Joshi N, 2010, INT J COMPUT VISION, V88, P52, DOI 10.1007/s11263-009-0290-5; KADIR T, 2005, 228305 OUEL U OXF; Karacali B, 2007, INT J COMPUT VISION, V72, P219, DOI 10.1007/s11263-006-8704-0; Laidlaw DH, 1998, IEEE T MED IMAGING, V17, P74, DOI 10.1109/42.668696; Papoulis A, 2002, PROBABILITY RANDOM V, V4th; Petrou M, 2006, IEEE T IMAGE PROCESS, V15, P3020, DOI 10.1109/TIP.2006.877516; PLUIM J, 2000, THESIS IMAGE SCI I; Rajwade A, 2009, IEEE T PATTERN ANAL, V31, P475, DOI 10.1109/TPAMI.2008.97; RAYKAR VC, 2006, P 6 SIAM INT C DAT M; RAYKAR VC, 2011, C CODE FAST OPTIMAL; Shen DG, 2007, PATTERN RECOGN, V40, P1161, DOI 10.1016/j.patcog.2006.08.012; SHIMAZAKI H, 2011, MATLAB CODE HISTOGRA; Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Yan CX, 2003, PATTERN RECOGN LETT, V24, P2935, DOI 10.1016/S0167-8655(03)00154-5; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	22	9	9	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1673	1680		10.1109/TPAMI.2011.51	http://dx.doi.org/10.1109/TPAMI.2011.51			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21422492				2022-12-18	WOS:000291807200014
J	Tsai, YT; Fang, KL; Lin, WC; Shih, ZC				Tsai, Yu-Ting; Fang, Kuei-Li; Lin, Wen-Chieh; Shih, Zen-Chung			Modeling Bidirectional Texture Functions with Multivariate Spherical Radial Basis Functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Reflectance and shading models; bidirectional texture functions; parameterization; spherical radial basis functions	REAL-TIME; REPRESENTATION; REFLECTANCE; APPEARANCE; APPROXIMATION; COMPRESSION; ALGORITHM	This paper presents a novel parametric representation for bidirectional texture functions. Our method mainly relies on two original techniques, namely, multivariate spherical radial basis functions (SRBFs) and optimized parameterization. First, since the surface appearance of a real-world object is frequently a mixed effect of different physical factors, the proposed sum-of-products model based on multivariate SRBFs especially provides an intrinsic and efficient representation for heterogenous materials. Second, optimized parameterization particularly aims at overcoming the major disadvantage of traditional fixed parameterization. By using a parametric model to account for variable transformations, the parameterization process can be tightly integrated with multivariate SRBFs into a unified framework. Finally, a hierarchical fitting algorithm for bidirectional texture functions is developed to exploit spatial coherence and reduce computational cost. Our experimental results further reveal that the proposed representation can easily achieve high-quality approximation and real-time rendering performance.	[Tsai, Yu-Ting] Yuan Ze Univ, Dept Comp Sci & Engn, Chungli 320, Taoyuan, Taiwan; [Fang, Kuei-Li; Lin, Wen-Chieh; Shih, Zen-Chung] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan	Yuan Ze University; National Yang Ming Chiao Tung University	Tsai, YT (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, 135 Yuan Tung Rd, Chungli 320, Taoyuan, Taiwan.	yttsai@saturn.yzu.edu.tw; zean.fang@gmail.com; wclin@cs.nctu.edu.tw; zcshih@cs.nctu.edu.tw			National Science Council of Taiwan [NSC96-2221-E-009-152-MY3, NSC99-2628-E-009-178, NSC100-2218-E-155-002]	National Science Council of Taiwan(Ministry of Science and Technology, Taiwan)	The authors would like to thank the anonymous reviewers for profound comments and suggestions, Dr. Xin Tong for providing BTF data, and Jia-Yin Ji for preparing the model Cloth. This work was supported in part by the National Science Council of Taiwan under Grant No. NSC96-2221-E-009-152-MY3, NSC99-2628-E-009-178, and NSC100-2218-E-155-002.	BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Chen WC, 2002, ACM T GRAPHIC, V21, P447, DOI 10.1145/566570.566601; COLE FH, 2002, THESIS HARVARD U; Cula OG, 2001, PROC CVPR IEEE, P1041; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Filip J, 2009, IEEE T PATTERN ANAL, V31, P1921, DOI 10.1109/TPAMI.2008.246; Filip J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409091; Goldman D. B., 2009, IEEE T PATTERN ANAL, V32, P1060, DOI DOI 10.1109/TPAMI.2009.102; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Green P, 2007, COMPUT GRAPH FORUM, V26, P495, DOI 10.1111/j.1467-8659.2007.01072.x; HAINDL M, 2003, P 3 INT WORKSH TEXT, P47; HAINDL M, 2005, P 4 INT WORKSH TEXT, P95; Haindl M, 2007, IEEE T PATTERN ANAL, V29, P1859, DOI 10.1109/TPAMI.2007.1139; Han C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239479; *ILM, 2006, TECHN INTR OPENEXR; KOUDELKA ML, 2003, P 3 INT WORKSH TEXT, P59; LAFORTUNE EPF, 1997, P SIGGRAPH, P117; Latta L, 2002, ACM T GRAPHIC, V21, P509, DOI 10.1145/566570.566610; Lawrence J, 2004, ACM T GRAPHIC, V23, P496, DOI 10.1145/1015706.1015751; Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949; Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Ma W.-C., 2005, P 2005 S INT 3D GRAP, P187; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; McAllister D.K., 2002, P ACM SIGGRAPH EUROG, P79; McCool MD, 2001, COMP GRAPH, P171, DOI 10.1145/383259.383276; Meseth J, 2004, COMPUT GRAPH-UK, V28, P105, DOI 10.1016/j.cag.2003.10.011; Muller G, 2006, COMPUT GRAPH FORUM, V25, P369, DOI 10.1111/j.1467-8659.2006.00956.x; Muller G, 2005, COMPUT GRAPH FORUM, V24, P83, DOI 10.1111/j.1467-8659.2005.00830.x; Muller G, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P198, DOI 10.1109/CGI.2004.1309211; Nishino K, 2001, IEEE T PATTERN ANAL, V23, P1257, DOI 10.1109/34.969116; NVIDIA, 2010, NVIDIA CUDA COMP UN; Peers P, 2006, ACM T GRAPHIC, V25, P746, DOI 10.1145/1141911.1141950; Ramantoorthi R, 2002, ACM T GRAPHIC, V21, P517, DOI 10.1145/566570.566611; RUSINKIEWICZ SM, 1998, P EUR WORKSH REND, P11; SATTLER M, 2003, P EUR S REND, P167; SEITZ SM, 1996, P SIGGRAPH 96, P21; Sloan PP, 2003, ACM T GRAPHIC, V22, P370, DOI 10.1145/882262.882279; Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612; Stark MM, 2005, IEEE T VIS COMPUT GR, V11, P126, DOI 10.1109/TVCG.2005.26; Suykens F, 2003, COMPUT GRAPH FORUM, V22, P463, DOI 10.1111/1467-8659.00694; Tan P., 2005, EUROGRAPHICS S RENDE, P111; Tsai YT, 2006, ACM T GRAPHIC, V25, P967, DOI 10.1145/1141911.1141981; Vasilescu MAO, 2004, ACM T GRAPHIC, V23, P336, DOI 10.1145/1015706.1015725; Wang HC, 2005, ACM T GRAPHIC, V24, P527, DOI 10.1145/1073204.1073224; Wang JP, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618479; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236; Zickler T, 2006, IEEE T PATTERN ANAL, V28, P1287, DOI 10.1109/TPAMI.2006.170	54	9	9	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1356	1369		10.1109/TPAMI.2010.211	http://dx.doi.org/10.1109/TPAMI.2010.211			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21135438				2022-12-18	WOS:000290574000006
J	Liu, YH				Liu, Yonghuai			Penalizing Closest Point Sharing for Automatic Free Form Shape Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tentative correspondence; closest point sharing; penalization; weight; deterministic annealing; accurate and robust registration; overlapping free form shapes	RANGE IMAGE REGISTRATION; 3D	For accurate registration of overlapping free form shapes, different points in one shape must select different points in another as their most sensible correspondents. To reach this ideal state, in this paper we develop a novel algorithm to penalize those points in one shape that select the same closest point in another as their tentative correspondents. The novel algorithm then models the relative weight change over time of a tentative correspondence as the difference between the negative functions of the numbers of points in one shape that actually and ideally select the same closest point in another. Such modeling results in an optimal estimation of the weights of different tentative correspondences, in the sense of deterministic annealing, that lead the camera motion parameters to be estimated in the weighted least squares sense. The proposed algorithm is initialized using the pure translational motion derived from the centroids difference of the overlapping free form shapes being registered. Experimental results show that it outperforms three selected state-of-the-art algorithms on the whole for the accurate and robust registration of real overlapping free form shapes captured using two different laser scanners under typical imaging conditions.	Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Dyfed, Wales	Aberystwyth University	Liu, YH (corresponding author), Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Dyfed, Wales.	yyl@aber.ac.uk	Liu, Yonghuai/ABF-3794-2020					BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Dewaele G, 2004, LECT NOTES COMPUT SC, V3021, P495; Fisher R.A., 1930, GENETICAL THEORY NAT; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; KHOUALED S, 2009, P BRIT MACH VIS C; Liu YH, 2008, PATTERN RECOGN LETT, V29, P841, DOI 10.1016/j.patrec.2007.12.004; Liu YH, 2007, PATTERN RECOGN, V40, P2418, DOI 10.1016/j.patcog.2006.11.025; Liu YH, 2006, IMAGE VISION COMPUT, V24, P762, DOI 10.1016/j.imavis.2006.01.009; Low KL, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P171; Masuda T, 2009, COMPUT VIS IMAGE UND, V113, P1158, DOI 10.1016/j.cviu.2009.05.003; *OSU, 2010, MSU WSU RANG IM DAT; Phillips JM, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427; PUZICHA J, 1997, P 15 IMACS WORLD C S, V6, P445; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Santamaria J, 2007, SOFT COMPUT, V11, P819, DOI 10.1007/s00500-006-0132-0; Sara R, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P377, DOI 10.1109/3DIM.2005.51; Schutz C, 1998, INT C PATT RECOG, P982, DOI 10.1109/ICPR.1998.711852; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Sharp GC, 2008, IEEE T PATTERN ANAL, V30, P120, DOI 10.1109/TPAMI.2007.1130; Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108; WANG F, 2006, P IEEE C COMP VIS PA, P1283; Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806; Zhu L, 2007, INT J ADV MANUF TECH, V32, P505, DOI 10.1007/s00170-005-0370-9; [No title captured]	25	9	11	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					1058	1064		10.1109/TPAMI.2010.207	http://dx.doi.org/10.1109/TPAMI.2010.207			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	21135433				2022-12-18	WOS:000288677800015
J	Guo, Q; Guo, FL; Shao, JQ				Guo, Qi; Guo, Falei; Shao, Jiaqing			Irregular Shape Symmetry Analysis: Theory and Application to Quantitative Galaxy Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bilateral and rotational symmetry; irregularity; symmetry measure; galaxy classification	HUBBLE-SPACE; MORPHOLOGY; AXIS; NEARBY; AXES	This paper presents a set of imperfectly symmetric measures based on a series of geometric transformation operations for quantitatively measuring the "amount" of symmetry of arbitrary shapes. The definitions of both bilateral symmetricity and rotational symmetricity give new insight into analyzing the geometrical property of a shape and enable characterizing arbitrary shapes in a new way. We developed a set of criteria for quantitative galaxy classification using our proposed irregular shape symmetry measures. Our study has demonstrated the effectiveness of the proposed method for the characterization of the shape of the celestial bodies. The concepts described in the paper are applicable to many fields, such as mathematics, artificial intelligence, digital image processing, robotics, biomedicine, etc.	[Guo, Qi] Univ Cambridge, Strangeways Res Lab, Cambridge CB1 8RN, England; [Shao, Jiaqing] Univ Kent, Dept Elect, Canterbury CT2 7NT, Kent, England	University of Cambridge; University of Kent	Guo, Q (corresponding author), Univ Cambridge, Strangeways Res Lab, Worts Causeway, Cambridge CB1 8RN, England.	qi.guo@srl.cam.ac.uk; faleiguo@hotmail.com; j.shao@kent.ac.uk			US National Aeronautics and Space Administration; Direct For Computer & Info Scie & Enginr [0803705] Funding Source: National Science Foundation	US National Aeronautics and Space Administration(National Aeronautics & Space Administration (NASA)); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This research has made use of the NASA/IPAC Extragalactic Database (NED), which is operated by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the US National Aeronautics and Space Administration, and the SIMBAD database, operated at CDS, Strasbourg, France. The authors would like to thank Professor Rangaraj Rangayyan of the University of Calgary, Canada, for providing the mammographic tumor contours. They also wish to thank the anonymous referees and the Associate Editor for their comments, which have improved the quality of this paper.	Abraham RG, 1996, ASTROPHYS J SUPPL S, V107, P1, DOI 10.1086/192352; Abraham RG, 2001, SCIENCE, V293, P1273, DOI 10.1126/science.1060855; Abraham RG, 2000, ASTRON J, V120, P2835, DOI 10.1086/316877; Abraham RG, 1996, MON NOT R ASTRON SOC, V279, pL47, DOI 10.1093/mnras/279.3.L47; ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; Bershady MA, 2000, ASTRON J, V119, P2645, DOI 10.1086/301386; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; Brinchmann J, 1998, ASTROPHYS J, V499, P112, DOI 10.1086/305621; BUDDEN FJ, 1972, FASCINATION GROUPS; Castleman K.R., 1996, DIGITAL IMAGE PROCES; CHUI CK, 1970, P AM MATH SOC, V26, P480, DOI 10.2307/2037364; Conselice CJ, 2000, ASTROPHYS J, V529, P886, DOI 10.1086/308300; Falconer K.J., 2014, FRACTAL GEOMETRY MAT, V3rd ed.; FREY D, 1949, STUDIUM GEN; Fukushima S, 1997, IEEE T PATTERN ANAL, V19, P144, DOI 10.1109/34.574795; GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P753, DOI 10.1109/34.236253; Giblin PJ, 2003, IEEE T PATTERN ANAL, V25, P895, DOI 10.1109/TPAMI.2003.1206518; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; GUO Q, 2008, THESIS U READING; Guo Q, 2007, INT J COMPUT ASS RAD, V2, pS336; Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29; Heijmans HJAM, 1998, IEEE T PATTERN ANAL, V20, P980, DOI 10.1109/34.713363; Hubble E, 1926, ASTROPHYS J, V64, P321, DOI 10.1086/143018; Hubble E.P., 1936, REALM NEBULAE; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; MASUDA T, 1993, PATTERN RECOGN, V26, P1245, DOI 10.1016/0031-3203(93)90209-F; MATHERON G, 1988, IMAGE ANAL MATH MORP, V2, P359; Miller W., 1972, SYMMETRY GROUPS THEI; MINOVIC P, 1993, IEEE T PATTERN ANAL, V15, P507, DOI 10.1109/34.211472; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; NELDER JA, 1965, COMPUT J, V308, P7; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; Prasad VSN, 2004, IEEE T IMAGE PROCESS, V13, P1559, DOI 10.1109/TIP.2004.837564; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; SAINTMARC P, 1993, IEEE T PATTERN ANAL, V15, P1191, DOI 10.1109/34.244680; Shen DG, 1999, IEEE T PATTERN ANAL, V21, P466, DOI 10.1109/34.765657; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 2001, VISION RES, V41, P1153, DOI 10.1016/S0042-6989(00)00274-1; TSAI WH, 1991, PATTERN RECOGN, V24, P95, DOI 10.1016/0031-3203(91)90080-O; van den Bergh S, 2002, ASTRON J, V123, P2913, DOI 10.1086/340355; van den Bergh S, 2007, NATURE, V445, P265, DOI 10.1038/445265a; Volonteri M, 2000, ASTRON ASTROPHYS SUP, V145, P111, DOI 10.1051/aas:2000233; Weyl H., 1952, SYMMETRY; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	47	9	9	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1730	1743		10.1109/TPAMI.2010.13	http://dx.doi.org/10.1109/TPAMI.2010.13			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724752				2022-12-18	WOS:000281000700001
J	Guo, F; Chellappa, R				Guo, Feng; Chellappa, Rama			Video Metrology Using a Single Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video metrology; mensuration; rectification		This paper presents a video metrology approach using an uncalibrated single camera that is either stationary or in planar motion. Although theoretically simple, measuring the length of even a line segment in a given video is often a difficult problem. Most existing techniques for this task are extensions of single image-based techniques and do not achieve the desired accuracy especially in noisy environments. In contrast, the proposed algorithm moves line segments on the reference plane to share a common endpoint using the vanishing line information followed by fitting multiple concentric circles on the image plane. A fully automated real-time system based on this algorithm has been developed to measure vehicle wheelbases using an uncalibrated stationary camera. The system estimates the vanishing line using invariant lengths on the reference plane from multiple frames rather than the given parallel lines, which may not exist in videos. It is further extended to a camera undergoing a planar motion by automatically selecting frames with similar vanishing lines from the video. Experimental results show that the measurement results are accurate enough to classify moving vehicles based on their size.	[Guo, Feng] Objectvideo Inc, Reston, VA USA; [Chellappa, Rama] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Guo, F (corresponding author), Objectvideo Inc, Reston, VA USA.	fguo@umiacs.umd.edu; rama@cfar.umd.edu	Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020					BJORCK A, 1996, NUMERICAL METHODS LE, pCH4; Bose B, 2003, P JOINT IEEE INT WOR, P94; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; CHEN Q, 2004, P EUR C COMP VIS, V3, P521; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; Hartley R., 2004, ROBOTICA; Jiang G, 2005, IEEE I CONF COMP VIS, P333; Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80; Krahnstoever N., 2005, P 10 IEEE INT C COMP; Liang BJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P205, DOI 10.1109/ROBOT.2002.1013362; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178; MOONS T, 1993, APPL INVARIANCE COMP, P297; STAUFFER C, 2003, P JOINT IEEE INT WOR; Tomasi C, 1991, CMUCS91132; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	16	9	11	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1329	1335		10.1109/TPAMI.2010.26	http://dx.doi.org/10.1109/TPAMI.2010.26			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489235				2022-12-18	WOS:000277649100015
J	Kovalsky, SZ; Cohen, G; Hagege, R; Francos, JM				Kovalsky, Shahar Z.; Cohen, Guy; Hagege, Rami; Francos, Joseph M.			Decoupled Linear Estimation of Affine Geometric Deformations and Nonlinear Intensity Transformations of Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Affine transformations; image registration; linear estimation; parameter estimation; domain registration; nonlinear range registration	ALIGNMENT; DOMAIN; RANGE	We consider the problem of registering two observations on an arbitrary object, where the two are related by a geometric affine transformation of their coordinate systems, and by a nonlinear mapping of their intensities. More generally, the framework is that of jointly estimating the geometric and radiometric deformations relating two observations on the same object. We show that the original high-dimensional, nonlinear, and nonconvex search problem of simultaneously recovering the geometric and radiometric deformations can be represented by an equivalent sequence of two linear systems. A solution of this sequence yields an exact, explicit, and efficient solution to the joint estimation problem.	[Kovalsky, Shahar Z.; Cohen, Guy; Hagege, Rami; Francos, Joseph M.] Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-84105 Beer Sheva, Israel	Ben Gurion University	Kovalsky, SZ (corresponding author), Ben Gurion Univ Negev, Dept Elect & Comp Engn, POB 653, IL-84105 Beer Sheva, Israel.	shaharko@ee.bgu.ac.il; guycohen@ee.bgu.ac.il; hagege@ee.bgu.ac.il; francos@ee.bgu.ac.il	COHEN, GUY/F-1614-2012	COHEN, GUY/0000-0002-6352-3859; Kovalsky, Shahar/0000-0001-8924-5538				[Anonymous], [No title captured]; BARROS A, 2002, P IEEE INT C AC SPEE, V4, P3345; BARTOLI AE, 2006, P BRIT MACH VIS C, P157; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Candocia FM, 2003, IEEE T IMAGE PROCESS, V12, P409, DOI 10.1109/TIP.2003.811497; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P3011, DOI 10.1364/JOSAA.11.003011; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; FRANCOS JM, 2003, 37 AS C SIGN SYST CO, V2, P1615; Grossberg MD, 2003, PROC CVPR IEEE, P602; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; HAGEGE R, 2004, P IEEE INT C AC SPEE, V3, P305; HAGEGE R, 2005, P IEEE SP 13 WORKSH, P55; HAGEGE R, 2009, THESIS BENGURION U; Jia JY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P156, DOI 10.1109/ICCV.2003.1238331; Jin HL, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P684, DOI 10.1109/ICCV.2001.937588; Joshi S, 2003, MED IMAGE ANAL, V7, P155, DOI 10.1016/S1361-8415(03)00002-1; KANNALA J, 2005, P SCAND C IM AN, P224; Keysers D, 2003, PATTERN RECOGN LETT, V24, P445, DOI 10.1016/S0167-8655(02)00268-4; Kim KH, 2006, CREATIVITY RES J, V18, P3, DOI 10.1207/s15326934crj1801_2; Kovalsky SZ, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P561, DOI 10.1109/SSP.2007.4301321; Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160; Manders C, 2004, IEEE IMAGE PROC, P2965; Manders CE, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P418, DOI 10.1109/ISIMP.2004.1434089; Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434; MANN S, 1996, P IEEE INT C IM PROC, V3, P193; Pratt WK, 2001, DIGITAL IMAGE PROCES; Queiroz-Neto J.P., 2004, P GEOINFO SAO PAUL B, P343; Richard FJP, 2004, INT C PATT RECOG, P649, DOI 10.1109/ICPR.2004.1333856; Schechner YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P17, DOI 10.1109/ICCV.2001.937494; Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang KM, 1997, ANN STAT, V25, P1251; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	33	9	14	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					940	946		10.1109/TPAMI.2010.22	http://dx.doi.org/10.1109/TPAMI.2010.22			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299716	Green Submitted			2022-12-18	WOS:000275569300013
J	Kuparinen, T; Kyrki, V				Kuparinen, Toni; Kyrki, Ville			Optimal Reconstruction of Approximate Planar Surfaces Using Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; photometry; surface reconstruction; Wiener filtering; sharpening and deblurring; roughness	NOISE-REDUCTION; ERROR ANALYSIS	Photometric stereo can be used to obtain a fast and noncontact surface reconstruction of Lambertian surfaces. Despite several published works concerning the uncertainties and optimal light configurations of photometric stereo, no solutions for optimal surface reconstruction from noisy real images have been proposed. In this paper, optimal surface reconstruction methods for approximate planar textured surfaces using photometric stereo are derived, given that the statistics of imaging errors are measurable. Simulated and real surfaces are experimentally studied, and the results validate that the proposed approaches improve the surface reconstruction especially for the high-frequency height variations.	[Kuparinen, Toni; Kyrki, Ville] Lappeenranta Univ Technol, Dept Informat Technol, Lappeenranta 53851, Finland	Lappeenranta University of Technology	Kuparinen, T (corresponding author), Lappeenranta Univ Technol, Dept Informat Technol, POB 20, Lappeenranta 53851, Finland.	tkuparin@lut.fi; kyrki@lut.fi	Kyrki, Ville/P-4933-2019; Kyrki, Ville/F-3034-2011	Kyrki, Ville/0000-0002-5230-5549; Kyrki, Ville/0000-0002-5230-5549	European Regional Development Fund (ERDF); Finnish Funding Agency for Technology and Innovation (TEKES), Stora Enso, UPM, Metso; Future Printing Center (FPC); Academy of Finland [114646]	European Regional Development Fund (ERDF)(European Commission); Finnish Funding Agency for Technology and Innovation (TEKES), Stora Enso, UPM, Metso(Finnish Funding Agency for Technology & Innovation (TEKES)); Future Printing Center (FPC); Academy of Finland(Academy of Finland)	Toni Kuparinen gratefully appreciates the funding provided by the European Regional Development Fund (ERDF), the Finnish Funding Agency for Technology and Innovation (TEKES), Stora Enso, UPM, Metso, and the Future Printing Center (FPC). Ville Kyrki was supported by the Academy of Finland grant 114646.	Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31; AGRAWAL A, 2006, P EUR C COMP VIS, P578; Barsby T, 2006, TRENDS BIOTECHNOL, V24, P1, DOI 10.1016/j.tibtech.2005.11.001; Bellmann A, 2007, PROC CVPR IEEE, P2700; CHANTLER MJ, 1995, IEE P-VIS IMAGE SIGN, V142, P199, DOI 10.1049/ip-vis:19952065; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1707; Forsyth D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P466, DOI 10.1109/CVPR.1989.37889; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Hansson P, 2000, OPT ENG, V39, P2555, DOI 10.1117/1.1287261; *HER WATT U TEXT L, 2008, PHOT PHOT IM DAT; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JIANG XY, 1991, SIGNAL PROCESS, V23, P221, DOI 10.1016/0165-1684(91)90001-Y; Karacali B, 2004, INT J COMPUT VISION, V60, P25, DOI 10.1023/B:VISI.0000027788.50090.b6; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; KUPARINEN T, 2008, P INT C COMP VIS THE, P571; KUPARINEN T, 2007, P IEEE ICIP, P545; LAHDEKORPI M, 2006, P 28 IMEKO WORLD C; Lambert J.H., 2001, PHOTOMETRY MEASURE G; McGunnigle G, 2003, MEAS SCI TECHNOL, V14, P699, DOI 10.1088/0957-0233/14/6/301; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Noakes L, 2003, J MATH IMAGING VIS, V18, P119, DOI 10.1023/A:1022104332058; Petrovic N, 2001, PROC CVPR IEEE, P743; RAY R, 1983, IEEE T PATTERN ANAL, V5, P631, DOI 10.1109/TPAMI.1983.4767454; SCHLUNS K, 1997, 13 U AUCKL COMP INF; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; Spence AD, 2006, IEE P-VIS IMAGE SIGN, V153, P149, DOI 10.1049/ip-vis:20050229; Stout K.J., 1993, DEV METHODS CHARACTE; Sun J, 2007, IMAGE VISION COMPUT, V25, P1073, DOI 10.1016/j.imavis.2006.04.024; WEI T, 2003, P INT C COMP AN IM P, P116; WEI T, 2001, P INT WORKSH ROB VIS, P84; WOODHAM R, 1978, 479 MIT ART INT LAB	32	9	9	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2282	2289		10.1109/TPAMI.2009.101	http://dx.doi.org/10.1109/TPAMI.2009.101			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834147				2022-12-18	WOS:000271140100014
J	Grall-Maes, E; Beauseroy, P				Grall-Maes, Edith; Beauseroy, Pierre			Optimal Decision Rule with Class-Selective Rejection and Performance Constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Decision rule; pattern classification; multiclass; class-selective rejection; partial rejection; preselection; constraints; statistical decision theory	COST	The problem of defining a decision rule which takes into account performance constraints and class-selective rejection is formalized in a general framework. In the proposed formulation, the problem is defined using three kinds of criteria. The first is the cost to be minimized, which defines the objective function, the second are the decision options, determined by the admissible assignment classes or subsets of classes, and the third are the performance constraints. The optimal decision rule within the statistical decision theory framework is obtained by solving the stated optimization problem. Two examples are provided to illustrate the formulation and the decision rule is obtained.	[Grall-Maes, Edith; Beauseroy, Pierre] Univ Technol Troyes, Inst Charles Delaunay, CNRS, FRE2848, F-10010 Troyes, France	Centre National de la Recherche Scientifique (CNRS); Universite de Technologie de Troyes	Grall-Maes, E (corresponding author), Univ Technol Troyes, Inst Charles Delaunay, CNRS, FRE2848, 12 Rue Marie Curie,BP 2060, F-10010 Troyes, France.	edith.grall@utt.fr; pierre.beauseroy@utt.fr						BACH FR, 2005, P 10 INT WORKSH ART; Bazaraa MS., 2013, NONLINEAR PROGRAMMIN; BOUNSIAR A, 2005, P EUR SIGN PROC C; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; DAVENPORT MA, 2006, P IEEE INT C AC SPEE; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Duda R.O., 1973, J ROYAL STAT SOC SER; Fletcher R, 1987, PRACTICAL METHODS OP, V1; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Fumera G, 2000, PATTERN RECOGN, V33, P2099, DOI 10.1016/S0031-3203(00)00059-5; Fumera G, 2002, LECT NOTES COMPUT SC, V2388, P68; Grail E., 2006, P 14 EUR SIGN PROC C; GRALL E, 2006, P IEEE INT C AC SPEE; GRALLMAES E, 2005, P GRETSI 05 LOUV LA, P1145; GUPTA SS, 1965, TECHNOMETRICS, V7, P225, DOI 10.2307/1266672; HA T, 1998, P JOINT IAPR INT WOR, P726; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P608, DOI 10.1109/34.601248; Ha TM, 1996, IEEE INTERNATIONAL JOINT SYMPOSIA ON INTELLIGENCE AND SYSTEMS, PROCEEDINGS, P282, DOI 10.1109/IJSIS.1996.565080; Horiuchi T, 1998, PATTERN RECOGN, V31, P1579, DOI 10.1016/S0031-3203(97)00136-2; Li M, 2006, PATTERN RECOGN, V39, P1230, DOI 10.1016/j.patcog.2006.01.010; Lin JS, 1996, IEEE T MED IMAGING, V15, P206, DOI 10.1109/42.491422; Minoux M., 1986, MATH PROGRAMMING THE; Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009; Peng YH, 2005, LECT NOTES ARTIF INT, V3614, P483; Platt JC, 2000, ADV NEUR IN, P61; Rao S.S., 1996, ENG OPTIMIZATION THE, Vfourth; Santos-Pereira CM, 2005, PATTERN RECOGN LETT, V26, P943, DOI 10.1016/j.patrec.2004.09.042; Schurmann J, 1996, PATTERN CLASSIFICATI; Tortorella F, 2004, PATTERN ANAL APPL, V7, P128, DOI 10.1007/s10044-004-0209-2	30	9	10	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2073	2082		10.1109/TPAMI.2008.239	http://dx.doi.org/10.1109/TPAMI.2008.239			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762932				2022-12-18	WOS:000269767600011
J	Alcantara, DA; Carmichael, O; Harcourt-Smith, W; Sterner, K; Frost, SR; Dutton, R; Thompson, P; Delson, E; Amenta, N				Alcantara, Dan A.; Carmichael, Owen; Harcourt-Smith, Will; Sterner, Kirstin; Frost, Stephen R.; Dutton, Rebecca; Thompson, Paul; Delson, Eric; Amenta, Nina			Exploration of Shape Variation Using Localized Components Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature representation; size and shape; life and medical sciences	CORPUS-CALLOSUM; SEX; ISTHMUS; HAND	Localized Components Analysis (LoCA) is a new method for describing surface shape variation in an ensemble of objects using a linear subspace of spatially localized shape components. In contrast to earlier methods, LoCA optimizes explicitly for localized components and allows a flexible trade-off between localized and concise representations, and the formulation of locality is flexible enough to incorporate properties such as symmetry. This paper demonstrates that LoCA can provide intuitive presentations of shape differences associated with sex, disease state, and species in a broad range of biomedical specimens, including human brain regions and monkey crania.	[Alcantara, Dan A.; Amenta, Nina] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Carmichael, Owen] Univ Calif Davis, Ctr Neurosci, Dept Neurol, Davis, CA 95618 USA; [Carmichael, Owen] Univ Calif Davis, Ctr Neurosci, Dept Comp Sci, Davis, CA 95618 USA; [Harcourt-Smith, Will] Amer Museum Nat Hist, Dept Vertebrate Paleontol, New York, NY 10024 USA; [Harcourt-Smith, Will] Amer Museum Nat Hist, NYCEP Morphometr Grp, New York, NY 10024 USA; [Sterner, Kirstin] NYU, Dept Anthropol, New York, NY 10003 USA; [Sterner, Kirstin] NYU, NYCEP Morphometr Grp, New York, NY 10003 USA; [Frost, Stephen R.] Univ Oregon, Dept Anthropol, Eugene, OR 97403 USA; [Dutton, Rebecca] Univ Calif San Francisco, Sch Med, San Francisco, CA 94143 USA; [Thompson, Paul] Univ Calif Los Angeles, Dept Neurol, Los Angeles, CA 90095 USA; [Delson, Eric] CUNY, Lehman Coll, Dept Anthropol, New York, NY USA; [Delson, Eric] Amer Museum Nat Hist, NYCEP Morphometr Grp, New York, NY 10024 USA	University of California System; University of California Davis; University of California System; University of California Davis; University of California System; University of California Davis; American Museum of Natural History (AMNH); American Museum of Natural History (AMNH); New York University; New York University; University of Oregon; University of California System; University of California San Francisco; University of California System; University of California Los Angeles; City University of New York (CUNY) System; Lehman College (CUNY); American Museum of Natural History (AMNH)	Alcantara, DA (corresponding author), Univ Calif Davis, Dept Comp Sci, 1 Shields Ave, Davis, CA 95616 USA.	dfalcantara@ucdavis.edu; ocarmichael@ucdavis.edu; willhs@amnh.org; kns210@nyu.edu; sfrost@uoregon.edu; rebecca.dutton@ucsf.edu; thompson@loni.ucla.edu; eric.delson@lehman.cuny.edu; amenta@ucdavis.edu	Carmichael, Owen/N-1955-2017	Sterner, Kirstin/0000-0001-8429-4533; Delson, Eric/0000-0002-4062-7567; Carmichael, Owen/0000-0002-0576-0047	US National Science Foundation [(NSF)IIS-0513660, NSF IIS-0513894]; NATIONAL INSTITUTE ON AGING [P30AG010129, K01AG030514, R01AG021431, R01AG021028] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This research was funded by grants US National Science Foundation (NSF)IIS-0513660 and NSF IIS-0513894. The authors thank Professor Howard Aizenstein, Professor Oscar Lopez, and Professor James Becker for their roles in collecting the CC and ventricle data. This is NYCEP Morphometrics contribution number 32.	Alcantara D, 2007, LECT NOTES COMPUT SC, V4584, P519; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; BALLESTER MAG, 2005, P SPIE INT C MED IM; Bookstein F. L., 1991, MORPHOMETRIC TOOLS L; CARMICHAEL OT, 2006, P IEEE INT S BIOM IM; Chen PS, 2001, WORLD J GASTROENTERO, V7, P647; COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4; Curran-Everett D, 2000, AM J PHYSIOL-REG I, V279, pR1, DOI 10.1152/ajpregu.2000.279.1.R1; Frost SR, 2003, ANAT REC PART A, V275A, P1048, DOI 10.1002/ar.a.10112; GHOSH D, 2007, CSE20076 U CAL DEP C; HABIB M, 1991, BRAIN COGNITION, V16, P41, DOI 10.1016/0278-2626(91)90084-L; Narr KL, 2001, BIOL PSYCHIAT, V50, P84, DOI 10.1016/S0006-3223(00)01120-3; Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SJOSTRAND K, 2006, P SPIE INT C MED IM; STEGMANN MB, 2006, P SPIE INT C MED IM; STEINMETZ H, 1992, NEUROLOGY, V42, P749, DOI 10.1212/WNL.42.4.749; Thompson PM, 2006, NEUROIMAGE, V31, P12, DOI 10.1016/j.neuroimage.2005.11.043; Thompson PM, 2004, NEUROIMAGE, V22, P1754, DOI 10.1016/j.neuroimage.2004.03.040; Uzumcu M, 2003, LECT NOTES COMPUT SC, V2878, P451; VERMAAK J, 2003, P C COMP VIS PATT RE; WITELSON SF, 1989, BRAIN, V112, P799, DOI 10.1093/brain/112.3.799; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	23	9	9	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1510	1516		10.1109/TPAMI.2008.287	http://dx.doi.org/10.1109/TPAMI.2008.287			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542583	Green Accepted, Green Submitted			2022-12-18	WOS:000267050600013
J	Leichter, I; Lindenbaum, M; Rivlin, E				Leichter, Ido; Lindenbaum, Michael; Rivlin, Ehud			Bittracker - A bitmap tracker for visual tracking under very general conditions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; motion; pixel classification	VIDEO OBJECT SEGMENTATION; OPTICAL-FLOW; MINIMIZATION; RELAXATION; CONTOURS; COLOR; IMAGE	This paper addresses the problem of visual tracking under very general conditions: a possibly nonrigid target whose appearance may drastically change over time, general camera motion, a 3D scene, and no a priori information except initialization. This is in contrast to the vast majority of trackers, which rely on some limited model in which, for example, the target's appearance is known a priori or restricted, the scene is planar, or a pan tilt zoom camera is used. Their goal is to achieve speed and robustness, but their limited context may cause them to fail in the more general case. The proposed tracker works by approximating, in each frame, a probability distribution function (PDF) of the target's bitmap and then estimating the maximum a posteriori bitmap. The PDF is marginalized over all possible motions per pixel, thus avoiding the stage in which optical flow is determined. This is an advantage over other general-context trackers that do not use the motion cue at all or rely on the error-prone calculation of optical flow. Using a Gibbs distribution with respect to the first-order neighborhood system yields a bitmap PDF whose maximization may be transformed into that of a quadratic pseudo-Boolean function, the maximum of which is approximated via a reduction to a maximum-flow problem. Many experiments were conducted to demonstrate that the tracker is able to track under the aforementioned general context.	[Leichter, Ido; Lindenbaum, Michael; Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Leichter, I (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	idol@cs.technion.ac.il; mic@cs.technion.ac.il; ehudr@cs.technion.ac.il						Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; CRIMINISI A, 2006, P IEEE C COMP VIS PA, V1, P53; Cucchiara R, 2004, REAL-TIME IMAGING, V10, P127, DOI 10.1016/j.rti.2004.03.002; Frey BJ, 2003, PROC CVPR IEEE, P45; Gelgon M, 2000, PATTERN RECOGN, V33, P725, DOI 10.1016/S0031-3203(99)00083-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jehan-Besson S, 2003, INT J COMPUT VISION, V53, P45, DOI 10.1023/A:1023031708305; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jojic N, 2001, PROC CVPR IEEE, P199; Julesz B., 1971, FDN CYCLOPEAN PERCEP; Kang HS, 2005, STEEL COMPOS STRUCT, V5, P17, DOI 10.12989/scs.2005.5.1.017; Khan S, 2001, PROC CVPR IEEE, P746; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193; Komprobst P, 2000, PROC CVPR IEEE, P118, DOI 10.1109/CVPR.2000.854756; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; LEICHTER I, 2006, CIS20063 ISR I TECHN; Liu D, 2005, INT J NUMER METHOD H, V15, P7, DOI 10.1108/09615530510571921; Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621; Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P782, DOI 10.1109/TCSVT.2004.828341; Nguyen HT, 2002, IEEE T IMAGE PROCESS, V11, P1081, DOI [10.1109/TIP.2002.802522, 10.1190/TIP.2002.802522]; Nicolescu M, 2003, IEEE T PATTERN ANAL, V25, P492, DOI 10.1109/TPAMI.2003.1190574; Nicolescu M, 2003, PROC CVPR IEEE, P382; Papadimitriou T, 2004, IEEE T CIRC SYST VID, V14, P485, DOI 10.1109/TCSVT.2004.825562; Paragios NK, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1139, DOI 10.1109/ICCV.1998.710859; Patras I, 2003, SIGNAL PROCESS-IMAGE, V18, P51, DOI 10.1016/S0923-5965(02)00092-9; Patras I, 2001, IEEE T PATTERN ANAL, V23, P326, DOI 10.1109/34.910886; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Precioso F, 2005, IEEE T IMAGE PROCESS, V14, P910, DOI 10.1109/TIP.2005.849307; Sclaroff S, 2003, COMPUT VIS IMAGE UND, V89, P197, DOI 10.1016/S1077-3142(03)00003-1; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; Sun CM, 2002, IMAGE VISION COMPUT, V20, P981, DOI 10.1016/S0262-8856(02)00112-9; Sun SJ, 2003, IEEE T CIRC SYST VID, V13, P75, DOI 10.1109/TCSVT.2002.808089; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; Tsai YP, 2005, IEEE T CIRC SYST VID, V15, P175, DOI 10.1109/TCSVT.2004.839973; Tsaig Y, 2002, IEEE T CIRC SYST VID, V12, P597, DOI 10.1109/TCSVT.2002.800513; Wang SG, 2003, CHINESE J ASTRON AST, V3, P1, DOI 10.1088/1009-9271/3/1/1; WU QX, 1995, IEEE T PATTERN ANAL, V17, P843, DOI 10.1109/34.406650; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96	45	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1572	1588		10.1109/TPAMI.2007.70816	http://dx.doi.org/10.1109/TPAMI.2007.70816			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617716				2022-12-18	WOS:000257504400006
J	Siskind, JM; Sherman, JJ; Pollak, I; Harper, MP; Bouman, CA				Siskind, Jeffrey M.; Sherman, James J., Jr.; Pollak, Ilya; Harper, Mary P.; Bouman, Charles A.			Spatial random tree grammars for modeling hierarchical structure in images with regions of arbitrary shape	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian methods for image understanding; multiscale analysis	RANDOM-FIELD MODEL; STATISTICAL-ANALYSIS; MAXIMUM-LIKELIHOOD; CLASSIFICATION; SEGMENTATION; RECOGNITION	We present a novel probabilistic model for the hierarchical structure of an image and its regions. We call this model spatial random tree grammars (SRTGs). We develop algorithms for the exact computation of likelihood and maximum a posteriori (MAP) estimates and the exact expectation-maximization (EM) updates for model-parameter estimation. We collectively call these algorithms the center-surround algorithm. We use the center-surround algorithm to automatically estimate the maximum likelihood (ML) parameters of SRTGs and classify images based on their likelihood and based on the MAP estimate of the associated hierarchical structure. We apply our method to the task of classifying natural images and demonstrate that the addition of hierarchical structure significantly improves upon the performance of a baseline model that lacks such structure.	Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA; Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus; University System of Maryland; University of Maryland College Park	Siskind, JM (corresponding author), Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.	qobi@purdue.edu; shermanj@umd.edu; ipollak@ecn.purdue.edu; harper@purdue.edu; bouman@ecn.purdue.edu						BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Bobick AF, 1998, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1998.698609; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Chi ZY, 1998, COMPUT LINGUIST, V24, P299; Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855; CHOI H, 2000, P INT SOC OPT ENG SO; Chomsky N., 1957, SYNTACTIC STRUCTURES; Chomsky N, 1975, LOGICAL STRUCTURE LI; Chomsky Noam, 1959, INFORM CONTR, V2, DOI [10.1016/S0019-9958(59)90362-6, DOI 10.1016/S0019-9958(59)90362-6]; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P557, DOI 10.1109/ICPR.1996.546886; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; FU KS, 1982, SYNTACTIC PATTERN RE; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; He X., 2004, P IEEE C COMP VIS PA; Kanungo T, 2003, IEEE T IMAGE PROCESS, V12, P583, DOI 10.1109/TIP.2003.811487; Kasami T, 1965, AFCRL65758; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; KRISHNAMOORTHY M, 1993, IEEE T PATTERN ANAL, V15, P737, DOI 10.1109/34.221173; Kumar S., 2005, P IEEE INT C COMP VI; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X; LEVINSON S, 1986, P IEEE ICASSP, P1241; Li J, 2000, IEEE T INFORM THEORY, V46, P1826, DOI 10.1109/18.857794; Li J, 2000, IEEE T IMAGE PROCESS, V9, P1604, DOI 10.1109/83.862641; LUETTGEN MR, 1993, IEEE T SIGNAL PROCES, V41, P3377, DOI 10.1109/78.258081; Manning CD, 1999, FDN STAT NATURAL LAN; MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552; Morel J.-M., 1995, VARIATIONAL METHODS; NAGY G, 1984, P 7 INT C PATT REC M, P347; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Pollak I, 2000, IEEE T IMAGE PROCESS, V9, P256, DOI 10.1109/83.821738; POLLAK I, 2003, P INT C AC SPEECH SI; POLLAK I, 2003, P INT C IM PROC SEPT; POLLAK I, 2003, TRECE0303 PURD U SCH; POTAMIANOS GG, 1993, IEEE T INFORM THEORY, V39, P1322, DOI 10.1109/18.243449; POTTER D, 1999, THESIS BROWN U; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100; Rosenfeld A., 1979, PICTURE LANGUAGES; SANKOFF D, 1971, J APPL PROBAB, V8, P233, DOI 10.2307/3211893; SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; TORRALBA A, 2004, P 18 ANN C NEUR INF; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819; Wang W, 2006, IEEE T IMAGE PROCESS, V15, P3033, DOI 10.1109/TIP.2006.877496; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; YOUNGER DH, 1967, INFORM CONTROL, V10, P189, DOI 10.1016/S0019-9958(67)80007-X; [No title captured]; [No title captured]	56	9	9	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1504	1519		10.1109/TPAMI.2007.1169	http://dx.doi.org/10.1109/TPAMI.2007.1169			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627040				2022-12-18	WOS:000247965600002
