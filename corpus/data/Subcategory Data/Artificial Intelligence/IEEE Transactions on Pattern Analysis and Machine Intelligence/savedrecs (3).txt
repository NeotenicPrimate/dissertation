PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	STORVIK, G				STORVIK, G			A BAYESIAN-APPROACH TO DYNAMIC CONTOURS THROUGH STOCHASTIC SAMPLING AND SIMULATED ANNEALING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DYNAMIC CONTOURS; BAYESIAN MODELING STOCHASTIC SAMPLING; SIMULATED ANNEALING	IMAGES	In many applications of image analysis, simply connected objects are to be located in noisy images. During the last 5-6 years active contour models have become popular for finding the contours of such objects. Connected to these models are iterative algorithms for finding the minimizing energy curves making the curves behave dynamically through the iterations. These approaches do however have several disadvantages. The numerical algorithms that are in use constraint the models that can be used. Furthermore, in many cases only local minima can be achieved. In this paper, we discuss a method for curve detection based on a fully Bayesian approach. A model for image contours which allows the number of nodes on the contours to vary is introduced. Iterative algorithms based on stochastic sampling is constructed, which make it possible to simulate samples from the posterior distribution, making estimates and uncertainty measures of specific quantities available. Further, simulated annealing schemes making the curve move dynamically towards the global minimum energy configuration are presented. In theory, no restrictions on the models are made. In practice, however, computational aspects must be taken into consideration when choosing the models. Much more general models than the one used for active contours may however be applied. The approach is applied to ultrasound images of the left ventricle and to Magnetic Resonance images of the human brain, and show promising results.			STORVIK, G (corresponding author), UNIV OSLO, INST MATH, POB 1053, N-0314 OSLO 3, NORWAY.		Storvik, Geir/HHR-8538-2022; Rohlf, F J/A-8710-2008					Amini A. A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P95, DOI 10.1109/CCV.1988.589976; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Besag J. E., 1989, J APPL STAT, V16, P395, DOI [10.1080/02664768900000049, DOI 10.1080/02664768900000049]; CANTONI O, 1992, ANN PROBAB, V20, P1109; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; DUFRESNE TE, 1991, AUG IEEE INT C SYST, P262; FRIEDLAND N, 1989, IEEE T MED IMAG, V8; GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEITNER F, 1991, CURVES SURFACES, P279; LUNDERVOLD A, 1990, MAY NOBIM C TROMS; LUNDERVOLD A, 1994, UNPUB IEEE T MED IMA; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Ripley B.D., 1987, STOCHASTIC SIMULATIO; STORVIK G, 1992, INTERFACE 92; STORVIK G, 1993, 8TH SCIA C; STORVIK G, 1994, 1 U OSL I MATH TECH; TAN HL, 1992, IEEE T PATTERN ANAL, V14, P3, DOI 10.1109/34.107010; VENKATESWAR V, 1992, IEEE T PATTERN ANAL, V14, P1111, DOI 10.1109/34.166627; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	25	108	121	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					976	986		10.1109/34.329011	http://dx.doi.org/10.1109/34.329011			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827		Green Submitted			2022-12-18	WOS:A1994PM82700002
J	GIDAS, B				GIDAS, B			A RENORMALIZATION-GROUP APPROACH TO IMAGE-PROCESSING PROBLEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											GIDAS, B (corresponding author), BROWN UNIV, DIV APPL MATH, PROVIDENCE, RI 02912 USA.							BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Binder K., 1979, MONTE CARLO METHODS; BRADDOCK OJ, 1978, HDB SENSORY PHYSL PE, V8; BURT P, 1981, PSYCHOL REV, V88, P171, DOI 10.1037/0033-295X.88.2.171; Burt P., 1984, MULTIRESOLUTION IMAG; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CHELLAPPA R, 1982, IEEE T ACOUST SPEECH, V30, P461, DOI 10.1109/TASSP.1982.1163911; COOPER DB, 1983, IEEE T PATTERN ANAL, V5, P299, DOI 10.1109/TPAMI.1983.4767392; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595; GELFAND S, 1985, MIT LIDS1494 TECH RE; Gelfand S. B., 1985, Proceedings of the 24th IEEE Conference on Decision and Control (Cat. No.85CH2245-9), P779; GELLMANN M, 1954, PHYS REV, V95, P1300, DOI 10.1103/PhysRev.95.1300; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1985 P AM STAT ASS S; GEMAN S, 1987, 1986 P INT C MATH; GIDAS B, 1985, J STAT PHYS, V39, P73, DOI 10.1007/BF01007975; GIDAS B, 1987, P WORKSHOP STOCHASTI; GIDAS B, 1987, EFFICIENT METHODS CO; GRENANDER U, 1983, TUTORIAL PATTERN THE; HABIBI A, 1972, PR INST ELECTR ELECT, V60, P878, DOI 10.1109/PROC.1972.8787; HACKBUSH W, IN PRESS MULTIGRID M; HAJEK B, IN PRESS MATH OPER R; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; Hanson A., 1978, COMPUTER VISION SYST; HINTON GE, 1984, CMUCS84119 CARN MELL; HUNT BR, 1977, IEEE T COMPUT, V26, P219, DOI 10.1109/TC.1977.1674810; JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021; JAIN AK, 1974, IEEE T COMPUT, VC 23, P470, DOI 10.1109/T-C.1974.223969; KADANOFF LP, 1976, ANN PHYS-NEW YORK, V100, P359, DOI 10.1016/0003-4916(76)90066-X; KADANOFF LP, 1975, PHYS REV B, V11, P377, DOI 10.1103/PhysRevB.11.377; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KIRPATRICK S, 1983, SCIENCE, V220, P621; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MIGDAL AA, 1975, ZH EKSP TEOR FIZ, V42, P743; MITRA D, 1985, 24TH P C DEC CONTR, P761; NAHI NE, 1972, IEEE T COMPUT, VC 21, P734; NIEMEYER T, 1974, PHYSICA, V71, P17, DOI 10.1016/0031-8914(74)90044-5; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; STUECKELBERG E, 1953, HELV PHYS ACTA, V26, P489; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TRUSSELL HJ, 1980, IEEE T ACOUST SPEECH, V28, P114, DOI 10.1109/TASSP.1980.1163348; TYLER CW, 1973, SCIENCE, V181, P276, DOI 10.1126/science.181.4096.276; TYLER CW, 1977, VISION RES, V17, P109, DOI 10.1016/0042-6989(77)90208-5; VANLEEUWEN JMJ, 1975, PHYS REV LETT, V34, P1056, DOI 10.1103/PhysRevLett.34.1056; Wilson K. G., 1974, Physics Reports. Physics Letters Section C, V12c, P75, DOI 10.1016/0370-1573(74)90023-4; WILSON KG, 1975, REV MOD PHYS, V47, P773, DOI 10.1103/RevModPhys.47.773; WITKIN AP, 1984, IMAGE UNDERSTANDING; YUILLE AL, 1983, MIT772 ART INT LAB M; [No title captured]	52	108	111	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					164	180		10.1109/34.16712	http://dx.doi.org/10.1109/34.16712			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900005
J	OSHIMA, M; SHIRAI, Y				OSHIMA, M; SHIRAI, Y			OBJECT RECOGNITION USING 3-DIMENSIONAL INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											OSHIMA, M (corresponding author), ELECTROTECH LAB,SAKURA,IBARAKI 305,JAPAN.							AGIN G, 1972, AI AIM173 STANF U ME; Barrow H. G., 1971, Machine Intelligence Volume 6, P377; BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; BROOKS R, 1981, 7TH P INT JOINT C AR, P619; DANE C, 1982, THESIS U PENNSYLVANI; DUDA RO, 1979, IEEE T PATTERN ANAL, V1, P259, DOI 10.1109/TPAMI.1979.4766922; GENNERY DB, 1979, 6TH P INT JOINT C AR, P320; GUZMAN A, 1968, MIT MACTR59 REP; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; INOKUCHI S, 1980, 5TH P INT C PATT REC, P1301; ISHII M, 1976, PATTERN RECOGN, V8, P229, DOI 10.1016/0031-3203(76)90043-1; Kyura N., 1973, Bulletin of the Electrotechnical Laboratory, V37, P996; MILGRAM DL, 1980, 5TH P INT C PATT REC, P912; MITICHE A, 1982, MAY P IEEE INT C AC, P1906; NEVATIA R, 1973, 3RD P INT JOINT C AR, P641; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; Oshima M., 1973, Bulletin of the Electrotechnical Laboratory, V37, P493; OSHIMA M, 1979, PATTERN RECOGN, V11, P9, DOI 10.1016/0031-3203(79)90024-4; POPPLESTONE RJ, 1975, 4TH P INT JOINT C AR, P664; SHAPIRA R, 1978, IEEE T COMPUT, V27, P841, DOI 10.1109/TC.1978.1675204; SHIRAI Y, 1972, PATTERN RECOGN, V4, P243, DOI 10.1016/0031-3203(72)90003-9; SHIRAI Y, 1973, COMPUT GRAPHICS IMAG, V2, P298; SUGIHARA K, 1979, ARTIF INTELL, V12, P41, DOI 10.1016/0004-3702(79)90004-3; TSUJI S, 1975, 4TH P INT JOINT C AR, P811; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; YACHIDA M, 1977, IEEE T COMPUT, V26, P882, DOI 10.1109/TC.1977.1674936	26	108	112	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					353	361		10.1109/TPAMI.1983.4767405	http://dx.doi.org/10.1109/TPAMI.1983.4767405			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869120				2022-12-18	WOS:A1983RA57800001
J	Zhang, XQ; Wang, D; Zhou, ZY; Ma, Y				Zhang, Xiaoqin; Wang, Di; Zhou, Zhengyuan; Ma, Yi			Robust Low-Rank Tensor Recovery with Rectification and Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank tensor recovery; rectification; alignment; ADMM; proximal gradient	MATRIX COMPLETION; MODELS; FACTORIZATION; ALGORITHM	Low-rank tensor recovery in the presence of sparse but arbitrary errors is an important problem with many practical applications. In this work, we propose a general framework that recovers low-rank tensors, in which the data can be deformed by some unknown transformations and corrupted by arbitrary sparse errors. We give a unified presentation of the surrogate-based formulations that incorporate the features of rectification and alignment simultaneously, and establish worst-case error bounds of the recovered tensor. In this context, the state-of-the-art methods 'RASL' and 'TILT' can be viewed as two special cases of our work, and yet each only performs part of the function of our method. Subsequently, we study the optimization aspects of the problem in detail by deriving two algorithms, one based on the alternating direction method of multipliers (ADMM) and the other based on proximal gradient. We provide convergence guarantees for the latter algorithm, and demonstrate the performance of the former through in-depth simulations. Finally, we present extensive experimental results on public datasets to demonstrate the effectiveness and efficiency of the proposed framework and algorithms.	[Zhang, Xiaoqin; Wang, Di] Wenzhou Univ, Coll Comp Sci & Artificial Intelligence, Wenzhou 325035, Zhejiang, Peoples R China; [Zhou, Zhengyuan] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Ma, Yi] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Wenzhou University; Stanford University; University of California System; University of California Berkeley	Wang, D (corresponding author), Wenzhou Univ, Coll Comp Sci & Artificial Intelligence, Wenzhou 325035, Zhejiang, Peoples R China.	zhangxiaoqinnan@gmail.com; wangdi@wzu.edu.cn; zyzhou@stanford.edu; yima@eecs.berkeley.edu	Wang, Di/AAB-1437-2019	Wang, Di/0000-0003-0435-0609; Ma, Yi/0000-0001-5485-419X	National Key Research and Development Program of China [2018YFB1004904]; National Natural Science Foundation of China [61772374]; Natural Science Foundation of Zhejiang Province [LY17F030004, LR17F030001]; Project of Science and Technology Plans of Wenzhou City [C20170008, G20160002, ZG2017016]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Zhejiang Province(Natural Science Foundation of Zhejiang Province); Project of Science and Technology Plans of Wenzhou City	This work was supported in part by the National Key Research and Development Program of China [grant no. 2018YFB1004904], in part by the National Natural Science Foundation of China [grant no. 61772374], in part by the Natural Science Foundation of Zhejiang Province [grant nos. LY17F030004, LR17F030001], in part by the Project of Science and Technology Plans of Wenzhou City [grant nos. C20170008, G20160002, ZG2017016]. A preliminary version of this paper was accepted by Advances in Neural Information Processing Systems 2013 [47].	Aybat NS, 2018, IEEE T AUTOMAT CONTR, V63, P5, DOI 10.1109/TAC.2017.2713046; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Candes EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793; Chen L., 2018, ARXIV180310803V1; Chen XJ, 2010, SIAM J SCI COMPUT, V32, P2832, DOI 10.1137/090761471; Cheng WD, 2017, CONSERV LETT, V10, P757, DOI 10.1111/conl.12339; Cox M., 2008, P IEEE C COMP VIS PA, P1; Davenport MA, 2016, IEEE J-STSP, V10, P608, DOI 10.1109/JSTSP.2016.2539100; Fu YF, 2016, IEEE T NEUR NET LEAR, V27, P2120, DOI 10.1109/TNNLS.2016.2553155; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010; Gross D, 2011, IEEE T INFORM THEORY, V57, P1548, DOI 10.1109/TIT.2011.2104999; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Li Y, 2010, LECT NOTES COMPUT SC, V6313, P790; Lin TY, 2016, J SCI COMPUT, V69, P52, DOI 10.1007/s10915-016-0182-0; Lin Z., 2009, UILUENG092215; Lin ZC, 2018, IEEE T PATTERN ANAL, V40, P208, DOI 10.1109/TPAMI.2017.2651816; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lyu Q, 2013, NEUROCOMPUTING, V119, P413, DOI 10.1016/j.neucom.2013.03.017; Mohan K, 2012, J MACH LEARN RES, V13, P3441; Mu C, 2014, PR MACH LEARN RES, V32, P73; Nie F., 2012, PROC 26 AAAI C ARTIF, P655; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Schechter Sc] Eric, 1997, HDB ANAL ITS FDN; Tomioka R., 2011, ARXIV10100789; Vedaldi A., 2008, P IEEE C COMP VIS PA, P1; Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290; Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218; Yang JF, 2013, MATH COMPUT, V82, P301; Yong HW, 2018, IEEE T PATTERN ANAL, V40, P1726, DOI 10.1109/TPAMI.2017.2732350; Zeng WJ, 2018, IEEE T SIGNAL PROCES, V66, P1125, DOI 10.1109/TSP.2017.2784361; Zhang X., 2013, ADV NEURAL INF PROCE, V26, P1637; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zhou P., 2017, P IEEE C COMP VIS PA, P1; Zuo WM, 2013, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2013.34	47	107	107	6	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					238	255		10.1109/TPAMI.2019.2929043	http://dx.doi.org/10.1109/TPAMI.2019.2929043			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31329109				2022-12-18	WOS:000597206900016
J	Wu, W; Chen, Z; Gao, XR; Li, YQ; Brown, EN; Gao, SK				Wu, Wei; Chen, Zhe; Gao, Xiaorong; Li, Yuanqing; Brown, Emery N.; Gao, Shangkai			Probabilistic Common Spatial Patterns for Multichannel EEG Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Common spatial patterns; Fukunaga-Koontz transform; sparse Bayesian learning; variational Bayes; electroencephalogram; brain-computer interface	FEATURE-EXTRACTION; CLASSIFICATION; FILTERS; ALGORITHM; OPTIMIZATION; FRAMEWORK; MIXTURES	Common spatial patterns (CSP) is a well-known spatial filtering algorithm for multichannel electroencephalogram (EEG) analysis. In this paper, we cast the CSP algorithm in a probabilistic modeling setting. Specifically, probabilistic CSP (P-CSP) is proposed as a generic EEG spatio-temporal modeling framework that subsumes the CSP and regularized CSP algorithms. The proposed framework enables us to resolve the overfitting issue of CSP in a principled manner. We derive statistical inference algorithms that can alleviate the issue of local optima. In particular, an efficient algorithm based on eigendecomposition is developed for maximum a posteriori (MAP) estimation in the case of isotropic noise. For more general cases, a variational algorithm is developed for group-wise sparse Bayesian learning for the P-CSP model and for automatically determining the model size. The two proposed algorithms are validated on a simulated data set. Their practical efficacy is also demonstrated by successful applications to single-trial classifications of three motor imagery EEG data sets and by the spatio-temporal pattern analysis of one EEG data set recorded in a Stroop color naming task.	[Wu, Wei; Li, Yuanqing] S China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China; [Chen, Zhe] NYU, Dept Psychiat, Dept Neurosci & Physiol, Sch Med, New York, NY 10016 USA; [Gao, Xiaorong; Gao, Shangkai] Tsinghua Univ, Dept Biomed Engn, Beijing 100084, Peoples R China; [Brown, Emery N.] Harvard Univ, Dept Brain & Cognit Sci, MIT, Cambridge, MA 02139 USA; [Brown, Emery N.] Harvard Univ, Div Hlth Sci & Technol, MIT, Cambridge, MA 02139 USA	South China University of Technology; New York University; Tsinghua University; Harvard University; Massachusetts Institute of Technology (MIT); Harvard University; Massachusetts Institute of Technology (MIT)	Wu, W (corresponding author), S China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.	auweiwu@scut.edu.cn; zhe.sage.chen@gmail.com; gxr-dea@tsinghua.edu.cn; auyqli@scut.edu.cn; enb@neurostat.mit.edu; gsk-dea@tsinghua.edu.cn		Chen, Zhe (Sage)/0000-0002-6483-6056	Specialized Research Fund for the Doctoral Program of Higher Education of China [20130172120032]; Guangdong Natural Science Foundation [S2013010013445]; National High-tech R&D Program of China (863 Program) [2012AA011601]; National Natural Science Foundation of China [91120305]; US National Institutes of Health (NIH) [DP1-OD003646]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM104948] Funding Source: NIH RePORTER; OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF HEALTH [DP1OD003646] Funding Source: NIH RePORTER	Specialized Research Fund for the Doctoral Program of Higher Education of China(Specialized Research Fund for the Doctoral Program of Higher Education (SRFDP)); Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); National High-tech R&D Program of China (863 Program)(National High Technology Research and Development Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by the Specialized Research Fund for the Doctoral Program of Higher Education of China (20130172120032), Guangdong Natural Science Foundation (S2013010013445), National High-tech R&D Program of China (863 Program) under grant 2012AA011601, the National Natural Science Foundation of China under grant 91120305, and the US National Institutes of Health (NIH) under grant DP1-OD003646. The authors are grateful to Klaus-Robert Muller, Benjamin Blankertz, Gabriel Curio, Gert Pfurscheller, Alois Schlogl, and Wenjing Gao for providing the EEG data sets used in this paper. All correspondence should be directed to W. Wu.	Amari S, 1996, ADV NEUR IN, V8, P757; ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; [Anonymous], 2008, P 25 INT C MACH LEAR; Arvaneh M, 2013, IEEE T NEUR NET LEAR, V24, P610, DOI 10.1109/TNNLS.2013.2239310; Baars BJ, 2010, COGNITION, BRAIN, AND CONSCIOUSNESS: INTRODUCTION TO COGNITIVE NEUROSCIENCE, 2ND EDITION, P1; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; Blankertz B., 2008, ADV NEURAL INFORM PR, P113; Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2008.4408441; Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642; Blankertz B, 2011, NEUROIMAGE, V56, P814, DOI 10.1016/j.neuroimage.2010.06.048; Devlaminck D, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/217987; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Dornhege G, 2006, IEEE T BIO-MED ENG, V53, P2274, DOI 10.1109/TBME.2006.883649; Farquhar J., 2006, P 3 INT BRAIN COMP I; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Gelman A, 2006, BAYESIAN ANAL, V1, P515, DOI 10.1214/06-BA117A; Gouy-Pailler C, 2010, IEEE T BIO-MED ENG, V57, P469, DOI 10.1109/TBME.2009.2032162; Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154; Hanslmayr S, 2008, J COGNITIVE NEUROSCI, V20, P215, DOI 10.1162/jocn.2008.20020; Hastie T, 2009, ELEMENTS STAT LEARNI; Higashi H, 2013, IEEE T BIO-MED ENG, V60, P1100, DOI 10.1109/TBME.2012.2215960; Hill N. J., 2007, BRAIN COMPUTER INTER; Huo XM, 2004, IEEE SIGNAL PROC LET, V11, P123, DOI 10.1109/LSP.2003.821650; Kang H, 2009, IEEE SIGNAL PROC LET, V16, P683, DOI 10.1109/LSP.2009.2022557; Kawanabe M, 2014, NEURAL COMPUT, V26, P349, DOI 10.1162/NECO_a_00544; KOLES Z J, 1990, Brain Topography, V2, P275, DOI 10.1007/BF01129656; Kreutz-Delgado K., 1997, UCSDCIE9771; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; Li YQ, 2006, NEURAL COMPUT, V18, P2730, DOI 10.1162/neco.2006.18.11.2730; Lotte F, 2011, IEEE T BIO-MED ENG, V58, P355, DOI 10.1109/TBME.2010.2082539; Lu HP, 2010, IEEE T BIO-MED ENG, V57, P2936, DOI 10.1109/TBME.2010.2082540; Mackey L., 2009, P ADV NEUR INF PROC, V21, P1017; Niedermeyer E., 1999, ELECTROEN CLIN NEURO, V4th; Nummemnaa A, 2007, NEUROIMAGE, V35, P669, DOI 10.1016/j.neuroimage.2006.05.001; Onaran I, 2013, BIOMED SIGNAL PROCES, V8, P282, DOI 10.1016/j.bspc.2012.10.003; Palmer Jason, 2006, ADV NEURAL INFORM PR, P1059; Parra L, 2004, J MACH LEARN RES, V4, P1261; Pham DT, 2001, IEEE T SIGNAL PROCES, V49, P1837, DOI 10.1109/78.942614; Robert C.P., 2007, BAYESIAN CHOICE DECI, Vsecond; Samek W., 2013, ADV NEURAL INFORM PR, P1007; Samek W, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026013; Sanei S, 2007, EEG SIGNAL PROCESSIN; Seeger MW, 2010, IEEE SIGNAL PROC MAG, V27, P81, DOI 10.1109/MSP.2010.938082; Suk HI, 2013, IEEE T PATTERN ANAL, V35, P286, DOI 10.1109/TPAMI.2012.69; Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055; Tomioka R., 2006, 40 U TOK DEP MATH EN, DOI 10.1007/11861898_42; Turner R., 2011, BAYESIAN TIME SERIES; Wang HX, 2012, IEEE T BIO-MED ENG, V59, P653, DOI 10.1109/TBME.2011.2177523; Wu W, 2005, P ANN INT IEEE EMBS, P2387; Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174; Wu W, 2008, IEEE T BIO-MED ENG, V55, P1733, DOI 10.1109/TBME.2008.919125; Wu W, 2009, IEEE ENG MED BIO, P4658, DOI 10.1109/IEMBS.2009.5332646; Wu W, 2011, NEUROIMAGE, V56, P1929, DOI 10.1016/j.neuroimage.2011.03.032; Yong XY, 2008, INT CONF ACOUST SPEE, P417; Zhang HH, 2011, IEEE T NEURAL NETWOR, V22, P52, DOI 10.1109/TNN.2010.2084099; Zhang S, 2007, IEEE T PATTERN ANAL, V29, P1732, DOI 10.1109/TPAMI.2007.1089; Zhao QB, 2009, INT CONF ACOUST SPEE, P525, DOI 10.1109/ICASSP.2009.4959636	58	107	115	8	78	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					639	653		10.1109/TPAMI.2014.2330598	http://dx.doi.org/10.1109/TPAMI.2014.2330598			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26005228	Green Published, Green Accepted			2022-12-18	WOS:000349626200012
J	Zhang, L; van der Maaten, L				Zhang, Lu; van der Maaten, Laurens			Preserving Structure in Model-Free Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Model-free tracking; multiple-object tracking; online learning; structured SVM	POSE ESTIMATION; LOCALIZATION; OBJECTS	Model-free trackers can track arbitrary objects based on a single (bounding-box) annotation of the object. Whilst the performance of model-free trackers has recently improved significantly, simultaneously tracking multiple objects with similar appearance remains very hard. In this paper, we propose a new multi-object model-free tracker (using a tracking-by-detection framework) that resolves this problem by incorporating spatial constraints between the objects. The spatial constraints are learned along with the object detectors using an online structured SVM algorithm. The experimental evaluation of our structure-preserving object tracker (SPOT) reveals substantial performance improvements in multi-object tracking. We also show that SPOT can improve the performance of single-object trackers by simultaneously tracking different parts of the object. Moreover, we show that SPOT can be used to adapt generic, model-based object detectors during tracking to tailor them towards a specific instance of that object.	[Zhang, Lu; van der Maaten, Laurens] Delft Univ Technol, Dept Intelligent Syst, NL-2600 GA Delft, Netherlands	Delft University of Technology	Zhang, L (corresponding author), Delft Univ Technol, Dept Intelligent Syst, Mekelweg 4, NL-2600 GA Delft, Netherlands.	lu.zhang@tudelft.nl; l.j.p.vandermaaten@tudelft.nl			EU-FP7 Social Signal Processing (SSPNet); China Scholarship Council	EU-FP7 Social Signal Processing (SSPNet); China Scholarship Council(China Scholarship Council)	This work was supported by EU-FP7 Social Signal Processing (SSPNet) and by the China Scholarship Council. The authors thank two anonymous reviewers for helpful comments on earlier versions of this paper. In addition, the authors thank David Tax, Marco Loog, and Martijn van de Giessen for many helpful discussions, and Zdenek Kalal and Helmut Grabner for their implementations of the TLD and OAB trackers.	Adam A., 2006, IEEE C COMP VIS PATT; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Balan A. O., 2006, 2006 IEEE COMPUTER S, V1, P758; Bibby C., 2010, P EUR C COMP VIS; Birchfield S., 1998, P IEEE C COMP VIS PA; Bischof H., 2006, BMVC, P47; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Blake A., 1998, ACTIVE SHAPE MODELS; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Bottou L., 1998, ONLINE LEARNING NEUR; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Caraffi C, 2012, IEEE INT C INTELL TR, P975, DOI 10.1109/ITSC.2012.6338748; CERMAN L, 2009, P SCAND C IM AN; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; Crammer K, 2006, J MACH LEARN RES, V7, P551; Cristinacce D, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P429; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733; Dollar P., 2010, P BRIT MACH VIS C, P681; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Dredze M., 2008, P 25 INT C MACHINE L, V307, P264, DOI DOI 10.1145/1390156.1390190; Duan GQ, 2012, LECT NOTES COMPUT SC, V7574, P129, DOI 10.1007/978-3-642-33712-3_10; Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965; Ess A., 2008, P IEEE C COMP VIS PA; Felzenszwalb P., DISTANCE TRANSFORMS; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Ferrari V., 2009, P IEEE C COMP VIS PA; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gao H, 2013, IEEE SYMP COMMUN VEH; Grabner H., 2008, P EUR C COMP VIS; Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Kalal Z., 2010, P IEEE C INT C IM PR; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Lafferty J, 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.1038/NPROT.2006.61; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Li Y, 2008, LECT NOTES COMPUT SC, V5305, P409; LIN RS, 2004, ADV NEURAL INFORM PR, P801; Liu X., 2007, P IEEE INT C COMP VI, P1; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Maaten L., 2011, P 14 INT C ARTIFICIA, P479; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Minka T., 2005, MSRTR2005144; Ott P, 2011, PROC CVPR IEEE, P1513, DOI 10.1109/CVPR.2011.5995357; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Platt J., 1999, ADV LARGE MARGIN CLA; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Roth Peter M., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2727, DOI 10.1109/CVPRW.2009.5206616; Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Shi J, 1994, P IEEE C COMP VIS PA; Stalder S, 2010, LECT NOTES COMPUT SC, V6311, P369, DOI 10.1007/978-3-642-15549-9_27; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wu Z, 2012, PROC CVPR IEEE, P1948, DOI 10.1109/CVPR.2012.6247896; Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146; YANG Y, 2011, CVPR, P1385; Yang Y, 2012, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2012.6248095; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yu T, 2004, PROC CVPR IEEE, P834; Yu T., 2005, P IEEE C COMP VIS PA; Zhang L., 2013, P IEEE C COMP VIS PA; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zoutendijk G., 1960, METHODS FEASIBLE DIR	76	107	117	8	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					756	769		10.1109/TPAMI.2013.221	http://dx.doi.org/10.1109/TPAMI.2013.221			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353198				2022-12-18	WOS:000334109000010
J	Tzimiropoulos, G; Argyriou, V; Zafeiriou, S; Stathaki, T				Tzimiropoulos, Georgios; Argyriou, Vasileios; Zafeiriou, Stefanos; Stathaki, Tania			Robust FFT-Based Scale-Invariant Image Registration with Image Gradients	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Global motion estimation; correlation methods; FFT; scale-invariant image registration; frontal view face registration	FOURIER-TRANSFORM	We present a robust FFT-based approach to scale-invariant image registration. Our method relies on FFT-based correlation twice: once in the log-polar Fourier domain to estimate the scaling and rotation and once in the spatial domain to recover the residual translation. Previous methods based on the same principles are not robust. To equip our scheme with robustness and accuracy, we introduce modifications which tailor the method to the nature of images. First, we derive efficient log-polar Fourier representations by replacing image functions with complex gray-level edge maps. We show that this representation both captures the structure of salient image features and circumvents problems related to the low-pass nature of images, interpolation errors, border effects, and aliasing. Second, to recover the unknown parameters, we introduce the normalized gradient correlation. We show that, using image gradients to perform correlation, the errors induced by outliers are mapped to a uniform distribution for which our normalized gradient correlation features robust performance. Exhaustive experimentation with real images showed that, unlike any other Fourier-based correlation techniques, the proposed method was able to estimate translations, arbitrary rotations, and scale factors up to 6.	[Tzimiropoulos, Georgios; Zafeiriou, Stefanos; Stathaki, Tania] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England; [Argyriou, Vasileios] Kingston Univ, Fac Comp Informat Syst & Math, Kingston upon Thames KT1 2EE, Surrey, England	Imperial College London; Kingston University	Tzimiropoulos, G (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.	gt204@imperial.ac.uk; vasileios.argyriou@kingston.ac.uk; szafeiri@imperial.ac.uk; t.stathaki@imperial.ac.uk		Tzimiropoulos, Georgios/0000-0002-1803-5338	DOD Counterdrug Technology Development Program Office; Systems Engineering for Autonomous Systems (SEAS) Defence Technology Centre	DOD Counterdrug Technology Development Program Office; Systems Engineering for Autonomous Systems (SEAS) Defence Technology Centre	The authors would like to thank Professor Wolberg and Dr. Zokai for graciously running their algorithm [7] on the image pairs of Section 1 of the supplementary material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.107, as well as for providing the image pairs of Section 3 of the supplementary material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.107. They are grateful to Professor Michael Elad for providing the Matlab implementation of the polar FFT. They would also like to thank the associate editor and the anonymous reviewers whose suggestions and comments greatly improved the quality of this work. Portions of the research in this paper use the FERET database of facial images collected under the FERET program, sponsored by the DOD Counterdrug Technology Development Program Office. This work was supported by the Systems Engineering for Autonomous Systems (SEAS) Defence Technology Centre established by the UK Ministry of Defence.	[Anonymous], 2010, IMAGE DATABASE; Argyriou V, 2003, ELECTRON LETT, V39, P980, DOI 10.1049/el:20030666; Averbuch A, 2006, APPL COMPUT HARMON A, V21, P145, DOI 10.1016/j.acha.2005.11.003; AVERBUCH A, SIAM J SCI IN PRESS; BRACEWELL RN, 1993, ELECTRON LETT, V29, P304, DOI 10.1049/el:19930207; FITCH AJ, 2002, P BMVC, V1, P133; FRIGO M, 2007, FFTW CELL PROCESSOR; Garcia A.L., 2004, PROBABILITY RANDOM P; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Govindaraju Naga, 2008, P ACM IEEE C SUP; HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837; Keller Y, 2007, SIGNAL PROCESS, V87, P124, DOI 10.1016/j.sigpro.2006.04.013; Keller Y, 2005, IEEE T IMAGE PROCESS, V14, P12, DOI 10.1109/TIP.2004.838692; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; Liu HZ, 2006, IEEE SIGNAL PROC LET, V13, P17, DOI 10.1109/LSP.2005.860549; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Pan W, 2009, IEEE T PATTERN ANAL, V31, P400, DOI 10.1109/TPAMI.2008.83; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761; Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276; Stone HS, 2003, J VIS COMMUN IMAGE R, V14, P114, DOI 10.1016/S1047-3203(03)00002-6; Zokai S, 2005, IEEE T IMAGE PROCESS, V14, P1422, DOI 10.1109/TIP.2005.854501	23	107	119	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1899	1906		10.1109/TPAMI.2010.107	http://dx.doi.org/10.1109/TPAMI.2010.107			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20479492				2022-12-18	WOS:000281000700014
J	Borenstein, E; Ullman, S				Borenstein, Eran; Ullman, Shimon			Combined Top-Down/Bottom-Up Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Class-specific top-down segmentation; multiscale segmentation; learning to segment; combining top-down and bottom-up segmentation; object cover; fragment-based representation; combined segmentation and recognition	OBJECT RECOGNITION; FIGURE; SEGREGATION	We construct an image segmentation scheme that combines top-down (TD) with bottom-up (BU) processing. In the proposed scheme, segmentation and recognition are intertwined rather than proceeding in a serial manner. The TD part applies stored knowledge about object shapes acquired through learning, whereas the BU part creates a hierarchy of segmented regions based on uniformity criteria. Beginning with unsegmented training examples of class and nonclass images, the algorithm constructs a bank of class-specific fragments and determines their figure-ground segmentation. This fragment bank is then used to segment novel images in a TD manner: The stored fragments are first used to recognize images containing class objects and then to create a complete cover that best approximates these objects. The resulting TD segmentation is then integrated with BU multiscale grouping to better delineate the object boundaries. Our experiments, applied to a large set of four classes (horses. pedestrians, cars, and faces), demonstrate segmentation results that surpass those achieved by previous TD or BU schemes. The main novel aspects of this work are the fragment learning phase, which efficiently learns the figure-ground labeling of segmentation fragments, even in training sets with high object and background variability, combining the resulting TD segmentation with BU criteria, and the use of segmentation to improve recognition.	[Borenstein, Eran] Brown Univ, Div Appl Math, Providence, RI 02912 USA; [Ullman, Shimon] Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel	Brown University; Weizmann Institute of Science	Borenstein, E (corresponding author), Brown Univ, Div Appl Math, 182 George St, Providence, RI 02912 USA.	eran_borenstein@brown.edu; shimon.ullman@weizmann.ac.il			ISF [7-0369]; EU IST [FP6-2005-015803]	ISF(Israel Science Foundation); EU IST(European Commission)	The authors Would like to thank Eitan Sharon for useful discussions and for his BU segmentation code. This work was Supported by ISF Grant 7-0369 and EU IST Grant FP6-2005-015803.	Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113; Amit Y, 2000, NEURAL COMPUT, V12, P1141, DOI 10.1162/089976600300015538; Baylis GC, 2001, NAT NEUROSCI, V4, P937, DOI 10.1038/nn0901-937; BERNSTEIN E, 2005, P COMP VIS PATT REC, V2; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; BORENSTEIN E, 2004, P EUR C COMP VIS ECC; BORENSTEIN E, 2002, P EUR C COMP VIS ECC, V2, P109; BORENSTEIN E, 2004, P COMP VIS PATT REC; Brady MJ, 2003, J VISION, V3, P413, DOI 10.1167/3.6.2; BUF JD, 1990, PATTERN RECOGNITION, V23; BURL MC, 1998, LNCS, V1407; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1995, IEEE T PATTERN ANAL; CHEN X, 2003, P INT C COMP VIS ICC; FLEURET F, 2004, J MACHINE LEARNI NOV; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hupe JM, 1998, NATURE, V394, P784, DOI 10.1038/29537; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar MP, 2005, PROC CVPR IEEE, P18; LAMME VAF, 1995, J NEUROSCI, V15, P1605; Leibe Bastian, 2003, P BRIT MACH VIS C BM; LEVIN A., 2006, P EUR C COMP VIS ECC; LIU L, 2001, P INT C COMP VIS ICC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MIKOLAJCZYK K, 2002, P ECCV, V1, P128; MONTANARI U, 1971, COMM ACM, V14; Mori G., 2004, P COMP VIS PATT REC; MUMFORD D, 1985, P COMP VIS PATT REC; Needham A, 2001, J EXP CHILD PSYCHOL, V78, P3, DOI 10.1006/jecp.2000.2598; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; PETERSON MA, 1994, CURR DIR PSYCHOL SCI, V3, P105, DOI 10.1111/1467-8721.ep10770552; Quinn PC, 2003, COGNITIVE SCI, V27, P923, DOI 10.1016/j.cogsci.2003.07.001; REN X, 2005, P INT C COMP VIS ICC; SALI E, 1999, P BRIT MACH VIS C BM; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Sharon E, 2006, NATURE, V442, P810, DOI 10.1038/nature04977; SHASHUA A, 1988, P INT C COMP VIS; Shi J., 1997, P COMP VIS PATT REC; SUPPER H, 2001, J VISION, V1, P345; ULLMAN S, 2001, P 4 INT WORKSH VIS F; ULLMAN S, 2000, P BMCV 00, P73; Weeks AR, 1997, P SOC PHOTO-OPT INS, V3026, P143, DOI 10.1117/12.271117; Winn J, 2005, IEEE I CONF COMP VIS, P756; WINN J, 2006, P COMP VIS PATT REC; YU SX, 2002, P ANN C ADV NEUR INF; YUILLE A, 1992, ACTIVE VISION, P21; Zemel RS, 2002, J EXP PSYCHOL HUMAN, V28, P202, DOI 10.1037//0096-1523.28.1.202; ZHAO L, 2005, P INT C COMP VIS ICC, V1; Zipser K, 1996, J NEUROSCI, V16, P7376	52	107	112	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2109	2125		10.1109/TPAMI.2007.70840	http://dx.doi.org/10.1109/TPAMI.2007.70840			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988946				2022-12-18	WOS:000260033900004
J	Hu, WM; Wu, O; Chen, ZY; Fu, ZY; Maybank, S				Hu, Weiming; Wu, Ou; Chen, Zhouyao; Fu, Zhouyu; Maybank, Steve			Recognition of pornographic web pages by classifying texts and images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						web pages; pornographic texts; pornographic images; data fusion; recognition	ENGINE	With the rapid development of the World Wide Web, people benefit more and more from the sharing of information. However, Web pages with obscene, harmful, or illegal content can be easily accessed. It is important to recognize such unsuitable, offensive, or pornographic Web pages. In this paper, a novel framework for recognizing pornographic Web pages is described. A C4.5 decision tree is used to divide Web pages, according to content representations, into continuous text pages, discrete text pages, and image pages. These three categories of Web pages are handled, respectively, by a continuous text classifier, a discrete text classifier, and an algorithm that fuses the results from the image classifier and the discrete text classifier. In the continuous text classifier, statistical and semantic features are used to recognize pornographic texts. In the discrete text classifier, the naive Bayes rule is used to calculate the probability that a discrete text is pornographic. In the image classifier, the object's contour-based features are extracted to recognize pornographic images. In the text and image fusion algorithm, the Bayes theory is used to combine the recognition results from images and texts. Experimental results demonstrate that the continuous text classifier outperforms the traditional keyword-statistics-based classifier, the contour-based image classifier outperforms the traditional skin-region-based image classifier, the results obtained by our fusion algorithm outperform those by either of the individual classifiers, and our framework can be adapted to different categories of Web pages.	Chinese Acad Sci, Inst Automat, NLPR, Beijing 100080, Peoples R China; Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HT, England	Chinese Academy of Sciences; Institute of Automation, CAS; University of London; Birkbeck University London	Hu, WM (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, POB 2728, Beijing 100080, Peoples R China.	wmhu@nlpr.ia.ac.cn; owu@nlpr.ia.ac.cn; zychen82@nlpr.ia.ac.cn; zyfu@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk						Arentz WA, 2004, COMPUT VIS IMAGE UND, V94, P295, DOI 10.1016/j.cviu.2003.10.007; BOSSON A, 2002, P INT C IM VID RETR, P50; Brin S., 1998, COMPUT NETW ISDN SYS, V30, P107, DOI [DOI 10.1016/S0169-7552(98)00110-X, 10.1016/s0169-7552(98)00110-x]; BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560; CHAN Y, 2000, P EUR SIGN PROC C, V3; Du RB, 2003, ICON 2003: 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, P325; Eysenbach G., 2000, J MED INTERNET RES, V2; FLECK MM, 1996, P EUR C COMP VIS, V2, P592; Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399; Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462; FORSYTH DA, 1998, P 32 AS C SIGN SYST, V1, P905; FORSYTH DA, 1997, P INT C IM PROC, V3, P5; Hammami M, 2006, IEEE T KNOWL DATA EN, V18, P272, DOI 10.1109/TKDE.2006.34; Hammami M, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P574; Ho WH, 2004, IEEE SYS MAN CYBERN, P4792; HUNTER CD, 1999, THESIS U PENNSYLVANI; Ioffe S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1092, DOI 10.1109/ICCV.1999.790398; Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708; IOFFE S, 1999, ADV NEURAL INFORM PR; JIAO F, 2001, P IEEE INT C INF TEC, V3, P378; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; KELLER D, 2000, FINAL REPORT DVB REG; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; KOKAR MM, 2001, P 4 INT C INF FUS, V1; LALMAS M, P 20 ANN INT ACM SIG, P110; Lee PY, 2005, IEEE T MULTIMEDIA, V7, P1183, DOI 10.1109/TMM.2005.858414; Lee PY, 2002, IEEE INTELL SYST, V17, P48, DOI 10.1109/MIS.2002.1039832; LIANG KM, 2004, P AS C COMP VIS, P497; LUKIANIUK A, 1996, P IEEE INT WORKSH CE, P3740; McCallum A., 1998, AAAI 98 WORKSHOP LEA, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426; McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1; MILANOVA MG, 2000, P 11 PORT C PATT REC, P49; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; ROTTA AL, 2001, WP223V1023 NETPROTEC; SMITH D, 1999, P IEE EUR WORKSH DIS, V99; Song R., 2004, P 13 INT C WORLD WID, P203, DOI DOI 10.1145/988672.988700; Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612; Wang JZ, 1998, COMPUT COMMUN, V21, P1355, DOI 10.1016/S0140-3664(98)00203-5; WANG JZ, 1997, P INT WORKSH INT DIS, P20; Yang JF, 2004, INT C PATT RECOG, P479, DOI 10.1109/ICPR.2004.1333806; Yang Yiming, 1997, P 14 INT C MACHINE L, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Zheng HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1223, DOI 10.1109/ICME.2004.1394442	43	107	116	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1019	1034		10.1109/TPAMI.2007.1133	http://dx.doi.org/10.1109/TPAMI.2007.1133			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431300				2022-12-18	WOS:000245600800008
J	Deng, HW; Clausi, DA				Deng, HW; Clausi, DA			Gaussian MRF rotation-invariant features for image classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random field (MRF); Gaussian MRF (GMRF) model; isotropic; anisotropic; least squares estimate (LSE); discrete Fourier transform (DFT); rotational invariance; texture analysis; classification	TEXTURE CLASSIFICATION; SPATIAL-INTERACTION; WAVELET; SCALE	Features based on Markov random field (MRF) models are sensitive to texture rotation. This paper develops an anisotropic circular Gaussian MRF (ACGMRF) model for retrieving rotation-invariant texture features. To overcome the singularity problem of the least squares estimate method, an approximate least squares estimate method is designed and implemented. Rotation-invariant features are obtained from the ACGMRF model parameters using the discrete Fourier transform. The ACGMRF model is demonstrated to be a statistical improvement over three published methods. The three methods include a Laplacian pyramid, an isotropic circular GMRF (ICGMRF), and gray level cooccurrence probability features.	Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	University of Waterloo	Deng, HW (corresponding author), Univ Waterloo, Dept Syst Design Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.	h2deng@engmail.uwaterloo.ca; dclausi@engmail.uwaterloo.ca	Clausi, David A/J-4613-2013					Arof H, 1998, IEE P-VIS IMAGE SIGN, V145, P167, DOI 10.1049/ip-vis:19981688; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Bishop T., 1975, DISCRETE MULTIVARIAT; BRODATZ P, 1968, TEXTURE PHOTOGRAPHIC; Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; GREENSPAN H, 1994, INT C PATT RECOG, P162, DOI 10.1109/ICPR.1994.576896; Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Li S. Z., 2001, COMP SCI W; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Porter R, 1997, IEE P-VIS IMAGE SIGN, V144, P180, DOI 10.1049/ip-vis:19971182; Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993	15	107	114	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					951	955		10.1109/TPAMI.2004.30	http://dx.doi.org/10.1109/TPAMI.2004.30			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579954	Green Submitted			2022-12-18	WOS:000221323900013
J	Pollefeys, M; Van Gool, L				Pollefeys, M; Van Gool, L			Stratified self-calibration with the modulus constraint	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						self-calibration; affine calibration; metric calibration; metric 3D reconstruction; 3D modeling; uncalibrated image sequences	EUCLIDEAN RECONSTRUCTION; SEQUENCES; POINT	In computer vision and especially for 3D reconstruction, one of the key issues is the retrieval of the calibration parameters of the camera. These are needed to obtain metric information about the scene from the camera. Often these parameters are obtained through cumbersome calibration procedures. There is a way to avoid explicit calibration of the camera. Self-calibration is based on finding the set of calibration parameters which satisfy some constraints (e.g., constant calibration parameters). Several techniques have been proposed but it often proved difficult to reach a metric calibration at once. Therefore, in this paper, a stratified approach is proposed, which goes from projective through affine to metric. The key concept to achieve this is the modulus constraint. It allows retrieval of the affine calibration for constant intrinsic parameters. It is also suited for use in conjunction with scene knowledge. In addition, ii the affine calibration is known, it can also be used to cope with a changing focal length.	Katholieke Univ Leuven, VISICS PSI ESAT Grp, B-3001 Heverlee, Belgium	KU Leuven	Pollefeys, M (corresponding author), Katholieke Univ Leuven, VISICS PSI ESAT Grp, Kardinaal Mercierlaan 94, B-3001 Heverlee, Belgium.	Marc.Pollefeys@esat.kuleuven.ac.be; Luc.VanGool@esat.kuleuven.ac.be	Pollefeys, Marc/I-7607-2013					ARMSTRONG M, 1994, P BRIT MACH VIS C; BEARDSLEY P, 1996, EUR C COMP VIS, P683; DEVERNAY F, 1996, P IEEE C COMP VIS PA; FALKENHAGEN L, 1994, P EUR WORKSH COMB RE; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; HARRIS C, 1988, P 4 ALV VIS C, P1447; HARTLEY R, 1994, P 3 EUR C COMP VIS, P471; HARTLEY R, 1992, P 2 EUR C COMP VIS, P579; Hartley R. I., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P237; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362; Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P339, DOI 10.1109/ICPR.1996.546045; Horaud R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96, DOI 10.1109/ICCV.1998.710706; KOCH R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P109, DOI 10.1109/ICCV.1995.466799; Laveau S., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P147, DOI 10.1007/BFb0015531; LUONG QT, 1996, INT J COMPUTER VISIO; LUONG QT, 1994, P 3 EUR C COMP VIS S, P589; MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236; Mohr R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P543, DOI 10.1109/CVPR.1993.341077; Mohr R., 1994, APPL INVARIANCE COMP, P297; Moons T., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P297; Morgan A. P., 1987, SOLVING POLYNOMIAL S; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Pollefeys M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P31, DOI 10.1007/BFb0015521; Pollefeys M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P349, DOI 10.1109/ICPR.1996.546047; Pollefeys M, 1997, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.1997.609357; POLLEFEYS M, 1996, RECENT DEV COMPUTER, V1035, P405; POLLEFEYS M, 1997, P INT C COMP AN IM P, P175; PROESMANS M, 1994, ECCV, P295; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467; Sturm P., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P838; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; STURM P, 1997, THESIS INP GRENOBLE; SZELISKI R, 1993, 933 DEC; TORR P, 1995, THESIS OXFORD U PRES; TORR P, 1994, P BRIT MACH VIS C; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Tuytelaars T., 1997, Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC'97. Proceedings, P278, DOI 10.1007/BFb0017873; ZELLER C, 1996, 2793 INRIA; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zisserman A., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P93, DOI 10.1109/WVRS.1995.476857	43	107	115	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					707	724		10.1109/34.784285	http://dx.doi.org/10.1109/34.784285			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000003
J	BOURLARD, H; WELLEKENS, CJ				BOURLARD, H; WELLEKENS, CJ			LINKS BETWEEN MARKOV-MODELS AND MULTILAYER PERCEPTRONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BOURLARD, H (corresponding author), PHILIPS RES LABS,AV ALBERT EINSTEIN 4,B-1348 LOUVAIN LA NEUVE,BELGIUM.							BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAHL LR, 1986, P IEEE INT C AC SPEE, P49; Bourlard H., 1989, Computer Speech and Language, V3, P1, DOI 10.1016/0885-2308(89)90011-9; BOURLARD H, 1987, 1ST P IEEE INT C NEU, P407; BOURLARD H, 1986, P EUSIPCO 86, P507; BOURLARD H, 1985, SPEECH SPEAKER RECOG; Bourlard H., 1990, ADV NEURAL INFORMATI, V2, P186; Bridle J. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P899; BRIDLE JS, 1989, P C NEURAL NETWORK C; BROWN PF, 1987, THESIS CARNEGIEMELLO; BURR DJ, 1987, AIP C P NEURAL INFOR; Devijver PA, 1982, PATTERN RECOGNITION; ELMAN JL, 1988, CRL8801 U CAL TECH R; FUKUNAGA K, 1972, INTRO STATISTICAL PA; FURUI S, 1986, IEEE T ACOUST SPEECH, V34, P52, DOI 10.1109/TASSP.1986.1164788; HINTON GE, 1987, CMUCS87115 CARN U TE; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; JORDAN ML, 1986, 8604 U CAL DAV TECH; LeCun Y., 1987, THESIS U PARIS 6; LIPPMAN RP, 1987, 1ST P INT C NEUR NET; Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]; MACKAY DJ, 1987, RIPRREP10001487 TECH; MARCUS SM, 1981, J PHONETICS, V9, P197, DOI 10.1016/S0095-4470(19)30945-3; MARCUS SM, 1985, SPEECH SPEAKER RECOG; MARTIN EA, 1987, P ICASSP 87 DALLAS; MERIALDO B, 1988, P IEEE INT C AC SPEE, P111; Morgan N, 1990, ADV NEURAL INF PROCE, V2, P630; MURVEIT H, 1986, IEEE T ACOUST SPEECH, V34, P1465, DOI 10.1109/TASSP.1986.1164986; MURVEIT H, 1988, P IEEE INT C ACOUSTI, P115; NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320; Noll A., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1277; PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229; PINEDA FJ, 1988, J COMPLEXITY, V59; Poritz A. B., 1988, P IEEE INT C AC SPEE, P7; Prager R. W., 1986, Computer Speech and Language, V1, P3, DOI 10.1016/S0885-2308(86)80008-0; ROBINSON AJ, 1987, CUEDFINFENGTR1 CAMBR; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; Sejnowski T. J., 1987, Complex Systems, V1, P145; SOLLA SA, 1988, UNPUB ACCELERATED LE; TANK DW, 1987, 1ST P IEEE INT C NEU, P455; UNNIKRISHNAN KP, 1988, P C NEURAL NETWORK C; WAIBEL A, 1988, P ICASSP 88 NEW YORK; WATROUS RL, 1987, 1ST P INT C NEUR NET, V4, P381; WATROUS RL, 1986, MSCIS8678 U PENNS TE; WELLEKENS CJ, 1986, P ICASSP 86 TOKYO; WELLEKENS CJ, 1987, P ICASSP 87	46	107	111	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1167	1178		10.1109/34.62605	http://dx.doi.org/10.1109/34.62605			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500		Green Submitted			2022-12-18	WOS:A1990EN50000004
J	MILLIGAN, GW; SOON, SC; SOKOL, LM				MILLIGAN, GW; SOON, SC; SOKOL, LM			THE EFFECT OF CLUSTER SIZE, DIMENSIONALITY, AND THE NUMBER OF CLUSTERS ON RECOVERY OF TRUE CLUSTER STRUCTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									OHIO STATE UNIV,COLL ADM SCI,COLUMBUS,OH 43210; FLIGHT SYST INC,ARLINGTON,VA 22209	University System of Ohio; Ohio State University	MILLIGAN, GW (corresponding author), OHIO STATE UNIV,FAC MANAGEMENT SCI,COLUMBUS,OH 43210, USA.							BLASHFIELD RK, 1976, PSYCHOL BULL, V83, P377, DOI 10.1037/0033-2909.83.3.377; CHILDRESS M, 1981, JUN M CLASS SOC TOR; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; DOWNTON M, 1980, JUN M CLASS SOC BOUL; DUBIEN JL, 1981, AUG M AM STAT ASS DE; EVERITT B, 1975, CLUSTER ANAL; FOWLKES EB, 1980, JUN M CLASS SOC BOUL; KUIPER FK, 1975, BIOMETRICS, V31, P777, DOI 10.2307/2529565; Milligan G. W., 1980, Decision Sciences, V11, P669, DOI 10.1111/j.1540-5915.1980.tb01168.x; MILLIGAN GW, 1981, MULTIVAR BEHAV RES, V16, P379, DOI 10.1207/s15327906mbr1603_7; MILLIGAN GW, 1980, PATTERN RECOGN, V12, P41, DOI 10.1016/0031-3203(80)90001-1; MILLIGAN GW, 1980, PSYCHOMETRIKA, V45, P325, DOI 10.1007/BF02293907; MILLIGAN GW, 1981, PSYCHOMETRIKA, V46, P187, DOI 10.1007/BF02293899; MOREY L, 1981, JUN M CLASS SOC TOR; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; SNEATH PHA, 1969, NUMERICAL TAXONOMY	17	107	108	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					40	47		10.1109/TPAMI.1983.4767342	http://dx.doi.org/10.1109/TPAMI.1983.4767342			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	PZ844	21869081				2022-12-18	WOS:A1983PZ84400005
J	Maninis, KK; Pont-Tuset, J; Arbelaez, P; Van Gool, L				Maninis, Kevis-Kokitsi; Pont-Tuset, Jordi; Arbelaez, Pablo; Van Gool, Luc			Convolutional Oriented Boundaries: From Image Segmentation to High-Level Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Contour detection; contour orientation; hierarchical image segmentation; object proposals; semantic contours		We present Convolutional Oriented Boundaries ( COB), which produces multiscale oriented contours and region hierarchies starting from generic image classification Convolutional Neural Networks (CNNs). COB is computationally efficient, because it requires a single CNN forward pass for multi-scale contour detection and it uses a novel sparse boundary representation for hierarchical segmentation; it gives a significant leap in performance over the state-of-the-art, and it generalizes very well to unseen categories and datasets. Particularly, we show that learning to estimate not only contour strength but also orientation provides more accurate results. We perform extensive experiments for low-level applications on BSDS, PASCAL Context, PASCAL Segmentation, and NYUD to evaluate boundary detection performance, showing that COB provides state-of-the-art contours and region hierarchies in all datasets. We also evaluate COB on high-level tasks when coupled with multiple pipelines for object proposals, semantic contours, semantic segmentation, and object detection on MS-COCO, SBD, and PASCAL; showing that COB also improves the results for all tasks.	[Maninis, Kevis-Kokitsi; Pont-Tuset, Jordi; Van Gool, Luc] ETHZ, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Arbelaez, Pablo] Univ Los Andes, Dept Biomed Engn, Bogota 111711, Colombia	Swiss Federal Institutes of Technology Domain; ETH Zurich; Universidad de los Andes (Colombia)	Maninis, KK (corresponding author), ETHZ, Comp Vis Lab, CH-8092 Zurich, Switzerland.	kmaninis@vision.ee.ethz.ch; jponttuset@vision.ee.ethz.ch; pa.arbelaez@uniandes.edu.co; vangool@vision.ee.ethz.ch		Arbelaez, Pablo/0000-0001-5244-2407	Swiss Commission for Technology and Innovation (CTI) [19015.1 PFES]; EU Framework Programme for Research and Innovation Horizon [645331]; armasuisse	Swiss Commission for Technology and Innovation (CTI); EU Framework Programme for Research and Innovation Horizon; armasuisse	Research funded by the EU Framework Programme for Research and Innovation Horizon 2020 (Grant No. 645331, EurEyeCase), and by the Swiss Commission for Technology and Innovation (CTI, Grant No. 19015.1 PFES-ES, NeGeVA). The authors gratefully acknowledge support by armasuisse and thank NVidia for donating the GPUs used in this work.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392; Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65; Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Everingham M., 2012, PASCAL VISUAL OBJECT; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Humayun A, 2015, IEEE I CONF COMP VIS, P1600, DOI 10.1109/ICCV.2015.187; Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50; Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Khoreva A, 2016, PROC CVPR IEEE, P183, DOI 10.1109/CVPR.2016.27; Kittler J, 1983, IMAGE VISION COMPUT, V1, P37, DOI DOI 10.1016/0262-8856(83)90006-9; Kokkinos I.., 2016, P 4 INT C LEARN REPR, P1; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Kokkinos I, 2010, LECT NOTES COMPUT SC, V6312, P650, DOI 10.1007/978-3-642-15552-9_47; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li Y, 2016, PROC CVPR IEEE, P1619, DOI 10.1109/CVPR.2016.179; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17; Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Martin D., 2001, P ICCV, P416, DOI DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Pinheiro Pedro O., 2015, ADV NEURAL INFORM PR, V3, P5; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Pont-Tuset J, 2015, IEEE I CONF COMP VIS, P1546, DOI 10.1109/ICCV.2015.181; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren XF, 2008, LECT NOTES COMPUT SC, V5304, P533; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Roberts Lawrence G, 1963, THESIS, P2; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Uijlings JRR, 2015, PROC CVPR IEEE, P4712, DOI 10.1109/CVPR.2015.7299103; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252; Xie S., 2017, CORR, P1; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yang Jianwei, 2016, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2016.28; Yu F., 2016, P ICLR 2016; Zhao QH, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/487686; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	76	106	111	4	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					819	833		10.1109/TPAMI.2017.2700300	http://dx.doi.org/10.1109/TPAMI.2017.2700300			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28475046	Green Submitted			2022-12-18	WOS:000426687100004
J	Ma, ZY; Teschendorff, AE; Leijon, A; Qiao, YY; Zhang, HG; Guo, J				Ma, Zhanyu; Teschendorff, Andrew E.; Leijon, Arne; Qiao, Yuanyuan; Zhang, Honggang; Guo, Jun			Variational Bayesian Matrix Factorization for Bounded Support Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonnegative matrix factorization; Bayesian estimation; bounded support data; variational inference; extended factorized approximation; relative convexity; collaborative filtering; bioinformatics	MONTE-CARLO EM; DNA METHYLATION; BETA-MIXTURE; MODEL; ALGORITHMS	A novel Bayesian matrix factorization method for bounded support data is presented. Each entry in the observation matrix is assumed to be beta distributed. As the beta distribution has two parameters, two parameter matrices can be obtained, which matrices contain only nonnegative values. In order to provide low-rank matrix factorization, the nonnegative matrix factorization (NMF) technique is applied. Furthermore, each entry in the factorized matrices, i.e., the basis and excitation matrices, is assigned with gamma prior. Therefore, we name this method as beta-gamma NMF (BG-NMF). Due to the integral expression of the gamma function, estimation of the posterior distribution in the BG-NMF model can not be presented by an analytically tractable solution. With the variational inference framework and the relative convexity property of the log-inverse-beta function, we propose a new lower-bound to approximate the objective function. With this new lower-bound, we derive an analytically tractable solution to approximately calculate the posterior distributions. Each of the approximated posterior distributions is also gamma distributed, which retains the conjugacy of the Bayesian estimation. In addition, a sparse BG-NMF can be obtained by including a sparseness constraint to the gamma prior. Evaluations with synthetic data and real life data demonstrate the good performance of the proposed method.	[Ma, Zhanyu; Zhang, Honggang; Guo, Jun] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China; [Teschendorff, Andrew E.] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Computat Syst Genom, Shanghai 200031, Peoples R China; [Teschendorff, Andrew E.] UCL, Stat Genom Grp, London WC1E 6BT, England; [Leijon, Arne] KTH Royal Inst Technol, Sch Elect & Engn, SE-10044 Stockholm, Sweden; [Qiao, Yuanyuan] Beijing Univ Posts & Telecommun, Network Monitor & Control Lab, Beijing 100876, Peoples R China	Beijing University of Posts & Telecommunications; Chinese Academy of Sciences; Shanghai Institutes for Biological Sciences, CAS; Max Planck Society; University of London; University College London; Royal Institute of Technology; Beijing University of Posts & Telecommunications	Ma, ZY (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China.	mazhanyu@bupt.edu.cn; a.teschendorff@ucl.ac.uk; leijon@kth.se; qyybupt@126.com; zhhg@bupt.edu.cn; guojun@bupt.edu.cn	Qiao, Yuanyuan/AAB-9230-2020	Qiao, Yuanyuan/0000-0002-3573-9847	National Nature Science Foundation of China [61402047, 61175011, 61273217]; Chinese 111 program of Advanced Intelligence and Network Service Grant [B08004]; EU FP7 IRSES MobileCloud Project [612212]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Chinese 111 program of Advanced Intelligence and Network Service Grant; EU FP7 IRSES MobileCloud Project	The authors would like to thank Professor Cedric Fevotte for his fruitful discussion and suggestions. This work was partly supported by the National Nature Science Foundation of China Grant No. 61402047, No. 61175011, No. 61273217, Chinese 111 program of Advanced Intelligence and Network Service Grant No. B08004, and EU FP7 IRSES MobileCloud Project Grant No. 612212.	[Anonymous], 2011, THESIS KTH ROYAL I T; [Anonymous], [No title captured]; [Anonymous], 2008, P 25 INT C MACH LEAR; BESAG J, 1986, J R STAT SOC B, V48, P259; Bibikova M, 2006, GENOME RES, V16, P383, DOI 10.1101/gr.4410706; Bishop C.M, 2006, PATTERN RECOGN; Blei D. M., 2006, P ADV NEUR INF PROC; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bouguila N, 2006, STAT COMPUT, V16, P215, DOI 10.1007/s11222-006-8451-7; Boyd S, 2004, CONVEX OPTIMIZATION; Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43; Brookes M., 2005, MATRIX REFERENCE MAN; Cook, 2010, ICML, P439; Curtis C, 2012, NATURE, V486, P346, DOI 10.1038/nature10983; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Egozcue Martin, 2009, J INEQUALITIES PURE, V10, P1; Feinberg AP, 2006, NAT REV GENET, V7, P21, DOI 10.1038/nrg1748; Fevotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO_a_00168; Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771; Guillamet D, 2001, PROC CVPR IEEE, P942; Guillamet D, 2002, LECT NOTES ARTIF INT, V2504, P336; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; Houseman EA, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-365; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Jaakkola TS, 2001, NEU INF PRO, P129; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Ji Y, 2005, BIOINFORMATICS, V21, P2118, DOI 10.1093/bioinformatics/bti318; Jones PA, 2007, CELL, V128, P683, DOI 10.1016/j.cell.2007.01.029; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kirbiz S, 2011, INT CONF ACOUST SPEE, P253; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; Ma ZY, 2014, PATTERN RECOGN, V47, P3143, DOI 10.1016/j.patcog.2014.04.002; Ma ZY, 2013, J BIOINF COMPUT BIOL, V11, DOI 10.1142/S0219720013500054; Ma ZY, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2374; Ma ZY, 2011, IEEE T PATTERN ANAL, V33, P2160, DOI 10.1109/TPAMI.2011.63; Moffa G, 2014, COMPUT STAT DATA AN, V72, P252, DOI 10.1016/j.csda.2013.10.019; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; PALMER JA, 2003, RELATIVE CONVEXITY; Paquet U, 2012, STAT COMPUT, V22, P945, DOI 10.1007/s11222-011-9264-x; Plerou V, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.066126; Quintana FA, 1999, COMPUT STAT DATA AN, V29, P429, DOI 10.1016/S0167-9473(98)00075-9; Raiko T, 2008, LECT NOTES COMPUT SC, V4984, P566; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Schmidt K. D., 2003, COVARIANCE MONOTONE; Schmidt M. N., 2009, LECT NOTES COMPUTER; Schmidt M. N., 2008, COMPUT INTEL NEUROSC, V2008, P8; Su X., 2009, ADV ARTIFICIAL INTEL, DOI DOI 10.1155/2009/421425; Teschendorff AE, 2013, BIOINFORMATICS, V29, P189, DOI 10.1093/bioinformatics/bts680; Teschendorff AE, 2011, BIOINFORMATICS, V27, P1496, DOI 10.1093/bioinformatics/btr171; Widschwendter M, 2007, NAT GENET, V39, P157, DOI 10.1038/ng1941; Wilson KW, 2008, INT CONF ACOUST SPEE, P4029, DOI 10.1109/ICASSP.2008.4518538; Wilson KW, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P411; Zhuang J, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-59	57	106	106	2	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					876	889		10.1109/TPAMI.2014.2353639	http://dx.doi.org/10.1109/TPAMI.2014.2353639			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353300				2022-12-18	WOS:000351213400013
J	Laxhammar, R; Falkman, G				Laxhammar, Rikard; Falkman, Goran			Online Learning and Sequential Anomaly Detection in Trajectories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Anomaly detection; trajectory data; online learning; conformal prediction		Detection of anomalous trajectories is an important problem in the surveillance domain. Various algorithms based on learning of normal trajectory patterns have been proposed for this problem. Yet, these algorithms typically suffer from one or more limitations: They are not designed for sequential analysis of incomplete trajectories or online learning based on an incrementally updated training set. Moreover, they typically involve tuning of many parameters, including ad-hoc anomaly thresholds, and may therefore suffer from overfitting and poorly-calibrated alarm rates. In this article, we propose and investigate the Sequential Hausdorff Nearest-Neighbor Conformal Anomaly Detector (SHNN-CAD) for online learning and sequential anomaly detection in trajectories. This is a parameter-light algorithm that offers a well-founded approach to the calibration of the anomaly threshold. The discords algorithm, originally proposed by Keogh et al., is another parameter-light anomaly detection algorithm that has previously been shown to have good classification performance on a wide range of time-series datasets, including trajectory data. We implement and investigate the performance of SHNN-CAD and the discords algorithm on four different labeled trajectory datasets. The results show that SHNN-CAD achieves competitive classification performance with minimum parameter tuning during unsupervised online learning and sequential anomaly detection in trajectories.	[Laxhammar, Rikard] Saab AB, S-17541 Jarfalla, Sweden; [Falkman, Goran] Univ Skovde, S-54128 Skovde, Sweden	Saab Group; University of Skovde	Laxhammar, R (corresponding author), Saab AB, S-17541 Jarfalla, Sweden.	rikard.laxhammar@saabgroup.com; goran.falkman@his.se	Falkman, Göran/B-8279-2015	Falkman, Göran/0000-0001-8884-2154	Saab AB; Swedish Knowledge Foundation; University of Skovde	Saab AB; Swedish Knowledge Foundation(General Electric); University of Skovde	This work has been supported in part by Saab AB and in part by the Swedish Knowledge Foundation in cooperation with University of Skovde. The authors would like to thank K. Wallenius and E. Sviestins for providing valuable feedback regarding the manuscript of this article and V. Vovk for valuable feedback regarding conformal anomaly detection. Moreover, the authors would like to acknowledge C. Piciarelli and A. Lazarevic for making their datasets publicly available, and S. Khalid for kindly providing the LAB-dataset.	Alt H, 2009, LECT NOTES COMPUT SC, V5760, P235, DOI 10.1007/978-3-642-03456-5_16; [Anonymous], DATA STRUCTURES ALGO; Atev S, 2010, IEEE T INTELL TRANSP, V11, P647, DOI 10.1109/TITS.2010.2048101; Axelsson S., 2000, ACM Transactions on Information and Systems Security, V3, P186, DOI 10.1145/357830.357849; Brax C., 2008, P 11 INT C INF FUS C; Bu Y., 2009, P 15 ACM SIGKDD NEW; Dee HM, 2008, MACH VISION APPL, V19, P329, DOI 10.1007/s00138-007-0077-z; Duda R.O., 2000, PATTERN CLASSIFICATI; Eskin E., 2000, P 17 ICML SAN FRANC; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Gammerman, 2005, ALGORITHMIC LEARNING; Gammerman A, 2007, COMPUT J, V50, P151, DOI [10.1093/comjnl/bxl065, 10.1093/comjnl/bx1065]; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Hawkins DM., 1980, IDENTIFICATION OUTLI, DOI DOI 10.1007/978-94-015-3994-4; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; Keogh E., 2005, P 5 IEEE ICDM WASH D; Keogh E, 2007, DATA MIN KNOWL DISC, V14, P99, DOI 10.1007/s10618-006-0049-3; Khalid S, 2010, PATTERN RECOGN, V43, P173, DOI 10.1016/j.patcog.2009.04.025; Latecki L. J., 2007, P 5 INT C MLDM LEIPZ; Laxhammar R., 2010, P 1 INT WORKSH STREA; Laxhammar R., 2009, P 12 INT C INF FUS W; Laxhammar R., 2011, P 14 INT C INF FUS C; Lee J.-G., 2008, P 24 ICDE WASH DC US; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; Morris B., 2008, P IEEE 5 INT C AVSS; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Owens AJ., 2000, P 3 IEEE INT WORKSH; Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004; Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599; Pokrajac, 2007, P IEEE S CIDM HON HI; Porikli F., 2004, P 6 IEEE INT WORKSH; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; Riveiro M., 2011, THESIS OREBO U SWEDE; Russel S., 2003, ARTIF INTELL, V4th; Scholkopf B., 2000, P NIPS, V12; Shafer G, 2008, J MACH LEARN RES, V9, P371; Sillito R.R., 2008, P BMVC, P1034; Taleb NassimNicholas., 2004, FOOLED RANDOMNESS HI; Vlachos M., 2002, P 18 IEEE INT C DAT; Yankov D, 2007, IEEE DATA MINING, P381, DOI 10.1109/ICDM.2007.61; Z Fu, 2005, P IEEE ICIP; Zhao M., 2009, ADV NEURAL INFORM PR, P2250	42	106	114	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1158	1173		10.1109/TPAMI.2013.172	http://dx.doi.org/10.1109/TPAMI.2013.172			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353278				2022-12-18	WOS:000337124200009
J	Patron-Perez, A; Marszalek, M; Reid, I; Zisserman, A				Patron-Perez, Alonso; Marszalek, Marcin; Reid, Ian; Zisserman, Andrew			Structured Learning of Human Interactions in TV Shows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human interaction recognition; video retrieval; structured SVM		The objective of this work is recognition and spatiotemporal localization of two-person interactions in video. Our approach is person-centric. As a first stage we track all upper bodies and heads in a video using a tracking-by-detection approach that combines detections with KLT tracking and clique partitioning, together with occlusion detection, to yield robust person tracks. We develop local descriptors of activity based on the head orientation (estimated using a set of pose-specific classifiers) and the local spatiotemporal region around them, together with global descriptors that encode the relative positions of people as a function of interaction type. Learning and inference on the model uses a structured output SVM which combines the local and global descriptors in a principled manner. Inference using the model yields information about which pairs of people are interacting, their interaction class, and their head orientation (which is also treated as a variable, enabling mistakes in the classifier to be corrected using global context). We show that inference can be carried out with polynomial complexity in the number of people, and describe an efficient algorithm for this. The method is evaluated on a new dataset comprising 300 video clips acquired from 23 different TV shows and on the benchmark UT-Interaction dataset.	[Patron-Perez, Alonso] George Washington Univ, Dept Comp Sci, 801 22nd St NW, Washington, DC 20052 USA; [Marszalek, Marcin] Google Inc, CH-8134 Adliswil, Switzerland; [Reid, Ian; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	George Washington University; Google Incorporated; University of Oxford	Patron-Perez, A (corresponding author), George Washington Univ, Dept Comp Sci, 801 22nd St NW, Washington, DC 20052 USA.	apatron@gwu.edu; marcin@robots.ox.ac.uk; ian@robots.ox.ac.uk; az@robots.ox.ac.uk		Reid, Ian/0000-0001-7790-6423	ERC [228180]; CONACYT; EPSRC [EP/H050795/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/H050795/1] Funding Source: researchfish	ERC(European Research Council (ERC)European Commission); CONACYT(Consejo Nacional de Ciencia y Tecnologia (CONACyT)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the ERC grant VisRec no. 228180 and CONACYT.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Benfold B., 2008, P BRIT MACH VIS C; Benfold B., 2009, P BRIT MACH VIS C; Benfold B, 2011, PROC CVPR IEEE; Blaschko M., 2008, P 10 EUR C COMP VIS; Blaschko M. B., 2009, P BRIT MACH VIS C; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, HISTOGRAMS ORIENTED; Desai C., 2009, P 12 IEEE INT C COMP; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018; Felzenszwalb PF, 2010, DISCRIMINATIVELY TRA; Ferrari V., 2009, P IEEE C COMP VIS PA; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Gilbert A., 2009, P 12 IEEE INT C COMP; Joachims T., 2008, MULTICLASS SUPPORT V; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Klaser A., 2010, P INT WORKSH SIGN GE; Lan T., 2010, P NEUR INF PROC SYST; Laptev I., 2007, P 11 IEEE INT C COMP; Liu J., 2009, P IEEE C COMP VIS PA; Lovegrove S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.93; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Marszalek M., 2009, P IEEE C COMP VIS PA; Niebles J.C., 2010, P 11 EUR C COMP VIS; Oliver N., 1998, P INT C NEUR INF PRO; Park S, 2006, COMPUT VIS IMAGE UND, V102, P1, DOI 10.1016/j.cviu.2005.07.011; Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1; Patron-Perez A., 2010, TV HUMAN INTERACTION; Rodriguez M.D., 2008, P 2008 IEEE C COMP V; Ryoo M.S., 2009, P 12 IEEE INT C COMP; Ryoo M.S., 2006, P IEEE C COMP VIS PA; Ryoo M.S., 2010, P INT C PATT REC CON; Taskar B., 2003, P NEUR INF PROC SYST; Tomasi C, 1991, CMUCS91132; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Waltisberg D., 2010, P INT C PATT REC CON; Wang Y., 2010, P 11 EUR C COMP VIS; Wu X., 2009, P ACM INT C MULT; Yuan F., 2010, P EUR C COMP VIS WOR	41	106	110	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2441	2453		10.1109/TPAMI.2012.24	http://dx.doi.org/10.1109/TPAMI.2012.24			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	23079467				2022-12-18	WOS:000309913700012
J	Han, B; Davis, LS				Han, Bohyung; Davis, Larry S.			Density-Based Multifeature Background Subtraction with Support Vector Machine	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Background modeling and subtraction; Haar-like features; support vector machine; kernel density approximation		Background modeling and subtraction is a natural technique for object detection in videos captured by a static camera, and also a critical preprocessing step in various high-level computer vision applications. However, there have not been many studies concerning useful features and binary segmentation algorithms for this problem. We propose a pixelwise background modeling and subtraction technique using multiple features, where generative and discriminative techniques are combined for classification. In our algorithm, color, gradient, and Haar-like features are integrated to handle spatio-temporal variations for each pixel. A pixelwise generative background model is obtained for each feature efficiently and effectively by Kernel Density Approximation (KDA). Background subtraction is performed in a discriminative manner using a Support Vector Machine (SVM) over background likelihood vectors for a set of features. The proposed algorithm is robust to shadow, illumination changes, spatial variations of background. We compare the performance of the algorithm with other density-based methods using several different feature combinations and modeling techniques, both quantitatively and qualitatively.	[Han, Bohyung] POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea; [Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Pohang University of Science & Technology (POSTECH); University System of Maryland; University of Maryland College Park	Han, B (corresponding author), POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea.	bhhan@postech.ac.kr; lsd@cs.umd.edu			National Research Foundation of Korea (NRF); Ministry of Education, Science, and Technology [2011-0005749]	National Research Foundation of Korea (NRF)(National Research Foundation of Korea); Ministry of Education, Science, and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea)	This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science, and Technology (2011-0005749).	[Anonymous], 2012, CAVIAR CONTEXT AWARE; Elgammal A., 2000, COMPUTER VISION ECCV, P751, DOI [10.1007/3-540-45053-X_48, DOI 10.1007/3-540-45053-X_48]; Friedman N., 1997, CVPR, P130; Han B., 2004, P AS C COMP VIS; Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771; Han BY, 2010, INTELLIGENT VIDEO SURVEILLANCE: SYSTEMS AND TECHNOLOGY, P79; Hao ZF, 2007, LECT NOTES COMPUT SC, V4669, P603; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Heikkila M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68; Javed O, 2002, LECT NOTES COMPUT SC, V2353, P343; Jepson AD, 2001, PROC CVPR IEEE, P415; Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin HH, 2009, IEEE T SIGNAL PROCES, V57, P1641, DOI 10.1109/TSP.2009.2014810; McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8; Mittal A., 2000, P IEEE C COMP VIS PA; Mittal A., 2004, P IEEE C COMP VIS PA; Monnet A., 2003, P 9 IEEE INT C COMP; Parag T., 2006, P IEEE INT C COMP VI, P1916; Paragios N, 2001, PROC CVPR IEEE, P1034; PRIEBE CE, 1993, PATTERN RECOGN, V26, P771, DOI 10.1016/0031-3203(93)90130-O; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Seki M., 2003, P IEEE C COMP VIS PA; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Zhang JM, 2007, 2007 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY: ENHANCING CRITICAL INFRASTRUCTURE DEPENDABILITY, P64, DOI 10.1109/WI-IATW.2007.84; Zhong J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P44, DOI 10.1109/ICCV.2003.1238312; Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005	32	106	118	1	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					1017	1023		10.1109/TPAMI.2011.243	http://dx.doi.org/10.1109/TPAMI.2011.243			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22156099				2022-12-18	WOS:000301747400014
J	Benedek, C; Descombes, X; Zerubia, J				Benedek, Csaba; Descombes, Xavier; Zerubia, Josiane			Building Development Monitoring in Multitemporal Remotely Sensed Image Pairs with Stochastic Birth-Death Dynamics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Building extraction; change detection; marked point processes; multiple birth and death dynamics	MARKED POINT PROCESS; PERFORMANCE EVALUATION; AERIAL; EXTRACTION; FRAMEWORK	In this paper, we introduce a new probabilistic method which integrates building extraction with change detection in remotely sensed image pairs. A global optimization process attempts to find the optimal configuration of buildings, considering the observed data, prior knowledge, and interactions between the neighboring building parts. We present methodological contributions in three key issues: 1) We implement a novel object-change modeling approach based on Multitemporal Marked Point Processes, which simultaneously exploits low-level change information between the time layers and object-level building description to recognize and separate changed and unaltered buildings. 2) To answer the challenges of data heterogeneity in aerial and satellite image repositories, we construct a flexible hierarchical framework which can create various building appearance models from different elementary feature-based modules. 3) To simultaneously ensure the convergence, optimality, and computation complexity constraints raised by the increased data quantity, we adopt the quick Multiple Birth and Death optimization technique for change detection purposes, and propose a novel nonuniform stochastic object birth process which generates relevant objects with higher probability based on low-level image features.	[Benedek, Csaba] Hungarian Acad Sci MTA SZTAKI, Comp & Automat Res Inst, Distributed Events Anal Res Grp, H-1111 Budapest, Hungary; [Descombes, Xavier; Zerubia, Josiane] Univ Nice, INRIA Sophia Antipolis, INRIA, CNRS,Ariana Res Grp, F-06902 Sophia Antipolis, France	Eotvos Lorand Research Network; Hungarian Academy of Sciences; Hungarian Institute for Computer Science & Control; Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; Universite Cote d'Azur	Benedek, C (corresponding author), Hungarian Acad Sci MTA SZTAKI, Comp & Automat Res Inst, Distributed Events Anal Res Grp, Kende Utca 13-17, H-1111 Budapest, Hungary.	bcsaba@sztaki.hu; xavier.descombes@inria.fr; Josiane.Zerubia@inria.fr	Benedek, Csaba/D-3700-2013; Benedek, Csaba/ABB-9304-2021	Zerubia, Josiane/0000-0002-7444-0856	INRIA, Ariana Project Team, INRIA Sophia Antipolis-Mediterrannee, France; Hungarian Academy of Sciences	INRIA, Ariana Project Team, INRIA Sophia Antipolis-Mediterrannee, France; Hungarian Academy of Sciences(Hungarian Academy of Sciences)	The authors acknowledge the test data provided by Andras Gorog (BUDAPEST images), the French Defense Agency (ABIDJAN), and Veronique Prinet from LIAMA Laboratory of CAS Beijing (BEIJING). They are grateful to the authors of the reference methods and their colleagues for their help in the evaluation, especially to Dr. Beril Sirmacek and Cosmin Mihai. They thank their colleagues at MTA SZTAKI for linguistic corrections and checking the notations of the manuscript. Csaba Benedek's present work was partially funded by the INRIA postdoctoral fellowship, in the Ariana Project Team, INRIA Sophia Antipolis-Mediterrannee, France, and by the Janos Bolyai Research Scholarship of the Hungarian Academy of Sciences.	Benedek C., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1417, DOI 10.1109/ICPR.2010.350; Benedek C., 2009, P IEEE WORKSH APPL C, P100; BENEDEK C, 2009, 7143 INRIA; Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633; Bignone F., 1996, P EUR C COMP VIS ECC, P83; Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678; Champion N., 2007, INT ARCH PHOTOGRAMME, VXXXVI, P197; Dare PM, 2005, PHOTOGRAMM ENG REM S, V71, P169, DOI 10.14358/PERS.71.2.169; Descombes X, 2002, IEEE SIGNAL PROC MAG, V19, P77, DOI 10.1109/MSP.2002.1028354; Descombes X, 2009, J MATH IMAGING VIS, V33, P347, DOI 10.1007/s10851-008-0117-y; Fournier A., 2008, P INT C PATT REC; Hatsuda H., 2010, P INT C BIOINF COMP, P605; Jaw J. J., 2008, P ISPRS C, VXXXVII, P707; Karantzalos K, 2010, IEEE T GEOSCI REMOTE, V48, P2283, DOI 10.1109/TGRS.2009.2039220; Karantzalos K, 2009, IEEE T GEOSCI REMOTE, V47, P133, DOI 10.1109/TGRS.2008.2002027; Katartzis A, 2008, IEEE T GEOSCI REMOTE, V46, P259, DOI 10.1109/TGRS.2007.904953; Khoshelham K, 2005, PHOTOGRAMM ENG REM S, V71, P855, DOI 10.14358/PERS.71.7.855; Kumar S, 2003, PROC CVPR IEEE, P119; Lacoste C, 2005, IEEE T PATTERN ANAL, V27, P1568, DOI 10.1109/TPAMI.2005.206; Lafarge F, 2010, IEEE T PATTERN ANAL, V32, P135, DOI 10.1109/TPAMI.2008.281; Lafarge F, 2010, IEEE T PATTERN ANAL, V32, P1597, DOI 10.1109/TPAMI.2009.152; Muller S., 2005, INT ARCH PHOTOGRAMME, VXXXVI, P143; Noronha S, 2001, IEEE T PATTERN ANAL, V23, P501, DOI 10.1109/34.922708; Ortner M, 2008, IEEE T PATTERN ANAL, V30, P105, DOI 10.1109/TPAMI.2007.1159; Peng J, 2005, PATTERN RECOGN LETT, V26, P587, DOI 10.1016/j.patrec.2004.09.033; Porway J, 2010, INT J COMPUT VISION, V88, P254, DOI 10.1007/s11263-009-0306-1; Rottensteiner F, 2008, INT ARCH PHOTOGRAMME, VXXXVII, P265; Rottensteiner F, 2007, ISPRS J PHOTOGRAMM, V62, P135, DOI 10.1016/j.isprsjprs.2007.03.001; Saeedi P, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P623, DOI 10.1109/ICARCV.2008.4795590; Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P311, DOI 10.1109/34.761262; Sirmacek B., 2008, P INT S COMP INF SCI; Sirmacek B, 2011, IEEE T GEOSCI REMOTE, V49, P211, DOI 10.1109/TGRS.2010.2053713; Sirmacek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440; Song Z., 2008, P ISPRS C, P271; Song ZY, 2006, IEEE IMAGE PROC, P3225, DOI 10.1109/ICIP.2006.312910; Tanathong S, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P65, DOI 10.1109/ECTICON.2008.4600373; Tsai VJD, 2006, IEEE T GEOSCI REMOTE, V44, P1661, DOI 10.1109/TGRS.2006.869980; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Utasi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3385, DOI 10.1109/CVPR.2011.5995699	39	106	110	1	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					33	50		10.1109/TPAMI.2011.94	http://dx.doi.org/10.1109/TPAMI.2011.94			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576749	Green Submitted			2022-12-18	WOS:000297069900003
J	Prabhu, U; Heo, JG; Savvides, M				Prabhu, Utsav; Heo, Jingu; Savvides, Marios			Unconstrained Pose-Invariant Face Recognition Using 3D Generic Elastic Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose-invariant face recognition; generic elastic models; 3D face modeling	SHAPE	Classical face recognition techniques have been successful at operating under well-controlled conditions; however, they have difficulty in robustly performing recognition in uncontrolled real-world scenarios where variations in pose, illumination, and expression are encountered. In this paper, we propose a new method for real-world unconstrained pose-invariant face recognition. We first construct a 3D model for each subject in our database using only a single 2D image by applying the 3D Generic Elastic Model (3D GEM) approach. These 3D models comprise an intermediate gallery database from which novel 2D pose views are synthesized for matching. Before matching, an initial estimate of the pose of the test query is obtained using a linear regression approach based on automatic facial landmark annotation. Each 3D model is subsequently rendered at different poses within a limited search space about the estimated pose, and the resulting images are matched against the test query. Finally, we compute the distances between the synthesized images and test query by using a simple normalized correlation matcher to show the effectiveness of our pose synthesis method to real-world data. We present convincing results on challenging data sets and video sequences demonstrating high recognition accuracy under controlled as well as unseen, uncontrolled real-world scenarios using a fast implementation.	[Prabhu, Utsav; Heo, Jingu; Savvides, Marios] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Prabhu, U (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.	uprabhu@andrew.cmu.edu; jheo@andrew.cmu.edu; marioss@andrew.cmu.edu			Office of the Director of National Intelligence (ODNI); Army Research Laboratory (ARL)	Office of the Director of National Intelligence (ODNI); Army Research Laboratory (ARL)(United States Department of DefenseUS Army Research Laboratory (ARL))	This research was funded by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL). All statements of fact, opinion, or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of IARPA, the ODNI, or the US Government. The authors would like to thank the various members of the CMU Biometrics Center for help with different modules such as automatic facial landmarking and pose estimation.	Alex M, 2002, LECT NOTES COMPUT SC, V2350, P447; [Anonymous], 2008, P 2008 IEEE C COMP V; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; CHAI X, 2003, P IEEE 4 PAC RIM C M, V2, P1413; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Heo J., 2009, THESIS CARNEGIE MELL; Horn B. K. P, 1970, SHAPE SHADING METHOD; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366; Park SW, 2007, IEEE T SYST MAN CY B, V37, P1156, DOI 10.1109/TSMCB.2007.904575; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Phillips PJ, 2005, PROC CVPR IEEE, P947; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Seshadri K, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P319; Shakhnarovich G., 2004, HDB FACE RECOGNITION, P141; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wen Yi Zhao, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P285, DOI 10.1109/AFGR.2000.840648; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Xie CY, 2005, LECT NOTES COMPUT SC, V3723, P32; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120	26	106	112	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1952	1961		10.1109/TPAMI.2011.123	http://dx.doi.org/10.1109/TPAMI.2011.123			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21670487				2022-12-18	WOS:000293969000004
J	Lanz, O				Lanz, Oswald			Approximate Bayesian multibody tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; tracking; occlusion; approximate inference; Bayes filter; particle filter		Visual tracking of multiple targets is a challenging problem, especially when efficiency is an issue. Occlusions, if not properly handled, are a major source of failure. Solutions supporting principled occlusion reasoning have been proposed but are yet unpractical for online applications. This paper presents a new solution which effectively manages the trade-off between reliable modeling and computational efficiency. The Hybrid Joint-Separable (HJS) filter is derived from a joint Bayesian formulation of the problem, and shown to be efficient while optimal in terms of compact belief representation. Computational efficiency is achieved by employing a Markov random field approximation to joint dynamics and an incremental algorithm for posterior update with an appearance likelihood that implements a physically-based model of the occlusion process. A particle filter implementation is proposed which achieves accurate tracking during partial occlusions, while in cases of complete occlusion, tracking hypotheses are bound to estimated occlusion volumes. Experiments show that the proposed algorithm is efficient, robust, and able to resolve long-term occlusions between targets with identical appearance.	Ist Trentino Cultura, ITCirst, SSI Div, TeV Grp, I-38050 Povo, Italy		Lanz, O (corresponding author), Ist Trentino Cultura, ITCirst, SSI Div, TeV Grp, Via Sommarive 18, I-38050 Povo, Italy.	lanz@itc.it	Lanz, Oswald/AAW-7865-2021	Lanz, Oswald/0000-0003-4793-4276				ARULAMPALAM S, 2002, IEEE T SIGNAL PROCES, V50; CHOO K, 2001, P INT C COMP VIS; COMANICIU D, 2003, IEEE T PATTERN ANAL, V25; Coughlan J. M., 2002, P EUR C COMP VIS; Cover MT, 1991, ELEMENTS INFORM THEO; DEUTSCHER J, 2000, P INT C COMP VIS PAT; DIAO Q, 2003, P BAY MOD APPL WORKS; Doucet A., 2001, SEQUENTIAL MONTE CAR; Isard M., 1998, INT J COMPUTER VISIO, V29; ISARD M, 2003, P INT C COMP VIS PAT; ISARD M, 2003, P INT C COMP VIS; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jordan M. I., 1999, MACHINE LEARNING; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; LANZ O, 2005, P INT C COMP VIS PAT; Li S., 1995, MARKOV RANDOM FIELD, P1; MACCORMICK J, 2000, INT J COMP VIS, V39; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; Opper M, 2001, ADV MEAN FIELD METHO; OTSUKA K, 2004, P INT C COMP VIS PAT; SANTUARI A, 2003, P INT C VIS IM IM PR; SIDENBLADH H, 2003, INT J COMPUTER VISIO, V54; SIGAL L, 2004, P INT C COMP VIS PAT; SMINCHISESCU C, 2006, J IMAGE VISION COMPU, V24; SMINCHISESCU C, 2001, 4208 INRIA; SUDDERTH E, 2003, P INT C COMP VIS PAT; SUDDERTH E, 2005, ADV NEURAL INFORM PR; SULLIVAN J, 2001, INT J COMPUTER VISIO, V44; SULLIVAN J, 2001, P INT C COMP VIS; SUN J, 2002, P EUR C COMP VIS; TAO H, 1999, P VIS ALG WORKSH; TWEED D, 2002, P BRIT MACH VIS C; VERMAAK J, 2001, P INT C COMP VIS; VO B, 2005, IEEE T AEROSPACE ELE, V41; Yedidia J. S., 2003, EXPLORING ARTIFICIAL; YU T, 2005, P INT C COMP VIS PAT	36	106	110	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1436	1449		10.1109/TPAMI.2006.177	http://dx.doi.org/10.1109/TPAMI.2006.177			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929730				2022-12-18	WOS:000238950800007
J	Martinez, AM; Zhu, ML				Martinez, AM; Zhu, ML			Where are linear feature extraction methods applicable?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction; generalized eigenvalue decomposition; performance evaluation; classifiers; pattern recognition	DISCRIMINANT-ANALYSIS; FACE RECOGNITION; MODEL; LDA	A fundamental problem in computer vision and pattern recognition is to determine where and, most importantly, why a given technique is applicable. This is not only necessary because it helps us decide which techniques to apply at each given time. Knowing why current algorithms cannot be applied facilitates the design of new algorithms robust to such problems. In this paper, we report on a theoretical study that demonstrates where and why generalized eigen-based linear equations do not work. In particular, we show that when the smallest angle between the ith eigenvector given by the metric to be maximized and the first i eigenvectors given by the metric to be minimized is close to zero, our results are not guaranteed to be correct. Several properties of such models are also presented. For illustration, we concentrate on the classical applications of classification and feature extraction. We also show how we can use our findings to design more robust algorithms. We conclude with a discussion on the broader impacts of our results.	Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Martinez, AM (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, 205 Dresse Lab,2015 Neil Ave, Columbus, OH 43210 USA.	aleix@ece.osu.edu; zhum@ece.osu.edu	Martinez, Aleix M/A-2380-2008		NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC005241] Funding Source: NIH RePORTER; NIDCD NIH HHS [R01 DC 005241] Funding Source: Medline	NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD)); NIDCD NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))		BARTLETT MS, 2001, KLUWER INT SERIES EN, V612; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge JR, 2001, PROC CVPR IEEE, P535; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Cook R., 1998, WILEY PROB STAT; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671, DOI 10.1109/TPAMI.1983.4767461; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GUPTA H, 1996, EXPT EVALUATION LINE; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; LEIBE B, 2003, P IEEE COMP VIS PATT; LI J, 1991, J AM STAT SOC, V86, P316; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Mardia KV, 1979, MULTIVARIATE ANAL; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MULLER KE, 1982, AM STAT, V36, P342, DOI 10.2307/2683082; Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322; Rao CR, 2002, LINEAR STAT INFERENC; ROBLEDO I, 2003, IEEE T PATTERN ANAL, V25, P1323; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Thacker WC, 1996, TELLUS A, V48, P584, DOI 10.1034/j.1600-0870.1996.t01-3-00007.x; Vapnik V., 2000, NATURE STAT LEARNING; VASWANI N, 2004, P INT C PATT REC; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; ZHU M, 2004, P IEEE WORKSH LEARN	36	106	111	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1934	1944		10.1109/TPAMI.2005.250	http://dx.doi.org/10.1109/TPAMI.2005.250			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16358412				2022-12-18	WOS:000232532600008
J	Krishnapuram, B; Hartemink, AJ; Carin, L; Figueiredo, MAT				Krishnapuram, B; Hartemink, AJ; Carin, L; Figueiredo, MAT			A Bayesian approach to joint feature selection and classifier design	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; statistical learning; feature selection; sparsity; support vector machines; relevance vector machines; sparse probit regression; automatic relevance determination; EM algorithm		This paper adopts a Bayesian approach to simultaneously learn both an optimal nonlinear classifier and a subset of predictor variables (or features) that are most relevant to the classification task. The approach uses heavy-tailed priors to promote sparsity in the utilization of both basis functions and features; these priors act as regularizers for the likelihood function that rewards good classification on the training data. We derive an expectation-maximization (EM) algorithm to efficiently compute a maximum a posteriori (MAP) point estimate of the various parameters. The algorithm is an extension of recent state-of-the-art sparse Bayesian classifiers, which in turn can be seen as Bayesian counterparts of support vector machines. Experimental comparisons using kernel classifiers demonstrate both parsimonious feature selection and excellent classification accuracy on a range of synthetic and benchmark data sets.	Duke Univ, Dept Elect Engn, Durham, NC 27708 USA; Duke Univ, Dept Comp Sci, Durham, NC 27708 USA; Inst Super Tecn, Inst Telecomunicacoes, P-1049001 Lisbon, Portugal	Duke University; Duke University; Instituto de Telecomunicacoes; Universidade de Coimbra; Universidade de Lisboa; Instituto Superior Tecnico	Krishnapuram, B (corresponding author), Duke Univ, Dept Elect Engn, Durham, NC 27708 USA.	balaji@ee.duke.edu; amink@cs.duke.edu; lcarin@ee/duke.edu; mtf@lx.it.pt	Figueiredo, Mario/C-5428-2008	Figueiredo, Mario/0000-0002-0970-7745; Carin, Lawrence/0000-0001-6277-7948				ALBERT JH, 1993, J AM STAT ASSOC, V88, P669, DOI 10.2307/2290350; [Anonymous], 2002, LEARNING KERNELS; BENDOR A, 2000, P 4 ANN INT C COMP M; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HERBERICH R, 2002, LEARNING KERNEL CLAS; Husmeier D, 1999, IEE CONF PUBL, P533, DOI 10.1049/cp:19991164; Husmeier D, 1999, NEURAL NETWORKS, V12, P677, DOI 10.1016/S0893-6080(99)00020-9; KRISHNAPURAM B, 2003, P 7 ANN INT C COMP M; Krishnapuram B., 2002, P 2002 WORKSH GEN SI; Lee Y. J., 2001, P SIAM INT C DAT MIN; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; Neal RM., 1996, BAYESIAN LEARNING NE, P29; SEEGER M, 2000, P ADV NEUR INF PROC, V12; Sun XB, 2003, SIAM J MATRIX ANAL A, V24, P768, DOI 10.1137/S0895479800380374; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; WESTON J, 2000, P ADV NEUR INF PROC, V12; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807	20	106	111	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1105	1111		10.1109/TPAMI.2004.55	http://dx.doi.org/10.1109/TPAMI.2004.55			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742887				2022-12-18	WOS:000222605100001
J	Greminger, MA; Nelson, BJ				Greminger, MA; Nelson, BJ			Vision-based force measurement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						force measurement; deformable templates; elasticity; nonrigid tracking	OBJECTS	This paper demonstrates a method to visually measure the force distribution applied to a linearly elastic object using the contour data in an image. The force measurement is accomplished by making use of the result from linear elasticity that the displacement field of the contour of a linearly elastic object is sufficient to completely recover the force distribution applied to the object. This result leads naturally to a deformable template matching approach where the template is deformed according to the governing equations of linear elasticity. An energy minimization method is used to match the template to the contour data in the image. This technique of visually measuring forces we refer to as vision-based force measurement (VBFM). VBFM has the potential to increase the robustness and reliability of micromanipulation and biomanipulation tasks where force sensing is essential for success. The effectiveness of VBFM is demonstrated for both a microcantilever beam and a microgripper. A sensor resolution of less than +/- 3 nN for the microcantilever and +/- 3 mN for the microgripper was achieved using VBFM. Performance optimizations for the energy minimization problem are also discussed that make this algorithm feasible for real-time applications.	Univ Minnesota, Dept Mech Engn, Minneapolis, MN 55455 USA; ETH, Inst Robot & Intelligent Syst, CH-8092 Zurich, Switzerland	University of Minnesota System; University of Minnesota Twin Cities; Swiss Federal Institutes of Technology Domain; ETH Zurich	Greminger, MA (corresponding author), Univ Minnesota, Dept Mech Engn, 111 Church St SE, Minneapolis, MN 55455 USA.	grem@me.umn.edu; brad.nelson@iris.mavt.ethz.ch	Nelson, Bradley/B-7761-2013	Nelson, Bradley/0000-0001-9070-6987				CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Danuser G, 1996, P SOC PHOTO-OPT INS, V2782, P180, DOI 10.1117/12.250744; DONG L, 2001, P 2001 IEEE INT C RO; Guenther RB., 1988, PARTIAL DIFFERENTIAL; Kaneko M, 2001, IEEE-ASME T MECH, V6, P7, DOI 10.1109/3516.914386; KASS M, 1988, INT J COMPUT VISION, P321, DOI DOI 10.1007/BF00133570; Metaxas D., 1997, PHYS BASED DEFORMABL; NAKAMURA G, 1993, AM J MATH, V115, P1161, DOI 10.2307/2375069; NELSON B, 1998, IEEE CONTROL SYS DEC; Payne LE., 1971, UNIQUENESS THEOREMS, DOI [10.1007/978-3-642-65101-4, DOI 10.1007/978-3-642-65101-4]; Samet H., 1990, DESIGN ANAL SPATIAL, V85; SOKOLNIKOFF IS, 1983, MATH THEORY ELASTICI; SYLVESTER J, 1990, SIAM PROC S, P101; Tortonese M., 1991, IEEE PUBLICATION, P448; Tsap LV, 1998, COMPUT VIS IMAGE UND, V69, P330, DOI 10.1006/cviu.1998.0663; Vanderplaats GN., 1984, NUMERICAL OPTIMIZATI, V3; Wang XY, 2001, SENSOR ACTUAT A-PHYS, V94, P142, DOI 10.1016/S0924-4247(01)00705-1; YANG G, 2001, P 2001 IEEE INT C RO; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169	19	106	114	5	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					290	298		10.1109/TPAMI.2004.1262305	http://dx.doi.org/10.1109/TPAMI.2004.1262305			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376877				2022-12-18	WOS:000188949400001
J	Desolneux, A; Moisan, L; Morel, JM				Desolneux, A; Moisan, L; Morel, JM			A grouping principle and four applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gestalt grouping laws; a contrario probabilistic model; binomial law; number of false alarms; histogram modes; clusters; alignments	PROBABILISTIC HOUGH TRANSFORM	Wertheimer's theory suggests a general perception law according to which objects having a quality in common get perceptually grouped. The Helmholtz principle is a quantitative version of this general grouping law. It states that a grouping is perceptually "meaningful" if its number of occurrences would be very small in a random situation: Geometric structures are then characterized as large deviations from randomness. In two previous works, we have applied this principle to the detection of orientation alignments and boundaries in a digital image. In this paper, we show that the method is fully general and can be extended to a grouping by any quality. We treat as an illustration the alignments of objects, their grouping by color and by size, and the vicinity gestalt (clusters). Collaboration of the gestalt grouping laws and their pyramidal structure are illustrated in a case study.	UFR Mathinfo, F-75270 Paris 06, France; ENS, CMLA, UMR 8536, F-94235 Cachan, France	Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI); UDICE-French Research Universities; Universite Paris Saclay	Desolneux, A (corresponding author), UFR Mathinfo, 45 Rue St Peres, F-75270 Paris 06, France.	desolneux@math-info.univ-paris5.fr; moisan@cmla.ens-cachan.fr; morel@cmla.ens-cachan.fr	Moisan, Lionel/A-7400-2010	Moisan, Lionel/0000-0001-6019-2698; Morel, Jean-Michel/0000-0002-6108-897X				ALMANSA A, 2003, VANISHING POINT DETE, V25, P502; [Anonymous], 1985, PERCEPTUAL ORG VISUA; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; DESOLNEUX A, UNPUB ANN STAT; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; GEMAN D, 2001, IEEE T INFORMATION T, V47; GOUSSEAU Y, 2000, THESIS U PARIS DAUPH; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; Kanizsa G., 1980, GRAMMATICA VEDERE; KASS M, 1987, P 1 INT COMP VIS C; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; SHAASHUA A, 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Shaked D, 1996, COMPUT VIS IMAGE UND, V63, P512, DOI 10.1006/cviu.1996.0038; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; ZUCKER SW, 1988, PERCEPTION, V17, P229, DOI 10.1068/p170229	17	106	107	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					508	513		10.1109/TPAMI.2003.1190576	http://dx.doi.org/10.1109/TPAMI.2003.1190576			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100011
J	Liu, CL; Koga, M; Fujisawa, H				Liu, CL; Koga, M; Fujisawa, H			Lexicon-driven segmentation and recognition of handwritten character strings for Japanese address reading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mail address reading; handwritten character string recognition; touching character splitting; character classification; lexicon matching; beam search	WORD RECOGNITION; COMBINATION; STRATEGIES	This paper describes a handwritten character string recognition system for Japanese mail address reading on very large vocabulary. The address phrases are recognized as a whole because there is no extra space between words. The lexicon contains 111,349 address phrases, which are stored in a trie structure. In recognition, the text line image is matched with the lexicon entries (phrases) to obtain reliable segmentation and retrieve valid address phrases. In this paper, we first introduce some effective techniques for text line image preprocessing and presegmentation. In presegmentation, the text line image is separated into primitive segments by connected component analysis and touching pattern splitting based on contour shape analysis. In lexicon matching, consecutive segments are dynamically combined into candidate character patterns. An accurate character classifier is embedded in lexicon matching to select characters matched with a candidate pattern from a dynamic category set. A beam search strategy is used to control the lexicon matching so as to achieve real-time recognition. In experiments on 3,589 live mail images, the proposed method achieved correct rate of 83.68 percent while the error rate is less than 1 percent.	Hitachi Ltd, Cent Res Lab, Kokubunji, Tokyo 1858601, Japan	Hitachi Limited	Liu, CL (corresponding author), Hitachi Ltd, Cent Res Lab, 1-280 Higashi Koigakubo, Kokubunji, Tokyo 1858601, Japan.	liucl@crl.hitachi.co.jp; koga@crl.hitachi.co.jp; fujisawa@crl.hitachi.co.jp	Fujisawa, Hiromichi/AAF-2788-2020	Fujisawa, Hiromichi/0000-0001-7626-4836				Bellman RE, 1957, DYNAMIC PROGRAMMING; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; CHANG CH, 1997, P INT C COMP PROC OR, P273; CHEN CH, 1995, P 3 INT C DOC AN REC, P919; Chen D. Y., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P543, DOI 10.1109/ICDAR.1999.791845; Dengel A., 1997, HDB CHARACTER RECOGN, P227; Favata JT, 2001, IEEE T PATTERN ANAL, V23, P1009, DOI 10.1109/34.955113; Filatov A, 1999, LECT NOTES COMPUT SC, V1655, P157; FREDKIN E, 1960, COMMUN ACM, V3, P490, DOI 10.1145/367390.367400; FUJISAWA H, 1992, P IEEE, V80, P1079, DOI 10.1109/5.156471; GAO J, 1999, P 5 INT C DOC AN REC, P633; Hamanaka M., 1993, P 3 INT WORKSH FRONT, P343; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Ikeda H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P641, DOI 10.1109/ICDAR.1999.791869; Ishidera E, 1997, PROC INT CONF DOC, P1016, DOI 10.1109/ICDAR.1997.620663; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; KATAGIRI S, 1991, P IEEE WORKSH NEUR N, P299; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Kim SH, 2001, PATTERN RECOGN, V34, P1437, DOI 10.1016/S0031-3203(00)00098-4; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; KOBAYASHI Y, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P487, DOI 10.1109/ICPR.1992.201824; Koga M, 1999, LECT NOTES COMPUT SC, V1655, P115; Koga M, 1998, INT C PATT RECOG, P1137, DOI 10.1109/ICPR.1998.711896; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LEE CH, 1989, IEEE T ACOUST SPEECH, V37, P1649, DOI 10.1109/29.46547; Lifchitz A., 2000, P 7 INT WORKSH FRONT, P313; Liu C.-L., 1997, PROGR HANDWRITING RE, P161; Liu CL, 2000, IEEE T PATTERN ANAL, V22, P636, DOI 10.1109/34.862202; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Lu Y, 1996, PATTERN RECOGN, V29, P77, DOI 10.1016/0031-3203(95)00072-0; MAEDA Y, 1986, P INT C PATT REC, P769; MARUKAWA K, 1991, P 1 ICDAR SAINT MAL, P916; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Murase H., 1986, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ69D, P1292; MURASE H, 1988, P 9 ICPR, P1143; NEY H, 1992, IEEE T PATTERN ANAL, V14, P586, DOI 10.1109/34.134063; Nillson N. J, 1980, PRINCIPLES ARTIFICIA; Ratzlaff E. H., 1996, P 5 INT WORKSH FRONT, P177; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; SENI G, 1999, ADV HANDWRITING RECO, P49; Srihari S. N., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P5, DOI 10.1109/ICDAR.1995.598932; SRIHARI SN, 1992, P IEEE, V80, P1120, DOI 10.1109/5.156474; Strathy N. W., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P577, DOI 10.1109/ICDAR.1993.395669; Tseng LY, 1998, PATTERN RECOGN LETT, V19, P963, DOI 10.1016/S0167-8655(98)00073-7; Tseng YH, 1999, PATTERN RECOGN LETT, V20, P791, DOI 10.1016/S0167-8655(99)00043-4; TSUKUMO J, 1988, P 9 INT C PATT REC, P168; Waibel A, 1996, P 5 INT WORKSH FRONT, P183; Winston P.H., 1992, ARTIF INTELL; Wong PK, 1999, IEEE T SYST MAN CY B, V29, P286, DOI 10.1109/3477.752802; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7	53	106	122	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1425	1437		10.1109/TPAMI.2002.1046151	http://dx.doi.org/10.1109/TPAMI.2002.1046151			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY					2022-12-18	WOS:000178846400002
J	Ge, YR; Fitzpatrick, JM				Ge, YR; Fitzpatrick, JM			On the generation of skeletons from discrete Euclidean distance maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Euclidean; skeleton; shape analysis; medial axis transform; axis of symmetry; distance transform; Euclidean distance transform	SHAPE-DESCRIPTION; TRANSFORM; MODEL; IMAGES	The skeleton is an important representation for shape analysis. A common approach for generating discrete skeletons takes three steps: 1) computing the distance map, 2) detecting maximal disks from the distance map, and 3) linking the centers of maximal disks (CMDs) into a connected skeleton. Algorithms using approximate distance metrics are abundant and their theory has been well established. However, the resulting skeletons may be inaccurate and sensitive to rotation. In this paper, we study methods for generating skeletons based on the exact Euclidean metric. We first show that no previous algorithms identifies the exact set of discrete maximal disks under the Euclidean metric. We then propose new algorithms and show that they are correct. To link CMDs into connected skeletons, we examine two prevalent approaches: connected thinning and steepest ascent. We point out that the connected thinning approach does not work properly for Euclidean distance maps. Only the steepest ascent algorithm produces skeletons that are truly medially placed. The resulting skeletons have all the desirable properties: they have the same simple connectivity as the figure, they are well-centered, they are insensitive to rotation, and they allow exact reconstruction. The effectiveness of our algorithms is demonstrated with numerous examples.	WAKE FOREST UNIV,BOWMAN GRAY SCH MED,DEPT RADIOL,WINSTON SALEM,NC 27109; VANDERBILT UNIV,DEPT COMP SCI,NASHVILLE,TN 37235	Wake Forest University; Wake Forest Baptist Medical Center; Vanderbilt University	Ge, YR (corresponding author), WAKE FOREST UNIV,BOWMAN GRAY SCH MED,DEPT MATH & COMP SCI,BOX 7388,WINSTON SALEM,NC 27109, USA.							ARCELLI C, 1993, IMAGE VISION COMPUT, V11, P163, DOI 10.1016/0262-8856(93)90055-L; ARCELLI C, 1992, PATTERN RECOGN LETT, V13, P237, DOI 10.1016/0167-8655(92)90074-A; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; ARCELLI C, 1988, COMPUT VISION GRAPH, V43, P361, DOI 10.1016/0734-189X(88)90089-8; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BORGEFORS G, 1991, P 6 INT C IM AN PROC, V1, P115; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5; DILL AR, 1987, IEEE T PATTERN ANAL, V9, P495, DOI 10.1109/TPAMI.1987.4767937; GE Y, 1995, THESIS VANDERBILT U; KLEIN F, 1987, PATTERN RECOGN LETT, V5, P19, DOI 10.1016/0167-8655(87)90022-5; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2; MEYER F, 1990, P SOC PHOTO-OPT INS, V1360, P251, DOI 10.1117/12.24212; MEYER F, 1989, SIGNAL PROCESS, V16, P335, DOI 10.1016/0165-1684(89)90030-3; NIBLACK CW, 1992, CVGIP-GRAPH MODEL IM, V54, P420, DOI 10.1016/1049-9652(92)90026-T; PAGNELMALM I, 1992, CVGIP-IMAG UNDERSTAN, V56, P399; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; PIZER SM, 1992, TR92025 U N CAR DEP; RIAZANOFF S, 1990, PATTERN RECOGN LETT, V11, P25, DOI 10.1016/0167-8655(90)90052-4; ROM H, 1991, P SOC PHOTO-OPT INS, V1570, P262, DOI 10.1117/12.48430; ROSENFEL.A, 1966, J ACM, V13, P471; Rosenfeld A., 1982, DIGITAL PICTURE PROC; TALBOT H, 1992, P SOC PHOTO-OPT INS, V1818, P862, DOI 10.1117/12.131499; Vincent L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P520, DOI 10.1109/CVPR.1991.139746; WRIGHT MW, 1993, IEE PROC-I, V140, P7, DOI 10.1049/ip-i-2.1993.0003	32	106	112	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1055	1066		10.1109/34.544075	http://dx.doi.org/10.1109/34.544075			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900001
J	Jolly, MPD; Lakshmanan, S; Jain, AK				Jolly, MPD; Lakshmanan, S; Jain, AK			Vehicle segmentation and classification using deformable templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object shape models; contour extraction; deformable templates; Bayesian inference; simulated annealing; motion detection; travel time estimation	IMAGE; RESTORATION	This paper proposes a segmentation algorithm using deformable template models to segment a vehicle of interest both from the stationary complex background and other moving vehicles in an image sequence. We define a polygonal template to characterize a general model of a vehicle and derive a prior probability density function to constrain the template to be deformed within a set of allowed shapes. We propose a likelihood probability density function which combines motion information and edge directionality to ensure that the deformable template is contained within the moving areas in the image and its boundary coincides with strong edges with the same orientation in the image. The segmentation problem is reduced to a minimization problem and solved by the Metropolis algorithm. The system was successfully tested on 405 image sequences containing multiple moving vehicles on a highway.	UNIV MICHIGAN, DEPT ELECT & COMP ENGN, DEARBORN, MI 48128 USA; MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA	University of Michigan System; University of Michigan; Michigan State University	Jolly, MPD (corresponding author), SIEMENS CORP RES, 755 COLL RD E, PRINCETON, NJ 08540 USA.			Lakshmanan, Sridhar/0000-0001-7387-3943				AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CREMER M, 1987, TRANSPORT RES B-METH, V21, P117, DOI 10.1016/0191-2615(87)90011-7; DUBUISSON M, 1995, THESIS MICHIGAN STAT; Dubuisson M.-P., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P266, DOI 10.1109/IVS.1994.639518; DUBUISSON MP, 1995, INT J COMPUT VISION, V14, P83, DOI 10.1007/BF01421490; DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1986, SIAM J CONTROL OPTIM, V24, P1031, DOI 10.1137/0324060; GEMAN S, 1995, COMMUNICATION    APR; Grenander U., 1991, HANDS PATTERN THEORE; GRENANDER U, 1991, MONOGRAPH ELECTRONIC; GRENANDER U, 1993, STAT IMAGES, V1, P89; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; KOLLER D, 1994, INT C PATT RECOG, P126, DOI 10.1109/ICPR.1994.576243; LAKSHMANAN S, 1995, P INT C AC SPEECH SI, V5, P2955; LAKSHMANAN S, 1995, IN PRESS IEEE T PATT; MARDIA KV, 1992, P INT C PATT REC HAG, V2, P132; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MICHALOPOULOS PG, 1991, IEEE T VEH TECHNOL, V40, P21, DOI 10.1109/25.69968; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; Phillips D. B., 1993, STAT IMAGES, V1, P299; SRIVASTAVA A, 1995, IEEE T SIGNAL PROCES, V43, P1282, DOI 10.1109/78.382418; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; STRENSKI PN, 1991, ALGORITHMICA, V6, P346, DOI 10.1007/BF01759050; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TANAKA Y, 1992, P IEEE INT VEH S DET, P353; *TRANSP RES BOARD, 1991, ADV VEH HIGHW TECHN; WANG YF, 1992, IEEE T PATTERN ANAL, V14, P572, DOI 10.1109/34.134061; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; [No title captured]	33	106	135	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					293	308		10.1109/34.485557	http://dx.doi.org/10.1109/34.485557			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500006
J	DRUMHELLER, M				DRUMHELLER, M			MOBILE ROBOT LOCALIZATION USING SONAR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									THINKING MACHINES CORP,CAMBRIDGE,MA 02142		DRUMHELLER, M (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.							Ballard D.H., 1982, COMPUTER VISION; DRUMHELLER M, 1984, THESIS MIT CAMBRIDGE; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; GIRALT G, 1979, 6TH P INT JOINT C AR; GRIMSON WEL, 1984, AI763 MIT AI LAB MEM; GRIMSON WEL, 1985, 1985 P INT C ROB AUT, P61; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; LEWIS RA, 1977, P IJCAI 5; MILLER DP, 1984, 9TH P WT PEC MEM REM, P362; MORAVEC H, 1981, ROBOT ROVER VISUAL N; MORAVEC HP, 1985, MAR P IEEE INT C ROB, P116; THOMPSON AM, 1979, P IJCAI 6 TOKYO, P335; ULTRASONIC RANGING S; MODEL E 220 ULTRASON	14	106	109	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					325	332		10.1109/TPAMI.1987.4767907	http://dx.doi.org/10.1109/TPAMI.1987.4767907			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869403	Green Submitted			2022-12-18	WOS:A1987G163300014
J	BHANU, B; FAUGERAS, OD				BHANU, B; FAUGERAS, OD			SHAPE-MATCHING OF TWO-DIMENSIONAL OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV PARIS 11,PARIS,FRANCE; INST NATL RECH INFORMAT & AUTOMAT,COMP VIS & ROBOT GRP,ROCQUENCOURT,FRANCE	UDICE-French Research Universities; Universite Paris Saclay	BHANU, B (corresponding author), FORD AEROSP & COMMUN CORP,DIV AERONUTRON,NEWPORT BEACH,CA 92660, USA.			Bhanu, Bir/0000-0001-8971-6416				BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BHANU B, 1982, IEEE T PATTERN ANAL, V4, P408, DOI 10.1109/TPAMI.1982.4767273; Bhanu B., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P349; BHANU B, 1981, SHAPE MATCHING IMAGE; DAVIS L, 1980, 123 U TEX DEP COMP S; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DAVIS LS, 1980, TR134 U TEX DEP COMP; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; FAUGERAS OD, 1980, 8TH P WORLD COMP C I, P695; FAUGERAS OD, 1980, 4TH P INT C AN OPT S, P790; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Luenberger D. G., 1973, INTRO LINEAR NONLINE; MARTIN WN, 1979, PATTERN RECOGN, V11, P169, DOI 10.1016/0031-3203(79)90004-9; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P307, DOI 10.1109/TPAMI.1979.4766928; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PELEG S, 1980, DEC P ICPR 80 MIAM B, P54; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; YACHIDA M, 1978, NOV P IJCPR 78 KYOT	21	106	106	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					137	156		10.1109/TPAMI.1984.4767499	http://dx.doi.org/10.1109/TPAMI.1984.4767499			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869179				2022-12-18	WOS:A1984SF59100002
J	Huang, G; Liu, Z; Pleiss, G; Maaten, LV; Weinberger, KQ				Huang, Gao; Liu, Zhuang; Pleiss, Geoff; Maaten, Laurens van der; Weinberger, Kilian Q.			Convolutional Networks with Dense Connectivity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural network; deep learning; image classification		Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections-one between each layer and its subsequent layer-our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, encourage feature reuse and substantially improve parameter efficiency. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less parameters and computation to achieve high performance.	[Huang, Gao] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Pleiss, Geoff; Weinberger, Kilian Q.] Cornell Univ, Dept Comp Sci, Ithaca, NY 14850 USA; [Liu, Zhuang] Berkeley Artificial Intelligence Res, Berkeley, CA 94704 USA; [Maaten, Laurens van der] Facebook AI Res, New York, NY 10003 USA	Tsinghua University; Cornell University; Facebook Inc	Huang, G (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	gaohuang@tsinghua.edu.cn; zhuangl@berkeley.edu; kwq4@cornell.edu; lvdmaaten@fb.com; geoff@cs.cornell.edu		Liu, Zhuang/0000-0001-6395-0212; Huang, Gao/0000-0002-7251-0988	NSF [1740822, III-1618134, III-1526012, IIS-1149882, IIS-1724282]; Office of Naval Research [N00014-17-1-2175]; Bill and Melinda Gates Foundation; SAP America Inc.; NSF TRIPODS Award [1740822]	NSF(National Science Foundation (NSF)); Office of Naval Research(Office of Naval Research); Bill and Melinda Gates Foundation(Bill & Melinda Gates Foundation); SAP America Inc.; NSF TRIPODS Award	The authors are supported in part by the NSF III-1618134, III-1526012, IIS-1149882, IIS-1724282, the Office of Naval Research Grant N00014-17-1-2175, the Bill and Melinda Gates Foundation, SAP America Inc., and the NSF TRIPODS Award #1740822 (Cornell TRIPODS Center for Data Science for Improved Decision Making). We thank Danlu Chen, Daniel Sedra, Tongcheng Li and Yu Sun for many insightful discussions.	Chassang A, 3 INT C LEARN REPRES; Chen Tianqi, 2016, TRAINING DEEP NETS S, V6, P6; Chen YP, 2017, ADV NEUR IN, V30; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Cortes C, 2017, PR MACH LEARN RES, V70; Deng J., 2009, P 2009 IEEE C COMP V, P248, DOI DOI 10.1109/CVPR.2009.5206848; Fahlman S.E., 1990, ADV NEURAL INFORM PR, P524; Glorot X., 2011, P 14 INT C ART INT S, P315; Goodfellow I.J., 2013, COMPUTER SCI, P1319; Gross S., 2016, FACEBOOK RES, V6, DOI DOI 10.1109/CVPR.2016.90; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hu H., 2017, LOG DENSENET TO SPAR; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Iandola F.N., 2016, ARXIV PREPRINT ARXIV; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918; Liao Q., 2016, CORR; Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Netzer Y., 2011, NIPS WORKSH DEEP LEA, P14; Pezeshki M, 2016, PR MACH LEARN RES, V48; Rasmus A, 2015, ADV NEUR IN, V28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Sermanet P, 2012, INT C PATT RECOG, P3288; Springenberg J.T., 2014, ARXIV14126806; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Srivastava RK, 2015, ADV NEUR IN, V28; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Szegedy C., 2015, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2015.7298594; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Targ S, 2016, RESNET RESNET GEN RE; Wei Z., 2016, DEEPLY FUSED NETS; Wilamowski BM, 2010, IEEE T NEURAL NETWOR, V21, P1793, DOI 10.1109/TNN.2010.2073482; Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064	48	105	105	5	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					8704	8716		10.1109/TPAMI.2019.2918284	http://dx.doi.org/10.1109/TPAMI.2019.2918284			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	31135351	Green Submitted			2022-12-18	WOS:000880661400014
J	Sun, SJ; Akhtar, N; Song, HS; Mian, AS; Shah, M				Sun, Shijie; Akhtar, Naveed; Song, HuanSheng; Mian, Ajmal S.; Shah, Mubarak			Deep Affinity Network for Multiple Object Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple object tracking; deep tracking; deep affinity; tracking challenge; on-line tracking	MULTITARGET TRACKING; PERFORMANCE; ALGORITHM	Multiple Object Tracking (MOT) plays an important role in solving many fundamental problems in video analysis and computer vision. Most MOT methods employ two steps: Object Detection and Data Association. The first step detects objects of interest in every frame of a video, and the second establishes correspondence between the detected objects in different frames to obtain their tracks. Object detection has made tremendous progress in the last few years due to deep learning. However, data association for tracking still relies on hand crafted constraints such as appearance, motion, spatial proximity, grouping etc. to compute affinities between the objects in different frames. In this paper, we harness the power of deep learning for data association in tracking by jointly modeling object appearances and their affinities between different frames in an end-to-end fashion. The proposed Deep Affinity Network (DAN) learns compact, yet comprehensive features of pre-detected objects at several levels of abstraction, and performs exhaustive pairing permutations of those features in any two frames to infer object affinities. DAN also accounts for multiple objects appearing and disappearing between video frames. We exploit the resulting efficient affinity computations to associate objects in the current frame deep into the previous frames for reliable on-line tracking. Our technique is evaluated on popular multiple object tracking challenges MOT15, MOT17 and UA-DETRAC. Comprehensive benchmarking under twelve evaluation metrics demonstrates that our approach is among the best performing techniques on the leader board for these challenges. The open source implementation of our work is available at https://github.com/shijieS/SST.git.	[Sun, Shijie; Song, HuanSheng] Changan Univ, Sch Informat Engn, Xian 710000, Shaanxi, Peoples R China; [Akhtar, Naveed; Mian, Ajmal S.] Univ Western Australia, Dept Comp Sci & Software Engn, Crawley, WA 6009, Australia; [Shah, Mubarak] Univ Cent Florida, Ctr Res Comp Vis CRCV, Dept Comp Sci, Orlando, FL 32816 USA	Chang'an University; University of Western Australia; State University System of Florida; University of Central Florida	Song, HS (corresponding author), Changan Univ, Sch Informat Engn, Xian 710000, Shaanxi, Peoples R China.	shijieSun@chd.edu.cn; naveed.akhtar@uwa.edu.au; hshsong@chd.edu.cn; ajmal.mian@uwa.edu.au; shah@crcv.ucf.edu	AKHTAR, NAVEED/AAT-1283-2020	AKHTAR, NAVEED/0000-0003-3406-673X; Shah, Mubarak/0000-0001-6172-5572; Mian, Ajmal/0000-0002-5206-3842	ARC [DP160101458, DP190102443]; National Natural Science Foundation of China [61572083]; Joint Found of of Ministry of Education of China [6141A02022610]; Key projects of key R&D projects in Shaanxi [2018ZDXM-GY047]; Team cultivation project of Central University [300102248402]; China Scholarship Council; IARPA, via IARPA RD [D17PC00345]; ODNI	ARC(Australian Research Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Joint Found of of Ministry of Education of China(Ministry of Education, China); Key projects of key R&D projects in Shaanxi; Team cultivation project of Central University; China Scholarship Council(China Scholarship Council); IARPA, via IARPA RD; ODNI	This research was supported by ARC grant DP160101458 and DP190102443, the National Natural Science Foundation of China (Grant No. 61572083), the Joint Found of of Ministry of Education of China (Grant No. 6141A02022610), Key projects of key R&D projects in Shaanxi (Grant No. 2018ZDXM-GY047), Team cultivation project of Central University (Grant No. 300102248402) and China Scholarship Council. Mubarak Shah acknowledges the support of ODNI, and IARPA, via IARPA R&D Contract No. D17PC00345. The views, findings, opinions, and conclusions or recommendations contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the ODNI, IARPA or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purpose not withstanding any copyright annotation thereon. The GPU used for this work was donated by NVIDIA Corporation.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, P 31 AAAI C ART INT; Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278; Bunyak F., 2017, IEEE INT C ADV VID S, P1; Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384; Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Eiselein V, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P325, DOI 10.1109/AVSS.2012.59; Emami P., 2018, ARXIV PREPRINT ARXIV; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fu ZY, 2017, INT CONF ACOUST SPEE, P4376, DOI 10.1109/ICASSP.2017.7952983; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henschel R, 2018, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2018.00192; Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132; Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42; Impiombato D, 2015, NUCL INSTRUM METH A, V794, P185, DOI 10.1016/j.nima.2015.05.028; Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142; Izadinia H, 2012, LECT NOTES COMPUT SC, V7577, P100, DOI 10.1007/978-3-642-33783-3_8; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Keuper M, 2016, ARXIV160706317; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; Kutschbach Tino, 2017, 2017 14 IEEE INT C A, P1, DOI DOI 10.1109/AVSS.2017.8078517; Leal-Taixe L., 2015, ARXIV150401942; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935; Lin CY, 2017, INT CONF IMAG VIS; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Luo WH, 2021, ARTIF INTELL, V293, DOI 10.1016/j.artint.2020.103448; Milan A., 2016, ARXIV160300831; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan Anton, 2016, ARXIV PREPRINT ARXIV; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Nair V, 2010, P 27 INT C MACHINE L, P807; Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465; Ning G, 2017, CAN J GASTROENTEROL, V2017, DOI 10.1155/2017/3612403; Paszke A, 2017, NEURAL INFORM PROCES; Patino L, 2016, IEEE COMPUT SOC CONF, P1240, DOI 10.1109/CVPRW.2016.157; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7; Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292; Selvadurai APS, 2007, PROC MONOGR ENG WATE, P3; Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1; Shafique K., 2008, P IEEE C COMP VIS PA, P1; Sheng H., 2018, IEEE T CIRCUITS SYST, DOI [10.1109/TCSVT.2018.2882182, DOI 10.1109/TCSVT.2018.2882182]; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Tang SY, 2015, PROC CVPR IEEE, P5033, DOI 10.1109/CVPR.2015.7299138; Wang L, 2017, IEEE INT CON MULTI, P1135, DOI 10.1109/ICME.2017.8019461; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wen L., 2015, ARXIV151104136; Wen LY, 2019, AAAI CONF ARTIF INTE, P8981; Wojke N, 2018, IEEE WINT CONF APPL, P748, DOI 10.1109/WACV.2018.00087; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892; Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155; Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240; Zhang S., 2015, NEURAL INFORM PROCES, P685; Zhang SP, 2017, IEEE T NEUR NET LEAR, V28, P2357, DOI 10.1109/TNNLS.2016.2586194; Zhang Yunhua, 2018, ARXIV180904320	96	105	108	40	164	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					104	119		10.1109/TPAMI.2019.2929520	http://dx.doi.org/10.1109/TPAMI.2019.2929520			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31329110	Green Submitted			2022-12-18	WOS:000597206900008
J	Lathuiliere, S; Mesejo, P; Alameda-Pineda, X; Horaud, R				Lathuiliere, Stephane; Mesejo, Pablo; Alameda-Pineda, Xavier; Horaud, Radu			A Comprehensive Analysis of Deep Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Task analysis; Pose estimation; Computer vision; Systematics; Deep learning; Benchmark testing; Deep learning; regression; computer vision; convolutional neural networks; statistical significance; empirical and systematic evaluation; head-pose estimation; full-body pose estimation; facial landmark detection	CONVOLUTIONAL NEURAL-NETWORKS; REJECTIVE MULTIPLE TEST; HUMAN POSE; FORESTS; MIXTURE; TESTS	Deep learning revolutionized data science, and recently its popularity has grown exponentially, as did the amount of papers employing deep networks. Vision tasks, such as human pose estimation, did not escape from this trend. There is a large number of deep models, where small changes in the network architecture, or in the data pre-processing, together with the stochastic nature of the optimization procedures, produce notably different results, making extremely difficult to sift methods that significantly outperform others. This situation motivates the current study, in which we perform a systematic evaluation and statistical analysis of vanilla deep regression, i.e., convolutional neural networks with a linear regression top layer. This is the first comprehensive analysis of deep regression techniques. We perform experiments on four vision problems, and report confidence intervals for the median performance as well as the statistical significance of the results, if any. Surprisingly, the variability due to different data pre-processing procedures generally eclipses the variability due to modifications in the network architecture. Our results reinforce the hypothesis according to which, in general, a general-purpose network (e.g., VGG-16 or ResNet-50) adequately tuned can yield results close to the state-of-the-art without having to resort to more complex and ad-hoc regression models.	[Lathuiliere, Stephane; Mesejo, Pablo; Alameda-Pineda, Xavier; Horaud, Radu] INRIA, PERCEPT Team, F-38334 Montbonnot St Martin, France; [Lathuiliere, Stephane; Mesejo, Pablo; Alameda-Pineda, Xavier; Horaud, Radu] Univ Grenoble Alpes, F-38334 Montbonnot St Martin, France; [Mesejo, Pablo] Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Granada 18071, Spain	Inria; Communaute Universite Grenoble Alpes; UDICE-French Research Universities; Universite Grenoble Alpes (UGA); University of Granada	Lathuiliere, S (corresponding author), INRIA, PERCEPT Team, F-38334 Montbonnot St Martin, France.; Lathuiliere, S (corresponding author), Univ Grenoble Alpes, F-38334 Montbonnot St Martin, France.	stephane.lathuiliere@inria.fr; pablo.mesejo-santiago@inria.fr; Xavier.Alameda-Pineda@inria.fr; radu.horaud@inria.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X; Alameda-Pineda, Xavier/0000-0002-5354-1084	EU funding via the FP7 ERC Advanced Grant VHIA [340113]	EU funding via the FP7 ERC Advanced Grant VHIA	EU funding via the FP7 ERC Advanced Grant VHIA #340113 is greatly acknowledged.	Agarwal A, 2004, PROC CVPR IEEE, P882; Alameda-Pineda X, 2017, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2017.59; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.154; [Anonymous], 2011, LECT NOTES COMPUT II; Ba J. Lei, 2016, ARXIV160706450; Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64; Belagiannis V, 2015, IEEE I CONF COMP VIS, P2830, DOI 10.1109/ICCV.2015.324; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Carvalho M, 2018, IEEE IMAGE PROC, P2915, DOI 10.1109/ICIP.2018.8451312; Chandrasekhar V, 2016, SIGNAL PROCESS, V128, P426, DOI 10.1016/j.sigpro.2016.05.021; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137; Chollet F., 2015, **NON-TRADITIONAL**; Chou CR, 2013, COMPUT VIS IMAGE UND, V117, P1095, DOI 10.1016/j.cviu.2013.02.009; Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601; Conover W., 1998, PRACTICAL NONPARAMET; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002; Drouard V, 2017, IEEE T IMAGE PROCESS, V26, P1428, DOI 10.1109/TIP.2017.2654165; Duchi J, 2011, J MACH LEARN RES, V12, P2121; DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Fisher R., 1925, STAT METHODS RES WOR; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Goodfellow I., 2016, **DROPPED REF**; Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.2307/2336325; HOLLAND BS, 1987, BIOMETRICS, V43, P417, DOI 10.2307/2531823; HOLM S, 1979, SCAND J STAT, V6, P65; HOMMEL G, 1988, BIOMETRIKA, V75, P383, DOI 10.1093/biomet/75.2.383; Hueber T, 2015, IEEE-ACM T AUDIO SPE, V23, P2246, DOI 10.1109/TASLP.2015.2464702; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Ithapu V. K., 2017, ARCHITECTURAL CHOICE; Johnson S., 2010, P BRIT MACH VIS C; King DB, 2015, ACS SYM SER, V1214, P1; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lathuiliere S., 2018, P EUR C COMPUT VIS, P202; Lathuiliere S, 2017, PROC CVPR IEEE, P7149, DOI 10.1109/CVPR.2017.756; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; Liu XB, 2016, IEEE IMAGE PROC, P1289, DOI 10.1109/ICIP.2016.7532566; Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15; Mesejo P, 2015, INT J NEURAL SYST, V25, DOI 10.1142/S0129065715500124; Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007; Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819; Nemenyi P., 1963, THESIS; Neubauer C, 1998, IEEE T NEURAL NETWOR, V9, P685, DOI 10.1109/72.701181; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie XC, 2018, PROC CVPR IEEE, P2100, DOI 10.1109/CVPR.2018.00224; Nuzzo R, 2014, NATURE, V506, P150, DOI 10.1038/506150a; Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299; Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052; Ramanan D., 2007, ADV NEURAL INFORM PR, V19, P1129; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134; ROM DM, 1990, BIOMETRIKA, V77, P663, DOI 10.2307/2337008; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Saxena S., 2016, P 30 INT C NEUR INF, P4053; Sermanet P., 2014, P INT C LEARN REPR, P44; Simonyan K., 2015, P INT C LEARN REPR, P1; Smith L. N., 2016, CORR, P1097; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sterne JAC, 2001, BMJ-BRIT MED J, V322, P226, DOI 10.1136/bmj.322.7280.226; Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Sutskever I., 2013, P 30 INT C MACH LEAR, V28, P1139; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P2; Tompson J., 2014, P ADV NEUR INF PROC, V27, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Vidgen B, 2016, FRONT PHYS, V4, DOI 10.3389/fphy.2016.00006; Wang B., 2013, P 7 INT C IM GRAPH, P650; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Yan S., 2007, P IEEE C COMP VIS PA, P1; Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yao X, 1999, P IEEE, V87, P1423, DOI 10.1109/5.784219; Yosinski J, 2014, ADV NEUR IN, V27; Zeiler M.D., 2012, ADADELTA ADAPTIVE LE, DOI DOI 10.48550/ARXIV.1212.5701; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	90	105	105	11	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2065	2081		10.1109/TPAMI.2019.2910523	http://dx.doi.org/10.1109/TPAMI.2019.2910523			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30990175	Green Submitted			2022-12-18	WOS:000557354900001
J	Bilen, H; Fernando, B; Gavves, E; Vedaldi, A				Bilen, Hakan; Fernando, Basura; Gavves, Efstratios; Vedaldi, Andrea			Action Recognition with Dynamic Image Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human action classification; video classification; motion representation; deep learning; convolutional neural networks	HISTOGRAMS	We introduce the concept of dynamic image, a novel compact representation of videos useful for video analysis, particularly in combination with convolutional neural networks (CNNs). A dynamic image encodes temporal data such as RGB or optical flow videos by using the concept of 'rank pooling'. The idea is to learn a ranking machine that captures the temporal evolution of the data and to use the parameters of the latter as a representation. We call the resulting representation dynamic image because it summarizes the video dynamics in addition to appearance. This powerful idea allows to convert any video to an image so that existing CNN models pre-trained with still images can be immediately extended to videos. We also present an efficient approximate rank pooling operator that runs two orders of magnitude faster than the standard ones with any loss in ranking performance and can be formulated as a CNN layer. To demonstrate the power of the representation, we introduce a novel four stream CNN architecture which can learn from RGB and optical flow frames as well as from their dynamic image representations. We show that the proposed network achieves state-of-the-art performance, 95.5 and 72.5 percent accuracy, in the UCF101 and HMDB51 respectively.	[Bilen, Hakan] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland; [Fernando, Basura] Australian Natl Univ, ACRV, Res Sch Engn, Canberra, ACT 2601, Australia; [Gavves, Efstratios] Univ Amsterdam, QUVA Lab, NL-1012 WX Amsterdam, Netherlands; [Vedaldi, Andrea] Univ Oxford, VGG, Oxford OX1 2JD, England	University of Edinburgh; Australian National University; University of Amsterdam; University of Oxford	Bilen, H (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.	hbilen@ed.ac.uk; basura.fernando@anu.edu.au; egavves@uva.nl; vedaldi@robots.ox.ac.uk	Bilen, Hakan/ACY-3128-2022; Gavves, Efstratios/AAA-6992-2019; Bilen, Hakan/AAG-3202-2022; Bilen, Hakan/H-9130-2016; Vedaldi, Andrea/B-9071-2015	Fernando, Basura/0000-0002-6920-9916; Bilen, Hakan/0000-0002-6947-6918; Gavves, Efstratios/0000-0001-8947-1332; Vedaldi, Andrea/0000-0003-1374-2858	EPSRC [EP/L024683/1]; ERC Starting Grant IDIU; Australian Research Council Centre of Excellence for Robotic Vision [CE140100016]; Engineering and Physical Sciences Research Council [EP/L024683/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ERC Starting Grant IDIU; Australian Research Council Centre of Excellence for Robotic Vision(Australian Research Council); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work acknowledges the support of the EPSRC grant EP/L024683/1, the ERC Starting Grant IDIU and the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016).	Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Bilen Hakan, 2016, CVPR, DOI DOI 10.1109/CVPR.2016.331; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Cheron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Courtney PG, 2015, IEEE COMP SEMICON; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Feichtenhofer Christoph, 2016, NIPS; Fernando B, 2016, ICML; Fernando B, 2017, INT J COMPUT VISION, V124, P335, DOI 10.1007/s11263-017-1030-x; Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148; Fernando B, 2016, PROC CVPR IEEE, P1924, DOI 10.1109/CVPR.2016.212; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676; Gould Stephen, 2016, ARXIV160705447; Hoai M, 2015, LECT NOTES COMPUT SC, V9007, P3, DOI 10.1007/978-3-319-16814-2_1; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Kellokumpu V., 2008, P BRIT MACH C; Kinghorn DB, 1996, INT J QUANTUM CHEM, V57, P141, DOI 10.1002/(SICI)1097-461X(1996)57:2<141::AID-QUA1>3.0.CO;2-Y; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lan T, 2015, IEEE I CONF COMP VIS, P4552, DOI 10.1109/ICCV.2015.517; Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Li Y, 2016, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2016.215; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Mazloom M, 2014, IEEE T MULTIMEDIA, V16, P2214, DOI 10.1109/TMM.2014.2359771; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013; Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Pirsiavash H., 2009, P ADV NEUR INF PROC, P1482; Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807; de Souza CR, 2016, LECT NOTES COMPUT SC, V9911, P697, DOI 10.1007/978-3-319-46478-7_43; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691; Schindler K, 2008, PROC CVPR IEEE, P3025; Shechtman E, 2005, PROC CVPR IEEE, P405; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457; Soomro K., 2012, ARXIV; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2017, IEEE WINT CONF APPL, P168, DOI 10.1109/WACV.2017.26; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98; Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67; Yeung S., 2015, ARXIV150705738; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zha S., 2015, P BRIT MACH VIS C; Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110	77	105	112	3	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2799	2813		10.1109/TPAMI.2017.2769085	http://dx.doi.org/10.1109/TPAMI.2017.2769085			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990080	Green Accepted, Green Published, Green Submitted			2022-12-18	WOS:000449355500001
J	Lin, L; Wang, GR; Zuo, WM; Feng, XC; Zhang, L				Lin, Liang; Wang, Guangrun; Zuo, Wangmeng; Feng, Xiangchu; Zhang, Lei			Cross-Domain Visual Matching via Generalized Similarity Measure and Feature Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Similarity model; cross-domain matching; person verification; deep learning	FACE RECOGNITION; DISTANCE; RETRIEVAL	Cross-domain visual data matching is one of the fundamental problems in many real-world vision tasks, e.g., matching persons across ID photos and surveillance videos. Conventional approaches to this problem usually involves two steps: i) projecting samples from different domains into a common space, and ii) computing (dis-)similarity in this space based on a certain distance. In this paper, we present a novel pairwise similarity measure that advances existing models by i) expanding traditional linear projections into affine transformations and ii) fusing affine Mahalanobis distance and Cosine similarity by a data-driven combination. Moreover, we unify our similarity measure with feature representation learning via deep convolutional neural networks. Specifically, we incorporate the similarity measure matrix into the deep architecture, enabling an end-to-end way of model optimization. We extensively evaluate our generalized similarity model in several challenging cross-domain matching tasks: person re-identification under different views and face verification over different modalities (i.e., faces from still images and videos, older and younger faces, and sketch and photo portraits). The experimental results demonstrate superior performance of our model over other state-of-the-art methods.	[Lin, Liang; Wang, Guangrun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China; [Lin, Liang; Wang, Guangrun] Natl Univ Def Technol, Collaborat Innovat Ctr High Performance Comp, Changsha 410073, Hunan, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China; [Feng, Xiangchu] Xidian Univ, Sch Math & Stat, Xian, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Sun Yat Sen University; National University of Defense Technology - China; Harbin Institute of Technology; Xidian University; Hong Kong Polytechnic University	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.	linliang@ieee.org; wanggrun@mail2.sysu.edu.cn; cswmzuo@gmail.com; xcfeng@mail.xidian.edu.cn; cslzhang@comp.polyu.edu.hk	Zuo, Wangmeng/B-3701-2008	Liang, Lin/0000-0003-2248-3755; Zhang, Lei/0000-0002-2078-4215	Hong Kong Scholar Program; Guangdong Natural Science Foundation [S2013050014548, 2014A030313201]; Program of Guangzhou Zhujiang Star of Science and Technology [2013J2200067]; Fundamental Research Funds for the Central Universities; Special Program for Applied Research on Super Computation of the NSFC-Guangdong Joint Fund	Hong Kong Scholar Program; Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); Program of Guangzhou Zhujiang Star of Science and Technology; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Special Program for Applied Research on Super Computation of the NSFC-Guangdong Joint Fund	This work was supported in part by the Hong Kong Scholar Program, in part by Guangdong Natural Science Foundation under Grant S2013050014548 and 2014A030313201, in part by Program of Guangzhou Zhujiang Star of Science and Technology under Grant 2013J2200067, and in part by the Fundamental Research Funds for the Central Universities. This work was also supported by Special Program for Applied Research on Super Computation of the NSFC-Guangdong Joint Fund (the second phase).	Ahmed E., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299016; Andrew Galen, 2013, ICML; Bouchaffra D, 2012, IEEE T NEUR NET LEAR, V23, P1229, DOI 10.1109/TNNLS.2012.2200261; Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chang H, 2007, ROY I PH S, V61, P1, DOI 10.1017/S1358246107000124; CHEN BC, 2014, EUR C COMP VIS, P768; Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005; Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357; Gray D., 2007, P IEEE 10 INT C WORK; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Huang Gary B., 2007, 0749 U MASS, P7; Huang ZW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493448; Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58; Kang C., 2014, CROSS MODAL SIMILARI; Kostinger Martin, 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247939; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo P., 2015, IEEE T NEUR NET LEAR, DOI [10.1109/TNNLS.2015.244043, DOI 10.1109/TNNLS.2015.244043]; McFee B., 2010, P 27 INT C MACHINE L, P775; Mignon A., 2012, P AS C COMP VIS, P1; Ramage D., 2009, P 2009 C EMP METH NA, V1, P248, DOI DOI 10.3115/1699510.1699543; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Sharma A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247923; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353; Vincent P, 2002, ADV NEUR IN, V14, P985; Wang GR, 2016, AAAI CONF ARTIF INTE, P3611; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang RP, 2012, IEEE T IMAGE PROCESS, V21, P4466, DOI 10.1109/TIP.2012.2206039; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wang XG, 2004, PROC CVPR IEEE, P564; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16; Zhai X., 2013, P AAAI C ART INT AAA; Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315; Zhang W, 2010, LECT NOTES COMPUT SC, V6316, P420, DOI 10.1007/978-3-642-15567-3_31; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zhiwu Huang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P589, DOI 10.1007/978-3-642-37444-9_46; Zhu J, 2009, P 26 ANN INT C MACH, P1257; Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331; Zhuang Yueting, 2013, 27 AAAI C ART INT, P1070	60	105	112	2	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1089	1102		10.1109/TPAMI.2016.2567386	http://dx.doi.org/10.1109/TPAMI.2016.2567386			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27187945	Green Submitted			2022-12-18	WOS:000401091200004
J	Jiang, ZL; Lin, Z; Davis, LS				Jiang, Zhuolin; Lin, Zhe; Davis, Larry S.			Recognizing Human Actions by Learning and Matching Shape-Motion Prototype Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; shape-motion prototype tree; hierarchical K-means clustering; joint probability; dynamic time warping	ACTION RECOGNITION	A shape-motion prototype-based approach is introduced for action recognition. The approach represents an action as a sequence of prototypes for efficient and flexible action matching in long video sequences. During training, an action prototype tree is learned in a joint shape and motion space via hierarchical K-means clustering and each training sequence is represented as a labeled prototype sequence; then a look-up table of prototype-to-prototype distances is generated. During testing, based on a joint probability model of the actor location and action prototype, the actor is tracked while a frame-to-prototype correspondence is established by maximizing the joint probability, which is efficiently performed by searching the learned prototype tree; then actions are recognized using dynamic prototype sequence matching. Distance measures used for sequence matching are rapidly obtained by look-up table indexing, which is an order of magnitude faster than brute-force computation of frame-to-frame distances. Our approach enables robust action matching in challenging situations (such as moving cameras, dynamic backgrounds) and allows automatic alignment of action sequences. Experimental results demonstrate that our approach achieves recognition rates of 92.86 percent on a large gesture data set (with dynamic backgrounds), 100 percent on the Weizmann action data set, 95.77 percent on the KTH action data set, 88 percent on the UCF sports data set, and 87.27 percent on the CMU action data set.	[Jiang, Zhuolin; Davis, Larry S.] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA; [Lin, Zhe] Adobe Syst Inc, Adv Technol Labs, San Jose, CA 95110 USA	University System of Maryland; University of Maryland College Park; Adobe Systems Inc.	Jiang, ZL (corresponding author), Univ Maryland, Inst Adv Comp Studies, AV Williams Bldg, College Pk, MD 20742 USA.	zhuolin@umiacs.umd.edu; zlin@adobe.com; lsd@umiacs.umd.edu			US Army Research Laboratory [DAAD 19-012-0012 ARL-CTA-DJH]; VIRAT	US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); VIRAT	This work was funded by the US Army Research Laboratory Robotics Collaborative Technology Alliance program (contract number: DAAD 19-012-0012 ARL-CTA-DJH) and the VIRAT program.	Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008; Ali S, 2007, IEEE I CONF COMP VIS, P1703; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064; Chiaraviglio L, 2009, P GREENMETRICS WORKS, P1; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Elgammal A, 2003, PROC CVPR IEEE, P571; Fanti C, 2005, PROC CVPR IEEE, P1166; Fathi A, 2008, PROC CVPR IEEE, P3064; Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202; Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Ke Y, 2007, IEEE I CONF COMP VIS, P1424; Ke Y, 2007, PROC CVPR IEEE, P3835; Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004; Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98; Kovashka A., 2010, P IEEE C COMP VIS PA, P1; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Laptev I, 2007, IEEE I CONF COMP VIS, P2165; Li H, 2005, IEEE I CONF COMP VIS, P236; Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597; Liu JG, 2008, PROC CVPR IEEE, P2971; Lv F., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383131; Mikolajczyk K, 2008, PROC CVPR IEEE, P2229; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Natarajan P, 2010, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR.2010.5539876; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Niebles JC, 2007, PROC CVPR IEEE, P1235; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Nowozin S, 2007, IEEE I CONF COMP VIS, P1727; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Salvador  S., 2004, KDD WORKSH MIN TEMP, P70; Schindler K, 2008, PROC CVPR IEEE, P3025; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Shen Y., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587755; Shet V.D., 2004, P IND C COMP VIS GRA, P656; Shi QF, 2008, PROC CVPR IEEE, P1673; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; Souvenir R, 2008, PROC CVPR IEEE, P1634; Thurau C., 2008, CVPR, P1; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; US-ARMY, 1987, FIELD MAN, P21; Veeraraghavan A, 2006, 2006 IEEE COMPUTER S, V1, P959; Vitaladevuni S. N., 2008, P IEEE C COMP VIS PA, P1; Wang H., BRIT MACH VIS C LOND, P1; Wang L, 2007, 2007 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2007.383298, DOI 10.1109/CVPR.2007.383298]; Wang Y, 2007, LECT NOTES COMPUT SC, V4814, P240; Weinland D., 2008, CVPR 2008, P1, DOI DOI 10.1109/CVPR.2008.4587731; Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66; Yao A., 2010, P IEEE C COMP VIS PA, P1; Yao B., 2009, P IEEE INT C COMP VI, P1; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]	61	105	116	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					533	547		10.1109/TPAMI.2011.147	http://dx.doi.org/10.1109/TPAMI.2011.147			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21788666				2022-12-18	WOS:000299381600009
J	Shafait, F; Keysers, D; Breuel, TM				Shafait, Faisal; Keysers, Daniel; Breuel, Thomas M.			Performance evaluation and benchmarking of six-page segmentation algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document page segmentation; OCR; performance evaluation; performance metric	PAGE IMAGES; DOCUMENT; SYSTEM	Informative benchmarks are crucial for optimizing the page segmentation step of an OCR system, frequently the performance limiting step for overall OCR system performance. We show that current evaluation scores are insufficient for diagnosing specific errors in page segmentation and fail to identify some classes of serious segmentation errors altogether. This paper introduces a vectorial score that is sensitive to, and identifies, the most important classes of segmentation errors (over, under, and mis-segmentation) and what page components (lines, blocks, etc.) are affected. Unlike previous schemes, our evaluation method has a canonical representation of ground-truth data and guarantees pixel-accurate evaluation results for arbitrary region shapes. We present the results of evaluating widely used segmentation algorithms (x-y cut, smearing, whitespace analysis, constrained text-line finding, docstrum, and Voronoi) on the UW-III database and demonstrate that the new evaluation scheme permits the identification of several specific flaws in individual segmentation methods.	[Shafait, Faisal; Keysers, Daniel] DFKI GmbH, German Res Ctr Artificial Intelligence, Image Understanding & Pattern Recognit Res Grp, D-67663 Kaiserslautern, Germany; [Breuel, Thomas M.] Tech Univ Kaiserslautern, Dept Comp Sci, D-67663 Kaiserslautern, Germany	German Research Center for Artificial Intelligence (DFKI); University of Kaiserslautern	Shafait, F (corresponding author), DFKI GmbH, German Res Ctr Artificial Intelligence, Image Understanding & Pattern Recognit Res Grp, D-67663 Kaiserslautern, Germany.	faisal.shafait@dfki.de; daniel.keysers@dfki.de; tmb@informatik.uni-kl.de	Shafait, Faisal/A-1342-2012	Shafait, Faisal/0000-0002-0922-0566				Antonacopoulos A, 2006, LECT NOTES COMPUT SC, V3872, P302; Antonacopoulos A, 2005, PROC INT CONF DOC, P75, DOI 10.1109/ICDAR.2005.184; Antonacopoulos A, 2003, PROC INT CONF DOC, P688; BAIRD HS, 1994, DOCUMENT IMAGE ANAL, P17; Breuel TM, 2002, LECT NOTES COMPUT SC, V2423, P188; Breuel TM, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P428, DOI 10.1109/IWFHR.2002.1030948; Breuel TM, 2003, P S DOC IM UND TECHN; BREUEL TM, 2002, P DOC REC RETR 8; Cattoni R., 1998, 970309 IRST; Cinque L, 2002, PATTERN RECOGN, V35, P1167, DOI 10.1016/S0031-3203(01)00082-6; Das A. K., 2002, International Journal on Document Analysis and Recognition, V4, P183, DOI 10.1007/s100320100060; DORI D, 1997, HDB CHARACTER RECOGN, P421; Ford G., 2003, P S DOC IM UND TECHN, P199; Guyon Isabelle, 1997, HDB CHARACTER RECOGN, P779; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909; Kanai J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P424, DOI 10.1109/ICDAR.1993.395703; Keysers D, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P44; Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684; Liang JS, 2001, COMPUT VIS IMAGE UND, V84, P144, DOI 10.1006/cviu.2001.0933; LOTTI F, 2004, DOCUMENT ANAL SYSTEM; Mandal S, 2006, INT J DOC ANAL RECOG, V8, P172, DOI 10.1007/s10032-005-0006-5; Mao S, 2003, PROC SPIE, V5010, P197, DOI 10.1117/12.476326; Mao S, 2001, IEEE T PATTERN ANAL, V23, P242, DOI 10.1109/34.910877; Mao S., 2002, INT J DOC ANAL RECOG, V4, P205; Marinai S, 2005, PROC INT CONF DOC, P432, DOI 10.1109/ICDAR.2005.150; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Okun O., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P621, DOI 10.1109/ICDAR.1999.791864; SHAFAIT F, 2007, P 2 INT WORKSH CAM B, P181; SHAFAIT F, 2006, P 7 IAPR WORKSH DOC, P368, DOI 10.1007/11669487_33; Shafait F, 2007, LECT NOTES COMPUT SC, V4522, P651; Shafait F, 2006, INT C PATT RECOG, P872; SHIN C, 1999, P S DOC IM UND TECHN, P166; Vincent L, 2007, PROC INT CONF DOC, P819; Wang YL, 2006, PATTERN RECOGN, V39, P57, DOI 10.1016/j.patcog.2005.06.009; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; Yanikoglu B. A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P601, DOI 10.1109/ICDAR.1995.601968	39	105	108	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					941	954		10.1109/TPAMI.2007.70837	http://dx.doi.org/10.1109/TPAMI.2007.70837			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421102				2022-12-18	WOS:000254872500002
J	O'Toole, AJ; Phillips, PJ; Jiang, F; Ayyad, J; Penard, N; Abdi, H				O'Toole, Alice J.; Phillips, P. Jonathon; Jiang, Fang; Ayyad, Janet; Penard, Nils; Abdi, Herve			Face recognition algorithms surpass humans matching faces over changes in illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face and gesture recognition; performance evaluation of algorithms and systems; human information processing		There has been significant progress in improving the performance of computer-based face recognition algorithms over the last decade. Although algorithms have been tested and compared extensively with each other, there has been remarkably little work comparing the accuracy of computer-based face recognition systems with humans. We compared seven state-of-the-art face recognition algorithms with humans on a face-matching task. Humans and algorithms determined whether pairs of face images, taken under different illumination conditions, were pictures of the same person or of different people. Three algorithms surpassed human performance matching face pairs prescreened to be "difficult" and six algorithms surpassed humans on "easy" face pairs. Although illumination variation continues to challenge face recognition algorithms, current algorithms compete favorably with humans. The superior performance of the best algorithms over humans, in light of the absolute performance levels of the algorithms, underscores the need to compare algorithms with the best current control-humans.	Univ Texas Dallas, Sch Behav & Brain Sci, Richardson, TX 75083 USA; NIST, Gaithersburg, MD 20899 USA	University of Texas System; University of Texas Dallas; National Institute of Standards & Technology (NIST) - USA	O'Toole, AJ (corresponding author), Univ Texas Dallas, Sch Behav & Brain Sci, GR4-1, Richardson, TX 75083 USA.	otoole@utdallas.edu; jonathon@nist.gov; fxj018100@utdallas.edu; jha011100@utdallas.edu; npenard@utdallas.edu; herve@utdallas.edu	Abdi, Hervé/G-6620-2011	O'Toole, Alice/0000-0001-7981-1508; Abdi, Herve/0000-0002-9522-1978				Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; BLACKBURN DM, 2001, FRVT 2000 EVALUATION; Braje WL, 1998, PSYCHOBIOLOGY, V26, P371; Braje WL, 2000, PERCEPTION, V29, P383, DOI 10.1068/p3051; Braje WL, 2003, J VISION, V3, P161, DOI 10.1167/3.2.4; Burton AM, 2005, COGNITIVE PSYCHOL, V51, P256, DOI 10.1016/j.cogpsych.2005.06.003; Gross R, 2005, HANDBOOK OF FACE RECOGNITION, P193, DOI 10.1007/0-387-27257-7_10; Hancock PJB, 2000, TRENDS COGN SCI, V4, P330, DOI 10.1016/S1364-6613(00)01519-9; Hill H, 1996, J EXP PSYCHOL HUMAN, V22, P986, DOI 10.1037/0096-1523.22.4.986; HUSKEN M, 2005, P IEEE WORKSH FAC RE; Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90; Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896; O'Toole A.J., 2006, FACE PROCESSING ADV; O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3; Phillips D, 2006, CHEM WORLD-UK, V3, P15; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P235, DOI 10.1109/AFGR.2002.1004160; PHILLIPS PJ, 2003, 6965 NISTIR; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353; Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414; Tarr MJ, 1998, COGNITION, V67, P1, DOI 10.1016/S0010-0277(98)00026-2; Troje NF, 1998, VISION RES, V38, P79, DOI 10.1016/S0042-6989(97)00165-X; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Xie CY, 2005, LECT NOTES COMPUT SC, V3723, P32; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	27	105	105	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1642	1646		10.1109/TPAMI.2007.1107	http://dx.doi.org/10.1109/TPAMI.2007.1107			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	189CD	17627050				2022-12-18	WOS:000247965600012
J	Wang, H				Wang, H			Nearest neighbors by neighborhood counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; nearest neighbors; distance; similarity; neighborhood counting measure	CLASSIFICATION	Finding nearest neighbors is a general idea that underlies many artificial intelligence tasks, including machine learning, data mining, natural language understanding, and information retrieval. This idea is explicitly used in the k- nearest neighbors algorithm ( kNN), a popular classification method. In this paper, this idea is adopted in the development of a general methodology, neighborhood counting, for devising similarity functions. We turn our focus from neighbors to neighborhoods, a region in the data space covering the data point in question. To measure the similarity between two data points, we consider all neighborhoods that cover both data points. We propose to use the number of such neighborhoods as a measure of similarity. Neighborhood can be defined for different types of data in different ways. Here, we consider one definition of neighborhood for multivariate data and derive a formula for such similarity, called neighborhood counting measure or NCM. NCM was tested experimentally in the framework of kNN. Experiments show that NCM is generally comparable to VDM and its variants, the state- of- the- art distance functions for multivariate data, and, at the same time, is consistently better for relatively large k values. Additionally, NCM consistently outperforms HEOM ( a mixture of Euclidean and Hamming distances), the " standard" and most widely used distance function for multivariate data. NCM has a computational complexity in the same order as the standard Euclidean distance function and NCM is task independent and works for numerical and categorical data in a conceptually uniform way. The neighborhood counting methodology is proven sound for multivariate data experimentally. We hope it will work for other types of data.	Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland; Univ Metz, LITA, F-57045 Metz, France	Ulster University; Universite de Lorraine	Wang, H (corresponding author), Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland.	h.wang@ulster.ac.uk		Wang, Hui/0000-0003-2633-6015				Ash RB., 2000, PROBABILITY MEASURE; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DOMINGOS P, 1995, P 1995 INT JOINT C A; DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P327; ELKAN C, 1999, RESULTS KDD 99 CLASS; Fix E., 1951, TR4 US AIR FORC SCH; Gardenfors P, 2004, CONCEPTUAL SPACES GE; HAND DJ, 2001, PRINCIPLES DATA MINI; HAYASHI H, 2001, OPTIMIZATION NEAREST; Mitchell T, 1997, MACHINE LEARING; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; Newman C. B. D., 1998, UCI REPOSITORY MACHI; OSBORNE H, 1997, P INT WORKSH SIM CAT, P173; RACHLIN J, 1994, P 11 INT C MACH LEAR, P242; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Snedecor GW, 2002, STAT METHODS; STANFILL C, 1986, COMMUN ACM, V29, P1229, DOI 10.1145/7902.7907; Stevens S.S., 1951, MATH MEASUREMENT PSY; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; Wang H, 2004, INT J APPROX REASON, V36, P223, DOI 10.1016/j.ijar.2003.10.007; Wikipedia Foundation, WIK FREE ENC; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1, DOI 10.1613/jair.346	29	105	114	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					942	953		10.1109/TPAMI.2006.126	http://dx.doi.org/10.1109/TPAMI.2006.126			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724588				2022-12-18	WOS:000236734400008
J	Kwon, H; Nasrabadi, NM				Kwon, H; Nasrabadi, NM			Kernel matched subspace detectors for hyperspectral target detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						target detection; subspace detectors; matched signal detectors; kernel-based learning; hyperspectral data; spectral mixture models; nonlinear detection	CLASSIFICATION; PATTERN	In this paper, we present a kernel realization of a matched subspace detector (MSD) that is based on a subspace mixture model defined in a high-dimensional feature space associated with a kernel function. The linear subspace mixture model for the MSD is first reformulated in a high-dimensional feature space and then the corresponding expression for the generalized likelihood ratio test (GLRT) is obtained for this model. The subspace mixture model in the feature space and its corresponding GLRT expression are equivalent to a nonlinear subspace mixture model with a corresponding nonlinear GLRT expression in the original input space. In order to address the intractability of the GLRT in the feature space, we kernelize the GLRT expression using the kernel eigenvector representations as well as the kernel trick where dot products in the feature space are implicitly computed by kernels. The proposed kernel-based nonlinear detector, so-called kernel matched subspace detector (KMSD), is applied to several hyperspectral images to detect targets of interest. KMSD showed superior detection performance over the conventional MSD when tested on several synthetic data and real hyperspectral imagery.	USA, Res Lab, ATTN, AMSRD ARL SE SE, Adelphi, MD 20783 USA	United States Department of Defense; US Army Research, Development & Engineering Command (RDECOM); US Army Research Laboratory (ARL)	Kwon, H (corresponding author), USA, Res Lab, ATTN, AMSRD ARL SE SE, 2800 Powder Mill Rd, Adelphi, MD 20783 USA.	hkwon@arl.army.mil						[Anonymous], 2002, LEARNING KERNELS; Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Chang CI, 1998, IEEE T GEOSCI REMOTE, V36, P898, DOI 10.1109/36.673681; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Healey G, 1999, IEEE T GEOSCI REMOTE, V37, P2706, DOI 10.1109/36.803418; Kwon H, 2005, IEEE T GEOSCI REMOTE, V43, P388, DOI 10.1109/TGRS.2004.841487; Kwon H, 2004, P SOC PHOTO-OPT INS, V5806, P827; Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107; Ruiz A, 2001, IEEE T NEURAL NETWOR, V12, P16, DOI 10.1109/72.896793; SCHARF LL, 1994, IEEE T SIGNAL PROCES, V42, P2146, DOI 10.1109/78.301849; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; STRANG G, 1986, LINEAR ALGEBRA ITS A; Thai B, 2002, IEEE T GEOSCI REMOTE, V40, P599, DOI 10.1109/TGRS.2002.1000320; Van Trees H. L, 2004, DETECTION ESTIMATION; Vapnik V.N., 1999, NATURE STAT LEARNING; Williamson RC, 2001, IEEE T INFORM THEORY, V47, P2516, DOI 10.1109/18.945262	22	105	111	3	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					178	194		10.1109/TPAMI.2006.39	http://dx.doi.org/10.1109/TPAMI.2006.39			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468616				2022-12-18	WOS:000233824500002
J	Wang, HZ; Suter, D				Wang, HZ; Suter, D			Robust adaptive-scale parametric model estimation for computer vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust model fitting; random sample consensus; least-median-of-squares; residual consensus; adaptive least kth order squares; kernel density estimation; mean shift; range image segmentation; fundamental matrix estimation	RANGE IMAGE SEGMENTATION; MEAN SHIFT	Robust model fitting essentially requires the application of two estimators. The first is an estimator for the values of the model parameters. The second is an estimator for the scale of the noise in the (inlier) data. Indeed, we propose two novel robust techniques: the Two-Step Scale estimator (TSSE) and the Adaptive Scale Sample Consensus (ASSC) estimator. TSSE applies nonparametric density estimation and density gradient estimation techniques, to robustly estimate the scale of the inliers. The ASSC estimator combines Random Sample Consensus (RANSAC) and TSSE: using a modified objective function that depends upon both the number of inliers and the corresponding scale. ASSC is very robust to discontinuous signals and data with multiple structures, being able to tolerate more than 80 percent outliers. The main advantage of ASSC over RANSAC is that prior knowledge about the scale of inliers is not needed. ASSC can simultaneously estimate the parameters of a model and the scale of the inliers belonging to that model. Experiments on synthetic data show that ASSC has better robustness to heavily corrupted data than Least Median Squares (LMedS), Residual Consensus (RESC), and Adaptive Least Kth order Squares (ALKS). We also apply ASSC to two fundamental computer vision tasks: range image segmentation and robust fundamental matrix estimation. Experiments show very promising results.	Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia	Monash University	Wang, HZ (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia.	hanzi.wang@eng.monash.edu.au; d.suter@eng.monash.edu.au	Wang, Hanzi/F-8796-2012	Suter, David/0000-0001-6306-3023				Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812; Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; CHEN H, 2003, P 9 INT C COMP VIS; CHEN H, 2001, P 2001 IEEE C COMP V; Chen HF, 2002, LECT NOTES COMPUT SC, V2350, P236; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; COMANICIU D, 2002, P EUR C COMP VIS ECC; COMANICIU D, 2001, P 8 INT C COMP VIS; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GOTARDO PFU, 2003, P IEEE C COMP VIS PA; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Huber P., 1981, ROBUST STAT; Koster K, 2000, IEEE T PATTERN ANAL, V22, P430, DOI 10.1109/34.857001; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; MILLER JV, 1996, P C COMP VIS PATT RE; Ong EP, 1999, INT J COMPUT VISION, V31, P51, DOI 10.1023/A:1008046826441; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Scott DW, 2001, TECHNOMETRICS, V43, P274, DOI 10.1198/004017001316975880; SIEGEL AF, 1982, BIOMETRIKA, V69, P242, DOI 10.1093/biomet/69.1.242; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280; TERRELL GR, 1985, J AM STAT ASSOC, V80, P209, DOI 10.2307/2288074; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Wand M.P., 1995, KERNEL SMOOTHING; Wang H, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P178; WANG H, IN PRESS INT J COMPU; WANG H, 2003, DIGITAL IMAGE COMPUT, P581; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	40	105	114	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1459	1474		10.1109/TPAMI.2004.109	http://dx.doi.org/10.1109/TPAMI.2004.109			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521494				2022-12-18	WOS:000223737000006
J	Toh, KA; Tran, QL; Srinivasan, D				Toh, KA; Tran, QL; Srinivasan, D			Benchmarking a reduced multivariate polynomial pattern classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; parameter estimation; pattern recognition; multivariate polynomials; machine learning	STATISTICAL CLASSIFIERS; GLOBAL OPTIMIZATION; SINGLE NEURON; COMPLEXITY; EVOLUTION; NETWORKS	A novel method using a reduced multivariate polynomial model has been developed for biometric decision fusion where simplicity and ease of use could be a concern. However, much to our surprise, the reduced model was found to have good classification accuracy for several commonly used data sets from the Web. In this paper, we extend the single output model to a multiple outputs model to handle multiple class problems. The method is particularly suitable for problems with small number of features and large number of examples. Basic component of this polynomial model boils down to construction of new pattern features which are sums of the original features and combination of these new and original features using power and product terms. A linear regularized least-squares predictor is then built using these constructed features. The number of constructed feature terms varies linearly with the order of the polynomial, instead of having a power law in the case of full multivariate polynomials. The method is simple as it amounts to only a few lines of Matlab code. We perform extensive experiments on this reduced model using 42 data sets. Our results compared remarkably well with best reported results of several commonly used algorithms from the literature. Both the classification accuracy and efficiency aspects are reported for this reduced model.	Inst Infocomm Res, Singapore 119613, Singapore; Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); National University of Singapore	Toh, KA (corresponding author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	katoh@i2r.a-star.edu.sg; qltran@i2r.a-star.edu.sg; dipti@nus.edu.sg	Srinivasan, Dipti/D-1736-2016	Srinivasan, Dipti/0000-0003-4877-3478				Bishop, 1995, NEURAL NETWORKS PATT; BLAKE CL, 1998, UCI RESPOSITORY MACH; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Brazdil P, 1999, STATLOG DATASETS; CAMPBELL W, 2000, P INT C MACH LEARN J; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; HORNIK H, 2002, NEURAL NETWORKS, V2, P359; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075, DOI 10.1109/TPAMI.2002.1023804; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; *MATHWORKS, 2003, MATL SIM; Neter J., 1996, APPL LINEAR REGRESSI; PEDERSON L, 1988, STATLIB CASE STUDIES; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; PRECUP D, 2003, MACHINE LEARNING; Raudys S, 1998, NEURAL NETWORKS, V11, P297, DOI 10.1016/S0893-6080(97)00136-6; Raudys S, 1998, NEURAL NETWORKS, V11, P283, DOI 10.1016/S0893-6080(97)00135-4; Scholkopf B., 2001, LEARNING KERNELS SUP; SHIN Y, 1995, IEEE T NEURAL NETWOR, V6, P610, DOI 10.1109/72.377967; Shin Y., 1991, P INT JOINT C NEUR N, V1, P13, DOI DOI 10.1109/IJCNN.1991.155142; Toh KA, 2003, IEEE T SYST MAN CY B, V33, P977, DOI 10.1109/TSMCB.2002.804366; Toh KA, 2002, COMPUT OPTIM APPL, V23, P77, DOI 10.1023/A:1019976724755; TOH KA, 2004, IEEE T CIRCUITS SYST; TORN A, 1989, LECT NOTES COMPUT SC, V350, P1; Wade W. R., 2000, INTRO ANAL	28	105	105	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					740	755		10.1109/TPAMI.2004.3	http://dx.doi.org/10.1109/TPAMI.2004.3			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579935				2022-12-18	WOS:000220756500008
J	Almansa, A; Desolneux, A; Vamech, S				Almansa, A; Desolneux, A; Vamech, S			Vanishing point detection without any a priori information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vanishing point; perceptual grouping; Gestalt theory; Helhmotz principle		Even though vanishing points in digital images result from parallel lines in the 3D scene, most of the proposed detection algorithms are forced to rely heavily either on additional properties (like orthogonality or coplanarity and equal distance) of the underlying 3D lines, or on knowledge of the camera calibration parameters, in order to avoid spurious responses. In this work, we develop a new detection algorithm that relies on the Helmoltz principle recently proposed for computer vision by Desolneux et al. [8], [9], both at the line detection and line grouping stages. This leads to a vanishing point detector with a low false alarms rate and a high precision level, which does not rely on any a priori information on the image or calibration parameters, and does not require any parameter tuning.	ENS Cachan, CMLA, F-74235 Cachan, France; UFR Math Info, F-75270 Paris 06, France	UDICE-French Research Universities; Universite Paris Saclay	Almansa, A (corresponding author), ENS Cachan, CMLA, 61 Ave President Wilson, F-74235 Cachan, France.	almansa@cmla.ens-cachan.fr; desolneux@math-info.univ-paris5.fr; vamech@cmla.ens-cachan.fr	Almansa, Andres/A-4152-2008	Almansa, Andres/0000-0001-8196-1329				ALMANSA A, 2002, THESIS ENS CACHAN FR; ALMANSA A, 2000, CMLA200124 CMLA ENS; AMIT Y, 1999, NEURAL COMPUTATION; Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; DESOLNEUX A, 2000, 200023 CMLA ENS CACH; DESOLNEUX A, 2002, 2000206 CMLA; Kanizsa G., 1980, GRAMMATICA VEDERE; LIEBOWITZ D, 1999, EUROGRAPHICS, V18; LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598; PAPADOPOULO T, 1996, ENABLING TECHNOLOGIE; ROTHER G, 2000, P BRIT MACH VIS C; RUDIN L, 1995, P INV TRIAL IM PROC; Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4; Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P282, DOI 10.1109/34.754631; SNTALO LA, 1976, ENCY MATH ITS APPL, V1; TUYTELAARS T, 1997, P INT C IM PROC ICIP, V2, P736; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640	23	105	117	2	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					502	507		10.1109/TPAMI.2003.1190575	http://dx.doi.org/10.1109/TPAMI.2003.1190575			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV		Green Submitted			2022-12-18	WOS:000181758100010
J	Myers, R; Wilson, RC; Hancock, ER				Myers, R; Wilson, RC; Hancock, ER			Bayesian graph edit distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph matching; edit-distance; Bayesian; MAP estimation; stereo images	PATTERN-RECOGNITION; COMPUTATION; RELAXATION	This paper describes a novel framework for comparing and matching corrupted relational graphs. The paper develops the idea of edit-distance originally introduced for graph-matching by Sanfeliu and Fu [1]. We show how the Levenshtein distance can be used to model the probability distribution for structural errors in the graph-matching problem. This probability distribution is used to locate matches using MAP label updates. We compare the resulting graph-matching algorithm with that recently reported by Wilson and Hancock. The use of edit-distance offers an elegant alternative to the exhaustive compilation of label dictionaries. Moreover, the method is polynomial rather than exponential in its worst-case complexity. We support our approach with an experimental study on synthetic data and illustrate its effectiveness on an uncalibrated stereo correspondence problem. This demonstrates experimentally that the gain in efficiency is not at the expense of quality of match.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England; Praxis Crit Syst Ltd, Bath BA1 1PX, Avon, England	University of York - UK	Myers, R (corresponding author), Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England.		Hancock, Edwin R/C-6071-2008; Hancock, Edwin/N-7548-2019	Hancock, Edwin R/0000-0003-4496-2028; Hancock, Edwin/0000-0003-4496-2028				BARROW HG, 1971, MACHINE INTELLIGENCE, V6; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3; BUNKE H, 1995, IEEE T SYST MAN CYB, V25, P202, DOI 10.1109/21.362950; Bunke H, 1999, IEEE T PATTERN ANAL, V21, P917, DOI 10.1109/34.790431; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MESSMER BT, 1994, SHAPE STRUCTURE PATT; Myers R, 1997, PATTERN RECOGN LETT, V18, P1363, DOI 10.1016/S0167-8655(97)00111-6; MYERS R, 1998, LECT NOTES COMPUTER, V1451, P159; Oommen BJ, 1996, IEEE T PATTERN ANAL, V18, P669, DOI 10.1109/34.506420; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7, P90, DOI 10.1109/TPAMI.1985.4767621; Shewchuk J, 1996, P 1 WORKSH APPL COMP, P124; TANG YC, 1992, IEEE T SYST MAN CYB, V22, P115, DOI 10.1109/21.141316; VIDAL E, 1995, IEEE T PATTERN ANAL, V17, P899, DOI 10.1109/34.406656; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WILSON R, 1995, THESIS U YORK; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WONG AKC, 1980, IEEE T PATTERN ANAL, V2, P341, DOI 10.1109/TPAMI.1980.4767033; ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082; Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866	29	105	112	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					628	635		10.1109/34.862201	http://dx.doi.org/10.1109/34.862201			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE		Green Submitted, Green Accepted			2022-12-18	WOS:000088667700008
J	Merlet, N; Zerubia, J				Merlet, N; Zerubia, J			New prospects in line detection by dynamic programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line detection; energy minimization; dynamic programming; curvature; satellite images	FEATURE-EXTRACTION; EDGE	The detection of lines in satellite images has drawn a lot of attention within the last 15 years. Problems of resolution, noise, and image understanding are involved, and one of the best methods developed so far is the F* algorithm of Fischler, which achieves robustness, rightness, and rapidity. Like other methods of dynamic programming, it consists of defining a cost which depends on local information; then a summation-minimization process in the image is performed. We present herein a mathematical formalization of the F* algorithm, which allows us to extend the cost both to cliques of more than two points (to deal with the contrast), and to neighborhoods of size larger than one (to take into account the curvature). Thus, all the needed information (contrast, grey-level, curvature) is synthesized in a unique cost function defined on the digital original image. This cost is used to detect roads and valleys in satellite images (SPOT).	INRIA,F-06902 SOPHIA ANTIPOLIS,FRANCE	Inria	Merlet, N (corresponding author), HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL.							BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; COX IJ, 1993, INT J COMPUT VISION, V11, P5, DOI 10.1007/BF01420590; FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3; GEMAN D, 1991, P IGARSS ESPOO; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MCKEOWN DM, 1988, P CVPR; MERLET N, 1994, P ICASSP ADEL; MERLET N, 1993, 1889 INRIA HEBREW U; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115	10	105	121	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					426	431		10.1109/34.491623	http://dx.doi.org/10.1109/34.491623			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500007
J	SHUM, HY; IKEUCHI, K; REDDY, R				SHUM, HY; IKEUCHI, K; REDDY, R			PRINCIPAL COMPONENT ANALYSIS WITH MISSING DATA AND ITS APPLICATION TO POLYHEDRAL OBJECT MODELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; 3D OBJECT MODELING; MULTIPLE VIEW MERGING; RANGE IMAGE PROCESSING; PRINCIPAL COMPONENT ANALYSIS	3-D OBJECTS; REPRESENTATION; RECOGNITION; SHAPE	Observation-based object modeling often requires integration of shape descriptions from different views. In current conventional methods, to sequentially merge multiple views, an accurate description of each surface patch has to be precisely known in each view, and the transformation between adjacent views needs to be accurately recovered. When noisy data and mismatches are present, the recovered transformation become erroneous. In addition, the transformation errors accumulate and propagate along the sequence, resulting in an inaccurate object model. To overcome these problems, we have developed a weighted least-squares (WLS) approach which simultaneously recovers object shape and transformation among different views without recovering interframe motion as an intermediate step. We show that object modeling from a sequence of range images is a problem of principal component analysis with missing data (PCAMD), which can be generalized as a WLS minimization problem. An efficient algorithm is devised to solve the problem of PCAMD, After we have segmented planar surface regions in each view and tracked them over the image sequence, we construct a normal measurement matrix of surface normals, and a distance measurement matrix of normal distances to the origin for all visible regions appeared over the whole sequence of views, respectively. These two measurement matrices, which have many missing elements due to noise, occlusion, and mismatching, enable us to formulate multiple view merging as a combination of two WLS problems. A two-step algorithm is presented to computer planar surface descriptions and transformations among different views simultaneously, After surface equations are extracted, spatial connectivity among these surfaces is established to enable the polyhedral object model to be constructed. Experiments using synthetic data and real range images show that our approach is robust against noise and mismatching and generates accurate polyhedral object models by averaging over all visible surfaces. Two examples are presented to illustrate the reconstruction of polyhedral object models from sequences of real range images.			SHUM, HY (corresponding author), CARNEGIE MELLON UNIV,INST ROBOT,DEPT COMP SCI,PITTSBURGH,PA 15213, USA.							AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; DEBRUNNER C, 1992, P 2 EUR C COMP VIS, P217; DOBKIN D, 1993, ALGORITHMICA, V10, P1, DOI 10.1007/BF01908629; Dodge Y., 1985, ANAL EXPT MISSING DA; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Ferrie F. P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P117; Golub G. H., 1996, MATRIX COMPUTATIONS; IKEUCHI K, 1987, INT J COMPUT VISION, P145; PARVIN B, 1992, MAY P IEEE INT C R A, P1602; POELMAN C, 1992, CMUCS92208; RUHE A, 1974, UMINF4874 UM U DEP I; Shamos, 1988, COMPUTATIONAL GEOMET; Soucy M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P348, DOI 10.1109/CVPR.1992.223166; Sugihara K., 1986, MACHINE INTERPRETATI; SZELISKI R, 1993, DEC CRL933; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VEMURI BC, 1986, JUN P C COMP VIS PAT, P435; WIBERG T, 1976, 2 S COMP STAT, P229	22	105	108	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					854	867		10.1109/34.406651	http://dx.doi.org/10.1109/34.406651			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900003
J	LEUNG, MK; YANG, YH				LEUNG, MK; YANG, YH			FIRST SIGHT - A HUMAN-BODY OUTLINE LABELING SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COINCIDENCE EDGE; DIFFERENCE PICTURE; HUMAN BODY; HUMAN BODY MODEL; LABELING; MODEL; MOTION; OUTLINE; POSE; POSTURE; RIBBON; STICK FIGURE	CURVED OBJECTS; MOTION; REPRESENTATIONS; SYMMETRIES; EXTRACTION; IMAGES	First Sight, a vision system in labeling the outline of a moving human body, is proposed in this paper. The emphasis of First Sight is on the analysis of motion information gathered solely from the outline of a moving human object. Two main processes are implemented in First Sight. The first process uses a novel technique to extract the outline of a moving human body from an image sequence. The second process, which employs a new human body model, interprets the outline and produces a labeled two-dimensional human body stick figure for each frame of the image sequence. Extensive knowledge of the structure, shape, and posture of the human body is used in the model. The experimental results of applying the technique on unedited image sequences with self-occlusions and missing boundary lines are encouraging.	UNIV SASKATCHEWAN,DEPT COMP SCI,COMP VIS LAB,SASKATOON,SK S7N 0W0,CANADA	University of Saskatchewan	LEUNG, MK (corresponding author), NANYANG TECHNOL UNIV,SCH APPL SCI,DIV COMP ENGN,SINGAPORE 2263,SINGAPORE.							Aggarwal J. K., 1981, Progress in pattern recognition. Vol.1, P377; AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; AKITA K, 1984, PATTERN RECOGN, V17, P73, DOI 10.1016/0031-3203(84)90036-0; BADLER NI, 1979, P IEEE, V67, P1397, DOI 10.1109/PROC.1979.11475; BADLER NI, 1979, COMPUT SURV, V11, P19, DOI 10.1145/356757.356760; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BROOKS RA, 1979, P DARPA IMAGE UNDERS, P72; DIFRANCO D, 1980, THESIS QUEENS U KING; HERMAN M, 1979, THESIS U MARYLAND; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; HOGG D, 1988, J PARALLEL ARCHITECT, P119; JAIN R, 1981, IEEE T PATTERN ANAL, V3, P489, DOI 10.1109/TPAMI.1981.4767143; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; KLANDERMAN GA, 1993, IEEE T PATTERN ANAL, V15, P850; Laban R., 1975, LABANS PRINCIPLES DA; LEE HJ, 1984, THESIS NATL C TUNG U; LEUNG MK, 1987, PATTERN RECOGN, V20, P321, DOI 10.1016/0031-3203(87)90007-0; LEUNG MK, 1987, PATTERN RECOGN, V20, P55, DOI 10.1016/0031-3203(87)90017-3; LEUNG MK, 1992, THESIS U SASKATCHEWA; LONG W, 1990, PATTERN RECOGN, V23, P1351, DOI 10.1016/0031-3203(90)90081-U; Long W., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P439, DOI 10.1142/S0218001491000259; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; RAO K, 1988, INT J COMPUT VISION, V2, P33, DOI 10.1007/BF00836280; RASHID RF, 1980, IEEE T PATTERN ANAL, V2, P574, DOI 10.1109/TPAMI.1980.6447705; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1; RUCKLIDGE WJ, 1992, COMPUTER VISION PATT, P654; WEBB JA, 1981, COMPUTER, V14, P40, DOI 10.1109/C-M.1981.220561; YANG YH, 1992, MACH VISION APPL, V5, P17	34	105	116	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					359	377		10.1109/34.385981	http://dx.doi.org/10.1109/34.385981			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800004
J	KRIEGMAN, DJ; PONCE, J				KRIEGMAN, DJ; PONCE, J			ON RECOGNIZING AND POSITIONING CURVED 3-D OBJECTS FROM IMAGE CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,ROBOT LAB,STANFORD,CA 94305	Stanford University								BAJCSY R, 1987, 1ST P INT C COMP VIS, P231; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; BOLLES RC, 1984, ROBOTICS RES, P413; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BUCHBERGER B, 1987, TRENDS COMPUTER ALGE, P52; Callahan J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P240; Canny, 1988, COMPLEXITY ROBOT MOT; CANNY J, 1985, FINDING LINES EDGES, P240; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; CRYLUK D, 1988, APR P IM UND WORKSH, P731; DIXON A, 1908, P LONDON MATH SOC 2, V7; EGGERT D, 1989, NOV P IEEE WORKSH IN, P102; FAN TJ, 1988, APR P IEEE INT C ROB, P1400; FAROUKI RT, 1987, IBM J RES DEV, V31, P314, DOI 10.1147/rd.313.0314; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Gigus Z., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P30, DOI 10.1109/CCV.1988.589969; Goldman RN, 1985, VISUAL COMPUT, V1, P101, DOI 10.1007/BF01898352; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1989, IEEE T PATTERN ANAL, V11, P632, DOI 10.1109/34.24797; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; HEBERT M, 1985, JUN P IEEE C COMP VI; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; HORAUD R, 1987, JUN P INT C COMP VIS; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; IKEUCHI K, 1987, FEB P DARPA IM UND W, P321; JERIAN C, 1988, DEC P INT C COMP VIS, P197; KAJIYA JT, 1982, JUL P SIGGRAPH 82, P245; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Koenderink J. J., 1984, PERCEPTION, V13; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN D, IN PRESS INT COMP VI; KRIEGMAN D, 1988, APR P IEEE INT C ROB; KRIEGMAN D, 1989, NOV P IEEE WORKSH IN; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; Macaulay F.S., 1916, ALGEBRAIC THEORY MOD; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Marr D., 1982, VISION; NALWA V, 1987, FEB P IM UND WORKSH, P956; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PENTLAND A, 1986, SRI406 TECH NOT; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1987, INT J COMPUT VISION, V1; PONCE J, 1989, P IEEE INT C ROBOT A; PONCE J, 1990, JUL P AM ASS ART INT; Press WH, 1988, NUMERICAL RECIPES C; RIEGER J, 1987, IMAGE VISION COMPUT, V1, P91; SALMON G, 1866, MODERN HIGHER ALGEBR; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; Shafer S. A., 1985, SHADOWS SILHOUETTES; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; ULUPINAR F, 1988, DEC INT C COMP VIS T, P414; [No title captured]; [No title captured]	57	105	107	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1127	1137		10.1109/34.62602	http://dx.doi.org/10.1109/34.62602			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000001
J	HUANG, TS; LEE, CH				HUANG, TS; LEE, CH			MOTION AND STRUCTURE FROM ORTHOGRAPHIC PROJECTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									PURDUE UNIV,DEPT COMP SCI,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	HUANG, TS (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							ALOIMONOS J, 1986, JUN P IEEE C COMP VI, P510; HUANG TS, 1986, MOTION STRUCTURE ORT; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009	3	105	111	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					536	541		10.1109/34.24786	http://dx.doi.org/10.1109/34.24786			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400009
J	JAIN, AK; DUBES, RC; CHEN, CC				JAIN, AK; DUBES, RC; CHEN, CC			BOOTSTRAP TECHNIQUES FOR ERROR ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											JAIN, AK (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; Devijver PA, 1982, PATTERN RECOGNITION; DIACONIS P, 1983, SCI AM, V248, P116, DOI 10.1038/scientificamerican0583-116; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; Duda R.O., 1973, J ROYAL STAT SOC SER; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; Efron B., 1982, CBMS NSF REGIONAL C, V38; Efron B., 1981, CANADIAN J STATISTIC, V9, P139, DOI [10.1093/jtm/taab016, DOI 10.1093/jtm/taab016]; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; LACHENBRUCH P, 1968, TECHNOMETRICS, V10, P167; MORRISON DF, 1976, MULTIVARIATE STATIST	14	105	108	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					628	633		10.1109/TPAMI.1987.4767957	http://dx.doi.org/10.1109/TPAMI.1987.4767957			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869421				2022-12-18	WOS:A1987J739300004
J	NEGAHDARIPOUR, S; HORN, BKP				NEGAHDARIPOUR, S; HORN, BKP			DIRECT PASSIVE NAVIGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV HAWAII,DEPT ELECT ENGN,HONOLULU,HI 96822	University of Hawaii System	NEGAHDARIPOUR, S (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.			/0000-0003-3434-391X				BARRON J, 1984, RBCVTR845 U TOR TOR; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; HAY JC, 1966, PSYCHOL REV, V73, P550, DOI 10.1037/h0023863; HILDRETH E, 1983, MEASUREMENT VISUAL M; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MAYBANK SJ, 1984, 6TH P EUR C ART INT, P641; NEGAHDARIPOUR S, 1985, MIT AI821 MEM; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30; TSAI RY, 1984, IEEE T PATTERN ANAL, V6	10	105	110	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					168	176		10.1109/TPAMI.1987.4767884	http://dx.doi.org/10.1109/TPAMI.1987.4767884			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869389	Green Submitted			2022-12-18	WOS:A1987F378500017
J	Vagharshakyan, S; Bregovic, R; Gotchev, A				Vagharshakyan, Suren; Bregovic, Robert; Gotchev, Atanas			Light Field Reconstruction Using Shearlet Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image-based rendering; light field reconstruction; shearlets; frames; view synthesis	IMAGE; REPRESENTATIONS	In this article we develop an image based rendering technique based on light field reconstruction from a limited set of perspective views acquired by cameras. Our approach utilizes sparse representation of epipolar-plane images (EPI) in shearlet transform domain. The shearlet transform has been specifically modified to handle the straight lines characteristic for EPI. The devised iterative regularization algorithm based on adaptive thresholding provides high-quality reconstruction results for relatively big disparities between neighboring views. The generated densely sampled light field of a given 3D scene is thus suitable for all applications which require light field reconstruction. The proposed algorithm compares favorably against state of the art depth image based rendering techniques and shows superior performance specifically in reconstructing scenes containing semi-transparent objects.	[Vagharshakyan, Suren; Bregovic, Robert; Gotchev, Atanas] Tampere Univ Technol, Dept Signal Proc, Tampere 33720, Finland	Tampere University	Vagharshakyan, S (corresponding author), Tampere Univ Technol, Dept Signal Proc, Tampere 33720, Finland.	suren.vagharshakyan@tut.fi; robert.bregovic@tut.fi; atanas.gotchev@tut.fi	Gotchev, Atanas/A-5049-2010	Gotchev, Atanas/0000-0003-2320-1000; Vagharshakyan, Suren/0000-0003-1687-2391; Bregovic, Robert/0000-0002-3878-7588	PROLIGHT-IAPP Marie Curie Action of the People programme of the European Unions Seventh Framework Programme, REA grant [32449]; Academy of Finland [137012]	PROLIGHT-IAPP Marie Curie Action of the People programme of the European Unions Seventh Framework Programme, REA grant; Academy of Finland(Academy of Finland)	The research leading to these results has received funding from the PROLIGHT-IAPP Marie Curie Action of the People programme of the European Unions Seventh Framework Programme, REA grant agreement 32449 and from the Academy of Finland, grant No. 137012: High-Resolution Digital Holography: A Modern Signal Processing Approach.	Adelson E., 1991, COMPUT MODELS VISUAL; Blender Online Community, 2015, BLEND 3D MOD REND PA; Blumensath T, 2010, IEEE J-STSP, V4, P298, DOI 10.1109/JSTSP.2010.2042411; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Candes E., 1999, CURVELETS SURPRISING; Candes EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116; Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932; Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376; Donoho DL, 2001, CONSTR APPROX, V17, P353, DOI 10.1007/s003650010032; Easley GR, 2006, CONF REC ASILOMAR C, P974, DOI 10.1109/ACSSC.2006.354897; Fadili JM, 2010, COMPUT SCI ENG, V12, P44, DOI 10.1109/MCSE.2010.14; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Hauser S., 2014, ARXIV12021773V2; Hauser S, 2012, SEISMIC DATA RECONST; Heber S, 2016, PROC CVPR IEEE, P3746, DOI 10.1109/CVPR.2016.407; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Jurik J., 2012, 2012 IEEE COMP SOC C, P9; Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251; Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]; Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926; Kutyniok G, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-8316-0; Kutyniok G, 2016, ACM T MATH SOFTWARE, V42, DOI 10.1145/2740960; Kutyniok G, 2011, J APPROX THEORY, V163, P1564, DOI 10.1016/j.jat.2011.06.005; Laine A. F., 2005, P SPIE C SER, V5914, DOI DOI 10.1117/12.615237; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Liang CK, 2011, IEEE T IMAGE PROCESS, V20, P446, DOI 10.1109/TIP.2010.2063036; Lim WQ, 2013, IEEE T IMAGE PROCESS, V22, P2056, DOI 10.1109/TIP.2013.2244223; Lin ZC, 2004, INT J COMPUT VISION, V58, P121, DOI 10.1023/B:VISI.0000015916.91741.27; Mallat S., 2008, WAVELET TOUR SIGNAL; Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256; Pearson J, 2013, IEEE T IMAGE PROCESS, V22, P3405, DOI 10.1109/TIP.2013.2268939; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Schedl David C, 2015, IEEE ICCP, P1, DOI DOI 10.1109/ICCPHOT.2015.7168365; Shum H. Y., 2007, IMAGE BASED RENDERIN; Sinha SN, 2014, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2014.205; Smirnov S., 2013, P IEEE INT C MULT EX, P1; Stewart J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P150; Tanimoto M., 2009, ISOIECJTC1SC29WG11M; Tanimoto M., 2009, JTC1SC29WG11M ISOIEC; Tanimoto M, 2009, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2009.5202803; Tosic I, 2014, IEEE COMPUT SOC CONF, P441, DOI 10.1109/CVPRW.2014.71; Toyohiro S., 2015, NAGOYA U MULTIVIEW S; Vagharshakyan S, 2015, IEEE IMAGE PROC, P1379, DOI 10.1109/ICIP.2015.7351026; Vaish V., 2008, NEW STANFORD LIGHT F; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Yucer K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2876504; Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52	49	104	108	3	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					133	147		10.1109/TPAMI.2017.2653101	http://dx.doi.org/10.1109/TPAMI.2017.2653101			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28092525	Green Submitted			2022-12-18	WOS:000417806000011
J	Gopalan, R; Li, RN; Chellappa, R				Gopalan, Raghuraman; Li, Ruonan; Chellappa, Rama			Unsupervised Adaptation Across Domain Shifts by Generating Intermediate Data Representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain adaptation; unsupervised; Grassmann manifold; object recognition	OBJECT RECOGNITION; MANIFOLDS; GEOMETRY	With unconstrained data acquisition scenarios widely prevalent, the ability to handle changes in data distribution across training and testing data sets becomes important. One way to approach this problem is through domain adaptation, and in this paper we primarily focus on the unsupervised scenario where the labeled source domain training data is accompanied by unlabeled target domain test data. We present a two-stage data-driven approach by generating intermediate data representations that could provide relevant information on the domain shift. Starting with a linear representation of domains in the form of generative subspaces of same dimensions for the source and target domains, we first utilize the underlying geometry of the space of these subspaces, the Grassmann manifold, to obtain a 'shortest' geodesic path between the two domains. We then sample points along the geodesic to obtain intermediate cross-domain data representations, using which a discriminative classifier is learnt to estimate the labels of the target data. We subsequently incorporate non-linear representation of domains by considering a Reproducing Kernel Hilbert Space representation, and a low-dimensional manifold representation using Laplacian Eigenmaps, and also examine other domain adaptation settings such as (i) semi-supervised adaptation where the target domain is partially labeled, and (ii) multi-domain adaptation where there could be more than one domain in source and/or target data sets. Finally, we supplement our adaptation technique with (i) fine-grained reference domains that are created by blending samples from source and target data sets to provide some evidence on the actual domain shift, and (ii) a multi-class boosting analysis to obtain robustness to the choice of algorithm parameters. We evaluate our approach for object recognition problems and report competitive results on two widely used Office and Bing adaptation data sets.	[Gopalan, Raghuraman] AT&T Labs Res, Multimedia Technol Res Dept, Middletown, NJ 07748 USA; [Li, Ruonan] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA; [Chellappa, Rama] Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA	AT&T; Harvard University; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Gopalan, R (corresponding author), AT&T Labs Res, Multimedia Technol Res Dept, Middletown, NJ 07748 USA.	raghuram@research.att.com; ruonanli@seas.harvard.edu; rama@umiacs.umd.edu	Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020		MURI from the Office of Naval Research [1141221258513]	MURI from the Office of Naval Research	The authors thank the reviewers for their insightful comments and valuable suggestions that improve the quality of this manuscript. Partially supported by a MURI from the Office of Naval Research under the Grant 1141221258513.	Absil PA, 2004, ACTA APPL MATH, V80, P199, DOI 10.1023/B:ACAP.0000013855.14971.91; [Anonymous], 2007, P 15 ACM INT C MULTI; [Anonymous], 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587733; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Ben-David Shai, 2007, NEURIPS, P7; Benbouzid D, 2012, J MACH LEARN RES, V13, P549; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Blitzer J., 2007, ADV NEURAL INFORM PR, V20, P129; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Blitzer J., 2011, PROC INT C ARTIF INT, P173; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Chen M., 2011, ADV NEURAL INF PROCE, P2456; CHIKUSE Y, 2003, LECT NOTES STAT, V174; Dai Wenyuan, 2007, AAAI, P540; Dredze M., 2008, PROC C EMPIRICALMETH, P689; Duan L., 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411; Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Gallivan KA, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P315; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564; Hoffman J, 2012, LECT NOTES COMPUT SC, V7573, P702, DOI 10.1007/978-3-642-33709-3_50; Japkowicz N., 2002, Intelligent Data Analysis, V6, P429; Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924; Jiang J., 2008, LIT SURVEY DOMAIN AD; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kumar A., 2010, ADV NEURAL INFORM PR, V23, P478; Lai K, 2010, INT J ROBOT RES, V29, P1019, DOI 10.1177/0278364910369190; Lui YM, 2008, LECT NOTES COMPUT SC, V5303, P44, DOI 10.1007/978-3-540-88688-4_4; Mansour Yishay, 2009, P COLT; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Pal D., 2010, INT C ART INT STAT, P129; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Rostamizadeh A., 2009, ADV NEURAL INFORM PR, P1041; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shi Y., 2012, P INT C MACH LEARN, P1079; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Tur G, 2009, INT CONF ACOUST SPEE, P3721, DOI 10.1109/ICASSP.2009.4960435; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273; Wold H., 1985, ENCY STAT SCI, V6; WONG YC, 1967, P NATL ACAD SCI USA, V57, P589, DOI 10.1073/pnas.57.3.589; Xing DK, 2007, LECT NOTES ARTIF INT, V4702, P324; Zheng JJ, 2012, INT C PATT RECOG, P2095	58	104	104	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2288	2302		10.1109/TPAMI.2013.249	http://dx.doi.org/10.1109/TPAMI.2013.249			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353067				2022-12-18	WOS:000343702400013
J	Gao, Z; Cheong, LF; Wang, YX				Gao, Zhi; Cheong, Loong-Fah; Wang, Yu-Xiang			Block-Sparse RPCA for Salient Motion Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Block-sparse RPCA; salient motion; dynamic background; camera jitter	BACKGROUND SUBTRACTION; SIGNALS; IMAGE	Recent evaluation [2], [13] of representative background subtraction techniques demonstrated that there are still considerable challenges facing these methods. Challenges in realistic environment include illumination change causing complex intensity variation, background motions (trees, waves, etc.) whose magnitude can be greater than those of the foreground, poor image quality under low light, camouflage, etc. Existing methods often handle only part of these challenges; we address all these challenges in a unified framework which makes little specific assumption of the background. We regard the observed image sequence as being made up of the sum of a low-rank background matrix and a sparse outlier matrix and solve the decomposition using the Robust Principal Component Analysis method. Our contribution lies in dynamically estimating the support of the foreground regions via a motion saliency estimation step, so as to impose spatial coherence on these regions. Unlike smoothness constraint such as MRF, our method is able to obtain crisply defined foreground regions, and in general, handles large dynamic background motion much better. Furthermore, we also introduce an image alignment step to handle camera jitter. Extensive experiments on benchmark and additional challenging data sets demonstrate that our method works effectively on a wide range of complex scenarios, resulting in best performance that significantly outperforms many state-of-the-art approaches.	[Gao, Zhi] Natl Univ Singapore, Interact & Digital Media Inst, Singapore 119613, Singapore; [Cheong, Loong-Fah; Wang, Yu-Xiang] Natl Univ Singapore, Elect & Comp Engn Dept, Singapore 119613, Singapore	National University of Singapore; National University of Singapore	Gao, Z (corresponding author), Natl Univ Singapore, Interact & Digital Media Inst, Singapore 119613, Singapore.	gaozhinus@gmail.com; eleclf@nus.edu.sg; wangyx@nus.edu.sg		Wang, Yu-Xiang/0000-0002-6403-212X	JPP [R-263-000-A24-232]; PSF [1321202075]; theory and methods of digital conservation for cultural heritage [2012CB725300]; Singapore NRF under its IRC@SG Funding Initiative	JPP; PSF; theory and methods of digital conservation for cultural heritage; Singapore NRF under its IRC@SG Funding Initiative(National Research Foundation, Singapore)	The authors would like to thank Tom SF Haines and Dr. Tao Xiang from University College London for running their DPGMM code on our sequences for experimental comparison. This work is supported by these Grants: JPP Grant R-263-000-A24-232, PSF Grant 1321202075, theory and methods of digital conservation for cultural heritage (2012CB725300), and the Singapore NRF under its IRC@SG Funding Initiative and administered by the IDMPO at the SeSaMe centre.	Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613; Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508; Bugeau A, 2009, COMPUT VIS IMAGE UND, V113, P459, DOI 10.1016/j.cviu.2008.11.005; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Cavallaro A, 2001, PROC SPIE, V4310, P465; Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12; Eldar YC, 2010, IEEE T SIGNAL PROCES, V58, P3042, DOI 10.1109/TSP.2010.2044837; Elgammal A., 2000, COMPUTER VISION ECCV, P751, DOI [10.1007/3-540-45053-X_48, DOI 10.1007/3-540-45053-X_48]; Evangelio RH, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P300, DOI 10.1109/AVSS.2012.69; Gao Z, 2012, LECT NOTES COMPUT SC, V7576, P690, DOI 10.1007/978-3-642-33715-4_50; Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919; Haines TSF, 2012, LECT NOTES COMPUT SC, V7575, P99, DOI 10.1007/978-3-642-33765-9_8; Huang JZ, 2009, IEEE I CONF COMP VIS, P64, DOI 10.1109/ICCV.2009.5459202; Huwer S, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P37, DOI 10.1109/VS.2000.856856; Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004; Lin Z., 2009, ARXIVORGABS10095055; Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285; Matsuyama T., 2000, P AS C COMP VIS, P662; Mittal A, 2004, PROC CVPR IEEE, P302; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Qiu C., 2011, ARXIVORGABS11063286; Schick A., 2012, P IEEE COMP SOC C CO, P27, DOI DOI 10.1109/CVPRW.2012.6238923; Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Stojnic M, 2009, IEEE T SIGNAL PROCES, V57, P3075, DOI 10.1109/TSP.2009.2020754; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Tang Gongguo, 2011, P 45 ANN C INF SCI S, P1, DOI DOI 10.1109/WICOM.2011.6040117; TraKuPong P. Kadew, 2011, EUR, P135; Veit T., 2005, P IEEE INT C IM PROC, V1, P1061; Wixson L, 2000, IEEE T PATTERN ANAL, V22, P774, DOI 10.1109/34.868680; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zelnik-Manor L, 2012, IEEE T SIGNAL PROCES, V60, P2386, DOI 10.1109/TSP.2012.2187642; Zheng JY, 2006, TRANSPORT RES REC, P82; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132; Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005	38	104	114	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					1975	1987		10.1109/TPAMI.2014.2314663	http://dx.doi.org/10.1109/TPAMI.2014.2314663			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352629				2022-12-18	WOS:000341981300006
J	Tommasi, T; Orabona, F; Caputo, B				Tommasi, Tatiana; Orabona, Francesco; Caputo, Barbara			Learning Categories from Few Examples with Multi Model Knowledge Transfer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Knowledge transfer; image categorization; discriminative learning		Learning a visual object category from few samples is a compelling and challenging problem. In several real-world applications collecting many annotated data is costly and not always possible. However, a small training set does not allow to cover the high intraclass variability typical of visual objects. In this condition, machine learning methods provide very few guarantees. This paper presents a discriminative model adaptation algorithm able to proficiently learn a target object with few examples by relying on other previously learned source categories. The proposed method autonomously chooses from where and how much to transfer information by solving a convex optimization problem which ensures to have the minimal leave-one-out error on the available training set. We analyze several properties of the described approach and perform an extensive experimental comparison with other existing transfer solutions, consistently showing the value of our algorithm.	[Tommasi, Tatiana] Katholieke Univ Leuven, ESAT PSI, B-3001 Louvain, Belgium; [Tommasi, Tatiana] Katholieke Univ Leuven, iMinds, B-3001 Louvain, Belgium; [Orabona, Francesco] Toyota Technol Inst, Chicago, IL 60637 USA; [Caputo, Barbara] Univ Roma La Sapienza, Dept Comp Control & Management Engn, I-00185 Rome, Italy	KU Leuven; IMEC; KU Leuven; Toyota Technological Institute - Chicago; Sapienza University Rome	Tommasi, T (corresponding author), Katholieke Univ Leuven, ESAT PSI, B-3001 Louvain, Belgium.	tatiana.tommasi@esat.kuleuven.be; francesco@orabona.com; caputo@dis.uniroma1.it	Caputo, Barbara/J-8976-2015	Caputo, Barbara/0000-0001-7169-0158; Tommasi, Tatiana/0000-0001-8229-7159				Aytar Y., 2012, P BMVC; Aytar Y., 2011, P IEEE ICCV BARC SPA; Bart E., 2005, P IEEE CVPR; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bosch A., 2007, P 6 CIVP AMST NETH; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Brabanter J.D., 2002, LEAST SQUARES SUPPOR, DOI DOI 10.1142/9789812776655; Cawley GC, 2006, IEEE IJCNN, P1661; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Dai W., 2007, P 24 ICML CORV OR US; Dai W., 2009, P 26 ICML MONTR QC C; Daume III H., 2007, P ACL; Davis J., 2009, P 26 ICML NEW YORK N; Deng J., 2009, P IEEE CVPR; Deselaers T., 2008, P WORK NOT CLEF AARH; Duchi J., 2008, P 25 ICML HELS FINL; Everingham M., PASCAL VISUAL OBJECT; Fink M, 2004, P NIPS, V17, P449; Gehler P., 2009, P IEEE 12 ICCV KYOT; GIBBONS JD, 1985, NONPARAMETRIC STAT I; Griffin G., 2007, UCBCSD041366 CAL I T; Guillaumin M., 2012, P IEEE CVPR; Hofstadter D.R, 1996, FLUID CONCEPTS CREAT; Hush D, 2006, J MACH LEARN RES, V7, P733; Intrator N., 1996, Connection Science, V8, P205, DOI 10.1080/095400996116884; Kuettel D., 2012, P 12 ECCV FLOR IT; Lampert C. H., 2009, P IEEE CVPR; Lazebnik S., 2006, P IEEE CVPR; Lehmann T., 2003, P SPIE; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lim J. J., 2011, P NIPS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahmud M. M., 2007, P NIPS; Mesnil G., 2012, P ICML WORKSH UNS TR, P97; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Quattoni A., 2008, P IEEE CVPR; Ruckert U., 2008, P ECML PKDD ANTW BEL; Scholkopf B., 2001, LEARNING KERNELS SUP; Stark M., 2009, P IEEE 12 ICCV KYOT; Steinwart I, 2005, IEEE T INFORM THEORY, V51, P128, DOI 10.1109/TIT.2004.839514; Taylor M. E., 2007, ICAPS WORKSH AIPL PR; Thrun S., 1996, P NIPS; Tommasi T., 2012, P BMVC; Tommasi T., 2009, P BMVC; Tommasi T., 2008, P CLEF AARH DENM; Torrey L., 2009, TRANSFER LEARNING; Tuzel O., 2007, P IEEE CVPR; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Yang J., 2007, P 7 IEEE ICDM OM NE; Yao Y., 2010, P IEEE CVPR; Zhang Y., 2010, P 16 ACM SIGKDD INT	53	104	113	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					928	941		10.1109/TPAMI.2013.197	http://dx.doi.org/10.1109/TPAMI.2013.197			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353227	Green Submitted			2022-12-18	WOS:000336054200008
J	Chakrabarti, A; Hirakawa, K; Zickler, T				Chakrabarti, Ayan; Hirakawa, Keigo; Zickler, Todd			Color Constancy with Spatio-Spectral Statistics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; statistical modeling; spatial correlations; maximum likelihood; illumination statistics	ILLUMINATION CHROMATICITY; ALGORITHM	We introduce an efficient maximum likelihood approach for one part of the color constancy problem: removing from an image the color cast caused by the spectral distribution of the dominating scene illuminant. We do this by developing a statistical model for the spatial distribution of colors in white balanced images (i.e., those that have no color cast), and then using this model to infer illumination parameters as those being most likely under our model. The key observation is that by applying spatial band-pass filters to color images one unveils color distributions that are unimodal, symmetric, and well represented by a simple parametric form. Once these distributions are fit to training data, they enable efficient maximum likelihood estimation of the dominant illuminant in a new image, and they can be combined with statistical prior information about the illuminant in a very natural manner. Experimental evaluation on standard data sets suggests that the approach performs well.	[Chakrabarti, Ayan; Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Hirakawa, Keigo] Univ Dayton, Intelligent Signal Syst Lab, Dayton, OH 45469 USA	Harvard University; University of Dayton	Chakrabarti, A (corresponding author), Harvard Univ, Sch Engn & Appl Sci, 33 Oxford St, Cambridge, MA 02138 USA.	ayanc@eecs.harvard.edu; khirakawa1@udayton.edu; zickler@seas.harvard.edu			US Office of Naval Research [N000140911022]; US Army Research Laboratory; US Army Research Office [54262-CI]	US Office of Naval Research(Office of Naval Research); US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office	The authors would like to thank the associate editor and reviewers for their thoughtful comments. A. Chakrabarti and T. Zickler were supported by US Office of Naval Research award N000140911022 and the US Army Research Laboratory and the US Army Research Office under contract/grant number 54262-CI.	Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529; Barnard K., 2000, P EUR C COMP VIS; BRAINARD D, 1993, J OPT SOC AM A, V14, P1393; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374; Chakrabarti A., 2009, P BRIT MACH VIS C; Chakrabarti A., 2008, P IEEE C COMP VIS PA; CHONG HY, 2007, P IEEE INT C COMP VI; Ciurea F., 2003, P IS T SID COL IM C; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson G. D., 1993, P IEEE INT C COMP VI; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Gehler P. V., 2008, P IEEE C COMP VIS PA; Gershon R., 1988, PERCEPTION, V17, P755; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Hansen T, 2006, NAT NEUROSCI, V9, P1367, DOI 10.1038/nn1794; Hirakawa K., 2005, P IEEE C IM PROC; Hogg RV., 2010, PROBABILITY STAT INF; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; HURLBERT AC, 1988, SCIENCE, V239, P482, DOI 10.1126/science.3340834; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Olkkonen M, 2008, J VISION, V8, DOI 10.1167/8.8.8; Rosenberg C., 2003, P ADV NEUR INF PROC; Saenko Kate, 2010, P EUR C COMP VIS; Selesnick IW, 2008, IEEE T SIGNAL PROCES, V56, P3482, DOI 10.1109/TSP.2008.920488; Shi L., 2012, REPROCESSED VERSION; Shi LL, 2011, J OPT SOC AM A, V28, P940, DOI 10.1364/JOSAA.28.000940; Singh B., 2003, P WORKSH STAT COMP T; Sinz F, 2009, J MULTIVARIATE ANAL, V100, P817, DOI 10.1016/j.jmva.2008.07.006; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; Webster MA, 1996, NETWORK-COMP NEURAL, V7, P587, DOI 10.1088/0954-898X/7/4/002; Werner A, 2003, VISION RES, V43, P1611, DOI 10.1016/S0042-6989(03)00174-3; WEST G, 1982, J MATH BIOL, V15, P249, DOI 10.1007/BF00275077; Xiong WH, 2006, J IMAGING SCI TECHN, V50, P341, DOI 10.2352/J.ImagingSci.Technol.(2006)50:4(341)	36	104	117	3	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1509	1519		10.1109/TPAMI.2011.252	http://dx.doi.org/10.1109/TPAMI.2011.252			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22745000	Green Submitted			2022-12-18	WOS:000305188500005
J	Zhang, Y; Zhou, ZH				Zhang, Yin; Zhou, Zhi-Hua			Cost-Sensitive Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; cost-sensitive face recognition; cost-sensitive learning; multiclass cost-sensitive learning	CLASSIFICATION	Most traditional face recognition systems attempt to achieve a low recognition error rate, implicitly assuming that the losses of all misclassifications are the same. In this paper, we argue that this is far from a reasonable setting because, in almost all application scenarios of face recognition, different kinds of mistakes will lead to different losses. For example, it would be troublesome if a door locker based on a face recognition system misclassified a family member as a stranger such that she/he was not allowed to enter the house, but it would be a much more serious disaster if a stranger was misclassified as a family member and allowed to enter the house. We propose a framework which formulates the face recognition problem as a multiclass cost-sensitive learning task, and develop two theoretically sound methods for this task. Experimental results demonstrate the effectiveness and efficiency of the proposed methods.	[Zhang, Yin; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Dept Comp Sci & Technol, Nanjing 210093, Peoples R China	Nanjing University	Zhang, Y (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Dept Comp Sci & Technol, Mailbox 419,22 Hankou Rd, Nanjing 210093, Peoples R China.	zhangyin@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn			National Science Foundation of China [60635030, 60721002]; Jiangsu Science Foundation [BK2008018]; National Fundamental Research Program of China [2010CB327900]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Jiangsu Science Foundation; National Fundamental Research Program of China	The authors would like to thank Ji Zhu for guidance on implementing mbKLR, Yoonkyung Lee for sharing the code of mcSVM, Xu-Ying Liu and Yu-Yin Sun for reading a preliminary draft, and the helpful comments and suggestions from the associate editor and anonymous reviewers. This research was supported by the National Science Foundation of China (60635030 and 60721002), the Jiangsu Science Foundation (BK2008018), and the National Fundamental Research Program of China (2010CB327900).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Ciraco M., 2005, P 1 INT WORKSHOP UTI, P46; Domingos P.M., 1999, P 5 ACM SIGKDD INT C, P155, DOI DOI 10.1145/312129.312220; Drummond C., 2003, P ICML WORKSH LEARN, VII; Elkan C., 2001, INT JOINT C ART INT, V17, P973, DOI DOI 10.5555/1642194.1642224; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; Landgrebe TCW, 2008, IEEE T PATTERN ANAL, V30, P810, DOI 10.1109/TPAMI.2007.70740; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224; LI Z, 2004, P IEEE INT C COMP VI, V2, P374; Liu XY, 2006, IEEE DATA MINING, P970; Maloof M. A., 2003, LEARNING DATA SETS A, V2, P2; Martinez A., 1998, 24 CVC, P24; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659, DOI 10.1109/TKDE.2002.1000348; Ting KM, 2000, LECT NOTES ARTIF INT, V1810, P413; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ZHANG Y, 2008, P IEEE CS C COMP VIS; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou Z., 2006, P 21 NAT C ART INT, P567; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	27	104	124	2	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1758	1769		10.1109/TPAMI.2009.195	http://dx.doi.org/10.1109/TPAMI.2009.195			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724754				2022-12-18	WOS:000281000700003
J	Boykov, Y; Veksler, O; Zabih, R				Boykov, Y; Veksler, O; Zabih, R			A variable window approach to early vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image restoration; motion; stereo; adaptive windows; visual correspondence	COMPUTER VISION; STEREO; ALGORITHM; IMAGES	Early vision relies heavily on rectangular windows for tasks such as smoothing and computing correspondence. While rectangular windows are efficient, they yield poor results near object boundaries. We describe an efficient method for choosing an arbitrarily shaped connected window, in a manner that varies at each pixel. Our approach can be applied to several problems, including image restoration and visual correspondence, it runs in linear time, and takes a few seconds on traditional benchmark images. Performance on both synthetic and real imagery appears promising.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Cornell University	Boykov, Y (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	yura@cs.cornell.edu; olga@cs.cornell.edu; rdz@cs.cornell.edu	Veksler, Olga/B-6549-2015; Boykov, Yuri/C-1718-2015	Veksler, Olga/0000-0002-9664-6601; 				BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; Bolles R. C., 1993, DARPA IM UND WORKSH, P263; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; COX I, 1995, IEEE INT C IM PROC; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gennert M. A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P139, DOI 10.1109/CCV.1988.589984; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; HANNA M, 1974, THESIS STANFORD U; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ishikawa H, 1998, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.1998.698598; JONES DG, 1992, 2ND P EUR C COMP VIS, P395; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; LITTLE J, 1992, VISION INTERFACE, P97; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Negahdaripour S., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P2, DOI 10.1109/ICCV.1993.378241; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; SZELISKI R, 1985, IEEE COMP SOC C COMP, P284; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010	24	104	112	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1283	1294		10.1109/34.735802	http://dx.doi.org/10.1109/34.735802			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV		Green Submitted			2022-12-18	WOS:000077578300001
J	KEREN, D; COOPER, D; SUBRAHMONIA, J				KEREN, D; COOPER, D; SUBRAHMONIA, J			DESCRIBING COMPLICATED OBJECTS BY IMPLICIT POLYNOMIALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							IMAGE	This paper introduces and focuses on two problems. First is the representation power of closed implicit polynomials of modest degree for curves in 2-D images and surfaces in 3-D range data. Super quadrics are a small subset of object boundaries that are well fitted by these polynomials. The second problem is the stable computationally efficient fitting of noisy data by closed implicit polynomial curves and surfaces. The attractive features of these polynomials for Vision is discussed.			KEREN, D (corresponding author), BROWN UNIV,DIV ENGN,ENGN MAN MACHINE SYST,PROVIDENCE,RI 02912, USA.							ABHYANKAR SS, 1990, ALBEBRAIC GEOMETRY S; ALBERT A, 1972, REGRESSION MOOREPENR; BAJCSY R, 1987, 1ST P INT C COMP VIS, P231; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BOULT TE, 1988, P DARPA IMAGE UNDERS, P1052; CERNUSCHIFRIAS B, 1984, THESIS BROWN U PROVI; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; Faugeras O. D., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P8; FAUGERAS OD, 1983, P CVPR; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; FORSYTH DA, 1990, P EUROPEAN C COMPUTE; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; PRATT V, 1987, ACM SIGGRAPH, V21, P145; PRESS WH, 1986, NUMERICAL RECEIPES; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SUBRAHMONIA J, 1991, LEMS94 BROWN U TECH; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Taubin G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P103, DOI 10.1109/CVPR.1992.223220; TAUBIN G, 1991, P DARPA ESPIRIT WORK; TAUBIN G, 1990, THESIS BROWN U PROVI; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237	24	104	110	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					38	53		10.1109/34.273718	http://dx.doi.org/10.1109/34.273718			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300004
J	VAILLANT, R; FAUGERAS, OD				VAILLANT, R; FAUGERAS, OD			USING EXTREMAL BOUNDARIES FOR 3-D OBJECT MODELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EXTREMAL BOUNDARIES; NONPOLYEDRIC OBJECTS; OBJECT MODELING; SURFACE REPRESENTATION	STEREO	This paper is devoted to the study of the extremal boundaries of 3-D curved objects. The extremal boundaries are the images of special curves drawn on the object and are called rims. They are viewpoint dependent and characterized by the fact that the optical rays of their points are tangential to the surface of the object. We first study the mathematics of the relationship between the extremal boundaries and the surface of the object. This study allows us to design an algorithm for detecting those boundaries in the images that are likely to be extremal (for this, we need at least three images). Once this has been done, we show that we can reconstruct the rims and compute the differential properties of the surface of the object along them up to the second order. If a qualitative description is sufficient, we show that the sign of the Gaussian curvature of the surface along the rim can be computed in a much simpler way. Experimental results are presented on synthetic and real images. This paper provides a better understanding of the relationship between the apparent and real shape of a 3-D object as well as algorithms for reconstructing the local shape of such an object along the rims. It opens potential applications to the modeling of 3-D objects.	ECOLE POLYTECH, APPL MATH, F-91128 PALAISEAU, FRANCE	Institut Polytechnique de Paris	VAILLANT, R (corresponding author), INST NATL RECH INFORMAT & AUTOMAT, COMP VIS & ROBOT GRP, VALBONNE, FRANCE.							AYACHE N, 1987, 1ST P INT C COMP VIS; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BLAKE A, 1990, 1ST P EUR C COMP VIS; BRADY M, 1985, 2ND P INT S ROB RES, P5; Carmo M. P., 1976, DIFFERENTIAL GEOMETR, V2nd; CIPOLLA R, 1990, 3RD P INT C COMP VIS; DERICHE R, 1987, INT J COMPUTER V APR, P15; Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15; FAUGERAS OD, 1990, ARTIF INTELL, V44, P41, DOI 10.1016/0004-3702(90)90098-K; GIBLIN P, 1986, 1ST P INT C COMP VIS; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; Hilbert D., 1932, GEOMETRY IMAGINATION; Horn B., 1986, ROBOT VISION, P1; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; LIM HS, 1988, P DARPA IM UND WORKS, P809; Marr D., 1982, VISION; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; RONEN B, 1988, 2ND P INT C COMP VIS; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; VAILLANT R, 1989, APR INT WORKSH IND A; VAILLANT R, 1989, P NASA C SPACE TELER; VAILLANT R, 1990, THESIS U PARIS SUD C	23	104	110	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					157	173		10.1109/34.121787	http://dx.doi.org/10.1109/34.121787			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900006
J	MAREFAT, M; KASHYAP, RL				MAREFAT, M; KASHYAP, RL			GEOMETRIC REASONING FOR RECOGNITION OF 3-DIMENSIONAL OBJECT FEATURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,PURDUE ENGN RES CTR INTELLIGENT MFG SYST,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	MAREFAT, M (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							BROWN CM, 1982, COMPUT SURV, V12, P69; BUCHANAN BG, 1985, RULE BASED EXPERT SY, P272; Chang T. C., 1985, INTRO AUTOMATED PROC; CHOI BK, 1982, THESIS PURDUE U W LA; DEFLORIANA L, 1987, 3RD P ANN S COMP GEO; HENDERSON MR, 1984, THESIS PURDUE U W LA; JOSHI S, 1987, THESIS PURDUE U W LA; KUNG H, 1984, THESIS OKLAHOMA STAT; Kyprianou L.K., 1980, THESIS CAMBRIDGE U C; LEE YC, 1987, IEEE COMPUT GRAPH, P20; REQUICHA AAG, 1980, IEEE COMPUT GRAPH, V12, P45; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Staley SM, 1983, COMPUTERS MECHANICAL, P61; WEILER KJ, 1986, THESIS RENSSELAER PO; Winston P. H., 1984, ARTIF INTELL, P159; WOO TC, 1982, MAR P C CAD CAM TECH, P76	16	104	116	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1990	12	10					949	965		10.1109/34.58868	http://dx.doi.org/10.1109/34.58868			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EA042					2022-12-18	WOS:A1990EA04200002
J	SHAPIRO, LG; HARALICK, RM				SHAPIRO, LG; HARALICK, RM			A METRIC FOR COMPARING RELATIONAL DESCRIPTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SHAPIRO, LG (corresponding author), MACHINE VIS INT, ANN ARBOR, MI 48104 USA.		Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				BARROW HG, 1972, FRONTIERS PATTERN RE, P1; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; Feustel CD, 1982, PATTERN RECOGN LETT, V1, P125, DOI 10.1016/0167-8655(82)90025-3; FREUDER EC, 1978, COMMUN ASS COMPUT MA, V21; GASCHNIG J, 1972, 5TH P INT JOINT C AR; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1979, 6TH P INT JOINT C AR; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MARR D, 1975, MIT341 AI LAB MEM; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; MULGAONKAR PG, 1982, IDENTIFICATION MAN M; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SANFELIEU A, 1983, IEEE T SYST MAN CYBE, V13; SCHNEIER M, 1979, WORKSHOP REPRESENT 3; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SHAPIRO LG, 1984, PATTERN RECOGN, V17, P385, DOI 10.1016/0031-3203(84)90068-2; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHAPIRO LG, 1980, IEEE T PATTERN ANAL, V2, P111, DOI 10.1109/TPAMI.1980.4766989; SHAPIRO LG, 1980, AUG IEEE WORKSH PICT; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	24	104	106	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					90	94		10.1109/TPAMI.1985.4767621	http://dx.doi.org/10.1109/TPAMI.1985.4767621			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869243				2022-12-18	WOS:A1985ABF0900008
J	PELEG, S				PELEG, S			A NEW PROBABILISTIC RELAXATION SCHEME	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PELEG, S (corresponding author), UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742, USA.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				EKLUNDH J, 1978, TR662 U MAR COMP SCI; EKLUNDH JO, 1978, TR701 U MAR COMP SCI; KIRBY R, UNPUBLISHED; Pavlidis T., 1977, STRUCTURAL PATTERN R; PELEG S, 1979, COMMUN ACM, V22, P598, DOI 10.1145/359168.359174; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1979, COMPUT VISION GRAPH, V10, P235, DOI 10.1016/0146-664X(79)90003-0; PELEG S, 1979, TR739 U MAR COMP SCI; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Zucker S. W., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P307; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1976, IEEE T COMPUT, V26, P394; ZUCKER SW, 1978, 78157 MCGILL U COMP	13	104	105	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					362	369		10.1109/TPAMI.1980.4767035	http://dx.doi.org/10.1109/TPAMI.1980.4767035			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JZ206	21868912				2022-12-18	WOS:A1980JZ20600009
J	Berman, D; Levy, D; Avidan, S; Treibitz, T				Berman, Dana; Levy, Deborah; Avidan, Shai; Treibitz, Tali			Underwater Single Image Color Restoration Using Haze-Lines and a New Quantitative Dataset	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image color analysis; Attenuation; Image restoration; Channel estimation; Three-dimensional displays; Cameras; Optical attenuators; Image processing and computer vision; image enhancement; computational photography; image restoration; image color analysis	ENHANCEMENT; VISIBILITY; LIGHT; WATER	Underwater images suffer from color distortion and low contrast, because light is attenuated while it propagates through water. Attenuation under water varies with wavelength, unlike terrestrial images where attenuation is assumed to be spectrally uniform. The attenuation depends both on the water body and the 3D structure of the scene, making color restoration difficult. Unlike existing single underwater image enhancement techniques, our method takes into account multiple spectral profiles of different water types. By estimating just two additional global parameters: the attenuation ratios of the blue-red and blue-green color channels, the problem is reduced to single image dehazing, where all color channels have the same attenuation coefficients. Since the water type is unknown, we evaluate different parameters out of an existing library of water types. Each type leads to a different restored image and the best result is automatically chosen based on color distribution. We also contribute a dataset of 57 images taken in different locations. To obtain ground truth, we placed multiple color charts in the scenes and calculated its 3D structure using stereo imaging. This dataset enables a rigorous quantitative evaluation of restoration algorithms on natural images for the first time.	[Berman, Dana; Avidan, Shai] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel; [Levy, Deborah; Treibitz, Tali] Univ Haifa, Charney Sch Marine Sci, Hatter Dept Marine Technol, IL-3498838 Haifa, Israel	Tel Aviv University; University of Haifa	Berman, D (corresponding author), Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel.	dana.menaker@gmail.com; dlrun14@gmail.com; avidan@eng.tau.ac.il; ttreibitz@univ.haifa.ac.il			Leona M. and Harry B. Helmsley Charitable Trust; Maurice Hatter Foundation; Israel Science Foundation [680/18]; Ministry of Science, Technology and Space grant [3 - 12487]; Technion Ollendorff Minerva Center for Vision and Image Sciences; Mediterranean Sea Research Center of Israel; Apple Graduate Fellowship	Leona M. and Harry B. Helmsley Charitable Trust; Maurice Hatter Foundation; Israel Science Foundation(Israel Science Foundation); Ministry of Science, Technology and Space grant; Technion Ollendorff Minerva Center for Vision and Image Sciences; Mediterranean Sea Research Center of Israel; Apple Graduate Fellowship	TT was supported by the The Leona M. and Harry B. Helmsley Charitable Trust, The Maurice Hatter Foundation, Israel Science Foundation Grant #680/18, Ministry of Science, Technology and Space grant #3 - 12487, and the Technion Ollendorff Minerva Center for Vision and Image Sciences. DB was supported by The Mediterranean Sea Research Center of Israel and by Apple Graduate Fellowship.	Akkaynak D, 2019, PROC CVPR IEEE, P1682, DOI 10.1109/CVPR.2019.00178; Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703; Akkaynak D, 2017, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2017.68; Akkaynak D, 2014, J OPT SOC AM A, V31, P312, DOI 10.1364/JOSAA.31.000312; Ancuti CO, 2017, IEEE IMAGE PROC, P695; Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252; Ancuti C, 2016, INT C PATT RECOG, P4202, DOI 10.1109/ICPR.2016.7900293; Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661; Anwar S., 2019, ARXIV190707863 2; Asano Y, 2016, LECT NOTES COMPUT SC, V9910, P635, DOI 10.1007/978-3-319-46466-4_38; AUSTIN RW, 1986, OPT ENG, V25, P471, DOI 10.1117/12.7973845; Berman D., 2017, P BRIT MACH VIS C BM, V1, P1; Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Blasinski H., 2017, IMAGING APPL OPTICS; Bryson M., 2012, ROBOTICS SCI SYSTEMS; Bryson M, 2016, J FIELD ROBOT, V33, P853, DOI 10.1002/rob.21638; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Carlevaris-Bianco N, 2010, OCEANS-IEEE; Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113; Duarte A., 2016, OCEANS-IEEE; Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003; Finlayson, 2014, P BRIT MACH VIS C, DOI 10.13140/RG.2.1.4625.6806; Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006; Gao YK, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043014; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Jerlov NG, 1976, MARINE OPTICS; Jiang J, 2013, IEEE WORK APP COMP, P168, DOI 10.1109/WACV.2013.6475015; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050; Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886; Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704; Ma F., 2017, SPARSE DENSE DEPTH P; Mobley C. D., 1994, LIGHT WATER RAD TRAN; Morimoto T, 2010, PROC CVPR IEEE, P207, DOI 10.1109/CVPR.2010.5540211; Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915; Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846; Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749; Perez J, 2017, OCEANS-IEEE; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871; Schechner YY, 2004, PROC CVPR IEEE, P536; Schwartzman A, 2017, IEEE INT CONF COMPUT, P124; Sheinin M, 2016, PROC CVPR IEEE, P3764, DOI 10.1109/CVPR.2016.409; Shin YS, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761342; Sumner R., 2014, PROCESSING RAW IMAGE; Swirski Y, 2009, IEEE I CONF COMP VIS, P205, DOI 10.1109/ICCV.2009.5459166; Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643; Treibitz T, 2012, J OPT SOC AM A, V29, P1516, DOI 10.1364/JOSAA.29.001516; Xianghua Xie M. W. J., 2015, P BRIT MACH VIS C; Yamashita A, 2007, IEEE INT CONF ROBOT, P4570, DOI 10.1109/ROBOT.2007.364183; Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020	55	103	105	57	159	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2822	2837		10.1109/TPAMI.2020.2977624	http://dx.doi.org/10.1109/TPAMI.2020.2977624			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32142424	Green Submitted			2022-12-18	WOS:000670578800022
J	Chu, WS; De la Torre, F; Cohn, JF				Chu, Wen-Sheng; De la Torre, Fernando; Cohn, Jeffrey F.			Selective Transfer Machine for Personalized Facial Expression Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial expression analysis; personalization; domain adaptation; transfer learning; support vector machine (SVM)	SUPPORT VECTOR MACHINE; ACTION UNIT DETECTION; RECOGNITION; OPTIMIZATION; ADAPTATION; FEATURES; EMOTION; MODELS; FACE	Automatic facial action unit (AU) and expression detection from videos is a long-standing problem. The problem is challenging in part because classifiers must generalize to previously unknown subjects that differ markedly in behavior and facial morphology (e. g., heavy versus delicate brows, smooth versus deeply etched wrinkles) from those on which the classifiers are trained. While some progress has been achieved through improvements in choices of features and classifiers, the challenge occasioned by individual differences among people remains. Person-specific classifiers would be a possible solution but for a paucity of training data. Sufficient training data for person-specific classifiers typically is unavailable. This paper addresses the problem of how to personalize a generic classifier without additional labels from the test subject. We propose a transductive learning method, which we refer to as a Selective Transfer Machine (STM), to personalize a generic classifier by attenuating person-specific mismatches. STM achieves this effect by simultaneously learning a classifier and re-weighting the training samples that are most relevant to the test subject. We compared STM to both generic classifiers and cross-domain learning methods on four benchmarks: CK+ [44], GEMEP-FERA [67], RUFACS [4] and GFT [57]. STM outperformed generic classifiers in all.	[Chu, Wen-Sheng; De la Torre, Fernando; Cohn, Jeffrey F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Cohn, Jeffrey F.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA	Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Chu, WS (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	wensheng.chu@gmail.com; ftorre@cs.cmu.edu; jeffcohn@cs.cmu.edu	Chu, Wen-Sheng/AAF-6871-2019	Chu, Wen-Sheng/0000-0001-8592-6088	National Institutes of Health (NIH) [R01MH096951]; National Science Foundation (NSF) [RI-1116583]; Army Research Laboratory Collaborative Technology Alliance Program [W911NF-10-2-0016]; NATIONAL INSTITUTE OF MENTAL HEALTH [R01MH096951] Funding Source: NIH RePORTER; Direct For Computer & Info Scie & Enginr [1418026] Funding Source: National Science Foundation	National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation (NSF)(National Science Foundation (NSF)National Research Foundation of Korea); Army Research Laboratory Collaborative Technology Alliance Program; NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH)); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	The authors would like thank many anonymous reviewers for constructive feedback. Research reported in this paper was supported in part by the National Institutes of Health (NIH) under Award Number R01MH096951, the National Science Foundation (NSF) under the grant RI-1116583, and Army Research Laboratory Collaborative Technology Alliance Program under cooperative agreement W911NF-10-2-0016. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or the NSF.	[Anonymous], 2013, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2013.439; [Anonymous], 2007, P 15 ACM INT C MULTI; [Anonymous], 2007, FACE RECOGNITION, DOI [10.5772/4847, DOI 10.5772/4847]; AUMANN RJ, 1986, ISRAEL J MATH, V54, P159, DOI 10.1007/BF02764940; Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Chan C. F., 2010, P EUR SIGN PROC C EU, P1, DOI DOI 10.1109/APPEEC.2010.5448850; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chang KY, 2009, PROC CVPR IEEE, P533, DOI 10.1109/CVPRW.2009.5206612; Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chattopadhyay R, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382582; Chen JX, 2013, PATTERN RECOGN LETT, V34, P1964, DOI 10.1016/j.patrec.2013.02.002; Chew SW, 2012, IEEE T SYST MAN CY B, V42, P1006, DOI 10.1109/TSMCB.2012.2194485; Chew Sien W., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P915, DOI 10.1109/FG.2011.5771373; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815; De la Torre F., 2011, VISUAL ANAL HUMANS, P377; Ding XY, 2013, IEEE I CONF COMP VIS, P2400, DOI 10.1109/ICCV.2013.298; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Dudik M., 2005, NIPS 05 P 18 INT C N, V18, P323; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; FLOUDAS CA, 1990, COMPUT CHEM ENG, V14, P1397, DOI 10.1016/0098-1354(90)80020-C; Gehrig T., 2011, IEEE COMP SOC C COMP, P1; Girard JM, 2015, BEHAV RES METHODS, V47, P1136, DOI 10.3758/s13428-014-0536-1; Goldberg D. A., 2009, U.S. Patent, Patent No. [7,561,723, 7561723]; Gretton A, 2009, NEURAL INF PROCESS S, P131; Gunes H, 2005, IEEE SYS MAN CYBERN, P3437; Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45; Jeni L. A., 2015, P IEEE INT C AUT FAC; Jixu Chen, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2655, DOI 10.1109/CVPRW.2009.5206580; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Kanade Takeo, 2000, P 4 IEEE INT C AUT F, P1, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]; Kapoor Ashish, 2005, P 13 ANN ACM INT C M, P677, DOI [10.1145/1101149.1101300, DOI 10.1145/1101149.1101300]; Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414; Liu M., 2013, 10 IEEE INT C WORKSH, P1, DOI [DOI 10.1109/FG.2013.6553734, DOI 10.1128/GEN0MEA.00300-13]; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Lucey S., 2007, FACE RECOGNITION, P275; Martinez A, 2012, J MACH LEARN RES, V13, P1589; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Orrite C, 2009, LECT NOTES COMPUT SC, V5524, P176, DOI 10.1007/978-3-642-02172-5_24; Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192; Rudovic O, 2012, LECT NOTES COMPUT SC, V7584, P260, DOI 10.1007/978-3-642-33868-7_26; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sangineto E, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P357, DOI 10.1145/2647868.2654916; Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Sayette MA, 2012, PSYCHOL SCI, V23, P869, DOI 10.1177/0956797611435134; Sebe, 2014, P 16 INT C MULT INT, P128, DOI [10.1145/2663204.2663247, DOI 10.1145/2663204.2663247]; Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567; Shang LF, 2009, PROC CVPR IEEE, P2090, DOI 10.1109/CVPRW.2009.5206509; Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25; Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sugiyama M., 2008, NIPS, P1433; Sugiyama M, 2007, J MACH LEARN RES, V8, P985; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0; Watson P., 2013, 2013 10 IEEE INT C W, P1; WENDELL RE, 1976, OPER RES, V24, P643, DOI 10.1287/opre.24.4.643; Whitehill J., 2013, SOC EMOTIONS NATURE, V88; Wu T., 2010, 2010 IEEE COMP SOC C, P42, DOI [DOI 10.1109/CVPRW.2010.5543267, 10.1109/CVPRW.2010.5543267]; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yamada M, 2012, LECT NOTES COMPUT SC, V7575, P674, DOI 10.1007/978-3-642-33765-9_48; Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978; Yang S, 2014, LECT NOTES COMPUT SC, V8888, P269, DOI 10.1007/978-3-319-14364-4_26; Zeng JB, 2015, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2015.413; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao K., 2015, P IEEE C COMP VIS PA; Zhong L., 2012, P IEEE C COMP VIS PA, P1499; Zhou F, 2010, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2010.5539966; Zhu YF, 2011, IEEE T AFFECT COMPUT, V2, P79, DOI 10.1109/T-AFFC.2011.10	86	103	107	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					529	545		10.1109/TPAMI.2016.2547397	http://dx.doi.org/10.1109/TPAMI.2016.2547397			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	28113267	Green Accepted, hybrid			2022-12-18	WOS:000395555100009
J	Norouzi, M; Punjani, A; Fleet, DJ				Norouzi, Mohammad; Punjani, Ali; Fleet, David J.			Fast Exact Search in Hamming Space with Multi-Index Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary codes; Hamming distance; nearest neighbor search; multi-index hashing; large-scale image retrieval	NEAREST-NEIGHBOR; SCENE	There is growing interest in representing image data and feature descriptors using compact binary codes for fast near neighbor search. Although binary codes are motivated by their use as direct indices (addresses) into a hash table, codes longer than 32 bits are not being used as such, as it was thought to be ineffective. We introduce a rigorous way to build multiple hash tables on binary code substrings that enables exact k-nearest neighbor search in Hamming space. The approach is storage efficient and straight-forward to implement. Theoretical analysis shows that the algorithm exhibits sub-linear run-time behavior for uniformly distributed codes. Empirical results show dramatic speedups over a linear scan baseline for datasets of up to one billion codes of 64, 128, or 256 bits.	[Norouzi, Mohammad; Punjani, Ali; Fleet, David J.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S3H5, Canada	University of Toronto	Norouzi, M (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S3H5, Canada.	norouzi@cs.toronto.edu; alipunjani@cs.toronto.edu; fleet@cs.toronto.edu		/0000-0003-0734-7114	NSERC Canada; GRAND Network Centre of Excellence; Canadian Institute for Advanced Research (CIFAR)	NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); GRAND Network Centre of Excellence; Canadian Institute for Advanced Research (CIFAR)(Canadian Institute for Advanced Research (CIFAR))	This research was financially supported in part by NSERC Canada, the GRAND Network Centre of Excellence, and the Canadian Institute for Advanced Research (CIFAR). The authors would also like to thank M. Aly, R. Fergus, R. Johnson, A. Mehrabian, and P. Perona for useful discussions about this work.	Alahi A., 2012, PROC IEEE CONF COMPU; Aly M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.40; Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; Babenko Artem, 2012, P IEEE C COMP VIS PA; Bergamo A., 2011, P NIPS, V24; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Charikar M., 2002, P ACM S THEOR COMP M; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2011, PROC CVPR IEEE; Gordo A, 2011, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2011.5995505; Greene D., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), P722, DOI 10.1109/SFCS.1994.365720; Grohe M., 2006, TEXT THEORET COMP S; He J., 2011, P IEEE C COMP VIS PA; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2011, INT CONF ACOUST SPEE, P861; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kuettel D., 2012, P EUR C COMP VIS FLO; Kulis B., 2009, P NIPS, V22; Liu W., 2012, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Minsky M., 1969, PERCEPTRONS; Muja M., 2009, P INT C COMP VIS THE; Norouzi M., 2012, P NIPS; Norouzi M., 2011, P INT C MACH LEARN B; Norouzi M., 2012, P IEEE C COMP VIS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Raginsky M., 2009, P NIPS, V22; Rastegari M., 2012, P EUR C COMP VIS FLO; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shakhnarovich G., 2003, P IEEE INT C COMP VI, V2; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A., 2008, P IEEE C COMP VIS PA; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Trzcinski T., 2012, P NIPS; Wang J., 2010, P INT C MACH LEARN H; Weiss Y., 2008, P NIPS, V21	37	103	106	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1107	1119		10.1109/TPAMI.2013.231	http://dx.doi.org/10.1109/TPAMI.2013.231			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353274	Green Submitted			2022-12-18	WOS:000337124200005
J	Sugano, Y; Matsushita, Y; Sato, Y				Sugano, Yusuke; Matsushita, Yasuyuki; Sato, Yoichi			Appearance-Based Gaze Estimation Using Visual Saliency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaze estimation; visual attention; face and gesture recognition	ATTENTION; ALLOCATION	We propose a gaze sensing method using visual saliency maps that does not need explicit personal calibration. Our goal is to create a gaze estimator using only the eye images captured from a person watching a video clip. Our method treats the saliency maps of the video frames as the probability distributions of the gaze points. We aggregate the saliency maps based on the similarity in eye images to efficiently identify the gaze points from the saliency maps. We establish a mapping between the eye images to the gaze points by using Gaussian process regression. In addition, we use a feedback loop from the gaze estimator to refine the gaze probability maps to improve the accuracy of the gaze estimation. The experimental results show that the proposed method works well with different people and video clips and achieves a 3.5-degree accuracy, which is sufficient for estimating a user's attention on a display.	[Sugano, Yusuke; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Sato Lab, Meguro Ku, Tokyo 1538505, Japan; [Matsushita, Yasuyuki] Microsoft Res Asia, Beijing 100080, Peoples R China	University of Tokyo; Microsoft; Microsoft Research Asia	Sugano, Y (corresponding author), Univ Tokyo, Inst Ind Sci, Sato Lab, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	sugano@iis.u-tokyo.ac.jp; yasumat@microsoft.com; ysato@iis.u-tokyo.ac.jp	Sugano, Yusuke/X-3689-2019	Sugano, Yusuke/0000-0003-4206-710X; Matsushita, Yasuyui/0000-0002-1935-4752	CREST, JST	CREST, JST(Japan Science & Technology Agency (JST)Core Research for Evolutional Science and Technology (CREST))	This research was supported by CREST, JST.	Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Cerf M., 2008, ADV NEURAL INFORM PR, V20, P241, DOI DOI 10.1145/2185520.2185525; Chen J, 2011, P IEEE C COMP VIS PA; Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952; Guestrin ED, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P267, DOI 10.1145/1344471.1344531; Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30; Hansen Dan Witzner, 2010, P 2010 S EYE TRACK R, P13; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Horvitz E, 2003, COMMUN ACM, V46, P52, DOI 10.1145/636772.636798; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; ITTI L, 2009, VISION RES, V49, P1295, DOI DOI 10.1016/J.VISRES.2008.09.007; Jacob Robert J. K., 1995, EYE TRACKING ADV INT, P258, DOI [10.1093/oso/9780195075557.003.0015, DOI 10.1093/OSO/9780195075557.003.0015]; JUDD T., 2009, P 12 IEEE INT C COMP; Kienzle W., 2006, ADV NEURAL INFORM PR, P689; Kienzle W, 2007, LECT NOTES COMPUT SC, V4713, P405; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Lawson R, 1987, SIAM CLASSICS APPL M; Lu F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.126; Nagamatsu T, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P95, DOI 10.1145/1344471.1344496; Ohno T., 2006, P ACM S EYE TRACKING, P34, DOI [10.1145/1117309.1117318, DOI 10.1145/1117309.1117318]; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Schutz A. C., 2011, J VISION, V11; Sugano Y, 2008, LECT NOTES COMPUT SC, V5304, P656, DOI 10.1007/978-3-540-88690-7_49; Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984; Sundararajan S, 2001, NEURAL COMPUT, V13, P1103, DOI 10.1162/08997660151134343; Vertegaal R, 2006, COMPUT HUM BEHAV, V22, P771, DOI 10.1016/j.chb.2005.12.012; Villanueva A, 2008, IEEE T SYST MAN CY B, V38, P1123, DOI 10.1109/TSMCB.2008.926606; Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285; Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9	34	103	111	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					329	341		10.1109/TPAMI.2012.101	http://dx.doi.org/10.1109/TPAMI.2012.101			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22547429				2022-12-18	WOS:000312560600007
J	Wang, QF; Yin, F; Liu, CL				Wang, Qiu-Feng; Yin, Fei; Liu, Cheng-Lin			Handwritten Chinese Text Recognition by Integrating Multiple Contexts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Handwritten Chinese text recognition; confidence transformation; geometric models; language models; refined beam search; candidate character augmentation; maximum character accuracy training	POST-PROCESSING SYSTEM; CLASSIFIER COMBINATION; OFFLINE RECOGNITION; CHARACTER; SEGMENTATION; MODEL; ALGORITHMS; ONLINE	This paper presents an effective approach for the offline recognition of unconstrained handwritten Chinese texts. Under the general integrated segmentation-and-recognition framework with character oversegmentation, we investigate three important issues: candidate path evaluation, path search, and parameter estimation. For path evaluation, we combine multiple contexts (character recognition scores, geometric and linguistic contexts) from the Bayesian decision view, and convert the classifier outputs to posterior probabilities via confidence transformation. In path search, we use a refined beam search algorithm to improve the search efficiency and, meanwhile, use a candidate character augmentation strategy to improve the recognition accuracy. The combining weights of the path evaluation function are optimized by supervised learning using a Maximum Character Accuracy criterion. We evaluated the recognition performance on a Chinese handwriting database CASIA-HWDB, which contains nearly four million character samples of 7,356 classes and 5,091 pages of unconstrained handwritten texts. The experimental results show that confidence transformation and combining multiple contexts improve the text line recognition performance significantly. On a test set of 1,015 handwritten pages, the proposed approach achieved character-level accurate rate of 90.75 percent and correct rate of 91.39 percent, which are superior by far to the best results reported in the literature.	[Wang, Qiu-Feng; Yin, Fei; Liu, Cheng-Lin] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Wang, QF (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun E Rd, Beijing 100190, Peoples R China.	wangqf@nlpr.ia.ac.cn; fyin@nlpr.ia.ac.cn; liucl@nlpr.ia.ac.cn			National Natural Science Foundation of China (NSFC) [60825301, 60933010]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China (NSFC) under Grants 60825301 and 60933010.	Barnett J. A., 1981, P 7 INT JOINT C ART, P868; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535; Dai Ruwei, 2007, Frontiers of Computer Science in China, V1, P126, DOI 10.1007/s11704-007-002-5; Ding X., 2006, P SUMM AR CHIN HANDW, P61; Fei Yin, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P7, DOI 10.1109/ICFHR.2010.9; Fei Yin, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P951, DOI 10.1109/ICDAR.2009.93; Fu Q, 2006, INT C PATT RECOG, P974; Fujisawa H, 2008, PATTERN RECOGN, V41, P2435, DOI 10.1016/j.patcog.2008.03.015; Han Z, 2005, PROC INT CONF DOC, P111; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Ishidera E., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P8, DOI 10.1109/ICDAR.2001.953745; Jiang Y, 2006, LECT NOTES COMPUT SC, V4109, P127; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257, DOI 10.1109/89.568732; Kigo K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P214, DOI 10.1109/ICDAR.1993.395746; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Koga M, 1998, INT C PATT RECOG, P1137, DOI 10.1109/ICPR.1998.711896; Li NX, 2010, IEEE SYS MAN CYBERN, P3664, DOI 10.1109/ICSMC.2010.5641873; Li YX, 2005, PATTERN ANAL APPL, V8, P272, DOI 10.1007/s10044-005-0009-3; Li YX, 2004, PATTERN RECOGN, V37, P1901, DOI 10.1016/j.patcog.2004.03.002; Liang ZZ, 2005, PATTERN RECOGN LETT, V26, P1498, DOI 10.1016/j.patrec.2004.12.001; Lin XF, 1998, PATTERN RECOGN LETT, V19, P975, DOI 10.1016/S0167-8655(98)00072-5; Liu C.-L., 2010, P 2 CJK JOINT WORKSH; Liu CL, 2008, LECT NOTES COMPUT SC, V4768, P104; Liu CL, 2007, IEEE T PATTERN ANAL, V29, P1465, DOI 10.1109/TPAMI.2007.1090; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu CL, 2008, STUD COMPUT INTELL, V90, P139; Liu CL, 2000, IEEE T PATTERN ANAL, V22, P636, DOI 10.1109/34.862202; Liu CL, 2005, PATTERN RECOGN, V38, P11, DOI 10.1016/j.patcog.2004.05.013; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P1395, DOI 10.1109/TPAMI.2004.104; Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9; Murase H., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P1143, DOI 10.1109/ICPR.1988.28462; Nakagawa M, 2005, IEICE T INF SYST, VE88D, P1815, DOI 10.1093/ietisy/e88-d.8.1815; Ney H, 2000, P IEEE, V88, P1224, DOI 10.1109/5.880081; Povey D., 2003, THESIS; Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96; Quiniou Solen, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P466, DOI 10.1109/ICDAR.2009.78; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Senda S., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P184, DOI 10.1109/ICDAR.2001.953780; Stolcke Andreas, 2002, P INT, P901; Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012; Su TH, 2007, INT J DOC ANAL RECOG, V10, P27, DOI 10.1007/s10032-006-0037-6; Tang HS, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P263; Tseng LY, 1998, PATTERN RECOGN LETT, V19, P963, DOI 10.1016/S0167-8655(98)00073-7; Tulyakov S., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P164, DOI 10.1109/ICDAR.2001.953776; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; Wang CH, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P539; Wang QF, 2011, PROC INT CONF DOC, P518, DOI 10.1109/ICDAR.2011.110; Wuthrich Markus, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P211, DOI 10.1109/ICDAR.2009.17; Xiang-Dong Zhou, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P521, DOI 10.1109/ICDAR.2009.95; Xu RF, 2005, INT J PATTERN RECOGN, V19, P415, DOI 10.1142/S0218001405004046; Zhou XD, 2007, PROC INT CONF DOC, P48; Zhu BL, 2010, INT J DOC ANAL RECOG, V13, P121, DOI 10.1007/s10032-009-0111-y	55	103	114	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1469	1481		10.1109/TPAMI.2011.264	http://dx.doi.org/10.1109/TPAMI.2011.264			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22201052				2022-12-18	WOS:000305188500002
J	Sandler, R; Lindenbaum, M				Sandler, Roman; Lindenbaum, Michael			Nonnegative Matrix Factorization with Earth Mover's Distance Metric for Image Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonnegative matrix factorization; earth mover's distance; image segmentation	ALGORITHMS	Nonnegative matrix factorization (NMF) approximates a given data matrix as a product of two low-rank nonnegative matrices, usually by minimizing the L-2 or the KL distance between the data matrix and the matrix product. This factorization was shown to be useful for several important computer vision applications. We propose here two new NMF algorithms that minimize the Earth mover's distance (EMD) error between the data and the matrix product. The algorithms (EMD NMF and bilateral EMD NMF) are iterative and based on linear programming methods. We prove their convergence, discuss their numerical difficulties, and propose efficient approximations. Naturally, the matrices obtained with EMD NMF are different from those obtained with L-2-NMF. We discuss these differences in the context of two challenging computer vision tasks, texture classification and face recognition, perform actual NMF-based image segmentation for the first time, and demonstrate the advantages of the new methods with common benchmarks.	[Sandler, Roman] Yahoo Res, IL-31905 Haifa, Israel; [Lindenbaum, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Sandler, R (corresponding author), Yahoo Res, Matam Adv Technol Pk,Matam Tower 3,7th Floor, IL-31905 Haifa, Israel.	romats@yahoo-inc.com; mic@cs.technion.ac.il			Israeli Science Foundation	Israeli Science Foundation(Israel Science Foundation)	This work was supported by the Israeli Science Foundation. The authors thank Dr. Michael Zibulevsky and Dr. Boris Bachelis for valuable discussions.	Alpert S, 2007, P IEEE C COMP VIS PA; ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; BROADHURST RE, 2005, P TEXT AN SYNTH WORK; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T, 2005, PROC CVPR IEEE, P1124; DONOHO D, 2003, P NEURAL INFORM PROC; GRAUMAN K, 2004, P IEEE CS C COMP VIS; Guillamet D., 2002, P INT C PATT REC; Haindl M, 2008, INT C PATT RECOG, P2933; HAZAN T, 2007, 200713 HEBR U; Heiler M, 2006, J MACH LEARN RES, V7, P1385; Hillier F., 2015, INTRO OPERATIONS RES, V10th; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; LI S, 2001, P IEEE CS C COMP VIS, V1; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; PELE O, 2009, P IEEE INT C COMP VI; RUBNER Y, 1999, THESIS STANFORD U; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; SANDLER R, 2009, P IEEE CS C COMP VIS; SANDLER R, 2008, IEEE C COMP VIS PATT; SANDLER R, 2008, P IEEE CS C COMP VIS; Sandler R, 2009, INT J COMPUT VISION, V84, P308, DOI 10.1007/s11263-009-0237-x; SHI J, 1997, P IEEE CS C COMP VIS; SHIRDHONKAR S, 2008, P IEEE CS C COMP VIS; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Sra S., 2006, ADV NEURAL INFORM PR, V18, P283; THURAU C, 2008, P IEEE CS C COMP VIS; Ullman S., 1996, HIGH LEVEL VISION OB; WERMAN M, 1985, COMPUT VISION GRAPH, V32, P328, DOI 10.1016/0734-189X(85)90055-6; YANG J, 2008, P IEEE CS C COMP VIS	41	103	107	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1590	1602		10.1109/TPAMI.2011.18	http://dx.doi.org/10.1109/TPAMI.2011.18			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21263163				2022-12-18	WOS:000291807200008
J	Gil, J; Kimmel, R				Gil, J; Kimmel, R			Efficient dilation, erosion, opening, and closing algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; running maximum filter; min-max filter; computational efficiency	MAX FILTERS; MIN; EVOLUTION	We propose an efficient and deterministic algorithm for computing the one-dimensional dilation and erosion (max and min) sliding window filters. For a p-element sliding window, our algorithm computes the 1D filter using 1.5 + o(1) comparisons per sample point. Our algorithm constitutes a deterministic improvement over the best previously known such algorithm, independently developed by van Herk [25] and by Gil and Werman [12] (the HGW algorithm). Also, the results presented in this paper constitute an improvement over the Gevorkian et al. [9] (GAA) variant of the HGW algorithm. The improvement over the GAA variant is also in the computation model. The GAA algorithm makes the assumption that the input is independently and identically distributed (the i.i.d. assumption), whereas our main result is deterministic. We also deal with the problem of computing the dilation and erosion filters simultaneously, as required, e.g., for computing the unbiased morphological edge. In the case of i.i.d. inputs, we show that this simultaneous computation can be done more efficiently then separately computing each. We then turn to the opening filter, defined as the application of the min filter to the max filter and give an efficient algorithm for its computation. Specifically, this algorithm is only slightly slower than the computation of just the max filter. The improved algorithms are readily generalized to two dimensions (for a rectangular window), as well as to any higher finite dimension (for a hyperbox window), with the number of comparisons per window remaining constant. For the sake of concreteness, we also make a few comments on implementation considerations in a contemporary programming language.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Gil, J (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	yogi@cs.technion.ac.il; ron@cs.technion.ac.il						BROCKETT RW, 1994, IEEE T SIGNAL PROCES, V42, P3377, DOI 10.1109/78.340774; CHAUDHURI BB, 1990, PATTERN RECOGN LETT, V11, P77, DOI 10.1016/0167-8655(90)90116-J; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DORST L, 1994, SIGNAL PROCESS, V38, P79, DOI 10.1016/0165-1684(94)90058-2; Gevorkian DZ, 1997, IEEE T PATTERN ANAL, V19, P526, DOI 10.1109/34.589214; Gil J, 2000, COMP IMAG VIS, V18, P301; GIL J, 1993, IEEE T PATTERN ANAL, V15, P504, DOI 10.1109/34.211471; HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188; LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088; MARAGOS P, 1995, IEEE T SIGNAL PROCES, V43, P864, DOI 10.1109/78.376839; PITAS I, 1989, IEEE T CIRCUITS SYST, V36, P795, DOI 10.1109/31.90400; Rivest J.-F., 1993, Journal of Electronic Imaging, V2, P326, DOI 10.1117/12.159642; SAPIRO G, 1993, PATTERN RECOGN, V26, P1363, DOI 10.1016/0031-3203(93)90142-J; Serra J, 1982, IMAGE ANAL MATH MORP; Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646; Soille P., 1999, MORPHOLOGICAL IMAGE, DOI 10.1007/978-3-662-03939-7; STROUSTRUP B, 1997, C PLUS PLUS PROGRAMM; VANHERK M, 1992, PATTERN RECOGN LETT, V13, P517, DOI 10.1016/0167-8655(92)90069-C; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	25	103	117	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1606	1617		10.1109/TPAMI.2002.1114852	http://dx.doi.org/10.1109/TPAMI.2002.1114852			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA		Green Submitted			2022-12-18	WOS:000179444600005
J	Meijster, A; Wilkinson, MHF				Meijster, A; Wilkinson, MHF			A comparison of algorithms for connected set openings and closings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; connected set operators; attribute filters; pattern spectra; multiscale analysis; union-find	SCALE-SPACE; IMAGE; OPERATORS	The implementation of morphological connected set operators for image filtering and pattern recognition is discussed. Two earlier algorithms based on priority queues and hierarchical queues, respectively, are compared to a more recent union-find approach. Unlike the earlier algorithms which process regional extrema in the image sequentially, the union-find method allows simultaneous processing of extrema. In the context of area openings, closings, and pattern spectra, the union-find algorithm outperforms the previous methods on almost all natural and synthetic images tested. Finally, extensions to pattern spectra and the more general class of attribute operators are presented for all three algorithms, and memory usages are compared.	Univ Groningen, Ctr High Performance Comp & Visualizat, NL-9700 AV Groningen, Netherlands; Univ Groningen, Inst Math & Comp Sci, NL-9700 AV Groningen, Netherlands	University of Groningen; University of Groningen	Meijster, A (corresponding author), Univ Groningen, Ctr High Performance Comp & Visualizat, POB 800, NL-9700 AV Groningen, Netherlands.	a.meijster@rc.rug.nl; michael@cs.rug.nl	Wilkinson, Michael/Q-2847-2019; Wilkinson, Michael H.F./C-2386-2009; Wilkinson, Michael/AAA-8471-2020	Wilkinson, Michael/0000-0001-6258-1128; Wilkinson, Michael H.F./0000-0001-6258-1128; 				Bangham JA, 1996, J ELECTRON IMAGING, V5, P283, DOI 10.1117/12.243349; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P529, DOI 10.1109/34.494642; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P520, DOI 10.1109/34.494641; BANGHAM JA, 1996, P IEEE EUR C COMP VI, P189; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Cheng F, 1992, IEEE T IMAGE PROCESS, V1, P533, DOI 10.1109/83.199924; Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X; DILLENCOURT MB, 1992, J ACM, V39, P253, DOI 10.1145/128749.128750; Fiorio C, 1996, THEOR COMPUT SCI, V154, P165, DOI 10.1016/0304-3975(94)00262-2; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; Hesselink WH, 2001, SCI COMPUT PROGRAM, V41, P173, DOI 10.1016/S0167-6423(01)00007-7; Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009; Matheron G., 1975, RANDOM SETS INTEGRAL; Meijster A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P668, DOI 10.1109/ICIP.2001.958207; Meijster A., 1998, P 9 EUR SIGN PROC C, P1665; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; URBACH ER, 2001, 2000915 U GRON I MAT; Vincent L., 2000, Fundamenta Informaticae, V41, P57; Vincent L., 1993, P 1 WORKSH MATH MORP, P22; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; Wilkinson M. H. F., 2001, MED IMAGE COMPUTING; Wilkinson MHF, 2000, COMP IMAG VIS, V18, P311; [No title captured]	25	103	112	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					484	494		10.1109/34.993556	http://dx.doi.org/10.1109/34.993556			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM		Green Submitted			2022-12-18	WOS:000174574100005
J	IVERSON, LA; ZUCKER, SW				IVERSON, LA; ZUCKER, SW			LOGICAL/LINEAR OPERATORS FOR IMAGE CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDGE DETECTION; FEATURE EXTRACTION; IMAGE PROCESSING; COMPUTER VISION; NONLINEAR OPERATORS	CAT STRIATE CORTEX; RECEPTIVE-FIELDS; SIMPLE CELLS; SUMMATION; VISION; MODEL	We propose a language for designing image measurement operators suitable for early vision, We refer to them as logical/linear (L/L) operators, since they unify aspects of linear operator theory and Boolean logic, A family of these operators appropriate for measuring the low-order differential structure of image curves is developed, These L/L, operators are derived by decomposing a linear model into logical components to ensure that certain structural preconditions for the existence of an image curve are upheld, Tangential conditions guarantee continuity, while normal conditions select and categorize contrast profiles. The resulting operators allow for coarse measurement of curvilinear differential structure (orientation and curvature) while successfully segregating edge-and line-like features, By thus reducing the incidence of false-positive responses, these operators are a substantial improvement over (thresholded) linear operators which attempt to resolve the same class of features.	MCGILL UNIV,DEPT ELECT ENGN,MONTREAL,PQ H3A 2A7,CANADA	McGill University	IVERSON, LA (corresponding author), SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025, USA.							Birkhoff G., 1977, SURVEY MODERN ALGEBR; Canny J., 1986, IEEE T PATTERN ANAL, P679; DAVIS LS, 1976, IEEE T SYST MAN CYB, V6, P127, DOI 10.1109/TSMC.1976.5409183; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; Duda R.O., 1973, J ROYAL STAT SOC SER; FREEMAND W, 1991, IEEE T PATTERN ANAL; HARALICK RM, 1982, IEEE PATTERN ANAL MA, V6, P58; HERKOVITZ A, 1970, MIT AI183 LAB MEM; HEUCKEL MH, 1971, J ASSOC COMPUT MACH, V18, P113; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; IVERSON LA, 1993, THESIS MCGILL U MONT; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1988, BIOL CYBERN, V58, P163, DOI 10.1007/BF00364136; KOENDERINK JJ, 1984, SENSORY EXPERIENCE A, P123; KOENDERINK JJ, 1990, BIOL CYBERNETICS, V63; KOENDERINK JJ, 1987, BOOLEAN CYBERNETICS, V55; LECLERC Y, 1984, 8319R MCGILL U COMP; LINK NK, 1988, BIOL CYBERN, V59, P247, DOI 10.1007/BF00332913; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; MOVSHON JA, 1978, J PHYSIOL-LONDON, V283, P53, DOI 10.1113/jphysiol.1978.sp012488; PERONA P, 1991, 3RD INT C COMP VIS O, P52; PERONA P, 1992, 2ND P EUR C COMP VIS, P3; Protter M.H., 1984, MAXIMUM PRINCIPLES D; RUMELHART DE, 1986, LEARNING INTERNAL RE, V1, P318; SAPLEY RH, 1985, ANNU REV NEUROSCI, V8, P547; SCHUMER RA, 1984, VISION RES, V24, P565, DOI 10.1016/0042-6989(84)90110-X; WATT RJ, 1983, VISION RES, V23, P97, DOI 10.1016/0042-6989(83)90046-9; YOUNG RA, 1985, GMR4290 GEN MOT RES; Zucker S. W., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P568, DOI 10.1109/CCV.1988.590037; ZUCKER SW, 1986, BEHAV RES METH INSTR, V18, P608, DOI 10.3758/BF03201436; ZUCKER SW, 1989, NEURAL COMPUTATION, V1; [No title captured]	36	103	109	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1995	17	10					982	996		10.1109/34.464562	http://dx.doi.org/10.1109/34.464562			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RX289					2022-12-18	WOS:A1995RX28900005
J	HE, Y; KUNDU, A				HE, Y; KUNDU, A			2-D SHAPE CLASSIFICATION USING HIDDEN MARKOV MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTOREGRESSIVE MODEL; HIDDEN MARKOV MODEL; NONSTATIONARY TRANSITION; PATTERN RECOGNITION; SEGMENTAL K-MEANS ALGORITHM; SHAPE CLASSIFICATION; SHAPE OCCLUSION; SHAPE ORIENTATION; STATIONARITY TEST	RECOGNITION; WORD	In this paper, we present a planar shape recognition approach based on the hidden Markov model and autoregressive parameters. This approach segments closed shapes into segments and explores the characteristic relations between consecutive segments to make classifications at a finer level. The algorithm can tolerate a lot of shape contour perturbation and a moderate amount of occlusion. An orientation scheme is described to make the overall classification insensitive to shape orientation. Excellent recognition results have been reported. A distinct advantage of the approach is that the classifier does not have to be trained again when a new class of shapes is added.			HE, Y (corresponding author), SUNY BUFFALO,SCH MED,DEPT ELECT & COMP ENGN,BUFFALO,NY 14260, USA.		Rohlf, F J/A-8710-2008					ANDERSON TW, 1957, ANN MATH STAT, V28, P89, DOI 10.1214/aoms/1177707039; BEYER WH, 1968, HDB TABLES PROBABILI; BLUM H, 1964, P S MODELS PERCEPTIO; DAS M, 1990, IEEE T PATTERN ANAL, V12, P97, DOI 10.1109/34.41389; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; FORNEY GD, 1973, P IEEE, V61, P263; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; Horn B., 1986, ROBOT VISION, P1; JUANG BH, 1990, IEEE T ACOUST SPEECH, V38, P1639, DOI 10.1109/29.60082; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KUNDU A, 1989, PATTERN RECOGN, V22, P283, DOI 10.1016/0031-3203(89)90076-9; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1977, IEEE T COMPUT, V26, P800, DOI 10.1109/TC.1977.1674918; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; RABINER LR, 1986, AT&T TECH J, V65, P21, DOI 10.1002/j.1538-7305.1986.tb00368.x; RABINER LR, 1985, AT&T TECH J, V64, P1211, DOI 10.1002/j.1538-7305.1985.tb00272.x; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SMITH SP, 1982, COMPUT VISION GRAPH, V20, P259, DOI 10.1016/0146-664X(82)90084-3; YOU Z, 1984, COMPUT VISION GRAPH, V28, P185, DOI 10.1016/S0734-189X(84)80021-3; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	24	103	111	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1991	13	11					1172	1184		10.1109/34.103276	http://dx.doi.org/10.1109/34.103276			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN338					2022-12-18	WOS:A1991GN33800005
J	DERIN, H; ELLIOTT, H; CRISTI, R; GEMAN, D				DERIN, H; ELLIOTT, H; CRISTI, R; GEMAN, D			BAYES SMOOTHING ALGORITHMS FOR SEGMENTATION OF BINARY IMAGES MODELED BY MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MASSACHUSETTS, DEPT MATH & STAT, AMHERST, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	DERIN, H (corresponding author), UNIV MASSACHUSETTS, DEPT ELECT & COMP ENGN, AMHERST, MA 01003 USA.							ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827; ASKAR M, 1981, IEEE T AUTOMAT CONTR, V26, P558, DOI 10.1109/TAC.1981.1102630; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CHELLAPPA R, 1982, IEEE T ACOUST SPEECH, V30, P461, DOI 10.1109/TASSP.1982.1163911; COOPER DB, 1980, COMPUTER GRAPHICS IM, V10, P326; ELLIOTT H, 1982, IEEE T PATTERN ANAL, V4, P167, DOI 10.1109/TPAMI.1982.4767224; ELLIOTT H, 1981, COMPUT VISION GRAPH, V17, P291, DOI 10.1016/0146-664X(81)90010-1; ELLIOTT H, 1984, MAR IEEE INT C AC SP; GEMAN D, UNPUB IEEE T PATTERN; HABIBI A, 1972, PR INST ELECTR ELECT, V60, P878, DOI 10.1109/PROC.1972.8787; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; HO YC, 1964, IEEE T AUTOMAT CONTR, VAC 9, P333, DOI 10.1109/TAC.1964.1105763; Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021; KANAL LN, 1980, IMAGE MODELING; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KAUFMAN H, 1979, 18TH P C DEC CONT FT; KINDERMANN R, 1980, MARKOV FIELDS THEIR, V1; NAHI NE, 1972, PR INST ELECTR ELECT, V60, P872, DOI 10.1109/PROC.1972.8786; NAHI NE, 1972, IEEE T COMPUT, VC 21, P734; NAHI NE, 1973, IEEE T COMMUN, VCO21, P305, DOI 10.1109/TCOM.1973.1091662; PICKARD DK, 1977, J APPL PROBAB, V14, P717, DOI 10.2307/3213345; SCHARF LL, 1981, IEEE T AUTOMAT CONTR, V26, P1018, DOI 10.1109/TAC.1981.1102775; THERRIEN CW, 1981, MIT552 LINC LAB TECH; THERRIEN CW, 1980, 5TH P INT C PATT REC; WOODS JW, 1977, IEEE T INFORM THEORY, V23, P473, DOI 10.1109/TIT.1977.1055750; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786	27	103	106	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					707	720		10.1109/TPAMI.1984.4767595	http://dx.doi.org/10.1109/TPAMI.1984.4767595			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499652				2022-12-18	WOS:A1984TX36100005
J	Rahmani, H; Mahmood, A; Huynh, D; Mian, A				Rahmani, Hossein; Mahmood, Arif; Du Huynh; Mian, Ajmal			Histogram of Oriented Principal Components for Cross-View Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spatio-temporal keypoint; pointcloud; view invariance	ENSEMBLE	Existing techniques for 3D action recognition are sensitive to viewpoint variations because they extract features from depth images which are viewpoint dependent. In contrast, we directly process pointclouds for cross-view action recognition from unknown and unseen views. We propose the histogram of oriented principal components (HOPC) descriptor that is robust to noise, viewpoint, scale and action speed variations. At a 3D point, HOPC is computed by projecting the three scaled eigenvectors of the pointcloud within its local spatio-temporal support volume onto the vertices of a regular dodecahedron. HOPC is also used for the detection of spatio-temporal keypoints (STK) in 3D pointcloud sequences so that view-invariant STK descriptors (or Local HOPC descriptors) at these key locations only are used for action recognition. We also propose a global descriptor computed from the normalized spatio-temporal distribution of STKs in 4-D, which we refer to as STK-D. We have evaluated the performance of our proposed descriptors against nine existing techniques on two cross-view and three single-view human action recognition datasets. The experimental results show that our techniques provide significant improvement over state-of-the-art methods.	[Rahmani, Hossein; Mahmood, Arif; Du Huynh; Mian, Ajmal] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia	University of Western Australia	Rahmani, H (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	hossein@csse.uwa.edu.au; arif.mahmood@uwa.edu.au; du.huynh@uwa.edu.au; ajmal.mian@uwa.edu.au	Mahmood, Arif/R-7949-2019; Rahmani, Hossein/S-5134-2019	Mahmood, Arif/0000-0001-5986-9876; Rahmani, Hossein/0000-0003-1920-0371; Huynh, Du/0000-0003-3080-9655; Mian, Ajmal/0000-0002-5206-3842	ARC [DP110102399]	ARC(Australian Research Council)	The authors thank the authors of [29] for providing the Northwestern-UCLA Multiview Action3D dataset and especially Dr. Jiang Wang for answering our questions about the implementation of AOG [29] and AE [28] methods. They also thank the authors of [3], [8], [9], [10], [36], [41], [42] for making their codes publicly available. This work was supported by ARC Discovery grant DP110102399.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; [Anonymous], 2007, 2007 IEEE C COMP VIS; Blank M, 2005, IEEE I CONF COMP VIS, P1395; CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880; Chen YW, 2006, STUDIES FUZZINESS SO, P207; Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6; Coxeter H. S. M, 1973, REGULAR POLYTOPES; Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13; Farhadi Ali, 2009, CVPR; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Jia XF, 2012, INT C PATT RECOG, P3001; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822; Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Liu Z., 2016, DESCRIPTION EXPT SET; Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Maji Subhransu, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Qadir O, 2011, IEEE C EVOL COMPUTAT, P208; Rahmani H, 2014, INT C PATT RECOG, P3511, DOI 10.1109/ICPR.2014.604; Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Seitz SM, 1997, INT J COMPUT VISION, V25, P231, DOI 10.1023/A:1007928103394; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868; Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341; Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Weinland D, 2007, IEEE I CONF COMP VIS, P170; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397; Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365; Xie JY, 2011, EXPERT SYST APPL, V38, P5809, DOI 10.1016/j.eswa.2010.10.050; Yang X., 2012, P 20 ACM INT C MULTI, P1057, DOI [10.1145/2393347.2396382, DOI 10.1145/2393347.2396382]; Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108; Yilmaz A, 2005, PROC CVPR IEEE, P984; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265; Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347; Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394; [No title captured]	60	102	106	3	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2430	2443		10.1109/TPAMI.2016.2533389	http://dx.doi.org/10.1109/TPAMI.2016.2533389			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26915114	Green Submitted			2022-12-18	WOS:000387984700007
J	Zamir, AR; Shah, M				Zamir, Amir Roshan; Shah, Mubarak			Image Geo-Localization Based on Multiple Nearest Neighbor Feature Matching Using Generalized Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geo-location; image localization; Generalized Minimum Clique Problem (GMCP); generalized minimum spanning tree (GMST); feature matching; multiple nearest neighbor feature matching; feature correspondence; generalized graphs		In this paper, we present a new framework for geo-locating an image utilizing a novel multiple nearest neighbor feature matching method using Generalized Minimum Clique Graphs (GMCP). First, we extract local features (e. g., SIFT) from the query image and retrieve a number of nearest neighbors for each query feature from the reference data set. Next, we apply our GMCP-based feature matching to select a single nearest neighbor for each query feature such that all matches are globally consistent. Our approach to feature matching is based on the proposition that the first nearest neighbors are not necessarily the best choices for finding correspondences in image matching. Therefore, the proposed method considers multiple reference nearest neighbors as potential matches and selects the correct ones by enforcing consistency among their global features (e.g., GIST) using GMCP. In this context, we argue that using a robust distance function for finding the similarity between the global features is essential for the cases where the query matches multiple reference images with dissimilar global features. Towards this end, we propose a robust distance function based on the Gaussian Radial Basis Function (G-RBF). We evaluated the proposed framework on a new data set of 102k street view images; the experiments show it outperforms the state of the art by 10 percent.	[Zamir, Amir Roshan; Shah, Mubarak] Univ Cent Florida, Ctr Comp Vis Res, Harris Corp Engn Ctr, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Zamir, AR (corresponding author), Univ Cent Florida, Ctr Comp Vis Res, Harris Corp Engn Ctr, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	aroshan@cs.ucf.edu; shah@eecs.ucf.edu						Althaus E, 2002, J COMPUT BIOL, V9, P597, DOI 10.1089/106652702760277336; [Anonymous], 2009, CLUSTER ANAL; [Anonymous], P IEEE C COMP VIS PA; Avrithis Y., 2010, P INT C MULT 2010; BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200; Cao B., 2010, P 3 INT C IM SIGN PR; Chen D., 2011, P IEEE C COMP VIS PA; Efros A.A, 2008, P IEEE C COMP VIS PA; Feremans C, 2003, EUR J OPER RES, V148, P1, DOI 10.1016/S0377-2217(02)00404-6; Ghosh D., 2003, 20030802 IND I MAN; GOWER JC, 1969, ROY STAT SOC C-APP, V18, P54; Hakeem A., 2006, P 18 INT C PATT REC; Hao Q., 2012, P IEEE C COMP VIS PA; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Jegou H., 2009, P IEEE INT C COMP VI; Knopp J., 2010, P EUR C COMP VIS 201; Koster AMCA, 1998, OPER RES LETT, V23, P89, DOI 10.1016/S0167-6377(98)00043-1; Li Y., 2010, P 11 EUR C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K., 2003, P BRIT MACH VIS C 20; MORTENSEN E, 2005, P IEEE C COMP VIS PA; Muja M., 2009, P INT C COMP VIS THE; MYUNG YS, 1995, NETWORKS, V26, P231, DOI 10.1002/net.3230260407; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Philbin J., 2008, P IEEE C COMP VIS PA; Philbin J, 2007, CVPR; Sattler T., 2012, P 12 EUR C COMP VIS; Sattler T., 2009, P IEEE 12 INT C COMP; Sattler T., 2011, P 13 IEEE INT C COMP; Sivic Josef, 2003, P 9 IEEE INT C COMP; Torii A., 2013, P IEEE INT C COMP VI; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P178, DOI 10.1109/TPAMI.2009.148; Wang Z., 2006, P 9 PAC RIM INT C AR; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Wu G, 2005, P 11 ACM SIGKDD INT; Zamir A. R., 2010, P 11 EUR C COMP VIS; Zamir AR, 2012, P 12 EUR C COMP VIS; Zhang Y., 2011, P IEEE C COMP VIS PA	40	102	107	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1546	1558		10.1109/TPAMI.2014.2299799	http://dx.doi.org/10.1109/TPAMI.2014.2299799			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353337				2022-12-18	WOS:000340191900005
J	Yang, XW; Prasad, L; Latecki, LJ				Yang, Xingwei; Prasad, Lakshman; Latecki, Longin Jan			Affinity Learning with Diffusion on Tensor Product Graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Diffusion process; tensor product graph; affinity learning; image retrieval; image segmentation		In many applications, we are given a finite set of data points sampled from a data manifold and represented as a graph with edge weights determined by pairwise similarities of the samples. Often the pairwise similarities (which are also called affinities) are unreliable due to noise or due to intrinsic difficulties in estimating similarity values of the samples. As observed in several recent approaches, more reliable similarities can be obtained if the original similarities are diffused in the context of other data points, where the context of each point is a set of points most similar to it. Compared to the existing methods, our approach differs in two main aspects. First, instead of diffusing the similarity information on the original graph, we propose to utilize the tensor product graph (TPG) obtained by the tensor product of the original graph with itself. Since TPG takes into account higher order information, it is not a surprise that we obtain more reliable similarities. However, it comes at the price of higher order computational complexity and storage requirement. The key contribution of the proposed approach is that the information propagation on TPG can be computed with the same computational complexity and the same amount of storage as the propagation on the original graph. We prove that a graph diffusion process on TPG is equivalent to a novel iterative algorithm on the original graph, which is guaranteed to converge. After its convergence we obtain new edge weights that can be interpreted as new, learned affinities. We stress that the affinities are learned in an unsupervised setting. We illustrate the benefits of the proposed approach for data manifolds composed of shapes, images, and image patches on two very different tasks of image retrieval and image segmentation. With learned affinities, we achieve the bull's eye retrieval score of 99.99 percent on the MPEG-7 shape dataset, which is much higher than the state-of-the-art algorithms. When the data points are image patches, the NCut with the learned affinities not only significantly outperforms the NCut with the original affinities, but it also outperforms state-of-the-art image segmentation methods.	[Yang, Xingwei] GE Global Res, Image Analyt Lab, Niskayuna, NY 12309 USA; [Prasad, Lakshman] Los Alamos Natl Lab, Space & Remote Sensing Sci Grp, Intelligence & Space Res Div, Los Alamos, NM 87545 USA; [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	General Electric; United States Department of Energy (DOE); Los Alamos National Laboratory; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Yang, XW (corresponding author), GE Global Res, Image Analyt Lab, KWC 406,1 Res Circle, Niskayuna, NY 12309 USA.	happyyxw@gmail.com; prasad@lanl.gov; latecki@temple.edu		Prasad, Lakshman/0000-0003-3967-3643; Latecki, Longin Jan/0000-0002-5102-8244	US Department of Energy [71498-001-09]; US National Science Foundation [IIS-0812118, BCS-0924164, OIA-1027897]	US Department of Energy(United States Department of Energy (DOE)); US National Science Foundation(National Science Foundation (NSF))	This work was supported by US Department of Energy Award 71498-001-09 and by US National Science Foundation Grants IIS-0812118, BCS-0924164, OIA-1027897.	Arbelaez P., 2009, P IEEE COMP VIS PATT; Bai X., 2010, P EUR C COMP VIS; Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Donoser M., 2009, P 11 IEEE INT C COMP; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gopalan R., 2010, P EUR C COMP VIS; Huang Y., 2009, P IEEE C COMP VIS PA; Jegou H., 2010, INT J COMPUT VISION, V87, p[191, 2371]; Jegou H., 2008, P EUR C COMP VIS; Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285; Jegou M.D.H., 2008, P EUR C COMP VIS; KIM T, 2010, P IEEE C COMP VIS PA; Kontschieder P., 2009, P 9 AS C COMP VIS; Ladicky L., 2009, P 12 IEEE INT C COMP; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Lancaster P., 1995, ALGEBRAIC RICCATI EQ; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Lazebnik S., 2006, P IEEE C COMP VIS PA; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lim J.J., 2009, P 12 IEEE INT C COMP; Ling H., 2010, P 11 EUR C COMP VIS; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malisiewicz T., 2007, P BRIT MACH VIS C; Martin D., 2001, P 8 IEEE INT C COMP; MEILA M, 2005, P 22 INT C MACH LEAR; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Nister D., 2006, P IEEE COMP VIS PATT; Plath N, 2009, P 26 ANN INT C MACH; Prasad L., 2008, P IEEE C COMP VIS PA; Qin D., 2011, P IEEE C COMP VIS PA; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rao S.R., 2009, P 9 AS C COMP VIS; REN X, 2003, P 9 IEEE INT C COMP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J., 2006, P ECCV; Sivi J., 2003, P 9 IEEE INT C COMP; Stewenius H., 2012, OBJECT RECOGNITION B; Szummer M., 2001, P ADV NEUR INF PROC; Temlyakov A., 2010, P IEEE COMP VIS PATT; Van Loan CF, 2000, J COMPUT APPL MATH, V123, P85, DOI 10.1016/S0377-0427(00)00393-9; WANG J, 2008, P IEEE C COMP VIS PA; Xingwei Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2369, DOI 10.1109/CVPR.2011.5995325; Yang X., 2009, P IEEE C COMP VIS PA; Zhou D., 2007, P ADV NEUR INF PROC; Zhou D. Y., 2003, P ADV NEURAL INFORM	49	102	105	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					28	38		10.1109/TPAMI.2012.60	http://dx.doi.org/10.1109/TPAMI.2012.60			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22392704	Green Submitted			2022-12-18	WOS:000311127700005
J	Lafarge, F; Descombes, X; Zerubia, J; Pierrot-Deseilligny, M				Lafarge, Florent; Descombes, Xavier; Zerubia, Josiane; Pierrot-Deseilligny, Marc			Structural Approach for Building Reconstruction from a Single DSM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; urban area; digital surface model; stochastic models; Monte Carlo simulations	IMAGE SEGMENTATION; EXTRACTION; MODELS	We present a new approach for building reconstruction from a single Digital Surface Model (DSM). It treats buildings as an assemblage of simple urban structures extracted from a library of 3D parametric blocks (like a LEGO set). First, the 2D-supports of the urban structures are extracted either interactively or automatically. Then, 3D-blocks are placed on the 2D-supports using a Gibbs model which controls both the block assemblage and the fitting to data. A Bayesian decision finds the optimal configuration of 3D-blocks using a Markov Chain Monte Carlo sampler associated with original proposition kernels. This method has been validated on multiple data set in a wide-resolution interval such as 0.7 m satellite and 0.1 m aerial DSMs, and provides 3D representations on complex buildings and dense urban areas with various levels of detail.	[Lafarge, Florent; Descombes, Xavier; Zerubia, Josiane] INRIA Sophia Antipolis, Ariana Res Grp, F-06902 Sophia Antipolis, France; [Lafarge, Florent] French Mapping Agcy, Matis Lab, F-06902 Sophia Antipolis, France; [Pierrot-Deseilligny, Marc] IGN, French Mapping Agcy, Matis Lab, F-94165 St Mande, France	Universite Gustave-Eiffel	Lafarge, F (corresponding author), INRIA Sophia Antipolis, Ariana Res Grp, 2004 Routes Lucioles, F-06902 Sophia Antipolis, France.	florent.lafarge@inria.fr; xavier.descombes@inria.fr; josiane.zerubia@inria.fr; marc.pierrot-deseilligny@ign.fr		Zerubia, Josiane/0000-0002-7444-0856	French Mapping Agency (IGN); French Space Agency (CNES)	French Mapping Agency (IGN); French Space Agency (CNES)(Centre National D'etudes Spatiales)	The first author would like to thank the French Mapping Agency (IGN) and the French Space Agency (CNES) for partial financial support during his PhD. The authors thank CNES for providing PLEIADES simulations and IGN for providing the DSMs and ground truth.	BAILLARD C, 1999, P ISPRS C AUT EXTR G; BAILLOEUL T, 2005, ENERGY MINIMIZATION; BALTSAVIAS EP, 2004, ISPRS J PHOTOGRAMMET, V58; Bredif M., 2007, 2007 IEEE INT C IMAG; Brenner C, 2005, INT J APPL EARTH OBS, V6, P187, DOI 10.1016/j.jag.2004.10.006; BRENNER C, 2006, P ISPRS COMM 3 S PHO; Collins RT, 1998, COMPUT VIS IMAGE UND, V72, P143, DOI 10.1006/cviu.1998.0729; Dick AR, 2004, INT J COMPUT VISION, V60, P111, DOI 10.1023/B:VISI.0000029665.07652.61; Fischer A, 1998, COMPUT VIS IMAGE UND, V72, P185, DOI 10.1006/cviu.1998.0721; Frueh C, 2005, INT J COMPUT VISION, V61, P159, DOI 10.1023/B:VISI.0000043756.03810.dd; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GRENANDER U, 1994, J R STAT SOC B, V56, P549; GULCH E, 2001, P 3 INT WORKSH AUT E; Haala N, 1999, ISPRS J PHOTOGRAMM, V54, P130, DOI 10.1016/S0924-2716(99)00010-6; HAARIO H, 1991, ADV APPL PROBAB, V23, P866, DOI 10.2307/1427681; Han F, 2004, IEEE T PATTERN ANAL, V26, P1138, DOI 10.1109/TPAMI.2004.70; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hirschmuller H, 2005, P IEEE C COMP VIS PA; Kim Z, 2004, COMPUT VIS IMAGE UND, V96, P60, DOI 10.1016/j.cviu.2004.05.004; Lafarge F., 2007, THESIS ECOLE NATL SU; Lafarge F., 2008, P IEEE C COMP VIS PA; Lafarge F, 2008, ISPRS J PHOTOGRAMM, V63, P365, DOI 10.1016/j.isprsjprs.2007.09.003; LEE C, 2003, P IEEE WORKSH HIGH L; Maas HG, 1999, ISPRS J PHOTOGRAMM, V54, P153, DOI 10.1016/S0924-2716(99)00004-0; Mayer H, 1999, COMPUT VIS IMAGE UND, V74, P138, DOI 10.1006/cviu.1999.0750; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MULLER P, 2006, P ACM SIGGRAPH; Ortner M, 2007, INT J COMPUT VISION, V72, P107, DOI 10.1007/s11263-005-5033-7; PERRIN G, 2005, ENERGY MINIMIZATION; Pierrot-Deseilligny M., 2006, INT ARCH PHOTOGRAMME, V36; ROY S, 1998, P IEEE INT C COMP VI; SCHOLZE S, 2002, P 24 DAGM S PATT REC; TAILLANDIER F, 2004, P ISPRS C; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Van Laarhoven P.J., 1987, SIMULATED ANNEALING, P7; VARANELLI JM, 1996, THESIS U VIRGINIA; VESTRI C, 2001, P IEEE C COMP VIS PA; WEIDNER U, 1995, ISPRS J PHOTOGRAMM, V50, P38, DOI 10.1016/0924-2716(95)98236-S; WHITE S, 1984, P IEEE INT C COMP DE; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]; [No title captured]	41	102	110	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					135	147		10.1109/TPAMI.2008.281	http://dx.doi.org/10.1109/TPAMI.2008.281			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926904	Green Submitted			2022-12-18	WOS:000271826700011
J	Lacoste, C; Descombes, X; Zerubia, J				Lacoste, C; Descombes, X; Zerubia, J			Point processes for unsupervised line network extraction in remote sensing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stochastic processes; Monte Carlo; simulated annealing; edge and feature detection; remote sensing	ROAD EXTRACTION; AERIAL IMAGES; SATELLITE IMAGERY; FEATURES; SNAKES	This paper addresses the problem of unsupervised extraction of line networks ( for example, road or hydrographic networks) from remotely sensed images. We model the target line network by an object process, where the objects correspond to interacting line segments. The prior model, called "Quality Candy," is designed to exploit as fully as possible the topological properties of the network under consideration, while the radiometric properties of the network are modeled using a data term based on statistical tests. Two techniques are used to compute this term: one is more accurate, the other more efficient. A calibration technique is used to choose the model parameters. Optimization is done via simulated annealing using a Reversible Jump Markov Chain Monte Carlo (RJMCMC) algorithm. We accelerate convergence of the algorithm by using appropriate proposal kernels. The results obtained on satellite and aerial images are quantitatively evaluated with respect to manual extractions. A comparison with the results obtained using a previous model, called the "Candy" model, shows the interest of adding quality coefficients with respect to interactions in the prior density. The relevance of using an offline computation of the data potential is shown, in particular, when a proposal kernel based on this computation is added in the RJMCMC algorithm.	CREATIS, INSA, F-69621 Villeurbanne, France; INRIA, F-06902 Sophia Antipolis, France	Institut National de la Sante et de la Recherche Medicale (Inserm); Institut National des Sciences Appliquees de Lyon - INSA Lyon; Inria	Lacoste, C (corresponding author), CREATIS, INSA, 7 Rue Jean Capaelle,Bat Blaise Pascal, F-69621 Villeurbanne, France.	caroline.lacoste@creatis.insa-lyon.fr; Xavier.Descombes@inria.fr; Josiane.Zerubia@inria.fr						Barzohar M, 1996, IEEE T PATTERN ANAL, V18, P707, DOI 10.1109/34.506793; Baumgartner A, 1999, PHOTOGRAMM ENG REM S, V65, P777; Bhattacharya U, 1997, INT J REMOTE SENS, V18, P3379, DOI 10.1080/014311697216937; Couloigner I, 2000, PHOTOGRAMM ENG REM S, V66, P867; Doucette P, 2001, ISPRS J PHOTOGRAMM, V55, P347, DOI 10.1016/S0924-2716(01)00027-2; Duda R.O., 1973, J ROYAL STAT SOC SER; FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEYER CJ, 1994, SCAND J STAT, V21, P359; GREEN PJ, 1995, BIOMETRIKA, V57, P97; GRUN A, 1995, ISPRS J PHOTOGRAMM, V50, P11; Haverkamp D, 2002, OPT ENG, V41, P2107, DOI 10.1117/1.1496785; LACOSTE C, 2002, 4516 INRIA SOPH ANT; Laptev I, 2000, MACH VISION APPL, V12, P23, DOI 10.1007/s001380050121; Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623; Neuenschwander WM, 1997, INT J COMPUT VISION, V25, P191, DOI 10.1023/A:1007924018415; PESKUN PH, 1973, BIOMETRIKA, V60, P607; RUELLE D, 1970, COMMUN MATH PHYS, V18, P127, DOI 10.1007/BF01646091; SERENDERO MA, 1989, THESIS U NICE SOPHIA; Stoica R, 2004, INT J COMPUT VISION, V57, P121, DOI 10.1023/B:VISI.0000013086.45688.5d; STOICA R, 2001, THESIS U NICE SOPHIA; Tupin F, 1998, IEEE T GEOSCI REMOTE, V36, P434, DOI 10.1109/36.662728; van Lieshout M., 1993, BSR9306 CWI; van Lieshout M. N. M., 2001, PNAR0115 CWI; VANIESHOUT M, 2000, MARKOV POINT PROCESS; Vosselman G., 1995, AUTOMATIC EXTRACTION, P265; Wang D, 1996, INT J REMOTE SENS, V17, P827, DOI 10.1080/01431169608949048; ZLOTNICK A, 1993, CVGIP-IMAG UNDERSTAN, V57, P243, DOI 10.1006/ciun.1993.1016	28	102	109	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1568	1579		10.1109/TPAMI.2005.206	http://dx.doi.org/10.1109/TPAMI.2005.206			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16237992				2022-12-18	WOS:000231086700005
J	North, B; Blake, A; Isard, M; Rittscher, J				North, B; Blake, A; Isard, M; Rittscher, J			Learning and classification of complex dynamics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; learning dynamics; Auto-Regressive Process; Expectation Maximization	ALGORITHM	Standard, exact techniques based on likelihood maximization are available for learning Auto-Regressive Process models of dynamical processes. The uncertainty of observations obtained from real sensors means that dynamics can be observed only approximately. Learning can still be achieved via "EM-K"-Expectation-Maximization (EM) based on Kalman Filtering. This cannot handle more complex dynamics, however, involving multiple classes of motion. A problem arises also in the case of dynamical processes observed visually: background clutter arising for example, in camouflage, produces non-Gaussian observation noise. Even with a single dynamical class, non-Gaussian observations put the learning problem beyond the scope of EM-K. For those cases, we show here how "EM-C"-based on the CONDENSATION algorithm which propagates random "particle-sets," can solve the learning problem. Here, learning in clutter is studied experimentally using visual observations of a hand moving over a desktop. The resulting learned dynamical model is shown to have considerable predictive value: When used as a prior for estimation of motion, the burden of computation in visual observation is significantly reduced. Multiclass dynamics are studied via visually observed juggling; plausible dynamical models have been found to emerge from the learning process, and accurate classification of motion has resulted. In practice, EM-C learning is computationally burdensome and the paper concludes with some discussion of computational complexity.	Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England; Microsoft Res, Cambridge CB2 3NH, England	University of Oxford; Microsoft	North, B (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.	ablake@microsoft.com		Rittscher, Jens/0000-0002-8528-8298				Anderson B. D. O., 1979, OPTIMAL FILTERING; Astrom KJ., 1984, COMPUTER CONTROLLED; Bar-Shalom Y., 1988, TRACKING DATA ASS; Blake A, 1998, PHILOS T R SOC A, V356, P1283, DOI 10.1098/rsta.1998.0222; Blake A, 1997, ADV NEUR IN, V9, P361; BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1; BLAKE A, 1999, ADV NEURAL INFORMATI, V11; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; BOBICK AF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P382; BREGLER C, 1997, P C COMP VIS PATT RE; Brockwell P., 1996, INTRO TIME SERIES FO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GELB A, 1974, APPL OPT EST; GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776; GEMAN D, 1987, IMAGE VISION COMPUT, V5, P61, DOI 10.1016/0262-8856(87)90028-X; GHAHRAMANI Z, 1999, ADV NEURAL INFORMATI, V11; GOODWIN CC, 1984, ADAPTIVE FILTERING P; Grenander U., 1991, HANDS PATTERN THEORE; Huang X., 1990, HIDDEN MARKOV MODELS; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS, P343; ISARD M, 1998, P 5 EUR C COMP VIS, V1, P893; ISARD M, 1998, P 5 EUR C COMP VIS, P768; Kitagawa Genshiro, 2021, J COMPUT GRAPH STAT, V5, P1, DOI [DOI 10.2307/1390750, 10.2307/1390750]; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; Ljung L., 1987, SYSTEM IDENTIFICATIO; MacCormick J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390, DOI 10.1109/ICCV.1998.710748; North B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P384, DOI 10.1109/ICCV.1998.710747; Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203; Pavlovic V., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P609, DOI 10.1109/CVPR.1999.784983; Rabiner L., 1993, FUNDAMENTALS SPEECH; REYNARD D, 1996, P 4 EUR C COMP VIS, P357; ROBERTS R, 1995, CLIN CARDIOL, V18, P2; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; WELLNER P, 1991, P ACM S US INT SOFTW; Winston P. H., 1984, ARTIFICIAL INTELLIGE	39	102	108	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					1016	1034		10.1109/34.877523	http://dx.doi.org/10.1109/34.877523			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY					2022-12-18	WOS:000089741300008
J	LEE, HC; BRENEMAN, EJ; SCHULTE, CP				LEE, HC; BRENEMAN, EJ; SCHULTE, CP			MODELING LIGHT-REFLECTION FOR COMPUTER COLOR-VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LEE, HC (corresponding author), EASTMAN KODAK CO,IMAGING SCI LAB,ROCHESTER,NY 14650, USA.							AGOSTON GA, 1979, COLOR THEORY ITS APP, pCH5; Beck J., 1972, SURFACE COLOR PERCEP; Boyd R. W, 1983, RADIOMETRY DETECTION; BROOKS MJ, 1985, MIT AI280 MEM; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; DZMURA M, 1986, J OPT SOC AM A, V3, P1662, DOI 10.1364/JOSAA.3.001662; Edwards D. F., 1985, HDB OPTICAL CONSTANT; EVANS RM, 1959, EYE FILM CAMERA COLO; FLOCK HR, 1984, PERCEPT PSYCHOPHYS, V35, P293, DOI 10.3758/BF03205945; GERSHON R, 1987, 10TH P INT JOINT C A, P752; Grum F., 1979, OPTICAL RAD MEASUREM; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; HEALEY G, 1987, 1ST P INT C COMP VIS, P151; HEALEY G, 1987, 10TH P INT JOINT C A, P759; Horn B., 1986, ROBOT VISION, P1; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; Hunter R., 1975, MEASUREMENT APPEARAN; HURLBERT A, 1986, J OPT SOC AM A, V3, P1684, DOI 10.1364/JOSAA.3.001684; HURLBERT A, 1987, MIT AI909 MEM; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KANTHACK R, 1918, TABLE REFRACTIVE IND, V1; KLINKER G, 1987, 1ST P INT C COMP VIS, P145; KOLATTUKUDY PE, 1968, SCIENCE, V159, P498, DOI 10.1126/science.159.3814.498; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; LEE HC, 1989, 42ND P SPSE ANN C BO, P149; LEE HC, 1986, 229507A KOD RES LAB; LEE HC, 1988, MIT AI1068 MEM; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; METZLER DE, 1977, BIOCHEMISTRY; NASSAU K, 1983, PHYSICS CHEM COLOR; NICODEMUS FE, 1977, US BUREAU STANDARDS, V160; NICOLAIDES N, 1974, SCIENCE, V186, P19, DOI 10.1126/science.186.4158.19; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SNELL JF, 1978, HDB OPTICS; TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2, DOI 10.1109/TPAMI.1987.4767868; Willmouth F. M., 1986, OPTICAL PROPERTIES P; Wyszecki Gunter, 1982, COLOR SCI, V8; 1976, NBS9101 TECH NOT; 1970, PUBL CIE, V17	42	102	108	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1990	12	4					402	409		10.1109/34.50626	http://dx.doi.org/10.1109/34.50626			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CV929					2022-12-18	WOS:A1990CV92900007
J	VERE, SA				VERE, SA			PLANNING IN TIME - WINDOWS AND DURATIONS FOR ACTIVITIES AND GOALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											VERE, SA (corresponding author), JET PROP LAB,INFORMAT SYST RES SECT,PASADENA,CA 91109, USA.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; BUNDY A, 1978, ARTIF INTELL, V10, P129, DOI 10.1016/S0004-3702(78)80009-5; BUNDY A, 1977, 45 U ED DEP ART INT; DEKLEER J, 1975, MIT AITR352 TECH REP; Elmaghraby S.E., 1977, ACTIVITY NETWORKS PR; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; FIKES RE, 1972, MACHINE INTELLIGENCE, V7; FUNT BV, 1980, ARTIF INTELL, V13, P201, DOI 10.1016/0004-3702(80)90002-8; HENDRIX GG, 1973, ARTIF INTELL, V4, P145, DOI 10.1016/0004-3702(73)90010-6; KIVIAT PJ, 1968, SIMSCRIPT 2 PROGRAMM; MCDERMOTT D, 1981, 196 YAL U DEP COMP S; RIEGER C, 1976, TR495 U MAR DEP COMP; Sacerdoti E.D., 1977, STRUCTURE PLANS BEHA; SACERDOTI ED, 1979, P 6 INT JOINT C ART, P1077; SIKLOSSY L, 1973, P 3 IJCAI, P423; TATE A, 1976, 25 U ED DEP ART INT; Tate A., 1977, P 5 INT JOINT C ART, P888; THORNDYKE PW, 1981, P IJCAI, P171; VERE SA, 1977, ARTIF INTELL, V8, P47, DOI 10.1016/0004-3702(77)90004-2; WESSON RB, 1977, P IJCAI77 CAMBRIDGE, P473	20	102	107	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					246	267		10.1109/TPAMI.1983.4767389	http://dx.doi.org/10.1109/TPAMI.1983.4767389			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QS785	21869110				2022-12-18	WOS:A1983QS78500002
J	Wang, XS; Hua, Y; Kodirov, E; Robertson, NM				Wang, Xinshao; Hua, Yang; Kodirov, Elyor; Robertson, Neil M.			Ranked List Loss for Deep Metric Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Measurement; Training; Shape; Image retrieval; Extraterrestrial measurements; Task analysis; Pattern analysis; Deep metric learning; discriminative representation learning; learning to rank; information retrieval	MONOCULAR DEPRIVATION; VISUAL DEPRIVATION; RECOVERY; PERIOD	The objective of deep metric learning (DML) is to learn embeddings that can capture semantic similarity and dissimilarity information among data points. Existing pairwise or tripletwise loss functions used in DML are known to suffer from slow convergence due to a large proportion of trivial pairs or triplets as the model improves. To improve this, ranking-motivated structured losses are proposed recently to incorporate multiple examples and exploit the structured information among them. They converge faster and achieve state-of-the-art performance. In this work, we unveil two limitations of existing ranking-motivated structured losses and propose a novel ranked list loss to solve both of them. First, given a query, only a fraction of data points is incorporated to build the similarity structure. Consequently, some useful examples are ignored and the structure is less informative. To address this, we propose to build a set-based similarity structure by exploiting all instances in the gallery. The learning setting can be interpreted as few-shot retrieval: given a mini-batch, every example is iteratively used as a query, and the rest ones compose the gallery to search, i.e., the support set in few-shot setting. The rest examples are split into a positive set and a negative set. For every mini-batch, the learning objective of ranked list loss is to make the query closer to the positive set than to the negative set by a margin. Second, previous methods aim to pull positive pairs as close as possible in the embedding space. As a result, the intraclass data distribution tends to be extremely compressed. In contrast, we propose to learn a hypersphere for each class in order to preserve useful similarity structure inside it, which functions as regularisation. Extensive experiments demonstrate the superiority of our proposal by comparing with the state-of-the-art methods on the fine-grained image retrieval task. Our source code is available online: https://github.com/XinshaoAmosWang/Ranked-List-Loss-for-DML.	[Wang, Xinshao; Kodirov, Elyor; Robertson, Neil M.] Zenith Ai, Belfast BT1 6FB, Antrim, North Ireland; [Wang, Xinshao] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Hua, Yang; Robertson, Neil M.] Queens Univ Belfast, EEECS ECIT, Belfast BT7 1NN, Antrim, North Ireland	University of Oxford; Queens University Belfast	Hua, Y (corresponding author), Queens Univ Belfast, EEECS ECIT, Belfast BT7 1NN, Antrim, North Ireland.	xinshao.wang@eng.ox.ac.uk; y.hua@qub.ac.uk; elyor@zenithai.co.uk; n.robertson@qub.ac.uk	hua, yang/GSE-0594-2022	Garnier, Romain/0000-0003-4275-5033; Wang, Xinshao/0000-0001-8907-8258; Hua, Yang/0000-0001-5536-503X	AnyVision Industrial Research Funding	AnyVision Industrial Research Funding	This work was supported by the AnyVision Industrial Research Funding.	Achille Alessandro, 2019, INT C LEARN REPR; Andrew Zhai, 2019, Arxiv, DOI arXiv:1811.12649; Avinash Ravichandran, 2019, Arxiv, DOI arXiv:1911.12528; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196; Cakir F, 2019, IEEE T PATTERN ANAL, V41, P2424, DOI 10.1109/TPAMI.2019.2914897; Carlos D. Castillo, 2017, Arxiv, DOI arXiv:1703.09507; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130; Elyor Kodirov, 2019, Arxiv, DOI arXiv:1911.09976; Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17; GIFFIN F, 1978, J PHYSIOL-LONDON, V274, P511, DOI 10.1113/jphysiol.1978.sp012164; Goldberger J, 2004, ADV NEURAL INF PROCE, V17, P513, DOI DOI 10.5555/2976040.2976105; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hensch TK, 2004, ANNU REV NEUROSCI, V27, P549, DOI 10.1146/annurev.neuro.27.070203.144327; Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Huang C., 2016, P 30 INT C NEURAL IN, P1270; Deng JK, 2018, Arxiv, DOI arXiv:1801.07698; Kandel E. R., 2013, PRINCIPLES NEURAL SC, V5th; Kim W, 2018, LECT NOTES COMPUT SC, V11205, P760, DOI 10.1007/978-3-030-01246-5_45; KONISHI M, 1985, ANNU REV NEUROSCI, V8, P125, DOI 10.1146/annurev.ne.08.030185.001013; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Law MT, 2017, PR MACH LEARN RES, V70; Lim DKH, 2014, PR MACH LEARN RES, V32, P1980; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Liu WY, 2016, PR MACH LEARN RES, V48; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Lu J, 2019, IEEE I CONF COMP VIS, P7960, DOI 10.1109/ICCV.2019.00805; McFee B., 2010, P 27 INT C MACHINE L, P775; Mirzasoleiman B, 2015, AAAI CONF ARTIF INTE, P1812; MITCHELL DE, 1988, J PHYSIOL-LONDON, V395, P639, DOI 10.1113/jphysiol.1988.sp016939; Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47; OLSON CR, 1980, EXP BRAIN RES, V39, P17; Opitz M, 2017, IEEE I CONF COMP VIS, P5199, DOI 10.1109/ICCV.2017.555; Prabhu Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P263, DOI 10.1145/2623330.2623651; Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655; Roth K, 2019, IEEE I CONF COMP VIS, P7999, DOI 10.1109/ICCV.2019.00809; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sanakoyeu A, 2019, PROC CVPR IEEE, P471, DOI 10.1109/CVPR.2019.00056; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Snell J, 2017, ADV NEUR IN, V30; Sohn K, 2016, ADV NEUR IN, V29; Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Suh Y, 2019, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2019.00742; Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016; Triantafillou E, 2017, ADV NEUR IN, V30; Ustinova E., 2016, ADV NEURAL INFORM PR, V29, P4170; van der Maaten L, 2014, J MACH LEARN RES, V15, P3221; Wah C., 2011, TECH REP; Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI 10.1109/ICCV.2017.283; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wang XS, 2022, IEEE T PATTERN ANAL, V44, P5414, DOI [10.1109/TPAMI.2021.3068449, 10.1109/CVPR.2019.00535]; Wang XS, 2019, AAAI CONF ARTIF INTE, P5361; Wang X, 2020, PROC CVPR IEEE, P6387, DOI 10.1109/CVPR42600.2020.00642; Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; WIESEL TN, 1963, J NEUROPHYSIOL, V26, P978, DOI 10.1152/jn.1963.26.6.978; Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309; Xuan H, 2018, LECT NOTES COMPUT SC, V11220, P751, DOI 10.1007/978-3-030-01270-0_44; Yen IEH, 2016, PR MACH LEARN RES, V48; Yu T, 2018, LECT NOTES COMPUT SC, V11205, P191, DOI 10.1007/978-3-030-01246-5_12; Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94	76	101	102	11	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5414	5429		10.1109/TPAMI.2021.3068449	http://dx.doi.org/10.1109/TPAMI.2021.3068449			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33760730	hybrid, Green Accepted, Green Submitted			2022-12-18	WOS:000836666600065
J	Wang, WG; Shen, JB; Xie, JW; Cheng, MM; Ling, HB; Borji, A				Wang, Wenguan; Shen, Jianbing; Xie, Jianwen; Cheng, Ming-Ming; Ling, Haibin; Borji, Ali			Revisiting Video Saliency Prediction in the Deep Learning Era	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video saliency; dynamic visual attention; benchmark; deep learning	VISUAL-ATTENTION; DETECTION MODEL	Predicting where people look in static scenes, a.k.a visual saliency, has received significant research interest recently. However, relatively less effort has been spent in understanding and modeling visual attention over dynamic scenes. This work makes three contributions to video saliency research. First, we introduce a new benchmark, called DHF1K (Dynamic Human Fixation 1K), for predicting fixations during dynamic scene free-viewing, which is a long-time need in this field. DHF1K consists of 1K high-quality elaborately-selected video sequences annotated by 17 observers using an eye tracker device. The videos span a wide range of scenes, motions, object types and backgrounds. Second, we propose a novel video saliency model, called ACLNet (Attentive CNN-LSTM Network), that augments the CNN-LSTM architecture with a supervised attention mechanism to enable fast end-to-end saliency learning. The attention mechanism explicitly encodes static saliency information, thus allowing LSTM to focus on learning a more flexible temporal saliency representation across successive frames. Such a design fully leverages existing large-scale static fixation datasets, avoids overfitting, and significantly improves training efficiency and testing performance. Third, we perform an extensive evaluation of the state-of-the-art saliency models on three datasets : DHF1K, Hollywood-2, and UCF sports. An attribute-based analysis of previous saliency models and cross-dataset generalization are also presented. Experimental results over more than 1.2K testing videos containing 400K frames demonstrate that ACLNet outperforms other contenders and has a fast processing speed (40 fps using a single GPU). Our code and all the results are available at https://github.com/wenguanwang/DHF1K.	[Wang, Wenguan; Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China; [Wang, Wenguan; Shen, Jianbing] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Xie, Jianwen] Hikvis Res Inst, City Of Industry, CA 91748 USA; [Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, Nankai 300071, Peoples R China; [Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Borji, Ali] MarkableAI, New York, NY 11201 USA	Beijing Institute of Technology; Nankai University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Shen, JB (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.	wenguanwang.ai@gmail.com; shenjianbingcg@gmail.com; Jianwen.Xie@hikvision.com; cmm@nankai.edu.cn; hbling@temple.edu; aliborji@gmail.com	Wang, Wenguan/AAA-5782-2022; Cheng, Ming-Ming/A-2527-2009	Wang, Wenguan/0000-0002-0802-9567; Cheng, Ming-Ming/0000-0001-5550-8758; Ling, Haibin/0000-0003-4094-8413	Beijing Natural Science Foundation [4182056]; National Natural Science Foundation of China [61572264]; national youth talent support program; Tianjin Natural Science Foundation [17JCJQJC43700, 18ZXZNGX00110]; Specialized Fund for Joint Building Program of Beijing Municipal Education Commission	Beijing Natural Science Foundation(Beijing Natural Science Foundation); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); national youth talent support program; Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin); Specialized Fund for Joint Building Program of Beijing Municipal Education Commission	This work was supported in part by the Beijing Natural Science Foundation under Grant 4182056, the National Natural Science Foundation of China under Grant 61572264, the national youth talent support program, and the Tianjin Natural Science Foundation under grants 17JCJQJC43700 and 18ZXZNGX00110, and the Specialized Fund for Joint Building Program of Beijing Municipal Education Commission. A preliminary version of this work has appeared in CVPR 2018 [1].	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Agarwal G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P133; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2006, NIPS; Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710; Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49; Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338; Cerf M., 2008, ADV NEURAL INFORM PR, V20, P241, DOI DOI 10.1145/2185520.2185525; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377; Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819; Das Abhishek, 2016, P C EMP METH NAT LAN, P932; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875; Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549; Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613; Feichtenhofer C, 2015, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2015.7298892; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Gao D, 2008, ADV NEURAL INFORM PR, P497; Gao D., 2005, ADV NEURAL INFORM PR, P481; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Gorji S, 2018, PROC CVPR IEEE, P7501, DOI 10.1109/CVPR.2018.00783; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X., 2008, P ADV NEUR INF PROC; Hou YT, 2007, IEEE INFOCOM SER, P1, DOI 10.1109/INFCOM.2007.9; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Jeremy MWolfe, 2007, INTEGRATED MODELS CO, P1, DOI [DOI 10.1093/ACPROF:OSO/9780195189193.003.0008, 10.1093/acprof:oso/9780195189193.003.0008]; Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710; Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560; Judd T., 2012, MIT CSAIL TR; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138; Khatoonabadi SH, 2015, PROC CVPR IEEE, P5501, DOI 10.1109/CVPR.2015.7299189; Kingma D.P, P 3 INT C LEARNING R; Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Leboran V, 2017, IEEE T PATTERN ANAL, V39, P893, DOI 10.1109/TPAMI.2016.2567391; Leifman G, 2017, IEEE I CONF COMP VIS, P1707, DOI 10.1109/ICCV.2017.188; Li WC, 2017, INT CONF ACOUST SPEE, P3156, DOI 10.1109/ICASSP.2017.7952738; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu NA, 2018, IEEE T NEUR NET LEAR, V29, P392, DOI 10.1109/TNNLS.2016.2628878; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu Z, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P568, DOI 10.1109/ICIS.2009.165; Ma Y.-F., 2002, 2002 INT C IM PROC 2, pI; Ma YF, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P426, DOI 10.1109/ICIP.2001.958142; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z; MOTTER BC, 1994, J NEUROSCI, V14, P2178; Muthuswamy K, 2013, IEEE SIGNAL PROC LET, V20, P996, DOI 10.1109/LSP.2013.2277884; Pan JH, 2018, CRIT REV FOOD SCI, V58, P2026, DOI 10.1080/10408398.2017.1300134; Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152; Rush Alexander M, 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Shi XS, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P802, DOI 10.1109/IAEAC.2015.7428667; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sinha A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P161; Song H, 2018, JOINT INT CONF SOFT, P718, DOI 10.1109/SCIS-ISIS.2018.00119; T_ackstr_om O, 2016, P 2016 C EMP METH NA; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Wang W, 2019, ARXIV190409146; Wang W., 2019, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2017.2905607, DOI 10.1109/TPAMI.2017.2905607]; Wang W., 2019, P IEEE C COMP VIS PA, P3064, DOI DOI 10.1109/CVPR.2019.00318; Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514; Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612; Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594; Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784; Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013; Wischnewski M, 2010, COGN COMPUT, V2, P326, DOI 10.1007/s12559-010-9080-1; Xie E., 2019, P IEEE C COMP VIS PA; Xiong JY, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON BIOMEDICAL AND BIOINFORMATICS ENGINEERING (ICBBE 2018), P62, DOI 10.1145/3301879.3301883; Xu K., 2015, P INT C MACH LEARN; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925; Yu Y, 2017, PROC CVPR IEEE, P6119, DOI 10.1109/CVPR.2017.648; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zheng QH, 2007, WORM'07: PROCEEDINGS OF THE 2007 ACM WORKSHOP ON RECURRING MALCODE, P9	97	101	103	20	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					220	237		10.1109/TPAMI.2019.2924417	http://dx.doi.org/10.1109/TPAMI.2019.2924417			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31247542				2022-12-18	WOS:000597206900015
J	Bok, Y; Jeon, HG; Kweon, IS				Bok, Yunsu; Jeon, Hae-Gon; Kweon, In So			Geometric Calibration of Micro-Lens-Based Light Field Cameras Using Line Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational photography and camera; calibration; plenoptic; light field cameras		We present a novel method for the geometric calibration of micro-lens-based light field cameras. Accurate geometric calibration is the basis of various applications. Instead of using sub-aperture images, we directly utilize raw images for calibration. We select appropriate regions in raw images and extract line features from micro-lens images in those regions. For the entire process, we formulate a new projection model of a micro-lens-based light field camera, which contains a smaller number of parameters than previous models. The model is transformed into a linear form using line features. We compute the initial solution of both the intrinsic and the extrinsic parameters by a linear computation and refine them via non-linear optimization. Experimental results demonstrate the accuracy of the correspondences between rays and pixels in raw images, as estimated by the proposed method.	[Bok, Yunsu; Jeon, Hae-Gon; Kweon, In So] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Bok, Y (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.	ysbok@rcv.kaist.ac.kr; hgjeon@rcv.kaist.ac.kr; iskweon77@kaist.ac.kr	Kweon, In So/C-2023-2011; Jeon, Hae-Gon/W-5908-2019	Jeon, Hae-Gon/0000-0003-1105-1666	National Research Foundation of Korea (NRF) grant - Korea government (MSIP) [2010-0028680]	National Research Foundation of Korea (NRF) grant - Korea government (MSIP)(National Research Foundation of Korea)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680). The authors would like to thank Gyeongmin Choe and Jinsun Park for supporting our experiments. Hae-Gon Jeon is the corresponding author.	ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783; [Anonymous], 2016, 3D LIGHT FIELD CAM T; Bando Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451239; Bando Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409087; Bok Y, 2014, LECT NOTES COMPUT SC, V8694, P47, DOI 10.1007/978-3-319-10599-4_4; Cho D, 2014, LECT NOTES COMPUT SC, V8692, P90, DOI 10.1007/978-3-319-10593-2_7; Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137; Dansereau DG, 2011, IEEE INT C INT ROBOT, P4455, DOI 10.1109/IROS.2011.6048841; Dong FC, 2013, INT J ROBOT RES, V32, P206, DOI 10.1177/0278364912469420; Fanello SR, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601223; Georgiev T, 2010, COMPUT GRAPH FORUM, V29, P1955, DOI 10.1111/j.1467-8659.2010.01662.x; Heber S, 2014, LECT NOTES COMPUT SC, V8694, P751; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johannsen O., 2013, LECT NOTES COMPUTER, P302, DOI [DOI 10.1007/978-3-642-44964-2_15, 10.1007/ 978-3-642-44964-2_15]; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359; Liang CK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665075; Liang CK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360654; Lippmann G., 1908, J PHYS THEOR APPL, V7, P821, DOI [DOI 10.1051/JPHYSTAP:019080070082100, 10.1051/jphystap:019080070082100]; Ng, 2005, LIGHT FIELD PHOTOGRA; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Taguchi Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866194; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Vaish V, 2004, PROC CVPR IEEE, P2; Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347; Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289	29	101	116	1	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					287	300		10.1109/TPAMI.2016.2541145	http://dx.doi.org/10.1109/TPAMI.2016.2541145			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	26978556				2022-12-18	WOS:000395553400006
J	Cabral, R; De la Torre, F; Costeira, JP; Bernardino, A				Cabral, Ricardo; De la Torre, Fernando; Costeira, Joao Paulo; Bernardino, Alexandre			Matrix Completion for Weakly-Supervised Multi-Label Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly-supervised learning; multi-label image classification; segmentation; rank minimization; nuclear norm	RANK; RECOGNITION	In the last few years, image classification has become an incredibly active research topic, with widespread applications. Most methods for visual recognition are fully supervised, as they make use of bounding boxes or pixelwise segmentations to locate objects of interest. However, this type of manual labeling is time consuming, error prone and it has been shown that manual segmentations are not necessarily the optimal spatial enclosure for object classifiers. This paper proposes a weakly-supervised system for multi-label image classification. In this setting, training images are annotated with a set of keywords describing their contents, but the visual concepts are not explicitly segmented in the images. We formulate the weakly-supervised image classification as a low-rank matrix completion problem. Compared to previous work, our proposed framework has three advantages: (1) Unlike existing solutions based on multiple-instance learning methods, our model is convex. We propose two alternative algorithms for matrix completion specifically tailored to visual data, and prove their convergence. (2) Unlike existing discriminative methods, our algorithm is robust to labeling errors, background noise and partial occlusions. (3) Our method can potentially be used for semantic segmentation. Experimental validation on several data sets shows that our method outperforms state-of-the-art classification algorithms, while effectively capturing each class appearance.	[Cabral, Ricardo] Carnegie Mellon Univ, ECE Dept, Pittsburgh, PA 15213 USA; [Cabral, Ricardo; Costeira, Joao Paulo; Bernardino, Alexandre] Inst Super Tecn, ISR, Lisbon, Portugal; [De la Torre, Fernando] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Universidade de Lisboa; Instituto Superior Tecnico; Carnegie Mellon University	Cabral, R (corresponding author), Carnegie Mellon Univ, ECE Dept, Pittsburgh, PA 15213 USA.	rscabral@cmu.edu; torre@cs.cmu.edu; jpc@isr.ist.utl.pt; alex@isr.ist.utl.pt	Costeira, Joao P/D-8157-2013; Bernardino, Alexandre/G-1316-2010	Costeira, Joao P/0000-0001-6769-2935; Bernardino, Alexandre/0000-0003-3991-1269; Cabral, Ricardo/0000-0002-4919-8711	FCT (Portuguese Foundation for Science and Technology) through the Carnegie Mellon Portugal program [FCT/CMU/P11]; FCT [Printart PTDC/EEA-CRO/098822/2008, PEst-OE/EEI/LA0009/2013]; project Poeticon++ from the European FP7 program [288382]; NSF [IIS-1116583];  [CPS-0931999]	FCT (Portuguese Foundation for Science and Technology) through the Carnegie Mellon Portugal program; FCT(Portuguese Foundation for Science and TechnologyEuropean Commission); project Poeticon++ from the European FP7 program; NSF(National Science Foundation (NSF)); 	Support for this research was provided by the FCT (Portuguese Foundation for Science and Technology) through the Carnegie Mellon Portugal program under grant FCT/CMU/P11. Partially funded by FCT projects Printart PTDC/EEA-CRO/098822/2008 and PEst-OE/EEI/LA0009/2013 and project Poeticon++ from the European FP7 program (grant agreement no. 288382). Fernando De la Torre was partially supported by Grant CPS-0931999 and NSF IIS-1116583. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF).	[Anonymous], 2014, 2 INT C LEARN REPR I; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Balzano L., 2010, 2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton), P704, DOI 10.1109/ALLERTON.2010.5706976; Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654; Berg T. L., 2004, P ADV NEUR INF PROC, V17, P137; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; Cabral R. S., 2011, ADV NEURAL INFORM PR, P190; Cabral RS, 2011, IEEE IMAGE PROC, P1417, DOI 10.1109/ICIP.2011.6115706; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Candes EJ, 2008, ANN ALLERTON CONF, P806, DOI 10.1109/ALLERTON.2008.4797640; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Dai YC, 2010, LECT NOTES COMPUT SC, V6314, P396; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Desai C, 2009, IEEE I CONF COMP VIS, P229, DOI 10.1109/ICCV.2009.5459256; Deselaers T, 2010, LECT NOTES COMPUT SC, V6314, P452, DOI 10.1007/978-3-642-15561-1_33; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Duchi J., 2008, PROC 25 INT C MACH L, P272; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365; Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730; Fergus R, 2003, PROC CVPR IEEE, P264; Goldberg A., 2010, P NIPS, V23, P757; Harchaoui Z, 2012, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2012.6248078; Hiriart-Urruty J. B., 2001, FUNDAMENTALS CONVEX; Huang D, 2012, LECT NOTES COMPUT SC, V7575, P616, DOI 10.1007/978-3-642-33765-9_44; Jamieson M, 2007, IEEE 11 INT C COMP V, P1; Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205; Li F, 2010, P ADV NEUR INF PROC, V10, P1360; Lin Z., 2009, MATH PROGRAMMI UNPUB; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Loeff N, 2008, LECT NOTES COMPUT SC, V5305, P451, DOI 10.1007/978-3-540-88693-8_33; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341; Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426; MITCHELL TOM M., 1997, MACH LEARN, P2; Pirsiavash H., 2009, P ADV NEUR INF PROC, P1482; Razavian Ali Sharif, 2014, CVPR; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Toh KC, 2010, PAC J OPTIM, V6, P615; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vezhnevets A, 2010, PROC CVPR IEEE, P3249, DOI 10.1109/CVPR.2010.5540060; Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2011.5995545; Vijayanarasimhan S, 2009, PROC CVPR IEEE, P2262, DOI 10.1109/CVPRW.2009.5206705; Wang H, 2010, LECT NOTES COMPUT SC, V6316, P126, DOI 10.1007/978-3-642-15567-3_10; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xiong F, 2012, LECT NOTES COMPUT SC, V7576, P580, DOI 10.1007/978-3-642-33715-4_42; Yakhnenko O, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.59; Yang C., 2006, COMPUTER VISION PATT, P2057, DOI DOI 10.1109/CVPR.2006.250; Zha Zheng-Jun, 2008, CVPR, P1; Zhengdong Zhang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2321, DOI 10.1109/CVPR.2011.5995548; Zhou Zhi-Hua, 2006, ADV NEURAL INFORM PR, P1609; Zhu G., 2010, ACM MULT, P461	62	101	113	0	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					121	135		10.1109/TPAMI.2014.2343234	http://dx.doi.org/10.1109/TPAMI.2014.2343234			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353213				2022-12-18	WOS:000346970600011
J	Wang, XG; Wang, M; Li, W				Wang, Xiaogang; Wang, Meng; Li, Wei			Scene-Specific Pedestrian Detection for Static Video Surveillance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pedestrian detection; transfer learning; confidence-encoded SVM; domain adaptation; video surveillance		The performance of a generic pedestrian detector may drop significantly when it is applied to a specific scene due to the mismatch between the source training set and samples from the target scene. We propose a new approach of automatically transferring a generic pedestrian detector to a scene-specific detector in static video surveillance without manually labeling samples from the target scene. The proposed transfer learning framework consists of four steps. 1) Through exploring the indegrees from target samples to source samples on a visual affinity graph, the source samples are weighted to match the distribution of target samples. 2) It explores a set of context cues to automatically select samples from the target scene, predicts their labels, and computes confidence scores to guide transfer learning. 3) The confidence scores propagate among target samples according to their underlying visual structures. 4) Target samples with higher confidence scores have larger influence on training scene-specific detectors. All these considerations are formulated under a single objective function called confidence-encoded SVM, which avoids hard thresholding on confidence scores. During test, only the appearance-based detector is used without context cues. The effectiveness is demonstrated through experiments on two video surveillance data sets. Compared with a generic detector, it improves the detection rates by 48 and 36 percent at one false positive per image (FPPI) on the two data sets, respectively. The training process converges after one or two iterations on the data sets in experiments.	[Wang, Xiaogang; Wang, Meng; Li, Wei] Chinese Univ Hong Kong, Dept Elect Engn, Ho Sin Hang Engn Bldg, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Wang, XG (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Ho Sin Hang Engn Bldg, Shatin, Hong Kong, Peoples R China.		Wang, Xiaogang/L-4369-2014	Wang, Xiaogang/0000-0002-9021-0954	General Research Fund; Research Grants Council of Hong Kong [CUHK 417110, CUHK 417011, CUHK 419412]	General Research Fund; Research Grants Council of Hong Kong(Hong Kong Research Grants Council)	This work was supported by General Research Fund sponsored by Research Grants Council of Hong Kong (Project nos. CUHK 417110, CUHK 417011, and CUHK 419412).	Ali K., 2011, P IEEE C COMP VIS PA; [Anonymous], P IEEE C COMP VIS PA; [Anonymous], P IEEE WORKSH APPL C; [Anonymous], P IEEE C COMP VIS PA; Benenson R., 2012, P P IEEE C COMP VIS; Bengio Y., 2009, P INT C MACH LEARN I; Bose B., 2007, P IEEE C COMP VIS PA; Bourdev L., 2009, P 12 IEEE INT C COMP; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dai W., 2007, P 24 INT C MACH LEAR; Dalal N., 2005, HISTOGRAMS ORIENTED; Dalal N., 2006, P 9 EUR C COMP VIS E; Daume III H., 2010, P WORKSH DOM AD NAT; Dollar P., 2009, P IEEE C COMP VIS PA; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Enzweiler M., 2010, PROC IEEE CONF COMPU; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Geronimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Jain V., 2011, P IEEE C COMP VIS PA; Javed O., 2005, P IEEE C COMP VIS PA; Jiang W., 2008, P 15 IEEE INT C IM P; Kulis B., 2011, P IEEE C COMP VIS PA; Kumar M.P., 2010, P C NEUR INF PROC SY; LEVIN A, 2003, P 9 IEEE INT C COMP; LIN Z, 2007, P 11 IEEE INT C COMP; Liu J., 2011, P IEEE C COMP VIS PA; Mislove A, 2007, P 7 ACM SIGCOMM C IN; Nakajima C, 2003, PATTERN RECOGN, V36, P1997, DOI 10.1016/S0031-3203(03)00061-X; Ouyang W., 2013, P IEEE C COMP VIS PA; Ouyang Wanli, 2012, P IEEE C COMP VIS PA; Pang JB, 2011, IEEE T IMAGE PROCESS, V20, P1388, DOI 10.1109/TIP.2010.2103951; Qi G., 2011, P 20 INT C WORLD WID; Qi G.-J., 2011, P IEEE C COMP VIS PA; Roth P.M., 2005, P IEEE INT WORKSH VI; Roth PM, 2009, P IEEE C COMP VIS PA; Sabzmeydani P, 2007, P IEEE C COMP VIS PA; Schwartz W.R., 2009, P 12 IEEE INT C COMP; Stalder S., 2010, P 11 EUR C COMP VIS; Tomasi C., 1991, TECHNICAL REPORT; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Walk S., 2010, P IEEE C COMP VIS PA; Wang M., 2011, P IEEE C COMP VIS PA; Wang X, 2009, P IEEE C COMP VIS PA; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wojek C., 2009, P IEEE C COMP VIS PA; WU B., 2007, P IEEE C COMP VIS PA; Wu B., 2005, P 10 IEEE INT C COMP; Wu X., 2004, P 10 ACM SIGKDD INT; Yang J., 2007, P 15 ACM INT C MULT; Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770	55	101	107	0	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					361	374		10.1109/TPAMI.2013.124	http://dx.doi.org/10.1109/TPAMI.2013.124			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356355				2022-12-18	WOS:000328899500012
J	Hamsici, OC; Martinez, AM				Hamsici, Onur C.; Martinez, Aleix M.			Bayes optimality in linear discriminant analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear discriminant analysis; feature extraction; Bayes optimal; convex optimization; pattern recognition; data mining; data visualization	REDUCTION; LDA	We present an algorithm that provides the one-dimensional subspace, where the Bayes error is minimized for the C class problem with homoscedastic Gaussian distributions. Our main result shows that the set of possible one-dimensional spaces v, for which the order of the projected class means is identical, defines a convex region with associated convex Bayes error function g(v). This allows for the minimization of the error function using standard convex optimization algorithms. Our algorithm is then extended to the minimization of the Bayes error in the more general case of heteroscedastic distributions. This is done by means of an appropriate kernel mapping function. This result is further extended to obtain the d-dimensional solution for any given d by iteratively applying our algorithm to the null space of the (d - 1)-dimensional solution. We also show how this result can be used to improve upon the outcomes provided by existing algorithms and derive a low-computational cost, linear approximation. Extensive experimental validations are provided to demonstrate the use of these algorithms in classification, data analysis and visualization.	[Hamsici, Onur C.; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Hamsici, OC (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, 2015 Neil Ave, Columbus, OH 43210 USA.	hamsicio@ece.osu.edu; aleix@ece.osu.edu	Martinez, Aleix M/A-2380-2008		NIDCD NIH HHS [R01 DC 005241] Funding Source: Medline; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC005241] Funding Source: NIH RePORTER	NIDCD NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))		[Anonymous], [No title captured]; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Beiden SV, 2003, IEEE T PATTERN ANAL, V25, P1561, DOI 10.1109/TPAMI.2003.1251149; Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671, DOI 10.1109/TPAMI.1983.4767461; Gill PE, 1991, NUMERICAL LINEAR ALG, V1; Leibe B., 2003, P IEEE C COMP VIS PA; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Lotlikar R, 2000, IEEE T PATTERN ANAL, V22, P623, DOI 10.1109/34.862200; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Mika S., 1999, P IEEE NEUR NETW SIG; Newman D.J., UCI REPOSITORY MACHI; Phillips P.J., 2005, P IEEE C COMP VIS PA; Rao CR, 2002, LINEAR STAT INFERENC; SCHERVISH MJ, 1984, J STAT PLAN INFER, V10, P167, DOI 10.1016/0378-3758(84)90068-5; Sommer M, 2004, INT J AVIAT PSYCHOL, V14, P103, DOI 10.1207/s15327108ijap1401_6; VERBECK BB, 2002, P NATL ACAD SCI USA, V99, P13172; Yang J, 2004, J CHROMATOGR B, V813, P53, DOI 10.1016/j.jchromb.2004.09.023; Ye JP, 2004, IEEE ACM T COMPUT BI, V1, P181, DOI 10.1109/TCBB.2004.45	22	101	103	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					647	657		10.1109/TPAMI.2007.70717	http://dx.doi.org/10.1109/TPAMI.2007.70717			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276970				2022-12-18	WOS:000253135600008
J	Barbu, A; Zhu, SC				Barbu, A; Zhu, SC			Generalizing Swendsen-Wang to sampling arbitrary posterior probabilities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Swendsen-Wang; cluster sampling; Markov chain Monte Carlo; Bayesian inference; image segmentation; stereo matching	IMAGE SEGMENTATION; MONTE-CARLO; MARKOV-CHAINS; OPTIMIZATION; VISION	Many vision tasks can be formulated as graph partition problems that minimize energy functions. For such problems, the Gibbs sampler [9] provides a general solution but is very slow, while other methods, such as Ncut [24] and graph cuts [4], [22], are computationally effective but only work for specific energy forms [17] and are not generally applicable. In this paper, we present a new inference algorithm that generalizes the Swendsen-Wang method [25] to arbitrary probabilities defined on graph partitions. We begin by computing graph edge weights, based on local image features. Then, the algorithm iterates two steps. 1) Graph clustering: It forms connected components by cutting the edges probabilistically based on their weights. 2) Graph relabeling: It selects one connected component and flips probabilistically, the coloring of all vertices in the component simultaneously. Thus, it realizes the split, merge, and regrouping of a "chunk" of the graph, in contrast to Gibbs sampler that flips a single vertex. We prove that this algorithm simulates ergodic and reversible Markov chain jumps in the space of graph partitions and is applicable to arbitrary posterior probabilities or energy functions defined on graphs. We demonstrate the algorithm on two typical problems in computer vision-image segmentation and stereo vision. Experimentally, we show that it is 100-400 times faster in CPU time than the classical Gibbs sampler and 20-40 times faster then the DDMCMC segmentation algorithm [27]. For stereo, we compare performance with graph cuts and belief propagation. We also show that our algorithm can automatically infer generative models and obtain satisfactory results ( better than the graphic cuts or belief propagation) in the same amount of time.	Univ Calif Los Angeles, Dept Comp Sci & Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Barbu, A (corresponding author), Univ Calif Los Angeles, Dept Comp Sci & Stat, 8125 Math Sci Bldg, Los Angeles, CA 90095 USA.	abarbu@ucla.edu; sczhu@stat.ucla.edu	Barbu, Adrian/C-6865-2009	Barbu, Adrian/0000-0002-9548-7872				BARBU A, 2004, P IEEE C COMP VIS PA; BARKER SA, 1998, P SPIE C BAYES INF I, P200; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cooper C, 1999, RANDOM STRUCT ALGOR, V15, P242, DOI 10.1002/(SICI)1098-2418(199910/12)15:3/4<242::AID-RSA4>3.0.CO;2-C; EDWARDS RG, 1988, PHYS REV D, V38, P2009, DOI 10.1103/PhysRevD.38.2009; FOX C, 2000, P 20 INT WORKSH BAYE; Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gore VK, 1999, J STAT PHYS, V97, P67, DOI 10.1023/A:1004610900745; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HIGDON D, 1996, I STAT DECISION SCI; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Huber M, 2003, RANDOM STRUCT ALGOR, V22, P43, DOI 10.1002/rsa.10071; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOLMOGOROV V, 2002, P EUR C COMP VIS, V3, P65; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419; Propp JG, 1996, RANDOM STRUCT ALGOR, V9, P223, DOI 10.1002/(SICI)1098-2418(199608/09)9:1/2<223::AID-RSA14>3.0.CO;2-O; Puzicha J, 2000, PATTERN RECOGN, V33, P617, DOI 10.1016/S0031-3203(99)00076-X; ROY S, 1998, P INT C COMP VIS; Scharstein Daniel, 2002, INT J COMPUTER VISIO; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; TAPPEN MF, 2003, P INT C COMP VISION; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; TU ZW, 2002, P EUR C COMP VIS; Wang JJ, 1999, HUM BRAIN MAPP, V8, P170, DOI 10.1002/(SICI)1097-0193(1999)8:4<170::AID-HBM2>3.0.CO;2-W; WINKLER G, 1995, IMAGE ANAL RANDOM FI, P171; WOLFF U, 1989, PHYS REV LETT, V62, P361, DOI 10.1103/PhysRevLett.62.361; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; YEDIDIA JS, 2000, TR200026 MERL; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; [No title captured]	34	101	107	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1239	1253		10.1109/TPAMI.2005.161	http://dx.doi.org/10.1109/TPAMI.2005.161			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119263				2022-12-18	WOS:000229700900005
J	Jermyn, IH; Ishikawa, H				Jermyn, IH; Ishikawa, H			Globally optimal regions and boundaries as minimum ratio weight cycles	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						region identification; ratio; energy minimization; global optimum; active contour; snake; segmentation	CLOSURE	We describe anew form of energy functional for the modeling and identification of regions in images. The energy is defined on the space of boundaries in the image domain and can incorporate very general combinations of modeling information both from the boundary (intensity gradients, etc.) and from the interior of the region (texture, homogeneity, etc.). We describe two polynomial-time digraph algorithms for finding the global minima of this energy. One of the algorithms is completely general, minimizing the functional for any choice of modeling information. It runs in a few seconds on a 256x256 image. The other algorithm applies to a subclass of functionals, but has the advantage of being extremely parallelizable. Neither algorithm requires initialization.	NYU, Courant Inst Math Sci, New York, NY 10012 USA; INRIA Sophia Antipolis, F-06902 Sophia Antipolis, France	New York University	Jermyn, IH (corresponding author), INRIA Sophia Antipolis, 2004 Route Lucioles BP 93, F-06902 Sophia Antipolis, France.	Ian.Jermyn@sophia.inria.fr; ishikawa@cs.nyu.edu						AHUJA RK, 1993, NETWORK FLOWS THEORY, P133; AMINI AA, 1988, P 2 INT C COMP VIS, P95; COX IJ, 1996, P INT C PATT REC, V2, P557; DANTZIG GB, 1966, P INT S THEOR GRAPHS, P77; ELDER J, 1994, VISION RES, V34, P3361, DOI 10.1016/0042-6989(94)90070-1; ELDER J, 1993, VISION RES, V33, P981, DOI 10.1016/0042-6989(93)90080-G; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; GEIGER D, 1993, IEEE T PATTERN ANAL, V17; GUY G, 1996, P INT J COMPUTER VIS, V20; Henzinger MR, 1997, J COMPUT SYST SCI, V55, P3, DOI 10.1006/jcss.1997.1493; ISHIKAWA H, 2001, P 8 IEEE INT C COMP; Jermyn I. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P904, DOI 10.1109/ICCV.1999.790318; KANIZA G, 1979, ORG VISION ESSAYS GE; KARP RM, 1978, DISCRETE MATH, V23, P309, DOI 10.1016/0012-365X(78)90011-0; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495; LAWLER E. L., 1966, P INT S THEORY GRAPH, P209; LEUNG T, 1998, P EUR C COMP VIS; MAHAMUD S, 1999, P 7 IEEE INT C COMP; MEGGIDO N, 1979, MATH OPER RES, V4, P414; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; PARENT P, 1989, IEEE T PATTERN ANAL, V11; Seiffert AE, 1998, VISION RES, V38, P3569, DOI 10.1016/S0042-6989(98)00035-2; SHASHUA A, 1988, P 2 INT C COMP VIS; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SPERLING G, 1989, Spatial Vision, V4, P183, DOI 10.1163/156856889X00112; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; WILLIAMS L, 1997, NEURAL COMPUT, V9, P849; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	31	101	104	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1075	1088		10.1109/34.954599	http://dx.doi.org/10.1109/34.954599			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK		Green Accepted			2022-12-18	WOS:000171586600003
J	McNames, J				McNames, J			A fast nearest-neighbor algorithm based on a principal axis search tree	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor; vector quantization encoding; principal components analysis; closest point; intrinsic dimension; post office problem	VECTOR QUANTIZATION	A new fast nearest-neighbor algorithm is described that uses principal component analysis to build an efficient search tree. At each node in the tree, the data set is partitioned along the direction of maximum variance. The search algorithm efficiently uses a depth-first search and a new elimination criterion. The new algorithm was compared to 16 other fast nearest-neighbor algorithms on three types of common benchmark data sets including problems from time series prediction and image vector quantization. This comparative study illustrates the strengths and weaknesses of all of the leading algorithms. The new algorithm performed very well on all of the data sets and was consistently ranked among the top three algorithms.	Portland State Univ, Dept Elect & Comp Engn, Portland, OR 97207 USA	Portland State University	McNames, J (corresponding author), Portland State Univ, Dept Elect & Comp Engn, POB 751, Portland, OR 97207 USA.							Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Baek S, 1997, IEEE SIGNAL PROC LET, V4, P325, DOI 10.1109/97.650035; BAKAMIDIS SG, 1993, IEEE INT C AC SPEECH, V5, P658; CHEN CY, 1995, PATTERN RECOGN LETT, V16, P339, DOI 10.1016/0167-8655(94)00109-G; CHEN SH, 1989, IEE PROC-I, V136, P391, DOI 10.1049/ip-i-2.1989.0059; Chen TS, 1997, IEEE T CIRC SYST VID, V7, P555, DOI 10.1109/76.585935; CHEN Y, 1984, SHIPIN YU FAJIAO GON, V1, P11; Franti P, 1997, OPT ENG, V36, P3043, DOI 10.1117/1.601531; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Katsavounidis I, 1996, IEEE T IMAGE PROCESS, V5, P398, DOI 10.1109/83.480778; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761, DOI 10.1109/TPAMI.1986.4767859; Lin YC, 1996, OPT ENG, V35, P2921, DOI 10.1117/1.600976; LUBIARZ S, 1997, P IEEE INT C AC SPEE, V2, P1491; McNames J., 1998, P INT WORKSH ADV BLA, P112; MCNAMES J, 1999, THESIS STANFORD U; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; POGGI G, 1993, ELECTRON LETT, V29, P1141, DOI 10.1049/el:19930761; SOLEYMANI MR, 1987, IEEE T COMMUN, V35, P677, DOI 10.1109/TCOM.1987.1096830; Tai SC, 1996, IEEE T COMMUN, V44, P1623, DOI 10.1109/26.545888; Weigend A. S, 1994, TIME SERIES PREDICTI; Wu KS, 1996, J CHIN INST ENG, V19, P719, DOI 10.1080/02533839.1996.9677837	24	101	111	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2001	23	9					964	976		10.1109/34.955110	http://dx.doi.org/10.1109/34.955110			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	470RP					2022-12-18	WOS:000170885200003
J	Lee, KM; Meer, P; Park, RH				Lee, KM; Meer, P; Park, RH			Robust adaptive segmentation of range images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust methods; least kth order squares; range image segmentation; surface fitting; autonomous image analysis	COMPUTER VISION; ESTIMATOR	We propose a novel image segmentation technique using the robust, adaptive least Mh order squares (ALKS) estimator which minimizes the Mh order statistics of the squared of residuals. The optimal value of k is determined from the data, and the procedure detects the homogeneous surface patch representing the relative majority of the pixels. The ALKS shows a better tolerance to structured outliers than other recently proposed similar techniques: Minimize the Probability of Randomness (MINPRAN) and Residual Consensus (RESC). The performance of the new, fully autonomous, range image segmentation algorithm is compared to several other methods.	Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08855 USA; Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea	Rutgers State University New Brunswick; Sogang University	Lee, KM (corresponding author), Samsung Elect Co Ltd, Comp Div, Mobile R&D Grp, 416 Maetan-3 Dong, Suwon 442742, Kyungki Do, South Korea.	kmlee@tongky.sec.samsung.co.kr; meer@caip.rutgers.edu; rhpark@ccs.sogang.ac.kr	Park, Rae-Hong/Q-7908-2019; Park, Rae-Hong/Q-7955-2019	Park, Rae-Hong/0000-0002-4792-2980				ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; BESL PJ, 1988, SURFACES RANGE IMAGE; Bolles R.C., 1981, P 7 INT JOINT C ART, V1981, P637; BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P987, DOI 10.1109/34.329010; FAN TJ, 1987, IEEE T ROBOTIC AUTOM, V3, P527; Haralick RM., 1992, COMPUTER ROBOT VISIO; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KOIVUNEN V, 1992, P 11 INT C PATT REC, V3, P214; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Meer P., 1990, P DARPA IM UND WORKS, P231; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; MINTZ D, 1992, P 1991 DARPA IM UND, P345; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; STEWART CV, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P969, DOI 10.1109/ICCV.1995.466829; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443; [No title captured]	22	101	107	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					200	205		10.1109/34.659940	http://dx.doi.org/10.1109/34.659940			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800009
J	LAI, KF; CHIN, RT				LAI, KF; CHIN, RT			DEFORMABLE CONTOURS - MODELING AND EXTRACTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DEFORMABLE MODEL; RIGID TEMPLATE; SNAKE; ACTIVE CONTOUR; BOUNDARY EXTRACTION		This paper considers the problem of modeling and extracting arbitrary deformable contours from noisy images, We propose a global contour model based on a stable and regenerative shape matrix, which is invariant and unique under rigid motions. Combined with Markov random field to model local deformations, this yields prior distribution that exerts influence over a global model while allowing for deformations, We then cast the problem of extraction into posterior estimation and show its equivalence to energy minimization of a generalized active contour model. We discuss pertinent issues in shape training, energy minimization, line search strategies, minimax regularization and initialization by generalized Hough transform. Finally, we present experimental results and compare its performance to rigid template matching.	UNIV WISCONSIN,MADISON,WI 53706; HONG KONG UNIV SCI & TECHNOL,HONG KONG,HONG KONG	University of Wisconsin System; University of Wisconsin Madison; Hong Kong University of Science & Technology			Chin, Roland Tai Hong/E-9856-2010					AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BLAKE A, 1993, P 4 INT C COMP VIS B, P66; Grimson W. E. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P316, DOI 10.1109/CVPR.1992.223257; HINTON GE, 1992, NEURAL INFORMATION P, V4, P512; KASS M, 1987, 1ST P INT C COMP VIS, P259; LAI KF, 1993, AS C COMP VIS, P542; POGGIO T, 1984, P AARPA IM UND WORKS, P257; SRIMSON WL, 1990, IEEE T PATTERN ANAL, V12, P255; SUBRAHMONIA J, 1992, CURVES SURFACES COMP, V3, P104; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836	13	101	127	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1084	1090		10.1109/34.473235	http://dx.doi.org/10.1109/34.473235			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854		Green Submitted			2022-12-18	WOS:A1995TD85400007
J	Elnaggar, A; Heinzinger, M; Dallago, C; Rehawi, G; Wang, Y; Jones, L; Gibbs, T; Feher, T; Angerer, C; Steinegger, M; Bhowmik, D; Rost, B				Elnaggar, Ahmed; Heinzinger, Michael; Dallago, Christian; Rehawi, Ghalia; Wang, Yu; Jones, Llion; Gibbs, Tom; Feher, Tamas; Angerer, Christoph; Steinegger, Martin; Bhowmik, Debsindhu; Rost, Burkhard			ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Proteins; Training; Amino acids; Task analysis; Databases; Computational modeling; Three-dimensional displays; Computational biology; high performance computing; machine learning; language modeling; deep learning	PROTEIN SECONDARY STRUCTURE; NEURAL-NETWORKS; PREDICTION; LOCALIZATION	Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models (LMs) taken from Natural Language Processing (NLP). These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The protein LMs (pLMs) were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw pLM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks: (1) a per-residue (per-token) prediction of protein secondary structure (3-state accuracy Q3=81%-87%); (2) per-protein (pooling) predictions of protein sub-cellular location (ten-state accuracy: Q10=81%) and membrane versus water-soluble (2-state accuracy Q2=91%). For secondary structure, the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without multiple sequence alignments (MSAs) or evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that pLMs learned some of the grammar of the language of life. All our models are available through https://github.com/agemagician/ProtTrans.	[Elnaggar, Ahmed; Heinzinger, Michael; Dallago, Christian; Rehawi, Ghalia; Rost, Burkhard] Tech Univ Munich TUM, Dept Informat Bioinformat & Computat Biol i12, D-85748 Garching, Germany; [Wang, Yu] Med AI Technol Wu Xi Ltd, Wuxi 214000, Jiangsu, Peoples R China; [Jones, Llion] Google, Google AI, Mountain View, CA 94043 USA; [Gibbs, Tom; Feher, Tamas; Angerer, Christoph] NVIDIA, Santa Clara, CA 95051 USA; [Steinegger, Martin] Seoul Natl Univ, Sch Biol Sci, Seoul 08826, South Korea; [Bhowmik, Debsindhu] Oak Ridge Natl Lab, POB 2009, Oak Ridge, TN 37830 USA	Technical University of Munich; Google Incorporated; Nvidia Corporation; Seoul National University (SNU); United States Department of Energy (DOE); Oak Ridge National Laboratory	Elnaggar, A (corresponding author), Tech Univ Munich TUM, Dept Informat Bioinformat & Computat Biol i12, D-85748 Garching, Germany.	ahmed.elnaggar@tum.de; mheinzinger@rostlab.org; christian@dallago.us; ghalia.rihawi93@gmail.com; wang_yu@hotmail.com; llion@google.com; tgibbs@nvidia.com; tfeher@nvidia.com; cangerer@nvidia.com; martin.steinegger@snu.ac.kr; bhowmikd@ornl.gov; assistant@rostlab.org		Rehawi, Ghalia/0000-0001-5115-8658	Software Campus 2.0 (TUM) through the German Ministry for Research and Education (BMBF); Alexander von Humboldt foundation through the German Ministry for Research and Education (BMBF); Deutsche Forschungsgemeinschaft [DFG-GZ: RO1320/4-1]; NVIDIA; National Research Foundation of Korea [2019R1A6A1A10073437, NRF-2020M3A9G7103933]; SeoulNational University; Google Cloud; Google Cloud Research Credits Program under Covid19 HPC Consortium grant; DOE Office of Science User Facility [DEAC05-00OR22725]; TPU pods under TensorFlow Research Cloud grant	Software Campus 2.0 (TUM) through the German Ministry for Research and Education (BMBF)(Federal Ministry of Education & Research (BMBF)); Alexander von Humboldt foundation through the German Ministry for Research and Education (BMBF); Deutsche Forschungsgemeinschaft(German Research Foundation (DFG)); NVIDIA; National Research Foundation of Korea(National Research Foundation of Korea); SeoulNational University; Google Cloud(Google Incorporated); Google Cloud Research Credits Program under Covid19 HPC Consortium grant; DOE Office of Science User Facility(United States Department of Energy (DOE)); TPU pods under TensorFlow Research Cloud grant	The authors would like to thank Tim Karl, TUM, and Jian Kong, TUM, for invaluable help with hard-and software, Inga Weise, TUM, and Aline Schmidt, TUM, for support with many other aspects of this work, Florian Matthes, TUM, for his generous support and encouragement, crucial support and feedback from NVIDIA, in particular to Ulrich Michaelis, Ada Sedova, Geetika Gupta, Axel Koehler, Frederic Pariente, Jonathan Lefman, and Thomas Bradley, and many at ORNL without whom no aspect of this work could have been realized, particular thanks to John Gounley, Hong-Jun Yoon, Georgia Tourassi, Bill, Brian, Junqi, Graham, and Ver~onica (ORNL Summit). The authors would also like to thank Jack Wells (ORNL) for opening the door to kicking off this project. From IBM, the authors would like to thank Nicolas Castet and Bryant Nelson for their help to fix issues and enhance the performance of IBM PowerAI. From Google, the authors would like to thank Jamie Kinney, Alex Schroeder, Nicole DeSantis, Andrew Stein, Vishal Mishra, Eleazar Ortiz, Nora Limbourg, Cristian Mezzanotte, and all TFRC Team for helping to setup a project on Google Cloud and solving Google cloud issues. No ProtTrans model was easily publicly available without support from the Hugging Face team, including Patrick von Platen, Julien Chaumond, and Clement Delangue. The authors would also like to thank Konstantin Wei ss enow for helping with grant writing and providing early results for the structure prediction task. The authors would also like to thank both Adam Roberts and Colin Raffel for help with the T5 model, and the editor and the anonymous reviewers for essential criticism, especially, for suggesting to compare t-SNEs to randomly initialized models. The authors would also like to thank Leibniz Rechenzentrum (LRZ) for providing access to DGX-1(V100) for the testing phase. This work was supported in part by Software Campus 2.0 (TUM) through the German Ministry for Research and Education (BMBF), in part by the Alexander von Humboldt foundation through the German Ministry for Research and Education (BMBF), in part by the Deutsche Forschungsgemeinschaft under Grant DFG-GZ: RO1320/4-1, and in part by NVIDIA with the donation of 2 Titan GPUs used for the development phase. The work of Martin Steinegger was supported in part by the National Research Foundation of Korea under Grants 2019R1A6A1A10073437 and NRF-2020M3A9G7103933, in part by the New Faculty Startup Fund and the Creative-Pioneering Researchers Program through SeoulNational University. The work of Rostlab was supported in part by Google Cloud and in part by Google Cloud Research Credits Program to fund this project under Covid19 HPC Consortium grant. This work used resources of the Oak Ridge National Laboratory (ORNL) Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Grant DEAC05-00OR22725, and resources of TPU pods under TensorFlow Research Cloud grant. A. Elnaggar and M. Heinzinger contributed equally to thiswork.	Abadi M., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467; Abriata LA, 2018, PROTEINS, V86, P97, DOI 10.1002/prot.25423; Adam Roberts, 2020, Arxiv, DOI arXiv:1910.10683; Aditya Ramesh, 2020, Arxiv, DOI arXiv:2005.14165; Alec Radford, 2019, Arxiv, DOI arXiv:1904.10509; Alexander Sergeev, 2018, Arxiv, DOI arXiv:1802.05799; Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1; AlQuraishi M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2932-0; AlQuraishi M, 2019, CELL SYST, V8, P292, DOI 10.1016/j.cels.2019.03.006; ANFINSEN C, 1961, J BIOL CHEM, V236, P1361; Armenteros J. J. A., 2020, BIORXIV; Armenteros JJA, 2017, BIOINFORMATICS, V33, P3387, DOI 10.1093/bioinformatics/btx431; Asgari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141287; BAIROCH A, 1991, NUCLEIC ACIDS RES, V19, P2247, DOI 10.1093/nar/19.suppl.2247; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Bateman A, 2019, NUCLEIC ACIDS RES, V47, pD506, DOI 10.1093/nar/gky1049; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bernhofer M, 2021, NUCLEIC ACIDS RES, V49, pW535, DOI 10.1093/nar/gkab354; Bernhofer M, 2016, PROTEINS, V84, P1706, DOI 10.1002/prot.25155; Bryan Catanzaro, 2020, Arxiv, DOI arXiv:1909.08053; Chandonia JM, 2019, NUCLEIC ACIDS RES, V47, pD475, DOI 10.1093/nar/gky1134; Cho-Jui Hsieh, 2020, Arxiv, DOI arXiv:1904.00962; Christopher Clark, 2018, Arxiv, DOI arXiv:1802.05365; Christopher D. Manning, 2020, Arxiv, DOI arXiv:2003.10555; Coin L, 2003, P NATL ACAD SCI USA, V100, P4516, DOI 10.1073/pnas.0737502100; Cuff JA, 1999, PROTEINS, V34, P508, DOI 10.1002/(SICI)1097-0134(19990301)34:4<508::AID-PROT10>3.0.CO;2-4; David Kung, 2017, Arxiv, DOI arXiv:1708.02188; Dessailly BH, 2009, STRUCTURE, V17, P869, DOI 10.1016/j.str.2009.03.015; Drozdetskiy A, 2015, NUCLEIC ACIDS RES, V43, pW389, DOI 10.1093/nar/gkv332; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Elrod-Erickson M, 1998, STRUCTURE, V6, P451, DOI 10.1016/S0969-2126(98)00047-1; F. Limited, 2019, PRESS RELEASE ANNOUN; Gaurav Singh Tomar, 2019, Arxiv, DOI arXiv:1909.11218; github.com, NVIDIA APEX; Goldberg T, 2012, BIOINFORMATICS, V28, pI458, DOI 10.1093/bioinformatics/bts390; Google TPU, TPU DOCS SYST; Hammer N, 2016, ARXIV; Haruki Imai, 2019, Arxiv, DOI arXiv:1807.02037; Heffernan R, 2017, BIOINFORMATICS, V33, P2842, DOI 10.1093/bioinformatics/btx218; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Hopf TA, 2012, CELL, V149, P1607, DOI 10.1016/j.cell.2012.04.012; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jacob Devlin, 2019, Arxiv, DOI arXiv:1810.04805; Jaime Carbonell, 2019, Arxiv, DOI arXiv:1901.02860; Jaime Carbonell, 2020, Arxiv, DOI arXiv:1906.08237; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jeff Rasley, 2020, Arxiv, DOI arXiv:1910.02054; Jeremy Howard, 2018, Arxiv, DOI arXiv:1801.06146; Feng JW, 2018, Arxiv, DOI arXiv:1808.00079; John J., 2020, 14 CRITICAL ASSESSME; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Kevin Gimpel, 2020, Arxiv, DOI arXiv:1909.11942; Kirk D., 2007, ISMM, V7, P103, DOI DOI 10.1145/1296907.1296909; Kitaev Nikita, 2020, ARXIV; Klausen MS, 2019, PROTEINS, V87, P520, DOI 10.1002/prot.25674; Kosciolek T, 2016, PROTEINS, V84, P145, DOI 10.1002/prot.24863; Kulandaisamy A, 2020, HUM MUTAT, V41, P581, DOI 10.1002/humu.23961; Lin MM, 2012, P NATL ACAD SCI USA, V109, P9851, DOI 10.1073/pnas.1207382109; Littmann M., 2021, SCI REP-UK, V11, P1; Marks DS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028766; Marquet C, 2022, HUM GENET, V141, P1629, DOI 10.1007/s00439-021-02411-y; Nambiar A, 2020, BIORXIV; Paszke A, 2019, ADV NEUR IN, V32; Perdigao N, 2015, P NATL ACAD SCI USA, V112, P15898, DOI 10.1073/pnas.1508380112; Radivojac P, 2004, PROTEIN SCI, V13, P71, DOI 10.1110/ps.03128904; Rao R. M., 2020, BIORXIV; Rao R, 2021, PR MACH LEARN RES, V139; Rao RS, 2019, ADV NEUR IN, V32; Rives A., 2019, BIORXIV, DOI 10.1101/622803https://www.biorxiv.org/content/10.1101/622803v3.; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Rost B, 1996, ANNU REV BIOPH BIOM, V25, P113, DOI 10.1146/annurev.bb.25.060196.000553; Rost B, 1996, METHOD ENZYMOL, V266, P525; ROST B, 1993, P NATL ACAD SCI USA, V90, P7558, DOI 10.1073/pnas.90.16.7558; Rost B, 1996, CURR OPIN BIOTECH, V7, P457, DOI 10.1016/S0958-1669(96)80124-8; Schafferhans A, 2018, PROTEOMICS, V18, DOI 10.1002/pmic.201800227; Schelling M, 2018, PROTEINS, V86, P1064, DOI 10.1002/prot.25585; Min SW, 2019, Arxiv, DOI arXiv:1912.05625; St _ark H., 2021, BIORXIV; Steinegger M, 2019, NAT METHODS, V16, P603, DOI 10.1038/s41592-019-0437-4; Steinegger M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04964-5; Steinegger M, 2017, NAT BIOTECHNOL, V35, P1026, DOI 10.1038/nbt.3988; Suzek BE, 2015, BIOINFORMATICS, V31, P926, DOI 10.1093/bioinformatics/btu739; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang S, 2016, SCI REP-UK, V6, DOI 10.1038/srep18962; Wang S, 2016, NUCLEIC ACIDS RES, V44, pW430, DOI 10.1093/nar/gkw306; Wells J., 2016, ANNOUNCING SUPERCOMP; Yang JY, 2020, P NATL ACAD SCI USA, V117, P1496, DOI 10.1073/pnas.1914677117; Yang YD, 2018, BRIEF BIOINFORM, V19, P482, DOI 10.1093/bib/bbw129	99	100	102	30	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					7112	7127		10.1109/TPAMI.2021.3095381	http://dx.doi.org/10.1109/TPAMI.2021.3095381			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34232869	hybrid, Green Submitted			2022-12-18	WOS:000853875300088
J	Seo, HJ; Milanfar, P				Seo, Hae Jong; Milanfar, Peyman			Training-Free, Generic Object Detection Using Locally Adaptive Regression Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; image representation; correlation and regression analysis	BAYES DECISION RULE; IMAGE; RECOGNITION; REPRESENTATION; SCENE; SHAPE	We present a generic detection/localization algorithm capable of searching for a visual object of interest without training. The proposed method operates using a single example of an object of interest to find similar matches, does not require prior knowledge (learning) about objects being sought, and does not require any preprocessing step or segmentation of a target image. Our method is based on the computation of local regression kernels as descriptors from a query, which measure the likeness of a pixel to its surroundings. Salient features are extracted from said descriptors and compared against analogous features from the target image. This comparison is done using a matrix generalization of the cosine similarity measure. We illustrate optimality properties of the algorithm using a naive-Bayes framework. The algorithm yields a scalar resemblance map, indicating the likelihood of similarity between the query and all patches in the target image. By employing nonparametric significance tests and nonmaxima suppression, we detect the presence and location of objects similar to the given query. The approach is extended to account for large variations in scale and rotation. High performance is demonstrated on several challenging data sets, indicating successful detection of objects in diverse contexts and under different imaging conditions.	[Seo, Hae Jong; Milanfar, Peyman] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Seo, HJ (corresponding author), Univ Calif Santa Cruz, 1156 High St,Mailcode SOE2, Santa Cruz, CA 95064 USA.	rokaf@soe.ucsc.edu; milanfar@soe.ucsc.edu	Milanfar, Peyman/B-2551-2009		US Air Force Office [FA 9550-07-01-0365]	US Air Force Office	This work was supported in part by US Air Force Office of Scientific Research Grant FA 9550-07-01-0365.	Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242; Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BENGIO Y, 2005, ADV NEURAL INFORM PR, V18, P115; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9; Brox T, 2007, LECT NOTES COMPUT SC, V4814, P152; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Calinski T, 2006, COMMUN STAT-SIMUL C, V35, P727, DOI 10.1080/03610910600716290; CHANDRASEKHAR V, 2009, P C VIS COMM IM PROC; CHEN DM, 2009, P IEEE DAT COMPR C M; Devernay F, 1995, RR2724 I NAT RECH IN; Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36; Duda R.O., 2000, PATTERN CLASSIFICATI; ESCOUFIER Y, 2006, P 17 S COMP STAT, P285; Everingham M, 2009, PASCAL VISUAL OBJECT; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154; Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203; Grauman K, 2007, J MACH LEARN RES, V8, P725; Han SH, 2008, IEEE IMAGE PROC, P1700, DOI 10.1109/ICIP.2008.4712101; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; HORST P, 1963, MATRIX ALGEBRA SOCIA; Jurie F, 2005, IEEE I CONF COMP VIS, P604; Kapoor A, 2006, LECT NOTES COMPUT SC, V3953, P302, DOI 10.1007/11744078_24; Kay S. M., 1993, FUNDAMENTALS STAT SI; Ke Y, 2004, PROC CVPR IEEE, P506; Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529; Kim T., 2007, 2007 IEEE INSTRUMENT, P1, DOI 10.1109/IMTC.2007.379340; Kumar N, 2008, LECT NOTES COMPUT SC, V5303, P364, DOI 10.1007/978-3-540-88688-4_27; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LIN D., 2005, P IEEE INT C IM PROC, V3, P764; Liu CJ, 2008, IEEE T PATTERN ANAL, V30, P1116, DOI 10.1109/TPAMI.2008.66; Liu CJ, 2007, IEEE T PATTERN ANAL, V29, P1086, DOI 10.1109/TPAMI.2007.1063; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MA Y, 2007, P 24 INT C MACH LEAR, V227, P577; MASNADISHIRAZI H, 2007, P IEEE INT C COMP VI, P1; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mutch J, 2006, P IEEE C COMP VIS PA, P11, DOI [10.1109/CVPR.2006.200, DOI 10.1109/CVPR.2006.200]; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Phillips PJ, 2005, PROC CVPR IEEE, P947; Ponce J., 2007, CATEGORY LEVEL OBJEC; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Rummel RJ., 1970, APPL FACTOR ANAL; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Schneider JW, 2007, J AM SOC INF SCI TEC, V58, P1586, DOI 10.1002/asi.20643; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Takeda H, 2008, IEEE IMAGE PROC, P637, DOI 10.1109/ICIP.2008.4711835; Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; TATSUOKA MM, 1988, MULTIVARIATE ANAL; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Tuytelaars T, 2007, IEEE I CONF COMP VIS, P754; Vasconcelos M, 2009, IEEE T PATTERN ANAL, V31, P228, DOI 10.1109/TPAMI.2008.77; Vincent P, 2002, ADV NEURAL INFORM PR, V15, P825; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	67	100	110	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1688	1704		10.1109/TPAMI.2009.153	http://dx.doi.org/10.1109/TPAMI.2009.153			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634561	Green Submitted			2022-12-18	WOS:000279969000011
J	Palma-Amestoy, R; Provenzi, E; Bertalmio, M; Caselles, V				Palma-Amestoy, Rodrigo; Provenzi, Edoardo; Bertalmio, Marcelo; Caselles, Vicent			A Perceptually Inspired Variational Framework for Color Enhancement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Perceptual color enhancement; variational principles; gradient descent approach	RETINEX THEORY; VISION; LIGHTNESS; ALGORITHM; INDUCTION; MODEL	The basic phenomenology of human color vision has been widely taken as an inspiration to devise explicit color correction algorithms. The behavior of these models in terms of significative image features ( such as contrast and dispersion) can be difficult to characterize. To cope with this, we propose using a variational formulation of color contrast enhancement that is inspired by the basic phenomenology of color perception. In particular, we devise a set of basic requirements to be fulfilled by an energy to be considered as "perceptually inspired," showing that there is an explicit class of functionals satisfying all of them. We single out three explicit functionals that we consider of basic interest, showing similarities and differences with existing models. The minima of such functionals is computed using a gradient descent approach. We also present a general methodology to reduce the computational cost of the algorithms under analysis from O(N-2) to O(N logN), where N is the number of input pixels.	[Palma-Amestoy, Rodrigo] Univ Chile, Dept Elect Engn, Santiago, Chile; [Provenzi, Edoardo] Univ Milan, Dipartimento Tecnol Informaz, I-26013 Crema, CR, Italy; [Bertalmio, Marcelo; Caselles, Vicent] Univ Pompeu Fabra, Dept Tecnol, Barcelona 08003, Spain	Universidad de Chile; University of Milan; Pompeu Fabra University	Palma-Amestoy, R (corresponding author), Univ Chile, Dept Elect Engn, Ave Tupper 2007,Casilla 412-3, Santiago, Chile.	ropalma@ing.uchile.cl; provenzi@dti.unimi.it; marcelo.bertalmio@upf.edu; vicent.caselles@upf.edu	Bertalmío, Marcelo/A-4341-2012	PROVENZI, Edoardo/0000-0002-1476-1236; Bertalmio, Marcelo/0000-0002-1023-8325	Alfa CVFA [AML//19.0902/97/0666/II-0366-FA]; PRIN-MIUR [2005115173-002]; PNPGC [MTM2006-14836]; IP-RA-CINE [IST-511316]	Alfa CVFA; PRIN-MIUR(Ministry of Education, Universities and Research (MIUR)Research Projects of National Relevance (PRIN)); PNPGC; IP-RA-CINE	Rodrigo Palma-Amestoy acknowledges the support by Alfa CVFA, AML//19.0902/97/0666/II-0366-FA. Edoardo Provenzi acknowledges the partial support by PRIN-MIUR Research Project 2005115173-002. Marcelo Bertalmio and Vicent Caselles acknowledge the partial support by PNPGC Project Reference MTM2006-14836 and IP-RA-CINE Project IST-511316.	Ambrosio L, 2005, LEC MATH; Bertalmio M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P337; CREUTZFELDT O, 1990, J OPT SOC AM A, V7, P1644, DOI 10.1364/JOSAA.7.001644; CREUTZFELDT O, 1987, EXP BRAIN RES, V67, P270; Ebner M., 2007, COMPUTER VISION; FUNT B, 1998, P 5 EUR C COMP VIS, P445; Gonzales R., 2002, DIGITAL IMAGE PROCES; Gregory RL, 1997, EYE BRAIN; Hubel David H, 1995, EYE BRAIN VISION, P6; HURLBERT A, 1986, J OPT SOC AM A, V3, P1684, DOI 10.1364/JOSAA.3.001684; HURVICH LM, 1990, VISION RES, V4, P135; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250; MCCANN JJ, 2004, J ELECTRON IMAGING, V13, P1; Michelson Albert A., 1927, STUDIES OPTICS; Palmer S.E., 1999, VISION SCI PHOTONS P; Pratt WK, 2007, DIGITAL IMAGE PROCES, Vxix; Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613; PROVENZI E, 1932, IEEE T PATT IN PRESS; Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946; Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9; Sapiro G, 1997, J DIFFER EQUATIONS, V135, P238, DOI 10.1006/jdeq.1996.3237; Shapley R., 1984, PROG RETIN RES, V3, P263, DOI [DOI 10.1016/0278-4327(84)90011-7, 10.1016/0278-4327(84)90011-7]; Soille P., 1999, MORPHOLOGICAL IMAGE, DOI 10.1007/978-3-662-03939-7; USUI S, 1997, J DALTONS COLOUR VIS, P475; WANDELL B, 1993, VISION BRAIN; Wandell B.A., 1995, FDN VISION; WEST G, 1979, J MATH BIOL, V8, P47, DOI 10.1007/BF00280585; Wyszecky G, 2000, COLOR SCI CONCEPTS M; Zaidi Q., 1999, COLOR BRIGHTNESS IND; Zeki S, 1998, BRAIN, V121, P1669, DOI 10.1093/brain/121.9.1669	34	100	106	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					458	474		10.1109/TPAMI.2008.86	http://dx.doi.org/10.1109/TPAMI.2008.86			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147875				2022-12-18	WOS:000262480200006
J	Hernandez-Marin, S; Wallace, AM; Gibson, GJ				Hernandez-Marin, Sergio; Wallace, Andrew M.; Gibson, Gavin J.			Bayesian analysis of Lidar signals with multiple returns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional reconstruction; burst illumination laser; delayed rejection; Lidar; photon counting; reversible jump MCMC	LASER-RADAR; LADAR	Time- Correlated Single Photon Counting and Burst Illumination Laser data can be used for range profiling and target classification. In general, the problem is to analyze the response from a histogram of either photon counts or integrated intensities to assess the number, positions, and amplitudes of the reflected returns from object surfaces. The goal of our work is a complete characterization of the 3D surfaces viewed by the laser imaging system. The authors present a unified theory of pixel processing that is applicable to both approaches based on a Bayesian framework, which allows for careful and thorough treatment of all types of uncertainties associated with the data. We use reversible jump Markov chain Monte Carlo ( RJMCMC) techniques to evaluate the posterior distribution of the parameters and to explore spaces with different dimensionality. Further, we use a delayed rejection step to allow the generated Markov chain to mix better through the use of different proposal distributions. The approach is demonstrated on simulated and real data, showing that the return parameters can be estimated to a high degree of accuracy. We also show some practical examples from both near and far- range depth imaging.	Heriot Watt Univ, Sch Engn & Phys Sci, ERP Joint Res Inst Image & Signal Proc, Edinburgh EH14 4AS, Midlothian, Scotland; Heriot Watt Univ, Sch Math & Comp Sci, Dept Actuarial Math & Stat, Maxwell Inst Math Sci, Edinburgh EH14 4AS, Midlothian, Scotland	Heriot Watt University; Heriot Watt University; University of Edinburgh	Hernandez-Marin, S (corresponding author), Heriot Watt Univ, Sch Engn & Phys Sci, ERP Joint Res Inst Image & Signal Proc, Edinburgh EH14 4AS, Midlothian, Scotland.	snh3@hw.ac.uk; a.m.wallace@hw.ac.uk; g.j.gibson@ma.hw.ac.uk		Wallace, Andrew/0000-0003-4425-8591				Albota MA, 2002, APPL OPTICS, V41, P7671, DOI 10.1364/AO.41.007671; Aull B. F., 2002, Lincoln Laboratory Journal, V13, P335; Burnham K.P., 2002, MODEL SELECTION MULT, V2nd Edn, DOI 10.1007/b97636; Busck J, 2004, APPL OPTICS, V43, P4705, DOI 10.1364/AO.43.004705; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DUNCAN S, 2006, P SPIE INFRARED TECH, V6206, P4705; Gilks W, 1995, M CHAIN MONTE CARLO; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Green PJ, 2001, BIOMETRIKA, V88, P1035, DOI 10.1093/biomet/88.4.1035; Halmos MJ, 2001, P SOC PHOTO-OPT INS, V4377, P84, DOI 10.1117/12.440096; HERNANDEZMARIN S, 2005, P IAPR C MACH VIS AP, P193; LINDLEY DV, 1957, BIOMETRIKA, V44, P187; Pellegrini S, 2000, MEAS SCI TECHNOL, V11, P712, DOI 10.1088/0957-0233/11/6/314; PESKUN PH, 1973, BIOMETRIKA, V60, P607; Popescu SC, 2003, CAN J REMOTE SENS, V29, P564, DOI 10.5589/m03-027; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Schilling BW, 2002, APPL OPTICS, V41, P2791, DOI 10.1364/AO.41.002791; Tierney L, 1999, STAT MED, V18, P2507, DOI 10.1002/(SICI)1097-0258(19990915/30)18:17/18<2507::AID-SIM272>3.0.CO;2-J; Tierney L, 1998, ANN APPL PROBAB, V8, P1; Titterington DM, 1985, STAT ANAL FINITE MIX; Waagepetersen R, 2001, INT STAT REV, V69, P49, DOI 10.1111/j.1751-5823.2001.tb00479.x; Wallace AM, 2006, IEE P-VIS IMAGE SIGN, V153, P160, DOI 10.1049/ip-vis:20045023; Wallace A. M., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P466; Wallace AM, 2005, J OPT A-PURE APPL OP, V7, pS438, DOI 10.1088/1464-4258/7/6/028; Wallace AM, 2001, COMPUT CONTROL ENG J, V12, P157, DOI 10.1049/cce:20010403; WAX M, 1985, IEEE T ACOUST SPEECH, V33, P387, DOI 10.1109/TASSP.1985.1164557	26	100	106	3	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2170	2180		10.1109/TPAMI.2007.1122	http://dx.doi.org/10.1109/TPAMI.2007.1122			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934226	Green Submitted			2022-12-18	WOS:000250087900009
J	Lobo, J; Dias, J				Lobo, J; Dias, J			Vision and inertial sensor cooperation using gravity as a vertical reference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing and computer vision; edge and feature detection; sensor fusion	STABILIZATION	This paper explores the combination of inertial sensor data with vision. Visual and inertial sensing are two sensory modalities that can be explored to give robust solutions on image segmentation and recovery of 3D structure from images, increasing the capabilities of autonomous robots and enlarging the application potential of vision systems. In biological systems, the information provided by the vestibular system is fused at a very early processing stage with vision, playing a key role on the execution of visual movements such as gaze holding and tracking, and the visual cues aid the spatial orientation and body equilibrium. In this paper, we set a framework for using inertial sensor data in vision systems, and describe some results obtained. The unit sphere projection camera model is used, providing a simple model for inertial data integration. Using the vertical reference provided by the inertial sensors, the image horizon line can be determined. Using just one vanishing point and the vertical, we can recover the camera's focal distance and provide an external bearing for the system's navigation frame of reference. Knowing the geometry of a stereo rig and its pose from the inertial sensors, the collineation of level planes can be recovered, providing enough restrictions to segment and reconstruct vertical features and leveled planar patches.	Univ Coimbra, ISR, P-3030290 Coimbra, Portugal; Univ Coimbra, Dept Elect & Comp Engn, P-3030290 Coimbra, Portugal	Universidade de Coimbra; Universidade de Coimbra	Lobo, J (corresponding author), Univ Coimbra, ISR, P-3030290 Coimbra, Portugal.	jlobo@isr.uc.pt; jorge@isr.uc.pt	Lobo, Jorge/A-3105-2011; Dias, Jorge Miranda/A-1842-2011	Lobo, Jorge/0000-0001-6857-0737; Dias, Jorge Miranda/0000-0002-2725-8867				ALLEN JJ, 1998, P POS LOC NAV S APR; Alves J, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P1693; AMERS AL, 1997, VRML 2 0 SOURCEBOOK; *AN DEV, 2003, MEMS INT MICR EL SYS; Berthoz A., 2000, BRAINS SENSE MOVEMEN; Bhanu B., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P954, DOI 10.1109/ROBOT.1990.126114; BRILLAULTOMAHONY B, 1991, CVGIP-IMAG UNDERSTAN, V54, P289, DOI 10.1016/1049-9660(91)90069-2; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; CARPENTER H, 1988, MOVEMENTS EYES; CARUSO MJ, 1998, NEW PERSPECTIVES MAG; Collinson R. P. G., 1996, INTRO AVIONICS; COORG S, 1998, THESIS MIT; Dias J, 1998, IEEE T ROBOTIC AUTOM, V14, P1, DOI 10.1109/70.660834; DIAS J, 1995, IEEE INT CONF ROBOT, P472, DOI 10.1109/ROBOT.1995.525328; DIAS J, 1998, P IEEE C ROB AUT, V3, P1; Dickmanns ED, 1998, ARTIF INTELL, V103, P49, DOI 10.1016/S0004-3702(98)00071-X; EASON RO, 1992, DATA FUSION ROBOTICS, pCH9; GILLINGHAM KK, 1996, SPATIAL ORIENTATION, pCH11; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hoff WA, 1996, P SOC PHOTO-OPT INS, V2904, P538, DOI 10.1117/12.256311; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; *INT, 2003, INT OP SOURC COMP VI; Jahne B, 2005, DIGITAL IMAGE PROCES, V4; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Kurazume R., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1856, DOI 10.1109/ROBOT.2000.844865; LI M, 1994, P 3 EUR C COMP VIS S, P543; Lobo J, 2003, ROBOT AUTON SYST, V44, P69, DOI 10.1016/S0921-8890(03)00011-3; Lobo J, 1997, ISIE '97 - PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-3, P825, DOI 10.1109/ISIE.1997.648646; Lobo J, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P1907; Lobo J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P92, DOI 10.1109/IRDS.2002.1041368; Lobo J, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P103, DOI 10.1109/MFI.2001.1013516; Lobo J, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P912, DOI 10.1109/IROS.1998.727316; LOBO J, 2002, THESIS U COIMBRA; LOBO J, 2001, P 9 INT S INT ROB SY, P229; LOBO J, 1998, SENSORS MOBILE ROBOT, P50; LUTHER AC, 1998, VIDEO CAMERA TECHNOL; Mukai T., 2000, Information Fusion, V1, P45, DOI 10.1016/S1566-2535(00)00003-8; Mukai T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P411, DOI 10.1109/ICCV.1999.791250; OROURKE J, 1993, COMPUTATIONAL GEOMET; Panerai F, 1998, NEURAL NETWORKS, V11, P1191, DOI 10.1016/S0893-6080(98)00026-4; Panerai F, 2000, ROBOT AUTON SYST, V30, P195, DOI 10.1016/S0921-8890(99)00072-X; PANERAI F, 1997, P INT S INT ROB SYST; Pitman G., 1962, INERTIAL GUIDANCE; SAVAGE PG, 1984, STRAPDOWN SYSTEM ALG, P1; SHUSTER MD, 1993, IEEE T AERO ELEC SYS, V29, P263, DOI 10.1109/7.249140; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Vieville T., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P591, DOI 10.1109/ICCV.1993.378157; Vieville T., 1997, FEW STEPS 3D ACTIVE; VIEVILLE T, 1993, INTELLIGENT ROBOTS S; VIEVILLE T, 1989, P 5 INT S ROB RES, P57; VIEVILLE T, 1990, NATO ASI SERIES F, V63, P339; WANG LL, 1991, IEEE T PATTERN ANAL, V13, P370, DOI 10.1109/34.88572; WILLSON RG, 1994, J OPT SOC AM A, V11, P2946, DOI 10.1364/JOSAA.11.002946; You S, 1999, P IEEE VIRT REAL ANN, P260, DOI 10.1109/VR.1999.756960; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	55	100	171	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1597	1608		10.1109/TPAMI.2003.1251152	http://dx.doi.org/10.1109/TPAMI.2003.1251152			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000009
J	Raphael, C				Raphael, C			Automatic segmentation of acoustic musical signals using hidden Markov models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic musical accompaniment; hidden Markov models; computer music	SPEECH RECOGNITION	In this paper, we address an important step toward our goal of automatic musical accompaniment-the segmentation problem. Given a score to a piece of monophonic music and a sampled recording of a performance of that score, we attempt to segment the data into a sequence of contiguous regions corresponding to the notes and rests in the score. Within the framework of a hidden Markov model, we model our prior knowledge, perform unsupervised learning of the data model parameters, and compute the segmentation that globally minimizes the posterior expected number of segmentation errors. We also show how to produce "online" estimates of score position. We present examples of our experimental results, and readers are encouraged to access actual sound data we have made available from these experiments.	Univ Massachusetts, Dept Math & Stat, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Raphael, C (corresponding author), Univ Massachusetts, Dept Math & Stat, Amherst, MA 01003 USA.							BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAIRD B, 1993, COMPUT MUSIC J, V17, P73, DOI 10.2307/3680871; BAUM L, 1967, INEQUALITIES, V3, P1; BLOCH JJ, 1985, P ICMC, P279; BROWN JC, 1992, J ACOUST SOC AM, V92, P1394, DOI 10.1121/1.403933; Dannenberg R., 1997, P INT COMP MUS C, P301; DANNENBERG RB, 1984, ICMC, V0084, P00193; IMAI T, 1997, P INT C AC SPEECH SI, P727; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; LEE KF, 1988, THESIS CARNEGIE MELL; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; VERCOE B, 1985, P ICMC, P275; VERCOE B., 1984, P INT COMP MUS C, P199; [No title captured]	14	100	109	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					360	370		10.1109/34.761266	http://dx.doi.org/10.1109/34.761266			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL					2022-12-18	WOS:000079781200007
J	Rothe, I; Susse, H; Voss, K				Rothe, I; Susse, H; Voss, K			The method of normalization to determine invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						invariants; normalization; fourier descriptors; invariant moments; legendre descriptors; projective invariants	FOURIER DESCRIPTORS; MOMENT INVARIANTS; IMAGE-ANALYSIS; RECOGNITION; OBJECTS	The determination of invariant characteristics is an important problem in pattern recognition. Many invariants are known, which have been obtained either by normalization [1], [2], [3], [4], [5], [6], [7], [8], [9], [10] or by other methods [11], [12], [13], [14], [15], [16]. This paper shows that the method of normalization is much more general and allows to derive a lot of sets of invariants from the second list as well. To this end, the normalization method is generalized and is presented in such a way that it is easy to apply, thus unifying and simplifying the determination of invariants. Furthermore, this paper discusses the advantages and disadvantages of the invariants obtained by normalization. Their main advantage is that the normalization process provides us with a standard position of the object. Because of the generality of the method, also new invariants are obtained such as normalized moments more stable than known ones, Legendre descriptors and Zernike descriptors to affine transformations, two-dimensional Fourier descriptors and affine moment invariants obtained by combining Hu's moment invariants and normalized moments.	UNIV JENA, INST INFORMAT, D-07743 JENA, GERMANY	Friedrich Schiller University of Jena	Rothe, I (corresponding author), JENOPT SYSTHEMHAUS, PRUSSINGSTR 41, D-07743 JENA, GERMANY.		Rohlf, F J/A-8710-2008					ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617; ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; ARBTER K, 1990, THESIS TECHN U HAMBU; ASTROM K, 1994, LECTURE NOTES COMPUT, V801, P439; BARRETT EB, 1991, CVGIP-IMAG UNDERSTAN, V53, P46, DOI 10.1016/1049-9660(91)90004-9; BRILL MH, 1992, ARTIF INT, P193; BURKHARDT H, 1979, 7 VDI; CANO, 1992, FROM PIXELS FEATURES; DIRILTEN H, 1977, IEEE T COMPUT, V26, P314, DOI 10.1109/TC.1977.1674832; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Lee M., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P300, DOI 10.1109/ICPR.1990.118119; LENZ R, 1994, PATTERN RECOGN, V27, P1523, DOI 10.1016/0031-3203(94)90130-9; Mundy J., 1992, GEOMETRIC INVARIANCE; Orr J. A., 1988, JAI PRESS, V3, P101; PAPADEMETRION P, 1992, P 11 ICRP, P476; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799; REEVES AP, 1988, IEEE T PATTERN ANAL, V10, P937, DOI 10.1109/34.9115; REEVES AP, 1981, P PRIP, P171; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; REISS TH, 1993, RECOGNITION PLANAR O; ROTHE I, 1995, P 5 C CAIP 95, P9; ROTHE I, 1994, TR503 U ROCH; ROTHE I, 1993, P 15 DAGM 1993, P67; SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990; SINCLAIR D, 1994, IEEE T PATTERN ANAL, V16, P769, DOI 10.1109/34.308471; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; UDAGAWA K, 1964, ELECTR COMMUN JPN, V47, P34; VANGOOL LJ, 1992, ARTIF INT, P157; VOSS K, 1995, PROCEEDINGS OF EUROPE-CHINA WORKSHOP ON GEOMETRICAL MODELING & INVARIANTS FOR COMPUTER VISION, P356; VOSS K, 1995, ADAPTIVE MODELLE INV; WANG K, 1977, THESIS SYRACUSE U; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	38	100	111	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					366	376		10.1109/34.491618	http://dx.doi.org/10.1109/34.491618			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500002
J	REEVES, AP; PROKOP, RJ; ANDREWS, SE; KUHL, FP				REEVES, AP; PROKOP, RJ; ANDREWS, SE; KUHL, FP			3-DIMENSIONAL SHAPE-ANALYSIS USING MOMENTS AND FOURIER DESCRIPTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									USA,ARMAMENT RES & DEV COMMAND,AMCCOM,DOVER,NJ 07801		REEVES, AP (corresponding author), CORNELL UNIV,SCH ELECT ENGN,ITHACA,NY 14853, USA.							DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; MITCHELL OR, 1984, OPT ENG, V23, P484, DOI 10.1117/12.7973326; MITCHELL OR, 1982, SPIE P ROBOTICS IND, V360, P190; REEVES AP, 1981, 1981 P PATT REC IM P, P171; REEVES AP, 1981, TREE8137 PURD U TECH; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9	9	100	111	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					937	943		10.1109/34.9115	http://dx.doi.org/10.1109/34.9115			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100015
J	COHEN, FS; COOPER, DB				COHEN, FS; COOPER, DB			SIMPLE PARALLEL HIERARCHICAL AND RELAXATION ALGORITHMS FOR SEGMENTING NONCAUSAL MARKOVIAN RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									BROWN UNIV,DIV ENGN,PROVIDENCE,RI 02912	Brown University	COHEN, FS (corresponding author), UNIV RHODE ISL,DEPT ELECT ENGN,KINGSTON,RI 02881, USA.							BARTLETT MS, 1976, STATISTICAL ANAL SPA; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; Cohen F. S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1104; COHEN FS, 1984, P SOC PHOTO-OPT INST, V449, P17, DOI 10.1117/12.939219; COHEN FS, 1986, MODELLING APPLICATIO; COHEN FS, 1985, APR P INT C AC SPEEC, P925; COHEN FS, UNPUB UNSUPERVISED T; COHEN FS, 1985, P SPIE, V595; COHEN FS, UNPUB REAL TIME SURF; COHEN FS, 1986, DEP ELEC ENG U RHODE; COHEN FS, 1983, THESIS BROWN U PROVI; COHEN FS, 1985, APR P INT C AC SPEEC, P897; COOPER DB, 1983, IEEE T PATTERN ANAL, V5; COOPER DB, 1980, COMPUT GRAPHICS  APR, P326; CROSS RJ, 1980, 8002 MICH STAT U COL; EKSTROM MP, 1976, IEEE T ACOUST SPEECH, V24, P115, DOI 10.1109/TASSP.1976.1162785; ELLIOT H, 1987, IEEE T PAMI, V9, P39; FAN Z, 1986, DEP ELEC ENG U RHODE; FAN Z, UNPUB TEXTURED IMAGE; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; GEMAN D, 1983, STOCHASTIC RELAXATIO; HINTON GE, 1983, JUN P IEEE COMP VIS, P448; HINTON GE, 1984, COMMUNICATION    APR; KASHYAP R, 1983, IEEE T PAMI, P60; KAUFMAN H, 1979, 18TH P C DEC CONTR F; LOEVE M, 1960, PROBABILITY THEORY, P228; RANGANATH S, 1983, SIPL835 U CAL DAV DE; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHARF LL, 1981, IEEE T AUTOMAT CONTR, V26, P1018, DOI 10.1109/TAC.1981.1102775; SCHENKER P, 1980, 5TH C P INT S PATT R; SILVERMAN JF, 1986, LEMS20 BROWN U DIV E; SILVERMAN JF, 1986, APR P IEEE INT C ROB, P299; SILVERMAN JF, IN PRESS IEEE T PATT; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786	36	100	102	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					195	219		10.1109/TPAMI.1987.4767895	http://dx.doi.org/10.1109/TPAMI.1987.4767895			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869391				2022-12-18	WOS:A1987G163300002
J	NARENDRA, PM				NARENDRA, PM			A SEPARABLE MEDIAN FILTER FOR IMAGE NOISE SMOOTHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NARENDRA, PM (corresponding author), HONEYWELL INC,CTR SYST & RES,SIGNAL & IMAGE PROC SECT,MINNEAPOLIS,MN 55431, USA.							ANDREWS HC, 1976, APPL OPTICS, V15, P495, DOI 10.1364/AO.15.000495; EVERSOLE WL, 1978, NOV P ARPA WORKSH IM, P191; FLOYD RW, 1975, COMMUN ACM, V18, P173, DOI 10.1145/360680.360694; GIBBONS JD, 1971, NONPARAMETRIC STATIS, P32; HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188; KNUTH DE, 1973, ART COMPUTER PROGRAM, V3, P220; MORGAN DR, 1973, ELECT DES, V21, P72; MORGAN DR, 1973, ELECTRON DESIGN, V21; SHAMOS MI, 1978, NOV P IM UND WORKSH, P127; TUKEY JW, 1976, EXPLORATORY DATA ANA, P205; Tukey JW, 1978, CONTRIBUTIONS SURVEY, P251	11	100	108	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					20	29		10.1109/TPAMI.1981.4767047	http://dx.doi.org/10.1109/TPAMI.1981.4767047			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868916				2022-12-18	WOS:A1981LK11600003
J	Rogez, G; Weinzaepfel, P; Schmid, C				Rogez, Gregory; Weinzaepfel, Philippe; Schmid, Cordelia			LCR-Net plus plus : Multi-Person 2D and 3D Pose Detection in Natural Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Two dimensional displays; Pose estimation; Proposals; Joints; Heating systems; Training data; Human 3D pose estimation; 2D pose estimation; detection; localization; classification; regression; CNN		We propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images. Key to our approach is the generation and scoring of a number of pose proposals per image, which allows us to predict 2D and 3D poses of multiple people simultaneously. Hence, our approach does not require an approximate localization of the humans for initialization. Our Localization-Classification-Regression architecture, named LCR-Net, contains 3 main components: 1) the pose proposal generator that suggests candidate poses at different locations in the image; 2) a classifier that scores the different pose proposals; and 3) a regressor that refines pose proposals both in 2D and 3D. All three stages share the convolutional feature layers and are trained jointly. The final pose estimation is obtained by integrating over neighboring pose hypotheses, which is shown to improve over a standard non maximum suppression algorithm. Our method recovers full-body 2D and 3D poses, hallucinating plausible body parts when the persons are partially occluded or truncated by the image boundary. Our approach significantly outperforms the state of the art in 3D pose estimation on Human3.6M, a controlled environment. Moreover, it shows promising results on real images for both single and multi-person subsets of the MPII 2D pose benchmark and demonstrates satisfying 3D pose results even for multi-person images.	[Rogez, Gregory; Schmid, Cordelia] Univ Grenoble Alpes, INRIA, Grenoble INP, CNRS,LJK, F-38400 St Martin Dheres, France; [Weinzaepfel, Philippe] NAVER LABS Europe, F-38240 Meylan, France	Centre National de la Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; UDICE-French Research Universities; Universite Grenoble Alpes (UGA); Inria	Rogez, G (corresponding author), Univ Grenoble Alpes, INRIA, Grenoble INP, CNRS,LJK, F-38400 St Martin Dheres, France.	gregory.rogez@inria.fr; philippe.weinzaepfel@naverlabs.com; cordelia.schmid@inria.fr			ERC advanced grant Allegro; Amazon Academic Research Award	ERC advanced grant Allegro; Amazon Academic Research Award	This work was supported by ERC advanced grant Allegro and an Amazon Academic Research Award. We thank NVIDIA for donating the GPUs used for this research.	Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; [Anonymous], P IEEE COMP SOC C CO; [Anonymous], 2008, 2008 IEEE C COMP VIS; [Anonymous], P 11 INT C EN MIN ME; [Anonymous], 2016, P 30 INT C NEUR INF; [Anonymous], 2016, P BRIT MACH VIS C; [Anonymous], P BRIT MACH VIS C; Bo LF, 2008, PROC CVPR IEEE, P1833; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610; Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Du Y, 2016, LECT NOTES COMPUT SC, V9908, P20, DOI 10.1007/978-3-319-46493-0_2; Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740; Fan XC, 2014, LECT NOTES COMPUT SC, V8689, P174, DOI 10.1007/978-3-319-10590-1_12; Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu PY, 2016, PROC CVPR IEEE, P5600, DOI 10.1109/CVPR.2016.604; Huang SY, 2017, PROC CVPR IEEE, P4664, DOI 10.1109/CVPR.2017.496; Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Iqbal U, 2016, LECT NOTES COMPUT SC, V9914, P627, DOI 10.1007/978-3-319-48881-3_44; Katircioglu I, 2018, INT J COMPUT VISION, V126, P1326, DOI 10.1007/s11263-018-1066-6; Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500; Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326; Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23; Lin MD, 2017, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2017.588; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288; Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064; Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170; Muller M., 2007, TECHNICAL REPORT; Newell A, 2017, ADV NEUR IN, V30; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373; Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299; Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395; Park S, 2016, LECT NOTES COMPUT SC, V9915, P156, DOI 10.1007/978-3-319-49409-8_15; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; de Souza CR, 2017, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2017.278; Rogez G, 2018, INT J COMPUT VISION, V126, P993, DOI 10.1007/s11263-018-1071-9; Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134; Sanzari M, 2016, LECT NOTES COMPUT SC, V9912, P566, DOI 10.1007/978-3-319-46484-8_34; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466; Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988; Simonyan K, 2015, 3 INT C LEARN REPR I; Sminchisescu C, 2005, PROC CVPR IEEE, P390; Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284; Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425; Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113; Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492; Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144; Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535; Zhou F, 2014, LECT NOTES COMPUT SC, V8694, P62, DOI 10.1007/978-3-319-10599-4_5; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51; Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17	78	99	103	7	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1146	1161		10.1109/TPAMI.2019.2892985	http://dx.doi.org/10.1109/TPAMI.2019.2892985			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30640602	Green Submitted			2022-12-18	WOS:000523685800010
J	Wang, SY; Ding, ZM; Fu, Y				Wang, Shuyang; Ding, Zhengming; Fu, Yun			Cross-Generation Kinship Verification with Sparse Discriminative Metric	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kinship verification; generative adversarial networks; metric learning		Kinship verification is a very important technique in many real-world applications, e.g., personal album organization, missing person investigation and forensic analysis. However, it is extremely difficult to verify a family pair with generation gap, e.g., father and son, since there exist both age gap and identity variation. It is essential to well fight off such challenges to achieve promising kinship verification performance. To this end, we propose a towards-young cross-generation model for effective kinship verification by mitigating both age and identity divergences. Specifically, we explore a conditional generative model to bring in an intermediate domain to bridge each pair. Thus, we could extract more effective features through deep architectures with a newly-designed Sparse Discriminative Metric Loss (SDM-Loss), which is exploited to involve the positive and negative information. Experimental results on kinship benchmark demonstrate the superiority of our proposed model by comparing with the state-of-the-art kinship verification methods.	[Wang, Shuyang] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Ding, Zhengming] Indiana Univ Purdue Univ, Dept Comp Informat & Technol, 420 Univ Blvd Indianapolis, Indianapolis, IN 46202 USA; [Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Coll Comp & Informat Sci, Boston, MA 02115 USA	Northeastern University; Indiana University System; Indiana University-Purdue University Indianapolis; Northeastern University	Wang, SY (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	shuyangwang@ece.neu.edu; zd2@iu.edu; yunfu@ece.neu.edu	Ding, Zhengming/AAJ-2918-2021	Ding, Zhengming/0000-0002-6994-5278; Fu, Yun/0000-0002-5098-2853				Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5; Arjovsky M, 2017, PR MACH LEARN RES, V70; Bottino A., 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P405; Chen ZX, 2015, CHINA COMMUN, V12, P1; Choi Y., 2017, ARXIV171109020; Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227; Dibeklioglu H, 2017, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2017.269; Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614; Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590; Fu Yun, 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2967219; Fu Yun, 2011, 22 INT JOINT C ART I, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He XF, 2005, IEEE I CONF COMP VIS, P1208; He XF, 2004, ADV NEUR IN, V16, P153; Huang X., 2017, P AAAI JOINT WORKSH, P4; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760; Kim SM, 2016, IEEE INT CONF EMBED, P212, DOI 10.1109/RTCSA.2016.48; Kim Taeksoo, 2017, P 34 INT C MACH LEAR, P1857, DOI [10.5555/3305381.3305573, DOI 10.5555/3305381.3305573]; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li M., 2016, ARXIV161005586 CORR; Liu ZC, 2004, IEEE COMPUT GRAPH, V24, P30, DOI 10.1109/MCG.2004.1297008; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; LU J, 2015, BIOMED RES INT, V2015, P00001; Mirza M., 2014, ARXIV; Nie F., 2008, P 23 AAAI C ART INT, P671; Parkhi Omkar M., 2015, BRIT MACH VIS C; Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135; Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; van den Oord Aaron, 2016, ARXIV160605328; Wang S., 2009, ARTIF INTELL, P591; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wang SY, 2017, IEEE INT CONF AUTOMA, P216, DOI 10.1109/FG.2017.35; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Wu XX, 2016, ADV SOC SCI EDUC HUM, V70, P1; Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436; Xiong C, 2016, IEEE T CIRC SYST VID, V26, P517, DOI 10.1109/TCSVT.2015.2406191; Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Yin Wu, 1994, Proceedings of the Second Pacific Conference on Computer Graphics and Applications, Pacific Graphics '94. Fundamentals of Computer Graphics, P201; Yun F, 2004, IEEE IMAGE PROC, P3523; Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324; Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463; Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614; Zhengming Ding, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163088; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	61	99	104	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2783	2790		10.1109/TPAMI.2018.2861871	http://dx.doi.org/10.1109/TPAMI.2018.2861871			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30072315				2022-12-18	WOS:000489838200016
J	Joo, H; Simon, T; Li, XL; Liu, H; Tan, L; Gui, L; Banerjee, S; Godisart, T; Nabbe, B; Matthews, I; Kanade, T; Nobuhara, S; Sheikh, Y				Joo, Hanbyul; Simon, Tomas; Li, Xulong; Liu, Hao; Tan, Lei; Gui, Lin; Banerjee, Sean; Godisart, Timothy; Nabbe, Bart; Matthews, Iain; Kanade, Takeo; Nobuhara, Shohei; Sheikh, Yaser			Panoptic Studio: A Massively Multiview System for Social Interaction Capture	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human motion capture; social interaction capture; multiview system; markerless motion capture	MOTION CAPTURE; TRACKING; SHAPE	We present an approach to capture the 3D motion of a group of people engaged in a social interaction. The core challenges in capturing social interactions are: (1) occlusion is functional and frequent; (2) subtle motion needs to be measured over a space large enough to host a social group; (3) human appearance and configuration variation is immense; and (4) attaching markers to the body may prime the nature of interactions. The Panoptic Studio is a system organized around the thesis that social interactions should be measured through the integration of perceptual analyses over a large variety of view points. We present a modularized system designed around this principle, consisting of integrated structural, hardware, and software innovations. The system takes, as input, 480 synchronized video streams of multiple people engaged in social activities, and produces, as output, the labeled time-varying 3D structure of anatomical landmarks on individuals in the space. Our algorithm is designed to fuse the "weak" perceptual processes in the large number of views by progressively generating skeletal proposals from low-level appearance cues, and a framework for temporal refinement is also presented by associating body parts to reconstructed dense 3D trajectory stream. Our system and method are the first in reconstructing full body motion of more than five people engaged in social interactions without using markers. We also empirically demonstrate the impact of the number of views in achieving this goal.	[Joo, Hanbyul; Simon, Tomas; Nabbe, Bart; Kanade, Takeo; Sheikh, Yaser] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA; [Li, Xulong] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China; [Liu, Hao; Gui, Lin] Ocean Univ China, Shanghai 201306, Peoples R China; [Tan, Lei] Hunan Univ, Hunan Sheng 410006, Peoples R China; [Banerjee, Sean] Clarkson Univ, Dept Comp Sci, Potsdam, NY 13699 USA; [Godisart, Timothy] Oculus Res Pittsburgh, Pittsburgh, PA 15213 USA; [Matthews, Iain] Disney Res Pittsburgh, Pittsburgh, PA 15213 USA; [Nobuhara, Shohei] Kyoto Univ, Dept Intelligence Sci & Technol, Kyoto, Kyoto 6068501, Japan	Carnegie Mellon University; Beijing University of Posts & Telecommunications; Ocean University of China; Hunan University; Clarkson University; Kyoto University	Joo, H (corresponding author), Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA.	hanbyulj@cs.cmu.edu; tsimon@cs.cmu.edu; lixulong@bupt.edu.cn; liu.hao@ouc.edu.cn; leit@hnu.edu.cn; lgui@qnlm.ac; sbanerje@clarkson.edu; Timothy.godisart@oculus.com; bana@cs.cmu.edu; iainm@disneyresearch.ccmi; tk@cs.cmu.edu; nob@i.kyoto-u.ac.jp; yaser@cs.cmu.edu	Nobuhara, Shohei/GNP-2576-2022	Nobuhara, Shohei/0000-0002-3204-8696				Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Alahi A, 2014, PROC CVPR IEEE, P2211, DOI 10.1109/CVPR.2014.283; Alameda-Pineda X, 2016, IEEE T PATTERN ANAL, V38, P1707, DOI 10.1109/TPAMI.2015.2496269; Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Aviezer H, 2012, SCIENCE, V338, P1225, DOI 10.1126/science.1224313; Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356; Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216; Birdwhistell R.L., 1970, KINESICS CONTEXT ESS; Brazelton T.B., 1974, MOTHER INFANT INTERA; Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b; Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32; Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5; Choi WG, 2014, LECT NOTES COMPUT SC, V8692, P417, DOI 10.1007/978-3-319-10593-2_28; Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945; CONDON WS, 1974, CHILD DEV, V45, P456; Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3; Cristani M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.23; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Elhayek A, 2017, IEEE T PATTERN ANAL, V39, P501, DOI 10.1109/TPAMI.2016.2557779; Elhayek A, 2015, PROC CVPR IEEE, P3810, DOI 10.1109/CVPR.2015.7299005; Furukawa Y., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2009.5206868; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Gavrila DM, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P737; Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350; Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142; Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381; Joo H, 2014, PROC CVPR IEEE, P1122, DOI 10.1109/CVPR.2014.147; Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394; Kehl R, 2006, COMPUT VIS IMAGE UND, V104, P190, DOI 10.1016/j.cviu.2006.07.010; Lepri B, 2012, IEEE T AFFECT COMPUT, V3, P443, DOI 10.1109/T-AFFC.2012.17; Liu YB, 2013, IEEE T PATTERN ANAL, V35, P2720, DOI 10.1109/TPAMI.2013.47; Matsuyama T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P234, DOI 10.1109/TDPVT.2002.1024068; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Meeren HKM, 2005, P NATL ACAD SCI USA, V102, P16518, DOI 10.1073/pnas.0507650102; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Petit B., 2009, 28 ANN C COMP GRAPH; PHILPOTT JS, 1983, THESIS; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; Rehg JM, 2013, PROC CVPR IEEE, P3414, DOI 10.1109/CVPR.2013.438; Sapir Edward, 1949, CULTURE LANGUAGE PER; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Vlasenko D, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2007, VOL 5, PTS A-C,, P97; Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520; Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Williams R., 1979, DOVER PUBLICATIONS; Wu C., VISUALSFM VISUAL STR; Yang Y, 2012, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2012.6248095; Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59; Zen G., 2010, P 1 ACM INT WORKSHOP, P37, DOI [DOI 10.1145/1878039.1878048, 10.1145/1878039.1878048]	57	99	101	4	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					190	204		10.1109/TPAMI.2017.2782743	http://dx.doi.org/10.1109/TPAMI.2017.2782743			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990012	Green Submitted, hybrid			2022-12-18	WOS:000452434800015
J	Yan, JC; Cho, MS; Zha, HY; Yang, XK; Chu, SM				Yan, Junchi; Cho, Minsu; Zha, Hongyuan; Yang, Xiaokang; Chu, Stephen M.			Multi-Graph Matching via Affinity Optimization with Graduated Consistency Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; feature correspondence	ALGORITHM	This paper addresses the problem of matching common node correspondences among multiple graphs referring to an identical or related structure. This multi-graph matching problem involves two correlated components: i) the local pairwise matching affinity across pairs of graphs; ii) the global matching consistency that measures the uniqueness of the pairwise matchings by different composition orders. Previous studies typically either enforce the matching consistency constraints in the beginning of an iterative optimization, which may propagate matching error both over iterations and across graph pairs; or separate affinity optimization and consistency enforcement into two steps. This paper is motivated by the observation that matching consistency can serve as a regularizer in the affinity objective function especially when the function is biased due to noises or inappropriate modeling. We propose composition-based multi-graph matching methods to incorporate the two aspects by optimizing the affinity score, meanwhile gradually infusing the consistency. We also propose two mechanisms to elicit the common inliers against outliers. Compelling results on synthetic and real images show the competency of our algorithms.	[Yan, Junchi; Yang, Xiaokang] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai Key Lab Media Proc & Transmiss, Shanghai 200240, Peoples R China; [Yan, Junchi] IBM Res, New Delhi, India; [Cho, Minsu] Ecole Normale Super, INRIA, WILLOW Team, 24 Rue Lhomond, F-75231 Paris, France; [Zha, Hongyuan] E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China; [Zha, Hongyuan] Georgia Inst Technol, Coll Comp, Sch Computat Sci & Engn, Atlanta, GA 30332 USA; [Chu, Stephen M.] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA	Shanghai Jiao Tong University; International Business Machines (IBM); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); East China Normal University; University System of Georgia; Georgia Institute of Technology; International Business Machines (IBM)	Yan, JC; Yang, XK (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai Key Lab Media Proc & Transmiss, Shanghai 200240, Peoples R China.; Yan, JC (corresponding author), IBM Res, New Delhi, India.; Cho, MS (corresponding author), Ecole Normale Super, INRIA, WILLOW Team, 24 Rue Lhomond, F-75231 Paris, France.; Zha, HY (corresponding author), E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.; Zha, HY (corresponding author), Georgia Inst Technol, Coll Comp, Sch Computat Sci & Engn, Atlanta, GA 30332 USA.; Chu, SM (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.	yanjunchi@sjtu.edu.cn; minsu.cho@inria.fr; zha@cc.gatech.edu; xkyang@sjtu.edu.cn; schu@us.ibm.com	Yang, Xiaokang/C-6137-2009; Cho, Minsu/AAR-6323-2020	Yang, Xiaokang/0000-0003-4029-3322; Yan, Junchi/0000-0001-9639-7679	US National Science Foundation (NSF) [DMS-1317424]; NSFC [61527804, 61129001, 61221001]; STCSM [15JC1401700, 14XD1402100, 13511504501]; 111 Program [B07022]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM108341] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); NSFC(National Natural Science Foundation of China (NSFC)); STCSM(Science & Technology Commission of Shanghai Municipality (STCSM)); 111 Program(Ministry of Education, China - 111 Project); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	The work is supported by US National Science Foundation (NSF) DMS-1317424, NSFC (61527804, 61129001, 61221001), STCSM (15JC1401700, 14XD1402100, 13511504501) and the 111 Program (B07022). A preliminary version appeared in [1]. The current paper makes several extensions and improvements: i) a new graduated consistency-regularized affinity optimization algorithm (CAO-C in Algorithm 2) achieving more accurate matching results, meanwhile helps reinterpret the method (CAO-UC in Algorithm 3) in [1]; ii) an inlier eliciting mechanism against considerable outliers based on node-wise consistency and affinity; iii) more technical details of the algorithms and convergence discussion which are not fully described in [1]; iv) extensive evaluations that involve more various settings and additional datasets. In addition, more emerging state-of-the-arts [2], [3], [4] are compared especially after the year 2013. The source code will be made public available.	AHO AV, 1989, ACM T PROGR LANG SYS, V11, P491, DOI 10.1145/69558.75700; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Charpiat Guillaume, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P328, DOI 10.1109/ICCVW.2009.5457683; Chen YX, 2014, PR MACH LEARN RES, V32, P100; Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51; Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Cho Minsu, 2010, EUR C COMP VIS; Collins T, 2014, LECT NOTES COMPUT SC, V8695, P138, DOI 10.1007/978-3-319-10584-0_10; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; EPPSTEIN D, 1995, PROCEEDINGS OF THE SIXTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P632; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013; Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775; GAVRIL F, 1987, J ALGORITHM, V8, P592, DOI 10.1016/0196-6774(87)90053-8; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gold S., 1996, J ARTIFICIAL NEURAL, V2, P381; Hu N, 2013, PROC CVPR IEEE, P2906, DOI 10.1109/CVPR.2013.374; Huang QX, 2013, COMPUT GRAPH FORUM, V32, P177, DOI 10.1111/cgf.12184; Huang QX, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366186; Jia K., 2014, ARXIV14037877; KOOPMANS TC, 1957, ECONOMETRICA, V25, P53, DOI 10.2307/1907742; LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2; Leordeanu M, 2011, IEEE I CONF COMP VIS, P2274, DOI 10.1109/ICCV.2011.6126507; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Liu SX, 2014, IEEE CONF VIS ANAL, P183, DOI 10.1109/VAST.2014.7042494; LUKS EM, 1982, J COMPUT SYST SCI, V25, P42, DOI 10.1016/0022-0000(82)90009-5; Pachauri D., 2013, ADV NEURAL INFORM PR, V26, P1860; Sole-Ribalta A, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413500018; Sole-Ribalta A, 2011, COMPUT VIS IMAGE UND, V115, P929, DOI 10.1016/j.cviu.2010.12.007; Sole-Ribalta A, 2010, LECT NOTES COMPUT SC, V6218, P180, DOI 10.1007/978-3-642-14980-1_17; Sole-Ribalta A, 2009, LECT NOTES COMPUT SC, V5856, P137, DOI 10.1007/978-3-642-10268-4_16; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Viksten F, 2009, IEEE INT CONF ROBOT, P1139; Wang WY, 2014, LECT NOTES COMPUT SC, V8689, P756, DOI 10.1007/978-3-319-10590-1_49; Williams ML, 1997, PATTERN RECOGN LETT, V18, P1275, DOI 10.1016/S0167-8655(97)00117-7; Yan JC, 2013, IEEE I CONF COMP VIS, P1649, DOI 10.1109/ICCV.2013.207; Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759; Yan JC, 2015, IEEE T IMAGE PROCESS, V24, P994, DOI 10.1109/TIP.2014.2387386; Yan JC, 2014, LECT NOTES COMPUT SC, V8689, P407, DOI 10.1007/978-3-319-10590-1_27; Zaslavskiy M, 2009, BIOINFORMATICS, V25, pI259, DOI 10.1093/bioinformatics/btp196; Zass R, 2008, PROC CVPR IEEE, P1221; Zhang SY, 2015, 2015 IEEE WORKSHOP ON ENVIRONMENTAL, ENERGY AND STRUCTURAL MONITORING SYSTEMS (EESMS), P1, DOI [10.1109/EESMS.2015.7175842, 10.1109/INTMAG.2015.7156970]; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	52	99	99	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1228	1242		10.1109/TPAMI.2015.2477832	http://dx.doi.org/10.1109/TPAMI.2015.2477832			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26372208	Green Submitted, hybrid			2022-12-18	WOS:000375609000014
J	Mathe, S; Sminchisescu, C				Mathe, Stefan; Sminchisescu, Cristian			Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual action recognition; human eye-movements; consistency analysis; saliency prediction; large scale learning	ATTENTION; SEARCH; SCENE; HISTOGRAMS; MOVEMENTS; SELECTION; GUIDANCE; PREDICT; VIDEO	Systems based on bag-of-words models from image features collected at maxima of sparse interest point operators have been used successfully for both computer visual object and action recognition tasks. While the sparse, interest-point based approach to recognition is not inconsistent with visual processing in biological systems that operate in 'saccade and fixate' regimes, the methodology and emphasis in the human and the computer vision communities remains sharply distinct. Here, we make three contributions aiming to bridge this gap. First, we complement existing state-of-the art large scale dynamic computer vision annotated datasets like Hollywood-2 [1] and UCF Sports [2] with human eye movements collected under the ecological constraints of visual action and scene context recognition tasks. To our knowledge these are the first large human eye tracking datasets to be collected and made publicly available for video, vision. imar. ro/eyetracking (497,107 frames, each viewed by 19 subjects), unique in terms of their (a) large scale and computer vision relevance, (b) dynamic, video stimuli, (c) task control, as well as free-viewing. Second, we introduce novel dynamic consistency and alignment measures, which underline the remarkable stability of patterns of visual search among subjects. Third, we leverage the significant amount of collected data in order to pursue studies and build automatic, end-to-end trainable computer vision systems based on human eye movements. Our studies not only shed light on the differences between computer vision spatio-temporal interest point image sampling strategies and the human fixations, as well as their impact for visual recognition performance, but also demonstrate that human fixations can be accurately predicted, and when used in an end-to-end automatic system, leveraging some of the advanced computer vision practice, can lead to state of the art results.	[Mathe, Stefan; Sminchisescu, Cristian] Romanian Acad, Inst Math, Bucharest, Romania; [Mathe, Stefan] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada; [Sminchisescu, Cristian] Lund Univ, Fac Engn, Dept Math, S-22100 Lund, Sweden	Institute of Mathematics of the Romanian Academy; Romanian Academy of Sciences; University of Bucharest; University of Toronto; Lund University	Mathe, S (corresponding author), Romanian Acad, Inst Math, Bucharest, Romania.	stefan.mathe@imar.ro; cristian.sminchisescu@math.lth.se			CNCS-UEFISCDI, under PNII [RU-RC-2/2009, CT-ERC-2012-1, PCE-2011-3-0438]	CNCS-UEFISCDI, under PNII(Consiliul National al Cercetarii Stiintifice (CNCS)Unitatea Executiva pentru Finantarea Invatamantului Superior, a Cercetarii, Dezvoltarii si Inovarii (UEFISCDI))	This work was supported by CNCS-UEFISCDI, under PNII RU-RC-2/2009, CT-ERC-2012-1 and PCE-2011-3-0438. Correspondence should be sent to C. Sminchisescu.	Alfred L, 1967, EYE MOVEMENTS VISION, P171, DOI [DOI 10.1007/978-1-4899-5379-7, 10.1007/978-1-4899-5379-7]; Borji A, 2014, J VISION, V14, DOI 10.1167/14.3.29; Borji A, 2011, IEEE INT CONF ROBOT, P1902; Bruce N., 2005, P 18 INT C NEUR INF, P155; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dorr M, 2010, J VISION, V10, DOI 10.1167/10.10.28; Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720; Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Greene MR, 2012, VISION RES, V62, P1, DOI 10.1016/j.visres.2012.03.019; Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427; Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034; Hariharan B., 2010, P 27 INT C MACHINE L, P423; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hwang AD, 2011, VISION RES, V51, P1192, DOI 10.1016/j.visres.2011.03.010; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Itti L., 2005, NEUROBIOLOGY ATTENTI; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Judd T., 2012, 1 MIT DEP EL ENG COM; Judd T, 2011, J VISION, V11, DOI 10.1167/11.4.14; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kienzle W., 2006, ADV NEURAL INFORM PR, P689; Kienzle W, 2007, LECT NOTES COMPUT SC, V4713, P405; Land M. F., 2009, LOOKING AND ACTING; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Larochelle H., 2010, ADV NEURAL INFORM PR, P1243; Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015; Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9; Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597; Marat S., 2007, P ANN C ASS ED JOURN, P1; Marinoiu E, 2013, IEEE I CONF COMP VIS, P1289, DOI 10.1109/ICCV.2013.163; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Mathe S., 2013, P ADV NEUR INF PROC, P1925; Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60; McMains SA, 2004, NEURON, V42, P677, DOI 10.1016/S0896-6273(04)00263-6; Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012; NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Rolls E.T., 2008, MEMORY ATTENTION DEC; Rosenholtz R, 1999, VISION RES, V39, P3157, DOI 10.1016/S0042-6989(99)00077-2; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444; Sminchisescu C, 2005, INT J COMPUT VISION, V61, P81, DOI 10.1023/B:VISI.0000042935.43630.46; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walther D, 2005, COMPUT VIS IMAGE UND, V100, P41, DOI 10.1016/j.cviu.2004.09.004; Wasserman L, 2010, ALL STAT CONCISE COU; Winkler S, 2013, INT WORK QUAL MULTIM, P212, DOI 10.1109/QoMEX.2013.6603239; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235	64	99	105	0	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1408	1424		10.1109/TPAMI.2014.2366154	http://dx.doi.org/10.1109/TPAMI.2014.2366154			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352449	Green Submitted			2022-12-18	WOS:000355931100009
J	He, KM; Sun, J				He, Kaiming; Sun, Jian			Image Completion Approaches Using the Statistics of Similar Patches	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image completion; image inpainting; natural image statistics	FIELDS; PROPAGATION	Image completion involves filling missing parts in images. In this paper we address this problem through novel statistics of similar patches. We observe that if we match similar patches in the image and obtain their offsets (relative positions), the statistics of these offsets are sparsely distributed. We further observe that a few dominant offsets provide reliable information for completing the image. Such statistics can be incorporated into both matching-based and graph-based methods for image completion. Experiments show that our method yields better results in various challenging cases, and is faster than existing state-of-the-art methods.	[He, Kaiming; Sun, Jian] Microsoft Res Asia, Visual Comp Grp, Beijing 100080, Peoples R China	Microsoft; Microsoft Research Asia	He, KM (corresponding author), Microsoft Res Asia, Visual Comp Grp, Beijing 100080, Peoples R China.	kahe@microsoft.com; jiansun@microsoft.com						Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Bagon S, 2008, LECT NOTES COMPUT SC, V5305, P30, DOI 10.1007/978-3-540-88693-8_3; Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036; Barnes C, 2011, THESIS PRINCETON U P; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Bertalmio M, 2003, PROC CVPR IEEE, P707; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen ZY, 2013, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2013.316; Criminisi A, 2003, PROC CVPR IEEE, P721; Darabi S., 2012, P ANN C COMP GRAPH I; Deselaers T, 2010, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2010.5539775; Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Farbman Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024209; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2; He KM, 2012, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2012.6247665; Jia JY, 2004, IEEE T PATTERN ANAL, V26, P771, DOI 10.1109/TPAMI.2004.10; Jia JY, 2003, PROC CVPR IEEE, P643; Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7; Kim VG, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2167076.2167080; Komodakis N., 2006, IEEE COMPUTER SOC C, V1, P442, DOI DOI 10.1109/CVPR.2006.141; Kopf J., 2012, P SIGGRAPH AS C; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Mansfield A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.121; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159; Roth S, 2005, PROC CVPR IEEE, P860; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Simakov D., 2008, 2008 IEEE CVPR, P1; Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274; Wexler Y, 2004, PROC CVPR IEEE, P120; Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60; Zhang YD, 2013, PROC CVPR IEEE, P1171, DOI 10.1109/CVPR.2013.155; Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401	42	99	119	4	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2423	2435		10.1109/TPAMI.2014.2330611	http://dx.doi.org/10.1109/TPAMI.2014.2330611			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353149				2022-12-18	WOS:000344988000008
J	Hu, WM; Li, X; Luo, WH; Zhang, XQ; Maybank, S; Zhang, ZF				Hu, Weiming; Li, Xi; Luo, Wenhan; Zhang, Xiaoqin; Maybank, Stephen; Zhang, Zhongfei			Single and Multiple Object Tracking Using Log-Euclidean Riemannian Subspace and Block-Division Appearance Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual object tracking; occlusion reasoning; log-euclidean Riemannian subspace; incremental learning; block-division appearance model	VISUAL TRACKING; PEOPLE; RECOGNITION	Object appearance modeling is crucial for tracking objects, especially in videos captured by nonstationary cameras and for reasoning about occlusions between multiple moving objects. Based on the log-euclidean Riemannian metric on symmetric positive definite matrices, we propose an incremental log-euclidean Riemannian subspace learning algorithm in which covariance matrices of image features are mapped into a vector space with the log-euclidean Riemannian metric. Based on the subspace learning algorithm, we develop a log-euclidean block-division appearance model which captures both the global and local spatial layout information about object appearances. Single object tracking and multi-object tracking with occlusion reasoning are then achieved by particle filtering-based Bayesian state inference. During tracking, incremental updating of the log-euclidean block-division appearance model captures changes in object appearance. For multi-object tracking, the appearance models of the objects can be updated even in the presence of occlusions. Experimental results demonstrate that the proposed tracking algorithm obtains more accurate results than six state-of-the-art tracking algorithms.	[Hu, Weiming; Li, Xi; Luo, Wenhan; Zhang, Xiaoqin] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Maybank, Stephen] Univ London Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England; [Zhang, Zhongfei] SUNY Binghamton, Watson Sch Engn & Appl Sci, Dept Comp Sci, Binghamton, NY 13902 USA	Chinese Academy of Sciences; Institute of Automation, CAS; University of London; Birkbeck University London; State University of New York (SUNY) System; State University of New York (SUNY) Binghamton	Li, X (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Zhongguancun E Rd,POB 2728, Beijing 100190, Peoples R China.	wmhu@nlpr.ia.ac.cn; lixi@nlpr.ia.ac.cn; whluo@nlpr.ia.ac.cn; xqzhang@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk; zhongfei@cs.binghamton.edu	Luo, Wenhan/GZL-0535-2022; Li, Xi/L-1234-2013	Li, Xi/0000-0003-3023-1662; Luo, Wenhan/0000-0002-5697-4168	NSFC [60825204, 60935002, 61100147]; National 863 High-Tech R&D Program of China [2012AA012504]; Natural Science Foundation of Beijing [4121003]; US National Science Foundation [IIS-0812114, CCF-1017828]; National Basic Research Program of China [2012CB316400]; Alibaba Financial-Zhejiang University Joint Research Lab	NSFC(National Natural Science Foundation of China (NSFC)); National 863 High-Tech R&D Program of China(National High Technology Research and Development Program of China); Natural Science Foundation of Beijing(Beijing Natural Science Foundation); US National Science Foundation(National Science Foundation (NSF)); National Basic Research Program of China(National Basic Research Program of China); Alibaba Financial-Zhejiang University Joint Research Lab	The authors thank Drs. Xue Zhou, Wei Li, Xinchu Shi, Mingliang Zhu, and Jian Chen for their valuable suggestions on the work. This work is partly supported by the NSFC (Grant No. 60825204, 60935002, 61100147), the National 863 High-Tech R&D Program of China (Grant No. 2012AA012504), the Natural Science Foundation of Beijing (Grant No. 4121003), the US National Science Foundation (IIS-0812114, CCF-1017828), the National Basic Research Program of China (2012CB316400), and the Alibaba Financial-Zhejiang University Joint Research Lab.	[Anonymous], COMPUTER VISION PATT; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Black MJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P660, DOI 10.1109/ICCV.1998.710788; Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI DOI 10.1109/CVPR.2008.4587581; Fletcher PT, 2004, LECT NOTES COMPUT SC, V3117, P87; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; Gay-Bellile V, 2010, IEEE T PATTERN ANAL, V32, P87, DOI 10.1109/TPAMI.2008.265; Grabner M, 2007, PROC CVPR IEEE, P200; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; He W, 2009, IEEE I CONF COMP VIS, P1586, DOI 10.1109/ICCV.2009.5459360; Herbst E., 2009, TECHNICAL REPORT; Ho J, 2004, PROC CVPR IEEE, P782; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Ilic S, 2007, IEEE I CONF COMP VIS, P936; Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549; Ishiguro K, 2008, PROC CVPR IEEE, P3009; Jepson AD, 2001, PROC CVPR IEEE, P415; Jin Y., 2007, 2007 IEEE 11 INT C C, P1, DOI [10.1109/ICCV.2007.4408952, DOI 10.1109/ICCV.2007.4408952]; Joshi N, 2007, IEEE I CONF COMP VIS, P1501; Khan S., 2000, AS C COMP VIS, P1132; Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102; Kwon J, 2009, PROC CVPR IEEE, P991, DOI 10.1109/CVPRW.2009.5206501; Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502; Lee KC, 2005, PROC CVPR IEEE, P852; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; Li J, 2005, IEEE I CONF COMP VIS, P1252; Li XB, 2008, CAN J EDUC ADM POLIC, P1, DOI 10.1109/CVPR.2008.4587516; Li YM, 2004, PATTERN RECOGN, V37, P1509, DOI 10.1016/j.patcog.2003.11.010; Liang DW, 2010, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2010.5539808; Lim HA, 2006, MULTIPLICITY YOURS: CLONING, STEM CELL RESEARCH, AND REGENERATIVE MEDICINE, P1; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; Mitzel D, 2010, LECT NOTES COMPUT SC, V6311, P397, DOI 10.1007/978-3-642-15549-9_29; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Porikli F., 2008, P INT WORKSH OBJ REC; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Qu W, 2007, IEEE T MULTIMEDIA, V9, P511, DOI 10.1109/TMM.2006.886266; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Rossmann W., 2002, GROUPS INTRO LINEAR; Silveira G, 2007, PROC CVPR IEEE, P186; Skocaj D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1494; Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Sudderth E., 2004, ADV NEURAL INFORM PR, V17, P1369; Ta DN, 2009, PROC CVPR IEEE, P2929; Tran S., 2007, IEEE 11 INT C COMP V, P1; Tuzel O., 2007, PROC CVPR IEEE, P1, DOI [DOI 10.1109/CVPR.2007.383197, 10.1109/CVPR.2007.383197]; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Wang CH, 2009, IEEE I CONF COMP VIS, P747; Wang H., 2005, P IEEE INT C IM PROC, V2, P410; Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]; Wu B., 2006, 2006 IEEE COMP SOC C, V1, P951, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Wu Y, 2003, PROC CVPR IEEE, P789; Yan S., 2007, P IEEE INT C COMP VI, P1; Yang M, 2007, IEEE I CONF COMP VIS, P897; Yang M, 2009, IEEE T IMAGE PROCESS, V18, P1633, DOI 10.1109/TIP.2009.2019807; Yilmaz A, 2007, PROC CVPR IEEE, P140; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742; Zhao Q., 2007, P ICWSM, P1; Zhao T, 2004, PROC CVPR IEEE, P406; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152; Zhou X, 2007, LECT NOTES COMPUT SC, V4843, P832	66	99	106	2	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2420	2440		10.1109/TPAMI.2012.42	http://dx.doi.org/10.1109/TPAMI.2012.42			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22331855				2022-12-18	WOS:000309913700011
J	Gotardo, PFU; Martinez, AM				Gotardo, Paulo F. U.; Martinez, Aleix M.			Computing Smooth Time Trajectories for Camera and Deformable Shape in Structure from Motion with Occlusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structure from motion; matrix factorization; missing data; camera trajectory; shape trajectory	NONRIGID SHAPE; MISSING DATA; RECOVERY	We address the classical computer vision problems of rigid and nonrigid structure from motion (SFM) with occlusion. We assume that the columns of the input observation matrix W describe smooth 2D point trajectories over time. We then derive a family of efficient methods that estimate the column space of W using compact parameterizations in the Discrete Cosine Transform (DCT) domain. Our methods tolerate high percentages of missing data and incorporate new models for the smooth time trajectories of 2D-points, affine and weak-perspective cameras, and 3D deformable shape. We solve a rigid SFM problem by estimating the smooth time trajectory of a single camera moving around the structure of interest. By considering a weak-perspective camera model from the outset, we directly compute euclidean 3D shape reconstructions without requiring postprocessing steps such as euclidean upgrade and bundle adjustment. Our results on real SFM data sets with high percentages of missing data compared positively to those in the literature. In nonrigid SFM, we propose a novel 3D shape trajectory approach that solves for the deformable structure as the smooth time trajectory of a single point in a linear shape space. A key result shows that, compared to state-of-the-art algorithms, our nonrigid SFM method can better model complex articulated deformation with higher frequency DCT components while still maintaining the low-rank factorization constraint. Finally, we also offer an approach for nonrigid SFM when W is presented with missing data.	[Gotardo, Paulo F. U.; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Dreese Labs 205, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Gotardo, PFU (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Dreese Labs 205, 2015 Neil Ave, Columbus, OH 43210 USA.	gotardop@ece.osu.edu; aleix@ece.osu.edu			US National Science Foundation (NSF) [0713055]; US National Institutes of Health [R01 DC 005241]; NATIONAL EYE INSTITUTE [R01EY020834] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R21DC011081, R01DC005241] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	The authors thank the reviewers for their constructive comments. This research was supported in part by the US National Science Foundation (NSF), grant 0713055, and the US National Institutes of Health, grant R01 DC 005241.	AKHTER I, 2008, P NEUR INF PROC SYST; Akhter I, 2009, PROC CVPR IEEE, P1534, DOI 10.1109/CVPRW.2009.5206620; BARTOLI A, 2008, IEEE CVPR, V1, P1; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Buchanan AM, 2005, PROC CVPR IEEE, P316; Chen P, 2004, IEEE T PATTERN ANAL, V26, P1051, DOI 10.1109/TPAMI.2004.52; Chen P, 2008, INT J COMPUT VISION, V80, P125, DOI 10.1007/s11263-008-0135-7; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; Ding LY, 2009, IMAGE VISION COMPUT, V27, P1826, DOI 10.1016/j.imavis.2009.02.005; Forsyth David A, 2012, COMPUTER VISION MODE; FORTUNA J, 2010, INT J COMPUTER VISIO; Golub G. H., 2012, MATRIX COMPUTATIONS; Guilbert N, 2006, INT J COMPUT VISION, V69, P317, DOI 10.1007/s11263-006-8113-4; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; HARTLEY R, 2003, P AUSTR JAP ADV WORK; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; JAIN AK, 1979, IEEE T PATTERN ANAL, V1, P356, DOI 10.1109/TPAMI.1979.4766944; Jia HJ, 2009, IEEE T PATTERN ANAL, V31, P841, DOI 10.1109/TPAMI.2008.122; Magnus J. R, 1999, MATRIX DIFFERENTIAL; Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004; Martinec D, 2002, LECT NOTES COMPUT SC, V2351, P355; Olsen SI, 2008, J MATH IMAGING VIS, V31, P233, DOI 10.1007/s10851-007-0060-3; Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602; POLLEFEYS M, 2002, P EUR C COMP VIS, V2, P837; RABAUD V, 2008, P IEEE CVPR, V1, P1; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; TARDIF JP, 2007, P CVPR, P1; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Wiberg T, 1976, P 2 S COMP STAT, P229; Xiao J, 2004, PROC CVPR IEEE, P668; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Yan JY, 2008, IEEE T PATTERN ANAL, V30, P865, DOI 10.1109/TPAMI.2007.70739	34	99	100	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2051	2065		10.1109/TPAMI.2011.50	http://dx.doi.org/10.1109/TPAMI.2011.50			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21383398	Green Accepted, Green Submitted			2022-12-18	WOS:000293969000012
J	Goldman, DB; Curless, B; Hertzmann, A; Seitz, SM				Goldman, Dan B.; Curless, Brian; Hertzmann, Aaron; Seitz, Steven M.			Shape and Spatially-Varying BRDFs from Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape/scene analysis; reflectance digitization and image capture	RECONSTRUCTION; REFLECTANCE; RECIPROCITY	This paper describes a photometric stereo method designed for surfaces with spatially-varying BRDFs, including surfaces with both varying diffuse and specular properties. Our optimization-based method builds on the observation that most objects are composed of a small number of fundamental materials by constraining each pixel to be representable by a combination of at most two such materials. This approach recovers not only the shape but also material BRDFs and weight maps, yielding accurate rerenderings under novel lighting conditions for a wide variety of objects. We demonstrate examples of interactive editing operations made possible by our approach.	[Goldman, Dan B.] Adobe Syst Inc, Seattle, WA 98103 USA; [Curless, Brian; Seitz, Steven M.] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Hertzmann, Aaron] Univ Toronto, Dept Comp Sci, Bahen Ctr, Toronto, ON M5S 2E4, Canada	Adobe Systems Inc.; University of Washington; University of Washington Seattle; University of Toronto	Goldman, DB (corresponding author), Adobe Syst Inc, 801 N 34th St, Seattle, WA 98103 USA.	dgoldman@adobe.com; curless@cs.washingto.edu; hertzman@dgp.toronto.edu; seitz@cs.washingto.edu		Hertzmann, Aaron/0000-0001-9667-0292	US National Science Foundation [CCR-0098005, IIS-0413198]; NSERC; Washington Research Foundation; US Office of Naval Research; Animation Research Labs; Microsoft Corporation; Adobe Systems	US National Science Foundation(National Science Foundation (NSF)); NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); Washington Research Foundation; US Office of Naval Research(Office of Naval Research); Animation Research Labs; Microsoft Corporation(Microsoft); Adobe Systems	This work was supported in part by the US National Science Foundation under grants CCR-0098005 and IIS-0413198, NSERC, the Washington Research Foundation, a US Office of Naval Research YIP award, Animation Research Labs, Microsoft Corporation, and Adobe Systems.	Alldrin N, 2008, PROC CVPR IEEE, P2447; Bajcsy R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P785, DOI 10.1109/ICPR.1990.118217; Biermann H, 2002, ACM T GRAPHIC, V21, P312, DOI 10.1145/566570.566583; Forsyth David A, 2012, COMPUTER VISION MODE; GEORGHIADES AS, 2003, P EUR WORKSH REND, P230; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Jin HL, 2004, LECT NOTES COMPUT SC, V3022, P114; Jin HL, 2003, PROC CVPR IEEE, P171; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; LARSON GW, 1992, P SIGGRAPH JUL, P265; Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949; Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891; Malik J., 2008, P 24 ANN C COMPUTER, P31, DOI DOI 10.1145/1401132.1401174; Mallick SP, 2005, PROC CVPR IEEE, P619; Marschner S., 1999, P 10 EUR WORKSH REND, P139; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; MATUSIK W, 2003, P 14 EUR WORKSH REND, P241; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Paterson JA, 2005, COMPUT GRAPH FORUM, V24, P383, DOI 10.1111/j.1467-8659.2005.00863.x; Press W.H., 1992, NUMERICAL RECIPES C, V2; SATO Y, 1997, P SIGGRAPH 97, P379; Silver W.M., 1980, THESIS MIT; Tong X, 2002, ACM T GRAPHIC, V21, P665, DOI 10.1145/566570.566634; TREUILLE A, 2004, P EUR C COMP VIS; TRUCCO E, 1998, INTRO TECHNIQUES 3 D; Tu P, 2003, PROC CVPR IEEE, P541; Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297; Vogiatzis G., 2006, P 2006 IEEE COMP SOC, V2, P1847, DOI [10.1109/CVPR.2006.245, DOI 10.1109/CVPR.2006.245]; Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; YAMAZAKI T, 1998, P ICIRS 98 AUG, P368; Ying LI, 2001, SPRING EUROGRAP, P301; YU T, 2004, P CVPR 2004, V2, P226; Yu YZ, 1999, COMP GRAPH, P215; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	38	99	105	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1060	1071		10.1109/TPAMI.2009.102	http://dx.doi.org/10.1109/TPAMI.2009.102			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431131				2022-12-18	WOS:000276671900008
J	Schechner, YY; Nayar, SK; Belhumeur, PN				Schechner, Yoav Y.; Nayar, Shree K.; Belhumeur, Peter N.			Multiplexing for optimal lighting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						physics-based vision; image-based rendering; multiplexed illumination; Hadamard codes; photon noise	REFLECTANCE; ILLUMINATION	Imaging of objects under variable lighting directions is an important and frequent practice in computer vision, machine vision, and image-based rendering. Methods for such imaging have traditionally used only a single light source per acquired image. They may result in images that are too dark and noisy, e. g., due to the need to avoid saturation of highlights. We introduce an approach that can significantly improve the quality of such images, in which multiple light sources illuminate the object simultaneously from different directions. These illumination-multiplexed frames are then computationally demultiplexed. The approach is useful for imaging dim objects, as well as objects having a specular reflection component. We give the optimal scheme by which lighting should be multiplexed to obtain the highest quality output, for signal-independent noise. The scheme is based on Hadamard codes. The consequences of imperfections such as stray light, saturation, and noisy illumination sources are then studied. In addition, the paper analyzes the implications of shot noise, which is signal-dependent, to Hadamard multiplexing. The approach facilitates practical lighting setups having high directional resolution. This is shown by a setup we devise, which is flexible, scalable, and programmable. We used it to demonstrate the benefit of multiplexing in experiments.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Technion Israel Institute of Technology; Columbia University	Schechner, YY (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	yoav@ee.technion.ac.il; nayar@cs.columbia.edu; belhumeur@cs.columbia.edu						BARRETT HH, 1981, RADIOLOGICAL IMAGING, V1, P82; BARRTETT HH, 1981, RADIOLOGICAL IMAGING, V1, P285; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Cula OG, 2005, PROC CVPR IEEE, P1116; Dana KJ, 2004, J OPT SOC AM A, V21, P1, DOI 10.1364/JOSAA.21.000001; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; *EASTM KOD CO, 2000, 01001 DS EASTM KOD C; *EASTM KOD CO, 2003, MTDPS0233 EASTM KOD; Epstein J. L., 1995, FAMILY SCH CONNECTIO, P108; FARID H, 1999, P CVPR, V1, P262; Fateley WG, 2002, VIB SPECTROSC, V29, P163, DOI 10.1016/S0924-2031(01)00205-3; FELLERS TJ, 2004, OPTICAL MICROSCOPY P; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; *HAM PHOTN KK, 1998, XEN FLASH LAMPS CAT; *HAM PHOTN KK, 2000, SUP QUIET XEN LAMPS; Hanley QS, 1999, APPL SPECTROSC, V53, P1, DOI 10.1366/0003702991945317; Harwit M., 1979, HADAMARD TRANSFORM O; Hatzitheodorou M, 1998, J COMPLEXITY, V14, P63, DOI 10.1006/jcom.1997.0448; Healey G., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P151; Horn B., 1986, ROBOT VISION; IOUE S, 1997, VIDEO MICROSCOPY, pCH6; JAIN AN, 1989, FUNDAMENTALS DIGITAL, P155; Koudelka ML, 2001, PROC CVPR IEEE, P568; Lee SH, 1998, J ELECTRON MATER, V27, P684, DOI 10.1007/s11664-998-0036-0; Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891; Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806; LUONG QT, 2002, P EUR C COMP VIS, P163; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Marschner SR, 2000, APPL OPTICS, V39, P2592, DOI 10.1364/AO.39.002592; MASSELUS V, 2002, P 13 EUR WORKSH REND, P247; Matusik W, 2002, ACM T GRAPHIC, V21, P427, DOI 10.1145/566570.566599; MATUSIK W, 2004, P EUR S REND; Moses Y, 1996, PERCEPTION, V25, P443, DOI 10.1068/p250443; Nitzsche G, 2003, PROC SPIE, V5111, P273, DOI 10.1117/12.510052; Osadchy M, 2004, COMPUT VIS IMAGE UND, V93, P245, DOI 10.1016/j.cviu.2003.10.001; Ramantoorthi R, 2002, ACM T GRAPHIC, V21, P517, DOI 10.1145/566570.566611; Sato I, 2005, IEEE I CONF COMP VIS, P325; Schechner YY, 2004, PROC SPIE, V5529, P198, DOI 10.1117/12.559573; Schechner YY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P808; Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Turner JF, 1996, APPL SPECTROSC, V50, P277, DOI 10.1366/0003702963906609; Wuttig A., 2002, Proceedings of the SPIE - The International Society for Optical Engineering, V4480, P334, DOI 10.1117/12.453357; Yuille A, 2003, J OPT SOC AM A, V20, P24, DOI 10.1364/JOSAA.20.000024	48	99	124	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1339	1354		10.1109/TPAMI.2007.1151	http://dx.doi.org/10.1109/TPAMI.2007.1151			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568139				2022-12-18	WOS:000247186500004
J	Martel-Brisson, N; Zaccarin, A				Martel-Brisson, Nicolas; Zaccarin, Andre			Learning and removing cast shadows through a multidistribution approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shadow detection; GMM; GMSM; background subtraction; multidistribution; segmentation; image models; pixel classification		Moving cast shadows are a major concern for foreground detection algorithms. The processing of foreground images in surveillance applications typically requires that such shadows be identified and removed from the detected foreground. This paper presents a novel pixel-based statistical approach to model moving cast shadows of nonuniform and varying intensity. This approach uses the Gaussian mixture model (GMM) learning ability to build statistical models describing moving cast shadows on surfaces. This statistical modeling can deal with scenes with complex and time-varying illumination, including light saturated areas, and prevent false detection in regions where shadows cannot be detected. The proposed approach can be used with pixel-based descriptions of shadowed surfaces found in the literature. It significantly reduces their false detection rate without increasing the missed detection rate. Results obtained with different scene types and shadow models show the robustness of the approach.	Univ Laval, Dept Elect & Comp Engn, Comp Vis & Syst Lab, Quebec City, PQ G1K 7P4, Canada	Laval University	Martel-Brisson, N (corresponding author), Univ Laval, Dept Elect & Comp Engn, Comp Vis & Syst Lab, Quebec City, PQ G1K 7P4, Canada.	nmartel@gel.ulaval.ca; zaccarin@gel.ulaval.ca						Cucchiara R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P334, DOI 10.1109/ITSC.2001.948679; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Fung GSK, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P404, DOI 10.1109/ICIAP.2001.957043; Horprasert T., 1999, P INT C COMP VIS FRA; Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51; Pinel JM, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P285, DOI 10.1109/ICIP.2002.1038961; Power P. W., 2002, IMAGE VISION COMPUT, P267; Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520; Salvador E., 2004, COMPUT VIS IMAGE UND, V95, P238, DOI DOI 10.1016/j.cviu.2004.03.008; Schreer O, 2002, PROCEEDINGS VIPROMCOM-2002, P371, DOI 10.1109/VIPROM.2002.1026685; Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; THONGKAMWITOON T, 2004, P IEEE INT C MULTIME, V2, P1459	13	99	112	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1133	1146		10.1109/TPAMI.2007.1039	http://dx.doi.org/10.1109/TPAMI.2007.1039			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496373				2022-12-18	WOS:000246395300003
J	GARCIA, P; VIDAL, E				GARCIA, P; VIDAL, E			INFERENCE OF KAPPA-TESTABLE LANGUAGES IN THE STRICT SENSE AND APPLICATION TO SYNTACTIC PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											GARCIA, P (corresponding author), UNIV POLITECN VALENCIA,DEPT SISTEMAS INFORMAT & COMPUTAC,E-46071 VALENCIA,SPAIN.							ABRAMSON N, 1966, INFORMATION THEORY C; Aho AV, 1974, DESIGN ANAL COMPUTER; ANGLUIN D, 1983, COMPUT SURV, V15, P237, DOI 10.1145/356914.356918; ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BIERMANN AW, 1972, IEEE T COMPUT, VC 21, P592, DOI 10.1109/TC.1972.5009015; CHAUDHURI R, 1986, J ACM, V33, P702, DOI 10.1145/6490.214099; DEROUAULT AM, 1986, IEEE T PATTERN ANAL, V8, P742, DOI 10.1109/TPAMI.1986.4767855; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FU KS, 1982, SYNTACTIC PATTERN RE; GARCIA P, 1987, IEEE T PATTERN ANAL, V9, P841, DOI 10.1109/TPAMI.1987.4767991; GARCIA P, 1988, THESIS U POLITECNICA; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; ITOGA SY, 1981, IEEE T PATTERN ANAL, V3, P191, DOI 10.1109/TPAMI.1981.4767078; KUDO M, 1988, PATTERN RECOGN, V21, P401, DOI 10.1016/0031-3203(88)90053-2; LEVINE B, 1981, IEEE T PATTERN ANAL, V3; MARYANSKI FJ, 1977, IEEE T COMPUT, V26, P531; McNaughton R., 1974, Mathematical Systems Theory, V8, P60, DOI 10.1007/BF01761708; MICLET L, 1980, IEEE T SYST MAN CYB, V10, P737, DOI 10.1109/TSMC.1980.4308394; PETERSON JL, 1980, COMPUTER PROGRAMS SP; RADHAKRISHNAN V, 1988, PATTERN RECOGN, V21, P55, DOI 10.1016/0031-3203(88)90071-4; RADHAKRISHNAN V, 1987, IEEE T SYST MAN CYBE, V17; RICHETIN M, 1984, PATTERN RECOGN, V17, P245, DOI 10.1016/0031-3203(84)90063-3; RULOT H, 1987, PATTERN RECOGN, P451; Salomaa Arto., 1981, JEWELS FORMAL LANGUA; SHANNON CE, 1948, BELL SYST TECH J, V27, P390; SMITH AR, 1985, P IEEE ICASSP 85; VENTA O, 1986, P IEEE ICPR 86, P1214; VENTA O, 1984, P IEEE ICPR 84, P1240; VERNADAT F, 1984, P IEEE ICPR 84, P1370; VIDAL E, 1985, NEW SYSTEMS ARCHITEC, P427; Zalcstein Y., 1972, J COMPUT SYST SCI, V6, P151	38	99	102	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1990	12	9					920	925		10.1109/34.57687	http://dx.doi.org/10.1109/34.57687			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DV778					2022-12-18	WOS:A1990DV77800008
J	SANDERSON, AC; WEISS, LE; NAYAR, SK				SANDERSON, AC; WEISS, LE; NAYAR, SK			STRUCTURED HIGHLIGHT INSPECTION OF SPECULAR SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,DEPT ELECT & COMP ENGN,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University								Agin G.J, 1972, REPRESENTATION DESCR; BABU MDR, 1985, PATTERN RECOGN, V18, P53, DOI 10.1016/0031-3203(85)90006-8; Besl P. J., 1985, IEEE Journal of Robotics and Automation, VRA-1, P42, DOI 10.1109/JRA.1985.1086997; BRACHO R, CMURITR836 CARN U RO; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; DAVY JG, 1985, BRAZING SOLDERING, P50; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; HORN BKP, 1984, SCI AM, V251, P100, DOI 10.1038/scientificamerican0884-100; HORN BKP, 1977, ARTIFICIAL INTELL, V8; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; IKEUCHI K, 1980, MIT AI566 ART INT LA; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MERRILL PA, 1985, TR851R MCGILL U REP; NAKAGAWA Y, 1982, P SOC PHOTO-OPT INST, V336, P121, DOI 10.1117/12.933619; VANZETTI R, 1981, 24TH P IPC ANN M, P1; Woodham R.J., 1979, IMAGE UNDERSTANDING, V155, P136; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479	18	99	107	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					44	55		10.1109/34.3866	http://dx.doi.org/10.1109/34.3866			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366		Green Submitted			2022-12-18	WOS:A1988L436600005
J	BURR, DJ				BURR, DJ			ELASTIC MATCHING OF LINE DRAWINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BURR, DJ (corresponding author), BELL TEL LABS INC,HOLMDEL,NJ 07733, USA.							BAKER H, 1977, 5TH P INT JOINT C AR, P649; BARNARD ST, 1979, 791 U MINN DEP COMP; BURR DC, UNPUBLISHED; BURR DJ, 1979, AUG P IEEE COMP SOC; BURR DJ, 1978, THESIS U ILLINOIS UR; Burrell David B., 1979, AUG P IEEE COMP SOC, P17; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; GANAPATHY S, 1975, AIM272 STANF U STANF; GREENBERG ME, 1977, THESIS MIT CAMBRIDGE; HANNAH MJ, 1974, AIM239 STANF U STANF; HORN BKP, 1978, COMMUN ACM, V21, P914, DOI 10.1145/359642.359647; LILLESTRAND RL, 1972, IEEE T COMPUT, VC 21, P654, DOI 10.1109/T-C.1972.223570; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MOORE RK, 1979, JAN IEEE T PATT AN M, V1, P86; PERKINS DN, 1970, THESIS MIT CAMBRIDGE; PRICE K, 1979, JAN IEEE T PATT AN M, V1, P110; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; RUBIN S, 1978, THESIS CARNEGIEMELLO; STERN G, 1978, THESIS U UTAH SALT L; ULLMAN JR, 1974, MAY IEEE T SYST MAN, V4; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; [No title captured]	22	99	103	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					708	713		10.1109/TPAMI.1981.4767176	http://dx.doi.org/10.1109/TPAMI.1981.4767176			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868995				2022-12-18	WOS:A1981MR99600015
J	Zhu, XY; Liu, XM; Lei, Z; Li, Z				Zhu, Xiangyu; Liu, Xiaoming; Lei, Zhen; Li, Z.			Face Alignment in Full Pose Range: A 3D Total Solution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face alignment; 3D morphable model; convolutional neural network; cascaded regression	MODEL; SHAPE; LOCALIZATION	Face alignment, which fits a face model to an image and extracts the semantic meanings of facial pixels, has been an important topic in the computer vision community. However, most algorithms are designed for faces in small to medium poses (yaw angle is smaller than 45 degree), which lack the ability to align faces in large poses up to 90 degree. The challenges are three-fold. First, the commonly used landmark face model assumes that all the landmarks are visible and is therefore not suitable for large poses. Second, the face appearance varies more drastically across large poses, from the frontal view to the profile view. Third, labelling landmarks in large poses is extremely challenging since the invisible landmarks have to be guessed. In this paper, we propose to tackle these three challenges in an new alignment framework termed 3D Dense Face Alignment (3DDFA), in which a dense 3D Morphable Model (3DMM) is fitted to the image via Cascaded Convolutional Neural Networks. We also utilize 3D information to synthesize face images in profile views to provide abundant samples for training. Experiments on the challenging AFLW database show that the proposed approach achieves significant improvements over the state-of-the-art methods.	[Zhu, Xiangyu; Lei, Zhen; Li, Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, 95 Zhongguancun Donglu, Beijing 100190, Peoples R China; [Zhu, Xiangyu; Lei, Zhen; Li, Z.] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun Donglu, Beijing 100190, Peoples R China; [Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; Michigan State University	Lei, Z (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, 95 Zhongguancun Donglu, Beijing 100190, Peoples R China.; Lei, Z (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun Donglu, Beijing 100190, Peoples R China.	xiangyu.zhu@nlpr.ia.ac.cn; liuxm@msu.edu; zlei@nlpr.ia.ac.cn; szli@nlpria.ac.cn			National Key Research and Development Plan [2016YFC0801002]; Chinese National Natural Science Foundation [61473291, 61572501, 61502491, 61572536]; AuthenMetric RD Funds	National Key Research and Development Plan; Chinese National Natural Science Foundation(National Natural Science Foundation of China (NSFC)); AuthenMetric RD Funds	This work was supported by the National Key Research and Development Plan (Grant No. 2016YFC0801002), the Chinese National Natural Science Foundation Projects #61473291, #61572501, #61502491, #61572536 and AuthenMetric R&D Funds.	Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206; [Anonymous], 2006, COMP VIS PATT REC 20, DOI DOI 10.1109/CVPR.2006.11; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bettadapura V., 2012, FACE EXPRESSION RECO, P1; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen FX, 2016, LECT NOTES COMPUT SC, V9967, P40, DOI 10.1007/978-3-319-46654-5_5; Cootes T. F., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P680; Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2006, P BRIT MACH VIS C, V3, P929; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gross R, 2006, IMAGE VISION COMPUT, V24, P593, DOI 10.1016/j.imavis.2005.08.001; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448; Hou XW, 2001, PROC CVPR IEEE, P828; Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166; Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56; Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142; Jourabloo A., 2017, P IEEE INT C COMP VI, P1; Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001; Li SZ, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P324, DOI 10.1109/AFGR.2002.1004174; LIANG Z, 2015, ARXIV150703409; Martens J., 2010, P 27 INT C MACH LEAR, P735; Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523; Messer K., 2005, P 2 INT C AUD VID BA, VVolume 964, P965; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; PIOTRASCHKE M, 2016, PROC CVPR IEEE, P3418, DOI DOI 10.1109/CVPR.2016.372; Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Romdhani S, 2005, PROC CVPR IEEE, P986; Romdhani S., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P483; Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Saragih J, 2007, IEEE I CONF COMP VIS, P2173; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Wu Y., 2015, ARXIV151104031; Xiangyu Zhu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163096; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Zhang J., 2014, LECT NOTES COMPUT SC, P1; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhou Y, 2005, PROC CVPR IEEE, P741; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	73	98	99	5	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					78	92		10.1109/TPAMI.2017.2778152	http://dx.doi.org/10.1109/TPAMI.2017.2778152			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990058	Green Submitted			2022-12-18	WOS:000452434800007
J	Rudd, EM; Jain, LP; Scheirer, WJ; Boult, TE				Rudd, Ethan M.; Jain, Lalit P.; Scheirer, Walter J.; Boult, Terrance E.			The Extreme Value Machine	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; supervised classification; open set recognition; open world recognition; statistical extreme value theory	NOVELTY DETECTION; CLASSIFICATION; RECOGNITION	It is often desirable to be able to recognize when inputs to a recognition function learned in a supervised manner correspond to classes unseen at training time. With this ability, new class labels could be assigned to these inputs by a human operator, allowing them to be incorporated into the recognition function-ideally under an efficient incremental update mechanism. While good algorithms that assume inputs from a fixed set of classes exist, e.g., artificial neural networks and kernel machines, it is not immediately obvious how to extend them to perform incremental learning in the presence of unknown query classes. Existing algorithms take little to no distributional information into account when learning recognition functions and lack a strong theoretical foundation. We address this gap by formulating a novel, theoretically sound classifier-the Extreme Value Machine (EVM). The EVM has a well-grounded interpretation derived from statistical Extreme Value Theory (EVT), and is the first classifier to be able to perform nonlinear kernel-free variable bandwidth incremental learning. Compared to other classifiers in the same deep network derived feature space, the EVM is accurate and efficient on an established benchmark partition of the ImageNet dataset.	[Rudd, Ethan M.; Jain, Lalit P.; Boult, Terrance E.] Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA; [Scheirer, Walter J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	University of Colorado System; University of Colorado at Colorado Springs; University of Notre Dame	Rudd, EM (corresponding author), Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA.	erudd@vast.uccs.edu; ljain@vast.uccs.edu; walter.scheirer@nd.edu; tboult@vast.uccs.edu	Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529	US National Science Foundation [IIS-1320956]	US National Science Foundation(National Science Foundation (NSF))	This work was supported by US National Science Foundation IIS-1320956: Open Vision - Tools for Open Set Computer Vision and Learning.	Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Aiolli F, 2008, LECT NOTES COMPUT SC, V5163, P305, DOI 10.1007/978-3-540-87536-9_32; [Anonymous], 1998, STAT LEARNING THEORY; [Anonymous], 2013, P 12 PYTH SCI C, DOI DOI 10.1088/1749-4699/8/1/014008; Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bishop C.M, 2006, PATTERN RECOGN; Bodesheim P, 2015, IEEE WINT CONF APPL, P813, DOI 10.1109/WACV.2015.113; Cevikalp H, 2012, PROC CVPR IEEE, P3138, DOI 10.1109/CVPR.2012.6248047; Coles S., 2001, EXTREME VALUE THEORY; Crammer K, 2006, J MACH LEARN RES, V7, P551; Fisher RA, 1928, P CAMB PHILOS SOC, V24, P180, DOI 10.1017/S0305004100015681; Fragoso V, 2013, IEEE I CONF COMP VIS, P2472, DOI 10.1109/ICCV.2013.307; Fragoso V, 2013, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2013.357; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Garg A., 2003, ICML, P210; Gibert X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P131, DOI 10.1109/ICCVW.2015.27; Gopalan R, 2012, FOUND TRENDS COMPUT, V8, P285, DOI 10.1561/0600000057; Haines TSF, 2014, INT J COMPUT VISION, V106, P315, DOI 10.1007/s11263-013-0630-3; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9; Hsu W C, 2003, PRACTICAL GUIDE SUPP; Jain LP, 2014, LECT NOTES COMPUT SC, V8691, P393, DOI 10.1007/978-3-319-10578-9_26; Jhon S.-T., 2006, ADV LARGE MARGIN CLA, P349; Kapoor A, 2012, PROC CVPR IEEE, P2539, DOI 10.1109/CVPR.2012.6247971; Kotz S., 2001, EXTREME VALUE DISTRI; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Laskov P, 2006, J MACH LEARN RES, V7, P1909; Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83; Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35; Pelckmans K., 2008, P INT C NEUR INF PRO, V20, P1137; Pentina A, 2015, LECT NOTES ARTIF INT, V9355, P194, DOI 10.1007/978-3-319-24486-0_13; PICKANDS J, 1975, ANN STAT, V3, P119; Platt JC, 2000, ADV NEUR IN, P61; Reyzin L., 2006, PROC 23 INT C MACH L, P753, DOI DOI 10.1145/1143844.1143939; Ristin M, 2014, PROC CVPR IEEE, P3654, DOI 10.1109/CVPR.2014.467; Royer A, 2015, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2015.7298746; Scheirer W, 2010, LECT NOTES COMPUT SC, V6313, P481; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; Scheirer WJ, 2011, IEEE T PATTERN ANAL, V33, P1689, DOI 10.1109/TPAMI.2011.54; Slavik P., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P435, DOI 10.1006/jagm.1997.0887; Valentini G, 2004, J MACH LEARN RES, V5, P725; Yeh T, 2008, PROC CVPR IEEE, P61; Zhang H, 2017, IEEE T PATTERN ANAL, V39, P1690, DOI 10.1109/TPAMI.2016.2613924	49	98	102	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					762	768		10.1109/TPAMI.2017.2707495	http://dx.doi.org/10.1109/TPAMI.2017.2707495			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28541894	Green Submitted, hybrid			2022-12-18	WOS:000424465900019
J	Ren, SQ; He, KM; Girshick, R; Zhang, XY; Sun, J				Ren, Shaoqing; He, Kaiming; Girshick, Ross; Zhang, Xiangyu; Sun, Jian			Object Detection Networks on Convolutional Feature Maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; CNN; convolutional feature map		Most object detectors contain two important components: a feature extractor and an object classifier. The feature extractor has rapidly evolved with significant research efforts leading to better deep convolutional architectures. The object classifier, however, has not received much attention and many recent systems (like SPPnet and Fast/Faster R-CNN) use simple multi-layer perceptrons. This paper demonstrates that carefully designing deep networks for object classification is just as important. We experiment with region-wise classifier networks that use shared, region-independent convolutional features. We call them "Networks on Convolutional feature maps" (NoCs). We discover that aside from deep feature maps, a deep and convolutional per-region classifier is of particular importance for object detection, whereas latest superior image classification models (such as ResNets and GoogLeNets) do not directly lead to good detection accuracy without using such a per-region classifier. We show by experiments that despite the effective ResNets and Faster R-CNN systems, the design of NoCs is an essential element for the 1st-place winning entries in ImageNet and MS COCO challenges 2015.	[Ren, Shaoqing] Univ Sci & Technol China, Hefei 230026, Peoples R China; [He, Kaiming; Sun, Jian] Microsoft Res, Visual Comp Grp, Beijing 100080, Peoples R China; [Zhang, Xiangyu] Xi An Jiao Tong Univ, Xian 710049, Peoples R China; [Girshick, Ross] Facebook AI Res, Seattle, WA 98101 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Microsoft; Xi'an Jiaotong University; Facebook Inc	Ren, SQ (corresponding author), Univ Sci & Technol China, Hefei 230026, Peoples R China.	sqren@mail.ustc.edu.cn; kahe@microsoft.com; rbg@fb.com; xyz.clx@stu.xjtu.edu.cn; jiansun@microsoft.com						Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hoiem Derek, 2012, ECCV, P340, DOI [10.1007/978-3-642-33712-3_25, DOI 10.1007/978-3-642-33712-3_25]; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lenc K, 2015, ARXIV150606981; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mallat S, 1999, WAVELET TOUR SIGNAL, DOI DOI 10.1016/B978-012466606-1/50004-0; Nair V, 2010, P 27 INT C MACHINE L, P807; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sanjoy D., 2013, INT C MACH LEARN, P1319, DOI DOI 10.5555/3042817.3043084; Savalle P.-A., 2014, P EUR C COMP VIS PAR; Sermanet P., 2013, C LEARN REPR ICLR 20, P16; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wan L, 2015, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2015.7298686; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78	34	98	106	7	78	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1476	1481		10.1109/TPAMI.2016.2601099	http://dx.doi.org/10.1109/TPAMI.2016.2601099			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27541490	Green Submitted			2022-12-18	WOS:000402744400017
J	Xiao, M; Guo, YH				Xiao, Min; Guo, Yuhong			Feature Space Independent Semi-Supervised Domain Adaptation via Kernel Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain adaptation; kernel matching; heterogeneous feature spaces		Domain adaptation methods aim to learn a good prediction model in a label-scarce target domain by leveraging labeled patterns from a related source domain where there is a large amount of labeled data. However, in many practical domain adaptation learning scenarios, the feature distribution in the source domain is different from that in the target domain. In the extreme, the two distributions could differ completely when the feature representation of the source domain is totally different from that of the target domain. To address the problems of substantial feature distribution divergence across domains and heterogeneous feature representations of different domains, we propose a novel feature space independent semi-supervised kernel matching method for domain adaptation in this work. Our approach learns a prediction function on the labeled source data while mapping the target data points to similar source data points by matching the target kernel matrix to a submatrix of the source kernel matrix based on a Hilbert Schmidt Independence Criterion. We formulate this simultaneous learning and mapping process as a non-convex integer optimization problem and present a local minimization procedure for its relaxed continuous form. We evaluate the proposed kernel matching method using both cross domain sentiment classification tasks of Amazon product reviews and cross language text classification tasks of Reuters multilingual newswire stories. Our empirical results demonstrate that the proposed kernel matching method consistently and significantly outperforms comparison methods on both cross domain classification problems with homogeneous feature spaces and cross domain classification problems with heterogeneous feature spaces.	[Xiao, Min; Guo, Yuhong] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Xiao, M (corresponding author), Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA.	minxiao@temple.edu; yuhong@temple.edu						Amini M.R., 2009, ADV NEURAL INFORM PR, P28, DOI DOI 10.5555/2984093.2984097; Belkin M, 2002, NIPS, P953; Belkin Misha, 2005, P 10 INT WORKSH ART, P17; Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Blitzer J., 2011, PROC INT C ARTIF INT, P173; Chen M., 2011, ADV NEURAL INF PROCE, P2456; Dai W., 2008, P 22 ANN C NEUR INF; Daume H, 2007, P 45 ANN M ASS COMP, V45, P256; Donahue J., 2014, ICML, P647; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Duan L., 2012, P INT C MACH LEARN, V1, P711; Duan L., 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411; Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63; Hoffman J., 2013, P INT C LEARN REPR; Jagarlamudi J, 2010, AAAI CONF ARTIF INTE, P1020; Jiang Jing, 2007, P 16 ACM C INF KNOWL, P401; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kumar A., 2010, ADV NEURAL INFORM PR, V23, P478; Mirrashed F, 2013, IEEE I CONF COMP VIS, P2608, DOI 10.1109/ICCV.2013.324; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pan Sinno, 2007, ADAPTIVE LOCALIZATIO, V2, P1108; Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1118; Quadrianto N., 2008, P NIPS, P1289; Quadrianto N., 2010, MULTIMEDIA INFORM RE, P339; Rai Piyush, 2010, P NAACL HLT 2010 WOR, P27; Rostamizadeh A., 2009, ADV NEURAL INFORM PR, P1041; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sha, 2013, P INT C MACH LEARN; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Song L., 2007, P 24 INT C MACHINE L, P823, DOI [10.1145/1273496.1273600, DOI 10.1145/1273496.1273600]; Sugiyama M., 2008, NIPS, P1433; Tan S., 2009, P HUM LANG TECHN 200, P181; Tur G, 2009, INT CONF ACOUST SPEE, P3721, DOI 10.1109/ICASSP.2009.4960435; Wang C., 2011, P IJCAI, V22, P1541; Wang Hua-Yan, 2011, P AAAI, P513; Xiaoxiao Shi, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P1049, DOI 10.1109/ICDM.2010.65; Zheng V. W., 2008, PROC AAAI C ARTIF IN, P1427; Zhu Y., 2011, P 25 AAAI C ART INT	40	98	102	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					54	66		10.1109/TPAMI.2014.2343216	http://dx.doi.org/10.1109/TPAMI.2014.2343216			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353208				2022-12-18	WOS:000346970600006
J	Mahadevan, V; Vasconcelos, N				Mahadevan, Vijay; Vasconcelos, Nuno			Biologically Inspired Object Tracking Using Center-Surround Saliency Mechanisms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; discriminant tracking; saliency; attention; motion saliency; automatic target initialization; scale adaptive tracking; discriminant center-surround architecture; video modeling	ATTENTIVE TRACKING; DENSITY; SELECTION; TARGETS; MODELS	A biologically inspired discriminant object tracker is proposed. It is argued that discriminant tracking is a consequence of top-down tuning of the saliency mechanisms that guide the deployment of visual attention. The principle of discriminant saliency is then used to derive a tracker that implements a combination of center-surround saliency, a spatial spotlight of attention, and feature-based attention. In this framework, the tracking problem is formulated as one of continuous target-background classification, implemented in two stages. The first, or learning stage, combines a focus of attention (FoA) Mechanism, and bottom-up saliency to identify a maximally discriminant set of features for target detection. The second, or detection stage, uses a feature-based attention mechanism and a target-tuned top-down discriminant saliency detector to detect the target. Overall, the tracker iterates between learning discriminant features from the target location in a video frame and detecting the location of the target in the next. The statistics of natural images are exploited to derive an implementation which is conceptually simple and computationally efficient. The saliency formulation is also shown to establish a unified framework for classifier design, target detection, automatic tracker initialization, and scale adaptation. Experimental results show that the proposed discriminant saliency tracker outperforms a number of state-of-the-art trackers in the literature.	[Mahadevan, Vijay] Yahoo Labs, Bangalore 560071, Karnataka, India; [Vasconcelos, Nuno] Univ Calif San Diego, Elect & Comp Eningeering Dept, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Mahadevan, V (corresponding author), Yahoo Labs, Embassy Golf Links Business Pk, Bangalore 560071, Karnataka, India.	vijay.mahadevan@gmail.com; nvasconcelos@ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302				Adam A., 2006, IEEE C COMP VIS PATT; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Allen R, 2004, APPL COGNITIVE PSYCH, V18, P337, DOI 10.1002/acp.975; [Anonymous], 2007, PASCAL VISUAL OBJECT; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Birchfield ST, 2005, PROC CVPR IEEE, P1158; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Blaser E, 2000, NATURE, V408, P196, DOI 10.1038/35041567; Bretzner L, 1998, COMPUT VIS IMAGE UND, V71, P385, DOI 10.1006/cviu.1998.0650; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; CAVANAGH P, 1992, SCIENCE, V257, P1563, DOI 10.1126/science.1523411; Cavanagh P, 2005, TRENDS COGN SCI, V9, P349, DOI 10.1016/j.tics.2005.05.009; Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2530, DOI 10.1152/jn.00692.2001; CHERNOFF H, 1954, ANN MATH STAT, V25, P573, DOI 10.1214/aoms/1177728725; Collins R., 2003, P IEEE C COMP VIS PA, V2; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N., 2005, HISTOGRAMS ORIENTED; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Feldman J, 2006, COGNITION, V99, P131, DOI 10.1016/j.cognition.2004.12.008; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gao D., 2005, P ADV NEUR INF PROC; Gao D., 2007, P IEEE INT C COMP VI; Gao D., 2007, P IEEE C COMP VIS PA; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Gao DS, 2009, NEURAL COMPUT, V21, P239, DOI 10.1162/neco.2009.11-06-391; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Grabner H, 2006, IEEE C COMP VIS PATT, P260; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Han BY, 2005, IEEE I CONF COMP VIS, P1492; Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; Ho J., 2004, P IEEE C COMP VIS PA, V1; Intriligator J, 2001, COGNITIVE PSYCHOL, V43, P171, DOI 10.1006/cogp.2001.0755; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jinggang Huang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P541, DOI 10.1109/CVPR.1999.786990; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Keane BP, 2006, COGNITIVE PSYCHOL, V52, P346, DOI 10.1016/j.cogpsych.2005.12.001; LIN RS, 2004, ADV NEURAL INFORM PR, P801; MAGGIO E, 2005, P IEEE INT C AC SPEE; Mahadevan V., 2008, P IEEE C COMP VIS PA, V1; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Makovski T, 2009, VIS COGN, V17, P180, DOI 10.1080/13506280802211334; Masnadi-Shirazi H, 2010, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2010.5540136; Nguyen HT, 2006, INT J COMPUT VISION, V69, P277, DOI 10.1007/s11263-006-7067-x; NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M; Palmer S.E., 1999, VISION SCI PHOTONS P; POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160; PYLYSHYN Z W, 1988, Spatial Vision, V3, P179, DOI 10.1163/156856888X00122; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sekuler AB, 1999, PERCEPTION, V28, P415, DOI 10.1068/p2909; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; Toyama K, 1996, PROC CVPR IEEE, P189, DOI 10.1109/CVPR.1996.517073; Toyama K., 2000, P EUR C COMP VIS; Treue S, 1999, NATURE, V399, P575, DOI 10.1038/21176; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Vasconcelos M, 2009, IEEE T PATTERN ANAL, V31, P228, DOI 10.1109/TPAMI.2008.77; Vasconcelos N., 2002, P ADV NEUR INF PROC; Verstraten FAJ, 2000, VISION RES, V40, P3651, DOI 10.1016/S0042-6989(00)00213-3; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yilmaz A, 2007, PROC CVPR IEEE, P140; Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008	73	98	104	0	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					541	554		10.1109/TPAMI.2012.98	http://dx.doi.org/10.1109/TPAMI.2012.98			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22529325	Green Submitted			2022-12-18	WOS:000314792900003
J	Egozi, A; Keller, Y; Guterman, H				Egozi, Amir; Keller, Yosi; Guterman, Hugo			A Probabilistic Approach to Spectral Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphs; spectral matching; probabilistic matching; point matching	ALGORITHM; ASSIGNMENT	Spectral Matching (SM) is a computationally efficient approach to approximate the solution of pairwise matching problems that are np-hard. In this paper, we present a probabilistic interpretation of spectral matching schemes and derive a novel Probabilistic Matching (PM) scheme that is shown to outperform previous approaches. We show that spectral matching can be interpreted as a Maximum Likelihood (ML) estimate of the assignment probabilities and that the Graduated Assignment (GA) algorithm can be cast as a Maximum a Posteriori (MAP) estimator. Based on this analysis, we derive a ranking scheme for spectral matchings based on their reliability, and propose a novel iterative probabilistic matching algorithm that relaxes some of the implicit assumptions used in prior works. We experimentally show our approaches to outperform previous schemes when applied to exhaustive synthetic tests as well as the analysis of real image sequences.	[Egozi, Amir; Guterman, Hugo] Ben Gurion Univ Negev, Dept Elect Engn, IL-84105 Beer Sheva, Israel; [Keller, Yosi] Bar Ilan Univ, Fac Engn, IL-52100 Ramat Gan, Israel; [Guterman, Hugo] Ben Gurion Univ Negev, Dept Comp & Elect Engn, IL-84105 Beer Sheva, Israel	Ben Gurion University; Bar Ilan University; Ben Gurion University	Egozi, A (corresponding author), Ben Gurion Univ Negev, Dept Elect Engn, IL-84105 Beer Sheva, Israel.	agozi@ee.bgu.ac.il; yosi.keller@gmail.com; hugo@ee.bgu.ac.il		Guterman, Hugo/0000-0002-3803-9862				Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51; Chertok M, 2010, IEEE T PATTERN ANAL, V32, P1227, DOI 10.1109/TPAMI.2009.121; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cour T., 2007, P ADV NEURAL INFORM, P313; Cour T, 2007, ARTIF INTELL, P75; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Dasgupta S., 2008, ALGORITHMS; Duchenne O., 2009, P IEEE C COMP VIS PA; Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448; Garey M., 1990, COMPUTERS INTRACTABI; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; JOHNSON RM, 1963, PSYCHOMETRIKA, V28, P259, DOI 10.1007/BF02289573; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; Mjolsness E., 1991, YALEUDCSTR854; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Nemhauser G.L., 1988, INTEGER COMBINATORIA; Raj A, 2005, IEEE I CONF COMP VIS, P1048; Rangarajan A, 1999, NEURAL COMPUT, V11, P1455, DOI 10.1162/089976699300016313; Rangarajan A, 1996, IEEE T NEURAL NETWOR, V7, P1365, DOI 10.1109/72.548165; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; van Wyk BJ, 2004, IEEE T PATTERN ANAL, V26, P1526, DOI 10.1109/TPAMI.2004.95; Wang HF, 2006, PATTERN RECOGN, V39, P1012, DOI 10.1016/j.patcog.2005.05.013; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zass R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587500	37	98	103	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					18	27		10.1109/TPAMI.2012.51	http://dx.doi.org/10.1109/TPAMI.2012.51			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22350163				2022-12-18	WOS:000311127700004
J	Thornton, J; Savvides, M; Kumar, BVKV				Thornton, Jason; Savvides, Marios; Kumar, B. V. K. Vijaya			A Bayesian approach to deformed pattern matching of iris images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern matching; image processing; iris recognition; statistical models for pattern recognition	RECOGNITION; FILTERS	We describe a general probabilistic framework for matching patterns that experience in-plane nonlinear deformations, such as iris patterns. Given a pair of images, we derive a maximum a posteriori probability (MAP) estimate of the parameters of the relative deformation between them. Our estimation process accomplishes two things simultaneously: It normalizes for pattern warping and it returns a distortion-tolerant similarity metric which can be used for matching two nonlinearly deformed image patterns. The prior probability of the deformation parameters is specific to the pattern-type and, therefore, should result in more accurate matching than an arbitrary general distribution. We show that the proposed method is very well suited for handling iris biometrics, applying it to two databases of iris images which contain real instances of warped patterns. We demonstrate a significant improvement in matching accuracy using the proposed deformed Bayesian matching methodology. We also show that the additional computation required to estimate the deformation is relatively inexpensive, making it suitable for real-time applications.	Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Thornton, J (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Hamerschlag Hall B200-13,5000 Forbes Ave, Pittsburgh, PA 15213 USA.	jthornto@andrew.cmu.edu; Marios.Savvides@ri.cmu.edu; kumar@ece.cmu.edu		Bhagavatula, Vijayakumar/0000-0001-7126-6381				Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Boles WW, 1997, FIRST INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ELECTRONIC SYSTEMS, PROCEEDINGS 1997 - KES '97, VOLS 1 AND 2, P533, DOI 10.1109/KES.1997.619433; Cootes TF, 2001, PROC SPIE, V4322, P236, DOI 10.1117/12.431093; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Fancourt C, 2005, LECT NOTES COMPUT SC, V3546, P1; Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944; GROSS R, 2004, P IEEE WORKSH FAC PR, P72; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huang JZ, 2005, J COMPUT SCI TECH-CH, V20, P419, DOI 10.1007/s11390-005-0419-0; KUMAR BVK, 2003, P IEEE MULT MOD US A, P173; Kumar BVKV, 2002, IEEE IMAGE PROC, P53; KUMAR BVKV, 1992, APPL OPTICS, V31, P4773, DOI 10.1364/AO.31.004773; KUMAR BVKV, 1994, OPT LETT, V19, P1556, DOI 10.1364/OL.19.001556; LEVIN E, 1992, P ICASSP, V3, P149; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633; MASEK L, 2003, THESIS U W AUSTR; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PEREZ P, 1998, CWI Q, V11, P413; REFREGIER P, 1991, OPT LETT, V16, P829, DOI 10.1364/OL.16.000829; RUE H., 2005, GAUSSIAN MARKOV RAND; Savvides M, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P45, DOI 10.1109/AVSS.2003.1217900; Simoncelli EP, 1999, HDB COMPUTER VISION, P397; Tekalp M., 1995, DIGITAL VIDEO PROCES, V1; THORNTON J, 2005, P INT C IM AN REC, P1098; WILDES R, 2005, BIOMETRIC SYSTEMS, P63; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669; 2004, CASIA IRIS IMAGE DAT	31	98	102	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					596	606		10.1109/TPAMI.2007.1006	http://dx.doi.org/10.1109/TPAMI.2007.1006			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299217				2022-12-18	WOS:000244855600008
J	Hilaire, X; Tombre, K				Hilaire, X; Tombre, K			Robust and accurate vectorization of line drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document analysis; graphics recognition and interpretation; vectorization; curve segmentation; performance evaluation; line drawings	PERFORMANCE EVALUATION; ENGINEERING DRAWINGS; HOUGH TRANSFORM; ALGORITHM; CURVES; IMAGES; SYSTEM; MODEL	This paper presents a method for vectorizing the graphical parts of paper- based line drawings. The method consists of separating the input binary image into layers of homogeneous thickness, skeletonizing each layer, segmenting the skeleton by a method based on random sampling, and simplifying the result. The segmentation method is robust with a best bound of 50 percent noise reached for indefinitely long primitives. Accurate estimation of the recognized vector's parameters is enabled by explicitly computing their feasibility domains. Theoretical performance analysis and expression of the complexity of the segmentation method are derived. Experimental results and comparisons with other vectorization systems are also provided.	LORIA, F-54602 Villersles Nancy, France	Universite de Lorraine	Hilaire, X (corresponding author), LORIA, 615 Rue Jardin Bot, F-54602 Villersles Nancy, France.	xhilaire@free.fr; tombre@loria.fr						[Anonymous], STRUCTURED DOCUMENT; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Bodansky E., 2000, International Journal on Document Analysis and Recognition, V3, P67, DOI 10.1007/s100320000034; Chen Y, 1996, COMPUT VIS IMAGE UND, V63, P273, DOI 10.1006/cviu.1996.0019; Chhabra AK, 1998, LECT NOTES COMPUT SC, V1389, P390; CHHABRA AK, 2000, P 15 INT C PATT REC, V4, P4864; DANDECY VP, 1994, P 12 INT C PATT REC, V1, P301, DOI DOI 10.1109/ICPR.1994.576283; DIBAJA GS, 1994, J VIS COMMUN IMAGE R, V5, P107; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; Dori D, 1997, ADV ENG SOFTW, V28, P11, DOI 10.1016/S0965-9978(96)00035-X; DORST L, 1991, VISION GEOMETRY, V119, P45; Dosch P., 2000, International Journal on Document Analysis and Recognition, V3, P102, DOI 10.1007/PL00010901; ELLIMAN D, 2002, GRAPHICS RECOGNITION; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; HILAIRE X, 2002, GRAPHICS RECOGNITION; HILAIRE X, 2004, THESIS I POLYTECHNIQ; Hori O., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P353, DOI 10.1109/ICDAR.1993.395716; Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484; JOSEPH SH, 1992, IEEE T PATTERN ANAL, V14, P928, DOI 10.1109/34.161351; Kanungo T, 2000, IEEE T PATTERN ANAL, V22, P1209, DOI 10.1109/34.888707; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870; KULTANEN P, 1990, P MVA, P173; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; Lee KH, 2000, IEEE T PATTERN ANAL, V22, P1224, DOI 10.1109/34.888708; LIU W, 2004, GRAPHICS RECOGNITION; Liu WY, 1997, MACH VISION APPL, V9, P240, DOI 10.1007/s001380050045; Liu WY, 1998, IEEE T PATTERN ANAL, V20, P424, DOI 10.1109/34.677280; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; NAGASAMY V, 1990, COMPUT VISION GRAPH, V49, P379, DOI 10.1016/0734-189X(90)90111-8; OROURKE J, 1986, DISCRETE COMPUT GEOM, V1, P105, DOI 10.1007/BF02187688; Phillips IT, 1999, IEEE T PATTERN ANAL, V21, P849, DOI 10.1109/34.790427; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8; Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253; SMITH RW, 1987, PATTERN RECOGN, V20, P7, DOI 10.1016/0031-3203(87)90013-6; Song JQ, 2005, PATTERN RECOGN, V38, P539, DOI 10.1016/j.patcog.2004.09.003; Song JQ, 2004, IEEE T PATTERN ANAL, V26, P1491, DOI 10.1109/TPAMI.2004.103; Song JQ, 2002, IEEE T PATTERN ANAL, V24, P1048, DOI 10.1109/TPAMI.2002.1023802; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; THIEL E, 1994, THESIS U J FOURIER G; TOMBRE K, 2000, GRAPHICS RECOGNITION; Tombre K., 2002, P 5 IAPR INT WORKSH; TOMBRE K, 1998, LECT NOTES COMPUTER; VEELAERT P, 2002, P 10 INT C DISCR GEO; WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7; WENYIN L, 1998, ADV PATTERN RECOGNIT; WENYIN L, 1998, LECT NOTES COMPUTER, P9; WENYIN L, 2001, P CVPR WORKSH EMP EV; WENYIN L, 2002, LNCS, V2390, P273; YAMADA H, 1997, HDB CHARACTER RECOGN, P503; Zheng YF, 2005, IEEE T PATTERN ANAL, V27, P777, DOI 10.1109/TPAMI.2005.89	53	98	104	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					890	904		10.1109/TPAMI.2006.127	http://dx.doi.org/10.1109/TPAMI.2006.127			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724584	Green Submitted			2022-12-18	WOS:000236734400004
J	Frey, BJ; Jojic, N				Frey, BJ; Jojic, N			A comparison of algorithms for inference and learning in probabilistic graphical models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graphical models; Bayesian networks; probability models; probabilistic inference; reasoning; learning; Bayesian methods; variational techniques; sum-product algorithm; loopy belief propagation; EM algorithm; mean field; Gibbs sampling; free energy; Gibbs free energy; Bethe free energy	BELIEF-PROPAGATION	Research into methods for reasoning under uncertainty is currently one of the most exciting areas of artificial intelligence, largely because it has recently become possible to record, store, and process large amounts of data. While impressive achievements have been made in pattern classification problems such as handwritten character recognition, face detection, speaker identification, and prediction of gene function, it is even more exciting that researchers are on the verge of introducing systems that can perform large-scale combinatorial analyses of data, decomposing the data into interacting components. For example, computational methods for automatic scene analysis are now emerging in the computer vision community. These methods decompose an input image into its constituent objects, lighting conditions, motion patterns, etc. Two of the main challenges are finding effective representations and models in specific applications and finding efficient algorithms for inference and learning in these models. In this paper, we advocate the use of graph-based probability models and their associated inference and learning algorithms. We review exact techniques and various approximate, computationally efficient techniques, including iterated conditional modes, the expectation maximization (EM) algorithm, Gibbs sampling, the mean field method, variational techniques, structured variational techniques and the sum-product algorithm ("loopy" belief propagation). We describe how each technique can be applied in a vision model of multiple, occluding objects and contrast the behaviors and performances of the techniques using a unifying cost function, free energy.	Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G4, Canada; Microsoft Corp, Machine Learning & Appl Stat Grp, Redmond, WA 98052 USA	University of Toronto; Microsoft	Frey, BJ (corresponding author), Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	frey@psi.toronto.edu; jojic@microsoft.com						ADELSON EH, 1990, P AAAI WORKSH QUAL V; BARNDORFFNIELSO.OE, 1978, INFORMATION EXPONENT; BESAG J, 1986, J R STAT SOC B, V48, P259; CAHAN D, 1993, H VONHELMHOLTZ; COWELL RG, 1999, PROBABILISTIC NETWOR; COWELL RG, 1996, J BAYESIAN STAT, V5, P581; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Frey BJ, 1998, ADV NEUR IN, V10, P479; FREY BJ, 2003, P 19 C UNC ART INT; FREY BJ, 1999, P IEEE INT C COMP VI; FREY BJ, 2002, ADV NEURAL INFORMATI, V14; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GHAHRAMANI Z, 2001, ADV NEURAL INFORMATI, V13; HECKERMAN D, 1998, LEARNING GRAPHICAL M; Hinton G. E., 1986, PARALLEL DISTRIBUTED, V1, DOI DOI 10.1234/12345678; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; JOJIC N, 2000, P IEEE C COMP VIS PA; JOJIC N, 2001, P IEEE C COMP VIS PA; JOJIC N, 2003, P IEEE INT C COMP VI; JORDAN M, 1998, LEARNING GRAPHICAL M; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; MACKAY DJC, 1995, NUCL INSTRUM METH A, V354, P73, DOI 10.1016/0168-9002(94)00931-7; Mezard M, 2002, SCIENCE, V297, P812, DOI 10.1126/science.1073287; Minka T.P., 2001, P 17 C UNC ART INT, P362; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Neal RM, 1993, CRGTR931 U TOR DEP C; NEAL RM, 1991, CRGTR912 U TOR; NG AY, 2002, ADV NEURAL INFORMATI, V14; Wainwright MJ, 2003, 649 U CAL DEP STAT; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; WILLIAMS CW, 2003, ADV NEURAL INFORMATI, V15; Yedidia J., 2001, P INT JOINT C ART IN	37	98	109	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1392	1416		10.1109/TPAMI.2005.169	http://dx.doi.org/10.1109/TPAMI.2005.169			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173184				2022-12-18	WOS:000230463300004
J	Hamouz, M; Kittler, J; Kamarainen, JK; Paalanen, P; Kalviainen, H; Matas, J				Hamouz, M; Kittler, J; Kamarainen, JK; Paalanen, P; Kalviainen, H; Matas, J			Feature-based affine-invariant localization of faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face localization; face authentication		We present a novel method for localizing faces in person identification scenarios. Such scenarios involve high resolution images of frontal faces. The proposed algorithm does not require color, copes well in cluttered backgrounds, and accurately localizes faces including eye centers. An extensive analysis and a performance evaluation on the XM2VTS database and on the realistic Bio1D and BANCA face databases is presented. We show that the algorithm has precision superior to reference methods.	Univ Surrey, Sch Elect & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; Lappeenranta Univ Technol, Dept Informat Technol, FI-53851 Lappeenranta, Finland; Czech Tech Univ, Fac Elect Engn, Ctr Machine Percept, Dept Cybernet, Prague 12135, Czech Republic	University of Surrey; Lappeenranta University of Technology; Czech Technical University Prague	Hamouz, M (corresponding author), Univ Surrey, Sch Elect & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	m.hamouz@surrey.ac.uk; j.kittler@surrey.ac.uk; jkamarai@lut.fi; paalanen@lut.fi; kalviai@lut.fi; matas@cmp.felk.cvut.cz	Kämäräinen, Joni-Kristian/G-4296-2014; , Matas/AAW-3282-2020		Engineering and Physical Sciences Research Council [GR/S46543/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; Cootes TF, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P748, DOI 10.1109/ICCV.2001.937601; CRISTINACCE D, 2003, P BRIT MACH VIS C, V1, P213; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; GOODMAN NR, 1963, ANN MATH STAT, V34, P152, DOI 10.1214/aoms/1177704250; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; Hamouz M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P67, DOI 10.1109/AFGR.2004.1301510; HAMOUZ M, 2003, P INT C AUD VID BAS, P276; HAMOUZ M, 2002, P JOINT IAPR INT WOR, P566; JESORSKY O, 2001, P 3 INT C AUD VID BA, P90; Kamarainen J.-K., 2002, P IAPR WORKSH MACH V, P228; KOSTIN A, 2002, P 6 INT C PATT REC I, P371; KOTROPOULOS C, 1997, P IEEE INT C IM PROC, V1, P105; Kyrki V, 2004, PATTERN RECOGN LETT, V25, P311, DOI 10.1016/j.patrec.2003.10.008; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Matas J., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P604; Matas J, 2000, INT C PATT RECOG, P858; Messer K, 2003, LECT NOTES COMPUT SC, V2688, P964; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Sadeghi M, 2003, LECT NOTES COMPUT SC, V2688, P35; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Weber M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P20, DOI 10.1109/AFGR.2000.840607; WEBER M, 2000, P ECCV, V1, P18; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Yang MH, 2000, ADV NEUR IN, V12, P862; Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6	32	98	106	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1490	1495		10.1109/TPAMI.2005.179	http://dx.doi.org/10.1109/TPAMI.2005.179			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173191				2022-12-18	WOS:000230463300011
J	Wang, S; Kubota, T; Siskind, JM; Wang, J				Wang, S; Kubota, T; Siskind, JM; Wang, J			Salient closed boundary extraction with ratio contour	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; perceptual organization; boundary detection; edge detection; graph models	EDGE-DETECTION; IMAGE SEGMENTATION; ORGANIZATION; SNAKES; ROBUST	We present ratio contour, a novel graph-based method for extracting salient closed boundaries from noisy images. This method operates on a set of boundary fragments that are produced by edge detection. Boundary extraction identifies a subset of these fragments and connects them sequentially to form a closed boundary with the largest saliency. We encode the Gestalt laws of proximity and continuity in a novel boundary-saliency measure based on the relative gap length and average curvature when connecting fragments to form a closed boundary. This new measure attempts to remove a possible bias toward short boundaries. We present a polynomial-time algorithm for finding the most-salient closed boundary. We also present supplementary preprocessing steps that facilitate the application of ratio contour to real images. We compare ratio contour to two closely related methods for extracting closed boundaries: Elder and Zucker's method based on the shortest-path algorithm and Williams and Thornber's method based on spectral analysis and a strongly-connected-components algorithm. This comparison involves both theoretic analysis and experimental evaluation on both synthesized data and real images.	Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA; Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA	University of South Carolina; University of South Carolina System; University of South Carolina Columbia; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Wang, S (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.	songwang@cse.sc.edu; kubota@cse.sc.edu; qobi@purdue.edu; wang286@cse.sc.edu		Wang, Song/0000-0003-4152-5295				Ahuja R. K., 1993, NETWORK FLOWS THEORY; Alter TD, 1996, PROC CVPR IEEE, P13, DOI 10.1109/CVPR.1996.517047; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Cohen L. D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P587, DOI 10.1109/ICCV.1990.139601; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; EDMONDS J, 1965, CANADIAN J MATH, V17, P449, DOI 10.4153/CJM-1965-045-4; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; Gdalyahu Y., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P596, DOI 10.1109/CVPR.1999.784979; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kimia BB, 2003, INT J COMPUT VISION, V54, P157, DOI 10.1023/A:1023713602895; KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495; LEE TS, 1992, P EUR C COMP VIS, P165; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570; MUMFORD D, 1994, GEOMETRY DRIVEN DIFF, P135; Nitzberg M., 1993, LECT NOTES COMPUTER, V662; PERONA P, 1998, P EUR C COMP VIS, P655; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; RAMAN SV, 1993, CVGIP-IMAG UNDERSTAN, V57, P81, DOI 10.1006/ciun.1993.1005; RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490; Roberts L, 1965, MACHINE PERCEPTION 3; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sobel I, 1970, THESIS STANFORD U ST; Soundararajan P, 2003, IEEE T PATTERN ANAL, V25, P642, DOI 10.1109/TPAMI.2003.1201817; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; Veksler O, 2000, PROC CVPR IEEE, P339, DOI 10.1109/CVPR.2000.855838; Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819; Williams D. J., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P592, DOI 10.1109/ICCV.1990.139602; Williams F., 1996, DRUG DELIV, V3, P81, DOI 10.3109/10717549609031177; WILLIAMS L, 1997, NEURAL COMPUT, V9, P849; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	68	98	108	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					546	561		10.1109/TPAMI.2005.84	http://dx.doi.org/10.1109/TPAMI.2005.84			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794160	Green Submitted, Green Published			2022-12-18	WOS:000226845700006
J	Rajagopalan, AN; Chaudhuri, S; Mudenagudi, U				Rajagopalan, AN; Chaudhuri, S; Mudenagudi, U			Depth estimation and image restoration using defocused stereo pairs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						defocus; stereo; disparity; Markov random field; blur identification; depth recovery		We propose a method for estimating depth from images captured with a real aperture camera by fusing defocus and stereo cues. The idea is to use stereo-based constraints in conjunction with defocusing to obtain improved estimates of depth over those of stereo or defocus alone. The depth map as well as the original image of the scene are modeled as Markov random fields with a smoothness prior, and their estimates are obtained by minimizing a suitable energy function using simulated annealing. The main advantage of the proposed method, despite being computationally less efficient than the standard stereo or DFD method, is simultaneous recovery of depth as well as space-variant restoration of the original focused image of the scene.	Indian Inst Technol, Dept Elect Engn, Madras 600036, Tamil Nadu, India; Indian Inst Technol, Dept Elect Engn, Bombay 400076, Maharashtra, India; BVB Coll Engn, Dept Elect Engn, Hubli 580031, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay; KLE Technological University	Rajagopalan, AN (corresponding author), Indian Inst Technol, Dept Elect Engn, Madras 600036, Tamil Nadu, India.	raju@ee.iitm.ernet.in; sc@ee.iitb.ac.in; umakm@yahoo.com	Mudenagudi, Uma/P-8930-2019	Mudenagudi, Uma/0000-0003-1111-7522; Ambasamudram, Rajagopalan/0000-0002-0006-6961				BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; DESCHENES F, 2002, P IEEE INT C PATT RE, V3, P627; Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773; Flusser J, 1999, INT J PATTERN RECOGN, V13, P1123, DOI 10.1142/S021800149900063X; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; JULESZ B, 1964, SCIENCE, V145, P356, DOI 10.1126/science.145.3630.356; Kubota A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P447, DOI 10.1109/ICIP.1999.822936; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Rajagopalan AN, 1997, COMPUT VIS IMAGE UND, V68, P309, DOI 10.1006/cviu.1997.0534; Rajagopalan AN, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1047, DOI 10.1109/ICCV.1998.710846; Rajan D, 2003, IEEE T PATTERN ANAL, V25, P1102, DOI 10.1109/TPAMI.2003.1227986; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; SUBBARAO M, 1988, P INT C COMP VIS, P149; Subrahmonia J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P390, DOI 10.1109/ICPR.1990.118134; TSAI YP, 1998, DEPTH ESTIMATION INT; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977	20	98	108	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1521	1525		10.1109/TPAMI.2004.102	http://dx.doi.org/10.1109/TPAMI.2004.102			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521498				2022-12-18	WOS:000223737000010
J	Zunic, J; Rosin, PL				Zunic, J; Rosin, PL			A new convexity measure for polygons	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; polygons; convexity; measurement	SHAPE	Convexity estimators are commonly used in the analysis of shape. In this paper, we define and evaluate a new convexity measure for planar regions bounded by polygons. The new convexity measure can be understood as a "boundary-based" measure and in accordance with this it is more sensitive to measured boundary defects than the so called "area-based" convexity measures. When compared with the convexity measure defined as the ratio between the Euclidean perimeter of the convex hull of the measured shape and the Euclidean perimeter of the measured shape then the new convexity measure also shows some advantages-particularly for shapes with holes. The new convexity measure has the following desirable properties: 1) the estimated convexity is always a number from (0, 1] 2) the estimated convexity is 1 if and only if the measured shape is convex, 3) there are shapes whose estimated convexity is arbitrarily close to 0, 4) the new convexity measure is invariant under similarity transformations, and 5) there is a simple and fast procedure for computing the new convexity measure.	Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England; Serbian Acad Arts & Sci, Math Inst, Belgrade, Serbia; Cardiff Univ, Dept Comp Sci, Queens Bldg,Newport Rd,POB 916, Cardiff CF24 3XF, S Glam, Wales	University of Exeter; Serbian Academy of Sciences & Arts; Cardiff University	Zunic, J (corresponding author), Univ Exeter, Dept Comp Sci, Harrison Bldg,N Pk Rd, Exeter EX4 4QF, Devon, England.	J.Zunic@ex.ac.uk; Paul.Rosin@cs.cf.ac.uk		Rosin, Paul/0000-0002-4965-3884	Biotechnology and Biological Sciences Research Council [754/BIO14262] Funding Source: Medline	Biotechnology and Biological Sciences Research Council(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC))		ACKETA DM, 1995, J COMB THEORY A, V69, P358, DOI 10.1016/0097-3165(95)90058-6; [Anonymous], 2001, SHAPE ANAL CLASSIFIC; Bookstein F. L., 1991, MORPHOMETRIC TOOLS L; BOXER L, 1993, PATTERN RECOGN LETT, V14, P163, DOI 10.1016/0167-8655(93)90067-N; Du Buf J.M.H., 2002, AUTOMATIC DIATOM IDE; Fischer S., 2002, AUTOMATIC DIATOM IDE, P109; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; FREEMAN H, 1975, COMMUN ACM, V18, P409, DOI 10.1145/360881.360919; Hawkins A. E., 1993, SHAPE POWDER PARTICL; Hyde S., 1997, LANGUAGE SHAPE; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738; MARTIN RR, 1988, COMPUT AIDED DESIGN, V20, P506, DOI 10.1016/0010-4485(88)90040-1; Murthy SK, 1994, J ARTIF INTELL RES, V2, P1, DOI 10.1613/jair.63; PITTY AF, 1988, GEOMORPHOLOGY; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; Rosin PL, 2003, MACH VISION APPL, V14, P172, DOI 10.1007/s00138-002-0118-6; Rosin PL, 2000, IEEE T SYST MAN CY A, V30, P202, DOI 10.1109/3468.833102; Sonka M., 1993, IMAGE PROCESSING ANA, DOI DOI 10.1007/978-1-4899-3216-7_4; STERN HI, 1989, PATTERN RECOGN LETT, V10, P229, DOI 10.1016/0167-8655(89)90093-7; Toussaint G.T., 1983, P IEEE MED EL C MELE, V83; WEST W, 2004, MONOGRAPH BRIT DESMI	23	98	102	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					923	934		10.1109/TPAMI.2004.19	http://dx.doi.org/10.1109/TPAMI.2004.19			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579950	Green Submitted			2022-12-18	WOS:000221323900009
J	Zhang, B; Srihari, SN				Zhang, B; Srihari, SN			Fast k-nearest neighbor classification using cluster-based trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor classification; nonmetrics; metrics; cluster tree	ALGORITHM; SEARCH	Most fast k-nearest neighbor (k-NN) algorithms exploit metric properties of distance measures for reducing computation cost and a few can work effectively on both metric and nonmetric measures. We propose a cluster-based tree algorithm to accelerate k-NN classification without any presuppositions about the metric form and properties of a dissimilarity measure. A mechanism of early decision making and minimal side-operations for choosing searching paths largely contribute to the efficiency of the algorithm. The algorithm is evaluated through extensive experiments over standard NIST and MNIST databases.	Univ Calif Los Angeles, Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Biostat, Los Angeles, CA 90095 USA; SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Amherst, NY 14228 USA	University of California System; University of California Los Angeles; University of California Los Angeles Medical Center; David Geffen School of Medicine at UCLA; University of California System; University of California Los Angeles; University of California Los Angeles Medical Center; David Geffen School of Medicine at UCLA; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Zhang, B (corresponding author), Univ Calif Los Angeles, Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA.	binzhang@mednet.ucla.edu; srihari@cedar.buffalo.edu	Srihari, Sargur N/E-8100-2011					BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179, DOI 10.1109/T-C.1974.223827; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hunttenlocher D., 1997, IEEE T PATTERN ANAL, V19, P1; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761, DOI 10.1109/TPAMI.1986.4767859; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Puzicha J., 1999, P IEEE INT C COMP VI, P1165, DOI DOI 10.1109/ICCV.1999.790412; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, P145, DOI 10.1016/0167-8655(86)90013-9; Zhang B, 2003, P JCIS INT C COMP VI	23	98	112	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					525	528		10.1109/TPAMI.2004.1265868	http://dx.doi.org/10.1109/TPAMI.2004.1265868			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382657				2022-12-18	WOS:000220102800009
J	Caspi, Y; Irani, M				Caspi, Y; Irani, M			Spatio-temporal alignment of sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sequence-to-sequence alignment; space-time analysis; direct methods; feature-based methods	MOTION; RECOVERY; IMAGES	This paper studies the problem of sequence-to-sequence alignment, namely, establishing correspondences in time and in space between two different video sequences of the same dynamic scene. The sequences are recorded by uncalibrated video cameras which are either stationary or jointly moving, with fixed (but unknown) internal parameters and relative intercamera external parameters. Temporal variations between image frames (such as moving objects or changes in scene illumination) are powerful cues for alignment, which cannot be exploited by standard image-to-image alignment techniques. We show that, by folding spatial and temporal cues into a single alignment framework, situations which are inherently ambiguous for traditional image-to-image alignment methods, are often uniquely resolved by sequence-to-sequence alignment. Furthermore, the ability to align and integrate information across multiple video sequences both in time and in space gives rise to new video applications that are not possible when only image-to-image alignment is used.	Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Caspi, Y (corresponding author), Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel.							BAKER S, 2001, P IEEE C COMP VIS PA; Baker S, 2001, CMURITR0103; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, P EUR C COMP VIS, P237; Birchfield S, 1996, KLT IMPLEMENTATION K; BURT PJ, 1993, P 4 INT C COMP VIS B, P173, DOI DOI 10.1109/ICCV.1993.378222; Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940; CASPI Y, 2001, P 8 INT C COMP VIS V, V2, P76; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Giese MA, 2000, INT J COMPUT VISION, V38, P59, DOI 10.1023/A:1008118801668; GIESE MA, 1999, GOETTINGEN NEUROBIOL; Hampel FR., 2011, WILEY SERIES PROBABI; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; IRANI M, 1992, P EUR C COMP VIS, P282; Irani Michal, 1999, P INT WORKSH VIS ALG, P267, DOI DOI 10.1007/3-540-44480-7-18; Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Sawhney HS, 1997, PROC CVPR IEEE, P450, DOI 10.1109/CVPR.1997.609364; SHECHTMAN E, 2002, P EUR C COMP VIS; STEIN GP, 1998, P DARPA IU WORKSH, P1037; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Syeda-Mahmood T., 2001, P IEEE WORKSH DET RE; SZELISKI R, 1997, P COMP GRAPH ANN C S, V8, P251; Tomasi C, 1991, CMUCS91132; TORR PHS, 1999, P VIS ALG WORKSH, P279; XU C, 1996, EPIPOLAR GEOMETRY ST; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; ZOGHLAMI I, 1997, IEEE C COMP VIS PATT, P420	34	98	114	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1409	1424		10.1109/TPAMI.2002.1046148	http://dx.doi.org/10.1109/TPAMI.2002.1046148			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY		Green Submitted			2022-12-18	WOS:000178846400001
J	Leitao, HCD; Stolfi, J				Leitao, HCD; Stolfi, J			A multiscale method for the reassembly of two-dimensional fragmented objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						outline matching; planar shape matching; multiscale analysis; planar shape invariants; ceramic fragments; archaeology; fracture analysis	SOLVING JIGSAW PUZZLES; SURFACE	We describe here an efficient procedure for reassembling unknown two-dimensional objects that have been broken or torn into a large number of irregular fragments-a problem that often arises in archaeology, art restoration, forensics, and other disciplines. The procedure compares the curvature-encoded fragment outlines, at progressively increasing scales of resolution, using an incremental dynamic programming sequence-matching algorithm. The total cost gets reduced by a factor proportional to the mean number of samples per segment, which makes the method viable for problems of practical size (thousands of fragments). The performance of our method is illustrated with an artificial but realistic example.	Univ Fed Fluminense, Inst Comp, BR-24210240 Rio De Janeiro, Brazil; Univ Estadual Campinas, Inst Comp, BR-13084971 Sao Paulo, Brazil	Universidade Federal Fluminense; Universidade Estadual de Campinas	Leitao, HCD (corresponding author), Univ Fed Fluminense, Inst Comp, BR-24210240 Rio De Janeiro, Brazil.	hcgl@ic.uff.br; stolfi@ic.unicamp.br	Stolfi, Jorge/B-3304-2012					[Anonymous], 1997, INTRO COMPUTATIONAL; Barequet G, 1997, IEEE T PATTERN ANAL, V19, P929, DOI 10.1109/34.615444; BOUSSOFIANE F, 1993, IEEE T PATTENR ANAL, V15, P445; Bunke H., 1993, Computer Analysis of Images and Patterns. 5th International Conference, CAIP '93 Proceedings, P299; BUNKE H, 1993, PATTERN RECOGN, V26, P1797, DOI 10.1016/0031-3203(93)90177-X; BURDEA GC, 1989, IEEE T ROBOTIC AUTOM, V5, P752, DOI 10.1109/70.88097; Hal?r R., 1997, P CZECH PATT REC WOR, P126; Hori K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P440, DOI 10.1109/CVPR.1999.784718; Hori K., 2000, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ83D-II, P1392; HORI K, 2000, J COMPUTER ARCHAEOLO, V5, P1; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; Kalvin AD, 1996, IEEE VISUAL, P359, DOI 10.1109/VISUAL.1996.568132; Legault R, 1997, IEEE T PATTERN ANAL, V19, P801, DOI 10.1109/34.608276; LEITAO HCG, 2000, P WSCG 2000 8 INT C, V2, P389; LEITAO HCG, 1998, IC9806 U CAMP I COMP; LEITAO HCG, 1999, THESIS U CAMPINAS; LEITAO HCG, 2001, IC0104 U CAMP I COMP; LEUTWYLER K, 2002, SOLVING DITITAL JIGS; LEVOY M, 1999, SCANNIGN FRAGMENTS F; MENARD C, 1997, P 21 WORKSH AUSTR AS, P203; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387; Papaionnou G, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.909015; PEARSON WR, 1992, METHOD ENZYMOL, V210, P575; POPE A, 1994, TR9404 U CAL BERK; RADACK GM, 1989, COMPUT VISION GRAPH, V45, P380, DOI 10.1016/0734-189X(89)90090-X; ROSIN P, 1993, PATTERN RECOGN, V26, P1383, DOI 10.1016/0031-3203(93)90144-L; SMITH RW, 1970, NATL GEOGRAPHIC MAGA, V138, P644; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Ucoluk G, 1999, COMPUT GRAPH-UK, V23, P573, DOI 10.1016/S0097-8493(99)00075-8; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WEBSTER RW, 1991, IEEE T SYST MAN CYB, V21, P1271, DOI 10.1109/21.120080; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108	34	98	114	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1239	1251		10.1109/TPAMI.2002.1033215	http://dx.doi.org/10.1109/TPAMI.2002.1033215			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW					2022-12-18	WOS:000177640500007
J	Arica, N; Yarman-Vural, FT				Arica, N; Yarman-Vural, FT			Optical character recognition for cursive handwriting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten word recognition; preprocessing; segmentation; optical character recognition; cursive handwriting; hidden Markov model; search; graph; lexicon matching	WORD RECOGNITION; SEGMENTATION	In this paper, a new analytic scheme, which uses a sequence of segmentation and recognition algorithms, is proposed for offline cursive handwriting recognition problem. First, some global parameters, such as slant angle, baselines, and stroke width and height are estimated. Second, a segmentation method finds character segmentation paths by combining gray scale and binary information. Third, Hidden Markov Model (HMM) is employed for shape recognition to label and rank the character candidates. For this purpose, a string of codes is extracted from each segment to represent the character candidates. The estimation of feature space parameters is embedded in HMM training stage together with the estimation of the HMM model parameters. Finally, the lexicon information and HMM ranks are combined in a graph optimization problem for word-level recognition. This method corrects most of the errors produced by segmentation and HMM ranking stages by maximizing an information measure in an efficient graph search algorithm. The experiments in dicate higher recognition rates compared to the available methods reported in the literature.	Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey	Middle East Technical University	Arica, N (corresponding author), Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey.	nafiz@ceng.metu.edu.tr; vural@ceng.metu.edu.tr	yarman, fatos/AAP-5605-2021; Arica, Nafiz/ADD-3793-2022	ARICA, NAFIZ/0000-0002-3810-5866				Arica N, 2000, PATTERN RECOGN LETT, V21, P583, DOI 10.1016/S0167-8655(00)00023-4; Arica N, 1998, INT C PATT RECOG, P1127, DOI 10.1109/ICPR.1998.711893; Atici AA, 1997, SIGNAL PROCESS, V62, P87, DOI 10.1016/S0165-1684(97)00117-5; Caesar T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P382, DOI 10.1109/ICDAR.1995.599018; Casey R. G., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1028, DOI 10.1109/ICDAR.1995.602078; Dengel A., 1997, HDB CHARACTER RECOGN, P227; Gopisetty S, 1996, IBM J RES DEV, V40, P211, DOI 10.1147/rd.402.0211; Gorski N., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P523, DOI 10.1109/ICDAR.1999.791840; Guillevic D, 1998, PATTERN ANAL APPL, V1, P28, DOI 10.1007/BF01238024; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Kim U., 1999, ASIAN J SOC PSYCHOL, V2, P1, DOI [10.1111/1467-839X.00023, DOI 10.1111/1467-839X.00023]; Kornai A., 1996, P 5 INT WORKSH FRONT, P373; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P1045, DOI 10.1109/34.541415; Madhvanath S, 1999, IEEE T PATTERN ANAL, V21, P928, DOI 10.1109/34.790433; Mao JC, 1998, INT C PATT RECOG, P1285, DOI 10.1109/ICPR.1998.711936; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; Shridhar M, 1997, PROC INT CONF DOC, P861, DOI 10.1109/ICDAR.1997.620634; Srihari SN, 1997, PROC INT CONF DOC, P892, DOI 10.1109/ICDAR.1997.620640; Srihari SN, 1996, P IEEE, V84, P1038, DOI 10.1109/5.503302; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; WANG J, 1994, PATTERN RECOGN, V27, P649, DOI 10.1016/0031-3203(94)90044-2	23	98	112	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					801	813		10.1109/TPAMI.2002.1008386	http://dx.doi.org/10.1109/TPAMI.2002.1008386			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300008
J	Marshall, D; Lukacs, G; Martin, R				Marshall, D; Lukacs, G; Martin, R			Robust segmentation of primitives from range data in the presence of geometric degeneracy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonlinear least squares; geometric distance; cylinder; cone; sphere; torus; surface fitting; segmentation	ELLIPSES; RECONSTRUCTION; SURFACES; CURVES; MODELS	This paper addresses a common problem in the segmentation of range images. We would like to identify and fit surfaces of known type wherever these are a good fit. This paper presents methods for the least-squares fitting of spheres, cylinders, cones, and tori to 3D point data, and their application within a segmentation framework. Least-squares fitting of surfaces other than planes, even of simple geometric type, has been rarely studied. Our main application areas of this research are reverse engineering of solid models from depth-maps and automated 3D inspection where reliable extraction of these surfaces is essential. Our fitting method has the particular advantage of being robust in the presence of geometric degeneracy, i.e.. as the principal curvatures of the surfaces being fitted decrease (or become more equal), the results returned naturally become closer and closer to those surfaces of "simpler type." i.e., planes, cylinders, cones, or spheres, which best describe the data. Many other methods diverge because, in such cases, various parameters or their combination become infinite.	Cardiff Univ, Dept Comp Sci, Cardiff CF24 3XF, S Glam, Wales; Hungarian Acad Sci, Comp & Automat Res Inst, H-1518 Budapest, Hungary	Cardiff University; Eotvos Lorand Research Network; Hungarian Academy of Sciences; Hungarian Institute for Computer Science & Control	Marshall, D (corresponding author), Cardiff Univ, Dept Comp Sci, POB 916, Cardiff CF24 3XF, S Glam, Wales.	dave@cs.cf.ac.uk; lukacs@sztaki.hu; ralph@cs.cf.ac.uk	Martin, Ralph R/D-2366-2010					Acot Pascal, 1998, EUROPEAN ORIGINS SCI, P671; BAJCSY R, 1990, ANAL INTERPRETATION; BENKO P, 1999, P ADV WORKSH CONFL C; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1988, SURFACES RANGE IMAGE; Bjork, 1996, NUMERICAL METHODS LE, DOI 10.1137/1.9781611971484; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; Clark J, 1997, IMAGE VISION COMPUT, V15, P107, DOI 10.1016/S0262-8856(96)01126-2; Faugeras O. D., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P8; FITZGIBBON AW, 1996, P 13 INT C PATT REC; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Hebert M., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P836; JAKLIC A, 1996, LRV962 U LJUBLJ COMP; Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; LEONARDIS A, 1993, THESIS U LJUBLJANA; LIONG P, 1990, COMPUTER VISION GRAP, V52, P78; LUKACS G, 1997, 2 RECCAD GEOM MOD LA; LUKACS G, 1997, 3 RECCAD GEOM MOD LA; Pottmann H, 1998, COMPUTING, V60, P307, DOI 10.1007/BF02684378; PRATT V, 1987, ACM SIGGRAPH, V21, P145; Rosin PL, 1996, PATTERN RECOGN LETT, V17, P1461, DOI 10.1016/S0167-8655(96)00102-X; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Thompson WB, 1999, IEEE T ROBOTIC AUTOM, V15, P57, DOI 10.1109/70.744602; Trucco E, 1998, INT J COMPUT INTEG M, V11, P293, DOI 10.1080/095119298130642; Varady T, 1997, COMPUT AIDED DESIGN, V29, P255, DOI 10.1016/S0010-4485(96)00054-1; Werghi N, 1999, COMPUT AIDED DESIGN, V31, P363, DOI 10.1016/S0010-4485(99)00038-X; WERGHI N, 1999, P 2 INT C 3D DIG IM, P45; WERGHI N, 1997, P BRIT MACH VIS C BM, P520; WERGHI N, 1998, IEEE INT WORKSH MOD, P45; WERGHI N, 1998, P 5 EUR C COMP VIS F, V2, P185	34	98	113	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					304	314		10.1109/34.910883	http://dx.doi.org/10.1109/34.910883			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW					2022-12-18	WOS:000167276200007
J	Lee, SW				Lee, SW			Off-line recognition of totally unconstrained handwritten numerals using multilayer cluster neural network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						totally unconstrained handwritten numeral recognition; multilayer cluster neural network; genetic algorithm		In this paper, we propose a new scheme for off-line recognition of totally unconstrained handwritten numerals using a simple multilayer cluster neural network trained with the back propagation algorithm and show that the use of genetic algorithms avoids the problem of finding local minima in training the multilayer cluster neural network with gradient descent technique, and improves the recognition rates. In the proposed scheme, Kirsch masks are adopted for extracting feature vectors and a three-layer duster neural network with five independent subnetworks is developed for classifying similar numerals efficiently. In order to verify the performance of the proposed multilayer duster neural network, experiments with handwritten numeral database of Concordia University of Canada, that of Electro-Technical Laboratory of Japan, and that of Electronics and Telecommunications Research Institute of Korea were performed. For the case of determining the initial weights using a genetic algorithm, 97.10%, 99.12%, and 99.40% correct recognition rates were obtained, respectively.			Lee, SW (corresponding author), KOREA UNIV,DEPT COMP SCI & ENGN,1,5-KA,ANAM DONG,SEONGBUK KU,SEOUL 136701,SOUTH KOREA.		Lee, Seong-Whan/C-7928-2012					AHMED P, 1987, INT J PATTERN RECOGN, V1, P1; BEUN M, 1973, PHILIPS TECH REV, V33, P89; BEUN M, 1973, PHILIPS TECH REV, V33, P130; Cohen E., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P221, DOI 10.1142/S0218001491000156; DUERR B, 1980, PATTERN RECOGN, V12, P189, DOI 10.1016/0031-3203(80)90043-6; GADER PD, 1990, P US POST SERV ADV T, P539; KIM YJ, 1995, P 3 INT C DOC AN REC, P715; KNERR S, 1992, IEEE T NEURAL NETWOR, V3, P962, DOI 10.1109/72.165597; KRZYZAK A, 1990, P 1 INT WORKSH FRONT, P155; KUAN CL, 1988, P US POSTAL SERVICE, P1033; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; LECUN Y, 1990, P INT WORKSHOP FRONT, P145; Lee D.-S., 1993, P 3 INT WORKSH FRONT, P153; LEGAULT R, 1989, COMPUTER VISION SHAP, P225; Lemarie B., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P412, DOI 10.1109/ICDAR.1993.395705; MAI TA, 1990, IEEE T SYST MAN CYB, V20, P835, DOI 10.1109/21.105083; Mitchell B. T., 1989, Machine Vision and Applications, V2, P231, DOI 10.1007/BF01215877; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; STRINGA L, 1990, IEEE T PATTERN ANAL, V12, P1210, DOI 10.1109/34.62612; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; SUEN CY, 1990, APR P INT WORKSH FRO, P131; [No title captured]	24	98	107	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					648	652		10.1109/34.506416	http://dx.doi.org/10.1109/34.506416			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400009
J	WENG, JY; AHUJA, N; HUANG, TS				WENG, JY; AHUJA, N; HUANG, TS			MATCHING 2 PERSPECTIVE VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DYNAMIC SCENE ANALYSIS; MOTION ESTIMATION; OPTICAL FLOW; STEREO MATCHING; STRUCTURE FROM MOTION; 2-VIEW MATCHING	APPARENT MOTION; ERROR ANALYSIS; OPTICAL-FLOW; STEREO; SEQUENCES	Establishing correspondences between different perspective images of the same scene is one of the most challenging and critical steps in motion and scene analysis. Part of the difficulty is due to a wide variety of 3-D structural discontinuities and occlusions that occur in real-world scenes. This paper describes a computational approach to image matching that uses multiple attributes associated with each image point to yield a generally overdetermined system of constraints, taking into account possible structural discontinuities and occlusions. In the algorithm implemented, intensity, edgeness, and cornerness attributes are used in conjunction with the constraints arising from intraregional smoothness, field continuity and discontinuity, and occlusions to compute dense displacement fields and occlusion maps along the pixel grids. The intensity, edgeness, and cornerness are invariant under rigid motion in the image plane. In order to cope with large disparities, a multiresolution multigrid structure is employed. Coarser level edgeness and cornerness measures are obtained by blurring the finer level measures. The algorithm has been tested on real-world scenes with depth discontinuities and occlusions. A special case of two-view matching is stereo matching, where the motion between two images is known. The algorithm can be easily specialized to perform stereo matching using the epipolar constraint.	ECOLE POLYTECH, MONTREAL H3C 3A7, QUEBEC, CANADA; CTR RECH INFORMAT, MONTREAL, QUEBEC, CANADA; UNIV ILLINOIS, DEPT ELECT & COMP ENGN, URBANA, IL 61801 USA; UNIV ILLINOIS, COORDINATED SCI LAB, URBANA, IL 61801 USA	Universite de Montreal; Polytechnique Montreal; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	WENG, JY (corresponding author), UNIV ILLINOIS, BECKMAN INST, URBANA, IL 61801 USA.							ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ANANDAN P, 1985, P IEEE WORKSHOP COMP, P186; AYACHE N, 1987, 1ST P INT C COMP VIS, P73; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARNARD TB, 1986, 5TH P NAT C ART INT, P676; Born M., 1975, PRINCIPLES OPTICS, VFifth; BRADDICK O, 1974, VISION RES, V14, P519, DOI 10.1016/0042-6989(74)90041-8; BRADDICK OJ, 1980, PHILOS T ROY SOC B, V290, P137, DOI 10.1098/rstb.1980.0087; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; Glazer F., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P432; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GU WK, 1987, IEEE T PATTERN ANAL, V9, P390, DOI 10.1109/TPAMI.1987.4767921; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HILDRETH E, 1983, MEASUREMENT VISUAL M; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Kingslake R., 1978, LENS DESIGN FUNDAMEN; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; LIM HS, 1987, P IMAGE UNDERSTANDIN; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MORAVEC HP, 1980, 340 STANF ART INT LA; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; QUAM L, 1984, P IMAGE UNDERSTANDIN, P149; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VERRI A, 1987, 1ST P INT C COMP VIS, P171; Waxman A. M., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P49; WENG J, 1989, MAR P IEEE WORKSH VI, P359; WENG J, 1989, JUN P IEEE C COMP VI, P144; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Zuniga O. A., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P30	33	98	109	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1992	14	8					806	825		10.1109/34.149592	http://dx.doi.org/10.1109/34.149592			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JG613					2022-12-18	WOS:A1992JG61300002
J	Bao, WB; Lai, WS; Zhang, XY; Gao, ZY; Yang, MH				Bao, Wenbo; Lai, Wei-Sheng; Zhang, Xiaoyun; Gao, Zhiyong; Yang, Ming-Hsuan			MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interpolation; Kernel; Estimation; Motion estimation; Adaptation models; Optical imaging; Motion compensation; Motion estimation; motion compensation; convolutional neural network; adaptive warping	FRAME RATE; OPTICAL-FLOW; ALGORITHM	Motion estimation (ME) and motion compensation (MC) have been widely used for classical video frame interpolation systems over the past decades. Recently, a number of data-driven frame interpolation methods based on convolutional neural networks have been proposed. However, existing learning based methods typically estimate either flow or compensation kernels, thereby limiting performance on both computational efficiency and interpolation accuracy. In this work, we propose a motion estimation and compensation driven neural network for video frame interpolation. A novel adaptive warping layer is developed to integrate both optical flow and interpolation kernels to synthesize target frame pixels. This layer is fully differentiable such that both the flow and kernel estimation networks can be optimized jointly. The proposed model benefits from the advantages of motion estimation and compensation methods without using hand-crafted features. Compared to existing methods, our approach is computationally efficient and able to generate more visually appealing results. Furthermore, the proposed MEMC-Net architecture can be seamlessly adapted to several video enhancement tasks, e.g., super-resolution, denoising, and deblocking. Extensive quantitative and qualitative evaluations demonstrate that the proposed method performs favorably against the state-of-the-art video frame interpolation and enhancement algorithms on a wide range of datasets.	[Bao, Wenbo; Zhang, Xiaoyun; Gao, Zhiyong] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China; [Lai, Wei-Sheng; Yang, Ming-Hsuan] Univ Calif Merced, Dept Elect Engn & Comp Sci, Merced, CA 95340 USA	Shanghai Jiao Tong University; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif Merced, Dept Elect Engn & Comp Sci, Merced, CA 95340 USA.	baowenbo@sjtu.edu.cn; wlai24@ucmerced.edu; xiaoyun.zhang@sjtu.edu.cn; zhiyong.gao@sjtu.edu.cn; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304	National Natural Science Foundation of China [61771306]; Natural Science Foundation of Shanghai [18ZR1418100]; Chinese National Key S&T Special Program [2013ZX01033001-002-002]; Shanghai Key Laboratory of Digital Media Processing and Transmissions [STCSM 18DZ2270700]; NSF Career Grant [1149783]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Shanghai(Natural Science Foundation of Shanghai); Chinese National Key S&T Special Program; Shanghai Key Laboratory of Digital Media Processing and Transmissions; NSF Career Grant(National Science Foundation (NSF)NSF - Office of the Director (OD))	W. Bao, X. Zhang, and Z. Gao are supported in part by the National Natural Science Foundation of China (61771306), the Natural Science Foundation of Shanghai (18ZR1418100), the ChineseNational Key S&T Special Program(2013ZX01033001-002-002), and the Shanghai Key Laboratory of Digital Media Processing and Transmissions (STCSM 18DZ2270700). W.-S. Lai andM.-H. Yang are supported in part by NSF Career Grant (1149783) and gifts fromAdobe, Google, and NEC.	Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Bao WB, 2018, IEEE T IMAGE PROCESS, V27, P3813, DOI 10.1109/TIP.2018.2825100; Biswas M, 2010, IEEE IMAGE PROC, P785, DOI 10.1109/ICIP.2010.5652571; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Castagno R, 1996, IEEE T CIRC SYST VID, V6, P436, DOI 10.1109/76.538926; CHARBONNIER P, 1994, IEEE IMAGE PROC, P168; Chen ZY, 2013, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2013.316; Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835; de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938; Kaviani HR, 2016, IEEE T CIRC SYST VID, V26, P1581, DOI 10.1109/TCSVT.2015.2469120; Kim US, 2014, IEEE T CIRC SYST VID, V24, P384, DOI 10.1109/TCSVT.2013.2278142; Kingma D.P, P 3 INT C LEARNING R; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; Lai WS, 2017, ADV NEUR IN, V30; Lee WH, 2014, IEEE T IMAGE PROCESS, V23, P399, DOI 10.1109/TIP.2013.2288139; Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614; Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI 10.1109/ICCV.2017.478; Long GC, 2016, LECT NOTES COMPUT SC, V9910, P434, DOI 10.1007/978-3-319-46466-4_26; Maas A. L., 2013, P 30 INT C MACH LEAR, P3; Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324; Mathieu Michael, 2016, ICLR; Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747; Nair V., 2010, ICML, P807; NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087; Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183; Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37; Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244; ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Soomro K., 2012, ARXIV; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; van Amersfoort J., 2017, ARXIV171106045; Wang C, 2010, IEEE T CIRC SYST VID, V20, P886, DOI 10.1109/TCSVT.2010.2046057; Wang DM, 2010, IEEE T BROADCAST, V56, P142, DOI 10.1109/TBC.2010.2043895; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165; Wu JY, 2016, IEEE T WIREL COMMUN, V15, P2713, DOI 10.1109/TWC.2015.2509063; Wu JY, 2015, IEEE T CIRC SYST VID, V25, P1988, DOI 10.1109/TCSVT.2015.2441412; Xu J, 2017, PROC CVPR IEEE, P5807, DOI 10.1109/CVPR.2017.615; Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2; Zhai JF, 2005, IEEE INT SYMP CIRC S, P4927; Zhang YB, 2007, IEEE IMAGE PROC, P441; Zhang YB, 2009, IEEE T CIRC SYST VID, V19, P1289, DOI 10.1109/TCSVT.2009.2022798; Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744	59	97	98	7	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					933	948		10.1109/TPAMI.2019.2941941	http://dx.doi.org/10.1109/TPAMI.2019.2941941			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31722471	Green Submitted			2022-12-18	WOS:000616309900013
J	Monfort, M; Andonian, A; Zhou, BL; Ramakrishnan, K; Bargal, SA; Yan, T; Brown, L; Fan, QF; Gutfruend, D; Vondrick, C; Oliva, A				Monfort, Mathew; Andonian, Alex; Zhou, Bolei; Ramakrishnan, Kandan; Bargal, Sarah Adel; Yan, Tom; Brown, Lisa; Fan, Quanfu; Gutfruend, Dan; Vondrick, Carl; Oliva, Aude			Moments in Time Dataset: One Million Videos for Event Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Visualization; Feature extraction; Vocabulary; Animals; Three-dimensional displays; Convolution; Video dataset; action recognition; event recognition		We present the Moments in Time Dataset, a large-scale human-annotated collection of one million short videos corresponding to dynamic events unfolding within three seconds. Modeling the spatial-audio-temporal dynamics even for actions occurring in 3 second videos poses many challenges: meaningful events do not include only people, but also objects, animals, and natural phenomena; visual and auditory events can be symmetrical in time ("opening" is "closing" in reverse), and either transient or sustained. We describe the annotation process of our dataset (each video is tagged with one action or activity label among 339 different classes), analyze its scale and diversity in comparison to other large-scale video datasets for action recognition, and report results of several baseline models addressing separately, and jointly, three modalities: spatial, temporal and auditory. The Moments in Time dataset, designed to have a large coverage and diversity of events in both visual and auditory modalities, can serve as a new challenge to develop models that scale to the level of complexity and abstract reasoning that a human processes on a daily basis.	[Monfort, Mathew; Andonian, Alex; Ramakrishnan, Kandan; Yan, Tom; Oliva, Aude] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Zhou, Bolei] Chinese Univ Hong Kong, Hong Kong, Peoples R China; [Bargal, Sarah Adel] Boston Univ, 111 Cummington Mall, Boston, MA 02215 USA; [Brown, Lisa; Fan, Quanfu; Gutfruend, Dan] IBM Res, Armonk, NY 10504 USA; [Brown, Lisa; Fan, Quanfu; Gutfruend, Dan] MIT, IBM Watson Lab, 75 Binney St, Cambridge, MA 02142 USA; [Vondrick, Carl] Columbia Univ, 530 West 120th St, New York, NY 10027 USA	Massachusetts Institute of Technology (MIT); Chinese University of Hong Kong; Boston University; International Business Machines (IBM); Massachusetts Institute of Technology (MIT); Columbia University	Zhou, BL (corresponding author), Chinese Univ Hong Kong, Hong Kong, Peoples R China.	mmonfort@mit.edu; aandonia@mit.edu; bzhou@ie.cuhk.edu.hk; krama@mit.edu; sbargal@bu.edu; tom.yan.555@gmail.com; lisabr@us.ibm.com; qfan@us.ibm.com; dgutfre@us.ibm.com; cvondrick@gmail.com; oliva@mit.edu		Bargal, Sarah/0000-0003-3157-0412	MIT-IBM Watson AI Lab; Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) [D17PC00341]; Toyota Research Institute/MIT CSAIL Joint Research Center	MIT-IBM Watson AI Lab(International Business Machines (IBM)); Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC); Toyota Research Institute/MIT CSAIL Joint Research Center	This work was supported by the MIT-IBM Watson AI Lab, the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract number D17PC00341 and the Toyota Research Institute/MIT CSAIL Joint Research Center.	Abu-El-Haija S., 2016, ARXIV; [Anonymous], 2017, ARXIV170508421; [Anonymous], [No title captured]; [Anonymous], 2006, P HUM LANG TECHN C N; [Anonymous], 2016, ARXIV PREPRINT ARXIV; [Anonymous], 2003, P TREEB LEX THEOR; Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73; Aytar Y, 2016, P 30 INT C NEUR INF, P892; Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014; Baker Collin F., 1998, P 36 ANN M ASS COMP, P86, DOI DOI 10.3115/980845.980860; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Davies M, 2016, CORPUS CONT AM ENGLI; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Fouhey D.F., 2017, ARXIV171202310; Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261; Goyal R., 2017, ARXIV170604261; Gygli M, 2016, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2016.114; He K., 2015, CORR; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Itseez, 2015, OP SOURC COMP VIS LI; Jiang Y.-G., 2014, ECCV WORKSH; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Piczak KJ, 2015, IEEE INT WORKS MACH; Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Schuler Karin Kipper, 2005, THESIS; Simonyan K, 2014, ADV NEUR IN, V27; Soomro K., 2012, CRCVTR1201; Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang Y, 2018, PROC CVPR IEEE, P7044, DOI 10.1109/CVPR.2018.00736; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou MM, 2014, INTERNATIONAL CONFERENCE ON EDUCATION AND SOCIAL SCIENCES (INTCESS14), VOLS I AND II, P487	49	97	99	7	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					502	508		10.1109/TPAMI.2019.2901464	http://dx.doi.org/10.1109/TPAMI.2019.2901464			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30802849	Green Submitted			2022-12-18	WOS:000508386100020
J	Yong, HW; Meng, DY; Zuo, WM; Zhang, L				Yong, Hongwei; Meng, Deyu; Zuo, Wangmeng; Zhang, Lei			Robust Online Matrix Factorization for Dynamic Background Subtraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Backgroun0d subtraction; mixture of Gaussians; low-rank matrix factorization; subspace learning; online learning	IMAGE; APPROXIMATION; SEGMENTATION; ALGORITHM; TRACKING	We propose an effective online background subtraction method, which can be robustly applied to practical videos that have variations in both foreground and background. Different from previous methods which often model the foreground as Gaussian or Laplacian distributions, we model the foreground for each frame with a specific mixture of Gaussians (MoG) distribution, which is updated online frame by frame. Particularly, our MoG model in each frame is regularized by the learned foreground/background knowledge in previous frames. This makes our online MoG model highly robust, stable and adaptive to practical foreground and background variations. The proposed model can be formulated as a concise probabilistic MAP model, which can be readily solved by EM algorithm. We further embed an affine transformation operator into the proposed model, which can be automatically adjusted to fit a wide range of video background transformations and make the method more robust to camera movements. With using the sub-sampling technique, the proposed method can be accelerated to execute more than 250 frames per second on average, meeting the requirement of real-time background subtraction for practical video processing tasks. The superiority of the proposed method is substantiated by extensive experiments implemented on synthetic and real videos, as compared with state-of-the-art online and offline background subtraction methods.	[Yong, Hongwei] Xi An Jiao Tong Univ, Sch Math, Xian 710049, Shaanxi, Peoples R China; [Yong, Hongwei; Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China	Xi'an Jiaotong University; Hong Kong Polytechnic University; Xi'an Jiaotong University; Xi'an Jiaotong University; Harbin Institute of Technology	Meng, DY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.; Meng, DY (corresponding author), Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China.	yonghw@stu.xjtu.edu.cn; dymeng@mail.xjtu.edu.cn; cswmzuo@gmail.com; cslzhang@comp.polyu.edu.hk	Zuo, Wangmeng/B-3701-2008	Zhang, Lei/0000-0002-2078-4215; Zuo, Wangmeng/0000-0002-3330-783X	China NSFC [61373114, 61661166011, 11690011, 61603292]; HK GRC GRF grant [PolyU 152135/16E]; 973 Program of China [2013CB329404]; Macau Science and Technology Development Funds [003/2016/AFJ]	China NSFC(National Natural Science Foundation of China (NSFC)); HK GRC GRF grant; 973 Program of China(National Basic Research Program of China); Macau Science and Technology Development Funds	This research was supported by China NSFC projects under contracts 61373114, 61661166011, 11690011, 61603292, HK GRC GRF grant (PolyU 152135/16E), 973 Program of China (2013CB329404), and Macau Science and Technology Development Funds (003/2016/AFJ).	Allili MS, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P503, DOI 10.1109/CRV.2007.7; [Anonymous], 2017, PATTERN RECOGN; Beleznai C, 2006, INT C PATT RECOG, P79; Bishop CM, 2006, PATTERN RECOGNITION; Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001; Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009; Braham M, 2016, INT CONF SYST SIGNAL, P113; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262; Cao XY, 2015, IEEE I CONF COMP VIS, P1493, DOI 10.1109/ICCV.2015.175; Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737; Cheung SCS, 2005, EURASIP J APPL SIG P, V2005, P2330, DOI 10.1155/ASP.2005.2330; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Ebadi SE, 2016, IEEE IMAGE PROC, P3972, DOI 10.1109/ICIP.2016.7533105; Ebadi SE, 2015, IEEE IMAGE PROC, P4863, DOI 10.1109/ICIP.2015.7351731; Ehadi SE, 2015, INT CONF SYST SIGNAL, P49, DOI 10.1109/IWSSIP.2015.7314174; Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139; GABRIEL KR, 1979, TECHNOMETRICS, V21, P489, DOI 10.2307/1268288; Haines TSF, 2012, LECT NOTES COMPUT SC, V7575, P99, DOI 10.1007/978-3-642-33765-9_8; He J, 2014, IMAGE VISION COMPUT, V32, P800, DOI 10.1016/j.imavis.2014.02.015; He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848; Huang JZ, 2011, J MACH LEARN RES, V12, P3371; Javed S, 2015, 30TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, VOLS I AND II, P86, DOI 10.1145/2695664.2695863; Javed S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P930, DOI 10.1109/ICCVW.2015.123; Lee B., 2002, IVCNZ 2002, P315; MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814; Meng DY, 2013, IEEE I CONF COMP VIS, P1337, DOI 10.1109/ICCV.2013.169; Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Rodriguez P, 2016, J MATH IMAGING VIS, V55, P1, DOI 10.1007/s10851-015-0610-z; Rodriguez P, 2015, IEEE IMAGE PROC, P537, DOI 10.1109/ICIP.2015.7350856; Rodriguez P, 2014, IEEE IMAGE PROC, P3414, DOI 10.1109/ICIP.2014.7025692; Senior AW, 2011, LECT NOTES COMPUT SC, V6468, P164; Srebro N., 2003, P 20 INT C MACHINE L, P720; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Su TF, 2011, LECT NOTES COMPUT SC, V6494, P535, DOI 10.1007/978-3-642-19318-7_42; Nguyen TM, 2012, IEEE T MED IMAGING, V31, P103, DOI 10.1109/TMI.2011.2165342; Wang J, 2014, PR MACH LEARN RES, V32, P235; Wang NY, 2013, IEEE I CONF COMP VIS, P1785, DOI 10.1109/ICCV.2013.224; Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10; Xu J, 2013, IEEE I CONF COMP VIS, P3376, DOI 10.1109/ICCV.2013.419; Yang S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P641; Zhao Q, 2014, PR MACH LEARN RES, V32, P55; Zheng JY, 2006, TRANSPORT RES REC, P82; Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828; Zhou TB, 2011, INT J NEPHROL, V2011, DOI 10.4061/2011/360357; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132	50	97	103	0	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1726	1740		10.1109/TPAMI.2017.2732350	http://dx.doi.org/10.1109/TPAMI.2017.2732350			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28767363	Green Submitted			2022-12-18	WOS:000434294800014
J	Liu, TL; Tao, DC; Song, ML; Maybank, SJ				Liu, Tongliang; Tao, Dacheng; Song, Mingli; Maybank, Stephen J.			Algorithm-Dependent Generalization Bounds for Multi-Task Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-task learning; learning to learn; inductive bias; regularization; stability; generalization; learning theory	COVERING NUMBERS; STABILITY	Often, tasks are collected for multi-task learning (MTL) because they share similar feature structures. Based on this observation, in this paper, we present novel algorithm-dependent generalization bounds for MTL by exploiting the notion of algorithmic stability. We focus on the performance of one particular task and the average performance over multiple tasks by analyzing the generalization ability of a common parameter that is shared in MTL. When focusing on one particular task, with the help of a mild assumption on the feature structures, we interpret the function of the other tasks as a regularizer that produces a specific inductive bias. The algorithm for learning the common parameter, as well as the predictor, is thereby uniformly stable with respect to the domain of the particular task and has a generalization bound with a fast convergence rate of order O(1/n), where n is the sample size of the particular task. When focusing on the average performance over multiple tasks, we prove that a similar inductive bias exists under certain conditions on the feature structures. Thus, the corresponding algorithm for learning the common parameter is also uniformly stable with respect to the domains of the multiple tasks, and its generalization bound is of the order O(1/T), where T is the number of tasks. These theoretical analyses naturally show that the similarity of feature structures in MTL will lead to specific regularizations for predicting, which enables the learning algorithms to generalize fast and correctly from a few examples.	[Liu, Tongliang; Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, 81 Broadway St, Ultimo, NSW 2007, Australia; [Liu, Tongliang; Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, 81 Broadway St, Ultimo, NSW 2007, Australia; [Song, Mingli] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China; [Maybank, Stephen J.] Univ London, Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England	University of Technology Sydney; University of Technology Sydney; Zhejiang University; University of London; Birkbeck University London	Liu, TL (corresponding author), Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, 81 Broadway St, Ultimo, NSW 2007, Australia.; Liu, TL (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, 81 Broadway St, Ultimo, NSW 2007, Australia.	tliang.liu@gmail.com; dacheng.tao@uts.edu.au; brooksong@ieee.org; sjmaybank@dcs.bbk.ac.uk	Liu, Tongliang/AAA-1506-2021	Liu, Tongliang/0000-0002-9640-6472	Australian Research Council [DP-140102164, FT-130101457]; National Natural Science Foundation of China [61572428, U1509206]	Australian Research Council(Australian Research Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The work was supported in part by Australian Research Council Project DP-140102164, FT-130101457, the National Natural Science Foundation of China under Grant 61572428 and U1509206.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2011, JMLR WORKSHOP C P; Argyriou A., 2007, ADV NEURAL INFORM PR, P25; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Audiffren J., 2013, AS C MACH LEARN ACML, P1; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Bartlett PL, 1997, IEEE T INFORM THEORY, V43, P1721, DOI 10.1109/18.623181; Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Caruana R., 1993, ICML, DOI [DOI 10.1016/B978-1-55860-307-3.50012-5, 10.1016/b978-1-55860-307-3.50012-5]; Chen D, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE OF MANAGEMENT SCIENCE AND INFORMATION SYSTEM, VOLS 1-4, P1375; Chen JH, 2013, IEEE T PATTERN ANAL, V35, P1025, DOI 10.1109/TPAMI.2012.189; Collobert R., 2008, P 25 ICML, V25, P160, DOI DOI 10.1145/1390156.1390177; David ShaiBen, 2003, P 16 ANN C COMP LEAR, V2777, P567; DUDLEY R.M, 1967, J FUNCT ANAL, V1, P290, DOI DOI 10.1016/0022-1236(67)90017-1; Elisseeff A., 2003, NATO SCI SER SUBSER, V190, P111; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Gong PH, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P761, DOI 10.1145/2623330.2623641; Guo Y, 2002, IEEE T INFORM THEORY, V48, P239, DOI 10.1109/18.971752; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Kakade S. M., 2009, P 30 INT C MACH LEAR, P441; Koltchinskii V, 2001, IEEE T INFORM THEORY, V47, P1902, DOI 10.1109/18.930926; Kumar A., 2012, INT C MACH LEARN; Kuzborskij Ilja, 2013, P 30 INT C MACH LEAR, P942; Lin Binbin, 2012, Adv Neural Inf Process Syst, V2012, P296; Liu QH, 2009, IEEE T PATTERN ANAL, V31, P1074, DOI 10.1109/TPAMI.2008.296; Lounici K., 2009, P 22 ANN C LEARN THE, P73; Massart P., 2000, ANN FAC SCI TOULOUSE, V9, P245, DOI DOI 10.5802/afst.961; Maurer A, 2006, J MACH LEARN RES, V7, P117; Maurer A, 2009, MACH LEARN, V75, P327, DOI 10.1007/s10994-009-5109-7; McDiarmid C., 1998, CONCENTRATION, P195, DOI DOI 10.1007/978-3-662-12788-9_6; Micchelli Charles A, 2004, ADV NEURAL INFORM PR, P921; Mohri M., 2018, FDN MACHINE LEARNING; Pillonetto G, 2010, IEEE T PATTERN ANAL, V32, P193, DOI 10.1109/TPAMI.2008.297; Pinelis I., 1994, ANN PROBAB, V22, P1679, DOI [10.1214/aop/1176988477, DOI 10.1214/AOP/1176988477]; Pong TK, 2010, SIAM J OPTIMIZ, V20, P3465, DOI 10.1137/090763184; Pontil M., 2013, PROC ANN C LEARN THE, P55; Rai P., 2010, INT C ART INT STAT, P613; RAKHLIN A., 2012, P INT C MACH LEARN, P1571; Sauer N., 1972, J COMB THEORY A, V13, P145, DOI [10.1016/0097-3165(72)90019-2, DOI 10.1016/0097-3165(72)90019-2]; Shalev-Shwartz S, 2010, J MACH LEARN RES, V11, P2635; Tsianos KI, 2012, ANN ALLERTON CONF, P593, DOI 10.1109/Allerton.2012.6483272; Vapnik V.N., 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1_1; Wang XG, 2009, PROC CVPR IEEE, P142, DOI 10.1109/CVPRW.2009.5206736; Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; Zhang XL, 2015, IEEE T PATTERN ANAL, V37, P28, DOI 10.1109/TPAMI.2014.2343221; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975; Zhou DX, 2003, IEEE T INFORM THEORY, V49, P1743, DOI 10.1109/TIT.2003.813564; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702	54	97	100	1	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					227	241		10.1109/TPAMI.2016.2544314	http://dx.doi.org/10.1109/TPAMI.2016.2544314			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019472	Green Accepted			2022-12-18	WOS:000395553400002
J	Neumann, L; Matas, J				Neumann, Lukas; Matas, Jiri			Real-Time Lexicon-Free Scene Text Localization and Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Text-in-the wild; scene text; end-to-end text recognition; photo OCR	SEGMENTATION	An end-to-end real-time text localization and recognition method is presented. Its real-time performance is achieved by posing the character detection and segmentation problem as an efficient sequential selection from the set of Extremal Regions. The ER detector is robust against blur, low contrast and illumination, color and texture variation. In the first stage, the probability of each ER being a character is estimated using features calculated by a novel algorithm in constant time and only ERs with locally maximal probability are selected for the second stage, where the classification accuracy is improved using computationally more expensive features. A highly efficient clustering algorithm then groups ERs into text lines and an OCR classifier trained on synthetic fonts is exploited to label character regions. The most probable character sequence is selected in the last stage when the context of each character is known. The method was evaluated on three public datasets. On the ICDAR 2013 dataset the method achieves state-of-the-art results in text localization; on the more challenging SVT dataset, the proposed method significantly outperforms the state-of-the-art methods and demonstrates that the proposed pipeline can incorporate additional prior knowledge about the detected text. The proposed method was exploited as the baseline in the ICDAR 2015 Robust Reading competition, where it compares favourably to the state-of-the art.	[Neumann, Lukas] Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Prague, Czech Republic; [Matas, Jiri] Czech Tech Univ, Dept Cybernet, Prague, Czech Republic	Czech Technical University Prague; Czech Technical University Prague	Neumann, L (corresponding author), Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Prague, Czech Republic.	neumalu1@cmp.felk.cvut.cz; matas@cmp.felk.cvut.cz	, Matas/AAW-3282-2020	Neumann, Lukas/0000-0002-9428-3712	Czech Science Foundation [GACR P103/12/G084]; Google PhD Fellowship; Google Research Award	Czech Science Foundation(Grant Agency of the Czech Republic); Google PhD Fellowship(Google Incorporated); Google Research Award(Google Incorporated)	The authors were supported by the Czech Science Foundation Project GACR P103/12/G084. Lukas would also like to acknowledge the support of the Google PhD Fellowship and the Google Research Award.	Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Iwamura M, 2013, PROC INT CONF DOC, P1365, DOI 10.1109/ICDAR.2013.276; Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z; Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514; Karatzas D., 2013, P ICDAR, P1156; Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221; Lee CY, 2014, PROC CVPR IEEE, P4050, DOI 10.1109/CVPR.2014.516; Lee J., 2011, P INT C DOC AN REC 2, V2011, P429, DOI DOI 10.1371/J0URNAL.P0NE.0090352; Liu CL, 2004, PATTERN RECOGN, V37, P265, DOI 10.1016/S0031-3203(03)00224-3; Matas J, 2005, LECT NOTES COMPUT SC, V3540, P541; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Neumann L., 2010, LNCS, P2067; Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Neumann L, 2011, PROC INT CONF DOC, P687, DOI 10.1109/ICDAR.2011.144; Niculescu-Mizil A., 2005, P 21 C UNC ART INT, P413, DOI DOI 10.5555/3020336.3020388; Novikova T, 2012, LECT NOTES COMPUT SC, V7577, P752, DOI 10.1007/978-3-642-33783-3_54; Pratt WK, 2001, DIGITAL IMAGE PROCES; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vojfr T., 2014, REGISTRATION RECOGNI, P113, DOI DOI 10.1007/978-3-642-44907-9_6; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Wang T, 2012, INT C PATT RECOG, P3304; Weinman JJ, 2014, IEEE T PATTERN ANAL, V36, P375, DOI 10.1109/TPAMI.2013.126; Weinman JJ, 2009, IEEE T PATTERN ANAL, V31, P1733, DOI 10.1109/TPAMI.2009.38; Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0; Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515; Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210; Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182; Zhang J., 2010, LNCS, P832	40	97	100	2	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1872	1885		10.1109/TPAMI.2015.2496234	http://dx.doi.org/10.1109/TPAMI.2015.2496234			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26540676				2022-12-18	WOS:000381432700012
J	Li, AN; Lin, M; Wu, Y; Yang, MH; Yan, SC				Li, Annan; Lin, Min; Wu, Yi; Yang, Ming-Hsuan; Yan, Shuicheng			NUS-PRO: A New Visual Tracking Challenge	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; performance evaluation; benchmark database		Numerous approaches on object tracking have been proposed during the past decade with demonstrated success. However, most tracking algorithms are evaluated on limited video sequences and annotations. For thorough performance evaluation, we propose a large-scale database which contains 365 challenging image sequences of pedestrians and rigid objects. The database covers 12 kinds of objects, and most of the sequences are captured from moving cameras. Each sequence is annotated with target location and occlusion level for evaluation. A thorough experimental evaluation of 20 state-of-the-art tracking algorithms is presented with detailed analysis using different metrics. The database is publicly available and evaluation can be carried out online for fair assessments of visual tracking algorithms.	[Li, Annan] Agcy Sci Technol & Res, Inst Infocomm Res, Singapore, Singapore; [Lin, Min; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore; [Wu, Yi] Nanjing Univ Informat Sci & Technol, Sch Informat & Control Engn, Nanjing 210044, Jiangsu, Peoples R China; [Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA 95344 USA	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); National University of Singapore; Nanjing University of Information Science & Technology; University of California System; University of California Merced	Li, AN (corresponding author), Agcy Sci Technol & Res, Inst Infocomm Res, Singapore, Singapore.; Lin, M; Yan, SC (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.; Wu, Y (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Informat & Control Engn, Nanjing 210044, Jiangsu, Peoples R China.; Yang, MH (corresponding author), Univ Calif, Sch Engn, Merced, CA 95344 USA.	lia@i2r.a-star.edu.sg; linmin@nus.edu.sg; ywu.china@gmail.com; mhyang@ucmerced.edu; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022; Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; 	National Natural Science Foundation of China [61328205]; National Science Foundation [1149783, 1152576]; Direct For Computer & Info Scie & Enginr [1152576] Funding Source: National Science Foundation	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Science Foundation(National Science Foundation (NSF)); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was done when A. Li was a research fellow in National University of Singapore. The authors would like to thank Quanhong Fu for her help in English writing. This work was partially supported by National Natural Science Foundation of China (No. 61328205). The work of M.-H. Yang was supported in part by the National Science Foundation CAREER Grant 1149783 and IIS Grant 1152576. A. Li is the corresponding author of the article.	Adam A., 2006, IEEE C COMP VIS PATT; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881; Bischof H., 2006, BMVC, P47; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kristan M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P98, DOI 10.1109/ICCVW.2013.20; Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Pang Y, 2013, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2013.346; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891; Smeaton A.F., 2006, MIR 2006 P 8 ACM INT, P321, DOI DOI 10.1145/1178677.1178722; Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445; Wang Q., 2011, SOC PHOTOPTICAL INST, V8138; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wu Y., 2013, P IEEE COMP SOC C CO; Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhang Kaihua, 2012, LNCS, P866; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882	31	97	110	5	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					335	349		10.1109/TPAMI.2015.2417577	http://dx.doi.org/10.1109/TPAMI.2015.2417577			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761738				2022-12-18	WOS:000369989600011
J	Paisley, J; Wang, C; Blei, DM; Jordan, MI				Paisley, John; Wang, Chong; Blei, David M.; Jordan, Michael I.			Nested Hierarchical Dirichlet Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; Dirichlet process; topic modeling; stochastic optimization		We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical topic modeling. The nHDP generalizes the nested Chinese restaurant process (nCRP) to allow each word to follow its own path to a topic node according to a per-document distribution over the paths on a shared tree. This alleviates the rigid, single-path formulation assumed by the nCRP, allowing documents to easily express complex thematic borrowings. We derive a stochastic variational inference algorithm for the model, which enables efficient inference for massive collections of text documents. We demonstrate our algorithm on 1.8 million documents from The New York Times and 2.7 million documents from Wikipedia.	[Paisley, John] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA; [Wang, Chong] Voleon Capital Management, Berkeley, CA USA; [Blei, David M.] Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA; [Jordan, Michael I.] Univ Calif Berkeley, Dept EECS, Berkeley, CA USA; [Jordan, Michael I.] Univ Calif Berkeley, Dept Stat, Berkeley, CA USA	Columbia University; Princeton University; University of California System; University of California Berkeley; University of California System; University of California Berkeley	Paisley, J (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.	jpaisley@columbia.edu; chongw@cs.princeton.edu; blei@cs.princeton.edu; jordan@eecs.berkeley.edu	Jordan, Michael I/C-5253-2013; Paisley, John/AAF-8586-2019	Jordan, Michael/0000-0001-8935-817X				Adams R., 2010, ADV NEURAL INF PROCE; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Aldous D.J., 1985, LECT NOTES MATH, V1117, P1, DOI DOI 10.1007/BFB0099421; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; [Anonymous], 2011, ISBA B; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei D., 2003, P ADV NEUR INF PROC; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Fox EB, 2011, ANN APPL STAT, V5, P1020, DOI 10.1214/10-AOAS395; Hoffman M., 2010, ONLINE LEARNING LATE, P856; Hoffman MD, 2013, J MACH LEARN RES, V14, P1303; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kim J. H., 2012, P 21 ACM INT C INF K, P783; Kurihara K., 2006, ADV NEURAL INFORM PR, V19, P761; Paisley J, 2012, BAYESIAN ANAL, V7, P997, DOI 10.1214/12-BA734; Ranganath R., 2013, P 30 INT C MACH LEAR, V28, P298; Ren L, 2008, P 25 INT C MACH LEAR, P824, DOI [10.1145/1390156.1390260, DOI 10.1145/1390156.1390260]; Rodriguez A, 2008, J AM STAT ASSOC, V103, P1131, DOI 10.1198/016214508000000553; Sato M, 2001, NEURAL COMPUT, V13, P1649, DOI 10.1162/089976601750265045; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Teh Y., 2008, P ADV NEUR INF PROC; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Wang C., 2012, ADV NEURAL INFORM PR; Wang C., 2011, P 14 INT C ART INT S, V15, P752; Wang C., 2009, P ADV NEURAL INFORM; Winn J, 2005, J MACH LEARN RES, V6, P661	29	97	97	1	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					256	270		10.1109/TPAMI.2014.2318728	http://dx.doi.org/10.1109/TPAMI.2014.2318728			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353240	Green Submitted			2022-12-18	WOS:000349625500005
J	Zhou, BL; Tang, XO; Zhang, HP; Wang, XG				Zhou, Bolei; Tang, Xiaoou; Zhang, Hepeng; Wang, Xiaogang			Measuring Crowd Collectiveness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Crowd behavior analysis; collective motion; video analysis; graph connectivity	FLOCKS; BEHAVIOR; PATTERN	Collective motions of crowds are common in nature and have attracted a great deal of attention in a variety of multidisciplinary fields. Collectiveness, which indicates the degree of individuals acting as a union, is a fundamental and universal measurement for various crowd systems. By quantifying the topological structures of collective manifolds of crowd, this paper proposes a descriptor of collectiveness and its efficient computation for the crowd and its constituent individuals. The Collective Merging algorithm is then proposed to detect collective motions from random motions. We validate the effectiveness and robustness of the proposed collectiveness on the system of self-driven particles as well as other real crowd systems such as pedestrian crowds and bacteria colony. We compare the collectiveness descriptor with human perception for collective motion and show their high consistency. As a universal descriptor, the proposed crowd collectiveness can be used to compare different crowd systems. It has a wide range of applications, such as detecting collective motions from crowd clutters, monitoring crowd dynamics, and generating maps of collectiveness for crowded scenes. A new Collective Motion Database, which consists of 413 video clips from 62 crowded scenes, is released to the public.	[Zhou, Bolei] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Zhang, Hepeng] Shanghai Jiao Tong Univ, Dept Phys, Shanghai 200030, Peoples R China; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Massachusetts Institute of Technology (MIT); Chinese University of Hong Kong; Shanghai Jiao Tong University; Chinese University of Hong Kong	Zhou, BL (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.		Wang, Xiaogang/L-4369-2014; Zhang, Hepeng/B-4942-2013	Wang, Xiaogang/0000-0002-9021-0954; Zhang, Hepeng/0000-0001-7806-407X	Research Grants Council of Hong Kong [CUHK417110, CUHK417011]; National Natural Science Foundation of China [61005057, 2192019]	Research Grants Council of Hong Kong(Hong Kong Research Grants Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was partially supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No. CUHK417110 and CUHK417011) and National Natural Science Foundation of China (Project No. 61005057 and 2192019).	Ali S., 2007, P IEEE C COMP VIS PA; [Anonymous], 1897, CROWD STUDY POPULAR; Ballerini M, 2008, P NATL ACAD SCI USA, V105, P1232, DOI 10.1073/pnas.0711437105; Ballerini M, 2008, ANIM BEHAV, V76, P201, DOI 10.1016/j.anbehav.2008.02.004; Bialek W., 2011, ARXIV11070604; Biggs N, 1993, ALGEBRAIC GRAPH THEO, V2nd; BROSTOW GJ, 2006, P IEEE C COMP VIS PA; Brox T., 2010, P EUR C COMP VIS ECC; Buhl J, 2006, SCIENCE, V312, P1402, DOI 10.1126/science.1125142; Camazine S., 2003, SELF ORG BIOL SYSTEM; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; Chang M., 2011, P IEEE INT C COMP VI; Chate H, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.046113; Coppersmith D., 1990, J SYMBOLIC COMPUTATI; Couzin ID, 2009, TRENDS COGN SCI, V13, P36, DOI 10.1016/j.tics.2008.10.002; Couzin ID, 2003, ADV STUD BEHAV, V32, P1, DOI 10.1016/S0065-3454(03)01001-5; Delvenne JC, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.046117; Emonet R., 2011, P IEEE C COMP VIS PA; Forsyth D.R., 2009, GROUP DYNAMICS; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Guy SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366209; Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hospedales T., 2009, P IEEE 12 INT C COMP; Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136; Knuth D.E., 1997, FUNDAMENTAL ALGORITH, VI; Kratz L., 2009, P IEEE C COMP VIS PA; Kratz L., 2012, P EUR C COMP VIS ECC; Lan T., 2012, P IEEE C COMP VIS PA; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x; Lin D., 2009, P IEEE C COMP VIS PA; Lin D., 2010, P IEEE C COMP VIS PA; Mahadevan V., 2010, P IEEE C COMP VIS PA; Makris NC, 2009, SCIENCE, V323, P1734, DOI 10.1126/science.1169441; Mehran R, 2010, P EUR C COMP VIS ECC; Mehran Ramin, 2009, P IEEE C COMP VIS PA; Miller JH, 2007, PRINC STUD COMPLEX, P1, DOI 10.1007/1-4020-5602-8_1; Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Moussaid M, 2009, TOP COGN SCI, V1, P469, DOI 10.1111/j.1756-8765.2009.01028.x; Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468; Olfati-Saber R, 2006, IEEE T AUTOMAT CONTR, V51, P401, DOI 10.1109/TAC.2005.864190; Palla G, 2007, NATURE, V446, P664, DOI 10.1038/nature05670; Parrish JK, 1999, SCIENCE, V284, P99, DOI 10.1126/science.284.5411.99; Pelechano N., 2008, SYNTHESILECT COMPU; Pellegrini S., 2009, P IEEE INT C COMP VI; Petitjean L, 2010, BIOPHYS J, V98, P1790, DOI 10.1016/j.bpj.2010.01.030; Raafat RM, 2009, TRENDS COGN SCI, V13, P420, DOI 10.1016/j.tics.2009.08.002; Rabaud V, 2006, P IEEE C COMP VIS PA; Reynolds C. W., 1987, P 14 ANN C COMPUTER, V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406, DOI 10.1145/37401.37406]; Rodriguez M., 2009, P IEEE 12 INT C COMP; Saligrama V., 2012, P IEEE C COMP VIS PA; Scovanner P., 2009, P IEEE 12 INT C COMP; Scovanner P., 2009, P IEEE INT C COMP VI; Tomasi C., 1991, INT J COMPUTER VISIO; Toner J, 2005, ANN PHYS-NEW YORK, V318, P170, DOI 10.1016/j.aop.2005.04.011; Toner J, 1998, PHYS REV E, V58, P4828, DOI 10.1103/PhysRevE.58.4828; van den Berg J., 2011, P INT S ROB RES; VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226; Vicsek T, 2010, ARXIV10105017; WANG X, 2008, P IEEE C COMP VIS PA; Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wu S., 2010, P IEEE C COMP VIS PA; Zhang HP, 2010, P NATL ACAD SCI USA, V107, P13626, DOI 10.1073/pnas.1001651107; Zhou B., 2012, P 12 EUR C COMP VIS; Zhou B., 2012, P IEEE C COMP VIS PA; Zhou B., 2013, P IEEE C COMP VIS PA; Zhou B., 2011, P IEEE C COMP VIS PA	71	97	106	0	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1586	1599		10.1109/TPAMI.2014.2300484	http://dx.doi.org/10.1109/TPAMI.2014.2300484			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353340	Green Published			2022-12-18	WOS:000340191900008
J	Choi, W; Savarese, S				Choi, Wongun; Savarese, Silvio			Understanding Collective Activities of People from Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Collective activity recognition; tracking; tracklet association	TRACKING; MODEL	This paper presents a principled framework for analyzing collective activities at different levels of semantic granularity from videos. Our framework is capable of jointly tracking multiple individuals, recognizing activities performed by individuals in isolation (i.e., atomic activities such as walking or standing), recognizing the interactions between pairs of individuals (i.e., interaction activities) as well as understanding the activities of group of individuals (i.e., collective activities). A key property of our work is that it can coherently combine bottom-up information stemming from detections or fragments of tracks (or tracklets) with top-down evidence. Top-down evidence is provided by a newly proposed descriptor that captures the coherent behavior of groups of individuals in a spatial-temporal neighborhood of the sequence. Top-down evidence provides contextual information for establishing accurate associations between detections or tracklets across frames and, thus, for obtaining more robust tracking results. Bottom-up evidence percolates upwards so as to automatically infer collective activity labels. Experimental results on two challenging data sets demonstrate our theoretical claims and indicate that our model achieves enhances tracking results and the best collective classification results to date.	[Choi, Wongun] NEC Labs, Princeton, NJ 08540 USA; [Savarese, Silvio] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	NEC Corporation; Stanford University	Choi, W (corresponding author), NEC Labs, Princeton, NJ 08540 USA.	wongun@nec-labs.com; ssilvio@stanford.edu			ONR [N000141110389]; DARPA UPSIDE [HR0011-13-2-0016]; Toyota	ONR(Office of Naval Research); DARPA UPSIDE; Toyota	The authors acknowledge the support of the ONR grant N000141110389, DARPA UPSIDE award HR0011-13-2-0016 and Toyota. They appreciate Khuram Shahid for his contribution to this project.	Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Breiman L., 2004, RANDOM FOREST; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Choi W., 2012, P 12 EUR C COMP VIS; Choi W., 2010, P 11 EUR C COMP VIS; Choi W., 2009, P WORKSH VIS SURV VS; Choi WG, 2011, PROC CVPR IEEE; Cupillard F, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P177, DOI 10.1109/ACV.2002.1182178; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dollar P., 2005, P IEEE 2 JOINT INT W; Ess A., 2008, P IEEE C COMP VIS PA; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Joachims T., 2009, MACHINE LEARNING, V77; Khan S. M., 2005, 13th Annual ACM International Conference on Multimedia, P403, DOI 10.1145/1101149.1101237; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Lan T., 2010, P ADV NEUR INF PROC; Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821; LAND AH, 1960, ECONOMETRICA, V28, P497, DOI 10.2307/1910129; Leal-Taixe L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); LeCun Yann, 2006, PREDICTING STRUCTURE, P2; Li R, 2009, P IEEE C COMP VIS PA; Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990; Mehran A. O. Ramin, 2009, P IEEE C COMP VIS PA; NI B. B., 2009, P IEEE C COMP VIS PA; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pirsiavash H., 2011, P IEEE C COMP VIS PA; Rodriguez M., 2009, P IEEE INT C COMP VI; Ryoo MS, 2011, INT J COMPUT VISION, V93, P183, DOI 10.1007/s11263-010-0355-5; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Savarese S, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P119; Scovanner P., 2009, P IEEE INT C COMP VI; Singh V.K., 2008, P IEEE WORKSH MOT VI; Swears E., 2011, P IEEE WORKSH APPL C; Weston J., 1998, CSDTR9804 ROYAL HOLL; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Yamaguchi K., 2011, P IEEE C COMP VIS PA; YEN JY, 1971, MANAGE SCI, V17, P712, DOI 10.1287/mnsc.17.11.712; Zhang L., 2008, P IEEE C COMP VIS PA; Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013	45	97	104	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1242	1257		10.1109/TPAMI.2013.220	http://dx.doi.org/10.1109/TPAMI.2013.220			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353284				2022-12-18	WOS:000337124200015
J	Fu, YW; Hospedales, TM; Xiang, T; Gong, SG				Fu, Yanwei; Hospedales, Timothy M.; Xiang, Tao; Gong, Shaogang			Learning Multimodal Latent Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Attribute learning; latent attribute space; multitask learning; transfer learning; zero-shot learning		The rapid development of social media sharing has created a huge demand for automatic media classification and annotation techniques. Attribute learning has emerged as a promising paradigm for bridging the semantic gap and addressing data sparsity via transferring attribute knowledge in object recognition and relatively simple action classification. In this paper, we address the task of attribute learning for understanding multimedia data with sparse and incomplete labels. In particular, we focus on videos of social group activities, which are particularly challenging and topical examples of this task because of their multimodal content and complex and unstructured nature relative to the density of annotations. To solve this problem, we 1) introduce a concept of semilatent attribute space, expressing user-defined and latent attributes in a unified framework, and 2) propose a novel scalable probabilistic topic model for learning multimodal semilatent attributes, which dramatically reduces requirements for an exhaustive accurate attribute ontology and expensive annotation effort. We show that our framework is able to exploit latent attributes to outperform contemporary approaches for addressing a variety of realistic multimedia sparse data learning tasks including: multitask learning, learning with label noise, N-shot transfer learning, and importantly zero-shot learning.	[Fu, Yanwei; Hospedales, Timothy M.; Xiang, Tao; Gong, Shaogang] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Fu, YW (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, Room 329,CS Bldg, London E1 4NS, England.	yanwei.fu@eecs.qmul.ac.uk; tmh@eecs.qmul.ac.uk; txiang@eecs.qmul.ac.uk; sgg@eecs.qmul.ac.uk		Hospedales, Timothy/0000-0003-4867-7486	EPSRC [EP/E028594/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/E028594/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Asuncion A., 2009, UAI 09 P 25 C UNC AR, P2734; Barrow H., 1978, COMPUTER VISION SYST; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Blei David M., 2007, P ADV NEUR INF PROC; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Cao L., 2011, P NIST TRECVID WORKS; Farhadi A., 2009, P IEEE C COMP VIS PA; Farhadi A, 2010, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2010.5539924; Fu Y., 2012, P EUR C COMP VIS; Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150; Hospedales T., 2011, P INT C DAT MIN; Hospedales T, 2012, INT J COMPUT VISION, V98, P303, DOI 10.1007/s11263-011-0510-7; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; Hwang S., 2011, P IEEE C COMP VIS PA; Jiang Y. G., 2010, P NIST TRECVID WORKS; Jiang Y.G., 2011, P ACM INT C MULT RET; Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235; Kankuekul Pichai, 2012, P IEEE C COMP VIS PA; Kumar N., 2009, P IEEE INT C COMP VI; Lampert C. H., 2009, P IEEE C COMP VIS PA; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Liu J., 2011, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahajan D, 2011, IEEE I CONF COMP VIS, P1227, DOI 10.1109/ICCV.2011.6126373; Mimno D., 2009, P 2009 C EMP METH NA, V2, DOI [10.3115/1699571.1699627, DOI 10.3115/1699571.1699627]; Newman D, 2009, J MACH LEARN RES, V10, P1801; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Palatucci M., 2009, P ADV NEUR INF PROC; Parikh D., 2011, P IEEE C COMP VIS PA; Qi G.-J., 2007, P ACM INT C MULT; SALAKHUTDINOV R., 2011, P IEEE C COMP VIS PA; Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156; Sorokin A., 2008, P IEEE C COMP VIS PA; Tang J., 2009, P ACM INT C MULT; Tang JH, 2009, IEEE T SYST MAN CY B, V39, P409, DOI 10.1109/TSMCB.2008.2006045; Toderici G, 2010, PROC CVPR IEEE, P3447, DOI 10.1109/CVPR.2010.5539985; Wang C., 2009, P IEEE C COMP VIS PA; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Yang KY, 2011, IEEE T MULTIMEDIA, V13, P662, DOI 10.1109/TMM.2011.2147777; YANG Y, 1997, P MACH LEARN INT WOR; Yu Xiaodong, 2010, P EUR C COMP VIS; ZHU X, 2007, 1530 U WISC MAD DEP	44	97	103	2	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					303	316		10.1109/TPAMI.2013.128	http://dx.doi.org/10.1109/TPAMI.2013.128			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356351				2022-12-18	WOS:000328899500008
J	Scheirer, WJ; Rocha, A; Micheals, RJ; Boult, TE				Scheirer, Walter J.; Rocha, Anderson; Micheals, Ross J.; Boult, Terrance E.			Meta-Recognition: The Theory and Practice of Recognition Score Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Meta-recognition; performance modeling; multialgorithm fusion; object recognition; face recognition; fingerprint recognition; content-based image retrieval; similarity scores; extreme value theory		In this paper, we define meta-recognition, a performance prediction method for recognition algorithms, and examine the theoretical basis for its postrecognition score analysis form through the use of the statistical extreme value theory (EVT). The ability to predict the performance of a recognition system based on its outputs for each match instance is desirable for a number of important reasons, including automatic threshold selection for determining matches and nonmatches, and automatic algorithm selection or weighting for multi-algorithm fusion. The emerging body of literature on postrecognition score analysis has been largely constrained to biometrics, where the analysis has been shown to successfully complement or replace image quality metrics as a predictor. We develop a new statistical predictor based upon the Weibull distribution, which produces accurate results on a per instance recognition basis across different recognition problems. Experimental results are provided for two different face recognition algorithms, a fingerprint recognition algorithm, a SIFT-based object recognition system, and a content-based image retrieval system.	[Scheirer, Walter J.; Boult, Terrance E.] Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA; [Rocha, Anderson] Univ Estadual Campinas, IC, BR-13084971 Campinas, SP, Brazil; [Micheals, Ross J.] NIST, Gaithersburg, MD 20899 USA	University of Colorado System; University of Colorado at Colorado Springs; Universidade Estadual de Campinas; National Institute of Standards & Technology (NIST) - USA	Scheirer, WJ (corresponding author), Univ Colorado, Dept Comp Sci, 1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918 USA.	wjs3@vast.uccs.edu; anderson.rocha@ic.unicamp.br; ross.micheals@nist.gov; tboult@vast.uccs.edu	Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529	ONR [N00014-07-M-0421, N00014-09-M-0448]; US National Science Foundation (NSF) [065025]; FAPESP [2010/05647-4]	ONR(Office of Naval Research); US National Science Foundation (NSF)(National Science Foundation (NSF)); FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP))	This work was supported in part by ONR STTR N00014-07-M-0421, ONR SBIR N00014-09-M-0448, US National Science Foundation (NSF) PFI Award #065025, and FAPESP Award #2010/05647-4. The authors also thank J. Ross Beveridge, who provided valuable feedback on early drafts of this work.	AGGARWAL G, 2008, P IEEE C AC SPEECH S; ALMEIDA J, 2008, P ACM S APPL COMP, P1179; Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360; BERMAN SM, 1962, ANN MATH STAT, V33, P894, DOI 10.1214/aoms/1177704458; Beveridge J. R., 2008, P INT C AUT FAC GEST; BEVERIDGE JR, 2008, P 1 MULT BIOM GRAND; BOLME D, 2003, P INT C VIS SYST GRA, P304; Broadwater JB, 2010, IEEE T SIGNAL PROCES, V58, P490, DOI 10.1109/TSP.2009.2031285; Cox MT, 2005, ARTIF INTELL, V169, P104, DOI 10.1016/j.artint.2005.10.009; Croarkin C., 2008, NIST SEMATECH E HDB; FLAVELL JH, 1988, PERSPECTIVES DEV MEM, P3; Furui S, 1997, PATTERN RECOGN LETT, V18, P859, DOI 10.1016/S0167-8655(97)00073-1; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Grother P, 2004, PROC CVPR IEEE, P68; Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019; Gumbel E. J., 1954, STAT THEORY EXTREME; Kotz S., 2001, EXTREME VALUE DISTRI; Li WL, 2005, 2005 IEEE International Conference on Computational Intelligence for Homeland Security and Personal Safety, P57; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; *NIST, 2004, NIST BIOM SCOR SET; OKADA K, 1998, FACE RECOGNITION THE, P186; PHILLIPS P, 2009, P IEEE 3 INT C BIOM, P1; POH N, 2009, P IEEE 3 INT C BIOM; POH N, 2009, P EUR SIGN PROC C; Riopka T, 2005, LECT NOTES COMPUT SC, V3546, P850; SCHEIRER W, 2008, P IEEE WORKSH BIOM; SCHEIRER W, 2008, P IEEE 2 INT C BIOM; Scheirer W, 2010, LECT NOTES COMPUT SC, V6313, P481; Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56; SHI Z, 2008, P SPIE C; Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812; TABASSI E, 2004, 7151 NISTIR; Tulyakov S., 2008, P IEEE WORKSH BIOM	33	97	99	3	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1689	1695		10.1109/TPAMI.2011.54	http://dx.doi.org/10.1109/TPAMI.2011.54			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21422483				2022-12-18	WOS:000291807200016
J	Zhu, JJ; Wang, L; Yang, RG; Davis, JE; Pan, ZG				Zhu, Jiejie; Wang, Liang; Yang, Ruigang; Davis, James E.; Pan, Zhigeng			Reliability Fusion of Time-of-Flight Depth and Stereo Geometry for High Quality Depth Maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time-of-Flight sensor; multisensor fusion; global optimization; stereo vision		Time-of-flight range sensors have error characteristics, which are complementary to passive stereo. They provide real-time depth estimates in conditions where passive stereo does not work well, such as on white walls. In contrast, these sensors are noisy and often perform poorly on the textured scenes where stereo excels. We explore their complementary characteristics and introduce a method for combining the results from both methods that achieve better accuracy than either alone. In our fusion framework, the depth probability distribution functions from each of these sensor modalities are formulated and optimized. Robust and adaptive fusion is built on a pixel-wise reliability weighting function calculated for each method. In addition, since time-of-flight devices have primarily been used as individual sensors, they are typically poorly calibrated. We introduce a method that substantially improves upon the manufacturer's calibration. We demonstrate that our proposed techniques lead to improved accuracy and robustness on an extensive set of experimental results.	[Zhu, Jiejie; Pan, Zhigeng] Hangzhou Normal Univ, DMHCIRC, Hangzhou 310036, Zhejiang, Peoples R China; [Wang, Liang] Microsoft Corp, Microsoft Appl Sci Grp, Redmond, WA 98121 USA; [Yang, Ruigang] Univ Kentucky, Dept Comp Sci, Lexington, KY 40507 USA; [Davis, James E.] Univ Calif Santa Cruz, Ctr Entrepreneurship, Santa Cruz, CA 95064 USA	Hangzhou Normal University; Microsoft; University of Kentucky; University of California System; University of California Santa Cruz	Zhu, JJ (corresponding author), Hangzhou Normal Univ, DMHCIRC, Hangzhou 310036, Zhejiang, Peoples R China.	jjzhu@cs.ucf.edu; lwan@cs.uky.edu; ryang@cs.uky.edu; davis@cs.ucsc.edu; zgpan@cad.zju.edu.cn		Yang, Ruigang/0000-0001-5296-6307; Pan, Zhi-geng/0000-0003-0717-5850	University of Kentucky Research Foundation; US Department of Homeland Security; US National Science Foundation (NSF) [HCC-0448185]; NSF [CCF-0746690]; China NSFC [60533080]; China 863 Plans [2006AA01Z335];  [CPA-0811647]	University of Kentucky Research Foundation; US Department of Homeland Security(United States Department of Homeland Security (DHS)); US National Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); China NSFC(National Natural Science Foundation of China (NSFC)); China 863 Plans(National High Technology Research and Development Program of China); 	Ruigang Yang was supported by the University of Kentucky Research Foundation, the US Department of Homeland Security, US National Science Foundation (NSF) HCC-0448185, and CPA-0811647. James E. Davis was supported by NSF CCF-0746690. Zhigeng Pan was supported by the China NSFC 60533080 and the China 863 Plans 2006AA01Z335. The authors thank Qing Zhang and Xueqing Xiang for collecting part of the data. This work was done when Jiejie Zhu was with the University of Kentucky as a postdoctoral researcher.	*3DV SYST, 2004, Z CAM; BEDER C, 2007, P IEEE INT C COMP VI; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; BRUNTON A, 2006, P 3 CAN C COMP ROB V; Canesta Inc, 2006, CAN EL PERC DEV KIT; Chen S., 2008, ACTIVE SENSOR PLANNI; Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755; Diebel James, 2005, NEURAL INF PROCESS S, P291; Fuchs M, 2008, PROC CVPR IEEE, P464; Gokturk S.B., 2004, P C COMP VIS PATT RE, P35, DOI [10.1109/CVPR.2004.17, DOI 10.1109/CVPR.2004.291]; Gonzalez-Banos H, 2004, PROC CVPR IEEE, P234; GUAN L, 2008, P IEEE WORKSH MULT M; GUDMUNDSSON SA, 2007, P INT S SIGN CIRC SY, P1; GUDMUNDSSON SA, 2007, P INT WORKSH DYN 3D; Hartley R., 2003, MULTIPLE VIEW GEOMET; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUHLE B, 2008, P 1 WORKSH TIM OF FL; Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913; KAHLAMMN T, 2006, P SPIE C EL REM SENS, V2; Kawahito S, 2007, IEEE SENS J, V7, P1578, DOI 10.1109/JSEN.2007.907561; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448; LEHMANN M, 2004, CCD CMOS LOCK IN PIX; LIANG CK, 2009, P IEEE C COMP VIS PA; Lindner M., 2007, P INT S SIGN CIRC SY; LINDNER M, 2007, P SPIE C INT ROB COM, V25; MAY S, 2006, P IEEE RSJ INT C INT, P1578; OGGIER T, 2005, P C 1 RANG IM RES DA; Prasad T., 2006, COMP VIS WINT WORKSH, P82; REULKE R, 2006, P C IM ENG VIS METR; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SCHUON S, 2008, P 1 WORKSH TIM OF FL; Sun J, 2005, PROC CVPR IEEE, P399; *SWISSR INC, 2006, SR 2; VERRI A, 1986, J OPT SOC AM A, V3, P297, DOI 10.1364/JOSAA.3.000297; WANG L, 2008, P 10 EUR C COMP VIS; Xu Z., 1998, P INT C MECH MACH VI, P259; YANG Q, 2006, CVPR, P2347; YANG Q., 2006, P BRIT MACH VIS C; Yang Q. X., 2007, P IEEE INT C COMP VI; Yoon KJ, 2005, PROC CVPR IEEE, P924; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zheng Y., 2006, P IEEE C COMP VIS PA, P461; Zhu J., 2008, P IEEE C COMP VIS PA; Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68	45	97	113	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1400	1414		10.1109/TPAMI.2010.172	http://dx.doi.org/10.1109/TPAMI.2010.172			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	20820074				2022-12-18	WOS:000290574000009
J	Jiang, XD				Jiang, Xudong			Asymmetric Principal Component and Discriminant Analyses for Pattern Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimension reduction; feature extraction; principal component analysis; discriminant analysis; classification; face detection	FACE; EXTRACTION	This paper studies the roles of the principal component and discriminant analyses in the pattern classification and explores their problems with the asymmetric classes and/or the unbalanced training data. An asymmetric principal component analysis (APCA) is proposed to remove the unreliable dimensions more effectively than the conventional PCA. Targeted at the two-class problem, an asymmetric discriminant analysis in the APCA subspace is proposed to regularize the eigenvalue that is, in general, a biased estimate of the variance in the corresponding dimension. These efforts facilitate a reliable and discriminative feature extraction for the asymmetric classes and/or the unbalanced training data. The proposed approach is validated in the experiments by comparing it with the related methods. It consistently achieves the highest classification accuracy among all tested methods in the experiments.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Jiang, XD (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	exdjiang@ntu.edu.sg	Jiang, Xudong/B-1555-2008	Jiang, Xudong/0000-0002-9104-2315	Singapore A*STAR SERC research project [062 130 0056]	Singapore A*STAR SERC research project(Agency for Science Technology & Research (A*STAR))	This work was supported by Singapore A*STAR SERC research project grant no. 062 130 0056.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hsieh PF, 2006, IEEE T PATTERN ANAL, V28, P223, DOI 10.1109/TPAMI.2006.26; HSIEH PF, 1998, P IEEE INT GEOSC REM, V4, P2050; Jiang XD, 2006, ELECTRON LETT, V42, P1089, DOI 10.1049/el:20062035; Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822; Liu W, 2004, LECT NOTES COMPUT SC, V3087, P32; Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17; SCHNEIDERMAN H, 2005, P IEEE C COMP VIS PA; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Zhang S, 2007, IEEE T PATTERN ANAL, V29, P1732, DOI 10.1109/TPAMI.2007.1089	22	97	98	3	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					931	937		10.1109/TPAMI.2008.258	http://dx.doi.org/10.1109/TPAMI.2008.258			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19441177				2022-12-18	WOS:000264144500012
J	Jia, JY; Tang, CK				Jia, Jiaya; Tang, Chi-Keung			Image stitching using structure deformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image stitching; structure deformation; image alignment	ELASTIC REGISTRATION	The aim of this paper is to achieve seamless image stitching without producing visual artifact caused by severe intensity discrepancy and structure misalignment, given that the input images are roughly aligned or globally registered. Our new approach is based on structure deformation and propagation for achieving the overall consistency in image structure and intensity. The new stitching algorithm, which has found applications in image compositing, image blending, and intensity correction, consists of the following main processes. Depending on the compatibility and distinctiveness of the 2D features detected in the image plane, single or double optimal partitions are computed subject to the constraints of intensity coherence and structure continuity. Afterwards, specific 1D features are detected along the computed optimal partitions from which a set of sparse deformation vectors is derived to encode 1D feature matching between the partitions. These sparse deformation cues are robustly propagated into the input images by solving the associated minimization problem in gradient domain, thus providing a uniform framework for the simultaneous alignment of image structure and intensity. We present results in general image compositing and blending in order to show the effectiveness of our method in producing seamless stitching results from complex input images.	[Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; [Tang, Chi-Keung] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong; Hong Kong University of Science & Technology	Jia, JY (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	leojia@cse.cuhk.edu.hk; cktang@cs.ust.hk	cai, bo/G-1491-2010; Jia, Jiaya/I-3251-2012					Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; ARONOV B, 1993, COMPUTATIONAL GEOMET, P27; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; Brown M, 2005, PROC CVPR IEEE, P510; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; CHEN MH, 2000, M CARLO METHODS BAYE; Davatzikos C, 1996, IEEE T MED IMAGING, V15, P112, DOI 10.1109/42.481446; DAVIS J, 1998, P IEEE CS C COMP VIS; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; EPPSTEIN D, 1992, CGTA COMPUTATIONAL G, V1; Fang H., 2004, P ACM SIGGRAPH 04; Fornefett M, 2001, IMAGE VISION COMPUT, V19, P87, DOI 10.1016/S0262-8856(00)00057-3; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HASLER D, 2001, P SPIE; Jia JY, 2005, IEEE I CONF COMP VIS, P1651; Jia JY, 2005, IEEE T PATTERN ANAL, V27, P36, DOI 10.1109/TPAMI.2005.20; Jia JY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P156, DOI 10.1109/ICCV.2003.1238331; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; LESTER H, 1997, P MED IMAGE UNDERSTA; LEVIN A, 2004, P EUR C COMP VIS MAY; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; MORTEN BN, 1996, P VISUALIZATION BIOM, V1131, P267; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618; Ruprecht D., 1995, IEEE COMPUTER GRAPHI, V15; Sand P, 2004, ACM T GRAPHIC, V23, P592, DOI 10.1145/1015706.1015765; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; SOUVAINE D., 1994, 9452 DIMACS; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Szeliski R., 2004, MSRTR200492; TAL A, 1999, P EUROGRAPHICS 99, P339; Uyttendaele M., 2001, P IEEE C COMP VIS PA; Wu Q, 2004, ACM T GRAPHIC, V23, P364, DOI 10.1145/1015706.1015730	37	97	116	3	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					617	631		10.1109/TPAMI.2007.70729	http://dx.doi.org/10.1109/TPAMI.2007.70729			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276968	Green Submitted			2022-12-18	WOS:000253135600006
J	Boulanger, J; Kervrann, C; Bouthemy, P				Boulanger, Jerome; Kervrann, Charles; Bouthemy, Patrick			Space-time adaptation for patch-based image sequence restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image sequence restoration; denoising; nonparametric estimation; nonlinear filtering; bias-variance trade-off	REMOVAL; MOTION	We present a novel space-time patch-based method for image sequence restoration. We propose an adaptive statistical estimation framework based on the local analysis of the bias-variance trade-off. At each pixel, the space-time neighborhood is adapted to improve the performance of the proposed patch-based estimator. The proposed method is unsupervised and requires no motion estimation. Nevertheless, it can also be combined with motion estimation to cope with very large displacements due to camera motion. Experiments show that this method is able to drastically improve the quality of highly corrupted image sequences. Quantitative evaluations on standard artificially noise-corrupted image sequences demonstrate that our method outperforms other recent competitive methods. We also report convincing results on real noisy image sequences.	INRA, UR341, F-78352 Jouy En Josas, France; INRIA Rennes, IRISA, F-35042 Rennes, France	INRAE; UDICE-French Research Universities; Universite Paris Saclay	Boulanger, J (corresponding author), INRA, UR341, F-78352 Jouy En Josas, France.	jerome.boulanger@irisa.fr; charles.kervrann@irisa.fr; patrick.bouthemy@irisa.fr		Boulanger, Jerome/0000-0003-0237-3743				Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; BOULANGER J, 2005, P 8 INT C MED IM COM; BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; BUADES A, 2005, PREPRINT CMLA; Cheong HY, 2004, IEEE IMAGE PROC, P965; Dekeyser F, 2000, IEEE IMAGE PROC, P208, DOI 10.1109/ICIP.2000.900931; DUGAD R, 1999, P IEEE INT C IM PROC, V4, P156; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; ERCOLE C, 2005, P 1 INT WORKSH VID P; GASSER T, 1986, BIOMETRIKA, V73, P625; Katkovnik V, 2002, J MATH IMAGING VIS, V16, P223, DOI 10.1023/A:1020329726980; Kervrann C, 2004, LECT NOTES COMPUT SC, V3023, P132; KERVRANN C, 2006, P 9 EUR C COMP VIS; Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529; LEE SH, 1998, P IEEE INT C IM PROC, V3, P447; LEPSKI O, 1991, SIAM J THEORY PROBAB, V36, P654; Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509; MOTTA G, 2005, P IEEE INT C IM PROC, V3, P345; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; Polzehl J, 2000, J R STAT SOC B, V62, P335, DOI 10.1111/1467-9868.00235; Rajpoot N, 2004, IEEE IMAGE PROC, P957; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; RUSANOVSKYY D, 2005, P 7 ADV CONC INT VIS; SHI F, 2004, P IEEE INT C AC SPEE, V2, P949; Wexler Y, 2004, PROC CVPR IEEE, P120; Zhang D, 2002, IEEE T CIRC SYST VID, V12, P331, DOI 10.1109/TCSVT.2002.1003472; Zlokolica V, 2004, PROC SPIE, V5298, P403, DOI 10.1117/12.520847	30	97	98	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1096	1102		10.1109/TPAMI.2007.1064	http://dx.doi.org/10.1109/TPAMI.2007.1064			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431307	Green Submitted			2022-12-18	WOS:000245600800015
J	Suzuki, K; Horiba, I; Sugie, N				Suzuki, K; Horiba, I; Sugie, N			Neural edge enhancer for supervised edge enhancement from noisy images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						supervised edge enhancer; noisy image; robustness; neural network; edge detection; contour extraction	FREQUENCY-DOMAIN FILTER; OPERATOR; NETWORK; APPROXIMATION; ALGORITHM; SELECTION; DESIGN; BLUR	We propose a new edge enhancer based on a modified multilayer neural network, which is called a neural edge enhancer (NEE), for enhancing the desired edges clearly from noisy images. The NEE is a supervised edge enhancer: Through training with a set of input noisy images and teaching edges, the NEE acquires the function of a desired edge enhancer. The input images are synthesized from noiseless images by addition of noise. The teaching edges are made from the noiseless images by performing the desired edge enhancer. To investigate the performance, we carried out experiments to enhance edges from noisy artificial and natural images. By comparison with conventional edge enhancers, the following was demonstrated: The NEE was robust against noise, was able to enhance continuous edges from noisy images, and was superior to the conventional edge enhancers in similarity to the desired edges. To gain insight into the nonlinear kernel of the NEE, we performed analyses on the trained NEE. The results suggested that the trained NEE acquired directional gradient operators with smoothing. Furthermore, we propose a method for edge localization for the NEE. We compared the NEE, together with the proposed edge localization method, with a leading edge detector. The NEE was proven to be useful for enhancing edges from noisy images.	Univ Chicago, Dept Radiol, Kurt Rossmann Labs Radiol Image Res, Chicago, IL 60637 USA; Aichi Prefectural Univ, Fac Informat Sci & Technol, Nagakute, Aichi 4801198, Japan; Meijo Univ, Fac Sci & Technol, Tempaku Ku, Nagoya, Aichi 4688502, Japan	University of Chicago; Meijo University	Suzuki, K (corresponding author), Univ Chicago, Dept Radiol, Kurt Rossmann Labs Radiol Image Res, 5841 S Maryland Ave, Chicago, IL 60637 USA.	suzuki@uchicago.edu; horiba@ist.aichi-pu.ac.jp; sugie@ccmfs.meijo-u.ac.jp	Suzuki, Kenji/A-1284-2007	Suzuki, Kenji/0000-0002-3993-8309				ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; Aizenberg I, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P557, DOI 10.1109/NNSP.2000.890134; Aizenberg I.N., 2000, MULTI VALUED UNIVERS; Aizenberg I. N., 1998, P IEEE INT WORKSH CE, P301; Aizenberg IN, 1997, J ELECTRON IMAGING, V6, P272, DOI 10.1117/12.269905; ARAKAWA K, 1990, IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS : ICC 90, VOLS 1-4, P424, DOI 10.1109/ICC.1990.117116; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363; BHANDARKAR SM, 1994, PATTERN RECOGN, V27, P1159, DOI 10.1016/0031-3203(94)90003-5; BHUIYAN MS, 1993, IEEE IJCNN, P1223; BISHOP CM, 1995, NEURAL NETWORKS PATT, P230; BLAKEMORE C, 1970, NATURE, V228, P477, DOI 10.1038/228477a0; BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; COPPINI G, 1995, IEEE T MED IMAGING, V14, P301, DOI 10.1109/42.387712; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; DUDA RO, 1971, PATTERN CLASSIFICATI, P267; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Elder JH, 1996, PROC CVPR IEEE, P27, DOI 10.1109/CVPR.1996.517049; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Guan L, 1998, INT CONF ACOUST SPEE, P1245, DOI 10.1109/ICASSP.1998.675497; GUZELIS C, 1997, P IEEE INT C IM P, P1134; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12, P165, DOI 10.1109/34.44403; HAYKIN S, 1999, NEURAL NETWORKS COMP, P233; He ZQ, 1998, ICSP '98: 1998 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PROCEEDINGS, VOLS I AND II, P1382, DOI 10.1109/ICOSP.1998.770878; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; JAHNE B, 1997, DIGITAL IMAGE PROCES, P322; KASS L, 1988, VISUAL NEUROSCI, V1, P3, DOI 10.1017/S0952523800000985; LIN Y, 1993, IEEE T SIGNAL PROCES, V41, P1201, DOI 10.1109/78.205724; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; LU SW, 1996, P IEEE INT C SYST MA, V3, P2270; LUNSCHER WHHJ, 1983, IEEE T PATTERN ANAL, V5, P678, DOI 10.1109/TPAMI.1983.4767462; LUNSCHER WHHJ, 1986, IEEE T PATTERN ANAL, V8, P164, DOI 10.1109/TPAMI.1986.4767770; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MERO L, 1977, P INT JOINT C ART IN, P650; Muneyasu M, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1703, DOI 10.1109/ICNN.1995.488876; Nagai H, 1998, INT CONF ACOUST SPEE, P2749, DOI 10.1109/ICASSP.1998.678092; OHASHI G, 1993, P SOC PHOTO-OPT INS, V1898, P480, DOI 10.1117/12.154534; PARKER JR, 1997, ALGORITHMS IMAGE PRO, P1; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Pratt W. K., 1991, DIGITAL IMAGE PROCES, P491; Rekeczky C, 1998, INT J CIRC THEOR APP, V26, P375, DOI 10.1002/(SICI)1097-007X(199807/08)26:4<375::AID-CTA19>3.0.CO;2-#; REKECZKY C, 1997, P INT S NONL THEOR A, P209; Robinson G.S., 1977, COMPUT VISION GRAPH, V6, P492, DOI 10.1016/s0146-664x(77)80024-5; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V2, P84; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; RUSS JC, 1995, IMAGE PROCESSING HDB, P225; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B; Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485; Suzuki K, 2003, COMPUT VIS IMAGE UND, V89, P1, DOI 10.1016/S1077-3142(02)00030-9; Suzuki K, 2002, IEICE T INF SYST, VE85D, P1710; Suzuki K, 2001, PROC SPIE, V4322, P1771, DOI 10.1117/12.431066; Suzuki K, 2002, IEEE T SIGNAL PROCES, V50, P1787, DOI 10.1109/TSP.2002.1011218; SUZUKI K, 1995, SYST COMPUT JPN, V26, P66, DOI 10.1002/scj.4690260807; Suzuki K, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P537, DOI 10.1109/NNSP.2000.890132; Suzuki K, 2001, NEURAL PROCESS LETT, V13, P43, DOI 10.1023/A:1009639214138; Suzuki K, 1998, NEURAL NETWORKS FOR SIGNAL PROCESSING VIII, P323, DOI 10.1109/NNSP.1998.710662; Suzuki K, 1998, P INT C NEUR INF PRO, V1, P157; SUZUKI K, 2000, P IEEE INT S INT SIG, V2, P783; Suzuki K., 1998, P INT S NOIS RED IM, P85; SUZUKI K, 2000, QUANTUM INFORMATION, V2, P205; SUZUKI K, 2000, P IEEE INT S INT SIG, V1, P292; SUZUKI K, 1999, NEURAL NETWORKS SIGN, V9, P370; TOIVANEN P, 1998, P INT C ART NEUR NET, P737; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; VILARINO DL, 1998, P 5 IEEE INT WORKSH, P331; YIN L, 1994, IEEE T SIGNAL PROCES, V42, P419, DOI 10.1109/78.275617; YOO J, 1997, IEEE T IMAGE PROCESS, V6, P483; Zhang ZZ, 1996, IEEE T NEURAL NETWOR, V7, P857, DOI 10.1109/72.508929	73	97	100	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1582	1596		10.1109/TPAMI.2003.1251151	http://dx.doi.org/10.1109/TPAMI.2003.1251151			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000008
J	Chen, YK; Wang, JF				Chen, YK; Wang, JF			Segmentation of single- or multiple-touching handwritten numeral string using background and foreground analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						thinning; multiple-touching; segmentation; mixture Gaussian probability		A new approach of segmenting single- or multiple-touching handwritten numeral string (two-digits) is proposed. Most algorithms for segmenting connected digits mainly focus on the analysis of foreground pixels. Some concentrated on the analysis of background pixels only and others are based on a recognizer, in this paper, we combine background and foreground analysis to segment single- or multiple-touching handwritten numeral strings. Thinning of both foreground and background regions are first processed on the image of connected numeral strings and the feature points on foreground and background skeletons are extracted. Several possible segmentation paths are then constructed and useless strokes are removed. Finally, the parameters of geometric properties of each possible segmentation paths are determined and these parameters are analyzed by the mixture Gaussian probability function to decide the best segmentation path or reject it. Experimental results on NIST special database 19 (an update of NIST special database 3) and some other images collected by ourselves show that our algorithm can get a correct rate of 96 percent with rejection rate of 7.8 percent, which compares favorably with those reported in the literature.	Natl Cheng Kung Univ, Inst Informat Engn, Tainan 70101, Taiwan; Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan	National Cheng Kung University; National Cheng Kung University	Chen, YK (corresponding author), Natl Cheng Kung Univ, Inst Informat Engn, Tainan 70101, Taiwan.	chenek@server2.ncku.edu.tw; wangjf@server2.iie.ncku.edu.tw						ARICA N, 1998, P ICPR, V2, P1127; CHERIET M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P619, DOI 10.1109/ICPR.1992.201853; CHI Z, 1995, OPT ENG, V34, P1159, DOI 10.1117/12.196551; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; HU J, 1998, P INT C PATTERN RECO, V1, P372; Lee SW, 1999, IEEE T SYST MAN CY C, V29, P285, DOI 10.1109/5326.760572; Lu ZK, 1999, PATTERN RECOGN, V32, P921, DOI 10.1016/S0031-3203(98)00123-X; Rabiner L., 1993, FUNDAMENTALS SPEECH; SHI Z, 1997, P 4 IEEE INT C DOC A, V2, P455; Strathy N. W., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P577, DOI 10.1109/ICDAR.1993.395669; ZHAO B, 1997, P INT C DOCUMENT ANA, V2, P524	11	97	117	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1304	1317						14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200008
J	ABIDI, MA; CHANDRA, T				ABIDI, MA; CHANDRA, T			A NEW EFFICIENT AND DIRECT SOLUTION FOR POSE ESTIMATION USING QUADRANGULAR TARGETS - ALGORITHM AND EVALUATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						CAMERA CALIBRATION; INTERIOR ORIENTATION PARAMETERS; LANDMARK TRACKING; POSE ESTIMATION	POSITION	Pose estimation is an important operation for many vision tasks. In this paper, we propose a new algorithm for pose estimation based on the volume measurement of tetrahedra composed of feature-point triplets extracted from an arbitrary quadrangular target and the lens center of the vision system. The input to this algorithm are the six distances joining all feature pairs and the image coordinates of the quadrangular target The output of this algorithm are the effective focal length of the vision system, the interior orientation parameters of the target, the exterior orientation parameters of the camera with respect to an arbitrary coordinate system if the target coordinates are known in this frame, and the final pose of the camera. We have also developed a shape restoration technique which is applied prior to pose recovery in order to reduce the effects of inaccuracies caused by image projection. An evaluation of the method has shown that this pose estimation technique is accurate and robust. Because it is based on a unique and closed-form solution, its speed makes it a potential candidate for solving a variety of landmark-based tracking problems.			ABIDI, MA (corresponding author), UNIV TENNESSEE,DEPT ELECT & COMP ENGN,KNOXVILLE,TN 37996, USA.							ABIDI MA, 1990, IEEE T ROBOTIC AUTOM, V6, P159, DOI 10.1109/70.54732; ABIDI MA, 1991, COMPUTER, V24; CHANDRA T, 1989, LANDMARK TRACKING CA; CHEN CH, 1987, MAR P INT C ROB AUT, V2, P807; CHOU HL, 1986, PATTERN RECOGN, V19, P439, DOI 10.1016/0031-3203(86)90042-7; CYROS ML, 1988, DATACUBE WORLD REV, V2, P1; Duda R.O., 1973, J ROYAL STAT SOC SER; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fu KS, 1987, INTRO ROBOTICS CONTR; GANAPATHY S, 1984, P INT C ROB AUT ROM, V1, P130; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; HARALICK RM, 1989, PATTERN RECOGN, V22, P225, DOI 10.1016/0031-3203(89)90071-X; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P191, DOI 10.1016/0146-664X(80)90046-5; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; HUNG Y, 1985, MAR P IEEE INT C ROB, V1, P80; KABUKA MR, 1987, IEEE T ROBOTIC AUTOM, V3, P505, DOI 10.1109/JRA.1987.1087143; KIM YC, 1987, IEEE J ROBOT AUTOM, V3, P361; LESSARD J, 1987, MAR P IEEE INT C ROB, V2, P1203; Magee M. J., 1984, International Conference on Robotics, P140; MCVEY ES, 1986, IEEE T PATTERN ANAL, V8, P105, DOI 10.1109/TPAMI.1986.4767757; Polak E., 1971, COMPUTATIONAL METHOD; Rektorys K., 1969, SURVEY APPLICABLE MA; YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034	23	97	125	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					534	538		10.1109/34.391388	http://dx.doi.org/10.1109/34.391388			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394					2022-12-18	WOS:A1995QW39400010
J	SUPER, BJ; BOVIK, AC				SUPER, BJ; BOVIK, AC			SHAPE FROM TEXTURE USING LOCAL SPECTRAL MOMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE FROM TEXTURE; SHAPE RECOVERY; SURFACE ORIENTATION; MOMENTS; WAVELET; SPATIAL FREQUENCY; GABOR FUNCTIONS; TEXTURE; PROJECTION		We present a non-feature-based solution to the problem of computing the shape of curved surfaces from texture information. First, the use of local spatial-frequency spectra and their moments to describe texture is discussed and motivated. A new, more accurate method for measuring the local spatial-frequency moments of an image texture using Gabor elementary functions and their derivatives is presented. Also described is a technique for separating shading from texture information, which makes the shape-from-texture algorithm robust to the shading effects found in real imagery. Second, a detailed model for the projection of local spectra and spectral moments of any surface reflectance patterns (not just textures) is developed. Third, the conditions under which the projection model can be solved for the orientation of the surface at each point are explored. Unlike earlier non-feature-based, curved surface shape-from-texture approaches, the assumption that the surface texture is isotropic is not required; surface texture homogeneity can be assumed instead. The algorithm's ability to operate on anisotropic and nondeterministic textures, and on both smooth- and rough-textured surfaces, is demonstrated.	UNIV TEXAS, DEPT ELECT & COMP ENGN, AUSTIN, TX 78712 USA	University of Texas System; University of Texas Austin	SUPER, BJ (corresponding author), UNIV TEXAS, CTR VIS & IMAGE SCI, MEZES HALL 330, AUSTIN, TX 78712 USA.		Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X				ALBRECHT DG, 1991, VISUAL NEUROSCI, V7, P531, DOI 10.1017/S0952523800010336; Aloimonos J, 1985, P IJCAI 85 LOS ANGEL, P926; Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; BLOSTEIN D, 1987, 1ST P IEEE INT C COM, P444; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brown L. G., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P510, DOI 10.1109/CVPR.1988.196283; Dwight H., 1961, TABLES INTEGRALS OTH; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GARDING J, 1991, THESIS U STOCKHOLM; GARDING J, 1992, MAY P EUR C COMP VIS, P630; HAVLICEK JP, 1992, 26TH P IEEE AS C SIG, P805; Horn B., 1986, ROBOT VISION, P1; IKEUCHI K, 1984, ARTIF INTELL, V22, P49, DOI 10.1016/0004-3702(84)90025-0; Jau Y. C., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P515, DOI 10.1109/CVPR.1988.196284; KANATANI K, 1989, ARTIF INTELL, V38, P1, DOI 10.1016/0004-3702(89)90066-0; KENDER JR, 1979, 6 IJCAI TOK, P475; KRUMM J, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P354; KRUMM J, 1992, JUN P C COMP VIS PAT, P284; MALIK J, 1993, JUN P C COMP VIS PAT, P267; OHTA Y, 1981, P INT JOINT C ART IN, P746; Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217; STEVENS KA, 1981, BIOL CYBERN, V42, P95, DOI 10.1007/BF00336727; SUPER BJ, 1992, SPIE P, V1818; SUPER BJ, 1991, SPIE P, V1606; SUPER BJ, 1992, JUN P C COMP VIS PAT, P296; SUPER BJ, 1993, MAY ANN M ASS RES VI; SUPER BJ, 1993, TR93001 U TEX AUST C; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	28	97	103	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					333	343		10.1109/34.385983	http://dx.doi.org/10.1109/34.385983			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800002
J	LAURENTINI, A				LAURENTINI, A			HOW FAR 3D SHAPES CAN BE UNDERSTOOD FROM 2D SILHOUETTES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						COMPUTER VISION; 3D OBJECT RECONSTRUCTION; 2D IMAGES; VOLUME INTERSECTION; SHAPE FROM SILHOUETTES; VISUAL HULL	VIEWS; INTERSECTION; OCTREES; OBJECTS	Each 2D silhouette of a 3D unknown object O constrains O inside the volume obtained by back-projecting the silhouette from the corresponding viewpoint. A set of silhouettes specifies a boundary volume R, obtained by intersecting the volumes due to each silhouette, R more or less closely approximates O, depending on the viewpoints and the object itself. This approach to the reconstruction of 3D objects is usually referred to as volume intersection. This correspondence addresses the problem of inferring the shape of the unknown object O from the reconstructed object R. For doing this, we divide the points of the surface of R into hard points, which belong to the surface of any possible object originating R, and soft points, which may or may not belong to O. We consider two cases: In the first case R is the closest approximation of O which can be obtained from its silhouettes, i.e., its visual hull; in the second case, R is a generic reconstructed object. In both cases we supply necessary and sufficient conditions for a point to be hard and give rules for computing the hard surfaces.			LAURENTINI, A (corresponding author), POLITECN TORINO, DIPARTIMENTO AUTOMAT & INFORMAT, CSO DUCA ABRUZZI 24, I-10129 TURIN, ITALY.							AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7; CHIEN CH, 1989, IEEE T PATTERN ANAL, V11, P372, DOI 10.1109/34.19034; HONG TH, 1985, IEEE T PATTERN ANAL, V7, P721, DOI 10.1109/TPAMI.1985.4767730; KIM YC, 1986, INT J ROBOT AUTOM, V1, P77; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LAURENTINI A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P720, DOI 10.1109/ICPR.1992.201662; LAURENTINI A, 1992, L292 INT REPT; LAVAKUSHA AK, 1989, P MIV 89 TOKYO, P309; LAVAKUSHA AK, 1989, COMPUT VISION GRAPH, V45, P371; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; NOBORIO H, 1988, IEEE T PATTERN ANAL, V10, P769, DOI 10.1109/34.9101; POTEMESIL M, 1987, COMPUT VISION GRAPH, V40, P1; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; SHANMUKH K, 1991, PATTERN RECOGN LETT, V12, P165, DOI 10.1016/0167-8655(91)90045-N; SRINIVASAN P, 1990, PATTERN RECOGN, V23, P843, DOI 10.1016/0031-3203(90)90131-4; SRIVASTAVA S, 1987, NOV P IEEE WORKSH CO, P363	17	97	99	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					188	195		10.1109/34.368170	http://dx.doi.org/10.1109/34.368170			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500008
J	VERWER, BJH; VERBEEK, PW; DEKKER, ST				VERWER, BJH; VERBEEK, PW; DEKKER, ST			AN EFFICIENT UNIFORM COST ALGORITHM APPLIED TO DISTANCE TRANSFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											VERWER, BJH (corresponding author), DELFT UNIV TECHNOL, FAC APPL PHYS, PATTERN RECOGNIT GRP, LORENTZWEG 1, 2625 CJ DELFT, NETHERLANDS.							BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; DEKKER ST, IN PRESS; DORST L, 1986, THESIS DELFT U TECHN; DORST L, 1986, 1986 P EUR SIGN PROC, P917; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; Pearl Judea, 1984, HEURISTICS; PIPER J, 1987, PATTERN RECOGN, V20, P599, DOI 10.1016/0031-3203(87)90030-6; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; VERBEEK PW, 1986, DEC P INT AUT SYST, P634; Verwer B. J. H., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P137, DOI 10.1109/ICPR.1988.28189; YAMASHITA M, 1986, PATTERN RECOGN, V19, P237, DOI 10.1016/0031-3203(86)90014-2	12	97	102	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					425	429		10.1109/34.19041	http://dx.doi.org/10.1109/34.19041			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000010
J	KUBE, P; PENTLAND, A				KUBE, P; PENTLAND, A			ON THE IMAGING OF FRACTAL SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025	SRI International	KUBE, P (corresponding author), UNIV CALIF SAN DIEGO,DEPT COMP SCI & ENGN,LA JOLLA,CA 92093, USA.							FOURNIER A, 1982, COMMUN ACM, V25, P371, DOI 10.1145/358523.358553; Mandelbrot, 1982, FRACTAL GEOMETRY NAT, P394; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; PENTLAND AP, 1986, IMAGE VISION COMPUT, V3, P153; Voss R. F., 1985, FUNDAMENTAL ALGORITH	6	97	98	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					704	707		10.1109/34.6779	http://dx.doi.org/10.1109/34.6779			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500010
J	Lu, CY; Feng, JS; Yan, SC; Lin, ZC				Lu, Canyi; Feng, Jiashi; Yan, Shuicheng; Lin, Zhouchen			A Unified Alternating Direction Method of Multipliers by Majorization Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unified frameworks of ADMM; mixed ADMM; majorization minimization; convex optimization	LOW-RANK; CONVERGENCE RATE; ALGORITHM; GRAPH	Accompanied with the rising popularity of compressed sensing, the Alternating Direction Method of Multipliers (ADMM) has become the most widely used solver for linearly constrained convex problems with separable objectives. In this work, we observe that many existing ADMMs update the primal variable by minimizing different majorant functions with their convergence proofs given case by case. Inspired by the principle of majorization minimization, we respectively present the unified frameworks of Gauss-Seidel ADMMs and Jacobian ADMMs, which use different historical information for the current updating. Our frameworks generalize previous ADMMs to solve the problems with non-separable objectives. We also show that ADMMs converge faster when the used majorant function is tighter. We then propose the Mixed Gauss-Seidel and Jacobian ADMM (M-ADMM) which alleviates the slow convergence issue of Jacobian ADMMs by absorbing merits of the Gauss-Seidel ADMMs. M-ADMM can be further improved by backtracking and wise variable partition. We also propose to solve the multi-blocks problems by Proximal Gauss-Seidel ADMM which is of the Gauss-Seidel type. It convegences for non-strongly convex objective. Experiments on both synthesized and real-world data demonstrate the superiority of our new ADMMs. Finally, we release a toolbox that implements efficient ADMMs for many problems in compressed sensing.	[Lu, Canyi; Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Lin, Zhouchen] Peking Univ, Key Lab Machine Percept MOE, Sch EECS, Beijing Shi 100000, Peoples R China; [Lin, Zhouchen] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Minhang Qu 200240, Peoples R China	National University of Singapore; Peking University; Shanghai Jiao Tong University	Lin, ZC (corresponding author), Peking Univ, Key Lab Machine Percept MOE, Sch EECS, Beijing Shi 100000, Peoples R China.; Lin, ZC (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Minhang Qu 200240, Peoples R China.	canyilu@gmail.com; elefjia@nus.edu.sg; eleyans@nus.edu.sg; zlin@pku.edu.cn	Feng, Jiashi/AGX-6209-2022; Yan, Shuicheng/HCI-1431-2022		National Natural Science Foundation (NSF) of China [61625301, 61231002]; National Basic Research Program of China (973 Program) [2015CB352502]; Ministry of Education of Singapore AcRF Tier One grant [R-263-000-C21-112]; National University of Singapore [R-263-000-008-133]	National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Ministry of Education of Singapore AcRF Tier One grant(Ministry of Education, Singapore); National University of Singapore(National University of Singapore)	J. Feng is partially supported by National University of Singapore startup grant R-263-000-008-133 and Ministry of Education of Singapore AcRF Tier One grant R-263-000-C21-112. Z. Lin is supported by National Basic Research Program of China (973 Program) (Grant no. 2015CB352502) and National Natural Science Foundation (NSF) of China (Grant nos. 61625301 and 61231002). Z. Lin is the corresponding author for this paper.	Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Chen C., 2013, MATH PROG, V155, P57; Chen YD, 2014, IEEE T INFORM THEORY, V60, P6440, DOI 10.1109/TIT.2014.2346205; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Deng WY, 2014, NEURAL NETWORKS, V53, P1, DOI 10.1016/j.neunet.2014.01.008; Deng W, 2016, J SCI COMPUT, V66, P889, DOI 10.1007/s10915-015-0048-x; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; Goldstein T, 2014, SIAM J IMAGING SCI, V7, P1588, DOI 10.1137/120896219; Han DR, 2012, J OPTIMIZ THEORY APP, V155, P227, DOI 10.1007/s10957-012-0003-z; He B., 2015, BLOCK WISE ALTERNATI; He BS, 2015, SIAM J OPTIMIZ, V25, P2274, DOI 10.1137/130922793; He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936; Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673; Hong M., 2012, MATH PROGRAM, V162, P1; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Liang X, 2012, LECT NOTES COMPUT SC, V7576, P482, DOI 10.1007/978-3-642-33715-4_35; Lin TY, 2015, J OPER RES SOC CHINA, V3, P251, DOI 10.1007/s40305-015-0092-0; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Lin Z., 2015, MACH LEARN, V99, P287, DOI DOI 10.1007/s10994-014-5469-5; Lin ZC, 2015, MACH LEARN, V99, P287, DOI 10.1007/s10994-014-5469-5; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Liu J., 2009, SLEP SPARSE LEARNING; Lu CY, 2016, AAAI CONF ARTIF INTE, P739; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P2833, DOI 10.1109/TIP.2016.2553459; Lu CY, 2013, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2013.170; Mairal J., 2011, SPAMS SPARSE MODELIN; Mairal J., 2013, P 30 INT C INT C MAC, P783; Nesterov Y., 2004, INTRO LECT CONVEX OP, V87; Ouyang Hua, 2013, P 30 INT C MACH LEAR, P80; Oymak S, 2015, IEEE T INFORM THEORY, V61, P2886, DOI 10.1109/TIT.2015.2401574; Robinson DP, 2015, J OPTIMIZ THEORY APP, V166, P137, DOI 10.1007/s10957-015-0708-x; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Wang XF, 2015, PAC J OPTIM, V11, P645; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xia RK, 2014, AAAI CONF ARTIF INTE, P2149; Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944	43	96	104	4	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					527	541		10.1109/TPAMI.2017.2689021	http://dx.doi.org/10.1109/TPAMI.2017.2689021			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28368818	Green Submitted			2022-12-18	WOS:000424465900002
J	Fu, K; Jin, JQ; Cui, RP; Sha, F; Zhang, CS				Fu, Kun; Jin, Junqi; Cui, Runpeng; Sha, Fei; Zhang, Changshui			Aligning Where to See and What to Tell: Image Captioning with Region-Based Attention and Scene-Specific Contexts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image captioning; visual attention; scene-specific context; LSTM	GRADIENTS	Recent progress on automatic generation of image captions has shown that it is possible to describe the most salient information conveyed by images with accurate and meaningful sentences. In this paper, we propose an image captioning system that exploits the parallel structures between images and sentences. In our model, the process of generating the next word, given the previously generated ones, is aligned with the visual perception experience where the attention shifts among the visual regions-such transitions impose a thread of ordering in visual perception. This alignment characterizes the flow of latent meaning, which encodes what is semantically shared by both the visual scene and the text description. Our system also makes another novel modeling contribution by introducing scene-specific contexts that capture higher-level semantic information encoded in an image. The contexts adapt language models for word generation to specific scene types. We benchmark our system and contrast to published results on several popular datasets, using both automatic evaluation metrics and human evaluation. We show that either region-based attention or scene-specific contexts improves systems without those components. Furthermore, combining these two modeling ingredients attains the state-of-the-art performance.	[Fu, Kun; Jin, Junqi] Univ Southern Calif, Los Angeles, CA 90089 USA; [Fu, Kun; Jin, Junqi; Cui, Runpeng; Zhang, Changshui] Tsinghua Univ, Dept Automat, State Key Lab Intelligence Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China; [Sha, Fei] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90085 USA; [Sha, Fei] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA	University of Southern California; Tsinghua University; University of California System; University of California Los Angeles; University of Southern California	Fu, K (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.; Fu, K (corresponding author), Tsinghua Univ, Dept Automat, State Key Lab Intelligence Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	fuk11@mails.tsinghua.edu.cn; jjq14@mails.tsinghua.edu.cn; crp13@mails.tsinghua.edu.cn; feisha@usc.edu; zcs@mail.tsinghua.edu.cn	CUI, Runpeng/AAK-3464-2020	Cui, Runpeng/0000-0002-4737-788X	Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD/ARL) [W911NF-12-C-0012]; ARO [W911NF-12-1-0241]; ONR [N000141210066]; US National Science Foundation [IIS-1065243, 1451412, 1513966, CCF-1139148]; Alfred P. Sloan Research Fellowship; 973 Program [2013CB329503]; NSFC [61621136008, 61473167]; German Research Foundation (DFG) [DFC TRR-169]	Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD/ARL); ARO; ONR(Office of Naval Research); US National Science Foundation(National Science Foundation (NSF)); Alfred P. Sloan Research Fellowship(Alfred P. Sloan Foundation); 973 Program(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC)); German Research Foundation (DFG)(German Research Foundation (DFG))	The authors would like to thank the reviewers for their valuable suggestions on improving this paper. FS acknowledges the partial support by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD/ARL) contract number W911NF-12-C-0012. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government. Additionally, FS is partially supported by ARO Young Investigator Award #W911NF-12-1-0241, ONR #N000141210066, US National Science Foundation Awards IIS-1065243, 1451412, 1513966, CCF-1139148, and an Alfred P. Sloan Research Fellowship. CZ acknowledges the funding by 973 Program (2013CB329503), NSFC (Grant No. 61621136008, and No. 61473167) and the German Research Foundation (DFG) in Project Crossmodal Learning DFC TRR-169.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chen X, 2015, CORR, V1504, P325; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100; Donahue J., 2014, P IEEE C COMP VIS PA, P2625; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Elliott Desmond, 2013, P 2013 C EMP METH NA, P1292; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277; Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kingma D.P, P 3 INT C LEARNING R; Kiros J. R., 2015, T ASS COMPUT LINGUIS; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162; Kuznetsova P., 2012, P 50 ANN M ASS COMPU, V1, P359; Kuznetsova Polina, 2014, T ASSOC COMPUT LING, V2, P351, DOI DOI 10.1162/TACL_A_00188; Li S., 2011, P 15 C COMPUTATIONAL, P220; Lin C.-Y., 2004, P ACL WORKSH TEXT SU, P26; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mitchell Margaret, 2012, EACL; Mnih V, 2014, ADV NEUR IN, V27; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Sutskever Ilya, 2011, P 28 INT C MACH LEAR; Taylor Graham, 2009, P 26 ANN INT C MACH, DOI DOI 10.1145/1553374.1553505; Theano Development Team, 2016, ARXIV160502688 THEAN; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29; Xu K, 2015, PR MACH LEARN RES, V37, P2048; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166	41	96	105	1	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2321	2334		10.1109/TPAMI.2016.2642953	http://dx.doi.org/10.1109/TPAMI.2016.2642953			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28026750	hybrid			2022-12-18	WOS:000414395400001
J	Zhou, MY; Carin, L				Zhou, Mingyuan; Carin, Lawrence			Negative Binomial Process Count and Mixture Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Beta process; Chinese restaurant process; completely random measures; count modeling; Dirichlet process; gamma process; hierarchical Dirichlet process; mixed-membership modeling; mixture modeling; negative binomial process; normalized random measures; Poisson factor analysis; Poisson process; topic modeling	MAXIMUM-LIKELIHOOD-ESTIMATION; CHAIN MONTE-CARLO; DIRICHLET; DISPERSION; ESTIMATORS; PARAMETER; INFERENCE	The seemingly disjoint problems of count and mixture modeling are united under the negative binomial (NB) process. A gamma process is employed to model the rate measure of a Poisson process, whose normalization provides a random probability measure for mixture modeling and whose marginalization leads to an NB process for count modeling. A draw from the NB process consists of a Poisson distributed finite number of distinct atoms, each of which is associated with a logarithmic distributed number of data samples. We reveal relationships between various count-and mixture-modeling distributions and construct a Poisson-logarithmic bivariate distribution that connects the NB and Chinese restaurant table distributions. Fundamental properties of the models are developed, and we derive efficient Bayesian inference. It is shown that with augmentation and normalization, the NB process and gamma-NB process can be reduced to the Dirichlet process and hierarchical Dirichlet process, respectively. These relationships highlight theoretical, structural, and computational advantages of the NB process. A variety of NB processes, including the beta-geometric, beta-NB, marked-beta-NB, marked-gamma-NB and zero-inflated-NB processes, with distinct sharing mechanisms, are also constructed. These models are applied to topic modeling, with connections made to existing algorithms under Poisson factor analysis. Example results show the importance of inferring both the NB dispersion and probability parameters.	[Zhou, Mingyuan] Univ Texas Austin, McCombs Sch Business, Dept Informat Risk & Operat Management, Austin, TX 78712 USA; [Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	University of Texas System; University of Texas Austin; Duke University	Zhou, MY (corresponding author), Univ Texas Austin, McCombs Sch Business, Dept Informat Risk & Operat Management, Austin, TX 78712 USA.	mingyuan.zhou@mccombs.utexas.edu; lcarin@ee.duke.edu	Zhou, Mingyuan/AAE-8717-2021	Carin, Lawrence/0000-0001-6277-7948				Aldous D., 1983, LECT NOTES MATH, V1117, P1, DOI [10.1007/BFb0099420, DOI 10.1007/BFB0099421.1072]; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Asuncion A., 2009, P 25 UAI MONTR QC CA; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BLISS CI, 1953, BIOMETRICS, V9, P176, DOI 10.2307/3001850; Bradlow ET, 2002, J COMPUT GRAPH STAT, V11, P189, DOI 10.1198/106186002317375677; Broderick T., 2012, ARXIV11111802V3; Buntine W., 2006, SUBSPACE LATENT STRU; Cameron A., 1998, REGRESSION ANAL COUN; Canny J., 2004, P SIGIR SHEFF UK; Damien P, 1999, J ROY STAT SOC B, V61, P331; DEAN C, 1989, CAN J STAT, V17, P171, DOI 10.2307/3314846; Dunson DB, 2005, BIOSTATISTICS, V6, P11, DOI 10.1093/biostatistics/kxh025; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Fox E., 2007, P2777 MIT LIDS; Greenwood, 1920, J R STAT SOC, V83, P255; Griffin JE, 2011, J COMPUT GRAPH STAT, V20, P241, DOI 10.1198/jcgs.2010.08176; Griffiths T. L., 2005, P NIPS; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; HJORT NL, 1990, ANN STAT, V18, P1259, DOI 10.1214/aos/1176347749; Hofmann T., 1999, P UAI STOCKH SWED; Ishwaran H, 2000, BIOMETRIKA, V87, P371, DOI 10.1093/biomet/87.2.371; Ishwaran H, 2002, CAN J STAT, V30, P269, DOI 10.2307/3315951; Ishwaran H., 2001, JASA, V96; Johnson NL, 2005, WILEY SER PROBAB ST, P1, DOI 10.1002/0471715816; Jordan M., 2010, FRONTIERS STAT DECIS; Kalli M, 2011, STAT COMPUT, V21, P93, DOI 10.1007/s11222-009-9150-y; Kingman J. F. C., 1993, POISSON PROCESSES; KINGMAN JFC, 1967, PAC J MATH, V21, P59, DOI 10.2140/pjm.1967.21.59; Knowles D., 2007, P 7 ICA LOND UK; LAWLESS JF, 1987, CAN J STAT, V15, P209, DOI 10.2307/3314912; Lee D. D., 2001, P NIPS; Li L., 2011, P 28 ICML WASH DC US; Lijoi A, 2007, J R STAT SOC B, V69, P715, DOI 10.1111/j.1467-9868.2007.00609.x; Lloyd-Smith JO, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000180; MacEachern SN, 1998, J COMPUT GRAPH STAT, V7, P223, DOI 10.2307/1390815; Miller K. T., 2011, THESIS UC BERKELEY; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Paisley J., 2009, P 26 ICML NEW YORK N; Paisley J., 2011, P 14 AISTATS FORT LA; Papaspiliopoulos O, 2008, BIOMETRIKA, V95, P169, DOI 10.1093/biomet/asm086; PIEGORSCH WW, 1990, BIOMETRICS, V46, P863, DOI 10.2307/2532104; PIETERS EP, 1977, BIOMETRICS, V33, P718, DOI 10.2307/2529470; Pitman J, 1997, ANN PROBAB, V25, P855; Pitman J, 2006, COMBINATORIAL STOCHA; QUENOUILLE MH, 1949, BIOMETRICS, V5, P162, DOI 10.2307/3001917; Robinson MD, 2008, BIOSTATISTICS, V9, P321, DOI 10.1093/biostatistics/kxm030; Saha K, 2005, BIOMETRICS, V61, P179, DOI 10.1111/j.0006-341X.2005.030833.x; Teh Y.W., 2010, ENCY MACHINE LEARNIN; Teh Y. W., 2007, P AISTATS; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Thibaux R., 2007, P AISTATS; Thibaux R. J., 2008, THESIS UC BERKELEY; Titsias M. K., 2008, P NIPS; Walker SG, 2007, COMMUN STAT-SIMUL C, V36, P45, DOI 10.1080/03610910601096262; Wallach H. M., 2009, P 26 ICML MONTR QC C; Wang C., 2011, P 14 AISTATS FORT LA; Williamson S., 2010, P 27 ICML HAIF ISR; WILLSON LJ, 1984, BIOMETRICS, V40, P109, DOI 10.2307/2530749; Winkelmann R, 2008, ECONOMETRIC ANAL COU; Wolpert RL, 1998, BIOMETRIKA, V85, P251, DOI 10.1093/biomet/85.2.251; Wolpert RL, 2011, ANN STAT, V39, P1916, DOI 10.1214/11-AOS889; Zhou M., 2012, P NIPS; Zhou M., 2010, P IEEE SAM JERS ISR; Zhou M., 2012, P 15 AISTATS LA PALM; Zhou M., 2012, P 29 ICML SCOTL UK; Zhou M., 2011, P 14 AISTATS FORT LA; Zhou M., 2009, P NIPS; Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072	71	96	96	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					307	320		10.1109/TPAMI.2013.211	http://dx.doi.org/10.1109/TPAMI.2013.211			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353243	Green Submitted			2022-12-18	WOS:000349625500008
J	Akata, Z; Perronnin, F; Harchaoui, Z; Schmid, C				Akata, Zeynep; Perronnin, Florent; Harchaoui, Zaid; Schmid, Cordelia			Good Practice in Large-Scale Learning for Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large scale; fine-grained visual categorization; image classification; ranking; SVM; stochastic learning	CLASSIFIERS	We benchmark several SVM objective functions for large-scale image classification. We consider one-versus-rest, multiclass, ranking, and weighted approximate ranking SVMs. A comparison of online and batch methods for optimizing the objectives shows that online methods perform as well as batch methods in terms of classification accuracy, but with a significant gain in training speed. Using stochastic gradient descent, we can scale the training to millions of images and thousands of classes. Our experimental evaluation shows that ranking-based algorithms do not outperform the one-versus-rest strategy when a large number of training examples are used. Furthermore, the gap in accuracy between the different algorithms shrinks as the dimension of the features increases. We also show that learning through cross-validation the optimal rebalancing of positive and negative examples can result in a significant improvement for the one-versus-rest strategy. Finally, early stopping can be used as an effective regularization strategy when training with online algorithms. Following these "good practices," we were able to improve the state of the art on a large subset of 10K classes and 9M images of ImageNet from 16.7 percent Top-1 accuracy to 19.1 percent.	[Akata, Zeynep; Perronnin, Florent] Xerox Res Ctr Europe, F-38240 Meylan, Isere, France; [Perronnin, Florent; Harchaoui, Zaid; Schmid, Cordelia] INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, Isere, France	Xerox	Akata, Z (corresponding author), Xerox Res Ctr Europe, 6 Chemin Maupertuis, F-38240 Meylan, Isere, France.	zeynep.akata@inria.fr	Akata, Zeynep/I-6018-2016	Akata, Zeynep/0000-0002-1432-7747	QUAERO project; OSEO; French State agency for innovation; European integrated project AXES; ERC grant ALLEGRO; GARGANTUA project; Mastodons program of CNRS	QUAERO project; OSEO; French State agency for innovation; European integrated project AXES; ERC grant ALLEGRO; GARGANTUA project; Mastodons program of CNRS	The INRIA LEAR team acknowledges financial support from the QUAERO project supported by OSEO, the French State agency for innovation, the European integrated project AXES, the ERC grant ALLEGRO and the GARGANTUA project funded by the Mastodons program of CNRS. The authors wish to warmly thank Matthijs Douze and Mattis Paulin for providing a public implementation of the online learning code described in this paper.	Allwein E.L., 2000, P INT C MACH LEARN I; Bai B., 2009, P 18 ACM C INF KNOWL; Bartlett P.L., 2003, P C NEUR INF PROC SY; Bengio S., 2010, P C NEUR INF PROC SY; Bengio Y., REPRESENTATION LEARN; Berg A., 2010, ILSVRC; Bergamo A., 2011, P C NEUR INF PROC SY; Beygelzimer A., 2005, P INT C MACH LEARN I; Bordes A., 2007, P INT C MACH LEARN I; Bottou L., 2013, SGD; Bottou L., 2007, P C NEUR INF PROC SY; Bourreau Y.-L., 2010, P IEEE C COMP VIS PA; Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, P5, DOI 10.1023/A:1008640732416; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Csurka G., 2004, P ECCV WORKSH STAT L; Dean J., 2012, P C NEUR INF PROC SY; Deng J., 2010, P 11 EUR C COMP VIS; Deng J., 2011, P C NEUR INF PROC SY; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deselaers T., 2011, P IEEE C COMP VIS PA; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farquhar J., 2005, TECHNICAL REPORT; Franc V., 2008, P INT C MACH LEARN I; Gao T., 2011, P IEEE INT C COMP VI; Gehrke J., 2000, P DAT MIN KNOWL DISC; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Grangier D., 2006, P 17 EUR C MACH LEAR; Hsieh C.-J., 2008, P INT C MACH LEARN I; Jarrett K., 2009, P IEEE INT C COMP VI; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Joachims T., 1999, MAKING LARGE SCALE S, P41, DOI 10.17877/DE290R-5098; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Le Q., 2012, INT C MACH LEARN, DOI DOI 10.1109/MSP.2011.940881; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; LeCun Y., 1989, P C NEUR INF PROC SY; LeCun Y., 2004, P IEEE C COMP VIS PA; Lee T., 2004, J AM STAT ASS; Li L., 2010, P C NEUR INF PROC SY; Lin Y., 2011, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2009, P IEEE INT C COMP VI; Marszalek M., 2008, P 10 EUR C COMP VIS; MEHTA M, 1996, P INT C EXT DAT TECH; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Perronnin F, 2007, P IEEE C COMP VIS PA; Perronnin F., 2010, P 11 EUR C COMP VIS; Perronnin F., 2010, P IEEE C COMP VIS PA; Perronnin F., 2012, P IEEE C COMP VIS PA; Platt J, 1999, ADV KERNEL METHODS; Rastegari M., 2011, P IEEE INT C COMP VI; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Rohrbach M., 2011, P IEEE C COMP VIS PA; Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Sanchez J., 2011, P IEEE C COMP VIS PA; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Sheskin D. J, 2007, HDB PARAMETRIC NONPA, VFourth; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134; Tewari A, 2007, J MACH LEARN RES, V8, P1007; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torresani L., 2010, P 11 EUR C COMP VIS; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Usunier N., 2009, P INT C MACH LEARN I; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vedaldi A., 2010, P IEEE C COMP VIS PA; Vedaldi A, 2012, PROC CVPR IEEE, P2320, DOI 10.1109/CVPR.2012.6247943; Vural V., 2004, P INT C MACH LEARN I; Wang G., 2009, P IEEE INT C COMP VI; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Weston J., 2010, P EUR C MACH LEARN E; Weston J., 1998, TECHNICAL REPORT; Weston J., 1999, P 7 EUR S ART NEUR N, P219; Weston Jason, 2011, 22 INT JOINT C ART I; Xu J., 2008, P 31 ANN INT ACM SIG; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yue Y., 2007, P 31 ANN INT ACM SIG; Zhao B., 2011, P C NEUR INF PROC SY; Zhou Z., 2010, P 11 EUR C COMP VIS	89	96	104	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					507	520		10.1109/TPAMI.2013.146	http://dx.doi.org/10.1109/TPAMI.2013.146			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457507	Green Submitted			2022-12-18	WOS:000331450100009
J	Litman, R; Bronstein, AM				Litman, R.; Bronstein, A. M.			Learning Spectral Descriptors for Deformable Shape Correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Diffusion geometry; heat kernel signature (HKS); wave kernel signature (WKS); descriptor; deformable shapes; correspondence; retrieval; spectral methods; Laplace-Beltrami operator; metric learning; Wiener filter; Mahalanobis distance	SIGNATURE	Informative and discriminative feature descriptors play a fundamental role in deformable shape analysis. For example, they have been successfully employed in correspondence, registration, and retrieval tasks. In recent years, significant attention has been devoted to descriptors obtained from the spectral decomposition of the Laplace-Beltrami operator associated with the shape. Notable examples in this family are the heat kernel signature (HKS) and the recently introduced wave kernel signature (WKS). The Laplacian-based descriptors achieve state-of-the-art performance in numerous shape analysis tasks; they are computationally efficient, isometry-invariant by construction, and can gracefully cope with a variety of transformations. In this paper, we formulate a generic family of parametric spectral descriptors. We argue that to be optimized for a specific task, the descriptor should take into account the statistics of the corpus of shapes to which it is applied (the "signal") and those of the class of transformations to which it is made insensitive (the "noise"). While such statistics are hard to model axiomatically, they can be learned from examples. Following the spirit of the Wiener filter in signal processing, we show a learning scheme for the construction of optimized spectral descriptors and relate it to Mahalanobis metric learning. The superiority of the proposed approach in generating correspondences is demonstrated on synthetic and scanned human figures. We also show that the learned descriptors are robust enough to be learned on synthetic data and transferred successfully to scanned shapes.	[Litman, R.; Bronstein, A. M.] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel	Tel Aviv University	Litman, R (corresponding author), Tel Aviv Univ, Sch Elect Engn, POB 39040, IL-69978 Tel Aviv, Israel.	roeelitm@post.tau.ac.il			Israeli Science Foundation; German-Israeli Foundation	Israeli Science Foundation(Israel Science Foundation); German-Israeli Foundation(German-Israeli Foundation for Scientific Research and Development)	This work was supported by the Israeli Science Foundation and the German-Israeli Foundation.	Aflalo J., 2011, P SCAL SPAC VAR METH; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396; Belongie S, 2001, ADV NEUR IN, V13, P831; Ben Hamza A, 2003, LECT NOTES COMPUT SC, V2886, P378; BERARD P, 1994, GEOM FUNCT ANAL, V4, P373, DOI 10.1007/BF01896401; Bronstein A., 2010, EUROGRAPHICS WORKSHO, P87; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405; Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6; Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Dey TK, 2010, COMPUT GRAPH FORUM, V29, P1545, DOI 10.1111/j.1467-8659.2010.01763.x; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5; He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KAC M, 1966, AM MATH MON, V73, P1, DOI 10.2307/2313748; Leordeanu M., 2010, P IEEE INT C COMP VI, V2, P1482; Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66; Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378; Manay S, 2004, LECT NOTES COMPUT SC, V2034, P87; Memoli Facundo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P256, DOI 10.1109/ICCVW.2009.5457690; Mitra N. J., 2006, S GEOM PROC, P121, DOI DOI 10.1145/1281957.1281973; Pauly M, 2003, COMPUT GRAPH FORUM, V22, P281, DOI 10.1111/1467-8659.00675; Raviv D., 2010, PROCEDINGS ACM WORKS, P39, DOI DOI 10.1145/1877808.1877817; Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Sharma A, 2010, P NORDIA WORKSH CVPR, P29; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; Skraba P., 2010, 2010 IEEE COMP SOC C, P45, DOI DOI 10.1109/CVPRW.2010.5543285; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Wang C., 2011, P INT C SCAL SPAC VA, P580; Weinberger K.Q., P ADV NEURAL INFORM, P1473; Weiss Y., 2008, P ADV NEUR INF PROC; Yang L., 2006, DISTANCE METRIC LEAR, P1, DOI 10.1073/pnas.0809777106	40	96	103	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					171	180		10.1109/TPAMI.2013.148	http://dx.doi.org/10.1109/TPAMI.2013.148			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231874				2022-12-18	WOS:000327965100014
J	Cho, TS; Zitnick, CL; Joshi, N; Kang, SB; Szeliski, R; Freeman, WT				Cho, Taeg Sang; Zitnick, C. Lawrence; Joshi, Neel; Kang, Sing Bing; Szeliski, Richard; Freeman, William T.			Image Restoration by Matching Gradient Distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonblind deconvolution; image prior; image deblurring; image denoising		The restoration of a blurry or noisy image is commonly performed with a MAP estimator, which maximizes a posterior probability to reconstruct a clean image from a degraded image. A MAP estimator, when used with a sparse gradient image prior, reconstructs piecewise smooth images and typically removes textures that are important for visual realism. We present an alternative deconvolution method called iterative distribution reweighting (IDR) which imposes a global constraint on gradients so that a reconstructed image should have a gradient distribution similar to a reference distribution. In natural images, a reference distribution not only varies from one image to another, but also within an image depending on texture. We estimate a reference distribution directly from an input image for each texture segment. Our algorithm is able to restore rich mid-frequency textures. A large-scale user study supports the conclusion that our algorithm improves the visual realism of reconstructed images compared to those of MAP estimators.	[Cho, Taeg Sang] WilmerHale LLP, Boston, MA 02139 USA; [Zitnick, C. Lawrence; Joshi, Neel; Kang, Sing Bing; Szeliski, Richard] Microsoft Res, Redmond, WA 98004 USA; [Freeman, William T.] MIT, Cambridge, MA 02139 USA	Microsoft; Massachusetts Institute of Technology (MIT)	Cho, TS (corresponding author), WilmerHale LLP, 60 State St, Boston, MA 02139 USA.	taegsang@gmail.com; larryz@microsoft.com; neel@microsoft.com; sbkang@microsoft.com; szeliski@microsoft.com; billf@mit.edu						Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272; Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Cho T.S., 2010, P IEEE C COMP VIS PA; Cho TS, 2010, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2010.5540214; Christoudias C.M., 2002, P IEEE 16 INT C PATT; Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778; Fergus R., 2006, P ACM SIGGR; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gonzalez R.C., 2008, DIGITAL IMAGE PROCES; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; HaCohen Y., 2010, P IEEE INT C COMP PH; Heeger D.J., 1995, P ACM SIGGR; JOSHI N, 2009, P IEEE C COMP VIS PA; Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778767; Kopf J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239453; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P61, DOI 10.1109/79.543976; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; Levin A., 2007, P ACM SIGGR; Li YZ, 2008, PROC SPIE, V6806, DOI 10.1117/12.784164; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Matheron G., 1975, RANDOM SETS INTEGRAL; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; ROSSI JP, 1978, SMPTE J, V87, P134, DOI 10.5594/J17407; Roth S., 2007, P IEEE 11 INT C COMP; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; SAAD Y, 1986, SIAM J SCI STAT COMP, V7, P856, DOI 10.1137/0907058; SCHMIDT U, 2010, P IEEE C COMP VIS PA; Simoncelli EP, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P379; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175; Woodford O.J., 2009, P 12 IEEE INT C COMP; Yuan L., 2007, P ACM SIGGR; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	41	96	107	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					683	694		10.1109/TPAMI.2011.166	http://dx.doi.org/10.1109/TPAMI.2011.166			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	21844632	Green Submitted, Green Published			2022-12-18	WOS:000300581700005
J	Chen, K; Wang, SH				Chen, Ke; Wang, Shihai			Semi-Supervised Learning via Regularized Boosting Working on Multiple Semi-Supervised Assumptions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semi-supervised learning; boosting framework; smoothness assumption; cluster assumption; manifold assumption; regularization		Semi-supervised learning concerns the problem of learning in the presence of labeled and unlabeled data. Several boosting algorithms have been extended to semi-supervised learning with various strategies. To our knowledge, however, none of them takes all three semi-supervised assumptions, i.e., smoothness, cluster, and manifold assumptions, together into account during boosting learning. In this paper, we propose a novel cost functional consisting of the margin cost on labeled data and the regularization penalty on unlabeled data based on three fundamental semi-supervised assumptions. Thus, minimizing our proposed cost functional with a greedy yet stagewise functional optimization procedure leads to a generic boosting framework for semi-supervised learning. Extensive experiments demonstrate that our algorithm yields favorite results for benchmark and real-world classification tasks in comparison to state-of-the-art semi-supervised learning algorithms, including newly developed boosting algorithms. Finally, we discuss relevant issues and relate our algorithm to the previous work.	[Chen, Ke; Wang, Shihai] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	University of Manchester	Chen, K (corresponding author), Univ Manchester, Sch Comp Sci, Kilburn Bldg,Oxford Rd, Manchester M13 9PL, Lancs, England.	chen@cs.manchester.ac.uk; shihai.wang@postgrad.manchester.ac.uk	Chen, Ke/C-2560-2008; , Ke/ABG-5874-2020	Chen, Ke/0000-0001-9457-9364; 				Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bengio Y., 2006, SEMISUPERVISED LEARN, P193, DOI [10.7551/mitpress/9780262033589.003.0011, DOI 10.7551/MITPRESS/9780262033589.003.0011]; Bennett K.P., 2002, P 8 ACM SIGKDD INT C, P289; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Blum A., 2001, P INT C MACH LEARN I, P19, DOI DOI 10.1184/R1/6606860.V1; BOUSQUET O, 2004, ADV NEURAL INFORM PR, V16; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chapelle O, 2005, P 10 INT WORKSH ART, V2005, P57; CHAPELLE O, 2003, ADV NEURAL INFORM PR, V15; Chapelle O, 2008, J MACH LEARN RES, V9, P203; Chawla N, 2005, J ARTIF INTELL RES, V23, P331, DOI 10.1613/jair.1509; CHEN K, 2007, ADV NEURAL INFORM PR, V20; Collins Michael, 1999, 1999 JOINT SIGDAT C; DALCHEBUC F, 2002, ADV NEURAL INFORM PR, V14; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; GRANDVALET Y, 2005, ADV NEURAL INFORM PR, V17; HAFFARI G, 2006, SURVEY INDUCTIVE SEM; HERTZ T, 2004, P INT C MACH LEARN; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Joachims T., 2003, P 20 INT C MACH LEAR, P290, DOI DOI 10.1145/2612669.2612699; KEGL B, 2005, ADV NEURAL INFORM PR, V16; LESKES B, 2005, P INT C COMP LEARN T, P95; Loeff N., 2008, P 25 INT C MACH LEAR, P600; Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235; MARTINEZ A, 1998, 24 CVC PURDUE U; Mason Llew, 2000, ADV LARGE MARGIN CLA; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Saffari A., 2009, P IEEE INT C COMP VI; SAFFARI A, 2008, P EUR C COMP VIS, P588; Seeger M., 2000, LEARNING LABELED UNL; SILAPACHOTE P, 2004, P IASTED INT C VIS I; Szummer M., 2001, ADV NEURAL INFORM PR, V15; SZUMMER M, 2003, ADV NEURAL INFORM PR, V15; *UCI, 2007, UCI MACH LEARN REP; VALIZADEGAN H, 2008, P EUR C MACH LEARN K, P588; Vapnik V.N, 1998, STAT LEARNING THEORY; Yip AM, 2006, IEEE T PATTERN ANAL, V28, P877, DOI 10.1109/TPAMI.2006.117; Zhou D., 2004, ADV NEURAL INFORM PR, V16; Zhu X., 2003, INT C MACH LEARN; ZHU X, 2005, TR1530 U WISCONSIN D; Zhu X., 2005, P 22 INT C MACH LEAR, P1052, DOI DOI 10.1145/1102351.1102484; Zou H, 2008, ANN APPL STAT, V2, P1290, DOI 10.1214/08-AOAS198	43	96	110	5	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					129	143		10.1109/TPAMI.2010.92	http://dx.doi.org/10.1109/TPAMI.2010.92			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	20421671				2022-12-18	WOS:000284277600010
J	Wang, Y; Loe, KF; Wu, JK				Wang, Y; Loe, KF; Wu, JK			A dynamic conditional random field model for foreground and shadow segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						conditional random fields; dynamic models; foreground segmentation; shadow detection	SURVEILLANCE; TRACKING	This paper proposes a dynamic conditional random field (DCRF) model for foreground object and moving shadow segmentation in indoor video scenes. Given an image sequence, temporal dependencies of consecutive segmentation fields and spatial dependencies within each segmentation field are unified by a dynamic probabilistic framework based on the conditional random field (CRF). An efficient approximate filtering algorithm is derived for the DCRF model to recursively estimate the segmentation field from the history of observed images. The foreground and shadow segmentation method integrates both intensity and gradient features. Moreover, models of background, shadow, and gradient information are updated adaptively for nonstationary background processes. Experimental results show that the proposed approach can accurately detect moving objects and their cast shadows even in monocular grayscale video sequences.	Nanyang Technol Univ, Sch Comp Sci, Singapore 637553, Singapore; Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore; Inst Infocomm Res, Singapore 119613, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; National University of Singapore; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)	Wang, Y (corresponding author), Nanyang Technol Univ, Sch Comp Sci, 5 Nanyang Dr, Singapore 637553, Singapore.	yang.wang@ieee.org; loekf@comp.nus.edu.sg; jiankang@i2r.a-star.edu.sg		Wang, Yang/0000-0002-6815-0879				BESAG J, 1986, J R STAT SOC B, V48, P259; Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Doretto G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1236; Friedman N., 1997, P C UNC ART INT AUG, P175, DOI DOI 10.1016/J.CVIU.2007.08.003; Gordon G, 1999, P IEEE C COMP VIS PA, P2459, DOI [10.1109/CVPR.1999.784721, DOI 10.1109/CVPR.1999.784721]; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; HORPRASERT T, 1999, P FRAME RATE WORKSH; Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263; Jabri S, 2000, INT C PATT RECOG, P627, DOI 10.1109/ICPR.2000.902997; KAMIJO S, 2001, P EMMCVPR WORKSH, P298; KOLLER D, 1994, INT C PATT RECOG, P126, DOI 10.1109/ICPR.1994.576243; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Li S. Z., 2001, COMP SCI W; McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870; Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341; Paragios N, 2001, PROC CVPR IEEE, P1034; Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520; Rittscher J., 2000, PROC EUR C COMPUT VI, P336; Seki M, 2003, PROC CVPR IEEE, P65; Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; STENGER B, 2001, P IEEE INT C COMP VI, V1, P294, DOI DOI 10.1109/ICCV.2001.10008; TOYAMA K, 1999, P IEEE INT C COMP VI, V1, P255, DOI DOI 10.1109/ICCV.1999.791228; Wang Y, 2005, PATTERN RECOGN, V38, P1937, DOI 10.1016/j.patcog.2005.02.006; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236	27	96	123	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					279	289		10.1109/TPAMI.2006.25	http://dx.doi.org/10.1109/TPAMI.2006.25			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468623				2022-12-18	WOS:000233824500009
J	Gori, M; Maggini, M; Sarti, L				Gori, M; Maggini, M; Sarti, L			Exact and approximate graph matching using random walks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						exact graph matching; approximate graph matching; random walks; PageRank; image retrieval	ALGORITHM	In this paper, we propose a general framework for graph matching which is suitable for different problems of pattern recognition. The pattern representation we assume is at the same time highly structured, like for classic syntactic and structural approaches, and of subsymbolic nature with real- valued features, like for connectionist and statistic approaches. We show that random walk based models, inspired by Google's PageRank, give rise to a spectral theory that nicely enhances the graph topological features at node level. As a straightforward consequence, we derive a polynomial algorithm for the classic graph isomorphism problem, under the restriction of dealing with Markovian spectrally distinguishable graphs ( MSD), a class of graphs that does not seem to be easily reducible to others proposed in the literature. The experimental results that we found on different test- beds of the TC- 15 graph database show that the defined MSD class " almost always" covers the database, and that the proposed algorithm is significantly more efficient than top scoring VF algorithm on the same data. Most interestingly, the proposed approach is very well- suited for dealing with partial and approximate graph matching problems, derived for instance from image retrieval tasks. We consider the objects of the COIL- 100 visual collection and provide a graph- based representation, whose node's labels contain appropriate visual features. We show that the adoption of classic bipartite graph matching algorithms offers a straightforward generalization of the algorithm given for graph isomorphism and, finally, we report very promising experimental results on the COIL- 100 visual collection.	Univ Siena, DII, I-53100 Siena, Italy	University of Siena	Gori, M (corresponding author), Univ Siena, DII, Via Roma,56, I-53100 Siena, Italy.	marco@dii.unisi.it; maggini@dii.unisi.it; sarti@dii.unisi.it						BIANCHINI M, 2005, ACM T INTERNET TECHN; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Cordella L. P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P1172, DOI 10.1109/ICIAP.1999.797762; DEJONG KA, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P124; DEMAURO C, 2001, P 3 IAPR TC15 WORKSH, P250; Depiero F, 1996, PATTERN RECOGN, V29, P1031, DOI 10.1016/0031-3203(95)00140-9; Diligenti M, 2004, IEEE T KNOWL DATA EN, V16, P4, DOI 10.1109/TKDE.2004.1264818; Diligenti M., 2003, P INT JOINT C ART IN, P575; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; Foggia P., 2001, P 3 IAPR TC 15 WORKS, P188; Foggia P., 2001, P 3 IAPR TC 15 INT W, P176; GABOW HN, 1989, SIAM J COMPUT, V18, P1013, DOI 10.1137/0218069; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; McKay B. D., 1981, C NUMERANTIUM, V30, P45, DOI DOI 10.1016/J.JSC.2013.09.003; Nayar SK, 1996, IEEE INT CONF ROBOT, P2321, DOI 10.1109/ROBOT.1996.506510; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Page L., 1999, STANFORD INFOLAB; PARULO L, 1974, SYSTEM THEORY UNIFIE; PASINI A, 2004, 2 MATRICES RELATED T; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; SCHMIDT DC, 1976, J ACM, V23, P433, DOI 10.1145/321958.321963; Seneta E, 1981, NONNEGATIVE MATRICES; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Varadarajan KR, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P805	26	96	101	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1100	1111		10.1109/TPAMI.2005.138	http://dx.doi.org/10.1109/TPAMI.2005.138			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013757				2022-12-18	WOS:000229024300009
J	Golfarelli, M; Maio, D; Maltoni, D				Golfarelli, M; Maio, D; Maltoni, D			On the error-reject trade-off in biometric verification systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometric verification systems; statistical pattern recognition; Bayes error rate; rejection error rate; hand geometry; human face		In this work, we address the problem of performance evaluation in biometric verification systems. By formulating the optimum Bayesian decision criterion for a verification system and by assuming the data distributions to be multinormals, we derive two statistical expressions for calculating theoretically the false acceptance and false rejection rates. Generally, the adoption of a Bayesian parametric model does not allow for obtaining explicit expressions for the calculation of the system errors. As far as biometric verification systems are concerned, some hypotheses can be reasonably adopted, thus allowing simple and affordable expressions to be derived. By using two verification system prototypes, based on hand shape and human face, respectively, we show our results are well founded.	UNIV BOLOGNA, CNR, CSITE, DEIS, I-40136 BOLOGNA, ITALY	Consiglio Nazionale delle Ricerche (CNR); University of Bologna	Golfarelli, M (corresponding author), UNIV BOLOGNA, CORSO LAUREA SCI INFORMAZ, VIA SACCHI 3, I-47023 CESENA, FO, ITALY.							CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 1973, J ROYAL STAT SOC SER; ELLIS HD, 1986, NATO ASI SERIES, V28; FUKUNAGA K, 1990, STAT PATTERN RECOGNI, P90; Galton Francis, 1892, FINGER PRINTS; Goldstein A. J., 1971, P IEEE, V59; Grenander U., 1991, HANDS PATTERN THEORE; JENNINGS C, 1992, SENSOR REV, V12, P9; JOHNSON NL, 1972, DISTRIBUTIONS STATIS; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MESSERI P, 1972, ANTROPOLOGIA VIVENTE; MILLER B, 1994, IEEE SPECTRUM, V31, P22, DOI 10.1109/6.259484; Noether G.E., 1967, ELEMENT NONPARAMETRI; OSTERBURG J W, 1964, J Forensic Sci, V9, P413; OSTERBURG JW, 1977, J AM STAT ASSOC, V72, P772; SING IP, 1968, ANTHROPOMETRY; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71	20	96	97	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1997	19	7					786	796		10.1109/34.598237	http://dx.doi.org/10.1109/34.598237			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM693					2022-12-18	WOS:A1997XM69300014
J	Mohamed, M; Gader, P				Mohamed, M; Gader, P			Handwritten word recognition using segmentation-free hidden Markov modeling and segmentation-based dynamic programming techniques	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hidden Markov models; dynamic programming; handwritten word recognition; character recognition; neural networks; character segmentation		A lexicon-based, handwritten word recognition system combining segmentation-free and segmentation-based techniques is described. The segmentation-free technique constructs a continuous density hidden Markov model for each lexicon string. The segmentation-based technique uses dynamic programming to match word images and strings. The combination module uses differences in classifier capabilities to achieve significantly better performance.			Mohamed, M (corresponding author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65211, USA.							[Anonymous], 1992, P US POST SERV ADV T, P199; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; CHEN M, 1992, P US POST SERV ADV T, P563; Chen MY., 1993, P 3 INT WORKSH FRONT, P82; CHIANG JH, 1995, THESIS U MISSOURI CO; DOUGHERTY ER, 1992, INTRO MORPHOLOGIC TT, V9; DUDERSTADT RA, 1990, P US POST SERV ADV T, P233; GADER P, 1995, IEEE T FUZZY SYST, V3, P357, DOI 10.1109/91.413223; GADER P, 1995, MACH VISION APPL, V8, P31, DOI 10.1007/BF01213636; GADER PD, 1992, P ART NEUR NETW ENG, P421; GADER PD, 1992, P 5 USPS ADV TECHN C, P215; GADER PD, 1994, DIGITAL IMAGE PROCES, P223; GADER PD, IN PRESS IEEE T SYSM; GADER PD, 1990, ADV RES HANDWRITTEN; GADER PD, UNPUB NEURAL FUZZY M; GADER PD, 1992, P N AM FUZZ INF PROC, P257; GILLIES A, 1992, UNPUB SYSTEM RECOGNI; GILLIES A, 1992, P US POST SERV ADV T, P557; GILLIES AM, 1990, P US POST SERV ADV T, P247; Ho T. K., 1991, P 1 INT C DOC AN REC, P905; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; HO TK, 1990, P US POST SERV ADV T, P207; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P481; KIMURA F, 1993, P 3 INT WORKSH FRONT, P122; Lecolinet E., 1991, P 1 INT C DOC AN REC, P740; MOHAMED MA, 1995, THESIS U MISSOURI CO; Nobuyuki O., 1979, IEEE T SYSTEMS MAN C, VSMC-9; NOHL C, 1992, P US POSTAL SERVICE, P167; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; 1992, P US POST SERV ADV T; 1991, P INT C DOC AN REC S; 1993, P 3 INT WORKSH FRONT	33	96	107	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					548	554		10.1109/34.494644	http://dx.doi.org/10.1109/34.494644			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100007
J	ROCHA, J; PAVLIDIS, T				ROCHA, J; PAVLIDIS, T			A SHAPE-ANALYSIS MODEL WITH APPLICATIONS TO A CHARACTER-RECOGNITION SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE DISTANCE; GRAPH MATCHING; RELATIVE NEIGHBORHOOD GRAPH; BROKEN CHARACTER RECOGNITION; SUBGRAPH HOMEOMORPHISM	CHINESE-CHARACTERS; RELAXATION; GRAPH	A method for the recognition of multifont printed characters is proposed, giving emphasis to the identification of structural descriptions of character shapes using prototypes. Noise and shape variations are modeled as series of transformations from groups of features in the data to features in each prototype. Thus, the method manages systematically the relative distortion between a candidate shape and its prototype, accomplishing robustness to noise with less than two prototypes per class, on average. Our method uses a flexible matching between components and a flexible grouping of the individual components to be matched. A number of shape transformations are defined, including filling of gaps, so that the method handles broken characters. Also, a measure of the amount of distortion that these transformations cause is given. Classification of character shapes is defined as a minimization problem among the possible transformations that map an input shape into prototypical shapes. Some tests with hand-printed numerals confirmed the method's high robustness level.	SUNY STONY BROOK,DEPT COMP SCI,STONY BROOK,NY 11794; SUNY STONY BROOK,IMAGE ANAL LAB,STONY BROOK,NY 11794	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	ROCHA, J (corresponding author), UNIV ILLES BALEARS,PALMA DE MALLORCA,SPAIN.		Rocha, Jairo/K-9850-2014	Rocha, Jairo/0000-0002-8810-7376				BOKSER M, 1992, P IEEE, V80, P1066, DOI 10.1109/5.156470; BURR D, 1980, 5TH P INT C PATT REC, P223; Garey M.R., 1979, COMPUTERS INTRACTABI; HARAY F, 1972, GRAPH THEORY, P107; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; PEARL J, 1984, HEURISTICS INTELLIGE, P44; PINTSOV L, 1992, FEB SPIE ISTS S EL I, P115; Rice S. V., 1992, REPORT ACCURACY OCR; ROBERTSON N, 1985, SIAM J ALGEBRA DISCR, V6, P300, DOI 10.1137/0606030; SAKODA WJ, 1992, 5TH ADV TECHN C WASH, P727; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; XIE SL, 1988, PATTERN RECOGN, V21, P1, DOI 10.1016/0031-3203(88)90066-0; Yamada H., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P389; [No title captured]	20	96	98	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					393	404		10.1109/34.277592	http://dx.doi.org/10.1109/34.277592			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700005
J	KANATANI, K				KANATANI, K			STATISTICAL BIAS OF CONIC FITTING AND RENORMALIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CONIC; ELLIPSE; CURVE FITTING; ERROR ANALYSIS; RENORMALIZATION	ELLIPSES; MOTION; CURVES; PLANE; POSE	Introducing a statistical model or noise in terms of the covariance matrix of the N-vector, we point out that the least-squares conic fitting is statistically biased. We present a new fitting scheme called renormalization for computing an unbiased estimate by automatically adjusting to noise. Relationships to existing methods are discussed, and our method is tested using real and synthetic data.			KANATANI, K (corresponding author), GUNMA UNIV,DEPT COMP SCI,KIRYU,GUNMA 376,JAPAN.							Albano A., 1974, COMPUT VISION GRAPH, V3, P23, DOI [10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2CGIPBG0146-664X]; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; DAVIES ER, 1989, PATTERN RECOGN LETT, V9, P87, DOI 10.1016/0167-8655(89)90041-X; ELLIS T, 1992, IMAGE VISION COMPUT, V10, P271, DOI 10.1016/0262-8856(92)90041-Z; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; GNANADESIKAN R, 1977, METHODS STATISTICAL; KANATANI K, 1991, CVGIP-IMAG UNDERSTAN, V54, P333, DOI 10.1016/1049-9660(91)90034-M; KANATANI K, 1993, IEEE T PATTERN ANAL, V15, P37, DOI 10.1109/34.184773; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KANATANI K, CVGIP-IMAG UNDERSTAN, V58, P2836; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P133, DOI 10.1016/0031-3203(79)90059-1; PATON K, 1970, PATTERN RECOGN, V2, P39, DOI 10.1016/0031-3203(70)90040-3; PORRILL J, 1990, IMAGE VISION COMPUT, V8, P37, DOI 10.1016/0262-8856(90)90054-9; PRATT V, 1987, ACM SIGGRAPH, V21, P145; ROTHWELL CA, 1992, IMAGE VISION COMPUT, V10, P250, DOI 10.1016/0262-8856(92)90056-9; SAFAEERAD R, 1991, CVGIP-IMAG UNDERSTAN, V54, P259, DOI 10.1016/1049-9660(91)90067-Y; SAFAEERAD R, 1992, IEEE T ROBOTIC AUTOM, V8, P624, DOI 10.1109/70.163786; SAFAEERED R, 1992, IMAGE VISION COMPUT, V19, P532; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; Semple J.G, 1952, ALGEBRAIC PROJECTIVE	22	96	99	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					320	326		10.1109/34.276132	http://dx.doi.org/10.1109/34.276132			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400012
J	ROSE, K; GUREWITZ, E; FOX, GC				ROSE, K; GUREWITZ, E; FOX, GC			CONSTRAINED CLUSTERING AS AN OPTIMIZATION METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ANNEALING; CLUSTERING; MAXIMUM ENTROPY; NEURAL NETWORKS; NONCONVEX OPTIMIZATION; SELF-ORGANIZATION	ADAPTIVE PATTERN-CLASSIFICATION; ALGORITHMS	Our deterministic annealing approach to clustering is derived on the basis of the principle of maximum entropy, is independent of the initial state, and produces natural hierarchical clustering solutions by going through a sequence of phase transitions. This approach is modified here for a larger class of optimization problems by adding constraints to the free energy. The concept of constrained clustering is explained, and then, three examples are given in which it is used as means to introduce deterministic annealing. First, the previous clustering method is improved by adding cluster mass variables and a total mass constraint. Second, the traveling salesman problem (TSP) is reformulated as constrained clustering, yielding the elastic net (EN) approach to the problem. More insight is gained by identifying a second Lagrange multiplier that is related to the tour length and can also be used to control the annealing process. Finally, the ''open path'' constraint formulation is shown to relate to dimensionality reduction by self-organization in unsupervised learning. A similar annealing procedure is applicable in this case as well.	NUCL RES CTR NEGEV,DEPT PHYS,IL-84190 BEER SHEVA,ISRAEL; SYRACUSE UNIV,NE PARALLEL ARCHITECTURES CTR,SYRACUSE,NY 13244	Syracuse University	ROSE, K (corresponding author), UNIV CALIF SANTA BARBARA,DEPT ELECT & COMP ENGN,SANTA BARBARA,CA 93106, USA.							ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964; CHANG PC, 1986, IEEE T ACOUST SPEECH, V34, P679, DOI 10.1109/TASSP.1986.1164905; DUDA RO, 1974, PATTERN CLASSIFICATI; Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; DURBIN R, 1990, NATURE, V343, P644, DOI 10.1038/343644a0; Durbin R, 1989, NEURAL COMPUT, V1, P348, DOI 10.1162/neco.1989.1.3.348; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1111/j.1551-6708.1987.tb00862.x; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; GROSSBERG S, 1976, BIOL CYBERN, V23, P121, DOI 10.1007/BF00344744; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jaynes E.T., 1989, PAPERS PROBABILITY S; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kohonen T, 1984, SELF ORG ASS MEMORY; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Reklaitis G.V., 1983, ENG OPTIMIZATION; ROSE K, 1992, IEEE T INFORM THEORY, V38, P1249, DOI 10.1109/18.144705; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; Simic PD, 1990, NETWORK-COMP NEURAL, V1, P89, DOI 10.1088/0954-898X/1/1/007; Tsirukis AG, 1989, NEURAL COMPUT, V1, P511, DOI 10.1162/neco.1989.1.4.511; Van Laarhoven P.J., 1987, SIMULATED ANNEALING, P7; Weaver W., 1949, MATH THEORY INFORM; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1	28	96	102	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					785	794		10.1109/34.236251	http://dx.doi.org/10.1109/34.236251			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800003
J	PARKER, JR				PARKER, JR			GRAY LEVEL THRESHOLDING IN BADLY ILLUMINATED IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						GRADIENT; ILLUMINATION; IMAGE PROCESSING; SEGMENTATION; THRESHOLDING		Most gray level thresholding methods produces very good results in situations where the illumination gradient in the original raster image is regular and not too large. In other cases, such as a large linear change in illumination, a satisfactory bilevel image cannot be produced. One approach is to locate object pixels first, and then grow regions around these, generating a threshold value for each pixel. It can be assumed with a high degree of assurance that pixels at locations having a high gray level gradient form a part of an object, and that nearby pixels with similar gray levels will also be part of the same object. If regions are grown carefully, a threshold image will result.			PARKER, JR (corresponding author), UNIV CALGARY, DEPT COMP SCI, CALGARY T2N 1N4, ALBERTA, CANADA.							BRACHO R, 1985, JUN P IEEE COMP SOC, P341; BRINK AD, 1989, PATTERN RECOGN LETT, V9, P335, DOI 10.1016/0167-8655(89)90062-7; CASTLEMAN K, 1973, NOBEL S, V23; CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5; HARALICK RM, 1983, FUNDAMENTALS COMPUTE; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PEREZ A, 1987, IEEE T PATTERN ANAL, V9, P742, DOI 10.1109/TPAMI.1987.4767981; Pratt W. K., 1978, DIGITAL IMAGE PROCES; Prewitt J., 1970, PICTURE PROCESSING P, VVolume 10; RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039; STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; WALL RJ, 1974, THESIS U CALIFORNIA; Wilson R., 1988, IMAGE SEGMENTATION U	14	96	112	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					813	819		10.1109/34.85672	http://dx.doi.org/10.1109/34.85672			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200007
J	WANG, LL; TSAI, WH				WANG, LL; TSAI, WH			CAMERA CALIBRATION BY VANISHING LINES FOR 3-D COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						CAMERA CALIBRATION; COMPUTER VISION; VANISHING LINE; VANISHING POINT		A new approach to camera calibration by vanishing lines is proposed. Calibrated parameters include the orientation, the position, and the focal length of a camera. A hexagon is employed as the calibration target to generate a vanishing line of the ground plane from its projected image. It is shown that the vanishing line includes useful geometric hints about the camera orientation parameters and the focal length, from which the orientation parameters can be solved easily and analytically. And the camera position parameters can be calibrated by the use of related geometric projective relationships. The simplicity of the target eliminates the complexity of the environment setup and simplifies the feature extraction in relevant image processing. The calibration formulas are also simple to compute. Experimental results show the feasibility of the proposed approach.	NATL CHIAO TUNG UNIV,DEPT COMP & INFORMAT SCI,HSINCHU 30050,TAIWAN	National Yang Ming Chiao Tung University	WANG, LL (corresponding author), NATL CHIAO TUNG UNIV,INST COMP SCI & INFORMAT ENGN,HSINCHU 30050,TAIWAN.							CHOU HL, 1986, PATTERN RECOGN, V19, P439, DOI 10.1016/0031-3203(86)90042-7; COURTNEY JW, 1984, PATTERN RECOGN, V17, P585, DOI 10.1016/0031-3203(84)90012-8; DHOME M, 1988, JUN P IEEE COMP VIS, P61; FAIG W, 1975, PHOTOGRAMM ENG REM S, V41, P1479; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Foley J. D., 1982, FUNDAMENTALS INTERAC, P2; FUKUI I, 1981, PATTERN RECOGN, V14, P101, DOI 10.1016/0031-3203(81)90050-9; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P191, DOI 10.1016/0146-664X(80)90046-5; LIOU SP, 1987, COMPUT VISION GRAPH, V39, P116, DOI 10.1016/S0734-189X(87)80205-0; Magee M. J., 1984, International Conference on Robotics, P140; QUAN L, 1988, INT C COMPUTER VISIO, P679; SHAFER SA, 1982, 1982 IEEE WORKSH COM, P26; SOBEL I, 1974, ARTIF INTELL, V5, P185, DOI 10.1016/0004-3702(74)90029-0; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1	15	96	127	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					370	376						7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600007
J	PRADE, H				PRADE, H			A COMPUTATIONAL APPROACH TO APPROXIMATE AND PLAUSIBLE REASONING WITH APPLICATIONS TO EXPERT SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PRADE, H (corresponding author), UNIV TOULOUSE 3, F-31062 TOULOUSE, FRANCE.							ADAMO JM, 1980, FUZZY SET SYST, V3, P151, DOI 10.1016/0165-0114(80)90052-4; ADAMO JM, 1980, FUZZY SET SYST, V3, P261, DOI 10.1016/0165-0114(80)90024-X; Adams E., 1975, SYNTHESE, V30, P429, DOI 10.1007/BF00485053; ADAMS JB, 1976, MATH BIOSCI, V32, P177, DOI 10.1016/0025-5564(76)90064-X; Adlassnig K.P., 1982, P219; ALSINA C, BUSEFAL3 LSI U P SAB, P18; Baldwin J., 1979, ADV FUZZY SET THEORY, P93; Baldwin J. F., 1979, Fuzzy Sets and Systems, V2, P309, DOI 10.1016/0165-0114(79)90004-6; BALDWIN JF, 1980, FUZZY SET SYST, V3, P225, DOI 10.1016/0165-0114(80)90022-6; BALDWIN JF, 1980, SYNTHESE, V44, P397, DOI 10.1007/BF00413469; BALDWIN JF, 1980, KYBERNETES, V9, P223, DOI 10.1108/eb005560; BALDWIN JF, 1979, INT J MAN MACH STUD, V11, P351, DOI 10.1016/S0020-7373(79)80030-9; BALDWIN JF, 1979, INT J MAN MACH STUD, V11, P447, DOI 10.1016/S0020-7373(79)80037-1; BALDWIN JF, 1979, INT J MAN MACH STUD, V11, P397, DOI 10.1016/S0020-7373(79)80032-2; BALDWIN JF, 1979, INT J MAN MACH STUD, V11, P381, DOI 10.1016/S0020-7373(79)80031-0; BALDWIN JF, 1979, INT J MAN MACH STUD, V11, P465, DOI 10.1016/S0020-7373(79)80038-3; BALDWIN JF, 1980, FUZZY SET SYST, V3, P193, DOI 10.1016/0165-0114(80)90054-8; BALDWIN JF, 1981, APPLIED SYSTEMS CYBE, V6, P2859; BALDWIN JF, 1982, FUZZY SET POSSIBILIT, P169; BALDWIN JF, 1983, 13TH IEEE INT S MULT; BALDWIN JF, 1983, INTRO FRIL FUZZY REL; BALDWIN JF, 1979, 9TH P IEEE INT C MUL, P38; BALDWIN JF, 1981, 11TH INT SY MULT VAL, P100; BANDLER W, 1980, FUZZY SET SYST, V4, P13, DOI 10.1016/0165-0114(80)90060-3; BANDLER W, 1980, INT J MAN MACH STUD, V12, P89, DOI 10.1016/S0020-7373(80)80055-1; BANDLER W, 1983, BUSEFAL          PRI, P105; BANDLER W, 1984, CYBERNET SYST, V2, P581; BANON G, 1981, FUZZY SET SYST, V5, P291, DOI 10.1016/0165-0114(81)90057-9; BARNETT JA, 1981, 7TH P INT JOINT C AR, P868; BELLMAN RE, 1977, MODERN USES MULTIPLE, P103, DOI DOI 10.1007/978-94-010-1161-7; BONISSONE PP, 1983, 2ND WORKSH N AM FUZZ; BONISSONE PP, 1982, THEORY PRACTICE KNOW, P68; BOUCHON B, 1983, 5TH INT SEM FUZZ SET; BOUCHON B, 1983, SEP ACT JOURN UT INF; BOURELLY L, 1983, JUL P IFAC S FUZZ IN, P135; CANTONE RR, 1983, 8TH P INT JOINT C AR, P207; CATLETT J, ACCOUNTING CONFLICT, P8; CAYROL M, 1982, KYBERNETES, V11, P103, DOI 10.1108/eb005612; CAYROL M, 1980, 9TH P INT C CYB NAM, P53; CAYROL M, 1980, 10TH P IEEE INT C MU, P143; CAYROL M, 1982, COMPUT ARTIF INTELL, V1, P47; CHOURAQUI E, 1982, JUL P EUR C ART INT, P48; COHEN PR, 1983, 8TH P INT JOINT C AR, P355; COLBY KM, 1969, P INT JOINT C ARTIF, P319; COLLINS A, 1978, P C THEORETICAL ISSU, V2, P194; COLLINS A, 1978, 3810 BOLT BER NEWM R, P122; COULON D, 1982, CRIN82R058 TECH REP; DEMANTARAS RL, 1980, JUN CNRS ROUND TABL; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205; DESILVA O, 1982, 12TH P IEEE INT S MU, P267; DOYLE J, 1979, ARTIF INTELL, V12, P231, DOI 10.1016/0004-3702(79)90008-0; DOYLE J, 1983, AI MAG, V4, P39; DUBOIS D, 1983, FUZZY SET SYST, V10, P15, DOI 10.1016/S0165-0114(83)80099-2; DUBOIS D, 1981, IEEE T AUTOMAT CONTR, V26, P926, DOI 10.1109/TAC.1981.1102744; DUBOIS D, 1982, INT J GEN SYST, V8, P43, DOI 10.1080/03081078208934833; DUBOIS D, 1979, INFORM CONTROL, V43, P224, DOI 10.1016/S0019-9958(79)90730-7; DUBOIS D, UNPUB INT J GEN SYST; DUBOIS D, UNPUB ANAL FUZZY INF; DUBOIS D, 1984, BUSEFAL18 LSI U P SA, P33; DUBOIS D, 1982, 4TH P INT SEM FUZZ S; DUBOIS D, 1984, 10TH P TRIENN IFORS, P949; DUBOIS D, 1984, CYBERNET SYST, V15, P87; DUBOIS D, 1985, APPROXIMATE REASONIN; Dubois D., 1980, MATH SCI ENG SERIES, V144; DUBOIS D, 1985, UNPUB THEORIE POSSIB; DUBOIS D, 1984, 1983 P IEEE INT C CY, P300; DUBOIS D, UNPUB FUZZY SETS SYS; DUBOIS D, UNPUB AUTOMATICA; DUBOIS D, 1983, JUL P IFAC S FUZZ IN; Dubois D., 1982, FUZZY INFORM DECISIO, P167; DUBOIS D, 1983, J FUZZY MATH HUAZHON, V3; DUBOIS D, 1982, 2ND P WORLD C MATH S, P262; Duda R., 1981, EXPERT SYSTEMS MICRO, P153; DUDA RO, 1976, 124 SRI INT TECH NOT, P22; EFSTATHIOU J, 1984, FUZZY SET SYST, V13, P201; ERNST C, 1982, BUSEFAL9 LSI U P SAB, P93; ERNST C, 1982, APPLIED SYSTEMS CYBE, P196; EZHKOVA IV, 1978, ENG CYBERN, V16, P1; FARRENY H, 1981, NOV ACT C AFCET INF, P283; FARRENY H, 1984, OCT INT C ART INT MA; FARRENY H, 1982, JUL P EUR C ART INT, P43; FARRENY H, 1982, 2ND P WORLD C MATH S, P281; FIESCHI M, 1982, APPROXIMATE REASONIN, P269; FIESCHI M, 1984, SYSTEMES EXPERTS; FOX J, 1981, INT J MAN MACH STUD, V15, P213, DOI 10.1016/S0020-7373(81)80004-1; FOX MS, 1981, AUG P INT JOINT C AR, P313; Frank M.J., 1979, AEQUATIONES MATH, V19, P194, DOI DOI 10.1007/BF02189866; FREKSA C, 1980, AISB C AMSTERDAM; FREKSA C, UCBERL M8010 U CAL M; FRIEDMAN L, 1981, 7TH P INT JOINT C AR, P487; FRIEDMAN L, 1979, JPL7911 PUB, P23; FRIEDMAN L, 1980, 1ST P ANN NAT C ART, P292; FRIEDMAN L, 1980, 5EME ACT C DEM AUT A; FUKAMI S, 1980, FUZZY SET SYST, V4, P243, DOI 10.1016/0165-0114(80)90014-7; GAINES BR, 1975, ELECTRON LETT, V11, P188, DOI 10.1049/el:19750144; GAINES BR, 1976, INT J MAN MACH STUD, V8, P623, DOI 10.1016/S0020-7373(76)80027-2; GAINES BR, 1978, INFORM CONTROL, V38, P154, DOI 10.1016/S0019-9958(78)90165-1; GARVEY TD, 1981, 7TH P INT JOINT C AR, P319; Giles R., 1979, Fuzzy Sets and Systems, V2, P233, DOI 10.1016/0165-0114(79)90029-0; GILES R, 1980, FUZZY SET SYST, V4, P221, DOI 10.1016/0165-0114(80)90012-3; Giles R., 1982, FUZZY INFORM DECISIO, P183; GINSBERG ML, 1984, AUG P NAT C ART INT, P126; GOGUEN JA, 1969, SYNTHESE, V19, P325, DOI 10.1007/BF00485654; GUPTA MM, 1982, JAN P IFAC S THEOR A, P16; HAACK S, 1979, INT J MAN MACH STUD, V11, P437, DOI 10.1016/S0020-7373(79)80036-X; HAJEK P, 1983, COMBINING FUNCTIONS, P22; HALPERN JY, 1984, AUG P NAT C ART INT, P137; Hempel C., 1965, ASPECTS SCI EXPLANAT; Hisdal E., 1978, Fuzzy Sets and Systems, V1, P283, DOI 10.1016/0165-0114(78)90019-2; HISDAL E, 1982, FUZZY SET POSSIBILIT, P204; HISDAL E, APPLIED SYSTEMS CYBE, P2906; HOHLE V, 1982, FUZZY SET POSSIBILIT, P344; IMAOKA H, 1979, AUG P INT JOINT C AR, P419; ISHIZUKA M, 1982, INFORM SCIENCES, V28, P179, DOI 10.1016/0020-0255(82)90047-0; ISHIZUKA M, 1983, NEW GENERAT COMPUT, V1, P159, DOI 10.1007/BF03037422; ISHIZUKA M, 1981, CESIR816 PURD U MEM, P13; ISHIZUKA M, 1982, APPROXIMATE REASONIN, P261; ISHIZUKA M, 1981, 7TH P INT JOINT C AR, P837; KAUFMANN A, 1983, INTRO THEORIE SOUS E, V4; KAYSER D, 1979, SEP C REPR CONN RAIS, P440; KIM JH, 1983, 8TH P INT JOINT C AR, P190; KLEIN S, 1982, JUL P EUR C ART INT, P141; KLEMENT EP, FUZZY SETS SYST, V5, P21; Kling R., 1974, Journal of Cybernetics, V4, P105, DOI 10.1080/01969727408546069; KONOLIGE K, 1979, COMPUTER BASED CONSU, P83; LeFaivre R. A., 1974, Journal of Cybernetics, V4, P57, DOI 10.1080/01969727408546066; LEFAIVRE RA, 1974, THESIS U WISCONSIN; LEMMER JF, 1982, 3RD P ANN AM ART INT, P424; LESMO L, 1983, ISI832 U TOR TECH RE, P38; LESMO L, 1982, APPROXIMATE REASONIN, P249; LESMO L, 1983, ADV FUZZY SETS POSSI, P181; LESSER VR, 1980, 1ST P NAT C ART INT, P111; LOUI R, 1984, PERSPECTIVE PROBABIL; LOWRANCE JD, 1982, P IEEE INT C CYB SOC, P6; LU SY, 1984, AUG P NAT C ART INT, P216; MAMDANI EH, 1977, IEEE T COMPUT, V26, P1182, DOI 10.1109/TC.1977.1674779; MARTINCLOUAIRE R, 1984, 6TH P INT C CYB SYST, P175; MARTINCLOUAIRE R, 1984, BUSEFAL, P75; MARTINCLOUAIRE R, 1982, THESIS U SASKATCHEWA, P124; MARTINCLOUAIRE R, 1983, REPRESENTATION CONNA; MARTINCLOUAIRE R, UNPUB INT J MAN MACH; MARTINCLOUAIRE R, 1980, ARTIF INTELL, V13, P41; MCDERMOTT D, 1982, J ACM, V29, P33, DOI 10.1145/322290.322293; Michalski R. S., 1977, Computer Science and multiple-valued logic. Theory and applications, P506; MICHALSKI RS, 1980, INT J MAN MACH STUD, V12, P63, DOI 10.1016/S0020-7373(80)80054-X; MIZUMOTO M, 1982, FUZZY SET SYST, V8, P253, DOI 10.1016/S0165-0114(82)80004-3; MIZUMOTO M, 1981, CYBERNET SYST, V12, P247, DOI 10.1080/01969728108927676; MIZUMOTO M, 1979, ADV FUZZY SET THEORY, P117; MIZUMOTO M, 1983, FUZZY MATH, V3, P45; MIZUMOTO M, 1979, 18TH P IEEE C DEC CO, P777; MIZUMOTO M, 1983, APPROXIMATE REASONIN, P67; MIZUMOTO M, 1982, FUZZY SET POSSIBILIT, P211; MIZUMOTO M, 1981, APPLIED SYSTEMS CYBE, P2927; MIZUMOTO M, 1979, 6TH P INT JOINT C AR, P589; Moore R. C., 1983, 8TH P INT JOINT C AR, P272; NAKAMURA K, 1982, IEEE T SYST MAN CYB, V12, P193, DOI 10.1109/TSMC.1982.4308803; NAKAMURA K, 1983, FUZZY INFORMATION DE, P373; NEGOITA CV, 1980, KYBERNETES, V9, P189, DOI 10.1108/eb005555; NEGOITA CV, 1984, 6TH P INT C CYB SYST, P181; NG SW, 1980, 1ST ANN NAT C ART IN, P105; Nguyen H. T., 1978, Fuzzy Sets and Systems, V1, P299, DOI 10.1016/0165-0114(78)90020-9; OGAWA H, 1983, 2ND WORKSH N AM FUZZ; OKAMOTO MB, 1979, 6TH P INT JOINT C AR, P696; PEARL J, 1982, 3RD P ANN AM ART INT, P133; PEDNAULT EPD, 1981, ARTIF INTELL, V16, P213, DOI 10.1016/0004-3702(81)90011-4; PEDRYCZ W, 1982, 8214 DELFT U TECHN D; Polya G., 1968, MATH PLAUSIBLE REASO, VII; PRADE H, 1984, INFORM SYST, V9, P27, DOI 10.1016/0306-4379(84)90014-0; PRADE H, UNPUB KYBERNETES; PRADE H, 1984, 6TH P INT C CYB SYST, P187; PRADE H, 1980, 1ST P SEL PAP INT C, P57; PRADE H, 1984, 4EME P C AFCET REC F, P355; PRADE H, 1980, DEC P INT C APPL SYS, V6, P2953; PRADE H, 1982, THESIS U P SABATIER, P358; PRADE H, 1982, BUSEFAL9 LSI U P SAB, P88; PRADE H, UNPUB INFORM SCI, V34; PRADE H, 1982, FUZZY SET POSSIBILIT, P232; PRADE H, 1983, BUSEFAL14 LSI U P SA, P115; PRADE H, 1984, BUSEFAL18 LSI U P SA, P83; PRADE H, 1980, BUSEFAL4 LSI, P71; PRADE H, 1983, OCT IFAC INT S ART I; PRADE H, 1983, AUG INT JOINT C ART, P130; QUINLAN JR, 1983, 8TH P INT JOINT C AR, P137; RAUCH ME, 1984, AI MAGAZINE      FAL, P55; REITER R, 1983, COMPUT MATH APPL, V9, P15, DOI 10.1016/0898-1221(83)90004-4; REITER R, 1980, ARTIF INTELL, V13, P81, DOI 10.1016/0004-3702(80)90014-4; REITER R, 1981, AUG P INT JOINT C AR, P270; RESCHER N, 1976, PLAUSIBLE REASONING, P124; RESCHER N, 1969, MANY VALUED LOGIC, P359; RICH E, 1983, AUG P NAT C ART INT, P348; ROLLINGER CR, 1983, 8TH P INT JOINT C AR, P358; SAGE AP, 1983, LARGE SCALE SYST, V5, P35; SALES T, 1982, THESIS U POLITECNICA; SANCHEZ E, 1978, INFORM SCIENCES, V15, P45, DOI 10.1016/0020-0255(78)90021-X; SANCHEZ E, 1976, INFORM CONTROL, V30, P38, DOI 10.1016/S0019-9958(76)90446-0; SANCHEZ E, 1980, JUN TABL ROND CNRS Q, P11; SANCHEZ E, 1981, APPLIED SYSTEMS CYBE, V6, P2884; Sanchez E., 1977, FUZZY AUTOMATA DECIS, P221; SCHEFE P, 1980, INT J MAN MACH STUD, V12, P35, DOI 10.1016/S0020-7373(80)80053-8; SCHEFE P, 1979, 69 U HAMB I INF MITT, P30; SCHWARTZ DG, 1981, THESIS PORTLAND STAT; Schweizer B., 1963, PUBL MATH-DEBRECEN, V10, P69; SCHWYHLA W, 1980, 2ND P INT SEM FUZZ S, P143; SEMBI BS, 1979, 9TH P IEEE INT S MUL, P143; Shackle GLS., 1961, DECISION ORDER TIME; SHAFER G, UNPUB ANAL FUZZY INF; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Shortliffe EH., 1975, MATH BIOSCI, V23, P351, DOI [10.1016/0025-5564(75)90047-4, DOI 10.1016/0025-5564(75)90047-4]; SILVERT W, 1979, IEEE T SYST MAN CYB, V9, P657; Skala H. J., 1978, Fuzzy Sets and Systems, V1, P129, DOI 10.1016/0165-0114(78)90013-1; SMALL M, 1984, POLICY EVALUATION US; SMETS P, 1981, INFORM SCIENCES, V25, P1, DOI 10.1016/0020-0255(81)90008-6; SMETS P, 1981, FUZZY SET SYST, V5, P259, DOI 10.1016/0165-0114(81)90054-3; SMETS P, 1978, THESIS U LIBRE BRUXE, P269; SMETS P, 1982, FUZZY SET POSSIBILIT, P247; SOULA G, 1982, APPROXIMATE REASONIN, P77; SOULA G, 1983, P MEDINFO 83 AMSTERD; SUGENO M, 1983, FUZZY SET SYST, V9, P313, DOI 10.1016/S0165-0114(83)80030-X; SUGENO M, 1974, THESIS TOKYO I TECHN, P124; Suppes P., 1966, ASPECTS INDUCTIVE LO, P49; SZOLOVITS P, 1978, ARTIF INTELL, V11, P115, DOI 10.1016/0004-3702(78)90014-0; TANAKA H, 1982, FUZZY SETS POSSIBILI, P257; TANAKA K, 1981, APPLIED SYSTEMS CYBE, P2866; TANAKA K, 1982, FUZZY SET POSSIBILIT, P38; Thole U., 1979, Fuzzy Sets and Systems, V2, P167, DOI 10.1016/0165-0114(79)90023-X; TONG RM, 1982, FUZZY SET SYST, V7, P103, DOI 10.1016/0165-0114(82)90044-6; TONG RM, 1983, 8TH P INT JOINT C AR, P194; TONG RM, 1983, AUG P NAT C ART INT, P411; TRILLAS E, 1981, 3RD P INT SEM FUZZ S, P173; Trillas E, 1979, STOCHASTICA, V3, P47; Tsukamoto Y., 1978, Proceedings of the International Conference on Cybernetics and Society, P1217; TSUKAMOTO Y, 1979, THESIS TOKYO I TECHN; Tsukamoto Y., 1979, ADV FUZZY SET THEORY, P137; TSUKAMOTO Y, 1982, 4TH INT SEM FUZZ SET; TURKSEN IB, 1982, 6TH EUR M CYB SYST R; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; UMANO M, 1979, 6TH P INT JOINT C AR, P917; WAHLSTER W, 1977, 38 U HAMB I INF BER; WANG PZ, 1980, SELECTED PAPERS FUZZ, P32; WEBER S, 1983, FUZZY SET SYST, V11, P115, DOI 10.1016/S0165-0114(83)80073-6; WEISS SM, 1978, ARTIF INTELL, V11, P145, DOI 10.1016/0004-3702(78)90015-2; WEISS SM, 1979, 6TH P INT JOINT C AR, P942; WENSTOP F, 1979, ADV FUZZY SET THEORY, P501; WESLEY LP, 1983, 8TH P INT JOINT C AR, P203; WHALEN T, 1983, INT J MAN MACH STUD, V19, P57, DOI 10.1016/S0020-7373(83)80042-X; Whalen T., 1981, Proceedings of the International Conference on Cybernetics and Society, P649; WHALEN T, 1983, ADV FUZZY SETS POSSI, P199; WILLMOTT R, 1980, FUZZY SET SYST, V4, P31, DOI 10.1016/0165-0114(80)90061-5; WILLMOTT R, 1980, P 10 INT S MULT VAL, P253; WINSTON PH, 1980, COMMUN ACM, V23, P689, DOI 10.1145/359038.359042; Yager R. R., 1983, Journal of Information & Optimization Sciences, V4, P73; YAGER RR, 1982, INFORM SCIENCES, V28, P45, DOI 10.1016/0020-0255(82)90031-7; YAGER RR, 1979, INFORM SCIENCES, V18, P113, DOI 10.1016/0020-0255(79)90011-2; YAGER RR, 1980, INT J MAN MACH STUD, V13, P323, DOI 10.1016/S0020-7373(80)80046-0; YAGER RR, 1984, IEEE T SYST MAN CYB, V14, P636, DOI 10.1109/TSMC.1984.6313337; YAGER RR, 1980, INFORM SCIENCES, V22, P217, DOI 10.1016/S0020-0255(80)80015-6; YAGER RR, MII314 ION COLL TECH, P26; YAGER RR, 1982, 4TH INT SEM FUZZ SET; YAGER RR, 1983, MII308 ION COLL TECH, P47; YAGER RR, 1981, 3RD P INT SEM FUZZ S, P211; YAGER RR, 1980, RRY8003 ION COLL TEC, P27; YAGER RR, 1980, 2ND P INT SEM FUZZ S, P69; YAGER RR, 1983, MII301 ION COLL TECH, P32; YAGER RR, 1983, MII303 ION COLL TECH, P20; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5; Zadeh L.A., 1984, ASPECTS VAGUENESS, P257; Zadeh L. A., 1975, SYNTHESE, V30, P407, DOI DOI 10.1007/BF00485052; ZADEH LA, 1983, MED INFORM, V8, P173, DOI 10.3109/14639238309016081; ZADEH LA, 1983, FUZZY SET SYST, V11, P199, DOI 10.1016/S0165-0114(83)80081-5; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1978, INT J MAN MACH STUD, V10, P395, DOI 10.1016/S0020-7373(78)80003-0; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; ZADEH LA, 1980, P IEEE, V68, P421, DOI 10.1109/PROC.1980.11659; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1983, COMPUTER, V16, P61, DOI 10.1109/MC.1983.1654199; Zadeh LA, 1984, AI MAG, V5, P81, DOI DOI 10.1609/aimag.v5i3.452; ZADEH LA, 247 SRI INT TECH NOT, P75; ZADEH LA, 1979, UCBERL M7934 U CAL M, P17; Zadeh LA, 1975, FUZZY SETS THEIR APP; ZADEH LA, 1981, AAAS SELECTED S, V54, P69; ZADEH LA, 1979, UCBERL M7924 U CAL M, P12; ZADEH LA, 1980, 4TH P IEEE COMP SOFT, P842; ZADEH LA, 1979, MACH INTELL, V9, P149; ZADEH LA, 1979, AUG P INT JOINT C AR, P1004; ZADEH LA, 1979, UCBERL M7932 U CAL M, P35; ZADEH LA, 1980, 10TH P INT S MULT VA, P124; Zadeh LA, 1972, J CYBERNETICS, V2, P4, DOI [10.1080/01969727208542910, DOI 10.1080/01969727208542910]; Zadeh Lotfi A., 1979, ADV FUZZY SET THEORY, P3; ZIMMERMANN HJ, 1980, FUZZY SET SYST, V4, P37, DOI 10.1016/0165-0114(80)90062-7; [No title captured]; [No title captured]; 1980, CONJUNTOS BORROSOS	297	96	96	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					260	283		10.1109/TPAMI.1985.4767656	http://dx.doi.org/10.1109/TPAMI.1985.4767656			24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869262				2022-12-18	WOS:A1985AFM4400002
J	Liao, MH; Lyu, PY; He, MH; Yao, C; Wu, WH; Bai, X				Liao, Minghui; Lyu, Pengyuan; He, Minghang; Yao, Cong; Wu, Wenhao; Bai, Xiang			Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene text spotting; scene text detection; scene text recognition; arbitrary shapes; attention; segmentation	RECOGNITION	Unifying text detection and text recognition in an end-to-end training fashion has become a new trend for reading text in the wild, as these two tasks are highly relevant and complementary. In this paper, we investigate the problem of scene text spotting, which aims at simultaneous text detection and recognition in natural images. An end-to-end trainable neural network named as Mask TextSpotter is presented. Different from the previous text spotters that follow the pipeline consisting of a proposal generation network and a sequence-to-sequence recognition network, Mask TextSpotter enjoys a simple and smooth end-to-end learning procedure, in which both detection and recognition can be achieved directly from two-dimensional space via semantic segmentation. Further, a spatial attention module is proposed to enhance the performance and universality. Benefiting from the proposed two-dimensional representation on both detection and recognition, it easily handles text instances of irregular shapes, for instance, curved text. We evaluate it on four English datasets and one multi-language dataset, achieving consistently superior performance over state-of-the-art methods in both detection and end-to-end text recognition tasks. Moreover, we further investigate the recognition module of our method separately, which significantly outperforms state-of-the-art methods on both regular and irregular text datasets for scene text recognition.	[Liao, Minghui; Lyu, Pengyuan; He, Minghang; Bai, Xiang] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China; [Yao, Cong; Wu, Wenhao] Megvii Face Inc, Beijing 100190, Peoples R China	Huazhong University of Science & Technology	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.	mhliao@hust.edu.cn; lvpyuan@gmail.com; minghanghe@hust.edu.cn; yaocong2010@gmail.com; wwh@megvii.com; xbai@mail.hust.edu.cn		Bai, Xiang/0000-0002-3449-5940; Liao, Minghui/0000-0002-2583-4314	National Key R&D Program of China [2018YFB1004600]; National Program for Support of Topnotch Young Professionals; NSFC [61733007]; Program for HUST Academic Frontier Youth Team [2017QYTD08]	National Key R&D Program of China; National Program for Support of Topnotch Young Professionals; NSFC(National Natural Science Foundation of China (NSFC)); Program for HUST Academic Frontier Youth Team	Minghui Liao and Pengyuan Lyu contributed equally to this article. Xiang Bai is the corresponding author. This work was supported by National Key R&D Program of China No. 2018YFB1004600, NSFC 61733007. Dr. Xiang Bai was supported by the National Program for Support of Topnotch Young Professionals and the Program for HUST Academic Frontier Youth Team 2017QYTD08.	Almazan J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814; Bahdanau Dzmitry, 2015, NEURAL MACHINE TRANS; Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163; Bai X, 2018, IEEE ACCESS, V6, P66322, DOI 10.1109/ACCESS.2018.2878899; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; Busta M, 2019, LECT NOTES COMPUT SC, V11367, P127, DOI 10.1007/978-3-030-21074-8_11; Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242; Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157; Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584; Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; Dai YC, 2018, INT C PATT RECOG, P3604, DOI 10.1109/ICPR.2018.8546066; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Gehring J, 2017, PR MACH LEARN RES, V70; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gomez L, 2017, PATTERN RECOGN, V70, P60, DOI 10.1016/j.patcog.2017.04.027; Gomez R, 2017, PROC INT CONF DOC, P1435, DOI 10.1109/ICDAR.2017.234; Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914; Graves A., 2006, P 23 INT C MACH LEAR, P369; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331; He P, 2016, AAAI CONF ARTIF INTE, P3501; He T, 2018, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR.2018.00527; He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu H, 2017, IEEE I CONF COMP VIS, P4950, DOI 10.1109/ICCV.2017.529; Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33; Jaderberg M, 2014, ABS14062227 CORR; Jaderberg M, 2015, ADV NEUR IN, V28; Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z; Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34; Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942; Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221; Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245; Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560; Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472; Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619; Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107; Liao MH, 2017, AAAI CONF ARTIF INTE, P4161; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2; Lucas SM, 2003, PROC INT CONF DOC, P682; Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788; Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5; Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127; Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990; Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237; Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008; Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6; Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939; Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; Su BL, 2017, PATTERN RECOGN, V63, P397, DOI 10.1016/j.patcog.2016.10.016; Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3; Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4; Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76; Veit Andreas, 2016, ARXIV160107140; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Wang T, 2012, INT C PATT RECOG, P3304; Wojna Z, 2017, PROC INT CONF DOC, P844, DOI 10.1109/ICDAR.2017.143; Xue CH, 2018, LECT NOTES COMPUT SC, V11220, P370, DOI 10.1007/978-3-030-01270-0_22; Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280; Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813; Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515; Yu Fisher, 2016, MULTISCALE CONTEXT A; Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhong Z, 2016, ARXIV160507314, P1, DOI DOI 10.1109/ICASSP.2017.7952348; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283	81	95	101	13	75	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2021	43	2					532	548		10.1109/TPAMI.2019.2937086	http://dx.doi.org/10.1109/TPAMI.2019.2937086			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS2ZD	31449005	Green Submitted			2022-12-18	WOS:000607795000002
J	Braun, M; Krebs, S; Flohr, F; Gavrila, DM				Braun, Markus; Krebs, Sebastian; Flohr, Fabian; Gavrila, Dariu M.			EuroCity Persons: A Novel Benchmark for Person Detection in Traffic Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; benchmarking	PEDESTRIAN DETECTION; GRADIENTS	Big data has had a great share in the success of deep learning in computer vision. Recent works suggest that there is significant further potential to increase object detection performance by utilizing even bigger datasets. In this paper, we introduce the EuroCity Persons dataset, which provides a large number of highly diverse, accurate and detailed annotations of pedestrians, cyclists and other riders in urban traffic scenes. The images for this dataset were collected on-board a moving vehicle in 31 cities of 12 European countries. With over 238,200 person instances manually labeled in over 47,300 images, EuroCity Persons is nearly one order of magnitude larger than datasets used previously for person detection in traffic scenes. The dataset furthermore contains a large number of person orientation annotations (over 211,200). We optimize four state-of-the-art deep learning approaches (Faster R-CNN, R-FCN, SSD and YOLOv3) to serve as baselines for the new object detection benchmark. In experiments with previous datasets we analyze the generalization capabilities of these detectors when trained with the new dataset. We furthermore study the effect of the training set size, the dataset diversity (day-versus night-time, geographical region), the dataset detail (i.e., availability of object orientation information) and the annotation quality on the detector performance. Finally, we analyze error sources and discuss the road ahead.	[Braun, Markus; Krebs, Sebastian; Flohr, Fabian] Daimler AG, Environm Percept Grp, D-89081 Ulm, Germany; [Braun, Markus; Krebs, Sebastian; Gavrila, Dariu M.] Delft Univ Technol, Intelligent Vehicles Grp, NL-2628 CD Delft, Netherlands	Daimler AG; Delft University of Technology	Gavrila, DM (corresponding author), Delft Univ Technol, Intelligent Vehicles Grp, NL-2628 CD Delft, Netherlands.	markus.ma.braun@daimler.com; sebastian.krebs@daimler.com; fabian.flohr@daimler.com; d.m.gavrila@tudelft.nl		Braun, Markus/0000-0003-1439-850X; Flohr, Fabian/0000-0002-1499-3790				Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], [No title captured]; [Anonymous], 2018, BERKELEY DEEP DRIVE; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470; Beyer L, 2015, LECT NOTES COMPUT SC, V9358, P157, DOI 10.1007/978-3-319-24947-6_13; Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Braun M, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1546, DOI 10.1109/ITSC.2016.7795763; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Chen XZ, 2015, ADV NEUR IN, V28; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Demsar J, 2006, J MACH LEARN RES, V7, P1; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Ess A, 2007, IEEE I CONF COMP VIS, P2065; Everingham M., 2011, INT J COMPUT VISION, V111, P98; Geiger A., 2012, P IEEE COMP SOC C CO; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hall D, 2015, PROC CVPR IEEE, P5482, DOI 10.1109/CVPR.2015.7299187; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685; Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034; Huang J, 2017, IEEE INT C INT ROBOT, P3296; Huang SY, 2017, PROC CVPR IEEE, P4664, DOI 10.1109/CVPR.2017.496; Huh Minyoung, 2016, ARXIV160808614; Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706; Kooij JFP, 2014, LECT NOTES COMPUT SC, V8694, P618, DOI 10.1007/978-3-319-10599-4_40; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508; Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211; Li XF, 2016, IEEE INT VEH SYM, P1028; Liang YQ, 2014, P AMER CONTR CONF, P678, DOI 10.1109/ACC.2014.6858926; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639; Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217; Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411; Overett G, 2008, IEEE INT VEH SYM, P1038; Rajaram RN, 2015, IEEE INT C INTELL TR, P2335, DOI 10.1109/ITSC.2015.377; Redmon J., 2013, DARKNET OPEN SOURCE; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren Jimmy, 2017, CVPR, DOI DOI 10.1109/CVPR.2017.87; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sharpe GJ, 2011, COMBUST THEOR MODEL, V15, P691, DOI 10.1080/13647830.2011.558594; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347; Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108; Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390; Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28; Zhang S., 2014, CVPR; Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460; ZHANG SS, 2016, PROC CVPR IEEE, P1259, DOI DOI 10.1109/CVPR.2016.141; ZHANG SS, 2015, PROC CVPR IEEE, P1751, DOI DOI 10.1109/CVPR.2015.7298784; Zhu Y., 2016, P AS C COMP VIS, P416	76	95	99	2	74	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1844	1861		10.1109/TPAMI.2019.2897684	http://dx.doi.org/10.1109/TPAMI.2019.2897684			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30735986	Green Submitted			2022-12-18	WOS:000473598800005
J	Jia, K; Wang, XG; Tang, XO				Jia, Kui; Wang, Xiaogang; Tang, Xiaoou			Image Transformation Based on Learning Dictionaries across Image Spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image transformation; image mapping; sparse coding; intrinsic images; super-resolution	SELECTION; SPARSE; FACE; SUPERRESOLUTION; REGRESSION; ALGORITHM	In this paper, we propose a framework of transforming images from a source image space to a target image space, based on learning coupled dictionaries from a training set of paired images. The framework can be used for applications such as image super-resolution and estimation of image intrinsic components (shading and albedo). It is based on a local parametric regression approach, using sparse feature representations over learned coupled dictionaries across the source and target image spaces. After coupled dictionary learning, sparse coefficient vectors of training image patch pairs are partitioned into easily retrievable local clusters. For any test image patch, we can fast index into its closest local cluster and perform a local parametric regression between the learned sparse feature spaces. The obtained sparse representation (together with the learned target space dictionary) provides multiple constraints for each pixel of the target image to be estimated. The final target image is reconstructed based on these constraints. The contributions of our proposed framework are three-fold. 1) We propose a concept of coupled dictionary learning based on coupled sparse coding which requires the sparse coefficient vectors of a pair of corresponding source and target image patches to have the same support, i.e., the same indices of nonzero elements. 2) We devise a space partitioning scheme to divide the high-dimensional but sparse feature space into local clusters. The partitioning facilitates extremely fast retrieval of closest local clusters for query patches. 3) Benefiting from sparse feature-based image transformation, our method is more robust to corrupted input data, and can be considered as a simultaneous image restoration and transformation process. Experiments on intrinsic image estimation and super-resolution demonstrate the effectiveness and efficiency of our proposed method.	[Jia, Kui] Univ Illinois, Adv Digital Sci Ctr, Urbana, IL 61801 USA; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; [Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; Chinese University of Hong Kong; Chinese University of Hong Kong	Jia, K (corresponding author), Univ Illinois, Adv Digital Sci Ctr, Urbana, IL 61801 USA.	kuijia@gmail.com; xgwang@ee.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Wang, Xiaogang/L-4369-2014	Wang, Xiaogang/0000-0002-9021-0954	China Guangdong Province through Introduced Innovative RAMP;D Team of Guangdong Province [201001D0104648280]; National Natural Science Foundation of China [60903115]; Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR)	China Guangdong Province through Introduced Innovative RAMP;D Team of Guangdong Province; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR)(Agency for Science Technology & Research (A*STAR))	This work is partially supported by China Guangdong Province through Introduced Innovative R&D Team of Guangdong Province 201001D0104648280, the National Natural Science Foundation of China (Grant No. 60903115), and the research grant for the Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR).	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2004, P IEEE C COMP VIS PA; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19; Bae S., 2006, P ACM SIGGRAPH; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BESAG J, 1986, J R STAT SOC B, V48, P259; Dai S., 2007, P IEEE C COMP VIS PA; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Efros A.A., 2001, P ACM C COMP GRAPH I; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Glasner D., 2009, P 12 IEEE INT C COMP; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Grosse R., 2009, P 12 IEEE INT C COMP; Hertzmann A., 2001, P ACM SIGGRAPH; Huang K., 2007, ADV NEURAL INFORM PR, V19, P609; Jegou H, 2008, P 10 EUR C COMP VIS; Kavukcuoglu K., 2009, P IEEE C COMP VIS PA; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Lee H., 2007, P ADV NEUR INF PROC, V19; Li YZ, 2008, PROC SPIE, V6806, DOI 10.1117/12.784164; Lin D., 2005, P 10 IEEE INT C COMP; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu ZC, 2004, IEEE COMPUT GRAPH, V24, P30, DOI 10.1109/MCG.2004.1297008; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Mairal J., 2008, P ADV NEUR INF PROC; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Matsushita Y, 2004, LECT NOTES COMPUT SC, V3022, P274; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Nettleton DF, 2010, ARTIF INTELL REV, V33, P275, DOI 10.1007/s10462-010-9156-z; Nister D., 2006, P 2006 IEEE COMP SOC; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; ROTH S, 2005, P IEEE C COMP VIS PA; Roth V., 2008, P 25 INT C MACH LANG; Shen L., 2008, P IEEE C COMP VIS PA; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659; Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353; Tappen M.F., 2006, PROC IEEE CONF COMPU; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0; Wang Q., 2005, P 10 IEEE INT C COMP; Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Weiss Y., 2008, P ADV NEUR INF PROC; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yu G., 2010, ARXIV10063056; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x	54	95	99	1	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					367	380		10.1109/TPAMI.2012.95	http://dx.doi.org/10.1109/TPAMI.2012.95			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22529324	Green Published			2022-12-18	WOS:000312560600010
J	Dai, JF; Zhou, J				Dai, Jifeng; Zhou, Jie			Multifeature-Based High-Resolution Palmprint Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Palmprint; orientation field; the composite algorithm; density map; data fusion	IDENTIFICATION; VERIFICATION	Palmprint is a promising biometric feature for use in access control and forensic applications. Previous research on palmprint recognition mainly concentrates on low-resolution (about 100 ppi) palmprints. But for high-security applications (e. g., forensic usage), high-resolution palmprints (500 ppi or higher) are required from which more useful information can be extracted. In this paper, we propose a novel recognition algorithm for high-resolution palmprint. The main contributions of the proposed algorithm include the following: 1) use of multiple features, namely, minutiae, density, orientation, and principal lines, for palmprint recognition to significantly improve the matching performance of the conventional algorithm. 2) Design of a quality-based and adaptive orientation field estimation algorithm which performs better than the existing algorithm in case of regions with a large number of creases. 3) Use of a novel fusion scheme for an identification application which performs better than conventional fusion methods, e. g., weighted sum rule, SVMs, or Neyman-Pearson rule. Besides, we analyze the discriminative power of different feature combinations and find that density is very useful for palmprint recognition. Experimental results on the database containing 14,576 full palmprints show that the proposed algorithm has achieved a good performance. In the case of verification, the recognition system's False Rejection Rate (FRR) is 16 percent, which is 17 percent lower than the best existing algorithm at a False Acceptance Rate (FAR) of 10(-5), while in the identification experiment, the rank-1 live-scan partial palmprint recognition rate is improved from 82.0 to 91.7 percent.	[Dai, Jifeng; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Dai, JF (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	djf05@mails.tsinghua.edu.cn; jzhou@tsinghua.edu.cn	Dai, Jifeng/AAF-7709-2019; Dai, Jifeng/HGU-8741-2022	Dai, Jifeng/0000-0002-6785-0785	National 863 Hi-Tech Development Program of China [2008AA01Z123]; Nation Science Foundation of China [61020106004, 60875017, 61005023, 61021063]; Natural Science Foundation of Beijing [4042020]	National 863 Hi-Tech Development Program of China(National High Technology Research and Development Program of China); Nation Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Beijing(Beijing Natural Science Foundation)	The authors would like to thank Dr. Abhishek Nagar and Dr. Jianjiang Feng for their help in revising this paper. This work was supported by the National 863 Hi-Tech Development Program of China under Grant 2008AA01Z123, by the Nation Science Foundation of China under Grants 61020106004, 60875017, 61005023, and 61021063, and by the Natural Science Foundation of Beijing under Grant 4042020.	Ashbaugh D.R, 1999, CRC SER PR CRIM; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48; Chen FL, 2009, IEEE T IMAGE PROCESS, V18, P1665, DOI 10.1109/TIP.2009.2017995; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dewan Shaila, 2021, NEW YORK TIMES; Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9; GALTON F, 2002, FINGERPRINTS; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Hennings-Yeomans PH, 2007, IEEE T INF FOREN SEC, V2, P613, DOI 10.1109/TIFS.2007.902039; Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain A.K., 2007, HDB BIOMETRICS HDB B; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014; KONG A, 2004, P 17 INT C PATT REC, V1; Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3; Kumar A, 2005, PATTERN RECOGN, V38, P1695, DOI 10.1016/j.patcog.2005.03.012; Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214; Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73; Maltoni D., 2009, HDB FINGERPRINT RECO; Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0; Radon J., 1986, IEEE Transactions on Medical Imaging, VMI-5, P170, DOI 10.1109/TMI.1986.4307775; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; Shu W, 1998, OPT ENG, V37, P2359, DOI 10.1117/1.601756; SUN Z, 2001, P IEEE CS C COMP VIS, P279; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; TRAVIS J, 2000, FORENSIC FRICTION RI; Wan DR, 2006, IEEE T IMAGE PROCESS, V15, P1690, DOI 10.1109/TIP.2006.873442; Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021; You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5; Yue F, 2009, PATTERN RECOGN, V42, P2841, DOI 10.1016/j.patcog.2009.03.015; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608; Zhou J, 2009, PATTERN RECOGN, V42, P896, DOI 10.1016/j.patcog.2008.09.011; 2009, FBIS NEXT GENERATION	40	95	98	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					945	957		10.1109/TPAMI.2010.164	http://dx.doi.org/10.1109/TPAMI.2010.164			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20733215				2022-12-18	WOS:000288677800007
J	Xiang, SM; Nie, FP; Zhang, CS				Xiang, Shiming; Nie, Feiping; Zhang, Changshui			Semi-Supervised Classification via Local Spline Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semi-supervised classification; local spline regression; interactive image segmentation	DIMENSIONALITY REDUCTION; LAPLACIAN EIGENMAPS; UNLABELED DATA	This paper presents local spline regression for semi-supervised classification. The core idea in our approach is to introduce splines developed in Sobolev space to map the data points directly to be class labels. The spline is composed of polynomials and Green's functions. It is smooth, nonlinear, and able to interpolate the scattered data points with high accuracy. Specifically, in each neighborhood, an optimal spline is estimated via regularized least squares regression. With this spline, each of the neighboring data points is mapped to be a class label. Then, the regularized loss is evaluated and further formulated in terms of class label vector. Finally, all of the losses evaluated in local neighborhoods are accumulated together to measure the global consistency on the labeled and unlabeled data. To achieve the goal of semi-supervised classification, an objective function is constructed by combining together the global loss of the local spline regressions and the squared errors of the class labels of the labeled data. In this way, a transductive classification algorithm is developed in which a globally optimal classification can be finally obtained. In the semi-supervised learning setting, the proposed algorithm is analyzed and addressed into the Laplacian regularization framework. Comparative classification experiments on many public data sets and applications to interactive image segmentation and image matting illustrate the validity of our method.	[Xiang, Shiming] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Nie, Feiping; Zhang, Changshui] Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Tsinghua University	Xiang, SM (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	smxiang@gmail.com; feipingnie@gmail.com; zcs@mail.tsinghua.edu.cn	Nie, Feiping/B-3039-2012		National Natural Science Foundation of China [60975037, 60721003]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by the Projects (Grant No. 60975037 and 60721003) of the National Natural Science Foundation of China.	Adams R. A., 2003, SOBOLEV SPACES, VSecond; Ando R.K., 2007, P 24 INT C MACH LEAR, P25; Balcan M. F., 2004, ADV NEURAL INFORM PR, P89; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; BELKIN M, 2004, P 17 ANN C LEARN THE, P624; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Blum A., 2001, P INT C MACH LEARN I, P19, DOI DOI 10.1184/R1/6606860.V1; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chawla N, 2005, J ARTIF INTELL RES, V23, P331, DOI 10.1613/jair.1509; Cozman F. G., 2003, P 20 INT C MACH LEAR, P99; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Dasgupta S., 2001, ADV NEURAL INFORM PR, V14; Duchon Jean, 1977, LECT NOTES MATH, P2, DOI 10.1007/BFb0086566; Fujino A., 2005, PROC AAAI, P764; GETZ G, 2005, P ICML WORKSH LEARN; GOLDMAN S, 2000, P 17 INT C MACH LEAR, P327; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423; HE X, 2003, P ANN C NEUR INF PRO; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Joachims T., 2003, P 20 INT C MACH LEAR, P290, DOI DOI 10.1145/2612669.2612699; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Jones R., 2005, CMULTI05191; LAWRENCE ND, 2004, ADV NEURAL INFORM PR, V14, P753; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Miller DJ, 1997, ADV NEUR IN, V9, P571; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; ROTHER C, 2004, P ACM SIGGRAPH, P309; Scholkopf B., 2007, P ADV NEUR INF PROC, V19, P1529, DOI DOI 10.7551/MITPRESS/7503.003.0196; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Szummer M, 2002, ADV NEUR IN, V14, P945; Wahba G., 1990, SPLINE MODELS OBSERV; WALDER C, 2007, ADV NEURAL INFORM PR, P1561; Wang F., 2008, P 23 AAAI C ART INT, P726; Wang F., 2008, P 23 AAAI C ART INT, P720; WANG F, 2007, P 11 INT C ART INT S, P596; Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672; Wang J, 2005, IEEE I CONF COMP VIS, P936; Wendland H., 2005, SCATTERED DATA APPRO; Wu M., 2007, ARTIF INTELL, V2, P628; Wu M., 2007, P 24 INT C MACH LEAR, P1039; Xiang SM, 2006, LECT NOTES COMPUT SC, V4212, P825; Yang L, 2004, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2004.1334180; Yoon J, 2001, SIAM J MATH ANAL, V33, P946, DOI 10.1137/S0036141000373811; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhou Z.-H., 2007, PROC AAAI, P675; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186; Zhu X., 2003, INT C MACH LEARN; Zhu X, 2007, 1530 TR U WISC	60	95	105	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2039	2053		10.1109/TPAMI.2010.35	http://dx.doi.org/10.1109/TPAMI.2010.35			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847392				2022-12-18	WOS:000281990900008
J	Avraham, T; Lindenbaum, M				Avraham, Tamar; Lindenbaum, Michael			Esaliency (Extended Saliency): Meaningful Attention Using Stochastic Image Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; scene analysis; similarity measures; performance evaluation of algorithms and systems; object recognition; visual search; attention	VISUAL-ATTENTION; SELECTIVE ATTENTION; SEARCH; SEGMENTATION; ORGANIZATION; NETWORKS	Computer vision attention processes assign variable-hypothesized importance to different parts of the visual input and direct the allocation of computational resources. This nonuniform allocation might help accelerate the image analysis process. This paper proposes a new bottom-up attention mechanism. Rather than taking the traditional approach, which tries to model human attention, we propose a validated stochastic model to estimate the probability that an image part is of interest. We refer to this probability as saliency and thus specify saliency in a mathematically well-defined sense. The model quantifies several intuitive observations, such as the greater likelihood of correspondence between visually similar image regions and the likelihood that only a few of interesting objects will be present in the scene. The latter observation, which implies that such objects are (relaxed) global exceptions, replaces the traditional preference for local contrast. The algorithm starts with a rough preattentive segmentation and then uses a graphical model approximation to efficiently reveal which segments are more likely to be of interest. Experiments on natural scenes containing a variety of objects demonstrate the proposed method and show its advantages over previous approaches.	[Avraham, Tamar; Lindenbaum, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Avraham, T (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	tammya@cs.technion.ac.il; mic@cs.technion.ac.il			Israeli Science Foundation (ISF); European Commission (EC)	Israeli Science Foundation (ISF)(Israel Science Foundation); European Commission (EC)(European CommissionEuropean Commission Joint Research Centre)	The authors would like to thank Nabil Ouerhani for the human saliency maps [35], Robert Cowell [3] for sharing the XBAIES software package and for his advice, and Stanley Bileschi for sharing the StreetScenes database. This work was supported by the Israeli Science Foundation (ISF) and by the European Commission (EC) network of excellence, MUSCLE.	[Anonymous], 2004, ELECT LETT COMPUT VI, DOI DOI 10.5565/REV/ELCVIA.66; [Anonymous], 2006, NIPS; Avraham T, 2006, IEEE T PATTERN ANAL, V28, P251, DOI 10.1109/TPAMI.2006.28; AVRAHAM T, 2006, P INT WORKSH REPR US; Avraham T, 2008, J VISION, V8, DOI 10.1167/8.4.9; Bileschi S. M., 2006, STREETSCENES SCENE U; BOIMAN O, 2005, P 10 INT C COMP VIS; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CARRASCO M, 1995, PERCEPT PSYCHOPHYS, V57, P1241, DOI 10.3758/BF03208380; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COHEN A, 1991, J EXP PSYCHOL HUMAN, V17, P891, DOI 10.1037/0096-1523.17.4.891; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Draper BA, 2005, COMPUT VIS IMAGE UND, V100, P152, DOI 10.1016/j.cviu.2004.08.006; DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433; DUNCAN J, 1984, J EXP PSYCHOL GEN, V113, P501, DOI 10.1037/0096-3445.113.4.501; ERIKSEN CW, 1986, PERCEPT PSYCHOPHYS, V40, P225, DOI 10.3758/BF03211502; Fecteau JH, 2006, TRENDS COGN SCI, V10, P382, DOI 10.1016/j.tics.2006.06.011; Frintrop S, 2005, P 2 INT WORKSH ATT P; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677; JORDAN M, 1998, LEARNING GRAPHICAL M; Jurie F, 2004, PROC CVPR IEEE, P90; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; KOCH C, 1985, HUM NEUROBIOL, V4, P219; LIU F, 2006, P IEEE INT C MULT EX; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; NAKAYAMA K, 1986, NATURE, V320, P264, DOI 10.1038/320264a0; Navalpakkam V, 2002, LECT NOTES COMPUT SC, V2525, P453; Neisser U., 1967, COGNITIVE PSYCHOL; Nilsson D, 1998, STAT COMPUT, V8, P159, DOI 10.1023/A:1008990218483; PALETTA L, 2004, P EARL COGN VIS WORK; PALMER S, 1994, PSYCHON B REV, V1, P29, DOI 10.3758/BF03200760; PARKHURST DJ, 2003, J VISION, V3; PEARL J, 1998, PROBABILISTIC REASON; POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rutishauser U, 2004, PROC CVPR IEEE, P37; Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9; Siagian C, 2004, P 1 IEEE INT WORKSH; SPIRO B, 1991, GEOMICROBIOL J, V9, P1, DOI 10.1080/01490459109385981; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Sun YR, 2003, ARTIF INTELL, V146, P77, DOI 10.1016/S0004-3702(02)00399-5; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; TREISMAN A, 1988, Q J EXP PSYCHOL-A, V40, P201, DOI 10.1080/02724988843000104; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vogel J, 2004, LECT NOTES COMPUT SC, V3175, P195; WALKER KN, 1997, P BRIT MACH VIS C, P540; Watson SE, 1999, PERCEPT PSYCHOPHYS, V61, P31, DOI 10.3758/BF03211947; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; WESTHEIMER G, 1987, ADLERS PHYSL EYE CLI, pCH17; Wolfe J. M., 1998, ATTENTION; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171	60	95	100	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					693	708		10.1109/TPAMI.2009.53	http://dx.doi.org/10.1109/TPAMI.2009.53			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	555XA	20224124				2022-12-18	WOS:000274548800010
J	Weinman, JJ; Learned-Miller, E; Hanson, AR				Weinman, Jerod J.; Learned-Miller, Erik; Hanson, Allen R.			Scene Text Recognition Using Similarity and a Lexicon with Sparse Belief Propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene text recognition; optical character recognition; conditional random fields; factor graphs; graphical models; lexicon; language model; similarity; belief propagation; sparse belief propagation		Scene text recognition (STR) is the recognition of text anywhere in the environment, such as signs and storefronts. Relative to document recognition, it is challenging because of font variability, minimal language context, and uncontrolled conditions. Much information available to solve this problem is frequently ignored or used sequentially. Similarity between character images is often overlooked as useful information. Because of language priors, a recognizer may assign different labels to identical characters. Directly comparing characters to each other, rather than only a model, helps ensure that similar instances receive the same label. Lexicons improve recognition accuracy but are used post hoc. We introduce a probabilistic model for STR that integrates similarity, language properties, and lexical decision. Inference is accelerated with sparse belief propagation, a bottom-up method for shortening messages by reducing the dependency between weakly supported hypotheses. By fusing information sources in one model, we eliminate unrecoverable errors that result from sequential processing, improving accuracy. In experimental results recognizing text from images of signs in outdoor scenes, incorporating similarity reduces character recognition error by 19 percent, the lexicon reduces word recognition error by 35 percent, and sparse belief propagation reduces the lexicon words considered by 99.9 percent with a 12X speedup and no loss in accuracy.	[Weinman, Jerod J.] Grinnell Coll, Dept Comp Sci, Grinnell, IA 50112 USA; [Learned-Miller, Erik; Hanson, Allen R.] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Weinman, JJ (corresponding author), Grinnell Coll, Dept Comp Sci, 1116 8th Ave, Grinnell, IA 50112 USA.	weinman@grinnell.edu; elm@cs.umass.edu; hanson@cs.umass.edu			NEI NIH HHS [R21 EY018398, R21 EY018398-01] Funding Source: Medline; NATIONAL EYE INSTITUTE [R21EY018398] Funding Source: NIH RePORTER	NEI NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))		[Anonymous], 1959, P E JOINT COMP C, DOI DOI 10.1145/1460299.1460326; Beaufort R, 2007, PROC INT CONF DOC, P889; Breuel TM, 2003, PROC INT CONF DOC, P158; Breuel TM, 2001, INT CONF ACOUST SPEE, P1333, DOI 10.1109/ICASSP.2001.941172; Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223; Coughlan J, 2007, COMPUT VIS IMAGE UND, V106, P47, DOI 10.1016/j.cviu.2005.09.008; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DENG D, 1994, IEEE IMAGE PROC, P940, DOI 10.1109/ICIP.1994.413707; FLEMING PJ, 1986, COMMUN ACM, V29, P218, DOI 10.1145/5666.5673; Goodman J, 2003, EXPONENTIAL PRIORS M; HOBBY J, 1997, P INT C DOC AN REC I, V1, P394; HONG T, 1995, P SDAIR 5 LAS VEG, P177; Jacobs C, 2005, PROC INT CONF DOC, P695, DOI 10.1109/ICDAR.2005.233; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; KUKICH K, 1992, COMPUT SURV, V24, P377; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lucas SM, 2003, PROC INT CONF DOC, P462; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Niblack W., 1986, ADV COMPUTER GRAPHIC; PAL C, 2006, INT CONF ACOUST SPEE, P581; Rayner K., 1989, PSYCHOL READING; Schambach MP, 2005, PROC INT CONF DOC, P9, DOI 10.1109/ICDAR.2005.111; Sutton C., 2005, P C UNC ART INT, P568; Thillou C, 2005, EURASIP J APPL SIG P, V2005, P2127, DOI 10.1155/ASP.2005.2127; Weinman JJ, 2007, PROC INT CONF DOC, P979; WEINMAN JJ, 2006, P IEEE C COMP VIS PA, P308; WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117; ZHANG D, 2003, P COMP VIS PATT REC, V2, P528	29	95	100	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1733	1746		10.1109/TPAMI.2009.38	http://dx.doi.org/10.1109/TPAMI.2009.38			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696446	Green Accepted			2022-12-18	WOS:000268996500002
J	Zomet, A; Feldman, D; Peleg, S; Weinshall, D				Zomet, A; Feldman, D; Peleg, S; Weinshall, D			Mosaicing new views: The crossed-slits projection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonstationary mosaicing; crossed-slits projection; pushbroom camera; virtual walkthrough; image-based rendering	STEREO	We introduce anew kind of mosaicing, where the position of the sampling strip varies as a function of the input camera location. The new images that are generated this way correspond to a new projection model defined by two slits, termed here the Crossed-Slits (X-Slits) projection. In this projection model, every 3D point is projected by a ray defined as the line that passes through that point and intersects the two slits. The intersection of the projection rays with the imaging surface defines the image. X-Slits mosaicing provides two benefits. First, the generated mosaics are closer to perspective images than traditional pushbroom mosaics. Second, by simple manipulations of the strip sampling function, we can change the location of one of the virtual slits, providing a virtual walkthrough of a X-slits camera; all this can be done without recovering any 3D geometry and without calibration. A number of examples where we translate the virtual camera and change its orientation are given; the examples demonstrate realistic changes in parallax, reflections, and occlusions.	Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Zomet, A (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel.	zomet@cs.huji.ac.il; doronf@cs.huji.ac.il; peleg@cs.huji.ac.il; daphna@cs.huji.ac.il	Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				Aliaga DG, 2001, COMP GRAPH, P443, DOI 10.1145/383259.383311; BENEZRA M, 2000, 0021 HEBR U; BERGEN JR, 1992, P EUR C COMP VIS, P237; Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; Kang SB, 1998, PROC SPIE, V3641, P2, DOI 10.1117/12.333774; Kingslake R, 1992, OPTICS PHOTOGRAPHY; KLEIN A, 2001, MSRTR200145 MICR RES; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; NEWHALL B, 1964, HIST PHOTOGRAPHY 183, P162; Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794; Seitz SM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937495; Semple J. G., 1998, ALGEBRAIC PROJECTIVE; Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573; Sloan P.-P., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P17, DOI 10.1145/253284.253296; Takahashi T, 2000, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2000.854815; Weinshall D, 2002, LECT NOTES COMPUT SC, V2350, P614; Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859; ZHENG JY, 1992, INT J COMPUT VISION, V9, P55	25	95	107	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					741	754		10.1109/TPAMI.2003.1201823	http://dx.doi.org/10.1109/TPAMI.2003.1201823			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP		Green Submitted			2022-12-18	WOS:000182961300008
J	CHU, CC; AGGARWAL, JK				CHU, CC; AGGARWAL, JK			THE INTEGRATION OF IMAGE SEGMENTATION MAPS USING REGION AND EDGE INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONTOUR SMOOTHING; INFORMATION INTEGRATION; MAXIMUM LIKELIHOOD ESTIMATION; MULTISCALE PROCESSING; SEGMENTATION		We present an algorithm that integrates multiple region segmentation maps and edge maps. It operates independently of image sources and specific region-segmentation or edge-detection techniques. User-specified weights and the arbitrary mixing of region/edge maps are allowed. The integration algorithm enables multiple edge detection/region segmentation modules to work in parallel as front ends. The solution procedure consists of three steps. A maximum likelihood estimator provides initial solutions to the positions of edge pixels from various inputs. An iterative procedure using only local information (without edge tracing) then minimizes the contour curvature. Finally, regions are merged to guarantee that each region is large and compact. The channel-resolution width controls the spatial scope of the initial estimation and contour smoothing to facilitate multiscale processing. Experimental results are demonstrated using data from different types of sensors and processing techniques. The results show an improvement over individual inputs and a strong resemblance to human-generated segmentation.	UNIV TEXAS,COMP & VIS RES CTR,DEPT ELECT & COMP ENGN,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								ANDERSON HL, 1987, GRASP110 U PENNS LAB; Bachman C.G., 1979, LASER RADAR SYSTEMS; BAKER DC, 1989, J OPT SOC AM A, V6, P938, DOI 10.1364/JOSAA.6.000938; BHANU B, 1990, IEEE T AERO ELEC SYS, V26, P2, DOI 10.1109/7.53409; BOVIK AC, 1988, IEEE T ACOUST SPEECH, V36, P1618, DOI 10.1109/29.7550; CHU C, 1991, J MACHINE VISION APP, V4, P145; CHU CC, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P117; CHU CC, 1990, PATTERN RECOGN, V23, P569, DOI 10.1016/0031-3203(90)90035-J; CHU CC, 1991, SEVENTH IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE APPLICATIONS, VOL 1, P190; FUA P, 1987, P DARPA IMAGE UNDERS, P227; HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867; KASS M, 1987, 1ST P INT C COMP VIS, P259; KOHLER RR, 1984, COINS8404 U MASS TEC; LEVINE MD, 1985, IEEE T PATTERN ANAL, V6, P555; LUO RC, 1987, MAR P IEEE INT C ROB, P1941; Marr D., 1982, VISION, P62; NAKAMURA Y, 1989, IEEE INT C ROB AUT, P668; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; SHER D, 1987, FEB P DARPA IM UND W, P655; SRINATH MD, 1979, INTRO STATISTICAL SI; TOET A, 1990, J MACHINE VISION APP, V3, P1; Tong C. W., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V782, P10, DOI 10.1117/12.940553; Van Trees H. L, 2004, DETECTION ESTIMATION	24	95	102	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1241	1252		10.1109/34.250843	http://dx.doi.org/10.1109/34.250843			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176		Green Submitted			2022-12-18	WOS:A1993MP17600003
J	PORAT, B; FRIEDLANDER, B				PORAT, B; FRIEDLANDER, B			A FREQUENCY-DOMAIN ALGORITHM FOR MULTIFRAME DETECTION AND ESTIMATION OF DIM TARGETS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									SIGNAL PROC TECHNOL LTD,PALO ALTO,CA 94303		PORAT, B (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL.							ADELSON EH, 1985, J OPT SOC AM A, V2, P248; BARNIV Y, 1985, IEEE T AERO ELEC SYS, V21, P144, DOI 10.1109/TAES.1985.310548; Bolles R., 1987, INT J COMPUT VISION, P7; FRIEDLANDER B, 1987, TM100001 SAXP COMP C; FRIEDLANDER B, 1986, 863301 SAXP COMP COR; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; MOHANTY NC, 1981, IEEE T PATTERN ANAL, V3, P606, DOI 10.1109/TPAMI.1981.4767153; WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322	9	95	113	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1990	12	4					398	401		10.1109/34.50625	http://dx.doi.org/10.1109/34.50625			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CV929					2022-12-18	WOS:A1990CV92900006
J	SHIH, FYC; MITCHELL, OR				SHIH, FYC; MITCHELL, OR			THRESHOLD DECOMPOSITION OF GRAY-SCALE MORPHOLOGY INTO BINARY MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	SHIH, FYC (corresponding author), NEW JERSEY INST TECHNOL,DEPT COMP & INFORMAT SCI,NEWARK,NJ 07102, USA.							FITCH JP, 1985, IEEE T CIRCUITS SYST, V32, P445, DOI 10.1109/TCS.1985.1085740; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; MATHERON G., 1975, RANDOM SETS INTEGRAL; MEYER F, 1977, QUANTITATIVE ANAL MI; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Serra J, 1982, IMAGE ANAL MATH MORP; SHIH FY, 1987, DEC P SPIE S AUT INS, P304; SHIH FY, 1987, NOV P SPIE S AUT INS; SHIH FY, 1988, APR P IEEE INT C ROB; SHIH FY, 1988, JUN P COMP SOC C COM, P774; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; STERNBERG SR, 1984, P SOC PHOTO-OPT INST, V504, P202, DOI 10.1117/12.944864; STERNBERG SR, 1983, COMPUTER, V16, P22, DOI 10.1109/MC.1983.1654163; STERNBERG SR, 1985, MAR P IEEE C AC SPEE, P462; STERNBERG SR, 1980, MAY US FRANC SEM BIO; STERNBERG SR, 1982, BIOMEDICAL IMAGES CO, P294; STERNBERG SR, 1983, OCT IEEE WORKSH COMP, P237; WENDT PD, 1986, IEEE T ACOUST SPEECH, V34, P898, DOI 10.1109/TASSP.1986.1164871	18	95	100	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					31	42		10.1109/34.23111	http://dx.doi.org/10.1109/34.23111			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474					2022-12-18	WOS:A1989R447400003
J	ESHERA, MA; FU, KS				ESHERA, MA; FU, KS			AN IMAGE UNDERSTANDING SYSTEM USING ATTRIBUTED SYMBOLIC REPRESENTATION AND INEXACT GRAPH-MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	ESHERA, MA (corresponding author), MARTIN MARIETTA CORP,DEPT ARTIFICIAL INTELLIGENCE,BALTIMORE,MD 21227, USA.							AHUJA N, 1984, IEEE T PATTERN ANAL, V6, P463, DOI 10.1109/TPAMI.1984.4767551; Eshera M. A., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P75; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; ESHERA MA, 1985, TREE858 PURD U SCH E; ESHERA MA, 1983, MAY P ONR WORKSH STA; ESHERA MA, 1986, UNPUB HIERARCHIAL SC; Fu K. S., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P18; FU KS, 1983, IEEE T PATTERN ANAL, V5, P200; FU KS, 1982, SYNTACTIC PATTERN RE; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HOROWITZ SL, 1974, 2ND P INT JOINT C PA, P424; LEE JS, 1983, IEEE T SYST MAN CYB, V13, P85, DOI 10.1109/TSMC.1983.6313036; LU SY, 1978, IEEE T SYST MAN CYBE, V8; Pavlidis T., 1977, STRUCTURAL PATTERN R; SANFELIU A, 1983, IEEE T SYST MAN CYBE, V13; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; TSAI WH, 1980, IEEE T SYST MAN CYB, V10, P873, DOI 10.1109/TSMC.1980.4308414; YOU KC, 1979, IEEE T SYST MAN CYB, V9, P334, DOI 10.1109/TSMC.1979.4310222	20	95	100	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					604	618		10.1109/TPAMI.1986.4767835	http://dx.doi.org/10.1109/TPAMI.1986.4767835			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584	21869359				2022-12-18	WOS:A1986D758400003
J	WELLS, WM				WELLS, WM			EFFICIENT SYNTHESIS OF GAUSSIAN FILTERS BY CASCADED UNIFORM FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WELLS, WM (corresponding author), SRI INT,MENLO PK,CA 94025, USA.							BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; BURT PJ, 1980, TR860 U MAR COMP VIS; CANNY JF, 1983, MIT720 AI LAB TECH R; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P212, DOI 10.1109/TPAMI.1984.4767504; CROWLEY JL, 1984, MAR P IEEE WORKSH VI, P95; Feller W., 1957, INTRO PROBABILITY TH; FRIEDEN BR, 1983, PROBABILITY STATISTI; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MCDONNELL MJ, 1980, TR966 U MAR COMP VIS; Nicholson W. Q., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P467; Ponce J., 1985, P IEEE INT C ROB AUT, P420; PRICE KE, 1976, THESIS CARNEGIE MELL; WITKIN AP, 1983, 7TH P INT JOINT C AR, P1019	17	95	102	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					234	239		10.1109/TPAMI.1986.4767776	http://dx.doi.org/10.1109/TPAMI.1986.4767776			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869341				2022-12-18	WOS:A1986A107300010
J	FAUGERAS, OD; BERTHOD, M				FAUGERAS, OD; BERTHOD, M			IMPROVING CONSISTENCY AND REDUCING AMBIGUITY IN STOCHASTIC LABELING - AN OPTIMIZATION APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST IMAGE PROCESSING,LOS ANGELES,CA 90007	University of Southern California								BARNARD ST, 1979, 791 U MINN I TECHN D; BERTHOD M, UNPUBLISHED; EKLUNDH JO, 1978, 662 U MAR DEP COMP S; FAUGERAS OD, 1980, IEEE T PATTERN ANAL, V2, P323, DOI 10.1109/TPAMI.1980.4767031; FAUGERAS OD, 1979 P PRIP C, P318; Fox R.L, 1971, OPTIMIZATION METHODS; Hanson A. R., 1978, COMPUTER VISION SYST, P129; Lasdon L.S., 1970, OPTIMIZATION THEORY; LIONS JL, 1974, METHODES NUMERIQUES; Luenberger D. G., 1969, OPTIMIZATION VECTOR; Mesarovic MD, 1970, THEORY HIERARCHICAL; Pavlidis T., 1977, STRUCTURAL PATTERN R; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PELEG S, 1979, 721 U MAR DEP COMP S; PELEG S, 1979, 1979 P IEEE C PATT R, P337; PELEG S, 1979, 724 U MAR DEP COMP S; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHACHTER B, 1976, 476 U MAR DEP COMP S; ULLMAN S, 1979, COMPUT VISION GRAPH, V10, P115, DOI 10.1016/0146-664X(79)90045-5; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1978, 7815R DEP EL ENG COM; ZUCKER SW, 1978, 783R DEP EL ENG COMP; ZUCKER SW, 1978 P PRIP C, P307; ZUCKER SW, 1978 P IEEE PRIP C, P410	27	95	95	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					412	424		10.1109/TPAMI.1981.4767127	http://dx.doi.org/10.1109/TPAMI.1981.4767127			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868962				2022-12-18	WOS:A1981MQ35700006
J	Xu, M; Song, YH; Wang, JY; Qiao, ML; Huo, LY; Wang, ZL				Xu, Mai; Song, Yuhang; Wang, Jianyi; Qiao, Minglang; Huo, Liangyu; Wang, Zulin			Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Panoramic video; head movement; reinforcement learning; deep learning	VISUAL-ATTENTION; MODEL; HEVC	Panoramic video provides immersive and interactive experience by enabling humans to control the field of view (FoV) through head movement (HM). Thus, HM plays a key role in modeling human attention on panoramic video. This paper establishes a database collecting subjects' HM in panoramic video sequences. From this database, we find that the HM data are highly consistent across subjects. Furthermore, we find that deep reinforcement learning (DRL) can be applied to predict HM positions, via maximizing the reward of imitating human HM scanpaths through the agent's actions. Based on our findings, we propose a DRL-based HM prediction (DHP) approach with offline and online versions, called offline-DHP and online-DHP. In offline-DHP, multiple DRL workflows are run to determine potential HM positions at each panoramic frame. Then, a heat map of the potential HM positions, named the HM map, is generated as the output of offline-DHP. In online-DHP, the next HM position of one subject is estimated given the currently observed HM position, which is achieved by developing a DRL algorithm upon the learned offline-DHP model. Finally, the experiments validate that our approach is effective in both offline and online prediction of HM positions for panoramic video, and that the learned offline-DHP model can improve the performance of online-DHP.	[Xu, Mai; Song, Yuhang; Wang, Jianyi; Qiao, Minglang; Huo, Liangyu; Wang, Zulin] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China	Beihang University	Xu, M (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.	MaiXu@buaa.edu.cn; yuhangsong2017@gmail.com; IceClearWJY@buaa.edu.cn; MinglangQiao@buaa.edu.cn; huoliangyu@buaa.edu.cn; wzulinj@buaa.edu.cn	Wang, Jianyi/ADL-2553-2022	Wang, Jianyi/0000-0001-7025-3626; Song, Yuhang/0000-0002-7999-0291	National Nature Science Foundation of China [61573037]; Fok Ying Tung Education Foundation [151061]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fok Ying Tung Education Foundation(Fok Ying Tung Education Foundation)	This work was supported by the National Nature Science Foundation of China under Grant 61573037 and by the Fok Ying Tung Education Foundation under Grant 151061. M. Xu and Y. Song contributed equally to this work.	Assens M, 2017, IEEE INT CONF COMP V, P2331, DOI 10.1109/ICCVW.2017.275; Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665; Bazzani Loris, 2017, ICLR; Boccignone G, 2008, INT C PATT RECOG, P1; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Calderara S., 2017, PUBLIC PROCUREMENT F, P1; de la Fuente YS, 2017, MULTIMED TOOLS APPL, V76, P5631, DOI 10.1007/s11042-016-4097-4; Du H, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P153, DOI 10.1145/2908446.2908453; Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1419, DOI 10.1109/ICME.2000.871033; Gaddam VR, 2016, IEEE T MULTIMEDIA, V18, P1819, DOI 10.1109/TMM.2016.2586304; Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Hausknecht Matthew, 2015, 2015 AAAI FALL S SER; Hu HN, 2017, PROC CVPR IEEE, P1396, DOI 10.1109/CVPR.2017.153; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; ITTI L, 2009, VISION RES, V49, P1295, DOI DOI 10.1016/J.VISRES.2008.09.007; Jaderberg Max, 2017, ICLR; Jiang M, 2016, IEEE T NEUR NET LEAR, V27, P1241, DOI 10.1109/TNNLS.2015.2496306; Jiang Y, 2009, 2009 3RD INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, VOLS 1-11, P2944; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Khatoonabadi SH, 2015, PROC CVPR IEEE, P5501, DOI 10.1109/CVPR.2015.7299189; Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620; Kummerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513; Li J, 2015, IEEE I CONF COMP VIS, P190, DOI 10.1109/ICCV.2015.30; Lin YC, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2535, DOI 10.1145/3025453.3025757; Lin YW, 2013, IEEE T PATTERN ANAL, V35, P314, DOI 10.1109/TPAMI.2012.119; Liu HY, 2013, IEEE I CONF COMP VIS, P3232, DOI 10.1109/ICCV.2013.401; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Liu YF, 2017, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2017.343; Lowe T., 2015, P WORKSH EYE TRACK V, V1; MATIN E, 1974, PSYCHOL BULL, V81, P899, DOI 10.1037/h0037368; Minut S., 2001, P 5 INT C AUT AG, P457; Mnih V., 2014, NEURAL INFORM PROCES, DOI DOI 10.48550/ARXIV.1406.6247; Mnih V, 2016, PR MACH LEARN RES, V48; Neumann U., 2000, P 8 ACM INT C MULT, P493; Pan Junting, 2017, ABS170101081 CORR; Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren ZX, 2013, IEEE T IMAGE PROCESS, V22, P3120, DOI 10.1109/TIP.2013.2259837; SHUMAKER BP, 1984, SKY TELESCOPE, V68, P158; Stengel M, 2016, IEEE SIGNAL PROC MAG, V33, P139, DOI 10.1109/MSP.2016.2580913; Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191; Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50; Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423; Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang ZY, 2016, PR MACH LEARN RES, V48; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Xinding Sun, 2005, IEEE Transactions on Multimedia, V7, P981, DOI 10.1109/TMM.2005.854388; Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351; Xu M, 2017, IEEE T IMAGE PROCESS, V26, P369, DOI 10.1109/TIP.2016.2628583; Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844	56	94	94	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2693	2708		10.1109/TPAMI.2018.2858783	http://dx.doi.org/10.1109/TPAMI.2018.2858783			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30047871	Green Submitted			2022-12-18	WOS:000489838200010
J	Tang, JH; Shu, XB; Qi, GJ; Li, ZC; Wang, M; Yan, SC; Jain, R				Tang, Jinhui; Shu, Xiangbo; Qi, Guo-Jun; Li, Zechao; Wang, Meng; Yan, Shuicheng; Jain, Ramesh			Tri-Clustered Tensor Completion for Social-Aware Image Tag Refinement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Social image tag refinement; tensor completion; tri-clustering	ANNOTATION	Social image tag refinement, which aims to improve tag quality by automatically completing the missing tags and rectifying the noise-corrupted ones, is an essential component for social image search. Conventional approaches mainly focus on exploring the visual and tag information, without considering the user information, which often reveals important hints on the (in) correct tags of social images. Towards this end, we propose a novel tri-clustered tensor completion framework to collaboratively explore these three kinds of information to improve the performance of social image tag refinement. Specifically, the inter-relations among users, images and tags are modeled by a tensor, and the intra-relations between users, images and tags are explored by three regularizations respectively. To address the challenges of the super-sparse and large-scale tensor factorization that demands expensive computing and memory cost, we propose a novel tri-clustering method to divide the tensor into a certain number of sub-tensors by simultaneously clustering users, images and tags into a bunch of tri-clusters. And then we investigate two strategies to complete these sub-tensors by considering (in) dependence between the sub-tensors. Experimental results on a real-world social image database demonstrate the superiority of the proposed method compared with the state-of-the-art methods.	[Tang, Jinhui; Shu, Xiangbo; Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Qi, Guo-Jun] Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA; [Wang, Meng] Hefei Univ Technol, Dept Comp Sci, Hefei 230009, Anhui, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Jain, Ramesh] Univ Calif Irvine, Irvine, CA 92617 USA	Nanjing University of Science & Technology; State University System of Florida; University of Central Florida; Hefei University of Technology; National University of Singapore; University of California System; University of California Irvine	Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.	jinhuitang@njust.edu.cn; shuxb104@gmail.com; guojun.qi@ucf.edu; zechao.li@njust.edu.cn; eric.mengwang@gmail.com; eleyans@nus.edu.sg; jain@ics.uci.edu	Yan, Shuicheng/HCI-1431-2022; Shu, Xiangbo/AAC-6245-2022; Qi, Guo-Jun/AAH-8294-2019	Shu, Xiangbo/0000-0003-4902-4663; 	973 Program of China [2014CB347600]; National Natural Science Foundation of China [61522203, 61402228]; National Ten Thousand Talent Program of China (Young Top-Notch Talent)	973 Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Ten Thousand Talent Program of China (Young Top-Notch Talent)	This work was partially supported by the 973 Program of China (Project No. 2014CB347600), the National Natural Science Foundation of China (Grant Nos. 61522203 and 61402228), and the National Ten Thousand Talent Program of China (Young Top-Notch Talent).	Benoit A, 2006, FUTURE GENER COMP SY, V22, P838, DOI 10.1016/j.future.2006.02.006; Candes EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Crandall P. E., 1993, Proceedings the 2nd International Symposium on High Performance Distributed Computing (Cat. No.93TH0550-4), P42, DOI 10.1109/HPDC.1993.263859; Cui P, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2590974; Czekster R.M., 2010, P 2010 SPRING SIM MU, P242; Deng ZH, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1143, DOI 10.1145/2733373.2806302; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550; Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598; Li X, 2014, IEEE IMAGE PROC, P3062, DOI 10.1109/ICIP.2014.7025619; Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461; Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65; Li Zheng, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1187, DOI 10.1145/1873951.1874183; Lin DK, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P64; Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212; Liu D., 2010, P INT C MULT, P491; Liu D., 2009, P 18 INT C WORLD WID, P351; Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380; Liu XB, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2168996.2169001; Papalexakis Evangelos E., 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P521, DOI 10.1007/978-3-642-33460-3_39; Qi G.-J., 2012, P 22 INT C WORLD WID, P1041; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Resnik P, 1995, INT JOINT CONF ARTIF, P448; Sang J., 2011, P 19 ACM INT C MULT, P1129, DOI DOI 10.1145/2072298.2071956.ISBN; Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782; Tang J., 2011, ACM T INTEL SYST TEC, P14, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]; Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Wang C. C., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383221; Wang Changhu, 2006, P 14 ANN ACM INT C M, P647, DOI DOI 10.1145/1180639.1180774; Wang JZ, 2008, IEEE T PATTERN ANAL, V30, P1873, DOI 10.1109/TPAMI.2008.231; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Wu L, 2012, IEEE T PATTERN ANAL, V34, P863, DOI 10.1109/TPAMI.2011.195; Xiaofei He, 2005, 13th Annual ACM International Conference on Multimedia, P132; Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320; Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706; Zhao L., 2005, P 2005 ACM SIGMOD IN, P694, DOI [10.1145/1066157.1066236, DOI 10.1145/1066157.1066236]; Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204; Zhou QB, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P311; Zhu G., 2010, ACM MULT, P461; Zhuang J., 2011, PROC INT C WEB SEARC, P625	43	94	97	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1662	1674		10.1109/TPAMI.2016.2608882	http://dx.doi.org/10.1109/TPAMI.2016.2608882			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	28113651				2022-12-18	WOS:000404606300013
J	Joze, HRV; Drew, MS				Joze, Hamid Reza Vaezi; Drew, Mark S.			Exemplar-Based Color Constancy and Multiple Illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; exemplar based learning; multiple illuminants	OBJECT; CHROMATICITY; IMAGES	Exemplar-based learning or, equally, nearest neighbor methods have recently gained interest from researchers in a variety of computer science domains because of the prevalence of large amounts of accessible data and storage capacity. In computer vision, these types of technique have been successful in several problems such as scene recognition, shape matching, image parsing, character recognition, and object detection. Applying the concept of exemplar-based learning to the problem of color constancy seems odd at first glance since, in the first place, similar nearest neighbor images are not usually affected by precisely similar illuminants and, in the second place, gathering a dataset consisting of all possible real-world images, including indoor and outdoor scenes and for all possible illuminant colors and intensities, is indeed impossible. In this paper, we instead focus on surfaces in the image and address the color constancy problem by unsupervised learning of an appropriate model for each training surface in training images. We find nearest neighbor models for each surface in a test image and estimate its illumination based on comparing the statistics of pixels belonging to nearest neighbor surfaces and the target surface. The final illumination estimation results from combining these estimated illuminants over surfaces to generate a unique estimate. We show that it performs very well, for standard datasets, compared to current color constancy algorithms, including when learning based on one image dataset is applied to tests from a different dataset. The proposed method has the advantage of overcoming multi-illuminant situations, which is not possible for most current methods since they assume the color of the illuminant is constant all over the image. We show a technique to overcome the multiple illuminant situation using the proposed method and test our technique on images with two distinct sources of illumination using a multiple-illuminant color constancy dataset. The concept proposed here is a completely new approach to the color constancy problem and provides a simple learning-based framework.	[Joze, Hamid Reza Vaezi; Drew, Mark S.] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University	Joze, HRV (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	hrv1@sfu.ca; mark@cs.sfu.ca						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Belongie S, 2001, ADV NEUR IN, V13, P831; Bianco S, 2010, PATTERN RECOGN, V43, P695, DOI 10.1016/j.patcog.2009.08.007; Bianco S, 2008, IEEE T IMAGE PROCESS, V17, P2381, DOI 10.1109/TIP.2008.2006661; Bleier M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P774, DOI 10.1109/ICCVW.2011.6130331; Boyadzhiev I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366219; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P311; Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374; Chakrabarti A., 2008, P IEEE CVPR; Chakrabarti A, 2012, IEEE T PATTERN ANAL, V34, P1509, DOI 10.1109/TPAMI.2011.252; Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Drew M., 2009, P 17 COL IMAG C SPRI; Drew M., 2012, P ECCV; Drew M., 1998, P 6 ICCV BOMB IND; Ebner M, 2004, LECT NOTES COMPUT SC, V3023, P276; Finlayson G., 1995, P 5 ICCV CAMBR MA US; Finlayson G. D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P164, DOI 10.1109/ICCV.1993.378223; Finlayson G. D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P835, DOI 10.1109/ICCV.1999.790308; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582; Forsyth D., 1988, INT C COMP VIS 88, P9; Gehler P., 2008, P IEEE CVPR; GIJSENIJ A, 2008, INT J COMPUT VISION, V86, P127; Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93; Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243; Granzier JJM, 2012, I-PERCEPTION, V3, P190, DOI 10.1068/i0461; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226; Hsu E, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1399504.1360669, 10.1145/1360612.1360669]; Kuang J., 2008, P COL IMAG C; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li B, 2009, COLOR TECHNOL, V125, P328, DOI 10.1111/j.1478-4408.2009.00214.x; Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Mosny M., 2012, P COL IMAG C; Olkkonen M, 2008, J VISION, V8, DOI 10.1167/8.8.8; Rahtu E, 2009, LECT NOTES COMPUT SC, V5716, P873, DOI 10.1007/978-3-642-04146-4_93; Rosenberg C., 2003, P NIPS; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Shi L., 2010, RE PROCESSED VERSION; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Tsukada M., 1990, P 3 ICCV OS JAP; Vaezi Joze H., 2012, P 19 IEEE ICIP ORL F; Vaezi Joze H., 2012, P BMVC; Vaezi Joze H., 2010, P 17 IEEE ICIP HONG; van de Weijer J., 2007, P IEEE ICCV RIO JAN; van de Weijer J., 2005, P ICIP; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; Wu M, 2010, J OPT SOC AM A, V27, P2097, DOI 10.1364/JOSAA.27.002097; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xiong WH, 2006, J IMAGING SCI TECHN, V50, P341, DOI 10.2352/J.ImagingSci.Technol.(2006)50:4(341)	63	94	101	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					860	873		10.1109/TPAMI.2013.169	http://dx.doi.org/10.1109/TPAMI.2013.169			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353222				2022-12-18	WOS:000336054200003
J	Ulrich, M; Wiedemann, C; Steger, C				Ulrich, Markus; Wiedemann, Christian; Steger, Carsten			Combining Scale-Space and Similarity-Based Aspect Graphs for Fast 3D Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object recognition; machine vision; aspect graphs; similarity measures; hierarchical; models; robotics; industrial automation; image generation; projections; shape; feature measurement; least squares methods; perspective	POSE ESTIMATION; TRACKING; MODEL; SHAPE	This paper describes an approach for recognizing instances of a 3D object in a single camera image and for determining their 3D poses. A hierarchical model is generated solely based on the geometry information of a 3D CAD model of the object. The approach does not rely on texture or reflectance information of the object's surface, making it useful for a wide range of industrial and robotic applications, e.g., bin-picking. A hierarchical view-based approach that addresses typical problems of previous methods is applied: It handles true perspective, is robust to noise, occlusions, and clutter to an extent that is sufficient for many practical applications, and is invariant to contrast changes. For the generation of this hierarchical model, a new model image generation technique by which scale-space effects can be taken into account is presented. The necessary object views are derived using a similarity-based aspect graph. The high robustness of an exhaustive search is combined with an efficient hierarchical search. The 3D pose is refined by using a least-squares adjustment that minimizes geometric distances in the image, yielding a position accuracy of up to 0.12 percent with respect to the object distance, and an orientation accuracy of up to 0.35 degree in our tests. The recognition time is largely independent of the complexity of the object, but depends mainly on the range of poses within which the object may appear in front of the camera. For efficiency reasons, the approach allows the restriction of the pose range depending on the application. Typical runtimes are in the range of a few hundred ms.	[Ulrich, Markus; Wiedemann, Christian; Steger, Carsten] MVTec Software GmbH, D-81675 Munich, Germany		Ulrich, M (corresponding author), MVTec Software GmbH, Neherstr 1, D-81675 Munich, Germany.	ulrich@mvtec.com; wiedemann@mvtec.com; steger@mvtec.com		Steger, Carsten/0000-0003-3426-1703				BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; Borotschnig H, 2000, IMAGE VISION COMPUT, V18, P715, DOI 10.1016/S0262-8856(99)00075-X; Byne JHM, 1998, IMAGE VISION COMPUT, V16, P533, DOI 10.1016/S0262-8856(98)00100-0; Costa MS, 2000, COMPUT VIS IMAGE UND, V79, P364, DOI 10.1006/cviu.2000.0865; Cyr CM, 2004, INT J COMPUT VISION, V57, P5, DOI 10.1023/B:VISI.0000013088.59081.4c; David P, 2005, IEEE I CONF COMP VIS, P1581; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; Dickinson SJ, 1999, IEEE T PATTERN ANAL, V21, P673, DOI 10.1109/34.784283; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620; EGGERT DW, 1993, IEEE T PATTERN ANAL, V15, P1114, DOI 10.1109/34.244674; Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; Hinterstoisser S., 2007, P 11 IEEE INT C COMP; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jurie F, 1998, PATTERN RECOGN LETT, V19, P331, DOI 10.1016/S0167-8655(97)00175-X; Kender J.R., 1998, P 10 INT JOINT C ART, P801; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; Kollnig H, 1997, INT J COMPUT VISION, V23, P283, DOI 10.1023/A:1007927317325; LANSER S, 1995, INTELLIGENT AUTONOMOUS SYSTEMS - IAS-4, P529; Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Nayar SK, 1996, PROC CVPR IEEE, P471, DOI 10.1109/CVPR.1996.517114; Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293; Roy SD, 2000, IEEE T SYST MAN CY A, V30, P67, DOI 10.1109/3468.823482; Schiffenbauer R. D., 2001, TRCIS200101 POL U; Steger C., 2002, INT ARCH PHOTOGR REM, V34, P345; Steger C., 2000, INT ARCH PHOTOGRA B3, V33, P141; Steger C, 2007, MACHINE VISION ALGOR; Strzodka R, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P188, DOI 10.1109/ICIAP.2003.1234048; Ulrich M, 2003, PATTERN RECOGN, V36, P2557, DOI 10.1016/S0031-3203(03)00169-9; ULRICH M, 2003, THESIS TU MUNCHEN C; Ulrich M, 2009, IEEE INT CONF ROBOT, P2090; Vijayakumar B, 1998, COMPUT VIS IMAGE UND, V72, P287, DOI 10.1006/cviu.1998.0701; von Bank C, 2003, LECT NOTES COMPUT SC, V2781, P179; Weiss I, 2001, IEEE T PATTERN ANAL, V23, P116, DOI 10.1109/34.908963; Wiedemann C, 2008, LECT NOTES COMPUT SC, V5096, P132, DOI 10.1007/978-3-540-69321-5_14; Zerroug M., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P317; ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2	46	94	99	1	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1902	1914		10.1109/TPAMI.2011.266	http://dx.doi.org/10.1109/TPAMI.2011.266			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22201058				2022-12-18	WOS:000307522700003
J	Schroff, F; Criminisi, A; Zisserman, A				Schroff, Florian; Criminisi, Antonio; Zisserman, Andrew			Harvesting Image Databases from the Web	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised; computer vision; object recognition; image retrieval		The objective of this work is to automatically generate a large number of images for a specified object class. A multimodal approach employing both text, metadata, and visual features is used to gather many high-quality images from the Web. Candidate images are obtained by a text-based Web search querying on the object identifier (e.g., the word penguin). The Webpages and the images they contain are downloaded. The task is then to remove irrelevant images and rerank the remainder. First, the images are reranked based on the text surrounding the image and metadata features. A number of methods are compared for this reranking. Second, the top-ranked images are used as (noisy) training data and an SVM visual classifier is learned to improve the ranking further. We investigate the sensitivity of the cross-validation procedure to this noisy training data. The principal novelty of the overall method is in combining text/metadata and visual features in order to achieve a completely automatic ranking of the images. Examples are given for a selection of animals, vehicles, and other classes, totaling 18 classes. The results are assessed by precision/recall curves on ground-truth annotated data and by comparison to previous approaches, including those of Berg and Forsyth [5] and Fergus et al. [12].	[Schroff, Florian] Univ Calif San Diego, Dept Comp Sci & Engn, San Diego, CA 92093 USA; [Criminisi, Antonio] Microsoft Res Cambridge, Cambridge CB3 0FB, England; [Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England	University of California System; University of California San Diego; Microsoft; University of Oxford	Schroff, F (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, San Diego, CA 92093 USA.	gschroff@cs.ucsd.edu; antcrim@microsoft.com; az@robots.ox.ac.uk			ERC [228180]; Royal Academy of Engineering; Microsoft Research; EU	ERC(European Research Council (ERC)European Commission); Royal Academy of Engineering(Royal Academy of Engineering - UK); Microsoft Research(Microsoft); EU(European Commission)	The authors are grateful for financial support from Microsoft Research through a European PhD scholarship, EU Project CLASS, ERC grant VisRec no. 228180, and the Royal Academy of Engineering.	Aslam J. A., 2001, SIGIR Forum, P276; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BERG T, 2006, ANIMALS WEB DATA SET; BERG T, 2004, P IEEE C COMP VIS PA; BERG TL, 2006, P IEEE C COMP VIS PA; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COLLINS B, 2008, P 10 EUR C COMP VIS; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DORKO G, 2003, P 9 INT C COMP VIS; FERGUS R, 2005, P 10 INT C COMP VIS; FERGUS R, 2004, P 8 EUR C COMP VIS M; FRANKEL C, 1997, WEBSEER IMAGE SEARCH; FRITZ M, 2008, P IEEE C COMP VIS PA; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Hofmann T., 1999, P C UNC ART INT; JOACHIMS T, 2010, SVMLIGHT; KADIR T, 2004, P 8 EUR C COMP VIS M; LI J, 2007, P IEEE C COMP VIS PA; LIN WH, 2003, P IADIS INT C WWW IN; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; MIKOLAJCZYK K, 2004, P 8 EUR C COMP VIS M; Morik K., 1999, P 16 INT C MACH LEAR; *ON, 2010, ONIX TEXT RETR TOOLK; Porter Martin F, 2002, ENGLISH PORTER2 STEM; SAENKO K, 2008, P C ADV NEUR INF PRO; Schroff F., 2007, P 11 INT C COMP VIS; SCHROFF F, 2007, HARVESTING IMAGE DAT; SCHROFF F, 2009, THESIS U OXFORD; TEH Y, 2003, HIERARCHICAL DIRICHL; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; *VGG, 2010, AFF COV FEAT; VIJAYANARASIMHA.S, 2008, P IEEE C COMP VIS PA; Wang G., 2008, P IEEE C COMP VIS PA, P1; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	35	94	98	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					754	766		10.1109/TPAMI.2010.133	http://dx.doi.org/10.1109/TPAMI.2010.133			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	21330688				2022-12-18	WOS:000287370400008
J	Boutemedjet, S; Bouguila, N; Ziou, D				Boutemedjet, Sabri; Bouguila, Nizar; Ziou, Djemel			A Hybrid Feature Extraction Selection Approach for High-Dimensional Non-Gaussian Data Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised learning; mixture models; feature selection; dimensionality reduction; generalized Dirichlet mixture; EM; MML; information theory; object image categorization	STATISTICAL PATTERN-RECOGNITION; DIRICHLET MIXTURE MODEL; UNSUPERVISED SELECTION	This paper presents an unsupervised approach for feature selection and extraction in mixtures of generalized Dirichlet (GD) distributions. Our method defines a new mixture model that is able to extract independent and non-Gaussian features without loss of accuracy. The proposed model is learned using the Expectation-Maximization algorithm by minimizing the message length of the data set. Experimental results show the merits of the proposed methodology in the categorization of object images.	[Boutemedjet, Sabri; Ziou, Djemel] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada; [Bouguila, Nizar] Concordia Univ, Concordia Inst Informat Engn CIISE, Montreal, PQ H3G 1T7, Canada	University of Sherbrooke; Concordia University - Canada	Boutemedjet, S (corresponding author), Univ Sherbrooke, Dept Informat, 2500 Boul Univ, Sherbrooke, PQ J1K 2R1, Canada.	sabri.boutemed@usherbrooke.ca; bouguila@ciise.concordia.ca; cjemel.ziou@usherbrooke.ca	Bouguila, Nizar/AAJ-2518-2020; Bouguila, Nizar/AGN-5929-2022		Natural Sciences and Engineering Research Council of Canada (NSERC); Bell University Laboratories RD program; Concordia University	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Bell University Laboratories RD program; Concordia University	The completion of this research was made possible thanks to the Natural Sciences and Engineering Research Council of Canada (NSERC), Bell Canada's support through its Bell University Laboratories R&D program, and a start-up grant from Concordia University. The authors would like to thank the anonymous referees and the associate editor for their helpful comments.	BOSCH A, 2006, P EUR C COMP VIS, P517; Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664; BOUGUILA N, 2003, P 3 INT C MACH LEARN, P172; BOUGUILA N, 2006, STAT COMPUTING, V16; Bouguila N, 2007, IEEE T PATTERN ANAL, V29, P1716, DOI 10.1109/TPAMl.2007.1095; Bouguila N, 2006, IEEE T KNOWL DATA EN, V18, P993, DOI 10.1109/TKDE.2006.133; Bouguila N, 2006, IEEE T IMAGE PROCESS, V15, P2657, DOI 10.1109/TIP.2006.877379; BOUTEMEDJET S, 2007, P INT C IM AN REC, P330; CONNOR RJ, 1977, J AM STAT ASSOC, V39, P1; Constantinopoulos C, 2006, IEEE T PATTERN ANAL, V28, P1013, DOI 10.1109/TPAMI.2006.111; Csurka Gabriella, 2004, P ECCV INT WORKSH ST; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dy JG, 2004, J MACH LEARN RES, V5, P845; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; FEIFEI L, 2004, P IEEE CVPR WORKSH G; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FRIEDMAN JH, 2004, J ROYAL STAT SOC B, V66, P1, DOI DOI 10.1111/J.1467-9868.2004.02059.X; Graham MW, 2006, IEEE T SIGNAL PROCES, V54, P1289, DOI 10.1109/TSP.2006.870586; GRIM J, 1986, KYBERNETIKA, V22, P142; Grim J, 2002, PATTERN ANAL APPL, V5, P221, DOI 10.1007/s100440200020; Grim J, 2000, INT C PATT RECOG, P585, DOI 10.1109/ICPR.2000.906142; Grim J., 1999, P 4 SYST SCI EUR C V, P527; Grim J, 2006, INT C PATT RECOG, P235; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; LAW MHC, 2002, ADV NEURAL INFORM PR, V15, P625; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mao KZ, 2005, IEEE T SYST MAN CY B, V35, P339, DOI 10.1109/TSMCB.2004.843269; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Novovicova J, 1996, IEEE T PATTERN ANAL, V18, P218, DOI 10.1109/34.481557; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pan W, 2007, J MACH LEARN RES, V8, P1145; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; ROBERT CP, 2002, CAHIER DUCEREMADE; Robert CP., 2001, BAYESIAN CHOICE; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; VAITHYANATHAN S, 1999, ADV NEURAL INFORMATI, V12, P970; WANG HY, 2007, P 24 INT C MACH LEAR	42	94	98	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1429	1443		10.1109/TPAMI.2008.155	http://dx.doi.org/10.1109/TPAMI.2008.155			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542577				2022-12-18	WOS:000267050600007
J	Fu, Y; Yan, SC; Huang, TS				Fu, Yun; Yan, Shuicheng; Huang, Thomas S.			Correlation Metric for Generalized Feature Extraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; graph embedding; correlation embedding analysis; correlational principal component analysis; face recognition	FACE RECOGNITION; DIMENSIONALITY REDUCTION; CLASSIFICATION; ILLUMINATION	Beyond conventional linear and kernel-based feature extraction, we present a more generalized formulation for feature extraction in this paper. Two representative algorithms using the correlation metric are proposed based on this formulation. Correlation Embedding Analysis (CEA), which incorporates both correlational mapping and discriminant analysis, boosts the discriminating power by mapping the data from a high-dimensional hypersphere onto another low-dimensional hypersphere and preserving the neighboring relations with local-sensitive graph modeling. Correlational Principal Component Analysis (CPCA) generalizes the Principal Component Analysis (PCA) algorithm to the case with data distributed on a high-dimensional hypersphere. Their advantages stem from two facts: 1) directly working on normalized data, which are often the outputs from data preprocessing, and 2) directly designed with the correlation metric, which is shown to be generally better than euclidean distance for classification purpose in many real-world applications. Extensive visual recognition experiments compared with existing feature extraction algorithms demonstrate the effectiveness of the proposed algorithms.	[Fu, Yun; Huang, Thomas S.] Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	University of Illinois System; University of Illinois Urbana-Champaign; National University of Singapore	Fu, Y (corresponding author), Univ Illinois, Beckman Inst Adv Sci & Technol, 405 N Mathews Ave, Urbana, IL 61801 USA.	yunfu2@ifp.uiuc.edu; eleyans@nus.edu.sg; huang@ifp.uiuc.edu	Yan, Shuicheng/HCI-1431-2022		Beckman Graduate; US Government; AcRF Tier-1, Singapore [R-263-000-464-112]	Beckman Graduate; US Government; AcRF Tier-1, Singapore	This work was supported in part by the Beckman Graduate Fellowship, in part by the US Government VACE Program, and in part by the AcRF Tier-1, Singapore, under Grant R-263-000-464-112.	Banerjee A, 2005, J MACH LEARN RES, V6, P1345; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y., 2004, ADV NEURAL INFORM PR; CAI D, 2007, P 20 INT JOINT C ART, P708; CAI D, 2007, P 11 IEEE C COMP VIS; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Chen HT, 2005, PROC CVPR IEEE, P846; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Duda R.O., 2000, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FU Y, 2008, P IEEE INT C IM PROC; FU Y, 2007, P IEEE CVPR 1 WORKSH; Fu Y, 2008, IEEE T INF FOREN SEC, V3, P91, DOI 10.1109/TIFS.2007.916280; Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Graf ABA, 2003, IEEE T NEURAL NETWOR, V14, P597, DOI 10.1109/TNN.2003.811708; Ham J., 2004, P 21 INT C MACH LEAR, P47, DOI [10.1145/1015330.1015417, DOI 10.1145/1015330.1015417]; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kumar B.V.K. Vijaya, 2006, CORRELATION PATTERN; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li S.Z., 2005, HDB FACE RECOGNITION; Li ZF, 2005, PROC CVPR IEEE, P961; LIN D., 2005, P IEEE INT C IM PROC, V3, P764; MA Y, 2007, P 24 INT C MACH LEAR, V227, P577; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Rapisarda F., 2007, IMA Journal of Management Mathematics, V18, P55, DOI 10.1093/imaman/dp1010; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Weinberger KQ, 2004, PROC CVPR IEEE, P988; Weingessel A, 2000, IEEE T NEURAL NETWOR, V11, P1242, DOI 10.1109/72.883408; Yan SC, 2004, LECT NOTES COMPUT SC, V3021, P121; Yang J., 2008, P IEEE C COMP VIS PA; Yang MH, 2002, INT C PATT RECOG, P615, DOI 10.1109/ICPR.2002.1048014; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215	42	94	101	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2229	2235		10.1109/TPAMI.2008.154	http://dx.doi.org/10.1109/TPAMI.2008.154			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988954				2022-12-18	WOS:000260033900012
J	Gunatilaka, AH; Baertlein, BA				Gunatilaka, AH; Baertlein, BA			Feature-level and decision-level fusion of noncoincidently sampled sensors for land mine detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						land mines; sensor fusion; infrared; ground penetrating radar; metal detectors		We present and compare methods for feature-level (predetection) and decision-level (postdetection) fusion of multisensor data. This study emphasizes fusion techniques that are suitable for noncommensurate data sampled at noncoincident points. Decision-level fusion is most convenient for such data, but it is suboptimal in principle, since targets not detected by all sensors will not obtain the full benefits of fusion. A novel algorithm for feature-level fusion of noncommensurate, noncoincidently sampled data is described, in which a model is fitted to the sensor data and the model parameters are used as features. Formulations for both feature-level and decision-level fusion are described, along with some practical simplifications. A closed-form expression is available for feature-level fusion of normally distributed data and this expression is used with simulated data to study requirements for sample position accuracy in multisensor data. The performance of feature-level and decision-level fusion algorithms are compared for experimental data acquired by a metal detector, a ground-penetrating radar, and an infrared camera at a challenging test site containing surrogate mines. It is found that fusion of binary decisions does not perform significantly better than the best available sensor. The performance of feature-level fusion is significantly better than the individual sensors, as is decision-level fusion when detection confidence information is also available ("soft-decision" fusion).	Lucent Technol, Columbus, OH 43213 USA; Ohio State Univ, Electrosci Lab, Columbus, OH 43212 USA	Alcatel-Lucent; Lucent Technologies; University System of Ohio; Ohio State University	Gunatilaka, AH (corresponding author), Lucent Technol, 6200 E Broad St, Columbus, OH 43213 USA.							BAERTLEIN B, 1994, N6133193C0050 BALL S; BRUSMARK B, 1998, P 7 INT C GROUND PEN; CHAUDHURI S, 1990, P SOC PHOTO-OPT INS, V1306, P187, DOI 10.1117/12.21624; CLARK GA, 1993, P SOC PHOTO-OPT INS, V1942, P178, DOI 10.1117/12.160338; DAS Y, 1990, IEEE T GEOSCI REMOTE, V28, P278, DOI 10.1109/36.54354; Dasarathy B.V, 1994, DECISION FUSION; den Breejen E, 1999, P SOC PHOTO-OPT INS, V3710, P1235, DOI 10.1117/12.357003; Gunatilaka A, 1999, P SOC PHOTO-OPT INS, V3710, P1212, DOI 10.1117/12.357000; Gunatilaka A. H., 2000, P SPIE, V4038; HALL DL, 1992, MATH TECHNIQUES MULT; Johnson PG, 1999, P SOC PHOTO-OPT INS, V3710, P1149, DOI 10.1117/12.356995; Kay S. M., 1993, FUNDAMENTALS STAT SI; Marble JA, 2000, P SOC PHOTO-OPT INS, V4038, P1473, DOI 10.1117/12.396235; McFee J, 1998, PROC SPIE, V3392, P1082, DOI 10.1117/12.324158; Miao X, 1998, IEEE T NEURAL NETWOR, V9, P454, DOI 10.1109/72.668887; Nag S, 1999, P SOC PHOTO-OPT INS, V3710, P1313, DOI 10.1117/12.357015; Poor, 2013, INTRO SIGNAL DETECTI; Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461; Sendur IK, 1999, P SOC PHOTO-OPT INS, V3710, P1272, DOI 10.1117/12.357009; Varshney P. K., 1997, DISTRIBUTED DETECTIO; Weisenseel RA, 1999, P SOC PHOTO-OPT INS, V3710, P1179, DOI 10.1117/12.356998	21	94	96	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					577	589		10.1109/34.927459	http://dx.doi.org/10.1109/34.927459			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC		Green Submitted			2022-12-18	WOS:000169037600003
J	Grenander, U; Srivastava, A				Grenander, U; Srivastava, A			Probability models for clutter in natural images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image models; object recognition; clutter; transported model		We propose a framework for modeling clutter in natural images. Assuming that: 1) images are made up of 2D (projected) views of 3D (real) objects and 2) certain simplifying conditions hold. we derive an analytical density for natural images. This expression is shown to match well with the observed densities (histograms). In addition to deriving multidimensional densities,several extensions are also proposed.	Brown Univ, Dept Appl Math, Providence, RI 02912 USA; Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Brown University; State University System of Florida; Florida State University	Grenander, U (corresponding author), Brown Univ, Dept Appl Math, 182 George St,Box F, Providence, RI 02912 USA.	ulf@brownvm.brown.edu; anuj@stat.fsu.edu	Srivastava, Anuj/F-7417-2011; Srivastava, Anuj/L-4705-2019					CHI Z, 1998, THESIS BROWN U; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Grenander U, 1998, IEEE T PATTERN ANAL, V20, P790, DOI 10.1109/34.709572; Grenander U, 2000, IEEE T INFORM THEORY, V46, P1658, DOI 10.1109/18.850712; GRENANDER U, 1999, MONOGRAPH CTR IMAGIN; HUANG J, 1999, IEEE C COMP VIS PATT, P541; Lee Ann B, 2000, INT J COMPUT VISION; MUMFORD D, 2000, LECT REV ARO METR PA; Simoncelli EP, 1999, PROCEEDINGS OF THE IEEE SIGNAL PROCESSING WORKSHOP ON HIGHER-ORDER STATISTICS, P54, DOI 10.1109/HOST.1999.778691; SRIVASTAVA A, 2000, APS COMM NETW MULTIM, P869; WINKLER G., 1995, IMAGE ANAL RANDOM FI; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	12	94	95	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					424	429		10.1109/34.917579	http://dx.doi.org/10.1109/34.917579			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900009
J	Shufelt, JA				Shufelt, JA			Performance evaluation and analysis of vanishing point detection techniques	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; shape representation; vanishing points; photogrammetry; building detection; cartographic feature extraction; performance evaluation	STATISTICAL-ANALYSIS; PERSPECTIVE IMAGES; HOUGH TRANSFORM	Vanishing point detection algorithms based on a Gaussian sphere representation have been employed in a variety of computer vision systems, for extracting 3D line orientations as a first step towards object detection. Typically, these algorithms have been applied to imagery with strong perspective effects and with little noise or texture, resulting in good solutions for line orientations. However, these algorithms can fail if perspective effects are weak. or if texture edges are predominant; they also fail to take advantage of knowledge about the objects to be detected. In this paper. two new techniques for robust vanishing point detection on the Gaussian sphere are presented; primitive-based vanishing point analysis and interpretation plane error modeling. The performance of these methods, along with two other existing methods from the literature, are quantitatively evaluated and compared for the task of building detection in complex aerial imagery.	Carnegie Mellon Univ, Dept Comp Sci, Digital Mapping Lab, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Shufelt, JA (corresponding author), Carnegie Mellon Univ, Dept Comp Sci, Digital Mapping Lab, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	js@maps.cs.cmu.edu						BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BERGEVIN R, 1993, IEEE T PATTERN ANAL, V15, P19, DOI 10.1109/34.184772; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BRILLAULTOMAHONY B, 1991, CVGIP-IMAG UNDERSTAN, V54, P289, DOI 10.1016/1049-9660(91)90069-2; Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560; FRITSCH D, 1994, P ISPRS COMM 3 S S 3, V30, P23; Hsieh Y, 1996, PROC CVPR IEEE, P499, DOI 10.1109/CVPR.1996.517118; HSIEH Y, 1996, P ARPA IM UND WORKSH, V1, P435; KANATANI K, 1994, CVGIP-IMAG UNDERSTAN, V59, P286, DOI 10.1006/ciun.1994.1020; KANATANI K, 1992, IEEE T ROBOTIC AUTOM, V8, P767, DOI 10.1109/70.182677; LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598; MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9; MCGLONE C, 1995, P SOC PHOTO-OPT INS, V2486, P25; MCGLONE JC, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P54, DOI 10.1109/CVPR.1994.323810; MCKEOWN DM, 1993, P SOC PHOTO-OPT INS, V1944, P2; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; QUAN L, 1989, PATTERN RECOGN LETT, V9, P279, DOI 10.1016/0167-8655(89)90006-8; Shufelt J. A., 1996, INT ARCH PHOTOGRA B6, V31, P74; SHUFELT JA, 1996, P ARPA IM UND WORKSH, V2, P1113; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn	20	94	103	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					282	288		10.1109/34.754631	http://dx.doi.org/10.1109/34.754631			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000012
J	Law, T; Itoh, H; Seki, H				Law, T; Itoh, H; Seki, H			Image filtering, edge detection, and edge tracing using fuzzy reasoning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fuzzy reasoning; filtering; edge detection; tracing; joins		We characterize the problem of detecting edges in images as a fuzzy reasoning problem. The edge detection problem is divided into three stages: filtering, detection, and tracing. Images are filtered by applying fuzzy reasoning based on local pixel characteristics to control the degree of Gaussian smoothing. Filtered images are then subjected to a simple edge detection algorithm which evaluates the edge fuzzy membership Value for each pixel, based on local image characteristics. Finally, pixels having high edge membership are traced and assembled into structures, again using fuzzy reasoning to guide the tracing process. The filtering, detection, and tracing algorithms are tested on several test images. Comparison is made with a standard edge detection technique.			Law, T (corresponding author), NAGOYA INST TECHNOL,DEPT ARTIFICIAL INTELLIGENCE & COMP SCI,ITOH LAB,SHOWA KU,GOKISO CHO,NAGOYA,AICHI 466,JAPAN.							Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BEZDEK JC, 1993, P 5 INT FUZZ SYST WO, pR36; CANNY JF, 1983, 720 AITR MASS ART IN; Cavanagh P., 1991, REPRESENTATION VISIO, P295; FREEMAN W, 1992, P 3 INT C COMP VIS O; GRAHAM RE, 1962, IRE T INFORM THEOR, V8, P129, DOI 10.1109/TIT.1962.1057690; GRIMSON W, 1980, 565 AI MIT ART INT L; JUNG S, 1993, P 5 INT FUZZ SYST WO, P127; Kanisza G, 1979, ORG VISION; KIM JS, 1993, P 5 INT FUZZ SYST WO, P143; LAW T, 1994, P 3 INT C AUT ROB CO; LEVINE M, 1985, VISION MAN MACHINE, P151; LIM JS, 1990, 2 DIMENSIONAL SIGNAL, P529; MAMDANI EH, 1976, INT J MAN MACH STUD, V8, P669, DOI 10.1016/S0020-7373(76)80028-4; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NITZBERG M, 1991, LECT NOTES COMPUTER, P1; PAL SK, 1983, IEEE T PATTERN ANAL, V5, P69, DOI 10.1109/TPAMI.1983.4767347; PAL SK, 1982, IEEE T PATTERN ANAL, V4, P204, DOI 10.1109/TPAMI.1982.4767227; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; POPE AR, 1994, P IEEE CS C COMP VIS; RAO K, 1993, CVGIP-IMAG UNDERSTAN, V57, P1, DOI 10.1006/ciun.1993.1001; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; RODIECK R. W., 1965, VISION RES, V5, P583, DOI 10.1016/0042-6989(65)90033-7; SCHALKOFF RJ, 1989, DIGITAL IMAGE PROCES, P267; TAO C, 1993, P 2 IEEE INT C FUZZ, V2, P1356; TYAN C, 1993, P 2 INT C FUZZ SYST, V1, P600; VANDERHEIJDEN F, 1995, IEEE T PATTERN ANAL, V17, P69; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; Zadeh L. A., 1975, INFORMATION SCI, V8, P9	29	94	112	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					481	491		10.1109/34.494638	http://dx.doi.org/10.1109/34.494638			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100001
J	DEMENTHON, D; DAVIS, LS				DEMENTHON, D; DAVIS, LS			EXACT AND APPROXIMATE SOLUTIONS OF THE PERSPECTIVE-3-POINT PROBLEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						INVERSE PERSPECTIVE OF TRIANGLES; LOOKUP TABLES; ORTHOPERSPECTIVE; PARAPERSPECTIVE; PERSPECTIVE-N-POINT PROBLEM; POSE COMPUTATION; ROBOT VISION; SCALED ORTHOGRAPHIC PROJECTION; 3-D OBJECT RECOGNITION; WEAK PERSPECTIVE	OBJECT; POSE; VIEW	Model-based pose estimation techniques that match image and model triangles require large numbers of matching operations in real-world applications. We show that by using approximations to perspective, 2-D lookup tables can be built for each or the triangles of the models. An approximation called "weak perspective" has been applied previously to this problem; we consider two other perspective approximations: paraperspective and orthoperspective. These approximations produce lower errors for off-center image features than weak perspective.			DEMENTHON, D (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLL PK,MD 20742, USA.							ALOIMONOS J, 1987, CARTR320 U MAR CTR A; DAVIS LS, 1989 P DARPA IM UND, P631; DEMENTHON D, 1989, CARTR471 U MAR CTR A; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HARALICK RM, FT10 U WASH DEP EL E; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; HUTTENLOCHER D, 1988 P DARPA IM UND, P1114; KANATANI K, 1988, COMPUT VISION GRAPH, V41, P28, DOI 10.1016/0734-189X(88)90115-6; LAMDAN Y, 1988 P IEEE INT C RO, P1407; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; OHTA Y, 1981, P INT JOINT C ART IN, P746; PEHKONEN K, 1991, PATTERN RECOGN LETT, V12, P353, DOI 10.1016/S0167-8655(05)80005-4; ROBERTS LG, 1965, OPT ELEC OPTICAL INF; THOMPSON DW, 1987, IEEE J ROBOTIC AUTOM, P208; THOMPSON DW, 1987, P DARPA IMAGE UNDERS, P98; WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632	16	94	100	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1992	14	11					1100	1105		10.1109/34.166625	http://dx.doi.org/10.1109/34.166625			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JX370		Green Submitted			2022-12-18	WOS:A1992JX37000005
J	BLAKE, A				BLAKE, A			COMPARISON OF THE EFFICIENCY OF DETERMINISTIC AND STOCHASTIC ALGORITHMS FOR VISUAL RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BLAKE, A (corresponding author), UNIV OXFORD,DEPT ENGN SCI,OXFORD OX1 3PJ,ENGLAND.							Bellman R., 1962, APPL DYNAMIC PROGRAM; BESAG J, 1986, J R STAT SOC B, V48, P259; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P656; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4; BLAKE A, 1986, P ECAI BRIGHTON, P518; Blake A, 1983, PATTERN RECOGN LETT, V1, P393, DOI 10.1016/0167-8655(83)90077-6; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1981, IMAGES SURFACES; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; HORN BKP, 1981, COMPUTER VISION; IKEUCHI K, 1981, COMPUTER VISION, P141; KASHKO A, 1987, PARALLEL APPROACH GR; KIRPATRICK S, 1982, OPTIMIZATION SIMULAT; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; LUNDY M, 1984, CONVERGENCE ANNEALIN; MARROQUIN J, MIT792 AI LAB MEM; METROPOLIS N, J CHEM PHYS, V6, P1087; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; NAGEL HH, 1983, P INT JOINT C ART IN, P945; SMITH WE, 1983, OPT LETT, V8, P199, DOI 10.1364/OL.8.000199; Strang G., 1973, ANAL FINITE ELEMENT; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; WOODHAM RJ, 1977, P INT JOINT C ART IN, P635; Zienkiewicz O.C, 2006, FINITE ELEMENTS APPR; [No title captured]	30	94	97	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					2	12		10.1109/34.23109	http://dx.doi.org/10.1109/34.23109			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474		Green Published			2022-12-18	WOS:A1989R447400001
J	Liu, Y; Yuan, X; Suo, JL; Brady, DJ; Dai, QH				Liu, Yang; Yuan, Xin; Suo, Jinli; Brady, David J.; Dai, Qionghai			Rank Minimization for Snapshot Compressive Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Imaging; Image coding; Image reconstruction; Minimization; Hyperspectral imaging; Sensors; Compressive sensing; computational imaging; coded aperture; image processing; video processing; nuclear norm; rank minimization; low rank; hyperspectral images; coded aperture snapshot spectral imaging (CASSI); coded aperture compressive temporal imaging (CACTI)	SPARSE REPRESENTATION; SIGNAL RECOVERY; VIDEO; ALGORITHMS; RECONSTRUCTION; DESIGN; MODEL	Snapshot compressive imaging (SCI) refers to compressive imaging systems where multiple frames are mapped into a single measurement, with video compressive imaging and hyperspectral compressive imaging as two representative applications. Though exciting results of high-speed videos and hyperspectral images have been demonstrated, the poor reconstruction quality precludes SCI from wide applications. This paper aims to boost the reconstruction quality of SCI via exploiting the high-dimensional structure in the desired signal. We build a joint model to integrate the nonlocal self-similarity of video/hyperspectral frames and the rank minimization approach with the SCI sensing process. Following this, an alternating minimization algorithm is developed to solve this non-convex problem. We further investigate the special structure of the sampling process in SCI to tackle the computational workload and memory issues in SCI reconstruction. Both simulation and real data (captured by four different SCI cameras) results demonstrate that our proposed algorithm leads to significant improvements compared with current state-of-the-art algorithms. We hope our results will encourage the researchers and engineers to pursue further in compressive imaging for real applications.	[Liu, Yang; Suo, Jinli; Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Liu, Yang; Suo, Jinli; Dai, Qionghai] Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Beijing 100084, Peoples R China; [Yuan, Xin] Nokia Bell Labs, Murray Hill, NJ 07974 USA; [Brady, David J.] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Tsinghua University; Tsinghua University; Nokia Corporation; Nokia Bell Labs; Duke University	Suo, JL (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.; Suo, JL (corresponding author), Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Beijing 100084, Peoples R China.	y-liu16@mails.tsinghila.edu.cn; xyuan@bell-labs.com; jlsuo@tsinghua.edu.cn; david.brady@duke.edu; qhdai@tsinghua.edu.cn	Dai, Qionghai/ABD-5298-2021; Liu, Yang/GPJ-9865-2022	Dai, Qionghai/0000-0001-7043-3061; Liu, Yang/0000-0002-5787-0934; Yuan, Xin/0000-0002-8311-7524; Brady, David Jones/0000-0001-5655-2478	National Natural Science Foundation of China [61327902, 61722110, 61627804, 61631009]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank Dr. Patrick Llull for capturing the real video data of CACTI, Dr. Tsung-Han Tsai for capturing the real hyperspectral image data of CASSI, and Mr. Yangyang Sun and Dr. Shuo Pang for providing the UCF video data. This work was supported by the National Natural Science Foundation of China (grant Nos. 61327902, 61722110, 61627804, and 61631009). Y. Liu and X. Yuan contribute equally to this paper.	Arguello H, 2013, IEEE T IMAGE PROCESS, V22, P941, DOI 10.1109/TIP.2012.2222899; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Brady DJ, 2018, OPTICA, V5, P127, DOI 10.1364/OPTICA.5.000127; Brady DJ, 2015, ADV OPT PHOTONICS, V7, P756, DOI 10.1364/AOP.7.000756; Buades A., 2006, P IEEE INT C COMP VI, P60; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cao X, 2016, IEEE SIGNAL PROC MAG, V33, P95, DOI 10.1109/MSP.2016.2582378; Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Gao L, 2014, NATURE, V516, P74, DOI 10.1038/nature14005; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254; Huang JJ, 2015, INT CONF ACOUST SPEE, P3282, DOI 10.1109/ICASSP.2015.7178578; Huang JJ, 2015, INT CONF ACOUST SPEE, P1618, DOI 10.1109/ICASSP.2015.7178244; Iliadis M, 2018, DIGIT SIGNAL PROCESS, V72, P9, DOI 10.1016/j.dsp.2017.09.010; Jalali S, 2018, IEEE INT SYMP INFO, P416; Jalali S, 2016, APPL COMPUT HARMON A, V40, P352, DOI 10.1016/j.acha.2015.03.003; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Kittle D, 2010, APPL OPTICS, V49, P6824, DOI 10.1364/AO.49.006824; Kulkarni K, 2016, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2016.55; Landy M.S., 1991, COMPUTATIONAL MODELS; Liao XJ, 2014, SIAM J IMAGING SCI, V7, P797, DOI 10.1137/130936658; Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Llull P, 2015, OPTICA, V2, P822, DOI 10.1364/OPTICA.2.000822; Llull P, 2013, OPT EXPRESS, V21, P10526, DOI 10.1364/OE.21.010526; Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324; Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914; Metzler CA, 2016, IEEE T INFORM THEORY, V62, P5117, DOI 10.1109/TIT.2016.2556683; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Sun YY, 2017, OPT EXPRESS, V25, P18182, DOI 10.1364/OE.25.018182; Sun YY, 2016, OPT EXPRESS, V24, P22836, DOI 10.1364/OE.24.022836; Tsai TH, 2015, OPT LETT, V40, P4054, DOI 10.1364/OL.40.004054; Tsai TH, 2015, OPT EXPRESS, V23, P11912, DOI 10.1364/OE.23.011912; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wagadarikar AA, 2009, OPT EXPRESS, V17, P6368, DOI 10.1364/OE.17.006368; Wang LM, 2015, SIAM J IMAGING SCI, V8, P1923, DOI 10.1137/140998779; Wang LZ, 2019, IEEE T PATTERN ANAL, V41, P857, DOI 10.1109/TPAMI.2018.2817496; Wang LZ, 2017, IEEE T PATTERN ANAL, V39, P2104, DOI 10.1109/TPAMI.2016.2621050; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290; Xu K., 2016, ARXIV161205203CSCV; Yang JB, 2015, IEEE T IMAGE PROCESS, V24, P106, DOI 10.1109/TIP.2014.2365720; Yang JB, 2014, IEEE T IMAGE PROCESS, V23, P4863, DOI 10.1109/TIP.2014.2344294; Yang Y, 2016, ADV NEUR IN, V29; Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983; Yuan X, 2018, OPT EXPRESS, V26, P1962, DOI 10.1364/OE.26.001962; Yuan X, 2016, IEEE IMAGE PROC, P2539, DOI 10.1109/ICIP.2016.7532817; Yuan X, 2016, IEEE SENS J, V16, P8091, DOI 10.1109/JSEN.2016.2609201; Yuan X, 2015, IEEE J-STSP, V9, P964, DOI 10.1109/JSTSP.2015.2411575; Yuan X, 2014, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2014.424; Zha ZY, 2017, IEEE INT CON MULTI, P883, DOI 10.1109/ICME.2017.8019334; Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang L, 2017, IEEE SIGNAL PROC MAG, V34, P172, DOI 10.1109/MSP.2017.2717489; Zuo WM, 2013, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2013.34	69	93	94	16	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2990	3006		10.1109/TPAMI.2018.2873587	http://dx.doi.org/10.1109/TPAMI.2018.2873587			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30295611	Green Submitted			2022-12-18	WOS:000498677600015
J	You, S; Tan, RT; Kawakami, R; Mukaigawa, Y; Ikeuchi, K				You, Shaodi; Tan, Robby T.; Kawakami, Rei; Mukaigawa, Yasuhiro; Ikeuchi, Katsushi			Adherent Raindrop Modeling, Detection and Removal in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Outdoor vision; rainy scenes; raindrop detection; raindrop removal		Raindrops adhered to a windscreen or window glass can significantly degrade the visibility of a scene. Modeling, detecting and removing raindrops will, therefore, benefit many computer vision applications, particularly outdoor surveillance systems and intelligent vehicle systems. In this paper, a method that automatically detects and removes adherent raindrops is introduced. The core idea is to exploit the local spatio-temporal derivatives of raindrops. To accomplish the idea, we first model adherent raindrops using law of physics, and detect raindrops based on these models in combination with motion and intensity temporal derivatives of the input video. Having detected the raindrops, we remove them and restore the images based on an analysis that some areas of raindrops completely occludes the scene, and some other areas occlude only partially. For partially occluding areas, we restore them by retrieving as much as possible information of the scene, namely, by solving a blending function on the detected partially occluding areas using the temporal intensity derivative. For completely occluding areas, we recover them by using a video completion technique. Experimental results using various real videos show the effectiveness of our method.	[You, Shaodi; Kawakami, Rei] Univ Tokyo, Tokyo, Japan; [Tan, Robby T.] Yale NUS Coll, Singapore, Singapore; [Tan, Robby T.] Natl Univ Singapore, Singapore, Singapore; [Mukaigawa, Yasuhiro] Nara Inst Sci & Technol, Nara, Japan; [Ikeuchi, Katsushi] Microsoft Res Asia, Beijing, Peoples R China	University of Tokyo; Yale NUS College; National University of Singapore; Nara Institute of Science & Technology; Microsoft; Microsoft Research Asia	You, S (corresponding author), Univ Tokyo, Tokyo, Japan.	youshaodi@gmail.com; robby.tan@yale-nus.edu.sg; rei@nae-lab.org; mukaigawa@is.naist.jp; ki@cvl.iis.u-tokyo.ac.jp	Shaodi, YOU/AAA-4524-2022; Tan, Robby T./F-8826-2017	Shaodi, YOU/0000-0001-8973-645X; Tan, Robby T./0000-0001-7532-6919	Japan Society for the Promotion of Science (JSPS) through "Funding Program for Next Generation World-Leading Researchers (NEXT Program)"; Council for Science and Technology Policy (CSTP); Next-generation Energies for Tohoku Recovery (NET), MEXT, Japan	Japan Society for the Promotion of Science (JSPS) through "Funding Program for Next Generation World-Leading Researchers (NEXT Program)"(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); Council for Science and Technology Policy (CSTP)(Council for Science and Technology Policy (CSTP)); Next-generation Energies for Tohoku Recovery (NET), MEXT, Japan	This research is granted by: 1. The Japan Society for the Promotion of Science (JSPS) through the "Funding Program for Next Generation World-Leading Researchers (NEXT Program)," initiated by the Council for Science and Technology Policy (CSTP). 2. Next-generation Energies for Tohoku Recovery (NET), MEXT, Japan.	Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2; Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671; GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077; Garg K., 2003, TECH REP; Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6; Gu JW, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618490; Hara T, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P144, DOI 10.1109/CVMP.2009.17; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Jia JY, 2006, IEEE T PATTERN ANAL, V28, P832, DOI 10.1109/TPAMI.2006.108; Jia JY, 2004, PROC CVPR IEEE, P364; Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057; Kurihata H, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P205; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu Ming, 2009, P 17 ACM INT C MULT, P537, DOI [10.1145/1631272.1631350, DOI 10.1145/1631272.1631350]; Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82; Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343; Roser Martin, 2010, Computer Vision - ACCV 2010 Workshops. ACCV 2010 International Workshops. Revised Selected Papers, P235, DOI 10.1007/978-3-642-22819-3_24; Roser Martin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P570, DOI 10.1109/ICCVW.2009.5457650; Shiratori T., 2006, P IEEE C COMP VIS PA, V1, P411, DOI DOI 10.1109/CVPR.2006.330; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Stanley O., 2002, LEVEL SET METHODS DY; Subbarao M., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P498, DOI 10.1109/CVPR.1988.196281; Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643; Villermaux E, 2009, NAT PHYS, V5, P697, DOI 10.1038/NPHYS1340; Wexler Y, 2004, PROC CVPR IEEE, P120; Willson Reg G, 2005, OPTICAL MODEL IMAGE, P5; Yamashita A., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P400; Yamashita A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3794, DOI 10.1109/IROS.2009.5354639; You SD, 2013, PROC CVPR IEEE, P1035, DOI 10.1109/CVPR.2013.138; Zhou CY, 2007, 2007 IEEE C COMP VIS, P1	32	93	99	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1721	1733		10.1109/TPAMI.2015.2491937	http://dx.doi.org/10.1109/TPAMI.2015.2491937			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26485475	hybrid			2022-12-18	WOS:000381432700001
J	Feng, JJ; Zhou, J; Jain, AK				Feng, Jianjiang; Zhou, Jie; Jain, Anil K.			Orientation Field Estimation for Latent Fingerprint Enhancement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint matching; fingerprint enhancement; latent fingerprint; orientation field; dictionary; spelling correction	SINGULAR POINTS; IMAGE; MODEL; COMPUTATION; EXTRACTION; ALGORITHM	Identifying latent fingerprints is of vital importance for law enforcement agencies to apprehend criminals and terrorists. Compared to live-scan and inked fingerprints, the image quality of latent fingerprints is much lower, with complex image background, unclear ridge structure, and even overlapping patterns. A robust orientation field estimation algorithm is indispensable for enhancing and recognizing poor quality latents. However, conventional orientation field estimation algorithms, which can satisfactorily process most live-scan and inked fingerprints, do not provide acceptable results for most latents. We believe that a major limitation of conventional algorithms is that they do not utilize prior knowledge of the ridge structure in fingerprints. Inspired by spelling correction techniques in natural language processing, we propose a novel fingerprint orientation field estimation algorithm based on prior knowledge of fingerprint structure. We represent prior knowledge of fingerprints using a dictionary of reference orientation patches. which is constructed using a set of true orientation fields, and the compatibility constraint between neighboring orientation patches. Orientation field estimation for latents is posed as an energy minimization problem, which is solved by loopy belief propagation. Experimental results on the challenging NIST SD27 latent fingerprint database and an overlapped latent fingerprint database demonstrate the advantages of the proposed orientation field estimation algorithm over conventional algorithms.	[Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Tsinghua University; Michigan State University	Feng, JJ (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn; jain@cse.msu.edu			National Natural Science Foundation of China [61005023, 61225008, 61020106004, 61021063]; Ministry of Education of China [20120002110033]; WCU (World Class University) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Ministry of Education of China(Ministry of Education, China); WCU (World Class University) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea	This work was supported by the National Natural Science Foundation of China under Grants 61005023, 61225008, 61020106004, and 61021063, and by the Ministry of Education of China under Grant 20120002110033. Part of Anil Jain's research was supported by the WCU (World Class University) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008).	Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1; Cappelli R, 2007, IEEE T PATTERN ANAL, V29, P1489, DOI 10.1109/TPAMI.2007.1087; Champod C., 2017, FINGERPRINTS OTHER R, P136; Chen FL, 2011, IEEE T INF FOREN SEC, V6, P346, DOI 10.1109/TIFS.2011.2114345; Chen FL, 2009, IEEE T IMAGE PROCESS, V18, P1665, DOI 10.1109/TIP.2009.2017995; Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036; Cole Simon, 2002, SUSPECT IDENTITIES H; Dass SC, 2004, IEEE T IMAGE PROCESS, V13, P1358, DOI 10.1109/TIP.2004.834659; Dvornychenko V. N., 2006, 7377 NISTIR; Fan LL, 2008, IEEE T PATTERN ANAL, V30, P929, DOI 10.1109/TPAMI.2008.31; Feng J., 2012, IEEE T INFORM FORESN; Gonzalez Rafael C., 2007, DIGITAL IMAGE PROCES; Gottschlich C, 2009, IEEE T INF FOREN SEC, V4, P802, DOI 10.1109/TIFS.2009.2033219; Gu JW, 2006, IEEE T IMAGE PROCESS, V15, P1952, DOI 10.1109/TIP.2006.873443; Gu JW, 2004, PATTERN RECOGN, V37, P543, DOI 10.1016/S0031-3203(03)00178-X; Haber L, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P339, DOI 10.1007/0-387-21685-5_17; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Huckemann S, 2008, IEEE T PATTERN ANAL, V30, P1507, DOI 10.1109/TPAMI.2007.70826; Indovina M., 2009, 7577 NISTIR; Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Jiang XD, 2007, PATTERN RECOGN, V40, P705, DOI 10.1016/j.patcog.2006.04.028; Kamei T, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P113, DOI 10.1007/0-387-21685-5_6; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KUKICH K, 1992, COMPUT SURV, V24, P377; Lee KC, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P41, DOI 10.1109/BSYM.2008.4655521; Li J, 2006, PATTERN RECOGN, V39, P102, DOI 10.1016/j.patcog.2005.08.010; Li S, 2009, MARKOV RANDOM FIELD; Liu MH, 2005, EURASIP J APPL SIG P, V2005, P498, DOI 10.1155/ASP.2005.498; Lo P., 2007, US Patent Application Publication, Patent No. [2007/0292005A1, 20070292005]; Maltoni D., 2009, HDB FINGERPRINT RECO; Neurotechnology Inc, 2012, VERIFINGER; Nilsson K, 2003, PATTERN RECOGN LETT, V24, P2135, DOI 10.1016/S0167-8655(03)00083-7; OGORMAN L, 1989, PATTERN RECOGN, V22, P29, DOI 10.1016/0031-3203(89)90035-6; Oliveira MA, 2008, PATTERN RECOGN, V41, P367, DOI 10.1016/j.patcog.2007.05.019; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Rama R., 2011, P INT JOINT C BIOM; RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3; Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; Turroni F, 2011, IEEE T INF FOREN SEC, V6, P1002, DOI 10.1109/TIFS.2011.2150216; Ulery BT, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032800; Ulery BT, 2011, P NATL ACAD SCI USA, V108, P7733, DOI 10.1073/pnas.1018707108; Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003; Yoon S., 2011, P INT JOINT C BIOM; Yoon S, 2010, PROC SPIE, V7667, DOI 10.1117/12.851411; Zhao QJ, 2012, IEEE T INF FOREN SEC, V7, P904, DOI 10.1109/TIFS.2012.2187281; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608; Zhou J, 2009, IEEE T PATTERN ANAL, V31, P1239, DOI 10.1109/TPAMI.2008.188; Zhu E, 2006, PATTERN RECOGN, V39, P1452, DOI 10.1016/j.patcog.2006.03.001	53	93	98	0	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					925	940		10.1109/TPAMI.2012.155	http://dx.doi.org/10.1109/TPAMI.2012.155			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22826508	Green Submitted			2022-12-18	WOS:000314931000012
J	Wang, HZ; Chin, TJ; Suter, D				Wang, Hanzi; Chin, Tat-Jun; Suter, David			Simultaneously Fitting and Segmenting Multiple-Structure Data with Outliers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust statistics; model fitting; scale estimation; kernel density estimation; multiple structure segmentation	ROBUST ESTIMATION; MEAN SHIFT; SEGMENTATION; ESTIMATOR	We propose a robust fitting framework, called Adaptive Kernel-Scale Weighted Hypotheses (AKSWH), to segment multiple-structure data even in the presence of a large number of outliers. Our framework contains a novel scale estimator called Iterative Kth Ordered Scale Estimator (IKOSE). IKOSE can accurately estimate the scale of inliers for heavily corrupted multiple-structure data and is of interest by itself since it can be used in other robust estimators. In addition to IKOSE, our framework includes several original elements based on the weighting, clustering, and fusing of hypotheses. AKSWH can provide accurate estimates of the number of model instances and the parameters and the scale of each model instance simultaneously. We demonstrate good performance in practical applications such as line fitting, circle fitting, range image segmentation, homography estimation, and two-view-based motion segmentation, using both synthetic data and real images.	[Wang, Hanzi] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China; [Wang, Hanzi] Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China; [Chin, Tat-Jun; Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Xiamen University; Xiamen University; University of Adelaide	Wang, HZ (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China.	hanzi.wang@ieee.org; tat-jun.chin@adelaide.edu.au; david.suter@adelaide.edu.au	Wang, Hanzi/F-8796-2012	Suter, David/0000-0001-6306-3023	Australian Research Council (ARC) [DP0878801]; National Natural Science Foundation of China [61170179]; Special Research Fund for the Doctoral Program of Higher Education of China [20110121110033]; Xiamen Science & Technology Planning Project Fund of China [3502Z20116005]	Australian Research Council (ARC)(Australian Research Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Special Research Fund for the Doctoral Program of Higher Education of China(Specialized Research Fund for the Doctoral Program of Higher Education (SRFDP)); Xiamen Science & Technology Planning Project Fund of China	The authors would like to thank the reviewers for their valuable comments, which greatly helped to improve the paper. Parts of our code are developed based on the "Structure and Motion Toolkit" provided by Professor P. Torr. They also thank Dr. R. Toldo and Professor A. Fusiello for sharing the code of J-linkage, and Dr. R. Subbarao and Professor P. Meer for sharing the code of MS. They thank Professor A. Bab-Hadiashar for providing some range image data. This work was supported by the Australian Research Council (ARC) under the project DP0878801, by the National Natural Science Foundation of China under project 61170179, the Special Research Fund for the Doctoral Program of Higher Education of China under Project 20110121110033, and by the Xiamen Science & Technology Planning Project Fund (3502Z20116005) of China. Most of this work was completed when Hanzi Wang was at the University of Adelaide.	Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Duda R.O., 1973, J ROYAL STAT SOC SER; Ferraz L, 2007, LECT NOTES COMPUT SC, V4478, P355; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Hartley R., 2004, ROBOTICA; Hoseinnezhad R., 1997, P IEEE 11 INT C COMP, P1; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Huber P., 1981, ROBUST STAT; Kanatani K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P7; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; Lee Y., 2006, INT J INF TECHNOL, V12, P13; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; Tordoff B, 2002, LECT NOTES COMPUT SC, V2350, P82; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Tuzel O, 2005, IEEE I CONF COMP VIS, P18; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Wand M.P., 1995, KERNEL SMOOTHING; Wang H., 2008, P IEEE C COMP VIS PA; Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P178, DOI 10.1109/TPAMI.2009.148; Wang HZ, 2004, LECT NOTES COMPUT SC, V3023, P107; Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; Yang ZR, 2001, IEEE T PATTERN ANAL, V23, P396, DOI 10.1109/34.917574; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443; Zhang W, 2007, LECT NOTES COMPUT SC, V4358, P60; Zuliani M, 2005, IEEE IMAGE PROC, P2969	44	93	98	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1177	1192		10.1109/TPAMI.2011.216	http://dx.doi.org/10.1109/TPAMI.2011.216			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22064800				2022-12-18	WOS:000302916600011
J	Qi, GJ; Aggarwal, C; Tian, Q; Ji, H; Huang, TS				Qi, Guo-Jun; Aggarwal, Charu; Tian, Qi; Ji, Heng; Huang, Thomas S.			Exploring Context and Content Links in Social Media: A Latent Space Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Context and content links; latent semantic space; low-rank method; social Media; multimedia information networks		Social media networks contain both content and context-specific information. Most existing methods work with either of the two for the purpose of multimedia mining and retrieval. In reality, both content and context information are rich sources of information for mining, and the full power of mining and processing algorithms can be realized only with the use of a combination of the two. This paper proposes a new algorithm which mines both context and content links in social media networks to discover the underlying latent semantic space. This mapping of the multimedia objects into latent feature vectors enables the use of any off-the-shelf multimedia retrieval algorithms. Compared to the state-of-the-art latent methods in multimedia analysis, this algorithm effectively solves the problem of sparse context links by mining the geometric structure underlying the content links between multimedia objects. Specifically for multimedia annotation, we show that an effective algorithm can be developed to directly construct annotation models by simultaneously leveraging both context and content information based on latent structure between correlated semantic concepts. We conduct experiments on the Flickr data set, which contains user tags linked with images. We illustrate the advantages of our approach over the state-of-the-art multimedia retrieval techniques.	[Qi, Guo-Jun; Huang, Thomas S.] Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA; [Aggarwal, Charu] IBM TJ Watson Res Lab, Yorktown Hts, NY 10598 USA; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA; [Ji, Heng] CUNY, Dept Comp Sci, New York, NY 10031 USA	University of Illinois System; University of Illinois Urbana-Champaign; International Business Machines (IBM); University of Texas System; University of Texas at San Antonio (UTSA); City University of New York (CUNY) System	Qi, GJ (corresponding author), Univ Illinois, Beckman Inst Adv Sci & Technol, 405 N Mathews Ave, Urbana, IL 61801 USA.	qi4@ifp.uiuc.edu; charu@us.ibm.com; qitian@cs.utsa.edu; hengji@cs.qc.cuny.edu; huang@ifp.uiuc.edu	Qi, Guo-Jun/AAH-8294-2019	Qi, Guo-Jun/0000-0003-3508-1851	US Army Research Laboratory [W911NF-09-2-0053]; US National Science Foundation [IIS-1144111, IIS 1052851]; IBM; Google; FXPAL; NEC Laboratories of America	US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US National Science Foundation(National Science Foundation (NSF)); IBM(International Business Machines (IBM)); Google(Google Incorporated); FXPAL; NEC Laboratories of America	Research was sponsored by the US Army Research Laboratory Cooperative Agreement Number W911NF-09-2-0053 and the US National Science Foundation under Grant IIS-1144111. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the US Army Research Laboratory or the US Government. The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on. The work was also supported in part to Guo-Jun Qi by an IBM PhD fellowship award, as well as in part to Dr. Qi Tian by US National Science Foundation grant IIS 1052851, Faculty Research Awards by Google, FXPAL, and NEC Laboratories of America, respectively. This work was originally submitted to International ACM Conference on Multimedia 2010.	Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785; Bekkerman R., 2007, P IEEE C COMP VIS PA; Belkin M, 2002, ADV NEUR IN, V14, P585; Benitez A.B., 2000, P SPIE C SERIES; Berg Tamara, 2010, P 11 EUR C COMP VIS; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A., 2006, P EUR C COMP VIS; Candes EJ, 2008, IEEE T INFORM THEORY, V54, P2829, DOI 10.1109/TIT.2008.924688; Candes EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722; Chua T.-S., 2009, ACM C IM VID RETR, P8; Chung F.R.K., 1997, P REGIONAL C SERIES; FLICKNER M, 1997, INTELLIGENT MULTIMED, P7; Guillaumin M., 2010, P IEEE C COMP VIS PA; Hofmann T., 1999, P UNC ART INT; Labsky P.P. Martin, 2005, P INT WORKSH REPR AN; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028; Monay F, 2004, P 12 ANN ACM INT C M, P348, DOI DOI 10.1145/1027527.1027608; Qi G.-J., 2009, P 17 ACM INT C MULT; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sizov S., 2010, WSDM; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SNOEK CGM, 2006, P 14 ANN ACM INT C M; Tang J., 2009, P 17 ACM INT C MULT; Toh K. C., 2009, ACCELERATED PROXIMAL; Wang S., 2009, P 1 ACM WORKSH LARG, P121; Wright J., 2009, P ADV NEUR INF PROC, V58, P289; Xing E.P., 2003, P ADV NEUTR INF PROC; Yang Q., 2009, P JOINT C 47 ANN M A, P1; Yu J., 2010, P 19 INT C WORLD WID; Zhu S., 2007, P 30 ANN INT ACM SIG	31	93	94	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					850	862		10.1109/TPAMI.2011.191	http://dx.doi.org/10.1109/TPAMI.2011.191			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21968917				2022-12-18	WOS:000301747400002
J	Liang, J; DeMenthon, D; Doermann, D				Liang, Jian; DeMenthon, Daniel; Doermann, David			Geometric rectification of camera-captured document images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera-based OCR; image rectification; shape estimation; texture flow analysis	ORIENTATION; TEXTURE	Compared to typical scanners, handheld cameras offer convenient, flexible, portable, and noncontact image capture, which enables many new applications and breathes new life into existing ones. However, camera-captured documents may suffer from distortions caused by a nonplanar document shape and perspective projection, which lead to the failure of current optical character recognition (OCR) technologies. We present a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image. Our approach estimates the 3D document shape from texture flow information obtained directly from the image without requiring additional 3D/metric data or prior camera calibration. Our framework provides a unified solution for both planar and curved documents and can be applied in many, especially mobile, camera-based document analysis applications. Experiments show that our method produces results that are significantly more OCR compatible than the original images.	[Liang, Jian] Amazon Com, Seattle, WA 98104 USA; [DeMenthon, Daniel; Doermann, David] Univ Maryland, Inst Adv Comp Studies, Lab Language & Media Proc, College Pk, MD 20742 USA	Amazon.com; University System of Maryland; University of Maryland College Park	Liang, J (corresponding author), Amazon Com, 701 5th Ave,614B, Seattle, WA 98104 USA.	jliang@amazon.com; dementhon@umiacs.umd.edu; doermann@umiacs.umd.edu						Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; Cao HG, 2003, PROC INT CONF DOC, P71; Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346; Clark P., 2002, P ADV CONC INT VIS S, P190; Clark P., 2001, P 12 BRIT MACH VIS C, P421; Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023; Garding J., 1992, Journal of Mathematical Imaging and Vision, V2, P327, DOI 10.1007/BF00121877; Gumerov N, 2004, LECT NOTES COMPUT SC, V3023, P482; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; Knill DC, 2001, J OPT SOC AM A, V18, P12, DOI 10.1364/JOSAA.18.000012; LE DS, 1994, PATTERN RECOGN, V27, P1325, DOI 10.1016/0031-3203(94)90068-X; Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z; Liang J, 2005, PROC CVPR IEEE, P338; LIANG J, 2006, THESIS U MARYLAND CO; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620; Myers G. K., 2005, International Journal on Document Analysis and Recognition, V7, P147, DOI 10.1007/s10032-004-0133-4; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; Nakao T, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P63, DOI 10.1109/ACV.1998.732859; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Pollard S., 2005, International Journal on Document Analysis and Recognition, V7, P123, DOI 10.1007/s10032-004-0129-0; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; Taylor MJ, 1999, IMAGE VISION COMPUT, V17, P831, DOI 10.1016/S0262-8856(98)00155-3; Tsoi YC, 2004, PROC CVPR IEEE, P240; Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90; Ulges A., 2004, P ACM S DOC ENG, P198; Vailaya A, 2002, IEEE T IMAGE PROCESS, V11, P746, DOI 10.1109/TIP2002.801590; WAGNER MJ, 1995, EARTH OBSERVATION MA, V4, P51; Zappala A, 1999, IMAGE VISION COMPUT, V17, P589, DOI 10.1016/S0262-8856(98)00178-4; Zhang Z, 2003, PROC INT CONF DOC, P589	33	93	100	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					591	605		10.1109/TPAMI.2007.70724	http://dx.doi.org/10.1109/TPAMI.2007.70724			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276966	Green Submitted			2022-12-18	WOS:000253135600004
J	Li, F; Wechsler, H				Li, F; Wechsler, H			Open set face recognition using transduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; confidence; credibility; data fusion; information quality; Kolmogorov complexity; face recognition; open set recognition; performance evaluation; PSEI (pattern specific error inhomogeneities); randomness deficiency; strangeness; face surveillance; (multiclass) transduction; watch list; clustering; outlier detection	CLASSIFICATION	This paper motivates and describes a novel realization of transductive inference that can address the Open Set face recognition task. Open Set operates under the assumption that not all the test probes have mates in the gallery. It either detects the presence of some biometric signature within the gallery and finds its identity or rejects it, i.e., it provides for the "none of the above" answer. The main contribution of the paper is Open Set TCM-kNN (Transduction Confidence Machine-k Nearest Neighbors), which is suitable for multiclass authentication operational scenarios that have to include a rejection option for classes never enrolled in the gallery. Open Set TCM-kNN, driven by the relation between transduction and Kolmogorov complexity, provides a local estimation of the likelihood ratio needed for detection tasks. We provide extensive experimental data to show the feasibility, robustness, and comparative advantages of Open Set TCM-kNN on Open Set identification and watch list (surveillance) tasks using challenging FERET data. Last, we analyze the error structure driven by the fact that most of the errors in identification are due to a relatively small number of face patterns. Open Set TCM-kNN is shown to be suitable for PSEI (pattern specific error inhomogeneities) error analysis in order to identify difficult to recognize faces. PSEI analysis improves biometric performance by removing a small number of those difficult to recognize faces responsible for much of the original error in performance and/ or by using data fusion.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	George Mason University	Li, F (corresponding author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fli@cs.gmu.edu; wechsler@cs.gmu.edu						Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; BENGIO S, 2001, 0121 IDIAPRR EUR PRO; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bucklew J., 2013, SPR PRO COM, DOI [10.1007/978-1-4757-4078-3, 10.1007/978-1-4757-4036-3]; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Conover WJ, 1980, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daugman J, 1997, IEEE T PATTERN ANAL, V19, P675, DOI 10.1109/34.598225; Doddington G., 1998, INT C SPOKEN LANGUAG, P1351; Furui S, 1997, PATTERN RECOGN LETT, V18, P859, DOI 10.1016/S0167-8655(97)00073-1; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P148; GROTHER P, 2004, 7083 NISTIR; Jain A., 1999, BIOMETRICS PERSONAL; Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Juszczak P, 2004, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2004.1334545; Krogel MA, 2004, MACH LEARN, V57, P61, DOI 10.1023/B:MACH.0000035472.73496.0c; KUKAR M, 2002, P 13 EUR C MACH LEAR; Li M., 1997, INTRO KOLMOGOROV COM, DOI 10.1016/b978-0-444-88071-0.50009-6; LIU C, 2004, BIOMETRIC AUTHENTICA; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Mak MW, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P107, DOI 10.1109/ISIMP.2001.925343; MELLUISH T, 2001, TYPICALNESS FRAMEWOR; Mitchell T. M., 1999, P 6 INT C COGN SCI; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PANKANTI S, 2002, P 16 INT C PATT REC; Phillips P., 2003, FACE RECOGNITION VEN; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; PROEDROU K, 2001, CLRCTR0102 U LOND RO; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Saunders C., 1999, P 16 INT JOINT C ART; SNELICK R, 2003, P 5 INT C MULT INT; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Vapnik V., 2000, NATURE STAT LEARNING; Vapnik V.N, 1998, STAT LEARNING THEORY; VOVK V, 1999, P 16 INT C MACH LEAR; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	38	93	96	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1686	1697		10.1109/TPAMI.2005.192	http://dx.doi.org/10.1109/TPAMI.2005.192			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285369				2022-12-18	WOS:000231826300001
J	Fashing, M; Tomasi, C				Fashing, M; Tomasi, C			Mean shift is a bound optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mean shift; bound optimization; Newton's method; adaptive gradient descent; mode seeking	TRACKING; SPACE	We build on the current understanding of mean shift as an optimization procedure. We demonstrate that, in the case of piecewise constant kernels, mean shift is equivalent to Newton's method. Further, we prove that, for all kernels, the mean shift procedure is a quadratic bound maximization.	Duke Univ, Dept Comp Sci, Durham, NC 27707 USA	Duke University	Fashing, M (corresponding author), Duke Univ, Dept Comp Sci, Box 90129, Durham, NC 27707 USA.	mark@cs.duke.edu; tomasi@cs.duke.edu						CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Palumbo G. G. C., 1983, CATALOGUE RADIAL VEL; Ramanan D, 2003, PROC CVPR IEEE, P467; Ramanan D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P338	10	93	120	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					471	474		10.1109/TPAMI.2005.59	http://dx.doi.org/10.1109/TPAMI.2005.59			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747802				2022-12-18	WOS:000226300200016
J	Chen, P; Suter, D				Chen, P; Suter, D			Recovering the missing components in a large noisy low-rank matrix: Application to SFM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						imputation; missing-data problem; rank constraint; singular value decomposition; denoising capacity; structure from motion; affine SFM; linear subspace	FACTORIZATION METHOD; MOTION; SHAPE	In computer vision, it is common to require operations on matrices with "missing data," for example, because of occlusion or tracking failures in the Structure from Motion (SFM) problem. Such a problem can be tackled, allowing the recovery of the missing values, if the matrix should be of low rank ( when noise free). The filling in of missing values is known as imputation. Imputation can also be applied in the various subspace techniques for face and shape classification, online "recommender" systems, and a wide variety of other applications. However, iterative imputation can lead to the "recovery" of data that is seriously in error. In this paper, we provide a method to recover the most reliable imputation, in terms of deciding when the inclusion of extra rows or columns, containing significant numbers of missing entries, is likely to lead to poor recovery of the missing parts. Although the proposed approach can be equally applied to a wide range of imputation methods, this paper addresses only the SFM problem. The performance of the proposed method is compared with Jacobs' and Shum's methods for SFM.	Monash Univ, Dept Elect & Comp Sci, Clayton, Vic 3800, Australia	Monash University	Chen, P (corresponding author), Monash Univ, Dept Elect & Comp Sci, POB 35, Clayton, Vic 3800, Australia.	pei.chen@eng.monash.edu.au; d.suter@eng.monash.edu.au		Suter, David/0000-0001-6306-3023				Aguiar PMQ, 2003, IEEE T PATTERN ANAL, V25, P1134, DOI 10.1109/TPAMI.2003.1227988; Brand M, 2002, LECT NOTES COMPUT SC, V2350, P707; BRAND M, 2003, P SIAM 3 INT C DAT M; Brandt S., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P109; CHEN P, 2003, MECSE62003 MON U; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; FITZGIBBON AW, 1998, LECT NOTES COMPUTER, V1506, P155; Golub G. H., 1996, MATRIX COMPUTATIONS; GUERREIRO R, 2003, P C EN MIN METH COMP; HARRISON JM, 1988, STOCHASTIC DIFFERENT, V10, P147; Heyden A, 1998, INT C PATT RECOG, P47, DOI 10.1109/ICPR.1998.711076; Irani M, 2002, INT J COMPUT VISION, V48, P173, DOI 10.1023/A:1016372015744; IRANI M, 1999, P INT C COMP VIS; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; Kahl F, 1999, INT J COMPUT VISION, V33, P163, DOI 10.1023/A:1008192713051; Kanazawa Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCV.2001.937640; Martin S, 2002, CURR MED RES OPIN, V18, P355, DOI 10.1185/030079902125001128; Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; ROTHER C, 2002, P EUR C COMP VIS; SARWAR BM, 2000, P ACM WEBKDD 2000 WE, P309; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; Thomson RD, 1999, SPORTS ENG, V2, P109; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520	27	93	98	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1051	1063		10.1109/TPAMI.2004.52	http://dx.doi.org/10.1109/TPAMI.2004.52			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641734				2022-12-18	WOS:000221872400008
J	Tang, YY; You, XG				Tang, YY; You, XG			Skeletonization of ribbon-like shapes based on a new wavelet function	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ribbon-like shape; skeletonization; wavelet transform; wavelet skeleton	EDGE-DETECTION; LINE IMAGES; ALGORITHM	A wavelet-based scheme to extract skeleton of Ribbon-like shape is proposed in this paper, where a novel wavelet function plays a key role in this scheme, which possesses three significant characteristics, namely, 1) the position of the local maximum moduli of the wavelet transform with respect to the Ribbon-like shape is independent of the gray-levels of the image. 2) When the appropriate scale of the wavelet transform is selected, the local maximum moduli of the wavelet transform of the Ribbon-like shape produce two new parallel contours, which are located symmetrically at two sides of the original one and have the same topological and geometric properties as that of the original shape. 3) The distance between these two parallel contours equals to the scale of the wavelet transform, which is independent of the width of the shape. This new scheme consists of two phases: 1) Generation of wavelet skeleton-based on the desirable properties of the new wavelet function, symmetry analyses of the maximum moduli of the wavelet transform is described. Midpoints of all pairs of contour elements can be connected to generate a skeleton of the shape, which is defined as wavelet skeleton. 2) Modification of the wavelet skeleton-Thereafter, a set of techniques are utilized for modifying the artifacts of the primary wavelet skeleton. The corresponding algorithm is also developed in this paper. Experimental results show that the proposed scheme is capable of extracting exactly the skeleton of the Ribbon-like shape with different width as well as different gray-levels. The skeleton representation is robust against noise and affine transformation.	Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Hubei Univ, Fac Math & Comp Sci, Wuhan, Peoples R China	Hong Kong Baptist University; Hubei University	You, XG (corresponding author), Hubei Univ, Fac Math & Comp Sci, Wuhan, Peoples R China.	yytang@comp.hkbu.edu.hk; xyou@comp.hkbu.edu.hk						BLUM H, 1973, BIOLOGY; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BRADY M, 1983, HUMAN MACHINE VISION, P39; BRADY M, 1993, INT J ROBOT RES, V15, P973; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chang HH, 1999, IEEE T SYST MAN CY B, V29, P47, DOI 10.1109/3477.740165; Chui CK, 1992, INTRO WAVELETS; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075; JANSSEN RDT, 1997, HDB CHARACTER RECOGN; KOVESI P, 1997, P 10 AUSTR JOINT C A, P2; Kovesi P., 1995, 954 U W AUSTR; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEYTON M, 1988, SYMMETRY CAUSALITY M; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727; Mallat S., 1999, WAVELET TOUR SIGNAL; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARTINEZPEREZ MP, 1987, COMPUT VISION GRAPH, V39, P186, DOI 10.1016/S0734-189X(87)80165-2; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; ROM H, 1984, IEEE T PATTERN ANAL, V3, P36; SAINTMARC P, 1993, IEEE T PATTERN ANAL, V15, P1191, DOI 10.1109/34.244680; SMITH RW, 1987, PATTERN RECOGN, V20, P7, DOI 10.1016/0031-3203(87)90013-6; Tang YY, 2000, IEEE T SYST MAN CY B, V30, P93, DOI 10.1109/3477.826950; TANG YY, 1999, WAVELET THEORY ITS A; TOMBRE K, 1998, GRAPHICS RECOGNITION; VENKATESH S, 1990, PATTERN RECOGN LETT, V11, P339, DOI 10.1016/0167-8655(90)90043-2; YANG L, 2003, IEEE T SYSTEMS MAN C; Yang L. H., 2001, P 2 INT C WAV ITS AP, V1, P872; ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023; Zou JJ, 1999, PATTERN RECOGN, V32, P935, DOI 10.1016/S0031-3203(98)00129-0; Zou JJ, 2001, IEEE T SYST MAN CY B, V31, P401, DOI 10.1109/3477.931528	34	93	99	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1118	1133						16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX					2022-12-18	WOS:000184977300007
J	Giordana, N; Pieczynski, W				Giordana, N; Pieczynski, W			Estimation of generalized multisensor hidden Markov chains and unsupervised image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multisensor data; mixture estimation; generalized mixture estimation; hidden Markov chain; Bayesian segmentation; unsupervised segmentation	PARAMETER-ESTIMATION; MAXIMUM-LIKELIHOOD; EM ALGORITHM; FIELDS	This paper attacks the problem of generalized multisensor mixture estimation. A distribution mixture is said to be generalized when the exact nature of components is not known, but each of them belongs to a finite known set of families of distributions. Estimating such a mixture entails a supplementary difficulty: One must label, for each class and each sensor, the exact nature of the corresponding distribution. Such generalized mixtures have been studied assuming that the components lie in the Pearson system. Adaptations of classical algorithms, such as Expectation-Maximization, Stochastic Expectation-Maximization, or Iterative Conditional Estimation, can then be used to estimate such mixtures in the context of independent identically distributed data and hidden Markov random fields. We propose a more general procedure with applications to estimating generalized multisensor hidden Markov chains. Our proposed method is applied to the problem of unsupervised image segmentation. The method proposed allows one to: (i) identify the conditional distribution for each class and each sensor, (ii) estimate the unknown parameters in this distribution, (iii) estimate priors, and (iv) estimate the ''true'' class image.			Giordana, N (corresponding author), INST NATL TELECOMMUN, DEPT SIGNAL & IMAGE, 9 RUE CHARLES FOURIER, F-91000 EVRY, FRANCE.		Pieczynski, Wojciech/AAW-4428-2020					Benmiloud B., 1995, Traitement du Signal, V12, P433; BESAG J, 1986, J R STAT SOC B, V48, P259; Braathen B., 1993, MACHINE GRAPHICS VIS, V2, P39; CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3; Chellapa R., 1993, MARKOV RANDOM FIELDS; DELIGNON Y, UNPUB IEEE T IMAGE P; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DEVIJVER PA, 1993, ADV APPL STAT STAT I, V1, P187; Dubes R.C., 1989, J APPL STAT, V16, P131, DOI DOI 10.1080/02664768900000014; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIORDANA N, 1996, THESIS U TECHNOLOGIE; HARALICK RM, 1986, IEEE T GEOSCI REMOTE, V24, P997, DOI 10.1109/TGRS.1986.289563; JOHNSON NL, 1970, DISTRIBUTIONS STATIS, V1; KALEH GK, 1994, IEEE T COMMUN, V42, P2406, DOI 10.1109/26.297849; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; Law AM., 1991, SIMULATION MODELING, V2nd; MAFFET A, 1981, IEEE T GRS, V29; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MASSON P, 1993, IEEE T GEOSCI REMOTE, V31, P618, DOI 10.1109/36.225529; MOHN E, 1987, IEEE T GEOSCI REMOTE, V25, P796, DOI 10.1109/TGRS.1987.289751; PENG A, 1995, ADAPTIVE MIXTURE EST, V57, P389; PIECZYNSKI W, 1990, 122 LSTA; PIECZYNSKI W, 1992, MACHINE GRAPHICS VIS, V1, P261; QIAN W, 1989, J APPL STAT, V16, P267; QUELLE HC, 1993, P IGARSS 93, P1538; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; SKARBEK W, 1992, GEN HILBERT SCAN IMA, P45; TILTON JC, 1982, IEEE T GEOSCI REMOTE, V20, P445, DOI 10.1109/TGRS.1982.350410; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863	32	93	99	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					465	475		10.1109/34.589206	http://dx.doi.org/10.1109/34.589206			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300005
J	Revow, M; Williams, CKI; Hinton, GE				Revow, M; Williams, CKI; Hinton, GE			Using generative models for handwritten digit recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformable model; elastic net; optical character recognition; generative model; probabilistic model; mixture model	CHARACTER-RECOGNITION; IMAGES; NUMERALS	We describe a method of recognizing handwritten digits by fitting generative models that are built from deformable B-splines with Gaussian ''ink generators'' spaced along the length of the spline. The splines are adjusted using a novel elastic matching procedure based on the Expectation Maximization (EM) algorithm that maximizes the likelihood of the model generating the data. This approach has many advantages. 1) After identifying the model most likely to have generated the data, the system not only produces a classification of the digit but also a rich description of the instantiation parameters which can yield information such as the writing style. 2) During the process of explaining the image, generative models can perform recognition driven segmentation. 3) The method involves a relatively small number or parameters and hence training is relatively easy and fast. 4) Unlike many other recognition schemes, if does not rely on some form of pre-normalization of input images, but can handle arbitrary scalings, translations and a limited degree of image rotation. We have demonstrated our method of fitting models to images does not get trapped in poor local minima. The main disadvantage of the method is it requires much more computation than more standard OCR techniques.	ASTON UNIV, DEPT COMP SCI & APPL MATH, BIRMINGHAM B4 7ET, W MIDLANDS, ENGLAND	Aston University	Revow, M (corresponding author), UNIV TORONTO, DEPT COMP SCI, 6 KINGS COLL RD, TORONTO, ON M5S 3H5, CANADA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; BAJCSY R, 1983, J COMPUT ASSIST TOMO, V7, P618, DOI 10.1097/00004728-198308000-00008; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; Bertille J.-M., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P82, DOI 10.1109/ICDAR.1993.395777; BRIDLE JS, 1990, NATO ASI SERIES SYST; BROMLEY J, 1993, NEURAL COMPUT, V5, P367, DOI 10.1162/neco.1993.5.3.367; BROWN P, RC12750 IBM RES DIV; BROWN PF, 1987, THESIS CARNEGIE MELL; BURGES CJC, 1992, IJCNN, V3, P165; BURR DJ, 1981, COMPUT VISION GRAPH, V15, P102, DOI 10.1016/0146-664X(81)90072-1; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; BURR DJ, 1983, PHYSICAL BIOL P IMAG; CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; Durbin R, 1989, NEURAL COMPUT, V1, P348, DOI 10.1162/neco.1989.1.3.348; EDELMAN S, 1990, INT J COMPUT VISION, V5, P303, DOI 10.1007/BF00126503; Everitt B., 1984, INTRO LATENT VARIABL; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912; GEIST J, 1994, 2 CENS OPT CHAR REC; Grenander U., 1991, HANDS PATTERN THEORE; Gupta A., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P757, DOI 10.1142/S0218001493000376; HA TM, 1994, P 4 INT WORKSH FRONT, P97; HAMPSHIRE J, 1989, CMUCS89118 CARN MELL; HASTIE T, 1992, HANDWRITTEN DIGIT RE; HINTON G, 1992, ADV NEURAL INFORMATI, V4; Hinton G. E., 1995, ADV NEURAL INFORMATI, V7, P1015; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; IMPEDOVO S, 1994, FUNDAMENTALS HANDWRI; KASS M, 1987, P 1 INT C COMP VIS W; Keeler James D, 1991, P ADV NEUR INF PROC, P557; KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; LANITIS A, 1993, P BRIT MACH VIS C, V1, P329; LeCun Y., 1989, ADV NEURAL INFORM PR, P396; Lee D.-S., 1993, P 3 INT WORKSH FRONT, P153; Lee Y, 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; MENG XL, 1992, BAYESIAN STATISTICS, V4, P307; MOSHFEGHI M, 1991, CVGIP-GRAPH MODEL IM, V53, P271, DOI 10.1016/1049-9652(91)90049-P; SHRIDHAR M, 1986, PATTERN RECOGN, V19, P1, DOI 10.1016/0031-3203(86)90025-7; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; ULLMANN JR, 1972, MACHINE PERCEPTION P; VARGA M, 1990, IEE PROC-I, V137, P146, DOI 10.1049/ip-i-2.1990.0021; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; WILLIAMS C, 1994, THESIS U TORONTO; WILLIAMS CKI, 1993, SPATIAL VISION HUMAN; WILLIAMS CKI, 1995, ADV NEURAL INFORMATI, V7, P965; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59	53	93	98	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					592	606		10.1109/34.506410	http://dx.doi.org/10.1109/34.506410			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254		Green Accepted			2022-12-18	WOS:A1996UR25400003
J	LI, SZ				LI, SZ			ON DISCONTINUITY-ADAPTIVE SMOOTHNESS PRIORS IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DISCONTINUITIES; ENERGY FUNCTIONS; EULER EQUATION; COMPUTER VISION; MARKOV RANDOM FIELDS; MINIMIZATION; REGULARIZATION	COMPUTATIONAL VISION; REGULARIZATION; RECONSTRUCTION; IMAGES	A variety of analytic and probabilistic models in connection to Markov random fields (MRFs) have been proposed in the last decade for solving low level vision problems involving discontinuities. This paper presents a systematic study of these models and defines a general discontinuity adaptive (DA) MRP model. By analyzing the Euler equation associated with the energy minimization, it shows that the fundamental difference between different models lies in the behavior of interaction between neighboring points, which is determined by the a priori smoothness constraint encoded into the energy function, An important necessary condition is derived for the interaction to be adaptive to discontinuities to avoid oversmoothing, This forms the basis on which a class of adaptive interaction functions (AIFs) is defined. The DA model is defined in terms of the Euler equation constrained by this class of AIFs, Its solution is C-1 continuous and allows arbitrarily large but bounded slopes in dealing with discontinuities. Because of the continuous nature, it is stable to changes in parameters and data, a good property for regularizing ill-posed problems, Experimental results are shown.			LI, SZ (corresponding author), NANYANG TECHNOL UNIV,SCH ELECT & ELECTR ENGN,SINGAPORE 2263,SINGAPORE.							BERTERO M, 1988, P IEEE, V76; Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; Blake A, 1983, PATTERN RECOGN LETT, V1, P393, DOI 10.1016/0167-8655(83)90077-6; BOULT TE, 1987, 1ST P INT C COMP VIS, P457; Cesari L., 1983, OPTIMIZATION THEORY; COURANT R, 1953, METHODS MATH PHYSICS, V1; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; ELLIOTT H, 1984, MAR P INT C AC SPEEC; GEIGER D, 1991, IEEE T PATTERN ANAL, V13; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; HARRIS JG, 1987, 1ST P INT C COMP VIS, P277; HEBERT T, 1992, IEEE T SIGNAL PROCES, V40; Hinton G. H, 1978, THESIS U EDINBURGH E; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; KOCH CC, 1988, NEW MATERIALS MECHAN, P101; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LEE D, 1987, 1ST P INT C COMP VIS, P572; Li S., 1995, MARKOV RANDOM FIELD, P1; LI SZ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P709; LI SZ, 1994, JUN P IEEE CS C COMP; LI SZ, 1995, IMAGE VISION COMPUTI, V13; LI SZ, 1991, THESIS U SURREY GUIL; Liu S.-C., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P184, DOI 10.1109/CVPR.1989.37848; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN J, 1985, THESIS MIT; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; Nadabar S. G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P528, DOI 10.1109/CVPR.1992.223140; NORDSTROM N, 1990, P 1 EUR C COMP VIS, P18; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097; STEVENSON R, 1990, OCT P INT WORKSH ROB, P127; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1983, 8TH P INT JOINT C AR, P1073; Tikhonov A., 1977, SOLUTIONS ILL POSED; WAHBA G, 1980, APPROXIMATION THEO 3, V2; WEISS I, 1990, IEEE T PATTERN ANAL, V12, P345, DOI 10.1109/34.50621; WITKIN A, 1987, INT J COMPUT VISION, P133; YUILLE A, 1987, MIT987 AI LAB MEM; [No title captured]	45	93	100	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					576	586		10.1109/34.387504	http://dx.doi.org/10.1109/34.387504			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000003
J	SARKAR, S; BOYER, KL				SARKAR, S; BOYER, KL			ON OPTIMAL INFINITE IMPULSE-RESPONSE EDGE-DETECTION FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDGE DETECTION; FEATURE EXTRACTION; IIR FILTERS; IMAGE PROCESSING; MACHINE VISION; VARIATIONAL APPROACH	CONVOLUTION; STEREO	In this paper, we outline the design of an optimal, computationally efficient, infinite impulse response edge detection filter. We compute the optimal filter based on Canny's high signal to noise ratio, good localization criteria, and a criterion on the spurious response of the filter to noise. In our design procedure, we incorporate an expression for the width of the filter, which is appropriate for infinite length filters, directly in the expression for spurious responses. The three criteria are maximized using the variational method and nonlinear constrained optimization. The optimal filter parameters are tabulated for various values of the filter performance criteria. A complete methodology for implementing the optimal filters using approximating recursive digital filtering is presented. The approximating recursive digitial filter is separable into two linear filters operating in two orthogonal directions. The implementation is very simple and computationally efficient. It has a constant time of execution for different sizes of the operator and is readily amenable to real time hardware implementation.			SARKAR, S (corresponding author), OHIO STATE UNIV, DEPT ELECT ENGN, SIGNAL ANAL & MACHINE PERCEPT LAB, COLUMBUS, OH 43210 USA.		Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				BAKER HH, 1979, 7TH P INT JOINT C AR, P631; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782; BOVIK AC, 1986, PATTERN RECOGN, V19, P209, DOI 10.1016/0031-3203(86)90011-7; BOYER KL, 1988, P SOC PHOTO-OPT INS, V1005, P219; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; Burt P. J., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P669; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Canny J.F., 1983, AITR720 MIT ART INT, P6; CHEN JS, 1987, IEEE T PATTERN ANAL, V9, P584, DOI 10.1109/TPAMI.1987.4767946; COURANT R, 1953, METHODS MATH PHYSICS; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; FERRARI LA, 1987, IEEE T PATTERN ANAL, V9, P461, DOI 10.1109/TPAMI.1987.4767929; Gardner W. A., 1989, INTRO RANDOM PROCESS; GRIMSON WEL, 1981, IMAGES SURFACES COMP; GRIMSON WEL, 1986, TECHNIQUES 3D MACHIN, P75; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUANG JS, 1988, COMPUT VISION GRAPH, V43, P337, DOI 10.1016/0734-189X(88)90087-4; KAK AC, 1986, HDB IND ROBOTICS, P272; Luenberger D. G., 1973, INTRO LINEAR NONLINE; LUNSCHER WHHJ, 1983, IEEE T PATTERN ANAL, V5, P678, DOI 10.1109/TPAMI.1983.4767462; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1981, VISION COMPUTATIONAL; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; NAHI NE, 1972, IEEE T COMPUT, VC 21, P734; NAHI NE, 1977, IEEE T COMPUT, V26, P772, DOI 10.1109/TC.1977.1674915; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; POGGIO T, 1985, MA AIM833 MIT ART IN; RICE SO, 1945, AT&T TECH J, V24, P46, DOI 10.1002/j.1538-7305.1945.tb00453.x; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2; SPACEK L, 1984, THESIS U ESSEX COLCH; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI [10.1109/34.62607, 10.1117/12.19530]; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; WELLS WM, 1986, IEEE T PATTERN ANAL, V8, P234, DOI 10.1109/TPAMI.1986.4767776; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	40	93	100	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1991	13	11					1154	1171		10.1109/34.103275	http://dx.doi.org/10.1109/34.103275			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN338					2022-12-18	WOS:A1991GN33800004
J	SZELISKI, R				SZELISKI, R			FAST SURFACE INTERPOLATION USING HIERARCHICAL BASIS FUNCTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025; SCHLUMBERGER PALO ALTO RES,SCI STAFF,PALO ALTO,CA	SRI International; Schlumberger	SZELISKI, R (corresponding author), DIGITAL EQUIPMENT CORP,CAMBRIDGE RES LAB,RES STAFF,1 KENDALL SQ,BLDG 700,CAMBRIDGE,MA 02139, USA.							Ahlberg J.H., 1967, THEORY SPLINES THEIR; Axelsson O., 1984, FINITE ELEMENT SOLUT; BARTHE KJ, 1976, NUMERICAL METHODS FI; BOULT T, 1986, THESIS COLUMBIA U; Briggs W., 1987, MULTIGRID TUTORIAL; CENDES ZJ, 1987, IEEE COMPUT GRAPH, V7, P8, DOI 10.1109/MCG.1987.277064; CHOI DJ, 1987, 1987 P IM UND WORKSH, P639; CROWLEY JL, 1982, CMURITR8218 CARN U R; FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846; GEORGE A, 1981, COMPUTER SOLUTION LA; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; HACKBUSCH W., 1985, SPRINGER SER COMPUT, V4; HANNAH MJ, 1988, 1988 P IM UND WORKSH, P740; Hillis W., 1985, CONNECTION MACHINE; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; LECLERC YG, 1989, INT J COMPUT VISION, V3, P75; MALLAT SG, 1987, 1987 P IEEE COMP SOC, P2; Marr D., 1978, COMPUTER VISION SYST, P61; MARROQUIN JL, 1984, MIT AI792 ART INT LA; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MCBRYAN O, 1986, NA863 THINK MACH COR; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Potter Jerry L., 1985, MASSIVELY PARALLEL P; Press WH, 1986, NUMERICAL RECIPES C, V818; RON G, 1989, 1989 P IEEE COMP SOC, P350; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Simchony T., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P580, DOI 10.1109/CCV.1988.590038; SZELISKI R, 1990, 1ST EUR C COMP VIS A; SZELISKI R, 1989, BAYESIAN MODELING UN; SZELISKI R, 1989, 4 COPP MOUNT C MULT, P383; SZELISKI R, 1989, 470 ART INT CTR SRI; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; TERZOPOULOS D, 1985, 1985 P IM UND WORKSH, P156; TERZOPOULOS D, 1984, THESIS MIT; Tikhonov A., 1977, SOLUTIONS ILL POSED; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; YOUNG DM, 1971, ITERATIVE SOLUTION L; YSERENTANT H, 1986, NUMER MATH, V49, P379, DOI 10.1007/BF01389538	45	93	100	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					513	528		10.1109/34.56188	http://dx.doi.org/10.1109/34.56188			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300001
J	HUANG, TS; FAUGERAS, OD				HUANG, TS; FAUGERAS, OD			SOME PROPERTIES OF THE E-MATRIX IN 2-VIEW MOTION ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									INST NATL RECH INFORMAT & AUTOMAT,F-06565 VALBONNE,FRANCE		HUANG, TS (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							BRACCINI C, 1987, COMMUNICATION    FEB; BRACCINI C, 1986, SEP P EUSIPCO 86 HAG; FAUGERAS OD, 1987, 1ST P ICCV LOND; HUANG TS, 1986, ISP102 U ILL COORD S; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1987, COMMUNICATION   0323; LONGUETHIGGINS HC, 1987, COMMUNICATION; NETRAVALI A, IN PRESS INT J IMAGI; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WENG J, 1987, 1ST P ICCV LOND	10	93	100	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1989	11	12					1310	1312		10.1109/34.41368	http://dx.doi.org/10.1109/34.41368			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB716					2022-12-18	WOS:A1989CB71600006
J	SETHI, IK; SARVARAYUDU, GPR				SETHI, IK; SARVARAYUDU, GPR			HIERARCHICAL CLASSIFIER DESIGN USING MUTUAL INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									JAWAHARLAL NEHRU TECHNOL UNIV,JABALPUR,INDIA		SETHI, IK (corresponding author), INDIAN INST TECHNOL,DEPT ELECTR & ELECT COMMUN ENGN,KHARAGPUR 721302,W BENGAL,INDIA.			Sethi, Ishwar/0000-0002-2578-111X				DATTATREYA GR, 1980, 5TH P INT C PATTERN, V2, P1212; FANO RM, 1963, TRANSMISSION INFORMA; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FISHER RA, 1977, MACHINE RECOGNITION; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404, DOI 10.1109/TC.1977.1674849; HENRICHON EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P194; Kulkarni A. V., 1976, 3rd International Joint Conference on Pattern Recognition, P459; PAYNE HJ, 1977, IEEE T COMPUT C, V25, P905; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; SETHI IK, 1980, 5TH P INT C PATT REC, V2, P879	11	93	98	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					441	445		10.1109/TPAMI.1982.4767278	http://dx.doi.org/10.1109/TPAMI.1982.4767278			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869061				2022-12-18	WOS:A1982NT73500013
J	Palazzi, A; Abati, D; Calderara, S; Solera, F; Cucchiara, R				Palazzi, Andrea; Abati, Davide; Calderara, Simone; Solera, Francesco; Cucchiara, Rita			Predicting the Driver's Focus of Attention: The DR(eye)VE Project	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Focus of attention; driver's attention; gaze prediction	REAL-WORLD SCENES; EYE-MOVEMENTS; SALIENCY; MODEL; SEARCH	In this work we aim to predict the driver's focus of attention, The goal is to estimate what a person would pay attention to while driving, and which part of the scene around the vehicle is more critical for the task. To this end we propose a new computer vision model based on a multi-branch deep architecture that integrates three sources of information: raw video, motion and scene semantics. We also introduce DR (eye)VE, the largest dataset of driving scenes for which eye-tracking annotations are available. This dataset features more than 500,000 registered frames, matching ego-centric views (from glasses worn by drivers) and car-centric views (from roof-mounted camera), further enriched by other sensors measurements. Results highlight that several attention patterns are shared across drivers and can be reproduced to some extent. The indication of which elements in the scene are likely to capture the driver's attention may benefit several applications in the context of human-vehicle interaction and driver attention analysis.	[Palazzi, Andrea; Abati, Davide; Calderara, Simone; Solera, Francesco; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, MO, Italy	Universita di Modena e Reggio Emilia	Abati, D (corresponding author), Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, MO, Italy.	andrea.palazzi@unimore.it; davide.abati@unimore.it; simone.calderara@unimore.it; francesco.solera@unimore.it; rita.cucchiara@unimore.it	Calderara, Simone/M-6932-2015; Cucchiara, Rita/L-3006-2015	Calderara, Simone/0000-0001-9056-1538; Cucchiara, Rita/0000-0002-2239-283X; PALAZZI, ANDREA/0000-0003-2251-3918; Solera, Francesco/0000-0001-8985-7788	CINECA award under the ISCRA initiative	CINECA award under the ISCRA initiative(CINECA, Italy)	We acknowledge the CINECA award under the ISCRA initiative, for the availability of high performance computing resources and support. We also gratefully acknowledge the support of Facebook Artificial Intelligence Research and Panasonic Silicon Valley Lab for the donation of GPUs used for this research.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alletto S, 2016, IEEE COMPUT SOC CONF, P54, DOI 10.1109/CVPRW.2016.14; Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339; Bazzani Loris, 2017, ICLR; Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583; Borji A., 2015, P COMP VIS PATT REC; Borji A, 2016, J VISION, V16, DOI 10.1167/16.14.18; Borji A, 2014, IEEE T SYST MAN CY-S, V44, P523, DOI 10.1109/TSMC.2013.2279715; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Bremond R., 2014, P T RES ARENA; Bylinskii Z, 2015, MIT SALIENCY BENCHMA; Bylinskii Zoya, 2016, ARXIV160403605; Chen XZ, 2015, ADV NEUR IN, V28; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cornia M., 2016, CORR; Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fridman L, 2016, IEEE INTELL SYST, V31, P49, DOI 10.1109/MIS.2016.47; Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355; Frohlich B, 2014, IEEE INT VEH SYM, P37, DOI 10.1109/IVS.2014.6856477; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Gkamas T, 2011, 17 INT C DIG SIGN PR, P1; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Groner R, 1984, THEORETICAL APPL ASP, P523; Grubmuller S, 2017, AUTOMATED DRIVING: SAFER AND MORE EFFICIENT FUTURE DRIVING, P29, DOI 10.1007/978-3-319-31895-0_3; Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; Jain A, 2015, IEEE I CONF COMP VIS, P3182, DOI 10.1109/ICCV.2015.364; JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kingma D.P, P 3 INT C LEARNING R; Kummerer M, 2015, P NATL ACAD SCI USA, V112, P16054, DOI 10.1073/pnas.1510393112; Kumar P, 2013, IEEE INT VEH SYM, P797, DOI 10.1109/IVS.2013.6629564; Kummerer M., 2015, P INT C LEARN REPR; Larson AM, 2009, J VISION, V9, DOI 10.1167/9.10.6; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Ma Y.-F, 2003, P 11 ACM INT C MULTI, P374; Mannan SK, 1997, SPATIAL VISION, V11, P157, DOI 10.1163/156856897X00177; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Mauthner T, 2015, PROC CVPR IEEE, P2494, DOI 10.1109/CVPR.2015.7298864; Morris B, 2011, IEEE INT VEH SYM, P895, DOI 10.1109/IVS.2011.5940538; Mousavian A., 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597; Nilsson D, 2018, PROC CVPR IEEE, P6819, DOI 10.1109/CVPR.2018.00713; Palazzi A, 2017, IEEE INT VEH SYM, P920, DOI 10.1109/IVS.2017.7995833; Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117; Perry JS, 2002, P SOC PHOTO-OPT INS, V4662, P57, DOI 10.1117/12.469554; Peters R.J., 2007, 2007 IEEE C COMP VIS; Peters RJ, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279920.1279923; POSNER MI, 1985, COGNITIVE NEUROPSYCH, V2, P211, DOI 10.1080/02643298508252866; Pugeault N, 2015, IEEE T VEH TECHNOL, V64, P5424, DOI 10.1109/TVT.2015.2487826; Roge J, 2004, VISION RES, V44, P2737, DOI 10.1016/j.visres.2004.05.026; Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152; Ruksenas R, 2008, ELECTRON NOTES THEOR, V208, P57, DOI 10.1016/j.entcs.2008.03.107; Sardegna J., 2002, ENCY BLINDNESS VISIO; Schlkopf B., 2007, GRAPH BASED VISUAL S, P545; Simon L, 2009, IEEE INT VEH SYM, P48, DOI 10.1109/IVS.2009.5164251; Tatler BW, 2011, J VISION, V11, DOI 10.1167/11.5.5; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; Tawari A, 2014, IEEE INT VEH SYM, P344, DOI 10.1109/IVS.2014.6856607; Theeuwes J, 2010, ACTA PSYCHOL, V135, P77, DOI 10.1016/j.actpsy.2010.02.006; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Ueda Y, 2017, JPN PSYCHOL RES, V59, P109, DOI 10.1111/jpr.12144; Underwood G, 2011, VISION RES, V51, P2031, DOI 10.1016/j.visres.2011.07.020; Vicente F, 2015, IEEE T INTELL TRANSP, V16, P2014, DOI 10.1109/TITS.2015.2396031; Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163; Wang PQ, 2017, J VISION, V17, DOI 10.1167/17.4.9; Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Wolfe Jeremy M, 2010, Curr Biol, V20, pR346, DOI 10.1016/j.cub.2010.02.016; WOLFE JM, 1989, J EXP PSYCHOL HUMAN, V15, P419, DOI 10.1037/0096-1523.15.3.419; Yu F., 2016, P ICLR 2016; Zhai Y., 2006, PROC14TH ACM INT C M, DOI [10.1145/1180639.1180824, DOI 10.1145/1180639.1180824]; Zhong S.H., 2013, PROC 27 AAAI C ARTIF	77	92	97	6	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1720	1733		10.1109/TPAMI.2018.2845370	http://dx.doi.org/10.1109/TPAMI.2018.2845370			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	IC4XW	29994193	Green Submitted			2022-12-18	WOS:000470972300015
J	Ouyang, WL; Zhou, H; Li, HS; Li, QQ; Yan, JJ; Wang, XG				Ouyang, Wanli; Zhou, Hui; Li, Hongsheng; Li, Quanquan; Yan, Junjie; Wang, Xiaogang			Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CNN; convolutional neural networks; object detection; deep learning; deep model	SINGLE; IMAGE; MODEL	Feature extraction, deformation handling, occlusion handling, and classification are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture (Code available on www.ee.cuhk.edu.hk/wlouyang/projects/ouyangWiccv13Joint/index.html). By establishing automatic, mutual interaction among components, the deep model has average miss rate 8.57 percent/11.71 percent on the Caltech benchmark dataset with new/original annotations.	[Ouyang, Wanli] Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia; [Ouyang, Wanli; Zhou, Hui; Li, Hongsheng; Li, Quanquan; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China; [Yan, Junjie] SenseTime Grp Ltd, Shatin, Hong Kong, Peoples R China	University of Sydney; Chinese University of Hong Kong	Ouyang, WL (corresponding author), Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia.	wlouyang@ee.cuhk.edu.hk; hsli@ee.cuhk.edu.hk; liquanquan@sensetime.com; yanjunjie@sensetime.com; xgwang@ee.cuhk.edu.hk	Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761	General Research Fund - Research Grants Council of Hong Kong [CUHK 417110, CUHK 417011, CUHK 429412, CUHK 1420611, CUHK 14206114, CUHK 14205615, CUHK 14213616, CUHK14203015, CUHK14207814]; Hong Kong Innovation and Technology Support Programme [ITS/121/15FX]; National Natural Science Foundation of China [61371192, 61301269]; PhD programs foundation of China [20130185120039]	General Research Fund - Research Grants Council of Hong Kong(Hong Kong Research Grants Council); Hong Kong Innovation and Technology Support Programme; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); PhD programs foundation of China	This work is supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No. CUHK 417110, CUHK 417011, CUHK 429412, CUHK 1420611, CUHK 14206114, CUHK 14205615, CUHK 14213616, CUHK14203015, CUHK14207814) and the Hong Kong Innovation and Technology Support Programme (No. ITS/121/15FX), National Natural Science Foundation of China (Nos. 61371192, 61301269), and PhD programs foundation of China (No. 20130185120039).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bar-Hillel A., DEEPVISUALIZATION ON; Bar-Hillel A, 2010, LECT NOTES COMPUT SC, V6314, P127, DOI 10.1007/978-3-642-15561-1_10; Barinova O., 2010, P IEEE C COMP VIS PA, P1773; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Dikmen M, 2012, PROC CVPR IEEE, P3314, DOI 10.1109/CVPR.2012.6248069; Ding YY, 2012, PROC CVPR IEEE, P2895, DOI 10.1109/CVPR.2012.6248016; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, LECT NOTES COMPUT SC, V7573, P645, DOI 10.1007/978-3-642-33709-3_46; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Dollar Piotr, 2010, BMVC, DOI DOI 10.5244/C.24.68; Enzweiler M, 2010, PROC CVPR IEEE, P990, DOI 10.1109/CVPR.2010.5540111; Erhan D, 2009, 1341 U MONTR, V1341, P1, DOI DOI 10.2464/JILM.23.425; Ess A, 2007, IEEE I CONF COMP VIS, P2065; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gao TS, 2011, PROC CVPR IEEE, P1361, DOI 10.1109/CVPR.2011.5995623; Ge DJ, 2017, IEEE INT CONF FUZZY; Girshick R., 2015, RICH FEATURE HIERARC, P580; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.232; Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le Q., 2012, INT C MACH LEARN, DOI DOI 10.1109/MSP.2011.940881; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leibe B, 2005, PROC CVPR IEEE, P878; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120; Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963; Maji S, 2008, PROC CVPR IEEE, P2245; Marin J, 2013, IEEE I CONF COMP VIS, P2592, DOI 10.1109/ICCV.2013.322; Mathias M, 2013, IEEE I CONF COMP VIS, P1505, DOI 10.1109/ICCV.2013.190; Mikolajczyk K., 2006, IEEE C COMP VIS PATT, V1, P26; Nam W, 2014, ADV NEUR IN, V27; Norouzi Mohammad, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2735, DOI 10.1109/CVPRW.2009.5206577; Ouyang W., 2017, P IEEE 12 INT C COMP; Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642; Ouyang WL, 2016, IEEE T CIRC SYST VID, V26, P2123, DOI 10.1109/TCSVT.2015.2501940; Ouyang WL, 2016, INT J COMPUT VISION, V120, P14, DOI 10.1007/s11263-016-0890-9; Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854; Ouyang WL, 2015, IEEE T PATTERN ANAL, V37, P1875, DOI 10.1109/TPAMI.2014.2377734; Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257; Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414; Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411; Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062; Paisitkriangkrai S, 2016, IEEE T PATTERN ANAL, V38, P1243, DOI 10.1109/TPAMI.2015.2474388; Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371; Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18; Poon H., 2011, P 27 C UNC ART INT, P337, DOI DOI 10.1109/ICCVW.2011; Ramanan D., 2007, ADV NEURAL INFORM PR, V19, P1129; Ranzato Marc'Aurelio., 2007, PROC CVPR IEEE, P1, DOI [10.1109/CVPR.2007.383157, DOI 10.1109/CVPR.2007.383157]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sabzmeydani P., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383134; Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Shet V.D., 2007, P IEEE C COMP VIS PA, P1; Sun Y., 2013, P IEEE 12 INT C COMP, P1489; Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221; Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; WALK S, 2010, PROC CVPR IEEE, P1030, DOI DOI 10.1109/CVPR.2010.5540102; Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9; Wu B, 2005, IEEE I CONF COMP VIS, P90; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Yan JJ, 2015, PROC CVPR IEEE, P5107, DOI 10.1109/CVPR.2015.7299146; Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Yang Y., 2015, BMVC, P1; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22; Zeng XY, 2013, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2013.22; Zhang S., 2014, CVPR; Zhang SS, 2016, PROC CVPR IEEE, P1259, DOI 10.1109/CVPR.2016.141; ZHANG SS, 2015, PROC CVPR IEEE, P1751, DOI DOI 10.1109/CVPR.2015.7298784; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096	94	92	97	4	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1874	1887		10.1109/TPAMI.2017.2738645	http://dx.doi.org/10.1109/TPAMI.2017.2738645			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28809675				2022-12-18	WOS:000437271100007
J	Liao, SC; Jain, AK; Li, SZ				Liao, Shengcai; Jain, Anil K.; Li, Stan Z.			A Fast and Accurate Unconstrained Face Detector	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unconstrained face detection; normalized pixel difference; deep quadratic tree; AdaBoost; cascade classifier	HAAR-LIKE FEATURES; OBJECT DETECTION	We propose a method to address challenges in unconstrained face detection, such as arbitrary pose variations and occlusions. First, a new image feature called Normalized Pixel Difference (NPD) is proposed. NPD feature is computed as the difference to sum ratio between two pixel values, inspired by the Weber Fraction in experimental psychology. The new feature is scale invariant, bounded, and is able to reconstruct the original image. Second, we propose a deep quadratic tree to learn the optimal subset of NPD features and their combinations, so that complex face manifolds can be partitioned by the learned rules. This way, only a single soft-cascade classifier is needed to handle unconstrained face detection. Furthermore, we show that the NPD features can be efficiently obtained from a look up table, and the detection template can be easily scaled, making the proposed face detector very fast. Experimental results on three public face datasets (FDDB, GENKI, and CMU-MIT) show that the proposed method achieves state-of-the-art performance in detecting unconstrained faces with arbitrary pose variations and occlusions in cluttered scenes.	[Liao, Shengcai; Li, Stan Z.] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Liao, Shengcai; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Inst Automat, Beijing 100190, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Michigan State University	Liao, SC; Li, SZ (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.; Liao, SC; Li, SZ (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Inst Automat, Beijing 100190, Peoples R China.; Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	scliao@nlpr.ia.ac.cn; jain@cse.msu.edu; szli@nlpr.ia.ac.cn		Liao, Shengcai/0000-0001-8941-2295	NSFC [61203267]; National Science and Technology Support Program [2013BAK02B01]; CAS Project [KGZD-EW-102-2]	NSFC(National Natural Science Foundation of China (NSFC)); National Science and Technology Support Program; CAS Project(Chinese Academy of Sciences)	This work was supported by NSFC #61203267, National Science and Technology Support Program #2013BAK02B01, and CAS Project #KGZD-EW-102-2.	Abramson Y., 2007, International Journal of Intelligent Systems Technologies and Applications, V2, P102, DOI 10.1504/IJISTA.2007.012476; [Anonymous], 2010, PITTPATT SOFTW DEV K; [Anonymous], 2009, MPLAB GENKI DATABASE; Baluja S, 2004, IEEE IMAGE PROC, P589; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Berg T. L., 2004, P ADV NEUR INF PROC, V17, P137; Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310; Breiman L., 2017, CLASSIFICATION REGRE; Brubaker S., 2005, GITGVU0528; Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8; Chen J, 2006, INT C PATT RECOG, P516; Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Froba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514; Goldmann L, 2007, IEEE T INF FOREN SEC, V2, P559, DOI 10.1109/TIFS.2007.902019; Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306; Hotta K, 2004, IEEE IMAGE PROC, P597; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; Jain V., 2010, UMCS2010009; Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317; Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518; Jones M.J., 2003, TR200396 MITS EL RES; Kim T., 2008, ADV NEURAL INFORM PR, P841; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kostinger M., 2012, P DAGM COMP VIS APPL; Kriegler F. J., 1969, Proceedings of the 6th international symposium on remote sensing of environment, P97; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238; Li HX, 2013, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2013.103; Li JG, 2013, PROC CVPR IEEE, P3468, DOI 10.1109/CVPR.2013.445; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; Liao SC, 2006, LECT NOTES COMPUT SC, V3832, P40; Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297; Lienhart R, 2002, IEEE IMAGE PROC, P900; Lin YY, 2005, PROC CVPR IEEE, P680; Lin YY, 2004, LECT NOTES COMPUT SC, V3021, P402; Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47; Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69; Mita T, 2005, IEEE I CONF COMP VIS, P1619; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Sadr J., 2001, P ANN C NEUR INF PRO, P3; Seemann E., 2006, P IEEE INT C COMP VI, V2, P1582, DOI DOI 10.1109/CVPR.2006.193; Segui Santi, 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P90; Shen XH, 2013, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2013.444; Sinha P, 2002, LECT NOTES COMPUT SC, V2525, P249; Subburaman V. B., 2010, P WORKSH FAC DET WE; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang LT, 2011, SOFT COMPUT, V15, P417, DOI 10.1007/s00500-009-0523-0; Weber E. H., 1846, HANDWORTERBUCH PHYSL, VIII/2, P481; Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79; Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320; Yan SY, 2008, PROC CVPR IEEE, P3576; Yang B., 2014, IEEE INT JOINT C BIO, P1; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Zhang C., 2010, MSRTR201066; Zhang HM, 2006, IMAGE VISION COMPUT, V24, P327, DOI 10.1016/j.imavis.2005.11.010; Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	61	92	96	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					211	223		10.1109/TPAMI.2015.2448075	http://dx.doi.org/10.1109/TPAMI.2015.2448075			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI		Green Submitted			2022-12-18	WOS:000369989600002
J	Sprechmann, P; Bronstein, AM; Sapiro, G				Sprechmann, P.; Bronstein, A. M.; Sapiro, G.			Learning Efficient Sparse and Low Rank Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Parsimonious modeling; sparse and low-rank models; NMF; deep learning; real-time implementations; big data; proximal methods	SINGING-VOICE SEPARATION; THRESHOLDING ALGORITHM; CONVERGENCE; REGRESSION; SHRINKAGE; SELECTION	Parsimony, including sparsity and low rank, has been shown to successfully model data in numerous machine learning and signal processing tasks. Traditionally, such modeling approaches rely on an iterative algorithm that minimizes an objective function with parsimony-promoting terms. The inherently sequential structure and data-dependent complexity and latency of iterative optimization constitute a major limitation in many applications requiring real-time performance or involving large-scale data. Another limitation encountered by these modeling techniques is the difficulty of their inclusion in discriminative learning scenarios. In this work, we propose to move the emphasis from the model to the pursuit algorithm, and develop a process-centric view of parsimonious modeling, in which a learned deterministic fixed-complexity pursuit process is used in lieu of iterative optimization. We show a principled way to construct learnable pursuit process architectures for structured sparse and robust low rank models, derived from the iteration of proximal descent algorithms. These architectures learn to approximate the exact parsimonious representation at a fraction of the complexity of the standard optimization methods. We also show that appropriate training regimes allow to naturally extend parsimonious models to discriminative settings. State-of-the-art results are demonstrated on several challenging problems in image and audio processing with several orders of magnitude speed-up compared to the exact optimization algorithms.	[Sprechmann, P.; Sapiro, G.] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Bronstein, A. M.] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel	Duke University; Tel Aviv University	Sprechmann, P (corresponding author), Duke Univ, ECE Dept, Durham, NC 27708 USA.	pablo.sprechmann@duke.edu; bron@eng.tau.ac.il; guillermo.sapiro@duke.edu			US National Science Foundation (NSF); ONR; NGA; DARPA; AFOSR; ARO; BSF; ERC [335491]	US National Science Foundation (NSF)(National Science Foundation (NSF)); ONR(Office of Naval Research); NGA; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); ARO; BSF(US-Israel Binational Science Foundation); ERC(European Research Council (ERC)European Commission)	This work was partially supported by the US National Science Foundation (NSF), ONR, NGA, DARPA, AFOSR, ARO, and BSF. Pablo Sprechmann is the corresponding author. Alex Bronstein is supported by the ERC StG 335491 (RAPID). The authors would like to thank Dr. Alexey Castrodad for his insightful discussion and for providing the action recognition code and experimental setting.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2010, P INT C MACH LEARN; Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; COHEN JE, 1993, LINEAR ALGEBRA APPL, V190, P149, DOI 10.1016/0024-3795(93)90224-C; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Friedman J, 2010, STATISTICS-ABINGDON; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646, DOI DOI 10.5555/2984093.2984166; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsu CL, 2010, IEEE T AUDIO SPEECH, V18, P310, DOI 10.1109/TASL.2009.2026503; Huang PS, 2012, INT CONF ACOUST SPEE, P57, DOI 10.1109/ICASSP.2012.6287816; Jacob L., 2009, P 26 INT C MACH LEAR, P433, DOI DOI 10.1145/1553374.1553431; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jenatton R, 2011, J MACH LEARN RES, V12, P2297; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kavukcuoglu K., 2010, ARXIV10103467; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Li YY, 2009, INVERSE PROBL IMAG, V3, P487, DOI 10.3934/ipi.2009.3.487; Lijun Zhang, 2011, Frontiers of Electrical and Electronic Engineering in China, V6, P192, DOI 10.1007/s11460-011-0128-0; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Mardani M, 2013, IEEE T SIGNAL PROCES, V61, P5374, DOI 10.1109/TSP.2013.2279080; Mateos G., 2011, ARXIVORG1111788; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Sprechmann P., 2012, P 29 INT C MACH LEAR, P615; Sprechmann P., 2012, 13 INT SOC MUS INF R, P67; Sprechmann P., 2013, ADV NEURAL INF PROCE, V26, P908; Sprechmann P, 2011, INT CONF ACOUST SPEE, P5816; Sprechmann P, 2011, IEEE T SIGNAL PROCES, V59, P4183, DOI 10.1109/TSP.2011.2157912; Srebro N., 2005, P 18 ANN C LEARN THE, P599; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156; Yadong Mu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2609, DOI 10.1109/CVPR.2011.5995369; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhao P, 2009, ANN STAT, V37, P3468, DOI 10.1214/07-AOS584	48	92	93	0	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1821	1833		10.1109/TPAMI.2015.2392779	http://dx.doi.org/10.1109/TPAMI.2015.2392779			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353129	Green Submitted, hybrid			2022-12-18	WOS:000359216600007
J	Hutchinson, B; Deng, L; Yu, D				Hutchinson, Brian; Deng, Li; Yu, Dong			Tensor Deep Stacking Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; stacking networks; tensor; bilinear models; handwriting image classification; phone classification and recognition; MNIST; TIMIT; WSJ		A novel deep architecture, the tensor deep stacking network (T-DSN), is presented. The T-DSN consists of multiple, stacked blocks, where each block contains a bilinear mapping from two hidden layers to the output layer, using a weight tensor to incorporate higher order statistics of the hidden binary ([0, 1]) features. A learning algorithm for the T-DSN's weight matrices and tensors is developed and described in which the main parameter estimation burden is shifted to a convex subproblem with a closed-form solution. Using an efficient and scalable parallel implementation for CPU clusters, we train sets of T-DSNs in three popular tasks in increasing order of the data size: handwritten digit recognition using MNIST (60k), isolated state/phone classification and continuous phone recognition using TIMIT (1.1 m), and isolated phone classification using WSJ0 (5.2 m). Experimental results in all three tasks demonstrate the effectiveness of the T-DSN and the associated learning methods in a consistent manner. In particular, a sufficient depth of the T-DSN, a symmetry in the two hidden layers structure in each T-DSN block, our model parameter learning algorithm, and a softmax layer on top of T-DSN are shown to have all contributed to the low error rates observed in the experiments for all three tasks.	[Hutchinson, Brian] Univ Washington, Dept Elect Engn, Seattle, WA 98105 USA; [Deng, Li; Yu, Dong] Microsoft Res, Redmond, WA 98052 USA	University of Washington; University of Washington Seattle; Microsoft	Hutchinson, B (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98105 USA.	brianhutchinson@ee.washington.edu; deng@microsoft.com; dongyu@microsoft.com	Hutchinson, Brian/AAM-1407-2021	Hutchinson, Brian/0000-0002-5537-008X				[Anonymous], ADV NEUR INF PROC SY; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Ciresan D C, 2011, INT JOINT C ART INT; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L., 2012, P IEEE INT C AC SPEE; Deng L., 2011, P ICML WORKSH LEARN; Deng L., 2011, P ANN C INT SPEECH C; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Dunlavy DM, 2010, SAND20101422 SAND NA; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hutchinson B., 2012, P IEEE INT C AC SPEE; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Le Q., 2012, P INT C MACH LEARN; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Mohamed A., 2009, P NIPS WORKSH DEEP L; Mohamed A., 2010, P ANN C INT SPEECH C; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Paul D. B., 1992, P INT C SPOK LANG PR; Petersen K. B., 2012, MATRIX COOKBOOK; Ranzato M., 2010, P INT C ART INT STAT, V13; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Tur G., 2012, P IEEE INT C AC SPEE; Weisstein E., 2012, SYMMETRIC BILINEAR F; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yu D., 2012, P ANN C INT SPEECH C; Yu D., 2011, P 12 ANN C INT SPEEC; Yu Dong, 2012, P IEEE INT C AC SPEE	29	92	101	1	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1944	1957		10.1109/TPAMI.2012.268	http://dx.doi.org/10.1109/TPAMI.2012.268			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23267198				2022-12-18	WOS:000320381400010
J	Somol, P; Novovicova, J				Somol, Petr; Novovicova, Jana			Evaluating Stability and Comparing Output of Feature Selectors that Optimize Feature Subset Cardinality	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; feature stability; stability measures; similarity measures; sequential search; individual ranking; feature subset-size optimization; high dimensionality; small sample size	ALGORITHMS	Stability (robustness) of feature selection methods is a topic of recent interest, yet often neglected importance, with direct impact on the reliability of machine learning systems. We investigate the problem of evaluating the stability of feature selection processes yielding subsets of varying size. We introduce several novel feature selection stability measures and adjust some existing measures in a unifying framework that offers broad insight into the stability problem. We study in detail the properties of considered measures and demonstrate on various examples what information about the feature selection process can be gained. We also introduce an alternative approach to feature selection evaluation in the form of measures that enable comparing the similarity of two feature selection processes. These measures enable comparing, e. g., the output of two feature selection methods or two runs of one method with different parameters. The information obtained using the considered stability and similarity measures is shown to be usable for assessing feature selection methods (or criteria) as such.	[Somol, Petr; Novovicova, Jana] Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Pattern Recognit, CR-18208 Prague 8, Czech Republic	Czech Academy of Sciences; Institute of Information Theory & Automation of the Czech Academy of Sciences	Somol, P (corresponding author), Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Pattern Recognit, Vodarenskou Vezi 4, CR-18208 Prague 8, Czech Republic.	somol@utia.cas.cz; novovic@utia.cas.cz			CR MSMT [2C06019 ZIMOLEZ, 1M0572 DAR]; GACR [102/08/0593, 102/07/1594]; GAAV CR [AV0Z1075050506]	CR MSMT; GACR(Grant Agency of the Czech Republic); GAAV CR(Grant Agency of the Czech Republic)	This work has been supported by CR MSMT projects 2C06019 ZIMOLEZ and 1M0572 DAR and GACR grants 102/08/0593, 102/07/1594 and GAAV CR grant AV0Z1075050506.	Asuncion A, 2007, UCI MACHINE LEARNING; Bellman RE., 1961, ADAPTIVE CONTROL PRO, DOI [DOI 10.1515/9781400874668, 10.1515/9781400874668]; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116, DOI 10.1109/TSMC.1974.5408535; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 2001, PATTERN CLASSIFICATI; DUNNE K, 2002, TCDCD200228 TRIN COL; Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670; Hussein F, 2001, PROC INT CONF DOC, P1240, DOI 10.1109/ICDAR.2001.953980; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kalousis A, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P218, DOI 10.1109/ICDM.2005.135; Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krizek P, 2007, LECT NOTES COMPUT SC, V4673, P929; KUNCHEVA LI, 2007, P 25 IASTED INT MULT, P421; Loscalzo S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P567; McCallum A., 1998, AAAI 98 WORKSHOP LEA, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426; Novovicova J, 2006, LECT NOTES COMPUT SC, V4225, P578; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raudys S, 2006, LECT NOTES COMPUT SC, V4109, P622; SAEYS Y, 2008, P BEN, P45; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SOMOL P, 2008, P JOINT IAPR INT WOR, P956; SOMOL P, 2008, P 19 INT C PATT REC; Vafaie H., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), P200, DOI 10.1109/TAI.1992.246402; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Yang Yiming, 1997, P 14 INT C MACHINE L, P412, DOI DOI 10.1016/J.ESWA.2008.05.026	27	92	96	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					1921	1939		10.1109/TPAMI.2010.34	http://dx.doi.org/10.1109/TPAMI.2010.34			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847385				2022-12-18	WOS:000281990900001
J	Brox, T; Rosenhahn, B; Gall, J; Cremers, D				Brox, Thomas; Rosenhahn, Bodo; Gall, Juergen; Cremers, Daniel			Combined Region and Motion-Based 3D Tracking of Rigid and Articulated Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tracking; segmentation; motion	PERFORMANCE; FRAMEWORK; PEOPLE; MODELS	In this paper, we propose the combined use of complementary concepts for 3D tracking: region fitting on one side and dense optical flow as well as tracked SIFT features on the other. Both concepts are chosen such that they can compensate for the shortcomings of each other. While tracking by the object region can prevent the accumulation of errors, optical flow and SIFT can handle larger transformations. Whereas segmentation works best in case of homogeneous objects, optical flow computation and SIFT tracking rely on sufficiently structured objects. We show that a sensible combination yields a general tracking system that can be applied in a large variety of scenarios without the need to manually adjust weighting parameters.	[Brox, Thomas] Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA; [Rosenhahn, Bodo] Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany; [Gall, Juergen] Max Planck Inst Informat, Dept Comp Graph 4, D-66123 Saarbrucken, Germany; [Cremers, Daniel] Univ Bonn, Dept Comp Sci, D-53117 Bonn, Germany	University of California System; University of California Berkeley; Leibniz University Hannover; Max Planck Society; University of Bonn	Brox, T (corresponding author), Univ Calif Berkeley, Dept Comp Sci, 547 Soda Hall, Berkeley, CA 94720 USA.	brox@eecs.berkeley.edu; rosenhahn@tnt.uni-hannover.de; jgall@mpi-inf.mpg.de; dcremers@cs.uni-bonn.de			German Research Foundation (DFG); Max-Planck Center for Visual Computing and Communication	German Research Foundation (DFG)(German Research Foundation (DFG)); Max-Planck Center for Visual Computing and Communication	This project was partially funded by the German Research Foundation (DFG) and the Max-Planck Center for Visual Computing and Communication. The authors thank the anonymous reviewers for comments leading to improvements of the manuscript.	BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Brox T, 2007, LECT NOTES COMPUT SC, V4814, P152; Brox T, 2006, J VIS COMMUN IMAGE R, V17, P1053, DOI 10.1016/j.jvcir.2005.06.001; Brox T, 2006, LECT NOTES COMPUT SC, V3952, P98; Bruhn A, 2005, IEEE I CONF COMP VIS, P749; Bruhn A, 2006, COMP IMAG VIS, P283; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; Felzenszwalb P. F., 2004, TR20041963 CORN U CO; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GALL J, 2006, P IEEE PAC RIM S IM, P84; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1980, P ARPA IM UND WORKSH, P121; Marchand E, 2001, IMAGE VISION COMPUT, V19, P941, DOI 10.1016/S0262-8856(01)00054-3; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Memin E., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P920, DOI 10.1109/ICPR.1996.546158; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Murray R. M., 1994, MATH INTRO ROBOTIC M; OZUYSAL M, 2006, P EUR C COMP VIS, P592; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; ROBERTS LG, 1966, OPTICAL ELECTRO OPTI, P159; ROSENHAHN B, 2006, P INT WORKSH COMB IM, P263; Rosenhahn B, 2007, INT J COMPUT VISION, V73, P243, DOI [10.1007/s11263-006-9965-3, 10.1007/S11263-006-9965-3]; Shevlin F, 1998, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1998.711236; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733; SIDENBLADH H, 2002, P EUR C COMP VIS, P784; Sidenbladh H., 2000, LNCS, V2, P702; Sigal L, 2004, PROC CVPR IEEE, P421; SMINCHISESCU C, 2004, P INT C MACH LEARN; Sommer G., 2001, GEOMETRIC COMPUTING; SPENGLER M, 2001, P 9 INT WORKSH COMP, P93; Urtasun R., 2006, 2006 IEEE COMP SOC C, V1, P238, DOI DOI 10.1109/CVPR.2006.15; Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115, DOI 10.1109/TPAMI.2005.3	47	92	97	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					402	415		10.1109/TPAMI.2009.32	http://dx.doi.org/10.1109/TPAMI.2009.32			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075468				2022-12-18	WOS:000273609600002
J	Tong, Y; Chen, JX; Ji, Q				Tong, Yan; Chen, Jixu; Ji, Qiang			A Unified Probabilistic Framework for Spontaneous Facial Action Modeling and Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial action unit recognition; face pose estimation; facial action analysis; facial action coding system; Bayesian networks	EMOTION RECOGNITION; EXPRESSION ANALYSIS; FACE	Facial expression is a natural and powerful means of human communication. Recognizing spontaneous facial actions, however, is very challenging due to subtle facial deformation, frequent head movements, and ambiguous and uncertain facial motion measurements. Because of these challenges, current research in facial expression recognition is limited to posed expressions and often in frontal view. A spontaneous facial expression is characterized by rigid head movements and nonrigid facial muscular movements. More importantly, it is the coherent and consistent spatiotemporal interactions among rigid and nonrigid facial motions that produce a meaningful facial expression. Recognizing this fact, we introduce a unified probabilistic facial action model based on the Dynamic Bayesian network (DBN) to simultaneously and coherently represent rigid and nonrigid facial motions, their spatiotemporal dependencies, and their image measurements. Advanced machine learning methods are introduced to learn the model based on both training data and subjective prior knowledge. Given the model and the measurements of facial motions, facial action recognition is accomplished through probabilistic inference by systematically integrating visual measurements with the facial action model. Experiments show that compared to the state-of-the-art techniques, the proposed system yields significant improvements in recognizing both rigid and nonrigid facial motions, especially for spontaneous facial expressions.	[Tong, Yan] GE Global Res Ctr, Visualizat & Comp Vis Lab, Niskayuna, NY 12308 USA; [Chen, Jixu; Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	General Electric; Rensselaer Polytechnic Institute	Tong, Y (corresponding author), GE Global Res Ctr, Visualizat & Comp Vis Lab, 1 Res Circle,KW C410, Niskayuna, NY 12308 USA.	tongyan@ge.com; chenj4@rpi.edu; jiq@rpi.edu			US Air Force Office of Scientific Research (AFOSR) [F49620-03-1-0160]; US Defense Advanced Research Projects Agency (DARPA)/US Office of Naval Research (ONR) [N00014-03-1-1003]	US Air Force Office of Scientific Research (AFOSR)(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); US Defense Advanced Research Projects Agency (DARPA)/US Office of Naval Research (ONR)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)Office of Naval Research)	Portions of the research in this paper use Cohn and Kanade's DFAT - 504 database, Belfast natural facial expression database, and videos from Multiple Aspects of Discourse research lab at the University of Memphis. The authors gracefully acknowledge their support. This project is supported in part by the US Air Force Office of Scientific Research (AFOSR) Grant F49620-03-1-0160 and the US Defense Advanced Research Projects Agency (DARPA)/US Office of Naval Research (ONR) Grant N00014-03-1-1003.	ANISETTI M, 2006, P IASTED INT C SIGN, P111; [Anonymous], 2006, P 8 INT C MULT INT B, DOI DOI 10.1145/1180995.1181031; [Anonymous], 2007, FACE RECOGNITION, DOI [10.5772/4847, DOI 10.5772/4847]; Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; Bascle B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P323, DOI 10.1109/ICCV.1998.710738; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049; Braathen B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P360, DOI 10.1109/AFGR.2002.1004180; Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293; Cohn JF, 2004, IEEE SYS MAN CYBERN, P610; COHN JF, 2004, INT J WAVELETS MULTI, V2, P1; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; Dean T., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P524; DECAMPOS CP, 2008, P EUR C COMP VIS; Dornaika F, 2005, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2005.225; Douglas-Cowie E., 2003, P 15 INT C PHON SCI; Ekman P., 2009, TELLING LIES CLUES D; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 2005, WHAT FACE REVEALS BA, DOI DOI 10.1093/ACPROF:OSO/9780195179644.001.0001; Ekman P., 2002, FACIAL ACTION CODING; el Kaliouby R, 2005, REAL-TIME VISION FOR HUMAN-COMPUTER INTERACTION, P181; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Ioannou SV, 2005, NEURAL NETWORKS, V18, P423, DOI 10.1016/j.neunet.2005.03.004; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; Kapoor A, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P195; Korb K.B., 2004, COM SCI DAT; Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15; Lucey S., 2007, FACE RECOGNITION BOO; MARKS TK, 2005, ADV NEURAL INFORM PR, V17, P889; MURPHY K, 1990, CSD98990 DEP COMP SC; Murphy K, 2001, COMPUTER SCI STAT, V33, P1024; Nishio S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P206, DOI 10.1109/AFGR.1998.670950; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M., 2007, ARTIFICIAL INTELLIGE; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Russell JA., 1997, PSYCHOL FACIAL EXPRE; Russell S., 2021, ARTIF INTELL, V19, P23; Scherer K., 1982, HDB METHODS NONVERBA; SCHMIDT KL, 2001, P INT C MULT EXP, P728; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sebe N, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P517, DOI 10.1109/AFGR.2004.1301585; TIAN YL, 2004, HDB FACE RECOGNITION; TONG Y, 2008, P IEEE INT C COMP VI; Tong Y, 2007, PATTERN RECOGN, V40, P3195, DOI 10.1016/j.patcog.2007.02.021; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Valstar M.F., 2005, IEEE COMP SOC C COMP, DOI [10.1109/CVPR.2005.457, DOI 10.1109/CVPR.2005.457]; Vasilescu M.A.O., 2002, P EUR C COMP VIS, P447; WANG J, 2006, P IEEE INT C COMP VI, V2, P1399; Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008; Zeng Z., 2006, J MULTIMEDIA, V1, P1, DOI DOI 10.4304/jmm.1.5.1-8; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; ZHU Z, 2006, P IEEE INT C COMP VI, V1, P681; Zhu ZW, 2006, INT C PATT RECOG, P1092	53	92	97	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					258	273		10.1109/TPAMI.2008.293	http://dx.doi.org/10.1109/TPAMI.2008.293			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075457				2022-12-18	WOS:000272741500006
J	Guru, DS; Prakash, HN				Guru, D. S.; Prakash, H. N.			Online Signature Verification and Recognition: An Approach Based on Symbolic Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Symbolic features; interval-valued features; writer-dependent threshold; feature-dependent threshold; acceptance count; online signature verification; online signature recognition	CLASSIFIERS	In this paper, we propose a new method of representing online signatures by interval-valued symbolic features. Global features of online signatures are used to form an interval-valued feature vectors. Methods for signature verification and recognition based on the symbolic representation are also proposed. We exploit the notions of writer-dependent threshold and introduce the concept of feature-dependent threshold to achieve a significant reduction in equal error rate. Several experiments are conducted to demonstrate the ability of the proposed scheme in discriminating the genuine signatures from the forgeries. We investigate the feasibility of the proposed representation scheme for signature verification and also signature recognition using all 16,500 signatures from 330 individuals of the MCYT bimodal biometric database. Further, extensive experimentations are conducted to evaluate the performance of the proposed methods by projecting features onto Eigenspace and Fisherspace. Unlike other existing signature verification methods, the proposed method is simple and efficient. The results of the experimentations reveal that the proposed scheme outperforms several other existing verification methods, including the state-of-the-art method for signature verification.	[Guru, D. S.; Prakash, H. N.] Univ Mysore, Dept Studies Comp Sci, Mysore 570006, Karnataka, India	University of Mysore	Guru, DS (corresponding author), Univ Mysore, Dept Studies Comp Sci, Mysore 570006, Karnataka, India.	dsg@compsci.uni-mysore.ac.in; prakash_hn@yahoo.com		H N, Prakash/0000-0002-9046-4225				Aguilar J. F., 2006, THESIS BIOMETRIC RES; AGUILAR JF, 2005, P INT WORKSH BIOM RE, P188; Bajaj R, 1997, PATTERN RECOGN, V30, P1, DOI 10.1016/S0031-3203(96)00059-3; Billard L, 2006, SYMBOLIC DATA ANAL C, V1st; Bock H.H., 1999, ANAL SYMBOLIC DATA; Bovino L, 2003, PROC INT CONF DOC, P932; Chang C, 2004, FILM COMMENT, V40, P16; COETZER J, 2004, J APPL SIGNAL PROCES, V4, P559; Dimauro G., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P771, DOI 10.1142/S0218001494000401; Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5; Duda R. O., 2003, PATTERN CLASSIFICATI; Fang B, 2003, PATTERN RECOGN, V36, P91, DOI 10.1016/S0031-3203(02)00061-4; Fang P, 2005, LECT NOTES COMPUT SC, V3644, P631; Faundez-Zanuy M, 2007, PATTERN RECOGN, V40, P981, DOI 10.1016/j.patcog.2006.06.007; Feng H, 2003, PATTERN RECOGN LETT, V24, P2943, DOI 10.1016/S0167-8655(03)00155-7; GOWDA KC, 1991, PATTERN RECOGN, V24, P567, DOI 10.1016/0031-3203(91)90022-W; Guru DS, 2007, PATTERN RECOGN LETT, V28, P144, DOI 10.1016/j.patrec.2006.06.017; GURU DS, 2007, P INT C COMP INT MUL, V2, P312; GURU DS, 2000, PATTERN RECOGN, V15, P769; HAUNG K, 1997, PATTERN RECOGN, V30, P9; Huang K, 2002, PATTERN RECOGN, V35, P2467, DOI 10.1016/S0031-3203(01)00222-9; Jain AK, 2002, PATTERN RECOGN, V35, P2963, DOI 10.1016/S0031-3203(01)00240-0; Justino EJR, 2005, PATTERN RECOGN LETT, V26, P1377, DOI 10.1016/j.patrec.2004.11.015; Kashi R., 1998, International Journal on Document Analysis and Recognition, V1, P102, DOI 10.1007/s100320050010; Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017; Lee LL, 1996, IEEE T PATTERN ANAL, V18, P643, DOI 10.1109/34.506415; Letjman D., 2001, P 6  INT C DOC AN RE, P596; MOON T.K., 2000, MATH METHODS ALGORIT; MURAMATSU D, 2003, P INT C AUD VID BAS, P233; NALWA VS, 1997, P 3 AS C COMP VIS, V1, P10; Nanni L, 2006, NEUROCOMPUTING, V69, P854, DOI 10.1016/j.neucom.2005.08.007; Nanni L, 2006, NEUROCOMPUTING, V69, P869, DOI 10.1016/j.neucom.2005.06.007; Nanni L, 2005, NEUROCOMPUTING, V68, P217, DOI 10.1016/j.neucom.2005.05.004; Nelson W., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P749, DOI 10.1142/S0218001494000395; NELSON W, 1991, P IEEE INT C SYST MA, V1, P201; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; PARIZEAU M, 1990, IEEE T PATTERN ANAL, V12, P710, DOI 10.1109/34.56215; Sabourin R, 1997, IEEE T PATTERN ANAL, V19, P976, DOI 10.1109/34.615447; Wirtz B., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P179, DOI 10.1109/ICDAR.1995.598971; Wu QZ, 1997, PATTERN RECOGN LETT, V18, P665, DOI 10.1016/S0167-8655(97)00046-9; Wu QZ, 1998, PATTERN RECOGN, V31, P1865, DOI 10.1016/S0031-3203(98)00058-2	41	92	94	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1059	1073		10.1109/TPAMI.2008.302	http://dx.doi.org/10.1109/TPAMI.2008.302			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372610				2022-12-18	WOS:000265100000008
J	Xie, XH; Mirmehdi, M				Xie, Xianghua; Mirmehdi, Majid			TEXEMS: Texture exemplars for defect detection on random textured surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						defect detection; texture analysis; texem model; mixture model; EM algorithm	COLOR; CLASSIFICATION; INSPECTION; FEATURES	We present an approach to detecting and localizing defects in random color textures which requires only a few defect free samples for unsupervised training. It is assumed that each image is generated by a superposition of various-size image patches with added variations at each pixel position. These image patches and their corresponding variances are referred to here as textural exemplars or texems. Mixture models are applied to obtain the texems using multiscale analysis to reduce the computational costs. Novelty detection on color texture surfaces is performed by examining the same-source similarity based on the data likelihood in multiscale, followed by logical processes to combine the defect candidates to localize defects. The proposed method is compared against a Gabor filter bank-based novelty detection method. Also, we compare different texem generalization schemes for defect detection in terms of accuracy and efficiency.	Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England	University of Bristol	Xie, XH (corresponding author), Univ Bristol, Dept Comp Sci, MVB 2-08,Woodland Rd, Bristol BS8 1UB, Avon, England.	xie@cs.bris.ac.uk; majid@cs.bris.ac.uk		Xie, Xianghua/0000-0002-2701-8660; Mirmehdi, Majid/0000-0002-6478-1403				Boukouvalas C, 1997, IEEE T IND ELECTRON, V44, P132, DOI 10.1109/41.557508; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670; Escofet J, 1998, OPT ENG, V37, P2297, DOI 10.1117/1.601751; Jain A, 1998, IEEE T IMAGE PROCESS, V7, P124, DOI 10.1109/83.650858; Jojic N, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P34; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; KITTLER J, 1994, IAPR P MACH VIS APPL, P558; Kumar A, 2003, PATTERN RECOGN, V36, P1645, DOI 10.1016/S0031-3203(03)00005-0; Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; LUMBRERAS F, 2001, QUALITY CONTROL ARTI, V1, P114; Maenpaa T, 2003, PATTERN ANAL APPL, V6, P169, DOI 10.1007/s10044-002-0179-1; *MIT MEDIALAB, 1995, VISTEX TEXT DAT; Monadjemi A., 2004, P 15 BRIT MACH VIS C, P637; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Silven I, 2003, MACH VISION APPL, V13, P275, DOI 10.1007/s00138-002-0084-z; Silverman B.W, 1986, DENSITY ESTIMATION; Song KY, 1996, IMAGE VISION COMPUT, V14, P667, DOI 10.1016/0262-8856(96)84491-X; Tsai DM, 2005, IMAGING SCI J, V53, P27, DOI 10.1179/136821905X26935; Varma M, 2003, PROC CVPR IEEE, P691; XIE X, 2005, P IEEE INT C IM PROC, V3, P1124; Xie XH, 2005, LECT NOTES COMPUT SC, V3687, P404; Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1	24	92	98	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1454	1464		10.1109/TPAMI.2007.1038	http://dx.doi.org/10.1109/TPAMI.2007.1038			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568147				2022-12-18	WOS:000247186500012
J	Zhang, H; Wong, KYK; Zhang, GQ				Zhang, Hui; Wong, Kwan-Yee K.; Zhang, Guoqiang			Camera calibration from images of spheres	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						calibration; sphere; silhouette; surface of revolution (SOR)		This paper introduces a novel approach for solving the problem of camera calibration from spheres. By exploiting the relationship between the dual images of spheres and the dual image of the absolute conic (IAC), it is shown that the common pole and polar with regard to the conic images of two spheres are also the pole and polar with regard to the IAC. This provides two constraints for estimating the IAC and, hence, allows a camera to be calibrated from an image of at least three spheres. Experimental results show the feasibility of the proposed approach.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	University of Hong Kong	Zhang, H (corresponding author), Univ Hong Kong, Dept Comp Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.		; Wong, Kenneth Kwan Yee/C-1577-2009	ZHANG, Hui/0000-0002-1681-7926; Wong, Kenneth Kwan Yee/0000-0001-8560-9007				Agrawal M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P782; BEARDSLEY P, 1992, LECT NOTES COMPUT SC, V588, P312; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; DAUCHER D, 1994, P 3 ECCV, P449; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Gentle J. E., 1998, STATIST COMP, P87; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; PENNA MA, 1991, IEEE T PATTERN ANAL, V13, P1240, DOI 10.1109/34.107007; Teramoto H., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P499; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Wong KYK, 2003, IEEE T PATTERN ANAL, V25, P147, DOI 10.1109/TPAMI.2003.1177148; Ying XH, 2004, IEEE T PATTERN ANAL, V26, P1260, DOI 10.1109/TPAMI.2004.79; ZHANG H, 2005, P INT C IM PROC, V2, P1150; Zhang ZY, 2004, IEEE T PATTERN ANAL, V26, P892, DOI 10.1109/TPAMI.2004.21; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	17	92	102	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					499	U1		10.1109/TPAMI.2007.45	http://dx.doi.org/10.1109/TPAMI.2007.45			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224619	Green Submitted			2022-12-18	WOS:000243420500011
J	van de Weijer, J; Gevers, T; Geusebroek, JM				van de Weijer, J; Gevers, T; Geusebroek, JM			Edge and corner detection by photometric quasi-invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge and feature detection; invariants; color	COLOR	Feature detection is used in many computer vision applications such as image segmentation, object recognition, and image retrieval. For these applications, robustness with respect to shadows, shading, and specularities is desired. Features based on derivatives of photometric invariants, which we will call full invariants, provide the desired robustness. However, because computation of photometric invariants involves nonlinear transformations, these features are unstable and, therefore, impractical for many applications. We propose a new class of derivatives which we refer to as quasi-invariants. These quasi-invariants are derivatives which share with full photometric invariants the property that they are insensitive for certain photometric edges, such as shadows or specular edges, but without the inherent instabilities of full photometric invariants. Experiments show that the quasi-invariant derivatives are less sensitive to noise and introduce less edge displacement than full invariant derivatives. Moreover, quasi-invariants significantly outperform the full invariant derivatives in terms of discriminative power.	Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	van de Weijer, J (corresponding author), Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	joostw@science.uva.nl; gevers@science.uva.nl	van de Weijer, Joost/A-1643-2009	van de Weijer, Joost/0000-0002-9656-9706				CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2003, IEEE T MULTIMEDIA, V5, P237, DOI 10.1109/TMM.2003.811620; Haralick RM, 1992, COMPUTER ROBOT VISIO, V2; Harris C., 1988, P ALVEY VISION C, V15, P147, DOI DOI 10.5244/C.2.23; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Maxwell BA, 1997, COMPUT VIS IMAGE UND, V65, P269, DOI 10.1006/cviu.1997.0573; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; van de Weijer J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1520	14	92	95	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					625	630		10.1109/TPAMI.2005.75	http://dx.doi.org/10.1109/TPAMI.2005.75			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794166	Green Submitted			2022-12-18	WOS:000226845700012
J	Agam, G; Dinstein, I				Agam, G; Dinstein, I			Geometric separation of partially overlapping nonrigid objects applied to automatic chromosome classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; image segmentation; computational geometry; shape decomposition; biology computing; chromosome analysis	DIGITAL CURVES; SHAPE; ALGORITHMS	A common task in cytogenetic tests is the classification of human chromosomes. Successful separation between touching and overlapping chromosomes in a metaphase image is vital for correct classification. Current systems for automatic chromosome classification are mostly interactive and require human intervention for correct separation between touching and overlapping chromosomes. Since chromosomes are nonrigid objects, special separation methods are required to segregate them. Common methods for separation between touching chromosomes tend to fail where ambiguity or incomplete information are involved, and so are unable to segregate overlapping chromosomes. The proposed approach treats the separation problem as an identification problem, and, in this way, manages to segregate overlapping chromosomes. This approach encompasses low-level knowledge about the objects and uses only extracted information, therefore, it is fast and does not depend on the existence of a separating path. The method described in this paper can be adopted for other applications, where separation between touching and overlapping nonrigid objects is required.			Agam, G (corresponding author), BEN GURION UNIV NEGEV, DEPT ELECT & COMP ENGN, IL-84105 BEER SHEVA, ISRAEL.							AGAM G, 1993, P SOC PHOTO-OPT INS, V2060, P277, DOI 10.1117/12.165005; AGAM G, 1993, P IAICVNN 93, P379; CAROTHERS A, 1994, STAT COMPUT, V4, P161, DOI 10.1007/BF00142568; CHASSERY JM, 1984, IEEE T PATTERN ANAL, V6, P794, DOI 10.1109/TPAMI.1984.4767603; COOPER DH, 1989, IMAGE VISION COMPUT, V7, P50, DOI 10.1016/0262-8856(89)90020-6; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; Gaybay C, 1986, IEEE T PATTERN ANAL, V8, P140; HARWOOD D, 1987, PATTERN RECOGN LETT, V6, P155, DOI 10.1016/0167-8655(87)90002-X; JI LA, 1989, PATTERN RECOGN, V22, P519, DOI 10.1016/0031-3203(89)90021-6; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; LESTER JM, 1978, COMPUT BIOL MED, V8, P293, DOI 10.1016/0010-4825(78)90030-6; MACLANE S, 1979, ALGEBRA; NICKOLLS P, 1981, PATTERN RECOGN, V14, P219, DOI 10.1016/0031-3203(81)90066-2; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PIKAZ A, 1994, IEEE T PATTERN ANAL, V16, P808, DOI 10.1109/34.308476; PIKAZ A, 1995, PATTERN RECOGN, V28, P373, DOI 10.1016/0031-3203(94)00108-X; PIPER J, 1980, SIGNAL PROCESS, V2, P203, DOI 10.1016/0165-1684(80)90019-5; ROSENFELD A, 1982, DIGITAL PICTURE PROC, P257; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; VANDERHEYDT L, 1981, PATTERN RECOGN, V13, P147, DOI 10.1016/0031-3203(81)90012-1; WOLFSON HJ, 1992, ARTIF INT, P335	21	92	94	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1212	1222		10.1109/34.632981	http://dx.doi.org/10.1109/34.632981			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500003
J	MOHAN, R; NEVATIA, R				MOHAN, R; NEVATIA, R			PERCEPTUAL ORGANIZATION FOR SCENE SEGMENTATION AND DESCRIPTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONSTRAINT SATISFACTION NETWORKS; PERCEPTUAL ORGANIZATION; SEGMENTATION; SYMMETRY	CURVED OBJECTS; SHAPE; OPTIMIZATION; COMPUTATION; MODEL	A novel data-driven system for segmenting scenes into objects and their components is presented. This segmentation system generates hierarchies of features that correspond to structural elements such as boundaries and surfaces of objects. The technique is based on perceptual organization. In humans, perceptual organization is the ability to readily group elements in an image based on various realtionships between them. Here, perceptual organization is implemented as a mechanism to exploit geometrical regularities in the shapes of objects as projected onto images. Edges are recursively grouped on geometrical relationships into a description hierarchy ranging from edges to the visible surfaces of objects. These edge groupings, which are termed collated features, are abstract descriptors encoding structural information. The geometrical relationships employed are quasiinvariant over 2-D projections and are common to structures of most objects. Thus, collations have a high likelihood of corresponding to parts of objects. Collations serve as intermediate and high-level features for various visual processes. Applications of collations to stereo correspondence, object level semgentation, and shape description are illustrated.	UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089	University of Southern California	MOHAN, R (corresponding author), IBM CORP,THOMAS J WATSON RES CTR,EXPLORATORY COMP VIS GRP,YORKTOWN HTS,NY 10598, USA.							AGIN GJ, 1976, IEEE T COMPUT, V25; [Anonymous], 1985, PERCEPTUAL ORG VISUA; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BALLARD DH, 1983, NATURE, V306, P21, DOI 10.1038/306021a0; BINFORD TO, 1971, DEC P IEEE C SYST CO; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; BOLLE RM, 1989, JUN P IEEE C COMP VI; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BRADY M, 1983, HUMAN MACHINE VISION, P39; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BROOKS RA, 1979, APR P DARPA IM UND W, P72; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CONNELL JH, 1985, AIM823 MIT TECH REP; DOLAN J, 1989, P IMAGE UNDERSTANDIN, P1135; FAHLMAN SE, 1983, P NAT C AI MENLO PAR; FAHLMAN SE, 1987, IEEE COMPUT      JAN, P100; FAN TJ, 1988, IRIS237 U SO CAL I R; FELDMAN J, 1982, COGNITIVE SCI    JUL, P205; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; GARNER WR, 1963, J VERB LEARN VERB BE, V2, P446, DOI 10.1016/S0022-5371(63)80046-8; GARNER WR, 1974, PROCESSING INFORMATI; GAZIT SL, 1989, MAY P DARPA IM UND W; GRIMSON WEL, 1990, 1ST P EUR C COMP VIS, P552; HOCHBERG J, 1953, J EXP PSYCHOL, V46, P361, DOI 10.1037/h0055809; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; JACOBS DJ, 1987, DEC P IEEE COMP SOC; JULESZ B, 1981, PERCEPTUAL ORG, P27; KANADE T, 1979, CMUCS79153 CARN MELL; Kanade T., 1983, HUMAN MACHINE VISION, P237; Kanisza G, 1979, ORG VISION; Katz D., 1950, GESTALT PSYCHOL ITS; KELLY RE, 1977, J PHOTOGRAMMETRIC EN; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LAWS KI, 1980, THESIS U SO CALIF; LEEWENBERG ELJ, 1971, AM J PSYCHOL, V84, P307; LIM HS, 1987, FEB P DARPA IM UND W, P234; LOWE DG, 1983, P AAAI83; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Marr D., 1982, VISION; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MOHAN R, 1989, JUN P IEEE C COMP VI; MOHAN R, 1989, P INT JOINT C NEURAL; MOHAN R, 1989, IEEE T PATT ANAL MAC, V11; NACKMAN LR, 1985, IEEE T PATTERN ANAL, V7, P187, DOI 10.1109/TPAMI.1985.4767643; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NEVATIA R, 1976, COMPUTER ANAL SCENES; NEVATIA R, 1990, SEP P DARPA IMAGE UN; PALMER SE, 1983, HUMAN MACHINE VISION, P269; PONCE J, 1987, FEB P DARPA IM UND W; QUAN L, 1988, DEC P INT C COMP VIS; RAO K, 1988, IRIS250 U SO CAL I R; REYNOLDS G, 1987, FEB P DARPA IM UND W; ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SAINTMARC P, 1988, APR P DARPA IM UND W; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; STEVENS KA, 1987, COMPUT VISION GRAPH, V37, P238, DOI 10.1016/S0734-189X(87)80004-X; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TRIESMAN A, 1982, J EXP PSYCHOL HUMAN, V8, P194; TUCERYAN M, 1983, JUN P COMP VIS PATT, P47; ULUPINAR F, 1988, DEC P INT C COMP VIS; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; Wertheimer M., 1958, READINGS PERCEPTION, P115; WITKIN A, 1983, 7TH P INT JOINT C AR; ZUCKER SW, 1983, HUMAN MACHINE VISION, P545; ZUCKER SW, 1987, VISION BRAIN COOPERA, P231; 1981, PERCEPTUAL ORG	72	92	97	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					616	635		10.1109/34.141553	http://dx.doi.org/10.1109/34.141553			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600003
J	LOBREGT, S; VERBEEK, PW; GROEN, FCA				LOBREGT, S; VERBEEK, PW; GROEN, FCA			3-DIMENSIONAL SKELETONIZATION - PRINCIPLE AND ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											LOBREGT, S (corresponding author), DELFT UNIV TECHNOL,DEPT APPL PHYS,PATTERN RECOGNIT GRP,DELFT,NETHERLANDS.							GERRITSEN FA, 1977, P SEMINAR PATTERN RE; HERSANT T, 1977, NEWSLETTER STEREOLOG, P81; HERSANT T, 1976, NEWSLETTER 76 STEREO, P17; HILBERT D, 1932, ANSCHAULICHE GEOMETR, P254; Hilditch C.J., 1969, MACH INTELL, P403; ROSENFELD A, 1976, DIGITAL PICTURE PROC, P335	6	92	97	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					75	77		10.1109/TPAMI.1980.4766974	http://dx.doi.org/10.1109/TPAMI.1980.4766974			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD568	22499627				2022-12-18	WOS:A1980JD56800012
J	Huang, Y; Wang, W; Wang, L				Huang, Yan; Wang, Wei; Wang, Liang			Video Super-Resolution via Bidirectional Recurrent Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; recurrent neural networks; 3D convolution; video super-resolution	LEARNING ALGORITHM; RESOLUTION	Super resolving a low-resolution video, namely video super-resolution (SR), is usually handled by either single-image SR or multi-frame SR. Single-Image SR deals with each video frame independently, and ignores intrinsic temporal dependency of video frames which actually plays a very important role in video SR. Multi-Frame SR generally extracts motion information, e.g., optical flow, to model the temporal dependency, but often shows high computational cost. Considering that recurrent neural networks (RNNs) can model long-term temporal dependency of video sequences well, we propose a fully convolutional RNN named bidirectional recurrent convolutional network for efficient multi-frame SR. Different from vanilla RNNs, 1) the commonly-used full feedforward and recurrent connections are replaced with weight-sharing convolutional connections. So they can greatly reduce the large number of network parameters and well model the temporal dependency in a finer level, i.e., patch-based rather than frame-based, and 2) connections from input layers at previous timesteps to the current hidden layer are added by 3D feedforward convolutions, which aim to capture discriminate spatio-temporal patterns for short-term fast-varying motions in local adjacent frames. Due to the cheap convolutional operations, our model has a low computational complexity and runs orders of magnitude faster than other multi-frame SR methods. With the powerful temporal dependency modeling, our model can super resolve videos with complex motions and achieve well performance.	[Huang, Yan; Wang, Wei; Wang, Liang] Chinese Acad Sci CASIA, Inst Automat, NLPR, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100049, Peoples R China; [Huang, Yan; Wang, Wei; Wang, Liang] UCAS, Beijing 100049, Peoples R China; [Wang, Liang] Chinese Acad Sci CASIA, Inst Automat, CEBSIT, Beijing 100864, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS	Huang, Y (corresponding author), Chinese Acad Sci CASIA, Inst Automat, NLPR, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100049, Peoples R China.; Huang, Y (corresponding author), UCAS, Beijing 100049, Peoples R China.	yhuang@nlpr.ia.ac.cn; wangwei@nlpr.ia.ac.cn; wangliang@nlpr.ia.ac.cn	Huang, Yan/HCH-6526-2022		National Natural Science Foundation of China [61572504, 61525306, 61420106015, 61633021]; Strategic Priority Research Program of the CAS [XDB02070100]; National Key Research and Development Program of China [2016YFB1001000]; Beijing Natural Science Foundation [4162058]; NVIDIA DGX-1 AI Supercomputer; NVIDIA	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of the CAS; National Key Research and Development Program of China; Beijing Natural Science Foundation(Beijing Natural Science Foundation); NVIDIA DGX-1 AI Supercomputer; NVIDIA	This work is jointly supported by National Key Research and Development Program of China (2016YFB1001000), National Natural Science Foundation of China (61525306, 61633021, 61572504, 61420106015), Strategic Priority Research Program of the CAS (XDB02070100), and Beijing Natural Science Foundation (4162058). This work is also supported by grants from NVIDIA and the NVIDIA DGX-1 AI Supercomputer.	[Anonymous], 2013, COMPUT SCI; Baker S., 1999, SUPER RESOLUTION OPT, P99; Bascle B., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P573; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Fransens R, 2007, COMPUT VIS IMAGE UND, V106, P106, DOI 10.1016/j.cviu.2005.09.011; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212; Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang Jia-Bin, 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7299156; Huang Y., 2015, P ADV NEURAL INFORM, V28, P235; Huang Y., 2016, ABS161105588 CORR; Huang Y, 2015, IEEE I CONF COMP VIS, P4265, DOI 10.1109/ICCV.2015.485; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Jain V., 2008, P ADV NEUR INF PROC, V21, P1, DOI DOI 10.5555/2981780.2981876; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68; Ma ZY, 2015, PROC CVPR IEEE, P5224, DOI 10.1109/CVPR.2015.7299159; Mitzel D, 2009, LECT NOTES COMPUT SC, V5748, P432, DOI 10.1007/978-3-642-03798-6_44; Nair V, 2010, P 27 INT C MACHINE L, P807; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067; Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Shahar O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3353, DOI 10.1109/CVPR.2011.5995360; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409106; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Sutskever Ilya, 2007, AISTATS; Taylor G., 2006, P ADV NEUR INF PROC, P448; Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241; Tsai, 1984, ADV COMPUTER VISION, V1, P317; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Xingjian S., 2015, ADV NEURAL INFORM PR, P802, DOI DOI 10.1007/978-3-319-21233-3_6; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47	51	91	103	2	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					1015	1028		10.1109/TPAMI.2017.2701380	http://dx.doi.org/10.1109/TPAMI.2017.2701380			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28489532				2022-12-18	WOS:000426687100018
J	Harandi, M; Salzmann, M; Hartley, R				Harandi, Mehrtash; Salzmann, Mathieu; Hartley, Richard			Dimensionality Reduction on SPD Manifolds: The Emergence of Geometry-Aware Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Riemannian manifolds; Riemannian geometry; symmetric positive definite matrices; Grassmann manifolds; dimensionality reduction; visual recognition	PRINCIPAL GEODESIC ANALYSIS; RIEMANNIAN-MANIFOLDS; REGION COVARIANCE; SHAPE; CLASSIFICATION; STATISTICS; EFFICIENT; OPTIMIZATION; EXTRACTION; FRAMEWORK	Representing images and videos with Symmetric Positive Definite (SPD) matrices, and considering the Riemannian geometry of the resulting space, has been shown to yield high discriminative power in many visual recognition tasks. Unfortunately, computation on the Riemannian manifold of SPD matrices - especially of high-dimensional ones-comes at a high cost that limits the applicability of existing techniques. In this paper, we introduce algorithms able to handle high-dimensional SPD matrices by constructing a lower-dimensional SPD manifold. To this end, we propose to model the mapping from the high-dimensional SPD manifold to the low-dimensional one with an orthonormal projection. This lets us formulate dimensionality reduction as the problem of finding a projection that yields a low-dimensional manifold either with maximum discriminative power in the supervised scenario, or with maximum variance of the data in the unsupervised one. We show that learning can be expressed as an optimization problem on a Grassmann manifold and discuss fast solutions for special cases. Our evaluation on several classification tasks evidences that our approach leads to a significant accuracy gain over state-of-the-art methods.	[Harandi, Mehrtash; Hartley, Richard] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 2601, Australia; [Harandi, Mehrtash; Hartley, Richard] CSIRO, Data61, Canberra Res Lab, Canberra, ACT 2601, Australia; [Salzmann, Mathieu] Ecole Polytech Fed Lausanne, CVLab, CH-1015 Lausanne, Switzerland	Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Harandi, M (corresponding author), Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 2601, Australia.; Harandi, M (corresponding author), CSIRO, Data61, Canberra Res Lab, Canberra, ACT 2601, Australia.	mehrtash.harandi@data61.csiro.au; mathieu.salzmann@epfl.ch; richard.hartley@anu.edu.au	Harandi, Mehrtash/D-6586-2018	Harandi, Mehrtash/0000-0002-6937-6300; Salzmann, Mathieu/0000-0002-8347-8637				Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; Atkinson C., 1981, SANKHYA A, V43, P345; Bhatia R, 2007, PRINC SER APPL MATH, P1; Boumal N, 2014, J MACH LEARN RES, V15, P1455; Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198; Carreira J, 2015, IEEE T PATTERN ANAL, V37, P1177, DOI 10.1109/TPAMI.2014.2361137; Cheng SH, 2001, SIAM J MATRIX ANAL A, V22, P1112, DOI 10.1137/S0895479899364015; Cherian A, 2013, IEEE T PATTERN ANAL, V35, P2161, DOI 10.1109/TPAMI.2012.259; Cunningham JP, 2015, J MACH LEARN RES, V16, P2859; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Feragen A, 2015, PROC CVPR IEEE, P3032, DOI 10.1109/CVPR.2015.7298922; Fletcher PT, 2003, PROC CVPR IEEE, P95; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Goh A, 2008, 2008 IEEE C COMP VIS, P1; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622; Harandi M, 2015, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR.2015.7299018; Harandi MT, 2016, IEEE T NEUR NET LEAR, V27, P1294, DOI 10.1109/TNNLS.2014.2387383; Harandi MT, 2014, LECT NOTES COMPUT SC, V8690, P17, DOI 10.1007/978-3-319-10605-2_2; Horev I., 2015, P 4 AS C MACH LEARN, P1; Huang Z., 2017, P ASS ADV ART INT; Huang ZW, 2015, PR MACH LEARN RES, V37, P720; Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609; Huckemann S, 2010, STAT SINICA, V20, P1; Hussein Mohamed E, 2013, 23 INT JOINT C ART I; Ionescu C, 2015, IEEE I CONF COMP VIS, P2965, DOI 10.1109/ICCV.2015.339; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Kokiopoulou E, 2011, NUMER LINEAR ALGEBR, V18, P565, DOI 10.1002/nla.743; Kulis B, 2009, J MACH LEARN RES, V10, P341; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202; Liao ZC, 2013, PROC CVPR IEEE, P963, DOI 10.1109/CVPR.2013.129; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Lovasz L, 2009, MATCHING THEORY, V367; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48; Moreno PJ, 2004, ADV NEUR IN, V16, P1385; Muller M., 2007, TECHNICAL REPORT; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Petersen K.B., 2012, MATRIX COOKBOOK; Said S., 2007, P 15 EUR SIGN PROC C, P1700; Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006; Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667; Sivalingam R, 2014, IEEE T PATTERN ANAL, V36, P592, DOI 10.1109/TPAMI.2013.143; Sommer Stefan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P157, DOI 10.1109/CVPR.2009.5204053; Sommer S, 2010, LECT NOTES COMPUT SC, V6316, P43, DOI 10.1007/978-3-642-15567-3_4; Sra S., 2012, ADV NEURAL INFORM PR, P144; Strehl A., 2000, WORKSHOP ARTIFICIAL, P58; Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Wang H., 2011, P PUBLICATION KDD 11, P956, DOI [10.1145/2020408.2020565, DOI 10.1145/2020408.2020565]; Wang QL, 2016, PROC CVPR IEEE, P4433, DOI 10.1109/CVPR.2016.480; Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965; Wang ZZ, 2004, PROC CVPR IEEE, P228; Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Yger F., 2015, CORR	67	91	100	1	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					48	62		10.1109/TPAMI.2017.2655048	http://dx.doi.org/10.1109/TPAMI.2017.2655048			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28103548	Green Submitted			2022-12-18	WOS:000417806000005
J	Wu, ZY; Li, Y; Radke, RJ				Wu, Ziyan; Li, Yang; Radke, Richard J.			Viewpoint Invariant Human Re-Identification in Camera Networks Using Pose Priors and Subject-Discriminative Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human re-identification; viewpoint invariance; camera networks	PEDESTRIAN RECOGNITION; TRACKING; PEOPLE; VIDEO	Human re-identification across cameras with non-overlapping fields of view is one of the most important and difficult problems in video surveillance and analysis. However, current algorithms are likely to fail in real-world scenarios for several reasons. For example, surveillance cameras are typically mounted high above the ground plane, causing serious perspective changes. Also, most algorithms approach matching across images using the same descriptors, regardless of camera viewpoint or human pose. Here, we introduce a re-identification algorithm that addresses both problems. We build a model for human appearance as a function of pose, using training data gathered from a calibrated camera. We then apply this "pose prior" in online re-identification to make matching and identification more robust to viewpoint. We further integrate person-specific features learned over the course of tracking to improve the algorithm's performance. We evaluate the performance of the proposed algorithm and compare it to several state-of-the-art algorithms, demonstrating superior performance on standard benchmarking datasets as well as a challenging new airport surveillance scenario.	[Wu, Ziyan; Li, Yang; Radke, Richard J.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Wu, ZY (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	ziyan@alum.rpi.edu; liy21@rpi.edu; rjradke@ecse.rpi.edu	Radke, Richard/I-3289-2013	Radke, Richard/0000-0001-5064-7775	U.S. Department of Homeland Security [2013-ST-061-ED0001]	U.S. Department of Homeland Security(United States Department of Homeland Security (DHS))	This material was based upon work supported by the U.S. Department of Homeland Security under Award Number 2013-ST-061-ED0001. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied of the U.S. Department of Homeland Security. Thanks to Edward Hertelendy and Michael Young for supplying the data in Section 6.4. Thanks to Fei Xiong for the PCCA implementation used in this paper.	Alahi A, 2010, COMPUT VIS IMAGE UND, V114, P624, DOI 10.1016/j.cviu.2010.01.004; Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68; Bak S, 2012, LECT NOTES COMPUT SC, V7574, P806, DOI 10.1007/978-3-642-33712-3_58; Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008; Baltieri D., 2011, P 2011 JOINT ACMWORK, P59, DOI DOI 10.1145/2072572.2072590; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016; Bialkowski A., 2012, DICTA; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005; Conte D., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P297, DOI 10.1109/AVSS.2011.6027340; D'Angelo A, 2011, PROC SPIE, V7882, DOI 10.1117/12.876453; Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40; Eisenbach M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P184, DOI 10.1109/AVSS.2012.81; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9; Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003; Joachims T, 2006, PROC 22 ACM SIGKDD I, P217, DOI DOI 10.1145/1150402.1150429; Kai Jungling, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P197, DOI 10.1109/AVSS.2011.6027319; Li Y, 2008, INT C PATT RECOG, P2014; Lian GY, 2011, PATTERN RECOGN, V44, P1121, DOI 10.1016/j.patcog.2010.11.011; Lin Z, 2008, LECT NOTES COMPUT SC, V5358, P23, DOI 10.1007/978-3-540-89639-5_3; Liu C., 2012, ECCV LECT NOTES COMP, V7583, P391; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178; Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41; Ma Bingpeng, 2012, P BRIT MACH VIS C, P1; Mazzon R, 2012, PATTERN RECOGN LETT, V33, P1828, DOI 10.1016/j.patrec.2012.02.014; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; Tapaswi M, 2012, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2012.6247986; Teixeira LF, 2009, PATTERN RECOGN LETT, V30, P157, DOI 10.1016/j.patrec.2008.04.001; UK Home Office, I LIDS MULT CAM TRAC; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng WS, 2012, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2012.6247985; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23	50	91	100	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1095	1108		10.1109/TPAMI.2014.2360373	http://dx.doi.org/10.1109/TPAMI.2014.2360373			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353331				2022-12-18	WOS:000352533000015
J	Orbanz, P; Roy, DM				Orbanz, Peter; Roy, Daniel M.			Bayesian Models of Graphs, Arrays and Other Exchangeable Random Structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Exchangeable arrays; Bayesian nonparametrics; relational data; networks; graphs	CONSTRUCTION; BLOCKMODELS; INVARIANTS; GENERALIZE; THEOREM	The natural habitat of most Bayesian methods is data represented by exchangeable sequences of observations, for which de Finetti's theorem provides the theoretical foundation. Dirichlet process clustering, Gaussian process regression, and many other parametric and nonparametric Bayesian models fall within the remit of this framework; many problems arising in modern data analysis do not. This article provides an introduction to Bayesian models of graphs, matrices, and other data that can be modeled by random structures. We describe results in probability theory that generalize de Finetti's theorem to such data and discuss their relevance to nonparametric Bayesian modeling. With the basic ideas in place, we survey example models available in the literature; applications of such models include collaborative filtering, link prediction, and graph and network analysis. We also highlight connections to recent developments in graph theory and probability, and sketch the more general mathematical foundation of Bayesian methods for other types of data beyond sequences and arrays.	[Orbanz, Peter] Columbia Univ, Dept Stat, New York, NY 10027 USA; [Roy, Daniel M.] Univ Cambridge, Dept Engn, Cambridge CB2 3AP, England	Columbia University; University of Cambridge	Orbanz, P (corresponding author), Columbia Univ, Dept Stat, New York, NY 10027 USA.	porbanz@stat.columbia.edu; d.roy@eng.cam.ac.uk			EPSRC [EP/I026827/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Aldous D., 2010, PROBABILITY MATH GEN, V378, P35; Aldous D.J., 1985, LECT NOTES MATH, V1117, P1, DOI DOI 10.1007/BFB0099421; Aldous D, 2007, ELECTRON J PROBAB, V12, P1454, DOI 10.1214/EJP.v12-463; Aldous DJ, 2010, PROCEEDINGS OF THE INTERNATIONAL CONGRESS OF MATHEMATICIANS, VOL I: PLENARY LECTURES AND CEREMONIES, P141; ALDOUS DJ, 1981, J MULTIVARIATE ANAL, V11, P581, DOI 10.1016/0047-259X(81)90099-3; [Anonymous], 2007, AISTATS; Austin T, 2008, PROBAB SURV, V5, P80, DOI 10.1214/08-PS124; Bacallado S, 2013, ANN STAT, V41, P870, DOI 10.1214/13-AOS1102; Beal MJ, 2002, ADV NEUR IN, V14, P577; Benjamini I., 2001, ELECTRON J PROBAB, V6, DOI DOI 10.1214/EJP.V6-96; Bertoin J., 2006, RANDOM FRAGMENTATION; Bollobas B, 2007, RANDOM STRUCT ALGOR, V31, P3, DOI 10.1002/rsa.20168; Borgs C., 2006, STOC'06. Proceedings of the 38th Annual ACM Symposium on Theory of Computing, P261, DOI 10.1145/1132516.1132556; Broderick T, 2013, BAYESIAN ANAL, V8, P801, DOI 10.1214/13-BA823; Broderick T, 2013, STAT SCI, V28, P289, DOI 10.1214/13-STS434; Buhlmann H., 1960, THESIS ETH ZURICH; de Finetti B., 1930, MEMORIE R ACCADEMIA, VIV, P86; de Finetti Bruno, 1937, ANN LINSTITUT HENRI, VPoincare7, P1; DIACONIS P, 1980, ANN PROBAB, V8, P115, DOI 10.1214/aop/1176994828; Diaconis P., 1992, MATH 21 CENTURY 1988, V2, P15; Durrett R, 2006, RANDOM GRAPH DYNAMIC; Fortini S, 2012, BRAZ J PROBAB STAT, V26, P423, DOI 10.1214/11-BJPS176; FREEDMAN DA, 1963, ANN MATH STAT, V34, P1194, DOI 10.1214/aoms/1177703856; FREEDMAN DA, 1962, ANN MATH STAT, V33, P916, DOI 10.1214/aoms/1177704460; Frieze A, 1999, COMBINATORICA, V19, P175, DOI 10.1007/s004930050052; Griffiths T.L., 2006, ADV NEURAL INFORM PR, P475; Hewitt E., 1955, T AM MATH SOC, V80, P470, DOI DOI 10.1090/S0002-9947-1955-0076206-8; Hjort N. L., 2010, BAYESIAN NONPARAMETR; Hoff P., 2008, ADV NEURAL INFORM PR, P657; Hoff PD, 2011, BAYESIAN ANAL, V6, P179, DOI 10.1214/11-BA606; HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7; HOOVER D, 1979, RELATIONS PROBABILIT; Kallenberg O, 1999, J THEOR PROBAB, V12, P859, DOI 10.1023/A:1021692202530; Kallenberg O., 2001, FDN MODERN PROBABILI, VSecond; KALLENBERG O, 2005, PROB APPL S; Kemp Charles, 2006, AAAI, DOI DOI 10.1145/1837026.1837061; Kingman J. F. C., 1979, J R STAT SOC A GEN, V142, P146; KINGMAN JFC, 1978, J LOND MATH SOC, V18, P374, DOI 10.1112/jlms/s2-18.2.374; KUCHLER U, 1989, SCAND J STAT, V16, P237; Lloyd J. R., 2012, P ADV NEURAL INFORM, P1007; Lovasz L, 2007, GEOM FUNCT ANAL, V17, P252, DOI 10.1007/s00039-007-0599-6; Lovasz L, 2006, J COMB THEORY B, V96, P933, DOI 10.1016/j.jctb.2006.05.002; Lovasz Laszlo, 2013, LARGE NETWORKS GRAPH; MacEachern S, 2000, TECHNICAL REPORT; Miller Kurt T., 2009, NONPARAMETRIC LATENT, P1276; Orbanz P., 2013, BOREL LIFTINGS GRAPH; Paisley J, 2012, P INT C ART INT STAT, P850; Paisley J.W., 2010, P INT C MACH LEARN, P847; Pitman J, 2006, COMBINATORIAL STOCHA; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Roy D. M., 2009, ADV NEURAL INFORM PR; Roy D. M., 2011, THESIS MIT CAMBRIDGE; Schervish M. J., 1995, THEORY STAT; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Teh Y. W., 2010, BAYESIAN NONPARAMETR; Teh Yee W., 2011, ADV NEURAL INFORM PR, P819; Thibaux Romain, 2007, INT C ART INT STAT, P564; Varadarajan V. S., 1963, T AM MATH SOC, V109, P191, DOI 10.1090/S0002-9947-1963-0159923-5; Varadarajan V. S., 1963, T AM MATH SOC, V109, P564; WASSERMAN S, 1987, SOC NETWORKS, V9, P1, DOI 10.1016/0378-8733(87)90015-3; WOLFE P. J., 2013, NONPARAMETRIC GRAPHO; XU Z., 2006, P 22 C ANN C UNC ART, P544; Xu Zenglin, 2012, ICML; ZABELL SL, 1995, J THEOR PROBAB, V8, P175, DOI 10.1007/BF02213460; [No title captured]	71	91	92	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					437	461		10.1109/TPAMI.2014.2334607	http://dx.doi.org/10.1109/TPAMI.2014.2334607			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353253	Green Submitted			2022-12-18	WOS:000349625500018
J	Li, YH; Maguire, L				Li, Yuhua; Maguire, Liam			Selecting Critical Patterns Based on Local Geometrical and Statistical Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern selection; data reduction; border pattern; edge pattern	NEAREST-NEIGHBOR CLASSIFICATION; PROTOTYPE SELECTION; SEARCH ALGORITHM; CLASSIFIERS; REDUCTION; SUBSET; OPTIMIZATION; NETWORKS; CHOICE	Pattern selection methods have been traditionally developed with a dependency on a specific classifier. In contrast, this paper presents a method that selects critical patterns deemed to carry essential information applicable to train those types of classifiers which require spatial information of the training data set. Critical patterns include those edge patterns that define the boundary and those border patterns that separate classes. The proposed method selects patterns from a new perspective, primarily based on their location in input space. It determines class edge patterns with the assistance of the approximated tangent hyperplane of a class surface. It also identifies border patterns between classes using local probability. The proposed method is evaluated on benchmark problems using popular classifiers, including multilayer perceptrons, radial basis functions, support vector machines, and nearest neighbors. The proposed approach is also compared with four state-of-the-art approaches and it is shown to provide similar but more consistent accuracy from a reduced data set. Experimental results demonstrate that it selects patterns sufficient to represent class boundary and to preserve the decision surface.	[Li, Yuhua; Maguire, Liam] Univ Ulster, Sch Comp & Intelligent Syst, Magee BT48 7LJ, Londonderry, North Ireland	Ulster University	Li, YH (corresponding author), Univ Ulster, Sch Comp & Intelligent Syst, Magee BT48 7LJ, Londonderry, North Ireland.	y.li@ulster.ac.uk; lp.maguire@ulster.ac.uk	Li, Yuhua/F-2430-2010	Li, Yuhua/0000-0003-2913-4478; Maguire, Liam/0000-0001-6153-3298	Nuffield Foundation [NAL/32568]	Nuffield Foundation	The authors would like to thank E. Marchiori and D. R. Wilson for providing them with their pattern selection programs. The authors also thank the anonymous referees for their insightful comments to the improvement in technical contents and paper presentation. This work was supported in part by a grant (Ref: NAL/32568) from the Nuffield Foundation.	Ajoka S, 2008, ELECTR ENG JPN, V164, P69, DOI 10.1002/eej.20502; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Angiulli F, 2007, IEEE T PATTERN ANAL, V29, P1746, DOI 10.1109/TPAMI.2007.1086; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; BENTLEY JL, 1979, COMPUT SURV, V11, P397, DOI 10.1145/356789.356797; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Broomhead D. S., 1988, Complex Systems, V2, P321; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CACHIN C, 1994, NEURAL NETWORKS, V7, P175, DOI 10.1016/0893-6080(94)90066-3; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; Cha SH, 2002, PATTERN RECOGN, V35, P515, DOI 10.1016/S0031-3203(01)00032-2; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; Chen YX, 2009, IEEE T PATTERN ANAL, V31, P288, DOI 10.1109/TPAMI.2008.72; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Choi SH, 2002, IEEE T SYST MAN CY B, V32, P202, DOI 10.1109/3477.990876; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Demsar J, 2006, J MACH LEARN RES, V7, P1; Foody GM, 1999, INT J REMOTE SENS, V20, P3549, DOI 10.1080/014311699211192; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Ghosh AK, 2007, J COMPUT GRAPH STAT, V16, P482, DOI 10.1198/106186007x208380; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Guo G, 2007, PATTERN RECOGN LETT, V28, P2173, DOI 10.1016/j.patrec.2007.04.017; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289, DOI 10.1109/34.990132; Kim SW, 2003, PATTERN ANAL APPL, V6, P232, DOI 10.1007/s10044-003-0191-0; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; KRAMER MA, 1990, COMPUT CHEM ENG, V14, P1323, DOI 10.1016/0098-1354(90)80015-4; Li J, 2005, INT J ARTIF INTELL T, V14, P261, DOI 10.1142/S0218213005002090; Li YH, 2002, PATTERN RECOGN LETT, V23, P569, DOI 10.1016/S0167-8655(01)00133-7; Li YH, 2001, T I MEAS CONTROL, V23, P315, DOI 10.1177/014233120102300504; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Lyhyaoui A, 1999, IEEE T NEURAL NETWOR, V10, P1474, DOI 10.1109/72.809092; Marchiori E, 2008, J MACH LEARN RES, V9, P997; Marchiori E, 2010, IEEE T PATTERN ANAL, V32, P364, DOI 10.1109/TPAMI.2009.164; Markou M, 2006, IEEE T PATTERN ANAL, V28, P1664, DOI 10.1109/TPAMI.2006.196; MEHROTRA KG, 1991, IEEE T NEURAL NETWOR, V2, P548, DOI 10.1109/72.97932; Mekuz N, 2006, LECT NOTES COMPUT SC, V4174, P364; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Peres RT, 2009, IEEE T PATTERN ANAL, V31, P1331, DOI 10.1109/TPAMI.2008.269; Prokhorov DV, 2001, IEEE IJCNN, P1669, DOI 10.1109/IJCNN.2001.938412; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Samet H, 2008, IEEE T PATTERN ANAL, V30, P243, DOI 10.1109/TPAMI.2007.1182; Samko O, 2006, PATTERN RECOGN LETT, V27, P968, DOI 10.1016/j.patrec.2005.11.017; Sanchez JS, 2006, NEUROCOMPUTING, V69, P922, DOI 10.1016/j.neucom.2005.10.001; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sancho JL, 2000, NEUROCOMPUTING, V35, P3, DOI 10.1016/S0925-2312(00)00293-9; Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667; Scholkopf B, 2000, ADV NEUR IN, V12, P582; Shin H, 2003, LECT NOTES ARTIF INT, V2637, P376; Shin H, 2007, NEURAL COMPUT, V19, P816, DOI 10.1162/neco.2007.19.3.816; Tambouratzis T, 2000, COMPUT J, V43, P177, DOI 10.1093/comjnl/43.3.177; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Varshney KR, 2010, J MACH LEARN RES, V11, P491; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; Wen GH, 2008, PATTERN RECOGN, V41, P2226, DOI 10.1016/j.patcog.2007.12.015; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6	69	91	99	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1189	1201		10.1109/TPAMI.2010.188	http://dx.doi.org/10.1109/TPAMI.2010.188			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	21493967				2022-12-18	WOS:000289524000009
J	Carreira-Perpinan, MA				Carreira-Perpinan, Miguel A.			Gaussian mean-shift is an EM algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mean-shift algorithm; Gaussian mixtures; kernel density estimators; EM algorithm; clustering	MAXIMUM-LIKELIHOOD; FEATURE SPACE; CONVERGENCE	The mean-shift algorithm, based on ideas proposed by Fukunaga and Hostetler [ 16], is a hill-climbing algorithm on the density defined by a finite mixture or a kernel density estimate. Mean-shift can be used as a nonparametric clustering method and has attracted recent attention in computer vision applications such as image segmentation or tracking. We show that, when the kernel is Gaussian, mean-shift is an expectation-maximization ( EM) algorithm and, when the kernel is non-Gaussian, mean-shift is a generalized EM algorithm. This implies that mean-shift converges from almost any starting point and that, in general, its convergence is of linear order. For Gaussian mean-shift, we show: 1) the rate of linear convergence approaches 0 ( superlinear convergence) for very narrow or very wide kernels, but is often close to 1 ( thus, extremely slow) for intermediate widths and exactly 1 ( sublinear convergence) for widths at which modes merge, 2) the iterates approach the mode along the local principal component of the data points from the inside of the convex hull of the data points, and 3) the convergence domains are nonconvex and can be disconnected and show fractal behavior. We suggest ways of accelerating mean-shift based on the EM interpretation.	Oregon Hlth & Sci Univ, Dept Comp Sci & Elect Engn, OGI Sch Sci & Engn, Beaverton, OR 97006 USA	Oregon Health & Science University	Carreira-Perpinan, MA (corresponding author), Oregon Hlth & Sci Univ, Dept Comp Sci & Elect Engn, OGI Sch Sci & Engn, 20000 NW Walker Rd, Beaverton, OR 97006 USA.	miguel@csee.ogi.edu			Div Of Information & Intelligent Systems [0754089] Funding Source: National Science Foundation	Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))		[Anonymous], 1999, NUMERICAL OPTIMIZATI; ARSLAN O, 1993, STAT COMPUT, V3, P103, DOI 10.1007/BF00147772; Bermond O., 1999, P 1 INT C IND COMP A, P325; Carreira-Perpinan M. A., 2001, THESIS CITESEER; Carreira-Perpinan M. A., 2006, P 23 INT C MACH LEAR; Carreira-Perpinan MA, 2000, ADV NEUR IN, V12, P414; Carreira-Perpinan MA, 2000, IEEE T PATTERN ANAL, V22, P1318, DOI 10.1109/34.888716; Carreira-Perpinan MA, 2003, LECT NOTES COMPUT SC, V2695, P625; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; DeMenthon D., 2002, P STAT METH VID PROC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fashing M, 2005, IEEE T PATTERN ANAL, V27, P471, DOI 10.1109/TPAMI.2005.59; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Lindeberg T., 1994, SCALE SPACE THEORY C; McLachlan, 1997, EM ALGORITHM EXTENSI; MENG XL, 1994, LINEAR ALGEBRA APPL, V199, P413, DOI 10.1016/0024-3795(94)90363-8; Milnor J., 1969, ANN MATH STUDIES, V51; Petersen KB, 2005, NEURAL COMPUT, V17, P1921, DOI 10.1162/0899766054322991; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Thompson J.R., 1990, NONPARAMETRIC FUNCTI; Wang J, 2004, LECT NOTES COMPUT SC, V3022, P238; Wiggins S., 2003, TEXTS APPL MATH, V2; Williams C.K.I., 2003, EDIINFRR0185 U ED SC; WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2; WONG YF, 1993, NEURAL COMPUT, V5, P89, DOI 10.1162/neco.1993.5.1.89; Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129	34	91	99	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					767	776		10.1109/TPAMI.2007.1057	http://dx.doi.org/10.1109/TPAMI.2007.1057			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356198				2022-12-18	WOS:000244855700002
J	Kakadiaris, I; Metaxas, D				Kakadiaris, I; Metaxas, D			Model-based estimation of 3D human motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; human motion estimation; deformable models; model-based tracking; physics-based modeling	TRACKING	This paper presents the formulations and techniques that we have developed for the three-dimensional, model-based, motion estimation of human movement from multiple cameras. Our method is based on the spatio-temporal analysis of the subject's silhouette and it has the advantage that the subject does not have to wear markers or other devices. We present tracking results from experiments involving the recovery of complex motions in the presence of significant occlusion.	Univ Houston, Dept Comp Sci, Houston, TX 77204 USA; Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA	University of Houston System; University of Houston; University of Pennsylvania	Kakadiaris, I (corresponding author), Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.	ioannisk@uh.edu; dnm@central.cis.upenn.edu						Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859; AZARBAYEJANI A, 1996, P IMAGE COM 96 MAY; Barron C, 2000, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2000.855884; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; CHAM TJ, 1999, P COMP VIS PATT REC, V2, P239; Delamarre Q., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P716, DOI 10.1109/ICCV.1999.790292; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; Douros I., 1999, Proceedings IEEE International Workshop on Modelling People. MPeople'99, P29, DOI 10.1109/PEOPLE.1999.798343; FELDMAR J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P549, DOI 10.1109/ICCV.1995.466891; FREY W, 1996, NPSCS96003 COMP SCI; GAVRILA D, 1999, COMPUTER VISION IMAG, V73; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861; Gu J, 1998, LECT NOTES ARTIF INT, V1537, P229; Hilton A., 1999, Proceedings IEEE International Workshop on Modelling People. MPeople'99, P37, DOI 10.1109/PEOPLE.1999.798344; Iwasawa S., 1999, Proceedings IEEE International Workshop on Modelling People. MPeople'99, P3, DOI 10.1109/PEOPLE.1999.798340; Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753; Kakadiaris IA, 1996, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.1996.517057; KAKADIARIS IA, 1996, THESIS U PENNSYLVANI; KAKADIARIS IA, 1998, P COMP AN 98 C JUN, P155; Kumar V, 1996, COMMUN ACM, V39, P55, DOI 10.1145/230798.230804; LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PENTLAND A, 1995, P 7 INT FOR FRONT TE; Plankers R., 1999, Proceedings IEEE International Workshop on Modelling People. MPeople'99, P45, DOI 10.1109/PEOPLE.1999.798345; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; RMONEIT D, 2000, P IEEE WORKSH HUM MO, P2; SHARMA R, 1996, HUMAN INTERACTION CO; Wachter S, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P2, DOI 10.1109/NAMW.1997.609843; WREN C, 1998, P 2 INT C AUT FAC GE, P51; Yamamoto M, 1998, PROC CVPR IEEE, P2, DOI 10.1109/CVPR.1998.698580; Yamamoto M, 2000, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.2000.855813	34	91	95	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1453	1459		10.1109/34.895978	http://dx.doi.org/10.1109/34.895978			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR					2022-12-18	WOS:000165901900008
J	Sabourin, R; Genest, G; Preteux, FJ				Sabourin, R; Genest, G; Preteux, FJ			Off-line signature verification by local granulometric size distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						off-line signature verification; feature extraction; shape analysis; mathematical morphology		A fundamental problem in the field of off-line signature verification is the lack of a signature representation based on shape descriptors and pertinent features. The main difficulty lies in the local variability of the writing trace of the signature which is closely related to the identity of human beings, In this paper, we propose a new formalism for signature representation based on visual perception. A signature image consists of 512 x 128 pixels and is centered on a grid of rectangular retinas which are excited by local portions of the signature. Granulometric size distributions are used for the definition of local shape descriptors in an attempt to characterize the amount of signal activity exciting each retina on the focus of the attention grid. Experimental evaluation of this scheme is made using a signature database of 800 genuine signatures from 20 individuals. Two types of classifiers, a Nearest Neighbor and a threshold classifier, show a total error rate below 0.02 percent and 1.0 percent, respectively, in the context of random forgeries.	INST NATL TELECOMMUN, DEPT SIGNAL & IMAGE, F-91011 EVRY, FRANCE	IMT - Institut Mines-Telecom; Institut Polytechnique de Paris	Sabourin, R (corresponding author), ECOLE TECHNOL SUPER, DEPT GENIE PROD AUTOMATISEE, LAB IMAGERIE VIS INTELLIGENC ARTIFICIELLE, MONTREAL, PQ H3C 1K3, CANADA.		Sabourin, Robert/J-7642-2012	Sabourin, Robert/0000-0002-9098-1011				AMMAR M, 1988, INT J PATTERN RECOGN, V2, P489; ANASTASSOPOULOS V, 1991, CIRC SYST SIGNAL PR, V10, P293, DOI 10.1007/BF01187548; [Anonymous], 1992, STRUCTURED DOCUMENT, DOI DOI 10.1007/978-3-642-77281-8_10; BAILLARD C, 1994, RAPPORT STAGE 3E ANN; BISWAS SN, 1985, COMPUT VISION GRAPH, V32, P158, DOI 10.1016/S0734-189X(85)80066-9; BROCKLEHURST ER, 1985, J FORENSIC SCI SOC, V25, P445, DOI 10.1016/S0015-7368(85)72433-4; Bronskill J. F., 1988, Journal of Intelligent and Robotic Systems: Theory and Applications, V1, P117, DOI 10.1007/BF00348719; COULON O, 1994, TECHNIQUES SPECTRES; DOUGHERTY E, 1992, MORPHOLOGICAL IMAGE; DOUGHERTY E, 1992, P SPIE, V1660; Dougherty E. R., 1992, Journal of Electronic Imaging, V1, P46, DOI 10.1117/12.55174; Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5; DROUHARD JP, 1994, IEEE INT C NEUR NETW, P4294; HARRISON WR, 1981, SUSPECT DOCUMENTS TH; Huang Y. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P598, DOI 10.1109/ICDAR.1993.395664; LECLERC F, 1994, INT J PATTERN RECOGN, P3; Levine M., 1985, VISION MAN MACHINE; LOCARD E, 1959, PAYOT; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Matheron G., 1975, RANDOM SETS INTEGRAL; MATHYER J, 1961, J CRIM LAW CRIM, V52, P122, DOI 10.2307/1141512; Murshed N. A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P191, DOI 10.1109/ICDAR.1995.598974; NAGEL RN, 1977, IEEE T COMPUT, V26, P895, DOI 10.1109/TC.1977.1674937; NEMCEK WF, 1974, IEEE T SYST MAN CYB, VSMC4, P121, DOI 10.1109/TSMC.1974.5408537; Nouboud F, 1994, P INT WORKSH FRONT H, P145; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; QI YY, 1994, PATTERN RECOGN, V27, P1621, DOI 10.1016/0031-3203(94)90081-7; Sabourin R., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P709, DOI 10.1142/S0218001494000383; SABOURIN R, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P321, DOI 10.1109/ICPR.1992.201782; SABOURIN R, 1994, 12 ICPR JER ISR OCT, V2, P450; SABOURIN R, 1993, 2 IAPR C DOC AN REC, P1; SABOURIN R, 1995, 3 IAPR C DOC AN REC, P197; SABOURIN R, 1990, THESIS ECOLE POLYTEC; Schmitt M., 1990, Revue Technique Thomson-CSF, V22, P573; Serra J, 1982, IMAGE ANAL MATH MORP; Wilkison T.S, 1990, P SOC PHOTO-OPT INS, P293; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	37	91	95	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					976	988		10.1109/34.615447	http://dx.doi.org/10.1109/34.615447			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500004
J	ZHU, PF; CHIRLIAN, PM				ZHU, PF; CHIRLIAN, PM			ON CRITICAL-POINT DETECTION OF DIGITAL SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FEATURE POINT DETECTION; SHAPE REPRESENTATION; SHAPE ANALYSIS; FEATURE EXTRACTION; DIGITIZED CONTOUR; NONLINEAR ALGORITHM; SHAPE RECOGNITION	DOMINANT POINTS; PLANAR CURVES; SCALES	In this paper, we present a nonlinear algorithm for critical point detection (CPD) of 2D digital shapes, The algorithm eliminates the problems arising from curvature approximation and Gaussian filtering in the existing algorithms, Based on the definition of ''critical level,'' we establish a set of criteria for the design of an effective CPD algorithm for the first time, By quantifying the critical level to the modified area confined by three consecutive ''pseudocritical points,'' a simple but very effective algorithm is developed. The comparison of our experimental results with those of many other CPD algorithms shows that the proposed algorithm is superior in that it provides a sequence of figures at every detail level, and each has a smaller integral error than the others with the same number of critical points, The experimental results on shapes with various complexities also show the algorithm is reliable and robust with regard to noise.	UNIV NEW ORLEANS, DEPT ELECT ENGN, NEW ORLEANS, LA 70148 USA	University of Louisiana System; University of New Orleans	ZHU, PF (corresponding author), JAMES RIVER CORP, EASTON, PA 18042 USA.							ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; ROSIN PL, 1992, PATTERN RECOGN, V25, P1315, DOI 10.1016/0031-3203(92)90144-8; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; WALLACE TP, 1981, IEEE T PATTERN ANAL, V3, P310, DOI 10.1109/TPAMI.1981.4767104; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; ZHU P, 1993, THESIS STEVENS I TEC	18	91	102	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					737	748		10.1109/34.400564	http://dx.doi.org/10.1109/34.400564			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035					2022-12-18	WOS:A1995RL03500001
J	HEIJMANS, HJAM				HEIJMANS, HJAM			THEORETICAL ASPECTS OF GRAY-LEVEL MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DILATION; EROSION; FLAT OPERATOR; GRAY-LEVEL FUNCTION; MATHEMATICAL MORPHOLOGY; THRESHOLD SUPERPOSITION PRINCIPLE; TRANSLATION-INVARIANCE; UMBRA	MATHEMATICAL MORPHOLOGY; FILTERS; IMAGE	Originally, mathematical morphology has been developed for binary images and extensively uses set-theoretic operations such as union, intersection, and set complement. Furthermore, translation plays a major role in classical morphology. Later, the theory has been extended to gray-level images. Here one must distinguish between two particular classes of morphological operators, those which are invariant under gray-level translations, and those which are not. This paper presents a detailed study of morphological operators on the space of gray-level functions. It is shown how one can use binary morphological operators and thresholding techniques to build a large class of gray-level morphological operators. Particular attention is given to the class of so-called flat operators, i.e., operators which commute with thresholding. It is also shown how to define dilations and erosions with nonflat structuring elements if the gray-level set is finite. Surprisingly, merely truncation yields wrong results.			HEIJMANS, HJAM (corresponding author), CTR MATH & COMP SCI, DEPT PURE & APPL MATH, POB 4079, 1009 AB AMSTERDAM, NETHERLANDS.							Birkhoff G., 1984, LATTICE THEORY; Giardina C., 1988, MORPHOLOGICAL METHOD; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Harrison M. A., 1965, INTRO SWITCHING AUTO; HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O; HEIJMANS JAHM, 1991, IN PRESS J VIS COMM; JANOWITZ MF, 1986, STATISTICAL IMAGE PR; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1170, DOI 10.1109/TASSP.1987.1165254; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1153, DOI 10.1109/TASSP.1987.1165259; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; Matheron G., 1975, RANDOM SETS INTEGRAL; MATHERON G, 1967, ELEMENTS UNE THEORIE; RONSE C, 1991, IN PRESS COMPUT VISI; RONSE C, 1988, MATH MORPHOLOGY NEED; Serra J, 1982, IMAGE ANAL MATH MORP; Serra J, 1988, IMAGE ANAL MATH MORP; SHIH FYC, 1989, IEEE T PATTERN ANAL, V11, P31, DOI 10.1109/34.23111; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; STERNBERG SR, 1982, LECTURE NOTES MED IN, V17, P294; VERVAAT W, 1988, CWI MSR8801 REP; WENDT PD, IEEE T ACOUST SPEECH; 1986, SIGNAL PROCESS, V34, P898	22	91	97	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					568	582		10.1109/34.87343	http://dx.doi.org/10.1109/34.87343			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200006
J	KASTURI, R; BOW, ST; ELMASRI, W; SHAH, J; GATTIKER, JR; MOKATE, UB				KASTURI, R; BOW, ST; ELMASRI, W; SHAH, J; GATTIKER, JR; MOKATE, UB			A SYSTEM FOR INTERPRETATION OF LINE DRAWINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NO ILLINOIS UNIV,DE KALB,IL 60115	Northern Illinois University	KASTURI, R (corresponding author), PENN STATE UNIV,DEPT ELECT & COMP ENGN,UNIVERSITY PK,PA 16802, USA.							Alemany J., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V829, P125; BOW S, 1990, IMAGE ANAL APPLICATI; DORI D, 1989, COMPUTER VISION GRAP, V47, P1; EJIRI M, 1990, IMAGE ANAL APPL, P73; FAHN CS, 1988, COMPUT VISION GRAPH, V44, P119, DOI 10.1016/S0734-189X(88)80001-X; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; GATTIKER JR, 1988, THESIS PENNSYLVANIA; HONNENAHALLI S, 1987, THESIS PENNSYLVANIA; KARIMA M, 1985, IEEE COMPUT GRAPH, P24; OGORMAN L, 1988, JUN P CVPR ANN ARB, P235; OKAZAKI A, 1988, IEEE T PATTERN ANAL, V10, P331, DOI 10.1109/34.3898; Saint-Marc P., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P618, DOI 10.1109/CVPR.1989.37910; SHIH C, 1989, MACH VISION APPL, V2, P103; Srihari S. N., 1989, Machine Vision and Applications, V2, P141, DOI 10.1007/BF01212455; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TOMBRE K, 1988, P IAPR WORKSHOP SYNT, P178; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; [No title captured]	18	91	100	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1990	12	10					978	992		10.1109/34.58870	http://dx.doi.org/10.1109/34.58870			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EA042					2022-12-18	WOS:A1990EA04200004
J	SANDER, PT; ZUCKER, SW				SANDER, PT; ZUCKER, SW			INFERRING SURFACE TRACE AND DIFFERENTIAL STRUCTURE FROM 3-D IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MCGILL UNIV, MCGILL INTELLIGENT MACHINES RES CTR, MONTREAL H3A 2A7, QUEBEC, CANADA	McGill University	SANDER, PT (corresponding author), INST NATL RECH INFORMAT & AUTOMAT, DOMAINE VOLUCEAU ROCQUENCOURT, BP 105, F-78153 LE CHESNAY, FRANCE.							ARTZY E, 1981, COMPUT VISION GRAPH, V15, P1, DOI 10.1016/0146-664X(81)90103-9; BAJCSY R, 1983, J COMPUT ASSIST TOMO, V7, P618, DOI 10.1097/00004728-198308000-00008; Ballard D.H., 1982, COMPUTER VISION; Banchoff T., 1982, CUSPS GAUSS MAPPINGS; BESL P, 1986, JUN P IEEE C COMP VI, P77; BESL P, 1985, JUN IEEE P COMP VIS, P226; BOISSONNAT JD, 1984, ACM T GRAPHIC, V3, P266, DOI 10.1145/357346.357349; BRADY M, 1985, 2ND P INT S ROB RES, P5; BREWSTER LJ, 1984, IEEE COMPUT GRAPH, V4, P31, DOI 10.1109/MCG.1984.276061; BURKE WL, 1985, APPLIED DIFFERENTIAL; CAPPELLETTI JD, 1987, CARTR314 U MAR CTR A; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Duda R.O., 1972, PATTERN CLASSIFICATI; Eisenhart L P, 1909, TREATISE DIFFERENTIA; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FERRIE F, 1989, JUN P VIS INT 89 LON; FREUND J, 1971, MATH STATISTICS; FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846; GORDON R, 1975, SCI AM, V233, P56, DOI 10.1038/scientificamerican1075-56; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HERMAN GT, 1979, COMPUT VISION GRAPH, V9, P1, DOI 10.1016/0146-664X(79)90079-0; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; Levine M., 1985, VISION MAN MACHINE; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; LORENSEN WE, P SIGGRAPH 87 ANAHEI; Luenberger D. G., 1969, OPTIMIZATION VECTOR; Marr D., 1982, VISION; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PONCE J, 1985, P IJCAI; Poston T., 2014, CATASTROPHE THEORY I; PYKETT IL, 1982, SCI AM, V246, P78, DOI 10.1038/scientificamerican0582-78; RHODES ML, 1983, IEEE COMPUT GRAPH, V3, P31, DOI 10.1109/MCG.1983.263185; RICE J, IMSL REFERENCE EDITI; ROSENFELD A, 1981, DIGITAL PICTURE PROC; Sander P. T., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1165; SANDER PT, 1988, CIM886 MCGILL U MCGI; SANDER PT, 1987, 1ST P INT C COMP VIS, P241; SANDER PT, 1988, CIM881 MCGILL U MCGI; SANDER PT, IN PRESS IEEE T PATT; Spanier EH., 1966, ALGEBRAIC TOPOLOGY; Steenrod N., 1974, TOPOLOGY FIBRE BUNDL; TERPOGOSSIAN MM, 1980, SCI AM, V243, P170, DOI 10.1038/scientificamerican1080-170; Trivedi S. S., 1986, Visual Computer, V2, P209, DOI 10.1007/BF01900344; Vannier M. W., 1983, Computer Graphics, V17, P263, DOI 10.1145/964967.801157; YOKOYA N, 1987, TRCIM8716 MCGILL U M; ZUCKER SW, 1987, ANNU REV COMPUT SCI, V2, P69, DOI 10.1146/annurev.cs.02.060187.000441; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105	51	91	95	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1990	12	9					833	854		10.1109/34.57680	http://dx.doi.org/10.1109/34.57680			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DV778		Green Submitted			2022-12-18	WOS:A1990DV77800001
J	Vandenhende, S; Georgoulis, S; Van Gansbeke, W; Proesmans, M; Dai, DX; Van Gool, L				Vandenhende, Simon; Georgoulis, Stamatios; Van Gansbeke, Wouter; Proesmans, Marc; Dai, Dengxin; Van Gool, Luc			Multi-Task Learning for Dense Prediction Tasks: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Deep learning; Optimization; Neural networks; Computer architecture; Taxonomy; Computer vision; Multi-task learning; dense prediction tasks; pixel-level tasks; optimization; convolutional neural networks		With the advent of deep learning, many dense prediction tasks, i.e., tasks that produce pixel-level predictions, have seen significant performance improvements. The typical approach is to learn these tasks in isolation, that is, a separate neural network is trained for each individual task. Yet, recent multi-task learning (MTL) techniques have shown promising results w.r.t. performance, computations and/or memory footprint, by jointly tackling multiple tasks through a learned shared representation. In this survey, we provide a well-rounded view on state-of-the-art deep learning approaches for MTL in computer vision, explicitly emphasizing on dense prediction tasks. Our contributions concern the following. First, we consider MTL from a network architecture point-of-view. We include an extensive overview and discuss the advantages/disadvantages of recent popular MTL models. Second, we examine various optimization methods to tackle the joint learning of multiple tasks. We summarize the qualitative elements of these works and explore their commonalities and differences. Finally, we provide an extensive experimental evaluation across a variety of dense prediction benchmarks to examine the pros and cons of the different methods, including both architectural and optimization based strategies.	[Vandenhende, Simon; Van Gansbeke, Wouter; Proesmans, Marc] Katholieke Univ Leuven, Ctr Proc Speech & Images, Dept Elect Engn, B-3000 Leuven, Belgium; [Georgoulis, Stamatios; Dai, Dengxin] Swiss Fed Inst Technol, Comp Vis Lab, Dept Elect Engn, CH-8092 Zurich, Switzerland; [Van Gool, Luc] Katholieke Univ Leuven, Ctr Proc Speech & Images, B-3000 Leuven, Belgium; [Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland	KU Leuven; Swiss Federal Institutes of Technology Domain; ETH Zurich; KU Leuven; Swiss Federal Institutes of Technology Domain; ETH Zurich	Vandenhende, S (corresponding author), Katholieke Univ Leuven, Ctr Proc Speech & Images, Dept Elect Engn, B-3000 Leuven, Belgium.	siomn.vandenhende@kuleuven.be; georgous@ee.ethz.ch; wouter.vangansbeke@kuleuven.be; marc.proesmans@kuleuven.be; daid@ee.ethz.ch; vangool@vision.ee.ethz.ch			Toyota [C14/18/065]; Flemish Government under the Flemish AI programme	Toyota; Flemish Government under the Flemish AI programme	The authors would like to acknowledge the support by Toyota via the TRACE project and MACCHINA (KU Leuven, C14/18/065). This work was also supported by the Flemish Government under the Flemish AI programme. Finally, the authors would like to thank Shikun Liu, Wanli Ouyang and the anonymous reviewers for useful feedback.	Acharya A., 2014, PROC SIAM INT C DATA, P190; Agarwal A., 2010, P ADV NEUR INF PROC, P46; Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658; Bell S, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2608, DOI 10.1145/3394486.3403311; Bilen H., 2017, ARXIV; Bragman FJS, 2019, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2019.00147; Bruggemann D., 2020, PROC 31 BRIT MACH VI; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Chen Z, 2018, PR MACH LEARN RES, V80; Chen Zhao, 2020, PROC 34 INT C NEURAL; Chengzhi Mao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P158, DOI 10.1007/978-3-030-58536-5_10; Daum~e III H., 2009, PROC 25 C UNCERTAINT; Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344; Desideri JA, 2012, CR MATH, V350, P313, DOI 10.1016/j.crma.2012.03.014; Diba Ali, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P593, DOI 10.1007/978-3-030-58558-7_35; Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226; Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723; Dvornik N, 2017, IEEE I CONF COMP VIS, P4174, DOI 10.1109/ICCV.2017.447; Dwivedi K, 2019, PROC CVPR IEEE, P12379, DOI 10.1109/CVPR.2019.01267; Eigen D, 2014, ADV NEUR IN, V27; Espeholt L, 2018, PR MACH LEARN RES, V80; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Gao Y, 2019, PROC CVPR IEEE, P3200, DOI 10.1109/CVPR.2019.00332; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong T, 2019, IEEE ACCESS, V7, P141627, DOI 10.1109/ACCESS.2019.2943604; Guo M, 2018, LECT NOTES COMPUT SC, V11220, P282, DOI 10.1007/978-3-030-01270-0_17; Guo PS, 2020, PR MACH LEARN RES, V119; Gur M, 2007, J PHYSIOL-LONDON, V585, P383, DOI 10.1113/jphysiol.2007.143040; Hausman K., 2018, INT C LEARN REPR; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hinton G., 2015, ARXIV150302531; Huang SY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2049, DOI 10.1145/3240508.3240588; Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5; Jacob L., 2009, P 21TH NIPS, P745; Jalali A., 2010, ADV NEURAL INF PROCE, V23, P964; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kim DJ, 2018, IEEE WINT CONF APPL, P1699, DOI 10.1109/WACV.2018.00189; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Kumar A., 2012, P INT C MACH LEARN, P1723; Lee S, 2007, PROC MONOGR ENG WATE, P489, DOI 10.1145/1273496.1273558; Liang J, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P466, DOI 10.1145/3205455.3205489; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin X., 2019, ADV NEURAL INFORM PR, V32, P12060; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3; Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154; Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001; Liu Q., 2008, ADV NEURAL INFORM PR, P937; Liu SK, 2019, PROC CVPR IEEE, P1871, DOI 10.1109/CVPR.2019.00197; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Long MS, 2017, ADV NEUR IN, V30; Lu YX, 2017, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2017.126; Ma JQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1930, DOI 10.1145/3219819.3220007; Mallya A, 2018, LECT NOTES COMPUT SC, V11208, P72, DOI 10.1007/978-3-030-01225-0_5; Maninis KK, 2019, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2019.00195; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McCann B., 2018, ARXIV; Meyerson E., 2018, P INT C LEARN REPR I; Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433; Nekrasov V, 2019, IEEE INT CONF ROBOT, P7101, DOI 10.1109/ICRA.2019.8794220; Neven Davy, 2017, ARXIV170802550; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pasunuru R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1273, DOI 10.18653/v1/P17-1117; Pham H, 2018, PR MACH LEARN RES, V80; Raffel C, 2020, J MACH LEARN RES, V21; Rai P., 2010, INT C ART INT STAT, P613; Ramanan D., 2017, ARXIV 170206506; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Rebuffi SA, 2018, PROC CVPR IEEE, P8119, DOI 10.1109/CVPR.2018.00847; Reichart R., 2008, PROC 46 ANN M ASS CO, P861; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Rosenbaum C., 2018, 6 INT C LEARN REPR I; Ruder S., 2017, ARXIV; Ruder S, 2019, AAAI CONF ARTIF INTE, P4822; Sanh V, 2019, AAAI CONF ARTIF INTE, P6949; Sener O, 2018, ADV NEUR IN, V31; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Sinha A., 2018, ARXIV; Standley Trevor, 2020, P INT C MACH LEARN, P9120; Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584; Suteu M., 2019, ARXIV; Teichmann M, 2018, IEEE INT VEH SYM, P1013; Vandenhende Simon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P527, DOI 10.1007/978-3-030-58548-8_31; Vandenhende Simon, 2020, BRIT MACH VIS C, P2; Vasudevan Arun Balajee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P638, DOI 10.1007/978-3-030-58548-8_37; Wang Alex, 2018, ARXIV180407461, DOI DOI 10.18653/V1/W18-5446; Wang C., 2019, ARXIV; Widmer C, 2010, LECT N BIOINFORMAT, V6044, P522, DOI 10.1007/978-3-642-12683-3_34; Wilson A., 2007, PROC INT C MACH LEAR, P1015, DOI DOI 10.1145/1273496; Wulfmeier M., 2019, ARXIV; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yang Y, 2016, ADV NEUR IN, V29; Yosinski J, 2014, ADV NEUR IN, V27; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479; Yuan Y., 2018, ARXIV 180900916; Zamir Amir R., 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11194, DOI 10.1109/CVPR42600.2020.01121; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zhang Y., 2017, ARXIV; Zhang Y, 2009, LECT NOTES ARTIF INT, V5782, P617, DOI 10.1007/978-3-642-04174-7_40; Zhang ZY, 2019, PROC CVPR IEEE, P4101, DOI 10.1109/CVPR.2019.00423; Zhang ZY, 2018, LECT NOTES COMPUT SC, V11214, P238, DOI 10.1007/978-3-030-01249-6_15; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao XY, 2018, LECT NOTES COMPUT SC, V11205, P415, DOI 10.1007/978-3-030-01246-5_25; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702; Zhou L, 2020, PROC CVPR IEEE, P4513, DOI 10.1109/CVPR42600.2020.00457; Zoph B., 2017, P1; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	117	90	91	40	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3614	3633		10.1109/TPAMI.2021.3054719	http://dx.doi.org/10.1109/TPAMI.2021.3054719			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33497328	Green Submitted, Green Accepted			2022-12-18	WOS:000805820500021
J	Wang, Q; Gao, JY; Lin, W; Li, XL				Wang, Qi; Gao, Junyu; Lin, Wei; Li, Xuelong			NWPU-Crowd: A Large-Scale Benchmark for Crowd Counting and Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Crowd counting; crowd localization; crowd analysis; benchmark website		In the last decade, crowd counting and localization attract much attention of researchers due to its wide-spread applications, including crowd monitoring, public safety, space design, etc. Many convolutional neural networks (CNN) are designed for tackling this task. However, currently released datasets are so small-scale that they can not meet the needs of the supervised CNN-based algorithms. To remedy this problem, we construct a large-scale congested crowd counting and localization dataset, NWPU-Crowd, consisting of 5,109 images, in a total of 2,133,375 annotated heads with points and boxes. Compared with other real-world datasets, it contains various illumination scenes and has the largest density range (0 similar to 20; 033). Besides, a benchmark website is developed for impartially evaluating the different methods, which allows researchers to submit the results of the test set. Based on the proposed dataset, we further describe the data characteristics, evaluate the performance of some mainstream state-of-the-art (SOTA) methods, and analyze the new problems that arise on the new data. What's more, the benchmark is deployed at https://www.crowdbenchmark.com/, and the dataset/code/models/results are available at https://gjy3035.github.io/ NWPU-Crowd-Sample-Code/	[Wang, Qi; Gao, Junyu; Lin, Wei; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Wang, Qi; Gao, Junyu; Lin, Wei; Li, Xuelong] Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University	Li, XL (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Li, XL (corresponding author), Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.	crabwq@gmail.com; gjy3035@gmail.com; elonlin24@gmail.com; li@nwpu.edu.cn	Gao, Junyu/GLU-4957-2022	Wang, Qi/0000-0002-7028-4956; Lin, Wei/0000-0001-8425-956X	National Key R&D Program of China [2017YFB1002202]; National Natural Science Foundation of China [U1864204, 61773316, U1801262, 61871470]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key R&D Program of China under Grant 2017YFB1002202, National Natural Science Foundation of China under Grant U1864204, 61773316, U1801262, and 61871470.	Ali S, 2007, PROC CVPR IEEE, P65; Bahmanyar R., 2019, MRCNET CROWD COUNTIN; Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Draper N.R., 1998, APPL REGRESSION ANAL, Vthird; Fang YY, 2019, IEEE INT CON MULTI, P814, DOI 10.1109/ICME.2019.00145; Gao J, 2019, ARXIV191203677; Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139; Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018; Gao Junyu, 2019, ARXIV PREPRINT ARXIV; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166; Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; King DB, 2015, ACS SYM SER, V1214, P1; Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120; Lian DZ, 2019, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2019.00192; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131; Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545; Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186; Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524; Liu XL, 2019, IEEE T PATTERN ANAL, V41, P1862, DOI 10.1109/TPAMI.2019.2899857; Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Paszke A, 2019, ADV NEUR IN, V32; Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969; Sindagi VA, 2019, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2019.00131; Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206; Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416; Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wen L., 2019, ARXIV191201811; Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104; Zhang C, 2016, IEEE T MULTIMEDIA, V18, P1048, DOI 10.1109/TMM.2016.2542585; Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127; Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70	46	90	92	13	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2141	2149		10.1109/TPAMI.2020.3013269	http://dx.doi.org/10.1109/TPAMI.2020.3013269			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	32750840	Green Submitted			2022-12-18	WOS:000649590200024
J	Mittal, S; Tatarchenko, M; Brox, T				Mittal, Sudhanshu; Tatarchenko, Maxim; Brox, Thomas			Semi-Supervised Semantic Segmentation With High- and Low-Level Consistency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Training; Semantics; Gallium nitride; Generators; Standards; Semisupervised learning; Computer vision; semi-supervised learning; semantic segmentation; generative adversarial networks		The ability to understand visual information from limited labeled data is an important aspect of machine learning. While image-level classification has been extensively studied in a semi-supervised setting, dense pixel-level classification with limited data has only drawn attention recently. In this work, we propose an approach for semi-supervised semantic segmentation that learns from limited pixel-wise annotated samples while exploiting additional annotation-free images. The proposed approach relies on adversarial training with a feature matching loss to learn from unlabeled images. It uses two network branches that link semi-supervised classification with semi-supervised segmentation including self-training. The dual-branch approach reduces both the low-level and the high-level artifacts typical when training with few labels. The approach attains significant improvement over existing methods, especially when trained with very few labeled samples. On several standard benchmarks-PASCAL VOC 2012, PASCAL-Context, and Cityscapes-the approach achieves new state-of-the-art in semi-supervised learning.	[Mittal, Sudhanshu; Tatarchenko, Maxim; Brox, Thomas] Univ Freiburg, Comp Sci Dept, D-79085 Freiburg, Germany	University of Freiburg	Mittal, S (corresponding author), Univ Freiburg, Comp Sci Dept, D-79085 Freiburg, Germany.	mittal@cs.uni-freiburg.de; tatarchm@cs.uni-freiburg.de; brox@cs.uni-freiburg.de		Tatarchenko, Maxim/0000-0003-1988-1488; Mittal, Sudhanshu/0000-0002-7809-8058	German Federal Ministry of Education and Research; Intel Network of Intelligent Systems; Facebook	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); Intel Network of Intelligent Systems; Facebook(Facebook Inc)	This study was supported by the German Federal Ministry of Education and Research via the project Deep-PTL and by the Intel Network of Intelligent Systems. The authors would also like to thank Facebook for their P100 server donation and gift funding.	Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523; Athiwaratkun B., 2019, P ICLR; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Chen L.-C., 2014, ARXIV PREPRINT ARXIV; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Di Lin, 2016, Arxiv, DOI arXiv:1604.05144; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hong S., 2015, ARXIV PREPRINT ARXIV, P1495; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hung Wei-Chih, 2018, ARXIV180207934; Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181; King DB, 2015, ACS SYM SER, V1214, P1; Laine Samuli, 2017, P INT C LEARN REPR I, P3; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luc P., 2016, NIPS WORKSHOP ADVERS; Maas A. L., 2013, P 30 INT C MACH LEAR, P3; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Oliver Avital, 2018, ARXIV180409170; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Salimans T, 2016, ADV NEUR IN, V29; Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tang M, 2018, LECT NOTES COMPUT SC, V11220, P524, DOI 10.1007/978-3-030-01270-0_31; Tarvainen A, 2017, ADV NEUR IN, V30; Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747	40	90	92	38	111	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1369	1379		10.1109/TPAMI.2019.2960224	http://dx.doi.org/10.1109/TPAMI.2019.2960224			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31869780	Green Submitted			2022-12-18	WOS:000626525300019
J	Svarm, L; Enqvist, O; Kahl, F; Oskarsson, M				Svarm, Linus; Enqvist, Olof; Kahl, Fredrik; Oskarsson, Magnus			City-Scale Localization for Cameras with Known Vertical Direction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Localization; camera pose; position retrieval	OPTIMIZATION; GEOMETRY	We consider the problem of localizing a novel image in a large 3D model, given that the gravitational vector is known. In principle, this is just an instance of camera pose estimation, but the scale of the problem introduces some interesting challenges. Most importantly, it makes the correspondence problem very difficult so there will often be a significant number of outliers to handle. To tackle this problem, we use recent theoretical as well as technical advances. Many modern cameras and phones have gravitational sensors that allow us to reduce the search space. Further, there are new techniques to efficiently and reliably deal with extreme rates of outliers. We extend these methods to camera pose estimation by using accurate approximations and fast polynomial solvers. Experimental results are given demonstrating that it is possible to reliably estimate the camera pose despite cases with more than 99 percent outlier correspondences in city-scale models with several millions of 3D points.	[Svarm, Linus; Kahl, Fredrik; Oskarsson, Magnus] Lund Univ, Ctr Math Sci, SE-22100 Lund, Sweden; [Enqvist, Olof; Kahl, Fredrik] Chalmers Univ Technol, Dept Signals & Syst, SE-41296 Gothenburg, Sweden	Lund University; Chalmers University of Technology	Svarm, L (corresponding author), Lund Univ, Ctr Math Sci, SE-22100 Lund, Sweden.	linus@maths.lth.se; olof.enqvist@chalmers.se; fredrik@maths.lth.se; magnuso@maths.lth.se		Oskarsson, Magnus/0000-0002-1789-8094	Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots), ELLIIT; Swedish Research Council [2012-4215]	Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots), ELLIIT; Swedish Research Council(Swedish Research CouncilEuropean Commission)	We gratefully acknowledge funding from the Swedish Foundation for Strategic Research (Semantic Mapping and Visual Navigation for Smart Robots), ELLIIT and the Swedish Research Council (grants no. 2012-4215).	[Anonymous], 2013, LIS331DLH MEMS MOTIO; Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9006, P188, DOI 10.1007/978-3-319-16817-3_13; Ask E, 2013, PROC CVPR IEEE, P1722, DOI 10.1109/CVPR.2013.225; Breuel TM, 2003, COMPUT VIS IMAGE UND, V90, P258, DOI 10.1016/S1077-3142(03)00026-2; Byrod M, 2009, INT J COMPUT VISION, V84, P237, DOI 10.1007/s11263-009-0235-z; Choudhary S, 2012, LECT NOTES COMPUT SC, V7576, P130, DOI 10.1007/978-3-642-33715-4_10; Chum O., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P623; Cox D.A., 2005, USING ALGEBRAIC GEOM, V185; Enqvist O., 2011, P WORKSH OMN VIS CAM; Enqvist O, 2015, INT J COMPUT VISION, V112, P115, DOI 10.1007/s11263-014-0760-2; Enqvist O, 2012, LECT NOTES COMPUT SC, V7572, P738, DOI 10.1007/978-3-642-33718-5_53; Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1_20; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Hartley R., 2004, ROBOTICA; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Irschara Arnold, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2599, DOI 10.1109/CVPRW.2009.5206587; Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824; Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083; Kukelova Zuzana, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P216, DOI 10.1007/978-3-642-19309-5_17; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Naroditsky O, 2009, PROC CVPR IEEE, P1101, DOI 10.1109/CVPRW.2009.5206696; Nister D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P199; Olsson C, 2010, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR.2010.5539800; Oskiper T., 2007, P IEEE C COMP VIS PA, P1; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5_54; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; Steder Bastian, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P644, DOI 10.1109/IROS.2007.4399414; Svarm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75; Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119; Yu J, 2011, IEEE I CONF COMP VIS, P399; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310	40	90	93	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1455	1461		10.1109/TPAMI.2016.2598331	http://dx.doi.org/10.1109/TPAMI.2016.2598331			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27514034				2022-12-18	WOS:000402744400014
J	Liu, ZY; Qiao, H				Liu, Zhi-Yong; Qiao, Hong			GNCCP-Graduated NonConvexity and Concavity Procedure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Combinatorial optimization; graduated optimization; deterministic annealing; partial graph matching; quadratic assignment problem	ASSIGNMENT PROBLEM; ALGORITHM	In this paper we propose the graduated nonconvexity and concavity procedure (GNCCP) as a general optimization framework to approximately solve the combinatorial optimization problems defined on the set of partial permutation matrices. GNCCP comprises two sub-procedures, graduated nonconvexity which realizes a convex relaxation and graduated concavity which realizes a concave relaxation. It is proved that GNCCP realizes exactly a type of convex-concave relaxation procedure (CCRP), but with a much simpler formulation without needing convex or concave relaxation in an explicit way. Actually, GNCCP involves only the gradient of the objective function and is therefore very easy to use in practical applications. Two typical related NP-hard problems, partial graph matching and quadratic assignment problem (QAP), are employed to demonstrate its simplicity and state-of-the-art performance.	[Liu, Zhi-Yong; Qiao, Hong] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Liu, ZY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Room 904,Zidonghua Bldg,95 Zhongguan East Rd, Beijing 100190, Peoples R China.	zhiyong.liu@ia.ac.cn			National Science Foundation of China (NSFC) [61375005, 61033011, 61210009]	National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	The authors would like to thank the associate editor and anonymous reviewers whose comments greatly improved the manuscript. This work was supported by the National Science Foundation of China (NSFC) (grants 61375005, 61033011, 61210009).	BOURGEOIS F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945; Boyd S, 2004, CONVEX OPTIMIZATION; Burkard RE, 1997, J GLOBAL OPTIM, V10, P391, DOI 10.1023/A:1008293323270; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Griffin G., 2007, CALTECH 256 OBJECT C; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M., 2009, P NEUR INF PROC SYST; Liu Z.Y., 2012, J MACHINE LEARNING R, V25, P237; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; [刘智勇 Liu Zhiyong], 2012, [自动化学报, Acta Automatica Sinica], V38, P725; Loiola EM, 2007, EUR J OPER RES, V176, P657, DOI 10.1016/j.ejor.2005.09.032; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Misevicius A, 2003, INFORMATICA-LITHUAN, V14, P497; Rangarajan A., 1996, P NEUR INF PROC SYST; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zhou F., 2012, P IEEE C COMP VIS PA	22	90	94	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1258	1267		10.1109/TPAMI.2013.223	http://dx.doi.org/10.1109/TPAMI.2013.223			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353285				2022-12-18	WOS:000337124200016
J	Mohammadzade, H; Hatzinakos, D				Mohammadzade, Hoda; Hatzinakos, Dimitrios			Iterative Closest Normal Point for 3D Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional; face recognition; expression variation; point correspondence; 3D registration; surface normal vector; LDA	DISCRIMINANT-ANALYSIS; REGISTRATION; EIGENFACES; SAMPLE; LDA	The common approach for 3D face recognition is to register a probe face to each of the gallery faces and then calculate the sum of the distances between their points. This approach is computationally expensive and sensitive to facial expression variation. In this paper, we introduce the iterative closest normal point method for finding the corresponding points between a generic reference face and every input face. The proposed correspondence finding method samples a set of points for each face, denoted as the closest normal points. These points are effectively aligned across all faces, enabling effective application of discriminant analysis methods for 3D face recognition. As a result, the expression variation problem is addressed by minimizing the within-class variability of the face samples while maximizing the between-class variability. As an important conclusion, we show that the surface normal vectors of the face at the sampled points contain more discriminatory information than the coordinates of the points. We have performed comprehensive experiments on the Face Recognition Grand Challenge database, which is presently the largest available 3D face database. We have achieved verification rates of 99.6 and 99.2 percent at a false acceptance rate of 0.1 percent for the all versus all and ROC III experiments, respectively, which, to the best of our knowledge, have seven and four times less error rates, respectively, compared to the best existing methods on this database.	[Mohammadzade, Hoda; Hatzinakos, Dimitrios] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada	University of Toronto	Mohammadzade, H (corresponding author), Univ Toronto, Dept Elect & Comp Engn, 40 St George St,BAHEN Bld,Room 4144, Toronto, ON M5S 2E4, Canada.	hoda@-comm.utoronto.ca; dimitris@-comm.utoronto.ca	, Hoda/ABC-6387-2020	, Hoda/0000-0002-9852-5088	Natural Sciences and Engineering Research Council of Canada (NSERC)	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work has been supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).	Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V, 2007, IEEE I CONF COMP VIS, P1562; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Cook J, 2006, P IEEE INT C VID SIG, P83; Di Huang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P1, DOI 10.1109/FG.2011.5771323; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Heseltine T, 2004, IEEE IMAGE PROC, P1421; Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850; Huang J, 2003, LECT NOTES COMPUT SC, V2688, P27; Husken M., 2005, P INT C COMP VIS PAT, P174; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lim JS, 1990, 2 DIMENSIONAL SIGNAL; Lin WY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P727; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Lu X, 2006, P IEEE COMP SOC C CO, P1377, DOI DOI 10.1109/CVPR..96; Maurer T, 2005, P IEEE C COMP VIS PA, P154, DOI DOI 10.1109/CVPR.2005.581; McKeon R., 2010, THESIS U NOTRE DAME; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mohammadzade H., 2010, P 4 IEEE INT C BIOM, P1; Ocegueda O, 2011, PROC CVPR IEEE, P641, DOI 10.1109/CVPR.2011.5995613; Pentland A., 1994, P IEEE C COMP VIS PA, V19, P696; Phillips PJ, 2005, PROC CVPR IEEE, P947; Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14; Russ T., 2006, P IEEE C COMP VIS PA; Segundo MP, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P431, DOI 10.1109/ICIAP.2007.4362816; Smeets D, 2010, FORENSIC SCI INT, V201, P125, DOI 10.1016/j.forsciint.2010.03.023; Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2; Tumer K, 2002, PATTERN ANAL APPL, V5, P189, DOI 10.1007/s100440200017; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang J, 2008, PATTERN RECOGN, V41, P1528, DOI 10.1016/j.patcog.2007.10.024; Wang J, 2006, PATTERN RECOGN, V39, P1746, DOI 10.1016/j.patcog.2006.03.010; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Yuan X, 2005, IEEE INT SYMP CIRC S, P3211; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	46	90	108	0	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					381	397		10.1109/TPAMI.2012.107	http://dx.doi.org/10.1109/TPAMI.2012.107			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22585097				2022-12-18	WOS:000312560600011
J	Shechtman, E; Irani, M				Shechtman, Eli; Irani, Michal			Space-time behavior-based correlation - OR - How to tell if two underlying motion fields are similar without computing them?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						space-time analysis; motion analysis; action recognition; motion similarity measure; template matching; video correlation; video indexing; video browsing	RECOGNITION	We introduce a behavior-based similarity measure that tells us whether two different space-time intensity patterns of two different video segments could have resulted from a similar underlying motion field. This is done directly from the intensity information, without explicitly computing the underlying motions. Such a measure allows us to detect similarity between video segments of differently dressed people performing the same type of activity. It requires no foreground/ background segmentation, no prior learning of activities, and no motion estimation or tracking. Using this behavior-based similarity measure, we extend the notion of two-dimensional image correlation into the three-dimensional space-time volume and thus allowing to correlate dynamic behaviors and actions. Small space-time video segments (small video clips) are "correlated" against the entire video sequences in all three dimensions ( x, y, and t). Peak correlation values correspond to video locations with similar dynamic behaviors. Our approach can detect very complex behaviors in video sequences ( for example, ballet movements, pool dives, and running water), even when multiple complex activities occur simultaneously within the field of view of the camera. We further show its robustness to small changes in scale and orientation of the correlated behavior.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Shechtman, E (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.	eli.schechtman@weizmann.ac.il; michal.irani@weizmann.ac.il	Shechtman, Eli/B-2736-2012					BIGUN J, 1988, P SWED S IM AN S PIC; BLACK M, 1999, P IEEE C COMP VIS PA, V1, P1326; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; BREGLER C, 1997, P IEEE C COMP VIS PA; Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940; CHOMAT O, 2000, P EUR C COMP VIS; Dollar P., 2005, P 2 JOINT IEEE INT W; EFROS A, 2003, P INT C COMP VIS; FELDMAN D, 2006, P ECCV WORKSH DYN VI; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; JAHNE B, 1999, HDB COMPUTER VISION, V2; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Lindeberg T, 2004, INT C PATT RECOG, P57, DOI 10.1109/ICPR.2004.1334004; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Niebles J. C., 2006, P BRIT MACH VIS C; NIYOGI SA, 1994, P IEEE C COMP VIS PA; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; SHECHTMAN E, 2005, P CVPR, V1, P405; Sullivan J, 2002, LECT NOTES COMPUT SC, V2350, P629; Ukrainitz Y., 2006, P EUR C COMP VIS; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yilmaz A, 2005, PROC CVPR IEEE, P984; Zelnik-Manor L, 2001, PROC CVPR IEEE, P123; Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194	28	90	94	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					2045	2056		10.1109/TPAMI.2007.1119	http://dx.doi.org/10.1109/TPAMI.2007.1119			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848783	Green Submitted			2022-12-18	WOS:000249343900013
J	Hild, KE; Erdogmus, D; Torkkola, K; Principe, JC				Hild, Kenneth E., II; Erdogmus, Deniz; Torkkola, Kari; Principe, Jose C.			Feature extraction using information-theoretic learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction; information theory; classification; nonparametric statistics	PROBABILITY; DESIGN; ERROR	A classification system typically consists of both a feature extractor ( preprocessor) and a classifier. These two components can be trained either independently or simultaneously. The former option has an implementation advantage since the extractor need only be trained once for use with any classifier, whereas the latter has an advantage since it can be used to minimize classification error directly. Certain criteria, such as Minimum Classification Error, are better suited for simultaneous training, whereas other criteria, such as Mutual Information, are amenable for training the feature extractor either independently or simultaneously. Herein, an information-theoretic criterion is introduced and is evaluated for training the extractor independently of the classifier. The proposed method uses nonparametric estimation of Renyi's entropy to train the extractor by maximizing an approximation of the mutual information between the class labels and the output of the feature extractor. The evaluations show that the proposed method, even though it uses independent training, performs at least as well as three feature extraction methods that train the extractor and classifier simultaneously.	Univ Calif San Francisco, Biomagnet Imaging Lab, San Francisco, CA 94122 USA; Oregon Hlth & Sci Univ, Dept Comp Sci & Engn, OGI Sch Sci & Engn, Beaverton, OR 97006 USA; Oregon Hlth & Sci Univ, Dept Biomed Engn, OGI Sch Sci & Engn, Beaverton, OR 97006 USA; Motorola Labs, Ctr Human Interact Res, Tempe, AZ 85282 USA; Univ Florida, Computat NeuroEngn Lab, Gainesville, FL 32611 USA	University of California System; University of California San Francisco; Oregon Health & Science University; Oregon Health & Science University; Legend Holdings; Lenovo; State University System of Florida; University of Florida	Hild, KE (corresponding author), Univ Calif San Francisco, Biomagnet Imaging Lab, Room C-324B, San Francisco, CA 94122 USA.	k.hild@ieee.org; derdogmus@ieee.org; kari.torkkola@motorola.com; principe@cnel.ufl.edu	Erdogmus, Deniz/A-8170-2009; principe, jose/N-8099-2014		NIDCD NIH HHS [R01 DC009834] Funding Source: Medline	NIDCD NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))		[Anonymous], 2017, PAIN PRACT, V17, P1015; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Beirlant J., 1997, INT J MATH STAT SCI, V6, P17; Biem A, 1997, IEEE T SIGNAL PROCES, V45, P500, DOI 10.1109/78.554319; Biem A., 1993, P 1993 IEEE WORKSH N, P392; Bishop, 1995, NEURAL NETWORKS PATT; Bollacker KD, 1996, IEEE IJCNN, P1528, DOI 10.1109/ICNN.1996.549127; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Erdogmus D, 2004, J VLSI SIG PROC SYST, V37, P305, DOI 10.1023/B:VLSI.0000027493.48841.39; Erdogmus D, 2003, IEEE SIGNAL PROC LET, V10, P242, DOI 10.1109/LSP.2003.814400; ERDOGMUS D, 2002, IEEE T NEURAL NETWOR; ERDOGMUS D, UNPUB J VLSI SIGNAL; FRALICK SC, 1971, IEEE T INFORM THEORY, V17, P440, DOI 10.1109/TIT.1971.1054663; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub Gene H., 2013, MATRIX COMPUTATION, V3; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hild KE, 2006, SIGNAL PROCESS, V86, P182, DOI 10.1016/j.sigpro.2005.04.015; HILD KE, 2001, P INT WORKSH IND COM, P126; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Katagiri S, 1998, P IEEE, V86, P2345, DOI 10.1109/5.726793; KWAK N, 1999, P INT JOINT C NEUR N, V2, P1313; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li Q, 2002, INT CONF ACOUST SPEE, P97; MOREJON R, 2003, THESIS U FLORIDA; NEDELJKOVIC V, 1993, IEEE T NEURAL NETWOR, V4, P650, DOI 10.1109/72.238319; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Principe JC, 2000, J VLSI SIG PROCESS S, V26, P61, DOI 10.1023/A:1008143417156; RAJAGOPAL R, 1994, INT CONF ACOUST SPEE, P313, DOI 10.1109/ICASSP.1994.389657; Renyi A., 1970, PROBABILITY THEORY; Ripley B.D., 1995, PATTERN RECOGNITION; Theodoridis S., 2008, PATTERN RECOGN; Torkkola K, 2002, INT CONF ACOUST SPEE, P821; Torkkola K, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P376, DOI 10.1109/NNSP.2000.889429; TORKKOLA K, 2001, P C ADV NEUR INF PRO; Watanabe H, 1997, IEEE T SIGNAL PROCES, V45, P2655, DOI 10.1109/78.650091; XU D, 2001, P INT JOINT C NEUR N, V1, P459; YANG HH, 1999, P C ADV INT DAT AN C	38	90	97	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1385	1392		10.1109/TPAMI.2006.186	http://dx.doi.org/10.1109/TPAMI.2006.186			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929726	Green Accepted			2022-12-18	WOS:000238950800003
J	Marinai, S; Gori, M; Soda, G				Marinai, S; Gori, M; Soda, G			Artificial neural networks for document analysis and recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						character segmentation; document image analysis and recognition; layout analysis; neural networks; preprocessing; recursive neural networks; word recognition	SIGNATURE VERIFICATION; CHARACTER-RECOGNITION; PATTERN-RECOGNITION; SEGMENTATION; SKELETONIZATION; BACKPROPAGATION; CLASSIFICATION; EXTRACTION; MODELS; SYSTEM	Artificial neural networks have been extensively applied to document analysis and recognition. Most efforts have been devoted to the recognition of isolated handwritten and printed characters with widely recognized successful results. However, many other document processing tasks, like preprocessing, layout analysis, character segmentation, word recognition, and signature verification, have been effectively faced with very promising results. This paper surveys the most significant problems in the area of offline document image processing, where connectionist-based approaches have been applied. Similarities and differences between approaches belonging to different categories are discussed. A particular emphasis is given on the crucial role of prior knowledge for the conception of both appropriate architectures and learning algorithms. Finally, the paper provides a critical analysis on the reviewed approaches and depicts the most promising research guidelines in the field. In particular, a second generation of connectionist-based models are foreseen which are based on appropriate graphical representations of the learning environment.	Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy; Univ Siena, Dipartimento Ingn Informaz, I-53100 Siena, Italy	University of Florence; University of Siena	Marinai, S (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, I-50139 Florence, Italy.	marinai@dsi.unifi.it; marco@dii.unisi.it; soda@dsi.unifi.it		MARINAI, SIMONE/0000-0002-6702-2277				AHMED P, 1995, PATTERN RECOGN LETT, V16, P585, DOI 10.1016/0167-8655(95)80004-D; Amin A, 1996, PATTERN RECOGN, V29, P663, DOI 10.1016/0031-3203(95)00110-7; Bae JH, 1998, PATTERN RECOGN LETT, V19, P701, DOI 10.1016/S0167-8655(98)00048-8; BIANCHINI M, 1995, IEEE T NEURAL NETWOR, V6, P512, DOI 10.1109/72.363492; BROMLEY J, 1993, NEURAL COMPUT, V5, P367, DOI 10.1162/neco.1993.5.3.367; BURR DJ, 1988, IEEE T ACOUST SPEECH, V36, P1162, DOI 10.1109/29.1643; CAELLI TM, 2003, P PRASA 2003 LANG S, P1; Cardot H., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P679, DOI 10.1142/S021800149400036X; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Cesarini F, 1998, IEEE T PATTERN ANAL, V20, P730, DOI 10.1109/34.689303; Cesarini F., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1131, DOI 10.1109/ICDAR.2001.953962; Chen K, 2000, IEEE T NEURAL NETWOR, V11, P1106, DOI 10.1109/72.870043; Chi Z, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P275, DOI 10.1109/ISIMP.2001.925387; CHO SB, 1992, PATTERN RECOGN, V25, P1353, DOI 10.1016/0031-3203(92)90147-B; Clark P, 2000, INT C PATT RECOG, P450, DOI 10.1109/ICPR.2000.905373; CORDELLA LP, 1995, MACH VISION APPL, V8, P336; CORTELAZZO G, 1994, PATTERN RECOGN, V27, P1005, DOI 10.1016/0031-3203(94)90140-6; Datta A, 2001, PATTERN RECOGN, V34, P617, DOI 10.1016/S0031-3203(00)00013-3; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; DEWAARD WP, 1994, PATTERN RECOGN LETT, V15, P199, DOI 10.1016/0167-8655(94)90049-3; Diligenti M, 2001, PATTERN RECOGN, V34, P2049, DOI 10.1016/S0031-3203(00)00127-8; DONG JX, 2003, P 1 IAPR TC3 ART NEU, P39; Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5; EASTWOOD B, 1997, P INT C DOC AN REC I, P523; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; Feiden D, 2003, IEEE IJCNN, P1149; Feng XJ, 2002, IEEE T PATTERN ANAL, V24, P467, DOI 10.1109/34.993555; Francesconi E., 2001, International Journal on Document Analysis and Recognition, V3, P160, DOI 10.1007/PL00013556; Frasconi P, 1997, PATTERN RECOGN LETT, V18, P303, DOI 10.1016/S0167-8655(97)00018-4; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Frasconi P, 2001, IEEE T KNOWL DATA EN, V13, P145, DOI 10.1109/TKDE.2001.917554; FRASCONI P, 2001, FIELD GUIDE DYNAMICA; FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912; GADER P, 1995, IEEE T FUZZY SYST, V3, P357, DOI 10.1109/91.413223; GADER P, 1997, IEEE T SYST MAN CYB, P158; Garris MD, 1998, IEEE T IMAGE PROCESS, V7, P1097, DOI 10.1109/83.704304; Ghosn J, 2003, IEEE T NEURAL NETWOR, V14, P748, DOI 10.1109/TNN.2003.810608; Gori M, 2003, PATTERN RECOGN, V36, P103, DOI 10.1016/S0031-3203(02)00062-6; Gori M, 1998, IEEE T PATTERN ANAL, V20, P1121, DOI 10.1109/34.730549; GORI M, 2003, N12003 U FLOR; HU J, 1999, P 5 INT C DOC AN REC, P285; Imade S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P930, DOI 10.1109/ICDAR.1993.395584; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; Jung K, 2001, PATTERN RECOGN LETT, V22, P1503, DOI 10.1016/S0167-8655(01)00096-4; Karystinos GN, 2000, IEEE T NEURAL NETWOR, V11, P1050, DOI 10.1109/72.870038; Kim JH, 2000, PATTERN ANAL APPL, V3, P314, DOI 10.1007/s100440070003; Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LE DX, 1995, MACH VISION APPL, V8, P289, DOI 10.1007/BF01211490; Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEE DS, 1995, P SPIE DOCUMENT RECO, V2, P26; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P1045, DOI 10.1109/34.541415; Liu CL, 2004, IEEE T NEURAL NETWOR, V15, P430, DOI 10.1109/TNN.2004.824263; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3203(03)00085-2; Liu JH, 2002, PATTERN RECOGN, V35, P2061, DOI 10.1016/S0031-3203(01)00191-1; Lopez-Rubio E, 2000, INT C PATT RECOG, P606, DOI 10.1109/ICPR.2000.905410; Lu SW, 2003, PATTERN RECOGN, V36, P2395, DOI 10.1016/S0031-3203(03)00083-9; Lu ZK, 1998, J ELECTRON IMAGING, V7, P79, DOI 10.1117/1.482629; MAO J, 1995, P 3 INT C DOC AN REC, P78; Marinai S, 2003, PROC INT CONF DOC, P223; Marti UV, 2001, PROC INT CONF DOC, P101, DOI 10.1109/ICDAR.2001.953763; MARTIN GL, 1993, NEURAL COMPUT, V5, P419, DOI 10.1162/neco.1993.5.3.419; MARTIN P, 1991, P 1 INT C DOC AN REC, P417; MITCHELL TOM M., 1997, MACH LEARN, P2; Mui L., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1189, DOI 10.1142/S0218001494000590; Murshed N. A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P191, DOI 10.1109/ICDAR.1995.598974; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; NAGY G, 1984, P 7 INT C PATT REC M, P347; O'Gorman L., 1995, DOCUMENT IMAGE ANAL; Palaniappan R, 2000, PATTERN ANAL APPL, V3, P78, DOI 10.1007/s100440070014; Palmero G. I. S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P181, DOI 10.1109/ICDAR.1999.791754; Park DC, 2001, IEEE T NEURAL NETWOR, V12, P1134, DOI 10.1109/72.950142; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; RAINA R, 2004, ADV NEURAL INFORMATI, V16; Rondel N., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1141, DOI 10.1109/ICDAR.1995.602122; Shih FY, 1996, IEEE T SYST MAN CY B, V26, P797, DOI 10.1109/3477.537322; Simard PY, 2003, PROC INT CONF DOC, P958; Singh R, 2000, IEEE T NEURAL NETWOR, V11, P241, DOI 10.1109/72.822527; Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040; Strathy N. W., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P74, DOI 10.1109/ICDAR.1995.598947; Strouthopoulos C, 1998, IMAGE VISION COMPUT, V16, P879, DOI 10.1016/S0262-8856(98)00055-9; Strouthopoulos C, 2002, PATTERN RECOGN, V35, P1743, DOI 10.1016/S0031-3203(01)00167-4; Stubberud P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P778, DOI 10.1109/ICDAR.1995.602018; SU H, 1995, P 3 INT C DOC AN REC, P46; Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151; TAKAHASHI H, 1993, P 2 INT C DOC AN REC, P585; Taylor S. L., 1992, Machine Vision and Applications, V5, P211, DOI 10.1007/BF02626999; Teo RYM, 1997, PROC INT CONF DOC, P283, DOI 10.1109/ICDAR.1997.619857; Trentin E, 2003, IEEE T NEURAL NETWOR, V14, P1519, DOI 10.1109/TNN.2003.820838; Utschick W., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P315, DOI 10.1109/ICDAR.1995.599002; Wang DH, 2003, IEEE IJCNN, P1243; WANG J, 1994, PATTERN RECOGN, V27, P649, DOI 10.1016/0031-3203(94)90044-2; Whichello AP, 1996, PATTERN RECOGN, V29, P1429, DOI 10.1016/0031-3203(95)00171-9; Wong HS, 2001, IEEE T NEURAL NETWOR, V12, P516, DOI 10.1109/72.925555; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; YAN H, 1994, PATTERN RECOGN LETT, V15, P97, DOI 10.1016/0167-8655(94)90105-8; You DK, 2003, PROC INT CONF DOC, P142; YUAN J, 1995, P 3 INT C DOC AN REC, P752; ZEYU L, 2002, P INT JOINT C NEUR N, V1, P878	102	90	93	1	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					23	35		10.1109/TPAMI.2005.4	http://dx.doi.org/10.1109/TPAMI.2005.4			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628266				2022-12-18	WOS:000225028200004
J	Forbes, F; Peyrard, N				Forbes, F; Peyrard, N			Hidden Markov random field model selection criteria based on mean field-like approximations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; hidden Markov random fields; model selection; Bayesian Information Criterion; mean field; approximation; partition function	ALGORITHMS	Hidden Markov random fields appear naturally in problems such as image segmentation, where an unknown class assignment has to be estimated from the observations at each pixel. Choosing the probabilistic model that best accounts for the observations is an important first step for the quality of the subsequent estimation and analysis. A commonly used selection criterion is the Bayesian Information Criterion (BIC) of Schwarz (1978), but for hidden Markov random fields, its exact computation is not tractable due to the dependence structure induced by the Markov model. We propose approximations of BIC based on the mean field principle of statistical physics. The mean field theory provides approximations of Markov random fields by systems of independent variables leading to tractable computations. Using this principle, we first derive a class of criteria by approximating the Markov distribution in the usual BIC expression as a penalized likelihood. We then rewrite BIC in terms of normalizing constants, also called partition functions, instead of Markov distributions. It enables us to use finer mean field approximations and to derive other criteria using optimal lower bounds for the normalizing constants. To illustrate the performance of our partition function-based approximation of BIC as a model selection criterion, we focus on the preliminary issue of choosing the number of classes before the segmentation task. Experiments on simulated and real data point out our criterion as promising: It takes spatial information into account through the Markov model and improves the results obtained with BIC for independent mixture models.	INRIA Rhone Alpes, ZIRST, Projet IS2, F-38334 Saint Ismier, France; Inst Rech Informat & Syst Aleatoires, Projet VISTA, F-35042 Rennes, France	Universite de Rennes	Forbes, F (corresponding author), INRIA Rhone Alpes, ZIRST, Projet IS2, 655,Av Europe,Montbonnot, F-38334 Saint Ismier, France.	Florence.Forbes@inrialpes.fr; npeyrard@irisa.fr						Akaike H., 1973, 2 INT S INFORM THEOR, P267, DOI DOI 10.1007/978-1-4612-1694-0_15; Archer G.E.B., 2002, J STAT PLANNING INFE; BERGER JO, 1987, J AM STAT ASSOC, V82, P112, DOI 10.2307/2289131; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; BESAG J, 1986, J R STAT SOC B, V48, P259; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4; Chandler D., 1987, INTRO MODERN STAT ME; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; GASSIAT E, 2001, 200120 MATH; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN D, 1990, LECT NOTES MATH, V1427, P113; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hammersley J.M., 1971, MARKOV FIELDS FINITE; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Mclachlan G., 2000, WILEY SER PROB STAT; McLachlan GJ., 1987, MIXTURE MODELS INFER; NEWTON MA, 1994, J R STAT SOC B, V56, P3; PEYRARD N, 2001, THESIS U J FOURIER G; Potamianos G, 1997, IEEE T INFORM THEORY, V43, P1948, DOI 10.1109/18.641558; QIAN W, 1991, PHILOS T ROY SOC A, V337, P407, DOI 10.1098/rsta.1991.0132; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; RISSANEN J, 1989, WORD SCI; Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Seymour L, 1996, J STAT PLAN INFER, V51, P75, DOI 10.1016/0378-3758(95)00071-2; STANFORD D, 2001, DETERMINING NUMBER C; STANFORD D, 1999, THESIS U WASHINGTON; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1; ZERUBIA J, 1990, INT CONF ACOUST SPEE, P2193, DOI 10.1109/ICASSP.1990.115992; ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027; Zhou ZY, 1997, IEEE T IMAGE PROCESS, V6, P844, DOI 10.1109/83.585235	35	90	94	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1089	1101		10.1109/TPAMI.2003.1227985	http://dx.doi.org/10.1109/TPAMI.2003.1227985			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX					2022-12-18	WOS:000184977300005
J	LUTTON, E; MAITRE, H; LOPEZKRAHE, J				LUTTON, E; MAITRE, H; LOPEZKRAHE, J			CONTRIBUTION TO THE DETERMINATION OF VANISHING POINTS USING HOUGH TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BIAS AND ERRORS OF THE HOUGH TRANSFORM; HOUGH TRANSFORM; ORTHOGONAL DIRECTIONS DETECTION; VANISHING POINTS DETECTION	PERSPECTIVE IMAGES	We propose a method to locate three vanishing points on an image, corresponding to three orthogonal directions of the scene. This method is based on two cascaded Hough transforms. We show that, even in the case of synthetic images of high quality, a naive approach may fail, essentially because of the errors due to the limitation of the image size. We take into account these errors as well as errors due to detection inaccuracy of the image segments, and provide a method efficient, even in the case of real complex scenes.			LUTTON, E (corresponding author), TELECOM PARIS,DEPT IMAGES,PARIS,FRANCE.		Lutton, Evelyne/K-7931-2015	Lutton, Evelyne/0000-0003-0889-4427				BADLER N, 1974, 2ND P INT JOINT C PA, P157; Ballard D.H., 1982, COMPUTER VISION; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; Hough P.V.C., 1962, U.S. Patent, Patent No. [3,069,654, 306965418]; IANNINO A, 1979, THESIS STEVENS I TEC; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; KENDER J, 1979, AUG P INT JOINT C AR, P475; LI H, CVPR 86, P640; LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3; LOPEZKRAHE J, 1987, MAI MARI 87 PAR, P42; LOPEZKRAHE J, 1988, C TIPI 88 TRAITEMENT, V5, P281; LUTTON E, 1990, OCT P SPIE VIS COMM, P420; LUTTON E, 1990, THESIS PARIS; MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9; Maitre H., 1985, Traitement du Signal, V2, P305; MAITRE H, 1986, IEEE T PATTERN ANAL, V8, P669, DOI 10.1109/TPAMI.1986.4767840; QUAN L, 1989, PATTERN RECOGN LETT, V9, P279, DOI 10.1016/0167-8655(89)90006-8; QUAN L, 1988, 9TH P INT C PATT REC, P872; SEDGWICK HA, 1987, 1ST P INT C COMP VIS, P223; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHAPIRO SD, 1979, IEEE T PATTERN ANAL, V1, P310, DOI 10.1109/TPAMI.1979.4766929; SVALBE ID, 1989, IEEE T PATTERN ANAL, V11, P941, DOI 10.1109/34.35497	24	90	110	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					430	438		10.1109/34.277598	http://dx.doi.org/10.1109/34.277598			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700011
J	BIGUN, J; DUBUF, JM				BIGUN, J; DUBUF, JM			N-FOLDED SYMMETRIES BY COMPLEX MOMENTS IN GABOR SPACE AND THEIR APPLICATION TO UNSUPERVISED TEXTURE SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						N-FOLDED SYMMETRIES; REAL GEOMETRIC MOMENTS; LEGENDRE MOMENTS; COMPLEX MOMENTS; ZERNIKE MOMENTS; GABOR SPECTRAL DECOMPOSITION; TEXTURE FEATURES; UNSUPERVISED SEGMENTATION	IMAGE SEGMENTATION; FREQUENCY; INVARIANTS; FILTERS; SIGNAL; PHASE	Complex moments of the Gabor power spectrum yield estimates of the N-folded symmetry of the local image content at different frequency scales, that is, they allow to detect linear, rectangular, hexagonal/triangular, and so on, structures with very fine to very coarse resolutions. Results from experiments on the unsupervised segmentation of real textures indicate their importance for image processing applications. Real geometric moments computed in Gabor space also provide for very powerful texture features, but lack the clear geometrical interpretation of complex moments.			BIGUN, J (corresponding author), SWISS FED INST TECHNOL,SIGNAL PROC LAB,EPEL ECUBLENS,CH-1015 LAUSANNE,SWITZERLAND.		du Buf, Hans/M-5125-2013	du Buf, Hans/0000-0002-4345-1237				ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; BASTIAANS MJ, 1981, OPT ENG, V20, P594, DOI 10.1117/12.7972768; BIGUN J, 1992, SIGNAL PROCESS, V29, P1, DOI 10.1016/0165-1684(92)90095-E; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; BIGUN J, 1990, COMPUT VISION GRAPH, V51, P166, DOI 10.1016/0734-189X(90)90029-U; BIGUN J, 1993, PATTERN RECOGN LETT, V14, P573, DOI 10.1016/0167-8655(93)90108-P; Bigun J., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop, P75; BIGUN J, 1992, PROGRESS IN IMAGE ANALYSIS AND PROCESSING II, P191; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; BIGUN J, 1994, VISUAL COMMUN IMAGE, V16, P80; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; Du Buf J. M. H., 1992, Spatial Vision, V6, P221, DOI 10.1163/156856892X00109; DUBUF JMH, 1991, SIGNAL PROCESS, V23, P227, DOI 10.1016/0165-1684(91)90002-Z; DUBUF JMH, 1990, PATTERN RECOGN, V23, P291, DOI 10.1016/0031-3203(90)90017-F; DUBUF JMH, 1990, SIGNAL PROCESS, V21, P221, DOI 10.1016/0165-1684(90)90088-G; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; FREEMAN MO, 1988, J OPT SOC AM A, V5, P1073, DOI 10.1364/JOSAA.5.001073; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; JAIN AK, 1990, NOV P INT C SYST MAN, P14; PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910; REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087; REED T, 1991, IMAGE VISION COMPUT, V9, P175, DOI 10.1016/0262-8856(91)90012-E; SPANN M, 1985, PATTERN RECOGN, V18, P257, DOI 10.1016/0031-3203(85)90051-2; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; WILSON R, 1988, IEEE T PATTERN ANAL, V10, P193, DOI 10.1109/34.3882; Zernike F, 1934, PHYSICA, V1, P689	32	90	95	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					80	87		10.1109/34.273714	http://dx.doi.org/10.1109/34.273714			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300008
J	LYVERS, EP; MITCHELL, OR				LYVERS, EP; MITCHELL, OR			PRECISION EDGE CONTRAST AND ORIENTATION ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus								CANNY J, 1983, THESIS MIT; Duda R.O., 1973, J ROYAL STAT SOC SER; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P121, DOI 10.1109/TPAMI.1985.4767628; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HARALICK RM, 1985, IEEE T PATTERN ANAL, V7, P127, DOI 10.1109/TPAMI.1985.4767629; HILDRETH EC, 1980, MIT TR579 ART INT LA; HUECKEL MH, 1974, J ACM, V21, P350, DOI 10.1145/321812.321830; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; IANNINO A, 1979, AUG P IEEE C PATT RE, P130; Kittler J, 1983, IMAGE VISION COMPUT, V1, P37, DOI DOI 10.1016/0262-8856(83)90006-9; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; Noble B, 1969, APPL LINEAR ALGEBRA; PAPOULIS A, 1965, PROBABILITY RANDOM V, P65; PRATT WK, 1978, DIGITAL IMAGE PROCES, P498; Prewitt J., 1970, PICTURE PROCESSING P, VVolume 10; REEVES AP, 1983, 1983 P IEEE COMP SOC; ZUNIGA OA, IN PRESS INTEGRATED	19	90	104	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					927	937		10.1109/34.9114	http://dx.doi.org/10.1109/34.9114			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100014
J	Keuper, M; Tang, SY; Andres, B; Brox, T; Schiele, B				Keuper, Margret; Tang, Siyu; Andres, Bjoern; Brox, Thomas; Schiele, Bernt			Motion Segmentation & Multiple Object Tracking by Correlation Co-Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory; Motion segmentation; Computer vision; Correlation; Object tracking; Clustering algorithms; Computer vision; video analysis; motion; segmentation; tracking; correlation clustering		Models for computer vision are commonly defined either w.r.t. low-level concepts such as pixels that are to be grouped, or w.r.t. high-level concepts such as semantic objects that are to be detected and tracked. Combining bottom-up grouping with top-down detection and tracking, although highly desirable, is a challenging problem. We state this joint problem as a co-clustering problem that is principled and tractable by existing algorithms. We demonstrate the effectiveness of this approach by combining bottom-up motion segmentation by grouping of point trajectories with high-level multiple object tracking by clustering of bounding boxes. We show that solving the joint problem is beneficial at the low-level, in terms of the FBMS59 motion segmentation benchmark, and at the high-level, in terms of the Multiple Object Tracking benchmarks MOT15, MOT16, and the MOT17 challenge, and is state-of-the-art in some metrics.	[Keuper, Margret] Univ Mannheim, Data & Web Sci Grp, D-68131 Mannheim, Germany; [Tang, Siyu] Max Planck Inst Intelligent Syst, Dept Perceiving Syst, D-72076 Tubingen, Germany; [Tang, Siyu; Andres, Bjoern] Univ Tubingen, D-72074 Tubingen, Germany; [Andres, Bjoern; Schiele, Bernt] Max Planck Inst Informat, D-66123 Saarbrucken, Germany; [Andres, Bjoern] Bosch Ctr AI, D-71272 Renningen, Germany; [Brox, Thomas] Univ Freiburg, Dept Comp Sci, D-79085 Freiburg, Germany	University of Mannheim; Max Planck Society; Eberhard Karls University of Tubingen; Max Planck Society; University of Freiburg	Keuper, M (corresponding author), Univ Mannheim, Data & Web Sci Grp, D-68131 Mannheim, Germany.	keuper@informatik.uni-freiburg.de; stang@tuebingen.mpg.de; bjoern@andres.sc; brox@cs.uni-freiburg.de; schiele@mpi-inf.mpg.de		Keuper, Margret/0000-0002-8437-7993	ERC Starting Grant VideoLearn; DFG [KE 2264/1-1]	ERC Starting Grant VideoLearn; DFG(German Research Foundation (DFG))	Margret Keuper and Thomas Brox acknowledge funding by the ERC Starting Grant VideoLearn. Margret Keuper acknowledges funding by the DFG project KE 2264/1-1.	Andres B, 2012, LECT NOTES COMPUT SC, V7574, P778, DOI 10.1007/978-3-642-33712-3_56; Andres B, 2011, IEEE I CONF COMP VIS, P2611, DOI 10.1109/ICCV.2011.6126550; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], 2014, AS C COMP VIS; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; Beier T, 2016, LECT NOTES COMPUT SC, V9906, P715, DOI 10.1007/978-3-319-46475-6_44; Beier T, 2014, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2014.17; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65; Bideau P, 2016, LECT NOTES COMPUT SC, V9912, P433, DOI 10.1007/978-3-319-46484-8_26; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chang J, 2013, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2013.267; Chen L.-C., 2015, COMPUT SCI; Chen L, 2017, IEEE IMAGE PROC, P645; Cheriyadat AM, 2009, IEEE I CONF COMP VIS, P865, DOI 10.1109/ICCV.2009.5459311; Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347; CHOPRA S, 1993, MATH PROGRAM, V59, P87, DOI 10.1007/BF01581239; Cremers D., 2008, P IEEE C COMP VIS PA, P1; Demaine ED, 2006, THEOR COMPUT SCI, V361, P172, DOI 10.1016/j.tcs.2006.05.008; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fragkiadaki K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2073, DOI 10.1109/CVPR.2011.5995366; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fragkiadaki K, 2012, LECT NOTES COMPUT SC, V7576, P552, DOI 10.1007/978-3-642-33715-4_40; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Henschel R, 2014, LECT NOTES COMPUT SC, V8753, P265, DOI [10.1007/978-3-319-11752_2_1, 10.1007/978-3-319-11752-2_21]; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Ji P, 2014, LECT NOTES COMPUT SC, V8694, P204, DOI 10.1007/978-3-319-10599-4_14; Kappes JH, 2016, COMPUT VIS IMAGE UND, V143, P104, DOI 10.1016/j.cviu.2015.11.005; Keuper M, 2015, IEEE I CONF COMP VIS, P1751, DOI 10.1109/ICCV.2015.204; Keuper M, 2017, IEEE I CONF COMP VIS, P4252, DOI 10.1109/ICCV.2017.455; Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374; Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095; Kumar R, 2015, LECT NOTES COMPUT SC, V9006, P445, DOI 10.1007/978-3-319-16817-3_29; Levinkov E, 2017, PROC CVPR IEEE, P1904, DOI 10.1109/CVPR.2017.206; Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588; Li ZW, 2013, IEEE I CONF COMP VIS, P1369, DOI 10.1109/ICCV.2013.173; Milan A., 2016, ARXIV160300831CS; Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178; Muller S, 2016, LECT NOTES COMPUT SC, V9796, P117, DOI 10.1007/978-3-319-45886-1_10; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Rahmati H, 2014, LECT NOTES COMPUT SC, V8753, P159, DOI 10.1007/978-3-319-11752-2_13; Rematas K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCV.2011.6126455; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rosenhahn, 2017, CORR; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Shi F, 2013, IEEE I CONF COMP VIS, P3088, DOI 10.1109/ICCV.2013.383; Swoboda P, 2017, PROC CVPR IEEE, P4990, DOI 10.1109/CVPR.2017.530; Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394; Tang SY, 2015, PROC CVPR IEEE, P5033, DOI 10.1109/CVPR.2015.7299138; Tesfaye YT, 2016, IET COMPUT VIS, V10, P289, DOI 10.1049/iet-cvi.2015.0297; Wang XC, 2014, LECT NOTES COMPUT SC, V8689, P17, DOI 10.1007/978-3-319-10590-1_2; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174; Wojek C, 2010, LECT NOTES COMPUT SC, V6314, P467, DOI 10.1007/978-3-642-15561-1_34; Yarkony J, 2012, LECT NOTES COMPUT SC, V7577, P568, DOI 10.1007/978-3-642-33783-3_41; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460	79	89	91	3	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					140	153		10.1109/TPAMI.2018.2876253	http://dx.doi.org/10.1109/TPAMI.2018.2876253			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30334779				2022-12-18	WOS:000502294300011
J	Carneiro, G; Nascimento, JC				Carneiro, Gustavo; Nascimento, Jacinto C.			Combining Multiple Dynamic Models and Deep Learning Architectures for Tracking the Left Ventricle Endocardium in Ultrasound Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Left ventricle segmentation; deep belief networks; particle filters; dynamical model; discriminative classifiers	BOUNDARY DETECTION ALGORITHMS; LEVEL-SET; CARDIAC MR; ECHOCARDIOGRAPHIC SEQUENCES; AUTOMATIC SEGMENTATION; MAXIMUM-LIKELIHOOD; TIME SEGMENTATION; MEDICAL IMAGES; SHAPE; FRAMEWORK	We present a new statistical pattern recognition approach for the problem of left ventricle endocardium tracking in ultrasound data. The problem is formulated as a sequential importance resampling algorithm such that the expected segmentation of the current time step is estimated based on the appearance, shape, and motion models that take into account all previous and current images and previous segmentation contours produced by the method. The new appearance and shape models decouple the affine and nonrigid segmentations of the left ventricle to reduce the running time complexity. The proposed motion model combines the systole and diastole motion patterns and an observation distribution built by a deep neural network. The functionality of our approach is evaluated using a dataset of diseased cases containing 16 sequences and another dataset of normal cases comprised of four sequences, where both sets present long axis views of the left ventricle. Using a training set comprised of diseased and healthy cases, we show that our approach produces more accurate results than current state-of-the-art endocardium tracking methods in two test sequences from healthy subjects. Using three test sequences containing different types of cardiopathies, we show that our method correlates well with interuser statistics produced by four cardiologists.	[Carneiro, Gustavo] Univ Adelaide, Sch Comp Sci, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia; [Nascimento, Jacinto C.] Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal	University of Adelaide; Universidade de Lisboa; Instituto Superior Tecnico	Carneiro, G (corresponding author), Univ Adelaide, Sch Comp Sci, Australian Ctr Visual Technol, North Terrace,Inkarni Wardli Bldg, Adelaide, SA 5005, Australia.	gustavo.carneiro@adelaide.edu.au; jan@isr.ist.utl.pt	Nascimento, Jacinto/B-6128-2009	Nascimento, Jacinto/0000-0001-7468-5127; Carneiro, Gustavo/0000-0002-5571-6220	FCT (ISR/IST) through the PIDDAC Program funds; HEARTRACK [PTDC/EEA-CRO/103462/2008]; EU Project IMASEG3D [PIIF-GA-2009-236173];  [PTDC/EEA-CRO/098550/2008]	FCT (ISR/IST) through the PIDDAC Program funds; HEARTRACK; EU Project IMASEG3D; 	This work was supported by project the FCT (ISR/IST plurianual funding) through the PIDDAC Program funds and by project PTDC/EEA-CRO/098550/2008. This work was also supported by project "HEARTRACK"-PTDC/EEA-CRO/103462/2008. This work was partially funded by EU Project IMASEG3D (PIIF-GA-2009-236173).	Alberola-Lopez C, 2004, IEEE T MED IMAGING, V23, P658, DOI 10.1109/TMI.2004.826358; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Bardinet E, 1996, Med Image Anal, V1, P129, DOI 10.1016/S1361-8415(96)80009-0; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bernard O., 2007, P IEEE INT C IM PROC; Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343; BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8; Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427; Boyd S, 2004, CONVEX OPTIMIZATION; Carneiro G., 2010, P IEEE C COMP VIS PA; Carneiro G, 2008, IEEE T MED IMAGING, V27, P1342, DOI 10.1109/TMI.2008.928917; Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273; Carneiro G, 2010, I S BIOMED IMAGING, P1085, DOI 10.1109/ISBI.2010.5490181; CARREIRAPERPINA.MA, 2005, P WORKSH ART INT STA; Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755; Chalana V, 1996, IEEE T MED IMAGING, V15, P290, DOI 10.1109/42.500138; Chen T, 2008, IEEE T MED IMAGING, V27, P1084, DOI 10.1109/TMI.2008.918327; Comaniciu D, 2004, IEEE T MED IMAGING, V23, P849, DOI 10.1109/TMI.2004.827967; Cootes TF, 1999, LECT NOTES COMPUT SC, V1613, P322; Corsi C, 2002, IEEE T MED IMAGING, V21, P1202, DOI 10.1109/TMI.2002.804418; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Debreuve E, 2001, IEEE T MED IMAGING, V20, P643, DOI 10.1109/42.932748; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dias JMB, 1996, IEEE T MED IMAGING, V15, P25, DOI 10.1109/42.481438; Duan Q, 2010, COMPUT METH PROG BIO, V98, P223, DOI 10.1016/j.cmpb.2009.09.001; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fisher RA., 1948, AM STAT, V2, P30, DOI DOI 10.2307/2681650; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDLAND N, 1989, IEEE T MED IMAGING, V8, P344, DOI 10.1109/42.41487; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; GEORGESCU B, 2005, P IEEE C COMP VIS PA; Hammoude A., 1988, THESIS U WASHINGTON; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jacob G, 2002, IEEE T MED IMAGING, V21, P226, DOI 10.1109/42.996341; Jolly MP, 2009, LECT NOTES COMPUT SC, V5762, P910, DOI 10.1007/978-3-642-04271-3_110; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lin N, 2003, MED IMAGE ANAL, V7, P529, DOI 10.1016/S1361-8415(03)00035-5; Lorenzo-Valdes M, 2004, MED IMAGE ANAL, V8, P255, DOI 10.1016/j.media.2004.06.005; Lynch M, 2008, IEEE T MED IMAGING, V27, P195, DOI 10.1109/TMI.2007.904681; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; Mignotte M, 2001, PATTERN ANAL APPL, V4, P256, DOI 10.1007/PL00010988; Mikic I, 1998, IEEE T MED IMAGING, V17, P274, DOI 10.1109/42.700739; Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294; Montagnat J, 2005, MED IMAGE ANAL, V9, P87, DOI 10.1016/j.media.2004.06.025; Montagnat J, 2003, PATTERN RECOGN LETT, V24, P815, DOI 10.1016/S0167-8655(02)00184-8; Nascimento JC, 2008, IEEE T IMAGE PROCESS, V17, P392, DOI 10.1109/TIP.2007.915552; Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092; Okuma K., 2004, P EUR C COMP VIS; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Qian Z, 2006, LECT NOTES COMPUT SC, V4190, P636; Reiber JHC, 1996, INT J CARDIAC IMAG, V12, P69, DOI 10.1007/BF01880736; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALAKHUTDINOV R, 2007, AI STAT; SANDLER H, 1968, AM HEART J, V75, P325, DOI 10.1016/0002-8703(68)90089-6; Sarti A, 2005, IEEE T ULTRASON FERR, V52, P947, DOI 10.1109/TUFFC.2005.1504017; Senegas J, 2004, LECT NOTES COMPUT SC, V3117, P157; Setarehdan SK, 1999, IEEE T BIO-MED ENG, V46, P1364, DOI 10.1109/10.797997; Sun W, 2005, LECT NOTES COMPUT SC, V3565, P553; Sun W, 2008, IEEE T IMAGE PROCESS, V17, P2186, DOI 10.1109/TIP.2008.2004638; Terzopoulos D., 1993, TRACKING KALMAN SNAK; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Weng J, 1997, IEEE T MED IMAGING, V16, P378, DOI 10.1109/42.611346; Yang L., 2008, P IEEE C COMP VIS PA; Zagrodsky V, 2005, IEEE T MED IMAGING, V24, P1089, DOI 10.1109/TMI.2005.852057; Zheng YF, 2008, IEEE T MED IMAGING, V27, P1668, DOI 10.1109/TMI.2008.2004421; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115, DOI 10.1109/TPAMI.2005.3; Zhu X.J, 2005, SEMISUPERVISED LEARN; Zhu Y, 2010, IEEE T MED IMAGING, V29, P669, DOI 10.1109/TMI.2009.2031063	73	89	92	1	121	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2592	2607		10.1109/TPAMI.2013.96	http://dx.doi.org/10.1109/TPAMI.2013.96			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051722	Green Published, Green Submitted			2022-12-18	WOS:000324830900003
J	Goldman, DB				Goldman, Dan B.			Vignette and Exposure Calibration and Compensation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera calibration; photometry	ALGORITHM	We discuss calibration and removal of "vignetting" (radial falloff) and exposure (gain) variations from sequences of images. Even when the response curve is known, spatially varying ambiguities prevent us from recovering the vignetting, exposure, and scene radiances uniquely. However, the vignetting and exposure variations can nonetheless be removed from the images without resolving these ambiguities or the previously known scale and gamma ambiguities. Applications include panoramic image mosaics, photometry for material reconstruction, image-based rendering, and preprocessing for correlation-based vision algorithms.	Adobe Syst Inc, Seattle, WA 98103 USA	Adobe Systems Inc.	Goldman, DB (corresponding author), Adobe Syst Inc, 801 N 34th St, Seattle, WA 98103 USA.	dgoldman@adobe.com			Industrial Light and Magic, a division of Lucasfilm; US National Science Foundation (NSF) [IIS-0413198]; Animation Research Labs	Industrial Light and Magic, a division of Lucasfilm; US National Science Foundation (NSF)(National Science Foundation (NSF)); Animation Research Labs	The author would like to thank Jiun-Hung Chen for performing ground truth data acquisition, Adrien Treuille for suggesting the use of ODEs, Paul van Walree for providing his photography and diagrams in Section 1, Seon Joo Kim, Aseem Agarwala, Matthew Brown, Noah Snavely, and Yasutaka Furukawa for the use of and assistance with their research software, and Steve Seitz and Brian Curless for invaluable advice in the preparation of this paper. Special thanks to Steve Sullivan and Industrial Light and Magic, a division of Lucasfilm, which sponsored some preliminary studies of vignette behavior. This work was supported in part by US National Science Foundation (NSF) grant IIS-0413198 and the Animation Research Labs.	Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Altunbasak Y, 2003, IEEE T IMAGE PROCESS, V12, P395, DOI 10.1109/TIP.2003.809012; [Anonymous], 2004, P 3 INT C COMPUTER G; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Asada N., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P186, DOI 10.1109/ICPR.1996.546016; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Candocia FM, 2003, IEEE T IMAGE PROCESS, V12, P409, DOI 10.1109/TIP.2003.811497; Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Goldman DB, 2005, IEEE I CONF COMP VIS, P899; Grossberg MD, 2003, PROC CVPR IEEE, P602; HAPKE B, 1971, PHYS ASTRONOMY MOON; Hartley R., 2004, ROBOTICA; *HASS, 2008, HASS SPAC; Jensen HW, 2001, COMP GRAPH, P399, DOI 10.1145/383259.383306; Jia JY, 2005, IEEE T PATTERN ANAL, V27, P36, DOI 10.1109/TPAMI.2005.20; Kang S.B., 2000, LNCS, V1843, P640; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Kuthirummal S, 2008, LECT NOTES COMPUT SC, V5305, P74, DOI 10.1007/978-3-540-88693-8_6; LEVIN A, 2004, P ECCV, V4, P377; Litvinov A, 2005, PROC CVPR IEEE, P52; Litvinov A, 2005, J OPT SOC AM A, V22, P839, DOI 10.1364/JOSAA.22.000839; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manfroid J, 1996, ASTRON ASTROPHYS SUP, V118, P391, DOI 10.1051/aas:1996206; Mitsunaga T., 1999, CVPR, V1, P1374; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Ray S. F., 2002, APPL PHOTOGRAPHIC OP, DOI 10.4324/9780080499253; Scheidlinger S, 2003, INT J GROUP PSYCHOTH, V53, P245, DOI 10.1521/ijgp.53.2.245.42817; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; TEAGUE K, 2004, PROJECT APOLLO IMAGE; VANWALREE P, 2004, VIGNETTING; *WIK, 2005, VIGN; Yu WP, 2004, INT C PATT RECOG, P666, DOI 10.1109/ICPR.2004.1334617; ZHEN T, 2008, PROGR 2008 ISECS INT, V1, P8, DOI DOI 10.1109/CCCM.2008.85; Zheng Y., 2006, P IEEE C COMP VIS PA, P461	36	89	100	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2276	2288		10.1109/TPAMI.2010.55	http://dx.doi.org/10.1109/TPAMI.2010.55			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20975123				2022-12-18	WOS:000283558700012
J	Baek, J; McLachlan, GJ; Flack, LK				Baek, Jangsun; McLachlan, Geoffrey J.; Flack, Lloyd K.			Mixtures of Factor Analyzers with Common Factor Loadings: Applications to the Clustering and Visualization of High-Dimensional Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Normal mixture models; mixtures of factor analyzers; common factor loadings; model-based clustering	MODEL	Mixtures of factor analyzers enable model-based density estimation to be undertaken for high-dimensional data, where the number of observations n is not very large relative to their dimension p. In practice, there is often the need to further reduce the number of parameters in the specification of the component-covariance matrices. To this end, we propose the use of common component-factor loadings, which considerably reduces further the number of parameters. Moreover, it allows the data to be displayed in low-dimensional plots.	[Baek, Jangsun] Chonnam Natl Univ, Dept Stat, Kwangju 500757, South Korea; [McLachlan, Geoffrey J.; Flack, Lloyd K.] Univ Queensland, Dept Math, Brisbane, Qld 4072, Australia; [McLachlan, Geoffrey J.; Flack, Lloyd K.] Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia	Chonnam National University; University of Queensland; University of Queensland	Baek, J (corresponding author), Chonnam Natl Univ, Dept Stat, Kwangju 500757, South Korea.	jbaek@chonnam.ac.kr; gjm@maths.uq.edu.au; lkflack@pacific.net.au	McLachlan, Geoffrey J/A-1491-2008	McLachlan, Geoffrey J/0000-0002-5921-3145	Korean Research Foundation; Korean Government (MOEHRD) [KRF-2007-521-C00048]; Australian Research Council	Korean Research Foundation(National Research Foundation of Korea); Korean Government (MOEHRD)(Ministry of Education & Human Resources Development (MOEHRD), Republic of KoreaKorean Government); Australian Research Council(Australian Research Council)	The authors would like to thank the Associate Editor and the anonymous reviewers for their helpful comments in improving the manuscript. The work of J. Baek was supported by a grant from the Korean Research Foundation funded by the Korean Government (MOEHRD, Basic Research Promotion Fund, KRF-2007-521-C00048). The work of G. J. McLachlan was supported by the Australian Research Council. He also wishes to thank the Isaac Newton Institute for Mathematical Sciences for support to participate in its research program on Statistical Theory and Methods for Complex, High-Dimensional Data.	AXELROD S, 2002, P INT C SPOK LANG PR; BAEK J, 2008, PREPRINT SERIES I NE; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Galimberti G, 2008, COMPSTAT 2008: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P373, DOI 10.1007/978-3-7908-2084-3_31; GOPINATH R, 1998, P INT C SPEECH LANG, P397; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jaccard P., 1901, B SOC VAUD SCI N, V37, P241, DOI DOI 10.5169/SEALS-266440; Kumar N., 1997, THESIS J HOPKINS U; Mclachlan G., 2000, WILEY SER PROB STAT; McLachlan GJ, 2007, COMPUT STAT DATA AN, V51, P5327, DOI 10.1016/j.csda.2006.09.015; McLachlan G. J., 2008, EM ALGORITHM EXTENSI; McLachlan GJ, 2003, COMPUT STAT DATA AN, V41, P379, DOI 10.1016/S0167-9473(02)00183-4; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; OLSEN P, 2002, P INT C AC SPEECH SI, V1, P945; Rosti AVI, 2004, COMPUT SPEECH LANG, V18, P181, DOI 10.1016/j.csl.2003.09.004; Sanguinetti G, 2008, IEEE T PATTERN ANAL, V30, P535, DOI 10.1109/TPAMI.2007.70819; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Smyth C, 2006, PATTERN RECOGN, V39, P424, DOI 10.1016/j.patcog.2005.09.003; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Yoshida R, 2004, 2004 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS, P161; Yoshida R, 2006, BIOINFORMATICS, V22, P1538, DOI 10.1093/bioinformatics/btl129	25	89	89	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1298	1309		10.1109/TPAMI.2009.149	http://dx.doi.org/10.1109/TPAMI.2009.149			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489231				2022-12-18	WOS:000277649100011
J	Rahmani, R; Goldman, SA; Zhang, H; Cholleti, SR; Fritts, JE				Rahmani, Rouhollah; Goldman, Sally A.; Zhang, Hui; Cholleti, Sharath R.; Fritts, Jason E.			Localized content-based image retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; content-based image retrieval; multiple-instance learning; salient points		We define a localized content-based image retrieval as a CBIR task where the user is only interested in a portion of the image, and the rest of the image is irrelevant. In this paper, we present a localized CBIR system, ACCIO!, that uses labeled images in conjunction with a multiple-instance learning algorithm to first identify the desired object and weight the features accordingly, and then to rank images in the database using a similarity measure that is based upon only the relevant portions of the image. A challenge for localized CBIR is how to represent the image to capture the content. We present and compare two novel image representations, which extend traditional segmentation-based and salient point-based techniques, respectively, to capture content in a localized CBIR setting.	[Goldman, Sally A.; Zhang, Hui; Cholleti, Sharath R.] Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63130 USA; [Fritts, Jason E.] St Louis Univ, Dept Math & Comp Sci, St Louis, MO 63103 USA	Washington University (WUSTL); Saint Louis University	Rahmani, R (corresponding author), 1 Microsoft Way, Redmond, WA 98085 USA.	rouholr@microsoft.com; sg@wustl.edu; huizhan@wustl.edu; cholleti@wustl.edu; jfritts@slu.edu			US National Science Foundation [0329241]	US National Science Foundation(National Science Foundation (NSF))	The authors would like to thank John Krettek, Ibrahim Noorzaie, and Ian Bushner for all of their valuable feedback and ideas. This material is based upon work supported by the US National Science Foundation under Grant 0329241. This work was done while S. A. Goldman, H. Zhang, and S. R. Cholleti were with the Department of Computer Science and Engineering, Washington University in St. Louis. S. A. Goldman is currently on leave at Google, Inc.	Andrews S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P943; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bi JB, 2005, PROC CVPR IEEE, P1121; Chen YX, 2004, J MACH LEARN RES, V5, P913; Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P361, DOI 10.1109/ICPR.1996.546971; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DIETEL P, 1897, NATURL PFLANZ, V1, P2; DUYGULU P, 2002, P 7 EUR C COMP VIS E; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forsyth David A, 2012, COMPUTER VISION MODE; GEVERS T, 2004, EMERGING TOPICS COMP; HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747; Huang Xin, 2002, J Exp Ther Oncol, V2, P100, DOI 10.1046/j.1359-4117.2002.01016.x; Ke Y, 2004, PROC CVPR IEEE, P506; Ledwich L., 2004, P AUSTR C ROB AUT AC; LEE HK, 2002, P 3 IEEE PAC RIM C M, P209; Long F., 2003, MULTIMEDIA INFORM RE; LOUPIAS E, 2008, SALIENT POINTS DETEC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maron O, 1998, ADV NEUR IN, V10, P570; Maron O., 1998, P 15 INT C MACH LEAR, P341; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; Rahmani Rouhollah, 2005, P 7 ACM SIGMM INT WO, P227, DOI DOI 10.1145/1101826.1101863; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Tian Q, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P746, DOI 10.1109/ICIP.2000.899562; Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Wang JL, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P1256; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; WANG JZ, 2000, PROTEIN PROTOCOLS HD, P147; WOLF C, 2000, P 15 IEEE INT C PATT, V4, P4234; Yang C., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P233, DOI 10.1109/ICDE.2000.839416; ZHANG H, 2005, IMPROVED FINE GRAIN; ZHANG H, 2005, P IS T SPIES 16 ANN, P957; Zhang LB, 2006, J SEISM EXPLOR, V14, P287; Zhang Q, 2002, ADV NEUR IN, V14, P1073; ZHANG Q, 2002, P 19 INT C MACH LEAR, P682; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2837, P492	39	89	90	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1902	1912		10.1109/TPAMI.2008.112	http://dx.doi.org/10.1109/TPAMI.2008.112			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787239				2022-12-18	WOS:000259110000004
J	Greenspan, H; Goldberger, J; Mayer, A				Greenspan, H; Goldberger, J; Mayer, A			Probabilistic space-time video modeling via piecewise GMM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video representation; video segmentation; detection of events in video; Gaussian mixture model	IMAGE; SEGMENTATION; FRAMEWORK; TOOLS	In this paper, we describe a statistical video representation and modeling scheme. Video representation schemes are needed to segment a video stream into meaningful video-objects, useful for later indexing and retrieval applications. In the proposed methodology, unsupervised clustering via Gaussian mixture modeling extracts coherent space-time regions in feature space, and corresponding coherent segments (video-regions) in the video content. A key feature of the system is the analysis of video input as a single entity as opposed to a sequence of separate frames. Space and time are treated uniformly. The probabilistic space-time video representation scheme is extended to a piecewise GMM framework in which a succession of GMMs are extracted for the video sequence, instead of a single global model for the entire sequence. The piecewise GMM framework allows for the analysis of extended video sequences and the description of nonlinear, nonconvex motion patterns. The extracted space-time regions allow for the detection and recognition of video events. Results of segmenting video content into static versus dynamic video regions and video content editing are presented.	Tel Aviv Univ, Dept Biomed Engn, IL-69978 Ramat Aviv, Israel; Weizmann Inst Sci, IL-76100 Rehovot, Israel; Image Id Ltd, IL-46432 Herzla, Israel	Tel Aviv University; Weizmann Institute of Science	Greenspan, H (corresponding author), Tel Aviv Univ, Dept Biomed Engn, IL-69978 Ramat Aviv, Israel.	hayit@eng.tau.ac.il; facob@wisdom.weizmann.ac.il; a_mayer@netvision.net.il						Ahanger G, 1996, J VIS COMMUN IMAGE R, V7, P28, DOI 10.1006/jvci.1996.0004; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BREGLER C, 1997, P IEEE C COMP VIS PA; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Castagno R, 1998, IEEE T CIRC SYST VID, V8, P562, DOI 10.1109/76.718503; Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DeMenthon D., 2002, P STAT METH VID PROC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508; DUC B, 1995, P 6 INT C COMP AN IM, P238; Duda R.O., 1973, J ROYAL STAT SOC SER; Fowlkes C, 2001, PROC CVPR IEEE, P231; Greenberg L, 2002, AMBUL PEDIATR, V2, P4, DOI 10.1367/1539-4409(2002)002<0004:COTBRP>2.0.CO;2; Greenspan H, 2001, COMPUT VIS IMAGE UND, V84, P384, DOI 10.1006/cviu.2001.0946; Hampapur A, 1997, P SOC PHOTO-OPT INS, V3022, P188, DOI 10.1117/12.263407; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355; Khan S, 2001, PROC CVPR IEEE, P746; Kobla V, 1996, P SOC PHOTO-OPT INS, V2916, P78, DOI 10.1117/12.257312; MEGRET R, 2002, CSTR4403 LAMP U MAR; Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601; Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; WANG JYA, 1994, P SOC PHOTO-OPT INS, V2182, P120, DOI 10.1117/12.174204; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; ZHANG H, 1994, P INT C MULT COMP SY, P45; ZHANG HJ, 1994, P SOC PHOTO-OPT INS, V2185, P140, DOI 10.1117/12.171771; [No title captured]; [No title captured]	30	89	100	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					384	396		10.1109/TPAMI.2004.1262334	http://dx.doi.org/10.1109/TPAMI.2004.1262334			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376884				2022-12-18	WOS:000188949400008
J	Dori, D; Liu, WY				Dori, D; Liu, WY			Sparse pixel vectorization: An algorithm and its performance evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vectorization; line tracking; sparse pixel vectorization; polygonal approximation; performance evaluation	ENGINEERING DRAWINGS; SYSTEM; CONVERSION	Accurate and efficient vectorization of line drawings is essential for their higher level processing. We present a thinningless Sparse Pixel Vectorization (SPV) algorithm. Rather than visiting all the points along the wire's black area, SPV sparsely visits selected medial axis points. The result is a crude polyline, which is refined through polygonal approximation by removing redundant points. Due to the sparseness of pixel examination and the use of a specialized data structure, SPV is both time efficient and accurate, as evaluated by our proposed performance evaluation criteria.	Technion Israel Inst Technol, Fac Ind Engn & Management, IL-32000 Haifa, Israel; Microsoft Res, Sigma Ctr, Beijing 100080, Peoples R China	Technion Israel Institute of Technology; Microsoft	Dori, D (corresponding author), Technion Israel Inst Technol, Fac Ind Engn & Management, IL-32000 Haifa, Israel.		LIU, Wenyin/C-1345-2012					BOATTO L, 1992, COMPUTER, V25, P25, DOI 10.1109/2.144437; CHAI I, 1992, VISUAL FORM, P127; CHHABRA A, WEB PAGES 2 INT GRAP; Chhabra AK, 1998, LECT NOTES COMPUT SC, V1389, P390; Dori D, 1997, ADV ENG SOFTW, V28, P11, DOI 10.1016/S0965-9978(96)00035-X; Dori D., 1993, Machine Vision and Applications, V6, P69, DOI 10.1007/BF01211932; FAHN CS, 1988, COMPUT VISION GRAPH, V44, P119, DOI 10.1016/S0734-189X(88)80001-X; FILIPSKI AJ, 1992, P IEEE, V80, P1195, DOI 10.1109/5.156479; HORI O, 1993, P ICDAR93 TSUK JAP, P623; Hori O., 1996, LECT NOTES COMPUTER, V1072, P57; JIMENEZ J, 1982, IBM J RES DEV, V26, P724, DOI 10.1147/rd.266.0724; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870; KONG B, 1996, LECT NOTES COMPUTER, V1072, P270; LIN XG, 1985, COMPUT VISION GRAPH, V30, P84, DOI 10.1016/0734-189X(85)90020-9; LIU W, 1996, P 13 INT C PATT REC, V3, P808; LIU W, 1995, P 1 INT WORKSH GRAPH, P53; Liu WY, 1997, MACH VISION APPL, V9, P240, DOI 10.1007/s001380050045; Liu WY, 1998, IEEE T PATTERN ANAL, V20, P424, DOI 10.1109/34.677280; Monagan G., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P623, DOI 10.1109/ICDAR.1993.395659; NAGASAMY V, 1990, COMPUT VISION GRAPH, V49, P379, DOI 10.1016/0734-189X(90)90111-8; Phillips IT, 1998, LECT NOTES COMPUT SC, V1389, P372; ROOSLI M, 1995, P GREC95 U PARK PENN, P44; SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X; SMITH RW, 1987, PATTERN RECOGN, V20, P7, DOI 10.1016/0031-3203(87)90013-6; Tamura H., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P715; VAXIVIERE P, 1992, COMPUTER, V25, P46, DOI 10.1109/2.144439; Yoo JY, 1998, LECT NOTES COMPUT SC, V1389, P139	27	89	104	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					202	215		10.1109/34.754586	http://dx.doi.org/10.1109/34.754586			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000002
J	FLEET, DJ; LANGLEY, K				FLEET, DJ; LANGLEY, K			RECURSIVE FILTERS FOR OPTICAL-FLOW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter							VELOCITY	Working toward efficient (real-time) implementations of optical flow methods, we have applied simple recursive filters to achieve temporal smoothing and differentiation of image intensity, and to compute 2d now from component velocity constraints using spatiotemporal least-squares minimization. Accuracy in simulation is similar to that obtained in the study by Barren et al. [3],while requiring much less storage, less computation, and shorter delays.	UCL, DEPT PSYCHOL, LONDON, ENGLAND	University of London; University College London	FLEET, DJ (corresponding author), QUEENS UNIV, DEPT COMP & INFORMAT SCI, KINGSTON, ON K7L 3N6, CANADA.			/0000-0003-0734-7114				Adelson E. H., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P151; Barman H., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P44, DOI 10.1109/WVM.1991.212789; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, P EUR C COMP VIS, P237; BLACK MJ, 1991, JUN P COMP VIS PATT, P296; BRACEWELL RN, 1978, FOURIER TRANSFORM IT; FLEET DJ, 1989, IEEE T PATTERN ANAL, V11, P315, DOI 10.1109/34.21800; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Fleet DJ, 1992, MEASUREMENT IMAGE VE; GIROSI F, 1989, MAR P IEEE WORKSH VI, P116; HAGLUND L., 1992, ADAPTIVE MULTIDIMENS; Heeger D. J., 1988, INT J COMPUT VISION, V1, P279; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jackson L. B., 1989, DIGITAL FILTERS SIGN; Jepson A. D., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P124, DOI 10.1109/WVM.1991.212779; KARABASSIS E, 1993, UNPUB CVGIP; LANGLEY K, 1992, ISRAELI C VISION AI, P255; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2, DOI 10.1109/TPAMI.1982.4767188; SIMONCELLI EP, 1991, IEEE C COMP VIS PATT, P310, DOI 10.1109/CVPR.1991.139707; Singh A., 1992, Journal of Visual Communication and Image Representation, V3, P39, DOI 10.1016/1047-3203(92)90029-S; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895	24	89	98	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					61	67		10.1109/34.368151	http://dx.doi.org/10.1109/34.368151			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400007
J	PITAS, I; VENETSANOPOULOS, AN				PITAS, I; VENETSANOPOULOS, AN			MORPHOLOGICAL SHAPE DECOMPOSITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TORONTO,DEPT ELECT ENGN,TORONTO M5S 1A4,ONTARIO,CANADA	University of Toronto	PITAS, I (corresponding author), UNIV THESSALONIKI,DEPT ELECT ENGN,GR-54006 SALONIKA,GREECE.							HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HUANG TS, 1977, IEEE T COMMUN, V25, P1406, DOI 10.1109/TCOM.1977.1093775; LEVINE MD, 1983, COMPUT GRAPHICS IMAG, V21, P185; LVEINE MD, 1985, VISION MAN MACHINE; MARAGOS P, 1985, THESIS GEORG I TECHN; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PAVLIDIS T, 1972, FRONTIERS PATTERN RE; Pavlidis T., 1977, STRUCTURAL PATTERN R; PITAS I, 1989, NONLINEAR DIGITAL FI; PITAS I, UNPUB IEEE T ACOUST; PITAS I, IN PRESS COMPUT VISI; ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1; Serra J, 1982, IMAGE ANAL MATH MORP; Serra J, 1988, IMAGE ANAL MATH MORP; STERNBERG SR, 1979, 3RD P INT IEEE COMPS, P712; ZHAO Y, 1989, P INT C ACOUST SPEEC	18	89	92	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					38	45		10.1109/34.41382	http://dx.doi.org/10.1109/34.41382			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700004
J	CARLOTTO, MJ				CARLOTTO, MJ			HISTOGRAM ANALYSIS USING A SCALE-SPACE APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											CARLOTTO, MJ (corresponding author), ANAL SCI CORP,READING,MA 01867, USA.			cde, esperanza/0000-0001-8788-7609				ASADA H, 1984, MIT AI758 MEM; BABAUD J, 1983, 645 FAIRCH TECH REP; BHATTACHARYA C, 1967, BIOMETRICS, V23; Duda R.O., 1973, J ROYAL STAT SOC SER; EISENBERGER I, 1964, TECHNOMETRICS, V6; FERRANTE R, 1984, 1ST P C ART INT APPL; Marr D., 1980, P ROY SOC LONDON, V207; PEARSON K, 1894, PHIL T ROY SOC A, V185; Redner R., 1984, SIAM REV, V26; SAMMON J, 1962, PATTERN RECOGNITION, V10; STANSFIELD JL, 1980, MIT AI601 MEM; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1983, MIT AI730 MEM; YUILLE AL, 1983, MIT AI722 MEM	14	89	98	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					121	129		10.1109/TPAMI.1987.4767877	http://dx.doi.org/10.1109/TPAMI.1987.4767877			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869382				2022-12-18	WOS:A1987F378500010
J	Yoon, S; Feng, JJ; Jain, AK				Yoon, Soweon; Feng, Jianjiang; Jain, Anil K.			Altered Fingerprints: Analysis and Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprints; AFIS; obfuscation; alteration; ridge pattern; minutiae distribution; image quality; fingerprintness	IMAGE-QUALITY; COMPUTATION	The widespread deployment of Automated Fingerprint Identification Systems (AFIS) in law enforcement and border control applications has heightened the need for ensuring that these systems are not compromised. While several issues related to fingerprint system security have been investigated, including the use of fake fingerprints for masquerading identity, the problem of fingerprint alteration or obfuscation has received very little attention. Fingerprint obfuscation refers to the deliberate alteration of the fingerprint pattern by an individual for the purpose of masking his identity. Several cases of fingerprint obfuscation have been reported in the press. Fingerprint image quality assessment software (e.g., NFIQ) cannot always detect altered fingerprints since the implicit image quality due to alteration may not change significantly. The main contributions of this paper are: 1) compiling case studies of incidents where individuals were found to have altered their fingerprints for circumventing AFIS, 2) investigating the impact of fingerprint alteration on the accuracy of a commercial fingerprint matcher, 3) classifying the alterations into three major categories and suggesting possible countermeasures, 4) developing a technique to automatically detect altered fingerprints based on analyzing orientation field and minutiae distribution, and 5) evaluating the proposed technique and the NFIQ algorithm on a large database of altered fingerprints provided by a law enforcement agency. Experimental results show the feasibility of the proposed approach in detecting altered fingerprints and highlight the need to further pursue this problem.	[Yoon, Soweon; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Feng, Jianjiang] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Michigan State University; Tsinghua University	Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	yoonsowo@cse.msu.edu; jfeng@tsinghua.edu.cn; jain@cse.msu.edu	Feng, Jianjiang/I-3386-2012		NSF Center for Identification Technology Research (CITeR); WCU (World Class University); Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]	NSF Center for Identification Technology Research (CITeR); WCU (World Class University); Ministry of Education, Science and Technology through the National Research Foundation of Korea(National Research Foundation of Korea)	The authors would like to acknowledge the support of Morpho during the course of this research. An early version of this research [1] was supported by a grant from the NSF Center for Identification Technology Research (CITeR). The authors would like to thank John Manzo of the FBI and Laura Tierney and Arun Vemury of the DHS for providing access to the altered fingerprint images. Part of Anil Jain's research was supported by the WCU (World Class University) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008). All correspondence should be directed to Anil K. Jain.	Alonso-Fernandez F, 2007, IEEE T INF FOREN SEC, V2, P734, DOI 10.1109/TIFS.2007.908228; [Anonymous], 2011, NIST SPEC DAT 14 NIS; [Anonymous], 2010, 3 CHARGED CONSPIRING; [Anonymous], 2011, EURODAC EUROPEAN UNI; [Anonymous], 2011, SURG ALTERED FINGERP; [Anonymous], 2008, CRIMINALS CUTTING FI; [Anonymous], 2008, WOMAN ALTERS FINGERP; [Anonymous], 2011, NIST SPEC DAT 4 NIST; [Anonymous], 1997, MEN BLACK; [Anonymous], 2004, SWEDEN REFUGEES MUTI; [Anonymous], 2008, ASYLUM SEEKERS TORCH; [Anonymous], 2011, FBIS NEXT GEN ID NGI; [Anonymous], 2011, HIST FINGERPRINT REM; [Anonymous], 2011, ALTERED FINGERPRINTS; Antonelli A, 2006, IEEE T INF FOREN SEC, V1, P360, DOI 10.1109/TIFS.2006.879289; Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; BURKS JW, 1958, ARCH DERMATOL, V77, P8, DOI 10.1001/archderm.1958.01560010010002; Cappelli R, 2002, INT C PATT RECOG, P744, DOI 10.1109/ICPR.2002.1048096; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cummins H, 1935, J CRIM LAW CRIM, V25, P982, DOI 10.2307/1134845; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; de Water M. V., 1936, SCI NEWS LETT, V29, P90; Hall M., 2007, US TODAY         NOV; Huckemann S, 2008, IEEE T PATTERN ANAL, V30, P1507, DOI 10.1109/TPAMI.2007.70826; Jianjiang Feng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1622, DOI 10.1109/ICPR.2010.401; Maltoni Davide, 2009, HDB FINGERPRINT RECO, DOI [10.1007/978-1-84882-254-2, DOI 10.1007/978-1-84882-254-2]; Nandakumar K, 2009, LECT NOTES COMPUT SC, V5558, P743, DOI 10.1007/978-3-642-01793-3_76; Neurotechnology Inc, 2011, VERIFINGER; Nixon KA, 2005, P SOC PHOTO-OPT INS, V5779, P214, DOI 10.1117/12.606643; Patten J., 2008, SAVVY CRIMINALS OBLI; PLOTNICK H, 1958, ARCH DERMATOL, V77, P12, DOI 10.1001/archderm.1958.01560010014003; Roizenblatt R., 2005, AM J OPHTHALMOL, V140, P969; Ross A.A., 2006, HDB MULTIBIOMETRICS; Singh K., 2008, ALTERED FINGERPRINTS; Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083; Tabassi E., 2004, NIST INTERAGENCY REP; The Fed. Bureau of Investigation (FBI), 2011, INT AUT FING ID SYST; The U.S. Department of Homeland Security, 2011, US VISIT; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P72, DOI 10.1109/TPAMI.2010.73; Watson C., 2011, NIST BIOMETRIC IMAGE; Wein LM, 2005, P NATL ACAD SCI USA, V102, P7772, DOI 10.1073/pnas.0407496102; Wertheim K., 1998, J FORENSIC IDENTIFIC, V48, P466; Wong M, 2009, ANN ONCOL, V20, P1281, DOI 10.1093/annonc/mdp278; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608	44	88	99	8	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					451	464		10.1109/TPAMI.2011.161	http://dx.doi.org/10.1109/TPAMI.2011.161			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808092	Green Submitted			2022-12-18	WOS:000299381600003
J	Wang, Z; Chen, SC; Sun, TK				Wang, Zhe; Chen, Songcan; Sun, Tingkai			MultiK-MHKS: A novel multiple kernel learning algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple kernel learning; canonical correlation analysis; regularization learning; modified Ho-Kashyap algorithm; single learning process; pattern recognition		In this paper, we develop a new effective multiple kernel learning algorithm. First, we map the input data into m different feature spaces by m empirical kernels, where each generated feature space is taken as one view of the input space. Then, through borrowing the motivating argument from Canonical Correlation Analysis (CCA) that can maximally correlate the m views in the transformed coordinates, we introduce a special term called Inter-Function Similarity Loss R-IFSL into the existing regularization framework so as to guarantee the agreement of multiview outputs. In implementation, we select the Modification of Ho-Kashyap algorithm with Squared approximation of the misclassification errors (MHKS) as the incorporated paradigm and the experimental results on benchmark data sets demonstrate the feasibility and effectiveness of the proposed algorithm named MultiK-MHKS.	[Wang, Zhe; Chen, Songcan] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China; [Sun, Tingkai] Nanjing Univ Sci & Technol, Coll Comp Sci & Technol, Nanjing 210094, Peoples R China	Nanjing University of Aeronautics & Astronautics; Nanjing University of Science & Technology	Wang, Z (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, 29 Yudao St, Nanjing 210016, Peoples R China.	wangzhe_hy@nuaa.edu.cn; s.chen@nuaa.edu.cn; suntingkai@mail.njust.edu.cn						BACH F, 2004, P 21 INT C MACH LEA; Bennett BC, 2002, J SPORT EXERCISE PSY, V24, P31; Bi J., 2004, P 10 ACM SIGKDD INT, P521; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chen LN, 1997, IEEE T POWER SYST, V12, P1481, DOI 10.1109/59.627845; Cristianini N., 2000, INTRO SUPPORT VECTOR; de Diego IM, 2004, LECT NOTES COMPUT SC, V3077, P102; DEDIEGO IM, 2006, P INT C INT DAT ENG, P330; FARQUHAR JDR, 2005, NEURAL INFORM PROCES; GRANDVALET Y, 2002, NEURAL INFORM PROCES; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; Leski J, 2003, PATTERN RECOGN LETT, V24, P2281, DOI 10.1016/S0167-8655(03)00054-0; LI Y, 2005, J INTELLIGENT INFORM; Ma JS, 2003, NEUROCOMPUTING, V50, P479, DOI 10.1016/S0925-2312(02)00673-2; MITCHELL TOM M., 1997, MACH LEARN, P2; Moguerza JM, 2006, LECT NOTES COMPUT SC, V4225, P945; Momma M, 2002, SIAM PROC S, P261; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Ong CS, 2005, J MACH LEARN RES, V6, P1043; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SONNENBURG S, 2005, NEURAL INFROM PROCES; SONNENBURG S, 2006, J MACHINE LEARNING R; TSANG I, 2006, P INT C KNOWL DISC D; Vapnik VN., 1998, WILEY SERIES ADAPTIV, V2, P1; Xiong HL, 2005, IEEE T NEURAL NETWOR, V16, P460, DOI 10.1109/TNN.2004.841784; Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6	32	88	96	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					348	353		10.1109/TPAMI.2007.70786	http://dx.doi.org/10.1109/TPAMI.2007.70786			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084064				2022-12-18	WOS:000251580300012
J	Khan, Z; Balch, T; Dellaert, F				Khan, Zia; Balch, Tucker; Dellaert, Frank			MCMC data association and sparse factorization updating for real time multitarget tracking with merged and multiple measurements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov chain Monte Carlo; QR factorization; updating; downdating; Rao-Blackwellized; particle filter; multitarget tracking; merged measurements; linear least squares; laser range scanner	PROBABILISTIC DATA ASSOCIATION; NUMBER	In several multitarget tracking applications, a target may return more than one measurement per target and interacting targets may return multiple merged measurements between targets. Existing algorithms for tracking and data association, initially applied to radar tracking, do not adequately address these types of measurements. Here, we introduce a probabilistic model for interacting targets that addresses both types of measurements simultaneously. We provide an algorithm for approximate inference in this model using a Markov chain Monte Carlo (MCMC)-based auxiliary variable particle filter. We Rao-Blackwellize the Markov chain to eliminate sampling over the continuous state space of the targets. A major contribution of this work is the use of sparse least squares updating and downdating techniques, which significantly reduce the computational cost per iteration of the Markov chain. Also, when combined with a simple heuristic, they enable the algorithm to correctly focus computation on interacting targets. We include experimental results on a challenging simulation sequence. We test the accuracy of the algorithm using two sensor modalities, video, and laser range data. We also show the algorithm exhibits real time performance on a conventional PC.	Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Khan, Z (corresponding author), Georgia Inst Technol, Coll Comp, 801 Atlantic Dr, Atlanta, GA 30332 USA.	zkhan@cc.gatech.edu; tucker@cc.gatech.edu; dellaert@cc.gatech.edu		Khan, Zia/0000-0002-7859-3489; Dellaert, Frank/0000-0002-5532-3566				BALCH T, 2005, P IEEE; Branson K, 2005, PROC CVPR IEEE, P1039; Casella G, 1996, BIOMETRIKA, V83, P81, DOI 10.1093/biomet/83.1.81; Castellanos JA, 2000, MOBILE ROBOT LOCALIZ; CHANG KC, 1984, IEEE T AUTOMAT CONTR, V29, P585, DOI 10.1109/TAC.1984.1103597; COLLINS JB, 1992, IEEE T AEROSPACE ELE, V28; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; DAVIS TA, 2004, TR04001 U FLOR; Dellaert F., 2000, P IEEE C COMP VIS PA; Dongarra J. J., 1979, LINPACK USERS GUIDE; EGERSTEDT M, 2005, P IEEE INT C ROB AUT; FELDMAN A, 2004, ADAPTIVE BEHAV; GENNARI G, 2004, P IEEE C COMP VIS PA; Genovesio A, 2004, INT C PATT RECOG, P677, DOI 10.1109/ICPR.2004.1333863; Gilks WR, 1996, MARKOV CHAIN MONTE C; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; ISARD M, 1996, P EUR C COMP VIS, P343; JERRUM M, 1997, APPROXIMATION ALGORI, pCH12; KANADE T, 1998, P DARPA IM UND WORKS, P3; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; KHAN Z, 2005, BEHAV RES METHODS IN; KHAN Z, 2005, P IEEE C COMP VIS PA; KHAN Z, 2004, P EUR C COMP VIS; Kirubarajan T, 2001, IEEE T AERO ELEC SYS, V37, P2, DOI 10.1109/7.913664; KOCH W, 1997, IEEE T AERO ELEC SYS, V33, P589; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275; Montemerlo M., 2003, P IEEE INT C ROB AUT; Murphy K, 2001, STAT ENG IN, P499; Oh S., 2004, P 43 IEEE C DEC CONT; Pitt MK, 2001, STAT ENG IN, P273; Popoli R., 1999, DESIGN ANAL MODERN T; Ramanan D., 2003, P IEEE C COMP VIS PA; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Sanchez O, 2004, INT J COMPUT VISION, V57, P91, DOI 10.1023/B:VISI.0000013084.09631.d8; Schulz D., 2003, INT J ROBOTICS RES, V22; Sigal L, 2004, PROC CVPR IEEE, P421; Smith K, 2005, P IEEE C COMP VIS PA; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479; TU Z, 2001, P INT C COMPUTER VIS; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Vermaak J., 2003, P INT C COMP VIS; YU T, 2004, P IEEE C COMP VIS PA; ZHAO T, 2004, P IEEE C COMP VIS PA; ZHU SC, 2000, P IEEE C COMPUTER VI	48	88	92	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					1960	1972		10.1109/TPAMI.2006.247	http://dx.doi.org/10.1109/TPAMI.2006.247			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108370				2022-12-18	WOS:000241195700006
J	Appleton, B; Talbot, H				Appleton, B; Talbot, H			Globally minimal surfaces by continuous maximal flows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						partial differential equations; graph-theoretic methods; edge and feature detection	ACTIVE CONTOUR MODELS; ALGORITHMS	In this paper, we address the computation of globally minimal curves and surfaces for image segmentation and stereo reconstruction. We present a solution, simulating a continuous maximal flow by a novel system of partial differential equations. Existing methods are either grid-biased (graph-based methods) or suboptimal (active contours and surfaces). The solution simulates the flow of an ideal fluid with isotropic velocity constraints. Velocity constraints are defined by a metric derived from image data. An auxiliary potential function is introduced to create a system of partial differential equations. It is proven that the algorithm produces a globally maximal continuous flow at convergence, and that the globally minimal surface may be obtained trivially from the auxiliary potential. The bias of minimal surface methods toward small objects is also addressed. An efficient implementation is given for the flow simulation. The globally minimal surface algorithm is applied to segmentation in 2D and 3D as well as to stereo matching. Results in 2D agree with an existing minimal contour algorithm for planar images. Results in 3D segmentation and stereo matching demonstrate that the new algorithm is robust and free from grid bias.	Google Inc, Mountain View, CA 94043 USA; ESIEE, A2SI, IGM, F-93162 Noisy Le Grand, France	Google Incorporated; Universite Gustave-Eiffel; ESIEE Paris	Appleton, B (corresponding author), Google Inc, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	appleton@google.com; talboth@esiee.fr						APPLETON B, 2005, J MATH IMAGING VISIO; Appleton B., 2003, DIGITAL IMAGE COMPUT, P987; Bamford P, 1998, SIGNAL PROCESS, V71, P203, DOI 10.1016/S0165-1684(98)00145-5; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; FORD JLR, 1962, FLOWS NETWORKS; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; Hu TC, 1969, INTEGER PROGRAMMING; IRI M, 1979, SURVEY MATH PROGRAMM; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEUNG C, 2004, P BRIT MACH VIS C SE, V1, P97; LLOYD SA, 1986, PATTERN RECOGN LETT, V4, P273, DOI 10.1016/0167-8655(86)90008-5; Mitchell J. S. B., 1988, Proceedings of the Fourth Annual Symposium on Computational Geometry, P341, DOI 10.1145/73393.73428; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; SEDGEWICK R, 2002, ALGORITHMS C; Sethian J. A., 1999, LEVEL SET METHODS FA; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Siek J., 2002, BOOST GRAPH LIB USER; STRANG G, 1983, MATH PROGRAM, V26, P123, DOI 10.1007/BF02592050; Strang G., 1986, INTRO APPL MATH; Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; Weihe K, 1997, J COMPUT SYST SCI, V55, P454, DOI 10.1006/jcss.1997.1538; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186	31	88	93	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					106	118		10.1109/TPAMI.2006.12	http://dx.doi.org/10.1109/TPAMI.2006.12			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402623				2022-12-18	WOS:000233172000009
J	Hel-Or, Y; Hel-Or, H				Hel-Or, Y; Hel-Or, H			Real-time pattern matching using projection kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern matching; template matching; pattern detection; feature extraction; Walsh-Hadamard	COMPUTATION; STATISTICS; WALSH; TREES	A novel approach to pattern matching is presented in which time complexity is reduced by two orders of magnitude compared to traditional approaches. The suggested approach uses an efficient projection scheme which bounds the distance between a pattern and an image window using very few operations on average. The projection framework is combined with a rejection scheme which allows rapid rejection of image windows that are distant from the pattern. Experiments show that the approach is effective even under very noisy conditions. The approach described here can also be used in classification schemes where the projection values serve as input features that are informative and fast to extract.	Sch Comp Sci, Interdisciplinary Ctr, IL-46150 Herzliyya, Israel; Univ Haifa, Dept Comp Sci, IL-30905 Haifa, Israel	Reichman University; University of Haifa	Hel-Or, Y (corresponding author), Sch Comp Sci, Interdisciplinary Ctr, IL-46150 Herzliyya, Israel.	toky@idc.ac.il; hagit@cs.haifa.ac.il						Ahumada Jr A. J., 1998, P SOC INFORMATION DI, V24, P305; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616; Ben-Artzi G, 2004, INT C PATT RECOG, P556, DOI 10.1109/ICPR.2004.1334198; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Crow F. C., 1984, Computers & Graphics, V18, P207; EFROS AA, 2001, P SIGGRAPH; ELAD M, 2000, P INT WORKSH VIS FOR, P28; Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498; FITZGIBBON A, 2003, P INT C COMP VIS; FLEURET F, 1999, P IEEE WORKSH STAT C, P544; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Girod Bernd, 1993, P207; Golub G. H., 1996, MATRIX COMPUTATIONS; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hel-Or Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1486; Huo XM, 2004, APPL OPTICS, V43, P293, DOI 10.1364/AO.43.000293; KANE J, 1969, P IEEE, V57, P58; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; KITAJIMA H, 1976, IEEE T COMMUN, V24, P1256, DOI 10.1109/TCOM.1976.1093239; LEE MH, 1986, IEEE T ACOUST SPEECH, V34, P1666, DOI 10.1109/TASSP.1986.1164972; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; Luczak T, 1997, IEEE T INFORM THEORY, V43, P1439, DOI 10.1109/18.623143; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; MAMLOUK AM, 2003, DAGM 2003, P346; MURPHY OJ, 1986, INFORM PROCESS LETT, V23, P215, DOI 10.1016/0020-0190(86)90138-9; NEALEN A, 2004, P COMP GRAPH INT; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Samet H., 1990, DESIGN ANAL SPATIAL, V85; Samet Hanan, 1990, DESIGN ANAL SPATIAL, P2; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; SHANKS JL, 1969, IEEE T COMPUT, VC 18, P457, DOI 10.1109/T-C.1969.222685; Strang G., 1988, LINEAR ALGEBRA APPL, V3rd; Sundararajan D, 1998, IEEE T IMAGE PROCESS, V7, P898, DOI 10.1109/83.679439; UKRAINITZ Y, 2005, UNPUB P INT C COMP V; VIOLA P, 2001, P INT C COMP VIS WOR; WEISSMAN T, 2003, HPL200329; WU J, 2004, ADV NEURAL INFORMATI, V16	41	88	100	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1430	1445		10.1109/TPAMI.2005.184	http://dx.doi.org/10.1109/TPAMI.2005.184			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173186	Green Submitted			2022-12-18	WOS:000230463300006
J	Mitra, P; Murthy, CA; Pal, SK				Mitra, P; Murthy, CA; Pal, SK			Density-based multiscale data condensation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; multiscale condensation; scalability; density estimation; convergence in probability; instance learning	NEIGHBOR; CLASSIFICATION; REDUCTION; ALGORITHM; IMAGES	A problem gaining interest in pattern recognition applied to data mining is that of selecting a small representative subset from a very large data set. In this article, a nonparametric data reduction scheme is suggested. It attempts to represent the density underlying the data. The algorithm selects representative points in a multiscale fashion which is novel from existing density-based approaches, The accuracy of representation by the condensed set is measured in terms of the error in density estimates of the original and reduced sets. Experimental studies on several real life data sets show that the multiscale approach is superior to several related condensation methods both in terms of condensation ratio and estimation error. The condensed set obtained was also experimentally shown to be effective for some important data mining tasks like classification, clustering, and rule generation on large data sets. Moreover, it is empirically found that the algorithm is efficient in terms of sample complexity.	Indian Stat Inst, Machine Intelligence Unit, Kolkata 700035, W Bengal, India	Indian Statistical Institute; Indian Statistical Institute Kolkata	Mitra, P (corresponding author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700035, W Bengal, India.	pabitra_r@isical.ac.in; murthy@isical.ac.in; sankar@isical.ac.in						Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; ASPIN AA, 1949, BIOMETRIKA, V36, P290, DOI 10.1093/biomet/36.3-4.290; ASTRAHAN MM, 1970, SPEECH ANAL CLUSTERI; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; DENG K, 1995, P INT JOINT C ART IN; ESTER JSM, 1996, P 2 INT C KNOWL DISC, P226; FARAGO A, 1991, PROBL CONTROL INFORM, V20, P383; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115, DOI 10.1109/TPAMI.1984.4767485; Fukunaga K., 1972, INTRO STAT PATTERN R; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lehmann EL, 1976, TESTING STAT HYPOTHE; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396, DOI 10.1109/34.895974; LEWIS D, 1994, MACH LEARN P 11 INT, P148; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MOORE AW, 1997, MACH LEARN P 14 INT, P236; Olshen R., 1984, CLASSIFICATION REGRE; Pal S.K., 1999, NEURO FUZZY PATTERN; Pal SK, 2000, INT J REMOTE SENS, V21, P2269, DOI 10.1080/01431160050029567; Platt J, 1991, NEURAL COMPUT, V3, P213, DOI 10.1162/neco.1991.3.2.213; PLUTOWSKI M, 1993, IEEE T NEURAL NETWOR, V4, P305, DOI 10.1109/72.207618; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Roy Nicholas, 2001, ICML, P894; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WONG YF, 1993, IEEE T GEOSCI REMOTE, V31, P634, DOI 10.1109/36.225530; XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318; [No title captured]	34	88	102	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					734	747		10.1109/TPAMI.2002.1008381	http://dx.doi.org/10.1109/TPAMI.2002.1008381			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300003
J	Park, J; Keller, JM				Park, J; Keller, JM			Snakes on the watershed	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contour model; snakes; watershed algorithm; dynamic programming; energy minimization; white blood cell detection	ACTIVE CONTOUR; ALGORITHM	In this paper, we present a new approach for object boundary extraction, called the watersnake. It is a two-step snake algorithm whose energy functional is minimized by the dynamic programming method. It is more robust to local minima because it finds the solution by searching the entire energy space. To reduce the complexity of the minimization process, the watershed transformation and a coarse-to-fine strategy are used. The new technique is compared to standard methods for accuracy in synthetic data and is applied to segmentation of white blood cells in bone marrow Images.	Univ Missouri, Dept Comp Engn & Comp Sci, Columbia, MO 65211 USA	University of Missouri System; University of Missouri Columbia	Park, J (corresponding author), Univ Missouri, Dept Comp Engn & Comp Sci, Columbia, MO 65211 USA.							AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Beucher S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1928; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; Dougherty E. R., 1992, INTRO MORPHOLOGICAL; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PARK J, 1997, P IEEE INT C SYST MA, P1133; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L	15	88	111	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1201	1205		10.1109/34.954609	http://dx.doi.org/10.1109/34.954609			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600013
J	Li, XL; Parizeau, M; Plamondon, R				Li, XL; Parizeau, M; Plamondon, R			Training hidden Markov models with multiple observations - A combinatorial method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hidden Markov model; forward-backward procedure; Baum-Welch algorithm; multiple observation training	ONLINE HANDWRITING RECOGNITION; SPEECH RECOGNITION; PROBABILISTIC FUNCTIONS; ALGORITHM; WORD	Hidden Markov models (HMMs) are stochastic models capable of statistical learning and classification. They have been applied in speech recognition and handwriting recognition because of their great adaptability and Versatility in handling sequential signals. On the other hand, as these models have a complex structure and also because the involved data sets usually contain uncertainty, it is difficult to analyze the multiple observation training problem without certain assumptions. For many years researchers have used Levinson's training equations in speech and handwriting applications, simply assuming that all observations are independent of each other. This paper presents a formal treatment of HMM multiple observation training without imposing the above assumption. In this treatment, the multiple observation probability is expressed as a combination of individual observation probabilities without losing generality. This combinatorial method gives one more freedom in making different dependence-independence assumptions. By generalizing Baum's auxiliary function into this framework and building up an associated objective function using the Lagrange multiplier method, it is proven that the derived training equations guarantee the maximization of the objective function. Furthermore, we show that Levinson's training equations can be easily derived as a special case in this treatment.	CADlink Technol Corp, Ottawa, ON K1H 1E1, Canada; Univ Laval, Dept Genie Elect & Genie Informat, St Foy, PQ G1K 7P4, Canada; Ecole Polytech, Montreal, PQ H3C 3A7, Canada	Laval University; Universite de Montreal; Polytechnique Montreal	Li, XL (corresponding author), CADlink Technol Corp, 2440 Don Reid Dr,Suite 100, Ottawa, ON K1H 1E1, Canada.		Plamondon, Réjean/O-3214-2015	Plamondon, Réjean/0000-0002-4903-7539; Parizeau, Marc/0000-0001-9929-646X				BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BALDI P, 1994, NEURAL COMPUT, V6, P307, DOI 10.1162/neco.1994.6.2.307; BAUM LE, 1968, PAC J MATH, V27, P211, DOI 10.2140/pjm.1968.27.211; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BAUM LE, 1970, INEQUALITY, V3, P1; BELLEGARDA EJ, 1994, IEEE T PATTERN ANAL, V16, P1227, DOI 10.1109/34.387484; CHO SB, 1995, NEURAL COMPUT, V7, P358, DOI 10.1162/neco.1995.7.2.358; DAI JN, 1995, PATTERN RECOGN, V28, P53, DOI 10.1016/0031-3203(94)00075-W; Hu JY, 1996, IEEE T PATTERN ANAL, V18, P1039, DOI 10.1109/34.541414; IWAYAMA M, 1993, P 4 INT WORKSH ALG L, P237; Kaltenmeier A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P139, DOI 10.1109/ICDAR.1993.395764; KUNDU A, 1989, PATTERN RECOGN, V22, P283, DOI 10.1016/0031-3203(89)90076-9; Lee K. F., 1989, AUTOMATIC SPEECH REC; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; LI X, 1999, EPMRT9916; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1985, IEEE T ACOUST SPEECH, V33, P561, DOI 10.1109/TASSP.1985.1164586; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rigoll G., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P205, DOI 10.1109/ICPR.1996.546818; VELTMAN SR, 1994, IEEE T IMAGE PROCESS, V3, P314, DOI 10.1109/83.287027; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	23	88	105	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					371	377		10.1109/34.845379	http://dx.doi.org/10.1109/34.845379			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500006
J	Blane, MM; Lei, ZB; Civi, H; Cooper, DB				Blane, MM; Lei, ZB; Civi, H; Cooper, DB			The 3L algorithm for fitting implicit polynomial curves and surfaces to data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						least-squares fitting; implicit polynomial representations; curve and surface fitting; fitting with constraints; algebraic curves and surfaces	OBJECTS; RECOGNITION	In this paper, we introduce a completely new approach to fitting implicit polynomial geometric shape models to data and to studying these polynomials. The power of these models is in their ability to represent nonstar complex shapes in two- (2D) and three-dimensional (3D) data to permit fast, repeatable fitting to unorganized data which may not be uniformly sampled and which may contain gaps, to permit position-invariant shape recognition based on new complete sets of Euclidean and affine invariants and to permit fast, stable single-computation pose estimation. The algorithm represents a significant advancement of implicit polynomial technology for four important reasons. First, it is orders of magnitude faster than existing fitting methods for implicit polynomial 2D curves and 3D surfaces. and the algorithms for 2D and 3D are essentially the same. Second, it has significantly better repeatability, numerical stability. and robustness than current methods in dealing with noisy, deformed. or missing data. Third, it can easily fit polynomials of high, such as 14th or 16th, degree. Fourth, additional linear constraints can be easily incorporated into the fitting process, and general linear vector space concepts apply.	Brown Univ, Div Engn, Lab Engn Man Machine Syst, Providence, RI 02912 USA; Bell Labs, Murray Hill, NJ 07974 USA; IBM Turk Ltd, IBM Consulting Grp, TR-80613 Istanbul, Turkey	Brown University; AT&T; International Business Machines (IBM); IBM Turkey	Blane, MM (corresponding author), Brown Univ, Div Engn, Lab Engn Man Machine Syst, Providence, RI 02912 USA.	mmb@lems.brown.edu; zbl@research.bell-labs.com; hcivi@tr.ibm.com; cooper@lems.brown.edu						BAJAJ CL, 1992, P COMP GRAPH SIGGRAP, V26; BLANE MM, 1996, LEMS160 BROWN U DIV; BLOOMENTHAL J, 1997, INTRO IMPLICIT SURFA, P104; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; Campbell S.L., 1979, GEN INVERSES LINEAR; CIVI H, 1997, THESIS BOGAZICI U IS; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; HOFFMANN CM, 1993, IEEE COMPUT GRAPH, V13, P79, DOI 10.1109/38.180121; Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Lei Z, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P148, DOI 10.1109/ACV.1996.572044; LEI Z, 1998, J VLSI SIGNAL PROCES, V20; LEI Z, 1995, P IEEE INT C IM PROC; Lei ZB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P827, DOI 10.1109/ICCV.1998.710813; MOORE D, 1990, TR90135 RIC U DEP CO; PRATT V, 1987, ACM SIGGRAPH, V21, P145; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; Tarel JP, 1998, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.1998.698596; TASDIZEN T, 1998, LEMS176 BROWN U DIV; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273	24	88	94	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2000	22	3					298	313		10.1109/34.841760	http://dx.doi.org/10.1109/34.841760			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	306EJ					2022-12-18	WOS:000086584100007
J	Chakraborty, A; Duncan, JS				Chakraborty, A; Duncan, JS			Game-theoretic integration for image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; integration; game theory; boundary finding; region-based segmentation; MRF	EDGE-DETECTION; REGION; INFORMATION; ALGORITHMS; DIFFUSION; FRAMEWORK; SYSTEM; MODELS	Robust segmentation of structures from an image is essential for a variety of image analysis problems. However, the conventional methods of region-based segmentation and gradient-based boundary finding are often frustrated by poor image quality. Here we propose a method to integrate the two approaches using game theory in an effort to form a unified approach that is robust to noise and poor initialization. This combines the perceptual notions of complete boundary information using edge data and shape priors with gray-level homogeneity using two computational modules. The novelty of the method is that this is a bidirectional framework, whereby both computational modules improve their results through mutual information sharing. A number of experiments were performed both on synthetic datasets and datasets of real images to evaluate the new approach and it is shown that the integrated method typically performs better than conventional gradient-based boundary finding.	Siemens Corp Res, Princeton, NJ 08540 USA; Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA	Siemens AG; Yale University	Chakraborty, A (corresponding author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	chakrab@scr.siemens.com; duncan@noodle.med.yale.edu						ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Ballard D.H., 1982, COMPUTER VISION; BASAR T, 1985, IEEE T AUTOMAT CONTR, V30, P118, DOI 10.1109/TAC.1985.1103896; Basar T., 1999, DYNAMIC NONCOOPERATI, V2; BESAG J, 1986, J R STAT SOC B, V48, P259; Borel E, 1953, ECONOMETRICA, V21, P97, DOI 10.2307/1906946; BOZMA HI, 1992, IMAGE VISION COMPUT, V10, P431, DOI 10.1016/0262-8856(92)90028-2; BOZMA HI, 1994, IEEE T PATTERN ANAL, V16, P1074, DOI 10.1109/34.334387; BOZMA HI, 1992, THESIS YALE U; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASELLES V, 1996, INT J COMPUTER VISIO; Chakraborty A., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P624, DOI 10.1109/CVPR.1994.323790; CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241, DOI 10.1109/34.250843; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867; HO YC, 1980, IEEE P, V68, P644; KAKARALA R, 1992, IEEE T PATTERN ANAL, V14, P777, DOI 10.1109/34.142913; Kantorovich L.V., 1982, FUNCTIONAL ANAL; KASS M, 1988, INT J COMPUT VISION, V1, P312; KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443; KOHLER R, 1981, COMPUT VISION GRAPH, V15, P319, DOI 10.1016/S0146-664X(81)80015-9; Kuhn H., 1953, CONTRIBUTIONS THEORY, VII; KUHN HW, 1950, CONTRIBUTIONS THEORY, V2; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640; LI S, 1987, AUTOMATICA, V23, P523, DOI 10.1016/0005-1098(87)90081-1; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850; MCKINSEY JC, 1952, INTRO THEORY GAMES; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Owen G., 1982, GAME THEORY; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Rosenfeld A., 1982, DIGITAL PICTURE PROC; TAXT T, 1989, IEEE T PATTERN ANAL, V11, P1322, DOI 10.1109/34.41371; TEK H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P156, DOI 10.1109/ICCV.1995.466792; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; von Neumann J, 1947, THEORY GAMES EC BEHA; WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909; ZUBAL IG, 1992, J NUCL MED, V33, P1712	52	88	95	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					12	30		10.1109/34.745730	http://dx.doi.org/10.1109/34.745730			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900003
J	VERVEER, PJ; DUIN, RPW				VERVEER, PJ; DUIN, RPW			AN EVALUATION OF INTRINSIC DIMENSIONALITY ESTIMATORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter								The intrinsic dimensionality of a data set may be useful for understanding the properties of classifiers applied to it and thereby for the selection of an optimal classifier. In this paper we compare the algorithms for two estimators of the intrinsic dimensionality of a given data set and extend their capabilities. One algorithm is based on the local eigenvalues of the covariance matrix in several small regions in the feature space. The other estimates the intrinsic dimensionality from the distribution of the distances from an arbitrary data vector to a selection of its neighbors. The characteristics of the two estimators are investigated and the results are compared. It is found that both can be applied successfully, but that they might fail in certain cases. The estimators are compared and illustrated using data generated from chromosome banding profiles.	DELFT UNIV TECHNOL,FAC APPL PHYS,PATTERN RECOGNIT GRP,2628 CJ DELFT,NETHERLANDS	Delft University of Technology								BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; DUIN RPW, 1993, 8TH P SCAND C IM AN, P547; ERRINGTON PA, 1993, CYTOMETRY, V14, P627, DOI 10.1002/cyto.990140607; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GOLOMB BA, 1991, ADV NEURAL INFORMATI, P575; Jain A. K., 1988, ALGORITHMS CLUSTERIN; KAMATA SI, 1992, 11TH P IAPR INT C PA, V2, P573; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Pomerleau D.A., 1989, ALVINN AUTONOMOUS LA; SEJNOWSKI TJ, 1986, JHUEECS8601 J HOPK U; TRUNK GV, 1976, IEEE T COMPUT, V25, P165, DOI 10.1109/TC.1976.5009231; VERVEER PJ, 1993, ESTIMATORS INTRINSIC; Wyse N., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P415	14	88	92	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					81	86		10.1109/34.368147	http://dx.doi.org/10.1109/34.368147			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394		Green Submitted			2022-12-18	WOS:A1995QB39400011
J	MAN, Y; GATH, I				MAN, Y; GATH, I			DETECTION AND SEPARATION OF RING-SHAPED CLUSTERS USING FUZZY CLUSTERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						RING-SHAPED CLUSTERS; FUZZY CLUSTERING; INITIAL CONDITIONS; CLUSTER VALIDITY		A new fuzzy clustering algorithm, designed to detect and characterize ring-shaped clusters and combinations of ring-shaped and compact spherical clusters, has been developed. This FKR algorithm includes automatic search for proper initial conditions in the two cases of concentric and excentric (intersected) combinations of clusters. Validity criteria based on total fuzzy area and fuzzy density are used to estimate the optimal number of substructures in the data set. The FKR algorithm has been tested on a variety of simulated combinations of ring-shaped and compact spherical clusters, and its performance proved to be very good, both in identifying the input shapes and in recovering the input parameters. Application of the FKR algorithm to an MRI image of the heart's left ventricle was aimed to investigate the possibility of using this algorithm as an aid in image processing.			MAN, Y (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT BIOMED ENGN,IL-32000 HAIFA,ISRAEL.							Bezdek J.C., 1973, FUZZY MATH PATTERN C; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BEZDEK JC, 1981, SIAM J APPL MATH, V40, P358, DOI 10.1137/0140030; BEZDEK JC, 1981, SIAM J APPL MATH, V40, P339, DOI 10.1137/0140029; DAVE RN, 1990, INT J GEN SYST, V16, P343, DOI 10.1080/03081079008935087; DAVE RN, 1991, P SPIE C INTELLIGENT, V1607, P406; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; GATH I, 1989, PATTERN RECOGN LETT, V9, P77, DOI 10.1016/0167-8655(89)90040-8; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Gustafson E. E., 1979, P IEEE CDC SAN DIEG, P761; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964; JAIN AK, 1988, ALGORITHMS CLUSTERIN, P143; Morgan WA, 1939, BIOMETRIKA, V31, P13, DOI 10.2307/2334972; Pitman EJG, 1939, BIOMETRIKA, V31, P9, DOI 10.1093/biomet/31.1-2.9	15	88	91	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					855	861		10.1109/34.308484	http://dx.doi.org/10.1109/34.308484			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500014
J	KOPEC, GE; CHOU, PA				KOPEC, GE; CHOU, PA			DOCUMENT IMAGE DECODING USING MARKOV SOURCE MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DOCUMENT RECOGNITION; TEXT RECOGNITION; IMAGE DECODING; STOCHASTIC GRAMMARS; MARKOV SOURCES	CONTINUOUS SPEECH RECOGNITION	Document image Decoding (DID) is a communication theory approach to document image recognition, patterned after the use of hidden Markov models in speech recognition. In DID, a document recognition problem is viewed as consisting of three elements-an image generator, a noisy channel and an image decoder. A document image generator is a Markov source (stochastic finite-state automaton) that combines a message source with an imager. The message source produces a string of symbols, or text, that contains the information to be transmitted. The imager is modeled as a finite-state transducer that converts the one-dimensional message string into an ideal two-dimensional bitmap. The channel transforms the ideal image into a noisy observed image. The decoder estimates the message, given the observed image, by finding the a posteriori most probable path through the combined source and channel models using a Viterbi-like dynamic programming algorithm. The proposed approach is illustrated on the problem of decoding scanned telephone yellow pages to extract names and numbers from the listings. A finite-state model for yellow page columns was constructed and used to decode a database of scanned column images containing about 1100 individual listings. Overall, 99.5% of the listings were correctly recognized, with character classification rates of 98% and 99.6%, respectively, for the names and numbers.			KOPEC, GE (corresponding author), XEROX CORP,PALO ALTO RES CTR,INFORMAT SCI & TECHNOL LAB,PALO ALTO,CA 94304, USA.							Abelson H., 1980, TURTLE GEOMETRY; Agazzi OEx, 1993, 1993 P IEEE INT C AC, V5, P113; ANIGBOUGU JC, 1991, SEP P INT C DOC AN, P785; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BIARD H, 1990, JUN P IAPR WORKSH SY; CHEN F, 1993, 1993 P IEEE INT C AC, V5, P1; CHEN M, IN PRESS IEEE T PATT; CHOU PA, 1989, SPIE VISUAL COMMUN I, V1199, P852; GOLDFARB C, 1991, SGML HDB; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; Huang X., 1990, HIDDEN MARKOV MODELS; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; KARP RM, 1967, J ACM, V14, P563, DOI 10.1145/321406.321418; KOPEC G, 1992, P92000150 ISTL923 XE; KOPEC G, 1992, P9200061 EDL925 XER; KOPEC G, 1990, EP90; Kopec GE, 1993, IEEE T IMAGE PROCESS, V2, P510, DOI 10.1109/83.242359; Kruskal J.B., 1983, TIME WARPS STRING ED; Lamport Leslie, 1986, LATEX DOCUMENT PREPA; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; PRUSINKIEWICZ P, 1989, LECTURE NOTES BIOMAT, V79; Rao S.K., 1985, THESIS STANFORD U; RUBENSTEIN R, 1988, DIGITAL TYPOGRAPHY; TOMITA M, 1989, ACM INT WORKSHOP PAR, P414; VLONTZOS J, 1989, 1989 P IEEE INT C AC, P1719; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; 1990, POSTSCRIPT LANGUAGE; 1992, SMART YELLOW PAGES	28	88	130	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					602	617		10.1109/34.295905	http://dx.doi.org/10.1109/34.295905			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200005
J	TAUBIN, G; CUKIERMAN, F; SULLIVAN, S; PONCE, J; KRIEGMAN, DJ				TAUBIN, G; CUKIERMAN, F; SULLIVAN, S; PONCE, J; KRIEGMAN, DJ			PARAMETERIZED FAMILIES OF POLYNOMIALS FOR BOUNDED ALGEBRAIC CURVE AND SURFACE FITTING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BOUNDED ALGEBRAIC CURVES AND SURFACES; ALGEBRAIC CURVE AND SURFACE FITTING; ALGEBRAIC INVARIANCE	MODELS; OBJECTS; IMAGES	Interest in algebraic curves and surfaces of high degree as geometric models or shape descriptors for different model-based computer vision tasks has increased in recent years, and although their properties make them a natural choice for object recognition and positioning applications, algebraic curve and surface fitting algorithms often suffer from instability problems. One of the main reasons for these problems is that, while the data sets are always bounded, the resulting algebraic curves or surfaces are, in most cases, unbounded. In this paper, we propose to constrain the polynomials to a family with bounded zero sets, and use only members of this family in the fitting process. For every even number d we introduce a new parameterized family of polynomials of degree d whose level sets are always bounded, in particular, its zero sets. This family has the same number of degrees of freedom as a general polynomial of the same degree. Three methods for fitting members of this polynomial family to measured data points are introduced. Experimental results of fitting curves to sets or points in R2 and surfaces to sets of points in R3 are presented.	UNIV ILLINOIS, BECKMAN INST, URBANA, IL 61801 USA; YALE UNIV, CTR SYST SCI, NEW HAVEN, CT 06520 USA; YALE UNIV, DEPT ELECT ENGN, NEW HAVEN, CT 06520 USA; UNIV KANSAS, DEPT MATH, LAWRENCE, KS 66045 USA; UNIV ILLINOIS, DEPT COMP SCI, URBANA, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign; Yale University; Yale University; University of Kansas; University of Illinois System; University of Illinois Urbana-Champaign	TAUBIN, G (corresponding author), IBM CORP, THOMAS J WATSON RES CTR, EXPLORATORY COMP VIS GRP, YORKTOWN HTS, NY 10598 USA.			Taubin, Gabriel/0000-0002-1983-7607				Albano A., 1974, COMPUT VISION GRAPH, V3, P23, DOI [10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2CGIPBG0146-664X]; Artin E, 1927, HAMBURFER ABH, V5, P100; BAJCSY R, 1987, 1ST P INT C COMP VIS, P231; BIGGERSTAFF RH, 1972, J DENT RES, V51, P1509, DOI 10.1177/00220345720510055101; BINFORD TO, 1971, P IEEE C SYSTEMS CON; Bochnak J., 1987, ERGEBNISSE MATH IHRE, V12; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6, P418, DOI 10.1109/TPAMI.1984.4767547; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; Brocket R., 1973, GEOMETRIC METHODS SY, V3, P43, DOI [10.1007/978-94- 010-2675-8_2, DOI 10.1007/978-94-010-2675-8_2]; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CERNUSCHIFRIAS B, 1984, THESIS BROWN U PROV; CHEN DS, 1989, IEEE T PATTERN ANAL, V11, P749, DOI 10.1109/34.192470; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; Duda R.O., 1973, J ROYAL STAT SOC SER; FAROUKI RT, 1987, IBM J RES DEV, V31, P314, DOI 10.1147/rd.313.0314; FAUGERAS OD, 1983, P IEEE C COMPUTER VI; FORSYTH D, 1990, 1ST P EUR C COMP VIS; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; GROSS AD, 1988, 2ND P INT C COMP VIS; HALL EL, 1982, IEEE COMPUT      DEC, P42; HELGASON S, 1984, GROUPS GEOMETRIC ANA; Hilbert David, 1888, MATH ANN, V32, P342, DOI DOI 10.1007/BF01443605; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; PATON K, 1970, PATTERN RECOGN, V2, P39, DOI 10.1016/0031-3203(70)90040-3; PONCE J, 1992, CVGIP-IMAG UNDERSTAN, V55, P184, DOI 10.1016/1049-9660(92)90016-V; PRATT V, 1987, ACM SIGGRAPH, V21, P145; RIOUX M, 1988, CNRC29077 NAT RES CO; Roberts L, 1965, MACHINE PERCEPTION 3; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SOLINA F, 1987, THESIS U PENNSYLVANI; Sullivan S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P110, DOI 10.1109/CVPR.1993.340971; Taubin G., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P658, DOI 10.1109/ICCV.1993.378149; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TAUBIN G, 1991, THESIS BROWN U PROVI; TAUBIN G, 1994, IN PRESS ACM T GRAPH, V12; TAUBIN G, 1994, IN PRESS IEEE COMPUT, V14; TAUBIN G, 1993, 2ND P ACM IEEE S SOL, P221; TAUBIN G, 1988, MAY P IEEE C ROB AUT, P644; Walker R.J., 1950, ALGEBRAIC CURVES; [No title captured]; [No title captured]	45	88	88	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					287	303		10.1109/34.276128	http://dx.doi.org/10.1109/34.276128			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400009
J	ELFADEL, IM; PICARD, RW				ELFADEL, IM; PICARD, RW			GIBBS RANDOM-FIELDS, COOCCURRENCES, AND TEXTURE MODELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COOCCURRENCE STATISTICS; GIBBS DISTRIBUTION; IMAGE MODELS; MARKOV RANDOM FIELD; MATHEMATICAL MORPHOLOGY; NEIGHBORHOOD OPERATORS; PATTERN ANALYSIS; SET THEORY; TEXTURE MODELING	MARKOV RANDOM-FIELDS; SPATIAL-INTERACTION; IMAGES; SEGMENTATION; ALGORITHMS; MATRICES; FLUIDS	Gibbs random field (GRF) models and features from cooccurrence matrices are typically considered as separate but useful tools for texture discrimination. In this paper we show an explicit relationship between cooccurrences and a large class of CRF's. This result comes from a new framework based on a set-theoretic concept called the ''aura set'' and on measures of this set, ''aura measures.'' This framework is also shown to be useful for relating different texture analysis tools: We show how the aura set can be constructed with morphological dilation, how its measure yields cooccurrences, and how it can be applied to characterizing the behavior of the Gibbs model for texture. In particular, we show how the aura measure generalizes, to any number of gray levels and neighborhood oi der, some properties previously known for just the binary, nearest-neighbor GRF. Finally we illustrate how these properties can guide one's intuition about the types of GRF patterns which are most likely to form.	MIT,ELECTR RES LAB,CAMBRIDGE,MA 02139; MIT,MEDIA LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	ELFADEL, IM (corresponding author), KDD R&D LABS,SAITAMA,JAPAN.			Elfadel, Ibrahim/0000-0003-3220-9987				Baxter R.J., 1982, EXACTLY SOLVED MODEL; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Bollobas B., 1986, COMBINATORICA; CARNEVALI P, 1987, P COMPUTER VISION; Charles Kittle H., 1980, THERMAL PHYS, Vsecond, P353; CHELLAPPA R, 1984, P ICASSP; Chellappa R., 1985, PROGR PATTERN RECOGN, V2; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; CROSS GR, 1980, THESIS MICHIGAN STAT; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921; DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; ELFADEL IM, 1993, MIT204 MEDIA LAB PER; Even S, 1979, GRAPH ALGORITHMS; GAGALOWICZ A, 1986, P INT C PATTERN RECO; GARAND L, 1986, J CLIM APPL METEOROL, V25, P1052, DOI 10.1175/1520-0450(1986)025<1052:ASSMFT>2.0.CO;2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOTLIEB CC, 1990, COMPUT VISION GRAPH, V51, P70, DOI 10.1016/S0734-189X(05)80063-5; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HASSNER M, 1980, COMPUT VISION GRAPH, V12, P357, DOI 10.1016/0146-664X(80)90019-2; HUANG K, 1963, STATISTICAL MECHANIC; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Kindermann R., 1980, MARKOV RANDOM FIELDS, DOI [10.1090/conm/001, DOI 10.1090/CONM/001]; MARAGOS PA, 1990, P IEEE, P690; Picard R. W., 1992, Journal of Mathematical Imaging and Vision, V2, P5, DOI 10.1007/BF00123878; PICARD RW, 1991, P IEEE C COMPUTER VI; PICARD RW, 1993, MIT254 MED LAB PERC; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; ROTHMAN DH, 1988, J STAT PHYS, V52, P1119, DOI 10.1007/BF01019743; VANGOOL L, 1985, COMPUT VISION GRAPH, V29, P336, DOI 10.1016/0734-189X(85)90130-6; WITTEN TA, 1990, PHYS TODAY, V43, P21, DOI 10.1063/1.881249	33	88	92	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					24	37		10.1109/34.273719	http://dx.doi.org/10.1109/34.273719			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300003
J	BROIDA, TJ; CHELLAPPA, R				BROIDA, TJ; CHELLAPPA, R			ESTIMATING THE KINEMATICS AND STRUCTURE OF A RIGID OBJECT FROM A SEQUENCE OF MONOCULAR IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE SEQUENCE ANALYSIS; MOTION ANALYSIS; 3-D MOTION ESTIMATION; UNIQUENESS	3-DIMENSIONAL MOTION PARAMETERS; OPTICAL-FLOW; NOISY IMAGES; FRAMES; UNIQUENESS; BODY	The problem considered here involves the use of a sequence of noisy monocular images of a three-dimensional (3-D) moving object to estimate both its structure and kinematics. The object is assumed to be rigid, and its motion is assumed to be "smooth". A set of object match points is assumed to be available, consisting of fixed features on the object, the image plane coordinates of which have been extracted from successive images in the sequence. Structure is defined as the 3-D positions of these object feature points, relative to each other. Rotational motion occurs about the origin of an object-centered coordinate system, while translational motion is that of the origin of this coordinate system. In previous work [5]-[8] we have developed a model based approach for motion/structure estimation using a long sequence of monocular images. This approach provides a great deal of flexibility, by allowing the use of arbitrarily many image frames and feature points, and each model can easily be modified or extended for different problems. Our earlier work involved assumptions about object structure and/or motion, were primarily tested on simulated imagery, and did not address the issue of uniqueness of the model parameters. In this paper, which is a continuation of the research started in [7], results of an experiment with real imagery are presented, involving estimation of 28 unknown translational, rotational, and structural parameters, based on 12 images with 7 feature points. Uniqueness results are summarized for the case of purely translational motion. A test based on a singular value decomposition is described that determines whether or not noise-free data from an image sequence uniquely determines the elements of any given parameter vector, and empirical support of this test is given.	UNIV SO CALIF,INST SIGNAL & IMAGE PROC,LOS ANGELES,CA 90089	University of Southern California	BROIDA, TJ (corresponding author), HUGHES AIRCRAFT CO,RADAR SYST GRP,DIV ADV PROGRAMS,POB 92426,LOS ANGELES,CA 90009, USA.		Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012					ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALOIMONOS J, 1986, JUN P IEEE C COMP VI, P510; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; Blackman S.S., 1986, MULTIPLE TARGET TRAC; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROIDA TJ, 1989, J OPT SOC AM A, V6, P879, DOI 10.1364/JOSAA.6.000879; BROIDA TJ, 1987, THESIS U SO CALIFORN; DICKMANNS ED, 1988, JUN IEEE COMP SOC C, P820; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FRIEDLAND B, 1978, IEEE T AERO ELEC SYS, V14, P764, DOI 10.1109/TAES.1978.308627; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; JAIN RC, 1984, IEEE T PATTERN ANAL, V6, P624, DOI 10.1109/TPAMI.1984.4767575; KIM YC, 1987, IEEE T ROBOTIC AUTOM, V3, P599; KONSTANTINIDES K, 1988, IEEE T ACOUST SPEECH, V36, P757, DOI 10.1109/29.1585; MUTCH KM, 1985, IEEE T PATTERN ANAL, V7, P133, DOI 10.1109/TPAMI.1985.4767638; NIVA GD, 1982, JAN P ANN ROCK MOUNT, P269; POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Rudin W., 1976, PRINCIPLES MATH ANAL, V3; Scales L. E., 1985, INTRO NONLINEAR OPTI; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SHARIAT H, 1990, IEEE T PATTERN ANAL, V12, P417, DOI 10.1109/34.55102; SRIDHAR B, 1988, APR P AM HEL SOC M A; STALLARD DV, 1986, P IAAA GUIDANCE NAVI; Sugie N., 1984, Transactions of the Society of Instrument and Control Engineers, V20, P837; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; TIRUMALAI A, 1989, JUN P IEE COMP SOC C, P136; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WEBB JA, 1981, COMPUTER, V14, P40, DOI 10.1109/C-M.1981.220561; WENG J, 1988, JUN P IEEE C COMP VI; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; Wertz J.R., 1978, SPACECRAFT ATTITUDE; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666; ZHUANG X, 1988, IEEE J ROBOT AUTOM, V4, P236, DOI 10.1109/56.2089; [No title captured]	39	88	89	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					497	513		10.1109/34.87338	http://dx.doi.org/10.1109/34.87338			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200001
J	MEER, P; JOLION, JM; ROSENFELD, A				MEER, P; JOLION, JM; ROSENFELD, A			A FAST PARALLEL ALGORITHM FOR BLIND ESTIMATION OF NOISE VARIANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV LYON 1,INFORMAT GRAPH & INTELLIGENCE ARTIFICIELLE LAB,F-69622 VILLEURBANNE,FRANCE	UDICE-French Research Universities; Universite Claude Bernard Lyon 1	MEER, P (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742, USA.							BALAKRISHNAN AV, 1984, KALMAN FILTERING THE; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Brodatz P., 1966, TEXTURES; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DAVID HA, 1970, ORDER STATISTICS; Hillis W., 1985, CONNECTION MACHINE; IBRAHIM HAH, 1988, APR P IM UND WORKSH, P634; MEER P, 1989, PATTERN RECOGN, V22, P491, DOI 10.1016/0031-3203(89)90019-8; MEER P, 1988, CARTR373 U MAR COMP; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; POGGIO T, 1988, APR P DARPA IM UND W, P177; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; VOORHEES H, 1987, FEB P IM UND WORKSH, P892; [No title captured]	16	88	105	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					216	223		10.1109/34.44408	http://dx.doi.org/10.1109/34.44408			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282					2022-12-18	WOS:A1990CL28200010
J	BOYER, KL; KAK, AC				BOYER, KL; KAK, AC			STRUCTURAL STEREOPSIS FOR 3-D VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV, SCH ELECT ENGN, ROBOT VIS LAB, W LAFAYETTE, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus								ABRAMSON N, 1963, INFORMATION THEORY C; ARNOLD RD, 1978, P IMAGE UNDERSTANDIN, P65; BAKER HH, 1979, 7TH P INT JOINT C AR, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Boyer K. L., 1986, IEEE Expert, V1, P73, DOI 10.1109/MEX.1986.4306982; Boyer K. L., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P45; BOYER KL, 1986, TREE8612 PURD U SCH; BURR DJ, 1977, 5TH P INT JOINT C AR, P583; DRESCHLER LS, 1983, IMAGE SEQUENCE PROCE; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P633, DOI 10.1109/TPAMI.1981.4767164; GRIMSON WEL, 1981, IMAGES SURFACES COMP; GRIMSON WEL, 1984, MIT AI762 MEM; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1983, IEEE T PATTERN ANAL, V5, P417, DOI 10.1109/TPAMI.1983.4767411; KAK AC, 1986, HDB IND ROBOTICS, P272; KAK AC, 1986, TECHNIQUES 3D MACHIN, P185; Lawton D. T., 1982, Proceedings of the Workshop on Computer Vision: Representation and Control, P59; Lee H. S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1178; MARR D, 1981, VISION COMPUTATIONAL; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1984, IEEE T PATTERN ANAL, V6, P675, DOI 10.1109/TPAMI.1984.4767592; Moravec, 1981, IJCAI, V81, P785, DOI DOI 10.1007/S00427-011-0383-3; SAKAI T, 1972, COMPUT GRAPHICS IMAG, V1, P81; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7, P90, DOI 10.1109/TPAMI.1985.4767621; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHNEIER M, 1979, 6TH P IJCAI TOK, P818; SHVAYSTER H, P CVPR 85 SAN FRANCI, P320; Van Trees H., 2013, DETECTION ESTIMATION; WILLIAMS TD, 1983, IMAGE SEQUENCE PROCE; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WONG AKC, 1980, IEEE T PATTERN ANAL, V2, P341, DOI 10.1109/TPAMI.1980.4767033; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	36	88	89	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					144	166		10.1109/34.3880	http://dx.doi.org/10.1109/34.3880			23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400002
J	GOSHTASBY, A				GOSHTASBY, A			TEMPLATE MATCHING IN ROTATED IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GOSHTASBY, A (corresponding author), UNIV KENTUCKY,DEPT COMP SCI,LEXINGTON,KY 40506, USA.							ANUTA PE, 1969, SOC PHOTO-OPT INSTRU, V7, P168; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; CHANDRA DVS, 1982, APR P SOUTHCON, P549; CLARK CS, 1980, 5TH P INT C PATT REC, P217; Conover W.J., 1980, PRACTICAL NONPARAMET, P216; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GARRET GS, 1976, IEEE T SYST MAN CYBE, V1, P65; GIULIANO VE, 1961, INFORM CONTROL, V4, P332, DOI 10.1016/S0019-9958(61)80049-1; GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532; GOSHTASBY A, 1982, 8TH S MACH PROC REM, P347; HU MK, 1962, T INFORM THEORY, P179; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; SCHUTTE H, 1980, 5TH P INT JOINT C PA, P195; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; SVEDLOW M, 1976, S MACHINE PROCESSING; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8; WONG RY, 1978, IEEE P PATTERN RECOG, P96	18	88	100	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					338	344		10.1109/TPAMI.1985.4767663	http://dx.doi.org/10.1109/TPAMI.1985.4767663			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869269				2022-12-18	WOS:A1985AFM4400009
J	Bolya, D; Zhou, C; Xiao, FY; Lee, YJ				Bolya, Daniel; Zhou, Chong; Xiao, Fanyi; Lee, Yong Jae			YOLACT plus plus Better Real-Time Instance Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Instance segmentation; real time		We present a simple, fully-convolutional model for real-time ( > 30 fps) instance segmentation that achieves competitive results on MS COCO evaluated on a single Titan Xp, which is significantly faster than any previous state-of-the-art approach. Moreover, we obtain this result after training on only one GPU. We accomplish this by breaking instance segmentation into two parallel subtasks: (1) generating a set of prototype masks and (2) predicting per-instance mask coefficients. Then we produce instance masks by linearly combining the prototypes with the mask coefficients. We find that because this process doesn't depend on repooling, this approach produces very high-quality masks and exhibits temporal stability for free. Furthermore, we analyze the emergent behavior of our prototypes and show they learn to localize instances on their own in a translation variant manner, despite being fully-convolutional. We also propose Fast NMS, a drop-in 12 ms faster replacement for standard NMS that only has a marginal performance penalty. Finally, by incorporating deformable convolutions into the backbone network, optimizing the prediction head with better anchor scales and aspect ratios, and adding a novel fast mask re-scoring branch, our YOLACT++ model can achieve 34.1 mAP on MS COCO at 33.5 fps, which is fairly close to the state-of-the-art approaches while still running at real-time.	[Bolya, Daniel] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA; [Zhou, Chong; Xiao, Fanyi; Lee, Yong Jae] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA	University System of Georgia; Georgia Institute of Technology; University of California System; University of California Davis	Zhou, C (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.	dbolya3@gatech.edu; cczhou@ucdavis.edu; fyxiao@ucdavis.edu; yongjaeleel@ucdavis.edu		Xiao, Fanyi/0000-0002-9839-1139; Bolya, Daniel/0000-0003-0223-3599; Zhou, Chong/0000-0002-9776-7739; Lee, Yong Jae/0000-0001-9863-1270	ARO YIP [W911NF17-1-0410]; NSF CAREER [IIS-1751206]; NSF [IIS-1812850]; AWS ML Research Award; Google Cloud Platform research credits; XSEDE [IRI180001]	ARO YIP; NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF(National Science Foundation (NSF)); AWS ML Research Award; Google Cloud Platform research credits(Google Incorporated); XSEDE	This work was supported in part by ARO YIP W911NF17-1-0410, NSF CAREER IIS-1751206, NSF IIS-1812850, AWS ML Research Award, Google Cloud Platform research credits, and XSEDE IRI180001. Daniel Bolya and Chong Zhou contributed equally to this work.	Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113; Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Arnab A, 2017, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2017.100; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305; Benbarka N., ARXIV200202709, P2020; Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925; Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; De Brabandere Bert, 2017, ARXIV170802551; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dvornik N, 2017, IEEE I CONF COMP VIS, P4174, DOI 10.1109/ICCV.2017.447; Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fathi A., 2017, SEMANTIC INSTANCE SE, P3; Fu C-Y, 2019, ARXIV190103353, P190103353; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Harley AW, 2017, IEEE I CONF COMP VIS, P5048, DOI 10.1109/ICCV.2017.539; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657; Jetley S, 2017, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2017.448; Kirillov A, 2017, PROC CVPR IEEE, P7322, DOI 10.1109/CVPR.2017.774; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472; Liang XD, 2018, IEEE T PATTERN ANAL, V40, P2978, DOI 10.1109/TPAMI.2017.2775623; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Neven D, 2019, PROC CVPR IEEE, P8829, DOI 10.1109/CVPR.2019.00904; Newell A, 2017, ADV NEUR IN, V30; Norris Wade, 2019, DISTILL, DOI [10.23915/distill.00021, DOI 10.23915/DISTILL.00021]; Paszke A., 2016, ARXIV PREPRINT ARXIV; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Treml Michael, 2016, MLITS NIPS WORKSH; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yu X., 2007, BMVC, P1; Zhang TZ, 2013, IEEE I CONF COMP VIS, P281, DOI 10.1109/ICCV.2013.42; Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953	55	87	88	27	81	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					1108	1121		10.1109/TPAMI.2020.3014297	http://dx.doi.org/10.1109/TPAMI.2020.3014297			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32755851	Green Submitted			2022-12-18	WOS:000740006100040
J	Deng, WH; Hu, JN; Guo, J				Deng, Weihong; Hu, Jiani; Guo, Jun			Face Recognition via Collaborative Representation: Its Discriminant Nature and Superposed Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse representation; collaborative representation; sparse subspace clustering; face clustering; face recognition	100-PERCENT ACCURACY; ROBUST; IMAGE; CLASSIFICATION; DICTIONARY; EXTRACTION; FRAMEWORK	Collaborative representation methods, such as sparse subspace clustering (SSC) and sparse representation-based classification (SRC), have achieved great success in face clustering and classification by directly utilizing the training images as the dictionary bases. In this paper, we reveal that the superior performance of collaborative representation relies heavily on the sufficiently large class separability of the controlled face datasets such as Extended Yale B. On the uncontrolled or undersampled dataset, however, collaborative representation suffers from the misleading coefficients of the incorrect classes. To address this limitation, inspired by the success of linear discriminant analysis (LDA), we develop a superposed linear representation classifier (SLRC) to cast the recognition problem by representing the test image in term of a superposition of the class centroids and the shared intra-class differences. In spite of its simplicity and approximation, the SLRC largely improves the generalization ability of collaborative representation, and competes well with more sophisticated dictionary learning techniques, on the experiments of AR and FRGC databases. Enforced with the sparsity constraint, SLRC achieves the state-of-the-art performance on FERET database using single sample per person.	[Deng, Weihong; Hu, Jiani; Guo, Jun] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China	Beijing University of Posts & Telecommunications	Deng, WH (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.	whdeng@bupt.edu.cn; jnhu@bupt.edu.cn; guojun@bupt.edu.cn	Deng, Wei/GWC-9207-2022	Deng, Weihong/0000-0001-5952-6996	National Natural Science Foundation of China [61573068, 61471048, 61375031, 61532006]; Beijing Nova Program [Z161100004916088]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Nova Program(Beijing Municipal Science & Technology Commission)	The authors would like to thank the anonymous reviewers for their thoughtful and constructive remarks that are helpful to improve the quality of this paper. This work was partially supported by the National Natural Science Foundation of China under Grants 61573068, 61471048, 61375031, and 61532006, Beijing Nova Program under Grant No. Z161100004916088.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208; Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Dago-Casas P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2152, DOI 10.1109/ICCVW.2011.6130514; Deng WH, 2008, SCIENCE, V321, DOI 10.1126/science.1157523; Deng WH, 2014, PATTERN RECOGN, V47, P3738, DOI 10.1016/j.patcog.2014.06.020; Deng WH, 2014, IEEE T PATTERN ANAL, V36, P1275, DOI 10.1109/TPAMI.2013.194; Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58; Deng WH, 2012, PATTERN RECOGN, V45, P4438, DOI 10.1016/j.patcog.2012.06.010; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Deng WH, 2010, PATTERN RECOGN, V43, P2210, DOI 10.1016/j.patcog.2009.12.026; Deng WH, 2010, PATTERN RECOGN, V43, P1748, DOI 10.1016/j.patcog.2009.12.004; Deng WH, 2005, LECT NOTES COMPUT SC, V3723, P336; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365; Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Jenkins R, 2008, SCIENCE, V319, P435, DOI 10.1126/science.1149656; Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708; Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453; Jiang XD, 2011, IEEE SIGNAL PROC MAG, V28, P16, DOI 10.1109/MSP.2010.939041; Jiang XD, 2009, IEEE T PATTERN ANAL, V31, P931, DOI 10.1109/TPAMI.2008.258; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Kong S, 2012, LECT NOTES COMPUT SC, V7572, P186, DOI 10.1007/978-3-642-33718-5_14; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Martinez A., 1998, AR FACE DATABASE; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Penrose R., 1955, P CAMBRIDGE PHILOS S, V51, P406, DOI [10.1017/S0305004100030401, DOI 10.1017/S0305004100030401]; Phillips J.J., 2005, PROC CVPR IEEE, V1, P947, DOI DOI 10.1109/CVPR.2005.268; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; RAMIREZ I, 2010, PROC CVPR IEEE, P3501, DOI DOI 10.1109/CVPR.2010.5539964; Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Wright J., 2011, ARXIV11111014; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]; Zhou N, 2014, IEEE T PATTERN ANAL, V36, P715, DOI 10.1109/TPAMI.2013.189; Zhu M., 2006, RROC INT C COMP VIS, V1, P132, DOI DOI 10.1109/CVPR.2006.271	50	87	89	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2513	2521		10.1109/TPAMI.2017.2757923	http://dx.doi.org/10.1109/TPAMI.2017.2757923			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28976311				2022-12-18	WOS:000443875500017
J	Franczak, BC; Browne, RP; McNicholas, PD				Franczak, Brian C.; Browne, Ryan P.; McNicholas, Paul D.			Mixtures of Shifted Asymmetric Laplace Distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical computing; multivariate statistics	MAXIMUM-LIKELIHOOD-ESTIMATION; PROTEIN LOCALIZATION SITES; T-FACTOR ANALYZERS; DISCRIMINANT-ANALYSIS; VARIABLE SELECTION; MODEL; EXPRESSION	A mixture of shifted asymmetric Laplace distributions is introduced and used for clustering and classification. A variant of the EM algorithm is developed for parameter estimation by exploiting the relationship with the generalized inverse Gaussian distribution. This approach is mathematically elegant and relatively computationally straightforward. Our novel mixture modelling approach is demonstrated on both simulated and real data to illustrate clustering and classification applications. In these analyses, our mixture of shifted asymmetric Laplace distributions performs favourably when compared to the popular Gaussian approach. This work, which marks an important step in the non-Gaussian model-based clustering and classification direction, concludes with discussion as well as suggestions for future work.	[Franczak, Brian C.; Browne, Ryan P.; McNicholas, Paul D.] Univ Guelph, Dept Math & Stat, Guelph, ON N1G 2W1, Canada	University of Guelph	Franczak, BC (corresponding author), Univ Guelph, Dept Math & Stat, Guelph, ON N1G 2W1, Canada.	bfrancza@uoguelph.ca; rbrowne@uoguelph.ca; paul.mcnicholas@uoguelph.ca		McNicholas, Paul/0000-0002-2482-523X; Browne, Ryan/0000-0003-4543-0218	Ontario Graduate Scholarship; Ontario Ministry of Research and Innovation; Natural Sciences and Engineering Research Council of Canada	Ontario Graduate Scholarship(Ontario Graduate Scholarship); Ontario Ministry of Research and Innovation(Ministry of Research and Innovation, Ontario); Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	The authors gratefully acknowledge the helpful comments of two anonymous reviewers and an associate editor. This work was supported by an Ontario Graduate Scholarship (Franczak), the University Research Chair in Computational Statistics (McNicholas), an Early Researcher Award from the Ontario Ministry of Research and Innovation (McNicholas), and respective Discovery Grants from the Natural Sciences and Engineering Research Council of Canada (Browne, McNicholas).	Aitken AC, 1926, P R SOC EDINB, V46, P289, DOI DOI 10.1017/S0370164600022070; Ali MM, 2010, BRAZ J PROBAB STAT, V24, P1, DOI 10.1214/08-BJPS100; Andrews JL, 2011, J STAT PLAN INFER, V141, P1479, DOI 10.1016/j.jspi.2010.10.014; Baek J, 2011, BIOINFORMATICS, V27, P1269, DOI 10.1093/bioinformatics/btr112; Baek J, 2010, IEEE T PATTERN ANAL, V32, P1298, DOI 10.1109/TPAMI.2009.149; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Barndorff-Nielsen O., 1977, PROBAB THEORY REL, V38, P309, DOI [10.1007/BF00533162, DOI 10.1007/bf00533162]; Baudry JP, 2010, J COMPUT GRAPH STAT, V19, P332, DOI 10.1198/jcgs.2010.08111; Bhowmick D, 2006, BIOSTATISTICS, V7, P630, DOI 10.1093/biostatistics/kxj032; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Blaesild P., 1978, 37 AARH U DEP THEOR; BOHNING D, 1994, ANN I STAT MATH, V46, P373, DOI 10.1007/BF01720593; Bolin D., 2011, 12060622 ARXIV; Browne RP, 2012, IEEE T PATTERN ANAL, V34, P814, DOI 10.1109/TPAMI.2011.199; CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6; Cord A, 2006, PATTERN RECOGN LETT, V27, P627, DOI 10.1016/j.patrec.2005.09.028; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Eltoft T, 2006, IEEE SIGNAL PROC LET, V13, P300, DOI 10.1109/LSP.2006.870353; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Gallegos MT, 2005, ANN STAT, V33, P347, DOI 10.1214/009053604000000940; Ghahramani Z, 1997, CRGTR961; HALGREEN C, 1979, Z WAHRSCHEINLICHKEIT, V47, P13, DOI 10.1007/BF00533246; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Hennig Christian, 2010, Advances in Data Analysis and Classification, V4, P3, DOI 10.1007/s11634-010-0058-3; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jorgensen B., 1982, STAT PROPERTIES GENE; Karlis D, 2007, J STAT PLAN INFER, V137, P1942, DOI 10.1016/j.jspi.2006.07.001; Karlis D, 2009, STAT COMPUT, V19, P73, DOI 10.1007/s11222-008-9072-0; Kotz S., 2001, LAPLACE DISTRIBUTION; Lee S., 2011, 11094706 ARXIV; Lin TI, 2009, J MULTIVARIATE ANAL, V100, P257, DOI 10.1016/j.jmva.2008.04.010; Lin TI, 2010, STAT COMPUT, V20, P343, DOI 10.1007/s11222-009-9128-9; Lindsay B.G., 1995, SERIES PROBABILITY S, V5; Maugis C, 2009, BIOMETRICS, V65, P701, DOI 10.1111/j.1541-0420.2008.01160.x; McLachlan G., 2000, P 17 INT C MACHINE L, P599; McLachlan G. J., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P658, DOI 10.1007/BFb0033290; McLachlan GJ, 2007, COMPUT STAT DATA AN, V51, P5327, DOI 10.1016/j.csda.2006.09.015; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; McNicholas PD, 2010, COMPUT STAT DATA AN, V54, P711, DOI 10.1016/j.csda.2009.02.011; McNicholas P.D., 2013, J ROYAL STAT SOC C, V62, P352; McNicholas PD, 2012, J STAT PLAN INFER, V142, P1114, DOI 10.1016/j.jspi.2011.11.026; McNicholas PD, 2010, BIOINFORMATICS, V26, P2705, DOI 10.1093/bioinformatics/btq498; McNicholas PD, 2010, J STAT PLAN INFER, V140, P1175, DOI 10.1016/j.jspi.2009.11.006; McNicholas PD, 2008, STAT COMPUT, V18, P285, DOI 10.1007/s11222-008-9056-0; Mitianoudis N, 2005, IEEE SIGNAL PROC LET, V12, P277, DOI 10.1109/LSP.2005.843759; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; Punzo A, 2013, 13054669 ARXIV; Pyne S, 2009, P NATL ACAD SCI USA, V106, P8519, DOI 10.1073/pnas.0903028106; R Development Core Team, 2018, R LANG ENV STAT COMP; Raftery AE, 2006, J AM STAT ASSOC, V101, P168, DOI 10.1198/016214506000000113; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Sahu SK, 2003, CAN J STAT, V31, P129, DOI 10.2307/3316064; SCALLAN AJ, 1992, J ROY STAT SOC D-STA, V41, P227; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Scrucca L, 2010, STAT COMPUT, V20, P471, DOI 10.1007/s11222-009-9138-7; Shi F, 2006, IEEE IMAGE PROC, P2625, DOI 10.1109/ICIP.2006.313048; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Titterington DM, 1985, STAT ANAL FINITE MIX; Vrbik I, 2012, STAT PROBABIL LETT, V82, P1169, DOI 10.1016/j.spl.2012.02.020; Zhou H, 2010, SCAND J STAT, V37, P612, DOI 10.1111/j.1467-9469.2009.00681.x	63	87	87	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1149	1157		10.1109/TPAMI.2013.216	http://dx.doi.org/10.1109/TPAMI.2013.216			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353277	Green Submitted			2022-12-18	WOS:000337124200008
J	Zia, MZ; Stark, M; Schiele, B; Schindler, K				Zia, M. Zeeshan; Stark, Michael; Schiele, Bernt; Schindler, Konrad			Detailed 3D Representations for Object Recognition and Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D representation; recognition; single image 3D reconstruction; scene understanding; ultrawide baseline matching	ORGANIZATION; TRACKING	Geometric 3D reasoning at the level of objects has received renewed attention recently in the context of visual scene understanding. The level of geometric detail, however, is typically limited to qualitative representations or coarse boxes. This is linked to the fact that today's object class detectors are tuned toward robust 2D matching rather than accurate 3D geometry, encouraged by bounding-box-based benchmarks such as Pascal VOC. In this paper, we revisit ideas from the early days of computer vision, namely, detailed, 3D geometric object class representations for recognition. These representations can recover geometrically far more accurate object hypotheses than just bounding boxes, including continuous estimates of object pose and 3D wireframes with relative 3D positions of object parts. In combination with robust techniques for shape description and inference, we outperform state-of-the-art results in monocular 3D pose estimation. In a series of experiments, we analyze our approach in detail and demonstrate novel applications enabled by such an object class representation, such as fine-grained categorization of cars and bicycles, according to their 3D geometry, and ultrawide baseline matching.	[Zia, M. Zeeshan; Schindler, Konrad] ETH, Photogrammetry & Remote Sensing Lab, Inst Geodesy & Photogrammetry, CH-8093 Zurich, Switzerland; [Stark, Michael] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Schiele, Bernt] Max Planck Inst Informat, Comp Vis & Multimodal Comp Lab, D-66123 Saarbrucken, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; Stanford University; Max Planck Society	Zia, MZ (corresponding author), ETH, Photogrammetry & Remote Sensing Lab, Inst Geodesy & Photogrammetry, HIL D42-3,Wolfgang Pauli Str 15, CH-8093 Zurich, Switzerland.	mzia@ethz.ch; mst@stanford.edu; schiele@mpi-inf.mpg.de; konrads@ethz.ch		Pauldurai, Jona/0000-0002-7217-0872	Max Planck Center for Visual Computing and Communication	Max Planck Center for Visual Computing and Communication	The authors thank Bojan Pepik for providing his detections [45] for use as initialization. This work was supported by the Max Planck Center for Visual Computing and Communication.	Agarwal S., 2002, P EUR C COMP VIS; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Arie-Nachimson M., 2009, P IEEE INT C COMP VI; Bao SYZ, 2011, PROC CVPR IEEE; Barinova O., 2010, P EUR C COMP VIS; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; Chen Y., 2010, P EUR C COMP VIS; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farrell R., 2011, P IEEE INT C COMP VI; Fergus R, 2003, PROC CVPR IEEE, P264; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Glasner D., 2011, P IEEE INT C COMP VI; Gu C., 2010, P EUR C COMP VIS; Gupta A., 2010, P EUR C COMP VIS; Haag M, 1999, INT J COMPUT VISION, V35, P295, DOI 10.1023/A:1008112528134; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Hedau V., 2010, P EUR C COMP VIS; Hejrati M., 2012, P NEUR INF PROC SYST; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LEIBE B, 2006, CATEGORY LEVEL OBJEC; Leistner C., 2010, THESIS TU GRAZ; Leordeanu M., 2008, P IEEE C COMP VIS PA; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Li Y, 2011, IEEE T PATTERN ANAL, V33, P1860, DOI 10.1109/TPAMI.2011.40; Liebelt J, 2008, PROC CVPR IEEE, P2118; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Lopez-Sastre RJ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130367; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Menze B. H., 2011, P EUR C MACH LEARN K; Nilsback M., 2008, P 6 IND C COMP VIS G; Ozuysal M., 2009, P IEEE C COMP VIS PA; Payet N., 2011, P IEEE INT C COMP VI; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Roberts L.G., 1963, THESIS MIT; SALAKHUTDINOV R., 2011, P IEEE C COMP VIS PA; SAVARESE S., 2007, P IEEE INT C COMP VI; Schneiderman H., 2000, P IEEE C COMP VIS PA; SHAH M., 2007, P IEEE INT C COMP VI; Shalom S., 2008, P EUR S 3D OBJ RETR; Stark M., 2010, P BRIT MACH VIS C; Su H., 2009, ICCV; Sullivan G. D., 1995, P IEEE WORKSH CONT B; Sun M., 2010, P EUR C COMP VIS; Thomas A., 2006, P IEEE C COMP VIS PA; Vedaldi A., 2008, P INT C MULT; Villamizar M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.20; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang H., 2010, ECCV; Wojek C., 2010, P EUR C COMP VIS; Xiang Y., 2012, P IEEE C COMP VIS PA; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; ZHU L., 2010, P IEEE C COMP VIS PA; Zia M.Z, 2013, P IEEE C COMP VIS PA; Zia MZ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)	66	87	90	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2608	2623		10.1109/TPAMI.2013.87	http://dx.doi.org/10.1109/TPAMI.2013.87			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051723				2022-12-18	WOS:000324830900004
J	Ertekin, S; Bottou, L; Giles, CL				Ertekin, Seyda; Bottou, Leon; Giles, C. Lee			Nonconvex Online Support Vector Machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Online learning; nonconvex optimization; support vector machines; active learning		In this paper, we propose a nonconvex online Support Vector Machine (SVM) algorithm (LASVM-NC) based on the Ramp Loss, which has the strong ability of suppressing the influence of outliers. Then, again in the online learning setting, we propose an outlier filtering mechanism (LASVM-I) based on approximating nonconvex behavior in convex optimization. These two algorithms are built upon another novel SVM algorithm (LASVM-G) that is capable of generating accurate intermediate models in its iterative steps by leveraging the duality gap. We present experimental results that demonstrate the merit of our frameworks in achieving significant robustness to outliers in noisy data classification where mislabeled training instances are in abundance. Experimental evaluation shows that the proposed approaches yield a more scalable online SVM algorithm with sparser models and less computational running time, both in the training and recognition phases, without sacrificing generalization performance. We also point out the relation between nonconvex optimization and min-margin active learning.	[Ertekin, Seyda] MIT, Alfred P Sloan Sch Management, Cambridge, MA 02139 USA; [Bottou, Leon] NEC Labs Amer, Princeton, NJ 08540 USA; [Giles, C. Lee] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA	Massachusetts Institute of Technology (MIT); NEC Corporation; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Ertekin, S (corresponding author), MIT, Alfred P Sloan Sch Management, Cambridge, MA 02139 USA.	seyda@mit.edu; leon@bottou.org; giles@ist.psu.edu	Ertekin, Seyda/N-9066-2013; Ertekin, Seyda/AAP-5301-2021	Giles, C Lee/0000-0002-1931-585X				Bordes A, 2005, J MACH LEARN RES, V6, P1579; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Collobert R., 2006, P 23 INT C MACHINE L, P201, DOI DOI 10.1145/1143844.1143870.; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Ertekin S, 2007, P 16 ACM C CONFERENC, P127, DOI [10.1145/1321440.1321461, DOI 10.1145/1321440.1321461]; Glasmachers T, 2008, NEURAL COMPUT, V20, P374, DOI 10.1162/neco.2007.10-06-354; JOACHIMS T, 1997, 23 U DORTM; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Krause N., 2004, P 21 INT C MACH LEAR, P63; Liu YF, 2005, J COMPUT GRAPH STAT, V14, P219, DOI 10.1198/106186005X37238; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; Perez-Cruz F, 2003, IEEE T NEURAL NETWOR, V14, P296, DOI 10.1109/TNN.2003.809399; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Schohn G., 2000, P INT C MACH LEARN, P839; Scholkopf B., 2001, LEARNING KERNELS SUP; Shalev-Shwartz S., 2008, P 25 INT C MACH LEAR, V307, P928, DOI DOI 10.1145/1390156.1390273; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; STEINWART I, 2003, J MACHINE LEARNING R, V4, P1071; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Wang L, 2008, NEUROCOMPUTING, V71, P3020, DOI 10.1016/j.neucom.2007.12.032; XU DSL, 2006, P 21 NAT C ART INT; Yuille A., 2002, ADV NEURAL INFORM PR	23	87	97	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					368	381		10.1109/TPAMI.2010.109	http://dx.doi.org/10.1109/TPAMI.2010.109			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20513924				2022-12-18	WOS:000285313200012
J	Ding, LY; Martinez, AM				Ding, Liya; Martinez, Aleix M.			Features versus Context: An Approach for Precise and Detailed Detection and Delineation of Faces and Facial Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face detection; facial feature detection; shape extraction; subclass learning; discriminant analysis; adaptive boosting; face recognition; American sign language; nonmanuals	DISCRIMINANT-ANALYSIS; PEDESTRIAN DETECTION; OBJECT DETECTION; CASCADE; IMAGES; MODELS; CLASSIFICATION; RECOGNITION; VIEW	The appearance-based approach to face detection has seen great advances in the last several years. In this approach, we learn the image statistics describing the texture pattern (appearance) of the object class we want to detect, e.g., the face. However, this approach has had limited success in providing an accurate and detailed description of the internal facial features, i.e., eyes, brows, nose, and mouth. In general, this is due to the limited information carried by the learned statistical model. While the face template is relatively rich in texture, facial features (e.g., eyes, nose, and mouth) do not carry enough discriminative information to tell them apart from all possible background images. We resolve this problem by adding the context information of each facial feature in the design of the statistical model. In the proposed approach, the context information defines the image statistics most correlated with the surroundings of each facial component. This means that when we search for a face or facial feature, we look for those locations which most resemble the feature yet are most dissimilar to its context. This dissimilarity with the context features forces the detector to gravitate toward an accurate estimate of the position of the facial feature. Learning to discriminate between feature and context templates is difficult, however, because the context and the texture of the facial features vary widely under changing expression, pose, and illumination, and may even resemble one another. We address this problem with the use of subclass divisions. We derive two algorithms to automatically divide the training samples of each facial feature into a set of subclasses, each representing a distinct construction of the same facial component (e.g., closed versus open eyes) or its context (e. g., different hairstyles). The first algorithm is based on a discriminant analysis formulation. The second algorithm is an extension of the AdaBoost approach. We provide extensive experimental results using still images and video sequences for a total of 3,930 images. We show that the results are almost as good as those obtained with manual detection.	[Ding, Liya; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Dreese Lab 205, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Ding, LY (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Dreese Lab 205, 2015 Neil Ave, Columbus, OH 43210 USA.	dingl@ece.osu.edu; aleix@ece.osu.edu	Ding, Liya/B-8869-2014; Martinez, Aleix M/A-2380-2008	Ding, Liya/0000-0002-1209-875X; 	US National Science Foundation (NSF) [0713055]; US National Institutes of Health (NIH) [R01 DC 005241]; NATIONAL EYE INSTITUTE [R01EY020834] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC005241, R21DC011081] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	The authors thank the reviewers for their constructive comments. This research was partially supported by US National Science Foundation (NSF) Grant 0713055 and US National Institutes of Health (NIH) Grant R01 DC 005241.	Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55; Bartlett PL, 2007, J MACH LEARN RES, V8, P2347; Carneiro G, 2008, P IEEE C COMP VIS PA; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32; De la Torre F., 2008, P IEEE C COMP VIS PA; DELATORRE F, 2007, P IEEE INT C COMP VI; Ding L., 2008, P IEEE C COMP VIS PA; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Ekman P., 2002, FACIAL ACTION CODING; Escalera S, 2008, IEEE T PATTERN ANAL, V30, P1041, DOI 10.1109/TPAMI.2008.38; Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z; Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; LAPEDRIZA A, 2008, P IEEE C PATT REC CO; LI P, 2009, P IEEE C COMP VIS PA; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6; Liang L, 2006, LECT NOTES COMPUT SC, V3954, P333; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Makinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800; Martinez A., 1998, 24 CVC, P24; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Martinez AM, 2004, COMPUT VIS IMAGE UND, V95, P72, DOI 10.1016/j.cviu.2004.01.003; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; MESSING MS, 1999, GESTURE SPEECH SIGN; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37; Moon H, 2002, IEEE T IMAGE PROCESS, V11, P1209, DOI 10.1109/TIP.2002.800896; Moriyama T, 2006, IEEE T PATTERN ANAL, V28, P738, DOI 10.1109/TPAMI.2006.98; Paisitkriangkcrai S, 2008, IEEE T CIRC SYST VID, V18, P1140, DOI 10.1109/TCSVT.2008.928213; PATRAS I, 2007, P IEEE C COMP VIS PA; Romdhani S., 2007, P IEEE C COMP VIS PA; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Tang XS, 2005, LECT NOTES COMPUT SC, V3497, P93; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692; WANG P, 2005, P IEEE C COMP VIS PA; Wolf L., 2008, P EUR C COMP VIS WOR; Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0; Wu JX, 2008, IEEE T PATTERN ANAL, V30, P369, DOI 10.1109/TPAMI.2007.1181; Yang M, 2009, ENCY BIOMETRICS; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhao HT, 2008, IEEE T SYST MAN CY B, V38, P210, DOI 10.1109/TSMCB.2007.908870; ZHOU S, 2004, P INT C PATT REC; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	56	87	89	0	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2022	2038		10.1109/TPAMI.2010.28	http://dx.doi.org/10.1109/TPAMI.2010.28			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847391	Green Accepted			2022-12-18	WOS:000281990900007
J	Yager, N; Dunstone, T				Yager, Neil; Dunstone, Ted			The Biometric Menagerie	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; performance evaluation; authentication; identification; recognition; fingerprint; face; speech; iris; keystroke dynamics		It is commonly accepted that users of a biometric system may have differing degrees of accuracy within the system. Some people may have trouble authenticating, while others may be particularly vulnerable to impersonation. Goats, wolves, and lambs are labels commonly applied to these problem users. These user types are defined in terms of verification performance when users are matched against themselves (goats) or when matched against others (lambs and wolves). The relationship between a user's genuine and impostor match results suggests four new user groups: worms, doves, chameleons, and phantoms. We establish formal definitions for these animals and a statistical test for their existence. A thorough investigation is conducted using a broad range of biometric modalities, including 2D and 3D faces, fingerprints, iris, speech, and keystroke dynamics. Patterns that emerge from the results expose novel, important, and encouraging insights into the nature of biometric match results. A new framework for the evaluation of biometric systems based on the biometric menagerie, as opposed to collective statistics, is proposed.	[Yager, Neil; Dunstone, Ted] Biometix Pty Ltd, Natl Innovat Ctr, Eveleigh, NSW 1430, Australia		Yager, N (corresponding author), Biometix Pty Ltd, Natl Innovat Ctr, Suite 145,Australian Technol Pk, Eveleigh, NSW 1430, Australia.	neil@biometix.com; ted@biometix.com						[Anonymous], [No title captured]; ATKINSON TJ, 2004, P BIOM AUTH EUR C CO; Authi-Corp, 2007, IRIS06 DRAFT FIN REP; Bolle R., 2003, GUIDE BIOMETRICS; Chen K, 2003, PATTERN RECOGN, V36, P329, DOI 10.1016/S0031-3203(02)00034-1; Cook J., 2006, P BRIT MACH VIS C; Doddington G., 1998, P INT C SPOK LANG PR; Dunstone T, 2008, BIOMETRIC SYSTEM DAT, P111; Gunetti D., 2005, ACM Transactions on Information and Systems Security, V8, P312, DOI 10.1145/1085126.1085129; Hicklin A., 2005, 7271 NIST IR; Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144; Phillips P.J., 2005, P IEEE C COMP VIS PA; Poh N, 2006, PATTERN RECOGN, V39, P223, DOI 10.1016/j.patcog.2005.06.011; POH N, 2009, P MULT US AUTH WORKS; Poh N, 2008, IEEE T AUDIO SPEECH, V16, P594, DOI 10.1109/TASL.2008.916525; Prabhakar S., 2003, HDB FINGERPRINT RECO; Ramos-Castro D, 2007, PATTERN RECOGN LETT, V28, P90, DOI 10.1016/j.patrec.2006.06.008; Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57; WAYMAN JL, 1999, MULTIFINGER PENETRAT; Wittman M., 2006, P COMP VIS PATT REC; Yager N, 2006, PATTERN RECOGN LETT, V27, P317, DOI 10.1016/j.patrec.2005.08.016; YAGER N, 2007, P AUTOID; 2007, PERFORMIX BIOMETRIC	23	87	88	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					220	230		10.1109/TPAMI.2008.291	http://dx.doi.org/10.1109/TPAMI.2008.291			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075454				2022-12-18	WOS:000272741500003
J	Bigun, J; Bigun, T; Nilsson, K				Bigun, J; Bigun, T; Nilsson, K			Recognition by symmetry derivatives and the generalized structure tensor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussians; orientation fields; structure tensor; differential invariants; cross detection; fingerprints; tensor voting; tracking; filtering; feature measurement; wavelets and fractals; moments; invariants; vision and scene understanding; representations; shape; tracking; registration; alignment	MOMENT INVARIANTS; SEGMENTATION; FINGERPRINTS; TRANSFORMS	We suggest a set of complex differential operators that can be used to produce and filter dense orientation ( tensor) fields for feature extraction, matching, and pattern recognition. We present results on the invariance properties of these operators, that we call symmetry derivatives. These show that, in contrast to ordinary derivatives, all orders of symmetry derivatives of Gaussians yield a remarkable invariance: They are obtained by replacing the original differential polynomial with the same polynomial, but using ordinary coordinates x and y corresponding to partial derivatives. Moreover, the symmetry derivatives of Gaussians are closed under the convolution operator and they are invariant to the Fourier transform. The equivalent of the structure tensor, representing and extracting orientations of curve patterns, had previously been shown to hold in harmonic coordinates in a nearly identical manner. As a result, positions, orientations, and certainties of intricate patterns, e. g., spirals, crosses, parabolic shapes, can be modeled by use of symmetry derivatives of Gaussians with greater analytical precision as well as computational efficiency. Since Gaussians and their derivatives are utilized extensively in image processing, the revealed properties have practical consequences for local orientation based feature extraction. The usefulness of these results is demonstrated by two applications: 1) tracking cross markers in long image sequences from vehicle crash tests and 2) alignment of noisy fingerprints.	Halmstad Univ, SE-30118 Halmstad, Sweden; TietoEnator AB, S-58223 Linkoping, Sweden	Halmstad University	Bigun, J (corresponding author), Halmstad Univ, Box 823, SE-30118 Halmstad, Sweden.	josef.bigun@ide.hh.se; tomas.bigun@tietoenator.com; kenneth.nilsson@ide.hh.se						ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; BIGUN J, 1988, P 9 ICPR ROM, P345; BIGUN J, 2001, HHIDE131 HALMST U; Black MJ, 1993, P 4 INT C COMP VIS, P231, DOI DOI 10.1109/ICCV.1993.378214; BURKHARDT H, 1979, THESIS U KARLSRUHE, V10; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; Danielsson P.-E., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P1171; Danielsson PE, 2001, J VIS COMMUN IMAGE R, V12, P255, DOI 10.1006/jvci.2000.0472; DUDGEON DE, 1981, MULTIDIMENSIONAL DIG; FERRARO M, 1988, J OPT SOC AM A, V5, P738, DOI 10.1364/JOSAA.5.000738; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HOFFMAN WC, 1966, J MATH PSYCHOL, V3, P65, DOI 10.1016/0022-2496(66)90005-8; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; JOHANSSON B, 2001, THESIS LINKOPING U; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Knutsson H., 1989, Proceedings of 6th Scandinavian Conference on Image Analysis, P244; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; KUNTSSON H, 1988, Patent No. 4747152; LINDEBERG T, 1991, THESIS STOCKHOLM; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; MADIA KV, 1972, STAT DIRECTIONAL DAT; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Medioni G., 2000, COMPUTATIONAL FRAMEW; PERONA P, 1992, P EUR C COMP VIS, P3; RAO A, 1990, TAXONOMY TEXTURE DES; REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087; SIMONCELLI EP, 1996, P 3 INT C IMAG PROC, V3, P185; SLEPIAN D, 1964, BELL SYST TECH J, V43, P3009, DOI 10.1002/j.1538-7305.1964.tb01037.x; Stein E. M., 1971, FOURIER ANAL EUCLIDE; UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515; WILSON R, 1988, IEEE T PATTERN ANAL, V10, P193, DOI 10.1109/34.3882; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	42	87	94	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1590	1605		10.1109/TPAMI.2004.126	http://dx.doi.org/10.1109/TPAMI.2004.126			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573820	Green Published, Green Submitted			2022-12-18	WOS:000224388700005
J	Liu, JM; Tang, YY				Liu, JM; Tang, YY			Adaptive image segmentation with distributed behavior-based agents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						distributed autonomous agents; reactive behavior; evolutionary computation; breeding; diffusion; homogeneous-segment searching; adaptive image segmentation; and agent dynamics		This paper presents an autonomous agent-based image segmentation approach. In this approach, a digital image is viewed as a two-dimensional cellular environment in which the agents inhabit and attempt to label homogeneous segments. In so doing, the agents rely on some reactive behaviors such as breeding and diffusion. The agents that are successful in finding the pixels of a specific homogeneous segment will breed offspring agents inside their neighboring regions. Hence, the offspring agents will become likely to find more homogeneous-segment pixels. In the mean time, the unsuccessful agents will be inactivated, without further search in the environment.	Hong Kong Baptist Univ, Dept Comp Sci, 224 Waterloo Rd, Kowloon, Peoples R China	Hong Kong Baptist University	Liu, JM (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, 224 Waterloo Rd, Kowloon, Peoples R China.	jiming@comp.hkbu.edu.hk; yytang@comp.hkbu.edu.hk						Jain AK, 1996, IEEE T PATTERN ANAL, V18, P195, DOI 10.1109/34.481543; JOHNSON WL, 1997, P 1 INT C AUT AG MAR; LIU J, 1997, IEEE T EVOLUTIONARY, V1, P141, DOI DOI 10.1109/4235.687881; Liu JM, 1998, INT J PATTERN RECOGN, V12, P97, DOI 10.1142/S0218001498000087; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; PAVLIDIS T, 1982, ALGORITHM GRAPHICS I; Pitas I., 2000, DIGITAL IMAGE PROCES; Priebe CE, 1997, IEEE T PATTERN ANAL, V19, P494, DOI 10.1109/34.589209; WU XL, 1992, IEEE T INFORM THEORY, V38, P1755, DOI 10.1109/18.165448; [No title captured]	10	87	104	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					544	551		10.1109/34.771323	http://dx.doi.org/10.1109/34.771323			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD					2022-12-18	WOS:000080819100005
J	HERAULT, L; HORAUD, R				HERAULT, L; HORAUD, R			FIGURE-GROUND DISCRIMINATION - A COMBINATORIAL OPTIMIZATION APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FEATURE GROUPING; FIGURE-GROUND DISCRIMINATION; LOW-LEVEL VISION; MEAN FIELD ANNEALING; MICROCANONICAL ANNEALING; RECURSIVE NEURAL NETWORKS; SIMULATED ANNEALING; STOCHASTIC OPTIMIZATION THEORY; THRESHOLDING		In this paper, we attack the figure-ground discrimination problem from a combinatorial optimization perspective. In general, the solutions proposed in the past solved this problem only partially: Either the mathematical model encoding the figure-ground problem was too simple, the optimization methods that were used were not efficient enough, or they could not guarantee that the global minimum of the cost function describing the figure-ground model would be found. The method that we devised and is described in this paper is tailored around three main contributions. First, we suggest a mathematical model encoding the figure-ground discrimination problem that makes explicit a definition of shape (or figure) based on cocircularity, smoothness, proximity, and contrast. This model consists of building a cost function on the basis of image element interactions. Moreover, this cost function fits the constraints of an interacting spin system that, in turn, is a well suited physical model that solves hard combinatorial optimization problems Second, we suggest two combinatorial optimization methods for solving the figure-ground problem, namely i) mean field annealing, which combines mean field approximation theory and annealing, and ii) microcanonical annnealing. Mean field annealing may well be viewed as a deterministic approximation of stochastic methods such as simulated annealing. We describe, in detail, the theoretical bases of these methods, derive computational models, and provide practical algorithms. Third, we provide a comparison of the efficiency of mean field annealing, simulated annealing, and microcanonical annealing algorithms. Within the framework of such a comparison, the figure-ground problem may well be viewed as a benchmark. Index Terms-Feature grouping, figure-ground discrimination, low-level vision, mean field annealing, microcanonical annealing, recursive neural networks, simulated annealing, stochastic optimization theory, thresholding.	IMAG LAB GRENOBLE, LIFIA, GRENOBLE, FRANCE; ITMI, MEYLAN, FRANCE	UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA)	HERAULT, L (corresponding author), LETI, CEA TECHNOL AVANCEES, DEPT SYST, GRENOBLE, FRANCE.		Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; BLAKE A, 1989, IEEE T PATTERN ANAL, V11, P2, DOI 10.1109/34.23109; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CARNEVALI P, 1985, IBM J RES DEV, V29, P569, DOI 10.1147/rd.296.0569; CREUTZ M, 1983, PHYS REV LETT, V50, P1411, DOI 10.1103/PhysRevLett.50.1411; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GUTFINGER D, 1991, IEEE T PATTERN ANAL, V13, P552, DOI 10.1109/34.87342; HEARULT L, 1989, COMPLEX SYST, V3, P531; HERAULT L, 1991, NEURAL NETWORKS ADV, P165; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOHLER W, 1980, GESTALT PSYCHOL; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; ORLAND H, 1953, J PHYS LETT, V46, pL763; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Peterson C., 1989, International Journal of Neural Systems, V1, P3, DOI 10.1142/S0129065789000414; Peterson C., 1987, Complex Systems, V1, P995; REIF F, 1965, FUNDAMENTALS STATIST; SEJNOWSKI TJ, 1988, VISION BRAIN COOPERA, P703; Stanley H.E., 1971, INTRO PHASE TRANSITI; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; VANDENBOUT DE, 1989, JUN P INT JOINT C NE, P521; ZERUBIA J, 1990, APR P ICASSP ALB, P2193	29	87	98	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					899	914		10.1109/34.232076	http://dx.doi.org/10.1109/34.232076			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676		Green Submitted			2022-12-18	WOS:A1993LW67600004
J	HOULE, ME; TOUSSAINT, GT				HOULE, ME; TOUSSAINT, GT			COMPUTING THE WIDTH OF A SET	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											HOULE, ME (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2K6,QUEBEC,CANADA.			Houle, Michael/0000-0001-8486-8015				BROWN KQ, 1979, GEOMETRIC TRANSFORMS; GUIBAS LJ, 1986, 2ND P ACM S COMP GEO, P90; HOULE ME, 1984, SOCS8422 TECH REP; ICHIDA K, 1975, T ELEC COMMUN ENG D, V58, P689; IMAI H, IN PRESS COMPUTATION; KIRKPATRICK DG, 1982, 83577 CORN U DEP COM; KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9; LEE DT, 1980, 8003FC01 NW U TECH R; MCCALLUM D, 1979, INFORM PROCESSIN DEC, P201; MCQUEEN MM, 1985, PATTERN RECOGNIT JAN, P29; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; Shamos M.I., 1978, THESIS YALE U; Toussaint G., 1985, COMPUTATIONAL GEOMET, P335; TOUSSAINT G, UNPUB APPROXIMATING; TOUSSAINT GT, 1983, P MELECON 83 ATHENS	15	87	89	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					761	765		10.1109/34.6790	http://dx.doi.org/10.1109/34.6790			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500021
J	BHANU, B				BHANU, B			REPRESENTATION AND SHAPE-MATCHING OF 3-D OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BHANU, B (corresponding author), FORD AEROSP & COMMUN CORP,DIV AERONAUT,NEWPORT BEACH,CA 92663, USA.			Bhanu, Bir/0000-0001-8971-6416				BADLER N, 1978, COMPUT GRAPHICS, V12, P153; BAJCSY R, 1980, 5TH P INT C PATT REC, P1064; BALLARD DH, 1981, 7TH P IJCAI, P607; BHANU B, 1981, 2ND P SCAND C IM AN, P72; BHANU B, 1981, USCIPI1030 U SO CAL; BHANU B, 1983, 8TH P INT JOINT ART; BINFORD TO, 1971, DEC P IEEE C SYST CO; BOISSONNAT JD, 1981, 7TH P INT JOINT C AR, P658; BOISSONNAT JD, 1981, 7TH P INT JOINT C AR; CHIEN RT, 1974, 2ND P INT JOINT C PA, P496; DUDA RO, 1979, IEEE T PATTERN ANAL, V1, P259, DOI 10.1109/TPAMI.1979.4766922; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; HENDERSON TC, 1982, MAY P WORKSH IND APP, P181; HORN BKP, 1977, OCT P IMAG UND WORKS; INOKUCHI S, 1980, 5TH P INT C PATT REC, P1301; ISHII M, 1976, PATTERN RECOGN, V8, P229, DOI 10.1016/0031-3203(76)90043-1; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; KANADE T, 1977, 5TH P INT JOINT C AR, P1074; MCKEE JW, 1975, PATTERN RECOGN, V7, P25, DOI 10.1016/0031-3203(75)90012-6; MILGRAM DL, 1980, 5TH P INT C PATT REC, P912; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; OSHIMA M, 1981, 7TH P INT JOINT C AR, P601; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; POPPLESTONE RJ, 1975, 4TH P INT JOINT C AR, P664; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990; SHIRAI Y, 1978, 4TH P IJCPR KYOT, P86; UNDERWOOD SA, 1975, IEEE T COMPUT, VC 24, P651, DOI 10.1109/T-C.1975.224277; WALLACE TP, 1981, IEEE T PATTERN ANAL, V3, P310, DOI 10.1109/TPAMI.1981.4767104; ZUCKER SW, 1980, P IEEE C PATTERN REC, P162; [No title captured]	34	87	87	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					340	351		10.1109/TPAMI.1984.4767527	http://dx.doi.org/10.1109/TPAMI.1984.4767527			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869201				2022-12-18	WOS:A1984SR54200010
J	Zhang, DW; Han, JW; Yang, L; Xu, D				Zhang, Dingwen; Han, Junwei; Yang, Le; Xu, Dong			SPFTN: A Joint Learning Framework for Localizing and Segmenting Objects in Weakly Labeled Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Task analysis; Reliability; Supervised learning; Object segmentation; Semantics; Feature extraction; Weakly labeled videos; object segmentation; video object localization; deep neural networks; self-paced learning	CO-SEGMENTATION; EXTRACTION	Object localization and segmentation in weakly labeled videos are two interesting yet challenging tasks. Models built for simultaneous object localization and segmentation have been explored in the conventional fully supervised learning scenario to boost the performance of each task. However, none of the existing works has attempted to jointly learn object localization and segmentation models under weak supervision. To this end, we propose a joint learning framework called Self-Paced Fine-Tuning Network (SPFTN) for localizing and segmenting objects in weakly labelled videos. Learning the deep model jointly for object localization and segmentation under weak supervision is very challenging as the learning process of each single task would face serious ambiguity issue due to the lack of bounding-box or pixel-level supervision. To address this problem, our proposed deep SPFTN model is carefully designed with a novel multi-task self-paced learning objective, which leverages the task-specific prior knowledge and the knowledge that has been already captured to infer the confident training samples for each task. By aggregating the confident knowledge from each single task to mine reliable patterns and learning deep feature representation for both tasks, the proposed learning framework can address the ambiguity issue under weak supervision with simple optimization. Comprehensive experiments on the large-scale YouTube-Objects and DAVIS datasets demonstrate that the proposed approach achieves superior performance when compared with other state-of-the-art methods and the baseline networks/models.	[Zhang, Dingwen; Han, Junwei; Yang, Le] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia	Northwestern Polytechnical University; University of Sydney	Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.	zdw2006yyy@mail.nwpu.edu.cn; junweihan2010@gmail.com; nwpuyangle@gmail.com; dong.xu@sydney.edu.au	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730	National Key R&D Program of China [2017YFB0502904]; National Science Foundation of China [61876140]; China Postdoctoral Support Scheme for Innovative Talents [BX20180236]; Australian Research Council Future Fellowship [FT180100116]	National Key R&D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Support Scheme for Innovative Talents; Australian Research Council Future Fellowship(Australian Research Council)	This work was supported in part by the "National Key R&D Program of China"(2017YFB0502904), the National Science Foundation of China under Grants 61876140, and the China Postdoctoral Support Scheme for Innovative Talents under Grant BX20180236. This research is also partially supported by the Australian Research Council Future Fellowship under Grant FT180100116.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], P IEEE C COMP VIS PA; [Anonymous], PARALLEL DISTRIBUTED; Chen A. Y. C., 2010, Proceedings of 2010 Western New York Image Processing Workshop (WNYIPW), P14, DOI 10.1109/WNYIPW.2010.5649773; Chen D.-J., 2012, P ACM MULT, P805, DOI DOI 10.1145/2393347.2396317; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36; Faktor A., 2014, P BMVC, V2, P8; Fu HZ, 2014, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2014.405; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guo JM, 2013, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2013.278; Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hartmann G, 2012, LECT NOTES COMPUT SC, V7583, P198, DOI 10.1007/978-3-642-33863-2_20; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Joulin A, 2014, LECT NOTES COMPUT SC, V8694, P253, DOI 10.1007/978-3-319-10599-4_17; Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Kumar A, 2010, ASIA PACIF MICROWAVE, P1189; Kwak S, 2015, IEEE I CONF COMP VIS, P3173, DOI 10.1109/ICCV.2015.363; Lai BS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2053; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Liu X, 2014, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2014.15; Lu JS, 2015, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2015.7299000; Niu T, 2016, PROCEEDINGS OF 2016 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P535, DOI 10.1109/ICCSNT.2016.8070216; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen L, 2020, J MED ECON, V23, P456, DOI 10.1080/13696998.2020.1717500; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tokmakov P, 2016, LECT NOTES COMPUT SC, V9908, P388, DOI 10.1007/978-3-319-46493-0_24; Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Xu CL, 2016, PROC CVPR IEEE, P3083, DOI 10.1109/CVPR.2016.336; Xu CL, 2015, PROC CVPR IEEE, P2264, DOI 10.1109/CVPR.2015.7298839; Yan Y, 2017, PROC CVPR IEEE, P1022, DOI 10.1109/CVPR.2017.115; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang DW, 2017, PROC CVPR IEEE, P5340, DOI 10.1109/CVPR.2017.567; Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393; Zhang D, 2014, LECT NOTES COMPUT SC, V8695, P551, DOI 10.1007/978-3-319-10584-0_36; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhang Y, 2015, PROC CVPR IEEE, P3641, DOI 10.1109/CVPR.2015.7298987; Zhao L, 2005, IEEE I CONF COMP VIS, P454	60	86	91	8	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					475	489		10.1109/TPAMI.2018.2881114	http://dx.doi.org/10.1109/TPAMI.2018.2881114			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30442600				2022-12-18	WOS:000508386100017
J	Lu, JW; Liong, VE; Zhou, J				Lu, Jiwen; Liong, Venice Erin; Zhou, Jie			Simultaneous Local Binary Feature Learning and Encoding for Homogeneous and Heterogeneous Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; heterogeneous face matching; feature learning; binary feature; compact feature; biometrics	PATTERNS; GABOR; REPRESENTATION; VERIFICATION; MAGNITUDES; EIGENFACES; HISTOGRAM; MODEL; SCALE	In this paper, we propose a simultaneous local binary feature learning and encoding (SLBFLE) approach for both homogeneous and heterogeneous face recognition. Unlike existing hand-crafted face descriptors such as local binary pattern (LBP) and Gabor features which usually require strong prior knowledge, our SLBFLE is an unsupervised feature learning approach which automatically learns face representation from raw pixels. Unlike existing binary face descriptors such as the LBP, discriminant face descriptor (DFD), and compact binary face descriptor (CBFD) which use a two-stage feature extraction procedure, our SLBFLE jointly learns binary codes and the codebook for local face patches so that discriminative information from raw pixels from face images of different identities can be obtained by using a one-stage feature learning and encoding procedure. Moreover, we propose a coupled simultaneous local binary feature learning and encoding (C-SLBFLE) method to make the proposed approach suitable for heterogenous face matching. Unlike most existing coupled feature learning methods which learn a pair of transformation matrices for each modality, we exploit both the common and specific information from heterogeneous face samples to characterize their underlying correlations. Experimental results on six widely used face datasets including the LFW, YouTube Face (YTF), FERET, PaSC, CASIA VIS-NIR 2.0, and Multi-PIE datasets are presented to demonstrate the effectiveness of the proposed methods.	[Lu, Jiwen; Zhou, Jie] Tsinghua Univ, Natl Lab Informat Sci & Technol TNList, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Liong, Venice Erin] Nanyang Technol Univ, Interdisciplinary Grad Sch, Rapid Rich Object Search ROSE Lab, Singapore 639798, Singapore	Tsinghua University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Lu, JW (corresponding author), Tsinghua Univ, Natl Lab Informat Sci & Technol TNList, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	lujiwen@tsinghua.edu.cn; veniceer001@e.ntu.edu.sg; jzhou@tsinghua.edu.cn	Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2016YFB1001001]; National Natural Science Foundation of China [61672306, 61572271, 61527808, 61373074, 61373090]; National 1000 Young Talents Plan Program; National Basic Research Program of China [2014CB349304]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National 1000 Young Talents Plan Program; National Basic Research Program of China(National Basic Research Program of China); Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program	This work is supported by the National Key Research and Development Program of China under Grant 2016YFB1001001, the National Natural Science Foundation of China under Grants 61672306, 61572271, 61527808, 61373074 and 61373090, the National 1000 Young Talents Plan Program, the National Basic Research Program of China under Grant 2014CB349304, the Ministry of Education of China under Grant 20120002110033, and the Tsinghua University Initiative Scientific Research Program. Part of this work was presented in [1].	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Arashloo S. R., 2013, P IEEE 6 INT C BIOM, P1, DOI DOI 10.1109/BTAS.2013.6712721; Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Beveridge J. R., 2013, P 6 INT C BIOMETRICS, P1; Beveridge JR, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014); Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398; CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314; Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267; Dong Yi, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163093; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hu JL, 2015, LECT NOTES COMPUT SC, V9005, P252, DOI 10.1007/978-3-319-16811-1_17; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang Gary B., 2007, 0749 U MASS, P7; HUANG GB, 2012, PROC CVPR IEEE, P2518, DOI DOI 10.1109/CVPR; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P151; Jin Y, 2015, IEEE T INF FOREN SEC, V10, P640, DOI 10.1109/TIFS.2015.2390414; Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308; Juefei-Xu F, 2015, IEEE T IMAGE PROCESS, V24, P4780, DOI 10.1109/TIP.2015.2468173; Kan M., 2011, BMVC, V11, P125; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243; Le Q.V., 2011, NEURIPS, P1017; Lee H, 2016, ADV NEURAL INFORM PR, V19; Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Li H., 2010, P ACM MSWIM, P17; Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170; Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Lilei Zheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163085; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424; Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359; McCool C, 2013, IET BIOMETRICS, V2, P117, DOI 10.1049/iet-bmt.2012.0059; Mendez-Vazquez H, 2013, INT CONF BIOMETR; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Nguyen Hieu V, 2010, P AS C COMP VIS, P709, DOI DOI 10.1007/978-3-642-19309-5_55; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27; Ouamane A, 2015, IEEE INT CONF AUTOMA; Parkhi Omkar M., 2015, BRIT MACH VIS C; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rastegari M, 2012, LECT NOTES COMPUT SC, V7577, P876, DOI 10.1007/978-3-642-33783-3_63; Saxena S., 2016, P EUR C COMP VIS WOR, P1; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Sharma A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247923; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1; Struc V., 2013, P 22 INT EL COMP SCI, P121; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99; Verschae R., 2008, P WORKSH FAC REAL LI, P1; Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866; Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261; Weiss Y., 2008, NIPS, P1753; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Wolf L., 2008, P REAL LIF IM WORKSH, P1; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Wolf L, 2013, PROC CVPR IEEE, P3523, DOI 10.1109/CVPR.2013.452; Wolf L, 2010, LECT NOTES COMPUT SC, V5995, P88; Xi M, 2016, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP.2016.7532955; Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Ying YM, 2012, J MACH LEARN RES, V13, P1; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang H, 2014, PLANT BIOTECHNOL J, V12, P797, DOI 10.1111/pbi.12200; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	89	86	88	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1979	1993		10.1109/TPAMI.2017.2737538	http://dx.doi.org/10.1109/TPAMI.2017.2737538			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28796611				2022-12-18	WOS:000437271100014
J	Ham, B; Cho, M; Ponce, J				Ham, Bumsub; Cho, Minsu; Ponce, Jean			Robust Guided Image Filtering Using Nonconvex Potentials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Guided image filtering; joint image filtering; nonconvex optimization; majorize-minimization algorithm	HALF-QUADRATIC MINIMIZATION; RESTORATION; SIGNAL	Filtering images using a guidance signal, a process called guided or joint image filtering, has been used in various tasks in computer vision and computational photography, particularly for noise reduction and joint upsampling. This uses an additional guidance signal as a structure prior, and transfers the structure of the guidance signal to an input image, restoring noisy or altered image structure. The main drawbacks of such a data-dependent framework are that it does not consider structural differences between guidance and input images, and that it is not robust to outliers. We propose a novel SD (for static/dynamic) filter to address these problems in a unified framework, and jointly leverage structural information from guidance and input images. Guided image filtering is formulated as a nonconvex optimization problem, which is solved by the majorize-minimization algorithm. The proposed algorithm converges quickly while guaranteeing a local minimum. The SD filter effectively controls the underlying image structure at different scales, and can handle a variety of types of data from different sensors. It is robust to outliers and other artifacts such as gradient reversal and global intensity shift, and has good edge-preserving smoothing properties. We demonstrate the flexibility and effectiveness of the proposed SD filter in a variety of applications, including depth upsampling, scale-space filtering, texture removal, flash/non-flash denoising, and RGB/NIR denoising.	[Ham, Bumsub] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Cho, Minsu] POSTECH, Dept Comp Sci & Engn, Pohang 120749, South Korea; [Ponce, Jean] PSL Res Univ, Ecole Normale Super, F-75005 Paris, France; [Ponce, Jean] ENS, WILLOW Project Team, INRIA, CNRS,UMR 8548, F-75005 Paris, France	Yonsei University; Pohang University of Science & Technology (POSTECH); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite	Ham, B (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.	mimo@yonsei.ac.kr; mscho@postech.ac.kr; jean.ponce@ens.fr	Cho, Minsu/AAR-6323-2020	HAM, BUMSUB/0000-0002-3443-8161	ERC grant VideoWorld; Institut Universitaire de France; Institute for Information & communications Technology Promotion (IITP) grant - Korea government (MSIP) [2016-0-00197]	ERC grant VideoWorld; Institut Universitaire de France; Institute for Information & communications Technology Promotion (IITP) grant - Korea government (MSIP)	The authors would like to thank Francis Bach for helpful discussions. This work was supported in part by the ERC grant VideoWorld and the Institut Universitaire de France. The work of B. Ham was supported by Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea government (MSIP) (No. 2016-0-00197, Development of the high-precision natural 3D view generation technology using smart-car multi sensors and deep learning).	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Badri H, 2015, IEEE T VIS COMPUT GR, V21, P743, DOI 10.1109/TVCG.2015.2396064; Barron JT, 2016, LECT NOTES COMPUT SC, V9907, P617, DOI 10.1007/978-3-319-46487-9_38; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281; Chan Derek, 2008, WORKSH MULT MULT SEN; CHANDRASEKARAN R, 1989, MATH PROGRAM, V44, P293, DOI 10.1007/BF01587094; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; Chen LC, 2015, CORR; CHEN LC, 2016, PROC CVPR IEEE, P4545, DOI DOI 10.1109/CVPR.2016.492; Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995; Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303; Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574; Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666; Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115; Ham B, 2013, IEEE T IMAGE PROCESS, V22, P2574, DOI 10.1109/TIP.2013.2253479; Hampel F., 2011, ROBUST STAT APPROACH; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52; Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403; Kim TH, 2008, LECT NOTES COMPUT SC, V5304, P264; Kohli P., 2008, PRECEEDINGS 2008 IEE, P1, DOI DOI 10.1109/CVPR.2008.4587417; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Lanckriet G. R., 2009, P 22 INT C NEURAL IN, P1759; Lang ML, 2012, PLOS GENET, V8, P623, DOI 10.1371/journal.pgen.1002683; Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780; Li Y., 2016, EUR C COMP VIS; Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13; Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; McLachlan G., 2007, EM ALGORITHM EXTENSI, V382; Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600; Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164; Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862; Nikolova M, 2007, IEEE T IMAGE PROCESS, V16, P1623, DOI 10.1109/TIP.2007.896622; Pan J-Y., 2004, KDD, P653; Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Shen XY, 2015, IEEE I CONF COMP VIS, P3406, DOI 10.1109/ICCV.2015.389; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tong HH, 2006, IEEE DATA MINING, P613; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yan Q, 2013, IEEE I CONF COMP VIS, P1537, DOI 10.1109/ICCV.2013.194; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53; Zhang Z., 2004, P 21 INT C MACH LEAR, P117; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhou TH, 2015, PROC CVPR IEEE, P1191, DOI 10.1109/CVPR.2015.7298723; Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146	65	86	88	3	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					192	207		10.1109/TPAMI.2017.2669034	http://dx.doi.org/10.1109/TPAMI.2017.2669034			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28212077	Green Submitted			2022-12-18	WOS:000417806000015
J	Yang, XD; Tian, YL				Yang, Xiaodong; Tian, YingLi			Super Normal Vector for Human Activity Recognition with Depth Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human activity recognition; depth camera; feature representation; spatio-temporal information	IMAGE CLASSIFICATION; ACTIONLET ENSEMBLE; MOTION; POSE	The advent of cost-effectiveness and easy-operation depth cameras has facilitated a variety of visual recognition tasks including human activity recognition. This paper presents a novel framework for recognizing human activities from video sequences captured by depth cameras. We extend the surface normal to polynormal by assembling local neighboring hypersurface normals from a depth sequence to jointly characterize local motion and shape information. We then propose a general scheme of super normal vector (SNV) to aggregate the low-level polynormals into a discriminative representation, which can be viewed as a simplified version of the Fisher kernel representation. In order to globally capture the spatial layout and temporal order, an adaptive spatio-temporal pyramid is introduced to subdivide a depth video into a set of space-time cells. In the extensive experiments, the proposed approach achieves superior performance to the state-of-the-art methods on the four public benchmark datasets, i.e., MSRAction3D, MSRDailyActivity3D, MSRGesture3D, and MSRActionPairs3D.	[Yang, Xiaodong] NVIDIA Res, Santa Clara, CA 95050 USA; [Tian, YingLi] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA; [Tian, YingLi] CUNY, Grad Ctr, New York, NY 10031 USA	City University of New York (CUNY) System; City College of New York (CUNY); City University of New York (CUNY) System	Yang, XD (corresponding author), NVIDIA Res, Santa Clara, CA 95050 USA.	xiaodongy@nvidia.com; ytian@ccny.cuny.edu			US National Science Foundation [EFRI-1137172, IIS-1400802]	US National Science Foundation(National Science Foundation (NSF))	This work was supported in part by US National Science Foundation Grants EFRI-1137172 and IIS-1400802.	[Anonymous], 2009, BMVC, DOI DOI 10.5244/C.23.124; Bhattacharya S, 2014, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2014.287; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Coates Adam, 2011, P 28 INT C MACH LEAR, P921; Csurka G., 2004, P ECCV WORKSH STAT L; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Eweiwi A, 2015, LECT NOTES COMPUT SC, V9007, P428, DOI 10.1007/978-3-319-16814-2_28; Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269; Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436; Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Kurakin A, 2012, EUR SIGNAL PR CONF, P1975; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534; Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104; Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Molchanov P., 2016, P IEEE C COMP VIS PA; Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77; Shao, 2013, P 23 INT JOINT C ART; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31; Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang Xingxing, 2012, ASIAN C COMPUTER VIS, P572; Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365; Yang X., 2013, P NIST TRECVID WORKS; Yang X., 2012, P 20 ACM INT C MULTI, P1057, DOI [10.1145/2393347.2396382, DOI 10.1145/2393347.2396382]; Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108; Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001; Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11; [No title captured]	53	86	90	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					1028	1039		10.1109/TPAMI.2016.2565479	http://dx.doi.org/10.1109/TPAMI.2016.2565479			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113701	hybrid			2022-12-18	WOS:000399250000014
J	Ben Shitrit, H; Berclaz, J; Fleuret, F; Fua, P				Ben Shitrit, Horesh; Berclaz, Jerome; Fleuret, Francois; Fua, Pascal			Multi-Commodity Network Flow for Tracking Multiple People	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-object tracking; multi-commodity network flow; MCNF; tracklet association; linear programming; layered graph	MULTITARGET TRACKING; ALGORITHM; TARGETS; PATHS	In this paper, we show that tracking multiple people whose paths may intersect can be formulated as a multi-commodity network flow problem. Our proposed framework is designed to exploit image appearance cues to prevent identity switches. Our method is effective even when such cues are only available at distant time intervals. This is unlike many current approaches that depend on appearance being exploitable from frame-to-frame. Furthermore, our algorithm lends itself to a real-time implementation. We validate our approach on three publicly available datasets that contain long and complex sequences, the APIDIS basketball dataset, the ISSIA soccer dataset, and the PETS'09 pedestrian dataset. We also demonstrate its performance on a newer basketball dataset that features complete world championship basketball matches. In all cases, our approach preserves identity better than state-of-the-art tracking algorithms.	[Ben Shitrit, Horesh; Fleuret, Francois; Fua, Pascal] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland; [Berclaz, Jerome] Microsoft, Sunnyvale, CA 94089 USA; [Fleuret, Francois] Idiap Res Inst, CH-1920 Martigny, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Microsoft	Ben Shitrit, H (corresponding author), Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.	horesh.benshitrit@epfl.ch; jerome.berclaz@microsoft.com; francois.fleuret@idiap.ch; pascal.fua@epfl.ch		Fua, Pascal/0000-0002-6702-9970	CTI project "Image Based Object Tracking and Identification in Team Sports Environments"; Swiss National Science Foundation; European Community [247022-MASH]	CTI project "Image Based Object Tracking and Identification in Team Sports Environments"; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); European Community(European Commission)	This work was supported in part by the CTI project "Image Based Object Tracking and Identification in Team Sports Environments" and by a Swiss National Science Foundation project. Francois Fleuret was supported in part by the European Community's Seventh Framework Programme FP7-Challenge 2-Cognitive Systems, Interaction, Robotics-under grant agreement 247022-MASH.	Andriluka M., 2008, P CVPR; Andriyenko A., 2010, P ECCV; Andriyenko A., 2012, P CVPR; [Anonymous], 2010, MOSEK OPTIMIZATION T; Bazaraa MS, 2010, LINEAR PROGRAMMING N, V4th; BenShitrit H., 2011, P IEEE ICCV BARC SPA; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Black J., 2002, P IEEE WORKSH MOT VI; Blackman S.S., 1986, MULTIPLE TARGET TRAC; Breitenstein M., 2010, IEEE T PAMI, V33, P1820, DOI DOI 10.1109/TPAMI.2010.232; Choi D., 2006, P COCOON TAIP TAIW; Choi W., 2012, P ECCV; D'Orazio T., 2009, P INT C ADV VID SIGN; Delannay D., 2009, P ICDSC COM IT; Ellis A., 2009, P PETS SNOWB UT US D, P1; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; GE W, 2008, P BMVC; Giebel J., 2004, P ECCV; Henriques J. F., 2011, P ICCV; Huang J, 2009, J MACH LEARN RES, V10, P997; Iwase S., 2004, P ICPR; Jiang Huaizu, 2018, P CVPR; Joo SW, 2007, IEEE T IMAGE PROCESS, V16, P2849, DOI 10.1109/TIP.2007.906254; Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kondor R., 2007, P AISTATS; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Kuo C.-H., 2010, P CVPR; Kuo C. H., 2011, P CVPR; Leal-Taixe L., 2012, P CVPR; LI CL, 1992, NETWORKS, V22, P653, DOI 10.1002/net.3230220705; Li Y., 2009, P CVPR; Lu W.-L, 2011, P CVPR; Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8; Mauthner T., 2008, P ICPR; Misu T., 2009, ADV MULTIMEDIA MODEL; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; Oh S., 2004, P 43 IEEE CDC NASS B; OKUMA K, 2004, P ECCV; Perera A., 2006, P CVPR; Pirsiavash H., 2011, P CVPR; Poppe C., 2010, P INT C ADV VID SIGN; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Shin J., 2003, P IPSN PAL ALT CA US; Singh V.K., 2008, P IEEE WORKSH MOT VI; Smith K., 2005, P CVPR; Storms PPA, 2003, COMPUT OPER RES, V30, P1067, DOI 10.1016/S0305-0548(02)00057-6; Suurballe J. W., 1974, Networks, V4, P125, DOI 10.1002/net.3230040204; Wojek C., 2011, P CVPR; Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174; WOLF JK, 1989, IEEE T AERO ELEC SYS, V25, P287, DOI 10.1109/7.18692; Wu Z., 2012, P CVPR; Xu M., 2004, P ICIP; Yang B., 2012, P CVPR; Yang B., 2011, P CVPR; YANG C, 2005, P ICCV; Zhang L., 2008, P CVPR	58	86	88	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1614	1627		10.1109/TPAMI.2013.210	http://dx.doi.org/10.1109/TPAMI.2013.210			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353342	Green Submitted			2022-12-18	WOS:000340191900010
J	Jun, B; Choi, I; Kim, D				Jun, Bongjin; Choi, Inho; Kim, Daijin			Local Transform Features and Hybridization for Accurate Face and Human Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local binary pattern; local gradient pattern; binary histograms of oriented gradients; feature hybridization; face and human detection	TEXTURE CLASSIFICATION; BINARY; PATTERNS	We propose two novel local transform features: local gradient patterns (LGP) and binary histograms of oriented gradients (BHOG). LGP assigns one if the neighboring gradient of a given pixel is greater than its average of eight neighboring gradients and zero otherwise, which makes the local intensity variations along the edge components robust. BHOG assigns one if the histogram bin has a higher value than the average value of the total histogram bins, and zero otherwise, which makes the computation time fast due to no further postprocessing and SVM classification. We also propose a hybrid feature that combines several local transform features by means of the AdaBoost method, where the best feature having the lowest classification error is sequentially selected until we obtain the required classification performance. This hybridization makes face and human detection robust to global illumination changes by LBP, local intensity changes by LGP, and local pose changes by BHOG, which considerably improves detection performance. We apply the proposed features to face detection using the MIT+CMU and FDDB databases and human detection using the INRIA and Caltech databases. Our experimental results indicate that the proposed LGP and BHOG feature attain accurate detection performance and fast computation time, respectively, and the hybrid feature improves face and human detection performance considerably.	[Jun, Bongjin; Choi, Inho; Kim, Daijin] Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Pohang 790784, Gyeongbuk, South Korea	Pohang University of Science & Technology (POSTECH)	Jun, B (corresponding author), Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Room 206,Engn Bldg 2,San 31, Pohang 790784, Gyeongbuk, South Korea.	simple21@postech.ac.kr; ihchoi@postech.ac.kr; dkim@postech.ac.kr			Ministry of Knowledge Economy (MKE), Korea [NIPA-2012-H1502-12-1002]; National Research Foundation of Korea (NRF); Ministry of Education, Science and Technology, Korea [2011-0027953]	Ministry of Knowledge Economy (MKE), Korea(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); National Research Foundation of Korea (NRF)(National Research Foundation of Korea); Ministry of Education, Science and Technology, Korea(Ministry of Education, Science & Technology (MEST), Republic of Korea)	This work was supported by the Ministry of Knowledge Economy (MKE), Korea, under the Core Technology Development for Breakthrough of Robot Vision Research support program supervised by the National IT Industry Promotion Agency (NIPA) (NIPA-2012-H1502-12-1002). Also, this research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science and Technology, Korea (No. 2011-0027953).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bar-Hillel A, 2010, LECT NOTES COMPUT SC, V6314, P127, DOI 10.1007/978-3-642-15561-1_10; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004; Dollar P., 2004, P BRIT MACH VIS C, P1; Dollar P., 2007, IEEE C COMP VIS PATT, V1-8; Dollar P., 2010, P BRIT MACH VIS C, DOI [10.5244/C.24.68, DOI 10.5244/C.24.68]; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906; Feng X., 2005, Pattern Recognition and Image Analysis, V15, P546; Froba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514; Grimes D., 2003, NEURAL INFORM PROCES, V15, P1287; Heikkila M., 2004, P BRIT MACH VIS C, V1, P187, DOI DOI 10.5244/C.18.21; Heusch G, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P9; Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306; Jain V.., 2010, FDDB BENCHMARK FACE; Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317; Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518; Ke Y, 2004, PROC CVPR IEEE, P506; Kellokumpu V, 2009, LECT NOTES COMPUT SC, V5558, P1000, DOI 10.1007/978-3-642-01793-3_101; Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2008, IEEE C COMP VIS PATT, P1; Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Prisacariu V., 2009, FASTHOG A REAL TIME; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Rowley H.A., 1999, THESIS CARNEGIE MELL; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sabzmeydani P, 2007, PROC CVPR IEEE, P1251; Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Shet V.D., 2007, P IEEE C COMP VIS PA, P1; Subburaman V., 2010, P ECCV WORKSH FAC DE; Sun N, 2006, LECT NOTES COMPUT SC, V3972, P194; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102; Wang XX, 2008, PROCEEDINGS OF CRIOCM 2008 INTERNATIONAL RESEARCH SYMPOSIUM ON ADVANCES OF CONSTRUCTION MANAGEMENT AND REAL ESTATE, P82; Wojek C., 2009, P IEEE INT C COMP VI, P24; Xiangsheng Huang, 2004, Proceedings. Third International Conference on Image and Graphics, P184; Yan XJ, 2008, J MATH PHYS, V49, DOI 10.1063/1.3000575; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhu Qiang, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.119	54	86	90	1	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1423	1436		10.1109/TPAMI.2012.219	http://dx.doi.org/10.1109/TPAMI.2012.219			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599056				2022-12-18	WOS:000317857900012
J	Choi, MJ; Torralba, A; Willsky, AS				Choi, Myung Jin; Torralba, Antonio; Willsky, Alan S.			A Tree-Based Context Model for Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; scene analysis; Markov random fields; structural models; image databases		There has been a growing interest in exploiting contextual information in addition to local features to detect and localize multiple object categories in an image. A context model can rule out some unlikely combinations or locations of objects and guide detectors to produce a semantically coherent interpretation of a scene. However, the performance benefit of context models has been limited because most of the previous methods were tested on data sets with only a few object categories, in which most images contain one or two object categories. In this paper, we introduce a new data set with images that contain many instances of different object categories, and propose an efficient model that captures the contextual information among more than a hundred object categories using a tree structure. Our model incorporates global image features, dependencies between object categories, and outputs of local detectors into one probabilistic framework. We demonstrate that our context model improves object recognition performance and provides a coherent interpretation of a scene, which enables a reliable image querying system by multiple object categories. In addition, our model can be applied to scene understanding tasks that local detectors alone cannot solve, such as detecting objects out of context or querying for the most typical and the least typical scenes in a data set.	[Choi, Myung Jin] Two Sigma Investments, New York, NY 10012 USA; [Torralba, Antonio] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Willsky, Alan S.] MIT, Lab Informat & Decis Syst, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Choi, MJ (corresponding author), Two Sigma Investments, 379 W Broadway, New York, NY 10012 USA.	myungjin@mit.edu; torralba@csail.mit.edu; willsky@mit.edu			Shell International Exploration and Production, Inc.; US Army Research Office [W911NF-06-1-0076]; US National Science Foundation (NSF) [ISI 0747120]; US Air Force Office of Scientific Research [FA9550-06-1-0324]	Shell International Exploration and Production, Inc.; US Army Research Office; US National Science Foundation (NSF)(National Science Foundation (NSF)); US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	The authors would like to thank Taeg Sang Cho for valuable discussions and Joseph J. Lim for his help with experiments. This research was partially funded by Shell International Exploration and Production, Inc., by the US Army Research Office under award W911NF-06-1-0076, by US National Science Foundation (NSF) Career Award (ISI 0747120), and by the US Air Force Office of Scientific Research under Award No. FA9550-06-1-0324. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the author(s) and do not necessarily reflect the views of the US Air Force.	Bishop C.M, 2006, PATTERN RECOGN; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Dalal N., 2005, P IEEE CS C COMP VIS; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Desai C., 2009, P 12 IEEE INT C COMP; Divvala S.K., 2009, P IEEE C COMP VIS PA; Everingham M., 2011, PASCAL VISUAL OBJECT; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fergus R., 2003, P IEEE CS C COMP VIS; Galleguillos C., 2008, P IEEE C COMP VIS PA; Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x; He X., 2004, P IEEE CS C COMP VIS; Heitz G., 2008, P NEURAL INFORM PROC; Heitz G., 2008, P 10 EUR C COMP VIS; HOIEM D, 2006, P IEEE CS C COMP VIS; Jin Y., 2006, P IEEE CS C COMP VIS; Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239454, 10.1145/1276377.1276381]; Li Li-Jia, 2009, P IEEE C COMP VIS PA, P1; Malisiewicz T., 2009, P NEURAL INFORM PROC; Marszalek M., 2007, P IEEE C COMP VIS PA; Murphy K.P., 2003, P NEURAL INFORM PROC; Parikh D., 2007, P IEEE INT C COMP VI; Porway J., 2008, P IEEE C COMP VIS PA; Rabinovich A., 2007, P IEEE INT C COMP VI; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sudderth E.B., 2005, P IEEE INT C COMP VI; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A., 2005, ADV NEURAL INFORM PR; Tu Z., 2008, P IEEE C COMP VIS PA; WINN J, 2005, P IEEE INT C COMP VI	30	86	93	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					240	252		10.1109/TPAMI.2011.119	http://dx.doi.org/10.1109/TPAMI.2011.119			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21670482	Green Submitted			2022-12-18	WOS:000298105500004
J	Xu, H; Caramanis, C; Mannor, S				Xu, Huan; Caramanis, Constantine; Mannor, Shie			Sparse Algorithms Are Not Stable: A No-Free-Lunch Theorem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stability; sparsity; Lasso; regularization	STABILITY; CONSISTENCY; SELECTION	We consider two desired properties of learning algorithms: sparsity and algorithmic stability. Both properties are believed to lead to good generalization ability. We show that these two properties are fundamentally at odds with each other: A sparse algorithm cannot be stable and vice versa. Thus, one has to trade off sparsity and stability in designing a learning algorithm. In particular, our general result implies that l(1)-regularized regression (Lasso) cannot be stable, while l(2)-regularized regression is known to have strong stability properties and is therefore not sparse.	[Xu, Huan] Natl Univ Singapore, Dept Mech Engn, Singapore 117575, Singapore; [Caramanis, Constantine] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Mannor, Shie] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	National University of Singapore; University of Texas System; University of Texas Austin; Technion Israel Institute of Technology	Xu, H (corresponding author), Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore 117575, Singapore.	mpexuh@nus.edu.sg; caramanis@mail.utexas.edu; shie@ee.technion.ac.il	xu, huan/R-5436-2016; Xu, Huan/M-5155-2014	xu, huan/0000-0002-5712-0308; Caramanis, Constantine/0000-0001-9939-8378; Mannor, Shie/0000-0003-4439-7647	NUS [R-265-000-384-133]; US National Science Foundation (NSF) [EFRI-0735905, CNS-0721532, CNS-0831580]; DTRA [HDTRA1-08-0029]; Israel Science Foundation [890015]; Directorate For Engineering [1056028] Funding Source: National Science Foundation	NUS(National University of Singapore); US National Science Foundation (NSF)(National Science Foundation (NSF)); DTRA(United States Department of DefenseDefense Threat Reduction Agency); Israel Science Foundation(Israel Science Foundation); Directorate For Engineering(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))	This work was supported by NUS startup grant R-265-000-384-133, US National Science Foundation (NSF) (grants EFRI-0735905, CNS-0721532, CNS-0831580), DTRA (grant HDTRA1-08-0029), and Israel Science Foundation (contract 890015). A preliminary version of this work was presented in the 46th Allerton Conference on Communication, Control, and Computing.	[Anonymous], 2002, LEARNING KERNELS; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; DASPREMONT A, 2007, P 24 INT C MACH LEAR; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Evgeniou T, 2004, MACH LEARN, V55, P71, DOI 10.1023/B:MACH.0000019805.88351.60; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jaakkola T., 1999, ADV NEURAL INFORM PR, P470; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mangasarian OL, 2000, ADV NEUR IN, P135; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Poggio T, 1998, NEURAL COMPUT, V10, P1445, DOI 10.1162/089976698300017250; Shalev-Shwartz S., 2009, C LEARNING THEORY; Steinwart I, 2005, IEEE T INFORM THEORY, V51, P128, DOI 10.1109/TIT.2004.839514; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Wibisono Andre, 2009, MITCSAILTR2009060; Zhu J., 2003, P ADV NEUR INF PROC; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	26	86	92	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					187	193		10.1109/TPAMI.2011.177	http://dx.doi.org/10.1109/TPAMI.2011.177			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21844627	Green Submitted			2022-12-18	WOS:000297069900013
J	Veeraraghavan, A; Reddy, D; Raskar, R				Veeraraghavan, Ashok; Reddy, Dikpal; Raskar, Ramesh			Coded Strobing Photography: Compressive Sensing of High Speed Periodic Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational imaging; high-speed imaging; compressive sensing; compressive video sensing; stroboscopy	SUPERRESOLUTION; LIMITS	We show that, via temporal modulation, one can observe and capture a high-speed periodic video well beyond the abilities of a low-frame-rate camera. By strobing the exposure with unique sequences within the integration time of each frame, we take coded projections of dynamic events. From a sequence of such frames, we reconstruct a high-speed video of the high-frequency periodic process. Strobing is used in entertainment, medical imaging, and industrial inspection to generate lower beat frequencies. But this is limited to scenes with a detectable single dominant frequency and requires high-intensity lighting. In this paper, we address the problem of sub-Nyquist sampling of periodic signals and show designs to capture and reconstruct such signals. The key result is that for such signals, the Nyquist rate constraint can be imposed on the strobe rate rather than the sensor rate. The technique is based on intentional aliasing of the frequency components of the periodic signal while the reconstruction algorithm exploits recent advances in sparse representations and compressive sensing. We exploit the sparsity of periodic signals in the Fourier domain to develop reconstruction algorithms that are inspired by compressive sensing.	[Veeraraghavan, Ashok] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA; [Reddy, Dikpal] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; [Raskar, Ramesh] MIT, MIT Media Labs, Cambridge, MA 02139 USA	University System of Maryland; University of Maryland College Park; Massachusetts Institute of Technology (MIT)	Veeraraghavan, A (corresponding author), Mitsubishi Elect Res Labs, 201 Broadway,8th Floor, Cambridge, MA 02139 USA.	veerarag@merl.com; dikpal@umiacs.umd.edu; raskar@media.mit.edu			US Office of Naval Research [N00014-09-1-0664]	US Office of Naval Research(Office of Naval Research)	The authors would like to thank Professor Chellappa for his encouragement and support, John Barnwell for his help with the hardware, and Brandon Taylor for making a superb video for the project. They also thank Amit Agrawal, Jay Thornton, and numerous members of Mitsubishi Electric Research Labs for engaging discussions about the project. The work of Dikpal Reddy was supported by the US Office of Naval Research Grant N00014-09-1-0664. Ashok Veeraraghavan and Dikpal Reddy contributed equally to this work.	Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Baraniuk R., IEEE T INFO IN PRESS; Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718; BELONGIE S, 2004, P WORKSH SPAT COH VI; Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Bilinskis I., 1992, RANDOMIZED SIGNAL PR; Candes E.J., 2006, P INT C MATHEMATICIA, P1433, DOI DOI 10.4171/022-3/69; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008; *CHECKL, 2008, IND STROB; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; EDGERTON H, 2010, RAPATRONIC PHOTOGRAP, P1951; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; GREENSPAN H, 2001, P 4 INT C MED IM COM, P1204; Gustafsson MGL, 2005, P NATL ACAD SCI USA, V102, P13081, DOI 10.1073/pnas.0406877102; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Jia JY, 2006, IEEE T PATTERN ANAL, V28, P832, DOI 10.1109/TPAMI.2006.108; Laptev I, 2005, IEEE I CONF COMP VIS, P816; Larsson H, 2000, LARYNGOSCOPE, V110, P2117, DOI 10.1097/00005537-200012000-00028; LEVIN A, 2008, P ACM SIGGRAPH, V8; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Marvasti F., 2001, NONUNIFORM SAMPLING; Mergell P, 2000, J ACOUST SOC AM, V108, P2996, DOI 10.1121/1.1314398; Muybridge E, 1899, ANIMALS MOTION; Muybridge Eadweard, 1902, ANIMALS MOTION, P20; Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002; Oppenheim A.V., 1999, DISCRETE TIME SIGNAL; *POINTGR RES, 2008, PGR IEEE 1394 DIG CA; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Schade G, 2002, HNO, V50, P1079, DOI 10.1007/s00106-002-0709-6; Seitz SM, 1997, INT J COMPUT VISION, V25, P231, DOI 10.1023/A:1007928103394; Shaw HS, 2008, J VOICE, V22, P23, DOI 10.1016/j.jvoice.2006.08.006; Shechtman E, 2002, LECT NOTES COMPUT SC, V2350, P753; Theobalt C, 2004, ACM T GRAPHIC, V23, P540, DOI 10.1145/1015706.1015758; Tropp JA, 2010, IEEE T INFORM THEORY, V56, P520, DOI 10.1109/TIT.2009.2034811; WANDELL B, 1999, P INT S MULT IM COL, P11; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; [No title captured]	38	86	92	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					671	686		10.1109/TPAMI.2010.87	http://dx.doi.org/10.1109/TPAMI.2010.87			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20421670	Green Published			2022-12-18	WOS:000287370400002
J	Dambreville, S; Rathi, Y; Tannenbaum, A				Dambreville, Samuel; Rathi, Yogesh; Tannenbaum, Allen			A framework for image segmentation using shape models and kernel space shape priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel methods; shape priors; active contours; principal component analysis; level sets	SNAKES	Segmentation involves separating an object from the background in a given image. The use of image information alone often leads to poor segmentation results due to the presence of noise, clutter, or occlusion. The introduction of shape priors in the geometric active contour (GAC) framework has proven to be an effective way to ameliorate some of these problems. In this work, we propose a novel segmentation method combining image information with prior shape knowledge using level sets. Following the work of Leventon et al., we propose revisiting the use of principal component analysis (PCA) to introduce prior knowledge about shapes in a more robust manner. We utilize kernel PCA (KPCA) and show that this method outperforms linear PCA by allowing only those shapes that are close enough to the training data. In our segmentation framework, shape knowledge and image information are encoded into two energy functionals entirely described in terms of shapes. This consistent description permits us to fully take advantage of the KPCA methodology and leads to promising segmentation results. In particular, our shape-driven segmentation technique allows for the simultaneous encoding of multiple types of shapes and offers a convincing level of robustness with respect to noise, occlusions, or smearing.	[Dambreville, Samuel; Tannenbaum, Allen] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; [Rathi, Yogesh] Harvard Univ, Sch Med, Brigham & Womens Hosp, Psychiat Neuroimaging Lab, Boston, MA 02115 USA	University System of Georgia; Georgia Institute of Technology; Harvard University; Brigham & Women's Hospital; Harvard Medical School	Dambreville, S (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, 777 Atlantic Dr, Atlanta, GA 30332 USA.	samuel.dambreville@bme.gatech.edu; yogesh.rathi@gmail.com; tannenbu@ece.gatch.edu			NCRR NIH HHS [P41 RR013218-12, P41 RR013218, P41 RR-13218] Funding Source: Medline; NIBIB NIH HHS [U54 EB005149-05S30003, U54 EB005149-050003, U54 EB005149, U54 EB005149-05S4] Funding Source: Medline; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB005149] Funding Source: NIH RePORTER	NCRR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NIBIB NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Cremers D, 2004, LECT NOTES COMPUT SC, V3175, P36; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; DAMBREVILLE S, 2006, P INT C IM AN REC, V1, P173; Dambreville Samuel, 2006, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P977; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537; Kim J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P797, DOI 10.1109/ICIP.2002.1039092; KWOK J, IEEE T NEURAL NETWOR, V15, P1517; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Mika S., 1999, ADV NEURAL INFORM PR, V11; MOREL JM, 1994, VARIATIONAL METHODS; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S, 2003, LEVEL SET METHODS DY; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; PARAGIOS N, 1999, P IEEE INT C COMP VI, V2, P926; Paragios N., 2005, HDB MATH MODELS COMP; Rathi Y., 2006, P SOC PHOTO-OPT INS, V6064, P425; RATHI Y, 2006, P 2 INT WORKSH COMP, P96; RATHI Y, 2006, P INT C SIGN IM PROC, V534; Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214; ROUSSON M, 2002, P EUR C COMP VIS, P78; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Schore AN, 2001, INFANT MENT HEALTH J, V22, P7, DOI 10.1002/1097-0355(200101/04)22:1<7::AID-IMHJ2>3.0.CO;2-N; Sethian J. A., 1999, LEVEL SET METHODS DY; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; Wang YM, 1998, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1998.698628; Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	36	86	90	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1385	1399		10.1109/TPAMI.2007.70774	http://dx.doi.org/10.1109/TPAMI.2007.70774			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566493	Green Accepted, Green Submitted			2022-12-18	WOS:000256679700006
J	Ben-Ezra, M; Zomet, A; Nayar, SK				Ben-Ezra, M; Zomet, A; Nayar, SK			Video super-resolution using controlled subpixel detector shifts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sensors; jitter camera; jitter video; super-resolution; motion blur	IMAGE; RECONSTRUCTION; RESOLUTION; SEQUENCES; LIMITS	Video cameras must produce images at a reasonable frame-rate and with a reasonable depth of field. These requirements impose fundamental physical limits on the spatial resolution of the image detector. As a result, current cameras produce videos with a very low resolution. The resolution of videos can be computationally enhanced by moving the camera and applying super-resolution reconstruction algorithms. However, a moving camera introduces motion blur, which limits super-resolution quality. We analyze this effect and derive a theoretical result showing that motion blur has a substantial degrading effect on the performance of super-resolution. The conclusion is that, in order to achieve the highest resolution, motion blur should be avoided. Motion blur can be minimized by sampling the space-time volume of the video in a specific manner. We have developed a novel camera, called the "jitter camera," that achieves this sampling. By applying an adaptive super-resolution algorithm to the video produced by the jitter camera, we show that resolution can be notably enhanced for stationary or slowly moving objects, while it is improved slightly or left unchanged for objects with fast and complex motions. The end result is a video that has a significantly higher resolution than the captured one.	Siemens Corp Res, Princeton, NJ 08540 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Siemens AG; Columbia University	Ben-Ezra, M (corresponding author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	moshe.ben-ezra@siemens.com; zomet@cs.columbia.edu; nayar@cs.columbia.edu						Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BERGEN JR, 1992, P EUR C COMP VIS, P237; CAPEL D, 2000, P INT C PATT REC, V1, P600; Chiang MC, 2000, IMAGE VISION COMPUT, V18, P761, DOI 10.1016/S0262-8856(99)00044-X; Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; *MIN, 2005, DIM A1; *PHYS INSTR, 2005, M 111 MICR STAG; *POINT GREY RES, 2005, DRAG CAM; Pudlak P, 2000, INFORM PROCESS LETT, V74, P197, DOI 10.1016/S0020-0190(00)00058-2; RAMANATH R, 2002, J ELECT IMAGING, V11; Rav-Acha A, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P22, DOI 10.1109/WACV.2000.895398; Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915; SHECHTMAN E, 2002, P 7 EUR C COMP VIS, V1, P753; Shekarforoush H, 1999, J OPT SOC AM A, V16, P481, DOI 10.1364/JOSAA.16.000481; Simoncelli EP, 1999, P SOC PHOTO-OPT INS, V3813, P188, DOI 10.1117/12.366779; [No title captured]	20	86	113	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					977	987		10.1109/TPAMI.2005.129	http://dx.doi.org/10.1109/TPAMI.2005.129			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943428				2022-12-18	WOS:000228334700012
J	Li, SZ; Chan, KL; Wang, CL				Li, SZ; Chan, KL; Wang, CL			Performance evaluation of the nearest feature line method in image classification and retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image classification; image retrieval; nearest feature line (NFL); nearest-neighbor (NN) search; similarity metrics	FACE RECOGNITION; OBJECTS	A new method, the nearest feature line (NFL) method, is used in image classification and retrieval and its performance is evaluated and compared with other methods by extensive experiments. The NFL method is demonstrated to make efficient use of knowledge about multiple prototypes of a class to represent that class.	Microsoft Res China, Ctr Sight, Beijing 100080, Peoples R China; Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Microsoft; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Li, SZ (corresponding author), Microsoft Res China, Ctr Sight, Beijing 100080, Peoples R China.		Chan, Kap Luk/A-5150-2011					BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/ciun.1994.1017; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CHANG T, 1993, IEEE T IMAGE PROCESS, V3, P329; Edelman S, 1997, PHILOS T R SOC B, V352, P1191, DOI 10.1098/rstb.1997.0102; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; LI SZ, 2000, IEEE T SPEECH AU SEP; Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MEHTRE BM, 1995, PATTERN RECOGN LETT, V16, P325, DOI 10.1016/0167-8655(94)00096-L; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230	16	86	93	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1335	1339						5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200012
J	Perlovsky, LI				Perlovsky, LI			Conundrum of combinatorial complexity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; neural networks; rule systems; complexity; training; learning; a priori knowledge; fuzzy logic; Aristotelian logic	NEURAL NETWORKS; SPECIAL ISSUE; 3-D SCENES; ARCHITECTURES; RECOGNITION	This paper examines fundamental problems underlying difficulties encountered by pattern recognition algorithms, neural networks, and rule systems. These problems are manifested as combinatorial complexity of algorithms, of their computational or training requirements. The paper relates particular types of complexity problems to the roles of a priori knowledge and adaptive learning. Paradigms based on adaptive learning lead to the complexity of training procedures, while nonadaptive rule-based paradigms lead to complexity of rule systems. Model-based approaches to combining adaptivity with a priori knowledge lead to computational complexity. Arguments are presented for the Aristotelian logic being culpable for the difficulty of combining adaptivity and a priority. The potential role of the fuzzy logic in overcoming current difficulties is discussed. Current mathematical difficulties are related to philosophical debates of the past.	Nichols Res Corp, Lexington, MA 02173 USA		Perlovsky, LI (corresponding author), Nichols Res Corp, 70 Westview St, Lexington, MA 02173 USA.							AFNAN SM, 1958, KITAB ALSHIFA; APOSTLE H, 1966, METAPHYSICS; AQUINAS T, 1997, SUMMA CONTRA GENTILE, P1324; Bellman R., 1961, ADAPTIVE CONTROL PRO; BONNISONE PP, 1991, UNCERTAINTY ARTIFICI, V6; BOTHA RP, 1991, CHALLENGING CHOMSKY; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; CHEN RT, 1986, ACM COMPUT SURV, V18, P67; CHOMSKY N, 1981, EXPLANATION LINGUIST; CHOMSKY N., 1972, LANGUAGE MIND; *COOPER L, PHAEDRUS; Duda R.O., 1973, J ROYAL STAT SOC SER; Fukunaga K., 1972, INTRO STAT PATTERN R; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1992, IEEE T PATTERN ANAL, V14, P97; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P969; GROSSBERG S, 1988, NEURAL NETWORKS, V1, P17, DOI 10.1016/0893-6080(88)90021-4; GROSSBERG S, 1980, PSYCHOL REV, V87, P1, DOI 10.1037/0033-295X.87.1.1; KANT I, 1943, CRITIQUE PURE REASON, P1781; KESHAVAN HR, 1993, IEEE T PATTERN ANAL, V15, P193; KOSTER J, 1981, LEVELS SYNTACTIC REP; LAMDAN Y, 1988, P 2 INT C COMP VIS; Maimonides Moses, 1956, GUIDE PERPLEXED, P1190; MCCULLOCH W, 1943, B MATH BIOPHYS, V7, P115; MCCULLOCH WS, 1988, EMBODIMENTS MIND, P1965; MCCULLOCH WS, 1965, GEN SEMANTICS B, V26, P17; Michalski R. S., 1986, MACHINE LEARNING ART, V2; Minsky M., 1968, SEMANTIC INFORM PROC; Minsky M., 2019, FRAMEWORK REPRESENTI; MINSKY ML, 1969, PERCEPTRONS, P1988; NEGAHDARIPOUR S, 1991, FUTURE DIRECTIONS RE; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; Nilsson N., 1965, LEARNING MACHINES; OCCAM W, 1980, OCCAMS THEORY PROPOS, pR14; Perlovsky L. I., 1994, Journal of Mathematical Imaging and Vision, V4, P81, DOI 10.1007/BF01250006; Perlovsky L. I., 1996, P C INT SYST SEM 96, V1, P43; PERLOVSKY LI, 1991, ATR WORK GROUP M SEA; Pitts Walter, 1947, BULL MATH BIOPHYS, V9, P127, DOI 10.1007/BF02478291; Rosenblueth A., 1943, PHILOS SCI, V10, P18, DOI 10.1086/286788; SEGRE AM, 1992, IEEE EXPERT, V7, P31; Skinner B. F, 1974, BEHAVIORISM, V1st; SUN R, 1995, COMPUTATIONAL ARCHIT; Watanabe S, 1985, PATTERN RECOGNITION; Watson JB, 1913, PSYCHOL REV, V20, P158, DOI 10.1037/h0074428; WIDROW B, 1959, 1959 WESCON CONV R 4, P74; Wiener N, 1948, CYBERNETICS; Winston P. H., 1984, ARTIFICIAL INTELLIGE; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	50	86	87	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					666	670		10.1109/34.683784	http://dx.doi.org/10.1109/34.683784			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300009
J	KENT, JT; MARDIA, KV				KENT, JT; MARDIA, KV			SPATIAL CLASSIFICATION USING FUZZY MEMBERSHIP MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KENT, JT (corresponding author), UNIV LEEDS,SCH MATH,DEPT STAT,LEEDS LS2 9JT,W YORKSHIRE,ENGLAND.							AITCHISON J, 1982, J ROY STAT SOC B MET, V44, P139; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BESAG JE, 1983, B INT STAT I, V50, P422; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; CHELLAPPA R, 1982, IEEE T ACOUST SPEECH, V30, P461, DOI 10.1109/TASSP.1982.1163911; FOX L, 1964, INTRO NUMERICAL ALGE; GAINES BR, 1977, INT J MAN MACH STUD, V9, P1, DOI 10.1016/S0020-7373(77)80042-4; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HASLETT J, 1985, PATTERN RECOGN, V18, P287, DOI 10.1016/0031-3203(85)90054-8; KENT JT, 1987, P IMA C MATH SIGNAL, P395; Kittler J., 1984, Image and Vision Computing, V2, P13, DOI 10.1016/0262-8856(84)90040-4; KUNSCH HR, 1987, BIOMETRIKA, V74, P517, DOI 10.2307/2336690; MARDIA KV, 1984, COMMUN STAT-THEOR M, V13, P2181, DOI 10.1080/03610928408828822; MARDIA KV, 1987, J MULT ANAL, V24, P265; MARDIA KV, 1987, COMBINED RULE CLASSI; Mardia KV, 1979, MULTIVARIATE ANAL; Matheron G., 1973, Advances in Applied Probability, V5, P439, DOI 10.2307/1425829; SWITZER P, 1980, J INT ASS MATH GEOL, V12, P367, DOI 10.1007/BF01029421; SWITZER P, 1983, B INT STAT I, V50, P962; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786	21	86	88	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					659	671		10.1109/34.6774	http://dx.doi.org/10.1109/34.6774			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500005
J	Lin, L; Wang, KZ; Meng, DY; Zuo, WM; Zhang, L				Lin, Liang; Wang, Keze; Meng, Deyu; Zuo, Wangmeng; Zhang, Lei			Active Self-Paced Learning for Cost-Effective and Progressive Face Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cost-effective model; active learning; self-paced learning; incremental processing; face identification		This paper aims to develop a novel cost-effective framework for face identification, which progressively maintains a batch of classifiers with the increasing face images of different individuals. By naturally combining two recently rising techniques: active learning (AL) and self-paced learning (SPL), our framework is capable of automatically annotating new instances and incorporating them into training under weak expert recertification. We first initialize the classifier using a few annotated samples for each individual, and extract image features using the convolutional neural nets. Then, a number of candidates are selected from the unannotated samples for classifier updating, in which we apply the current classifiers ranking the samples by the prediction confidence. In particular, our approach utilizes the high-confidence and low-confidence samples in the self-paced and the active user-query way, respectively. The neural nets are later fine-tuned based on the updated classifiers. Such heuristic implementation is formulated as solving a concise active SPL optimization problem, which also advances the SPL development by supplementing a rational dynamic curriculum constraint. The new model finely accords with the "instructor-student-collaborative" learning mode in human education. The advantages of this proposed framework are two-folds: i) The required number of annotated samples is significantly decreased while the comparable performance is guaranteed. A dramatic reduction of user effort is also achieved over other state-of-the-art active learning techniques. ii) The mixture of SPL and AL effectively improves not only the classifier accuracy compared to existing AL/SPL methods but also the robustness against noisy data. We evaluate our framework on two challenging datasets, which include hundreds of persons under diverse conditions, and demonstrate very promising results. Please find the code of this project at: http://hcp.sysu.edu.cn/projects/aspl/	[Lin, Liang; Wang, Keze] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China; [Lin, Liang; Wang, Keze] Minist Educ, Engn Res Ctr Adv Comp Engn Software, Beijing, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710048, Shaanxi, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710048, Shaanxi, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China	Sun Yat Sen University; Xi'an Jiaotong University; Xi'an Jiaotong University; Harbin Institute of Technology; Hong Kong Polytechnic University	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.; Lin, L (corresponding author), Minist Educ, Engn Res Ctr Adv Comp Engn Software, Beijing, Peoples R China.	linliang@ieee.org; kezewang@gmail.com; dymeng@mail.xjtu.edu.cn; cswmzuo@gmail.com; cslzhang@comp.polyu.edu.hk	Wang, Keze/Z-3605-2019; Zuo, Wangmeng/B-3701-2008		State Key Development Program [2016YFB1001004]; National Natural Science Foundation of China [61671182, 61661166011, 61373114]; National Grand Fundamental Research 973 Program of China [2013CB329404]; Hong Kong Scholars Program; Hong Kong Polytechnic University Mainland University; CCF-Tencent Open Research Fund [AGR20160115]	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Grand Fundamental Research 973 Program of China(National Basic Research Program of China); Hong Kong Scholars Program; Hong Kong Polytechnic University Mainland University; CCF-Tencent Open Research Fund	This work was supported in part by the State Key Development Program under Grant 2016YFB1001004, in part by the National Natural Science Foundation of China under Grant 61671182, 61661166011 and 61373114, in part by the National Grand Fundamental Research 973 Program of China under Grant No. 2013CB329404, in part by Hong Kong Scholars Program and Hong Kong Polytechnic University Mainland University Joint Supervision Scheme, and sponsored by CCF-Tencent Open Research Fund (NO. AGR20160115).	Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Brinker K., 2003, ICML, P59; Celli F, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1101, DOI 10.1145/2647868.2654977; Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49; Elhamifar E, 2013, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2013.33; Gao Chenqiang, 2014, P INT C MULT RETR, P305; Hu G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P384, DOI 10.1109/ICCVW.2015.58; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Jiang L, 2015, AAAI CONF ARTIF INTE, P2694; Jiang L, 2014, ADV NEUR IN, V27; Joshi AJ, 2009, PROC CVPR IEEE, P2364; Kachites McCallum A., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P350; Kapoor A, 2007, IEEE I CONF COMP VIS, P134; Kapoor A, 2009, IEEE I CONF COMP VIS, P1058, DOI 10.1109/ICCV.2009.5459392; Karasuyama M., 2009, ADV NEURAL INFORM PR, P907; Kim TK, 2007, PROC CVPR IEEE, P124; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907; Lei Z., 2014, LEARNING FACE REPRES; Lei Z, 2016, IEEE T CIRC SYST VID, V26, P1685, DOI 10.1109/TCSVT.2015.2473415; Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3; Li X, 2013, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2013.116; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191; Ozawa S, 2005, NEURAL NETWORKS, V18, P575, DOI 10.1016/j.neunet.2005.06.016; Simonyan K, 2015, 3 INT C LEARN REPR I; Smith L. I., 2002, TUTORIAL PRINCIPAL C; Stone Z, 2010, P IEEE, V98, P1408, DOI 10.1109/JPROC.2010.2044551; Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Wang KZ, 2017, IEEE T CIRC SYST VID, V27, P2591, DOI 10.1109/TCSVT.2016.2589879; Wang KZ, 2016, PROC CVPR IEEE, P2138, DOI 10.1109/CVPR.2016.235; Wang XB, 2015, IEEE I CONF COMP VIS, P1787, DOI 10.1109/ICCV.2015.208; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Zhao HT, 2006, IEEE T SYST MAN CY B, V36, P873, DOI 10.1109/TSMCB.2006.870645; Zhao Q, 2015, AAAI CONF ARTIF INTE, P3196; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	41	85	90	1	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					7	19		10.1109/TPAMI.2017.2652459	http://dx.doi.org/10.1109/TPAMI.2017.2652459			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28092522	Green Submitted			2022-12-18	WOS:000417806000002
J	Elhamifar, E; Sapiro, G; Sastry, SS				Elhamifar, Ehsan; Sapiro, Guillermo; Sastry, S. Shankar			Dissimilarity-Based Sparse Subset Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Representatives; pairwise dissimilarities; simultaneous sparse recovery; encoding; convex programming; ADMM optimization; sampling; clustering; outliers; model identification; time-series data; video summarization; activity clustering; scene recognition	APPROXIMATION ALGORITHM; IDENTIFICATION	Finding an informative subset of a large collection of data points or models is at the center of many problems in computer vision, recommender systems, bio/health informatics as well as image and natural language processing. Given pairwise dissimilarities between the elements of a 'source set' and a 'target set,' we consider the problem of finding a subset of the source set, called representatives or exemplars, that can efficiently describe the target set. We formulate the problem as a row-sparsity regularized trace minimization problem. Since the proposed formulation is, in general, NP-hard, we consider a convex relaxation. The solution of our optimization finds representatives and the assignment of each element of the target set to each representative, hence, obtaining a clustering. We analyze the solution of our proposed optimization as a function of the regularization parameter. We show that when the two sets jointly partition into multiple groups, our algorithm finds representatives from all groups and reveals clustering of the sets. In addition, we show that the proposed framework can effectively deal with outliers. Our algorithm works with arbitrary dissimilarities, which can be asymmetric or violate the triangle inequality. To efficiently implement our algorithm, we consider an Alternating Direction Method of Multipliers (ADMM) framework, which results in quadratic complexity in the problem size. We show that the ADMM implementation allows to parallelize the algorithm, hence further reducing the computational time. Finally, by experiments on real-world datasets, we show that our proposed algorithm improves the state of the art on the two problems of scene categorization using representative images and time-series modeling and segmentation using representative models.	[Elhamifar, Ehsan] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA; [Elhamifar, Ehsan] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Sapiro, Guillermo] Duke Univ, Dept Elect & Comp Engn, Durham, NC USA; [Sastry, S. Shankar] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Northeastern University; Northeastern University; Duke University; University of California System; University of California Berkeley	Elhamifar, E (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.; Elhamifar, E (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	eelhami@ccs.neu.edu; guillermo.sapiro@duke.edu; sastry@eecs.berkeley.edu						Affandi R. H., 2013, P INT C MACH LEARN; Afsari B, 2012, PROC CVPR IEEE, P2208, DOI 10.1109/CVPR.2012.6247929; [Anonymous], 2006, ADV NEURAL INFORM PR; Awasthi P, 2015, PROCEEDINGS OF THE 6TH INNOVATIONS IN THEORETICAL COMPUTER SCIENCE (ITCS'15), P191, DOI 10.1145/2688073.2688116; Balzano Laura, 2010, P NIPS WORKSH LOW RA; Banerjee A, 2007, J MACH LEARN RES, V8, P1919; Barbic J, 2004, PROC GRAPH INTERF, P185; Bien J., 2010, ADV NEURAL INFORM PR, P217; Bien J, 2011, ANN APPL STAT, V5, P2403, DOI 10.1214/11-AOAS495; Borodin A., 2009, DETERMINANTAL POINT; Boutsidis C, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P968; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S, 2004, CONVEX OPTIMIZATION; CHAN TF, 1987, LINEAR ALGEBRA APPL, V88-9, P67, DOI 10.1016/0024-3795(87)90103-0; Charikar M, 2002, J COMPUT SYST SCI, V65, P129, DOI 10.1006/jcss.2002.1882; Chaux C, 2007, INVERSE PROBL, V23, P1495, DOI 10.1088/0266-5611/23/4/008; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550; Dhillon I. S., 2003, P 9 ACM SIGKDD INT C, P89; Duchi J., 2008, PROC 25 INT C MACH L, P272; Duda RO., 2004, PATTERN CLASSIFICATI; Dueck D, 2007, IEEE I CONF COMP VIS, P198; Elhamifar E., 2014, P C INT FED AUT CONT; Elhamifar E., 2012, ADV NEURAL INFORM PR, P19; Elhamifar E, 2013, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2013.33; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Esser E, 2012, IEEE T IMAGE PROCESS, V21, P3239, DOI 10.1109/TIP.2012.2190081; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Ferrari-Trecate G, 2003, AUTOMATICA, V39, P205, DOI 10.1016/S0005-1098(02)00224-8; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; Garcia S, 2012, IEEE T PATTERN ANAL, V34, P417, DOI 10.1109/TPAMI.2011.142; Gillenwater J, 2014, ADV NEUR IN, V27; Givoni IE, 2011, P 27 C UNC ART INT, P238; Gong B., 2014, ADV NEURAL INFORM PR, P2069; Grant M., CVX MATLAB SOFTWARE; Gu M, 1996, SIAM J SCI COMPUT, V17, P848, DOI 10.1137/0917055; Hartline J., 2008, P 17 INT C WORLD WID, P189; Jenatton R, 2011, J MACH LEARN RES, V12, P2777; Kaufman L, 1987, STAT DATA ANAL BASED; Koller D., 2009, PROBABILISTIC GRAPHI; Krause A, 2008, J MACH LEARN RES, V9, P2761; Kulesza A., 2011, P INT C MACH LEARN; Kusner MJ, 2014, PR MACH LEARN RES, V32, P622; Lashkari D., 2007, ADV NEURAL INFORM PR, P825; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li S, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P901; Li S, 2013, INFORM COMPUT, V222, P45, DOI 10.1016/j.ic.2012.01.007; Lin H., 2009, P ANN C INT SPEECH C; Lin H, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P381, DOI 10.1109/ASRU.2009.5373486; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350; MACCHI O, 1975, ADV APPL PROBAB, V7, P83, DOI 10.2307/1425855; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205105, 10.1073/pnas.0803205106]; Misra I, 2014, IEEE WINT CONF APPL, P339, DOI 10.1109/WACV.2014.6836080; Ng AY, 2002, ADV NEUR IN, V14, P849; Paoletti S, 2007, EUR J CONTROL, V13, P242, DOI 10.3166/EJC.13.242-260; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shmoys D.B., 1997, P 20 9 ANN ACM S THE, P265, DOI DOI 10.1145/258533.258600; Simon I, 2007, IEEE I CONF COMP VIS, P274; Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; Tropp JA, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P978; Van Overschee P., 1996, SUBSPACE IDENTIFICAT; Vidal R, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P167, DOI 10.1109/cdc.2003.1272554; Vijayanarasimhan S, 2012, LECT NOTES COMPUT SC, V7576, P496, DOI 10.1007/978-3-642-33715-4_36; Ward R., 2014, ARXIV13093256; Wesolowsky G. O., 1993, Location Science, V1, P5; Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137	71	85	88	3	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2182	2197		10.1109/TPAMI.2015.2511748	http://dx.doi.org/10.1109/TPAMI.2015.2511748			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26731635	Green Submitted			2022-12-18	WOS:000385945000004
J	Kong, Y; Jia, YD; Fu, Y				Kong, Yu; Jia, Yunde; Fu, Yun			Interactive Phrases: Semantic Descriptions for Human Interaction Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human interaction; action recognition; latent structural SVM		This paper addresses the problem of recognizing human interactions from videos. We propose a novel approach that recognizes human interactions by the learned high-level descriptions, interactive phrases. Interactive phrases describe motion relationships between interacting people. These phrases naturally exploit human knowledge and allow us to construct a more descriptive model for recognizing human interactions. We propose a discriminative model to encode interactive phrases based on the latent SVM formulation. Interactive phrases are treated as latent variables and are used as mid-level features. To complement manually specified interactive phrases, we also discover data-driven phrases from data in order to find potentially useful and discriminative phrases for differentiating human interactions. An information-theoretic approach is employed to learn the data-driven phrases. The interdependencies between interactive phrases are explicitly captured in the model to deal with motion ambiguity and partial occlusion in the interactions. We evaluate our method on the BIT-Interaction data set, UT-Interaction data set, and Collective Activity data set. Experimental results show that our approach achieves superior performance over previous approaches.	[Kong, Yu; Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China; [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA; [Fu, Yun] BBN Technol, Cambridge, MA USA; [Fu, Yun] Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA; [Fu, Yun] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Northeastern University; Beijing Institute of Technology; Northeastern University; Raytheon Technologies; Raytheon BBN Technologies; Tufts University; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Kong, Y (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	yukong@ece.neu.edu; jiayunde@bit.edu.cn; yunfu@ece.neu.edu	Kong, Yu/N-3387-2017	Kong, Yu/0000-0001-6271-4082	NSF CNS [1314484]; Natural Science Foundation of China (NSFC) [61375044]; Specialized Research Fund for the Doctoral Program of Higher Education [20121101110035]	NSF CNS(National Science Foundation (NSF)); Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Specialized Research Fund for the Doctoral Program of Higher Education(Specialized Research Fund for the Doctoral Program of Higher Education (SRFDP))	This work was supported in part by the NSF CNS award 1314484, Natural Science Foundation of China (NSFC) under Grant No. 61375044, and Specialized Research Fund for the Doctoral Program of Higher Education under Grant No. 20121101110035.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], [No title captured]; Bradley J. K., 2010, P INT C MACH LEARN; Choi W., 2011, P IEEE C COMP VIS PA; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Desai C., 2010, P IEEE C COMP VIS PA; Desai Chaitanya, 2009, P IEEE INT C COMP VI; Do T.-M.-T., 2009, P INT C MACH LEARN; Dollar P., 2005, P IEEE 2 JOINT INT W; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Ferrari V., 2007, P ADV NEUR INF PROC; FILIPOVYCH R, 2008, IEEE C COMP VIS PATT, P1; Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gupta A., 2008, P EUR C COMP VIS; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Kong Y., 2012, P EUR C COMP VIS; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Lafferty J., 2001, CONDITIONAL RANDOM F; Lampert C. H., 2009, P IEEE C COMP VIS PA; Lan T., 2010, P INT WORKSH SIGN GE; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Liu J., 2011, P IEEE C COMP VIS PA; Liu J., 2009, P IEEE C COMP VIS PA; Marszalek M., 2009, P IEEE C COMP VIS PA; Mehran Ramin, 2009, P IEEE C COMP VIS PA; Ni BB, 2009, PROC CVPR IEEE, P1470, DOI 10.1109/CVPRW.2009.5206853; Niebles J.C., 2010, P EUR C COMP VIS, V6312; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24; Ruonan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2450, DOI 10.1109/CVPRW.2009.5206676; Ryoo MS, 2011, INT J COMPUT VISION, V93, P183, DOI 10.1007/s11263-010-0355-5; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Ryoo M.S., 2010, ICPR; Ryoo M. S., 2011, P IEEE INT C COMP VI; Sadeghi M. A., 2011, P IEEE C COMP VIS PA; Shechtman E, 2005, PROC CVPR IEEE, P405; Slonim N., 2000, P 23 ANN INT ACM SIG; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vahdat A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1729, DOI 10.1109/ICCVW.2011.6130458; Wang Y., 2010, P EUR C COMP VIS; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709; Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461; Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235; Yu C., 2009, P INT C MACH LEARN; Yu TH, 2010, P BRIT MACH VIS C	51	85	88	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1775	1788		10.1109/TPAMI.2014.2303090	http://dx.doi.org/10.1109/TPAMI.2014.2303090			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352231				2022-12-18	WOS:000340210100006
J	Fuchs, E; Gruber, T; Nitschke, J; Sick, B				Fuchs, Erich; Gruber, Thiemo; Nitschke, Jiri; Sick, Bernhard			Online Segmentation of Time Series Based on Polynomial Least-Squares Approximations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series; orthogonal polynomials; least-squares approximation; online segmentation; piecewise polynomial representation; SwiftSeg	RECOGNITION	The paper presents SwiftSeg, a novel technique for online time series segmentation and piecewise polynomial representation. The segmentation approach is based on a least-squares approximation of time series in sliding and/or growing time windows utilizing a basis of orthogonal polynomials. This allows the definition of fast update steps for the approximating polynomial, where the computational effort depends only on the degree of the approximating polynomial and not on the length of the time window. The coefficients of the orthogonal expansion of the approximating polynomial-obtained by means of the update steps-can be interpreted as optimal (in the least-squares sense) estimators for average, slope, curvature, change of curvature, etc., of the signal in the time window considered. These coefficients, as well as the approximation error, may be used in a very intuitive way to define segmentation criteria. The properties of SwiftSeg are evaluated by means of some artificial and real benchmark time series. It is compared to three different offline and online techniques to assess its accuracy and runtime. It is shown that SwiftSeg-which is suitable for many data streaming applications-offers high accuracy at very low computational costs.	[Fuchs, Erich; Nitschke, Jiri] Univ Passau, Fac Comp Sci & Math, D-94030 Passau, Germany; [Gruber, Thiemo; Sick, Bernhard] Univ Appl Sci, Computationally Intelligent Syst Lab, Deggendorf, Germany	University of Passau	Fuchs, E (corresponding author), Univ Passau, Inst Software Syst Tech Applicat, D-94030 Passau, Germany.	fuchse@fim.uni-passau.de; nitschke@fim.uni-passau.de; thiemo.gruber@ft-deggendorf.de; bernhard.sick@ft-deggendorf.de		Sick, Bernhard/0000-0001-9467-656X	German Research Foundation (DFG) [SI 674/6-1]	German Research Foundation (DFG)(German Research Foundation (DFG))	This work was supported by the German Research Foundation (DFG) under the project number SI 674/6-1. The authors would like to thank G. Pisinger and A. Zimmermann, who gave an important hint to the update formulas for the squared error (residuum) of the polynomial approximation, and T. Reitmaier, who implemented the update for the SW technique. The authors also highly appreciate the support of E. Keogh, who provided some of the data sets, and they thank G. Leha and the anonymous reviewers of the paper for many very valuable comments that helped them to improve the quality of the paper.	Artieres T, 2007, IEEE T PATTERN ANAL, V29, P205, DOI 10.1109/TPAMI.2007.38; BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611; Bjorck A., 1996, NUMERICAL METHODS LE; BOISVERT RF, 2005, JAMA JAVA MATRIX PAC; DING H, 2008, P 34 INT C VER LARG, P1542; ELHAY S, 1991, SIAM J MATRIX ANAL A, V12, P327, DOI 10.1137/0612024; FITZGERALD W, 2005, P 20 NAT C ART INT, P1145; Fuchs E, 1999, INT S NUM M, V131, P93; Fuchs E, 1997, INT CONF ACOUST SPEE, P1965, DOI 10.1109/ICASSP.1997.598928; FUCHS E, 2004, P 12 EUR SIGN PROC C, P1509; Fuchs E, 1999, THESIS U PASSAU; Fuchs E, 2009, IEEE T NEURAL NETWOR, V20, P1450, DOI 10.1109/TNN.2009.2024679; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gorshkov Y, 2006, 2006 INTERNATIONAL SYMPOSIUM ON EVOLVING FUZZY SYSTEMS, PROCEEDINGS, P101, DOI 10.1109/ISEFS.2006.251141; Gruber C, 2006, LECT NOTES COMPUT SC, V3832, P500; Harada T, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2856, DOI 10.1109/IROS.2005.1545409; Henzinger M. R., 1999, External Memory Algorithms. DIMACS Workshop External Memory Algorithms and Visualization, P107; Junker H, 2008, PATTERN RECOGN, V41, P2010, DOI 10.1016/j.patcog.2007.11.016; Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531; Keogh E., 2004, DATA MINING TIME SER, P1, DOI [10.1142/9789812565402_0001, DOI 10.1142/9789812565402_0001]; Klinge R., 2002, ELEKTROKARDIOGRAMM; Kohlmorgen J, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P113, DOI 10.1109/NNSP.2001.943116; Kohlmorgen J, 1999, IEE CONF PUBL, P204, DOI 10.1049/cp:19991109; Lemire D, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P545; LI A, 2003, P WEB TECHN APPL 5 A, P178; Liu H, 1998, FEATURE EXTRACTION C; Liu H, 1998, FEATURE EXTRACTION C, DOI 10. 1007/978-1-4615-5725-8; Liu XY, 2008, IEEE T KNOWL DATA EN, V20, P1616, DOI 10.1109/TKDE.2008.29; LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2; Mager Johannes, 2008, 2008 IEEE Conference on Soft Computing in Industrial Applications. SMCia/08, P252, DOI 10.1109/SMCIA.2008.5045969; Marteau PF, 2009, IEEE T PATTERN ANAL, V31, P306, DOI 10.1109/TPAMI.2008.76; Nikiforov A. F., 1991, CLASSICAL ORTHOGONAL, DOI DOI 10.1007/978-3-642-74748-9; Rao YN, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P266, DOI 10.1109/ASSPCC.2000.882483; SHENA H, 2005, P 8 INT C INF FUS, V2, P1375; Tang L.-A., 2007, PROC ACM SIGMOD INT, P257; Tucker W, 2002, FOUND COMPUT MATH, V2, P53, DOI 10.1007/s102080010018; VULLINGS HJL, 1997, P 2 INT S ADV INT DA, P275; Ward JA, 2006, IEEE T PATTERN ANAL, V28, P1553, DOI 10.1109/TPAMI.2006.197	39	85	92	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2232	2245		10.1109/TPAMI.2010.44	http://dx.doi.org/10.1109/TPAMI.2010.44			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20975120				2022-12-18	WOS:000283558700009
J	Song, ML; Tao, DC; Chen, C; Li, XL; Chen, CW				Song, Mingli; Tao, Dacheng; Chen, Chun; Li, Xuelong; Chen, Chang Wen			Color to Gray: Visual Cue Preservation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color to gray; probabilistic graphical model; visual cue	IMAGES	Both commercial and scientific applications often need to transform color images into gray-scale images, e. g., to reduce the publication cost in printing color images or to help color blind people see visual cues of color images. However, conventional color to gray algorithms are not ready for practical applications because they encounter the following problems: 1) Visual cues are not well defined so it is unclear how to preserve important cues in the transformed gray-scale images; 2) some algorithms have extremely high time cost for computation; and 3) some require human-computer interactions to have a reasonable transformation. To solve or at least reduce these problems, we propose a new algorithm based on a probabilistic graphical model with the assumption that the image is defined over a Markov random field. Thus, color to gray procedure can be regarded as a labeling process to preserve the newly well-defined visual cues of a color image in the transformed gray-scale image. Visual cues are measurements that can be extracted from a color image by a perceiver. They indicate the state of some properties of the image that the perceiver is interested in perceiving. Different people may perceive different cues from the same color image and three cues are defined in this paper, namely, color spatial consistency, image structure information, and color channel perception priority. We cast color to gray as a visual cue preservation procedure based on a probabilistic graphical model and optimize the model based on an integral minimization problem. We apply the new algorithm to both natural color images and artificial pictures, and demonstrate that the proposed approach outperforms representative conventional algorithms in terms of effectiveness and efficiency. In addition, it requires no human-computer interactions.	[Song, Mingli; Chen, Chun] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Tao, Dacheng] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Li, Xuelong] Chinese Acad Sci, State Key Lab Transient Opt & Photon, Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China; [Chen, Chang Wen] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Zhejiang University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chinese Academy of Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; State Key Laboratory of Transient Optics & Photonics; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Song, ML (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.	brooksong@zju.edu.cn; dctao@ntu.edu.sg; chenc@zju.edu.cn; xuelong_li@opt.ac.cn; chencw@cse.buffalo.edu	Li, Xuelong/Z-3785-2019; li, xiang/GWM-6319-2022; Tao, Dacheng/A-5449-2012; Li, Xuelong/ABF-3381-2020	Li, Xuelong/0000-0002-0019-4197	Natural Science Foundation of China [60873124]; Nanyang Technological University [M58020010]; Natural Science Foundation of Zhejiang Provice [Y1090516]; Chinese Universities Scientific Fund [2009QNA5015]; National Key Technology RD Program [2008BAH26B02]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Nanyang Technological University(Nanyang Technological University); Natural Science Foundation of Zhejiang Provice; Chinese Universities Scientific Fund; National Key Technology RD Program(National Key Technology R&D Program)	The authors thank all six guest editors: Professors Qiang Ji, Jiebo Luo, Dimitris Metaxas, Antonio Torralba, Thomas Huang, and Erik Sudderth and all of the anonymous reviewers for their constructive comments on this manuscript. The author also thanks K. Rasche, A. Gooch, and Y. Zhang for their kind sharing of data and code. This project was partially supported by the the Natural Science Foundation of China (60873124), Nanyang Technological University SUG Grant (M58020010), the Natural Science Foundation of Zhejiang Provice (Y1090516), the Chinese Universities Scientific Fund (2009QNA5015), and the National Key Technology R&D Program (2008BAH26B02).	Alsam A., 2006, P IS T SID 14 COL IM, P263; Bala R, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P82; BALA R, 2004, P SOC PHOTO-OPT INS, P196; Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364; Borg I., 1997, MODERN MULTIDIMENSIO; BROWN R, 2006, PHOTOSHOP TIPS CONVE; DAVID HA, 1988, METHOD PAIRED COMPAR; DAVIS TA, 2003, TR03008 U FLOR; Fattal R, 2002, ACM T GRAPHIC, V21, P249; Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241; GREENFIELD GR, 2003, J WSCG 03, V11, P3; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Jolliffe I.T., 2002, PRINCIPLE COMPONENT, V2nd ed.; Kim HK, 2005, KOREAN J GENETIC, V27, P9; MALACARA D, 2002, COLOUR VISION COLOUR; Mantiuk R., 2006, ACM T APPL PERCEPTIO, V3, P286, DOI [DOI 10.1145/1166087.1166095, 10.1145/1166087.1166095]; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mika S, 1999, ADV NEUR IN, V11, P536; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Rasche K, 2005, COMPUT GRAPH FORUM, V24, P423, DOI 10.1111/j.1467-8659.2005.00867.x; Rasche K, 2005, IEEE COMPUT GRAPH, V25, P22, DOI 10.1109/MCG.2005.54; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036; Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Slater D, 1997, IEEE T PATTERN ANAL, V19, P1146, DOI 10.1109/34.625119; Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x; Socolinsky DA, 2002, IEEE T IMAGE PROCESS, V11, P923, DOI 10.1109/TIP.2002.801588; Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1; WU HR, 2001, DIGITAL VIDEO IMAGE; Wyszecki G, 2000, COLOUR SCI CONCEPTS, Vsecond	32	85	93	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1537	1552		10.1109/TPAMI.2009.74	http://dx.doi.org/10.1109/TPAMI.2009.74			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634551				2022-12-18	WOS:000279969000001
J	Pekalska, E; Haasdonk, B				Pekalska, Elzbieta; Haasdonk, Bernard			Kernel Discriminant Analysis for Positive Definite and Indefinite Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; pattern recognition; kernel methods; indefinite kernels; discriminant analysis	CLASSIFICATION	Kernel methods are a class of well established and successful algorithms for pattern analysis due to their mathematical elegance and good performance. Numerous nonlinear extensions of pattern recognition techniques have been proposed so far based on the so-called kernel trick. The objective of this paper is twofold. First, we derive an additional kernel tool that is still missing, namely kernel quadratic discriminant(KQD). We discuss different formulations of KQD based on the regularized kernel Mahalanobis distance in both complete and class-related subspaces. Second, we propose suitable extensions of kernel linear and quadratic discriminants to indefinite kernels. We provide classifiers that are applicable to kernels defined by any symmetric similarity measure. This is important in practice because problem-suited proximity measures often violate the requirement of positive definiteness. As in the traditional case, KQD can be advantageous for data with unequal class spreads in the kernel-induced spaces, which cannot be well separated by a linear discriminant. We illustrate this on artificial and real data for both positive definite and indefinite kernels.	[Pekalska, Elzbieta] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England; [Haasdonk, Bernard] Univ Stuttgart, Inst Appl Anal & Numer Simulat, D-70569 Stuttgart, Germany	University of Manchester; University of Stuttgart	Pekalska, E (corresponding author), Univ Manchester, Sch Comp Sci, Oxford Rd, Manchester M13 9PL, Lancs, England.	pekalska@cs.man.ac.uk; haasdonk@mathematik.uni-stuttgart.de			Engineering and Physical Science Research Council in the UK [EP/D066883/1]; German Academic Exchange Service (DAAD) [D/07/09940]	Engineering and Physical Science Research Council in the UK(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); German Academic Exchange Service (DAAD)(Deutscher Akademischer Austausch Dienst (DAAD))	This work is supported by the Engineering and Physical Science Research Council in the UK, project no. EP/D066883/1 and the German Academic Exchange Service (DAAD), contract no. D/07/09940.	Bognar J., 1974, INDEFINITE INNER PRO; CANU S, 2003, ADV LEARNING THEORY, V190, P89; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Der R., 2007, JMLR WORKSH C P, V2, P91; DRITSCHEL M, 1996, FIELDS I MONOGRAPHS, P141; DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361; Duda R.O., 2001, PATTERN CLASSIFICATI; Goldfarb L., 1985, PROGR PATTERN RECOGN, V2, P241; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; HAASDONK B, 2005, THESIS U FREIBURG; HAASDONK B, 2008, P INT C PATT REC; Haasdonk B, 2007, MACH LEARN, V68, P35, DOI 10.1007/s10994-007-5009-7; Hassett JM, 1996, J TRAUMA, V41, P1, DOI 10.1097/00005373-199607000-00001; Hein M, 2005, J COMPUT SYST SCI, V71, P333, DOI 10.1016/j.jcss.2004.10.013; Hettich S., 1998, UCI REPOSITORY MACHI; Hochreiter S, 2006, NEURAL COMPUT, V18, P1472, DOI 10.1162/neco.2006.18.6.1472; HUANG SY, 2005, KERNEL FISHERS DISCR; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Laub J, 2004, J MACH LEARN RES, V5, P801; MARY X, 2008, INTEGR EQUAT OPER TH, P419; Mika S., 1999, NEURAL NETWORKS SIGN, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121; Mika S, 2001, P AISTATS, P98; Ong C.S., 2004, P 21 INT C MACH LEAR, DOI DOI 10.1145/1015330.1015443; PEKALSKA E, 2006, P JOINT IAPR WORKSH, P871; Pekalska E, 2005, DISSIMILARITY REPRES; PEKALSKA E, 2009, INDEFINITE IN PRESS; Roth V., 2003, P ADV NEUR INF PROC, V16, P841; Rovnyak J, 2002, OPER THEORY ADV APPL, V134, P31; Ruiz A, 2001, IEEE T NEURAL NETWOR, V12, P16, DOI 10.1109/72.896793; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Schu┬lkopf B., 2004, KERNEL METHODS COMPU; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Simard PY, 2000, INT J IMAG SYST TECH, V11, P181, DOI 10.1002/1098-1098(2000)11:3<181::AID-IMA1003>3.0.CO;2-E; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; von Luxburg U, 2004, J MACH LEARN RES, V5, P669; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Wang J, 2008, PATTERN RECOGN, V41, P1528, DOI 10.1016/j.patcog.2007.10.024	40	85	85	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1017	1031		10.1109/TPAMI.2008.290	http://dx.doi.org/10.1109/TPAMI.2008.290			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372607				2022-12-18	WOS:000265100000005
J	Yan, JY; Pollefeys, M				Yan, Jingyu; Pollefeys, Marc			A factorization-based approach for articulated nonrigid shape, motion, and kinematic chain recovery from video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; 3D scene analysis; motion; shape; articulated; nonrigid; kinematic chain; factorization method	TRACKING; OBJECTS	Recovering articulated shape and motion, especially human body motion, from video is a challenging problem with a wide range of applications in medical study, sport analysis, animation, and so forth. Previous work on articulated motion recovery generally requires prior knowledge of the kinematic chain and usually does not concern the recovery of the articulated shape. The nonrigidity of some articulated part, for example, human body motion with nonrigid facial motion, is completely ignored. We propose a factorization-based approach to recover the shape, motion, and kinematic chain of an articulated object with nonrigid parts altogether directly from video sequences under a unified framework. The proposed approach is based on our modeling of the articulated nonrigid motion as a set of intersecting motion subspaces. A motion subspace is the linear subspace of the trajectories of an object. It can model a rigid or nonrigid motion. The intersection of two motion subspaces of linked parts models the motion of an articulated joint or axis. Our approach consists of algorithms for motion segmentation, kinematic chain building, and shape recovery. It handles outliers and can be automated. We test our approach through synthetic and real experiments and demonstrate how to recover an articulated structure with nonrigid parts via a single-view camera without prior knowledge of its kinematic chain.	[Yan, Jingyu] Microsoft Corp, Redmond, WA 98052 USA; [Pollefeys, Marc] ETH, Dept Comp Sci, CH-8092 Zurich, Switzerland	Microsoft; Swiss Federal Institutes of Technology Domain; ETH Zurich	Yan, JY (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	yanjingyu@gmail.com; marc.pollefeys@inf.ethz.ch	Pollefeys, Marc/I-7607-2013					BARTOLI A, 2005, P ICCV WORKSH DYN MO; BOULT T, 1991, P IEEE WORKSH VIS MO; Brand M, 2001, PROC CVPR IEEE, P315; BRAND M, 2005, P IEEE CS INT C COMP; Brandt Tobias, 2001, Curr Treat Options Neurol, V3, P463, DOI 10.1007/s11940-001-0034-5; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; BREGLER C, 2000, P IEEE CS C COMP VIS; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Ferrari-Trecate G, 2003, AUTOMATICA, V39, P205, DOI 10.1016/S0005-1098(02)00224-8; GEAR CW, 1994, P WORKSH MOT NONR AR; Golub Gene H., 2013, MATRIX COMPUTATION, V3; HAN M, 2000, P IEEE CS C COMP VIS; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Ichimura N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P600, DOI 10.1109/ICCV.1999.791279; Kanatani, 2012, INT J IMAGE GRAPHICS, V2, P179, DOI DOI 10.1142/S0219467802000585; Ng AY, 2002, ADV NEURAL INFORM PR, V14; POELMAN C, 1992, CMUCS92208; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sinclair D, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P991; Sminchisescu C, 2001, PROC CVPR IEEE, P447; Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Torresani L, 2001, PROC CVPR IEEE, P493; TORRESANI L, 2004, P 8 EUR C COMP VIS; TRESADERN P, 2005, P IEEE CS INT C COMP; VIDAL R, 2003, P IEEE CS C COMP VIS; VIDAL R, 2004, P IEEE CS C COMP VIS; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; XIAO J, 2004, P 8 EUR C COMP VIS; YAN J, 2005, P IEEE CS INT C COMP; YAN J, 2006, P 9 EUR C COMP VIS; YAN J, 2006, P IEEE CS C COMP VIS; YAN J, 2005, P ICCV WORKSH DYN VI; ZELNIKMANOR L, 2003, P IEEE CS C COMP VIS; ZHOU H, 2003, P 5 INT WORKSH GEST, P140	36	85	92	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					865	877		10.1109/TPAMI.2007.70739	http://dx.doi.org/10.1109/TPAMI.2007.70739			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369255				2022-12-18	WOS:000253879700009
J	Caetano, TS; Caelli, T; Schuurmans, D; Barone, DAC				Caetano, Tiberio S.; Caelli, Terry; Schuurmans, Dale; Barone, Dante A. C.			Graphical models and point pattern matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						point pattern matching; graph matching; graphical models; Markov random fields; junction tree algorithm	EDIT DISTANCE; RELAXATION; ALGORITHM	This paper describes a novel solution to the rigid point pattern matching problem in Euclidean spaces of any dimension. Although we assume rigid motion, jitter is allowed. We present a noniterative, polynomial time algorithm that is guaranteed to find an optimal solution for the noiseless case. First, we model point pattern matching as a weighted graph matching problem, where weights correspond to Euclidean distances between nodes. We then formulate graph matching as a problem of finding a maximum probability configuration in a graphical model. By using graph rigidity arguments, we prove that a sparse graphical model yields equivalent results to the fully connected model in the noiseless case. This allows us to obtain an algorithm that runs in polynomial time and is provably optimal for exact matching between noiseless point sets. For inexact matching, we can still apply the same algorithm to find approximately optimal solutions. Experimental results obtained by our approach show improvements in accuracy over current methods, particularly when matching patterns of different sizes.	Natl ICT Australia, Canberra, ACT 2601, Australia; Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT 0200, Australia; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, RS, Brazil	NICTA; Australian National University; University of Alberta; Universidade Federal do Rio Grande do Sul	Caetano, TS (corresponding author), Natl ICT Australia, Locked Bag 8001, Canberra, ACT 2601, Australia.	Tiberio.Caetano@nicta.com.au; Terry.Caelli@nicta.com.au; dale@cs.ualbeta.ca; barone@inf.ufrgs.br	Barone, Dante/ABW-6140-2022	Caelli, Terry/0000-0001-9281-2556				Akutsu T, 2003, DISCRETE APPL MATH, V127, P5, DOI 10.1016/S0166-218X(02)00282-2; Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; Caelli T, 2005, PATTERN RECOGN LETT, V26, P339, DOI 10.1016/j.patrec.2004.10.022; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Caetano TS, 2004, PROC CVPR IEEE, P466; Caetano TS, 2004, LECT NOTES COMPUT SC, V3138, P162; CAETANO TS, 2004, P IEEE INT C PATT RE, V2, P124; CAETANO TS, 2004, THESIS UFRGS; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; CONNELLY R, 1982, INVENT MATH, V66, P11, DOI 10.1007/BF01404753; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; DATTORRO J, 2005, THESIS STANFORD U; Davis MJ, 2001, ADV PHYSIOL EDUC, V25, P1; Demirci MF, 2004, LECT NOTES COMPUT SC, V3021, P322; DEREZENDE PJ, 1995, ALGORITHMICA, V13, P387, DOI 10.1007/BF01293487; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; Finn PW, 1998, COMP GEOM-THEOR APPL, V10, P263, DOI 10.1016/S0925-7721(98)00008-X; FU KS, 1983, IEEE T PATTERN ANAL, V5, P200; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Goodrich MT, 1999, IEEE T PATTERN ANAL, V21, P371, DOI 10.1109/34.761267; HANCOCK E, 2002, P JOINT INT WORKSH S, P31; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Huang HX, 2003, J GLOBAL OPTIM, V25, P3, DOI 10.1023/A:1021336413386; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; JORDAN MI, UNPUB INTRO PROBABIL; KESELMAN Y, 2003, P INT C COMP VIS PAT, V1, P18; Kittler J., 1989, International Journal of Pattern Recognition and Artificial Intelligence, V3, P29, DOI 10.1142/S021800148900005X; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; LI SZ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P866, DOI 10.1109/CVPR.1994.323915; MARTIN YC, 1993, J COMPUT AID MOL DES, V7, P83, DOI 10.1007/BF00141577; Mejia J, 2000, ADV SPACE RES, V26, P1407, DOI 10.1016/S0273-1177(00)00069-7; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MURTAGH F, 1992, PUBL ASTRON SOC PAC, V104, P301, DOI 10.1086/132993; Myers R, 2000, IEEE T PATTERN ANAL, V22, P628, DOI 10.1109/34.862201; NUSSINOV R, 1991, P NATL ACAD SCI USA, V88, P10495, DOI 10.1073/pnas.88.23.10495; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rangarajan A, 1999, NEURAL COMPUT, V11, P1455, DOI 10.1162/089976699300016313; Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56; Robles-Kelly A, 2004, INT J PATTERN RECOGN, V18, P315, DOI 10.1142/S0218001404003277; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Suganthan PN, 2002, PATTERN RECOGN, V35, P1883, DOI 10.1016/S0031-3203(01)00136-4; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; ULMANN S, 1979, COMPUTER GRAPHICS IM, V10, P115; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Wyk BJ, 2003, PATTERN RECOGN, V36, P2019, DOI 10.1016/S0031-3203(03)00009-8; van Wyk MA, 2002, IEEE T PATTERN ANAL, V24, P988, DOI 10.1109/TPAMI.2002.1017624; Wainwright M.J., 2002, THESIS MIT; WAINWRIGHT MJ, 2006, NEW DIRECTIOS STAT S; Wang HF, 2004, LECT NOTES COMPUT SC, V3138, P361; Weber N.O., 1994, WORLD 150 MANUF, V1, P20, DOI [10.1108/09642369210071316, DOI 10.1108/09642369210071316]; West D.B., 1996, INTRO GRAPH THEORY; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251	65	85	93	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1646	1663		10.1109/TPAMI.2006.207	http://dx.doi.org/10.1109/TPAMI.2006.207			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986545	Green Published, Green Submitted			2022-12-18	WOS:000239605500008
J	Zhu, SC; Liu, XW; Wu, YN				Zhu, SC; Liu, XW; Wu, YN			Exploring texture ensembles by efficient Markov chain Monte Carlo - Toward a "trichromacy" theory of texture	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gibbs ensemble; Julesz ensemble; texture modeling; texture synthesis; Markov chain Monte Carlo	DISCRIMINATION; MODELS	This article presents a mathematical definition of texture-the Julesz ensemble Omega(h), which is the set of all images (defined on Z(2)) that share identical statistics h. Then texture modeling is posed as an inverse problem: Given a set of images sampled from an unknown Julesz ensemble Omega(h,), we search for the statistics hi which define the ensemble. A Julesz ensemble Omega(h) has an associated probability distribution q(I;h), which is uniform over the images in the ensemble and has zero probability outside. In a companion paper [33], q(I; h) is shown to be the limit distribution of the FRAME (Filter, Random Field, And Minimax Entropy) model [36], as the image lattice Lambda --> Z(2). This conclusion establishes the intrinsic link between the scientific definition of texture on Z(2) and the mathematical models of texture on finite lattices. It brings two advantages to computer vision: 1) The engineering practice of synthesizing texture images by matching statistics has been put on a mathematical foundation. 2) We are released from the burden of learning the expensive FRAME model in feature pursuit, model selection and texture synthesis. In this paper, an efficient Markov chain Monte Carlo algorithm is proposed for sampling Julesz ensembles. The algorithm generates random texture images by moving along the directions of filter coefficients and, thus, extends the traditional single site Gibbs sampler. We also compare four popular statistical measures in the literature, namely, moments, rectified functions, marginal histograms, and joint histograms of linear filter responses in terms of their descriptive abilities. Our experiments suggest that a small number of bins in marginal histograms are sufficient for capturing a variety of texture patterns. We illustrate our theory and algorithm by successfully synthesizing a number of natural textures.	Ohio State Univ, Dept Comp & Informat Sci, Columbus, OH 43210 USA; Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	University System of Ohio; Ohio State University; University of California System; University of California Los Angeles	Zhu, SC (corresponding author), Ohio State Univ, Dept Comp & Informat Sci, Columbus, OH 43210 USA.	szhu@cis.ohio-state.edu; liux@cis.ohio-state.edu; ywu@math.ucla.edu						Akaike H., 1977, J R STAT SOC C-APPL, P27; ANDERSON CH, 1996, UNPUB STAT MODELS IM; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Bucklew J.A., 1990, LARGE DEVIATION TECH; CAELLI T, 1978, BIOL CYBERN, V29, P201, DOI 10.1007/BF00337276; Chellapa R., 1993, MARKOV RANDOM FIELDS; CHUBB C, 1991, COMPUTER MODELS VISU; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; Daugman J. G., 1985, J OPTICAL SOC AM, V2; DEBONET JS, 1997, ADV NEURAL INFORMATI, V10; GAGALOWICZ A, 1986, COMPUT GRAPH-UK, V10, P161, DOI 10.1016/0097-8493(86)90042-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Geman  S., 1986, P INT C MATH; Georgii HO., 1988, GIBBS MEASURES PHASE, DOI [10.1515/9783110850147, DOI 10.1515/9783110850147]; Gilks W.R., 1997, MARKOV CHAIN MONTE C; GILKS WR, 1997, MARKOV CHAIN MONTE C, pCH6; HEEGER DJ, 1995, SIGGRAPHS; Julesz B., 1995, DIALOGUES PERCEPTION; JULESZ B, 1984, DYNAMIC ASPECTS NEOC, P585; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KARNI A, 1991, P NATL ACAD SCI USA, V88, P4966, DOI 10.1073/pnas.88.11.4966; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Liu JS, 1999, J AM STAT ASSOC, V94, P1264, DOI 10.2307/2669940; LIU JS, IN PRESS BIOMETRIKA; Marr D., 1982, VISION; Picard R. W., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P371, DOI 10.1109/CVPR.1991.139718; POPAT K, 1997, IEEE T INFORMATION P, V6; Portilla J., 1999, P IEEE WORKSH STAT C; TREISMAN A, 1986, SCI AM           NOV; VISTNES R, 1989, INT J COMPUT VISION, V3, P313, DOI 10.1007/BF00132602; WESZKA J, 1976, IEEE T SYSTEM MA APR, V6; WU YN, 1999, P INT C COMP VIS SEP; Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754; ZHU S, 1997, NEURAL COMPUTATION, V9; ZHU SC, 1997, IEEE T PATTERN A NOV, V19; ZHU SC, 1999, IEEE T PATTERN A NOV, V21; Zhu XD, 1998, TAIWAN J MATH, V2, P1	38	85	89	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					554	569		10.1109/34.862195	http://dx.doi.org/10.1109/34.862195			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700002
J	Andrey, P; Tarroux, P				Andrey, P; Tarroux, P			Unsupervised segmentation of Markov random field modeled textured images using selectionist relaxation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						unsupervised texture segmentation; Markov/Gibbs random fields; partition function approximation; genetic algorithms; selectionist relaxation	GIBBS RANDOM-FIELDS; STATISTICAL-ANALYSIS; CLASSIFICATION; ALGORITHMS; NOISY	Among the existing texture segmentation methods, those relying on Markov random fields have retained substantial interest and have proved to be very efficient in supervised mode. The use of Markov random fields in unsupervised mode is, however, hampered by the parameter estimation problem. The recent solutions proposed to overcome this difficulty rely on assumptions about the shapes of the textured regions or about the number of textures in the input image that may not be satisfied in practice, in this paper, an evolutionary approach, selectionist relaxation, is proposed as a solution to the problem of segmenting Markov random field modeled textures in unsupervised mode. in selectionist relaxation, the computation is distributed among a population of units that iteratively evolves according to simple and local evolutionary rules. A unit is an association between a label and a texture parameter vector. The units whose likelihood is high are allowed to spread over the image and to replace the units that receive lower support from the data. Consequently, some labels are growing while others are eliminated. Starting with an initial random population, this evolutionary process eventually results in a stable labelization of the image, which is taken as the segmentation. In this work, the generalized Ising model is used to represent textured data. Because of the awkward nature of the partition function in this model, a high-temperature approximation is introduced to allow the evaluation of unit likelihoods. Experimental results on images containing various synthetic and natural textures are reported.	Ecole Normale Super, Dept Biol, Anim Lab, F-75230 Paris 05, France	UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS)	Andrey, P (corresponding author), Ecole Normale Super, Dept Biol, Anim Lab, 46 Rue Ulm, F-75230 Paris 05, France.		Andrey, Philippe/AAS-7228-2021					ANDREY P, 1994, PATTERN RECOGN, V27, P659, DOI 10.1016/0031-3203(94)90045-0; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V15, P298, DOI 10.1109/TSMC.1985.6313361; Chellappa R., 1985, PATTERN RECOGNITION, V2, P79; CHEN CC, 1993, PATTERN RECOGN LETT, V14, P907, DOI 10.1016/0167-8655(93)90155-7; COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; COHOON JP, 1991, IEEE T COMPUT AID D, V10, P483, DOI 10.1109/43.75631; COLLINS R, 1992, THESIS U CALIFORNIA; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Dubes R.C., 1989, J APPL STAT, V16, P131, DOI DOI 10.1080/02664768900000014; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIMELFARB GL, 1993, PATTERN RECOGN LETT, V14, P789, DOI 10.1016/0167-8655(93)90061-H; Goldberg David E, 1991, FDN GENETIC ALGORITH, DOI DOI 10.1016/B978-0-08-050684-5.50008-2; Goldberg DE, 1989, GENETIC ALGORITHMS S; HASSNER M, 1980, COMPUT VISION GRAPH, V12, P357, DOI 10.1016/0146-664X(80)90019-2; HOLLAND JH, 1992, ADAPTATION NATURAL A; HU RM, 1992, SIGNAL PROCESS, V26, P285, DOI 10.1016/0165-1684(92)90117-F; Kindermann R., 1980, CONT MATH; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MANDERICK B, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P428; MANJUNATH BS, 1990, IEEE T ACOUST SPEECH, V38, P1039, DOI 10.1109/29.56064; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; MUHLENBEIN H, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P416; NGUYEN HH, 1993, CVGIP-GRAPH MODEL IM, V55, P1, DOI 10.1006/cgip.1993.1001; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; Spiessens P., 1991, P 4 INT C GEN ALG, P279; SYSWERDA G, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P2; TANESE R, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P434; WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C	34	85	88	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					252	262		10.1109/34.667883	http://dx.doi.org/10.1109/34.667883			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400003
J	JANG, BK; CHIN, RT				JANG, BK; CHIN, RT			ONE-PASS PARALLEL THINNING - ANALYSIS, PROPERTIES, AND QUANTITATIVE-EVALUATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DERIVED GRID; MEDIAL AXIS; PARALLEL ALGORITHM; PATTERN RECOGNITION; SHAPE ANALYSIS; SKELETON; THINNING	DIGITAL PATTERNS; ALGORITHM	In this correspondence, we propose a one-pass parallel thinning algorithm based on a number of criteria including connectivity, unit-width convergence, medial axis approximation, noise immunity, and efficiency. A pipeline processing model is assumed for the development. Precise analysis of the thinning process is presented to show its properties, and proofs of skeletal connectivity and convergence are provided. The proposed algorithm is further extended to the derived-grid to attain an isotropic medial axis representation. A set of measures based on the desired properties of thinning is used for quantitative evaluation of various algorithms. Image reconstruction from connected skeletons is also discussed. Evaluation shows that our procedures compare favorably to others.	UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706	University of Wisconsin System; University of Wisconsin Madison	JANG, BK (corresponding author), EASTMAN KODAK CO,ROCHESTER,NY 14650, USA.		Chin, Roland Tai Hong/E-9856-2010					Abbott L., 1988, Machine Vision and Applications, V1, P23, DOI 10.1007/BF01212310; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; ARCELLI C, 1981, IEEE T PATTERN ANAL, V3, P134, DOI 10.1109/TPAMI.1981.4767071; ARCELLI C, 1989, IEEE T PATTERN ANAL, V11, P411, DOI 10.1109/34.19037; ARCELLI C, 1981, COMPUT VISION GRAPH, V17, P130, DOI 10.1016/0146-664X(81)90021-6; BERTRAND G, 1984, P INT C PATT REC, P326; BLUM B, 1964, P S MODELS PERCEPTIO; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BROWN RM, 1988, PATTERN RECOGN, V21, P91, DOI 10.1016/0031-3203(88)90017-9; CHEN YS, 1988, PATTERN RECOGN LETT, V7, P99, DOI 10.1016/0167-8655(88)90124-9; CHIN RT, 1987, COMPUT VISION GRAPH, V40, P30, DOI 10.1016/0734-189X(87)90054-5; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5; DECEGAMA AL, 1989, PARALLEL PROCESSING; GUO ZC, 1989, COMMUN ACM, V32, P359, DOI 10.1145/62065.62074; HALL RW, 1989, COMMUN ACM, V32, P124, DOI 10.1145/63238.63248; Hilditch C.J., 1969, MACH INTELL, P403; HOLT CM, 1987, COMMUN ACM, V30, P156, DOI 10.1145/12527.12531; HUNG SHY, 1983, PATTERN RECOGN, V16, P297, DOI 10.1016/0031-3203(83)90035-3; HWANG K, 1989, PARALLEL PROCESSING; JANG BK, 1990, IEEE T PATTERN ANAL, V12, P541, DOI 10.1109/34.56190; JANG BK, 1990, THESIS U WISCONSIN M; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; LU HE, 1986, COMMUN ACM, V29, P239, DOI 10.1145/5666.5670; NACCACHE NJ, 1984, IEEE T SYST MAN CYB, V14, P409, DOI 10.1109/TSMC.1984.6313233; RONSE C, 1986, THEOR COMPUT SCI, V43, P31, DOI 10.1016/0304-3975(86)90164-7; RONSE C, 1988, DISCRETE APPL MATH, V21, P67, DOI 10.1016/0166-218X(88)90034-0; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Serra J, 1982, IMAGE ANAL MATH MORP; Toriwaki J., 1981, Progress in pattern recognition. Vol.1, P187; XIE SL, 1988, PATTERN RECOGN, V21, P1, DOI 10.1016/0031-3203(88)90066-0; Yokoi S., 1973, System - Computers - Controls, V4, P32; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2; 1983, COMPUT, V16; 1987, P WORKSHOP COMP ARCH; [No title captured]	38	85	86	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1992	14	11					1129	1140		10.1109/34.166630	http://dx.doi.org/10.1109/34.166630			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JX370					2022-12-18	WOS:A1992JX37000010
J	SCHUNCK, BG				SCHUNCK, BG			IMAGE FLOW SEGMENTATION AND ESTIMATION BY CONSTRAINT LINE CLUSTERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SCHUNCK, BG (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ARTIFICIAL INTELLIGENCE LAB,ANN ARBOR,MI 48109, USA.							AMESWF, 1977, NUMERICAL METHODS PA; ANSTIS SM, 1970, VISION RES, V10, P1411, DOI 10.1016/0042-6989(70)90092-1; ANSTIS SM, 1975, VISION RES, V15, P957, DOI 10.1016/0042-6989(75)90236-9; BATALI J, 1979, NOV DARPA IM UND WOR; BENISRAEL A, 1974, GENERALIZED INVERSES; BLAKE A, 1987, VISUAL RECNSTRUCTION; BLAKE A, 1984, P NAT C ARTIFICIAL I, P23; BOULLION TL, 1971, GENERALIZED INVERSE; BRADDICK O, 1974, VISION RES, V14, P519, DOI 10.1016/0042-6989(74)90041-8; BRADY M, 1981, MIT654 ART INT LAB M; BUCKNER E, 1976, BIO CYBERN, V24, P85; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DAVID HA, 1981, ORDER STATISTICS; DAVIS LS, 1981, CONTOUR BASED MOTION; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1981, MIT663ART INT LAB ME; GRIMSON WEL, 1981, IMAGES SURFACES; GRIMSON WEL, 1981, MIT613 ART INT LAB M; HASKELL BG, 1974, IEEE T INFORM THEORY, V20, P119, DOI 10.1109/TIT.1974.1055161; Hildreth E., 1984, MEASUREMENT VISUAL M; HILDRETH EC, 1984, PROC R SOC SER B-BIO, V221, P189, DOI 10.1098/rspb.1984.0030; HILDRETH EC, 1982, MIT699 ART INT LAB C; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; HUTCHINSON JM, 1986, NEURAL NETWORKS COMP, P235; JONES RA, 1981, P C PATTERN RECOG IM, P508; Lawson C. L., 1974, SOLVING LEAST SQUARE; Limb J. O., 1975, Computer Graphics and Image Processing, V4, P311, DOI 10.1016/0146-664X(75)90001-5; LIMB JO, 1975, IEEE T COMMUN, VCO23, P474, DOI 10.1109/TCOM.1975.1092828; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARROQUIN JL, 1984, MIT792 ART INT LAB M; MUTCH KM, 1985, IEEE T PATTERN ANAL, V7, P133, DOI 10.1109/TPAMI.1985.4767638; NAGEL H, 1980, P INT C IMAGE ANAL P; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; NETRAVALI AN, 1979, AT&T TECH J, V58, P631, DOI 10.1002/j.1538-7305.1979.tb02238.x; NEVATIA R, 1982, MACHINE PERCEPTION; Noble B, 1969, APPL LINEAR ALGEBRA; PAQUIN R, 1983, COMPUT VISION GRAPH, V21, P205, DOI 10.1016/S0734-189X(83)80037-1; POGGIO T, 1985, COMPUT VISION GRAPH, V31, P139, DOI 10.1016/S0734-189X(85)80003-7; POGGIO T, 1976, Quarterly Reviews of Biophysics, V9, P377; POGGIO T, 1984, MIT773 ART INT LAB M; REICHARDT W, 1979, BIOL CYBERN, V35, P81, DOI 10.1007/BF00337434; Schetzen M., 1980, VOLTERRA WIENER THEO; Schunck B. G., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P58; SCHUNCK BG, 1986, COMPUT VISION GRAPH, V35, P20, DOI 10.1016/0734-189X(86)90124-6; SCHUNCK BG, 1983, THESIS MIT CAMBRIDGE; SCHUNCK BG, 1986, P WORKSHOP MOTION; Serfling RJ, 1980, APPROXIMATION THEORE; STULLER JA, 1980, AT&T TECH J, V59, P1227, DOI 10.1002/j.1538-7305.1980.tb03358.x; STULLER JA, 1979, BELL SYST TECH J, V58, P1673, DOI 10.1002/j.1538-7305.1979.tb02276.x; TERZOOULOS D, 1982, MIT671 ART INT LAB M; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VERRI A, 1987, P DARPA IMAGE UNDERS, P825; [No title captured]; [No title captured]	61	85	88	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1010	1027		10.1109/34.42834	http://dx.doi.org/10.1109/34.42834			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900001
J	ALMUALLIM, H; YAMAGUCHI, S				ALMUALLIM, H; YAMAGUCHI, S			A METHOD OF RECOGNITION OF ARABIC CURSIVE HANDWRITING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									TOKYO INST TECHNOL,DEPT ELECT & ELECTR ENGN,TOKYO 152,JAPAN	Tokyo Institute of Technology	ALMUALLIM, H (corresponding author), UNIV PETR & MINERALS,DEPT INFORMAT & COMP SCI,DHAHRAN,SAUDI ARABIA.							AMIN A, 1983, SPIE INT SOC OPT ENG, V359, P286; Badie K., 1982, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE65, P107; BAKIS R, 1968, IEEE T SYST SCI  JUL; Blesser B., 1973, 1st International Joint Conference on Pattern Recognition, P33; BOZINOVIC R, 1982, IEEE T PATTERN ANAL, V4, P655, DOI 10.1109/TPAMI.1982.4767321; BURR DJ, 1983, IEEE T PATTERN ANAL, V5; CHUANG PC, 1970, IEEE T SYST SCI  APR; DATTAREYA GR, DECISION TREE PATTER; EHRICH RW, 1975, IEEE T COMPUT, VC 24, P182, DOI 10.1109/T-C.1975.224184; Fu K.S., 1974, MATH SCI ENG; HARMON LD, 1972, P IEEE, V60, P1165, DOI 10.1109/PROC.1972.8878; KANAL LN, 1985, PROGR PATTERN RECOGN, V2; PAVLIDIS T, 1975, IEEE T SYST MAN CYBE, V5; Pavlidis T., 1977, STRUCTURAL PATTERN R; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2, P232; STARK L, 1970, IEEE T SYST SCI  JUL	16	85	86	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					715	722		10.1109/TPAMI.1987.4767970	http://dx.doi.org/10.1109/TPAMI.1987.4767970			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869434				2022-12-18	WOS:A1987J739300017
J	BROWN, CM				BROWN, CM			INHERENT BIAS AND NOISE IN THE HOUGH TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BROWN, CM (corresponding author), UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627, USA.							Ballard D.H., 1982, COMPUTER VISION; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BALLARD DH, 1981, 7TH P INT JOINT C AR, P1068; Barker RH., 1953, GROUP SYNCHRONIZATIO; BOEHMER AM, 1967, IEEE T INFORM THEORY, V13, P156, DOI 10.1109/TIT.1967.1053969; BROWN C, 1974, J APPL PHYS, V45, P1806, DOI 10.1063/1.1663494; BROWN CM, 1982, BIAS NOISE HOUGH TRA; BROWN CM, 1979, 49 U ROCH DEP COMP S; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; Coxeter H. S. M., 1963, REGULAR POLYTOPES; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; HELSTROM CW, 1968, STATISTICAL THEORY S; HOPKINS M, 1982, UNPUB AREA N SPHERE; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; IKEUCHI K, 1981, 7TH P IJCAI VANC; LAWS KI, 1982, GHOUGH GENERALIZED H; Marr D., 1982, VISION; O'Rourke J., 1981, 7TH P INT JOINT C AR, V2, P737; OGORMAN F, 1973, 3RD P IJC AI KYOT, P543; OROURKE J, 1981, 1981 P C INF SCI SYS, P301; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHAPIRO SD, 1978, COMPUT VISION GRAPH, V8, P219, DOI 10.1016/0146-664X(78)90050-3; SHAPIRO SD, 1979, IEEE T PATTERN ANAL, V1; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; Sloan K. R., 1981, 7 IJCAI, P734; SLOAN KR, 1980, 5TH P INT C PATT REC, P174; SLOAN KR, 1980, APR P IM UND WORKSH, P150; SLOAN KR, 1980, 81 U ROCH DEP COMP S; WELTI GR, 1960, IRE T INFORM THEOR, V6, P400, DOI 10.1109/TIT.1960.1057572	30	85	88	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					493	505		10.1109/TPAMI.1983.4767428	http://dx.doi.org/10.1109/TPAMI.1983.4767428			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869134				2022-12-18	WOS:A1983RM11800005
J	FAUGERAS, OD; PRATT, WK				FAUGERAS, OD; PRATT, WK			DECORRELATION METHODS OF TEXTURE FEATURE-EXTRACTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									INST RECH INFORMAT & AUTOMAT LAB, F-78150 LE CHESNAY, FRANCE; UNIV SO CALIF, INST IMAGE PROC, LOS ANGELES, CA 90007 USA	University of Southern California								BRODATZ P, 1956, TEXTURES PHOTOGRAPH; CAELLI T, 1978, BIOL CYBERN, V28, P167, DOI 10.1007/BF00337138; CAELLI T, 1978, BIOL CYBERN, V29, P201, DOI 10.1007/BF00337276; CONNERS RW, 1976, THESIS U MISSOURI CO; FAUGERAS OD, 1978, NOV P INT JOINT C PA, P549; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GAGALOWICZ A, 1979, AUG IEEE COMP SOC C; HARALICK RM, 1973, IEEE T GEOSCI REMOTE, VGE11, P171, DOI 10.1109/TGE.1973.294312; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hawkins JK, 1970, PICTURE PROCESSING P, P347; HSU S, 1977, P AM SOC PHOTOGRAMME, P203; JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; JULESZ B, 1978, BIOL CYBERN, V31, P137, DOI 10.1007/BF00336998; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; JULESZ B, 1970, F CYCLOPEAN PERCEPTI; PICKETT RM, 1970, PICTURE PROCESSING P, P289; POLLACK I, 1973, PERCEPT PSYCHOPHYS, V13, P276, DOI 10.3758/BF03214139; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PRATT WK, 1978, NOV P INT JOINT C PA, P545; PRATT WK, 1978, IEEE T SYST MAN  NOV; PURKS SR, 1977, J OPT SOC AM, V67, P765, DOI 10.1364/JOSA.67.000765; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777	24	85	88	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					323	332		10.1109/TPAMI.1980.4767031	http://dx.doi.org/10.1109/TPAMI.1980.4767031			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JZ206	21868908				2022-12-18	WOS:A1980JZ20600005
J	Cao, K; Liu, EY; Jain, AK				Cao, Kai; Liu, Eryun; Jain, Anil K.			Segmentation and Enhancement of Latent Fingerprints: A Coarse to Fine Ridge Structure Dictionary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Latent fingerprint; image decomposition; segmentation; ridge enhancement; sparse coding; dictionary learning	SPARSE; ALGORITHM; MODEL	Latent fingerprint matching has played a critical role in identifying suspects and criminals. However, compared to rolled and plain fingerprint matching, latent identification accuracy is significantly lower due to complex background noise, poor ridge quality and overlapping structured noise in latent images. Accordingly, manual markup of various features (e. g., region of interest, singular points and minutiae) is typically necessary to extract reliable features from latents. To reduce this markup cost and to improve the consistency in feature markup, fully automatic and highly accurate ("lights-out" capability) latent matching algorithms are needed. In this paper, a dictionary-based approach is proposed for automatic latent segmentation and enhancement towards the goal of achieving "lights-out" latent identification systems. Given a latent fingerprint image, a total variation (TV) decomposition model with L-1 fidelity regularization is used to remove piecewise-smooth background noise. The texture component image obtained from the decomposition of latent image is divided into overlapping patches. Ridge structure dictionary, which is learnt from a set of high quality ridge patches, is then used to restore ridge structure in these latent patches. The ridge quality of a patch, which is used for latent segmentation, is defined as the structural similarity between the patch and its reconstruction. Orientation and frequency fields, which are used for latent enhancement, are then extracted from the reconstructed patch. To balance robustness and accuracy, a coarse to fine strategy is proposed. Experimental results on two latent fingerprint databases (i.e., NIST SD27 and WVU DB) show that the proposed algorithm outperforms the state-of-the-art segmentation and enhancement algorithms and boosts the performance of a state-of-the-art commercial latent matcher.	[Cao, Kai; Liu, Eryun; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Cao, Kai] Xidian Univ, Sch Life Sci & Technol, Xian 710126, Shaanxi, Peoples R China; [Liu, Eryun] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China; [Liu, Eryun] Xidian Univ, Xian, Peoples R China; [Jain, Anil K.] Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea; [Jain, Anil K.] AAAS, Washington, DC USA	Michigan State University; Xidian University; Zhejiang University; Xidian University; Korea University	Cao, K (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	kaicao@cse.msu.edu; eryunliu@gmail.com; Jain@cse.msu.edu			National Natural Science Foundation of China [61101247, 61100234]; Brain Korea 21 PLUS Program through the National Research Foundation of Korea - Ministry of Education	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Brain Korea 21 PLUS Program through the National Research Foundation of Korea - Ministry of Education	The authors would like to thank Prof. Jay Kuo and Jianyang Zhang for providing them their segmentation and enhancement results. Kai Cao and Eryun Liu's research were partially supported by National Natural Science Foundation of China (Grant No. 61101247 and 61100234). Anil Jain's research was partially supported by the Brain Korea 21 PLUS Program through the National Research Foundation of Korea, funded by the Ministry of Education. All correspondence should be addressed to Anil Jain.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Buades A, 2010, IEEE T IMAGE PROCESS, V19, P1978, DOI 10.1109/TIP.2010.2046605; Chen XJ, 2004, EURASIP J APPL SIG P, V2004, P480, DOI 10.1155/S1110865704309194; Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036; Choi H.-S., 2012, P IEEE BIOM THEOR AP; Department of Justice, 2014, REV FBIS HANDL BRAND; Dror IE, 2012, J FORENSIC SCI, V57, P343, DOI 10.1111/j.1556-4029.2011.02013.x; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155; Garris MD, 2004, NIST FINGERPRINT IMA, V2; Girod Bernd, 1993, P207; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Indovina M., 2012, 7859 NISTIR; Jiang XD, 2000, IEEE IMAGE PROC, P462, DOI 10.1109/ICIP.2000.900995; Jiangyang Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P189, DOI 10.1109/ICB.2012.6199807; Karimi-Ashtiani S, 2008, IEEE IMAGE PROC, P1492, DOI 10.1109/ICIP.2008.4712049; Lian XC, 2010, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2010.5539915; Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Maltoni D., 2009, HDB FINGERPRINT RECO; Masanori Hara NEC, 2013, LIGHTS OUT LAT PROC; Neurotechnology Inc, 2014, VER; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Short N.J., 2011, 4 INT C IM CRIM DET, P1; TABASSI E, 2004, 7151 NISTIR; TEO PC, 1994, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.1994.413502; Turroni F, 2011, IEEE T INF FOREN SEC, V6, P1002, DOI 10.1109/TIFS.2011.2150216; Ulery BT, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032800; Ulery BT, 2011, P NATL ACAD SCI USA, V108, P7733, DOI 10.1073/pnas.1018707108; Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wilson C, 2004, 7123 NISTIR; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yoon S., 2010, P SPIE BIOMETRIC TEC; Yoon S, 2011, J BIONIC ENG, V8, P1, DOI 10.1016/S1672-6529(11)60007-3; Zhang JY, 2013, IEEE T INF FOREN SEC, V8, P1261, DOI 10.1109/TIFS.2013.2267491; Zhu E, 2006, PATTERN RECOGN, V39, P1452, DOI 10.1016/j.patcog.2006.03.001	40	84	85	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1847	1859		10.1109/TPAMI.2014.2302450	http://dx.doi.org/10.1109/TPAMI.2014.2302450			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352236	Green Submitted			2022-12-18	WOS:000340210100011
J	Ba, SO; Odobez, JM				Ba, Sileye O.; Odobez, Jean-Marc			Multiperson Visual Focus of Attention from Head Pose and Meeting Contextual Cues	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual focus of attention; conversational events; multimodal; contextual cues; dynamic Bayesian network; head pose; meeting analysis	DIRECTION; TRACKING	This paper introduces a novel contextual model for the recognition of people's visual focus of attention (VFOA) in meetings from audio-visual perceptual cues. More specifically, instead of independently recognizing the VFOA of each meeting participant from his own head pose, we propose to jointly recognize the participants' visual attention in order to introduce context-dependent interaction models that relate to group activity and the social dynamics of communication. Meeting contextual information is represented by the location of people, conversational events identifying floor holding patterns, and a presentation activity variable. By modeling the interactions between the different contexts and their combined and sometimes contradictory impact on the gazing behavior, our model allows us to handle VFOA recognition in difficult task-based meetings involving artifacts, presentations, and moving people. We validated our model through rigorous evaluation on a publicly available and challenging data set of 12 real meetings (5 hours of data). The results demonstrated that the integration of the presentation and conversation dynamical context using our model can lead to significant performance improvements.	[Ba, Sileye O.] Ecole Natl Telecommun Bretagne, LabSTICC, F-29238 Technopole Brest Iroise, France; [Odobez, Jean-Marc] Idiap Res Inst, CH-1920 Martigny, Switzerland	IMT - Institut Mines-Telecom; IMT Atlantique	Ba, SO (corresponding author), Ecole Natl Telecommun Bretagne, LabSTICC, F-29238 Technopole Brest Iroise, France.	sileye.ba@telecom-bretagne.eu; odobez@idiap.ch	Odobez, Jean-Marc/B-1426-2010	ba, sileye/0000-0003-4581-9880	Swiss National Center of Competence in Research and Interactive Multi-modal Information Management; IST European	Swiss National Center of Competence in Research and Interactive Multi-modal Information Management; IST European	This work was partly supported by the Swiss National Center of Competence in Research and Interactive Multi-modal Information Management (IM2), and the IST European projects FP6 Augmented Multi-Party Interaction with Distance Access (AMIDA). The authors thank Dr. Daniel Gatica-Perez, Dr. Hayley Hung, and Dinesh Jayagopi from the Idiap Research Institute for their helpful discussions. The author Sileye O. Ba was with the Idiap Research Institute while this work was done.	Argyle Michael, 1977, J ENV PSYCHOL NONVER, V1, P6, DOI [10.1007/BF01115461, DOI 10.1007/BF01115461]; BA S, 2008, P INT C AC SPEECH SI; Ba SO, 2009, IEEE T SYST MAN CY B, V39, P16, DOI 10.1109/TSMCB.2008.927274; BA SO, 2005, P ACM ICMI MMMP, P9; BASU S., 2002, THESIS MIT; CARLETTA J, 2005, P WORKSH MACH LEARN; Chen L., 2005, P WORKSH MACH LEARN; Dai P, 2008, IEEE T SYST MAN CY B, V38, P275, DOI 10.1109/TSMCB.2007.909939; Dielmann A, 2007, IEEE T MULTIMEDIA, V9, P25, DOI 10.1109/TMM.2006.886337; DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031; Durkalski VL, 2003, STAT MED, V22, P2417, DOI 10.1002/sim.1438; FAVRE S, 2008, P ACM INT C MULT; Freedman EG, 1997, J NEUROPHYSIOL, V77, P2328, DOI 10.1152/jn.1997.77.5.2328; GAUVAIN JL, 1992, SPEECH COMMUN, V11, P205, DOI 10.1016/0167-6393(92)90015-Y; Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009; JOVANOVIC N, 2004, P SIGDIAL; Jovanovic N, 2007, THESIS U TWENTE; JOVANOVIC N, 2006, P 11 C EUR CHAPT ASS; KATZENMEIR M, 2004, P INT C MULT INT; KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4; KLEINBAUER T, 2007, P EUR WORKSH NAT LAN; Kouadio M, 2002, J NETW COMPUT APPL, V25, P37, DOI 10.1006/jnca.2002.0125; KULYK O, 2006, P WORKSH MACH LEARN; Langton SRH, 2000, TRENDS COGN SCI, V4, P50, DOI 10.1016/S1364-6613(99)01436-9; McCowan I, 2005, IEEE T PATTERN ANAL, V27, P305, DOI 10.1109/TPAMI.2005.49; Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010; ODOBEZ JM, 2007, P IEEE INT C MULT EX; OHNO T, 2005, P C HUM FACT COMP SY, P1709; Otsuka K., 2006, P IEEE INT C MULT EX; Otsuka K., 2005, ICMI, P191, DOI 10.1145/1088463.1088497; PAVLOVIC V., 2000, ADV NEURAL INFORM PR, V13, P981; POPESCUBELIS A, 2008, P WORKSH MACH LEARN; SIRACUSA M, 2003, P INT C MULT INT; Smith K, 2008, IEEE T PATTERN ANAL, V30, P1212, DOI 10.1109/TPAMI.2007.70773; Stiefelhagen R, 2002, IEEE T NEURAL NETWOR, V13, P928, DOI 10.1109/TNN.2002.1021893; VANTURNHOUT K, 2005, P INT C MULT INT; VOIT M, 2008, P INT C MULT INT ICM; WELLNER P, 2004, P WORKSH MACH LEARN; YEO C, 2008, UCBEECS200879; Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735	40	84	86	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					101	116		10.1109/TPAMI.2010.69	http://dx.doi.org/10.1109/TPAMI.2010.69			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088322	Green Submitted			2022-12-18	WOS:000284277600008
J	Olsson, C; Kahl, F; Oskarsson, M				Olsson, Carl; Kahl, Fredrik; Oskarsson, Magnus			Branch-and-Bound Methods for Euclidean Registration Problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Registration; camera pose; global optimization; branch-and-bound		In this paper, we propose a practical and efficient method for finding the globally optimal solution to the problem of determining the pose of an object. We present a framework that allows us to use point-to-point, point-to-line, and point-to-plane correspondences for solving various types of pose and registration problems involving euclidean (or similarity) transformations. Traditional methods such as the iterative closest point algorithm or bundle adjustment methods for camera pose may get trapped in local minima due to the nonconvexity of the corresponding optimization problem. Our approach of solving the mathematical optimization problems guarantees global optimality. The optimization scheme is based on ideas from global optimization theory, in particular convex underestimators in combination with branch-and-bound methods. We provide a provably optimal algorithm and demonstrate good performance on both synthetic and real data. We also give examples of where traditional methods fail due to the local minima problem.	[Olsson, Carl; Kahl, Fredrik; Oskarsson, Magnus] Lund Univ, Ctr Math Sci, S-22100 Lund, Sweden	Lund University	Olsson, C (corresponding author), Lund Univ, Ctr Math Sci, Box 118, S-22100 Lund, Sweden.	calle@maths.lth.se; fredrik@maths.lth.se; magnuso@maths.lth.se		Oskarsson, Magnus/0000-0002-1789-8094	European Commission's Sixth Framework Programme [011838]; Swedish Research Council [2007-6476]; Swedish Foundation for Strategic Research (SSF); European Research Council [209480]	European Commission's Sixth Framework Programme(European Commission); Swedish Research Council(Swedish Research CouncilEuropean Commission); Swedish Foundation for Strategic Research (SSF)(Swedish Foundation for Strategic Research); European Research Council(European Research Council (ERC)European Commission)	This work has been funded by the European Commission's Sixth Framework Programme under Grant 011838 as part of the Integrated Project SMErobot, the Swedish Research Council (Grant 2007-6476), the Swedish Foundation for Strategic Research (SSF) through the programs Future Research Leaders and Vision in Cognitive Systems (VISCOS), and the European Research Council (GlobalVision Grant 209480).	Altmann S. L., 1986, ROTATIONS QUATERNION; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Boyd S, 2004, CONVEX OPTIMIZATION; Breuel TM, 2003, COMPUT VIS IMAGE UND, V90, P258, DOI 10.1016/S1077-3142(03)00026-2; BREUEL TM, 1992, THESIS MIT; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; Gelfand N, 2003, P 4 INT C 3 D DIG IM; Grunert J.A., 1841, GRUNERTS ARCHIV MATH, V1, P238; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hartley R., 2004, ROBOTICA; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Kahl F, 2008, INT J COMPUT VISION, V79, P271, DOI 10.1007/s11263-007-0117-1; KANAMORI T, 1993, J LOGIC PROGRAM, V15, P1, DOI 10.1016/0743-1066(93)90011-5; Kolman B, 1995, ELEMENTARY LINEAR PR; Olsson C., 2006, P IEEE COMP SOC C CO, V1, P1206, DOI DOI 10.1109/CVPR.2006.307; Olsson C, 2006, INT C PATT RECOG, P5; Pottmann H, 2006, INT J COMPUT VISION, V67, P277, DOI 10.1007/s11263-006-5167-2; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Ryoo HS, 2001, J GLOBAL OPTIM, V19, P403, DOI 10.1023/A:1011295715398; SLAMA C, 1984, MANUAL PHOTOGRAMMETR; Sturm J. F., 1998, USING SEDUMI 1 02 MA; Sutherland Ivan E., 1963, 296 MIT LINC LAB; Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231	23	84	87	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					783	794		10.1109/TPAMI.2008.131	http://dx.doi.org/10.1109/TPAMI.2008.131			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299855				2022-12-18	WOS:000264144500002
J	Ji, H; Fermuller, C				Ji, Hui; Fermueller, Cornelia			Robust Wavelet-Based Super-Resolution Reconstruction: Theory and Algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Perfect reconstruction filter banks; super-resolution; multiple frame alignment; wavelet denoising	RESOLUTION IMAGE-RECONSTRUCTION	We present an analysis and algorithm for the problem of super-resolution imaging, which is the reconstruction of high-resolution (HR) images from a sequence of low-resolution (LR) images. Super-resolution reconstruction entails solutions to two problems. One is the alignment of image frames. The other is the reconstruction of an HR image from multiple aligned LR images. Both are important for the performance of super-resolution imaging. Image alignment is addressed with a new batch algorithm, which simultaneously estimates the homographies between multiple image frames by enforcing the surface normal vectors to be the same. This approach can handle longer video sequences quite well. Reconstruction is addressed with a wavelet-based iterative reconstruction algorithm with an efficient denoising scheme. The technique is based on a new analysis of video formation. At a high level, our method could be described as a better-conditioned iterative back-projection scheme with efficient regularization criteria in each iteration step. Experiments with both simulated and real data demonstrate that our approach has better performance than existing super-resolution methods. It can remove even large amounts of mixed noise without creating artifacts.	[Ji, Hui] Natl Univ Singapore, Dept Math, Singapore 117543, Singapore; [Fermueller, Cornelia] Univ Maryland, Ctr Automat Res, Comp Vis Lab, UMIACS, College Pk, MD 20742 USA	National University of Singapore; University System of Maryland; University of Maryland College Park	Ji, H (corresponding author), Natl Univ Singapore, Dept Math, 2 Sci Dr 2, Singapore 117543, Singapore.	matjh@nus.edu.sg; fer@cfar.umd.edu	JI, Hui/C-5107-2016	JI, Hui/0000-0002-1674-6056	NUS ARF [R-146-050-091-101, R-146-050-091-133]; US National Science Foundation [0721634, 0523788]	NUS ARF; US National Science Foundation(National Science Foundation (NSF))	The authors would like to thank Professor Zuowei Shen for fruitful discussion and advice, as well as the three anonymous reviewers. This work was supported by NUS ARF under Grants R-146-050-091-101 and R-146-050-091-133 and by the US National Science Foundation under the CNS Grant 0721634 and CCF Grant 0523788.	Baker S, 2000, PROC CVPR IEEE, P372, DOI 10.1109/CVPR.2000.854852; Boor C, 2001, PRACTICAL GUIDE SPLI; Bose NK, 1998, INT J IMAG SYST TECH, V9, P294, DOI 10.1002/(SICI)1098-1098(1998)9:4<294::AID-IMA11>3.0.CO;2-X; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182; Chan RH, 2004, INT J IMAG SYST TECH, V14, P91, DOI 10.1002/ima.20012; Chan RH, 2004, APPL COMPUT HARMON A, V17, P91, DOI 10.1016/j.acha.2004.02.003; Chan RH, 2003, LINEAR ALGEBRA APPL, V366, P139, DOI 10.1016/S0024-3795(02)00497-4; ELAND M, 1997, IEEE T IMAGE PROCESS, P1646; FARSIU S, 2003, P INT SPIE; Fermuller C, 2002, P IEEE, V90, P1113, DOI 10.1109/JPROC.2002.801440; Govindu V. M, 2001, P IEEE C COMP VIS PA; Horn B., 1986, ROBOT VISION, P1; Ji H, 2006, IEEE T PATTERN ANAL, V28, P1018, DOI 10.1109/TPAMI.2006.109; Makadia A, 2006, IEEE T PATTERN ANAL, V28, P1170, DOI 10.1109/TPAMI.2006.150; MAKADIA A, 2007, INT J COMPUTER VISIO; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; MONDELL LJ, 1969, DIOPHANTINE EQUATION; Mrazek P, 2003, LECT NOTES COMPUT SC, V2695, P101; Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891; SHASHUA A, 1996, P 4 EUR C COMP VIS; TEKALP AM, 1992, P IEEE INT C AC SPEE, V3, P169; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; YOULA C, 1978, IEEE T CIRCUITS SYST; Zelnik-Manor L, 2000, IEEE T PATTERN ANAL, V22, P1105, DOI 10.1109/34.879791; Zhao WY, 2002, LECT NOTES COMPUT SC, V2350, P599; ZOMET A, 2001, P IEEE C COMP VIS PA; [No title captured]	28	84	91	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					649	660		10.1109/TPAMI.2008.103	http://dx.doi.org/10.1109/TPAMI.2008.103			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229081	Green Submitted			2022-12-18	WOS:000263396100006
J	Liu, CL				Liu, Cheng-Lin			Normalization-cooperated gradient feature extraction for handwritten character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; feature extraction; normalization-cooperated gradient feature (NCGF)	DIGIT RECOGNITION; LINE DENSITY	The gradient direction histogram feature has shown superior performance in character recognition. To alleviate the effect of stroke direction distortion caused by shape normalization and provide higher recognition accuracies, we propose a new feature extraction approach, called normalization-cooperated gradient feature (NCGF) extraction, which maps the gradient direction elements of original image to direction planes without generating the normalized image and can be combined with various normalization methods. Experiments on handwritten Japanese and Chinese character databases show that, compared to normalization-based gradient feature, the NCGF reduces the recognition error rate by factors ranging from 8.63 percent to 14.97 percent with high confidence of significance when combined with pseudo-two-dimensional normalization.	Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Liu, CL (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, POB 2728, Beijing 100080, Peoples R China.	liucl@nlpr.ia.ac.cn						Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hamanaka M., 1993, P 3 INT WORKSH FRONT, P343; Horiuchi T, 1997, PROC INT CONF DOC, P511, DOI 10.1109/ICDAR.1997.620551; Huang LL, 2003, PATTERN RECOGN, V36, P2501, DOI 10.1016/S0031-3203(03)00130-4; Kato N, 1999, IEEE T PATTERN ANAL, V21, P258, DOI 10.1109/34.754617; KAWAMURA A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P183, DOI 10.1109/ICPR.1992.201750; Kimura F, 1997, PATTERN RECOGN, V30, P1329, DOI 10.1016/S0031-3203(96)00153-7; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Liu CL, 2005, PROC INT CONF DOC, P121, DOI 10.1109/ICDAR.2005.119; Liu CL, 2005, PATTERN RECOGN, V38, P2242, DOI 10.1016/j.patcog.2005.04.019; Liu CL, 2004, PATTERN RECOGN, V37, P265, DOI 10.1016/S0031-3203(03)00224-3; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3203(03)00085-2; Liu CL, 2003, PROC INT CONF DOC, P524; Srikantan G, 1996, PATTERN RECOGN, V29, P1147, DOI 10.1016/0031-3203(95)00146-8; TSUKUMO J, 1988, P 9 INT C PATT REC, P168; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7	17	84	93	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1465	1469		10.1109/TPAMI.2007.1090	http://dx.doi.org/10.1109/TPAMI.2007.1090			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568148	Green Submitted			2022-12-18	WOS:000247186500013
J	Ouzounis, GK; Wilkinson, MHF				Ouzounis, Georgios K.; Wilkinson, Michael H. F.			Mask-based second-generation connectivity and attribute filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; second-generation connectivity; connectivity class; clustering; partitioning; dual input maxtree; attribute filter	IMAGE-ANALYSIS; OPERATORS; SEGMENTATION; OPENINGS	Connected filters are edge-preserving morphological operators, which rely on a notion of connectivity. This is usually the standard 4 and 8-connectivity, which is often too rigid since it cannot model generalized groupings such as object clusters or partitions. In the set-theoretical framework of connectivity, these groupings are modeled by the more general second-generation connectivity. In this paper, we present both an extension of this theory, and provide an efficient algorithm based on the Max-Tree to compute attribute filters based on these connectivities. We first look into the drawbacks of the existing framework that separates clustering and partitioning and is directly dependent on the properties of a preselected operator. We then propose a new type of second-generation connectivity termed mask-based connectivity which eliminates all previous dependencies and extends the ways the image domain can be connected. A previously developed Dual-Input Max-Tree algorithm for area openings is adapted for the wider class of attribute filters on images characterized by second-generation connectivity. CPU-times for the new algorithm are comparable to the original algorithm, typically deviating less than 10 percent either way.	Univ Groningen, Inst Math & Comp Sci, NL-9700 AV Groningen, Netherlands	University of Groningen	Ouzounis, GK (corresponding author), Univ Groningen, Inst Math & Comp Sci, POB 800, NL-9700 AV Groningen, Netherlands.	georgios@cs.rug.nl; m.h.f.wilkinson@rug.nl	Wilkinson, Michael/AAA-8471-2020; Ouzounis, Georgios/A-2067-2010; Ouzounis, Georgios/AAU-9186-2020; Wilkinson, Michael H.F./C-2386-2009; Wilkinson, Michael/Q-2847-2019	Ouzounis, Georgios/0000-0001-8914-3398; Wilkinson, Michael H.F./0000-0001-6258-1128; Wilkinson, Michael/0000-0001-6258-1128				[Anonymous], 1997, GRAPH THEORY; Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183; Braga-Neto U, 2004, IEEE T IMAGE PROCESS, V13, P1567, DOI 10.1109/TIP.2004.837514; Braga-Neto U, 2002, COMPUT VIS IMAGE UND, V85, P22, DOI 10.1006/cviu.2002.0961; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Caselles V, 2002, J MATH IMAGING VIS, V17, P249, DOI 10.1023/A:1020715626538; Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262; Heijmans H., 1994, MORPHOLOGICAL IMAGE; HEIJMANS HJA, 1995, P SUMMER SCH MORPHOL; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; Heijmans HJAM, 1997, IEEE T IMAGE PROCESS, V6, P713, DOI 10.1109/83.568928; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; MARAGOS P, 1990, IEEE T PATTERN ANAL, V12, P498, DOI 10.1109/34.55110; Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556; OUZOUNIS GK, 2005, P INT C IM PROC, V3, P844; OUZOUNIS GK, 2005, P INT S MATH MORPH I, P65; Ronse C, 1998, J MATH IMAGING VIS, V8, P41, DOI 10.1023/A:1008210216583; RONSE C, 1990, UNPUB OPENINGS MAIN; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475; Serra J., 2000, Fundamenta Informaticae, V41, P147; Serra J., 1988, IMAGE ANAL MATH MORP; Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646; Tzafestas CS, 2002, J MATH IMAGING VIS, V17, P109, DOI 10.1023/A:1020629402912; Urbach ER, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P305; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Vincent L, 1992, P NATO SHAP PICT WOR, P197; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; WILKINSON M, 2001, P INT C MED IM COMP, P770; WILKINSON MHF, 2005, P INT S MATH MORPH I, P85; Wilkinson MHF, 2007, IMAGE VISION COMPUT, V25, P426, DOI 10.1016/j.imavis.2006.04.015	34	84	87	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					990	1004		10.1109/TPAMI.2007.1045	http://dx.doi.org/10.1109/TPAMI.2007.1045			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431298	Green Submitted			2022-12-18	WOS:000245600800006
J	Herman, GT; Carvalho, BM				Herman, GT; Carvalho, BM			Multiseeded segmentation using fuzzy connectedness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; fuzzy connectedness; feature extraction; algorithms; clustering	IMAGE SEGMENTATION; OBJECT DEFINITION; ALGORITHMS	Fuzzy connectedness has been effectively used to segment out an object in a badly corrupted image. We generalize the approach by providing a definition which is shown to always determine a simultaneous segmentation of multiple objects. For any set of seed points, the segmentation is uniquely determined by the definition. An algorithm for finding this segmentation is presented and its output is illustrated. The algorithm is fast as compared to other segmentation algorithms in current use. We also report on an evaluation of the accuracy and robustness of the algorithm based on experiments in which several users were repeatedly asked to identify the seed points for the algorithm in a number of images.	Temple Univ, Ctr Comp Sci & Appl Math, Philadelphia, PA 19122 USA; Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of Pennsylvania	Herman, GT (corresponding author), Temple Univ, Ctr Comp Sci & Appl Math, Philadelphia, PA 19122 USA.			Motta de Carvalho, Bruno/0000-0002-9122-0257				AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; Carvalho BM, 1999, PATTERN ANAL APPL, V2, P73, DOI 10.1007/s100440050016; Dellepiane SG, 1996, IEEE T IMAGE PROCESS, V5, P429, DOI 10.1109/83.491317; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOWER JC, 1969, APPL STATIST, V18, P54, DOI DOI 10.2307/2346439; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KOEPFLER G, 1994, SIAM J NUMER ANAL, V31, P282, DOI 10.1137/0731015; Moghaddam H. A., 1998, Journal of Computing and Information Technology - CIT, V6, P215; Pollak I, 2000, IEEE T IMAGE PROCESS, V9, P256, DOI 10.1109/83.821738; Rice BL, 2000, INT J IMAG SYST TECH, V11, P62, DOI 10.1002/(SICI)1098-1098(2000)11:1<62::AID-IMA7>3.0.CO;2-6; ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X; Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Udupa JK, 1999, P SOC PHOTO-OPT INS, V3661, P236, DOI 10.1117/12.348578; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; [No title captured]	21	84	91	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					460	474		10.1109/34.922705	http://dx.doi.org/10.1109/34.922705			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA					2022-12-18	WOS:000168641000003
J	Guyon, I; Makhoul, J; Schwartz, R; Vapnik, V				Guyon, I; Makhoul, J; Schwartz, R; Vapnik, V			What size test set gives good error rate estimates?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; test set; test set size; benchmark; hypothesis testing; designed experiment; statistical significance; estimation; guaranteed estimators; recognition error		We address the problem of determining what size test set guarantees statistically significant results in a character recognition task, as a function of the expected error rate. We provide a statistical analysis showing that if, for example, the expected character error rate is around 1 percent, then, with a test set of at least 10,000 statistically independent handwritten characters (which could be obtained by taking 100 characters from each of 100 different writers), we guarantee, with 95 percent confidence, that: (1) The expected value of the character error rate is not worse than 1.25 E, where Eis the empirical character error rate of the best recognizer, calculated on the test set; and (2) a difference of 0.3 E between the error rates of two recognizers is significant. We developed this framework with character recognition applications in mind, but it applies as well to speech recognition and to other pattern recognition problems.	AT&T Bell Labs, Red Bank, NJ 07701 USA; BBN Syst & Technol Corp, Cambridge, MA 02138 USA	AT&T	Guyon, I (corresponding author), 955 Creston Rd, Berkeley, CA 94708 USA.							BOTTOU L, 1992, TM1135992012405 AT T; GEIST J, 1994, NISTIR5452 NIST US D; Gillick L., 1989, P ICASSP; Guyon I., 1994, P 12 INT C PATT REC; GUYON I, 1992, PIXELS FEATURES, V3, P493; GUYON I, IN PRESS OVERVIEW SY; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Mood A., 1974, INTRO THEORY STAT; WILKINSON RA, 1992, NISTIR4912 NIST US D	10	84	88	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1998	20	1					52	64		10.1109/34.655649	http://dx.doi.org/10.1109/34.655649			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YV876					2022-12-18	WOS:000071872400005
J	GAUCH, JM; PIZER, SM				GAUCH, JM; PIZER, SM			MULTIRESOLUTION ANALYSIS OF RIDGES AND VALLEYS IN GRAY-SCALE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; CURVATURE EXTREMA; GEOMETRIC MODELS; MULTIRESOLUTION ANALYSIS; RIDGES; SHAPE ANALYSIS; SYMMETRICAL AXIS; VALLEYS; WATERSHED BOUNDARIES	SHAPE	This paper describes two methods of identifying and analyzing the multiresolution behavior of ridges and valleys in grey-scale images. The first method uses the tools of differential geometry to focus on local image behavior. The resulting vertex curves mark the tops of ridges and bottoms of valleys in an image. The second method focuses on the global drainage patterns of rainfall on a terrain map. The resulting watershed boundaries also identify the tops of ridges and bottoms of valleys in an image. By following these two geometric representations through scale space, we build resolution hierarchies on ridges and valleys in the image that can be utilized for interactive image segmentation.	UNIV N CAROLINA,DEPT COMP SCI,MULTIDEPT MED IMAGE DISPLAY RES GRP,CHAPEL HILL,NC 27514; UNIV N CAROLINA,DEPT COMP SCI,GRAPH & IMAGE LAB,CHAPEL HILL,NC 27514; UNIV N CAROLINA,DEPT RADIOL,CHAPEL HILL,NC 27514; UNIV N CAROLINA,DEPT RADIAT ONCOL,CHAPEL HILL,NC 27514	University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill	GAUCH, JM (corresponding author), NORTHEASTERN UNIV,COLL COMP SCI,BOSTON,MA 02115, USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BAKER HH, 1988, 2ND P INT C COMP VIS; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1974, MATH ANAL FUNDAMENTA, V231, P19; BRADY M, 1984, MIT AI757 MEM; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY JF, 1983, MIT AI720 MEM; CLARK JJ, 1987, 1ST P INT C COMP VIS, P491; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; GAUCH JM, 1989, THESIS U N CAROLINA; GAUCH JM, 1988, 2ND P INT C COMP VIS; GAUCH JM, IN PRESS IEEE T PATT; HUMMEL RA, 1986, JUN P IEEE C COMP VI, P204; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; LEYTON M, 1986, SMOOTH PROCESS SHAPE; LIFSHITZ LM, 1987, THESIS U N CAROLINA; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NACKMAN LR, 1984, IEEE T PATTERN ANAL, V6, P442, DOI 10.1109/TPAMI.1984.4767549; PIZER SM, 1987, IEEE T PATT ANAL MAC, V9; RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; THORPE JA, 1979, ELEMENTARY TOPICS DI; VANDAM WJM, 1988, BEHAVIOR NOISE GAUSS; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1983, MIT AI722 MEM	28	84	87	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					635	646		10.1109/34.216734	http://dx.doi.org/10.1109/34.216734			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700013
J	CHEN, HH				CHEN, HH			POSE DETERMINATION FROM LINE-TO-PLANE CORRESPONDENCES - EXISTENCE CONDITION AND CLOSED-FORM SOLUTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CAMERA LOCATION; DEXTEROUS MANIPULATION; LIGHT-STRIPE VISION SYSTEM; MOTION ANALYSIS; POSE DETERMINATION	3-D OBJECTS; MOTION; RECOGNITION; ALGORITHM; POSITION; SURFACES; MODELS; VISION	Pose determination involves finding the position and orientation of an object with respect to a known coordinate frame. This paper considers a class of pose determinatiSon problems in which the sensory data are lines and the corresponding reference data are planes. The lines discussed here are different from edge lines in that they are not the intersection of boundary faces of the object. We describe a polynomial approach that, unlike previous methods, does not require a priori knowledge about the object location. Closed form solutions for orthogonal, parallel, and coplanar feature configurations of critical importance in real applications are derived. We also describe new findings concerning the necessary and sufficient conditions under which the line-to-plane pose determination problem can be solved.			CHEN, HH (corresponding author), AT&T BELL LABS,INFORMAT SYST RES LAB,TECH STAFF,CRAWFORDS CORNER RD,ROOM 4E-630,HOLMDEL,NJ 07733, USA.			Chen, Homer/0000-0002-8795-1911				AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Brand L., 1947, VECTOR TENSOR ANAL; CHEN HH, 1990, IEEE T PATTERN ANAL, V12, P1002, DOI 10.1109/34.58872; CHEN HH, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P374; CHEN HH, 1988, SENSING OJBECT LOCAT; Cox I. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P252, DOI 10.1109/CCV.1988.589996; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FAUGERAS OD, 1989, MAR P IEEE WORKSH VI, P248; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Foley J. D., 1982, FUNDAMENTALS INTERAC, P2; FORSTNER W, 1987, COMPUT VISION GRAPH, V40, P273, DOI 10.1016/S0734-189X(87)80144-5; GORDON SJ, 1988, IEEE T PATTERN ANAL, V10, P374, DOI 10.1109/34.3901; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HAMILTON WR, 1989, ELEMENTS QUATERNIONS, V1; HAMILTON WR, 1989, ELEMENTS QUATERNIONS, V2; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HUANG TS, 1990, TIME VARYING IMAGE P, V2, P243; HUANG TS, 1987, ENCY ARTIFICIAL INTE; HUNG Y, 1985, IEEE T ROBOTIC AUTOM, P80; JENKINS MA, 1970, SIAM J NUMER ANAL, V7, P545, DOI 10.1137/0707045; Korn G.A., 2000, MATH HDB SCI ENG DEF; Kumar R., 1989, P WORKSHOP INTERPRET, P52; LEVIN JZ, 1979, COMPUT VISION GRAPH, V11, P73, DOI 10.1016/0146-664X(79)90077-7; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Maron MJ, 1982, NUMERICAL ANAL; Morgan A. P., 1987, SOLVING POLYNOMIAL S; NEGAHDARIPOUR S, 1989, INT J COMPUT VISION, V3, P293, DOI 10.1007/BF00132601; SILVERMAN G, 1987, 1987 P WORKSHOP SPAT, P282; Sommerville D., 1958, INTRO GEOMETRY N DIM; SPEETER TH, 1990, INT J ROBOT RES, V9, P25, DOI 10.1177/027836499000900603; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034; ZHANG Z, 1988, 2ND P INT C COMP VIS, P177	38	84	92	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					530	541		10.1109/34.87340	http://dx.doi.org/10.1109/34.87340			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200003
J	BOUTHEMY, P				BOUTHEMY, P			A MAXIMUM-LIKELIHOOD FRAMEWORK FOR DETERMINING MOVING EDGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BOUTHEMY, P (corresponding author), CTR RENNES,INST NATL RECH INFORMAT & AUTOMAT,INST RECH INFORMAT & SYST ALEATOIRES,F-35042 RENNES,FRANCE.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BARRON J, 1984, SURVEY APPROACHES DE; Bouthemy P., 1987, Traitement du Signal, V4, P239; Bouthemy P., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P651; BOUTHEMY P, 1985, DEC P SPIE C COMP VI, V595, P162; BOUTHEMY P, 1987, 1ST P INT C COMP VIS, P463; Buxton B. F., 1984, Image and Vision Computing, V2, P59, DOI 10.1016/0262-8856(84)90001-5; CANNY JF, 1983, TR720 ART INT LAB MI; Cooper D. B., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P25; ESPIAU B, 1987, MAR P C IEEE ROB AUT; FLEET DJ, 1985, HIERARCHICAL CONSTRU; GLAZER F, 1981, 7TH P INT JOINT C AR, P644; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HAYNES SM, 1982, 6TH P INT C PATT REC, P754; HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HSU YZ, 1984, COMPUT VISION GRAPH, V26, P73, DOI 10.1016/0734-189X(84)90131-2; HUANG TS, 1983, IMAGE SEQUENCE PROCE, V2; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; JACOBSON L, 1987, COMPUT VISION GRAPH, V38, P29, DOI 10.1016/S0734-189X(87)80152-4; JAIN R, 1979, COMPUT VISION GRAPH, V11, P13, DOI 10.1016/0146-664X(79)90074-1; JAIN R, 1985, PATTERN RECOGNITIO 2, V1, P125; KAHN P, 1985, IEEE T PATTERN ANAL, V7, P402, DOI 10.1109/TPAMI.1985.4767679; LABIT C, 1983, IMAGE SEQUENCE PRO F, V2, P292; LEGTERS GR, 1982, IEEE T PATTERN ANAL, V4, P583, DOI 10.1109/TPAMI.1982.4767311; Mallat S. G., 1987, THEORY MULTIRESOLUTI; MARCE L, 1987, 3RD P INT C ADV ROB, P221; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; MITICHE A, 1984, P WORKSHOP COMPUTER, P63; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; MURRAY DW, 1986, PATTERN RECOGN LETT, V4, P87, DOI 10.1016/0167-8655(86)90028-0; Nagel H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1174; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1983, IMAGE SEQUENCE PRO F, V2, P2; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; ROUGEE A, 1986, MIT LIDSP1589 REP; SCHUNCK BG, 1986, COMPUT VISION GRAPH, V35, P20, DOI 10.1016/0734-189X(86)90124-6; STOREY R, 1986, NOV P INT EURASIP WO, V2; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105	43	84	94	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					499	511		10.1109/34.24782	http://dx.doi.org/10.1109/34.24782			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400005
J	Taniai, T; Matsushita, Y; Sato, Y; Naemura, T				Taniai, Tatsunori; Matsushita, Yasuyuki; Sato, Yoichi; Naemura, Takeshi			Continuous 3D Label Stereo Matching Using Local Expansion Moves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo vision; 3D reconstruction; graph cuts; Markov random fields; discrete-continuous optimization	MARKOV RANDOM-FIELDS; ENERGY MINIMIZATION; GRAPH-CUTS	We present an accurate stereo matching method using local expansion moves based on graph cuts. This new move-making scheme is used to efficiently infer per-pixel 3D plane labels on a pairwise Markov random field (MRF) that effectively combines recently proposed slanted patch matching and curvature regularization terms. The local expansion moves are presented as many a-expansions defined for small grid regions. The local expansion moves extend traditional expansion moves by two ways: localization and spatial propagation. By localization, we use different candidate a-labels according to the locations of local a-expansions. By spatial propagation, we design our local a-expansions to propagate currently assigned labels for nearby regions. With this localization and spatial propagation, our method can efficiently infer MRF models with a continuous label space using randomized search. Our method has several advantages over previous approaches that are based on fusion moves or belief propagation; it produces submodular moves deriving a subproblem optimality, it helps find good, smooth, piecewise linear disparity maps; it is suitable for parallelization; it can use cost-volume filtering techniques for accelerating the matching cost computations. Even using a simple pairwise MRF, our method is shown to have best performance in the Middlebury stereo benchmark V2 and V3.	[Taniai, Tatsunori; Sato, Yoichi; Naemura, Takeshi] Univ Tokyo, Bunkyo Ku, Tokyo 1138654, Japan; [Taniai, Tatsunori] RIKEN, AIP, Chuo Ku, Tokyo 1030027, Japan; [Matsushita, Yasuyuki] Osaka Univ, 2-2 Yamadaoka, Suita, Osaka 5650871, Japan	University of Tokyo; RIKEN; Osaka University	Taniai, T (corresponding author), Univ Tokyo, Bunkyo Ku, Tokyo 1138654, Japan.	taniai@iis.u-tokyo.ac.jp; yasumat@ist.osaka-u.ac.jp; ysato@iis.u-tokyo.ac.jp; naemura@hc.ic.i.u-tokyo.ac.jp	Taniai, Tatsunori/V-6975-2019	Taniai, Tatsunori/0000-0003-3361-4861; Sato, Yoichi/0000-0003-0097-4537; Matsushita, Yasuyui/0000-0002-1935-4752	JSPS KAKENHI [14J09001]; Microsoft Research Asia Ph.D. Fellowship	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); Microsoft Research Asia Ph.D. Fellowship	The authors would like to thank the anonymous reviewers including those of the conference paper. This work was supported by JSPS KAKENHI Grant Number 14J09001 and Microsoft Research Asia Ph.D. Fellowship.	Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Besse F, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.132; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Bleyer M, 2010, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2010.5539783; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Drouyer S, 2017, LECT NOTES COMPUT SC, V10225, P172, DOI 10.1007/978-3-319-57240-6_14; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293; Hong L, 2004, PROC CVPR IEEE, P74; Hosni Asmaa, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P337, DOI 10.1007/978-3-642-32717-9_34; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Hur J, 2017, IEEE I CONF COMP VIS, P312, DOI 10.1109/ICCV.2017.42; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Kim KR, 2016, IEEE IMAGE PROC, P3429, DOI 10.1109/ICIP.2016.7532996; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143; Li A, 2016, PROC CVPR IEEE, P4022, DOI 10.1109/CVPR.2016.436; Li G, 2010, IEEE T PATTERN ANAL, V32, P72, DOI 10.1109/TPAMI.2008.270; Li LC, 2018, IEEE T CIRC SYST VID, V28, P679, DOI 10.1109/TCSVT.2016.2628782; Li LC, 2017, APPL OPTICS, V56, P3411, DOI 10.1364/AO.56.003411; Liang Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3033, DOI 10.1109/CVPR.2011.5995480; Liu JY, 2010, PROC CVPR IEEE, P2181, DOI 10.1109/CVPR.2010.5539898; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705; Olsson C, 2014, INT C PATT RECOG, P4056, DOI 10.1109/ICPR.2014.695; Olsson C, 2013, PROC CVPR IEEE, P1730, DOI 10.1109/CVPR.2013.226; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Strandmark P, 2010, PROC CVPR IEEE, P2085, DOI 10.1109/CVPR.2010.5539886; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460; Taniai T, 2014, PROC CVPR IEEE, P1613, DOI 10.1109/CVPR.2014.209; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Wang ZF, 2008, PROC CVPR IEEE, P887; Wei YC, 2005, PROC CVPR IEEE, P902; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; Yamaguchi K, 2012, LECT NOTES COMPUT SC, V7576, P45, DOI 10.1007/978-3-642-33715-4_4; Yedidia JS, 2000, ADV NEURAL INFORM PR, V13, P689; Yoon KJ, 2005, PROC CVPR IEEE, P924; Zbontar J., 2016, J MACH LEARN RES, V17, P2	49	83	89	2	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2725	2739		10.1109/TPAMI.2017.2766072	http://dx.doi.org/10.1109/TPAMI.2017.2766072			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29989964	Green Submitted			2022-12-18	WOS:000446683700015
J	Yang, JM; Yang, MH				Yang, Jimei; Yang, Ming-Hsuan			Top-Down Visual Saliency via Joint CRF and Dictionary Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual saliency; top-down visual saliency; fixation prediction; dictionary learning and conditional random fields	FEATURES; ATTENTION	Top-down visual saliency is an important module of visual attention. In this work, we propose a novel top-down saliency model that jointly learns a Conditional Random Field (CRF) and a visual dictionary. The proposed model incorporates a layered structure from top to bottom: CRF, sparse coding and image patches. With sparse coding as an intermediate layer, CRF is learned in a feature-adaptive manner; meanwhile with CRF as the output layer, the dictionary is learned under structured supervision. For efficient and effective joint learning, we develop a max-margin approach via a stochastic gradient descent algorithm. Experimental results on the Graz-02 and PASCAL VOC datasets show that our model performs favorably against state-of-the-art top-down saliency methods for target object localization. In addition, the dictionary update significantly improves the performance of our model. We demonstrate the merits of the proposed top-down saliency model by applying it to prioritizing object proposals for detection and predicting human fixations.	[Yang, Jimei] Adobe Res, San Jose, CA 95110 USA; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA USA	Adobe Systems Inc.; University of California System; University of California Merced	Yang, JM (corresponding author), Adobe Res, San Jose, CA 95110 USA.	jimyang@adobe.com; mhyang@ucmerced.edu	Yang, Jimei/Q-1481-2017; Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304	NSF [1149783, 1152576]	NSF(National Science Foundation (NSF))	The work is supported in part by NSF CAREER Grant #1149783 and NSF IIS Grant #1152576.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Belkin M, 2002, ADV NEUR IN, V14, P585; Bertelli L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2153, DOI 10.1109/CVPR.2011.5995597; Bruce N., 2005, P 18 INT C NEUR INF, P155; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chikkerur S, 2010, VISION RES, V50, P2233, DOI 10.1016/j.visres.2010.05.013; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Garcia-Diaz A, 2012, J VISION, V12, DOI 10.1167/12.6.17; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X, 2007, 2007 IEEE C COMP VIS, V800, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jain A, 2012, LECT NOTES COMPUT SC, V7576, P718, DOI 10.1007/978-3-642-33715-4_52; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947; Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ladicky L, 2010, LECT NOTES COMPUT SC, V6315, P239, DOI 10.1007/978-3-642-15555-0_18; Lee H, 2016, ADV NEURAL INFORM PR, V19; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, P NEUR INF PROC SYST, P15; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Mathe S, 2013, ADV NEURAL INFORM PR, P1923; Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Szummer M, 2008, LECT NOTES COMPUT SC, V5303, P582, DOI 10.1007/978-3-540-88688-4_43; Tao LL, 2014, LECT NOTES COMPUT SC, V8693, P549, DOI 10.1007/978-3-319-10602-1_36; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]	44	83	93	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					576	588		10.1109/TPAMI.2016.2547384	http://dx.doi.org/10.1109/TPAMI.2016.2547384			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	28113265	Green Submitted, hybrid			2022-12-18	WOS:000395555100012
J	Crandall, DJ; Owens, A; Snavely, N; Huttenlocher, DP				Crandall, David J.; Owens, Andrew; Snavely, Noah; Huttenlocher, Daniel P.			SfM with MRFs: Discrete-Continuous Optimization for Large-Scale Structure from Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structure from motion; 3D reconstruction; Markov random fields; belief propagation	COLLECTIONS	Recent work in structure from motion (SfM) has built 3D models from large collections of images downloaded from the Internet. Many approaches to this problem use incremental algorithms that solve progressively larger bundle adjustment problems. These incremental techniques scale poorly as the image collection grows, and can suffer from drift or local minima. We present an alternative framework for SfM based on finding a coarse initial solution using hybrid discrete-continuous optimization and then improving that solution using bundle adjustment. The initial optimization step uses a discrete Markov random field (MRF) formulation, coupled with a continuous Levenberg-Marquardt refinement. The formulation naturally incorporates various sources of information about both the cameras and points, including noisy geotags and vanishing point (VP) estimates. We test our method on several large-scale photo collections, including one with measured camera positions, and show that it produces models that are similar to or better than those produced by incremental bundle adjustment, but more robustly and in a fraction of the time.	[Crandall, David J.] Indiana Univ, Sch Informat & Comp, Bloomington, IN 47408 USA; [Owens, Andrew] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Snavely, Noah; Huttenlocher, Daniel P.] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Indiana University System; Indiana University Bloomington; Massachusetts Institute of Technology (MIT); Cornell University	Crandall, DJ (corresponding author), Indiana Univ, Sch Informat & Comp, 901 E 10th St, Bloomington, IN 47408 USA.	djcran@indiana.edu; andrewo@mit.edu; snavely@cs.cornell.edu; dph@cs.cornell.edu			US National Science Foundation [IIS-0705774, IIS-0964027]; Indiana University Data to Insight Center; Lilly Endowment; Quanta Computer; MIT Lincoln Labs; Intel Corp.; NSF [EIA-0202048]; IBM; Direct For Computer & Info Scie & Enginr [1253549] Funding Source: National Science Foundation	US National Science Foundation(National Science Foundation (NSF)); Indiana University Data to Insight Center; Lilly Endowment; Quanta Computer; MIT Lincoln Labs; Intel Corp.(Intel Corporation); NSF(National Science Foundation (NSF)); IBM(International Business Machines (IBM)); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	The authors would like to thank Jon Kleinberg for the idea of applying MRFs to SfM, and Cornell Facilities for measuring survey points for the Quad dataset. This work was supported by the US National Science Foundation (IIS-0705774 and IIS-0964027), the Indiana University Data to Insight Center, the Lilly Endowment, Quanta Computer, MIT Lincoln Labs, and Intel Corp., and used compute resources of the Cornell Center for Advanced Computing and IU (funded by NSF EIA-0202048 and IBM).	Agarwal S., 2010, P 11 EUR C COMP VIS; Agarwal  S., 2009, P 12 IEEE INT C COMP; Arya S., 1993, P 4 ANN ACM SIAM S D; Bajramovic F., 2008, P BRIT MACH VIS C; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Byrod M, 2010, LECT NOTES COMPUT SC, V6312, P114, DOI 10.1007/978-3-642-15552-9_9; Chen D., 2011, P IEEE C COMP VIS PA; Crandall D, 2011, PROC CVPR IEEE; Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768; Devarajan D, 2007, EURASIP J APPL SIG P, V2007, P221; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Frahm J, 2010, P 11 EUR C COMP VIS; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782; Govindu VM, 2001, PROC CVPR IEEE, P218; Ihler AT, 2005, IEEE J SEL AREA COMM, V23, P809, DOI 10.1109/JSAC.2005.843548; Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824; Kaminsky R., 2009, P IEEE WORKSH INT VI; Lempitsky V. S., 2008, P IEEE C COMP VIS PA; Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427; Lothe P., 2009, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinec D., 2007, P IEEE C COMP VIS PA; Ni K., 2007, P 11 IEEE INT C COMP; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Ranganathan A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2191; Rother C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1210; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Sim K., 2006, P IEEE C COMP VIS PA, V1, P1230, DOI 10.1109/CVPR.2006.247; Sinha S., 2010, P 11 EUR C COMP VIS; Sinha SN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409112; Snavely N., 2008, P IEEE C COMP VIS PA; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Strecha C., 2010, P IEEE C COMP VIS PA; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B., 2000, VISION ALGORITHMS TH; Tron R., 2009, P IEEE C DEC CONTR; Verges-Llahi J, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P114	41	83	93	4	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2841	2853		10.1109/TPAMI.2012.218	http://dx.doi.org/10.1109/TPAMI.2012.218			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136425	Green Submitted			2022-12-18	WOS:000326502200003
J	Domke, J				Domke, Justin			Learning Graphical Model Parameters with Approximate Marginal Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphical models; conditional random fields; machine learning; inference; segmentation	INFORMATION; FIELDS	Likelihood-based learning of graphical models faces challenges of computational complexity and robustness to model misspecification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.				justin.domke@nicta.com.au						Andrei N, 2009, J COMPUT APPL MATH, V230, P570, DOI 10.1016/j.cam.2008.12.024; BAHL LR, 1988, P INT C AC SPEECH SI; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BORESI AP, 1991, APPROXIMATE SOLUTION; Carreira-Perpinan M, 2005, P INT WORKSH ART INT; Cramer H., 1999, MATH METHODS STAT; Dalal N., 2005, HISTOGRAMS ORIENTED; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Domke J, 2010, P ADV NEUR INF PROC; Domke J, 2011, P IEEE C COMP VIS PA; Domke J, 2008, P C UNC ART INT; Eaton F, 2009, P INT C ART INT STAT; Geyer C, 1991, P S INT; GROSS SS, 2007, P ADV NEUR INF PROC; He X., 2004, P IEEE C COMP VIS PA; Kakade S, 2002, P INT C MACH LEARN; Kim S, 2007, COMPUT VIS IMAGE UND, V105, P167, DOI 10.1016/j.cviu.2006.09.004; Kohli P, 2008, COMPUT VIS IMAGE UND, V112, P30, DOI 10.1016/j.cviu.2008.07.002; Konidaris G, 2011, P C ART INT; Kumar S, 2005, P INT C EN MIN METH; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Lafferty J., 2001, CONDITIONAL RANDOM F; Levin A, 2009, INT J COMPUT VISION, V81, P105, DOI 10.1007/s11263-008-0166-0; Lindsay BG, 1988, CONT MATH, V80, P221, DOI DOI 10.1090/CONM/080/999014; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; McAuley J.J, 2009, P BRIT MACH VIS C; Meltzer T, 2009, P C UNC ART INT; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Nowozin S, 2010, P EUR C COMP VIS; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Ren X., 2006, P EUR C COMP VIS; Ren XF, 2008, INT J COMPUT VISION, V77, P47, DOI 10.1007/s11263-007-0092-6; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Scharstein D, 2007, P IEEE C COMP VIS PA; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Stewart L, 2008, IEEE T PATTERN ANAL, V30, P1415, DOI 10.1109/TPAMI.2007.70790; Stoyanov V, 2011, P INT WORKSH ART INT; Stoyanov Veselin, 2012, P C N AM CHAPT ASS C; Sutton C. A., 2005, P C UNC ART INT; Szummer M., 2008, P EUR C COMP VIS; Toyoda T, 2008, IEEE T PATTERN ANAL, V30, P1483, DOI 10.1109/TPAMI.2008.105; Verbeek J.J, 2007, P ADV NEUR INF PROC; Vishwanathan S.V.N, 2006, P INT C MACH LEARN; Wainwright MJ, 2006, J MACH LEARN RES, V7, P1829; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Weinman JJ, 2008, LECT NOTES COMPUT SC, V5302, P617, DOI 10.1007/978-3-540-88682-2_47; Welling M, 2004, NEURAL COMPUT, V16, P197, DOI 10.1162/08997660460734056; Yang W, 2009, TECHNICAL REPORT; Yuan J., 2008, P IEEE C COMP VIS PA; Zhong P, 2007, IEEE T GEOSCI REMOTE, V45, P1469, DOI 10.1109/TGRS.2007.893739; Zhu SC, 2002, IEEE T PATTERN ANAL, V24, P1001, DOI 10.1109/TPAMI.2002.1017626	53	83	88	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2454	2467		10.1109/TPAMI.2013.31	http://dx.doi.org/10.1109/TPAMI.2013.31			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969389	Green Submitted			2022-12-18	WOS:000323175200011
J	Chen, N; Zhu, J; Sun, FC; Xing, EP				Chen, Ning; Zhu, Jun; Sun, Fuchun; Xing, Eric Poe			Large-Margin Predictive Latent Subspace Learning for Multiview Data Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Latent subspace model; large-margin learning; classification; regression; image retrieval and annotation		Learning salient representations of multiview data is an essential step in many applications such as image classification, retrieval, and annotation. Standard predictive methods, such as support vector machines, often directly use all the features available without taking into consideration the presence of distinct views and the resultant view dependencies, coherence, and complementarity that offer key insights to the semantics of the data, and are therefore offering weak performance and are incapable of supporting view-level analysis. This paper presents a statistical method to learn a predictive subspace representation underlying multiple views, leveraging both multiview dependencies and availability of supervising side-information. Our approach is based on a multiview latent subspace Markov network (MN) which fulfills a weak conditional independence assumption that multiview observations and response variables are conditionally independent given a set of latent variables. To learn the latent subspace MN, we develop a large-margin approach which jointly maximizes data likelihood and minimizes a prediction loss on training data. Learning and inference are efficiently done with a contrastive divergence method. Finally, we extensively evaluate the large-margin latent MN on real image and hotel review datasets for classification, regression, image annotation, and retrieval. Our results demonstrate that the large-margin approach can achieve significant improvements in terms of prediction performance and discovering predictive latent subspace representations.	[Chen, Ning; Zhu, Jun; Sun, Fuchun] Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Xing, Eric Poe] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Tsinghua University; Carnegie Mellon University	Chen, N (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, FIT Bldg, Beijing 100084, Peoples R China.	ningchen@tsinghua.edu.cn; dcszj@tsinghua.edu.cn; fcsun@tsinghua.edu.cn; epxing@cs.cmu.edu			CSC fellowship from China; National Key Project for Basic Research of China [2013CB329403, 2012CB316301]; Tsinghua Self-innovation Project [20121088071, 20111081111]; NNSF of China [60820304, 91120011]; US Office of Naval Research (ONR) at CMU [N000140910758]; ONR [N000140910758]; US National Science Foundation (NSF) [IIS-0713379]; NSF [DBI-0546594]; Alfred P. Sloan Research Fellowship	CSC fellowship from China; National Key Project for Basic Research of China(National Basic Research Program of China); Tsinghua Self-innovation Project; NNSF of China(National Natural Science Foundation of China (NSFC)); US Office of Naval Research (ONR) at CMU; ONR(Office of Naval Research); US National Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); Alfred P. Sloan Research Fellowship(Alfred P. Sloan Foundation)	The authors thank the reviewers for their helpful comments. Part of this work was done while Ning Chen was a visiting researcher at Carnegie Mellon University (CMU) under a CSC fellowship from China. Ning Chen, Jun Zhu, and Fuchun Sun are supported by National Key Project for Basic Research of China (Grant Nos. 2013CB329403, 2012CB316301), Tsinghua Self-innovation Project (Grant Nos. 20121088071, 20111081111), NNSF of China (Grant Nos: 60820304 and 91120011). Jun Zhu was supported by US Office of Naval Research (ONR) N000140910758 at CMU. Eric Poe Xing is supported by ONR N000140910758, US National Science Foundation (NSF) IIS-0713379, NSF Career DBI-0546594, and an Alfred P. Sloan Research Fellowship. Ning Chen and Jun Zhu contributed equally to this paper.	Akaho S., 2001, INT M PSYCH SOC, P263; Ando K., 2007, P INT C MACH LEARN; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Blei David M., 2007, P ADV NEUR INF PROC; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blum A., 1998, P ANN C LEARN THEOR; Brefeld U., 2004, P INT C MACH LEARN; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chaudhuri K., 2009, P INT C MACH LEARN; Chen N., 2010, P ADV NEUR INF PROC; Christoudias C. M., 2008, P C UNC ART INT; Chua T.S., 2009, P INT C IM VID RETR; CRAMMER K, 2001, J MACHINE LEARNING R, V2, P265, DOI DOI 10.1162/15324430260185628; Culp M, 2009, ANN APPL STAT, V3, P292, DOI 10.1214/08-AOAS202; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Diethe T, 2008, MULTIVIEW FISHER DIS; Ferrari V., 2004, P IEEE C COMP VIS PA; Foster D., 2008, TR20084 TTI; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Ganchev K., 2008, P C UNC ART INT; Gokalp D., 2007, P IEEE C COMP VIS PA; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Joachims T., 1999, MAKING LARGE SCALE S, P41, DOI 10.17877/DE290R-5098; Kakade S. M., 2007, P ANN C LEARN THEOR; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Larochelle H., 2008, P INT C MACH LEARN; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Lowe D. G., 1999, P IEEE C COMP VIS PA; McCallum A., 2006, P NATL C ART INT; Salakhutdinov R., 2009, P ADV NEUR INF PROC; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Thomas A., 2006, P IEEE C COMP VIS PA; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wallach H. M., 2006, P INT C MACH LEARN; Wang C., 2009, P IEEE C COMP VIS PA; Welling M., 2001, P INT C ART NEUR NET; Welling M., 2004, ADV NEURAL INFORM PR, V17, P1481; Weston J., 2010, P EUR C MACH LEARN; Xing E. P., 2005, P C UNC ART INT; Xing E. P., 2003, P C UNC ART INT; Yang J., 2007, P SIAM C DAT MIN; Yu C., 2009, P INT C MACH LEARN; Zhang J, 2008, MACH LEARN, V73, P221, DOI 10.1007/s10994-008-5050-1; Zhu J., 2010, P INT C MACH LEARN; Zhu J., 2010, P ADV NEUR INF PROC; Zhu J., 2008, ADV NEURAL INFORM PR, P1977; Zhu Jun, 2009, P INT C MACH LEARN	51	83	84	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2365	2378		10.1109/TPAMI.2012.64	http://dx.doi.org/10.1109/TPAMI.2012.64			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22392706	Green Submitted			2022-12-18	WOS:000309913700007
J	Arbel, E; Hel-Or, H				Arbel, Eli; Hel-Or, Hagit			Shadow Removal Using Intensity Surfaces and Texture Anchor Points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shadow removal; shading; color; texture; shadow detection; region growing; enhancement	MODELS	Removal of shadows from a single image is a challenging problem. Producing a high-quality shadow-free image which is indistinguishable from a reproduction of a true shadow-free scene is even more difficult. Shadows in images are typically affected by several phenomena in the scene, including physical phenomena such as lighting conditions, type and behavior of shadowed surfaces, occluding objects, etc. Additionally, shadow regions may undergo postacquisition image processing transformations, e. g., contrast enhancement, which may introduce noticeable artifacts in the shadow-free images. We argue that the assumptions introduced in most studies arise from the complexity of the problem of shadow removal from a single image and limit the class of shadow images which can be handled by these methods. The purpose of this paper is twofold: First, it provides a comprehensive survey of the problems and challenges which may occur when removing shadows from a single image. In the second part of the paper, we present our framework for shadow removal, in which we attempt to overcome some of the fundamental problems described in the first part of the paper. Experimental results demonstrating the capabilities of our algorithm are presented.	[Arbel, Eli; Hel-Or, Hagit] Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel	University of Haifa	Arbel, E (corresponding author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.	eliarbel@gmail.com; hagit@cs.haifa.ac.il						[Anonymous], 1987, ACM SIGGRAPH COMPUTE, DOI [10.1145/37402.37427, DOI 10.1145/37402.37427]; ARBEL E, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383081; BABA M, 2003, P ACM SIGGRAPH; BABA M, 2004, P ACM SIGGRAPH; Barnard K, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P97; Barrow H. G., 1978, COMPUTER VISION SYST; BEVILACQUA A, 2003, WSCG, V11, P57; CHUANG YY, 2003, P ACM SIGGRAPH 2003, P494; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DU Z, 2005, P INT C IM AN REC, P107; FIGOV Z, 2004, P IASTED INT C COMP; FINLAYSON G, 2007, P IEEE INT C COMP VI; Finlayson G. D., 2002, P IS T SID 10 COL IM, P73; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582; Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823; Fredembach C., 2005, P BRIT MACH VIS C, P970; Fredembach C, 2006, INT C PATT RECOG, P832; Grest D, 2003, VISION, MODELING, AND VISUALIZATION 2003, P253; Gu XD, 2005, IEEE T NEURAL NETWOR, V16, P692, DOI 10.1109/TNN.2005.844902; Jain A. K., 1989, FUNDAMENTALS DIGITAL; KELLER JB, 1962, J OPT SOC AM, V52, P116, DOI 10.1364/JOSA.52.000116; Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017; Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106; Levine MD, 2005, PATTERN RECOGN LETT, V26, P251, DOI 10.1016/j.patrec.2004.10.021; Lewis JP, 1994, PROC CANAD IMAG PROC, P120; Li S. Z., 2001, COMP SCI W; Lurig C, 2000, GRAPH MODELS, V62, P2, DOI 10.1006/gmod.1999.0515; Mamassian P, 1998, TRENDS COGN SCI, V2, P288, DOI 10.1016/S1364-6613(98)01204-2; Mohan A, 2007, IEEE COMPUT GRAPH, V27, P23, DOI 10.1109/MCG.2007.30; Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520; Primack H, 1996, PHYS REV LETT, V76, P1615, DOI 10.1103/PhysRevLett.76.1615; Rosin PL, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P347; Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008; Salvador E, 2001, INT CONF ACOUST SPEE, P1545, DOI 10.1109/ICASSP.2001.941227; So AWK, 2005, SEVENTH IASTED INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING, P315; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Wu TP, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243982; Wu TP, 2005, IEEE I CONF COMP VIS, P480; Xu L, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P1049	42	83	91	1	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1202	1216		10.1109/TPAMI.2010.157	http://dx.doi.org/10.1109/TPAMI.2010.157			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20733214				2022-12-18	WOS:000289524000010
J	Amit, Y; Geman, D; Wilder, K				Amit, Y; Geman, D; Wilder, K			Joint induction of shape features and tree classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape quantization; feature induction; invariant arrangements; multiple decision trees; randomization; digit recognition; local topographic codes	CHARACTER-RECOGNITION; HANDWRITTEN	We introduce a very large family of binary features for two-dimensional shapes. The salient ones for separating particular shapes are determined by inductive learning during the construction of classification trees. There is a feature for every possible geometric arrangement of local topographic codes. The arrangements express coarse constraints on relative angles and distances among the code locations and are nearly invariant to substantial affine and nonlinear deformations. They are also partially ordered, which makes it possible to narrow the search for informative ones at each node of the tree. Different trees correspond to different aspects of shape. They are statistically weakly dependent due to randomization and are aggregated in a simple way. Adapting the algorithm to a shape family is then fully automatic once training samples are provided. As an illustration, we classify handwritten digits from the NIST database; the error rate is .7 percent.	UNIV MASSACHUSETTS, DEPT MATH & STAT, AMHERST, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Amit, Y (corresponding author), UNIV CHICAGO, DEPT STAT, CHICAGO, IL 60637 USA.		Geman, Donald/A-3325-2010					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Amit Y., 1994, RANDOMIZED INQUIRIES; BOSER B, 1992, P COLT, V2; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Breiman L., 1994, 421 U CAL DEP STAT; CHO K, 1994, IEEE T PATTERN ANAL, V16, P882, DOI 10.1109/34.310683; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P705, DOI 10.1142/S0218001493000352; GARRIS MD, NIST SPECIAL DATABAS; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; JEDYNAK B, 1996, P IMAGE COM 96; KOVACSV ZM, 1995, PATTERN RECOGN, V28, P293, DOI 10.1016/0031-3203(94)00099-8; Kwok S., 1990, UNCERTAINTY ARTIFICI; LECUN Y, 1990, ADV NEURAL INFORMATI, V2; Mundy J., 1992, GEOMETRIC INVARIANCE; OLIVER JJ, 1994, P ECML 1994; Olshen R., 1984, CLASSIFICATION REGRE; REISS T, 1993, LECT NOTES COMPUTER, V676; SABOURIN M, 1992, NEURAL NETWORKS, V5, P843, DOI 10.1016/S0893-6080(05)80144-3; SHLIEN S, 1990, PATTERN RECOGN, V23, P757, DOI 10.1016/0031-3203(90)90098-6; SIMARD PY, 1994, INT C PATT RECOG, P262, DOI 10.1109/ICPR.1994.576916; SMITH SJ, 1994, IEEE T PATTERN ANAL, V16, P915, DOI 10.1109/34.310689; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546; WILDER KJ, 1997, DECISION TREE ALGORI; WILKINSON R, 1992, 1 CENS OPT CHAR REC	28	83	87	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1300	1305		10.1109/34.632990	http://dx.doi.org/10.1109/34.632990			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500012
J	Goudail, F; Lange, E; Iwamoto, T; Kyuma, K; Otsu, N				Goudail, F; Lange, E; Iwamoto, T; Kyuma, K; Otsu, N			Face recognition system using local autocorrelations and multiscale integration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; face recognition; autocorrelation; object recognition; shift invariant feature extraction; multiresolution image analysis	TEMPLATES	In this paper we investigate the performance of a technique for face recognition based on the computation of 25 local autocorrelation coefficients. We use a large database of 11,600 frontal facial images of 116 persons, organized in training and test sets, for evaluation. Autocorrelation coefficients are computationally inexpensive, inherently shift-invariant and quite robust against changes in facial expression. We focus on the difficult problem of recognizing a large number of known human faces while rejecting other, unknown faces which lie quite close in pattern space. A multiresolution system achieves a recognition rate of 95%, while falsely accepting only 1.5% of unknown faces. It operates at a speed of about one face per second. Without rejection of unknown faces, we obtain a peak recognition rate of 99.9%. The good performance indicates that local autocorrelation coefficients have a surprisingly high information content.	MITSUBISHI ELECTR CORP, ADV TECHNOL RES & DEV CTR, DEPT NEURAL & PARALLEL PROC TECHNOL, AMAGASAKI, HYOGO 661, JAPAN; MINIST INT TRADE & IND, AGCY IND SCI & TECHNOL, ELECTROTECH LAB, TSUKUBA, IBARAKI 305, JAPAN	Mitsubishi Electric Corporation; National Institute of Advanced Industrial Science & Technology (AIST)	Goudail, F (corresponding author), ECOLE SUPER PHYS MARSEILLE, LAB SIGNAL & IMAGE, DOMAINE UNIV ST JEROME, F-13397 MARSEILLE 20, FRANCE.		goudail, françois/AAG-2372-2020					ARBUCKLE TD, UNPUB INT J UNCERTAI; BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/ciun.1994.1017; BICHSEL M, 1991, THESIS EIDGENOSSISCH; BOUATTOUR H, 1992, P ART NEUR NETW, P1595; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Choquet G., 1954, ANN LINSTITUT FOURIE, V5, P131, DOI [10.5802/aif.53, DOI 10.5802/AIF.53]; COTTREL GW, 1990, P INT NEUR NETW C PA, P65; FUKUNAGA K, 1990, INTRO STATISTICAL PA; GOUDAIL F, 1993, P INT JOINT C NEUR N, P1297; GOUDAIL F, 1993, LARGE SCALE FACE REC; HAMMERSTROM D, 1990, JUN P INT JOINT C NE, P537; KAYA Y, 1972, FRONTIERS PATTERN RE; KONDO Y, 1994, P IEEE INT SOL STAT, P218; KURITA T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P213, DOI 10.1109/ICPR.1992.201757; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LANGE E, 1994, IEEE MICRO, V14, P29, DOI 10.1109/40.331383; LANGE E, 1995, P INT C ART NEUR NET, P287; LANGE E, 1996, TRENDS OPTICS RES DE, P63; Otsu N., 1988, Proceedings of IAPR Workshop on Computer Vision: Special Hardware and Industrial Applications, P431; PERRY JL, 1990, IJCNN WASH DC, P413; Ramacher U., 1991, VLSI DESIGN NEURAL N; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VALENTIN D, 1994, PATTERN RECOGN, V27, P1209, DOI 10.1016/0031-3203(94)90006-X; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59	25	83	85	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1024	1028		10.1109/34.541411	http://dx.doi.org/10.1109/34.541411			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100006
J	Shneier, M; AbdelMottaleb, M				Shneier, M; AbdelMottaleb, M			Exploiting the JPEG compression scheme for image retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image retrieval; JPEG; DCT; compressed domain processing; image databases		We address the problem of retrieving images from a large database using an image as a query. The method is specifically aimed at databases that store images in JPEG format, and works in the compressed domain to create index keys. A key is generated for each image in the database and is matched with the key generated for the query image. The keys are independent of the size of the image. Images that have similar keys are assumed to be similar, but there is no semantic meaning to the similarity.	PHILIPS LABS,BRIARCLIFF MANOR,NY 10510	Philips; Philips Research	Shneier, M (corresponding author), OFF NAVAL RES,800 N QUINCY ST,ARLINGTON,VA 22217, USA.			AbdelMottaleb, Mohamed/0000-0002-4163-7230				ARMAN F, 1993, STORAGE RETRIEVAL IM, V1908; CHANG SF, 1995, IEEE J SELECTED AREA, V13; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145; Hung A. C., 1993, PVRG JPEG CODEC 1 1; Pennebaker W. B., 1993, JPEG STILL IMAGE DAT, V1993rd; PENTLAND A, 1994, P SPIE C STOR RETR I; SMITH B, 1993, IEEE COMPUTER GRAPHI, V13; SMITH BC, 1994, ACM MULTIMEDIA, P77; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; YEO BL, 1995, P INT C MULT COMP SY, P81	11	83	92	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					849	853		10.1109/34.531805	http://dx.doi.org/10.1109/34.531805			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VE318					2022-12-18	WOS:A1996VE31800009
J	BERKMANN, J; CAELLI, T				BERKMANN, J; CAELLI, T			COMPUTATION OF SURFACE GEOMETRY AND SEGMENTATION USING COVARIANCE TECHNIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DIFFERENTIAL GEOMETRY; COVARIANCE; GAUSS MAP; IMAGE SEGMENTATION; JUMP MAP; CREASE MAP; REGION SEGMENTATION	3-D OBJECTS; RECOGNITION	In this correspondence, the application of covariance techniques to surface representation of 3-D objects is discussed and such ways of computing surface geometry are compared with traditional methods using Differential Geometry. It is shown how the covariance method provides surface descriptors that are invariant to rigid motions without explicitly using surface parameterizations or derivatives. Analogous covariance operators for both the Gauss and Weingarten maps are defined and a range image segmentation technique is presented that labels pixels as jump or crease discontinuities or planar, parabolic or curved region types.	UNIV MELBOURNE,DEPT COMP SCI,PARKVILLE,VIC 3052,AUSTRALIA	University of Melbourne				Caelli, Terry/0000-0001-9281-2556				BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; Ping Liang, 1990, Computer Vision, Graphics, and Image Processing, V52, P78, DOI 10.1016/0734-189X(90)90124-E; YOKOYA N, 1989, IEEE T PATTERN ANAL, V11, P643, DOI 10.1109/34.24798	5	83	85	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1114	1116		10.1109/34.334391	http://dx.doi.org/10.1109/34.334391			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100005
J	VANDENBOOMGAARD, R; SMEULDERS, A				VANDENBOOMGAARD, R; SMEULDERS, A			THE MORPHOLOGICAL STRUCTURE OF IMAGES - THE DIFFERENTIAL-EQUATIONS OF MORPHOLOGICAL SCALE-SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								In this paper we introduce a class of nonlinear differential equations that are solved using morphological operations. The erosion and dilation act as morphological propagators propagating the initial condition (original image in computer vision terminology) into the ''scale-space,'' much like the Gaussian convolution is the Propagator for the linear diffusion equation. Analysis starts in the set domain, resulting in the description of erosions and dilations in terms of contour propagation. We show that the structuring elements to be used must have the property that at each point of the contour there is a well-defined and unique normal vector. Then given the normal at a point of the dilated contour we can find the corresponding point (point-of-contact) on the original contour. In some situations we can even link the normal of the dilated contour with the normal in the point-of-contact of the original contour. The results of the set domain are then generalized to grey value images. The role of the normal is replaced with the function gradient. The same analysis also holds for the erosion. Using a family of increasingly larger structuring functions we are then able to link infinitesimal changes in grey value (resulting from the use of an infinitesimally larger structuring function) with the gradient in the image. The obtained differential equations bear great resemblance to the nonlinear differential equation, Burgers' equation, describing the propagation of a shock-wave. In the discussion we indicate that the results of this paper provide the theoretical basis to analyze morphological scale-space in much greater depth.			VANDENBOOMGAARD, R (corresponding author), UNIV AMSTERDAM,FAC MATH & COMP SCI,KRUISLAAN 403,1098 SJ AMSTERDAM,NETHERLANDS.							BLUM H, 1961, BIOL PROTOTYPES SYNT, P244; BROCKET R, 1992, MAR IEEE INT C AC SP; Burgers JM., 1974, NONLINEAR DIFFUSION; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; DORST L, 1994, SIGNAL PROCESS, V38, P79, DOI 10.1016/0165-1684(94)90058-2; HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555; KIMIA BB, 1990, LECTURE NOTES COMPUT, V427; KOENDERINK JJ, 1990, BIOL CYBERN; Lax P. D., 1973, HYPERBOLIC SYSTEMS C; Marr D., 1982, VISION; MATHERON G., 1975, RANDOM SETS INTEGRAL; MATHERON G, 1988, MATH MORPHOLOGY IMAG, V2; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Serra J, 1982, IMAGE ANAL MATH MORP; Smoller J., 1983, GRUNDLEHREN MATH WIS; VANDENBOOMGAARD R, 1992, 11TH IAPR INT C PATT, V3, P268; VANDENBOOMGAARD R, 1992, THESIS U AMSTERDAM; VANDENBOOMGAARD R, UNPUB DIMENSIONAL DE; VANDENBOOMGAARD R, 1992, SEP P WORKSH SHAP PI; VERWER BJH, 1988, PATTERN RECOGNITION; VERWER BJH, 1991, THESIS DELFT U TECHN; VINCENT L, 1991, SPIE MED IMAGING, V5	23	83	83	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1101	1113		10.1109/34.334389	http://dx.doi.org/10.1109/34.334389			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081		Green Submitted			2022-12-18	WOS:A1994PW08100004
J	WENG, JY; HUANG, TS; AHUJA, N				WENG, JY; HUANG, TS; AHUJA, N			MOTION AND STRUCTURE FROM LINE CORRESPONDENCES - CLOSED-FORM SOLUTION, UNIQUENESS, AND OPTIMIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; DYNAMIC SCENE ANALYSIS; MOTION ESTIMATION; OPTIMAL ESTIMATION; STRUCTURE FROM MOTION	IMAGE FLOW; PARAMETERS; ALGORITHM; SURFACES; SCENE	This paper discusses estimating motion and structure parameters from line correspondences of a rigid scene. We present in this paper a new closed-form solution to motion and structure parameters from line correspondences through three monocular perspective views. The algorithm makes use of redundancy in the data to improve the accuracy of the solutions. The uniqueness of the solution is established, and necessary and sufficient conditions for degenerate spatial line configurations have been derived. Optimization has been employed to further improve the accuracy of the estimates in the presence of noise. Simulations have showed that the errors of the optimized estimates are close to the theoretical lower error bound.	UNIV ILLINOIS,DEPT ELECT ENGN,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	WENG, JY (corresponding author), UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P348; Bottema O., 1979, THEORETICAL KINEMATI; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CRAMER H, 1946, MATH METHODS STATIST; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P313, DOI 10.1016/0734-189X(83)90029-4; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FAUGERAS OD, 1987, 1ST P INT C COMP VII; GIORDANO AA, 1985, LEAST SQUARES ESTIMA; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LIU YC, 1986, OCT P INT C PATT REC, P306; Longuet-Higgins H. C., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P395; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luenberger D. G., 1969, OPTIMIZATION VECTOR; MCINTOSH JH, 1988, COMPUT VISION GRAPH, V43, P386, DOI 10.1016/0734-189X(88)90091-6; MITICHE A, 1986, OCT P INT C PATT REC, P1110; RAO CR, 1973, LINEAR STATISTICAL I; Shuster M.D., 1978, P GUID CONTR C PAL A, P88; Sorenson H. W, 1980, CONTROL SYSTEMS THEO; SPETSAKIS M, 1987, 6TH P AAAI NAT C ART, P738; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WENG J, 1989, MAR P IEEE WORKSH VI, P359; WENG J, 1987, 1ST P INT C COMP VIS, P703; WENG J, 1988, JUN P IEEE C COMP VI, P381; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; YEN BL, 1983, IMAGE SEQUENCE PROCE; Zhuang X., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P366; ZHUANG XH, 1988, COMPUT VISION GRAPH, V42, P334, DOI 10.1016/S0734-189X(88)80043-4	31	83	95	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1992	14	3					318	336		10.1109/34.120327	http://dx.doi.org/10.1109/34.120327			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HF732		Green Submitted			2022-12-18	WOS:A1992HF73200002
J	KWEON, IS; KANADE, T				KWEON, IS; KANADE, T			HIGH-RESOLUTION TERRAIN MAP FROM MULTIPLE SENSOR DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						AUTONOMOUS ROBOTS; MATCHING; RANGE IMAGES; RUGGED TERRAIN; SENSOR FUSION; TERRAIN MAPS; 3-D VISION		This paper presents 3-D vision techniques for incrementally building an accurate 3-D representation of rugged terrain using multiple sensors. We have developed the locus method to model the rugged terrain. The locus method exploits sensor geometry to efficiently build a terrain representation from multiple sensor data. Incrementally modeling the terrain from a sequence of range images requires an accurate estimate of motion between successive images. In rugged terrain, estimating motion accurately is difficult because of occlusions and irregularities. We show how to extend the locus method to pixel-based terrain matching, called the iconic matching method to solve these problems. To achieve the required accuracy in the motion estimate, our terrain matching method combines feature matching, iconic matching, and inertial navigation data. Over a long distance of robot motion, it is difficult to avoid error accumulation in a composite terrain map that is the result of only local observations. However, a prior digital elevation map (DEM) can reduce this error accumulation if we estimate the vehicle position in the DEM. We apply the locus method to estimate the vehicle position in the DEM by matching a sequence of range images with the DEM. Experimental results from large-scale real and synthetic terrains demonstrate the feasibility and power of our 3-D mapping techniques for rugged terrain. In real world experiments, we built a composite terrain map by merging 125 real range images over a distance of 100 m. Using synthetic range images, we produced a composite map of 150 m from 159 images. In this work, we demonstrate a 3-D vision system for modeling rugged terrain. With this system, mobile robots operating in rugged environments can build accurate terrain models from multiple sensor data.	CARNEGIE MELLON UNIV,INST ROBOT,CTR VIS & AUTONOMOUS SYST,PITTSBURGH,PA 15213	Carnegie Mellon University			Kweon, In So/C-2023-2011					BARES J, 1988, SPECIAL ISSUES COOMP, V44, P75; BRADY M, 1985, MAR P CVGIP, P1; EDWARDS DL, 1988, PHOTOGRAMMETRIA, V43, P101; GENNERY DB, 1989, 1989 P IEEE C ROB AU; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; HEBERT M, 1989, 1989 P IEEE C ROB AU; HEBERT M, 1988, CMURITR8812 CARN U P; Kendall MG, 1963, GEOMETRICAL PROBABIL; KWEON I, 1988, P SPACE OPER AUTOMAT; KWEON I, 1988, P SPIE MOBILE ROBOTS; KWEON I, 1991, CMURITR911 CARN U PI; KWEON IS, 1990, THESIS CARNEGIE MELL; LEE PM, 1989, BAYESIAN STATISTICS; MATTHIES L, 1988, P IMAGE UNDERSTANDIN; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MOFFITT FH, 1982, SURVEYING; NORVELLE FR, 1981, FEB P ASP ACSM C; OLIN KE, 1989, P IU WORKSHOP; ROBERTS KS, 1988, P COMPUT VISION PATT; SZELISKI R, 1988, DEC P INT C COMP VIS; SZELISKI RS, 1988, THESIS CARNEGIE MELL; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; THOMAS HJ, 1990, 23RD P PITTSB C MOD	24	83	90	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					278	292		10.1109/34.121795	http://dx.doi.org/10.1109/34.121795			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900014
J	SALARI, V; SETHI, IK				SALARI, V; SETHI, IK			FEATURE POINT CORRESPONDENCE IN THE PRESENCE OF OCCLUSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SALARI, V (corresponding author), WAYNE STATE UNIV,DEPT COMP SCI,DETROIT,MI 48202, USA.			Sethi, Ishwar/0000-0002-2578-111X				ASADA M, 1983, COMPUT VISION GRAPH, V21, P118, DOI 10.1016/S0734-189X(83)80031-0; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; JENKIN M, 1986, COMPUT VISION GRAPH, V33, P16, DOI 10.1016/0734-189X(86)90219-7; PRAGER JM, 1983, COMPUT VISION GRAPH, V24, P271, DOI 10.1016/0734-189X(83)90057-9; RAMACHANDRAN VS, 1986, SCI AM, V254, P102, DOI 10.1038/scientificamerican0686-102; RASHID RF, 1980, IEEE T PATTERN ANAL, V2, P574, DOI 10.1109/TPAMI.1980.6447705; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; Thompson W. B., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P252; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; YACHIDA M, 1981, IEEE T PATTERN ANAL, V3, P12, DOI 10.1109/TPAMI.1981.4767046; Zuniga O. A., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P30	12	83	92	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					87	91		10.1109/34.41387	http://dx.doi.org/10.1109/34.41387			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700009
J	JAIN, AK; HOFFMAN, R				JAIN, AK; HOFFMAN, R			EVIDENCE-BASED RECOGNITION OF 3-D OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NORTHROP CORP, CTR RES & TECHNOL, AUTOMAT SCI GRP, PALOS VERDES PENINSULA, CA 90274 USA	Northrop Grumman Corporation	JAIN, AK (corresponding author), MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA.							Buchanan B.G., 1984, RULE BASED EXPERT SY; CHIEN CH, 1985, 3RD P WORKSH COMP VI, P49; COHEN PR, 1985, RES NOTES ARTIFICIAL, V2; Conover WJ, 1980, PRACTICAL NONPARAMET; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; Duda R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School, P153; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Garey M.R., 1979, COMPUTERS INTRACTABI; GIL B, 1983, COMPUT VISION GRAPH, V21, P395, DOI 10.1016/S0734-189X(83)80051-6; GRIMSON WEL, 1984, 1984 P IEEE INT C RO, P248; HALL EL, 1982, COMPUTER, V15, P42; Hebert M., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P458; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; Hoffman RL, 1986, THESIS MICHIGAN STAT; HORAUD P, 1984, 1984 P IEEE INT C RO, P78; HURT SL, 1984, PATTERN RECOGN, V17, P407, DOI 10.1016/0031-3203(84)90069-4; LU SW, 1985, NOV P INT FED AUT CO, P389; MAGEE MJ, 1985, IEEE T PATTERN ANAL, V7, P629, DOI 10.1109/TPAMI.1985.4767719; Marr D., 1982, VISION; Michalski R. S., 1986, MACHINE LEARNING ART, V2; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396, DOI 10.1109/TPAMI.1983.4767409; Michalski RS, 1983, MACHINE LEARNING ART, DOI 10.1007/978-3-662-12405-5; OSHIMA M, 1981, 7TH P INT JOINT C AR, P601; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Shortliffe EH., 1975, MATH BIOSCI, V23, P351, DOI [10.1016/0025-5564(75)90047-4, DOI 10.1016/0025-5564(75)90047-4]; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; Stockman G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P742; TOMITA F, 1984, P IEEE C ARTIFICIAL, P186; WANG YF, 1984, IEEE T PATTERN ANAL, V6, P513, DOI 10.1109/TPAMI.1984.4767556; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	31	83	85	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					783	802		10.1109/34.9102	http://dx.doi.org/10.1109/34.9102			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100002
J	REDDI, SS				REDDI, SS			RADIAL AND ANGULAR MOMENT INVARIANTS FOR IMAGE IDENTIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											REDDI, SS (corresponding author), AEROSP COMMUN CORP,DIV AERONUTRON,NEWPORT BEACH,CA 92663, USA.							DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692	2	83	86	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					240	242		10.1109/TPAMI.1981.4767087	http://dx.doi.org/10.1109/TPAMI.1981.4767087			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868944				2022-12-18	WOS:A1981MN96800019
J	Liu, J; Ding, HH; Shahroudy, A; Duan, LY; Jiang, XD; Wang, G; Kot, AC				Liu, Jun; Ding, Henghui; Shahroudy, Amir; Duan, Ling-Yu; Jiang, Xudong; Wang, Gang; Kot, Alex C.			Feature Boosting Network For 3D Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Pose estimation; Two dimensional displays; Boosting; Logic gates; Reliability; Task analysis; 3D pose estimation; convolutional LSTM; long short-term dependency; context consistency gate		In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image. In this method, the features learned by the convolutional layers are boosted with a new long short-term dependence-aware (LSTD) module, which enables the intermediate convolutional feature maps to perceive the graphical long short-term dependency among different hand (or body) parts using the designed Graphical ConvLSTM. Learning a set of features that are reliable and discriminatively representative of the pose of a hand (or body) part is difficult due to the ambiguities, texture and illumination variation, and self-occlusion in the real application of 3D pose estimation. To improve the reliability of the features for representing each body part and enhance the LSTD module, we further introduce a context consistency gate (CCG) in this paper, with which the convolutional feature maps are modulated according to their consistency with the context representations. We evaluate the proposed method on challenging benchmark datasets for 3D hand pose estimation and 3D full body pose estimation. Experimental results show the effectiveness of our method that achieves state-of-the-art performance on both of the tasks.	[Liu, Jun; Ding, Henghui; Jiang, Xudong; Kot, Alex C.] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Shahroudy, Amir] Chalmers Univ Technol, Dept Elect Engn, S-41296 Gothenburg, Sweden; [Duan, Ling-Yu] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Wang, Gang] Alibaba Grp, Hangzhou 311121, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chalmers University of Technology; Peking University; Alibaba Group	Liu, J (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.; Duan, LY (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	jliu029@ntu.edu.sg; ding0093@ntu.edu.sg; amirsh@chalmers.se; lingyu@pku.edu.cn; exdjiang@ntu.edu.sg; gangwang6@gmail.com; eackot@ntu.edu.sg	Jiang, Xudong/B-1555-2008; Ding, Henghui/C-7486-2019; Shahroudy, Amir/T-2261-2017	Jiang, Xudong/0000-0002-9104-2315; Ding, Henghui/0000-0003-4868-6526; Liu, Jun/0000-0002-4365-4165; Shahroudy, Amir/0000-0002-1045-6437; Kot, Alex/0000-0001-6262-8125	National Research Foundation, Singapore, under the IDM Strategic Research Programme; National Basic Research Program of China [2015CB351806]; National Natural Science Foundation of China [61661146005, U1611461]	National Research Foundation, Singapore, under the IDM Strategic Research Programme; National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research was carried out at the Rapid-Rich Object Search (ROSE) Lab at the Nanyang Technological University. ROSE is supported by the National Research Foundation, Singapore, under the IDM Strategic Research Programme. This work was in part supported by the National Basic Research Program of China under grant 2015CB351806, and the National Natural Science Foundation of China under Grant 61661146005 and Grant U1611461. We thank NVIDIA AI Technology Centre for GPU donation.	Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Cho K., 2014, P 2014 C EMP METH NA, P1724; Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510; Dauphin YN, 2017, PR MACH LEARN RES, V70; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ghezelghieh MF, 2016, INT CONF 3D VISION, P685, DOI 10.1109/3DV.2016.75; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hofmann M, 2012, INT J COMPUT VISION, V96, P103, DOI 10.1007/s11263-011-0451-1; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539; Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064; Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373; Park S, 2016, LECT NOTES COMPUT SC, V9915, P156, DOI 10.1007/978-3-319-49409-8_15; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Rhodin H, 2018, PROC CVPR IEEE, P8437, DOI 10.1109/CVPR.2018.00880; Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002; Shi XJ, 2015, ADV NEUR IN, V28; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simonyan K, 2014, ADV NEUR IN, V27; Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284; Tekin Bugra, 2016, BRIT MACH VIS C 2016, DOI DOI 10.5244/C.30.130; Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Xiong CM, 2016, PR MACH LEARN RES, V48; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Zanfir A, 2018, PROC CVPR IEEE, P2148, DOI 10.1109/CVPR.2018.00229; Zhang JW, 2017, IEEE IMAGE PROC, P982; Zhao RQ, 2018, IEEE T PATTERN ANAL, V40, P3059, DOI 10.1109/TPAMI.2017.2772922; Zhou XW, 2019, IEEE T PATTERN ANAL, V41, P901, DOI 10.1109/TPAMI.2018.2816031; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51; Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525	44	82	83	14	68	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					494	501		10.1109/TPAMI.2019.2894422	http://dx.doi.org/10.1109/TPAMI.2019.2894422			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30676946	Green Submitted			2022-12-18	WOS:000508386100019
J	Xie, J; Dai, GX; Zhu, F; Wong, EK; Fang, Y				Xie, Jin; Dai, Guoxian; Zhu, Fan; Wong, Edward K.; Fang, Yi			DeepShape: Deep-Learned Shape Descriptor for 3D Shape Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								Complex geometric variations of 3D models usually pose great challenges in 3D shape matching and retrieval. In this paper, we propose a novel 3D shape feature learning method to extract high-level shape features that are insensitive to geometric deformations of shapes. Our method uses a discriminative deep auto-encoder to learn deformation-invariant shape features. First, a multiscale shape distribution is computed and used as input to the auto-encoder. We then impose the Fisher discrimination criterion on the neurons in the hidden layer to develop a deep discriminative auto-encoder. Finally, the outputs from the hidden layers of the discriminative auto-encoders at different scales are concatenated to form the shape descriptor. The proposed method is evaluated on four benchmark datasets that contain 3D models with large geometric variations: McGill, SHREC' 10 ShapeGoogle, SHREC' 14 Human and SHREC' 14 Large Scale Comprehensive Retrieval Track Benchmark datasets. Experimental results on the benchmark datasets demonstrate the effectiveness of the proposed method for 3D shape retrieval.	[Xie, Jin; Dai, Guoxian; Zhu, Fan; Fang, Yi] New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi 129188, U Arab Emirates; [Wong, Edward K.] NYU, Tandon Sch Engn, Dept Comp Sci & Engn, New York, NY 10012 USA	New York University; New York University Tandon School of Engineering	Xie, J (corresponding author), New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi 129188, U Arab Emirates.	jin.xie@nyu.edu; guoxian.dai@nyu.edu; fan.zhu@nyu.edu; ewong@nyu.edu; yfang@nyu.edu	Dai, Guoxian/AHD-1334-2022		New York University Abu Dhabi [AD131, REF131]	New York University Abu Dhabi	The authors would like to thank the editor and the anonymous reviewers for their constructive comments on this paper. This work was supported by New York University Abu Dhabi under Grants AD131 and REF131.	Agathos A., 2009, P EUR WORKSH 3D OBJ, P29; [Anonymous], 3D OBJECT RETRIEVAL, DOI DOI 10.2312/3DOR/3DOR08/009-016; Assfalg J, 2007, IEEE T MULTIMEDIA, V9, P589, DOI 10.1109/TMM.2006.886271; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Boscaini D, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12693; Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405; Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Giachetti A, 2012, COMPUT GRAPH FORUM, V31, P1669, DOI 10.1111/j.1467-8659.2012.03172.x; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009; Krtgen M., 2003, 7 CENTR EUR SEM COMP; Lavoue G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x; Li B., 2014, P EUR WORKSH 3D OBJ, V2014, P131; Li CY, 2013, VISUAL COMPUT, V29, P513, DOI 10.1007/s00371-013-0815-3; Lian Z., 2015, P EUR WORKSH 3D OBJ, P107; Litman R, 2014, COMPUT GRAPH FORUM, V33, P127, DOI 10.1111/cgf.12438; Masci J., 2015, P IEEE INT C COMP VI, P37; Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005; Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386; Osada R., 2002, ACM T GRAPHIC, V33, p[133, 2145]; Pickup D., 2014, EUROGRAPHICS WORKSHO, P101; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392; Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Tabia H., 2013, P EUR WORKSH 3D OBJ, P17, DOI DOI 10.2312/3DOR/3DOR13/017-024; Tabia H, 2014, PROC CVPR IEEE, P4185, DOI 10.1109/CVPR.2014.533; Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Ye J, 2013, P 3 ACM C INT C MULT, P121; Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748; Zhou DY, 2004, ADV NEUR IN, V16, P169	34	82	89	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1335	1345		10.1109/TPAMI.2016.2596722	http://dx.doi.org/10.1109/TPAMI.2016.2596722			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27482929				2022-12-18	WOS:000402744400005
J	Peng, CL; Gao, XB; Wang, NN; Li, J				Peng, Chunlei; Gao, Xinbo; Wang, Nannan; Li, Jie			Graphical Representation for Heterogeneous Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heterogeneous face recognition; graphical representation; forensic sketch; infrared image; thermal image	SKETCH SYNTHESIS; SCALE; DATABASE	Heterogeneous face recognition (HFR) refers to matching face images acquired from different sources (i.e., different sensors or different wavelengths) for identification. HFR plays an important role in both biometrics research and industry. In spite of promising progresses achieved in recent years, HFR is still a challenging problem due to the difficulty to represent two heterogeneous images in a homogeneous manner. Existing HFR methods either represent an image ignoring the spatial information, or rely on a transformation procedure which complicates the recognition task. Considering these problems, we propose a novel graphical representation based HFR method (G-HFR) in this paper. Markov networks are employed to represent heterogeneous image patches separately, which takes the spatial compatibility between neighboring image patches into consideration. A coupled representation similarity metric (CRSM) is designed to measure the similarity between obtained graphical representations. Extensive experiments conducted on multiple HFR scenarios (viewed sketch, forensic sketch, near infrared image, and thermal infrared image) show that the proposed method outperforms state-of-the-art methods.	[Peng, Chunlei; Li, Jie] Xidian Univ, Video & Image Proc Syst Lab, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China; [Gao, Xinbo] Xidian Univ, State Key Lab Integrated Serv Networks, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China; [Wang, Nannan] Xidian Univ, State Key Lab Integrated Serv Networks, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China	Xidian University; Xidian University; Xidian University	Peng, CL (corresponding author), Xidian Univ, Video & Image Proc Syst Lab, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.	clp.xidian@gmail.com; xbgao@mail.xidian.edu.cn; nnwang@xidian.edu.cn; leejie@mail.xidian.edu.cn	Li, jie/GXG-4583-2022; Gao, Xinbo/Q-8622-2016	Gao, Xinbo/0000-0003-1443-0776	National Natural Science Foundation of China [61432014, 61501339, 61571343]; Fundamental Research Funds for the Central Universities [BDZ021403, XJS15049, JB160104, XJS15068, JB149901]; Microsoft Research Asia Project based Funding [FY13-RES-OPP-034]; Program for Changjiang Scholars and Innovative Research Team in University of China [IRT13088]; Shaanxi Innovative Research Team for Key Science and Technology [2012KCT-02]; China Post-Doctoral Science Foundation [2015M580818]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Microsoft Research Asia Project based Funding(Microsoft); Program for Changjiang Scholars and Innovative Research Team in University of China(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT)); Shaanxi Innovative Research Team for Key Science and Technology; China Post-Doctoral Science Foundation(China Postdoctoral Science Foundation)	This work was supported in part by the National Natural Science Foundation of China under Grant 61432014, Grant 61501339, and Grant 61571343, in part by the Fundamental Research Funds for the Central Universities under Grant BDZ021403, Grant XJS15049, Grant JB160104, Grant XJS15068 and Grant JB149901, in part by Microsoft Research Asia Project based Funding under Grant FY13-RES-OPP-034, in part by the Program for Changjiang Scholars and Innovative Research Team in University of China under Grant IRT13088, in part by the Shaanxi Innovative Research Team for Key Science and Technology under Grant 2012KCT-02, and in part by the China Post-Doctoral Science Foundation under Grant 2015M580818.	Alex AT, 2013, IEEE SYS MAN CYBERN, P1211, DOI 10.1109/SMC.2013.210; [Anonymous], TR2011006 INDR I INF; [Anonymous], 2015, IEEE C WORKSH AUT FA; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252; Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314; Galoogahi H. K., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P224, DOI 10.1109/ICME.2012.128; Galoogahi HK, 2012, IEEE IMAGE PROC, P1837, DOI 10.1109/ICIP.2012.6467240; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770; Gibson L., 2010, FORENSIC ART ESSENTI; Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58; Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229; Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180; Klum SJ, 2014, IEEE T INF FOREN SEC, V9, P2248, DOI 10.1109/TIFS.2014.2360825; Lei Z, 2012, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2012.6247967; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; Li J, 2008, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2008.4711792; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Liu QS, 2005, PROC CVPR IEEE, P1005; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez A., 1998, 24 CVC, P24; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Mignon A., 2012, P AS C COMP VIS, P1; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414; Taylor K.T., 2000, FORENSIC ART ILLUSTR; Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174; Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523; Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324; Zhen Lei, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P7, DOI 10.1109/ICB.2012.6199751; Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	47	82	85	2	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					301	312		10.1109/TPAMI.2016.2542816	http://dx.doi.org/10.1109/TPAMI.2016.2542816			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	26991700	Green Submitted			2022-12-18	WOS:000395553400007
J	Wang, XC; Turetken, E; Fleuret, F; Fua, P				Wang, Xinchao; Turetken, Engin; Fleuret, Francois; Fua, Pascal			Tracking Interacting Objects Using Intertwined Flows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-object tracking; interactions; network flows; mixed integer programming	MULTIOBJECT TRACKING; MULTITARGET TRACKING; PEOPLE; MODEL	In this paper, we show that tracking different kinds of interacting objects can be formulated as a network-flow mixed integer program. This is made possible by tracking all objects simultaneously using intertwined flow variables and expressing the fact that one object can appear or disappear at locations where another is in terms of linear flow constraints. Our proposed method is able to track invisible objects whose only evidence is the presence of other objects that contain them. Furthermore, our tracklet-based implementation yields real-time tracking performance. We demonstrate the power of our approach on scenes involving cars and pedestrians, bags being carried and dropped by people, and balls being passed from one player to the next in team sports. In particular, we show that by estimating jointly and globally the trajectories of different types of objects, the presence of the ones which were not initially detected based solely on image evidence can be inferred from the detections of the others.	[Wang, Xinchao; Fua, Pascal] Ecole Polytech Fed Lausanne, IC Fac, Comp Vis Lab, CH-1015 Lausanne, Switzerland; [Turetken, Engin] Swiss Ctr Elect & Microtechnol, CH-2002 Neuchatel, Switzerland; [Fleuret, Francois] Idiap Res Inst, Comp Vis & Learning Grp, CH-1920 Martigny, Switzerland; [Fleuret, Francois] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Wang, XC (corresponding author), Ecole Polytech Fed Lausanne, IC Fac, Comp Vis Lab, CH-1015 Lausanne, Switzerland.	xinchao.wang@epfl.ch; engin.tueretken@alumni.epfl.ch; francois.fleuret@idiap.ch; pascal.fua@epfl.ch	Wang, Xinchao/L-7655-2018	Wang, Xinchao/0000-0003-0057-1404; Fua, Pascal/0000-0002-6702-9970	Swiss National Science Foundation	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work was supported in part by the Swiss National Science Foundation. X. Wang and E. Turetken contributed equally to this paper.	Ahuja R. K., 1993, NETWORK FLOWS THEORY; Alahi A, 2014, PROC CVPR IEEE, P2211, DOI 10.1109/CVPR.2014.283; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriyenko A, 2010, LECT NOTES COMPUT SC, V6311, P466, DOI 10.1007/978-3-642-15549-9_34; [Anonymous], 2001, CONDITIONAL RANDOM F; Arora C, 2013, IEEE I CONF COMP VIS, P177, DOI 10.1109/ICCV.2013.29; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255; Baumgartner T, 2013, PROC CVPR IEEE, P3658, DOI 10.1109/CVPR.2013.469; Bellman RE, 1957, DYNAMIC PROGRAMMING; Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Chen S, 2014, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2014.148; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; Collins RT, 2014, LECT NOTES COMPUT SC, V8690, P298, DOI 10.1007/978-3-319-10605-2_20; D'Orazio T, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P559, DOI 10.1109/AVSS.2009.69; Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Fragkiadaki K, 2012, LECT NOTES COMPUT SC, V7576, P552, DOI 10.1007/978-3-642-33715-4_40; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532; Hong S, 2013, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2013.285; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57; Kwak S., 2015, UNSUPERVISED OBJECT; Kwon J, 2014, IEEE T PATTERN ANAL, V36, P625, DOI 10.1109/TPAMI.2013.170; Leal-Taixe L., 2015, ARXIV; Leal-Taixe L, 2014, PROC CVPR IEEE, P3542, DOI 10.1109/CVPR.2014.453; Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239; Liu JC, 2010, PROC CVPR IEEE, P1839, DOI 10.1109/CVPR.2010.5539855; Lucey P, 2013, PROC CVPR IEEE, P2706, DOI 10.1109/CVPR.2013.349; Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; Nillius P., 2006, P 2006 IEEE COMP SOC, V2, P2187; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Perera A. A., 2006, 2006 IEEE COMPUTER S, V1, P666; Possegger H, 2014, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2014.170; Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899; Rujikietgumjorn S, 2013, PROC CVPR IEEE, P3690, DOI 10.1109/CVPR.2013.473; Segal AV, 2013, IEEE I CONF COMP VIS, P2904, DOI 10.1109/ICCV.2013.361; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Sullivan J, 2006, LECT NOTES COMPUT SC, V3953, P619, DOI 10.1007/11744078_48; Tang SY, 2015, PROC CVPR IEEE, P5033, DOI 10.1109/CVPR.2015.7299138; Tang SY, 2013, IEEE I CONF COMP VIS, P1049, DOI 10.1109/ICCV.2013.134; Wang XC, 2014, LECT NOTES COMPUT SC, V8689, P17, DOI 10.1007/978-3-319-10590-1_2; Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835; Wojek C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1993, DOI 10.1109/CVPR.2011.5995547; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892; Yedidia J. S., 2000, NIPS, P689; Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742	70	82	86	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2312	2326		10.1109/TPAMI.2015.2513406	http://dx.doi.org/10.1109/TPAMI.2015.2513406			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26731639	Green Submitted			2022-12-18	WOS:000385945000013
J	Yan, Y; Ricci, E; Subramanian, R; Liu, GW; Lanz, O; Sebe, N				Yan, Yan; Ricci, Elisa; Subramanian, Ramanathan; Liu, Gaowen; Lanz, Oswald; Sebe, Nicu			A Multi-Task Learning Framework for Head Pose Estimation under Target Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-task learning; graph guided; head pose classification; video surveillance; multi-camera systems		Recently, head pose estimation (HPE) from low-resolution surveillance data has gained in importance. However, monocular and multi-view HPE approaches still work poorly under target motion, as facial appearance distorts owing to camera perspective and scale changes when a person moves around. To this end, we propose FEGA-MTL, a novel framework based on Multi-Task Learning (MTL) for classifying the head pose of a person who moves freely in an environment monitored by multiple, large field-of-view surveillance cameras. Upon partitioning the monitored scene into a dense uniform spatial grid, FEGA-MTL simultaneously clusters grid partitions into regions with similar facial appearance, while learning region-specific head pose classifiers. In the learning phase, guided by two graphs which a-priori model the similarity among (1) grid partitions based on camera geometry and (2) head pose classes, FEGA-MTL derives the optimal scene partitioning and associated pose classifiers. Upon determining the target's position using a person tracker at test time, the corresponding region-specific classifier is invoked for HPE. The FEGA-MTL framework naturally extends to a weakly supervised setting where the target's walking direction is employed as a proxy in lieu of head orientation. Experiments confirm that FEGA-MTL significantly outperforms competing single-task and multi-task learning methods in multi-view settings.	[Yan, Yan; Liu, Gaowen; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy; [Ricci, Elisa; Lanz, Oswald] Fdn Bruno Kessler, Technol Vis, I-06100 Trento, Italy; [Ricci, Elisa] Univ Perugia, Dept Engn, I-06100 Perugia, Italy; [Subramanian, Ramanathan] ADSC, Singapore, Singapore	University of Trento; Fondazione Bruno Kessler; University of Perugia	Yan, Y; Liu, GW; Sebe, N (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.; Ricci, E; Lanz, O (corresponding author), Fdn Bruno Kessler, Technol Vis, I-06100 Trento, Italy.; Ricci, E (corresponding author), Univ Perugia, Dept Engn, I-06100 Perugia, Italy.; Subramanian, R (corresponding author), ADSC, Singapore, Singapore.	yan@disi.unitn.it; eliricci@fbk.eu; Subramanian.R@adsc.com.sg; gaowen.liu@unitn.it; lanz@fbk.eu; sebe@disi.unitn.it	Lanz, Oswald/AAW-7865-2021	Sebe, Niculae/0000-0002-6597-7248; Subramanian, Ramanathan/0000-0001-9441-7074; Lanz, Oswald/0000-0003-4793-4276; Ricci, Elisa/0000-0002-0228-1147	MIUR Cluster project Active Ageing at Home; EC project ACANTO; EIT ICT Labs SSP 12205 Activity TIK-The Interaction Toolkit tasks [T1320A-T1321A]; A*STAR Singapore under the Human-Centered Cyber-physical Systems (HCCS) grant	MIUR Cluster project Active Ageing at Home; EC project ACANTO; EIT ICT Labs SSP 12205 Activity TIK-The Interaction Toolkit tasks; A*STAR Singapore under the Human-Centered Cyber-physical Systems (HCCS) grant	This work was partially supported by the MIUR Cluster project Active Ageing at Home, the EC project ACANTO, EIT ICT Labs SSP 12205 Activity TIK-The Interaction Toolkit tasks T1320A-T1321A and A*STAR Singapore under the Human-Centered Cyber-physical Systems (HCCS) grant.	[Anonymous], 1998, MULTITASK LEARNING; [Anonymous], 2012, P INT C MACH LEARN; [Anonymous], 2011, P ADV NEUR INF PROC; Argyriou A., 2007, NIPS, V19, P41, DOI DOI 10.1007/S10994-007-5040-8; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Benfold B, 2011, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2011.6126516; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Breitenstein M. D., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.458; Chamveha I, 2013, COMPUT VIS IMAGE UND, V117, P1502, DOI 10.1016/j.cviu.2013.06.005; Chen C, 2012, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2012.6247845; Chen X, 2012, ANN APPL STAT, V6, P719, DOI 10.1214/11-AOAS514; Dalal N., 2005, HISTOGRAMS ORIENTED; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Gong Pinghua, 2012, KDD, V2012, P895; Jalali A., 2010, ADV NEURAL INF PROCE, V23, P964; Kang Z., 2011, P INT C MACH LEARN, V2, P4; Lanz O, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P317, DOI 10.1109/ICIAP.2007.4362798; Lanz O, 2006, IEEE T PATTERN ANAL, V28, P1436, DOI 10.1109/TPAMI.2006.177; Munoz-Salinas R, 2012, MACH VISION APPL, V23, P479, DOI 10.1007/s00138-012-0410-z; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Orozco J., 2009, BRIT MACH VIS C, P1; Rajagopal AK, 2014, INT J COMPUT VISION, V109, P146, DOI 10.1007/s11263-013-0692-2; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; SUBRAMANIAN R, 2013, ICM P 2013 ACM INT, P3, DOI DOI 10.1145/2522848.2522862; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Voit M, 2009, LECT NOTES COMPUT SC, V5815, P415, DOI 10.1007/978-3-642-04667-4_42; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540; Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699; Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zabulis X., 2009, P BRIT MACH VIS ASS, P1; Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z; Zhou J., 2011, MALSAR MULTITASK LEA; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702	36	82	87	2	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1070	1083		10.1109/TPAMI.2015.2477843	http://dx.doi.org/10.1109/TPAMI.2015.2477843			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26372209	Green Submitted			2022-12-18	WOS:000375609000003
J	Fu, SY; He, HB; Hou, ZG				Fu, Siyao; He, Haibo; Hou, Zeng-Guang			Learning Race from Face: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Race classification; face recognition; image categorization; data clustering; face database; machine learning; computer vision	DEVELOPMENTAL INTERGROUP THEORY; FACIAL EXPRESSIONS; PERCEPTUAL DISCRIMINATION; RECOGNITION ALGORITHMS; PERSON CATEGORIZATION; AMYGDALA ACTIVITY; SOCIAL COGNITION; ERP EVIDENCE; SKIN TONE; 3D	Faces convey a wealth of social signals, including race, expression, identity, age and gender, all of which have attracted increasing attention from multi-disciplinary research, such as psychology, neuroscience, computer science, to name a few. Gleaned from recent advances in computer vision, computer graphics, and machine learning, computational intelligence based racial face analysis has been particularly popular due to its significant potential and broader impacts in extensive real-world applications, such as security and defense, surveillance, human computer interface (HCI), biometric-based identification, among others. These studies raise an important question: How implicit, non-declarative racial category can be conceptually modeled and quantitatively inferred from the face? Nevertheless, race classification is challenging due to its ambiguity and complexity depending on context and criteria. To address this challenge, recently, significant efforts have been reported toward race detection and categorization in the community. This survey provides a comprehensive and critical review of the state-of-the-art advances in face-race perception, principles, algorithms, and applications. We first discuss race perception problem formulation and motivation, while highlighting the conceptual potentials of racial face processing. Next, taxonomy of feature representational models, algorithms, performance and racial databases are presented with systematic discussions within the unified learning scenario. Finally, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potentially important cross-cutting themes and research directions for the issue of learning race from face.	[Fu, Siyao; He, Haibo] Univ Rhode Isl, Dept Elect Comp & Biomed Engn, Kingston, RI 02881 USA; [Hou, Zeng-Guang] Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China	University of Rhode Island; Chinese Academy of Sciences	Fu, SY (corresponding author), Univ Rhode Isl, Dept Elect Comp & Biomed Engn, Kingston, RI 02881 USA.	fu@ele.uri.edu; he@ele.uri.edu; hou@compsys.ia.ac.cn	He, Haibo/ABF-3668-2020	He, Haibo/0000-0002-5247-9370	US National Science Foundation (NSF) [CAREER ECCS 1053717]; Army Research Office (ARO) [W911NF-12-1-0378]; NSF-DFG Collaborative Research on "Autonomous Learning" [CNS 1117314]; National Natural Science Foundation of China (NSFC) [61225017, 61175076]; Minzu University of China; Direct For Computer & Info Scie & Enginr [1117314] Funding Source: National Science Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Army Research Office (ARO); NSF-DFG Collaborative Research on "Autonomous Learning"; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Minzu University of China; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported by the US National Science Foundation (NSF) under grant CAREER ECCS 1053717, Army Research Office (ARO) under grant W911NF-12-1-0378, NSF-DFG Collaborative Research on "Autonomous Learning" (a supplement grant to CNS 1117314), and National Natural Science Foundation of China (NSFC) under grants 61225017 and 61175076. S. Fu would also like to thank G. Yang and Minzu University of China for the support in the development of this work.	Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018; Ahmad A., 2013, INT J COMPUT TECHNOL, V4, P234; Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6; Akbari R., 2012, INT J SIGNLA PROCESS, V5, P85; Allison M., 2013, P 26 INT FLOR ART IN, P332; Anacleto J. C., 2010, ARXIV 1001 0418; Anitha CM., 2010, INT J ENG SCI TECHNO, V2, P5158; [Anonymous], 2000, NAT GENET, V24, P97; Anzures G, 2011, INFANCY, V16, P640, DOI 10.1111/j.1532-7078.2010.00066.x; Ball R., 2008, P 9 INT C PHYSIOLOGI, P150; Ball R, 2010, APPL ERGON, V41, P832, DOI 10.1016/j.apergo.2010.02.002; Barbujani G, 2005, CURR GENOMICS, V6, P215, DOI 10.2174/1389202054395973; Bastanfard A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P50; Bellustin N., 2011, INT J ADV COMPUT SCI, V3, P112, DOI [10.14569/SpecialIssue.2011.010318, DOI 10.14569/SPECIALISSUE.2011.010318]; Ben Azouz Z, 2006, VISUAL COMPUT, V22, P302, DOI 10.1007/s00371-006-0006-6; Bentin S, 2000, COGN NEUROPSYCHOL, V17, P35, DOI 10.1080/026432900380472; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Berretti S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168759; Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43; Bickel B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276419, 10.1145/1239451.1239484]; Biehl M, 1997, J NONVERBAL BEHAV, V21, P3, DOI 10.1023/A:1024902500935; Bigler RS, 2007, CURR DIR PSYCHOL SCI, V16, P162, DOI 10.1111/j.1467-8721.2007.00496.x; Bigler RS, 2006, ADV CHILD DEV BEHAV, V34, P39, DOI 10.1016/S0065-2407(06)80004-2; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; BOWCOCK AM, 1994, NATURE, V368, P455, DOI 10.1038/368455a0; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bradtmiller B, HEAD FACE ANTHROPOME; Brebnera J. L., 2011, THESIS; Brewer M. B., 1998, INTERGROUP RELATIONS; Brooks KR, 2010, PERCEPTION, V39, P1142, DOI 10.1068/p6703; BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x; Bruyer R, 2004, PERCEPTION, V33, P169, DOI 10.1068/p5094; BRYM RJ, 2006, SOCIOLOGY YOUR COMPA; Bulthoff I., 2012, J VIS, V12, P1282; Calder A., 2011, OXFORD HDB FACE PERC; Calder AJ, 2005, NAT REV NEUROSCI, V6, P641, DOI 10.1038/nrn1724; Catz O, 2009, ACTA PSYCHOL, V131, P143, DOI 10.1016/j.actpsy.2009.03.010; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chen JM, 2012, J EXP SOC PSYCHOL, V48, P152, DOI 10.1016/j.jesp.2011.10.005; Coon C.S., 1962, THE ORIGINS OF RACES; Corneille O, 2007, J PERS SOC PSYCHOL, V93, P335, DOI 10.1037/0022-3514.93.3.335; Cosmides L, 2003, TRENDS COGN SCI, V7, P173, DOI 10.1016/S1364-6613(03)00057-3; Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008; Cunningham WA, 2004, PSYCHOL SCI, V15, P806, DOI 10.1111/j.0956-7976.2004.00760.x; Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019; Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177; Davidenko N, 2007, J VISION, V7, DOI 10.1167/7.4.6; De Marsico M, 2013, LECT NOTES COMPUT SC, V8156, P472; De Zhang, 2012, Biometric Recognition. 7th Chinese Conference, CCBR 2012. Proceedings, P300, DOI 10.1007/978-3-642-35136-5_36; Dehon H, 2001, PERCEPTION, V30, P1107, DOI 10.1068/p3122; Demirkus M., 2010, P SPIE BIOM TECHN HU; Ding H., 2013, 2013 10 IEEE INT C W, P1, DOI [10.1109/FG.2013.6553815, DOI 10.1109/FG.2013.6553815]; Dolan RJ, 2002, SCIENCE, V298, P1191, DOI 10.1126/science.1076358; DONG H, 2001, ASIAN FACE IMAGE DAT; Duan XD, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P125, DOI 10.1109/ICACC.2010.5487194; Earnest Les, 1989, COMMUN ACM, V32.2, P173; Eberhardt JL, 2005, AM PSYCHOL, V60, P181, DOI 10.1037/0003-066X.60.2.181; Eberhardt JL, 2003, PERS SOC PSYCHOL B, V29, P360, DOI 10.1177/0146167202250215; EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86; Encyclopedia Britannica and Race,, 2012, ENCY BRIT ULT REF SU; Enlow D. H., 1990, FACIAL GROWTH; Evers V., 1997, THESIS; Fang F, 2011, PLAST RECONSTR SURG, V127, P874, DOI 10.1097/PRS.0b013e318200afdb; Farinella G, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P383, DOI 10.1109/ICIEV.2012.6317383; Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Freeman JB, 2010, NEUROREPORT, V21, P24, DOI 10.1097/WNR.0b013e3283320d54; Fu SY, 2012, COMPUT INTEL NEUROSC, V2012, DOI 10.1155/2012/946589; Fu SY, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1637, DOI 10.1109/IJCNN.2011.6033421; Fu Y, 2010, INTELLIGENT VIDEO SURVEILLANCE: SYSTEMS AND TECHNOLOGY, P407; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Furl N, 2002, COGNITIVE SCI, V26, P797, DOI 10.1016/S0364-0213(02)00084-8; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Gauthier I, 2000, J COGNITIVE NEUROSCI, V12, P495, DOI 10.1162/089892900562165; Godil A., 2004, P SPIE S BIOM TECHN, P351; Golby AJ, 2001, NAT NEUROSCI, V4, P845, DOI 10.1038/90565; Goldinger SD, 2009, J EXP PSYCHOL LEARN, V35, P1105, DOI 10.1037/a0016548; Grother P. J., 2010, NIST INTERAGENCY INT; GUO G, 2010, IEEE COMP SOC C COMP, P79; Guo GD, 2012, STUD COMPUT INTELL, V409, P101; Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]; Gupta S, 2010, INT J COMPUT VISION, V90, P331, DOI 10.1007/s11263-010-0360-8; Gutta S., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P4084, DOI 10.1109/IJCNN.1999.830815; Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948; Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774; Hadid A, 2013, NEUROCOMPUTING, V100, P197, DOI 10.1016/j.neucom.2011.10.040; Hamilton D. L., 1994, SOCIAL COGNITION IMP, P291; Haque A., 2005, P 27 ANN C COGN SCI, P899; Hart AJ, 2000, NEUROREPORT, V11, P2351, DOI 10.1097/00001756-200008030-00004; Haslanger S, 2000, NOUS, V34, P31, DOI 10.1111/0029-4624.00201; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275; HILL H, 1995, P ROY SOC B-BIOL SCI, V261, P367, DOI 10.1098/rspb.1995.0161; Hirsh AT, 2008, PAIN, V140, P231, DOI 10.1016/j.pain.2008.09.010; Ho AK, 2011, J PERS SOC PSYCHOL, V100, P492, DOI 10.1037/a0021562; Hollingsworth K, 2011, IMAGE VISION COMPUT, V29, P707, DOI 10.1016/j.imavis.2011.09.002; Hosoi S, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P195, DOI 10.1109/AFGR.2004.1301530; Huang D., 2011, P CVPR WORKSH COL SP, P1; Hugenberg K, 2010, PSYCHOL REV, V117, P1168, DOI 10.1037/a0020463; Hugenberg K, 2008, SOC PERSONAL PSYCHOL, V2, P1052, DOI 10.1111/j.1751-9004.2008.00090.x; Hwang BW, 2003, LECT NOTES COMPUT SC, V2688, P557; Ito TA, 2004, PERS SOC PSYCHOL B, V30, P1267, DOI 10.1177/0146167204264335; Ito TA, 2009, TRENDS COGN SCI, V13, P524, DOI 10.1016/j.tics.2009.10.002; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109; Jack RE, 2009, CURR BIOL, V19, P1543, DOI 10.1016/j.cub.2009.07.051; Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890; Johnson KJ, 2005, PSYCHOL SCI, V16, P875, DOI 10.1111/j.1467-9280.2005.01631.x; Jones CR, 2010, PERS SOC PSYCHOL B, V36, P1073, DOI 10.1177/0146167210375817; KASSIN SM, 1989, AM PSYCHOL, V44, P1089, DOI 10.1037/0003-066X.44.8.1089; Kaul C, 2014, SOC COGN AFFECT NEUR, V9, P326, DOI 10.1093/scan/nss138; Klare B., 2010, BIOMETRICS THEORY AP, P1, DOI [DOI 10.1109/BTAS.2010.5634533, 10.1109/btas.2010.5634533]; Klare BF, 2012, IEEE T INF FOREN SEC, V7, P1789, DOI 10.1109/TIFS.2012.2214212; Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272; Kubota JT, 2012, NAT NEUROSCI, V15, P940, DOI 10.1038/nn.3136; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kurzban R, 2001, P NATL ACAD SCI USA, V98, P15387, DOI 10.1073/pnas.251541498; Lagree S., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P440, DOI 10.1109/THS.2011.6107909; Lagree S., 2011, P 22 MIDW ART INT CO, P225; LeCun Y., 1995, HDB BRAIN THEORY NEU; Lei YH, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P701, DOI 10.1145/2348283.2348377; Levin DT, 1996, J EXP PSYCHOL LEARN, V22, P1364, DOI 10.1037/0278-7393.22.6.1364; Levin DT, 2002, PERCEPTION, V31, P567, DOI 10.1068/p3315; Levin DT, 2000, J EXP PSYCHOL GEN, V129, P559, DOI 10.1037//0096-3445.129.4.559; Li J., 2012, U.S. Patent, Patent No. [8 331 698 B2, 8331698]; Li S. Z., 2004, HDB FACE RECOGNITION; Li X, 2013, INVEST OPHTH VIS SCI, V54, P3650, DOI 10.1167/iovs.12-11126; Li Yanjun, 2008, PLoS One, V3, pe2166, DOI 10.1371/journal.pone.0002166; Lieberman MD, 2005, NAT NEUROSCI, V8, P720, DOI 10.1038/nn1465; Lin H., 2006, 6 WORLD C INT CONTR, V2, P9988; Lindsay R., 1983, EVALUATING WITNESS E; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Love R, 2001, LANCET, V358, P476, DOI 10.1016/S0140-6736(01)05671-9; Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; Luximon Y, 2010, TOOLS AND METHODS OF COMPETITIVE ENGINEERING, VOLS 1-2, P255; Lyle J. R., 2010, BIOM THEOR APPL SYST, P1; Mackal M. C., 2009, THESIS; Macrae CN, 2000, ANNU REV PSYCHOL, V51, P93, DOI 10.1146/annurev.psych.51.1.93; Maddox KB, 2004, PERS SOC PSYCHOL REV, V8, P383, DOI 10.1207/s15327957pspr0804_4; Malskies C. R., 2011, P VIS MOD VIS, P353; Manesh FS, 2010, I C CONT AUTOMAT ROB, P1644, DOI 10.1109/ICARCV.2010.5707882; Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3; Moon H., 2013, US Patent, Patent No. [8,379,937, 8379937]; Muhammad G., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P421; Muhammad G, 2012, INT J ARTIF INTELL T, V21, DOI 10.1142/S0218213012500194; Natu V, 2011, NEUROIMAGE, V54, P2547, DOI 10.1016/j.neuroimage.2010.10.006; Ng C.B., 2012, P PAC RIM INT C ART, P335; O'Toole A. J., 1991, Connection Science, V3, P163, DOI 10.1080/09540099108946583; O'Toole A. J., 2013, VIS COGN, V21, P1; O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3; O'Toole AJ, 1991, 13TH P ANN C COGN SC, P847; Ocegueda O, 2013, IEEE T PATTERN ANAL, V35, P728, DOI 10.1109/TPAMI.2012.126; Ofan RH, 2011, J COGNITIVE NEUROSCI, V23, P3153, DOI 10.1162/jocn_a_00014; OTOOLE AJ, 1993, J OPT SOC AM A, V10, P405, DOI 10.1364/JOSAA.10.000405; OTOOLE AJ, 1994, MEM COGNITION, V22, P208, DOI 10.3758/BF03208892; Ou Y., 2005, INT JOINT C NEUR NET, P1; Palmeri TJ, 2004, NAT REV NEUROSCI, V5, P291, DOI 10.1038/nrn1364; Papesh MH, 2010, COGNITION, V116, P283, DOI 10.1016/j.cognition.2010.05.001; Pessoa L, 2010, NAT REV NEUROSCI, V11, P773, DOI 10.1038/nrn2920; Phelps EA, 2003, NEUROPSYCHOLOGIA, V41, P203, DOI 10.1016/S0028-3932(02)00150-1; Phelps EA, 2000, J COGNITIVE NEUROSCI, V12, P729, DOI 10.1162/089892900562552; Phillips PJ, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870082; Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 1996, 995 ARM RES LAB; PLATZ SJ, 1988, J APPL SOC PSYCHOL, V18, P972, DOI 10.1111/j.1559-1816.1988.tb01187.x; Poggio T., 2013, SCHOLARPEDIA, V8, P3516, DOI DOI 10.4249/SCHOLARPEDIA.3516; Pratt JA, 2007, INTERACT COMPUT, V19, P512, DOI 10.1016/j.intcom.2007.02.003; Qiu X., 2007, P ICIP, V2, P405; Ramanathan N., 2009, J VISUAL LANG COMPUT, V15, P3349; Rehder B, 2005, COGNITIVE PSYCHOL, V51, P1, DOI 10.1016/j.cogpsych.2004.11.001; RHODES G, 1988, PERCEPTION, V17, P43, DOI 10.1068/p170043; Riccio D., 2012, 2012 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS 2012), DOI 10.1109/BIOMS.2012.6345776; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Risch N, 2002, GENOME BIOL, V3, DOI [10.1186/GB-2002-3-7-COMMENT2007, DOI 10.1186/GB-2002-3-7-C0MMENT2007, 10.1186/gb-2002-3-7-comment2007]; Robinette K. M., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P380, DOI 10.1109/IM.1999.805368; Roesch EB, 2011, J NONVERBAL BEHAV, V35, P1, DOI 10.1007/s10919-010-0095-9; Roh MC, 2007, INT J PATTERN RECOGN, V21, P1017, DOI 10.1142/S0218001407005818; Ronquillo J, 2007, SOC COGN AFFECT NEUR, V2, P39, DOI 10.1093/scan/nsl043; Roomi S. M. M., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P54, DOI 10.1109/NCVPRIPG.2011.19; Rossion B., 2002, INT J NEUROSCI, V112, P1499; Salah AA, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2896291; Salah S.H., 2013, P  IEEE INT C SING I, V21, P416; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; Samangooei S, 2010, MULTIMED TOOLS APPL, V49, P195, DOI 10.1007/s11042-009-0391-8; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Schiller D, 2009, NAT NEUROSCI, V12, P508, DOI 10.1038/nn.2278; Senior A, 2005, IEEE SECUR PRIV, V3, P50, DOI 10.1109/MSP.2005.65; Serre T., 2006, THESIS; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Solomon CJ, 2013, APPL SOFT COMPUT, V13, P3298, DOI 10.1016/j.asoc.2013.02.010; Stanley DA, 2011, P NATL ACAD SCI USA, V108, P7710, DOI 10.1073/pnas.1014345108; Stark  L., 2010, P 4 IEEE INT C BIOM, P1; Stephens JC, 2001, SCIENCE, V293, P489, DOI 10.1126/science.1059431; Strom MA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041193; Sukumar SR, 2008, IEEE IMAGE PROC, P1912, DOI 10.1109/ICIP.2008.4712154; Tariq U., 2011, GENDER RACE IDENTIFI; Tariq U, 2009, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2009.5414117; Tin H. H. K., 2011, ACEE INT J INFORM TE, V01; Toderici G, 2010, INT J COMPUT VISION, V89, P382, DOI 10.1007/s11263-009-0300-7; Trawalter S, 2008, J EXP SOC PSYCHOL, V44, P1322, DOI 10.1016/j.jesp.2008.03.006; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Wagner-Schuman M, 2011, INVEST OPHTH VIS SCI, V52, P625, DOI 10.1167/iovs.10-5886; Wallis J, 2012, ATTEN PERCEPT PSYCHO, V74, P1712, DOI 10.3758/s13414-012-0359-z; Walter Christian, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117490; Wang JW, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P17, DOI 10.1109/UIC-ATC.2013.19; Wiese H, 2012, BIOL PSYCHOL, V89, P137, DOI 10.1016/j.biopsycho.2011.10.002; Wilbraham DA, 2008, J VISION, V8, DOI 10.1167/8.15.5; Wong JY, 2008, CLEFT PALATE-CRAN J, V45, P232, DOI 10.1597/06-175; Wu B, 2004, INT C PATT RECOG, P914, DOI 10.1109/ICPR.2004.1334677; Xianchao Qiu, 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P411; Yin L., 2008, AUTOMATIC FACE GESTU, V08, P1, DOI DOI 10.1109/AFGR.2008.4813324; Yin LJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P362; Yiting Xie, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P143, DOI 10.1109/BTAS.2012.6374569; Young SG, 2012, PERS SOC PSYCHOL REV, V16, P116, DOI 10.1177/1088868311418987; Zarei A, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P514, DOI 10.1109/ICMLA.2012.94; Zawbaa H., 2012, ARXIV12052345; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang D., 2010, P 2010 IEEE COMPUTER, P108; Zhang D, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P62; Zhang H, 2011, LECT NOTES COMPUT SC, V7098, P82, DOI 10.1007/978-3-642-25449-9_11; Zhang Q., 2013, TELKOMNIKA INDONESIA, V11, P5076; Zhong C, 2009, LECT NOTES COMPUT SC, V5558, P386, DOI 10.1007/978-3-642-01793-3_40; Zhuang ZQ, 2005, J OCCUP ENVIRON HYG, V2, P567, DOI 10.1080/15459620500324727; [No title captured]	232	82	91	1	70	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2483	2509		10.1109/TPAMI.2014.2321570	http://dx.doi.org/10.1109/TPAMI.2014.2321570			27	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AT5MW	26353153	Green Submitted			2022-12-18	WOS:000344988000012
J	Gordo, A; Perronnin, F; Gong, YC; Lazebnik, S				Gordo, Albert; Perronnin, Florent; Gong, Yunchao; Lazebnik, Svetlana			Asymmetric Distances for Binary Embeddings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large-scale retrieval; binary codes; asymmetric distances	SCENE	In large-scale query-by-example retrieval, embedding image signatures in a binary space offers two benefits: data compression and search efficiency. While most embedding algorithms binarize both query and database signatures, it has been noted that this is not strictly a requirement. Indeed, asymmetric schemes that binarize the database signatures but not the query still enjoy the same two benefits but may provide superior accuracy. In this work, we propose two general asymmetric distances that are applicable to a wide variety of embedding techniques including locality sensitive hashing (LSH), locality sensitive binary codes (LSBC), spectral hashing (SH), PCA embedding (PCAE), PCAE with random rotations (PCAE-RR), and PCAE with iterative quantization (PCAE-ITQ). We experiment on four public benchmarks containing up to 1M images and show that the proposed asymmetric distances consistently lead to large improvements over the symmetric Hamming distance for all binary embedding techniques.	[Gordo, Albert] INRIA Grenoble Rhone Alpes, LEAR Grp, F-38330 Montbonnot St Martin, Rhone Alpes, France; [Perronnin, Florent] Xerox Res Ctr Europe, F-38240 Meylan, Rhone Alpes, France; [Gong, Yunchao] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA; [Lazebnik, Svetlana] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Xerox; University of North Carolina; University of North Carolina Chapel Hill; University of Illinois System; University of Illinois Urbana-Champaign	Gordo, A (corresponding author), INRIA Grenoble Rhone Alpes, LEAR Grp, 655 Ave Europe, F-38330 Montbonnot St Martin, Rhone Alpes, France.	albert.gordo@inria.fr; florent.perronnin@xrce.xerox.com; yunchao@cs.unc.edu; lazebnik@cs.unc.edu			Spanish project [TIN2009-14633-C03-03]; Spanish project CONSOLIDER-INGENIO [CSD2007-00018]; US National Science Foundation CAREER Award [IIS 1228082]; Microsoft Research Faculty Fellowship; Xerox; DARPA Computer Science Study Group	Spanish project(Spanish Government); Spanish project CONSOLIDER-INGENIO; US National Science Foundation CAREER Award(National Science Foundation (NSF)); Microsoft Research Faculty Fellowship(Microsoft); Xerox; DARPA Computer Science Study Group	A. Gordo was partially supported by the Spanish projects TIN2009-14633-C03-03 and CONSOLIDER-INGENIO 2010 (CSD2007-00018). He was with the Xerox Research Centre Europe when this paper was written and submitted. Y. Gong and S. Lazebnik were partially supported by US National Science Foundation CAREER Award IIS 1228082, Microsoft Research Faculty Fellowship, Xerox, and the DARPA Computer Science Study Group. A preliminary version of this paper [1] appeared in CVPR 2011.	[Anonymous], P INT C MACH LEARN; [Anonymous], 2010, P IEEE C COMP VIS PA; Bergamo A., 2011, NIPS, V24, P2088; Brandt J, 2010, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2010.5539852; Charikar M.S., 2002, P 34 ANN ACM S THEOR, V34, P380, DOI DOI 10.1145/509907.509965; Csurka G, 2004, P WORKSH STAT LEARN; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong W., 2008, P 31 ANN INT ACM SIG; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gong Y., 2012, P ADV NEUR INF PROC, P1205; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gordo A, 2011, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2011.5995505; Griffin G., 2007, CALTECH 256 OBJECT C; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M., 2012, ADV NEURAL INFORM PR, V25; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rahimi A., 2007, P C ADV NEUR INF PRO; SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Wang J., 2011, P INT C MACH LEARN; Weiss Y., 2008, P ADV NEUR INF PROC; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25	41	82	83	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					33	47		10.1109/TPAMI.2013.101	http://dx.doi.org/10.1109/TPAMI.2013.101			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231864				2022-12-18	WOS:000327965100004
J	Martinez, B; Valstar, MF; Binefa, X; Pantic, M				Martinez, Brais; Valstar, Michel F.; Binefa, Xavier; Pantic, Maja			Local Evidence Aggregation for Regression-Based Facial Point Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial point detection; object detection; probabilistic graphical networks; support vector regression	CLASSIFICATION; DATABASE	We propose a new algorithm to detect facial points in frontal and near-frontal face images. It combines a regression-based approach with a probabilistic graphical model-based face shape model that restricts the search to anthropomorphically consistent regions. While most regression-based approaches perform a sequential approximation of the target location, our algorithm detects the target location by aggregating the estimates obtained from stochastically selected local appearance information into a single robust prediction. The underlying assumption is that by aggregating the different estimates, their errors will cancel out as long as the regressor inputs are uncorrelated. Once this new perspective is adopted, the problem is reformulated as how to optimally select the test locations over which the regressors are evaluated. We propose to extend the regression-based model to provide a quality measure of each prediction, and use the shape model to restrict and correct the sampling region. Our approach combines the low computational cost typical of regression-based approaches with the robustness of exhaustive-search approaches. The proposed algorithm was tested on over 7,500 images from five databases. Results showed significant improvement over the current state of the art.	[Martinez, Brais] Univ London Imperial Coll Sci Technol & Med, Intelligent Behav Understanding Grp, Dept Comp, London SW7 2AZ, England; [Valstar, Michel F.] Univ Nottingham, Mixed Real Lab, Sch Comp Sci, Nottingham NG8 1BB, England; [Binefa, Xavier] Univ Pompeu Fabra, Dept Informat Technol & Telecommun, Barcelona 08018, Spain; [Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Pantic, Maja] Univ Twente, Fac Elect Engn Math & Comp Sci, Enschede, Netherlands; [Pantic, Maja] Univ Twente, Dept Comp Sci, Enschede, Netherlands	Imperial College London; University of Nottingham; Pompeu Fabra University; Imperial College London; University of Twente; University of Twente	Martinez, B (corresponding author), Univ London Imperial Coll Sci Technol & Med, Intelligent Behav Understanding Grp, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	b.martinez@imperial.ac.uk; michel.valstar@nottingham.ac.uk; xavier.binefa@upf.edu; m.pantic@imperial.ac.uk	Binefa, Xavier/D-7993-2014	Binefa, Xavier/0000-0002-4324-9952; Valstar, Michel/0000-0003-2414-161X	European Community [231287]; EPSRC [EP/H016988/1]; European Research Council under the ERC Starting Grant [ERC-2007-StG-203143]; Horizon Digital Economy Research, RCUK [EP/G065802/1]; EPSRC [EP/J017787/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/J017787/1, EP/H016988/1] Funding Source: researchfish	European Community(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); European Research Council under the ERC Starting Grant; Horizon Digital Economy Research, RCUK(UK Research & Innovation (UKRI)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work has been supported by the European Community's Seventh Framework Programme [FP7/20072013] under grant agreement no. 231287 (SSPNet). The work of Brais Martinez is also supported in part by EPSRC grant EP/H016988/1: Pain rehabilitation: E/Motion-based automated coaching. The work by Maja Pantic is funded in part by the European Research Council under the ERC Starting Grant agreement no. ERC-2007-StG-203143 (MAHNOB). The work of Michel Valstar is supported by Horizon Digital Economy Research, RCUK grant EP/G065802/1.	Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Belhumeur P. N., 2011, P IEEE C COMP VIS PA; Bishop C.M, 2006, PATTERN RECOGN; COOTES TF, 1998, LNCS, V1407, P484, DOI DOI 10.1007/BFB0054760; Cosar S, 2011, IMAGE VISION COMPUT, V29, P335, DOI 10.1016/j.imavis.2010.12.001; Cristinacce D., 2007, P BMVC, P880; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dibeklioglu H, 2012, IEEE T IMAGE PROCESS, V21, P844, DOI 10.1109/TIP.2011.2163162; Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Drucker H., 1997, P INT C MACHINE LEAR, P107; Efraty B., 2011, P INT JOINT C BIOM; Ekman P., 2002, FACS MANUAL; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hall MA., 1999, CORRELATION BASED FE; Hu Y, 2008, PROC CVPR IEEE, P85; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Kozakaya T, 2010, IMAGE VISION COMPUT, V28, P772, DOI 10.1016/j.imavis.2009.09.008; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Liang L., 2006, CVPR, V1, P1313; Liwicki S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P507, DOI 10.1109/FG.2011.5771449; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Messer K., 1999, P C AUD VID BAS BIOM; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ojansivu V., 2008, ROTATION INVARIANT L, P1, DOI DOI 10.1109/ICPR.2008.4761377; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; Patras I, 2010, IEEE T PATTERN ANAL, V32, P1553, DOI 10.1109/TPAMI.2009.175; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Rapp V., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P265, DOI 10.1109/FG.2011.5771409; Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Senechal T., 2011, P IEEE INT C AUT FAC, P1; Tresadern P.A., 2009, COMBINING LOCAL GLOB; Valstar M., 2010, P 3 INT WORKSH EMOTI, P65; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; Zhou SK, 2007, LECT NOTES COMPUT SC, V4584, P13	44	82	90	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1149	1163		10.1109/TPAMI.2012.205	http://dx.doi.org/10.1109/TPAMI.2012.205			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520256	Green Submitted			2022-12-18	WOS:000316126800010
J	Maier-Hein, L; Franz, AM; dos Santos, TR; Schmidt, M; Fangerau, M; Meinzer, HP; Fitzpatrick, JM				Maier-Hein, Lena; Franz, Alfred M.; dos Santos, Thiago R.; Schmidt, Mirko; Fangerau, Markus; Meinzer, Hans-Peter; Fitzpatrick, J. Michael			Convergent Iterative Closest-Point Algorithm to Accomodate Anisotropic and Inhomogenous Localization Error	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Registration; surface algorithms; ICP; point-based registration; anisotropic weighting	REGISTRATION; RANGE	Since its introduction in the early 1990s, the Iterative Closest Point (ICP) algorithm has become one of the most well-known methods for geometric alignment of 3D models. Given two roughly aligned shapes represented by two point sets, the algorithm iteratively establishes point correspondences given the current alignment of the data and computes a rigid transformation accordingly. From a statistical point of view, however, it implicitly assumes that the points are observed with isotropic Gaussian noise. In this paper, we show that this assumption may lead to errors and generalize the ICP such that it can account for anisotropic and inhomogenous localization errors. We 1) provide a formal description of the algorithm, 2) extend it to registration of partially overlapping surfaces, 3) prove its convergence, 4) derive the required covariance matrices for a set of selected applications, and 5) present means for optimizing the runtime. An evaluation on publicly available surface meshes as well as on a set of meshes extracted from medical imaging data shows a dramatic increase in accuracy compared to the original ICP, especially in the case of partial surface registration. As point-based surface registration is a central component in various applications, the potential impact of the proposed method is high.	[Maier-Hein, Lena; Franz, Alfred M.; dos Santos, Thiago R.; Fangerau, Markus; Meinzer, Hans-Peter] German Canc Res Ctr, Div Med & Biol Informat, D-69120 Heidelberg, Germany; [Schmidt, Mirko] Heidelberg Univ, Digital Image Proc Grp, D-69115 Heidelberg, Germany; [Fitzpatrick, J. Michael] Vanderbilt Univ, Dept Elect Engn & Comp Sci, Nashville, TN 37235 USA	Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg; Vanderbilt University	Maier-Hein, L (corresponding author), German Canc Res Ctr, Div Med & Biol Informat, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.	l.maier-hein@dkfz-heidelberg.de	Franz, Alfred/AAF-9668-2019		German Research Foundatation (DFG) [PD 15577]	German Research Foundatation (DFG)(German Research Foundation (DFG))	The authors would like to thank U. Rietdorf, M. Engel, and A. Seitel (DKFZ) as well as B. Radeleff and C. Sommer (University of Heidelberg) for providing the medical imaging data. This work was supported by the German Research Foundatation (DFG, PD 15577).	Amberg B., 2007, P IEEE C COMP VIS PA; Armesto L, 2010, IEEE INT CONF ROBOT, P1367, DOI 10.1109/ROBOT.2010.5509371; Balachandran R., 2009, P SOC PHOTO-OPT INS, V7261; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BISPO EM, 1994, P 6 IMA C MATH SURF, P119; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; Cash DM, 2007, J GASTROINTEST SURG, V11, P844, DOI 10.1007/s11605-007-0090-6; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Combes B, 2009, I S BIOMED IMAGING, P370, DOI 10.1109/ISBI.2009.5193061; Danilchenko A, 2011, IEEE T MED IMAGING, V30, P679, DOI 10.1109/TMI.2010.2091513; Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652; Estepar RSJ, 2004, LECT NOTES COMPUT SC, V3216, P234; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; Godin G., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2350, P279, DOI 10.1117/12.189139; Granger S., 2001, LECT NOTES COMPUTER, V2208, P752; Hansena MF, 2007, PROC SPIE, V6512, DOI 10.1117/12.707205; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P234, DOI 10.1109/IM.1997.603871; Jost T, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427, DOI 10.1109/IM.2003.1240278; Kaneko S, 2003, PATTERN RECOGN, V36, P2041, DOI 10.1016/S0031-3203(03)00050-5; Lange Robert, 2000, 3D TIME FLIGHT DISTA; Langis C, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P195, DOI 10.1109/IM.2001.924434; Mahalanobis, 1936, P NATL I SCI INDIA, V2, P49; Maier-Hein L, 2010, LECT NOTES COMPUT SC, V6361, P251; Maier-Hein L., 2011, P SOC PHOTO-OPT INS, V7962, P79620; Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150; Munch D., 2010, P SOC PHOTO-OPT INS, V7623, p76231A; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Neugebauer P, 1997, 1997 INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P130, DOI 10.1109/SMA.1997.634890; Ohta N., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P175, DOI 10.1007/BFb0055666; Penney Graeme P., 2001, MICCAI, P762; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Simon D., 1996, THESIS CARNEGIE MELL; Tamaki T., 2010, Proceedings 2010 First International Conference on Networking and Computing (ICNC 2010), P179, DOI 10.1109/IC-NC.2010.60; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Weik S, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P93, DOI 10.1109/IM.1997.603853; Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067	42	82	86	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1520	1532		10.1109/TPAMI.2011.248	http://dx.doi.org/10.1109/TPAMI.2011.248			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22184256				2022-12-18	WOS:000305188500006
J	Chatzis, SP; Kosmopoulos, DI; Varvarigou, TA				Chatzis, Sotirios P.; Kosmopoulos, Dimitrios I.; Varvarigou, Theodora A.			Robust Sequential Data Modeling Using an Outlier Tolerant Hidden Markov Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; student's t-distribution; expectation-maximization; factor analysis; sequential data modeling	EM; MIXTURES	Hidden Markov (chain) models using finite Gaussian mixture models as their hidden state distributions have been successfully applied in sequential data modeling and classification applications. Nevertheless, Gaussian mixture models are well known to be highly intolerant to the presence of untypical data within the fitting data sets used for their estimation. Finite Student's t-mixture models have recently emerged as a heavier-tailed, robust alternative to Gaussian mixture models, overcoming these hurdles. To exploit these merits of Student's t-mixture models in the context of a sequential data modeling setting, we introduce, in this paper, a novel hidden Markov model where the hidden state distributions are considered to be finite mixtures of multivariate Student's t-densities. We derive an algorithm for the model parameters estimation under a maximum likelihood framework, assuming full, diagonal, and factor-analyzed covariance matrices. The advantages of the proposed model over conventional approaches are experimentally demonstrated through a series of sequential data modeling applications.	[Chatzis, Sotirios P.] Univ Miami, Ctr Computat Sci, Coral Gables, FL 33146 USA; [Kosmopoulos, Dimitrios I.] NCSR Demokritos, Athens 15310, Greece; [Varvarigou, Theodora A.] Natl Tech Univ Athens, Dept Elect & Comp Engn, GR-15773 Athens, Greece	University of Miami; National Centre of Scientific Research "Demokritos"; National Technical University of Athens	Chatzis, SP (corresponding author), Univ Miami, Ctr Computat Sci, 5807 Ponce de Leon Blvd, Coral Gables, FL 33146 USA.	soteri0s@me.com; dkosmo@iit.demokritos.gr; dora@telecom.ntua.gr	Kosmopoulos, Dimitrios/P-4325-2015; Chatzis, Sotirios/H-1975-2014	Kosmopoulos, Dimitrios/0000-0003-3325-1247; Chatzis, Sotirios/0000-0002-4956-4013	Department of Electrical and Computer Engineering at the National Technical University of Athens	Department of Electrical and Computer Engineering at the National Technical University of Athens	At the time of paper submission, S.P. Chatzis was with the Department of Electrical and Computer Engineering at the National Technical University of Athens.	ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; Archambeau C, 2007, NEURAL NETWORKS, V20, P129, DOI 10.1016/j.neunet.2006.06.009; Arslan LM, 1999, IEEE T SPEECH AUDI P, V7, P46, DOI 10.1109/89.736330; CAPPE O, 2005, INFERENCE H MARKOV M; CHATZIS S, 2007, IEEE T FUZZ IN PRESS; Chatzis SP, 2008, IEEE T SIGNAL PROCES, V56, P949, DOI 10.1109/TSP.2007.907912; Chien JT, 2008, IEEE T PATTERN ANAL, V30, P606, DOI 10.1109/TPAMI.2007.70715; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dharanipragada S, 2006, IEEE T AUDIO SPEECH, V14, P1255, DOI 10.1109/TSA.2005.860835; Frankel J, 2007, IEEE T AUDIO SPEECH, V15, P246, DOI 10.1109/TASL.2006.876766; Ghahramani Z., 1997, EM ALGORITHM MIXTURE; Kosmopoulos D. I., 2006, International Journal of Intelligent Systems Technologies and Applications, V1, P359, DOI 10.1504/IJISTA.2006.009913; Lamel L. F., 1986, P DARPA SPEECH REC W, P100; Lee CH, 2007, IEEE SIGNAL PROC LET, V14, P489, DOI 10.1109/LSP.2006.891326; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Lindblad WJ, 2003, WOUND REPAIR REGEN, V11, P1, DOI 10.1046/j.1524-475X.2003.11101.x; MCLACHLAN G, 2000, F MIXTURE MODEL; MCLACHLAN G, 2006, COMPUTATIONAL STAT D, V51, P5327; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Mukundan R., 1998, MOMENT FUNCTIONS IMA; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; Rabinovitch A, 1989, Reg Immunol, V2, P77; Sha F., 2007, ADV NEURAL INFORM PR, P1249; Svensen M, 2005, NEUROCOMPUTING, V64, P235, DOI 10.1016/j.neucom.2004.11.018; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728	27	82	86	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1657	1669		10.1109/TPAMI.2008.215	http://dx.doi.org/10.1109/TPAMI.2008.215			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574625				2022-12-18	WOS:000267369800009
J	Saleemi, I; Shafique, K; Shah, M				Saleemi, Imran; Shafique, Khurram; Shah, Mubarak			Probabilistic Modeling of Scene Dynamics for Applications in Visual Surveillance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vision and scene understanding; Markov processes; machine learning; tracking; kernel density estimation; Metropolis-Hastings; Markov Chain Monte Carlo		We propose a novel method to model and learn the scene activity, observed by a static camera. The proposed model is very general and can be applied for solution of a variety of problems. The motion patterns of objects in the scene are modeled in the form of a multivariate nonparametric probability density function of spatiotemporal variables ( object locations and transition times between them). Kernel Density Estimation is used to learn this model in a completely unsupervised fashion. Learning is accomplished by observing the trajectories of objects by a static camera over extended periods of time. It encodes the probabilistic nature of the behavior of moving objects in the scene and is useful for activity analysis applications, such as persistent tracking and anomalous motion detection. In addition, the model also captures salient scene features, such as the areas of occlusion and most likely paths. Once the model is learned, we use a unified Markov Chain Monte Carlo (MCMC)-based framework for generating the most likely paths in the scene, improving foreground detection, persistent labeling of objects during tracking, and deciding whether a given trajectory represents an anomaly to the observed motion patterns. Experiments with real-world videos are reported which validate the proposed approach.	[Saleemi, Imran; Shah, Mubarak] Univ Cent Florida, Sch Elect Engn & Comp Sci, Harris Corp Engn Ctr HEC, Orlando, FL 32816 USA; [Shafique, Khurram] Object Video Inc, Reston, VA 20191 USA	State University System of Florida; University of Central Florida	Saleemi, I (corresponding author), Univ Cent Florida, Sch Elect Engn & Comp Sci, Harris Corp Engn Ctr HEC, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	imran.saleemi@gmail.com; kshafique@objectvideo.com; shah@eecs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572	US Government VACE Program	US Government VACE Program	This research was supported in part by the US Government VACE Program. The authors would like to thank Dr. Xin Li, Dr. Yaser Sheikh, and Dr. Marshall Tappen for their valuable comments throughout this research.	BENEDIKTSSON JA, 1992, IEEE T SYST MAN CYB, V22, P688, DOI 10.1109/21.156582; Biedermann I., 1981, PERCEPTUAL ORG, P213, DOI [10.4324/9781315512372-8, 10.4324/9781315512372]; BUXTON H, 2002, P GEN MOD BAS VIS WO; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; DOCKSTADER SL, 2001, P IEEE WORKSH MULT T; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123; Ellis T.J., 2003, P JOINT IEEE INT WOR; FERNYHOUGH JH, 1996, P 4 EUR C COMP VIS; Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; GRIMSON WEL, 1998, P INT C COMP VIS PAT; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; HOIEM D, 2006, P INT C COMP VIS PAT; HOWARD RJ, 1992, P 10 EUR C ART INT; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; HUANG T, 1997, P 15 INT JOINT C ART; HUNTER A, 2003, IEE INTELLIGENT DIST; Javed O., 2008, COMPUTER VISION IMAG, V109; Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8; KAUCIC R, 2005, P INT C COMP VIS PAT; KETTNAKER V, 1999, P INT C COMP VIS PAT; KOLLERMEIER EB, 2001, P 2 EUR WORKSH ADV V; LOU J, 2002, P 16 INT C PATT REC; Owens AJ., 2000, P 3 IEEE INT WORKSH; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PERERA A, 2006, P IEEE C COMP VIS PA, P666; REMAGNINO P, 2001, P BRIT MACH VIS C; Rosales Romer, 1998, IMPROVED TRACKING MU; SHAFIQUE K, 2003, P 9 IEEE INT C COMP; Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; STAUFFER C, 2005, P IEEE WORKSH MOT VI, V2, P96; STAUFFER C, 2003, P 2 IEEE EV MIN WORK; Tieu K, 2005, IEEE I CONF COMP VIS, P1842; Torralba Antonio, 2005, P586, DOI 10.1016/B978-012375731-9/50100-2; Turlach B.A., 1993, BANDWIDTH SELECTION; WALTER M, 1999, P BRIT MACH VIS C; WANG X, 2006, P 9 EUR C COMP VIS; 2001, P IEEE, V89	41	82	88	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1472	1485		10.1109/TPAMI.2008.175	http://dx.doi.org/10.1109/TPAMI.2008.175			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542580				2022-12-18	WOS:000267050600010
J	Felzenszwalb, PF				Felzenszwalb, PF			Representation and detection of deformable shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation; object recognition; deformable templates; chordal graphs; dynamic programming	RECOGNITION; SIMILARITY	We describe some techniques that can be used to represent and detect deformable shapes in images. The main difficulty with deformable template models is the very large or infinite number of possible nonrigid transformations of the templates. This makes the problem of finding an optimal match of a deformable template to an image incredibly hard. Using a new representation for deformable shapes, we show how to efficiently find a global optimal solution to the nonrigid matching problem. The representation is based on the description of objects using triangulated polygons. Our matching algorithm can minimize a large class of energy functions, making it applicable to a wide range of problems. We present experimental results of detecting shapes in medical images and images of natural scenes. Our method does not depend on initialization and is very robust, yielding good matches even in images with high clutter. We also consider the problem of learning a nonrigid shape model for a class of objects from examples. We show how to learn good models while constraining them to be in the form required by the matching algorithm.	Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; MIT, Cambridge, MA 02139 USA	University of Chicago; Massachusetts Institute of Technology (MIT)	Felzenszwalb, PF (corresponding author), Univ Chicago, Dept Comp Sci, 1100 E 58th St, Chicago, IL 60637 USA.	pff@cs.uchicago.edu						Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; BERN MW, 1995, LECT NOTES SERIES CO, P47; Bertele U., 1972, NONSERIAL DYNAMIC PR; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BOOKSTEIN FL, 1986, STAT SCI, V1; Cormen T.H., 1989, INTRO ALGORITHMS; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; De Berg Mark, 1997, COMPUTATIONAL GEOMET; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Geiger D, 2003, IEEE T PATTERN ANAL, V25, P86, DOI 10.1109/TPAMI.2003.1159948; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; Golumbic M.C., 1980, ALGORITHMIC GRAPH TH, DOI [10.1007/BF00390110, DOI 10.1007/BF00390110]; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; Grenander U., 1991, HANDS PATTERN THEORE; HARARY F, 1968, MATHEMATIKA, V15, P115, DOI 10.1112/S002557930000245X; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; RENANDER U, 1996, ELEMENTS PATTERN THE; Rose D. J., 1974, Discrete Mathematics, V7, P317, DOI 10.1016/0012-365X(74)90042-9; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; SEBASTIAN TB, 2001, P IEEE INT C IM PROC; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Small C.G., 1996, STAT THEORY SHAPE; Stegmann M, 2002, INFORM MATH MODELLIN; STEGMANN MB, 2003, IEEE T MED IMAGI MAY; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [No title captured]	38	82	95	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					208	220		10.1109/TPAMI.2005.35	http://dx.doi.org/10.1109/TPAMI.2005.35			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688558	Green Submitted			2022-12-18	WOS:000225689300004
J	Liu, TL; Chen, HT				Liu, TL; Chen, HT			Real-time tracking using trust-region methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; vision; iterative optimization; trust-region methods		Optimization methods based on iterative schemes can be divided into two classes: line-search methods and trust-region methods. While line-search techniques are commonly found in various vision applications, not much attention is paid to trust-region ones. Motivated by the fact that line-search methods can be considered as special cases of trust-region methods, we propose to establish a trust-region framework for real-time tracking. Our approach is characterized by three key contributions. First, since a trust-region tracking system is more effective, it often yields better performances than the outcomes of other trackers that rely on iterative optimization to perform tracking, e.g., a line-search-based mean-shift tracker. Second, we have formulated a representation model that uses two coupled weighting schemes derived from the covariance ellipse to integrate an object's color probability distribution and edge density information. As a result, the system can address rotation and nonuniform scaling in a continuous space, rather than working on some presumably possible discrete values of rotation angle and scale. Third, the framework is very flexible in that a variety of distance functions can be adapted easily. Experimental results and comparative studies are provided to demonstrate the efficiency of the proposed method.	Acad Sinica, Inst Informat Sci, Taipei, Taiwan; Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan	Academia Sinica - Taiwan; National Taiwan University	Liu, TL (corresponding author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.	liutyng@iis.sinica.edu.tw; pras@iis.sinica.edu.tw						Avidan S, 2001, PROC CVPR IEEE, P184; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; Bradski G.R., 1998, COMPUTER VISION FACE; Chen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P717, DOI 10.1109/ICCV.2001.937697; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Conn A.R., 2000, TRUST REGION METHODS, DOI [10.1137/1.9780898719857, DOI 10.1137/1.9780898719857]; Freedman D, 2000, INT J COMPUT VISION, V38, P173, DOI 10.1023/A:1008157803698; FREEDMAN D, 2000, P C COMP VIS PATT RE, V1, P139; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; *INT CORP, 2000, 663791005 INT CORP; ISARD M, 1996, P EUR C COMP VIS CAM, V1, P343; JAGERSAND M, 1997, P 1997 INT C ROB AUT; PHONG TQ, 1995, INT J COMPUT VISION, V15, P225, DOI 10.1007/BF01451742; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Sidenbladh H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P709, DOI 10.1109/ICCV.2001.937696; SIMINCHISESCU C, 2001, P C COMP VIS PATT RE, V1, P447; Toyama K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P50, DOI 10.1109/ICCV.2001.937599; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590	18	82	107	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					397	402		10.1109/TPAMI.2004.1262335	http://dx.doi.org/10.1109/TPAMI.2004.1262335			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376885				2022-12-18	WOS:000188949400009
J	Mallet, Y; Coomans, D; Kautsky, J; DeVel, O				Mallet, Y; Coomans, D; Kautsky, J; DeVel, O			Classification using adaptive wavelets for feature extraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						r class category; s set of high-pass filter coefficients I; level of decomposed data or level of the discrete wavelet transform; t band at some level of the discrete wavelet transform; n number of cases; p dimensionality or number of variables	REPRESENTATION	A major concern arising from the classification of spectral data is that the number of variables or dimensionality often exceeds the number of available spectra This leads to a substantial deterioration in performance of traditionally favored classifiers. It becomes necessary to decrease the number of variables to a manageable size, whilst, at the same time, retaining as much discriminatory information as possible. A new and innovative technique based on adaptive wavelets, which aims to reduce the dimensionality and optimize the discriminatory information is presented. The discrete wavelet transform is utilized to produce wavelet coefficients which are used for classification. Rather than using one of the standard wavelet bases, we generate the wavelet which optimizes specified discriminant criteria.	UNIV ADELAIDE,DEPT MATH & STAT,ADELAIDE,SA 5001,AUSTRALIA; JAMES COOK UNIV N QUEENSLAND,DEPT COMP SCI,TOWNSVILLE,QLD 4811,AUSTRALIA	University of Adelaide; James Cook University	Mallet, Y (corresponding author), JAMES COOK UNIV N QUEENSLAND,DEPT MATH & STAT,TOWNSVILLE,QLD 4811,AUSTRALIA.		everingham, yvette/A-8399-2012	Everingham, Yvette/0000-0002-2583-4365				AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; BOS M, 1994, CHEMOMETR INTELL LAB, V23, P115, DOI 10.1016/0169-7439(93)E0066-D; Brier G. W., 1950, MON WEATHER REV, V78, P1, DOI [10.1175/1520-0493(1950)0782.0.co;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; Coomans D., 1986, POTENTIAL PATTERN RE; DAUBECHIES I, 1992, 10 LECT WAVLEETS SCI; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; HABBEMA JDF, 1978, METHOD INFORM MED, V17, P217; KAUTSKY J, 1995, P 6 INT C COMP AN IM, P906; LEARNED RE, 1995, APPL COMPUT HARMON A, V2, P265, DOI 10.1006/acha.1995.1019; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mallet Y, 1996, CHEMOMETR INTELL LAB, V35, P157, DOI 10.1016/S0169-7439(96)00050-0; Mardia KV, 1979, MULTIVARIATE ANAL; *MATH WORKS INC, 1994, MATLAB OPT TOOLB US; SAITO N, 1994, P SOC PHOTO-OPT INS, V2, P303; STEFFEN P, 1993, IEEE T SIGNAL PROCES, V41, P3497, DOI 10.1109/78.258088; Strang G., 1996, WAVELETS FILTER BANK; SZU HH, 1992, OPT ENG, V31, P1907, DOI 10.1117/12.59918; TATE R, 1995, WAVELETS STAT, P377; TELFER BA, 1994, OPT ENG, V33, P2192, DOI 10.1117/12.172257; Turcajova R., 1994, Numerical Algorithms, V8, P27, DOI 10.1007/BF02145695; *U S CAR DEP MATH, LIFT SCHEM CONSTR 2	21	82	86	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1058	1066		10.1109/34.625106	http://dx.doi.org/10.1109/34.625106			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800002
J	LIN, CC; CHELLAPPA, R				LIN, CC; CHELLAPPA, R			CLASSIFICATION OF PARTIAL 2-D SHAPES USING FOURIER DESCRIPTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LIN, CC (corresponding author), UNIV SO CALIF,INST SIGNAL & IMAGE PROC,DEPT ELECT ENGN,LOS ANGELES,CA 90089, USA.		Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020					AMBLER AP, 1975, ARTIF INTELL, V6, P129, DOI 10.1016/0004-3702(75)90006-5; Ballard D.H., 1982, COMPUTER VISION; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; CHELLAPPA R, 1984, IEEE T PATTERN ANAL, V6, P102, DOI 10.1109/TPAMI.1984.4767482; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; FU KS, 1982, SYNTACTIC PATTERN RE; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; GROGAN TA, 1983, THESIS PURDUE U; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; MITCHELL OR, 1974, OPTICAL ENG, V23, P484; Oosterlinck A., 1976, 3rd International Joint Conference on Pattern Recognition, P334; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; POGGIO T, 1984, MIT773 AI LAB MEM; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; ROSEN C, 1974, EXPLORATORY RES ADV; SCHREIBER WF, 1972, PICTURE BANDWIDTH CO, P443; SINGER PF, 1985, JUN P COMP VIS PATT, P497; SINGER PF, 1983, JUN IEEE P COMP SOC, P146; TSAI WH, 1980, IEEE T SYST MAN CYB, V10, P873, DOI 10.1109/TSMC.1980.4308414; WECHSLER H, 1977, PATTERN RECOGN, V9, P21, DOI 10.1016/0031-3203(77)90027-9; YOU KC, 1979, IEEE T SYST MAN CYB, V9, P334, DOI 10.1109/TSMC.1979.4310222; ZHAN CT, 1972, IEEE T COMPUT, V21, P269	27	82	87	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					686	690		10.1109/TPAMI.1987.4767963	http://dx.doi.org/10.1109/TPAMI.1987.4767963			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869427				2022-12-18	WOS:A1987J739300010
J	SHANMUGAM, KS; DICKEY, FM; GREEN, JA				SHANMUGAM, KS; DICKEY, FM; GREEN, JA			OPTIMAL FREQUENCY-DOMAIN FILTER FOR EDGE DETECTION IN DIGITAL PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									BOEING CO, ELECTRO OPT GRP, WICHITA, KS 67210 USA	Boeing	SHANMUGAM, KS (corresponding author), WICHITA STATE UNIV, DEPT ELECT ENGN, WICHITA, KS 67208 USA.							Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DICKEY FM, 1977, APPL OPTICS, V16, P145, DOI 10.1364/AO.16.000145; Duda R.O., 1973, J ROYAL STAT SOC SER; FLAMMER C, 1956, SPHERIOIDAL WAVE FUN; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; HARALICK RM, 1975, IEEE T CIRCUITS SYST, VCA22, P440, DOI 10.1109/TCS.1975.1084059; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; LANDAU HJ, 1961, BELL SYST TECH J, V40, P65, DOI 10.1002/j.1538-7305.1961.tb03977.x; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; Roberts L. G., 1965, OPTICAL ELECTRO OPTI; ROSENFELD A, 1969, PICTURE PROCESSING C; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SLEPIAN D, 1961, BELL SYST TECH J, V40, P43, DOI 10.1002/j.1538-7305.1961.tb03976.x; SLEPIAN D, 1965, J MATH PHYS, V44, P93; STREIFER W, 1965, J OPT SOC AM, V55, P868, DOI 10.1364/JOSA.55.000868; WECHSLER H, 1977, IEEE T SYST MAN CYB, V17, P827	17	82	86	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					37	49		10.1109/TPAMI.1979.4766874	http://dx.doi.org/10.1109/TPAMI.1979.4766874			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868829				2022-12-18	WOS:A1979HA30300005
J	Hu, JF; Zheng, WS; Lai, JH; Zhang, JG				Hu, Jian-Fang; Zheng, Wei-Shi; Lai, Jianhuang; Zhang, Jianguo			Jointly Learning Heterogeneous Features for RGB-D Activity Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heterogeneous features learning; RGB-D activity recognition; action recognition	SEQUENCE; TASKS; POSE	In this paper, we focus on heterogeneous features learning for RGB-D activity recognition. We find that features from different channels (RGB, depth) could share some similar hidden structures, and then propose a joint learning model to simultaneously explore the shared and feature-specific components as an instance of heterogeneous multi-task learning. The proposed model formed in a unified framework is capable of: 1) jointly mining a set of subspaces with the same dimensionality to exploit latent shared features across different feature channels, 2) meanwhile, quantifying the shared and feature-specific components of features in the subspaces, and 3) transferring feature-specific intermediate transforms (i-transforms) for learning fusion of heterogeneous features across datasets. To efficiently train the joint model, a three-step iterative optimization algorithm is proposed, followed by a simple inference model. Extensive experimental results on four activity datasets have demonstrated the efficacy of the proposed method. A new RGB-D activity dataset focusing on human-object interaction is further contributed, which presents more challenges for RGB-D activity benchmarking.	[Hu, Jian-Fang; Zheng, Wei-Shi; Lai, Jianhuang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China; [Hu, Jian-Fang] Natl Univ Def Technol, Collaborat Innovat Ctr High Performance Comp, Changsha 410073, Hunan, Peoples R China; [Zheng, Wei-Shi] Sun Yat Sen Univ, Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou 510275, Guangdong, Peoples R China; [Lai, Jianhuang] Guangdong Prov Key Lab Informat Secur, Guangzhou 510275, Guangdong, Peoples R China; [Zhang, Jianguo] Univ Dundee, Sch Sci & Engn Comp, Dundee DD1 4HN, Scotland	Sun Yat Sen University; National University of Defense Technology - China; Sun Yat Sen University; University of Dundee	Hu, JF (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China.; Hu, JF (corresponding author), Natl Univ Def Technol, Collaborat Innovat Ctr High Performance Comp, Changsha 410073, Hunan, Peoples R China.	hujianf@mail2.sysu.edu.cn; wszheng@ieee.org; stsljh@mail.sysu.edu.cn; j.n.zhang@dundee.ac.uk		zhang, jianguo/0000-0001-9317-0268	National Key Research and Development Program of China [2016YFB1001002, 2016YFB1001003]; NSFC [61522115, 61573387, 61661130157, 61628212]; Guangdong Natural Science Funds for Distinguished Young Scholar [S2013050014265]; Guangdong Science and Technology Planning Project [2016A010102012]; Guangdong Program for Support of Top-notch Young Professionals [2014TQ01X779]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Guangdong Natural Science Funds for Distinguished Young Scholar; Guangdong Science and Technology Planning Project; Guangdong Program for Support of Top-notch Young Professionals	The authors would like to thank all reviewers' constructive advice for improving this work. The code for this work is available at: http://isee.sysu.edu.cn/similar to hujianfang/ProjectJOULE. html. This work was supported partially by the National Key Research and Development Program of China (2016YFB1001002, 2016YFB1001003), NSFC (61522115, 61573387, 61661130157, 61628212), Guangdong Natural Science Funds for Distinguished Young Scholar under Grant S2013050014265, the Guangdong Science and Technology Planning Project (2016A010102012), and Guangdong Program for Support of Top-notch Young Professionals (2014TQ01X779). The corresponding author for this paper is Wei-Shi Zheng.	Amit Y., 2007, ICML 07 P 24 INT C M, P17, DOI DOI 10.1145/1273496.1273499; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Chaaraoui AA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P91, DOI 10.1109/ICCVW.2013.19; Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83; Cao LL, 2009, IEEE I CONF COMP VIS, P1095, DOI 10.1109/ICCV.2009.5459401; Chen JH, 2013, IEEE T PATTERN ANAL, V35, P1025, DOI 10.1109/TPAMI.2012.189; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253; Han S., 2012, P 29 INT C MACH LEAR, P1463; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17; Hu JF, 2016, IEEE T CIRC SYST VID, V26, P647, DOI 10.1109/TCSVT.2015.2397200; Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172; Hussein Mohamed E, 2013, 23 INT JOINT C ART I; Jia XF, 2012, INT C PATT RECOG, P3001; Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Lei JN, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P208; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Lillo I, 2014, PROC CVPR IEEE, P812, DOI 10.1109/CVPR.2014.109; Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154; Mualler M., 2006, P 2006 ACM SIGGRAPH, P137; Ni BB, 2012, LECT NOTES COMPUT SC, V7573, P173, DOI 10.1007/978-3-642-33709-3_13; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Shahroudy A, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P73, DOI 10.1109/ISCCSP.2014.6877819; Shao, 2013, P 23 INT JOINT C ART; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Song Y, 2012, PROC CVPR IEEE, P2120, DOI 10.1109/CVPR.2012.6247918; Sung J., 2011, P 16 AAAI C PLAN ACT, P47; Vemulapalli R., 2013, CVPR, P588; Wang AR, 2015, IEEE I CONF COMP VIS, P1125, DOI 10.1109/ICCV.2015.134; Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62; Wang S, 2012, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2012.6247823; Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365; Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699; Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108; Yang Xiaolin, 2009, ADV NEURAL INFORM PR, P2151; Yao BP, 2012, LECT NOTES COMPUT SC, V7575, P173, DOI 10.1007/978-3-642-33765-9_13; Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67; Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhang Y., 2011, PROC 25 AAAI C ARTIF, P574; Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733; Zhao Y., 2012, J NANOTECHNOL, V2012, P1, DOI DOI 10.1186/1741-7015-10-3]; Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984; Zhou Q, 2013, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2013.281; Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005; Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78	59	81	85	3	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2186	2200		10.1109/TPAMI.2016.2640292	http://dx.doi.org/10.1109/TPAMI.2016.2640292			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28026749	Green Submitted			2022-12-18	WOS:000412028600006
J	Babenko, A; Lempitsky, V				Babenko, Artem; Lempitsky, Victor			The Inverted Multi-Index	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; Index; nearest neighbor search; product quantization	OBJECT; SCENE	A new data structure for efficient similarity search in very large datasets of high-dimensional vectors is introduced. This structure called the inverted multi-index generalizes the inverted index idea by replacing the standard quantization within inverted indices with product quantization. For very similar retrieval complexity and pre-processing time, inverted multi-indices achieve a much denser subdivision of the search space compared to inverted indices, while retaining their memory efficiency. Our experiments with large datasets of SIFT and GIST vectors demonstrate that because of the denser subdivision, inverted multi-indices are able to return much shorter candidate lists with higher recall. Augmented with a suitable reranking procedure, multi-indices were able to significantly improve the speed of approximate nearest neighbor search on the dataset of 1 billion SIFT vectors compared to the best previously published systems, while achieving better recall and incurring only few percent of memory overhead.	[Babenko, Artem] Yandex, Moscow, Russia; [Babenko, Artem] Natl Res Univ, Higher Sch Econ, London, England; [Lempitsky, Victor] Skolkovo Inst Sci & Technol, Moscow, Russia	University of London; London School Economics & Political Science; Skolkovo Institute of Science & Technology	Babenko, A (corresponding author), Yandex, Moscow, Russia.	artem.babenko@phystech.edu; victorlempitsky@gmail.com	Babenko, Artem/M-3540-2016	Babenko, Artem/0000-0002-1830-8252				Babenko A., 2014, CORR; Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Charikar M.S., 2002, P 34 ANN ACM S THEOR, V34, P380, DOI DOI 10.1145/509907.509965; Chum O., 2007, P 6 ACM INT C IM VID, P549, DOI DOI 10.1145/1282280.1282359; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Douze M., 2009, P ACM INT C IM VID R, P9; Ge T., 2013, MSRTR201359; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2011, INT CONF ACOUST SPEE, P861; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Ke Y, 2004, ACM MULTIMEDIA, V4, P869, DOI DOI 10.1145/1027527.1027729; Lee DC, 2010, LECT NOTES COMPUT SC, V6311, P648, DOI 10.1007/978-3-642-15549-9_47; Lejsek H., 2011, P 1 ACM INT C MULT R, P54; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv Q., 2004, P 13 ACM INT C INF K, P208, DOI DOI 10.1145/1031171.1031213; Malisiewicz T., 2009, ADV NEURAL INF PROCE, V22, P1222; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Philbin J, 2010, LECT NOTES COMPUT SC, V6313, P677; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schmid C., 2011, EXPLOITING DESCRIPTO; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sivic J., 2008, COMPUTER VISION PATT, P1, DOI 10.1109/CVPR.2008.4587635; Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vedaldi A., 2010, VLFEAT OPEN PORTABLE; Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651	39	81	83	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1247	1260		10.1109/TPAMI.2014.2361319	http://dx.doi.org/10.1109/TPAMI.2014.2361319			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357346				2022-12-18	WOS:000354377100010
J	Trzcinski, T; Christoudias, M; Lepetit, V				Trzcinski, Tomasz; Christoudias, Mario; Lepetit, Vincent			Learning Image Descriptors with Boosting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Learning feature descriptors; binary embedding; boosting	KERNEL	We propose a novel and general framework to learn compact but highly discriminative floating-point and binary local feature descriptors. By leveraging the boosting-trick we first show how to efficiently train a compact floating-point descriptor that is very robust to illumination and viewpoint changes. We then present the main contribution of this paper-a binary extension of the framework that demonstrates the real advantage of our approach and allows us to compress the descriptor even further. Each bit of the resulting binary descriptor, which we call BinBoost, is computed with a boosted binary hash function, and we show how to efficiently optimize the hash functions so that they are complementary, which is key to compactness and robustness. As we do not put any constraints on the weak learner configuration underlying each hash function, our general framework allows us to optimize the sampling patterns of recently proposed hand-crafted descriptors and significantly improve their performance. Moreover, our boosting scheme can easily adapt to new applications and generalize to other types of image data, such as faces, while providing state-of-the-art results at a fraction of the matching time and memory footprint.	[Trzcinski, Tomasz; Christoudias, Mario] Ecole Polytech Fed Lausanne, Comp Vis Lab, I&C Fac, CH-1015 Lausanne, Vaud, Switzerland; [Lepetit, Vincent] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Graz University of Technology	Trzcinski, T (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, I&C Fac, CH-1015 Lausanne, Vaud, Switzerland.	tomasz.trzcinski@epfl.ch; mario.christoudias@epfl.ch; lepetit@icg.tugraz.at	Trzcinski, Tomasz/G-1922-2018	Trzcinski, Tomasz/0000-0002-1486-8906				Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alahi A, 2011, J MATH IMAGING VIS, V41, P39, DOI 10.1007/s10851-010-0258-7; Ali K, 2012, IEEE T PATTERN ANAL, V34, P225, DOI 10.1109/TPAMI.2011.117; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222; CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992; Chandrasekhar Vijay, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2504, DOI 10.1109/CVPRW.2009.5206733; Chapelle O, 2011, MACH LEARN, V85, P149, DOI 10.1007/s10994-010-5231-6; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Freund Y., 1995, COMPUTATIONAL LEARNI, V904, P23, DOI [10.1007/3-540-59119-2_166, DOI 10.1007/3-540-59119-2_166]; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hastie T, 2009, ELEMENTS STAT LEARNI; Jain P, 2012, J MACH LEARN RES, V13, P519; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malekesmaeili M., 2012, IEEE T PATTERN ANAL, V34, P2481; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Norouzi M, 2012, PROC CVPR IEEE, P3108, DOI 10.1109/CVPR.2012.6248043; Rosset S, 2004, J MACH LEARN RES, V5, P941; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shakhnarovich G., 2006, THESIS MIT CAMBRIDGE; Shen S., 2009, P 10 AS C COMP VIS, P214; Simonyan K, 2012, LECT NOTES COMPUT SC, V7572, P243, DOI 10.1007/978-3-642-33718-5_18; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A., 2008, P 33 INT C INFR MILL, P1; Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; Trzcinski Tomasz, 2012, ADV NEURAL INFORM PR, P269, DOI DOI 10.1177/1753193411419945; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang J., 2010, ICML, P1127; Wang XG, 2009, PROC CVPR IEEE, P142, DOI 10.1109/CVPRW.2009.5206736; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25; Zervos M., 2013, THESIS EPFL LAUSANNE; Zitnick CL, 2010, LECT NOTES COMPUT SC, V6312, P170, DOI 10.1007/978-3-642-15552-9_13	44	81	97	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					597	610		10.1109/TPAMI.2014.2343961	http://dx.doi.org/10.1109/TPAMI.2014.2343961			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353264	Green Submitted			2022-12-18	WOS:000349626200009
J	Hu, WM; Li, X; Tian, GD; Maybank, S; Zhang, ZF				Hu, Weiming; Li, Xi; Tian, Guodong; Maybank, Stephen; Zhang, Zhongfei			An Incremental DPMM-Based Method for Trajectory Clustering, Modeling, and Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory clustering and modeling; incremental clustering; Dirichlet process mixture model; time-sensitive Dirichlet process mixture model; video retrieval	VIDEO RETRIEVAL; PATTERNS	Trajectory analysis is the basis for many applications, such as indexing of motion events in videos, activity recognition, and surveillance. In this paper, the Dirichlet process mixture model (DPMM) is applied to trajectory clustering, modeling, and retrieval. We propose an incremental version of a DPMM-based clustering algorithm and apply it to cluster trajectories. An appropriate number of trajectory clusters is determined automatically. When trajectories belonging to new clusters arrive, the new clusters can be identified online and added to the model without any retraining using the previous data. A time-sensitive Dirichlet process mixture model (tDPMM) is applied to each trajectory cluster for learning the trajectory pattern which represents the time-series characteristics of the trajectories in the cluster. Then, a parameterized index is constructed for each cluster. A novel likelihood estimation algorithm for the tDPMM is proposed, and a trajectory-based video retrieval model is developed. The tDPMM-based probabilistic matching method and the DPMM-based model growing method are combined to make the retrieval model scalable and adaptable. Experimental comparisons with state-of-the-art algorithms demonstrate the effectiveness of our algorithm.	[Hu, Weiming; Li, Xi; Tian, Guodong] Chinese Acad Sci, NLPR, Inst Automat, Beijing 100190, Peoples R China; [Maybank, Stephen] Univ London Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England; [Zhang, Zhongfei] SUNY Binghamton, Dept Comp Sci, Watson Sch Engn & Appl Sci, Binghamton, NY 13902 USA	Chinese Academy of Sciences; Institute of Automation, CAS; University of London; Birkbeck University London; State University of New York (SUNY) System; State University of New York (SUNY) Binghamton	Li, X (corresponding author), Chinese Acad Sci, NLPR, Inst Automat, 95 Zhongguancun East Rd,Box 2728, Beijing 100190, Peoples R China.	wmhu@nlpr.ia.ac.cn; lixichinanlpr@gmail.com; guodong_tian@126.com; sjmaybank@dcs.bbk.ac.uk; zhongfei@cs.binghamton.edu	Li, Xi/L-1234-2013	Li, Xi/0000-0003-3023-1662	Natural Science Foundation of China [60825204, 60935002]; National 863 High-Tech R&D Program of China [2012AA012504]; Natural Science Foundation of Beijing [4121003]; US National Science Foundation (NSF) [IIS-0812114, CCF-1017828]; National Basic Research Program of China [2012CB316400]; Alibaba Financial, Zhejiang University Joint Research Lab	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National 863 High-Tech R&D Program of China(National High Technology Research and Development Program of China); Natural Science Foundation of Beijing(Beijing Natural Science Foundation); US National Science Foundation (NSF)(National Science Foundation (NSF)); National Basic Research Program of China(National Basic Research Program of China); Alibaba Financial, Zhejiang University Joint Research Lab	The authors thank Drs. Xiaoqin Zhang and Guan Luo for their valuable suggestions on the work. This work is partly supported by the Natural Science Foundation of China (Grant No. 60825204, 60935002), the National 863 High-Tech R&D Program of China (Grant No. 2012AA012504), the Natural Science Foundation of Beijing (Grant No. 4121003), US National Science Foundation (NSF) (IIS-0812114, CCF-1017828), National Basic Research Program of China (2012CB316400), and Alibaba Financial, Zhejiang University Joint Research Lab.	Alon J, 2003, PROC CVPR IEEE, P375; ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C; Atev S, 2010, IEEE T INTELL TRANSP, V11, P647, DOI 10.1109/TITS.2010.2048101; Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei D.M., 2004, P INT C MACH LEARN, P121; Chen L., 2004, P 30 INT C VERY LARG, V30, P792, DOI [10.1016/B978-012088469-8/50070-X, DOI 10.1016/B978-012088469-8/50070-X]; Chen L., 2005, P 2005 ACM SIGMOD IN, P491, DOI DOI 10.1145/1066157.1066213; Chib S., 2004, MARKOV CHAIN MONTE C, P89; COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dagtas S, 2000, IEEE T IMAGE PROCESS, V9, P88, DOI 10.1109/83.817601; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Gu Z., 1997, THESIS U BRIT COLUMB; Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965; Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8; Jung CR, 2008, IEEE T CIRC SYST VID, V18, P1565, DOI 10.1109/TCSVT.2008.2005600; Jung YK, 2001, IEEE T INTELL TRANSP, V2, P151, DOI 10.1109/6979.954548; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406; KEOGH E., 2004, VLDB 04, V30, P780; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P285, DOI 10.1145/347090.347153; Little JJ, 2001, P SOC PHOTO-OPT INS, V4315, P545, DOI 10.1117/12.410966; Ma X, 2009, IEEE T CIRC SYST VID, V19, P397, DOI 10.1109/TCSVT.2009.2013510; Morris B, 2009, PROC CVPR IEEE, P312, DOI 10.1109/CVPRW.2009.5206559; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Morris BT, 2008, IEEE T INTELL TRANSP, V9, P425, DOI 10.1109/TITS.2008.922970; Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64; Naftel A., 2005, P INT WORKSH HUM ACT, P17; Naftel A., 2006, P IEEE INT C COMP VI, P47; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Palpanas T, 2004, PROC INT CONF DATA, P338; PAVLIDIS T, 1977, IEEE T COMPUT, V26, P800, DOI 10.1109/TC.1977.1674918; Piotto N, 2009, IEEE T MULTIMEDIA, V11, P1266, DOI 10.1109/TMM.2009.2030746; Sahouria E, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P526, DOI 10.1109/ICIP.1997.638824; Saleemi I, 2009, IEEE T PATTERN ANAL, V31, P1472, DOI 10.1109/TPAMI.2008.175; Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875; Sun J, 2005, IEEE I CONF COMP VIS, P717; Teh Yee Whye, 2010, ENCY MACHINE LEARNIN, DOI DOI 10.1007/978-0-387-30164-8_219; Veeraraghavan H, 2009, IEEE T INTELL TRANSP, V10, P628, DOI 10.1109/TITS.2009.2026440; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Wang XY, 2013, DATA MIN KNOWL DISC, V26, P275, DOI 10.1007/s10618-012-0250-5; Yajima C., 2002, Visual and Multimedia Information Management. IFIP TC2/WG2.6. Sixth Working Conference on Visual Database Systems, P357; Zhang CL, 2006, ICMLA 2006: 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P285; Zhu X., 2005, CMUCALD05104 SCH COM	45	81	85	1	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1051	1065		10.1109/TPAMI.2012.188	http://dx.doi.org/10.1109/TPAMI.2012.188			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520251				2022-12-18	WOS:000316126800003
J	Kratz, L; Nishino, K				Kratz, Louis; Nishino, Ko			Tracking Pedestrians Using Local Spatio-Temporal Motion Patterns in Extremely Crowded Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tracking; video analysis; crowded scenes; spatio-temporal motion patterns; hidden Markov models		Tracking pedestrians is a vital component of many computer vision applications, including surveillance, scene understanding, and behavior analysis. Videos of crowded scenes present significant challenges to tracking due to the large number of pedestrians and the frequent partial occlusions that they produce. The movement of each pedestrian, however, contributes to the overall crowd motion (i.e., the collective motions of the scene's constituents over the entire video) that exhibits an underlying spatially and temporally varying structured pattern. In this paper, we present a novel Bayesian framework for tracking pedestrians in videos of crowded scenes using a space-time model of the crowd motion. We represent the crowd motion with a collection of hidden Markov models trained on local spatio-temporal motion patterns, i.e., the motion patterns exhibited by pedestrians as they move through local space-time regions of the video. Using this unique representation, we predict the next local spatio-temporal motion pattern a tracked pedestrian will exhibit based on the observed frames of the video. We then use this prediction as a prior for tracking the movement of an individual in videos of extremely crowded scenes. We show that our approach of leveraging the crowd motion enables tracking in videos of complex scenes that present unique difficulty to other approaches.	[Kratz, Louis; Nishino, Ko] Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA	Drexel University	Kratz, L (corresponding author), Drexel Univ, Dept Comp Sci, 3141 Chestnut St, Philadelphia, PA 19104 USA.	lak24@drexel.edu; kon@drexel.edu			US National Science Foundation [IIS-0746717, IIS-0803670]; Nippon Telegraph and Telephone Corporation	US National Science Foundation(National Science Foundation (NSF)); Nippon Telegraph and Telephone Corporation	This work was supported in part by US National Science Foundation grants IIS-0746717 and IIS-0803670, and Nippon Telegraph and Telephone Corporation. The authors thank Nippon Telegraph and Telephone Corporation for providing the train station videos.	Ali S., 2008, P EUR C COMP VIS; Ali S, 2007, PROC CVPR IEEE, P65; [Anonymous], 2008, P IEEE C COMP VIS PA; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Betke M, 2007, PROC CVPR IEEE, P192; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; Brostow G.J., 2006, P IEEE INT C COMP VI, P594, DOI DOI 10.1109/CVPR.2006.320; Dalal N., 2005, P IEEE CS C COMP VIS; Hue C, 2006, IEEE T AERO ELEC SYS, V42, P37, DOI 10.1109/TAES.2006.1603404; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247; Klaser Alexander, 2008, BMVC; Kratz L., 2010, P IEEE INT C COMP VI; Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Leibe B., 2005, P IEEE CS C COMP VIS; Li Y., 2009, P IEEE C COMP VIS PA; Nestares O, 2001, PROC CVPR IEEE, P358; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rodriguez M., 2009, P 12 IEEE INT C COMP; Shechtman E, 2005, PROC CVPR IEEE, P405; Sugimura D., 2009, P 12 IEEE INT C COMP; Wright J., 2005, P IEEE WORKSH MOT VI, V2, P14; Wu B., 2006, 2006 IEEE COMP SOC C, V1, P951, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]; Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770	29	81	89	2	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					987	1002		10.1109/TPAMI.2011.173	http://dx.doi.org/10.1109/TPAMI.2011.173			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21844618				2022-12-18	WOS:000301747400012
J	Tai, YW; Du, H; Brown, MS; Lin, S				Tai, Yu-Wing; Du, Hao; Brown, Michael S.; Lin, Stephen			Correction of Spatially Varying Image and Video Motion Blur Using a Hybrid Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion deblurring; spatially varying motion blur; hybrid camera	SUPERRESOLUTION	We describe a novel approach to reduce spatially varying motion blur in video and images using a hybrid camera system. A hybrid camera is a standard video camera that is coupled with an auxiliary low-resolution camera sharing the same optical path but capturing at a significantly higher frame rate. The auxiliary video is temporally sharper but at a lower resolution, while the lower frame-rate video has higher spatial resolution but is susceptible to motion blur. Our deblurring approach uses the data from these two video streams to reduce spatially varying motion blur in the high-resolution camera with a technique that combines both deconvolution and super-resolution. Our algorithm also incorporates a refinement of the spatially varying blur kernels to further improve results. Our approach can reduce motion blur from the high-resolution video as well as estimate new high-resolution frames at a higher frame rate. Experimental results on a variety of inputs demonstrate notable improvement over current state-of-the-art methods in image/video deblurring.	[Tai, Yu-Wing] Korea Adv Inst Sci & Technol, Seoul, South Korea; [Du, Hao] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Brown, Michael S.] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore; [Lin, Stephen] Microsoft Res Asia, Beijing Sigma Ctr, Beijing 100190, Peoples R China	Korea Advanced Institute of Science & Technology (KAIST); University of Washington; University of Washington Seattle; National University of Singapore; Microsoft; Microsoft Research Asia	Tai, YW (corresponding author), Korea Adv Inst Sci & Technol, Seoul, South Korea.	yuwing@gmail.com; duhao@cs.washington.edu; brown@comp.nus.edu.sg; stevelin@microsoft.com	Tai, Yu Wing/C-2047-2011	Tai, Yu Wing/0000-0002-3148-0380				Aggarwal M, 2004, INT J COMPUT VISION, V58, P7, DOI 10.1023/B:VISI.0000016144.56397.1a; Agrawal A., 2007, P IEEE C COMP VIS PA; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BARDSLEY J, 2006, OPT EXPRESS, P1767; BASCLE B, 1996, P EUR C COMP VIS, P573; Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Ben-Ezra M, 2003, PROC CVPR IEEE, P657; BHAT P, 2007, P EUR S REND EGSR, P327; Bigas M, 2006, MICROELECTRON J, V37, P433, DOI 10.1016/j.mejo.2005.07.002; Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509; Chen J., 2008, P IEEE C COMP VIS PA; CHO S, 2007, P INT C COMP VIS; Chuang YY, 2001, PROC CVPR IEEE, P264; Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572; DEY N, 2004, P IEEE INT S BIOM IM; Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; FISH D, 1995, J OPTICAL SOC AM, V12; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Hansen P.C., 2006, DEBLURRING IMAGES MA; IRANI M, 1991, P CVGIP GRAPH MOD IM, V53, P231; JIA J, 2007, P IEEE C COMP VIS PA; Joshi N., 2008, P IEEE C COMP VIS PA; Joshi N, 2006, ACM T GRAPHIC, V25, P779, DOI 10.1145/1141911.1141955; Lauer TR, 2002, P SOC PHOTO-OPT INS, V4847, P167, DOI 10.1117/12.461035; Levin A., 2006, ADV NEURAL INFORM PR, V19, P841; Levin A, 2006, P IEEE C COMP VIS PA; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360670; Li F., 2008, P IEEE C COMP VIS PA; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141; McGuire M, 2005, ACM T GRAPHIC, V24, P567, DOI 10.1145/1073204.1073231; MCGUIRE M, 2006, P EUR S REND; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; SHAN Q, 2007, P INT C COMP VIS; Shan Qi, 2008, ACM T GRAPHICS; Shechtman E, 2005, IEEE T PATTERN ANAL, V27, P531, DOI 10.1109/TPAMI.2005.85; SMITH A, 1996, P ACM SIGGRAPH; Sroubek F, 2007, IEEE T IMAGE PROCESS, V16, P2322, DOI 10.1109/TIP.2007.903256; SUN J, 2004, ACM T GRAPHICS; Tai Y. - W., 2008, P IEEE C COMP VIS PA; Wang JW, 2005, I C COMP SYST APPLIC; Wang J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239460; Xiao J., 2006, P EUR C COMP VIS; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673; ZHANG G, 2007, P INT C COMP VIS; Zhao WY, 2002, LECT NOTES COMPUT SC, V2350, P599	55	81	86	0	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1012	1028		10.1109/TPAMI.2009.97	http://dx.doi.org/10.1109/TPAMI.2009.97			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431128				2022-12-18	WOS:000276671900005
J	Subrahmanya, N; Shin, YC				Subrahmanya, Niranjan; Shin, Yung C.			Sparse Multiple Kernel Learning for Signal Processing Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Composite kernel learning; feature group selection; heterogeneous data fusion; sensor selection	FEATURE-SELECTION; REGRESSION; SHRINKAGE	In many signal processing applications, grouping of features during model development and the selection of a small number of relevant groups can be useful to improve the interpretability of the learned parameters. While a lot of work based on linear models has been reported to solve this problem, in the last few years, multiple kernel learning has come up as a candidate to solve this problem in nonlinear models. Since all of the multiple kernel learning algorithms to date use convex primal problem formulations, the kernel weights selected by these algorithms are not strictly the sparsest possible solution. The main reason for using a convex primal formulation is that efficient implementations of kernel-based methods invariably rely on solving the dual problem. This work proposes the use of an additional log-based concave penalty term in the primal problem to induce sparsity in terms of groups of parameters. A generalized iterative learning algorithm, which can be used with a linear combination of this concave penalty term with other penalty terms, is given for model parameter estimation in the primal space. It is then shown that a natural extension of the method to nonlinear models using the "kernel trick" results in a new algorithm, called Sparse Multiple Kernel Learning (SMKL), which generalizes group-feature selection to kernel selection. SMKL is capable of exploiting existing efficient single kernel algorithms while providing a sparser solution in terms of the number of kernels used as compared to the existing multiple kernel learning framework. A number of signal processing examples based on the use of mass spectra for cancer detection, hyperspectral imagery for land cover classification, and NIR spectra from wheat, fescue grass, and diesel are given to highlight the ability of SMKL to achieve a very high accuracy with a very few kernels.	[Subrahmanya, Niranjan; Shin, Yung C.] Purdue Univ, Sch Mech Engn, W Lafayette, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus	Subrahmanya, N (corresponding author), Purdue Univ, Sch Mech Engn, 585 Purdue Mall, W Lafayette, IN 47907 USA.	nsubrahm@purdue.edu; shin@purdue.edu	Shin, Yung C/E-4626-2011; Shin, Yung/AAI-2429-2020	Shin, Yung C/0000-0003-3157-9345; 				Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; [Anonymous], 2002, LEARNING KERNELS; Bach F.R., 2004, P 21 INT C MACHINE L, P6, DOI 10.1145/ 1015330.1015424; Blake C., 1998, UCI REPOSITORY MACHI; BRADLEY PS, 1998, P 15 INT C MACH LEAR, P82; Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cotter Robert J, 2005, J Mass Spectrom Soc Jpn, V53, P7; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Girolami M, 2001, NEURAL COMPUT, V13, P2517, DOI 10.1162/089976601753196003; Girolami M., 2005, P 22 INT C MACH LEAR, P241, DOI DOI 10.1145/1102351.1102382; Guyon I., 2006, FEATURE EXTRACTION F; HALL DL, 1992, MATH TECHNIQUES MULT; Joachims T., 1999, ADV KERNEL METHODS S; Kim Y, 2006, STAT SINICA, V16, P375; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; MA S, 2007, BIOINFORMATICS, V8; Martens H., 2001, MULTIVARIATE ANAL QU; MEIER L, 2006, GROUP LASSO LOGISTIC; Neal R. M., 1998, LEARNING GRAPHICAL M; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Platt J C, 1999, ADV KERNEL METHODS S; Rakotomamonjy A., 2007, P 24 INT C MACH LEAR, V227, P775, DOI DOI 10.1145/1273496.1273594; Rossi F, 2007, CHEMOMETR INTELL LAB, V86, P208, DOI 10.1016/j.chemolab.2006.06.007; Simila T, 2007, COMPUT STAT DATA AN, V52, P406, DOI 10.1016/j.csda.2007.01.025; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Stoeckel J, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P410, DOI 10.1109/ICDM.2005.141; SUBRAHMANYA N, 2008, T ASME, V130; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vannucci M, 2005, CHEMOMETR INTELL LAB, V77, P139, DOI 10.1016/j.chemolab.2004.10.009; Wang LF, 2007, BIOINFORMATICS, V23, P1486, DOI 10.1093/bioinformatics/btm125; Weston J., 2003, Journal of Machine Learning Research, V3, P1439, DOI 10.1162/153244303322753751; Wipf DP, 2007, IEEE T SIGNAL PROCES, V55, P3704, DOI 10.1109/TSP.2007.894265; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang ZM, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P927; Zhao P, 2006, GROUPED HIERARCHICAL	44	81	86	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					788	798		10.1109/TPAMI.2009.98	http://dx.doi.org/10.1109/TPAMI.2009.98			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299705				2022-12-18	WOS:000275569300002
J	Mohamad, RAH; Likforman-Sulem, L; Mokbel, C				Mohamad, Ramy Al-Hajj; Likforman-Sulem, Laurence; Mokbel, Chafic			Combining Slanted-Frame Classifiers for Improved HMM-Based Arabic Handwriting Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Arabic handwriting; word recognition; feature extraction; IFN/ENIT database; hidden Markov models; HMM; neural network; multilayer perceptron; classifier combination	CHARACTER-RECOGNITION; WORD RECOGNITION; SYSTEM	The problem addressed in this study is the offline recognition of handwritten Arabic city names. The names are assumed to belong to a fixed lexicon of about 1,000 entries. A state-of-the-art classical right-left hidden Markov model (HMM)-based recognizer (reference system) using the sliding window approach is developed. The feature set includes both baseline-independent and baseline-dependent features. The analysis of the errors made by the recognizer shows that the inclination, overlap, and shifted positions of diacritical marks are major sources of errors. In this paper, we propose coping with these problems. Our approach relies on the combination of three homogeneous HMM-based classifiers. All classifiers have the same topology as the reference system and differ only in the orientation of the sliding window. We compare three combination schemes of these classifiers at the decision level. Our reported results on the benchmark IFN/ENIT database of Arabic Tunisian city names give a recognition rate higher than 90 percent accuracy and demonstrate the superiority of the neural network-based combination. Our results also show that the combination of classifiers performs better than a single classifier dealing with slant-corrected images and that the approach is robust for a wide range of orientation angles.	[Mohamad, Ramy Al-Hajj] Lebanese Int Univ, Beirut, Lebanon; [Likforman-Sulem, Laurence] TELECOM ParisTech TSI, Dept Signal & Image Proc, F-75013 Paris, France; [Mokbel, Chafic] Univ Balamand, Fac Engn, El Koura, Tripoli, Lebanon	IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; University Balamand	Mohamad, RAH (corresponding author), Lebanese Int Univ, Beirut, Lebanon.	al-hajj@enst.fr; likforman@telecom-paristech.fr; chafic.mokbel@balamand.edu.lb			SARIMA program	SARIMA program	The authors wish to thank the reviewers for their fruitful comments. The authors also wish to acknowledge the SARIMA program (http://www.irisa.fr/sarima) for partially supporting this research.	ABDULKADER A, 2006, P INT WORKSH FRONT H, P42; ALMUALLIM H, 1987, IEEE T PATTERN ANAL, V9, P715, DOI 10.1109/TPAMI.1987.4767970; Amin A, 1998, PATTERN RECOGN, V31, P517, DOI 10.1016/S0031-3203(97)00084-8; Amin A, 1996, PATTERN RECOGN, V29, P663, DOI 10.1016/0031-3203(95)00110-7; [Anonymous], [No title captured]; Arica N, 2002, IEEE T PATTERN ANAL, V24, P801, DOI 10.1109/TPAMI.2002.1008386; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Ben Amara N.E., 2003, IJDAR, V5, P195; Blumenstein M., 2002, Proceedings of Second IASTED International Conference Visualization, Imaging, and Image Processing, P480; Dehghan M, 2001, PATTERN RECOGN, V34, P1057, DOI 10.1016/S0031-3203(00)00051-0; DUIN RPW, 2002, P 16 INT C PATT REC; E-Hajj R, 2005, PROC INT CONF DOC, P893; El-Yacoubi A, 1999, INT SER COMPUTAT INT, P191; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; ELHAJJ R, 2007, P 9 INT C DOC AN REC; ELSHEIKH TS, 1988, SIGNAL PROCESS, V14, P177, DOI 10.1016/0165-1684(88)90005-9; ELSHEIKH TS, 1988, PATTERN RECOGN, V21, P293, DOI 10.1016/0031-3203(88)90042-8; ELWAKIL MS, 1989, PATTERN RECOGN, V22, P97, DOI 10.1016/0031-3203(89)90058-7; FARAH N, 2005, P 13 EUR S ART NEUR; Farooq F, 2005, PROC INT CONF DOC, P267, DOI 10.1109/ICDAR.2005.191; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; HUANG TS, 1995, ENVIRON GEOCHEM HLTH, V17, P1, DOI 10.1007/BF00188624; JIN J, 2005, P IST SPIE EL IM C; Khorsheed MS, 2003, PATTERN RECOGN LETT, V24, P2235, DOI 10.1016/S0167-8655(03)00050-3; Kim HJ, 1997, PATTERN RECOGN, V30, P491, DOI 10.1016/S0031-3203(96)00078-7; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; LEE DS, 1995, P 3 INT C DOC AN REC, P42; Lorigo L, 2005, PROC INT CONF DOC, P605, DOI 10.1109/ICDAR.2005.207; Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102; Luttin J., 2000, P 7 INT WORKSH FRONT, P493; Margner V, 2005, PROC INT CONF DOC, P70, DOI 10.1109/ICDAR.2005.52; MARGNER V, 2006, P C INT FRANC ECR DO; Miled H, 1997, PROC INT CONF DOC, P580, DOI 10.1109/ICDAR.1997.620568; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Mokbel C., 2002, P RES TRENDS SCI TEC; Pechwitz M, 2003, PROC INT CONF DOC, P890; Pechwitz M., 2002, P CIFED, P129; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; TAY YH, 2001, P IEEE REG 10 INT C; Touj S., 2005, IAJIT, V2, P318; Unicode Consortium, 2006, UN STAND VERS 5 0; YARDENI A, 2004, AVENTURELETTRES	43	81	87	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1165	1177		10.1109/TPAMI.2008.136	http://dx.doi.org/10.1109/TPAMI.2008.136			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443916				2022-12-18	WOS:000266188900002
J	Escalera, S; Tax, DMJ; Pujol, O; Radeva, P; Duin, RPW				Escalera, Sergio; Tax, David M. J.; Pujol, Oriol; Radeva, Petia; Duin, Robert P. W.			Subclass problem-dependent design for error-correcting output codes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiclass classification; subclasses; error-correcting output codes; embedding of dichotomizers	ECOC	A common way to model multiclass classification problems is by means of Error-Correcting Output Codes (ECOCs). Given a multiclass problem, the ECOC technique designs a code word for each class, where each position of the code identifies the membership of the class for a given binary problem. A classification decision is obtained by assigning the label of the class with the closest code. One of the main requirements of the ECOC design is that the base classifier is capable of splitting each subgroup of classes from each binary problem. However, we cannot guarantee that a linear classifier model convex regions. Furthermore, nonlinear classifiers also fail to manage some type of surfaces. In this paper, we present a novel strategy to model multiclass classification problems using subclass information in the ECOC framework. Complex problems are solved by splitting the original set of classes into subclasses and embedding the binary problems in a problem-dependent ECOC design. Experimental results show that the proposed splitting procedure yields a better performance when the class overlap or the distribution of the training objects conceal the decision boundaries for the base classifier. The results are even more significant when one has a sufficiently large training size.	[Escalera, Sergio; Pujol, Oriol; Radeva, Petia] Comp Vis Ctr, Barcelona 08193, Spain; [Tax, David M. J.; Duin, Robert P. W.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, ICT Grp, NL-2600 GA Delft, Netherlands	Centre de Visio per Computador (CVC); Delft University of Technology	Escalera, S (corresponding author), Comp Vis Ctr, Campus UAB,Edifici O, Barcelona 08193, Spain.	sergio@maia.ub.es; d.m.j.tax@gmail.com; r.duin@ieee.org	Radeva, Petia/I-3385-2015; Pujol, Oriol/F-7146-2016; Escalera, Sergio/L-2998-2015	Radeva, Petia/0000-0003-0047-5172; Pujol, Oriol/0000-0001-7573-009X; Escalera, Sergio/0000-0003-0617-8873				Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; ASUNCION A, 2007, LEARNING REPOSITORY; CASACUBERTA J, 2004, P 20 C INT SOC PHOT; DAUME H, 2005, J MACHINE LEARNING R, P1551; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263; ESCALERA S, 2008, P INT C COMP VIS THE, V2, P117; Escalera S, 2007, PATTERN RECOGN LETT, V28, P1759, DOI 10.1016/j.patrec.2007.05.007; Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313; FRIEDMAN J, 1998, ANN STAT, V38, P374; Ghani R, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P597, DOI 10.1109/ICDM.2001.989574; HASTIE T, 1998, P NEUR INF PROC SYST, V26, P421; Kapur J., 1992, ENTROPY OPTIMIZATION; Kittler J, 2001, PROC CVPR IEEE, P755; Nilsson N., 1965, LEARNING MACHINES; PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920; Pujol O, 2006, IEEE T PATTERN ANAL, V28, P1007, DOI 10.1109/TPAMI.2006.116; PUJOL O, UNPUB PATTERN RECOGN; SHI J, 2003, J MACHINE LEARNING R, P1415; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Utschick W, 2001, NEURAL COMPUT, V13, P1065, DOI 10.1162/08997660151134334; WINDEATT T, 2003, P INT C VIS INF ENG, P165; ZGU Q, 1998, J INTELL INF SYST, P139; Zhou J, 2005, PROC INT CONF DOC, P484; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	26	81	87	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1041	1054		10.1109/TPAMI.2008.38	http://dx.doi.org/10.1109/TPAMI.2008.38			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421109	Green Published			2022-12-18	WOS:000254872500009
J	Giblin, P; Kimia, BB				Giblin, P; Kimia, BB			A formal classification of 3D medial axis points and their local geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D medial axis; skeleton; shocks; curve skeleton; order of contact; local form; medial topology; ridges; generalized axis	SHAPE	This paper proposes a novel hypergraph skeletal representation for 3D shape based on a formal derivation of the generic structure of its medial axis. By classifying each skeletal point by its order of contact, we show that, generically, the medial axis consists of five types of points, which are then organized into sheets, curves, and points: 1) sheets (manifolds with boundary) which are the locus of bitangent spheres with regular tangency A(1)(2) (A(k)(n) notation means n distinct k-fold tangencies of the sphere of contact, as explained in the text); two types of curves, 2) the intersection curve of three sheets and the locus of centers of tritangent spheres, A(1)(3), and 3) the boundary of sheets, which are the locus of centers of spheres whose radius equals the larger principal curvature, i.e., higher order contact A(3) points; and two types of points, 4) centers of quad-tangent spheres, A(1)(4), and 5) centers of spheres with one regular tangency and one higher order tangency, A(1) A(3). The geometry of the 3D medial axis thus consists of sheets (A(1)(2)) bounded by one type of curve (A(3)) on their free end, which corresponds to ridges on the surface, and attached to two other sheets at another type of curve (A(1)(3)), which support a generalized cylinder description. The A(3) curves can only end in A(1)A(3) points where they must meet an A(1)(3) curve. The A(1)(3) curves meet together in fours at an A(1)(4) point. This formal result leads to a compact representation for 3D shape, referred to as the medial axis hypergraph representation consisting of nodes (A(1)(4) and A(1)A(3) points), links between pairs of nodes (A(1)(3) and A(3) curves) and hyperlinks between groups of links (A(1)(2) sheets). The description of the local geometry at nodes by itself is sufficient to capture qualitative aspects of shapes, in analogy to 2D. We derive a pointwise reconstruction formula to reconstruct a surface from this medial axis hypergraph together with the radius function. Thus, this information completely characterizes 3D shape and lays the theoretical foundation for its use in recognition, morphing, design, and manipulation of shapes.	Univ Liverpool, Dept Math Sci, Liverpool L69 3BX, Merseyside, England; Brown Univ, Div Engn, Providence, RI 02912 USA	University of Liverpool; Brown University	Giblin, P (corresponding author), Univ Liverpool, Dept Math Sci, Liverpool L69 3BX, Merseyside, England.	pjgiblin@liv.ac.uk; kimia@lems.brown.edu						Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7; ANOSHKINA EV, 1994, INT J SHAPE MODELING, V1, P1; Attali D, 1997, COMPUT VIS IMAGE UND, V67, P261, DOI 10.1006/cviu.1997.0536; AUGUST J, 1996, P INT C PATT REC, P1; BELYAEV A, 1997, TOPOLOGICAL MODELING, pCH18; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BOGAEVSKY IA, 1990, ST PETERSBURG LENING, V1, P807; Borgefors G, 1999, PATTERN RECOGN, V32, P1225, DOI 10.1016/S0031-3203(98)00082-X; Bouix S, 2000, LECT NOTES COMPUT SC, V1842, P603; Bruce J.W., 1992, CURVES SINGULARITIES; Bruce JW, 1996, INT J COMPUT VISION, V18, P195, DOI 10.1007/BF00123141; BRUCE JW, 1985, P ROY SOC EDINB A, V101, P163, DOI 10.1017/S0308210500026263; Choi HI, 1997, PAC J MATH, V181, P57, DOI 10.2140/pjm.1997.181.57; Dey TK, 2002, P 7 ACM S SOLID MODE, P356, DOI [10.1145/566282.566333, DOI 10.1145/566282.566333]; EIBER G, 1999, IEEE COMPUTER GR NOV, V19; Foley James D, 1996, COMPUTER GRAPHICS PR, V12110; FOLLEYMARIE F, 2003, THESIS BROWN U PROVI; Giblin P, 2000, MATHEMATICS OF SURFACES IX, P306; GIBLIN P, 2003, IEEE T PATTERN ANAL; Giblin P. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P385, DOI 10.1109/ICCV.1999.791246; GIBLIN PJ, 1998, IN PRESS INT J COMPU; GIBLIN PJ, 1999, IN PRESS IEEE T PATT, P79; GIBLIN PJ, 2002, P 7 EUR C COMP VIS, P718; Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439; Hallinan P. W., 1999, 2 3 DIMENSIONAL PATT; HISADA M, 2002, COMPUT GRAPH FORUM, V21, P1; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEYMARIE F, 2001, P IEEE INT C IMAGE P, P581; Ma CM, 1996, COMPUT VIS IMAGE UND, V64, P420, DOI 10.1006/cviu.1996.0069; Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7; METAXAS D, 1992, COMP GRAPH, V26, P309, DOI 10.1145/142920.134085; MORTENSEN M, 1997, GEOMETRIC MODELING; Okabe A., 2000, PROBABILITY STAT, V2; PORTEOUS IR, 1994, GEOMETRIC DIFFERENTI; Rangarajan A., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P237; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Serra J, 1988, IMAGE ANAL MATH MORP; Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Tek H, 2001, J MATH IMAGING VIS, V14, P211, DOI 10.1023/A:1011229911541; THIRION JP, 1995, COMPUT VIS IMAGE UND, V61, P190, DOI 10.1006/cviu.1995.1015; Zerroug M, 1996, IEEE T PATTERN ANAL, V18, P237, DOI 10.1109/34.485553; 1999, P 7 INT C COMP VIS; [No title captured]; [No title captured]; [No title captured]	49	81	82	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					238	251		10.1109/TPAMI.2004.1262192	http://dx.doi.org/10.1109/TPAMI.2004.1262192			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376898				2022-12-18	WOS:000187954300009
J	Yeung, DS; Wang, XZ				Yeung, DS; Wang, XZ			Improving performance of similarity-based clustering by feature weight learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; similarity-based clustering; transitive closure; fuzziness and nonspecificity; gradient-descent technique	FUZZY-SETS; RULES	Similarity-based clustering is a simple but powerful technique which usually results in a clustering graph for a partitioning of threshold values in the unit interval. The guiding principle of similarity-based clustering is "similar objects are grouped in the same cluster." To judge whether two objects are similar, a similarity measure must be given in advance. The similarity measure presented in this paper is determined in terms of the weighted distance between the features of the objects. Thus, the clustering graph and its performance (which is described by several evaluation indices defined in this paper) will depend on the feature weights. This paper shows that, by using gradient descent technique to learn the feature weights, the clustering performance can be significantly improved. It is also shown that our method helps to reduce the uncertainty (fuzziness and nonspecificity) of the similarity matrix. This enhances the quality of the similarity-based decision making.	Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China; Hebei Univ, Sch Math & Comp Sci, Baoding, Hebei, Peoples R China	Hong Kong Polytechnic University; Hebei University	Yeung, DS (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.		Wang, Xizhao/ABG-7225-2020					[Anonymous], 1995, UCI REPOSITORY MACHI; Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032; Basak J, 1998, PATTERN RECOGN LETT, V19, P997, DOI 10.1016/S0167-8655(98)00083-X; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4; Dubois D, 1997, FUZZY SET SYST, V90, P141, DOI 10.1016/S0165-0114(97)00080-8; Dubois D., 1980, FUZZY SET SYST; DUDA RO, 1973, PATTERN CLASSIFCATIO; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Higashi M., 1983, INT J GEN SYST, V9, P43; Jain A. K., 1989, ALGORITHMS CLUSTERIN; Klir G.J., 1987, FUZZY SETS UNCERTAIN; Nozaki K, 1997, FUZZY SET SYST, V86, P251, DOI 10.1016/0165-0114(95)00413-0; RAO SS, 1985, OPTIMIZATION THEORY; Yeung DS, 1997, FUZZY SET SYST, V88, P299, DOI 10.1016/S0165-0114(96)00052-8; ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1	16	81	105	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					556	561		10.1109/34.993562	http://dx.doi.org/10.1109/34.993562			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100011
J	Ratches, JA; Walters, CP; Buser, RG; Guenther, BD				Ratches, JA; Walters, CP; Buser, RG; Guenther, BD			Aided and automatic target recognition based upon sensory inputs from image forming systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Automatic Target Recognition; ATR; imaging sensors; image processing; aided target acquisition; multisensors sensor fusion; ATR algorithms; performance metrics; databases	OBJECT RECOGNITION; RANGE IMAGES; FLIR SCENES; PERFORMANCE; MODEL; CLUTTER; VISION	This paper systematically reviews 10 years of research that several Army Laboratories conducted in object recognition algorithms, processors, and evaluation techniques. In the military, object recognition is applied to the discrimination of military targets, ranging from human-aided to autonomous operations, and is called Automatic Target Recognition (ATR). The research described here has been concentrated in human-aided target recognition applications, but some attention has been paid to automatic processes. Definitions and performance metrics that have been developed are described along with performance data showing the present state-of-the-art. The effects of signal-to-noise and clutter parameters are indicated in the data. Multisensor fusion and model-based algorithms are discussed as the latest techniques under consideration by the military research community. The results demonstrate that useful performance can be achieved, and tools are evolving to understand and improve the performance under real-world conditions. The referenced research strongly indicates the need for the development of image science, as described in the paper, to support the theoretical underpinnings of ATR.	USA, RES OFF, RES TRIANGLE PK, NC 27709 USA		Ratches, JA (corresponding author), USA, COMMUN ELECT COMMAND, CTR RES DEV & ENGN, NIGHT VIS & ELECT SENSORS DIRECTORATE, FT BELVOIR, VA 22060 USA.		Guenther, Bob/V-9774-2019; Guenther, Bob/AAY-4525-2021	Guenther, Bob/0000-0002-3498-6299				AGGARWAL JK, 1991, MULTISENSOR FUSION C; ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; ARMAN F, 1993, CVGIP-IMAG UNDERSTAN, V58, P33, DOI 10.1006/ciun.1993.1030; AUGUSTYN K, 1992, IEEE T AERO ELEC SYS, V28, P105, DOI 10.1109/7.135437; BARAS JS, 1990, PROCEEDINGS OF THE 29TH IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, P1735, DOI 10.1109/CDC.1990.203918; Bhanu B., 1993, IEEE Aerospace and Electronics Systems Magazine, V8, P15, DOI 10.1109/62.240102; BIBERMAN LM, 1973, PERCEPTION DISPLAYED, P183; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BURT PJ, 1988, MACHINE VISION ALGOR; CHOW S, 1989, P SPIE, V1050; CLARK LG, 1991, OPT ENG, V30, P147, DOI 10.1117/12.55784; CLARK LG, 1993, IEEE P NAECON, V2, P1048; COOPER M, 1997, P SPIE, V3070; FLANNERY DL, 1988, OPT ENG, V27, P309, DOI 10.1117/12.7976675; FLANNERY DL, 1988, APPL OPTICS, V27, P4079, DOI 10.1364/AO.27.004079; Fu K. S., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P303; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P423, DOI 10.1109/34.19040; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9; FUKUNAGA K, 1990, INTRO PATTERN RECOGN; Gersho A., 1991, VECTOR QUANTIZATION; GRENANDER U, UNPUB HILBERT SCHMID; GRENANDER U, 1994, J ROY STAT SOC, V56, P569; HUMMEL JE, 1992, PSYCHOL REV, V99, P480, DOI 10.1037/0033-295X.99.3.480; KITROSSER JH, 1994, J IMAGING SCI TECHN, V38, P311; KRAMER A, 1993, SPIE S AER REM SENS, P29; LANTERMAN AD, 1994, P SOC PHOTO-OPT INS, V2234, P416, DOI 10.1117/12.181039; LANTERMAN AD, 1995, P SOC PHOTO-OPT INS, V2562, P150, DOI 10.1117/12.216951; Lanterman AD, 1996, P SOC PHOTO-OPT INS, V2756, P26, DOI 10.1117/12.241154; MAHESHKUMAR JR, 1996, OPTICAL ENG, V35; MARHAM KC, 1989, IEE P F RAD SIGN P, V136, P13; Marr D., 1982, VISION; Nair D, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P194, DOI 10.1109/ACV.1996.572055; NAIR D, 1996, P 4 EUR C COMP VIS C, V1, P579; NAIR D, 1996, P 13 INT C PATT REC, pA601; NANDHAKUMAR N, 1992, ADV COMPUT, V34, P60; POGGIO T, 1986, PERSPECT COMPUT, P190; Pomerantz J. R., 1981, PERCEPTUAL ORG, P141; POMERANTZ JR, 1978, FORMAL THEORIES VISU; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RATCHES JA, 1976, OPT ENG, V15, P525, DOI 10.1117/12.7972037; REAGO D, 1994, P 19 ARM SCI C ORL F; Rosenfeld A, 1997, COMPUT VIS IMAGE UND, V66, P33, DOI 10.1006/cviu.1997.0602; Roth M W, 1990, IEEE Trans Neural Netw, V1, P28, DOI 10.1109/72.80203; SCHACHTER BJ, 1977, IEEE T SYST MAN CYB, V7, P813; SCHMIEDER DE, 1983, IEEE T AERO ELEC SYS, V19, P622, DOI 10.1109/TAES.1983.309351; SHIRVAIKAR MV, 1992, OPT ENG, V31, P2628, DOI 10.1117/12.60013; VERLY JG, 1992, OPT ENG, V31, P2540, DOI 10.1117/12.60089; WALTERS CP, 1991, OPT ENG, V30, P247, DOI 10.1117/12.55806; WALTERS DKW, 1986, PATTERN RECOGNITION, V2; ZHOU YT, 1992, RES NOTES NEURAL COM, V5; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	52	81	87	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					1004	1019		10.1109/34.615449	http://dx.doi.org/10.1109/34.615449			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985		Green Submitted			2022-12-18	WOS:A1997XX98500006
J	Shen, DG; Ip, HHS				Shen, DG; Ip, HHS			Generalized affine invariant image normalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image normalization; image orientation; invariant image matching; symmetry detection; fold detection; complex moment; rotationally symmetric image	ROTATIONALLY SYMMETRICAL SHAPES; PATTERN-RECOGNITION; PRINCIPAL AXES; ORIENTATIONS; POINTS; TOOL	We provide a generalized image normalization technique which basically solved all problems in image normalization. The orientation of any image can be uniquely defined by at most three non-zero generalized complex (GC) moments. The correctness of our method is demonstrated theoretically as well as in practice by applying them to a number of ''degenerate'' images which have failed other previously reported techniques for image normalization.			Shen, DG (corresponding author), CITY UNIV HONG KONG,DEPT COMP SCI,IMAGE COMP GRP,TAT CHEE AVE,KOWLOON,HONG KONG.		Shen, Dinggang/ABF-6812-2020	Shen, Dinggang/0000-0002-7934-5698; IP, Ho Shing Horace/0000-0002-1509-9002				ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617; ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; CHOU SL, 1991, PATTERN RECOGN LETT, V12, P109, DOI 10.1016/0167-8655(91)90056-R; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; LEOU JJ, 1987, PATTERN RECOGN, V20, P571, DOI 10.1016/0031-3203(87)90028-8; LEU JG, 1989, PATTERN RECOGN LETT, V10, P243, DOI 10.1016/0167-8655(89)90095-0; LIN JC, 1993, PATTERN RECOGN, V26, P485, DOI 10.1016/0031-3203(93)90104-5; LIN JC, 1992, PATTERN RECOGN, V25, P473, DOI 10.1016/0031-3203(92)90046-L; LIN JC, 1994, PATTERN RECOGN LETT, V15, P1081, DOI 10.1016/0167-8655(94)90123-6; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; MITICHE A, 1983, COMPUT VISION GRAPH, V22, P396, DOI 10.1016/0734-189X(83)90084-1; PEI SC, 1995, IMAGE VISION COMPUT, V13, P711, DOI 10.1016/0262-8856(95)98753-G; PEI SC, 1994, PATTERN RECOGN, V27, P1193, DOI 10.1016/0031-3203(94)90005-1; PEI SC, 1992, PATTERN RECOGN, V25, P913, DOI 10.1016/0031-3203(92)90057-P; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2, P289; SHEN D, 1994, P INT S INF THEOR IT, P1043; TAZA A, 1989, IEEE T SYST MAN CYB, V19, P1281, DOI 10.1109/21.44049; TSAI WH, 1991, PATTERN RECOGN, V24, P95, DOI 10.1016/0031-3203(91)90080-O; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0	19	81	84	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					431	440		10.1109/34.589203	http://dx.doi.org/10.1109/34.589203			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300002
J	HEBERT, M; IKEUCHI, K; DELINGETTE, H				HEBERT, M; IKEUCHI, K; DELINGETTE, H			A SPHERICAL REPRESENTATION FOR RECOGNITION OF FREE-FORM SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						OBJECT RECOGNITION; DEFORMABLE SURFACES; RANGE DATA; POSE REGISTRATION; 3D MODELING; SURFACE MODELS; FREE-FORM SURFACES	OBJECT RECOGNITION; RECONSTRUCTION	We introduce a new surface representation for recognizing curved objects. Our approach begins by representing an object by a discrete mesh of points built from range data or from a geometric model of the object. The mesh is computed from the data by deforming a standard shaped mesh, for example, an ellipsoid, until it fits the surface of the object. We define local regularity constraints that the mesh must satisfy. We then define a canonical mapping between the mesh describing the object and a standard spherical mesh. A surface curvature index that is pose-invariant is stored at every node of the mesh. We use this object representation for recognition by comparing the spherical model of a reference object with the model extracted from a new observed scene. We show how the similarity between reference model and observed data can be evaluated and we show how the pose of the reference object in the observed scene can be easily computed using this representation. We present results on real range images which show that this approach to modelling and recognizing 3D objects has three main advantages: 1) First, it is applicable to complex curved surfaces that cannot be handled by conventional techniques. 2) Second, it reduces the recognition problem to the computation of similarity between spherical distributions; in particular, the recognition algorithm does not require any combinatorial search. 3) Finally, even though it is based on a spherical mapping, the approach can handle occlusions and partial views.	INRIA, EPIDAURE PROJECT, SOPHIA ANTIPOLIS, FRANCE	Inria	HEBERT, M (corresponding author), CARNEGIE MELLON UNIV, INST ROBOT, PITTSBURGH, PA 15213 USA.							ALEKSANDROV AD, 1967, TRANSLATION MATH MON; BESL P, 1986, JUN P IEEE C COMP VI, P77; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; DELINGETTE H, 1992, IMAGE VISION COMPUT, V10, P132, DOI 10.1016/0262-8856(92)90065-B; DELINGETTE H, 1992, CMUCS92124 CARN MELL; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FORSYTH DA, 1992, T PATTERN ANAL MACHI, V13, P971; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; IKEUCHI K, 1991, CVGIP-IMAG UNDERSTAN, V53, P154, DOI 10.1016/1049-9660(91)90024-J; IKEUCHI K, 1981, 7TH P INT JOINT C AR, P595; KANG SB, 1991, JUN P IEEE C COMP VI, P580; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Loeb Arthur, 1976, SPACE STRUCTURES; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; TAUBIN G, 1990, THESIS BROWN U; TAUBIN G, 1992, JUN P COMP VIS PATT; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Wenninger M.J., 1971, POLYHEDRON MODELS; Wenninger M.J., 1983, DUAL MODELS	23	81	88	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					681	690		10.1109/34.391410	http://dx.doi.org/10.1109/34.391410			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224		Green Submitted			2022-12-18	WOS:A1995RF22400004
J	KAHN, P; KITCHEN, L; RISEMAN, EM				KAHN, P; KITCHEN, L; RISEMAN, EM			A FAST LINE FINDER FOR VISION-GUIDED ROBOT NAVIGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,COMP VIS RES LAB,AMHERST,MA 01003	University of Massachusetts System; University of Massachusetts Amherst								ARKIN RC, 1987, THESIS U MASSACHUSET; Ballard D.H., 1982, COMPUTER VISION; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; Duda RO, 1973, PATTERN RECOGNITION; KIAHN P, 1987, 8757 U MASS DEP COMP; KITCHEN LJ, 1989, COMPUT VISION GRAPH, V47, P243, DOI 10.1016/S0734-189X(89)80009-X; Ronse C, 1984, CONNECTED COMPONENTS; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; VILNROTTER FM, 1986, IEEE T PATTERN ANAL, V8, P76, DOI 10.1109/TPAMI.1986.4767754	9	81	90	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1098	1102		10.1109/34.61710	http://dx.doi.org/10.1109/34.61710			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700008
J	TSAI, WH; YU, SS				TSAI, WH; YU, SS			ATTRIBUTED STRING MATCHING WITH MERGING FOR SHAPE-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NATL CHIAO TUNG UNIV,MICROELECTR & INFORMAT SCI & TECHNOL RES CTR,HSINCHU 300,TAIWAN	National Yang Ming Chiao Tung University	TSAI, WH (corresponding author), NATIONAL CHIAO TUNG UNIV,DEPT INFORMAT SCI,HSINCHU 300,TAIWAN.							AHO AV, 1972, SIAM J COMPUT, V4; Bahl L., 1975, IEEE T INFORM THEORY, V21; DAVIS LS, 1977, IEEE T COMPUT, V26; Duda R.O., 1973, J ROYAL STAT SOC SER; FREEMAN H, 1974, COMPUT SURVEYS, V6; FREEMAN H, 1977, IEEE COMPUT SOC C PA; Fu K.S., 1974, MATH SCI ENG; FU KS, 1983, IEEE T PATTERN ANAL, V5; FU KS, 1976, IEEE T COMPUT, V25; FU KS, 1975, IEEE T SYST MAN CYBE, V5; FUNG LW, 1975, IEEE T COMPUT, V24; LOWRANCE R, 1975, J ASS COMPUT MAC APR; LU SY, 1977, IEEE T COMPUT, V26; LU SY, 1978, IEEE T SYST MAN CYBE, V8; PAVLIDIS T, 1978, 4TH INT JOINT C PATT; Pavlidis T., 1977, STRUCTURAL PATTERN R; PAVLIDIS T, 1978, COMPUT GRAPHICS IMAG, V7; PERKINS WA, 1978, IEEE T COMPUT, V27; ROSENFELD A, 1973, IEEE T COMPUT, V22; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; TSAI W, 1980, IEEE T SYST MAN CYBE, V10; TSAI WH, 1979, IEEE T SYST MAN CYBE, V9; TSAI WH, 1980, 5TH INT C PATT REC M; TSAI WH, 1981, IEEE COMPUT SOC WORK; TSAI WH, 1983, IEEE T SYST MAN CYBE, V13; WAGNER RA, 1974, J ASS COMPUT MAC JAN; YOU KC, 1979, IEEE T SYST MAN CYBE, V9; YOU KC, 1983, COMPUT GRAPHICS IMAG, V13	28	81	88	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					453	462		10.1109/TPAMI.1985.4767684	http://dx.doi.org/10.1109/TPAMI.1985.4767684			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869283	Green Published			2022-12-18	WOS:A1985ALB6900009
J	Koller, O; Camgoz, NC; Ney, H; Bowden, R				Koller, Oscar; Camgoz, Necati Cihan; Ney, Hermann; Bowden, Richard			Weakly Supervised Learning with Multi-Stream CNN-LSTM-HMMs to Discover Sequential Parallelism in Sign Language Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; Assistive technology; Gesture recognition; Synchronization; Shape; Supervised learning; Speech recognition; Weakly supervised learning; hybrid CNN-LSTM-HMMs; continuous sign language recognition; lip reading; hand shape recognition	HIDDEN MARKOV-MODELS; RECOGNITION; CLASSIFICATION	In this work we present a new approach to the field of weakly supervised learning in the video domain. Our method is relevant to sequence learning problems which can be split up into sub-problems that occur in parallel. Here, we experiment with sign language data. The approach exploits sequence constraints within each independent stream and combines them by explicitly imposing synchronisation points to make use of parallelism that all sub-problems share. We do this with multi-stream HMMs while adding intermediate synchronisation constraints among the streams. We embed powerful CNN-LSTM models in each HMM stream following the hybrid approach. This allows the discovery of attributes which on their own lack sufficient discriminative power to be identified. We apply the approach to the domain of sign language recognition exploiting the sequential parallelism to learn sign language, mouth shape and hand shape classifiers. We evaluate the classifiers on three publicly available benchmark data sets featuring challenging real-life sign language with over 1,000 classes, full sentence based lip-reading and articulated hand shape recognition on a fine-grained hand shape taxonomy featuring over 60 different hand shapes. We clearly outperform the state-of-the-art on all data sets and observe significantly faster convergence using the parallel alignment approach.	[Koller, Oscar] Microsoft, Redmond, WA 98052 USA; [Camgoz, Necati Cihan] Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England; [Camgoz, Necati Cihan; Bowden, Richard] Univ Surrey, CVSSP, Cognit Vis Grp, Comp Vis & Machine Learning, Guildford GU2 7XH, Surrey, England; [Ney, Hermann] Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit Grp, D-52062 Aachen, Germany	Microsoft; University of Surrey; University of Surrey; RWTH Aachen University	Koller, O (corresponding author), Microsoft, Redmond, WA 98052 USA.	koller@cs.rwth-aachen.de; n.camgoz@surrey.ac.uk; ney@cs.rwth-aachen.de; r.bowden@surrey.ac.uk	Koller, Oscar/W-8720-2019; Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020; Camgoz, Necati Cihan/0000-0002-6866-4482	SNSF Sinergia project "Scalable Multimodal Sign Language Technology for Sign Language Learning and Assessment" (SMILE) [CRSII2 160811]; European Union's Horizon2020 research and innovation programme [762021]; EPSRC project ExTOL [EP/R03298X/1]; NVIDIA Corporation; EPSRC [EP/R03298X/1] Funding Source: UKRI	SNSF Sinergia project "Scalable Multimodal Sign Language Technology for Sign Language Learning and Assessment" (SMILE); European Union's Horizon2020 research and innovation programme; EPSRC project ExTOL(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); NVIDIA Corporation; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the SNSF Sinergia project "Scalable Multimodal Sign Language Technology for Sign Language Learning and Assessment" (SMILE) grant agreement number CRSII2 160811, the European Union's Horizon2020 research and innovation programme under grant agreement no. 762021 (Content4All) and the EPSRC project ExTOL (EP/R03298X/1). We would also like to thank NVI-DIA Corporation for their GPU grant.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Bengio S., 2003, P ADV NEUR INF PROC, P1213; Bengio S., 2002, 0226 IDIAPRR; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bisani M, 2008, SPEECH COMMUN, V50, P434, DOI 10.1016/j.specom.2008.01.002; Bourlard H, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P426; Bourlard H., 1993, CONNECTIONIST SPEECH; Bourlard H., 1996, 9607 IDIAPRR, P1; Bouzid Y, 2012, LECT NOTES COMPUT SC, V7383, P229, DOI 10.1007/978-3-642-31534-3_36; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Branicky M. S., 1997, Control Using Logic-Based Switching, P1, DOI 10.1007/BFb0036079; Buehler Patrick, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2961, DOI 10.1109/CVPRW.2009.5206523; Camgoz N. C., 2017, IEEE INT C COMP VIS, P22; Camgoz NC, 2018, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2018.00812; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367; Cooper H, 2009, PROC CVPR IEEE, P2560; Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dupont S., 1997, P EUR, P3; Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; FARHADI A, 2006, P CVPR, P1471; Forster J., 2013, P 4 WORKSH SPEECH LA, P41; Forster J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1911; Forster J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785; Forster J, 2013, LECT NOTES COMPUT SC, V7887, P89; Ghahramani Z, 1996, ADV NEUR IN, V8, P472; Gillick L., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P532, DOI 10.1109/ICASSP.1989.266481; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Jiangwen Deng, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P126; Kelly D, 2011, IEEE T SYST MAN CY B, V41, P526, DOI 10.1109/TSMCB.2010.2065802; Koller O., 2013, IEEE INT C AUT FAC G, P1, DOI [10.1109/FG.2013.6553777, DOI 10.1109/FG.2013.6553777]; Koller O, 2016, P BRIT MACH VIS C 20; Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3; Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364; Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412; Koller O, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P477, DOI 10.1109/ICCVW.2015.69; Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013; Koller O, 2014, LECT NOTES COMPUT SC, V8689, P281, DOI 10.1007/978-3-319-10590-1_19; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Liu SB, 2011, PROC CVPR IEEE, P913, DOI 10.1109/CVPR.2011.5995334; Liwicki M, 2007, PROC INT CONF DOC, P367; Ma JY, 2000, LECT NOTES COMPUT SC, V1948, P582; Nayak Sunita, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2583, DOI 10.1109/CVPRW.2009.5206599; Neti C., 2000, IDIAPRR352000, P1; Nishida N, 2016, LECT NOTES COMPUT SC, V9431, P682, DOI 10.1007/978-3-319-29451-3_54; Nock HJ, 2002, COGNITIVE SCI, V26, P283, DOI 10.1207/s15516709cog2603_5; Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421; PALLETT DS, 1990, INT CONF ACOUST SPEE, P97, DOI 10.1109/ICASSP.1990.115546; Petrocchi S, 2018, CHILD FAM SOC WORK, V23, P239, DOI 10.1111/cfs.12410; Pivac L., 2015, ONLINE DICT NZ SIGN; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; Quack T, 2007, IEEE I CONF COMP VIS, P612; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Rybach David, 2011, P IEEE AUT SPEECH RE; Schmidt C., 2013, P INT S SIGN LANG TR; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Senior A, 2014, P ICASSP, P5639; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Sutton V., 2008, SIGNWRITING BASICS I; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Theodorakis S, 2009, INT CONF ACOUST SPEE, P1601, DOI 10.1109/ICASSP.2009.4959905; Tomlinson MJ, 1996, INT CONF ACOUST SPEE, P821, DOI 10.1109/ICASSP.1996.543247; VARGA AP, 1990, INT CONF ACOUST SPEE, P845, DOI 10.1109/ICASSP.1990.115970; Vogler C, 2003, LECT NOTES ARTIF INT, V2915, P247; Vogler C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P116, DOI 10.1109/ICCV.1999.791206; von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x; Wellekens C.J., 1998, P INT C SPOK LANG PR, P2991; Williams R.J., 1995, BACKPROPAGATION THEO, V1, P433; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P275, DOI 10.1109/ICCV.2001.937529; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253; Zhu X, 2008, 1530 U WISCONSIN MAD	76	80	81	3	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2306	2320		10.1109/TPAMI.2019.2911077	http://dx.doi.org/10.1109/TPAMI.2019.2911077			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30990421	Green Submitted			2022-12-18	WOS:000557354900016
J	Keysers, D; Deselaers, T; Rowley, HA; Wang, LL; Carbune, V				Keysers, Daniel; Deselaers, Thomas; Rowley, Henry A.; Wang, Li-Lun; Carbune, Victor			Multi-Language Online Handwriting Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Online handwriting recognition; handwriting recognition	SYSTEM	We describe Google's online handwriting recognition system that currently supports 22 scripts and 97 languages. The system's focus is on fast, high-accuracy text entry for mobile, touch-enabled devices. We use a combination of state-of-the-art components and combine them with novel additions in a flexible framework. This architecture allows us to easily transfer improvements between languages and scripts. This made it possible to build recognizers for languages that, to the best of our knowledge, are not handled by any other online handwriting recognition system. The approach also enabled us to use the same architecture both on very powerful machines for recognition in the cloud as well as on mobile devices with more limited computational power by changing some of the settings of the system. In this paper we give a general overview of the system architecture and the novel components, such as unified time-and position-based input interpretation, trainable segmentation, minimum-error rate training for feature combination, and a cascade of pruning strategies. We present experimental results for different setups. The system is currently publicly available in several Google products, for example in Google Translate and as an input method for Android devices.	[Keysers, Daniel; Deselaers, Thomas; Carbune, Victor] Google Switzerland, CH-8002 Zurich, Switzerland; [Rowley, Henry A.; Wang, Li-Lun] Google Inc, Mountain View, CA 94043 USA	Google Incorporated; Google Incorporated	Keysers, D (corresponding author), Google Switzerland, CH-8002 Zurich, Switzerland.	keysers@google.com; deselaers@google.com; har@google.com; llwang@google.com; vcarbune@google.com	Rowley, Henry/R-8544-2019					Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308; Bai ZL, 2005, PROC INT CONF DOC, P262; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bharath A, 2007, PROC INT CONF DOC, P506; Biadsy F, 2011, INT J PATTERN RECOGN, V25, P1009, DOI 10.1142/S0218001411008956; Brants T., 2007, P 2007 JOINT C EMP M, P858; Brown P. F., 1993, Computational Linguistics, V19, P263; Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271; Delaye A, 2013, PATTERN RECOGN, V46, P117, DOI 10.1016/j.patcog.2012.07.015; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deselaers T, 2015, IEEE T HUM-MACH SYST, V45, P263, DOI 10.1109/THMS.2014.2365723; GOLDBERG D, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P80; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; JACOBSON G, 1989, ANN IEEE SYMP FOUND, P549, DOI 10.1109/SFCS.1989.63533; Jaeger S., 2003, International Journal on Document Analysis and Recognition, V6, P75, DOI 10.1007/s10032-003-0107-y; Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559; Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153; Kim J., 2014, HDB DOCUMENT IMAGE P, P887, DOI DOI 10.1007/978-0-85729-859-1; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182; Liwicki M, 2005, PROC INT CONF DOC, P956, DOI 10.1109/ICDAR.2005.132; Liwicki M, 2011, MACH VISION APPL, V22, P39, DOI 10.1007/s00138-009-0208-9; Macherey Wolfgang, 2008, P EMNLP, P725; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; Pal U, 2003, PATTERN RECOGN LETT, V24, P261, DOI 10.1016/S0167-8655(02)00240-4; Pittman JA, 2007, COMPUTER, V40, P49, DOI 10.1109/MC.2007.314; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rabiner L., 1993, FUNDAMENTALS SPEECH; Ratzlaff EH, 2003, PROC INT CONF DOC, P623; Rowley HA, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P36, DOI 10.1109/IWFHR.2002.1030881; Schenk J., 2006, P 10 INT WORKSH FRON, P619; Seni G, 1996, IEEE T PATTERN ANAL, V18, P757, DOI 10.1109/34.506798; Simard PY, 2003, PROC INT CONF DOC, P958; Stolcke A., 2002, P INT C SPOK LANG PR, P257; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Vanderkam Dan, 2013, TECH REP; YAEGER L, 1998, AAAI AI MAGAZINE; Zhou XD, 2007, PROC INT CONF DOC, P48	41	80	81	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1180	1194		10.1109/TPAMI.2016.2572693	http://dx.doi.org/10.1109/TPAMI.2016.2572693			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27244718				2022-12-18	WOS:000401091200010
J	Ristin, M; Guillaumin, M; Gall, J; Van Gool, L				Ristin, Marko; Guillaumin, Matthieu; Gall, Juergen; Van Gool, Luc			Incremental Learning of Random Forests for Large-Scale Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Incremental learning; random forests; large-scale image classification		Large image datasets such as ImageNet or open-ended photo websites like Flickr are revealing new challenges to image classification that were not apparent in smaller, fixed sets. In particular, the efficient handling of dynamically growing datasets, where not only the amount of training data but also the number of classes increases over time, is a relatively unexplored problem. In this challenging setting, we study how two variants of Random Forests (RF) perform under four strategies to incorporate new classes while avoiding to retrain the RFs from scratch. The various strategies account for different trade-offs between classification accuracy and computational efficiency. In our extensive experiments, we show that both RF variants, one based on Nearest Class Mean classifiers and the other on SVMs, outperform conventional RFs and are well suited for incrementally learning new classes. In particular, we show that RFs initially trained with just 10 classes can be extended to 1,000 classes with an acceptable loss of accuracy compared to training from the full data and with great computational savings compared to retraining for each new batch of classes.	[Ristin, Marko; Guillaumin, Matthieu; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland; [Gall, Juergen] Univ Bonn, Comp Vis Grp, Bonn, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Bonn	Ristin, M; Guillaumin, M; Van Gool, L (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland.; Gall, J (corresponding author), Univ Bonn, Comp Vis Grp, Bonn, Germany.	ristin@vision.ee.ethz.ch; guillaumin@vision.ee.ethz.ch; gall@iai.uni-bonn.de; vangool@vision.ee.ethz.ch			CTI project [15769.1 PFES-ES]; DFG Emmy Noether program [GA 1927/1-1]; DFG project [GA 1927/2-2 FOR 1505]; Toyota	CTI project; DFG Emmy Noether program(German Research Foundation (DFG)); DFG project(German Research Foundation (DFG)); Toyota	The authors acknowledge financial support from the CTI project (15769.1 PFES-ES), DFG Emmy Noether program (GA 1927/1-1), DFG project (GA 1927/2-2 FOR 1505) and Toyota.	Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146; Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799; Bengio Samy, 2010, ADV NEURAL INFORM PR, V1, P163, DOI [10.5555/2997189.2997208, DOI 10.5555/2997189.2997208]; Berg A., 2010, LARGE SCALE VISUAL R; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Deng Jia, 2011, ADV NEURAL INFORM PR, V1, P567, DOI [10.5555/2986459.2986523, DOI 10.5555/2986459.2986523]; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228; Guillaumin M, 2014, INT J COMPUT VISION, V110, P328, DOI 10.1007/s11263-014-0713-9; Guillaumin M, 2012, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2012.6248055; Hasan M, 2014, PROC CVPR IEEE, P796, DOI 10.1109/CVPR.2014.107; Jia D, 2012, PROC CVPR IEEE, P3450, DOI 10.1109/CVPR.2012.6248086; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuzborskij I., 2013, N N 1 MULTICLASS TRA; Kuzborskij I, 2013, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2013.431; Lakshminarayanan B., 2014, P ADV NEUR INF PROC, P3140; Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477; Liu BY, 2013, PROC CVPR IEEE, P843, DOI 10.1109/CVPR.2013.114; Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Razavi N, 2011, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2011.5995441; Ristin M, 2014, PROC CVPR IEEE, P3654, DOI 10.1109/CVPR.2014.467; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Saffari A., 2009, P OLCV; Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Schulter S, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.128; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; Wang A, 2009, P 16 IEEE INT C IM P, P1433; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yao A, 2012, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2012.6248060; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Yeh T., 2007, P IEEE INT C COMP VI, P1	44	80	87	4	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					490	503		10.1109/TPAMI.2015.2459678	http://dx.doi.org/10.1109/TPAMI.2015.2459678			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046493				2022-12-18	WOS:000370738900006
J	Yang, Y; Saleemi, I; Shah, M				Yang, Yang; Saleemi, Imran; Shah, Mubarak			Discovering Motion Primitives for Unsupervised Grouping and One-Shot Learning of Human Actions, Gestures, and Expressions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human actions; one-shot learning; unsupervised clustering; gestures; facial expressions; action representation; action recognition; motion primitives; motion patterns; histogram of motion primitives; motion primitives strings; Hidden Markov model	RECOGNITION	This paper proposes a novel representation of articulated human actions and gestures and facial expressions. The main goals of the proposed approach are: 1) to enable recognition using very few examples, i.e., one or k-shot learning, and 2) meaningful organization of unlabeled datasets by unsupervised clustering. Our proposed representation is obtained by automatically discovering high-level subactions or motion primitives, by hierarchical clustering of observed optical flow in four-dimensional, spatial, and motion flow space. The completely unsupervised proposed method, in contrast to state-of-the-art representations like bag of video words, provides a meaningful representation conducive to visual interpretation and textual labeling. Each primitive action depicts an atomic subaction, like directional motion of limb or torso, and is represented by a mixture of four-dimensional Gaussian distributions. For one-shot and k-shot learning, the sequence of primitive labels discovered in a test video are labeled using KL divergence, and can then be represented as a string and matched against similar strings of training videos. The same sequence can also be collapsed into a histogram of primitives or be used to learn a Hidden Markov model to represent classes. We have performed extensive experiments on recognition by one and k-shot learning as well as unsupervised action clustering on six human actions and gesture datasets, a composite dataset, and a database of facial expressions. These experiments confirm the validity and discriminative nature of the proposed representation.	[Yang, Yang; Saleemi, Imran; Shah, Mubarak] Univ Cent Florida, Dept Elect Engn & Comp Sci EECS, Comp Vis Lab, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Yang, Y (corresponding author), Univ Cent Florida, Dept Elect Engn & Comp Sci EECS, Comp Vis Lab, 4000 Cent Florida Blvd,Bldg 116,Suite 245, Orlando, FL 32816 USA.	yyang@eecs.ucf.edu; imran@eecs.ucf.edu; shah@eecs.ucf.edu	Yang, Yang/U-5084-2017; yang, yang/HGT-7999-2022; Cataldi, Antonio/AAM-7411-2021	Yang, Yang/0000-0002-4410-6021; Shah, Mubarak/0000-0001-6172-5572				Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008; [Anonymous], 2009, BMVC 2009 BRIT MACH; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], P IEEE; Bobick A., 1996, P 3 IEEE WORKSH APPL; Chen C., 2009, P IEEE WORKSH MOT VI; Dalal N., 2005, HISTOGRAMS ORIENTED; DARRELL T, 1993, P IEEE C COMP VIS PA; DAVIS J, 1997, P IEEE C COMP VIS PA; Dollar P., 2005, P 2 IEEE JOINT INT W; EFROS AA, 2003, P 9 IEEE INT C COMP; Fathi A., 2008, P IEEE C COMP VIS PA; Filipovych R., 2008, P IEEE C COMP VIS PA; Gilbert A., 2008, P EUR C COMP VIS; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hoey J., 2000, P IEEE C COMP VIS PA; Ikizler-Cinbis N., 2010, P EUR C COMP VIS; Jhuang H., 2007, P 11 IEEE INT C COMP; Ke Y., 2005, P 10 IEEE INT C COMP; Ke Y., 2007, P 11 IEEE INT C COMP; Klaser A., 2010, RR7373 INRIA GREN RH; Kovashka A., 2010, P IEEE C COMP VIS PA; Kratz L., 2009, P IEEE C COMP VIS PA; Kuehne H., 2011, P IEEE INT C COMP VI; Le QV, 2011, PROC CVPR IEEE; Lin Z., 2009, P 12 IEEE INT C COMP; Liu J., 2008, P IEEE C COMP VIS PA; Liu J., 2009, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Oreifej O., 2010, P IEEE C COMP VIS PA; PARAMESWARAN V, 2003, P IEEE C COMP VIS PA; Robertson N., 2005, P 10 IEEE INT C COMP; Rodriguez M.D., 2008, P 2008 IEEE C COMP V; Saleemi I., 2010, P IEEE C COMP VIS PA; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Singh V., 2011, P IEEE INT C COMP VI; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Thurau C., 2008, P IEEE C COMP VIS PA; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tran KN, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.64; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang H, 2011, PROC CVPR IEEE; Wang X., 2007, P IEEE C COMP VIS PA; Wang Y., 2007, P 2 C HUM MOT UND MO; Weinland D., 2007, P 11 IEEE INT C COMP; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Yacoob Y., 1998, P 6 IEEE INT C COMP; Yilmaz A., 2005, P 10 IEEE INT C COMP; Yilmaz A., 2005, P IEEE C COMP VIS PA; ZELNIKMANOR L, 2001, P IEEE C COMP VIS PA	51	80	85	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1635	1648		10.1109/TPAMI.2012.253	http://dx.doi.org/10.1109/TPAMI.2012.253			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681992				2022-12-18	WOS:000319060600008
J	Biswas, S; Bowyer, KW; Flynn, PJ				Biswas, Soma; Bowyer, Kevin W.; Flynn, Patrick J.			Multidimensional Scaling for Matching Low-Resolution Face Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; low-resolution matching; multidimensional scaling; iterative majorization	SUPERRESOLUTION; RECOGNITION; ILLUMINATION; EIGENFACES	Face recognition performance degrades considerably when the input images are of Low Resolution (LR), as is often the case for images taken by surveillance cameras or from a large distance. In this paper, we propose a novel approach for matching low-resolution probe images with higher resolution gallery images, which are often available during enrollment, using Multidimensional Scaling (MDS). The ideal scenario is when both the probe and gallery images are of high enough resolution to discriminate across different subjects. The proposed method simultaneously embeds the low-resolution probe images and the high-resolution gallery images in a common space such that the distance between them in the transformed space approximates the distance had both the images been of high resolution. The two mappings are learned simultaneously from high-resolution training images using an iterative majorization algorithm. Extensive evaluation of the proposed approach on the Multi-PIE data set with probe image resolution as low as 8 x 6 pixels illustrates the usefulness of the method. We show that the proposed approach improves the matching performance significantly as compared to performing matching in the low-resolution domain or using super-resolution techniques to obtain a higher resolution test image prior to recognition. Experiments on low-resolution surveillance images from the Surveillance Cameras Face Database further highlight the effectiveness of the approach.	[Biswas, Soma; Bowyer, Kevin W.; Flynn, Patrick J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	University of Notre Dame	Biswas, S (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, 384 Fitzpatrick Hall Engn, Notre Dame, IN 46556 USA.	sbiswas@nd.edu; kwb@nd.edu; flynn@nd.edu	Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X; Bowyer, Kevin/0000-0002-7562-4390	US Army [W91CRB-08-C-0093]; Intelligence Advanced Research Project Activity under Army Research Laboratory [W911NF-10-2-0067]	US Army(United States Department of DefenseUnited States Army); Intelligence Advanced Research Project Activity under Army Research Laboratory	This work is supported by the Biometrics Task Force and the Technical Support Working Group through US Army contract W91CRB-08-C-0093 and by the Intelligence Advanced Research Project Activity under Army Research Laboratory cooperative agreement W911NF-10-2-0067. Portions of the research in this paper use the SCface database of facial images. Credit is hereby given to the University of Zagreb, Faculty of Electrical Engineering and Computing, for providing the database of facial images.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Arandjelovic O., 2007, P IEEE INT C COMP VI; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Baker S., 2000, P 4 INT C AUT FAC GE; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Biswas S., 2010, P IEEE INT C BIOM TH; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346; Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043; Daugman J. G., 1996, P CARDTECH SECURETEC, P223; Elad M, 1999, IEEE T PATTERN ANAL, V21, P817, DOI 10.1109/34.790425; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Gross R., 2007, VELEST USERS GUIDE S; Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513; Hennings-Yeomans P.H., 2008, 2008 IEEE C COMP VIS, P1; Heo J, 2005, LECT NOTES COMPUT SC, V3656, P1089; Jia K, 2005, IEEE I CONF COMP VIS, P1683; Lee SW, 2006, PATTERN RECOGN, V39, P1809, DOI 10.1016/j.patcog.2006.04.033; Leeuw J. d., 1977, APPL CONVEX ANAL MUL, P133; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu W, 2005, PROC CVPR IEEE, P478; Phillips PJ, 2005, PROC CVPR IEEE, P947; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WEBB AR, 1995, PATTERN RECOGN, V28, P753, DOI 10.1016/0031-3203(94)00135-9; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou SK, 2007, IEEE T PATTERN ANAL, V29, P230, DOI 10.1109/TPAMI.2007.25	32	80	84	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					2019	2030		10.1109/TPAMI.2011.278	http://dx.doi.org/10.1109/TPAMI.2011.278			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22201067				2022-12-18	WOS:000307522700012
J	Ferradans, S; Bertalmio, M; Provenzi, E; Caselles, V				Ferradans, Sira; Bertalmio, Marcelo; Provenzi, Edoardo; Caselles, Vicent			An Analysis of Visual Adaptation and Contrast Perception for Tone Mapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						High-dynamic range images; tone mapping; Naka-Rushton equation; Weber-Fechner contrast	LIGHT ADAPTATION; COLOR CORRECTION; REPRODUCTION; RETINEX; VISION	Tone Mapping is the problem of compressing the range of a High-Dynamic Range image so that it can be displayed in a Low-Dynamic Range screen, without losing or introducing novel details: The final image should produce in the observer a sensation as close as possible to the perception produced by the real-world scene. We propose a tone mapping operator with two stages. The first stage is a global method that implements visual adaptation, based on experiments on human perception, in particular we point out the importance of cone saturation. The second stage performs local contrast enhancement, based on a variational model inspired by color vision phenomenology. We evaluate this method with a metric validated by psychophysical experiments and, in terms of this metric, our method compares very well with the state of the art.	[Ferradans, Sira; Bertalmio, Marcelo; Provenzi, Edoardo; Caselles, Vicent] Univ Pompeu Fabra, Dept Tecnol Informac & Comunicac, Barcelona 08018, Spain	Pompeu Fabra University	Ferradans, S (corresponding author), Univ Pompeu Fabra, Dept Tecnol Informac & Comunicac, C Tanger 122-140, Barcelona 08018, Spain.	sira.ferradans@upf.edu; marcelo.bertalmio@upf.edu; edoardo.provenzi@upf.edu; vicent.caselles@upf.edu	Bertalmío, Marcelo/A-4341-2012	Bertalmio, Marcelo/0000-0002-1023-8325; PROVENZI, Edoardo/0000-0002-1476-1236	PNPGC [MTM2006-14836]; Generalitat de Catalunya [2009 SGR 773]; Ministerio de Ciencia y Tecnologia de Espana	PNPGC; Generalitat de Catalunya(Generalitat de Catalunya); Ministerio de Ciencia y Tecnologia de Espana(Ministry of Science and Innovation, Spain (MICINN)Spanish Government)	The authors are extremely grateful to T. Aydin, who has provided them with the quality metric results, and to the reviewers, which have contributed a great deal to the improvement of the manuscript and the proposed method. The authors acknowledge partial support by PNPGC project, reference MTM2006-14836. They acknowledge partial support by GRC reference 2009 SGR 773 funded by the Generalitat de Catalunya. V. Caselles also acknowledges "ICREA Academia" prize by the Generalitat de Catalunya. E. Provenzi acknowledges the Ramon y Cajal fellowship by Ministerio de Ciencia y Tecnologia de Espana.	Ashikhmin M., 2002, EUR WORKSH REND, P1; Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668; BERTALMIO M, 2009, INT J COMPUTER VISIO; Bertalmio M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777; Boynton GM, 2002, CURR BIOL, V12, pR838, DOI 10.1016/S0960-9822(02)01347-7; Cadik M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003; Chiu K., 1993, Proceedings Graphics Interface '93, P245; Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689; Dunn FA, 2007, NATURE, V449, P603, DOI 10.1038/nature06150; DURAND F, 2002, P 29 ANN C COMP GRAP, P257, DOI DOI 10.1145/566570.566574; Fattal R, 2002, ACM T GRAPHIC, V21, P249; Ferwerda JA, 1996, P 23 ANN C COMP GRAP, P249, DOI [10.1145/237170.237262, DOI 10.1145/237170.237262]; Haro G, 2006, INT J COMPUT VISION, V69, P109, DOI 10.1007/s11263-006-6858-4; Hubel David H, 1995, EYE BRAIN VISION, P6; Irawan P., 2005, P EUR S REND, P231; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Keener J, 2008, MATH PHYSL; Kim MH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531333; Krawczyk G, 2005, COMPUT GRAPH FORUM, V24, P635, DOI 10.1111/j.1467-8659.2005.00888.x; Kuang JT, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265958; Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003; Kunkel T., 2010, P 7 S APPL PERC GRAH, V17; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233; Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242; Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936; MacMillan N. A., 2005, DETECTION THEORY USE; Mantiuk R, 2009, COMPUT GRAPH FORUM, V28, P193, DOI 10.1111/j.1467-8659.2009.01358.x; Mantiuk R., 2006, ACM T APPL PERCEPTIO, V3, P286, DOI [DOI 10.1145/1166087.1166095, 10.1145/1166087.1166095]; Palma-Amestoy R, 2009, IEEE T PATTERN ANAL, V31, P458, DOI 10.1109/TPAMI.2008.86; Palmer S.E., 1999, VISION SCI PHOTONS P; Pardo A, 2003, IEEE T IMAGE PROCESS, V12, P639, DOI 10.1109/TIP.2003.812373; Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810; Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613; Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9; Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575; Reinhard E., 2010, HIGH DYNAMIC RANGE I, V2nd, P145; Schlick C., 1994, PHOTOREALISTIC RENDE, P7; SHAPLEY R, 1984, VISUAL ADAPTATION RE, V3, P263; SHEVELL SK, 1977, VISION RES, V17, P427, DOI 10.1016/0042-6989(77)90035-9; STEVENS SS, 1961, SCIENCE, V133, P80, DOI 10.1126/science.133.3446.80; STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162; TAMBURRINO D, 2008, P SPIE, V6817; TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554; Tumblin J, 1999, P ACM SIGGRAPH, P83; VALETON JM, 1983, VISION RES, V23, P1539, DOI 10.1016/0042-6989(83)90167-0; Wade AR, 2002, J NEUROSCI, V22, P8148; Ward G., 1994, GRAPHICS GEMS, VIV, P415, DOI DOI 10.1016/B978-0-12-336156-1.50054-9; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; Yoshida A, 2005, PROC SPIE, V5666, P192, DOI 10.1117/12.587782	50	80	82	2	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2002	2012		10.1109/TPAMI.2011.46	http://dx.doi.org/10.1109/TPAMI.2011.46			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21383397	Green Accepted			2022-12-18	WOS:000293969000008
J	Chum, O; Matas, J				Chum, Ondrej; Matas, Jiri			Large-Scale Discovery of Spatially Related Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						minHash; image clustering; image retrieval; bag of words		We propose a randomized data mining method that finds clusters of spatially overlapping images. The core of the method relies on the min-Hash algorithm for fast detection of pairs of images with spatial overlap, the so-called cluster seeds. The seeds are then used as visual queries to obtain clusters which are formed as transitive closures of sets of partially overlapping images that include the seed. We show that the probability of finding a seed for an image cluster rapidly increases with the size of the cluster. The properties and performance of the algorithm are demonstrated on data sets with 10(4), 10(5), and 5 x 10(6) images. The speed of the method depends on the size of the database and the number of clusters. The first stage of seed generation is close to linear for databases sizes up to approximately 2(34) approximate to 10(10) images. On a single 2.4 GHz PC, the clustering process took only 24 minutes for a standard database of more than 100,000 images, i.e., only 0.014 seconds per image.	[Chum, Ondrej; Matas, Jiri] Czech Tech Univ, Fac Elect Engn, Prague 12135, Czech Republic	Czech Technical University Prague	Chum, O (corresponding author), Czech Tech Univ, Fac Elect Engn, Karlovo Namesti 13, Prague 12135, Czech Republic.	chum@cmp.felk.cvut.cz; matas@cmp.felk.cvut.cz	, Matas/AAW-3282-2020; Chum, Ondrej/F-5262-2015	Chum, Ondrej/0000-0001-7042-1810	Czech Science Foundation [102/09/P423]; Czech Government [MSM6840770038]; EC [ICT-215078 DIPLECS]	Czech Science Foundation(Grant Agency of the Czech Republic); Czech Government; EC(European CommissionEuropean Commission Joint Research Centre)	The authors would like to thank to Michal Perd'och for discussions and help, and James Philbin for providing the data and his implementation of the spatial verification [6]. Ondrej Chum was supported by Czech Science Foundation Project 102/09/P423, and Jiri Matas was supported by Czech Government grant MSM6840770038 and by EC project ICT-215078 DIPLECS.	[Anonymous], P IEEE C COMP VIS PA; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BRODER AZ, 1998, P SEQS SEQ 91; Chum O., 2007, P INT C IM VID RETR; Chum O., 2004, P AS C COMP VIS; Chum O., 2005, P IEEE C COMP VIS PA; Chum O., 2007, P IEEE INT C COMP VI; Chum Ondrej, 2008, P BRIT MACH VIS C, P1; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P IEEE C COMP VIS PA; FRAUNDORFER F, 2007, P IEEE C COMP VIS PA; Hofmann T, 1999, P ACM SIGIR; INDYK P, 1998, P S THEOR COMP; LI X, 2008, P EUR C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Nister D., 2006, P 2006 IEEE COMP SOC; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; PERDOCH M, 2009, P IEEE C VIS PATT RE; Philbin J., 2008, P IND C COMP VIS GRA; Philbin J, 2007, CVPR; QUACK T, 2008, P INT C IM VID RETR; QUACK T, 2006, P INT C IM VID RETR; Russell B. C., 2006, P IEEE C COMP VIS PA; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; SIVIC J, 2004, P IEEE C COMP VIS PA; Sivic J, 2003, P IEEE INT C COMP VI; SIVIC J, 2005, 2005005 AI MIT; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; [No title captured]; [No title captured]	31	80	86	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					371	377		10.1109/TPAMI.2009.166	http://dx.doi.org/10.1109/TPAMI.2009.166			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075465	Green Submitted			2022-12-18	WOS:000272741500014
J	Wang, S; Wang, Y; Jin, M; Gu, XFD; Samaras, D				Wang, Sen; Wang, Yang; Jin, Miao; Gu, Xianfeng David; Samaras, Dimitris			Conformal geometry and its applications on 3D shape matching, recognition, and stitching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representations; shape matching; conformal geometry; 3D face recognition	REPRESENTATION; REGISTRATION; PARAMETERIZATION	Three-dimensional shape matching is a fundamental issue in computer vision with many applications such as shape registration, 3D object recognition, and classification. However, shape matching with noise, occlusion, and clutter is a challenging problem. In this paper, we analyze a family of quasi-conformal maps including harmonic maps, conformal maps, and least-squares conformal maps with regards to 3D shape matching. As a result, we propose a novel and computationally efficient shape matching framework by using least-squares conformal maps. According to conformal geometry theory, each 3D surface with disk topology can be mapped to a 2D domain through a global optimization and the resulting map is a diffeomorphism, i.e., one-to-one and onto. This allows us to simplify the 3D shape-matching problem to a 2D image-matching problem, by comparing the resulting 2D parametric maps, which are stable, insensitive to resolution changes and robust to occlusion, and noise. Therefore, highly accurate and efficient 3D shape matching algorithms can be achieved by using the above three parametric maps. Finally, the robustness of least-squares conformal maps is evaluated and analyzed comprehensively in 3D shape matching with occlusion, noise, and resolution variation. In order to further demonstrate the performance of our proposed method, we also conduct a series of experiments on two computer vision applications, i.e., 3D face recognition and 3D nonrigid surface alignment and stitching.	SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Wang, S (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	swang@cs.sunysb.edu; yangwang@cs.sunysb.edu; mjin@cs.sunysb.edu; gu@cs.sunysb.edu; samaras@cs.sunysb.edu		Gu, Xianfeng/0000-0001-8226-5851	NCRR NIH HHS [RR13995] Funding Source: Medline; NATIONAL CENTER FOR RESEARCH RESOURCES [R21RR013995] Funding Source: NIH RePORTER	NCRR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))		Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296; ALLIEZ P, 2002, P SIGGRAPH 02, P347; ANDERSON G. D., 1997, CONFORMAL INVARINANT; Athitsos V, 2004, PROC CVPR IEEE, P268; BOTSCH M, 2000, P VIS MOD VIS AK VER, P129; Brown B., 2004, P S 3 DIM DAT PROC V; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819; Desbrun M, 2002, COMPUT GRAPH FORUM, V21, P209, DOI 10.1111/1467-8659.00580; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Eck M, 1995, P 22 ANN C COMP GRAP, P173, DOI DOI 10.1145/218380.218440; EELLS J, 1964, AM J MATH, V86, P109, DOI 10.2307/2373037; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9; FROME A, 2004, P EUR C COMP VIS MAY; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; GU X, 2004, IEEE T MED IMAGING, V23; GU X, 2004, P C MED IM COMP COMP; Haker S, 2000, IEEE T VIS COMPUT GR, V6, P181, DOI 10.1109/2945.856998; Hormann K., 2000, CURVE SURFACE DESIGN, P153; Huber D, 2004, PROC CVPR IEEE, P82; HURDAL MK, 2000, NEUROIMAGE, V11, pS467; Johnson A., 1997, THESIS CARNEGIE MELL; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kazhdan M., 2003, P S GEOM PROCESS, P156; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Levy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590; Liepa P., 2003, Symposium on Geometry Processing, P200; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220; ONeill B., 2006, ELEMENTARY DIFFERENT, DOI 10.1090/chel/341/01; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Ruiz-Correa S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1126; RUSINKIEWICZ S, 2002, P SIGGRAPH, P438; Schoen R., 1997, P C LECT NOT GEOM TO, VII; Sharon E, 2004, PROC CVPR IEEE, P350; Sheffer A, 2001, ENG COMPUT-GERMANY, V17, P326, DOI 10.1007/PL00013391; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Sun XM, 2004, ANN IEEE CONF COMPUT, P286, DOI 10.1109/CCC.2004.1313851; Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; WANG S, 2006, P C COMP VIS PATT RE, V2, P2453; Wang Y, 2005, IEEE I CONF COMP VIS, P388; Wang YL, 2005, IEEE I CONF COMP VIS, P1061; Wang YL, 2005, IEEE I CONF COMP VIS, P527; Wyngaerd J. V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P301, DOI 10.1109/ICCV.1999.791234; ZHANG D, 1999, P IEEE COMP SOC C CO, V2, P524	52	80	91	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1209	1220		10.1109/TPAMI.2007.1050	http://dx.doi.org/10.1109/TPAMI.2007.1050			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496378				2022-12-18	WOS:000246395300008
J	Xiao, JJ; Shah, M				Xiao, JJ; Shah, M			Motion layer extraction in the presence of occlusion using graph cuts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						layer-based motion segmentation; video analysis; graph cuts; level set representation; occlusion order constraint	SEGMENTATION; TRACKING	Extracting layers from video is very important for video representation, analysis, compression, and synthesis. Assuming that a scene can be approximately described by multiple planar regions, this paper describes a robust and novel approach to automatically extract a set of affine or projective transformations induced by these regions, detect the occlusion pixels over multiple consecutive frames, and segment the scene into several motion layers. First, after determining a number of seed regions using correspondences in two frames, we expand the seed regions and reject the outliers employing the graph cuts method integrated with level set representation. Next, these initial regions are merged into several initial layers according to the motion similarity. Third, an occlusion order constraint on multiple frames is explored, which enforces that the occlusion area increases with the temporal order in a short period and effectively maintains segmentation consistency over multiple consecutive frames. Then, the correct layer segmentation is obtained by using a graph cuts algorithm and the occlusions between the overlapping layers are explicitly determined. Several experimental results are demonstrated to show that our approach is effective and robust.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Xiao, JJ (corresponding author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.	jxiao@cs.ucf.edu; shah@cs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AYER S, 1995, P INT C COMP VIS; BERGEN L, 2000, P IEEE C COMP VIS PA; BIRCHFIELD S, 1999, P INT C COMP VIS; BOYKOV V, 2003, P INT C COMP VIS; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Dahlhaus E., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P241, DOI 10.1145/129712.129736; GIACCONE P, 1998, P BRIT MACH VIS C; ISHIKAWA H, 1998, P EUR C COMP VIS; Kang S. B., 2001, P IEEE C COMP VIS PA; KE Q, 2002, P IEEE WORKSH MOT VI; KE Q, 2001, P IEEE C COMP VIS PA; KHAN S, 2001, P IEEE C COMP VIS PA; KOLMOGOROV V, 2002, P EUR C COMP VIS; KOLMOGOROV V, 2001, P INT C COMP VIS; KWATRA V, 2003, P ACM SIGGRAPH; Osher S, 2003, LEVEL SET METHODS DY; Patras I, 2001, IEEE T PATTERN ANAL, V23, P326, DOI 10.1109/34.910886; Sethian J. A., 1999, LEVEL SET METHODS FA; Shi J, 1994, P IEEE C COMP VIS PA; SHI J, 1998, P INT C COMP VIS; Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; TORR PHS, 1993, P SPIE SENS FUS BOST, V6, P432; VIDAL R, 2004, P EUR C COMP VIS; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WEISS Y, 1997, P IEEE C COMP VIS PA; WILLS J, 2003, P IEEE C COMP VIS PA; XIAO J, 2003, P INT C COMP VIS; XIAO J, 2004, P IEEE C COMP VIS PA; XU N, 2003, P IEEE C COMP VIS PA; ZELNIKMANOR L, 1999, P INT C COMP VIS; ZHOU Y, 2003, P INT C COMP VIS	34	80	86	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1644	1659		10.1109/TPAMI.2005.202	http://dx.doi.org/10.1109/TPAMI.2005.202			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16237998				2022-12-18	WOS:000231086700011
J	Plankers, R; Fua, P				Plankers, R; Fua, P			Articulated soft objects for multiview shape and motion capture	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						body tracking; shape and motion; multiple views; implicit surfaces	TRACKING	We develop a framework for 3D shape and motion recovery of articulated deformable objects. We propose a formalism that incorporates the use of implicit surfaces into earlier robotics approaches that were designed to handle articulated structures. We demonstrate its effectiveness for human body modeling from synchronized video sequences. Our method is both robust and generic. It could easily be applied to other shape and motion recovery problems.	Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Plankers, R (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland.	Pascal.Fua@epfl.ch	Fua, Pascal/H-3928-2011	Fua, Pascal/0000-0002-6702-9970				Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; BITTAR E, 1995, COMPUT GRAPH FORUM, V14, pC457, DOI 10.1111/j.1467-8659.1995.cgf143_0457.x; Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290; BREGLER C, 1998, P C COMP VIS PATT RE; CHOO K, 2001, P INT C COMP VIS JUL; COVELL M, 2000, P C COMP VIS PATT RE; CRAIG JJ, 1989, INTRO ROBOTICS MECH, pCH5; DAVIS L, 1999, P 3 INT WORKSH COOP; DAVISON AJ, 2001, P EUR WORKSH COMP AN; Delamarre Q, 2001, COMPUT VIS IMAGE UND, V81, P328, DOI 10.1006/cviu.2000.0892; DESBRUN M, 1995, P SIGGRAPH 95, P287; DEUTSCHER J, 2000, P C COMP VIS PATT RE; DOUROS L, 1999, P ICCV WORKSH MOD PE; DRUMMOND T, 2001, P INT C COMP VIS JUL; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Fua P, 1997, INT J COMPUT VISION, V24, P19, DOI 10.1023/A:1007918123901; GAVRILA D, 1999, COMPUTER VISION IMAG, V73; HILTON A, 1999, P COMP AN MAY; KAKADIARIS I, 1995, P INT C COMP VIS; KAKADIARIS IA, 1996, P C COMP VIS PATT RE; LEE WS, 2000, P EUR COMP GRAPH FOR, pC1; MAUREL W, 2001, COMPUT GRAPH-UK, V24, P203; MOESLUND TB, 2001, P COMP VIS IM UND MA, V81; Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622; Plankers R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P394, DOI 10.1109/ICCV.2001.937545; PLANKERS R, 2002, P EUR C COMP VIS MAY; PLANKERS R, 2001, THESIS EPFL LAUSANNE; SAITO H, 1999, P C COMP VIS PATT RE; SMINCHISESCU C, 2001, P C COMP VIS PATT RE; SUN W, 1999, P EUR WORKSH COMP AN; THALMANN D, 1996, P COMP GRAPH INT JUN; Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758	32	80	87	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1182	1187		10.1109/TPAMI.2003.1227995	http://dx.doi.org/10.1109/TPAMI.2003.1227995			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX		Green Submitted			2022-12-18	WOS:000184977300014
J	Salah, AA; Alpaydin, E; Akarun, L				Salah, AA; Alpaydin, E; Akarun, L			A selective attention-based method for visual pattern recognition with application to handwritten digit recognition and face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	23rd Annual Conference of the Cognitive-Science-Society	AUG, 2001	EDINBURGH, SCOTLAND	Cognit Sci Soc		selective attention; Markov models; feature integration; face recognition; handwritten digit recognition	EYE-MOVEMENTS; PERCEPTION; MODEL; MECHANISMS	Parallel pattern recognition requires great computational resources; it is NP-complete. From an engineering point of view it is desirable to achieve good performance with limited resources. For this purpose, we develop a serial model for visual pattern recognition based on the primate selective attention mechanism. The idea in selective attention is that not all parts of an image give us information. If we can attend only to the relevant parts, we can recognize the image more quickly and using less resources. We simulate the primitive, bottom-up attentive level of the human visual system with a saliency scheme and the more complex, top-down, temporally sequential associative level with observable Markov models. In between, there is a neural network that analyses image parts and generates posterior probabilities as observations to the Markov model. We test our model first on a handwritten numeral recognition problem and then apply it to a more complex face recognition problem. Our results indicate the promise of this approach in complicated vision applications.	Bogazici Univ, Dept Comp Engn, Perceptual Intelligence Lab, TR-80815 Bebek, Istanbul, Turkey	Bogazici University	Salah, AA (corresponding author), Bogazici Univ, Dept Comp Engn, Perceptual Intelligence Lab, TR-80815 Bebek, Istanbul, Turkey.	salah@boun.edu.tr; alpaydin@boun.edu.tr; akarun@boun.edu.tr	Salah, Albert Ali/E-5820-2013; Akarun, Lale/AAR-7734-2020; ALPAYDIN, ETHEM/E-6127-2013; Salah, Albert Ali/ABH-5561-2020	Salah, Albert Ali/0000-0001-6342-428X; ALPAYDIN, ETHEM/0000-0001-7506-0321; Salah, Albert Ali/0000-0001-6342-428X; Akarun, Lale/0000-0002-8813-8084				Alpaydin E, 1996, ADV NEUR IN, V8, P771; Crick F., 1990, Seminars in the Neurosciences, V2, P263; CULHANE SM, 1992, P 11 INT C PATT REC, V1, P36; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; DIDDAY RL, 1975, INT J MAN MACH STUD, V7, P547, DOI 10.1016/S0020-7373(75)80032-0; Foster DH, 1998, P ROY SOC B-BIOL SCI, V265, P1605, DOI 10.1098/rspb.1998.0478; FUKUSHIMA K, 1987, APPL OPTICS, V26, P4985, DOI 10.1364/AO.26.004985; Grossberg S, 2000, TRENDS COGN SCI, V4, P233, DOI 10.1016/S1364-6613(00)01464-9; HACISALIHZADE SS, 1992, IEEE T SYST MAN CYB, V22, P474, DOI 10.1109/21.155948; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677; ITTI L, 1999, SPIE HUMAN VISION 4, V3644, P373; JAGERSAND M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P195, DOI 10.1109/ICCV.1995.466786; Keller JG, 1999, PATTERN ANAL APPL, V2, P251, DOI 10.1007/s100440050033; Klein RM, 2000, TRENDS COGN SCI, V4, P138, DOI 10.1016/S1364-6613(00)01452-2; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Legge GE, 1997, PSYCHOL REV, V104, P524, DOI 10.1037/0033-295X.104.3.524; Newman C. B. D., 1998, UCI REPOSITORY MACHI; NOTON D, 1971, SCI AM, V224, P34; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520; RABINER LR, 1989, P IEEE, V17; Rao R. P., 1997, 971 U ROCH COMP SCI; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; RIMEY RD, 1990, TR327 U ROCH COMP SC; Rybak IA, 1998, VISION RES, V38, P2387, DOI 10.1016/S0042-6989(98)00020-0; SALAH AA, 2001, FBECMPE03200112 BOG; Schill K, 2001, J ELECTRON IMAGING, V10, P152, DOI 10.1117/1.1329627; Smeraldi F, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P163, DOI 10.1109/ICIP.1998.999007; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Ungerleider L.G., 1982, ANAL VISUAL BEHAV; 1994, OLIVETTI RES LAB DAT	38	80	94	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					420	425		10.1109/34.990146	http://dx.doi.org/10.1109/34.990146			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	524WM		Green Submitted			2022-12-18	WOS:000174035900011
J	Patras, I; Hendriks, EA; Lagendijk, RL				Patras, I; Hendriks, EA; Lagendijk, RL			Video segmentation by MAP labeling of watershed segments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov Random Fields; motion-based segmentation; region labeling; watershed segmentation; motion estimation	MOTION SEGMENTATION; FIELDS; SEQUENCE; MODELS; FLOW	This paper addresses the problem of spatio-temporal segmentation of video sequences. An initial intensity segmentation method (watershed segmentation) provides a number of initial segments which are subsequently labeled, with a known number of labels, according to motion information. The label field is modeled as a Markov Random Field where the statistical spatial and temporal interactions are expressed on the basis of the initial watershed segments. The labeling criterion is the maximization of the conditional a posteriori probability of the label field given the motion hypotheses, the estimate of the label field of the previous frame, and the image intensities. For the optimization, an iterative motion estimation-labeling algorithm is proposed and experimental results are presented.	Delft Univ Technol, Informat & Commun Theory Grp, NL-2600 GA Delft, Netherlands	Delft University of Technology	Patras, I (corresponding author), Delft Univ Technol, Informat & Commun Theory Grp, POB 5031, NL-2600 GA Delft, Netherlands.			Patras, Ioannis/0000-0003-3913-4738				BESAG J, 1986, J R STAT SOC B, V48, P259; Beucher S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1928; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; BRADY N, 1996, P IEEE INT C IM PROC; CHANG MM, 1994, P IEEE INT C AC SPEE; Diehl N., 1991, Signal Processing: Image Communication, V3, P23, DOI 10.1016/0923-5965(91)90028-Z; DUBOIS E, 1993, MOTION ANAL IMAGE SE, P53; Dufaux F., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P306, DOI 10.1109/ICIP.1995.529707; FABLET R, 1999, P IEEE INT C IM PROC; Gelgon M, 2000, PATTERN RECOGN, V33, P725, DOI 10.1016/S0031-3203(99)00083-7; Gelgon M, 1997, PROC CVPR IEEE, P514, DOI 10.1109/CVPR.1997.609374; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; KONRAD J, 1996, P IEEE INT C IM PROC, V1, P909; Li S., 1995, MARKOV RANDOM FIELD, P1; MOSCHENI F, 1995, P INT C AC SPEECH SI; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; PATRAS I, 2000, ICT0001 DELFT U TECH; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; SHALEMBIER P, 1992, P SPIE VISUAL COMM I, V1818, P620; Stiller C, 1997, IEEE T IMAGE PROCESS, V6, P234, DOI 10.1109/83.551695; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; Wang DM, 1998, IEEE T CIRC SYST VID, V8, P539, DOI 10.1109/76.718501; Wang SH, 1998, BIOTECHNOL LETT, V20, P9, DOI 10.1023/A:1005362626457; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092	28	80	94	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					326	332		10.1109/34.910886	http://dx.doi.org/10.1109/34.910886			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW		Green Submitted			2022-12-18	WOS:000167276200010
J	Chuang, JH; Tsai, CH; Ko, MC				Chuang, JH; Tsai, CH; Ko, MC			Skeletonization of three-dimensional object using generalized potential field	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D skeletonization; medial axis transform; potential field; distance function; 3D thinning	MEDIAL AXIS TRANSFORM; THINNING ALGORITHM; SHAPE-DESCRIPTION; AUTOMATIC COARSE; COMPUTATION	The medial axis transform (MAT) is a skeletal representation of an object which has been shown to be useful in interrogation, animation, finite element mesh generation, path planning, and feature recognition. In this paper, the potential-based skeletonization approach for 2D MAT [1], which identifies object skeleton as potential valleys using a Newtonian potential model in place of the distance function, is generalized to three dimensions. The generalized potential functions given in [2], which decay faster with distance than the Newtonian potential, is used for the 3D case. The efficiency of the proposed approach results from the fact that these functions and their gradients can be obtained in closed forms for polyhedral surfaces. According to the simulation results, the skeletons obtained with the proposed approach are closely related to the corresponding MAT skeletons. While the medial axis (surface) is 2D in general for a 3D object, the potential valleys, being one-dimensional, form a more realistic skeleton. Other desirable attributes of the algorithm include stability against perturbations of the object boundary, the flexibility to obtain partial skeleton directly, and low time complexity.	Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 30056, Taiwan	National Yang Ming Chiao Tung University	Chuang, JH (corresponding author), Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 30056, Taiwan.							AHUJA N, 1978, IEEE T COMPUT, V27, P375, DOI 10.1109/TC.1978.1675110; Ahuja N, 1997, IEEE T PATTERN ANAL, V19, P169, DOI 10.1109/34.574801; ATTALI D, 1994, P INT C PATT REC OCT; BINFORD T, 1971, P IEEE SYST SCI CYB; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Brandt J. W., 1991, Journal of Visual Communication and Image Representation, V2, P151, DOI 10.1016/1047-3203(91)90005-Z; BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7; Chuang JH, 1998, IEEE T ROBOTIC AUTOM, V14, P778, DOI 10.1109/70.720353; CHUANG JH, 1992, P INT C CONTR ROB AU; DORST L, 1986, P 8 INT C PATT REC P, P286; DUTTA D, 1993, J MECH DESIGN, V115, P87, DOI 10.1115/1.2919330; GURSOY HN, 1992, ENG COMPUT, V8, P179, DOI 10.1007/BF01194321; GURSOY HN, 1992, ENG COMPUT, V8, P121, DOI 10.1007/BF01200364; Kirkpatrick D. G., 1979, 20th Annual Symposium of Foundations of Computer Science, P18, DOI 10.1109/SFCS.1979.15; Latombe J.-C, 2012, ROBOT MOTION PLANNIN, V124; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; LEVENDER D, 1992, IEEE COMPUT GRAPH, V12, P69; Ma CM, 1996, COMPUT VIS IMAGE UND, V64, P420, DOI 10.1006/cviu.1996.0069; MA CM, 1995, PATTERN RECOGN LETT, V16, P83, DOI 10.1016/0167-8655(94)00063-9; MEYER F, 1989, SIGNAL PROCESS, V16, P335, DOI 10.1016/0165-1684(89)90030-3; MEYER F, 1985, COMPUTER ARCHITECTUR; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; MONTANVERT A, 1986, P 8 INT C PATT REC, P430; NACKMAN LR, 1982, COMPUT VISION GRAPH, V20, P43, DOI 10.1016/0146-664X(82)90072-7; PRINZ FB, 1989, EDRC242489 CARN MELL; REDDY JM, 1995, COMPUT AIDED DESIGN, V27, P677, DOI 10.1016/0010-4485(94)00025-9; ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1; Sheehy DJ, 1996, IEEE T VIS COMPUT GR, V2, P62, DOI 10.1109/2945.489387; Sherbrooke EC, 1996, IEEE T VIS COMPUT GR, V2, P44, DOI 10.1109/2945.489386; TAKAHASHI O, 1989, IEEE T ROBOTIC AUTOM, V5, P143, DOI 10.1109/70.88035; TSAO YF, 1981, COMPUT VISION GRAPH, V17, P315, DOI 10.1016/0146-664X(81)90011-3; TURK G, 1992, COMP GRAPH, V26, P55, DOI 10.1145/142920.134008; TURKIYYAH G, 1990, R90188 CARN MELL U D; VERMEER PJ, 1994, THESIS PURDUE U; WILTON DR, 1984, IEEE T ANTENN PROPAG, V32, P276, DOI 10.1109/TAP.1984.1143304; XIA Y, 1989, IEEE T PATTERN ANAL, V11, P1076, DOI 10.1109/34.42838; [No title captured]	39	80	100	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1241	1251						11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200003
J	Sohn, SY				Sohn, SY			Meta analysis of classification algorithms for pattern recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; meta analysis; legit model; multivariate statistics	DECISION TREES; RELIABILITY; SELECTION	Various classification algorithms became available due to a surge of interdisciplinary research interests in the areas of data mining and knowledge discovery. We develop a statistical meta-model which compares the classification performances of several algorithms in terms of data characteristics. This empirical model is expected to aid decision making processes of finding the best classification tool in the sense of providing the minimum classification error among alternatives.	Yonsei Univ, Dept Comp Sci & Ind Syst Engn, Seoul 120749, South Korea	Yonsei University	Sohn, SY (corresponding author), Yonsei Univ, Dept Comp Sci & Ind Syst Engn, Shichondong 134, Seoul 120749, South Korea.	sohns@bubble.yonsei.ac.kr	Sohn, So Young/G-8043-2012					AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; Breiman L., 2017, CLASSIFICATION REGRE; BRILL FZ, 1992, IEEE T NEURAL NETWOR, V3, P324, DOI 10.1109/72.125874; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Buntine W., 1992, Statistics and Computing, V2, P63, DOI 10.1007/BF01889584; DRAPER BA, 1994, IEEE T PATTERN ANAL, V16, P888, DOI 10.1109/34.310684; Efron Bradley, 1982, JACKKNIFE BOOTSTRAP, V38, DOI [10.1137/1.9781611970319, DOI 10.1137/1.9781611970319]; FAYYAD U, 1997, TUT NOT 1 PAC AS C K; GNANADESIKAN R, 1995, J CLASSIF, V12, P113, DOI 10.1007/BF01202271; Hosmer DW, 1989, APPL LOGISTIC REGRES; JOACHIMSTHALER EA, 1988, DECISION SCI, V19, P322, DOI 10.1111/j.1540-5915.1988.tb00270.x; JUNG BJ, 1997, IE INTERFACES, V10, P47; Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P284; LIVARINEN J, 1994, P INT C ART NEUR NET, V1; LOWE D, 1991, IEEE T PATTERN ANAL, V13, P355, DOI 10.1109/34.88570; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Michie Donald, 1994, MACHINE LEARNING NEU, P2; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SHAUDYS FE, 1992, P INT JOINT C NEUR N; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P197, DOI 10.1142/S0218001488000145; SMITH JE, 1994, P IEE C GEN ALG IM P, P193; Sohn SY, 1997, COMPUT IND ENG, V33, P741, DOI 10.1016/S0360-8352(97)00236-2; SOHN SY, 1994, NAV RES LOG, V41, P707, DOI 10.1002/1520-6750(199410)41:6<707::AID-NAV3220410603>3.0.CO;2-R; Sohn SY, 1996, IIE TRANS, V28, P995; Sohn SY, 1997, IEEE T RELIAB, V46, P122, DOI 10.1109/24.589937; SOHN SY, 1997, UNPUB VARIABLE SELEC; SOHN SY, 1992, J STAT COMPUT SIM, V40, P247; SOHN SY, 1997, FAC MAINT ENG P SEOU, P157; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Wasserman PD, 1993, ADV METHODS NEURAL C; WONG MA, 1983, J ROY STAT SOC B MET, V45, P362	31	80	83	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1137	1144						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100003
J	Shen, DG; Ip, HHS; Cheung, KKT; Teoh, EK				Shen, DG; Ip, HHS; Cheung, KKT; Teoh, EK			Symmetry detection by generalized complex (GC) moments: A close-form solution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symmetry detection; reflectional and rotational symmetry; symmetric axis; generalized complex (GC) moments; fold number; fold axes; rotationally symmetric image; reflection-symmetric image	PRINCIPAL AXES; SHAPES; ORIENTATIONS; NORMALIZATION; TOOL	This paper presents a unified method for detecting both reflection-symmetry and rotation-symmetry of 2D images based on an identical set of features, i.e., the first three nonzero generalized complex (GC) moments. This method is theoretically guaranteed to detect all the axes of symmetries of every 2D image, if more nonzero GC moments are used in the feature set. Furthermore, we establish the relationship between reflectional symmetry and rotational symmetry in an image, which can be used to check the correctness of symmetry detection. This method has been demonstrated experimentally using more than 200 images.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Kowloon, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; City University of Hong Kong	Shen, DG (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	edgshen@ntu.edu.sg; cship@cityu.edu.hk; ktcheung@cs.cityu.edu.hk; eekteoh@ntu.edu.sg	Shen, Dinggang/ABF-6812-2020	Shen, Dinggang/0000-0002-7934-5698; IP, Ho Shing Horace/0000-0002-1509-9002				ATALLAH MJ, 1985, IEEE T COMPUTERS, V34; BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714; BLAKE A, 1993, P INT C PATT REC, P724; CHOU SL, 1991, PATTERN RECOGN LETT, V12, P109, DOI 10.1016/0167-8655(91)90056-R; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Ip H. H. S., 1997, P 2 INT C VIS INF SY; LABONTE F, 1993, P 4 INT C COMP VIS, P258; LIN JC, 1993, PATTERN RECOGN, V26, P485, DOI 10.1016/0031-3203(93)90104-5; LIN JC, 1994, PATTERN RECOGN LETT, V15, P1081, DOI 10.1016/0167-8655(94)90123-6; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; MAROLA G, 1989, COMPUT VISION GRAPH, V46, P179, DOI 10.1016/0734-189X(89)90168-0; MASUDA T, 1993, PATTERN RECOGNITION, V26; Miller W., 1972, SYMMETRY GROUPS THEI; OH WG, 1988, P INT C PATT REC, P1043; PEI SC, 1992, PATTERN RECOGN, V25, P913, DOI 10.1016/0031-3203(92)90057-P; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; REISFELD D, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P117, DOI 10.1109/ICPR.1992.201521; Shen D, 1996, ELECTRON LETT, V32, P1873, DOI 10.1049/el:19961249; SHEN D, UNPUB IEEE T PATTERN; Shen DG, 1999, PATTERN RECOGN, V32, P151, DOI 10.1016/S0031-3203(98)00137-X; Shen DG, 1997, IEEE T PATTERN ANAL, V19, P431, DOI 10.1109/34.589203; SUN C, 1997, IEEE T PATTERN ANAL, V19; SUN CM, 1995, PATTERN RECOGN LETT, V16, P987, DOI 10.1016/0167-8655(95)00049-M; Sun CM, 1997, OPT ENG, V36, P1073, DOI 10.1117/1.601290; TSAI WH, 1991, PATTERN RECOGN, V24, P95, DOI 10.1016/0031-3203(91)90080-O; WELY H, 1952, SYMMETRY; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZIELKE T, 1993, CVGIP-IMAG UNDERSTAN, V58, P177, DOI 10.1006/ciun.1993.1037	28	80	85	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1999	21	5					466	476		10.1109/34.765657	http://dx.doi.org/10.1109/34.765657			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	194LK					2022-12-18	WOS:000080194900007
J	Khaneja, N; Miller, MI; Grenander, U				Khaneja, N; Miller, MI; Grenander, U			Dynamic programming generation of curves on brain surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						brain mapping; deformable templates; curve generation		Dynamic programming algorithms are presented for automated generation of length minimizing geodesics and curves of; extremal curvature on the neocortex of the macaque and the Visible Human. Probabilistic models of curve variation are constructed in terms of the variability in speed, curvature, and torsion in the Frenet representation.	Harvard Univ, Div Appl Sci, Cambridge, MA 02138 USA; Johns Hopkins Univ, Ctr Imaging Sci, Dept Biomed Engn, Baltimore, MD 21218 USA; Johns Hopkins Univ, Ctr Imaging Sci, Dept Elect & Comp Engn, Baltimore, MD 21218 USA; Brown Univ, Div Appl Math, Providence, RI 02912 USA	Harvard University; Johns Hopkins University; Johns Hopkins University; Brown University	Khaneja, N (corresponding author), Harvard Univ, Div Appl Sci, Cambridge, MA 02138 USA.		Miller, Michael I./A-3213-2010					Bertsekas D.P., 1987, DYNAMIC PROGRAMMING; CLAUDIO M, 1994, GRAPH MODEL IM PROC, V56, P182; COOPER DB, 1981, IMAGE MODELING, P63; ELION JL, 1991, J AM COLL CARDIOLOGY, V17; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Hamann B., 1993, Computing (Supplementum), P139, DOI 10.1007/978-3-7091-6916-2_10; JOSHI SC, 1995, P SPIES 1995 GEOM ME; KENT JT, 1996, MONOGRAPH U LEEDS; KHANEJA N, 1996, THESIS WASHINGTON U; Miller M, 1997, Stat Methods Med Res, V6, P267, DOI 10.1191/096228097673360480; ONeill B., 1966, ELEMENTARY DIFFERENT; PORTEOUS IR, 1994, GEOMETRIC DIFFERENTI; THIRION JP, 1996, CVGIP-GRAPH MODEL IM, P503; Thompson PM, 1996, J NEUROSCI, V16, P4261; Van Essen DC, 1998, P NATL ACAD SCI USA, V95, P788, DOI 10.1073/pnas.95.3.788; VanEssen DC, 1997, NATURE, V385, P313, DOI 10.1038/385313a0; VANESSEN DC, 1980, J COMP NEUROL, V191, P255, DOI 10.1002/cne.901910208; VANESSEN DC, J NEUROSCIENCE, P7079; WELKER W, 1990, CEREB CORTEX, V83, P3	19	80	81	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1260	1265		10.1109/34.730559	http://dx.doi.org/10.1109/34.730559			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100011
J	Leonardis, A; Jaklic, A; Solina, F				Leonardis, A; Jaklic, A; Solina, F			Superquadrics for segmenting and modeling range data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						range image segmentation; recover-and-select paradigm; recovery of volumetric models; superquadrics	PERCEPTUAL ORGANIZATION; GLOBAL DEFORMATIONS; PARAMETRIC MODELS; IMAGES; SEGMENTATION; SHAPE; FORM	We present a novel approach to reliable and efficient recovery of part-descriptions in terms of superquadric models from range data. We show that superquadrics can directly be recovered from unsegmented data, thus avoiding any presegmentation steps (e.g., in terms of surfaces). The approach is based on the recover-and-select paradigm [10]. We present several experiments on real and synthetic range images, where we demonstrate the stability of the results with respect to viewpoint and noise.			Leonardis, A (corresponding author), UNIV LJUBLJANA,FAC COMP & INFORMAT SCI,COMP VIS LAB,TRZASKA C 25,LJUBLJANA 1001,SLOVENIA.		Solina, Franc/F-7411-2011	Solina, Franc/0000-0002-9268-6825				Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; Cochocki A., 1993, NEURAL NETWORKS OPTI; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; GUPTA A, 1993, CVGIP-IMAG UNDERSTAN, V58, P302, DOI 10.1006/ciun.1993.1044; JAKLIC A, THESIS U LJUBLJANA; JAKLIC A, 1996, LRV962 U LJUBLJANA C; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; LEONARDIS A, 1992, P 2 EUR C COMP VISIO, P653; LEONARDIS A, 1993, THESIS U LJUBLJANA; Marr D., 1982, VISION; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237; [No title captured]	22	80	85	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1289	1295		10.1109/34.632988	http://dx.doi.org/10.1109/34.632988			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500010
J	Amit, Y; Kong, A				Amit, Y; Kong, A			Graphical templates for model registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graphical templates; decomposable graphs; model registration; dynamic programming; image matching		A new method of model registration is proposed using graphical templates. A graph of landmarks is chosen in the template image. All possible candidates for these landmarks are found in the data image using local operators. A dynamic programming algorithm on decomposable subgraphs of the template graph finds the optimal match to a subset of the candidate points in polynomial time. This combination of local operators to describe points of interest/landmarks and a graph to describe their geometric orientation in the plane, yields fast and precise matches of the model to the data, with no initialization required.			Amit, Y (corresponding author), UNIV CHICAGO, DEPT STAT, CHICAGO, IL 60637 USA.			Kong, Augustine/0000-0001-8193-5438				AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; AMIT Y, 1994, SIAM J SCI COMPUT, V15, P207, DOI 10.1137/0915014; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; BARZOHAR M, 1993, P ARPA IU WORKSH WAS; Berge C., 1973, GRAPHS HYPERGRAPHS; BERTELE U, 1972, MATH SCI ENG SERIES, V91; Bookstein FL., 1986, STAT SCI, V1, P181, DOI [DOI 10.1214/SS/1177013696, 10.1214/ss/1177013696]; Bookstein L., 1991, MORPHOMETRIC TOOLS L; BOOKSTEIN LF, 1987, P 10 INT C INF PROC; Cootes TF, 1992, P BMVC, P267; COOTES TF, 1992, 3RD P BR MACH VIS C, P9; DARROCH JN, 1980, ANN STAT, V8, P522, DOI 10.1214/aos/1176345006; GRENANDER U, 1970, ADV COMPUTERS, V10; HABERMAN SJ, 1974, IMS MONOGRAPHS; Haralick R.M., 1992, COMPUTER ROBOT VISIO, V1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1981, IMAGE SEQUENCE ANAL; JIN Z, 1988, TIRM88036 TUR I; Meinguet J., 1979, J APPL MATH PHYS, V30, P292; MILLER MI, 1993, P NATL ACAD SCI USA, V90, P11944, DOI 10.1073/pnas.90.24.11944; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; OGAWA H, 1986, PATTERN RECOGN, V19, P35, DOI 10.1016/0031-3203(86)90029-4; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Petrocelli R. R., 1992, Proceedings of Computer in Cardiology 1992 (Cat. No.92CH3259-9), P207, DOI 10.1109/CIC.1992.269410; PHILLIPS DB, 1993, TR9302 IMP COLL DEP; Rose D. J., 1976, SIAM Journal on Computing, V5, P266, DOI 10.1137/0205021; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8; Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836	28	80	87	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					225	236		10.1109/34.485529	http://dx.doi.org/10.1109/34.485529			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500001
J	CALIFANO, A; MOHAN, R				CALIFANO, A; MOHAN, R			MULTIDIMENSIONAL INDEXING FOR RECOGNIZING VISUAL SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							OBJECT RECOGNITION	This paper introduces an analytical framework for studying some properties of model acquisition and recognition techniques based on indexing. The goal is to demonstrate that several problems previously associated with the approach can be attributed to the low dimensionality of invariants used. These include limited index selectivity, excessive accumulation of votes in the look-up table buckets, and excessive sensitivity to quantization parameters. Theoretical results demonstrate that using high-dimensional, highly descriptive global invariants produces better results in terms of accuracy, false positive suppression, and computation time. A practical example of high-dimensional global invariants is introduced and used to implement a 2-D shape acquisition/recognition system. The acquisition/recognition system is based on a two-step table look-up mechanism. First, local curve descriptors are obtained by correlating image contour information at short range. Then, seven-dimensional global invariants are computed by correlating triplets of local curve descriptors at longer range. This experimental system is meant to illustrate the behavior of a high-dimensional indexing scheme. Indeed, its performance shows good agreement with the analytical model with respect to database size, fault tolerance, and recognition speed. Model acquisition time is linear to cubic in the number of object features. Object recognition time is constant to linear in the number of models in the database and linear to cubic in the number of features in the image. The system has been tested extensively, with more than 250 arbitrary shapes in the database. Unsupervised shape and subpart acquisition is demonstrated.			CALIFANO, A (corresponding author), IBM CORP,THOMAS J WATSON RES CTR,EXPLORATORY COMP VIS GRP,COMPUTAT BIOL & PATTERN MATCHING GRP,YORKTOWN HTS,NY 10598, USA.		Califano, Andrea/F-7239-2012	Califano, Andrea/0000-0003-4742-3679				ASADA H, 1986, IEEE T PATTERN ANAL, V8; AYACHE N, 1984, OCT INT C INT ROB CO; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BALLARD DH, 1981, 7TH P INT JOINT C AR, P1068; BHANU B, 1984, IEEE T PATTERN ANAL, V8, P137; BOLLE RM, 1989, MAY P DARPA IM UND W; BOLLE RM, 1989, JUN P IEEE C COMP VI; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1983, 8TH P INT JOINT C AR, P1116; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971; CALIFANO A, 1988, 7TH P NAT C ART INT, P831; CALIFANO A, 1990, JUL P AAAI 90, P1067; CALIFANO A, 1991, JUN P IEEE C COMP VI, P28; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHAKRAVARTY I, 1982, P SPIE C ROB VIS ARL, P37; CHEN RT, 1986, ACM COMPUT SURV, V18, P66; CLEMENS DT, 1991, JUN P IEEE C COMP VI, P4; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; ETTINGER GJ, 1988, IEEE C COMP VIS PATT, P32; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FELDMAN JA, 1982, COGNITIVE SCI, V6, P205, DOI 10.1207/s15516709cog0603_1; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1990, 3RD P INT C COMP VIS; GRIMSON WEL, 1989, MIT AI1111 MEM; HANSEN C, 1987, DEC P IEEE COMP SOC, P100; Hinton Geoffrey E, 1981, PARALLEL MODELS ASS; HORAUD P, 1984, 1984 P IEEE INT C RO, P77; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; HUTTENLOCHER DP, 1988, MIT1045 AI LAB TECH; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KALVIN A, 1986, INT J ROBOTICS RES, V6; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; LAMDAN Y, P IEEE C COMPUTER VI, P335; LAMDAN Y, 1989, 213 NEW YORK U ROB L; LAMDAN Y, 1988, 2ND P INT C COMP VIS; LAMDAN Y, IEEE T ROBOTIC AUTOM, P1407; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; MUNDY JL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P268; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; RIGOUTSOS I, 1991, 554 NEW YORK U COUR; RIGOUTSOS I, 1991, 8TH P ISR C ART INT; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SABBAH D, 1985, COGNITIVE SCI, V9, P25, DOI 10.1207/s15516709cog0901_3; SHAPIRA R, 1977, 5TH P INT JOINT C AR, P22; STEIN F, 1990, JUN P INT C PATT REC; TAUBIN G, 1988, APR IEEE C ROB AUT; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; WEISS I, 1988, P IMAGE UNDERSTANDIN, P1125; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; [No title captured]; [No title captured]; [No title captured]; [No title captured]	57	80	90	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					373	392		10.1109/34.277591	http://dx.doi.org/10.1109/34.277591			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700004
J	ZHENG, JY				ZHENG, JY			ACQUIRING 3-D MODELS FROM SEQUENCES OF CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								This paper explores shape from contour for acquiring 3-D graphics models. In this method, a continuous sequence of images is taken as an object rotates. A smooth convex shape can be estimated instantaneously from its contour and by the first derivative of contour movement (trace of contour, or contour distribution with time). We also analyze shapes that do not satisfy the conditions of smoothness and visibility, which are indispensable for modeling an object. A region that does not expose as contour yields a nonsmoothness in the tracked contour movement. We can thus detect such a region by contour distribution filtering and extract its accurate location by computing the left and right derivatives of the distribution. This has not been studied previously. These unknown regions are obtained for further investigation using other visual cues. A general approach for building a geometrical object model using contours is then described. The entire process from silhouettes to a 3-D model is based on local computation; this is promising for producing shapes in real time. Our direct goal is to establish 3-D graphics models of human races for the growing needs of visual communications. We have obtained some good results.			ZHENG, JY (corresponding author), KYUSHU INST TECHNOL,FAC COMP SCI & SYST ENGN,FUKUOKA 820,JAPAN.							Baker H. H., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P2, DOI 10.1109/CVPR.1988.196209; Blake A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P394, DOI 10.1109/CCV.1988.590016; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; CIPOLLA R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P616; GIBLIN P, 1987, 1ST P INT C COMP VIS, P136; HARASHIMA H, 1991, IEICE TRANS COMMUN, V74, P1582; KASS M, 1988, ARTIF INTELL, V36, P91; Koenderink J., 1990, SOLID SHAPE; PANTLAND A, 1990, INT J COMPUT VISION, V4, P107; PETITJEAN S, 1992, INT J COMPUT VISION, V10, P231; TERZOPOULOS D, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727; TOMASI C, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P91; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; WILLIAMS L, 1990, P SIGGRAPH 90, P235; Zheng J. Y., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P777, DOI 10.1109/CVPR.1992.223175; ZHENG JY, 1992, INT J COMPUT VISION, V9, P55; ZHENG JY, 1990, 1990 P IEEE C ROB AU, V2, P1154; ZHENG JY, 1990, 10 INT C PATT REC, V1, P161; ZHENG JY, 1992, 11TH P ICPR, V1, P349; ZHENG JY, 1991, EIC IE9187 TECHN REP, P45	20	80	98	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					163	178						16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100004
J	ONCINA, J; GARCIA, P; VIDAL, E				ONCINA, J; GARCIA, P; VIDAL, E			LEARNING SUBSEQUENTIAL TRANSDUCERS FOR PATTERN-RECOGNITION INTERPRETATION TASKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FORMAL LANGUAGES; INDUCTIVE INFERENCE; LEARNING; RATIONAL TRANSDUCERS; SUBSEQUENTIAL FUNCTIONS; SYNTACTIC PATTERN RECOGNITION	INFERENCE; LANGUAGES	The ''interpretation'' framework in pattern recognition (PR) arises in the many cases in which the more classical paradigm of ''classification'' is not properly applicable generally because the number of classes is rather large or simply because the concept of ''class'' does not hold. A very general way of representing the results of interpretations of given objects or data is in terms of sentences of a ''semantic language'' in which the actions to be performed for each different object or datum are described. Interpretation can therefore be conveniently formalized through the concept of formal transduction, giving rise to the central PR problem of how to automatically learn a transducer from a training set of examples of the desired input-output behavior. This paper presents a formalization of the stated transducer learning problem, as well as an effective and efficient method for the inductive learning of an important class of transducers, namely, the class of subsequential transducers. The capabilities of subsequential transductions are illustrated through a series of experiments that also show the high effectiveness of the proposed learning method in obtaining very accurate and compact transducers for the corresponding tasks.			ONCINA, J (corresponding author), UNIV POLITECN VALENCIA,DEPT SISTEMAS INFORMAT & COMPUTAC,VALENCIA,SPAIN.			Oncina, Jose/0000-0003-3009-7299				ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; ANGLUIN D, 1983, ACM COMPUT SURV, V15, P237; Berstel J., 1979, TRANSDUCTIONS CONTEX; CORBI AM, 1991, ESTUDIO ALGORITMO IN; DEMORI R, 1986, OCT P NATO ADV RES W; FERRATE G, 1988, SYNTACTICAL STRUCTUR, P446; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FU KS, 1982, SYNTACTIC PATTERN RE; GARCIA P, 1987, IEEE T PATTERN ANAL, V9, P841, DOI 10.1109/TPAMI.1987.4767991; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; LUNEAU P, 1984, ROBOTICA, V1, P151; Miclet L., 1986, STRUCTURAL METHODS P; Miclet L., 1990, SYNTACTIC STRUCTURAL, P237; ONCINA J, 1992, 11TH P IAPR INT C PA; ONCINA J, 1991, DSIC II34 U POLITECN; ONCINA J, 1991, THESIS U POLITECNIA; SIMON JC, 1980, SIGNAL PROCESS, P5; TAKADA Y, 1988, INFORM PROCESS LETT, V28, P193, DOI 10.1016/0020-0190(88)90208-6; VELENTURF LPJ, 1978, IEEE T COMPUT, V27, P167; VIDAL E, 1990, STRUCTURAL PATTERN A, P17	24	80	80	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					448	458		10.1109/34.211465	http://dx.doi.org/10.1109/34.211465			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000003
J	HORAUD, R				HORAUD, R			NEW METHODS FOR MATCHING 3-D OBJECTS WITH SINGLE PERSPECTIVE VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									LAB ELETRON & TECH INFORMAT,GRENOBLE,FRANCE				Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BARNARD ST, 1984, APR WORKSH COMP VIS, P225; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1983, 8TH P INT JOINT C AR, P1116; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; COOPER L, 1984, SCI AM           DEC, P114; GOAD C, 1983, JUN P IM UND WORKSH, P94; GREGORY RL, 1974, INTELLIGENT EYE; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HORAUD R, 1986, 7TH P EUR C ART INT, P529; HORAUD R, 1984, MAR P INT C ROB ATL, P78; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KENDER JR, 1983, JUN P IM UND WORKSH, P249; LOWE D, 1985, 9TH P INT JOINT C AR, P953; Marr D., 1982, VISION; MARR D, 1979, MIT AI518 ART INT LA; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; Rock I., 1983, LOGIC PERCEPTION; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	20	80	90	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					401	412		10.1109/TPAMI.1987.4767922	http://dx.doi.org/10.1109/TPAMI.1987.4767922			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516633	Green Submitted			2022-12-18	WOS:A1987H076800005
J	MOHANTY, NC				MOHANTY, NC			COMPUTER TRACKING OF MOVING POINT TARGETS IN SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									FORD AEROSP & COMMUN CORP, DIV AERONUTRON, NEWPORT BEACH, CA 92663 USA									AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; AKAIKE H, 1973, SIAM J APPL MATH, V24, P234, DOI 10.1137/0124024; BALAKRISHNAN AV, 1969, COMMUN THEORY, P298; CHOW WK, 1977, IEEE T COMPUT, V26, P179, DOI 10.1109/TC.1977.5009299; DAVID HA, 1970, ORDER STATISTICS; HOLBEN RD, 1980, FEB SPIE TECH S LOS; JUSTICE JH, 1977, P IEEE, V65, P882, DOI 10.1109/PROC.1977.10584; KADAR I, 1979, COMPUT VISION GRAPH, V11, P262, DOI 10.1016/0146-664X(79)90092-3; MARTIN W, 1978, COMPUT GRAPHICS IMAG, V7; MILSTEIN LB, 1978, COMPUT VISION GRAPH, V7, P413, DOI 10.1016/S0146-664X(78)80007-0; MOHANTY NC, 1977, DETECTION RANDOMLY M; MOHANTY NC, 1978, P INT TELEMETERING C; NAGEL HH, 1978, COMPUT VISION GRAPH, V7, P149, DOI 10.1016/0146-664X(78)90111-9; PAPOULIS A, 1975, IEEE T CIRCUITS SYST, V22, P735, DOI 10.1109/TCS.1975.1084118; PAPOULIS A, 1965, PROBABILITY RANDOM V, P76; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; SMITH EA, 1972, IEEE T COMPUT, VC 21, P715, DOI 10.1109/T-C.1972.223574; Van Trees H. L, 2004, DETECTION ESTIMATION; WESZKA JS, 1974, IEEE T COMPUT, VC 23, P1322, DOI 10.1109/T-C.1974.223858	19	80	92	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					606	611		10.1109/TPAMI.1981.4767153	http://dx.doi.org/10.1109/TPAMI.1981.4767153			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868979				2022-12-18	WOS:A1981MQ35800011
J	KAWAGUCHI, E; ENDO, T				KAWAGUCHI, E; ENDO, T			METHOD OF BINARY-PICTURE REPRESENTATION AND ITS APPLICATION TO DATA-COMPRESSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KAWAGUCHI, E (corresponding author), KYUSHU UNIV,DEPT COMP SCI & COMMUN ENGN,FUKUOKA 812,JAPAN.							DECOULON F, 1976, ELECTRON LETT, V12, P61, DOI 10.1049/el:19760050; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; HUANG TS, 1977, IEEE T COMMUN, V25, P1406, DOI 10.1109/TCOM.1977.1093775; JOHNSEN O, 1976, AGEN20 MITT; KUBOTA K, 1974, J IECE JAPAN, V57, P1370; MURAKAMI S, 1976, T IECE JAPAN       D, V59, P117; MUSMANN HG, 1977, IEEE T COMMUN, V25, P1425, DOI 10.1109/TCOM.1977.1093776; TAKAGI M, 1973, T IECE JAPAN       D, V56, P170	8	80	83	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					27	35		10.1109/TPAMI.1980.4766967	http://dx.doi.org/10.1109/TPAMI.1980.4766967			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD568	22499620				2022-12-18	WOS:A1980JD56800004
J	Wang, D; Gao, XB; Wang, XM; He, LH				Wang, Di; Gao, Xinbo; Wang, Xiumei; He, Lihuo			Label Consistent Matrix Factorization Hashing for Large-Scale Cross-Modal Similarity Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hashing; multimodal; supervised; similarity search; cross-modal	QUANTIZATION	Multimodal hashing has attracted much interest for cross-modal similarity search on large-scale multimedia data sets because of its efficiency and effectiveness. Recently, supervised multimodal hashing, which tries to preserve the semantic information obtained from the labels of training data, has received considerable attention for its higher search accuracy compared with unsupervised multimodal hashing. Although these algorithms are promising, they are mainly designed to preserve pairwise similarities. When semantic labels of training data are given, the algorithms often transform the labels into pairwise similarities, which gives rise to the following problems: (1) constructing pairwise similarity matrix requires enormous storage space and a large amount of calculation, making these methods unscalable to large-scale data sets; (2) transforming labels into pairwise similarities loses the category information of the training data. Therefore, these methods do not enable the hash codes to preserve the discriminative information reflected by labels and, hence, the retrieval accuracies of these methods are affected. To address these challenges, this paper introduces a simple yet effective supervised multimodal hashing method, called label consistent matrix factorization hashing (LCMFH), which focuses on directly utilizing semantic labels to guide the hashing learning procedure. Considering that relevant data from different modalities have semantic correlations, LCMFH transforms heterogeneous data into latent semantic spaces in which multimodal data from the same category share the same representation. Therefore, hash codes quantified by the obtained representations are consistent with the semantic labels of the original data and, thus, can have more discriminative power for cross-modal similarity search tasks. Thorough experiments on standard databases show that the proposed algorithm outperforms several state-of-the-art methods.	[Wang, Di] Xidian Univ, Sch Comp Sci & Technol, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China; [Gao, Xinbo; Wang, Xiumei; He, Lihuo] Xidian Univ, Video & Image Proc Syst VIPs Lab, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China	Xidian University; Xidian University	Gao, XB (corresponding author), Xidian Univ, Video & Image Proc Syst VIPs Lab, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.	wangdi.wandy@gmail.com; xbgao@mail.xidian.edu.cn; wangxm@xidian.edu.cn; lihuo.he@gmail.com	ARSLAN, Okan/AAA-3232-2020; Gao, Xinbo/Q-8622-2016	Gao, Xinbo/0000-0003-1443-0776; He, Lihuo/0000-0002-0555-3574; Wang, Di/0000-0001-8027-4287	National Natural Science Foundation of China [61432014, 61702394, 61876146, 61501349, 61772402, U1605252, 61671339, 61472304]; National Key Research and Development Program of China [2016QY01W0200]; NationalHigh-Level Talents Special Support Program of China [CS31117200001]; China Postdoctoral Science Foundation [2018T111021, 2017M613082]; Key Industrial Innovation Chain in Industrial Domain [2016KTZDGY04-02]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; NationalHigh-Level Talents Special Support Program of China; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Key Industrial Innovation Chain in Industrial Domain	This work was supported in part by the National Natural Science Foundation of China under Grants 61432014, 61702394, 61876146, 61501349, 61772402, U1605252, 61671339, and 61472304, in part by the National Key Research and Development Program of China under Grant 2016QY01W0200, in part by NationalHigh-Level Talents Special Support Program of China under Grant CS31117200001, in part by China Postdoctoral Science Foundation funded project under Grants 2018T111021, and 2017M613082, and in part by Key Industrial Innovation Chain in Industrial Domain under Grant 2016KTZDGY04-02.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; Caicedo J. C., 2012, P 2 ACM INT C MULT R, P56; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921; Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Irie G, 2015, IEEE I CONF COMP VIS, P1886, DOI 10.1109/ICCV.2015.219; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kumar S, 2011, P TWENTYSECOND INT J, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230; Li YQ, 2018, IEEE T PATTERN ANAL, V40, P1526, DOI 10.1109/TPAMI.2017.2710186; Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Liu W., 2014, ADV NEURAL INFORM PR, V4, P3419; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205; Sheng Q, 2013, 2013 FIFTH INTERNATIONAL CONFERENCE ON GEO-INFORMATION TECHNOLOGIES FOR NATURAL DISASTER MANAGEMENT (GIT4NDM), P143, DOI 10.1109/GIT4NDM.2013.27; Song J., 2013, P 2013 ACM SIGMOD IN, P785, DOI [10.1145/2463676.2465274, DOI 10.1145/2463676.2465274]; Takahashi T, 2015, IEEE T PATTERN ANAL, V37, P1469, DOI 10.1109/TPAMI.2014.2382092; Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214; Yang E, 2018, IEEE T NEUR NET LEAR, V29, P5292, DOI 10.1109/TNNLS.2018.2793863; Yang EK, 2017, AAAI CONF ARTIF INTE, P1618; Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177; Zhen Y., 2012, PA CM SIGKDD INT C K, P940, DOI DOI 10.1145/2339530.2339678; Zheng F, 2018, IEEE T PATTERN ANAL, V40, P1059, DOI 10.1109/TPAMI.2016.2645565; Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415	36	79	84	3	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2466	2479		10.1109/TPAMI.2018.2861000	http://dx.doi.org/10.1109/TPAMI.2018.2861000			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30059294				2022-12-18	WOS:000489763000014
J	Dong, XY; Zheng, L; Ma, F; Yang, Y; Meng, DY				Dong, Xuanyi; Zheng, Liang; Ma, Fan; Yang, Yi; Meng, Deyu			Few-Example Object Detection with Model Communication	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Few-example learning; object detection; convolutional neural network	LOCALIZATION	In this paper, we study object detection using a large pool of unlabeled images and only a few labeled images per category, named "few-example object detection". The key challenge consists in generating trustworthy training samples as many as possible from the pool. Using few training examples as seeds, our method iterates between model training and high-confidence sample selection. In training, easy samples are generated first and, then the poorly initialized model undergoes improvement. As the model becomes more discriminative, challenging but reliable samples are selected. After that, another round of model improvement takes place. To further improve the precision and recall of the generated training samples, we embed multiple detection models in our framework, which has proven to outperform the single model baseline and the model ensemble method. Experiments on PASCAL VOC'07, MS COCO'14, and ILSVRC'13 indicate that by using as few as three or four samples selected for each category, our method produces very competitive results when compared to the state-of-the-art weakly-supervised approaches using a large number of image-level labels.	[Dong, Xuanyi; Zheng, Liang; Ma, Fan; Yang, Yi] Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia; [Yang, Yi] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710048, Shaanxi, Peoples R China	University of Technology Sydney; Chinese Academy of Sciences; Institute of Software, CAS; Xi'an Jiaotong University	Dong, XY (corresponding author), Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia.	xuanyi.dong@student.uts.edu.au; liangzheng06@gmail.com; fan.ma@student.uts.edu.au; yi.yang@uts.edu.au; dymeng@mail.xjtu.edu.cn	Dong, Xuanyi/Q-5434-2019; yang, yang/HGT-7999-2022; yang, yang/GWB-9426-2022; Yang, Yi/B-9273-2017; yang, yang/GVT-5210-2022	Dong, Xuanyi/0000-0001-9272-1590; Yang, Yi/0000-0002-0512-880X; Ma, Fan/0000-0002-4131-1222	National Key RAMP;D Program of China [2018YFB1004300]; Data to Decisions CRC (D2D CRC); China NSFC [61661166011, 11690011, 61603292, 61721002]; SIEF STEM+ Business Fellowship Program; Cooperative Research Centres Programme	National Key RAMP;D Program of China; Data to Decisions CRC (D2D CRC); China NSFC(National Natural Science Foundation of China (NSFC)); SIEF STEM+ Business Fellowship Program; Cooperative Research Centres Programme(Australian GovernmentDepartment of Industry, Innovation and ScienceCooperative Research Centres (CRC) Programme)	This research was supported by the National Key R&D Program of China (2018YFB1004300), the Data to Decisions CRC (D2D CRC), the Cooperative Research Centres Programme and the China NSFC projects under contracts 61661166011, 11690011, 61603292, 61721002. Liang Zheng is partially supported by SIEF STEM+ Business Fellowship Program.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bansal Ankan, 2018, ARXIV180404340; Bency AJ, 2016, LECT NOTES COMPUT SC, V9905, P714, DOI 10.1007/978-3-319-46448-0_43; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168; Cho M., 2015, P IEEE C COMP VIS PA, P3485; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Dai S., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383028; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412; Dong XY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P279, DOI 10.1145/3123266.3123455; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420; Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hoffman Judy, 2014, NIPS; Jiang L, 2015, AAAI CONF ARTIF INTE, P2694; Jiang L, 2014, ADV NEUR IN, V27; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar A, 2010, ASIA PACIF MICROWAVE, P1189; Levi K, 2004, PROC CVPR IEEE, P53; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liang XD, 2017, IEEE T PATTERN ANAL, V39, P1462, DOI 10.1109/TPAMI.2016.2598340; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Lin L, 2018, IEEE T PATTERN ANAL, V40, P7, DOI 10.1109/TPAMI.2017.2652459; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ma F, 2017, PR MACH LEARN RES, V70; Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Meng DY, 2017, INFORM SCIENCES, V414, P319, DOI 10.1016/j.ins.2017.05.043; Misra I, 2015, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2015.7298982; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Rahman S, 2019, LECT NOTES COMPUT SC, V11361, P547, DOI 10.1007/978-3-030-20887-5_34; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rochan M, 2015, PROC CVPR IEEE, P4315, DOI 10.1109/CVPR.2015.7299060; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Santoro A, 2016, PR MACH LEARN RES, V48; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Singh KK, 2016, PROC CVPR IEEE, P3548, DOI 10.1109/CVPR.2016.386; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Song X, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1637, DOI 10.1109/ICMA.2014.6885945; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Tang YX, 2016, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2016.233; Teh E. W., 2016, P BRIT MACH VIS C BM; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; Wang J., 2018, P INT JOINT C ART IN; Wang YX, 2015, PROC CVPR IEEE, P1619, DOI 10.1109/CVPR.2015.7298770; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Xu ZW, 2017, PROC CVPR IEEE, P5358, DOI 10.1109/CVPR.2017.569; Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938; Yang Y, 2013, PROC CVPR IEEE, P1650, DOI 10.1109/CVPR.2013.216; Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023; Zhang D., 2016, PROC INT JOINT C ART, P3538; Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749; Zhu Y, 2017, IEEE I CONF COMP VIS, P1859, DOI 10.1109/ICCV.2017.204; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	77	79	81	3	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1641	1654		10.1109/TPAMI.2018.2844853	http://dx.doi.org/10.1109/TPAMI.2018.2844853			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994192	Green Submitted			2022-12-18	WOS:000470972300009
J	Karanam, S; Gou, MR; Wu, ZY; Rates-Borras, A; Camps, O; Radke, RJ				Karanam, Srikrishna; Gou, Mengran; Wu, Ziyan; Rates-Borras, Angels; Camps, Octavia; Radke, Richard J.			A Systematic Evaluation and Benchmark for Person Re-Identification: Features, Metrics, and Datasets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Person re-identification; camera network; video analytics; benchmark	CLASSIFICATION; RECOGNITION; MODELS	Person re-identification (re-id) is a critical problem in video analytics applications such as security and surveillance. The public release of several datasets and code for vision algorithms has facilitated rapid progress in this area over the last few years. However, directly comparing re-id algorithms reported in the literature has become difficult since a wide variety of features, experimental protocols, and evaluation metrics are employed. In order to address this need, we present an extensive review and performance evaluation of single- and multi-shot re-id algorithms. The experimental protocol incorporates the most recent advances in both feature extraction and metric learning. To ensure a fair comparison, all of the approaches were implemented using a unified code library that includes 11 feature extraction algorithms and 22 metric learning and ranking techniques. All approaches were evaluated using a new large-scale dataset that closely mimics a real-world problem setting, in addition to 16 other publicly available datasets: VIPeR, GRID, CAVIAR, DukeMTMC4ReID, 3DPeS, PRID, V47, WARD, SAIVT-SoftBio, CUHK01, CHUK02, CUHK03, RAiD, iLIDSVID, HDA+, and Market1501. The evaluation codebase and results will be made publicly available for community use.	[Radke, Richard J.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; [Karanam, Srikrishna; Wu, Ziyan] Siemens Corp Technol, Princeton, NJ 08540 USA; [Gou, Mengran; Rates-Borras, Angels; Camps, Octavia] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA	Rensselaer Polytechnic Institute; Siemens AG; Northeastern University	Karanam, S (corresponding author), Siemens Corp Technol, Princeton, NJ 08540 USA.	srikrishna.karanam@siemens.com; mengran@coe.neu.edu; ziyan.wu@siemens.com; ratesborras.a@husky.neu.edu; camps@coe.neu.edu; rjradke@ecse.rpi.edu	Gou, Mengran/J-3027-2019; Radke, Richard/I-3289-2013	Gou, Mengran/0000-0003-3250-2139; Camps, Octavia/0000-0003-1945-9172; Radke, Richard/0000-0001-5064-7775	U.S. Department of Homeland Security [2013-ST-061-ED0001]; NSF [IIS-1318145, ECCS-1404163, CMMI-1638234]; AFOSR [FA9550-15-1-0392]	U.S. Department of Homeland Security(United States Department of Homeland Security (DHS)); NSF(National Science Foundation (NSF)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	This material is based upon work supported by the U.S. Department of Homeland Security under Award Number 2013-ST-061-ED0001 and in part by NSF grants IIS-1318145, ECCS-1404163, CMMI-1638234 and AFOSR grant FA9550-15-1-0392. S. Karanam and M. Gou contributed equally to this work. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the U.S. Department of Homeland Security. Thanks to Michael Young, Jim Spriggs, and Don Kemer for supplying the airport video data.	Ahmed E., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299016; An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], WORKSH DEM COMP VIS; [Anonymous], 2015, PROC CVPR IEEE; [Anonymous], 2015, 2015 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2015.7280360; Assari SM, 2016, LECT NOTES COMPUT SC, V9906, P119, DOI 10.1007/978-3-319-46475-6_8; Bak S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P179, DOI 10.1109/AVSS.2011.6027316; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Baltieri D., 2011, P 2011 JOINT ACMWORK, P59, DOI DOI 10.1145/2072572.2072590; Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008; Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Bialkowski A, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA); Camps O, 2017, IEEE T CIRC SYST VID, V27, P540, DOI 10.1109/TCSVT.2016.2556538; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Figueira D., 2014, ECCV; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; Garcia J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154; Gong S., 2014, PERSON REIDENTIFICAT, V1; Gong Yuan, 2017, ARXIV171103280; Gou M., 2016, P BRIT MACH VIS C, P1; Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Haque A, 2016, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2016.138; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Karanam Srikrishna, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P33, DOI 10.1109/CVPRW.2015.7301392; Karanam S, 2017, 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017), P157, DOI 10.1145/3131885.3131929; Karanam S, 2017, IMAGE VISION COMPUT, V60, P75, DOI 10.1016/j.imavis.2016.11.015; Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24; Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461; Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429; Li Y, 2014, INT SYMP DISTR COMPU, P34, DOI 10.1109/DCABES.2014.10; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Liao S., 2010, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2010.5539817; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Lisanti G., 2014, P INT C DISTRIBUTED, P1, DOI DOI 10.1145/2659021.2659036; Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055; Liu CX, 2013, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2013.62; Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434; Liu Z, 2015, NEUROCOMPUTING, V168, P1144, DOI 10.1016/j.neucom.2015.05.008; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5; Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002; Martinel N, 2016, PATTERN RECOGN LETT, V71, P23, DOI 10.1016/j.patrec.2015.11.022; Martinel N, 2012, 2012 SIXTH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC); Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148; Messelodi S, 2015, IMAGE VISION COMPUT, V44, P44, DOI 10.1016/j.imavis.2015.09.008; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Satta R., 2013, CORR; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Schmid C, 2001, PROC CVPR IEEE, P39; Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046; Simi Wang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1876, DOI 10.1109/ICCVW.2011.6130477; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wu ZY, 2015, IEEE T PATTERN ANAL, V37, P1095, DOI 10.1109/TPAMI.2014.2360373; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Yang M., 2013, PROC 10 IEEE INT C W, P1, DOI DOI 10.1109/FG.2013.6553727; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng L., 2016, ARXIV PREPRINT ARXIV; Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531; Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	116	79	82	1	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					523	536		10.1109/TPAMI.2018.2807450	http://dx.doi.org/10.1109/TPAMI.2018.2807450			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994059	Green Submitted, hybrid			2022-12-18	WOS:000458168800001
J	Zhou, F; De la Torre, F				Zhou, Feng; De la Torre, Fernando			Factorized Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; feature matching; quadratic assignment problem; iterative closet point method	ALGORITHM; RECOGNITION; KERNEL; MODEL	Graph matching (GM) is a fundamental problem in computer science, and it plays a central role to solve correspondence problems in computer vision. GM problems that incorporate pairwise constraints can be formulated as a quadratic assignment problem (QAP). Although widely used, solving the correspondence problem through GM has two main limitations: (1) the QAP is NP-hard and difficult to approximate; (2) GM algorithms do not incorporate geometric constraints between nodes that are natural in computer vision problems. To address aforementioned problems, this paper proposes factorized graph matching (FGM). FGM factorizes the large pairwise affinity matrix into smaller matrices that encode the local structure of each graph and the pairwise affinity between edges. Four are the benefits that follow from this factorization: (1) There is no need to compute the costly (in space and time) pairwise affinity matrix; (2) The factorization allows the use of a path-following optimization algorithm, that leads to improved optimization strategies and matching performance; (3) Given the factorization, it becomes straight-forward to incorporate geometric transformations (rigid and non-rigid) to the GM problem. (4) Using a matrix formulation for the GM problem and the factorization, it is easy to reveal commonalities and differences between different GM methods. The factorization also provides a clean connection with other matching algorithms such as iterative closest point; Experimental results on synthetic and real databases illustrate how FGM outperforms state-of-the-art algorithms for GM. The code is available at http://humansensing.cs.cmu.edu/fgm.	[Zhou, Feng; De la Torre, Fernando] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Zhou, F (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	zhfe99@gmail.com; ftorre@cs.cmu.edu			National Science Foundation [EEEC-0540865, RI-1116583, CPS-0931999]	National Science Foundation(National Science Foundation (NSF))	This work was partially supported by the National Science Foundation under Grant No. EEEC-0540865, RI-1116583 and CPS-0931999. Any opinions, findings, and conclusions expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Allgower Eugene L, 2003, INTRO NUMERICAL CONT; ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bunke H., 2000, P 13 VISION INTERFAC; Burkard R., 2009, ASSIGNMENT PROBLEMS; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; FUKUSHIMA M, 1984, TRANSPORT RES B-METH, V18, P169, DOI 10.1016/0191-2615(84)90029-8; Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; HORST R., 1995, HDB GLOBAL OPTIMIZAT; Jiang H, 2011, IEEE T PATTERN ANAL, V33, P1339, DOI 10.1109/TPAMI.2010.212; KOOPMANS TC, 1957, ECONOMETRICA, V25, P53, DOI 10.2307/1907742; LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383091; Leordeanu M., 2011, INT J COMPUT VISION, V96, P1; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; Loiola EM, 2007, EUR J OPER RES, V176, P657, DOI 10.1016/j.ejor.2005.09.032; Luo B, 2003, COMPUT VIS IMAGE UND, V92, P26, DOI 10.1016/S1077-3142(03)00097-3; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Quadrianto N, 2010, IEEE T PATTERN ANAL, V32, P1809, DOI 10.1109/TPAMI.2009.184; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Schellewald C., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P361; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Szeliski R., 2010, COMPUTER VISION ALGO, DOI DOI 10.1007/978-3-030-34372-9; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tian Y, 2012, LECT NOTES COMPUT SC, V7574, P821, DOI 10.1007/978-3-642-33712-3_59; Torr P.H.S., 2003, AISTATS; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; van Wyk BJ, 2004, IEEE T PATTERN ANAL, V26, P1526, DOI 10.1109/TPAMI.2004.95; Von Neumann John, 1953, CONTRIBUTIONS THEORY, V2, P5; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zaslavskiy M, 2009, BIOINFORMATICS, V25, pI259, DOI 10.1093/bioinformatics/btp196; Zass R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587500; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	66	79	85	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1774	1789		10.1109/TPAMI.2015.2501802	http://dx.doi.org/10.1109/TPAMI.2015.2501802			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26595909	Green Submitted, hybrid			2022-12-18	WOS:000381432700005
J	Heo, JP; Lee, Y; He, JF; Chang, SF; Yoon, SE				Heo, Jae-Pil; Lee, Youngwoon; He, Junfeng; Chang, Shih-Fu; Yoon, Sung-Eui			Spherical Hashing: Binary Code Embedding with Hyperspheres	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hashing; binary codes; large-scale image search	CLASSIFICATION; SEARCH	Many binary code embedding schemes have been actively studied recently, since they can provide efficient similarity search, and compact data representations suitable for handling large scale image databases. Existing binary code embedding techniques encode high-dimensional data by using hyperplane-based hashing functions. In this paper we propose a novel hypersphere-based hashing function, spherical hashing, to map more spatially coherent data points into a binary code compared to hyperplane-based hashing functions. We also propose a new binary code distance function, spherical Hamming distance, tailored for our hypersphere-based binary coding scheme, and design an efficient iterative optimization process to achieve both balanced partitioning for each hash function and independence between hashing functions. Furthermore, we generalize spherical hashing to support various similarity measures defined by kernel functions. Our extensive experiments show that our spherical hashing technique significantly outperforms state-of-the-art techniques based on hyperplanes across various benchmarks with sizes ranging from one to 75 million of GIST, BoW and VLAD descriptors. The performance gains are consistent and large, up to 100 percent improvements over the second best method among tested methods. These results confirm the unique merits of using hyperspheres to encode proximity regions in high-dimensional spaces. Finally, our method is intuitive and easy to implement.	[Heo, Jae-Pil; Lee, Youngwoon; Yoon, Sung-Eui] Korea Adv Inst Sci & Technol, Dept Comp Sci, Daejeon, South Korea; [Chang, Shih-Fu] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA	Korea Advanced Institute of Science & Technology (KAIST); Columbia University	Heo, JP (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Daejeon, South Korea.	jaepilheo@gmail.com; lywoon89@gmail.com; hejunf@gmail.com; sfchang@ee.columbia.edu; sungeui@gmail.com	Yoon, Sung-eui/C-1678-2011		IT R&D program of MSIP/IITP [10044970]; DAPA/ADD [UD140022PD]; MSIP/NRF [2013-067321];  [NRF-2013R1A1A2058052]	IT R&D program of MSIP/IITP(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea); DAPA/ADD; MSIP/NRF(National Research Foundation of Korea); 	The authors would like to thank anonymous reviewers for constructive comments. This work was supported in part by IT R&D program of MSIP/IITP (10044970), NRF-2013R1A1A2058052, DAPA/ADD (UD140022PD), and MSIP/NRF (2013-067321). This manuscript is extended from the conference paper version [1]. Sung-Eui Yoon is the corresponding author.	BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bohm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809; Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Chum Ondrej, 2008, BMVC, V810, P812, DOI DOI 10.5244/C.22.50; cker Chiueh T., 1994, P 20 INT C VER LARG, P582; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gong Y., 2011, P CVPR; Gordo A, 2011, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2011.5995505; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266; He J., 2011, P IEEE C COMP VIS PA, P817; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jain P, 2008, PROC CVPR IEEE, P3879; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jia Y, 2010, PROC CVPR IEEE, P3392, DOI 10.1109/CVPR.2010.5540006; Joly A., 2008, P 16 ACM INT C MULT, P209; Joly A, 2011, PROC CVPR IEEE, P873, DOI 10.1109/CVPR.2011.5995709; Kim K, 2012, COMPUT VIS IMAGE UND, V116, P991, DOI 10.1016/j.cviu.2012.05.001; Kong W., 2012, AAAI, P634; Kong W., 2012, P 35 INT ACM SIGIR C; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Lee Y., 2012, P AS C COMP VIS, P214; Lin RS, 2010, PROC CVPR IEEE, P848, DOI 10.1109/CVPR.2010.5540129; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu Wei, 2011, Reports in Parasitology, V1, P1; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Silpa-Anan C, 2008, PROC CVPR IEEE, P2308; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A, 2008, PROC CVPR IEEE, P2269; Wang J., 2010, ICML, P1127; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Weiss Yair, 2008, ADV NEURAL INFORM PR, P1753; Yaglom A. M., 1987, CHALLENGING MATH PRO; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	46	79	81	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2304	2316		10.1109/TPAMI.2015.2408363	http://dx.doi.org/10.1109/TPAMI.2015.2408363			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440269				2022-12-18	WOS:000362411000012
J	Wang, CD; Lai, JH; Suen, CY; Zhu, JY				Wang, Chang-Dong; Lai, Jian-Huang; Suen, Ching Y.; Zhu, Jun-Yong			Multi-Exemplar Affinity Propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; multi-exemplar; affinity propagation; factor graph; max-product belief propagation	MODEL; CLASSIFICATION; RECOGNITION; ALGORITHM; CUTS	The affinity propagation (AP) clustering algorithm has received much attention in the past few years. AP is appealing because it is efficient, insensitive to initialization, and it produces clusters at a lower error rate than other exemplar-based methods. However, its single-exemplar model becomes inadequate when applied to model multisubclasses in some situations such as scene analysis and character recognition. To remedy this deficiency, we have extended the single-exemplar model to a multi-exemplar one to create a new multi-exemplar affinity propagation (MEAP) algorithm. This new model automatically determines the number of exemplars in each cluster associated with a super exemplar to approximate the subclasses in the category. Solving the model is NP-hard and we tackle it with the max-sum belief propagation to produce neighborhood maximum clusters, with no need to specify beforehand the number of clusters, multi-exemplars, and superexemplars. Also, utilizing the sparsity in the data, we are able to reduce substantially the computational time and storage. Experimental studies have shown MEAP's significant improvements over other algorithms on unsupervised image categorization and the clustering of handwritten digits.	[Wang, Chang-Dong; Lai, Jian-Huang] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China; [Wang, Chang-Dong; Lai, Jian-Huang] Guangdong Prov Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China; [Suen, Ching Y.] Concordia Univ, Ctr Pattern Recognit & Machine Intelligence CENPA, Montreal, PQ H3G 1M8, Canada; [Zhu, Jun-Yong] Sun Yat Sen Univ, Sch Math & Computat Sci, Guangzhou 510275, Guangdong, Peoples R China	Sun Yat Sen University; Concordia University - Canada; Sun Yat Sen University	Wang, CD (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Waihuan East Rd, Guangzhou 510006, Guangdong, Peoples R China.	changdongwang@hotmail.com; stsljh@mail.sysu.edu.cn; suen@cenparmi.concordia.ca; jonesjunyong@gmail.com			NSFC [61173084, 61128009]; NSFC-GuangDong [U0835005]	NSFC(National Natural Science Foundation of China (NSFC)); NSFC-GuangDong(National Natural Science Foundation of Guangdong Province)	This work was supported by NSFC (61173084 and 61128009), NSFC-GuangDong (U0835005). The authors would like to thank Jianbo Shi for providing the Ncut code, Inderjit S. Dhillon for providing the Graclus code, Brendan J. Frey for providing the AP code, and Fei-Fei Li for providing the SceneClass13 and Caltech101 datasets.	Aiolli F, 2005, J MACH LEARN RES, V6, P817; AVIITZHAK HI, 1995, IEEE T PATTERN ANAL, V17, P418, DOI 10.1109/34.385977; Chang-Dong Wang, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P531, DOI 10.1109/ICDM.2010.57; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Dueck D., 2009, THESIS U TORONTO; Dueck D, 2008, LECT N BIOINFORMAT, V4955, P360; Dueck D, 2007, IEEE I CONF COMP VIS, P198; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Givoni I, 2009, P 12 INT C ART INT S, P161; Givoni IE, 2011, P 27 C UNC ART INT, P238; Givoni IE, 2009, NEURAL COMPUT, V21, P1589, DOI 10.1162/neco.2009.05-08-785; Grauman K., 2006, P IEEE C COMP VIS PA, P2596; Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4; Hansen P., 1997, Location Science, V5, P207, DOI 10.1016/S0966-8349(98)00030-8; Huang TH, 2009, PROC CVPR IEEE, P296, DOI 10.1109/CVPRW.2009.5206765; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leone M, 2008, EUR PHYS J B, V66, P125, DOI 10.1140/epjb/e2008-00381-8; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Liu MH, 2009, PATTERN RECOGN, V42, P689, DOI 10.1016/j.patcog.2008.09.015; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; Mikolajczyk K., 2006, P CVPR, V1, P26, DOI DOI 10.1109/CVPR.2006.202]; Rahman AFR, 1997, ELECTRON LETT, V33, P1208, DOI 10.1049/el:19970848; Reisinger J., 2010, HUMAN LANGUAGE TECHN, P109; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Strehl A., 2000, WORKSHOP ARTIFICIAL, P58; Tarlow D, 2008, P 24 C UNC ART INT, P537; Ting Luo, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P1602, DOI 10.1109/FSKD.2010.5569359; Verma R., 2007, P 11 IEEE INT C COMP, P1; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; Xiao JX, 2007, IEEE I CONF COMP VIS, P786; Xu L., 2004, P C NEUR INF PROC SY; You D, 2011, IEEE T PATTERN ANAL, V33, P631, DOI 10.1109/TPAMI.2010.173; Zhang XL, 2008, LECT NOTES ARTIF INT, V5212, P628, DOI 10.1007/978-3-540-87481-2_41; Zhao ZQ, 2010, APPL MATH MODEL, V34, P3884, DOI 10.1016/j.apm.2010.03.027; Zhou SK, 2004, INT C PATT RECOG, P191, DOI 10.1109/ICPR.2004.1333736; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172; Zhu QM, 2001, PATTERN RECOGN, V34, P547, DOI 10.1016/S0031-3203(00)00017-0	48	79	90	0	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2223	2237		10.1109/TPAMI.2013.28	http://dx.doi.org/10.1109/TPAMI.2013.28			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868781				2022-12-18	WOS:000322029000013
J	Zhao, QB; Caiafa, CF; Mandic, DP; Chao, ZC; Nagasaka, Y; Fujii, N; Zhang, LQ; Cichocki, A				Zhao, Qibin; Caiafa, Cesar F.; Mandic, Danilo P.; Chao, Zenas C.; Nagasaka, Yasuo; Fujii, Naotaka; Zhang, Liqing; Cichocki, Andrzej			Higher Order Partial Least Squares (HOPLS): A Generalized Multilinear Regression Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multilinear regression; partial least squares; higher order singular value decomposition; constrained block Tucker decomposition; electrocorticogram; fusion of behavioral and neural data	PLS; TENSOR; DECOMPOSITIONS; APPROXIMATION; CALIBRATION; SELECTION; 3-WAY; MODEL	A new generalized multilinear regression model, termed the higher order partial least squares (HOPLS), is introduced with the aim to predict a tensor (multiway array) Y from a tensor X through projecting the data onto the latent space and performing regression on the corresponding latent variables. HOPLS differs substantially from other regression models in that it explains the data by a sum of orthogonal Tucker tensors, while the number of orthogonal loadings serves as a parameter to control model complexity and prevent overfitting. The low-dimensional latent space is optimized sequentially via a deflation operation, yielding the best joint subspace approximation for both X and Y. Instead of decomposing X and Y individually, higher order singular value decomposition on a newly defined generalized cross-covariance tensor is employed to optimize the orthogonal loadings. A systematic comparison on both synthetic data and real-world decoding of 3D movement trajectories from electrocorticogram signals demonstrate the advantages of HOPLS over the existing methods in terms of better predictive ability, suitability to handle small sample sizes, and robustness to noise.	[Zhao, Qibin; Cichocki, Andrzej] RIKEN, Brain Sci Inst, Lab Adv Brain Signal Proc, Saitama, Japan; [Zhao, Qibin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China; [Caiafa, Cesar F.] Consejo Nacl Invest Cient & Tecn, CCT La Plata, IAR, RA-1033 Buenos Aires, DF, Argentina; [Mandic, Danilo P.] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, Commun & Signal Proc Res Grp, London, England; [Chao, Zenas C.; Nagasaka, Yasuo; Fujii, Naotaka] RIKEN, Brain Sci Inst, Lab Adapt Intelligence, Saitama, Japan; [Zhang, Liqing] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, MOE Microsoft Key Lab Intelligent Comp & Intellig, Shanghai 200030, Peoples R China; [Cichocki, Andrzej] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	RIKEN; Shanghai Jiao Tong University; Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET); National University of La Plata; Imperial College London; RIKEN; Microsoft; Shanghai Jiao Tong University; Polish Academy of Sciences; Systems Research Institute of the Polish Academy of Sciences	Zhao, QB (corresponding author), RIKEN, Brain Sci Inst, Lab Adv Brain Signal Proc, Saitama, Japan.	qbzhao@brain.riken.jp; ccaiafa@gmail.com; d.mandic@imperial.ac.uk; zenas.c.chao@gmail.com; nyasuo@brain.riken.jp; na@brain.riken.jp; zhang-lq@cs.sjtu.edu.cn; a.cichocki@riken.jp	Cichocki, Andrzej/A-1545-2015; Caiafa, Cesar/A-6045-2010; Cichocki, Andrzej/AAI-4209-2020; Zhao, Qibin/D-1689-2014	Cichocki, Andrzej/0000-0002-8364-7226; Caiafa, Cesar/0000-0001-5437-6095; 	JSPS [24700154]; National Natural Science Foundation of China [90920014, 91120305, 61202155]; CONICET [11420110100021]	JSPS(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CONICET(Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET))	This work was supported in part by JSPS Grants-in-Aid for Scientific Research (Grant No. 24700154), the National Natural Science Foundation of China (Grant Nos. 90920014, 91120305, 61202155), and the CONICET project PIP 2012-2014 (No. 11420110100021).	Abdi H, 2010, WIRES COMPUT STAT, V2, P97, DOI 10.1002/wics.51; Acar E, 2007, P ANN INT IEEE EMBS, P4273, DOI 10.1109/IEMBS.2007.4353280; Acar E, 2011, CHEMOMETR INTELL LAB, V106, P41, DOI 10.1016/j.chemolab.2010.08.004; Borraccetti MD, 2009, ANALYST, V134, P1682, DOI 10.1039/b903649k; Bro R, 2005, CHEMOMETR INTELL LAB, V75, P69, DOI 10.1016/j.chemolab.2004.04.014; Bro R, 2001, CHEMOMETR INTELL LAB, V58, P3, DOI 10.1016/S0169-7439(01)00134-4; Bro R, 1996, J CHEMOMETR, V10, P47, DOI 10.1002/(SICI)1099-128X(199601)10:1<47::AID-CEM400>3.0.CO;2-C; Bro R., 1998, THESIS DINAMARCA; Bro R, 2006, CRIT REV ANAL CHEM, V36, P279, DOI 10.1080/10408340600969965; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Chao ZC, 2010, FRONTIERS NEUROENGIN, V3; Cichocki Andrzej, 2009, NONNEGATIVE MATRIX T, P2; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; De Lathauwer L, 2008, SIAM J MATRIX ANAL A, V30, P1033, DOI 10.1137/070690729; de Silva V, 2008, SIAM J MATRIX ANAL A, V30, P1084, DOI 10.1137/06066518X; Dhanjal C, 2009, IEEE T PATTERN ANAL, V31, P1347, DOI 10.1109/TPAMI.2008.171; Ergon R, 2002, J CHEMOMETR, V16, P368, DOI 10.1002/cem.736; Ham J., 2004, P 21 INT C MACH LEAR, P47, DOI DOI 10.1145/1015330.1015417; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Hasegawa K, 2000, CHEMOMETR INTELL LAB, V50, P253, DOI 10.1016/S0169-7439(99)00063-5; Kim Hyunsoo, 2005, Int J Bioinform Res Appl, V1, P51, DOI 10.1504/IJBRA.2005.006902; Kolda T., 2006, SAND20062081 NAT LAB; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kovacevic N, 2007, NEUROIMAGE, V35, P1103, DOI 10.1016/j.neuroimage.2007.01.016; Kowalski B, 1982, CHEM SYSTEMS INDIREC, P191; Krishnan A, 2011, NEUROIMAGE, V56, P455, DOI 10.1016/j.neuroimage.2010.07.034; Li BB, 2002, CHEMOMETR INTELL LAB, V64, P79, DOI 10.1016/S0169-7439(02)00051-5; Martinez-Montes E, 2004, NEUROIMAGE, V22, P1023, DOI 10.1016/j.neuroimage.2004.03.038; McIntosh AR, 2004, NEUROIMAGE, V23, pS250, DOI 10.1016/j.neuroimage.2004.07.020; Montgomery D., 2001, INTRO LINEAR REGRESS; Nagasaka Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022561; Nilsson J, 1997, J CHEMOMETR, V11, P511; Rickert J, 2005, J NEUROSCI, V25, P8815, DOI 10.1523/JNEUROSCI.0816-05.2005; Rosipal R, 2002, J MACH LEARN RES, V2, P97, DOI 10.1162/15324430260185556; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Schaal S., 2000, P 17 INT C MACH LEAR, V1, P288; Smilde A, 2004, MULTIWAY ANAL APPL C; Smilde AK, 1997, J CHEMOMETR, V11, P367, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<367::AID-CEM481>3.0.CO;2-I; Smilde AK, 1999, J CHEMOMETR, V13, P31; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Trejo LJ, 2006, IEEE T NEUR SYS REH, V14, P225, DOI 10.1109/TNSRE.2006.875578; Trygg J, 2002, J CHEMOMETR, V16, P119, DOI 10.1002/cem.695; Tucker L. R., 1963, PROBLEMS MEASURING C, V15, P122; Wold H., 1982, SYSTEMS INDIRECT OBS, pI; Wold H., 1975, PERSPECTIVES PROBABI, V12, P117, DOI [10.1017/S0021900200047604, DOI 10.1017/S0021900200047604]; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; Zissis KD, 1999, ANAL CHIM ACTA, V384, P71, DOI 10.1016/S0003-2670(98)00844-7	49	79	82	2	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1660	1673		10.1109/TPAMI.2012.254	http://dx.doi.org/10.1109/TPAMI.2012.254			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681994	Green Submitted, Green Published			2022-12-18	WOS:000319060600010
J	Bulo, SR; Pelillo, M				Bulo, Samuel Rota; Pelillo, Marcello			A Game-Theoretic Approach to Hypergraph Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hypergraph clustering; evolutionary game theory; polynomial optimization; Baum-Eagon inequality; high-order replicator dynamics	PROBABILISTIC FUNCTIONS; FACE RECOGNITION; OPTIMIZATION; DYNAMICS	Hypergraph clustering refers to the process of extracting maximally coherent groups from a set of objects using high-order (rather than pairwise) similarities. Traditional approaches to this problem are based on the idea of partitioning the input data into a predetermined number of classes, thereby obtaining the clusters as a by-product of the partitioning process. In this paper, we offer a radically different view of the problem. In contrast to the classical approach, we attempt to provide a meaningful formalization of the very notion of a cluster and we show that game theory offers an attractive and unexplored perspective that serves our purpose well. To this end, we formulate the hypergraph clustering problem in terms of a noncooperative multiplayer "clustering game," and show that a natural notion of a cluster turns out to be equivalent to a classical (evolutionary) game-theoretic equilibrium concept. We prove that the problem of finding the equilibria of our clustering game is equivalent to locally optimizing a polynomial function over the standard simplex, and we provide a discrete-time high-order replicator dynamics to perform this optimization, based on the Baum-Eagon inequality. Experiments over synthetic as well as real-world data are presented which show the superiority of our approach over the state of the art.	[Bulo, Samuel Rota; Pelillo, Marcello] Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, I-30172 Venice, Italy	Universita Ca Foscari Venezia	Bulo, SR (corresponding author), Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, Via Torino 155, I-30172 Venice, Italy.	srotabul@dais.unive.it; pelillo@dais.unive.it		Rota Bulo, Samuel/0000-0002-2372-1367	FET programme within EU FP7 under the SIMBAD project [213250]	FET programme within EU FP7 under the SIMBAD project	The authors acknowledge financial support from the FET programme within EU FP7 under the SIMBAD project (contract 213250). They thank Sameer Agarwal and Ron Zass for providing them with the code of their algorithms, and Ilya Safro for pointing out some useful references. They would also like to thank the anonymous reviewers and the associate editor for their useful comments.	Agarwal S, 2005, PROC CVPR IEEE, P838; Agarwal S., 2006, ICML, P17, DOI DOI 10.1145/1143844.1143847; Albarelli A., 2009, P IEEE INT C COMP VI; [Anonymous], 2006, CVPR 06 P IEEE COMP; Banerjee A, 2005, P 11 ACM SIGKDD INT, P532, DOI DOI 10.1145/1081870.1081932; BAUM LE, 1968, PAC J MATH, V27, P211, DOI 10.2140/pjm.1968.27.211; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Berge C., 1989, HYPERGRAPHS COMBINAT; BLAKLEY GR, 1964, B AM MATH SOC, V70, P712, DOI 10.1090/S0002-9904-1964-11182-4; BOLLA M, 1993, DISCRETE MATH, V117, P19, DOI 10.1016/0012-365X(93)90322-K; Broom M, 1997, B MATH BIOL, V59, P931; Bul`o S. R., 2009, ADV NEURAL INFORM PR, P1571; Bulo SR, 2011, COMPUT VIS IMAGE UND, V115, P984, DOI 10.1016/j.cviu.2010.12.004; Crammer K., 2008, P INT C MACH LEARN; Etessami K, 2008, INT J GAME THEORY, V37, P93, DOI 10.1007/s00182-007-0095-0; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; FRANKL P, 1984, COMBINATORICA, V4, P149, DOI 10.1007/BF02579215; Fudenberg D., 1991, GAME THEORY; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gibson D., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P311; Govindu VM, 2005, PROC CVPR IEEE, P1150; Gupta G., 2005, P INT C MACH LEARN; Heller K., 2007, P INT C AI STAT; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; Hofbauer J., 1998, EVOLUTIONARY GAMES P; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Hu T., 1985, P VLSI CIRC LAYOUT T, P87; Huang YC, 2011, IEEE T PATTERN ANAL, V33, P1266, DOI 10.1109/TPAMI.2011.25; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; JARDINE N, 1968, COMPUT J, V11, P177, DOI 10.1093/comjnl/11.2.177; Karypis G, 2000, VLSI DES, V11, P285, DOI 10.1155/2000/19436; LaSalle J.P., 2012, STABILITY CONTROL DI, V62; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Liu H., 2010, ADV NEURAL INFORM PR, P1414; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; Luenberger D. G., 1979, INTRO DYNAMIC SYSTEM; Maynard Smith J., 1982, EVOLUTION THEORY GAM; MOHAMMED JL, 1983, IEEE T PATTERN ANAL, V5, P330, DOI 10.1109/TPAMI.1983.4767394; Nisan N., 2006, EL C COMP COMPL; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Pelillo M, 1997, J MATH IMAGING VIS, V7, P309, DOI 10.1023/A:1008255111261; Pelillo M, 2006, NEURAL COMPUT, V18, P1215, DOI 10.1162/neco.2006.18.5.1215; Perona P., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P655, DOI 10.1007/BFb0055696; Rodriguez JA, 2003, LINEAR MULTILINEAR A, V51, P285, DOI 10.1080/0308108031000084374; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; Shashua A., 1988, P IEEE INT C COMP VI; Shashua A, 2006, LECT NOTES COMPUT SC, V3954, P595; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Torsello A., 2008, P INT C PATT REC; Weibull J.W., 1997, EVOLUTIONARY GAME TH; Zhou D., 2006, ADV NEURAL INF PROCE, V19, P1601; Zien JY, 1999, IEEE T COMPUT AID D, V18, P1389, DOI 10.1109/43.784130	54	79	80	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1312	1327		10.1109/TPAMI.2012.226	http://dx.doi.org/10.1109/TPAMI.2012.226			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599050				2022-12-18	WOS:000317857900004
J	Dai, JF; Feng, JJ; Zhou, J				Dai, Jifeng; Feng, Jianjiang; Zhou, Jie			Robust and Efficient Ridge-Based Palmprint Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Palmprint; orientation field; density map; data fusion; distortion; matching; cascade filtering; generalized Hough transform; naive Bayes classifier	FINGERPRINT; IDENTIFICATION; VERIFICATION	During the past decade, many efforts have been made to use palmprints as a biometric modality. However, most of the existing palmprint recognition systems are based on encoding and matching creases, which are not as reliable as ridges. This affects the use of palmprints in large-scale person identification applications where the biometric modality needs to be distinctive as well as insensitive to changes in age and skin conditions. Recently, several ridge-based palmprint matching algorithms have been proposed to fill the gap. Major contributions of these systems include reliable orientation field estimation in the presence of creases and the use of multiple features in matching, while the matching algorithms adopted in these systems simply follow the matching algorithms for fingerprints. However, palmprints differ from fingerprints in several aspects: 1) Palmprints are much larger and thus contain a large number of minutiae, 2) palms are more deformable than fingertips, and 3) the quality and discrimination power of different regions in palmprints vary significantly. As a result, these matchers are unable to appropriately handle the distortion and noise, despite heavy computational cost. Motivated by the matching strategies of human palmprint experts, we developed a novel palmprint recognition system. The main contributions are as follows: 1) Statistics of major features in palmprints are quantitatively studied, 2) a segment-based matching and fusion algorithm is proposed to deal with the skin distortion and the varying discrimination power of different palmprint regions, and 3) to reduce the computational complexity, an orientation field-based registration algorithm is designed for registering the palmprints into the same coordinate system before matching and a cascade filter is built to reject the nonmated gallery palmprints in early stage. The proposed matcher is tested by matching 840 query palmprints against a gallery set of 13,736 palmprints. Experimental results show that the proposed matcher outperforms the existing matchers a lot both in matching accuracy and speed.	[Dai, Jifeng; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Dai, JF (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	djf05@mails.tsinghua.edu.cn; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn	Dai, Jifeng/AAF-7709-2019; Feng, Jianjiang/I-3386-2012; Dai, Jifeng/HGU-8741-2022	Dai, Jifeng/0000-0002-6785-0785	National Natural Science Foundation of China [61020106004, 60875017, 61005023, 61021063]; National 863 Hi-Tech Development Program of China [2008AA01Z123]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National 863 Hi-Tech Development Program of China(National High Technology Research and Development Program of China)	The authors would like to thank Abhishek Nagar for his help in revising this paper. This work was supported by the National Natural Science Foundation of China under Grants 61020106004, 60875017, 61005023, 61021063, and by the National 863 Hi-Tech Development Program of China under Grant 2008AA01Z123.	[Anonymous], 2012, POLYU PALMPR DAT; [Anonymous], 2011, DIR STAT WIK FREE EN; [Anonymous], 2006, BIOM TEST STAT; [Anonymous], 2011, HAND WIK FREE ENC; [Anonymous], 2012, 12007 ANSINISTITL; Ashbaugh D.R, 1999, CRC SER PR CRIM; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; Brunelli G. R., 1999, FINGER BONE JOINT IN, P167; Cappelli R., 2001, ADV PATTERN RECOGNIT, P371, DOI [DOI 10.1007/3-540-44732-6_38, 10.1007/3-540-44732-6_38]; Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597; Cummins H, 1961, FINGER PRINTS PALMS; Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9; Dutagaci H, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2890986; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Han CC, 2004, IMAGE VISION COMPUT, V22, P909, DOI 10.1016/j.imavis.2004.05.008; Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7; Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016; Jain A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P282, DOI 10.1109/ICIP.2001.958106; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Jain AK, 1999, P INT C IM PROC; Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011; Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252; Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014; KONG A, 2004, P 17 INT C PATT REC, V1; Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3; Kucken M, 2005, J THEOR BIOL, V235, P71, DOI 10.1016/j.jtbi.2004.12.020; Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214; Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73; Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Neurotechnology Inc, 2012, VERIFINGER; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; Ron Smith and Associates Inc., 2012, DEM PALM PRINTS; Ross A.A., 2006, HDB MULTIBIOMETRICS; Senior AW, 2001, IEICE T INF SYST, VE84D, P825; Shu W, 1998, OPT ENG, V37, P2359, DOI 10.1117/1.601756; Sun ZN, 2005, PROC CVPR IEEE, P279; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wan DR, 2006, IEEE T IMAGE PROCESS, V15, P1690, DOI 10.1109/TIP.2006.873442; Watson CI, 2000, P SOC PHOTO-OPT INS, V4043, P166, DOI 10.1117/12.381591; You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5; Yue F, 2009, PATTERN RECOGN, V42, P2841, DOI 10.1016/j.patcog.2009.03.015; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4	51	79	80	2	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1618	1632		10.1109/TPAMI.2011.237	http://dx.doi.org/10.1109/TPAMI.2011.237			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22156103				2022-12-18	WOS:000305188500013
J	Ouyang, WL; Tombari, F; Mattoccia, S; Di Stefano, L; Cham, WK				Ouyang, Wanli; Tombari, Federico; Mattoccia, Stefano; Di Stefano, Luigi; Cham, Wai-Kuen			Performance Evaluation of Full Search Equivalent Pattern Matching Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern matching; template matching; fast algorithms; full search equivalent algorithm; performance evaluation	MOTION ESTIMATION; RECOGNITION; FEATURES; FILTER	Pattern matching is widely used in signal processing, computer vision, and image and video processing. Full search equivalent algorithms accelerate the pattern matching process and, in the meantime, yield exactly the same result as the full search. This paper proposes an analysis and comparison of state-of-the-art algorithms for full search equivalent pattern matching. Our intention is that the data sets and tests used in our evaluation will be a benchmark for testing future pattern matching algorithms, and that the analysis concerning state-of-the-art algorithms could inspire new fast algorithms. We also propose extensions of the evaluated algorithms and show that they outperform the original formulations.	[Ouyang, Wanli; Cham, Wai-Kuen] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China; [Tombari, Federico] Univ Bologna, Comp Vis Lab, DEIS Dept Elect Comp Sci & Syst, Bologna, Italy; [Mattoccia, Stefano] Univ Bologna, Fac Engn, Dept Comp Sci & Syst, Bologna, Italy	Chinese University of Hong Kong; University of Bologna; University of Bologna	Ouyang, WL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.		cai, bo/G-1491-2010; Mattoccia, Stefano/AAV-6931-2021; Mattoccia, Stefano/C-5410-2018; Ouyang, Wanli/I-7135-2018	Mattoccia, Stefano/0000-0002-3681-7704; Mattoccia, Stefano/0000-0002-3681-7704; Ouyang, Wanli/0000-0002-9163-2761; Tombari, Federico/0000-0001-5598-5212				Ahumada Jr A. J., 1998, P SOC INFORMATION DI, V24, P305; Aksoy MS, 2004, J INTELL MANUF, V15, P569, DOI 10.1023/B:JIMS.0000034120.86709.8c; Alon Y., 2006, PROC IEEE C COMPUT V, V1, P689; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; BEI CD, 1985, IEEE T COMMUN, V33, P1132, DOI 10.1109/TCOM.1985.1096214; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; Ben-Yehuda M., 2005, P 12 INT C IM PROC, P834; Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Di Stefano L, 2003, MACH VISION APPL, V13, P213; Di Stefano L., 2003, P INT C IM PROC SEPT, V1, P269; Dufour RM, 2002, IEEE T IMAGE PROCESS, V11, P1385, DOI 10.1109/TIP.2002.806245; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Fitzgibbon A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1176; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; GEADAH YA, 1977, IEEE T COMPUT, V26, P435, DOI 10.1109/TC.1977.1674860; Gharavi-Alkhansari M, 2001, IEEE T IMAGE PROCESS, V10, P526, DOI 10.1109/83.913587; GIROD B, 1993, WHATS WRONG MEAN SQU, pCH15; Goshtasby AA, 2005, 2-D AND 3-D IMAGE REGISTRATION FOR MEDICAL, REMOTE SENSING, AND INDUSTRIAL APPLICATIONS, P1; Heckbert P. S., 1986, Computer Graphics, V20, P315, DOI 10.1145/15886.15921; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; KRATTENTHALER W, 1994, IEEE IMAGE PROC, P208, DOI 10.1109/ICIP.1994.413305; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lewis JP, 1994, PROC CANAD IMAG PROC, P120; LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809; Luczak T, 1997, IEEE T INFORM THEORY, V43, P1439, DOI 10.1109/18.623143; Mak CM, 2008, IEEE T CIRC SYST VID, V18, P735, DOI 10.1109/TCSVT.2008.918790; Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362; MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Moshe Y, 2009, IEEE T IMAGE PROCESS, V18, P2243, DOI 10.1109/TIP.2009.2025559; Ouyang W., 2010, P IEEE C COMP VIS PA; Ouyang WL, 2010, IEEE T PATTERN ANAL, V32, P165, DOI 10.1109/TPAMI.2009.104; Pan W.H., 2008, P 10 EUR C COMP VI 3; Pele O., 2007, P 8 AS C COMP VIS; Pele O, 2008, IEEE T PATTERN ANAL, V30, P1427, DOI 10.1109/TPAMI.2007.70794; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Schweitzer H, 2011, IEEE T PATTERN ANAL, V33, P459, DOI 10.1109/TPAMI.2010.105; Shin Y, 2008, PATTERN RECOGN LETT, V29, P1784, DOI 10.1016/j.patrec.2008.05.011; Simard PY, 1999, ADV NEUR IN, V11, P571; Tang F, 2007, IEEE T PATTERN ANAL, V29, P2120, DOI 10.1109/TPAMI.2007.1123; Tombari F, 2009, IEEE T PATTERN ANAL, V31, P129, DOI 10.1109/TPAMI.2008.46; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang HS, 1999, IEEE T IMAGE PROCESS, V8, P435, DOI 10.1109/83.748899; Wang Q., 2007, P IEEE C COMP VIS PA; Wei SD, 2008, IEEE T IMAGE PROCESS, V17, P2227, DOI 10.1109/TIP.2008.2004615; Wu X., 2005, INT J COMPUT VISION; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang RQ, 2009, INT CONF ACOUST SPEE, P1181, DOI 10.1109/ICASSP.2009.4959800; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	52	79	85	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					127	143		10.1109/TPAMI.2011.106	http://dx.doi.org/10.1109/TPAMI.2011.106			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576734				2022-12-18	WOS:000297069900009
J	Bianne-Bernard, AL; Menasri, F; Mohamad, RAH; Mokbel, C; Kermorvant, C; Likforman-Sulem, L				Bianne-Bernard, Anne-Laure; Menasri, Fares; Mohamad, Rami Al-Hajj; Mokbel, Chafic; Kermorvant, Christopher; Likforman-Sulem, Laurence			Dynamic and Contextual Information in HMM Modeling for Handwritten Word Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Latin and Arabic handwriting recognition; context-dependent HMMs; neural-network combination		This study aims at building an efficient word recognition system resulting from the combination of three handwriting recognizers. The main component of this combined system is an HMM-based recognizer which considers dynamic and contextual information for a better modeling of writing units. For modeling the contextual units, a state-tying process based on decision tree clustering is introduced. Decision trees are built according to a set of expert-based questions on how characters are written. Questions are divided into global questions, yielding larger clusters, and precise questions, yielding smaller ones. Such clustering enables us to reduce the total number of models and Gaussians densities by 10. We then apply this modeling to the recognition of handwritten words. Experiments are conducted on three publicly available databases based on Latin or Arabic languages: Rimes, IAM, and OpenHart. The results obtained show that contextual information embedded with dynamic modeling significantly improves recognition.	[Bianne-Bernard, Anne-Laure; Menasri, Fares; Kermorvant, Christopher] A2iA SA, F-75007 Paris, France; [Bianne-Bernard, Anne-Laure] Telecom ParisTech, F-75013 Paris, France; [Mohamad, Rami Al-Hajj] Lebanese Int Univ, Dept Comp Sci & Informat Technol, Beirut, Lebanon; [Likforman-Sulem, Laurence] Telecom ParisTech LTCI, Lab TSI, F-75013 Paris, France; [Mokbel, Chafic] Univ Balamand, Tripoli, Lebanon	IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; University Balamand	Bianne-Bernard, AL (corresponding author), A2iA SA, 40 Bis Rue Fabert, F-75007 Paris, France.	alb@a2ia.com; fm@a2ia.com; rami.elhajj@liu.edu.lb; chafic.mokbel@balamand.edu.lb; ck@a2ia.com; likforman@telecom-paristech.fr	Kermorvant, Christopher/AAS-7197-2020	Kermorvant, Christopher/0000-0002-7508-4080; ALHAJJ, Rami/0000-0001-5825-1062				Al-Hajj R, 2007, PROC INT CONF DOC, P959; [Anonymous], [No title captured]; Augustin E., 2006, INT WORKSHOP FRONTIE, P231; BIANNE AL, 2010, P SPIE DOCUMENT RECO; Caesar T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P408, DOI 10.1109/ICDAR.1993.395706; CHELBA C, 2002, P INT C SPOK LANG PR; Choisy C, 2007, PROC INT CONF DOC, P242; Ding W, 2008, INT C PATT RECOG, P1901; Duin RPW, 2002, INT C PATT RECOG, P765, DOI 10.1109/ICPR.2002.1048415; E-Hajj R, 2005, PROC INT CONF DOC, P893; ELABED H, 2008, P INT C FRONT HANDWR; ELHAJJ R, 2008, P SPIE DOCUMENT RECO; Espana-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141; Fink GA, 2007, PROC INT CONF DOC, P729; FRINKEN V, 2009, P COMP AN IM PATT, P189; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Grosicki Emmanuele, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1398, DOI 10.1109/ICDAR.2009.184; ISSAM B, 1999, IEEE T PATTERN ANAL, V21, P495; Kaltenmeier A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P139, DOI 10.1109/ICDAR.1993.395764; Kavallieratou E., 2002, International Journal on Document Analysis and Recognition, V4, P226, DOI 10.1007/s100320200079; KESSENTINI Y, 2008, P INT C FRONT HANDWR; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lee K., 1990, READINGS SPEECH RECO, P347; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Mohamad RAH, 2009, IEEE T PATTERN ANAL, V31, P1165, DOI 10.1109/TPAMI.2008.136; NATARAJAN P, 2006, P SUMM AR CHIN HANDW; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Palacios R., 2004, INT J IMAGE GRAPH, V4, P203, DOI [10.1142/S0219467804001373, DOI 10.1142/S0219467804001373]; Paquet T., 1993, Machine Vision and Applications, V6, P151, DOI 10.1007/BF01211938; Plamondon R, 1998, BIOL CYBERN, V78, P119, DOI 10.1007/s004220050419; Plotz T, 2009, INT J DOC ANAL RECOG, V12, P269, DOI 10.1007/s10032-009-0098-4; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199; RODRIGUEZ JA, 2008, P 1 INT C FRONT HAND; Schambach MP, 2003, PROC INT CONF DOC, P109; SCHUSSLER M, 1998, P 6 INT WORKSH FRONT, P505; SIRAT C, 1994, WRITING SYSTEMS COGN, V6; Suen CY, 1996, INT J IMAG SYST TECH, V7, P392, DOI 10.1002/(SICI)1098-1098(199624)7:4<392::AID-IMA14>3.0.CO;2-Y; TOSELLI AH, 2004, THESIS U POLITECNICA; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; Vinciarelli A, 2001, PATTERN RECOGN LETT, V22, P1043, DOI 10.1016/S0167-8655(01)00042-3; Wienecke M., 2005, International Journal on Document Analysis and Recognition, V7, P188, DOI 10.1007/s10032-004-0132-5; Young S. J., 1994, P HUM LANG TECHN, P307, DOI DOI 10.3115/1075812.1075885; Young SJ, 2006, HTK BOOK VERSION 3 4; ZEN H, 2003, P EUR, P3189; Zimmermann M, 2002, INT C PATT RECOG, P35, DOI 10.1109/ICPR.2002.1047394	45	79	79	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2066	2080		10.1109/TPAMI.2011.22	http://dx.doi.org/10.1109/TPAMI.2011.22			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21282849				2022-12-18	WOS:000293969000013
J	Stokman, H; Gevers, T				Stokman, Harro; Gevers, Theo			Selection and fusion of color models for image feature detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color; learning; feature detection; scene analysis		The choice of a color model is of great importance for many computer vision algorithms (e.g., feature detection, object recognition, and tracking) as the chosen color model induces the equivalence classes to the actual algorithms. As there are many color models available, the inherent difficulty is how to automatically select a single color model or, alternatively, a weighted subset of color models producing the best result for a particular task. The subsequent hurdle is how to obtain a proper fusion scheme for the algorithms so that the results are combined in an optimal setting. To achieve proper color model selection and fusion of feature detection algorithms, in this paper, we propose a method that exploits nonperfect correlation between color models or feature detection algorithms derived from the principles of diversification. As a consequence, a proper balance is obtained between repeatability and distinctiveness. The result is a weighting scheme which yields maximal feature discrimination. The method is verified experimentally for three different image feature detectors. The experimental results show that the fusion method provides feature detection results having a higher discriminative power than the standard weighting scheme. Further, it is experimentally shown that the color model selection scheme provides a proper balance between color invariance (repeatability) and discriminative power (distinctiveness).	Univ Amsterdam, Fac Sci, Intelligent Syst Lab, NL-1098 SJ Amsterdam, Netherlands; UAB, Comp Vis Ctr, ICREA, Barcelona 08193, Spain	University of Amsterdam; Autonomous University of Barcelona; Centre de Visio per Computador (CVC); ICREA	Stokman, H (corresponding author), Univ Amsterdam, Fac Sci, Intelligent Syst Lab, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	stokman@science.uva.nl; gevers@science.uva.nl			ICREA Funding Source: Custom	ICREA(ICREA)		Angulo J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P125; Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P311; Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083; MARKOWITZ H, 1952, J FINANCE, V0007; Moya MM, 1996, NEURAL NETWORKS, V9, P463, DOI 10.1016/0893-6080(95)00120-4; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039; SAPIRO G, 1996, IEEE T PATTERN ANAL, V18, P1582; Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P71; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824; Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; WOLFE P, 1959, ECONOMETRICA, V27, P382, DOI 10.2307/1909468	19	79	84	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					371	381		10.1109/TPAMI.2007.58	http://dx.doi.org/10.1109/TPAMI.2007.58			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224609	Green Submitted			2022-12-18	WOS:000243420500001
J	Shokoufandeh, A; Macrini, D; Dickinson, S; Siddiqi, K; Zucker, SW				Shokoufandeh, A; Macrini, D; Dickinson, S; Siddiqi, K; Zucker, SW			Indexing hierarchical structures using graph spectra	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structural indexing; graph spectra; object recognition; shock graphs	3-D OBJECT RECOGNITION; DISTANCE MEASURE; SHAPE; ALGORITHM; MODELS; SPACE	Hierarchical image structures are abundant in computer vision and have been used to encode part structure, scale spaces, and a variety of multiresolution features. In this paper, we describe a framework for indexing such representations that embeds the topological structure of a directed acyclic graph ( DAG) into a low- dimensional vector space. Based on a novel spectral characterization of a DAG, this topological signature allows us to efficiently retrieve a promising set of candidates from a database of models using a simple nearest- neighbor search. We establish the insensitivity of the signature to minor perturbation of graph structure due to noise, occlusion, or node split/ merge. To accommodate large- scale occlusion, the DAG rooted at each nonleaf node of the query " votes" for model objects that share that " part," effectively accumulating local evidence in a model DAG's topological subspaces. We demonstrate the approach with a series of indexing experiments in the domain of view- based 3D object recognition using shock graphs.	Coll Engn, Dept Comp Sci, Philadelphia, PA 19104 USA; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada; McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada; Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA	University of Toronto; McGill University; McGill University; Yale University	Shokoufandeh, A (corresponding author), Coll Engn, Dept Comp Sci, 3141 Chestnut St, Philadelphia, PA 19104 USA.	ashokouf@cs.drexel.edu; dmac@cs.toronto.edu; sven@cs.toronto.edu; siddiqi@cim.mcgill.ca; steven.zucker@yale.edu		Siddiqi, Kaleem/0000-0002-7347-9716				[Anonymous], P SIGMOD 96; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Biggs N, 1993, ALGEBRAIC GRAPH THEO, V2nd; Bohm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809; BOYER K, 1997, P 3 INT WORKSH VIS F; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; COSTA M, 1996, P INT WORKSH STRUCT, P130; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Cvetkovic D., 1990, LINEAR MULTILINEAR A, V28, P3, DOI [10.1080/03081089008818026, DOI 10.1080/03081089008818026]; Cvetkovic D. M., 1997, ENCY MATH ITS APPL, V66; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S; DIMITROV P, 2000, P INT C COMP VIS PAT; Drineas P, 2003, SIAM PROC S, P223; DRINEAS P, 2003, FAST MONTE CARLO ALG, V2; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; FLYNN PJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P119, DOI 10.1016/1049-9660(92)90012-R; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; GAROFALAKIS M, 2000, P ACM SIGMOD, P165; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Goldman R, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P436; Huet B, 2002, PATTERN RECOGN, V35, P1895, DOI 10.1016/S0031-3203(01)00172-8; Irniger C, 2004, INT C PATT RECOG, P383, DOI 10.1109/ICPR.2004.1334547; Katayama N., 1997, P ACM SIGMOD INT C M; KAUSHIK R, 2002, P INT C DAT ENG; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Lamdan Y., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P1407, DOI 10.1109/ROBOT.1988.12264; Lee D., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P264, DOI 10.1145/129712.129738; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; LOVASZ L, 1970, PERIOD MATH HUNG, V3, P1082; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Luo B, 2003, PATTERN RECOGN, V36, P2213, DOI 10.1016/S0031-3203(03)00084-0; Luo B, 2002, INT C PATT RECOG, P785, DOI 10.1109/ICPR.2002.1048135; MACRINI D, 2003, THESIS U TORONTO DEP; Messmer B. T., 1995, IAM95003 U BERN; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NEUMAIER A, 1982, LINEAR ALGEBRA APPL, V46, P9, DOI 10.1016/0024-3795(82)90022-2; Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P159, DOI 10.1145/275487.275505; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; Sengupta K., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P151, DOI 10.1109/ISCV.1995.476993; Sengupta K, 1998, COMPUT VIS IMAGE UND, V70, P177, DOI 10.1006/cviu.1997.0631; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7, P90, DOI 10.1109/TPAMI.1985.4767621; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Sossa H., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P811, DOI 10.1109/CVPR.1992.223252; Stewart G., 1990, MATRIX PERTURBATION; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WILKINSON J, 1965, ALGEBRAIC EIGNVALUE; WITKIN A, 1986, PIXELS PREDICATES; WONG AKC, 1989, IEEE T PATTERN ANAL, V11, P279, DOI 10.1109/34.21797; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [No title captured]	65	79	81	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1125	1140		10.1109/TPAMI.2005.142	http://dx.doi.org/10.1109/TPAMI.2005.142			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013759	Green Submitted			2022-12-18	WOS:000229024300011
J	Park, JS; Oh, YH; Ahn, SC; Lee, SW				Park, JS; Oh, YH; Ahn, SC; Lee, SW			Glasses removal from facial image using recursive error compensation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	International Conference on Audio-and Videos-Based Biometric Person Authentication	JUN, 2003	Guildford, ENGLAND			glasses removal; face recognition; face reconstruction; face synthesis; recursive error compensation	FACES	In this paper, we propose a new method of removing glasses from a human frontal facial image. We first detect the regions occluded by the glasses and generate a natural looking facial image without glasses by recursive error compensation using PCA reconstruction. The resulting image has no trace of the glasses frame or of the reflection and shade caused by the glasses. The experimental results show that the proposed method provides an effective solution to the problem of glasses occlusion and we believe that this method can also be used to enhance the performance of face recognition systems.	Korea Univ, Dept Comp Sci & Engn, Seoul 136701, South Korea; Korea Inst Sci & Technol, Seoul 136791, South Korea	Korea University; Korea Institute of Science & Technology (KIST)	Park, JS (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul 136701, South Korea.	jspark@image.korea.ac.kr; yhoh@image.korea.ac.kr; swlee@image.korea.ac.kr; asc@imrc.kist.re.kr	Lee, Seong-Whan/C-7928-2012					CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Hwang BW, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P278; Hwang BW, 2003, IEEE T PATTERN ANAL, V25, P365, DOI 10.1109/TPAMI.2003.1182099; HWANG BW, 2003, P INT C AUD VID BAS, P377; Jiang X, 1998, INT C PATT RECOG, P1071, DOI 10.1109/ICPR.1998.711877; Jing Z, 2000, INT C PATT RECOG, P933, DOI 10.1109/ICPR.2000.906227; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Park JS, 2003, LECT NOTES COMPUT SC, V2688, P369; SAITO Y, 1999, P INT C IM PROC, V4, P197; Wu HY, 2002, INT C PATT RECOG, P346, DOI 10.1109/ICPR.2002.1048310; Xiao Y, 2004, LECT NOTES COMPUT SC, V3072, P214	12	79	89	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					805	811		10.1109/TPAMI.2005.103	http://dx.doi.org/10.1109/TPAMI.2005.103			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	905LI	15875801				2022-12-18	WOS:000227569300013
J	Bulow, T				Bulow, T			Spherical diffusion for 3D surface smoothing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface smoothing; diffusion; spherical harmonics		A diffusion-based approach to surface smoothing is presented. Surfaces are represented as scalar functions defined on the sphere. The approach is equivalent to Gaussian smoothing on the sphere and is computationally efficient since it does not require iterative smoothing. Furthermore, it does not suffer from the well-known shrinkage problem. Evolution of important shape features ( parabolic curves) under diffusion is demonstrated. A nonlinear modification of the diffusion process is introduced in order to improve smoothing behavior of elongated and poorly centered objects.	Philips Res Labs, D-22335 Hamburg, Germany	Philips; Philips Research	Bulow, T (corresponding author), Philips Res Labs, Roentgenstr 24-26, D-22335 Hamburg, Germany.	thomas.buelow@philips.com						Ballard D.H., 1982, COMPUTER VISION; Belyaev A., 2003, ISR KOR BINATL C GEO, V2; BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013; Bulow T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P449, DOI 10.1109/TDPVT.2002.1024100; BULOW T, 2002, P EUROGRAPHICS; BULOW T, 2001, MSCIS0137 U PENNS CI; BULOW T, 2002, P 24 S PATT REC DAGM; Courant R., 1953, METHODS MATH PHYS, V1st English edition; DESBRUN M, 1999, P SIGGRAPH; DRISCOLL JR, 1994, ADV APPL MATH, V15, P202, DOI 10.1006/aama.1994.1008; ERTURK S, 1999, P BRIT MACH VIS C, P329; FREEDEN W, 1995, MATH METHOD APPL SCI, V18, P83, DOI 10.1002/mma.1670180202; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; Iijima T., 1962, BULL ELECT LAB, V26, P368; Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367; KANGASPUOSKARI M, 1993, J FLUID STRUCT, V7, P707, DOI 10.1006/jfls.1993.1041; KIN G, 1992, P 11 INT C PATT REC, VC, P638; KOENDERINK JJ, 1986, BIOL CYBERN, V53, P383, DOI 10.1007/BF00318204; Kyatkin A., 2001, ENG APPL NONCOMMUTAT; LINDEBERG T, 1994, ADV APPL STAT SER, V2, P225; MATHENY A, 1995, IEEE T PATTERN ANAL, V17, P967, DOI 10.1109/34.464561; Mokhtarian F, 2001, COMPUT VIS IMAGE UND, V83, P118, DOI 10.1006/cviu.2001.0919; Rosenberg S., 1997, LONDON MATH SOC STUD, DOI DOI 10.1017/CBO9780511623783; Schudy, 1979, P 6 C COMP APPL RAD; Sijbers J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P640; TANAKA K, 1993, P INT C INT ROB SYST; Tasdizen T, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P125, DOI 10.1109/VISUAL.2002.1183766; TAUBIN G, 1995, P SIGGRAPH; TAUBIN G, 2000, P EUROGRAPHICS; Waerden B.L. van der, 1974, GROUP THEORY QUANTUM; Weickert, 1996, ANISOTROPIC DIFFUSIO; WEICKERT J, 1997, GAUSSIAN SCALE SPACE; Weickert J., 1999, HDB COMPUTER VISION, V2, P423; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	35	79	79	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1650	1654		10.1109/TPAMI.2004.129	http://dx.doi.org/10.1109/TPAMI.2004.129			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573826				2022-12-18	WOS:000224388700011
J	Pieczynski, W				Pieczynski, W			Pairwise Markov chains	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian restoration; hidden data; image segmentation; iterative conditional estimation; hidden Markov chain; pairwise Markov chain; unsupervised classification	IMAGE SEGMENTATION; STATISTICAL-ANALYSIS; SPEECH RECOGNITION; MODELS; ALGORITHM; FAMILY; EM	We propose a new model called a Pairwise Markov Chain (PMC), which generalizes the classical Hidden Markov Chain (HMC) model. The generalization, which allows one to model more complex situations, in particular implies that in PMC the hidden process is not necessarily a Markov process. However, PMC allows one to use the classical Bayesian restoration methods like Maximum A Posteriori (MAP), or Maximal Posterior Mode (MPM). So, akin to HMC, PMC allows one to restore hidden stochastic processes, with numerous applications to signal and image processing, such as speech recognition, image segmentation, and symbol detection or classification, among others. Furthermore, we propose an original method of parameter estimation, which generalizes the classical Iterative Conditional Estimation (ICE) valid for of classical hidden Markov chain model, and whose extension to possibly non-Gaussian and correlated noise is briefly treated. Some preliminary experiments validate the interest of the new model.	Inst Natl Telecommun, Dept CITI, F-91000 Evry, France	IMT - Institut Mines-Telecom; Institut Polytechnique de Paris	Pieczynski, W (corresponding author), Inst Natl Telecommun, Dept CITI, 9 Rue Charles Fourier, F-91000 Evry, France.	Wojciech.Pieczynski@int-evry.fr	Pieczynski, Wojciech/AAW-4428-2020					Aas K, 1999, PATTERN RECOGN, V32, P703, DOI 10.1016/S0031-3203(98)00109-5; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BESAG J, 1986, J R STAT SOC B, V48, P259; CHEN JL, 1995, IEEE T IMAGE PROCESS, V4, P603, DOI 10.1109/83.382495; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; CHURCHILL GA, 1992, COMPUT CHEM, V16, P107, DOI 10.1016/0097-8485(92)80037-Z; COWELL RG, 1999, PROBABILISTIC NETWOR; DAI J, 1994, IEE P-VIS IMAGE SIGN, V141, P273, DOI 10.1049/ip-vis:19941321; Delignon Y, 1997, IEEE T IMAGE PROCESS, V6, P1364, DOI 10.1109/83.624951; Delmas JP, 1997, IEEE T SIGNAL PROCES, V45, P2613, DOI 10.1109/78.640732; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; ELJACOUBI A, 1999, IEEE T PATTERN ANAL, V21, P752; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206; KALEH GK, 1994, IEEE T COMMUN, V42, P2406, DOI 10.1109/26.297849; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Mignotte M, 2000, IEEE T IMAGE PROCESS, V9, P1216, DOI 10.1109/83.847834; Pieczynski W, 2000, IEEE T IMAGE PROCESS, V9, P308, DOI 10.1109/83.821750; Pieczynski W., 2000, Machine Graphics & Vision, V9, P705; QIAN W, 1989, J APPL STAT, V16, P267; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raphael C, 1999, IEEE T PATTERN ANAL, V21, P360, DOI 10.1109/34.761266; Salzenstein F., 1998, Traitement du Signal, V15, P119; WILSON ME, 1994, SCAND J CARING SCI, V8, P9, DOI 10.1111/j.1471-6712.1994.tb00216.x	26	79	83	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					634	639		10.1109/TPAMI.2003.1195998	http://dx.doi.org/10.1109/TPAMI.2003.1195998			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300010
J	Ahn, SJ; Rauh, W; Cho, HS; Warnecke, HJ				Ahn, SJ; Rauh, W; Cho, HS; Warnecke, HJ			Orthogonal distance fitting of implicit curves and surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit curve; implicit surface; curve fitting; surface fitting; orthogonal distance fitting; geometric distance; orthogonal contacting; nonlinear least squares; parameter estimation; Gauss-Newton method; parameter constraint; parametric model recovery; object segmentation; object classification; object reconstruction	SQUARES; OBJECTS; MOMENT; CIRCLE	Dimensional model fitting finds its applications in various fields of science and engineering and is a relevant subject in computer/machine vision and coordinate metrology. In this paper, we present two new fitting algorithms, distance-based and coordinate-based algorithm, for implicit surfaces and plane curves, which minimize the square sum of the orthogonal error distances between the model feature and the given data points. Each of the two algorithms has its own advantages and is to be purposefully applied to a specific fitting task, considering the implementation and memory space cost, and possibilities of observation weighting. By the new algorithms, the model feature parameters are grouped and simultaneously estimated in terms of form, position, and rotation parameters. The form parameters determine the shape of the model feature and the position/rotation parameters describe the rigid body motion of the model feature. The proposed algorithms are applicable to any kind of implicit surface and plane curve. In this paper, we also describe algorithm implementation and show various examples of orthogonal distance fit.	Fraunhofer Inst Mfg Egnn & Automat, Dept Informat Proc, IPA, D-70569 Stuttgart, Germany; Korea Adv Inst Sci & Technol, Dept Mech Engn, Yusung Gu, Taejon 305701, South Korea; Fraunhofer Soc, D-80636 Munich, Germany	Fraunhofer Gesellschaft; Korea Advanced Institute of Science & Technology (KAIST)	Ahn, SJ (corresponding author), Fraunhofer Inst Mfg Egnn & Automat, Dept Informat Proc, IPA, Nobelstr 12, D-70569 Stuttgart, Germany.	sja@ipa.fhg.de; wor@ipa.fhg.de; hscho@lca.kaist.ac.kr; warnecke@zv.fhg.de						Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7; Ahn SJ, 1999, INT J PATTERN RECOGN, V13, P987, DOI 10.1142/S0218001499000549; Ahn SJ, 2001, INT J PATTERN RECOGN, V15, P905, DOI 10.1142/S0218001401001222; AHN SJ, 1998, P 13 KOR AUT CONTR C, P1857; AHN SJ, 2002, P INT S ALG APPR, VJ; Altschuler M. D., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.182. Imaging Applications for Automated Industrial Inspection and Assembly, P187; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; Bennamoun M, 1997, IEEE T SYST MAN CY B, V27, P893, DOI 10.1109/3477.650052; BOGGS PT, 1987, SIAM J SCI STAT COMP, V8, P1052, DOI 10.1137/0908085; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BUTLER BP, 1994, 22894 DITC NAT PHYS; CAO XP, 1994, PATTERN RECOGN LETT, V15, P781, DOI 10.1016/0167-8655(94)90006-X; CHAUDHURI BB, 1991, PATTERN RECOGN LETT, V12, P1, DOI 10.1016/0167-8655(91)90021-D; *DIN, 1986, 32880 DIN; Draper N.R., 1998, APPL REGRESSION ANAL, V326; DRIESCHNER R, 1991, 13417 BCR EUR EN; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Fletcher R, 1987, PRACTICAL METHODS OP, V1; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Gardiner M., 1965, SCI AM, V213, P222; Gauss CF., 1963, THEORY MOTION HEAVEN; GOLDMAN RN, 1983, IEEE COMPUT GRAPH, V3, P21, DOI 10.1109/MCG.1983.263208; GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027; HOUGH PVC, 1953, Patent No. 3069654; HU G, 1995, P 5 INT C IM PROC IT, P345; *ISO, 2001, 1036062001 ISO; Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Press WH, 1988, NUMERICAL RECIPES C; Rosin PL, 2000, IEEE T PATTERN ANAL, V22, P726, DOI 10.1109/34.865190; SAFAEERAD R, 1992, PATTERN RECOGN LETT, V13, P497, DOI 10.1016/0167-8655(92)90067-A; Sampson CB, 1997, NUCL MED COMMUN, V18, P1, DOI 10.1097/00006231-199701000-00001; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SOURLIER D, 1995, THESIS ETH ZURICH SW; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TURNER DA, 1999, THESIS U HUDDERSFIEL; Voss K, 1999, IEEE T PATTERN ANAL, V21, P646, DOI 10.1109/34.777376; Voss K, 1997, IEEE T PATTERN ANAL, V19, P80, DOI 10.1109/34.566815; WAHL FM, 1984, 1452 IBM ZUR RES LAB	41	79	85	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					620	638						19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU					2022-12-18	WOS:000175187800005
J	Grenander, U; Miller, MI; Srivastava, A				Grenander, U; Miller, MI; Srivastava, A			Hilbert-Schmidt lower bounds for estimators on matrix Lie groups for ATR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose estimation; ATR; Hilbert-Schmidt bounds; Bayesian approach; performance analysis; orthogonal groups	TRACKING	Deformable template representations of observed imagery, model the variability of target pose via the actions of the matrix Lie groups on rigid templates. In this paper, we study the construction of minimum mean squared error estimators on the special orthogonal group, SO(n), for pose estimation. Due to the nonflat geometry of SO(n), the standard Bayesian formulation, of optimal estimators and their characteristics, requires modifications. By utilizing Hilbert-Schmidt metric defined on GL(n), a larger group containing SO(n), a mean squared criterion is defined on SO(n). The Hilbert-Schmidt estimate (HSE) is defined to be a minimum mean squared error estimator, restricted to SO(n). The expected error associated with the HSE is shown to be a lower bound. called the Hilbert-Schmidt bound (HSB), on the error incurred by any other estimator. Analysis and algorithms are presented for evaluating the HSE and the HSB in case of both ground-based and airborne targets.	Brown Univ, Div Appl Math, Providence, RI 02912 USA; Washington Univ, Dept Elect Engn, St Louis, MO 63130 USA; Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Brown University; Washington University (WUSTL); State University System of Florida; Florida State University	Grenander, U (corresponding author), Brown Univ, Div Appl Math, Providence, RI 02912 USA.		Miller, Michael I./A-3213-2010; Srivastava, Anuj/L-4705-2019					AGGARWAL JK, 1994, 20 WORK GROUP AUT TA; Amit Y., 1991, J AM STAT ASS; Boothby W. M., 1986, INTRO DIFFERENTIAL M; CHRISTENSEN GE, IEEE T IMAGE PROCESS; Golub G. H., 1996, MATRIX COMPUTATIONS; GRENANDER U, 1997, MONOGRAPH DIVISION A; Grenander U., 1993, GEN PATTERN THEORY; HENDRIKS H, 1991, J MULTIVARIATE ANAL, V38, P245, DOI 10.1016/0047-259X(91)90044-3; JACOBS SP, 1994, ELECT SIGNALS SYSTEM; JOSHI SC, 1995, P SPIES 1995 GEOM ME; JOSHI SC, 1995, P SPIES 1995 INT S O; KANATANI K, GROUP THEORETICAL ME; Lanterman AD, 1995, P SOC PHOTO-OPT INS, V2485, P309, DOI 10.1117/12.213096; Miller M. I., 1993, P NATL ACAD SCI, V90; MILLER MI, 1995, IEEE T SIGNAL PROCES, V43, P2678, DOI 10.1109/78.482117; MILLER MI, 1997, IEEE T IMAGE PROCESS, V6, P1; POLYA G, 1976, PROBLEMS THEOREMS AN; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SNYDER DL, 1993, J OPT SOC AM A, V10, P1014, DOI 10.1364/JOSAA.10.001014; SRIVASTAVA A, 1995, IEEE T SIGNAL PROCES, V43, P1282, DOI 10.1109/78.382418; SRIVASTAVA A, 1996, THESIS WASHINGTON U; Srivastava A., 1997, SYSTEMS CONTROL 21 C, V22; Steinberger M., 1994, ALGEBRA	24	79	84	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					790	802		10.1109/34.709572	http://dx.doi.org/10.1109/34.709572			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700003
J	Hamamoto, Y; Uchimura, S; Tomita, S				Hamamoto, Y; Uchimura, S; Tomita, S			A bootstrap technique for nearest neighbor classifier design	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						bootstrap; nearest neighbor classifier; error rate; peaking phenomenon; small training sample size; high dimensions; outlier	ERROR RATE ESTIMATION	A bootstrap technique for nearest neighbor classifier design is proposed. Our primary interest in designing a classifier is in small training sample size situations. Conventional bootstrapping techniques sample the training samples with replacement. On the other hand, our technique generates bootstrap samples by locally combining original training samples. The nearest neighbor classifier is designed on the bootstrap samples and is tested on the test samples independent of training samples. The performance of the proposed classifier is demonstrated on three artificial data sets and one real data set. Experimental results show that the nearest neighbor classifier designed on the bootstrap samples outperforms the conventional k-NN classifiers as well as the edited 1-NN classifiers, particularly in high dimensions.	OSHIMA NATL COLL MARITIME TECHNOL, OSHIMA 74221, JAPAN		Hamamoto, Y (corresponding author), YAMAGUCHI UNIV, FAC ENGN, UBE, YAMAGUCHI 755, JAPAN.							Chandrasekaran B., 1979, Journal of Cybernetics and Information Science, V2, P12; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fix E., 1952, DISCRIMINATORY ANAL; Fix E., 1951, 2149004 USAF SCH AV; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103, DOI 10.1109/TPAMI.1987.4767875; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Hamamoto Y., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P819, DOI 10.1109/ICDAR.1995.602027; HAMAMOTO Y, 1996, P 13 INT C PATT REC, V3, P250; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628, DOI 10.1109/TPAMI.1987.4767957; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326, DOI 10.1109/34.250849	22	79	83	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					73	79		10.1109/34.566814	http://dx.doi.org/10.1109/34.566814			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528		Green Submitted			2022-12-18	WOS:A1997WE52800009
J	ALNUWEIRI, HM; PRASANNA, VK				ALNUWEIRI, HM; PRASANNA, VK			PARALLEL ARCHITECTURES AND ALGORITHMS FOR IMAGE COMPONENT LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE COMPONENT LABELING; IMAGE COMPUTATIONS; PARALLEL ALGORITHMS; PARALLEL ARCHITECTURES	MESH-CONNECTED COMPUTERS; CELLULAR LOGIC; MULTIPROCESSOR; PROCESSOR; VISION; MACHINE; SYSTEM; ARRAY	In recent years, a considerable amount of research has been done on the problem of labeling digitized images. Because connectivity in images possesses both local and global properties, different algorithmic techniques have been proposed to exploit one or both of these properties. This paper provides a characterization and survey of the various parallel techniques proposed for this problem. Parallel architectures and parallel models of computation that implement these techniques are also studied.	UNIV SO CALIF,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089	University of Southern California	ALNUWEIRI, HM (corresponding author), UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1Z4,BC,CANADA.		Alnuweiri, Hussein/AAE-1470-2020					Agrawal A., 1987, Proceedings of the 1987 International Conference on Parallel Processing, P783; AGRAWALA AK, 1977, COMPUT VISION GRAPH, V6, P538, DOI 10.1016/S0146-664X(77)80015-4; Aho A.V, 1979, DESIGN ANAL COMPUTER; AHUJA N, 1984, IEEE T PATTERN ANAL, V6, P463, DOI 10.1109/TPAMI.1984.4767551; Alnuweiri H. M., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P931, DOI 10.1109/CVPR.1988.196344; ALNUWEIRI HM, 1989, PARALLEL COMPUT, V12, P71, DOI 10.1016/0167-8191(89)90007-0; ALNUWEIRI HM, 1991, IEEE T PATTERN ANAL, V13, P202, DOI 10.1109/34.67649; ALNUWEIRI HM, 1991, ALGORITHMICA, V6, P698, DOI 10.1007/BF01759068; ALNUWEIRI HM, IEEE T COMPUT, V40, P105; ALNUWEIRI HM, 1989, IEEE T CIRCUITS  OCT, P1365; ALNUWEIRI HM, 1991, PARALLEL ARCHITECTUR; ANDERSON RJ, 1988, VLSI ARCHITECTURES A, P81; ANNARATONE M, 1987, IEEE T COMPUT, V36, P1523, DOI 10.1109/TC.1987.5009502; ATALLAH M, 1986, P IEEE S F COMPUT SC, P222; BATCHER KE, 1980, IEEE T COMPUT, V29, P836, DOI 10.1109/TC.1980.1675684; BEYER WT, 1969, THESIS MIT CAMBRIDGE; BORODIN A, 1985, J COMPUT SYST SCI, V30, P130, DOI 10.1016/0022-0000(85)90008-X; BOUKNIGHT WJ, 1972, PR INST ELECTR ELECT, V60, P369, DOI 10.1109/PROC.1972.8647; BUEHRER RE, 1982, IEEE T COMPUT, V31, P1035, DOI 10.1109/TC.1982.1675920; CANTONI V, 1987, PARALLEL COMPUTER VI; COLE R, 1987, ALGORITHMICA, V3, P329; COXETER HSM, 1961, INTRO GEOMETRY, P62; CYPHER R, 1989, IEEE T PATTERN ANAL, V11, P258, DOI 10.1109/34.21794; Cypher R., 1987, Proceedings of the 1987 Workshop on Computer Architecture for Pattern Analysis and Machine Intelligence: CAPAMI '87 (Cat. No.TH0203-0), P5; CYPHER RE, 1990, IEEE T COMPUT, V39, P276, DOI 10.1109/12.45215; DOSHI KA, 1987, IEEE T COMPUT, V36, P460, DOI 10.1109/TC.1987.1676928; DUFF MJB, 1986, CELLULAR LOGIC IMAGE; DYER CD, 1981, IEEE T PATTERN ANAL, P29; DYER CR, 1982, MULTICOMPUTERS IMAGE, P409; FISHER AF, 1986, CONTACT DERMATITIS, P338; FOUNTAIN T, 1987, PROCESSOR ARRAYS ARC; GRANT G, 1981, COMPUT VISION GRAPH, V17, P225, DOI 10.1016/0146-664X(81)90003-4; GRAY SB, 1971, IEEE T COMPUT, VC 20, P551, DOI 10.1109/T-C.1971.223289; Hillis W., 1985, CONNECTION MACHINE; HINKLE EB, 1987, J PARALLEL DISTR COM, V4, P45, DOI 10.1016/0743-7315(87)90008-6; HWANG K, 1989, IEEE T COMPUT, V38; HWANG K, 1990, JUN P ACM INT C SUP, P7; HWANG K, 1987, COMPUTER ARCHITECTUR; IBRAHIM HAH, 1987, J PARALLEL DISTR COM, V4, P546, DOI 10.1016/0743-7315(87)90030-X; Ja'Ja' J., 1983, Integration, The VLSI Journal, V1, P305, DOI 10.1016/S0167-9260(83)80004-2; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; KOSARAJU SR, 1979, 11TH P ANN ACM S THE, P231; KUMAR V, 1986, 1986 P INT C PAR PRO, P270; KUMAR VKP, 1987, J PARALLEL DISTR COM, V4, P173, DOI 10.1016/0743-7315(87)90003-7; KUMAR VP, 1989, IEEE T PATTERN ANAL, V11, P1194; KUNG HT, 1986, DISTRIB COMPUT, V1, P246, DOI 10.1007/BF01660036; LEIGHTON FT, 1981, P IEEE S F COMPUT SC, P85; LEVIALDI S, 1972, COMMUN ACM, V15, P7, DOI 10.1145/361237.361240; LI HW, 1989, IEEE T PATTERN ANAL, V11, P233, DOI 10.1109/34.21792; LITTLE JJ, 1989, IEEE T PATTERN ANAL, V11, P244, DOI 10.1109/34.21793; LUMIA R, 1983, COMPUT VISION GRAPH, V22, P287, DOI 10.1016/0734-189X(83)90071-3; MARBERG JM, 1988, ALGORITHMICA, V3, P561, DOI 10.1007/BF01762132; Mead C. A., 1979, INTRO VLSI SYSTEMS; MILGRAM DL, 1976, COMPUT GRAPHICS IMAG, V5, P172; MILLER R, 1985, IEEE T PATTERN ANAL, V7, P216, DOI 10.1109/TPAMI.1985.4767645; MILLER R, 1987, SIAM J COMPUT, V16, P38, DOI 10.1137/0216004; MILLER R, 1988, 5TH P MIT C ADV RES, P163; MILLER R, 1985, 1985 P INT C PAR PRO, P697; MILLER R, 1987, HYPERCUBE MULTIPROCE, P418; Minsky M., 1969, PERCEPTRONS; NASSIMI D, 1982, J ACM, V29, P642, DOI 10.1145/322326.322329; NASSIMI D, 1981, IEEE T COMPUT, V30, P101, DOI 10.1109/TC.1981.6312172; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; NATH D, 1983, IEEE T COMPUT, V32, P569, DOI 10.1109/TC.1983.1676279; PARKINSON D, 1991, PARALLEL ARCHITECTUR; PARKINSON D, 1988, 33RD P IEEE COMP SOC, P196; PRESTON K, 1983, COMPUTER, V16, P36, DOI 10.1109/MC.1983.1654164; PRESTON K, 1971, COMPUT AUTOM, P609; PRZYTULA KW, 1987, AUG SPIE S OPT OPT A; REISIS D, 1987, JUN P INT C SUP ATH; ROBINSON IN, 1982, P IEEE CUSTOM INTEGR; ROSENFELD A, 1966, J ACM, V4; ROSENFELD A, 1970, J ACM            JAN; Rosenfeld A., 1982, DIGITAL PICTURE PROC; ROSENFELD A, 1983, IEEE COMPUT, V16; SAAD Y, 1988, IEEE T COMPUT, V37, P867, DOI 10.1109/12.2234; SAMET H, 1988, IEEE T PATTERN ANAL, V10, P579, DOI 10.1109/34.3918; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SANZ JLC, 1988, IEEE T PATTERN ANAL, V10, P830, DOI 10.1109/34.9106; SCHERSON ID, 1989, J PARALLEL DISTR COM, V7, P232, DOI 10.1016/0743-7315(89)90019-1; Shiloach Y., 1982, J ALGORITHMS, V3; SHU DB, 1987, MINIMUM SPANNING TRE; STONE HS, 1971, IEEE T COMPUT, V20; STOUT QF, 1986, COMMUNICATION; Sunwoo M. H., 1987, Proceedings of the 1987 Workshop on Computer Architecture for Pattern Analysis and Machine Intelligence: CAPAMI '87 (Cat. No.TH0203-0), P27; TANIMOTO SL, 1984, J PARALLEL DISTR COM, V1, P105, DOI 10.1016/0743-7315(84)90001-7; TARJAN R, 1984, 25TH P ANN S F COMP; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; THOMPSON CD, 1979, 11TH P ANN ACM S THE; TSENG PS, 1985, P INT C PARALLEL PRO; Tucker L. W., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P124; Ullman J., 1984, COMPUTATIONAL ASPECT; UNGER SH, 1958, P IRE, V46, P1744, DOI 10.1109/JRPROC.1958.286755; WALLACE RS, 1989, IEEE T PATTERN ANAL, V11, P227, DOI 10.1109/34.21791; WYLLIE JC, 1979, THESIS CORNELL U; YANG XD, 1988, P IEEE C COMPUT VISI; 1985, INTEL CONCURRENT COM; 1986, NCUBE PRODUCT REPORT	98	79	80	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1992	14	10					1014	1034		10.1109/34.159904	http://dx.doi.org/10.1109/34.159904			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR944					2022-12-18	WOS:A1992JR94400004
J	AYACHE, N; LUSTMAN, F				AYACHE, N; LUSTMAN, F			TRINOCULAR STEREO VISION FOR ROBOTICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTER VISION; EDGE SEGMENTS; MOBILE ROBOTS; STEREO VISION; 3-D MAPS; TRINOCULAR	ALGORITHM	We present an original approach for building a three-dimensional description of the environment of a robot using three cameras. The main advantages of trinocular versus binocular stereo are simplicity, reliability, and accuracy. We believe that these advantages now make trinocular stereo vision of practical use for many robotics applications. The technique has been successfully applied to several indoor and industrial scenes. Experimental results are presented and discussed.			AYACHE, N (corresponding author), INST NATL RECH INFORMAT & AUTOMAT, BP 105, F-78153 LE CHESNAY, FRANCE.							AYACHE N, 1988, INT J ROBOT RES, V7, P45, DOI 10.1177/027836498800700605; AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; AYACHE N, 1987, 1ST P INT C COMP VIS, P422; AYACHE N, 1989, VISION STEREOSCOPIQU; AYACHE N, 1987, AUG INT S ROB RES SA; AYACHE N, 1988, THESIS U PARIS SUD O; AYACHE N, 1987, AUG P INT JOINT C AR; AYACHE N, 1988, OCT P INT C PATT REC; AYACHE N, 1990, ARTIFICAL VISION  MO; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BAKER HH, 1983, JUN P IM UND WORKSH, P327; Barnard S. T, 1987, 10TH P IJCAI MIL, P832; BERTHOD M, 1984, AUG P INT C PATT REC, P841; BURR DJ, 1977, 805 U ILL COORD SCI; BURR DJ, 1977, AUG P IJCAI 5, P583; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DERICHE R, 1987, INT J COMPUT VISION, V2; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P66; Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15; FAUGERAS OD, IN PRESS; GERHARD A, 1986, OCT P INT C PATT REC, P512; GIRAUDON G, 1987, INRIA605 RAPP RECH; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GROSSMAN P, 1988, 4TH P ALV VIS C AVC; GUREWITZ E, 1986, OCT P INT C PATT REC, P966; ITO M, 1986, IEEE T PATTERN ANAL, V8, P524, DOI 10.1109/TPAMI.1986.4767817; Ito M., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P9; JAIN R, 1987, IEEE T PATTERN ANAL, V9, P356, DOI 10.1109/TPAMI.1987.4767919; LUSTMAN F, 1987, THESIS PARIS ORSAY; MARIMONT DH, 1986, MAY P IEEE COMP SOC, P7; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MOHR R, 1984, P 4 C REC FORM INT A, P71; MOHR R, 1984, AUG P INT C PATT REC, P71; NISHIHARA K, 1984, 1ST INT S ROB RES, P489; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OHTA Y, 1986, OCT P INT C PATT REC, P519; Pietikainen M., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P2; PIETIKAINEN M, 1987, AUG P NATO ADV WORKS; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; RANDALL G, 1990, 1ST P EUR C COMP VIS, P601; SAINTVINCENT AR, 1986, THESIS U P SABATIER; SKORDAS T, 1987, IMAG RR677I64 LIFIA; STEWART C, 1988, 768 U WISC MAD TECH; TOSCANI G, 1987, THESIS PARIS ORSAY; YACHIDA M, 1986, ORD INT S ROB RES, P11; YACHIDA M, 1986, OCT P INT C PATT REC, P1041	47	79	83	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					73	85		10.1109/34.67633	http://dx.doi.org/10.1109/34.67633			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EX773		Green Submitted			2022-12-18	WOS:A1991EX77300008
J	He, JZ; Zhang, SL; Yang, M; Shan, YH; Huang, TJ				He, Jianzhong; Zhang, Shiliang; Yang, Ming; Shan, Yanhu; Huang, Tiejun			BDCN: Bi-Directional Cascade Network for Perceptual Edge Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Edge detection; bi-directional cascade network; scale enhancement; convolutional neural network	BOUNDARIES; FEATURES	Exploiting multi-scale representations is critical to improve edge detection for objects at different scales. To extract edges at dramatically different scales, we propose a bi-directional cascade network (BDCN) architecture, where an individual layer is supervised by labeled edges at its specific scale, rather than directly applying the same supervision to different layers. Furthermore, to enrich multi-scale representations learned by each layer of BDCN, we introduce a scale enhancement module (SEM), which utilizes dilated convolution to generate multi-scale features, instead of using deeper CNNs. These new approaches encourage the learning of multi-scale representations in different layers and detect edges that are well delineated by their scales. Learning scale dedicated layers also results in a compact network with a fraction of parameters. We evaluate our method on three datasets, i.e., BSDS500, NYUDv2, and Multicue, and achieve ODS F-measure of 0.832, 2.7 percent higher than current state-of-the-art on the BSDS500 dataset. We also applied our edge detection result to other vision tasks. Experimental results show that, our method further boosts the performance of image segmentation, optical flow estimation, and object proposal generation.	[He, Jianzhong; Zhang, Shiliang; Huang, Tiejun] Peking Univ, Sch EECS, Dept Comp Sci, Beijing 100871, Peoples R China; [Yang, Ming; Shan, Yanhu] Horizon Robot Inc, Beijing 100800, Peoples R China; [Huang, Tiejun] Peng Cheng Lab, Shenzhen 518066, Peoples R China	Peking University; Peng Cheng Laboratory	Zhang, SL (corresponding author), Peking Univ, Sch EECS, Dept Comp Sci, Beijing 100871, Peoples R China.	jianzhonghe@pku.edu.cn; slzhang.jdl@pku.edu.cn; m-yang4@u.northwestern.edu; yanhu.shan@gmail.com; tjhuang@pku.edu.cn		Yang, Ming/0000-0003-1691-6817	National Key Research and Development Program of China [2018YFE0118400]; Beijing Natural Science Foundation [JQ18012]; Natural Science Foundation of China [61936011, 61425025, 61620106009, 61572050, 91538111]	National Key Research and Development Program of China; Beijing Natural Science Foundation(Beijing Natural Science Foundation); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant No. 2018YFE0118400, in part by Beijing Natural Science Foundation under Grant No. JQ18012, in part by the Natural Science Foundation of China under Grant No. 61936011, 61425025, 61620106009, 61572050, and 91538111.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392; Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65; Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng RX, 2018, LECT NOTES COMPUT SC, V11210, P570, DOI 10.1007/978-3-030-01231-1_35; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36; Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G., 2018, P INT C LEARNING REP, P1, DOI 10.48550/arXiv.1703.09844; Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50; Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52; Ke W, 2017, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2017.40; Kittler J, 1983, IMAGE VISION COMPUT, V1, P37, DOI DOI 10.1016/0262-8856(83)90006-9; Kokkinos I.., 2016, P 4 INT C LEARN REPR, P1; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Li XX, 2017, PROC CVPR IEEE, P6459, DOI 10.1109/CVPR.2017.684; Liao Y, 2017, IEEE INT CON MULTI, P859, DOI 10.1109/ICME.2017.8019358; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; LIN GS, 2016, PROC CVPR IEEE, P3194, DOI DOI 10.1109/CVPR.2016.348; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mely DA, 2016, VISION RES, V120, P93, DOI 10.1016/j.visres.2015.11.007; Murthy VN, 2016, PROC CVPR IEEE, P2240, DOI 10.1109/CVPR.2016.246; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Ren XF, 2008, LECT NOTES COMPUT SC, V5304, P533; Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Shuai B., 2016, ARXIV161108986; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Wang YP, 2019, IEEE T IMAGE PROCESS, V28, P1285, DOI 10.1109/TIP.2018.2874279; Wang YP, 2017, PROC CVPR IEEE, P1724, DOI 10.1109/CVPR.2017.187; Witkin AP, 1987, READINGS COMPUTER VI, P329; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252; Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu D, 2017, ADV NEUR IN, V30; Yan SY, 2018, SIGNAL PROCESS-IMAGE, V61, P73, DOI 10.1016/j.image.2017.11.005; Yang Jianwei, 2016, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2016.28; Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191; Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zheng WB, 2019, IEEE INT CONF COMP V, P2999, DOI 10.1109/ICCVW.2019.00362; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	76	78	80	42	82	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					100	113		10.1109/TPAMI.2020.3007074	http://dx.doi.org/10.1109/TPAMI.2020.3007074			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750803				2022-12-18	WOS:000728561300009
J	Luthi, M; Gerig, T; Jud, C; Vetter, T				Luthi, Marcel; Gerig, Thomas; Jud, Christoph; Vetter, Thomas			Gaussian Process Morphable Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical shape modeling; Gaussian processes; image analysis; non-rigid registration	ACTIVE SHAPE MODELS; SEGMENTATION; REGISTRATION	Models of shape variations have become a central component for the automated analysis of images. An important class of shape models are point distribution models (PDMs). These models represent a class of shapes as a normal distribution of point variations, whose parameters are estimated from example shapes. Principal component analysis (PCA) is applied to obtain a low-dimensional representation of the shape variation in terms of the leading principal components. In this paper, we propose a generalization of PDMs, which we refer to as Gaussian Process Morphable Models (GPMMs). We model the shape variations with a Gaussian process, which we represent using the leading components of its Karhunen-Loeve expansion. To compute the expansion, we make use of an approximation scheme based on the Nystrom method. The resulting model can be seen as a continuous analog of a standard PDM. However, while for PDMs the shape variation is restricted to the linear span of the example data, with GPMMs we can define the shape variation using any Gaussian process. For example, we can build shape models that correspond to classical spline models and thus do not require any example data. Furthermore, Gaussian processes make it possible to combine different models. For example, a PDM can be extended with a spline model, to obtain a model that incorporates learned shape characteristics but is flexible enough to explain shapes that cannot be represented by the PDM. We introduce a simple algorithm for fitting a GPMM to a surface or image. This results in a non-rigid registration approach whose regularization properties are defined by a GPMM. We show how we can obtain different registration schemes, including methods for multi-scale or hybrid registration, by constructing an appropriate GPMM. As our approach strictly separates modeling from the fitting process, this is all achieved without changes to the fitting algorithm. To demonstrate the applicability and versatility of GPMMs, we perform a set of experiments in typical usage scenarios in medical image analysis and computer vision: The model-based segmentation of 3D forearm images and the building of a statistical model of the face. To complement the paper, we have made all our methods available as open source.	[Luthi, Marcel; Gerig, Thomas; Vetter, Thomas] Univ Basel, Dept Math & Comp Sci, CH-4001 Basel, Switzerland; [Jud, Christoph] Univ Hosp Basel, Med Image Anal Ctr, CH-4056 Basel, Switzerland	University of Basel; University of Basel	Luthi, M (corresponding author), Univ Basel, Dept Math & Comp Sci, CH-4001 Basel, Switzerland.	marcel.luethi@unibas.ch; thomas.gerig@unibas.ch; christoph.jud@unibas.ch; thomas.vetter@unibas.ch	Jud, Christoph/AAN-1590-2020	Luethi, Marcel/0000-0002-9686-2195	Swiss National Science foundation [SNF153297]	Swiss National Science foundation(Swiss National Science Foundation (SNSF)European Commission)	This work has been funded as part of the Swiss National Science foundation project in the context of the project SNF153297. We thank Sandro Schonborn and Volker Roth for interesting and enlightening discussion. A special thanks goes to Ghazi Bouabene and Christoph Langguth, for their work on the Scalismo software, in which all the methods are implemented.	Albrecht T., 2008, CVPR, P1; AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; [Anonymous], 2013, SCALISMO SCALABLE IM; Berlinet A., 2004, REPRODUCING KERNEL H, V3; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Bruveris M, 2012, MULTISCALE MODEL SIM, V10, P1344, DOI 10.1137/110846324; COOTES TF, 1995, IMAGE VISION COMPUT, V13, P403, DOI 10.1016/0262-8856(95)99727-I; Davatzikos C, 2003, IEEE T MED IMAGING, V22, P414, DOI 10.1109/TMI.2003.809688; DAVIS MH, 1995, COMP MED SY, P81, DOI 10.1109/CBMS.1995.465443; Duvenaud D., 2014, AUTOMATIC MODEL CONS; Fortun D, 2015, COMPUT VIS IMAGE UND, V134, P1, DOI 10.1016/j.cviu.2015.02.008; Galun M, 2015, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2015.257; Gerig T, 2014, LECT NOTES COMPUT SC, V8674, P413, DOI 10.1007/978-3-319-10470-6_52; Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732; Grenander U., 2007, PATTERN THEORY REPRE, V1; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004; Holden M, 2008, IEEE T MED IMAGING, V27, P111, DOI 10.1109/TMI.2007.904691; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Joshi SC, 1997, LECT NOTES COMPUT SC, V1230, P381; Kainmueller D, 2013, MED IMAGE ANAL, V17, P429, DOI 10.1016/j.media.2012.11.006; Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616; Kybic J, 2003, IEEE T IMAGE PROCESS, V12, P1427, DOI 10.1109/TIP.2003.813139; Le YH, 2013, PROC CVPR IEEE, P1878, DOI 10.1109/CVPR.2013.245; Li M., 2010, P 27 INT C MACH LEAR, P631, DOI DOI 10.5555/3104322.3104403; Lipman Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602142; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422; Luthi M, 2013, LECT NOTES COMPUT SC, V8184, P66, DOI 10.1007/978-3-319-02267-3_9; Luthi Marcel, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P196, DOI 10.1007/978-3-642-23123-0_20; Luthi M., 2012, INSIGHT J; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Nain D, 2007, IEEE T MED IMAGING, V26, P598, DOI 10.1109/TMI.2007.893284; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Pizer S.M., 2017, STAT SHAPE DEFORMATI, P137; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618; Rueckert D., 2001, P MICCAI, V2208, P77; Schmah T, 2013, LECT NOTES COMPUT SC, V8149, P203, DOI 10.1007/978-3-642-40811-3_26; SCHOLKOPF B, 2005, P 22 INT C MACH LEAR, P776; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sommer S, 2013, J MATH IMAGING VIS, V46, P292, DOI 10.1007/s10851-012-0409-0; Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603; Styner MA, 2003, LECT NOTES COMPUT SC, V2732, P63; Tagliasacchi A., 2016, P SIGGRAPH ASIA COUR; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Wang YM, 2000, IEEE T PATTERN ANAL, V22, P738, DOI 10.1109/34.865192; Younes L, 2010, APPL MATH SCI, V171, P1, DOI 10.1007/978-3-642-12055-8; Zhao Z, 2005, LECT NOTES COMPUT SC, V3749, P221; Zhu JK, 2009, PROC CVPR IEEE, P1319, DOI 10.1109/CVPRW.2009.5206512	52	78	82	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1860	1873		10.1109/TPAMI.2017.2739743	http://dx.doi.org/10.1109/TPAMI.2017.2739743			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28816655	Green Submitted, Green Accepted, Bronze			2022-12-18	WOS:000437271100006
J	Wan, J; Guo, GD; Li, SZ				Wan, Jun; Guo, Guodong; Li, Stan Z.			Explore Efficient Local Features from RGB-D Data for One-Shot Learning Gesture Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						One-shot learning; gesture reco gnition; RGB-D data; bag of visual words model	BAG	Availability of handy RGB-D sensors has brought about a surge of gesture recognition research and applications. Among various approaches, one shot learning approach is advantageous because it requires minimum amount of data. Here, we provide a thorough review about one-shot learning gesture recognition from RGB-D data and propose a novel spatiotemporal feature extracted from RGB-D data, namely mixed features around sparse keypoints (MFSK). In the review, we analyze the challenges that we are facing, and point out some future research directions which may enlighten researchers in this field. The proposed MFSK feature is robust and invariant to scale, rotation and partial occlusions. To alleviate the insufficiency of one shot training samples, we augment the training samples by artificially synthesizing versions of various temporal scales, which is beneficial for coping with gestures performed at varying speed. We evaluate the proposed method on the Chalearn gesture dataset (CGD). The results show that our approach outperforms all currently published approaches on the challenging data of CGD, such as translated, scaled and occluded subsets. When applied to the RGB-D datasets that are not one-shot (e.g., the Cornell Activity Dataset-60 and MSR Daily Activity 3D dataset), the proposed feature also produces very promising results under leave-one-out cross validation or one-shot learning.	[Wan, Jun; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Room 1411,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China; [Wan, Jun; Li, Stan Z.] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Room 1411,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China; [Guo, Guodong] West Virginia Univ, Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; West Virginia University	Wan, J (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Room 1411,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China.; Wan, J (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Room 1411,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China.	jun.wan@nlpr.ia.ac.cn; guodong.guo@mail.wvu.edu; szli@nlpr.ia.ac.cn			Division Of Computer and Network Systems [1066197] Funding Source: National Science Foundation	Division Of Computer and Network Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))		[Anonymous], P 21 ACM INT C MULT, DOI DOI 10.1145/2502081.2502099; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bin Liang, 2013, Lecture Notes on Software Engineering, V1, P339, DOI 10.7763/LNSE.2013.V1.73; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bradski G., 2000, DOBBS J SOFTWARE TOO, V3; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dollar P., 2005, P IEEE INT WORKSH VI, P65, DOI [DOI 10.1109/VSPETS.2005.1570899, 10.1109/VSPETS.2005.1570899]; Elmezain Mahmoud, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3850, DOI 10.1109/ICPR.2010.938; Escalante H. J., 2013, ARXIV13104822; Fanello SR, 2013, J MACH LEARN RES, V14, P2617; Fanello SR, 2013, LECT NOTES COMPUT SC, V7887, P31; Farhadi A, 2007, PROC CVPR IEEE, P2676; Faria DR, 2014, IEEE ROMAN, P732, DOI 10.1109/ROMAN.2014.6926340; Goussies NA, 2014, J MACH LEARN RES, V15, P3667; Guyon Isabelle, 2013, Advances in Depth Image Analysis and Applications. International Workshop, WDIA 2012. Selected and Invited Papers: LNCS 7854, P186, DOI 10.1007/978-3-642-40303-3_19; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I, 2014, MACH VISION APPL, V25, P1929, DOI 10.1007/s00138-014-0596-3; Hernandez-Vela A, 2014, PATTERN RECOGN LETT, V50, P112, DOI 10.1016/j.patrec.2013.09.009; Jiang F, 2015, J MACH LEARN RES, V16, P227; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010; Klaser Alexander, 2008, BMVC; Konecny J, 2014, J MACH LEARN RES, V15, P2513; Krishnan R, 2015, PATTERN RECOGN, V48, P1302, DOI 10.1016/j.patcog.2014.10.026; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lee H, 2016, ADV NEURAL INFORM PR, V19; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Lui YM, 2012, J MACH LEARN RES, V13, P3297; Malgireddy MR, 2013, J MACH LEARN RES, V14, P2189; Malgireddy MR, 2012, COMP VIS PATT REC WO, P43; McAuliffe J.D., 2008, ADV NEURAL INFORM PR, P121; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; Ming Y.u.e., 2012, ICME, V2012, P344, DOI DOI 10.1109/ICME.2012.8; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; Ney H, 1999, IEEE SIGNAL PROC MAG, V16, P64, DOI 10.1109/79.790984; Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Otsu N, 1975, AUTOMATICA, V11, P23, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076, 10.1109/tsmc.1979.4310076]; Parisi GI, 2015, FRONT NEUROROBOTICS, V9, P1, DOI 10.3389/fnbot.2015.00003; Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52; Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40; Porikli F, 2013, IEEE SIGNAL PROC MAG, V30, P190, DOI 10.1109/MSP.2013.2241312; Qian K., 2013, INT J SMART HOME, V7, P203; Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9; Reifinger S, 2007, LECT NOTES COMPUT SC, V4552, P728; Roh MC, 2008, PATTERN RECOGN, V41, P1124, DOI 10.1016/j.patcog.2007.07.013; Shao, 2013, P 23 INT JOINT C ART; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Wan J, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023017; Wan J, 2014, IEEE T IMAGE PROCESS, V23, P3152, DOI 10.1109/TIP.2014.2328181; Wan J, 2013, J MACH LEARN RES, V14, P2549; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang Heng, 2009, BMVC, P1; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wu D., 2012, 2012 IEEE COMP VIS P, P7; Wu D, 2013, IEEE T CIRC SYST VID, V23, P236, DOI 10.1109/TCSVT.2012.2203731; Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161; Yang RD, 2010, IEEE T PATTERN ANAL, V32, P462, DOI 10.1109/TPAMI.2009.26; Zhang Chenyang, 2012, J COMP VIS IMAGE PRO, V2, P12; Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005	68	78	79	1	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1626	1639		10.1109/TPAMI.2015.2513479	http://dx.doi.org/10.1109/TPAMI.2015.2513479			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26731641				2022-12-18	WOS:000379926200011
J	Paisitkriangkrai, S; Shen, CH; van den Hengel, A				Paisitkriangkrai, Sakrapee; Shen, Chunhua; van den Hengel, Anton			Pedestrian Detection with Spatially Pooled Features and Structured Ensemble Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pedestrian detection; boosting; ensemble learning; spatial pooling; structured learning	CLASSIFICATION; GRADIENTS; PYRAMIDS; CASCADE	Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the prescribed range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. In addition, in order to achieve high object detection performance, we propose a new approach to extracting low-level visual features based on spatial pooling. Incorporating spatial pooling improves the translational invariance and thus the robustness of the detection process. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the proposed structured ensemble learning method with spatially pooled features. The result is the current best reported performance on the Caltech-USA pedestrian detection dataset.	[Paisitkriangkrai, Sakrapee; Shen, Chunhua; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Shen, Chunhua; van den Hengel, Anton] Australian Res Council Ctr Excellence Robot Vis, Melbourne, Vic, Australia	University of Adelaide	Paisitkriangkrai, S; Shen, CH; van den Hengel, A (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.; Shen, CH; van den Hengel, A (corresponding author), Australian Res Council Ctr Excellence Robot Vis, Melbourne, Vic, Australia.	paulp@cs.adelaide.edu.au; chunhua.shen@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au			Data to Decisions CRC Centre	Data to Decisions CRC Centre	This work was in part supported by Data to Decisions CRC Centre. C. Shen is the corresponding author.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Appel R., 2013, INT C MACH LEARN, P594, DOI DOI 10.5555/3042817.3043003; Behley J, 2013, IEEE INT C INT ROBOT, P4195, DOI 10.1109/IROS.2013.6696957; Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91; Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310; Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen G, 2013, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2013.235; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Coates Adam, 2011, P 28 INT C MACH LEAR, P921; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI DOI 10.1109/CVPR.2008.4587581; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Geiger A., 2011, ADV NEURAL INFORM PR, VVol. 24, P1467; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Hsu M.-J., 2012, COMP STAT, V28, p[1, 2]; Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076; Joachims T, 2006, PROC 22 ACM SIGKDD I, P217, DOI DOI 10.1145/1150402.1150429; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Komori O, 2011, IEICE T INF SYST, VE94D, P1863, DOI 10.1587/transinf.E94.D.1863; Komori O, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-314; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu C., 2009, THESIS MIT MA; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107; Masnadi-Shirazi H, 2011, IEEE T PATTERN ANAL, V33, P294, DOI 10.1109/TPAMI.2010.71; Narasimhan H., 2013, PROC INT C MACH LEAR, P516; Narasimhan H, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P167; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414; Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411; Paisitkriangkcrai S, 2008, IEEE T CIRC SYST VID, V18, P1140, DOI 10.1109/TCSVT.2008.928213; Paisitkriangkrai S., 2015, PEDESTRIAN DETECTION; Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36; Paisitkriangkrai S, 2013, IEEE I CONF COMP VIS, P1057, DOI 10.1109/ICCV.2013.135; Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371; Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18; Pepe M S, 2000, Biostatistics, V1, P123; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P, 2002, ADV NEUR IN, V14, P1311; Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Wu JX, 2008, IEEE T PATTERN ANAL, V30, P369, DOI 10.1109/TPAMI.2007.1181; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Wu S.H., 2008, P 14 ACM SIGKDD INT, P749, DOI [DOI 10.1145/1401890.1401980, 10.1145/1401890.1401980]; Xu J., 2014, ARXIV14085400; Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757	69	78	84	1	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1243	1257		10.1109/TPAMI.2015.2474388	http://dx.doi.org/10.1109/TPAMI.2015.2474388			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26336118	Green Submitted			2022-12-18	WOS:000375609000015
J	Mudunuri, SP; Biswas, S				Mudunuri, Sivaram Prasad; Biswas, Soma			Low Resolution Face Recognition Across Variations in Pose and Illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; stereo matching; multidimensional scaling; low resolution; super resolution	IMAGE SUPERRESOLUTION; COUPLED DICTIONARY	We propose a completely automatic approach for recognizing low resolution face images captured in uncontrolled environment. The approach uses multidimensional scaling to learn a common transformation matrix for the entire face which simultaneously transforms the facial features of the low resolution and the high resolution training images such that the distance between them approximates the distance had both the images been captured under the same controlled imaging conditions. Stereo matching cost is used to obtain the similarity of two images in the transformed space. Though this gives very good recognition performance, the time taken for computing the stereo matching cost is significant. To overcome this limitation, we propose a reference-based approach in which each face image is represented by its stereo matching cost from a few reference images. Experimental evaluation on the real world challenging databases and comparison with the state-of-the-art super-resolution, classifier based and cross modal synthesis techniques show the effectiveness of the proposed algorithm.	[Mudunuri, Sivaram Prasad; Biswas, Soma] Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Indian Institute of Science (IISC) - Bangalore	Mudunuri, SP; Biswas, S (corresponding author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.	sivaram.prasad@ee.iisc.ernet.in; soma.biswas@ee.iisc.ernet.in						Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bhatt HS, 2014, IEEE T IMAGE PROCESS, V23, P5654, DOI 10.1109/TIP.2014.2362658; Biswas S, 2013, IEEE T PATTERN ANAL, V35, P3037, DOI 10.1109/TPAMI.2013.68; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bohne J, 2014, LECT NOTES COMPUT SC, V8690, P679, DOI 10.1007/978-3-319-10605-2_44; Castillo CD, 2011, PROC CVPR IEEE, P537, DOI 10.1109/CVPR.2011.5995559; Castillo CD, 2009, IEEE T PATTERN ANAL, V31, P2298, DOI 10.1109/TPAMI.2009.123; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; Chang JM, 2007, LECT NOTES COMPUT SC, V4844, P733; Criminisi A, 2007, INT J COMPUT VISION, V71, P89, DOI 10.1007/s11263-006-8525-1; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; Ding L, 2012, IEEE SIGNAL PROC LET, V19, P721, DOI 10.1109/LSP.2012.2215586; Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Gross R., 2007, GUIDE CMU MULTIPIE D; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310; Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489; Kanade T, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P954; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957; Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134; Mignon A., 2012, P AS C COMP VIS, P1; Milborrow S., 2008, P EUR C COMP VIS; Nishiyama M, 2009, PROC CVPR IEEE, P1115, DOI 10.1109/CVPRW.2009.5206750; Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Shi JG, 2015, IEEE SIGNAL PROC LET, V22, P554, DOI 10.1109/LSP.2014.2364262; Vageeswaran P, 2013, IEEE T IMAGE PROCESS, V22, P1362, DOI 10.1109/TIP.2012.2228498; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x; WEBB AR, 1995, PATTERN RECOGN, V28, P753, DOI 10.1016/0031-3203(94)00135-9; Weinberger KQ, 2008, P 25 INT C MACH LEAR, P1160, DOI DOI 10.1145/1390156.1390302; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881; Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977; Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423	41	78	81	0	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					1034	1040		10.1109/TPAMI.2015.2469282	http://dx.doi.org/10.1109/TPAMI.2015.2469282			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046843				2022-12-18	WOS:000374164700017
J	Anand, S; Mittal, S; Tuzel, O; Meer, P				Anand, Saket; Mittal, Sushil; Tuzel, Oncel; Meer, Peter			Semi-Supervised Kernel Mean Shift Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semi-supervised kernel clustering; log det Bregman divergence; mean shift clustering		Mean shift clustering is a powerful nonparametric technique that does not require prior knowledge of the number of clusters and does not constrain the shape of the clusters. However, being completely unsupervised, its performance suffers when the original distance metric fails to capture the underlying cluster structure. Despite recent advances in semi-supervised clustering methods, there has been little effort towards incorporating supervision into mean shift. We propose a semi-supervised framework for kernel mean shift clustering (SKMS) that uses only pairwise constraints to guide the clustering procedure. The points are first mapped to a high-dimensional kernel space where the constraints are imposed by a linear transformation of the mapped points. This is achieved by modifying the initial kernel matrix by minimizing a log det divergence-based objective function. We show the advantages of SKMS by evaluating its performance on various synthetic and real datasets while comparing with state-of-the-art semi-supervised clustering algorithms.	[Anand, Saket] Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08903 USA; [Meer, Peter] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA; [Mittal, Sushil] Scibler Corp, Santa Clara, CA 95054 USA; [Tuzel, Oncel] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA	Rutgers State University New Brunswick; Rutgers State University New Brunswick	Anand, S (corresponding author), Indraprastha Inst Informat Technol, Delhi 110020, India.	anands@iiitd.ac.in; mittal@scibler.com; oncel@merl.com						Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BASU S, 2004, P 10 INT C KDD NEW Y; Basu S, 2009, CH CRC DATA MIN KNOW, P1; Bilenko M, 2004, ICML; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chen HF, 2005, IEEE T SYST MAN CY B, V35, P578, DOI 10.1109/TSMCB.2005.846659; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Comaniciu D., 2003, P IEEE C COMP VIS PA, V1, P56; Cristianini N., 2000, INTRO SUPPORT VECTOR; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Ester M., 1996, P 2 INT C KNOWL DISC, P226; FEIFEI L, 2004, P IEEE CVPR WGMBV NE; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Ghani R., 2002, P 19 INT C MACH LEAR, V2, P187; Hager GD, 2004, PROC CVPR IEEE, P790; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Jain P, 2012, J MACH LEARN RES, V13, P519; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Kulis B, 2009, J MACH LEARN RES, V10, P341; Kulis B, 2009, MACH LEARN, V74, P1, DOI 10.1007/s10994-008-5084-4; Lelis L, 2009, IEEE DATA MINING, P842, DOI 10.1109/ICDM.2009.143; Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44; LU Z, 2008, P CVPR; Lu ZW, 2010, LECT NOTES COMPUT SC, V6316, P1; NADLER B, 2007, P NIPS, P1017; Ng AY, 2002, ADV NEUR IN, V14, P849; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ruiz C, 2010, DATA MIN KNOWL DISC, V21, P345, DOI 10.1007/s10618-009-0157-y; Sheiretov Y, 2007, Proceedings of the ASME Turbo Expo 2007, Vol 5, P97; SIM T, 2002, P IEEE INT C AUT FAC; SUBBARAO R, 2006, P IEEE COMP SOC C CO, P1168; Tuzel O, 2005, IEEE I CONF COMP VIS, P18; Tuzel O, 2009, IEEE I CONF COMP VIS, P48, DOI 10.1109/ICCV.2009.5459204; Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wang J, 2004, LECT NOTES COMPUT SC, V3022, P238	41	78	94	1	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1201	1215		10.1109/TPAMI.2013.190	http://dx.doi.org/10.1109/TPAMI.2013.190			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353281	Green Submitted			2022-12-18	WOS:000337124200012
J	Tosato, D; Spera, M; Cristani, M; Murino, V				Tosato, Diego; Spera, Mauro; Cristani, Marco; Murino, Vittorio			Characterizing Humans on Riemannian Manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pedestrian characterization; covariance descriptors; Riemannian manifolds	HEAD POSE ESTIMATION; CLASSIFICATION; COVARIANCE; DESCRIPTOR	In surveillance applications, head and body orientation of people is of primary importance for assessing many behavioral traits. Unfortunately, in this context people are often encoded by a few, noisy pixels so that their characterization is difficult. We face this issue, proposing a computational framework which is based on an expressive descriptor, the covariance of features. Covariances have been employed for pedestrian detection purposes, actually a binary classification problem on Riemannian manifolds. In this paper, we show how to extend to the multiclassification case, presenting a novel descriptor, named weighted array of covariances, especially suited for dealing with tiny image representations. The extension requires a novel differential geometry approach in which covariances are projected on a unique tangent space where standard machine learning techniques can be applied. In particular, we adopt the Campbell-Baker-Hausdorff expansion as a means to approximate on the tangent space the genuine (geodesic) distances on the manifold in a very efficient way. We test our methodology on multiple benchmark datasets, and also propose new testing sets, getting convincing results in all the cases.	[Tosato, Diego; Spera, Mauro; Cristani, Marco; Murino, Vittorio] Univ Verona, Dipartimento Informat, I-37134 Verona, Italy; [Cristani, Marco; Murino, Vittorio] Ist Italiano Tecnol, Pattern Anal & Comp Vis PAVIS Dept, I-16163 Genoa, Italy	University of Verona; Istituto Italiano di Tecnologia - IIT	Tosato, D (corresponding author), Univ Verona, Dipartimento Informat, Str Grazie 15, I-37134 Verona, Italy.	diego.tosato@univr.it; mauro.spera@univr.it; marco.cristani@univr.it; vittorio.murino@univr.it		Murino, Vittorio/0000-0002-8645-2328				Agarwal A, 2006, LECT NOTES COMPUT SC, V3851, P50; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; BA S, 2007, P INT WORKSH CLASS E; Ba S.O., 2005, P IEEE INT C MULT EX, P1330; Bar-Hillel A, 2010, LECT NOTES COMPUT SC, V6314, P127, DOI 10.1007/978-3-642-15561-1_10; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Chang C.-C., 2013, LIBSVM LIB SUPPORT V; Chavel I., 2006, RIEMANNIAN GEOMETRY; Cherian A, 2011, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2011.6126523; Cristani M., 2011, P BRIT MACH VIS C; Cristani M., 2011, P WORKSH INT HUM BEH; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P., 2013, PIOTRS IMAGE VIDEO M; Dollar P., 2009, P BRIT MACH VIS C; Donoser M., 2008, P INT C PATT REC, P1, DOI DOI 10.1109/ICPR.2008.4761350; Duistermaat JJ, 2000, LIE GROUPS; Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Fanelli G., 2011, P IEEE C COMP VIS PA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fillard P, 2007, IEEE T MED IMAGING, V26, P1472, DOI 10.1109/TMI.2007.899173; Fisher R., 2013, CAVIAR CASE SCENARIO; Fletcher P. T., 2008, P 2008 IEEE C COMPUT, P1; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Gall J., 2009, P IEEE C COMP VIS PA; Gourier N., 2013, HEAD POS IM DAT POIN; Gross R., 2007, TR0708 CARN MELL U R; Huang D., 2011, P IEEE C COMP VIS PA; Huang YZ, 2008, PROC CVPR IEEE, P2000; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Odobez J.M., 2013, IDIAP HEAD POSE DATA; Odobez JM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1379; Orozco J., 2009, P BRIT MACH VIS C; Ricci E, 2009, IEEE IMAGE PROC, P2593, DOI 10.1109/ICIP.2009.5413994; Robertson N, 2006, LECT NOTES COMPUT SC, V3952, P402; Robertson NM, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/530325; Sabzmeydani P, 2007, PROC CVPR IEEE, P1251; Saul LK, 1999, MACH LEARN, V37, P75, DOI 10.1023/A:1007649326333; Schwartz W., 2009, P IEEE INT C COMP VI; Schwartz W.R., 2013, ETHZ DATA SET APPEAR; Sernesi E., 1993, LINEAR ALGEBRA GEOME; Shi W, 2010, PR IEEE COMP DESIGN, P321, DOI 10.1109/ICCD.2010.5647721; Smith K, 2008, IEEE T PATTERN ANAL, V30, P1212, DOI 10.1109/TPAMI.2007.70773; Sommer S, 2010, LECT NOTES COMPUT SC, V6316, P43, DOI 10.1007/978-3-642-15567-3_4; Tao H, 2007, PETS WORKSH; Tosato D., 2013, ARCO ARRRAY COVARIAN; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949; Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007; Voit M, 2008, LECT NOTES COMPUT SC, V4625, P307; Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102; Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9; Wu B., 2008, P IEEE C COMP VIS PA; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; Yao J., 2008, P 8 INT WORKSH VIS S; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	63	78	79	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1972	1984		10.1109/TPAMI.2012.263	http://dx.doi.org/10.1109/TPAMI.2012.263			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787347				2022-12-18	WOS:000320381400012
J	Kim, TH; Lee, KM; Lee, SU				Kim, Tae Hoon; Lee, Kyoung Mu; Lee, Sang Uk			Learning Full Pairwise Affinities for Spectral Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spectral segmentation; hierarchical segmentation; affinity estimation; semi-supervised learning	IMAGE SEGMENTATION; TEXTURE; CUTS	Segmenting a single image into multiple coherent groups remains a challenging task in the field of computer vision. Particularly, spectral segmentation which uses the global information embedded in the spectrum of a given image's affinity matrix is a major trend in image segmentation. This paper focuses on the problem of efficiently learning a full range of pairwise affinities gained by integrating local grouping cues for spectral segmentation. We first construct a sparse multilayer graph whose nodes are both the pixels and the oversegmented regions obtained by an unsupervised segmentation algorithm. By applying the semi-supervised learning strategy to this graph, the intra and interlayer affinities between all pairs of nodes can be estimated without iteration. These pairwise affinities are then applied into the spectral segmentation algorithms. In this paper, two types of spectral segmentation algorithms are introduced: K-way segmentation and hierarchical segmentation. Our algorithms provide high-quality segmentations which preserve object details by directly incorporating the full-range connections. Moreover, since our full affinity matrix is defined by the inverse of a sparse matrix, its eigendecomposition can be efficiently computed. The experimental results on the BSDS and MSRC image databases demonstrate the superiority of our segmentation algorithms in terms of relevance and accuracy compared with existing popular methods.	[Kim, Tae Hoon; Lee, Kyoung Mu; Lee, Sang Uk] Seoul Natl Univ, ASRI, Dept Elect & Comp Engn, Seoul 151744, South Korea	Seoul National University (SNU)	Kim, TH (corresponding author), Seoul Natl Univ, ASRI, Dept Elect & Comp Engn, 1 Gwanak Ro, Seoul 151744, South Korea.	th33@snu.ac.kr; kyoungmu@snu.ac.kr; sanguk@ipl.snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036				Arbelaez P., 2008, P IEEE C COMP VIS PA; Arbelaez P., 2006, P IEEE WORKSH PERC O; ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Belongie S., 1998, P EUR C COMP VIS; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Brin S., 1998, P INT C WORLD WID WE; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carreira-Perpinan M. A., 2006, P INT C MACH LEARN; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COUR T, 2005, P IEEE C COMP VIS PA; Donoser M., 2009, P IEEE INT C COMP VI; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; FOWLKES C, 2003, P IEEE C COMP VIS PA; GDALYAHU Y, 1999, P IEEE C COMP VIS PA; Golub Gene H., 2013, MATRIX COMPUTATION, V3; KIM T, 2010, P IEEE C COMP VIS PA; KOHLI P., 2008, P IEEE C COMP VIS PA; LEUNG T, 1998, P EUR C COMP VIS; Maire Michael, 2008, P IEEE C COMP VIS PA; Malisiewicz T., 2007, P BRIT MACH VIS C; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MEILA M, 2005, P INT C MACH LEARN; Mobahi H, 2011, INT J COMPUT VISION, V95, P86, DOI 10.1007/s11263-011-0444-0; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Pan J.-Y., 2004, P ACM SIGKDD 10 INT; Pock T., 2009, P IEEE C COMP VIS PA; PUZICHA J, 1997, P IEEE C COMP VIS PA; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161; SFIKAS G, 2008, P IEEE C COMP VIS PA; Sharon E., 2000, P IEEE C COMP VIS PA; Sharon E, 2006, NATURE, V442, P810, DOI 10.1038/nature04977; Shental N., 2003, P IEEE INT C COMP VI; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; WANG J, 2008, P IEEE C COMP VIS PA; Wang S, 2005, IEEE T PATTERN ANAL, V27, P546, DOI 10.1109/TPAMI.2005.84; Weiss Y., 1999, P IEEE INT C COMP VI; Yu S., 2003, P IEEE INT C COMP VI; YU SX, 2004, P IEEE C COMP VIS PA; ZABIH R, 2004, P IEEE C COMP VIS PA; Zhou D, 2003, P NEUR INF PROC SYST	44	78	88	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1690	1703		10.1109/TPAMI.2012.237	http://dx.doi.org/10.1109/TPAMI.2012.237			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681996	Green Submitted			2022-12-18	WOS:000319060600012
J	Chin, TJ; Yu, J; Suter, D				Chin, Tat-Jun; Yu, Jin; Suter, David			Accelerated Hypothesis Generation for Multistructure Data via Preference Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geometric model fitting; robust estimation; hypothesis generation; residual sorting; multiple structures		Random hypothesis generation is integral to many robust geometric model fitting techniques. Unfortunately, it is also computationally expensive, especially for higher order geometric models and heavily contaminated data. We propose a fundamentally new approach to accelerate hypothesis sampling by guiding it with information derived from residual sorting. We show that residual sorting innately encodes the probability of two points having arisen from the same model, and is obtained without recourse to domain knowledge (e. g., keypoint matching scores) typically used in previous sampling enhancement methods. More crucially, our approach encourages sampling within coherent structures and thus can very rapidly generate all-inlier minimal subsets that maximize the robust criterion. Sampling within coherent structures also affords a natural ability to handle multistructure data, a condition that is usually detrimental to other methods. The result is a sampling scheme that offers substantial speed-ups on common computer vision tasks such as homography and fundamental matrix estimation. We show on many computer vision data, especially those with multiple structures, that ours is the only method capable of retrieving satisfactory results within realistic time budgets.	[Chin, Tat-Jun; Yu, Jin; Suter, David] Univ Adelaide, Sch Comp Sci, ACVT, Adelaide, SA 5005, Australia	University of Adelaide	Chin, TJ (corresponding author), Univ Adelaide, Sch Comp Sci, ACVT, Adelaide, SA 5005, Australia.	tjchin@cs.adelaide.edu.au; jin.yu@cs.adelaide.edu.au; dsuter@cs.adelaide.edu.au		Suter, David/0000-0001-6306-3023	Australian Research Council [DP0878801]	Australian Research Council(Australian Research Council)	The authors would like to thank the reviewers for their insightful comments. This work was partly supported by the Australian Research Council grant DP0878801.	Capel D., 2005, P BRIT MACH VIS C; Chin T.-J., 2010, P 11 EUR C COMP VIS; Chum O., 2005, P IEEE C COMP VIS PA; Chum O., 2003, P DTSCH ARB MUST; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Enqvist O., 2009, P BRIT MACH VIS C; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P IEEE C COMP VIS PA; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Kanazawa Y., 2004, P BRIT MACH VIS C; Li H., 2009, P 12 IEEE INT C COMP; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009; Matas J., 2005, P 10 IEEE INT C COMP; Ni K., 2009, P 12 IEEE INT C COMP; NISTER D, 2003, P 9 IEEE INT C COMP; Raguram R., 2008, P 10 EUR C COMP VIS; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; Sattler T., 2009, P 12 IEEE INT C COMP; Sedgewick R., 2010, ALGORITHMS; Serradell E., 2010, P 11 EUR C COMP VIS; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199; TRON R, 2007, P IEEE C COMP VIS PA	25	78	85	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					625	638		10.1109/TPAMI.2011.169	http://dx.doi.org/10.1109/TPAMI.2011.169			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	21844630				2022-12-18	WOS:000300581700001
J	Xu, D; Chang, SF				Xu, Dong; Chang, Shih-Fu			Video event recognition using kernel methods with multilevel temporal alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						event recognition; news video; concept ontology; Temporally Aligned Pyramid Matching; video indexing; earth mover's distance	DISTANCE; MODELS	In this work, we systematically study the problem of event recognition in unconstrained news video sequences. We adopt the discriminative kernel-based method for which video clip similarity plays an important role. First, we represent a video clip as a bag of orderless descriptors extracted from all of the constituent frames and apply the earth mover's distance (EMD) to integrate similarities among frames from two clips. Observing that a video clip is usually comprised of multiple subclips corresponding to event evolution over time, we further build a multilevel temporal pyramid. At each pyramid level, we integrate the information from different subclips with Integer-value-constrained EMD to explicitly align the subclips. By fusing the information from the different pyramid levels, we develop Temporally Aligned Pyramid Matching (TAPM) for measuring video similarity. We conduct comprehensive experiments on the TRECVID 2005 corpus, which contains more than 6,800 clips. Our experiments demonstrate that 1) the TAPM multilevel method clearly outperforms single-level EMD (SLEMD) and 2) SLEMD outperforms keyframe and multiframe-based detection methods by a large margin. In addition, we conduct in-depth investigation of various aspects of the proposed techniques such as weight selection in SLEMD, sensitivity to temporal clustering, the effect of temporal alignment, and possible approaches for speedup. Extensive analysis of the results also reveals intuitive interpretation of video event recognition through video subclip alignment at different levels.	[Xu, Dong] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Chang, Shih-Fu] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Columbia University	Xu, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave,Blk N4, Singapore 639798, Singapore.	dongxu@ntu.edu.sg; sfchang@ee.columbia.edu	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730	Singapore A*STAR SERC [082 101 0018]; US Government	Singapore A*STAR SERC(Agency for Science Technology & Research (A*STAR)); US Government	This material is based upon work funded by Singapore A*STAR SERC Grant (082 101 0018) and the US Government. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the US Government. The authors also thank Akira Yanagawa and Wei Jiang for their help in generating the automatically detected concept scores from video and Tian Tsong Ng and Shuicheng Yan for their helpful discussions and suggestions. Part of this work was performed while Dong Xu was a postdoctoral research scientist at Columbia University.	AMIR A, 2005, P NIST TREC VID RETR; Boiman O, 2005, IEEE I CONF COMP VIS, P462; Bosch A., 2007, P 6 ACM INT C IM VID, V5, P401, DOI [10.1145/1282280.1282340, DOI 10.1145/1282280]; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; CAMPBELL M, 2006, P NIST TREC VID RETR; CAO J, 2006, P NIST TREC VID RETR; Chang C., 2008, LIBSVM LIB SUPPORT V; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Ebadollahi S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P881, DOI 10.1109/ICME.2006.262691; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Fanti C, 2005, PROC CVPR IEEE, P1166; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; GRAY RM, 1975, ANN PROBAB, V3, P315, DOI 10.1214/aop/1176996402; Harris C., 1988, P ALV VIS C; HAUPTMANN AG, 2006, P NIST TREC VID RETR; Jensen P.A., 2003, OPERATIONS RES MODEL; Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LIU J, 2006, P NIST TREC VID RETR; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; MORENO P, 2003, P NEUR INF PROC SYST; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63; NIEBLES J, 2005, P BRIT MACH VIS C; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Peursum P, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P399, DOI 10.1109/PERCOM.2003.1192764; Platt J., 1999, ADV LARGE MARGIN CLA; Rachev S., 1984, THEOR PROBAB APPL+, V29, P625, DOI 10.1137/1129093; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Smeaton A.F., 2006, MIR 2006 P 8 ACM INT, P321, DOI DOI 10.1145/1178677.1178722; VARMA M, 2007, P IEEE INT C COMP VI; VEERARAGHAVAN A, 2006, P IEEE COMP SOC C CO, P959; XU D, 2007, P IEEE C COMP VIS PA; Yanagawa A., 2007, COLUMBIA U BASELINE; YANAGAWA A, 2006, BRIEF DESCRIPTIONS V; Zhang D, 2005, PROC CVPR IEEE, P611; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; 2008, TRECVID; 2007, COLUMBIA U BASELINE; 2007, DTO LSCOM LEXICON DE	46	78	84	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1985	1997		10.1109/TPAMI.2008.129	http://dx.doi.org/10.1109/TPAMI.2008.129			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787246				2022-12-18	WOS:000259110000011
J	Yu, J				Yu, J			General c-means clustering model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						partitional clustering; mean; fixed point; optimality test; cluster validity; density estimator; Occam's razor; Hessian matrix	LEARNING VECTOR QUANTIZATION; CONVERGENCE THEOREM; PATTERN-RECOGNITION; FUZZY; ALGORITHM; OPTIMIZATION; COUNTEREXAMPLES; CLASSIFICATION; SHIFT	Partitional clustering is an important part of cluster analysis. Based on various theories, numerous clustering algorithms have been developed, and new clustering algorithms continue to appear in the literature. It is known that Occam's razor plays a pivotal role in data-based models, and partitional clustering is categorized as a data-based model. However, no relation had previously been discovered between Occam's razor and partitional clustering, as we discuss in this paper. The three main contributions of this paper can be summarized as follows: 1) According to a novel definition of the mean, a unifying generative framework for partitional clustering algorithms, called a general c-means clustering model (GCM), is presented and studied. 2) Based on the local optimality test of the GCM, the connection between Occam's razor and partitional clustering is established for the first time. As its application, a comprehensive review of the existing objective function-based clustering algorithms is presented based on GCM. 3) Under a common assumption about partitional clustering, a theoretical guide for devising and implementing clustering algorithm is discovered. These conclusions are verified by numerical experimental results.	Beijing Jiaotong Univ, Sch Comp Sci & Informat Technol, Beijing 100044, Peoples R China	Beijing Jiaotong University	Yu, J (corresponding author), Beijing Jiaotong Univ, Sch Comp Sci & Informat Technol, Beijing 100044, Peoples R China.	jianyu@center.njtu.edu.cn						Abonyi J, 2002, IEEE T SYST MAN CY B, V32, P612, DOI 10.1109/TSMCB.2002.1033180; Anderson E., 1935, B AM IRIS SOC, V59, P2; Baraldi A, 1998, IEEE T NEURAL NETWOR, V9, P724, DOI 10.1109/72.712148; Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032; Berkhin P., 2002, SURVEY CLUSTERING DA; Bezdek J. C., 1973, Journal of Cybernetics, V3, P58, DOI 10.1080/01969727308546047; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964; Bilmes J., 1997, GENTLE TUTORIAL EM A; BOBROWSKI L, 1991, IEEE T SYST MAN CYB, V21, P545, DOI 10.1109/21.97475; BUHMANN J, 1993, IEEE T INFORM THEORY, V39, P1133, DOI 10.1109/18.243432; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159; DAVE RN, 1991, PATTERN RECOGN LETT, V12, P657, DOI 10.1016/0167-8655(91)90002-4; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; DAVE RN, 1990, INT J GEN SYST, V16, P343, DOI 10.1080/03081079008935087; Duda R.O., 1973, J ROYAL STAT SOC SER; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; Frigui H, 1997, PATTERN RECOGN, V30, P1109, DOI 10.1016/S0031-3203(96)00140-9; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Gray RM., 1994, IEEE ACOUST SPEECH S, V1, P4; Gustafson D. E., 1979, Proceedings of the 1978 IEEE Conference on Decision and Control Including the 17th Symposium on Adaptive Processes, P761; Han J, 2006, DATA MINING CONCEPTS; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; HATHAWAY RJ, 1995, IEEE T FUZZY SYST, V3, P241, DOI 10.1109/91.388178; ICHIHASHI H, 2000, GAUSSIAN MIXTURE PDF; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Karayiannis NB, 1999, IEEE T NEURAL NETWOR, V10, P1153, DOI 10.1109/72.788654; KARAYIANNIS NB, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P630, DOI 10.1109/FUZZY.1994.343658; Karayiannis NB, 1997, IEEE T FUZZY SYST, V5, P622, DOI 10.1109/91.649915; KARAYIANNIS NB, 1996, P FUZZ IEEE 1996, V2, P8; Kaufman L., 2009, FINDING GROUPS DATA; Kaymak U, 2002, IEEE T FUZZY SYST, V10, P705, DOI 10.1109/TFUZZ.2002.805901; KRISHNAPURAM R, 1992, IEEE T NEURAL NETWOR, V3, P663, DOI 10.1109/72.159056; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387; KRISHNAPURAM R, 1996, IEEE T FUZZY SYST, P4385; LEE YJ, 1994, THESIS U MINNESOTA; Li RP, 1999, FUZZY SET SYST, V102, P253, DOI 10.1016/S0165-0114(97)00126-7; LI RP, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P2227, DOI 10.1109/FUZZY.1995.409989; Lin JS, 1999, NEURAL PROCESS LETT, V10, P35, DOI 10.1023/A:1018658712894; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Menard M, 2003, PATTERN RECOGN, V36, P1325, DOI 10.1016/S0031-3203(02)00049-3; MITCHELL TOM M., 1997, MACH LEARN, P2; MOU Y, 2003, J NO JIAOTONG U, V27, P26; Murphy M A, 1994, J Clin Neurosci, V1, P33, DOI 10.1016/0967-5868(94)90066-3; OHASHI Y, 1984, 9 M SAS US GRP INTL; Ozdemir D, 2002, PATTERN RECOGN, V35, P1785, DOI 10.1016/S0031-3203(01)00170-4; Ozdemir D, 2001, IEEE T IMAGE PROCESS, V10, P923, DOI 10.1109/83.923288; Pal NR, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P11, DOI 10.1109/FUZZY.1997.616338; Pedrycz W, 1996, PATTERN RECOGN LETT, V17, P625, DOI 10.1016/0167-8655(96)00027-X; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; ROSE K, 1993, IEEE T PATTERN ANAL, V15, P785, DOI 10.1109/34.236251; Runkler TA, 1999, FUZZY SET SYST, V101, P207, DOI 10.1016/S0165-0114(98)00164-X; Runkler TA, 1999, IEEE T FUZZY SYST, V7, P377, DOI 10.1109/91.784198; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; Schneider A, 2000, NINTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2000), VOLS 1 AND 2, P176, DOI 10.1109/FUZZY.2000.838654; SELIM SZ, 1999, IEEE T PATTERN ANAL, V21, P81; TIMM H, 2001, P EUR S INT TECHN EU; Tran D, 2000, NINTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2000), VOLS 1 AND 2, P152, DOI 10.1109/FUZZY.2000.838650; WANG S, 2001, NEC CITE SEER SEARCH; Wei CH, 2002, IEEE T NEURAL NETWOR, V13, P600, DOI 10.1109/TNN.2002.1000127; WEI W, 1994, PATTERN RECOGN, V27, P1567, DOI 10.1016/0031-3203(94)90134-1; Wu KL, 2002, PATTERN RECOGN, V35, P2267, DOI 10.1016/S0031-3203(01)00197-2; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; YANG MS, 1993, FUZZY SET SYST, V57, P365, DOI 10.1016/0165-0114(93)90030-L; Yang MS, 2005, EUR J OPER RES, V160, P515, DOI 10.1016/j.ejor.2003.07.004; Yang MS, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P647; Yasuda M, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P797, DOI 10.1109/FUZZ.2001.1009075; YASUDA M, 2001, P 2001 IEEE INT C SY, V4, P2415; Yu J, 2003, SCI CHINA SER F, V46, P321, DOI 10.1360/01yf0379; Yu J, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P98, DOI 10.1109/FUZZ.2002.1004967; YU J, 2003, GEN C MEANS CLUSTERI; Zhang JS, 2003, IEEE T SYST MAN CY B, V33, P983, DOI 10.1109/TSMCB.2003.816993; ZHANG M, IN PRESS J SOFTWARE	82	78	91	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1197	1211		10.1109/TPAMI.2005.160	http://dx.doi.org/10.1109/TPAMI.2005.160			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119260				2022-12-18	WOS:000229700900002
J	Sharp, GC; Lee, SW; Wehe, DK				Sharp, GC; Lee, SW; Wehe, DK			Multiview registration of 3D scenes by minimizing error between coordinate frames	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						registration; global registration; range images; multiple views; graph analysis	RANGE; LOCALIZATION; VIEWS	This paper addresses the problem of large-scale multiview registration of range images captured from unknown viewing directions. To reduce the computational burden, we separate the local problem of pairwise registration on neighboring views from the global problem of distribution of accumulated errors. We define the global problem as an optimization over the graph of neighboring views, and we show how the graph can be decomposed into a set of cycles such that the optimal transformation parameters for each cycle can be solved in closed form. We then describe an iterative procedure that can be used to integrate the solutions for the set of cycles across the graph of views. This method for error distribution does not require point correspondences between views, and can be used to integrate any method of pairwise registration or robot odometry.	Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA; Sogang Univ, Sch Media & Commun, Seoul 121742, South Korea; Univ Michigan, Dept Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA	Harvard University; Massachusetts General Hospital; Sogang University; University of Michigan System; University of Michigan	Sharp, GC (corresponding author), Massachusetts Gen Hosp, Dept Radiat Oncol, 55 Fruit St,FND5, Boston, MA 02114 USA.	gcsharp@partners.org; slee@ccs.sogang.ac.kr; dkw@umich.edu		Sharp, Gregory/0000-0001-8575-9611				BENJEMAA R, 1998, P EUR C COMP VIS; Berge C., 1962, THEORY GRAPHS ITS AP; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Gramkow C, 2001, INT J COMPUT VISION, V42, P7, DOI 10.1023/A:1011129215388; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Huber DF, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P153, DOI 10.1109/IM.2001.924424; JAIN R, 1995, MACHINE VISIOIN; JOHNSON AE, 2000, COMPUTER VISION PATT, V2, P413; Kang EY, 2000, INT C PATT RECOG, P257, DOI 10.1109/ICPR.2000.905314; Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733; Luenberger D. G., 1969, OPTIMIZATION VECTOR; MASUDA T, 1995, COMPUT VIS IMAGE UND, V61, P295, DOI 10.1006/cviu.1995.1024; Neugebauer P. J., 1997, International Journal of Shape Modeling, V3, P71, DOI 10.1142/S0218654397000070; *OH STAT U, 2004, OSU MSU WSU RANG IM; Olson CF, 2000, IEEE T ROBOTIC AUTOM, V16, P55, DOI 10.1109/70.833191; PENNEC X, 1996, IMAGE FUSION SHAPE V, P178; Pennec X., 1998, RR3371 INRIA; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; SAWHNEY H, 1998, P 5 EUR C COMP VIS, V2, P103; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Sharp GC, 2001, IEEE INT CONF ROBOT, P3542; SHARP GC, 2002, CSETR45302 U MICH; SHARP GC, 2002, P EUR C COMP VIS, V2, P587; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; STODDART AJ, 1996, P INT C PATT REC; Thrun S, 1998, MACH LEARN, V31, P29, DOI 10.1023/A:1007436523611; TROBINA M, 1995, BIWITR164 ETH ZUR CO; Williams J, 2000, IEICE T INF SYST, VE83D, P1662; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	37	78	83	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1037	1050		10.1109/TPAMI.2004.49	http://dx.doi.org/10.1109/TPAMI.2004.49			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641733				2022-12-18	WOS:000221872400007
J	Martin, P; Refregier, P; Goudail, F; Guerault, F				Martin, P; Refregier, P; Goudail, F; Guerault, F			Influence of the noise model on level set active contour segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; level-set methods; active contours; minimum description length	SNAKE-BASED SEGMENTATION; ALGORITHMS; FLOW	We analyze level set implementation of region snakes based on the maximum likelihood method for different noise models that belong to the exponential family. We show that this approach can improve segmentation results in noisy images and we demonstrate that the regularization term can be efficiently determined using an information theory-based approach, i.e., the minimum description length principle. The criterion to be optimized has no free parameter to be tuned by the user and the obtained segmentation technique is adapted to nonsimply connected objects.	ENSPM, UMR 6133, Inst Fresnel, Phys & Image Proc Grp, F-13397 Marseille 20, France; Simag Dev, F-13016 Marseille, France	UDICE-French Research Universities; Aix-Marseille Universite	Martin, P (corresponding author), ENSPM, UMR 6133, Inst Fresnel, Phys & Image Proc Grp, Dom Univ St Jerome, F-13397 Marseille 20, France.	pascal.martin@fresnel.fr; philippe.refregier@fresnel.fr; francois.goudail@fresnel.fr; frederic.guerault@simag.fr	goudail, françois/AAG-2372-2020					Azzalini A., 1996, STAT INFERENCE BASED; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; CHIOU GI, 1995, IEEE T IMAGE PROCESS, V4, P1407, DOI 10.1109/83.465105; CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Dias JMB, 1996, IEEE T MED IMAGING, V15, P25, DOI 10.1109/42.481438; FIGUEIREDO M, 1992, IEEE T MED IMAGING, V11, P416; Figueiredo MAT, 1997, LECT NOTES COMPUT SC, V1223, P35; Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Germain O, 1996, OPT LETT, V21, P1845, DOI 10.1364/OL.21.001845; Goodman J.W., 1975, STAT PROPERTIES LASE, P9; GOUDAIL F, 2003, P INT WORKSH ENERGY, P373; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Jehan-Besson S, 2002, EURASIP J APPL SIG P, V2002, P572, DOI 10.1155/S1110865702203157; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KERVRANN C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P724, DOI 10.1109/CVPR.1994.323887; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Ruch O, 2001, OPT LETT, V26, P977, DOI 10.1364/OL.26.000977; SETHIAN JA, 1990, J DIFFER GEOM, V31, P131; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	29	78	87	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					799	803		10.1109/TPAMI.2004.11	http://dx.doi.org/10.1109/TPAMI.2004.11			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579939				2022-12-18	WOS:000220756500012
J	Gevers, T; Stokman, H				Gevers, T; Stokman, H			Robust histogram construction from color invariants for object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; color invariants; noise robustness; histogram construction; noise propagation; kernel density estimation; matching		An effective object recognition scheme is to represent and match images on the basis of histograms derived from photometric color invariants. A drawback, however, is that certain color invariant values become very unstable in The presence of sensor noise. To suppress the effect of noise for unstable color invariant values, in this paper, histograms are computed by variable kernel density estimators. To apply variable kernel density estimation in a principled way, models are proposed for the propagation of sensor noise through color invariant variables. As a result, the associated uncertainty is obtained for each color invariant value. The associated uncertainty is used to derive the parameterization of the variable kernel for the purpose of robust histogram construction. It is empirically verified that the proposed density estimator compares favorably to traditional histogram schemes for the purpose of object recognition.	Univ Amsterdam, Dept Comp Sci, Fac Sci, Intelligent Sensory Informat Syst, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	Gevers, T (corresponding author), Univ Amsterdam, Dept Comp Sci, Fac Sci, Intelligent Sensory Informat Syst, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	gevers@science.uva.nl						Berwick D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P165, DOI 10.1109/ICCV.1998.710714; BURNS PD, 1997, COLOR RES APPL, V22; CROWLEY JL, 1998, P EUR C COMP VIS, P475; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; KENDER JR, 1976, SATURATION HUE NORMA; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; Shafarenko L, 1998, IEEE T IMAGE PROCESS, V7, P1354, DOI 10.1109/83.709666; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Silverman B.W, 1986, DENSITY ESTIMATION; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Taylor JR., 1982, INTRO ERROR ANAL, V2nd edition; Wand M.P., 1995, KERNEL SMOOTHING	16	78	83	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					113	118		10.1109/TPAMI.2004.1261083	http://dx.doi.org/10.1109/TPAMI.2004.1261083			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382690	Green Submitted			2022-12-18	WOS:000187161400009
J	Mahamud, S; Williams, LR; Thornber, KK; Xu, KL				Mahamud, S; Williams, LR; Thornber, KK; Xu, KL			Segmentation of multiple salient closed contours from real images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual organization; contours; Markov chains; eigenvectors		Using a saliency measure based on the global property of contour closure, we have developed a segmentation method which identifies smooth closed contours bounding objects of unknown shape in real images. The saliency measure incorporates the Gestalt principles of proximity and good continuity that previous methods have also exploited. Unlike previous methods, we incorporate contour closure by finding the eigenvector with the largest positive real eigenvalue of a transition matrix for a Markov process where edges from the image serve as states. Element (i, j) of the transition matrix is the conditional probability that a contour which contains edge j will also contain edge i. In this paper, we show how the saliency measure, defined for individual edges, can be used to derive a saliency relation, defined for pairs of edges, and further show that strongly-connected components of the graph representing the saliency relation correspond to smooth closed contours in the image. Finally, we report for the first time, results on large real images for which segmentation takes an average of about 10 seconds per object on a general-purpose workstation.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; NEC Res Inst, Princeton, NJ 08540 USA	Carnegie Mellon University; University of New Mexico; NEC Corporation	Mahamud, S (corresponding author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.	williams@cs.unm.edu						Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; Brent R.P., 1973, ALGORITHMS MINIMIZAT; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CORMEM TH, 1989, INTRO ALGORITHMS, pCH23; ELDER JH, 1996, P EUR C COMP VIS, V1, P14; GDALYAHU Y, 1999, ADV NEURAL INFORMATI, V11; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HORN RA, 1990, MATRIX ANAL, pCH8; JACOBS DW, 1993, P COMP VIS PATT REC; MAHAMUD S, 1999, P INT C COMP VIS; Medioni G., 2000, COMPUTATIONAL FRAMEW; MUMFORD D., 1993, ALGEBRAIC GEOMETRY I; PERONA P, 1998, P EUR C COMP VIS, V1, P655; RAMAN SV, 1993, CVGIP-IMAG UNDERSTAN, V57, P81, DOI 10.1006/ciun.1993.1005; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; SARKAR S, 2000, IEEE T PATTERN ANAL, V22; SHARON E, 1997, P COMP VIS PATT REC; SHASHUA A, 1988, P INT C COMP VIS; Shi J., 1997, P COMP VIS PATT REC; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; THORNBER KK, 1998, 97162 NEC; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Williams LR, 2001, NEURAL COMPUT, V13, P1683, DOI 10.1162/08997660152469305	27	78	89	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					433	444		10.1109/TPAMI.2003.1190570	http://dx.doi.org/10.1109/TPAMI.2003.1190570			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV		Green Submitted			2022-12-18	WOS:000181758100005
J	Torr, PHS; Szeliski, R; Anandan, P				Torr, PHS; Szeliski, R; Anandan, P			An integrated Bayesian approach to layer extraction from image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						layer extraction; segmentation; stereo matching; motion estimation	ALGORITHM; MOTION	This paper describes a Bayesian approach for modeling 3D scenes as a collection of approximately planar layers that are arbitrarily positioned and oriented in the scene. in contrast to much of the previous work on layer-based motion modeling, which computes layered descriptions of 2D image motion, our work leads to a 3D description of the scene. There are two contributions within the paper. The first is to formulate the prior assumptions about the layers and scene within a Bayesian decision making framework which is used to automatically determine the number of layers and the assignment of individual pixels to layers. The second is algorithmic. In order to achieve the optimization, a Bayesian version of RANSAC is developed with which to initialize the segmentation. Then, a generalized expectation maximization method is used to find the MAP solution.	Microsoft Res Ltd, Microsoft Res, Cambridge CB2 3NH, England; Microsoft Corp, Res, Redmond, WA 98052 USA	Microsoft; Microsoft	Torr, PHS (corresponding author), Microsoft Res Ltd, Microsoft Res, St George House,1 Guildhall St, Cambridge CB2 3NH, England.	philtorr@microsoft.com; szeliski@microsoft.com; anandan@microsoft.com						AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Gelman A, 2013, BAYESIAN DATA ANAL, P16; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRENANDER U, 1991, HANDS; JAYNES ET, PROBABILITY THEORY E; Mundy J., 1992, GEOMETRIC INVARIANCE; Sivia D., 2006, DATA ANAL BAYESIAN T; Szeliski R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P157, DOI 10.1109/CVPR.1999.786933; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092	18	78	90	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					297	303		10.1109/34.910882	http://dx.doi.org/10.1109/34.910882			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW					2022-12-18	WOS:000167276200006
J	Shen, DG; Davatzikos, C				Shen, DG; Davatzikos, C			An adaptive-focus deformable model using statistical and geometric information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contour; snake; statistical shape models; adaptive focus deformable model	SHAPE MODELS; SEGMENTATION; TRACKING	An active contour (snake) model is presented, with emphasis on medical imaging applications. There are three main novelties in the proposed model. First. an attribute vector is used to characterize the geometric structure around each point of the snake model: the deformable model then deforms in a way that seeks regions with similar attribute vectors. This is in contrast to most deformable models, which deform to nearby edges without considering geometric structure. and it was motivated by the need to establish point-correspondences that have anatomical meaning. Second, an adaptive-focus statistical model has been suggested which allows the deformation of the active contour in each stage to be influenced primarily by the most reliable matches. Third, a deformation mechanism that is robust to local minima is proposed by evaluating the snake energy function on segments of the snake at a time, instead of individual points. Various experimental results show the effectiveness of the proposed model.	Johns Hopkins Univ, Dept Radiol, Sch Med, Baltimore, MD 21287 USA	Johns Hopkins University	Shen, DG (corresponding author), Johns Hopkins Univ, Dept Radiol, Sch Med, JHOC 3230,601 N Caroline St, Baltimore, MD 21287 USA.	dgshen@cbmv.jhu.edu; hristos@rad.jhu.edu	Shen, Dinggang/ABF-6812-2020; Davatzikos, Christos/ABE-2057-2021	Shen, Dinggang/0000-0002-7934-5698; Davatzikos, Christos/0000-0002-1025-8561				Davatzikos C, 1997, COMPUT VIS IMAGE UND, V66, P207, DOI 10.1006/cviu.1997.0605; Ip HHS, 1998, IMAGE VISION COMPUT, V16, P135, DOI 10.1016/S0262-8856(97)00051-6; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kervrann C, 1998, GRAPH MODEL IM PROC, V60, P173, DOI 10.1006/gmip.1998.0469; LAI KF, 1995, IEEE T PATTERN ANAL, V17, P1084, DOI 10.1109/34.473235; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Miller M, 1997, Stat Methods Med Res, V6, P267, DOI 10.1191/096228097673360480; Szekely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(96)80003-X; WANG YF, 1992, IEEE T PATTERN ANAL, V14, P572, DOI 10.1109/34.134061; Wang YM, 1998, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1998.698628; WILLOUGHBY LG, 1992, NOVA HEDWIGIA, V55, P1; Yin LJ, 1999, PATTERN RECOGN LETT, V20, P651, DOI 10.1016/S0167-8655(99)00029-X	15	78	83	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					906	913		10.1109/34.868689	http://dx.doi.org/10.1109/34.868689			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN					2022-12-18	WOS:000089321500014
J	Daugman, J				Daugman, J			Face and gesture recognition: Overview	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material											Daugman, J (corresponding author), UNIV CAMBRIDGE,COMP LAB,PEMBROKE ST,CAMBRIDGE CB2 3QG,ENGLAND.								0	78	88	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1997	19	7					675	676		10.1109/34.598225	http://dx.doi.org/10.1109/34.598225			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM693					2022-12-18	WOS:A1997XM69300002
J	SARKAR, S; BOYER, KL				SARKAR, S; BOYER, KL			INTEGRATION, INFERENCE, AND MANAGEMENT OF SPATIAL INFORMATION USING BAYESIAN NETWORKS - PERCEPTUAL ORGANIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BAYESIAN NETWORKS; INFERENCE; INTEGRATION; MANAGEMENT OF SPATIAL INFORMATION; PERCEPTUAL ORGANIZATION	RECOGNITION; EXTRACTION; GESTALT; IMAGES	The use of knowledge bases has been advocated by many researchers to make computer vision more stable and reliable. The formalism of Bayesian networks provides a very elegant solution, in a probabilistic framework, to the problem of integrating top-down and bottom-up visual processes, as well serving as a knowledge base. We modify the formalism to handle spatial data and thus extend the application of Bayesian networks to visual processing. We call the modified form the perceptual inference network (PIN). We present the theoretical background of a PIN and demonstrate its viability in the context of perceptual organization. Perceptual organization imparts robustness, efficiency, and a qualitative and holistic nature to vision. Thus far, the approaches to the problem of perceptual organization have been purely bottom up, without much top-down knowledge-base influence, and are therefore entirely dependent on the inputs, which are obviously imperfect. The knowledge base, besides coping with such input imperfection, also allows us to integrate multiple organizations and form a composite organization hypothesis. The PIN imparts an active inferential and integrating nature to perceptual organization in an elegant probabilistic framework.			SARKAR, S (corresponding author), OHIO STATE UNIV,DEPT ELECT ENGN,SIGNAL ANAL & MACHINE PERCEPT LAB,COLUMBUS,OH 43210, USA.		Sarkar, Sudeep/ABD-7629-2021; Sarkar, Sudeep/A-8213-2009	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; Chelberg D. M., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P654, DOI 10.1109/ICCV.1990.139612; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; JENSEN FV, 1992, P SOC PHOTO-OPT INS, V1708, P536, DOI 10.1117/12.58599; Kanizsa G., 1979, ORG VISION; LIOU SP, 1991, IEEE T PATTERN ANAL, V13, P317, DOI 10.1109/34.88567; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MARR D, 1981, VISION COMPUTATIONAL; McCafferty James D., 1990, HUMAN MACHINE VISION; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; REED TR, 1990, IEEE T PATTERN ANAL, V12, P1, DOI 10.1109/34.41379; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; Sha'ashua A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P321, DOI 10.1109/CCV.1988.590008; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; Williams L. R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P133, DOI 10.1109/ICCV.1990.139510; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	37	78	82	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					256	274		10.1109/34.204907	http://dx.doi.org/10.1109/34.204907			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800007
J	IKEUCHI, K; SATO, K				IKEUCHI, K; SATO, K			DETERMINING REFLECTANCE PROPERTIES OF AN OBJECT USING RANGE AND BRIGHTNESS IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE RECONSTRUCTION; LAMBERTIAN REFLECTION; LEAST SQUARE FITTING; REFLECTANCE MAP; SEGMENTATION; SPECULAR REFLECTION; TORRANCE-SPARROW MODEL		This paper discusses a method of recovering reflectance properties of a surface from a range image given by a range finder and a brightness image given by a standard TV camera. We will use the Torrance-Sparrow model for our reflectance model. The model consists of the Lambertian and specular components; its reflectance properties consist of relative strength between the Lambertian and specular components and specular sharpness as well as light source direction. We will employ an iterative least square fitting method to obtain these parameters based on the range and brightness images. Using the obtained parameters, we segment an input image into four different parts: Lambertian reflection, specular reflection, interreflection, and shadow part. We will also reconstruct ideal images that consist of only Lambertian or specular reflection.	OSAKA UNIV,FAC ENGN SCI,DEPT CONTROL ENGN,OSAKA,JAPAN	Osaka University	IKEUCHI, K (corresponding author), CARNEGIE MELLON UNIV,SCH COMP SCI,PITTSBURGH,PA 15213, USA.							Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; BEST PJ, 1988, GMR6090 GM RES LAB C; BLINN JF, 1977, COMPUT GRAPH, V11, P192; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; HEALEY G, 1988, COMPUT VISION GRAPH, V42, P62, DOI 10.1016/0734-189X(88)90143-0; HORN BKP, 1978, AI498 MIT ART INT LA; HOUCHENS AF, 1967, THERMOPHYSICS SPACEC, P65; KLINKER GJ, 1988, INT J COMPUT VISION, V2; Lambert J.H., 1760, PHOTOMETRIA SIVE MEN; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; NAYAR SK, 1988, CMURITR8814 CARN MEL; SATO K, 1987, IEEE 1 ICCV, P657; Siegel R., 2001, THERMAL RAD HEAT TRA, V4th; TAGARE HD, 1989, FRAMEWORK CONSTRUCTI; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WOLFF LB, 1989, JUN P IEEE C COMP VI, P363; WOODHAM RJ, 1978, AITR457 MIT ART INT	17	78	88	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1991	13	11					1139	1153		10.1109/34.103274	http://dx.doi.org/10.1109/34.103274			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN338					2022-12-18	WOS:A1991GN33800003
J	STRAT, TM; FISCHLER, MA				STRAT, TM; FISCHLER, MA			CONTEXT-BASED VISION - RECOGNIZING OBJECTS USING INFORMATION FROM BOTH 2-D AND 3-D IMAGERY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								This paper describes results from an ongoing project concerned with recognizing objects in complex scene domains, especially in the domain that includes the natural outdoor world. Traditional machine recognition paradigms assume either 1) that all objects of interest are definable by a relatively small number of explicit shape models or 2) that all objects of interest have characteristic, locally measurable features. The failure of both assumptions in a complex domain such as the natural outdoor world has a dramatic impact on the form of an acceptable architecture for an object recognition system. In our work, we make the use of contextual information a central issue, and explicitly design a system to identify and use context as an integral part of recognition. In so doing, we provide a new paradigm for visual recognition that eliminates the traditional dependence on stored geometric models and universal image partitioning algorithms. This paradigm combines the results of many simple procedures that analyze monochrome, color, stereo, or 3-D range images. By interpreting their results along with relevant contextual knowledge, a reliable recognition result is achieved, even in the face of imperfect visual procedures. Initial experimentation with the system on ground-level outdoor imagery has already demonstrated competence beyond what we believe is attainable with other existing vision systems.			STRAT, TM (corresponding author), SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025, USA.							BARNARD ST, 1989, INT J COMPUT VISION, V3; BARROW HG, 1976, 121 SRI INT ART INT; BARROW HG, 1977, 137 SRI INT ART INT; BOLLES RC, 1983, 8TH P INT JOINT C AR, P1116; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; DRAPER BA, 1989, INT J COMPUT VISION, V2, P209, DOI 10.1007/BF00158165; FISCHLER MA, 1989, MAY P DARPA IMAG UND, P774; FISCHLER MA, 1988, P AAAI SPRING S SERI, P62; FUA P, 1987, P DARPA IMAGE UNDERS, P227; Hannah M., 1985, DEC P DARPA IM UND W, P149; Hanson A., 1978, COMPUTER VISION SYST, P303; HANSON AJ, 1988, APR P DARPA IM UND W, P576; HUTTENLOCHER DP, 1988, APR P DARPA IU WORKS, P1114; LAWS KI, 1988, 441 SRI INT ART INT; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; OHTA Y, 1980, THESIS KYOTO U KYOTO; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SLOAN K, 1977, THESIS U PENNSYLVANI; SMITH GB, 1987, FEB P DARPA IM UND W, P170; STRAT TM, 1989, TWENTY-THIRD ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P532; STRAT TM, 1988, IMAGE UNDERSTANDING, P1; STRAT TM, 1990, THESIS STANFORD U ST; TENENBAUM JM, 1975, 4TH P INT JOINT C AR, P682; TSOTSOS J, 1988, INT J COMPUT VISION, V1, P303; YAKIMOVSKY Y, 1973, 3RD P INT JOINT C AR, P580	25	78	80	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1991	13	10					1050	1065		10.1109/34.99238	http://dx.doi.org/10.1109/34.99238			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GM763					2022-12-18	WOS:A1991GM76300007
J	YOUNG, GSJ; CHELLAPPA, R				YOUNG, GSJ; CHELLAPPA, R			3-D MOTION ESTIMATION USING A SEQUENCE OF NOISY STEREO IMAGES - MODELS, ESTIMATION, AND UNIQUENESS RESULTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											YOUNG, GSJ (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN SYST,INST SIGNAL & IMAGE PROC,LOS ANGELES,CA 90089, USA.		Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012					ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1985, 3RD P WORKSH COMP VI; AGGARWAL JK, 1986, MAY P IEEE WORKSH MO; BARITZHACK IY, 1985, IEEE T AERO ELEC SYS, V21, P128, DOI 10.1109/TAES.1985.310546; BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROIDA TJ, 1989, J OPT SOC AM A, V6, P879, DOI 10.1364/JOSAA.6.000879; BROIDA TJ, 1990, JUL IEEE T AEROSP EL; Chen C. T., 1984, LINEAR SYSTEM THEORY; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; FRIEDLAND B, 1978, IEEE T AEROSP ELECTR, V14; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HUANG TS, 1985, IEEE C COMPUTER VISI, P518; HUANG TS, 1986, MAY P IEEE WORKSH MO; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; Longuet-Higgins H. C., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P395; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; Maybeck P. S., 1982, STOCHASTIC MODELS ES, V2; NIVA GD, 1982, P ANN ROCKY MOUNTAIN, P269; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; Sorenson H. W, 1980, CONTROL SYSTEMS THEO; STRANG G, 1980, LINEAR ALGEBRA ITS A; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30, P525, DOI 10.1109/TASSP.1982.1163931; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; Wertz J.R., 1978, SPACECRAFT ATTITUDE; YOUNG G, 1988, JUN P IEEE C COMP VI, P710; YOUNG GS, 1988, 22ND P ANN C INF SCI, P192; YOUNG GS, 1988, 22ND P AS C SYST SIG	37	78	83	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1990	12	8					735	759		10.1109/34.57666	http://dx.doi.org/10.1109/34.57666			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DQ388					2022-12-18	WOS:A1990DQ38800002
J	PONCE, J; CHELBERG, D; MANN, WB				PONCE, J; CHELBERG, D; MANN, WB			INVARIANT PROPERTIES OF STRAIGHT HOMOGENEOUS GENERALIZED CYLINDERS AND THEIR CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PONCE, J (corresponding author), STANFORD UNIV,DEPT COMP SCI,ROBOT LAB,STANFORD,CA 94305, USA.							AGIN GJ, 1972, AIM273 STANF ART INT; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BINFORD TO, 1987, P WORKSHOP UNCERTAIN; BINFORD TO, 1987, 4TH P INT S ROB RES; BINFORD TO, 1971, DEC P IEEE SYST CONT; BRADY JM, 1984, INT J ROBOTICS RES, V3; BRADY JM, 1985, 2ND P INT S ROB RES; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; HORAUD R, 1987, 1ST P INT C COMP VIS; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; KANADE T, 1981, ARTIFICIAL INTELL, V17; Koenderink J. J., 1984, PERCEPTION, V13; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; MARIMONT DH, 1984, P AAAI 84 AUST; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MARR D, 1977, PROC R SOC SER B-BIO, V197, P441, DOI 10.1098/rspb.1977.0080; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NEVATIA R, 1982, MACHINE PERCEPTION; PONCE J, 1987, INT J COMPUT VISION, V1; PONCE J, 1988, P IMAGE UNDERSTANDIN; PONCE J, 1987, 1ST P INT C COMP VIS; PONCE J, 1987, 3 DIMENSIONAL MACHIN; PONCE J, 1988, P INT C COMPUTER VIS; PONCE J, 1987, 1987 P IEEE WORKSH C; RAO K, 1987, FEB P IM UND WORKSH; ROBERTS KR, 1985, DEC P IMAG UND WORK; Shafer S. A., 1985, SHADOWS SILHOUETTES; SUMANAWEERA T, 1988, P IMAGE UNDERSTANDIN; VERRI A, 1986, MIT AIM832 ARTIFICIA; WILLIAMSON RE, 1979, MULTIVARIABLE MATH	36	78	81	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					951	966		10.1109/34.35498	http://dx.doi.org/10.1109/34.35498			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800005
J	GORMAN, JW; MITCHELL, OR; KUHL, FP				GORMAN, JW; MITCHELL, OR; KUHL, FP			PARTIAL SHAPE-RECOGNITION USING DYNAMIC-PROGRAMMING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907; USA,CTR ARMAMENT RES & DEV,DOVER,NJ 07801	Purdue University System; Purdue University; Purdue University West Lafayette Campus			Rohlf, F J/A-8710-2008					BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bellman R., 1962, APPL DYNAMIC PROGRAM; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; DAVALLOU F, 1984, 1984 C INT SYST MACH; Dreyfus S., 1977, ART THEORY DYNAMIC P; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Fuchs H., 1977, COMMUN ACM, V20; GIFFORD JP, 1982, THESIS PURDUE U W LA; GROGAN TA, 1983, TREE8322 PURD U SCH; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Kruskal J.B., 1983, TIME WARPS STRING ED; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; Myers C.M., 1980, IEEE T ACOUST SPEECH, V28; O'Rourke J., 1985, COMPUTATIONAL GEOMET, P295; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	19	78	80	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					257	266		10.1109/34.3887	http://dx.doi.org/10.1109/34.3887			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400009
J	Huang, C; Li, YN; Loy, CC; Tang, XO				Huang, Chen; Li, Yining; Loy, Chen Change; Tang, Xiaoou			Deep Imbalanced Learning for Face Recognition and Attribute Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Face recognition; Training; Task analysis; Protocols; Semantics; Image segmentation; Imbalanced learning; deep convolutional neural networks; face recognition; attribute prediction	CLASSIFICATION; SMOTE	Data for face analysis often exhibit highly-skewed class distribution, i.e., most data belong to a few majority classes, while the minority classes only contain a scarce amount of instances. To mitigate this issue, contemporary deep learning methods typically follow classic strategies such as class re-sampling or cost-sensitive training. In this paper, we conduct extensive and systematic experiments to validate the effectiveness of these classic schemes for representation learning on class-imbalanced data. We further demonstrate that more discriminative deep representation can be learned by enforcing a deep network to maintain inter-cluster margins both within and between classes. This tight constraint effectively reduces the class imbalance inherent in the local data neighborhood, thus carving much more balanced class boundaries locally. We show that it is easy to deploy angular margins between the cluster distributions on a hypersphere manifold. Such learned Cluster-based Large Margin Local Embedding (CLMLE), when combined with a simple k-nearest cluster algorithm, shows significant improvements in accuracy over existing methods on both face recognition and face attribute prediction tasks that exhibit imbalanced class distribution.	[Huang, Chen] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA; [Loy, Chen Change] Natl Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore; [Li, Yining; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China	Carnegie Mellon University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chinese University of Hong Kong	Huang, C (corresponding author), Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA.; Loy, CC (corresponding author), Natl Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.	chenh2@andrew.cmu.edu; ly015@ie.cuhk.edu; ccloy@ntu.edu.sg; xtang@ie.cuhk.edu.hk		Loy, Chen Change/0000-0001-5345-1591	SenseTime Group Limited; Research Grants Council of the Hong Kong SAR [CUHK 14241716, 14224316, 14209217]	SenseTime Group Limited; Research Grants Council of the Hong Kong SAR(Hong Kong Research Grants Council)	This work is supported by SenseTime Group Limited and the General Research Fund sponsored by the Research Grants Council of the Hong Kong SAR (CUHK 14241716, 14224316, 14209217).	[Anonymous], 2015, ARXIV150607310; Bengio Y., 2007, P 24 INT C MACH LEAR, P473, DOI DOI 10.1145/1273496.1273556; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Bulo SR, 2017, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR.2017.749; Caesar H., 2015, P BRIT MACH VIS C BM; Castro CL, 2013, IEEE T NEUR NET LEAR, V24, P888, DOI 10.1109/TNNLS.2013.2246188; Chandraker, 2018, ARXIV180309014; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chen BH, 2017, PROC CVPR IEEE, P4021, DOI 10.1109/CVPR.2017.428; Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251; Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205; Drummond JJ, 2003, ETHICS AND THEOLOGICAL DISCLOSURES: THE THOUGHT OF ROBERT SOKOLOWSKI, P1; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gunther M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P90; Guo Y., 2018, 170705574 ARXIV; Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91; Hand EM, 2018, AAAI CONF ARTIF INTE, P6878; He H, 2013, IMBALANCED LEARNING: FOUNDATIONS, ALGORITHMS, AND APPLICATIONS, P1, DOI 10.1002/9781118646106; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969; Huang C., 2016, P 30 INT C NEURAL IN, P1270; Huang C, 2018, IEEE T NEUR NET LEAR, V29, P1503, DOI 10.1109/TNNLS.2017.2671845; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129; Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19; Kalayeh MM, 2017, PROC CVPR IEEE, P4227, DOI 10.1109/CVPR.2017.450; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Khan Salman H, 2018, IEEE Trans Neural Netw Learn Syst, V29, P3573, DOI 10.1109/TNNLS.2017.2732482; Krawczyk B, 2014, APPL SOFT COMPUT, V14, P554, DOI 10.1016/j.asoc.2013.08.014; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Liu WY, 2018, ADV NEUR IN, V31; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Liu WY, 2016, PR MACH LEARN RES, V48; Liu Y., 2017, ARXIV171000870; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Maciejewski T., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P104, DOI 10.1109/CIDM.2011.5949434; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Nech A, 2017, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2017.363; Ng WWY, 2016, PATTERN RECOGN, V60, P875, DOI 10.1016/j.patcog.2016.06.013; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Ren MY, 2018, PR MACH LEARN RES, V80; Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Silpa-Anan C, 2008, PROC CVPR IEEE, P2308; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sohn K, 2016, ADV NEUR IN, V29; Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909; Ting Kai Ming, 2000, P 17 INT C MACH LEAR, P983; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770; Wang YC, 2017, ADV NEUR IN, V30; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wu Y, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P408, DOI 10.1145/3126636.3126693; Yi D, 2014, ARXIV PREPRINT ARXIV; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhou Z., 2006, P 21 NAT C ART INT, P567; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17	72	77	80	4	67	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2781	2794		10.1109/TPAMI.2019.2914680	http://dx.doi.org/10.1109/TPAMI.2019.2914680			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31071017	Green Submitted			2022-12-18	WOS:000575381000004
J	Yu, MY; Liu, L; Shao, L				Yu, Mengyang; Liu, Li; Shao, Ling			Structure-Preserving Binary Representations for RGB-D Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RGB-D fusion; flux; binary; structure-preserving; dimensionality reduction; local feature	DIMENSIONALITY; FEATURES	In this paper, we propose a novel binary local representation for RGB-D video data fusion with a structure-preserving projection. Our contribution consists of two aspects. Toacquire a general feature for the video data, we convert the problem to describing the gradient fields of RGB and depth information of video sequences. With the local fluxes of the gradient fields, which include the orientation and the magnitude of the neighborhood of each point, a new kind of continuous local descriptor called Local Flux Feature(LFF) is obtained. Then the LFFs from RGB and depth channels are fused into a Hamming space via the Structure Preserving Projection (SPP). Specifically, an orthogonal projection matrix is applied to preserve the pairwise structure with a shape constraint to avoid the collapse of data structure in the projected space. Furthermore, a bipartite graph structure of data is taken into consideration, which is regarded as a higher level connection between samples and classes than the pairwise structure of local features. The extensive experiments show not only the high efficiency of binary codes and the effectiveness of combining LFFs from RGB-D channels via SPP on various action recognition benchmarks of RGB-D data, but also the potential power of LFF for general action recognition.	[Yu, Mengyang; Liu, Li; Shao, Ling] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England	Northumbria University	Shao, L (corresponding author), Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.	m.y.yu@ieee.org; li2.liu@northumbria.ac.uk; ling.shao@ieee.org	Shao, Ling/D-3535-2011	Shao, Ling/0000-0002-8264-6117				Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4; Aho AV, 1974, DESIGN ANAL COMPUTER; [Anonymous], 2005, THESIS MIT CAMBRIDGE; Arfken G. B., 2005, MATH METHODS PHYS; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Belkin M, 2002, ADV NEUR IN, V14, P585; Bengio Y., 2003, P 16 INT C NEUR INF, P177; Berndt DJ, 1994, KDD WORKSH, V10, P359; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Cai D, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995390; Caseiro R, 2013, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2013.13; Cruz L., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P36, DOI 10.1109/SIBGRAPI-T.2012.13; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dollar P., 2005, P IEEE INT WORKSH VI, P65, DOI [DOI 10.1109/VSPETS.2005.1570899, 10.1109/VSPETS.2005.1570899]; Engel D., 2008, P INT C PATT REC, P1; Fathi A, 2008, PROC CVPR IEEE, P3064; Freeman W T, 1995, P INT WORKSH AUT FAC, P296; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Hadfield S, 2014, LECT NOTES COMPUT SC, V8690, P758, DOI 10.1007/978-3-319-10605-2_49; Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378; Hardy G.H., 1934, INEQUALITIES; He X., 2003, P NEUR INF PROC SYST; He XF, 2005, IEEE I CONF COMP VIS, P1208; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Holte M. B., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P342, DOI 10.1109/3DIMPVT.2011.50; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Klaser Alexander, 2008, BMVC; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lee H, 2016, ADV NEURAL INFORM PR, V19; Liu L., 2015, P BRIT MACH VIS C; Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975; Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu Wei, 2011, Reports in Parasitology, V1, P1; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mualler M., 2006, P 2006 ACM SIGGRAPH, P137; Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Norouzi M., 2011, INT C MACHINE LEARNI, P353; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Paton M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P24, DOI 10.1109/CRV.2012.11; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scovanner P., 2007, ACM MM, P357; Sempena S., 2011, P INT C ELECT ENG IN, P1, DOI DOI 10.1109/ICEEI.2011.6021605; Shah SAA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P638, DOI 10.1109/ICCVW.2013.88; Shao, 2013, P 23 INT JOINT C ART; Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Spinello L, 2012, IEEE INT CONF ROBOT, P4469, DOI 10.1109/ICRA.2012.6225137; Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Weiss Y., 2008, NIPS, P1753; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Yang YL, 2011, PROC IEEE MICR ELECT, P79, DOI 10.1109/MEMSYS.2011.5734366; Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y	74	77	79	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1651	1664		10.1109/TPAMI.2015.2491925	http://dx.doi.org/10.1109/TPAMI.2015.2491925			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26485473	Green Accepted, hybrid			2022-12-18	WOS:000379926200013
J	Guan, Y; Li, CT; Roli, F				Guan, Yu; Li, Chang-Tsun; Roli, Fabio			On Reducing the Effect of Covariate Factors in Gait Recognition: A Classifier Ensemble Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classifier ensemble; random subspace method; local enhancing; hybrid decision-level fusion; gait recognition; covariate factors; biometrics	DISCRIMINANT-ANALYSIS; FACE; IDENTIFICATION; PERFORMANCE	Robust human gait recognition is challenging because of the presence of covariate factors such as carrying condition, clothing, walking surface, etc. In this paper, we model the effect of covariates as an unknown partial feature corruption problem. Since the locations of corruptions may differ for different query gaits, relevant features may become irrelevant when walking condition changes. In this case, it is difficult to train one fixed classifier that is robust to a large number of different covariates. To tackle this problem, we propose a classifier ensemble method based on the random subspace nethod (RSM) and majority voting (MV). Its theoretical basis suggests it is insensitive to locations of corrupted features, and thus can generalize well to a large number of covariates. We also extend this method by proposing two strategies, i. e., local enhancing (LE) and hybrid decision-level fusion (HDF) to suppress the ratio of false votes to true votes (before MV). The performance of our approach is competitive against the most challenging covariates like clothing, walking surface, and elapsed time. We evaluate our method on the USF dataset and OU-ISIR-B dataset, and it has much higher performance than other state-of-the-art algorithms.	[Guan, Yu; Li, Chang-Tsun] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England; [Roli, Fabio] Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy	University of Warwick; University of Cagliari	Guan, Y (corresponding author), Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.	yg.yuguan@gmail.com; c-t.li@warwick.ac.uk; roli@diee.unica.it	Li, Chang-Tsun/C-1125-2018	Li, Chang-Tsun/0000-0003-4735-6138	Royal Society's International Exchange Programme [IE120092]	Royal Society's International Exchange Programme	The authors would like to thank the support from the Royal Society's International Exchange Programme (IE120092) and the constructive comments from the anonymous reviewers.	Bau III D, 1997, NUMERICAL LINEAR ALG; Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x; Chen CY, 2010, IEEE T SYST MAN CY B, V40, P208, DOI 10.1109/TSMCB.2009.2025028; Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]; Grinstead CM., 1997, INTRO PROBABILITY, V2; Guan Y, 2012, IEEE INT CONF MULTI, P284, DOI 10.1109/ICMEW.2012.55; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020; Huang Y, 2010, IEEE T CIRC SYST VID, V20, P431, DOI 10.1109/TCSVT.2009.2035852; Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495; Larsen PK, 2008, J FORENSIC SCI, V53, P1149, DOI 10.1111/j.1556-4029.2008.00807.x; Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122; Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969; Matovski DS, 2012, IEEE T INF FOREN SEC, V7, P543, DOI 10.1109/TIFS.2011.2176118; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Walck C, 2007, HDB STAT DISTRIBUTIO; Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769; Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418; Xu D, 2012, IEEE T IMAGE PROCESS, V21, P316, DOI 10.1109/TIP.2011.2160956; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Ye JP, 2005, IEEE T KNOWL DATA EN, V17, P1208, DOI 10.1109/TKDE.2005.148; Yu Guan, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P321, DOI 10.1109/IIH-MSP.2012.84	31	77	79	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1521	1528		10.1109/TPAMI.2014.2366766	http://dx.doi.org/10.1109/TPAMI.2014.2366766			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352457	Green Submitted, hybrid			2022-12-18	WOS:000355931100017
J	Kim, S; Yoo, CD; Nowozin, S; Kohli, P				Kim, Sungwoong; Yoo, Chang D.; Nowozin, Sebastian; Kohli, Pushmeet			Image Segmentation Using Higher-Order Correlation Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; correlation clustering; structural learning	CUTS	In this paper, a hypergraph-based image segmentation framework is formulated in a supervised manner for many high-level computer vision tasks. To consider short-and long-range dependency among various regions of an image and also to incorporate wider selection of features, a higher-order correlation clustering (HO-CC) is incorporated in the framework. Correlation clustering (CC), which is a graph-partitioning algorithm, was recently shown to be effective in a number of applications such as natural language processing, document clustering, and image segmentation. It derives its partitioning result from a pairwise graph by optimizing a global objective function such that it simultaneously maximizes both intra-cluster similarity and inter-cluster dissimilarity. In the HO-CC, the pairwise graph which is used in the CC is generalized to a hypergraph which can alleviate local boundary ambiguities that can occur in the CC. Fast inference is possible by linear programming relaxation, and effective parameter learning by structured support vector machine is also possible by incorporating a decomposable structured loss function. Experimental results on various data sets show that the proposed HO-CC outperforms other state-of-the-art image segmentation algorithms. The HO-CC framework is therefore an efficient and flexible image segmentation framework.	[Kim, Sungwoong] Qualcomm Res Korea, Seoul 135820, South Korea; [Yoo, Chang D.] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea; [Yoo, Chang D.] MIT, Elect Res Lab, Cambridge, MA 02139 USA; [Nowozin, Sebastian; Kohli, Pushmeet] Microsoft Res Cambridge, Machine Learning & Percept, Cambridge CB3 0FB, England; [Nowozin, Sebastian] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Nowozin, Sebastian] Tech Univ Berlin, Berlin, Germany	Qualcomm; Korea Advanced Institute of Science & Technology (KAIST); Massachusetts Institute of Technology (MIT); Microsoft; Max Planck Society; Technical University of Berlin	Kim, S (corresponding author), Qualcomm Res Korea, 119 Nonhyeon Dong, Seoul 135820, South Korea.	sungwoong.kim01@gmail.com; cdyoo@ee.kaist.ac.kr; Sebastian.Nowozin@microsoft.com; pkohli@microsoft.com	Yoo, Chang-Dong/C-1563-2011		National Research Foundation of Korea (NRF) - Korea government (MSIP) [NRF-2011-0017202, NRF-2010-0028680]	National Research Foundation of Korea (NRF) - Korea government (MSIP)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. NRF-2011-0017202 and No. NRF-2010-0028680).	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; BACH F, 2003, P NEUR INF PROC SYST; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; BATRA D, 2008, P IEEE C COMP VIS PA; Berge C., 1989, HYPERGRAPHS; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; CHOPRA S, 1993, MATH PROGRAM, V59, P87, DOI 10.1007/BF01581239; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour I., 2005, P INT C ART INT STAT; COUR T, 2005, P IEEE C COMP VIS PA; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEZA M, 1992, MATH OPER RES, V17, P981, DOI 10.1287/moor.17.4.981; DEZA MM, 1997, ALGORITHMS COMBINATO, V15; Ding L., 2008, P INT C MACH LEARN A; Ding L, 2010, PATTERN RECOGN, V43, P1863, DOI 10.1016/j.patcog.2009.11.025; Ducournau A., 2009, P IEEE INT C SIGN IM; ENDRES I., 2010, P EUR C COMP VIS ECC; ESTRADA F, 2004, P BRIT MACH VIS C BM; Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Finley T., 2008, P INT C MACH LEARN; Finley T., 2005, P INT C MACH LEARN; Fowlkes C., 2014, BERKELEY SEGMENTATIO; Freixenet J., 2002, P EUR C COMP VIS ECC; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Gould S., 2009, P IEEE INT C COMP VI; GROTSCHEL M, 1981, COMBINATORICA, V1, P169, DOI 10.1007/BF02579273; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Joachims T., 2005, P INT C MACH LEARN; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kim S., 2011, P NEUR INF PROC SYST; Kim S, 2013, IEEE T IMAGE PROCESS, V22, P488, DOI 10.1109/TIP.2012.2218822; KIM T, 2010, P IEEE C COMP VIS PA; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Kulesza A., 2007, P NEUR INF PROC SYST; Kumar M.P., 2010, P IEEE C COMP VIS PA; Ladicky L., 2009, P IEEE INT C COMP VI; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Malisiewicz T., 2007, P BRIT MACH VIS C BM; Martins A. F. T., 2009, P INT C MACH LEARN; McCallum Andrew, 2003, P IJCAI WORKSH INF I; MEILA M, 2005, P INT C MACH LEARN; Nemenyi P.B., 1963, THESIS PRINCETON U; Nowozin S., 2009, P INT C MACH LEARN; PELE O, 2009, P IEEE INT C COMP VI; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rao S.R., 2009, P AS C COMP VIS ACCV; Rital S, 2009, FUND INFORM, V96, P153, DOI 10.3233/FI-2009-172; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SHOTTON J., 2006, P EUR C COMP VIS ECC; Sipahi, 2010, 2010 IEEE WORLD C CO, DOI [10.1109/CEC.2010.5585957, DOI 10.1109/CEC.2010.5585957]; Taskar Ben, 2004, THESIS; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Turaga S., 2009, P NEUR INF PROC SYST; Wolsey LA, 1998, INTEGER PROGRAMMING	55	77	86	0	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1761	1774		10.1109/TPAMI.2014.2303095	http://dx.doi.org/10.1109/TPAMI.2014.2303095			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352230	Green Submitted			2022-12-18	WOS:000340210100005
J	Perakis, P; Passalis, G; Theoharis, T; Kakadiaris, IA				Perakis, Panagiotis; Passalis, Georgios; Theoharis, Theoharis; Kakadiaris, Ioannis A.			3D Facial Landmark Detection under Large Yaw and Expression Variations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face models; landmark detection; shape index; spin images		A 3D landmark detection method for 3D facial scans is presented and thoroughly evaluated. The main contribution of the presented method is the automatic and pose-invariant detection of landmarks on 3D facial scans under large yaw variations (that often result in missing facial data), and its robustness against large facial expressions. Three-dimensional information is exploited by using 3D local shape descriptors to extract candidate landmark points. The shape descriptors include the shape index, a continuous map of principal curvature values of a 3D object's surface, and spin images, local descriptors of the object's 3D point distribution. The candidate landmarks are identified and labeled by matching them with a Facial Landmark Model (FLM) of facial anatomical landmarks. The presented method is extensively evaluated against a variety of 3D facial databases and achieves state-of-the-art accuracy (4.5-6.3 mm mean landmark localization error), considerably outperforming previous methods, even when tested with the most challenging data.	[Perakis, Panagiotis; Passalis, Georgios; Theoharis, Theoharis] Univ Athens, Dept Informat & Telecommun, Comp Graph Lab, Ilisia 17584, Greece; [Perakis, Panagiotis; Passalis, Georgios; Theoharis, Theoharis; Kakadiaris, Ioannis A.] Univ Houston, Dept Comp Sci, Computat Biomed Lab, Houston, TX 77204 USA; [Theoharis, Theoharis] NTNU, Dept Comp & Informat Sci, NO-7491 Trondheim, Norway	National & Kapodistrian University of Athens; University of Houston System; University of Houston; Norwegian University of Science & Technology (NTNU)	Perakis, P (corresponding author), Univ Athens, Dept Informat & Telecommun, Comp Graph Lab, Ilisia 17584, Greece.	takis@antinoos.gr; passalis@di.uoa.gr; theotheo@di.uoa.gr; ioannisk@uh.edu	Theoharis, Theoharis/AAN-2555-2020; Perakis, Panagiotis/AAS-4573-2021	Kakadiaris, Ioannis/0000-0002-0591-1079	European Union (European Social Fund-ESF); Greek national funds through Operational Program "Education and Lifelong Learning" of the National Strategic Reference Framework (NSRF)-Research Funding Program: Heracleitus II. Investing in knowledge society through the European Social Fund; University of Houston Eckhard Pfeiffer Endowment Fund	European Union (European Social Fund-ESF)(European Social Fund (ESF)); Greek national funds through Operational Program "Education and Lifelong Learning" of the National Strategic Reference Framework (NSRF)-Research Funding Program: Heracleitus II. Investing in knowledge society through the European Social Fund; University of Houston Eckhard Pfeiffer Endowment Fund	This research has been cofinanced in part by: 1) the European Union (European Social Fund-ESF) and Greek national funds through the Operational Program "Education and Lifelong Learning" of the National Strategic Reference Framework (NSRF)-Research Funding Program: Heracleitus II. Investing in knowledge society through the European Social Fund, and 2) the University of Houston Eckhard Pfeiffer Endowment Fund. All statements of fact, opinion, or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of the sponsors.	Colbry D., 2006, THESIS MICHIGAN STAT; Colbry Dirk, 2005, IEEE COMP SOC C COMP, P1, DOI DOI 10.1109/CVPR.2005.441; Conde C, 2005, IAPR C MACH VIS APPL, P418; Cootes T, 2005, HANDBOOK OF FACE RECOGNITION, P39, DOI 10.1007/0-387-27257-7_3; Cootes T., 2001, TECHNICAL REPORT; DIBEKLIOGLU H, 2008, THESIS BOGAZICI U; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Faltemier TC, 2008, P 8 IEEE INT C AUT F, P1, DOI DOI 10.1109/AFGR.2008.4813413; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Johnson A., 1997, THESIS CARNEGIE MELL; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Lin T.H., 2006, P 44 ANN SE REG C, P423; LU X, 2005, MSUCSE0522 MICH STAT; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629; Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49; Perakis P, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P439; Perakis P., 2009, P EUR WORKSH 3D OBJ, P37, DOI DOI 10.2312/3DOR/3DOR09/037-044; Perakis P., 2010, TP201001 U ATH COMP; Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59; Phillips PJ, 2005, PROC CVPR IEEE, P947; Romero-Huertas M., 2008, P 2 IEEE INT C BIOM; Salah A. A., 2008, 2 IEEE INT C BIOM TH, P1, DOI [DOI 10.1109/BTAS.2008.4699324, 10.1109/BTAS.2008.4699324]; Segundo MP, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P431, DOI 10.1109/ICIAP.2007.4362816; Stegman M., 2002, TECHNICAL REPORT; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; UH-CBL, 2012, FAC LANDM ANN FIL; UND, 2012, U NOTR DAM BIOM DAT; Wei XZ, 2007, LECT NOTES COMPUT SC, V4642, P144; Xu C., 2006, PATTERN RECOGN, V27, P62; Yu T.H., 2008, P 2 IEEE INT C BIOM	37	77	83	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1552	1564		10.1109/TPAMI.2012.247	http://dx.doi.org/10.1109/TPAMI.2012.247			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681986	Green Submitted			2022-12-18	WOS:000319060600002
J	Ravichandran, A; Chaudhry, R; Vidal, R				Ravichandran, Avinash; Chaudhry, Rizwan; Vidal, Rene			Categorizing Dynamic Textures Using a Bag of Dynamical Systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic textures; categorization; linear dynamical systems	KERNELS	We consider the problem of categorizing video sequences of dynamic textures, i.e., nonrigid dynamical objects such as fire, water, steam, flags, etc. This problem is extremely challenging because the shape and appearance of a dynamic texture continuously change as a function of time. State-of-the-art dynamic texture categorization methods have been successful at classifying videos taken from the same viewpoint and scale by using a Linear Dynamical System (LDS) to model each video, and using distances or kernels in the space of LDSs to classify the videos. However, these methods perform poorly when the video sequences are taken under a different viewpoint or scale. In this paper, we propose a novel dynamic texture categorization framework that can handle such changes. We model each video sequence with a collection of LDSs, each one describing a small spatiotemporal patch extracted from the video. This Bag-of-Systems (BoS) representation is analogous to the Bag-of-Features (BoF) representation for object recognition, except that we use LDSs as feature descriptors. This choice poses several technical challenges in adopting the traditional BoF approach. Most notably, the space of LDSs is not euclidean; hence, novel methods for clustering LDSs and computing codewords of LDSs need to be developed. We propose a framework that makes use of nonlinear dimensionality reduction and clustering techniques combined with the Martin distance for LDSs to tackle these issues. Our experiments compare the proposed BoS approach to existing dynamic texture categorization methods and show that it can be used for recognizing dynamic textures in challenging scenarios which could not be handled by existing methods.	[Ravichandran, Avinash] Univ Calif Los Angeles, UCLA Vis Lab, Los Angeles, CA 90095 USA; [Chaudhry, Rizwan; Vidal, Rene] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA	University of California System; University of California Los Angeles; Johns Hopkins University	Ravichandran, A (corresponding author), Univ Calif Los Angeles, UCLA Vis Lab, Boelter Hall 3811A,405 Hilgard Ave, Los Angeles, CA 90095 USA.	avinash@cs.ucla.edu; rizwanch@cis.jhu.edu; rvidal@jhu.edu	Vidal, Rene/A-3367-2010					Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165; Bay H., 2006, P EUR C COMP VIS MAY; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chan AB, 2005, PROC CVPR IEEE, P846; Chan AB, 2007, PROC CVPR IEEE, P208; Cox T.F., 1994, MULTIDIMENSIONAL SCA; Dance C., 2004, P EUR C COMP VIS; De Cock K, 2002, SYST CONTROL LETT, V46, P265, DOI 10.1016/S0167-6911(02)00135-4; Dollar P., 2005, P IEEE INT WORKSH VI; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Doretto G., 2003, P IEEE C COMP VIS, P44; Duda RO., 2004, PATTERN CLASSIFICATI; Fujita K., 2003, P 3 INT WORKSH TEXT; Ghoreyshi A., 2006, WDV06, P127; Hofmann T., 1999, P UNC ART INT; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kaufman L., 2009, FINDING GROUPS DATA; Klaser Alexander, 2008, BMVC; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Ravichandran A., 2010, P AS C COMP VIS, P425; Ravichandran A., 2009, P IEEE C COMP VIS PA; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saisan P, 2001, PROC CVPR IEEE, P58; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5; Vidal R., 2007, P IEEE INT C COMP VI; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; Wang Heng, 2009, BMVC, P1; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; Willems G., 2008, P EUR C COMP VIS; Wong S.-F., 2007, P IEEE INT C COMP VI, P1, DOI DOI 10.1109/VTSA.2007.378923; Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549	39	77	81	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					342	353		10.1109/TPAMI.2012.83	http://dx.doi.org/10.1109/TPAMI.2012.83			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	23257470				2022-12-18	WOS:000312560600008
J	Fan, JL; Shen, XH; Wu, Y				Fan, Jialue; Shen, Xiaohui; Wu, Ying			Scribble Tracker: A Matting-Based Approach for Robust Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; matting; model updating; video analysis	IMAGE; SEGMENTATION; FRAMEWORK; MODELS	Model updating is a critical problem in tracking. Inaccurate extraction of the foreground and background information in model adaptation would cause the model to drift and degrade the tracking performance. The most direct yet difficult solution to the drift problem is to obtain accurate boundaries of the target. We approach such a solution by proposing a novel model adaptation framework based on the combination of matting and tracking. In our framework, coarse tracking results automatically provide sufficient and accurate scribbles for matting, which makes matting applicable in a tracking system. Meanwhile, accurate boundaries of the target can be obtained from matting results even when the target has large deformation. An effective model combining short-term features and long-term appearances is further constructed and successfully updated based on such accurate boundaries. The model can successfully handle occlusion by explicit inference. Extensive experiments show that our adaptation scheme largely avoids model drift and significantly outperforms other discriminative tracking models.	[Fan, Jialue; Shen, Xiaohui; Wu, Ying] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Northwestern University	Fan, JL (corresponding author), Northwestern Univ, Dept Elect Engn & Comp Sci, 2145 Sheridan Rd, Evanston, IL 60208 USA.	jialue.fan@northwestern.edu; xsh835@eecs.northwestern.edu; yingwu@eecs.northwestern.edu	Wu, Ying/B-7283-2009	Koochak, Atousa/0000-0001-6547-2728	US National Science Foundation [IIS-0347877, IIS-0916607]; US Army Research Laboratory; US Army Research Office [ARO W911NF-08-1-0504]	US National Science Foundation(National Science Foundation (NSF)); US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office	The authors would like to thank the anonymous reviewers for their constructive comments and suggestions. This work was supported in part by US National Science Foundation grants IIS-0347877, IIS-0916607, and the US Army Research Laboratory and the US Army Research Office under grant ARO W911NF-08-1-0504. An earlier version of this work appeared in [13].	Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B., 2009, P IEEE C COMP VIS PA; Bai X., 2009, P ACM SIGGR; Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z; Bibby C, 2008, P EUR C COMP VIS; Bibby C., 2010, P IEEE C COMP VIS PA; Bregler C., 1998, P IEEE C COMP VIS PA; Chuang Y.-Y., 2002, P ACM SIGGR; Chuang Y.Y., 2001, P IEEE C COMP VIS PA; Cohen M. F., 2007, P IEEE C COMP VIS PA; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D., 2000, P IEEE C COMP VIS PA; Dambreville S, 2008, IEEE T PATTERN ANAL, V30, P1385, DOI 10.1109/TPAMI.2007.70774; Fan J., 2010, P EUR C COMP VIS; Grabner H., 2008, P EUR C COMP VIS; Grabner H., 2006, 2006 IEEE COMP SOC C, P260; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; HAGER G, 1996, P IEEE C COMP VIS PA; He K., 2010, P IEEE C COMP VIS PA; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kalal Z., 2010, P IEEE C COMP VIS PA; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kim M., 2008, P IEEE C COMP VIS PA; Kohli P, 2008, COMPUT VIS IMAGE UND, V112, P30, DOI 10.1016/j.cviu.2008.07.002; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; Kwon J., 2010, P IEEE C COMP VIS PA; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Liu X., 2007, P INT C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu L, 2007, P IEEE C COMP VIS PA; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Nguyen HT, 2006, INT J COMPUT VISION, V69, P277, DOI 10.1007/s11263-006-7067-x; Ozuysal M., 2006, P EUR C COMP VIS; Pellegrini S., 2009, P IEEE INT C COMP VI; Ren X., 2007, P IEEE C COMP VIS PA; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; SCHOENEMANN T, 2008, P IEEE C COMP VIS PA; Stalder S., 2009, P 12 IEEE INT C COMP; TOYAMA K, 2001, P IEEE INT C COMP VI; Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019; Woodley T., 2007, P BRIT MACH VIS C; WU Y, 2009, P IEEE C COMP VIS PA; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yin Z., 2009, P IEEE C COMP VIS PA; YU T, 2004, P IEEE C COMP VIS PA; ZHOU Y, 2003, P INT C COMP VIS	48	77	88	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1633	1644		10.1109/TPAMI.2011.257	http://dx.doi.org/10.1109/TPAMI.2011.257			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22745003				2022-12-18	WOS:000305188500014
J	Zhang, LJ; Chen, C; Bu, JJ; Cai, D; He, XF; Huang, TS				Zhang, Lijun; Chen, Chun; Bu, Jiajun; Cai, Deng; He, Xiaofei; Huang, Thomas S.			Active Learning Based on Locally Linear Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active learning; experimental design; local structure; reconstruction	ALGORITHM	We consider the active learning problem, which aims to select the most representative points. Out of many existing active learning techniques, optimum experimental design (OED) has received considerable attention recently. The typical OED criteria minimize the variance of the parameter estimates or predicted value. However, these methods see only global euclidean structure, while the local manifold structure is ignored. For example, I-optimal design selects those data points such that other data points can be best approximated by linear combinations of all the selected points. In this paper, we propose a novel active learning algorithm which takes into account the local structure of the data space. That is, each data point should be approximated by the linear combination of only its neighbors. Given the local reconstruction coefficients for every data point and the coordinates of the selected points, a transductive learning algorithm called Locally Linear Reconstruction (LLR) is proposed to reconstruct every other point. The most representative points are thus defined as those whose coordinates can be used to best reconstruct the whole data set. The sequential and convex optimization schemes are also introduced to solve the optimization problem. The experimental results have demonstrated the effectiveness of our proposed method.	[Zhang, Lijun; Chen, Chun; Bu, Jiajun] Zhejiang Univ, Zhejiang Prov Key Lab Serv Robot, Coll Comp Sci, Hangzhou 310027, Peoples R China; [Cai, Deng; He, Xiaofei] Zhejiang Univ, State Key Lab CAD & CG, Coll Comp Sci, Hangzhou 310027, Peoples R China; [Huang, Thomas S.] Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA	Zhejiang University; Zhejiang University; University of Illinois System; University of Illinois Urbana-Champaign	Zhang, LJ (corresponding author), Zhejiang Univ, Zhejiang Prov Key Lab Serv Robot, Coll Comp Sci, Cao Guangbiao Bldg,Yuquan Campus, Hangzhou 310027, Peoples R China.	zljzju@zju.edu.cn; chenc@zju.edu.cn; bjj@zju.edu.cn; dengcai@cad.zju.edu.cn; xiaofeihe@cad.zju.edu.cn; huang@ifp.uiuc.edu			Ministry of Education; National Key Technology R&D Program of China [2008BAH26B00]; Program for New Century Excellent Talents in University [NCET-09-0685]; National Basic Research Program of China (973 Program) [2011CB302206]; Natural Science Foundation of China [90920303, 60875044]	Ministry of Education; National Key Technology R&D Program of China(National Key Technology R&D Program); Program for New Century Excellent Talents in University(Program for New Century Excellent Talents in University (NCET)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by Scholarship Award for Excellent Doctoral Student granted by Ministry of Education, National Key Technology R&D Program of China (2008BAH26B00), Program for New Century Excellent Talents in University (NCET-09-0685), National Basic Research Program of China (973 Program) under Grant 2011CB302206, and Natural Science Foundation of China under Grants 90920303 and 60875044.	Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Asprey SP, 2002, J PROCESS CONTR, V12, P545, DOI 10.1016/S0959-1524(01)00020-8; Atkinson A., 2007, OPTIMUM EXPT DESIGNS, V34; Belkin M, 2002, ADV NEUR IN, V14, P585; BELKIN M, 2004, P 17 ANN C LEARN THE, P624; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen C, 2010, NEUROCOMPUTING, V73, P951, DOI 10.1016/j.neucom.2009.08.021; Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; Fujii A, 1998, COMPUT LINGUIST, V24, P573; Golub G. H., 2012, MATRIX COMPUTATIONS; Grant M., 2014, CVX MATLAB SOFTWARE; Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7; GRARY SB, 1996, COMPUTATIONAL EC, V9, P241; HARDIN RH, 1993, J STAT PLAN INFER, V37, P339, DOI 10.1016/0378-3758(93)90112-J; Hastie T, 2009, ELEMENTS STAT LEARNI; He XF, 2004, ADV NEUR IN, V16, P153; Lee H., 2007, ADV NEURAL INF PROCE, P801; LEWIS DD, 1994, P 17 ANN INT ACM SIG, P3; Li XL, 2010, IEEE T KNOWL DATA EN, V22, P145, DOI 10.1109/TKDE.2009.64; Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe; MELVILLE P, 2004, P 21 INT C MACH LEAR; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Roy Nicholas, 2001, P 18 INT C MACH LEAR, P441; Settles B., 2009, ACTIVE LEARNING LIT; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiaofei He, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119; YU H, 2002, P INT C IM PROC, P24; Yu K., 2006, P 23 INT C MACH LEAR, P1081; Zhang H, 2009, ACM/IEEE SIXTH INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING AND COMMUNICATIONS (ICAC '09), P45; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu X., 2003, INT C MACH LEARN; Zhu X.J, 2005, SEMISUPERVISED LEARN	40	77	87	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2026	2038		10.1109/TPAMI.2011.20	http://dx.doi.org/10.1109/TPAMI.2011.20			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21282854	Green Submitted			2022-12-18	WOS:000293969000010
J	Zhu, JJ; Wang, L; Gao, JZ; Yang, RG				Zhu, Jiejie; Wang, Liang; Gao, Jizhou; Yang, Ruigang			Spatial-Temporal Fusion for High Accuracy Depth Maps Using Dynamic MRFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; MRFs; time-of-flight sensor; data fusion; global optimization	BELIEF PROPAGATION; STEREO; FIELDS	Time-of-flight range sensors and passive stereo have complimentary characteristics in nature. To fuse them to get high accuracy depth maps varying over time, we extend traditional spatial MRFs to dynamic MRFs with temporal coherence. This new model allows both the spatial and the temporal relationship to be propagated in local neighbors. By efficiently finding a maximum of the posterior probability using Loopy Belief Propagation, we show that our approach leads to improved accuracy and robustness of depth estimates for dynamic scenes.	[Zhu, Jiejie] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32826 USA; [Zhu, Jiejie; Wang, Liang; Gao, Jizhou; Yang, Ruigang] Univ Kentucky, Dept Comp Sci, Lexington, KY 40507 USA	State University System of Florida; University of Central Florida; University of Kentucky	Zhu, JJ (corresponding author), Univ Cent Florida, Dept Comp Sci, HEC234,4000 Cent Florida Blvd, Orlando, FL 32826 USA.	jjzhu@cs.ucf.edu; lwangd@cs.uky.edu; jgao5@cs.uky.edu; ryang@cs.uky.edu		Yang, Ruigang/0000-0001-5296-6307	University of Kentucky Research Foundation; US Department of Homeland Security; US National Science Foundation [HCC-0448185, CPA-0811647]; State Key Lab of CAD&CG, Zhejiang University, China [A0812]	University of Kentucky Research Foundation; US Department of Homeland Security(United States Department of Homeland Security (DHS)); US National Science Foundation(National Science Foundation (NSF)); State Key Lab of CAD&CG, Zhejiang University, China	This work is supported in part by the University of Kentucky Research Foundation, the US Department of Homeland Security, US National Science Foundation Grants HCC-0448185 and CPA-0811647, and the Open Project Program of the State Key Lab of CAD&CG (grant no.: A0812), Zhejiang University, China. This work was performed while Jiejie Zhu was with the University of Kentucky.	*3DV SYST, 2004, Z CAM; ALAHARI K, 2008, P IEEE C COMP VIS PA; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Canesta Inc, 2006, CAN EL PERC DEV KIT; Chen J., 2007, P IEEE C COMP VIS PA; Diebel J, 2005, P ADV NEUR INF PROC; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gonzalez-Banos H, 2004, PROC CVPR IEEE, P234; GUAN L, 2008, P IEEE WORKSH MULT M; GUOMUNDSSON SA, 2007, P INT WORKSH DYN 3D; Ihler AT, 2005, J MACH LEARN RES, V6, P905; ISARD M, 2006, P AS C COMP VIS; JUAN O, 2006, P IEEE C COMP VIS PA; KAHLMANN T, 2007, P C OPT 3D MEAS TECH; KAHLMANN T, 2006, P SPIE EL REM SENS 2; KANATANI K, 1984, ARTIF INTELL, V23, P213, DOI 10.1016/0004-3702(84)90010-9; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193; Kuhnert KD, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4780, DOI 10.1109/IROS.2006.282349; Linde A, 2008, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2008/03/005; Lindner Marvin, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P344, DOI 10.1504/IJISTA.2008.021297; Lindner M., 2007, P SPIE INT ROB COMP, P35; MICHELS J, 2005, P INT C MACH LEARN; Ogale AS, 2005, INT J COMPUT VISION, V65, P147, DOI 10.1007/s11263-005-3672-3; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; *PMDTEC INC, 2008, PHOT MIX DEV; Roth S, 2005, PROC CVPR IEEE, P860; ROTH S, 2007, P IEEE C COMP VIS PA; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D., 2003, P IEEE C COMP VIS PA; SCHILLER I, 2008, P 37 INT SOC PHOT RE; SCHILLER I, 2008, P INT SOC PHOT REM S; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; *SWISSR INC, 2006, SR 3; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; VERRI A, 1986, J OPT SOC AM A, V3, P297, DOI 10.1364/JOSAA.3.000297; Wills J, 2003, PROC CVPR IEEE, P37; YANG Q, 2006, CVPR, P2347; YANG Q., 2006, P BRIT MACH VIS C; YANG Q, 2007, P IEEE C COMP VIS PA; Yin Z., 2007, P IEEE C COMP VIS PA; Yoon KJ, 2005, PROC CVPR IEEE, P924; Zhu J., 2008, P IEEE C COMP VIS PA	49	77	85	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					899	909		10.1109/TPAMI.2009.68	http://dx.doi.org/10.1109/TPAMI.2009.68			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299713				2022-12-18	WOS:000275569300010
J	Yang, RD; Sarkar, S; Loeding, B				Yang, Ruiduo; Sarkar, Sudeep; Loeding, Barbara			Handling Movement Epenthesis and Hand Segmentation Ambiguities in Continuous Sign Language Recognition Using Nested Dynamic Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sign language; movement epenthesis; continuous gesture; segmentation; level building	MODELS	We consider two crucial problems in continuous sign language recognition from unaided video sequences. At the sentence level, we consider the movement epenthesis (me) problem and at the feature level, we consider the problem of hand segmentation and grouping. We construct a framework that can handle both of these problems based on an enhanced, nested version of the dynamic programming approach. To address movement epenthesis, a dynamic programming (DP) process employs a virtual me option that does not need explicit models. We call this the enhanced level building (eLB) algorithm. This formulation also allows the incorporation of grammar models. Nested within this eLB is another DP that handles the problem of selecting among multiple hand candidates. We demonstrate our ideas on four American Sign Language data sets with simple background, with the signer wearing short sleeves, with complex background, and across signers. We compared the performance with Conditional Random Fields (CRF) and Latent Dynamic-CRF-based approaches. The experiments show more than 40 percent improvement over CRF or LDCRF approaches in terms of the frame labeling rate. We show the flexibility of our approach when handling a changing context. We also find a 70 percent improvement in sign recognition rate over the unenhanced DP matching algorithm that does not accommodate the me effect.	[Yang, Ruiduo; Sarkar, Sudeep] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; [Loeding, Barbara] Univ S Florida Polytech, Lakeland, FL 33803 USA	State University System of Florida; University of South Florida; Florida Polytechnical University	Yang, RD (corresponding author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.	ryang@cse.usf.edu; sarkar@cse.usf.edu; bloeding@poly.usf.edu	Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207	US National Science Foundation [IIS 0312993]	US National Science Foundation(National Science Foundation (NSF))	This work was supported in part by the US National Science Foundation under grant IIS 0312993.	ALON J, 2005, P IEEE WORKSH MOT VI, V2, P254; Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332; Bauer B, 2000, INT C PATT RECOG, P463, DOI 10.1109/ICPR.2000.906112; Brashear H, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P45, DOI 10.1109/ISWC.2003.1241392; Brashear H., 2006, P 8 INT ACM SIGACCES, P79; Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837; DING L, 2007, P IEEE C ADV VID SIG; Gao W, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P553; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Kadous Mohammed Waleed, 1996, P WORKSH INT GEST LA, P165; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123; Loeding BL, 2004, LECT NOTES COMPUT SC, V3118, P1079; MARTINEZ AM, 2002, P INT C MULT INT; Morency L. -P., 2007, P I C COMP VI PATT R, P1, DOI DOI 10.1109/CVPR.2007.383299; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P284, DOI 10.1109/TASSP.1981.1163527; Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROBLEDO I, 2003, IEEE T PATTERN ANAL, V25, P1323; Sato Y, 2002, INT C PATT RECOG, P515, DOI 10.1109/ICPR.2002.1048351; SILVERMAN H, 1990, IEEE ASSP MAGAZINE, V26, P575; SKOUNAKIS M, 2003, P INT JOINT ART INT; Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014; STARNER T, 1995, P INT WORKSH AUT FAC, P189; Vogler C, 2003, LECT NOTES ARTIF INT, V2915, P247; Vogler C, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P33, DOI 10.1109/HUMO.2000.897368; Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895; Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744; Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188; WILBUR R, 2006, 0612 PURD U SCH EL C; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; YANG R, 2006, P IEEE INT C COMP VI, V1, P766; YANG R, 2009, J COMPUTER VISION IM, V113, P663; Yang RD, 2006, INT C PATT RECOG, P108; Yang RD, 2006, LECT NOTES COMPUT SC, V4061, P635; Yuan Q, 2002, INT C PATT RECOG, P75, DOI 10.1109/ICPR.2002.1044616; [No title captured]; 2008, OPEN SOURCE COMPUTER	39	77	77	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					462	477		10.1109/TPAMI.2009.26	http://dx.doi.org/10.1109/TPAMI.2009.26			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075472	Green Submitted			2022-12-18	WOS:000273609600006
J	Lu, XG; Jain, AK				Lu, Xiaoguang; Jain, Anil K.			Deformation modeling for robust 3D face matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformation modeling; 3D face recognition; facial expression; deformable model; expression transfer; nonrigid	RECOGNITION	Face recognition based on 3D surface matching is promising for overcoming some of the limitations of current 2D image-based face recognition systems. The 3D shape is generally invariant to the pose and lighting changes, but not invariant to the nonrigid facial movement such as expressions. Collecting and storing multiple templates to account for various expressions for each subject in a large database is not practical. We propose a facial surface modeling and matching scheme to match 2.5D facial scans in the presence of both nonrigid deformations and pose changes (multiview) to a stored 3D face model with neutral expression. A hierarchical geodesic-based resampling approach is applied to extract landmarks for modeling facial surface deformations. We are able to synthesize the deformation learned from a small group of subjects (control group) onto a 3D neutral model (not in the control group), resulting in a deformed template. A user-specific (3D) deformable model is built for each subject in the gallery with respect to the control group by combining the templates with synthesized deformations. By fitting this generative deformable model to a test scan, the proposed approach is able to handle expressions and pose changes simultaneously. A fully automatic and prototypic deformable model based 3D face matching system has been developed. Experimental results demonstrate that the proposed deformation modeling scheme increases the 3D face matching accuracy in comparison to matching with 3D neutral models by 7 and 10 percentage points, respectively, on a subset of the FRGC v2.0 3D benchmark and the MSU multiview 3D face database with expression variations.	[Lu, Xiaoguang] Siemens Corp Res, Princeton, NJ 08540 USA; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Siemens AG; Michigan State University	Lu, XG (corresponding author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	Lvxiaogu@ieee.org						BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; BRONSTEIN A, 2003, P AUD VID BAS BIOM P, P62; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Chang KI, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P187; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Gill P. E., 1981, PRACTICAL OPTIMIZATI; GORDON G, 1992, P IEEE COMP SOC C CO, P108; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Lee J. C., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P722, DOI 10.1109/ICCV.1990.139627; Li S.Z., 2005, HDB FACE RECOGNITION; Lu X, 2006, P IEEE COMP SOC C CO, P1377, DOI DOI 10.1109/CVPR..96; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585; Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290; Pan G, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P193; PASSALIS G, 2005, P IEEE WORKSH FAC RE; Phillips PJ, 2005, PROC CVPR IEEE, P947; PHILLIPS PJ, 2003, FRVT 2002 EVALUATION; PIGHIN F, 1998, P SIGGRAPH 98, P75; SUMNER RW, 2004, P ACM SIGGRAPH, P399; Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977; WILLIAMSLINERA G, 1990, BIOTROPICA, V22, P235, DOI 10.2307/2388533; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; 2007, MINOLTA VIVID 910 NO	34	77	90	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1346	1356		10.1109/TPAMI.2007.70784	http://dx.doi.org/10.1109/TPAMI.2007.70784			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566490	Green Submitted			2022-12-18	WOS:000256679700003
J	Tai, YW; Jia, JY; Tang, CK				Tai, Yu-Wing; Jia, Jiaya; Tang, Chi-Keung			Soft color segmentation and its applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color image segmentation and image synthesis	STEREO; PHOTOGRAPHY; ALGORITHMS; FLASH	We propose an automatic approach to soft color segmentation, which produces soft color segments with an appropriate amount of overlapping and transparency essential to synthesizing natural images for a wide range of image-based applications. Although many state-of-the-art and complex techniques are excellent at partitioning an input image to facilitate deriving a semantic description of the scene, to achieve seamless image synthesis, we advocate a segmentation approach designed to maintain spatial and color coherence among soft segments while preserving discontinuities by assigning to each pixel a set of soft labels corresponding to their respective color distributions. We optimize a global objective function, which simultaneously exploits the reliability given by global color statistics and flexibility of local image compositing, leading to an image model where the global color statistics of an image is represented by a Gaussian Mixture Model (GMM), whereas the color of a pixel is explained by a local color mixture model where the weights are defined by the soft labels to the elements of the converged GMM. Transparency is naturally introduced in our probabilistic framework, which infers an optimal mixture of colors at an image pixel. To adequately consider global and local information in the same framework, an alternating optimization scheme is proposed to iteratively solve for the global and local model parameters. Our method is fully automatic and is shown to converge to a good optimal solution. We perform extensive evaluation and comparison and demonstrate that our method achieves good image synthesis results for image-based applications such as image matting, color transfer, image deblurring, and image colorization.	Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Hong Kong University of Science & Technology; Chinese University of Hong Kong	Tai, YW (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	yuwing@gmail.com; leojia@cse.cuhk.edu.hk; cktang@cs.ust.hk	Tai, Yu Wing/C-2047-2011; Jia, Jiaya/I-3251-2012	Tai, Yu Wing/0000-0002-3148-0380; 				Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790; Berman A., 2000, U.S. Patent, Patent No. [6,134,345, 6134345]; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; BLACK MJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P15, DOI 10.1109/CVPR.1994.323805; Chuang YY, 2001, PROC CVPR IEEE, P264; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Csiszar I., 1984, STAT DECISIONS, V1, P205; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778; Gordon S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P370; Gray R., 2000, ENTROPY INFORM THEOR; Grunwarld P., 2002, MINIMUM DESCRIPTION; JIA J, 2004, P EUR C COMP VIS, V3, P342; KOLMOGOROV V, 2002, P EUR C COMP VIS, P82; Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753; Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; PIETIKAINEN M, 1982, PATTERN RECOGN, V15, P287, DOI 10.1016/0031-3203(82)90031-0; PORTER T, 1984, P SIGGRAPH, V84, P253; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; ROTHER C, 2004, P ACM INT C COMP GRA; Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793; Sharon E, 2001, PROC CVPR IEEE, P469; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SMITH AR, 1996, P SIGGRAPH 96, P259; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Sun Y, 2004, WIREL COMMUN MOB COM, V4, P315, DOI 10.1002/wcm.215; Tai YW, 2005, PROC CVPR IEEE, P747; Tang KL, 2005, PROC CVPR IEEE, P132; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WELSH T, 2002, P 29 ANN C COMP GRAP, P277; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224	40	77	80	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1520	1537		10.1109/TPAMI.2007.1168	http://dx.doi.org/10.1109/TPAMI.2007.1168			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627041	Green Submitted			2022-12-18	WOS:000247965600003
J	Kim, HC; Ghahramani, Z				Kim, Hyun-Chul; Ghahramani, Zoubin			Bayesian Gaussian process classification with the EM-EP algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian process classification; Bayesian methods; kernel methods; expectation propagation; EM-EP algorithm	SUPPORT VECTOR MACHINES; SELECTION	Gaussian process classifiers (GPCs) are Bayesian probabilistic kernel classifiers. In GPCs, the probability of belonging to a certain class at an input location is monotonically related to the value of some latent function at that location. Starting from a Gaussian process prior over this latent function, data are used to infer both the posterior over the latent function and the values of hyperparameters to determine various aspects of the function. Recently, the expectation propagation (EP) approach has been proposed to infer the posterior over the latent function. Based on this work, we present an approximate EM algorithm, the EM-EP algorithm, to learn both the latent function and the hyperparameters. This algorithm is found to converge in practice and provides an efficient Bayesian framework for learning hyperparameters of the kernel. A multiclass extension of the EM-EP algorithm for GPCs is also derived. In the experimental results, the EM-EP algorithms are as good or better than other methods for GPCs or Support Vector Machines (SVMs) with cross-validation.	Pohang Univ Sci & Technol, Dept Ind & Management Engn, Pohang 790784, South Korea; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Pohang University of Science & Technology (POSTECH); University of Cambridge	Kim, HC (corresponding author), Pohang Univ Sci & Technol, Dept Ind & Management Engn, San 31 Hyoja Dong, Pohang 790784, South Korea.	grass@postech.ac.kr; zoubin@eng.cam.ac.uk						Chu W, 2005, J MACH LEARN RES, V6, P1019; CHU W, 2003, THESIS NATL U SINGAP; CSATO L, 2000, P NEUR INF PROC SYST, V13; CSATO L, 2001, P NEURAL INFORMATION, V14; CSATO L, 2000, P NEURAL INFORM PROC, V13; Genz A., 1992, J COMPUT GRAPH STAT, V1, P141, DOI [DOI 10.1080/10618600.1992.10477010, 10.2307/1390838]; Gibbs M., 1997, EFFICIENT IMPLEMENTA; Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477; GIBBS MN, 1997, THESIS U CAMBRIDGE; Golub G. H., 1996, MATRIX COMPUTATION; Herbich R, 2001, J MACH LEARN RES, V1, P245, DOI 10.1162/153244301753683717; HESKES T, 2002, P UAI 2002, P216; KIM HC, 2003, P WORKSH PROB GRAPH; KIM HC, 2005, THESIS POSTECH; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; Kuss M, 2005, J MACH LEARN RES, V6, P1679; Kwok JTY, 1999, IEEE T NEURAL NETWOR, V10, P1018, DOI 10.1109/72.788642; Kwok JTY, 2000, IEEE T NEURAL NETWOR, V11, P1162, DOI 10.1109/72.870047; MINKA T, 2003, P NEUR INF PROC SYST, V16; Minka T., 2002, P 18 C UNCERTAINTY A, P352; Minka TP., 2001, THESIS MIT CAMBRIDGE; Neal R., 1997, BAYESIAN STAT, V6, P475; Neal RM, 1996, LECT NOTES STAT, V118; OHAGAN A, 1978, J R STAT SOC B, V40, P1; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; Platt JC, 2000, ADV NEUR IN, V12, P547; QI Y, 2003, EXPECTATION PROPAGAT; Rasmussen C.E., 1996, THESIS U TORONTO; Seeger M, 2000, ADV NEUR IN, V12, P603; SEEGER M, 2002, P NEURAL INFORMATION, V15; SEEGER M, 2004, 661 TR U CAL BERK DE; Seeger M, 2002, NOTES MINKAS EXPECTA; SNELSON E, 2005, P NEUR INF PROC SYST, V18; Sollich P, 2002, MACH LEARN, V46, P21, DOI 10.1023/A:1012489924661; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; WILLIAMS CKI, 1995, P NEUR INF PROC SYST	37	77	85	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					1948	1959		10.1109/TPAMI.2006.238	http://dx.doi.org/10.1109/TPAMI.2006.238			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108369				2022-12-18	WOS:000241195700005
J	Dinh, HQ; Turk, G; Slabaugh, G				Dinh, HQ; Turk, G; Slabaugh, G			Reconstructing surfaces by volumetric regularization using radial basis functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						regularization; surface fitting; implicit functions; noisy range data	POINTS	We present a new method of surface reconstruction that generates smooth and seamless models from sparse, noisy, nonuniform, and low resolution range data Data acquisition techniques from computer vision, such as stereo range images and space carving, produce 3D point sets that are imprecise and nonuniform when compared to laser or optical range scanners. Traditional reconstruction algorithms designed for dense and precise data do not produce smooth reconstructions when applied to vision-based data sets. Our method constructs a 3D implicit surface, formulated as a sum of weighted radial basis functions. We achieve three primary advantages over existing algorithms 1) the implicit functions we construct estimate the surface well in regions where there is little data, 2) the reconstructed surface is insensitive to noise in data acquisition because we can allow the surface to approximate, rather than exactly interpolate, the data, and 3) the reconstructed surface is locally detailed, yet globally smooth, because we use radial basis functions that achieve multiple orders of smoothness.	Georgia Inst Technol, Coll Comp, Graph Visualizat & Usabil Ctr, Atlanta, GA 30332 USA; Georgia Inst Technol, Sch Elect & Comp Engn, Ctr Signal & Image Proc, Atlanta, GA 30318 USA	University System of Georgia; Georgia Institute of Technology; University System of Georgia; Georgia Institute of Technology	Dinh, HQ (corresponding author), Georgia Inst Technol, Coll Comp, Graph Visualizat & Usabil Ctr, Atlanta, GA 30332 USA.	quynh@cc.gatech.edu; turk@cc.gatech.edu; slabaugh@ece.gatech.edu		Slabaugh, Greg/0000-0003-4060-5226				Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947; BAJAJ CL, 1994, GRAPH INTER, P174; BAJAJ CL, 1995, P SIGGRAPH, P109; Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351; BLANE MM, 2000, IEEE T VISUALIZATION; BLINN J, 1982, ACM T GRAPHICS, V1; BOULT TE, 1986, COMPUTER VISION PATT, P68; BRUCE JW, 1992, CURVES SINGULARITIES, P59; CARR JC, 2001, P 28 ANN C COMP GRAP, P67, DOI DOI 10.1145/383259.383266; CHEN F, 1996, 19965 MECSE; Culbertson W., 1999, VISION ALGORITHMS TH, V1883, P67; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576; DINH H, 2000, GVU0026 GEORG TECH C; EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635; FANG L, 1995, COMPUT AIDED DESIGN, V27, P48, DOI 10.1016/0010-4485(95)90752-2; Fomenko A. T., 1997, TOPOLOGICAL MODELING; Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899; GIROSI F, 1993, 75 MIT ART INT LAB, V1430; HILTON A, 1996, P 4 EUR C COMP VIS; HOPPE H, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011; Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731; KEREN D, 1998, INT J SHAPE MODELING, P111; KUTULAKOS KN, 1999, INT J COMPUTER V AUG; Lee MS, 1998, PROC CVPR IEEE, P346, DOI 10.1109/CVPR.1998.698629; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Morse BS, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P89, DOI 10.1109/SMA.2001.923379; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; NIELSEN M, 1997, J MATH IMAGES VISION; NIELSON GM, 1993, COMPUTER GRAPHICS AP, P60; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; SAVCHENKO VV, 1995, COMPUT GRAPH FORUM, V14, P181, DOI 10.1111/1467-8659.1440181; SCLAROFF S, 1991, P SIGGRAPH, P247; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; SLABAUGH G, 2001, INT WORKSH VOL GRAPH, P51; SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982; Suter D, 2000, IEEE T MED IMAGING, V19, P295, DOI 10.1109/42.848181; Szeliski R, 1996, INT J COMPUT VISION, V18, P171, DOI 10.1007/BF00055001; TANG C, 1998, IEEE T PATTERN ANAL, V20; Taubin G., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P658, DOI 10.1109/ICCV.1993.378149; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Taubin G, 1995, P 22 ANN C COMP GRAP, P351, DOI 10.1145/218380.218473; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8; Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580; Turk Greg, 1994, P SIGGRAPH; WAHBA G, 1990, CBMS NSF REG C SER A, P11; YNGVE G, IN PRESS ACM T VISUA; YUILLE AL, 1988, P INT C COMP VIS, P344, DOI DOI 10.1109/CCV.1988.590011	50	77	83	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1358	1371						14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF		Green Accepted			2022-12-18	WOS:000178196300006
J	Can, A; Stewart, CV; Roysam, B; Tanenbaum, HL				Can, A; Stewart, CV; Roysam, B; Tanenbaum, HL			A feature-based technique for joint, linear estimation of high-order image-to-mosaic transformations: Mosaicing the curved human retina	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust estimation; image mosaic; image montage; transformation estimation; retinal imaging; joint estimation	ROBUST	An algorithm for constructing image mosaics from multiple, uncalibrated, weak-perspective views of the human retina is presented and analyzed, It builds on a previously described algorithm for registering pairs of retinal images using a noninvertible, 12-parameter, quadratic image transformation model and a hierarchical, robust estimation technique. The major innovation presented here is a linear, feature-based, noniterative method for jointly estimating consistent transformations of all images onto the mosaic "anchor image." Constraints for this estimation are derived from pairwise registration-both directly with the anchor image and indirectly between pairs of nonanchor images. An incremental, graph-based technique constructs the set of registered image pairs used in the joint solution, The joint estimation technique allows images that do not overlap the anchor frame to be successfully mosaiced, a particularly valuable capability for mosaicing images of the retinal periphery, Experimental analysis of the algorithm on data sets from 16 eyes shows the average overall median transformation error in final mosaic construction to be 0 76 pixels, Overall, the technique is simpler, more accurate, and offers broader coverage than previously published methods.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; Ctr Sight, Albany, NY 12204 USA	Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute	Can, A (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	alican@alum.rpi.edu; stewart@cs.rpi.edu; roysab@rpi.edu; how1@albany.net						BECKER DE, 1998, IEEE T BIOMEDICAL EN, V45; BERGEN JR, 1992, P EUR C COMP VIS, P237; Berger JW, 1999, OPHTHALMOLOGY, V106, P1935, DOI 10.1016/S0161-6420(99)90404-9; Can A, 2002, IEEE T PATTERN ANAL, V24, P347, DOI 10.1109/34.990136; Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088; CAN A, 1999, P IEEE C COMP VIS PA, P286; Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709; Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395; DANI P, 1995, PATTERN RECOGN, V28, P431, DOI 10.1016/0031-3203(94)00106-V; Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630; Gracias N, 2000, COMPUT VIS IMAGE UND, V79, P66, DOI 10.1006/cviu.2000.0848; Hampel FR., 2011, WILEY SERIES PROBABI; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279; Mahurkar AA, 1996, INVEST OPHTH VIS SCI, V37, P1675; MILGRAM DL, 1975, IEEE T COMPUT, V24, P1113, DOI 10.1109/T-C.1975.224142; MILGRAM DL, 1977, IEEE T COMPUT, V26, P1175, DOI 10.1109/TC.1977.1674772; MUNDY J, 1992, GEOMETRIC INVARAIANC; Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346; PELEG S, 1981, COMPUT VISION GRAPH, V16, P90, DOI 10.1016/0146-664X(81)90094-0; Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SAWHNEY H, 1998, P 5 EUR C COMP VIS, V2, P103; Shen H, 2001, IEEE T INF TECHNOL B, V5, P77, DOI 10.1109/4233.908405; Shum HY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P953, DOI 10.1109/ICCV.1998.710831; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; TANAKA M, 1977, IEEE T SYST MAN CYB, V7, P42, DOI 10.1109/TSMC.1977.4309588; Um JS, 1999, INT J REMOTE SENS, V20, P2015, DOI 10.1080/014311699212326; Zappala A, 1999, IMAGE VISION COMPUT, V17, P589, DOI 10.1016/S0262-8856(98)00178-4	31	77	92	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					412	419		10.1109/34.990145	http://dx.doi.org/10.1109/34.990145			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM					2022-12-18	WOS:000174035900010
J	Stewart, CV				Stewart, CV			Bias in robust estimation caused by discontinuities and multiple structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust estimation; outliers; parameter estimation; discontinuities; multiple structures; bias	COMPUTER VISION; RANGE DATA; REGRESSION; SEGMENTATION; SQUARES	When fitting models to data containing multiple structures, such as when fitting surface patches to data taken from a neighborhood that includes a range discontinuity, robust estimators must tolerate both gross outliers and pseudo outliers. Pseudo outliers are outliers to the structure of interest, but inliers to a different structure. They differ from gross outliers because of their coherence. Such data occurs frequently in computer vision problems, including motion estimation, model fitting, and range data analysis. The focus in this paper is the problem of fitting surfaces near discontinuities in range data. To characterize the performance of least median of the squares, least trimmed squares, M-estimators, Hough transforms, RANSAC, and MINPRAN on this type of data, the ''pseudo outlier bias'' metric is developed using techniques from the robust statistics literature, and it is used to study the error in robust fits caused by distributions modeling various types of discontinuities. The results show each robust estimator to be biased at small, but substantial, discontinuities. They also show the circumstances under which different estimators are most effective. Most importantly, the results imply present estimators should be used with care, and new estimators should be developed.			Stewart, CV (corresponding author), RENSSELAER POLYTECH INST, DEPT COMP SCI, TROY, NY 12180 USA.							AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P987, DOI 10.1109/34.329010; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gaskill J.D., 1978, LINEAR SYSTEMS FOURI; HAMPEL FR, 1981, J AM STAT ASSOC, V76, P643, DOI 10.2307/2287524; Hampel FR., 2011, WILEY SERIES PROBABI; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; LEE KM, IN PRESS IEEE T PATT; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; MIRZA MJ, 1993, IEEE T ROBOTIC AUTOM, V9, P75, DOI 10.1109/70.210797; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; STEWART CV, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P969, DOI 10.1109/ICCV.1995.466829; STEWART CV, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P167, DOI 10.1109/CVPR.1994.323825; STEWART CV, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P1, DOI 10.1109/CVPR.1994.323951; STEWART CV, 1996, 964 DEP COMP SCI REN; Titterington DM, 1985, STAT ANAL FINITE MIX; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105	29	77	79	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					818	833		10.1109/34.608280	http://dx.doi.org/10.1109/34.608280			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700002
J	KRISHNAMOORTHY, M; NAGY, G; SETH, S; VISWANATHAN, M				KRISHNAMOORTHY, M; NAGY, G; SETH, S; VISWANATHAN, M			SYNTACTIC SEGMENTATION AND LABELING OF DIGITIZED PAGES FROM TECHNICAL JOURNALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								Alternating horizontal and vertical projection profiles are extracted from nested sub-blocks of scanned page images of technical documents. The thresholded profile strings are parsed using the compiler utilities Lex and Yacc. The significant document components are demarcated and identified by the recursive application of block grammars. Backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs. Results of the segmentation and labeling process are stored in a labeled X-Y tree. It is shown that families of technical documents that share the same layout conventions can be readily analyzed. More than 20 types of document entities can be identified in sample pages from the IBM Journal of Research and Development and IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE. Potential applications include preprocessors for optical character recognition, document archival, and digital reprographics.	IBM CORP,PENNANT SYST,BOULDER,CO 80301; UNIV NEBRASKA,DEPT ELECT COMP & SYST ENGN,LINCOLN,NE 68588	International Business Machines (IBM); University of Nebraska System; University of Nebraska Lincoln	KRISHNAMOORTHY, M (corresponding author), RENSSELAER POLYTECH INST,DEPT COMP SCI,TROY,NY 12180, USA.		SETH, SHARAD/F-9880-2010	Nagy, George/0000-0002-0521-1443				[Anonymous], STRUCTURED DOCUMENT; ASCHER RN, 1971, IEEE T COMPUT, VC 20, P1527, DOI 10.1109/T-C.1971.223166; BACKER E, 1992, SEP P INT C PATT REC; BAIRD HS, 1992, STRUCTURED IMAGE ANA; BAIRD HS, 1987, 40TH P SPSE C S HYBR, P21; DAMATO DP, 1992, P SPIE INT SOC OPT E, V1661; DENGEL A, 1989, 11TH P IJCAI DETR, P1249; JENKINS F, 1992, KEYWORD INDEXED BIBL; JOHNSON SC, 1975, 32 BELL LAB COMP SCI; KANAI J, 1990, JUN IAPR WORKSH STRU, P182; Kasturi R., 1992, Machine Vision and Applications, V5, P231, DOI 10.1007/BF02627001; KASTURI R, 1992, MACHINE VISION APPLI, V5; KLARNER DA, 1988, EUR J COMBIN, V9, P317, DOI 10.1016/S0195-6698(88)80062-3; Lesk M.E., 1975, 39 BELL LAB COMP SCI; LIEBOWITZ S, 1992, MAR P S DOC AN INF R, P58; LORETTE G, 1991, 1ST P INT C DOC AN R; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; Nagy G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P347; Nagy G., 1990, Proceedings of the 5th International Conference on Image Analysis and Processing. Progress in Image Analysis and Processing, P511; NAGY G, 1992, STRUCTURAL IMAGE ANA, P54; NAGY G, 1986, PATTERN RECOGNITION, V2; NAGY G, 1991, 1ST P INT C DOC AN R, P141; NAGY G, 1988, DOCPROCS 98, P169, DOI DOI 10.1145/62506.62539; NARTKER TA, 1992, MAR P S DOC AN INF R; OGORMAN L, 1992, COMPUTER, V25; PAVLIDIS T, 1992, P IEEE, V80; Rice S. V., 1992, REPORT ACCURACY OCR; TANAKA E, 1992, MEMO GRADUATE SCH A, V10, P111; VISWANATHAN M, 1992, P SOC PHOTO-OPT INS, V1661, P6, DOI 10.1117/12.130269; VISWANATHAN M, 1990, THESIS RENSSELAER PO; VISWANATHAN M, 1989, STRUCTURAL PATTERN A, P197; YU J, 1986, THESIS RENSSELAER PO	32	77	91	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					737	747		10.1109/34.221173	http://dx.doi.org/10.1109/34.221173			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185		Green Submitted			2022-12-18	WOS:A1993LM18500007
J	WAXMAN, AM; DUNCAN, JH				WAXMAN, AM; DUNCAN, JH			BINOCULAR IMAGE FLOWS - STEPS TOWARD STEREO MOTION FUSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									FLOW RES CO,SILVER SPRING,MD 20910		WAXMAN, AM (corresponding author), BOSTON UNIV,DEPT ELECT COMP & SYST ENGN,BOSTON,MA 02215, USA.		Duncan, James H/FVY-7148-2022	Duncan, James H/0000-0003-3740-9881				ADIV G, 1984, OCT P DARPA IM UND W, P113; BURT P, 1980, SCIENCE, V208, P615, DOI 10.1126/science.7367885; BUXTON BF, 1984, P EUROPEAN C ARTIFIC; EASTMAN R, 1985, 145 U MAR CTR AUT RE; EASTMAN R, 1986, CVGIP; GRIMSON WEL, 1981, IMAGES SURFACES; JENKIN MRM, 1984, RBCVTR843 U TOR DEP; KOENDERINK JJ, 1976, BIOL CYBERN, V21, P29, DOI 10.1007/BF00326670; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Marr D., 1982, VISION; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; POGGIO GF, 1984, ANNU REV NEUROSCI, V7, P379, DOI 10.1146/annurev.ne.07.030184.002115; POLLARD SB, 1986, PERCEPTION; POLLARD SB, 1985, DISPARITY GRADIENTS; PRAZDNY K, 1985, BIOL CYBERN, V52, P93, DOI 10.1007/BF00363999; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; PRAZDNY K, 1984, DETECTION BINOCULAR; REGAN D, 1979, VISION RES, V19, P1331, DOI 10.1016/0042-6989(79)90205-0; RICHARDS W, 1985, J OPT SOC AM A, V2, P343, DOI 10.1364/JOSAA.2.000343; RICHARDS W, 1983, MIT AI731 ART INT LA; SUBBARAO M, 1985, 3RD WORKSH COMP VIS, P129; SUBBARAO M, 1985, 113 U MAR CTR AUT RE; TSAI RY, 1981, R922 U ILL COORD SCI; TSAI RY, 1981, R921 U ILL COORD SCI; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, 1983, MIT721 ART INT LAB M; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P406, DOI 10.1109/TPAMI.1986.4767806; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1984, OCT P DARPA IM UND W, P130; WAXMAN AM, 1983, 24 U MAR CTR AUT RES; WAXMAN AM, 1986, IMAGE UNDERSTANDING; WAXMAN AM, 1984, 58 U MAR CTR AUT RES; WAXMAN AM, 1984, 2ND P IEEE WORKSH CO, P49; WOHN K, 1985, 134 U MAR CTR AUT RE; WOHN K, 1984, THESIS U MARYLAND CO; WOHN K, 1986, ANAL STRUCTURE IMAGE; WOHN K, 1986, INT J ROBOTICS RES	41	77	77	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1986	8	6					715	729		10.1109/TPAMI.1986.4767853	http://dx.doi.org/10.1109/TPAMI.1986.4767853			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	E4469	21869367				2022-12-18	WOS:A1986E446900003
J	Yu, HX; Wu, AC; Zheng, WS				Yu, Hong-Xing; Wu, Ancong; Zheng, Wei-Shi			Unsupervised Person Re-Identification by Deep Asymmetric Metric Embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Measurement; Cameras; Pattern matching; Distortion; Image color analysis; Feature extraction; Dictionaries; Unsupervised person re-identification; unsupervised metric learning; unsupervised deep learning; cross-view clustering; deep clustering		Person re-identification (Re-ID) aims to match identities across non-overlapping camera views. Researchers have proposed many supervised Re-ID models which require quantities of cross-view pairwise labelled data. This limits their scalabilities to many applications where a large amount of data from multiple disjoint camera views is available but unlabelled. Although some unsupervised Re-ID models have been proposed to address the scalability problem, they often suffer from the view-specific bias problem which is caused by dramatic variances across different camera views, e.g., different illumination, viewpoints and occlusion. The dramatic variances induce specific feature distortions in different camera views, which can be very disturbing in finding cross-view discriminative information for Re-ID in the unsupervised scenarios, since no label information is available to help alleviate the bias. We propose to explicitly address this problem by learning an unsupervised asymmetric distance metric based on cross-view clustering. The asymmetric distance metric allows specific feature transformations for each camera view to tackle the specific feature distortions. We then design a novel unsupervised loss function to embed the asymmetric metric into a deep neural network, and therefore develop a novel unsupervised deep framework named the DEep Clustering-based Asymmetric MEtric Learning (DECAMEL). In such a way, DECAMEL jointly learns the feature representation and the unsupervised asymmetric metric. DECAMEL learns a compact cross-view cluster structure of Re-ID data, and thus help alleviate the view-specific bias and facilitate mining the potential cross-view discriminative information for unsupervised Re-ID. Extensive experiments on seven benchmark datasets whose sizes span several orders show the effectiveness of our framework.	[Yu, Hong-Xing; Zheng, Wei-Shi] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China; [Yu, Hong-Xing] Guangdong Prov Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China; [Wu, Ancong] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510275, Peoples R China; [Wu, Ancong] NUDT, Collaborat Innovat Ctr High Performance Comp, Changsha, Hunan, Peoples R China; [Zheng, Wei-Shi] Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou 510006, Guangdong, Peoples R China	Sun Yat Sen University; Sun Yat Sen University; National University of Defense Technology - China	Zheng, WS (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China.	xKoven@gmail.com; wuancong@mail2.sysu.edu.cn; wszheng@ieee.org		Wu, Ancong/0000-0002-7969-3190	National Key Research and Development Program of China [2016YFB1001002]; NSFC [61522115, 61661130157, 61472456, U1611461]; Guangdong Province Science and Technology Innovation Leading Talents [2016TX03X157]; Royal Society Newton Advanced Fellowship [NA150459]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Guangdong Province Science and Technology Innovation Leading Talents; Royal Society Newton Advanced Fellowship	This work was supported partially by the National Key Research and Development Program of China (2016YFB1001002), NSFC(61522115, 61661130157, 61472456, U1611461), Guangdong Province Science and Technology Innovation Leading Talents (2016TX03X157), and the Royal Society Newton Advanced Fellowship (NA150459).	Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; An L, 2016, IEEE T CIRC SYST VID, V26, P776, DOI 10.1109/TCSVT.2015.2416561; [Anonymous], 2015, BRIT MACH VIS C; Arjovsky M, 2017, PR MACH LEARN RES, V70; Baltieri D., 2011, P 2011 JOINT ACMWORK, P59, DOI DOI 10.1145/2072572.2072590; Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001; Berthelot D., 2017, BEGAN BOUNDARY EQUIL; Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764; Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929; Chen YC, 2017, IEEE T CIRC SYST VID, V27, P1661, DOI 10.1109/TCSVT.2016.2515309; Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Cinbis RG, 2011, IEEE I CONF COMP VIS, P1559, DOI 10.1109/ICCV.2011.6126415; Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22; Ding C, 2005, SIAM PROC S, P606; Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Fujita T, 2014, PAC J MATH IND, V6, DOI 10.1186/s40736-014-0002-0; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Gray D., 2007, P IEEE INT WORKSH PE, V3, P1; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hartigan J.A., 1975, CLUSTERING ALGORITHM; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He R, 2018, IEEE T PATTERN ANAL; He ZY, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P11, DOI 10.1109/ISCSLP.2012.6423474; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang JY, 2011, IEEE I CONF COMP VIS, P794, DOI 10.1109/ICCV.2011.6126318; Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499; Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Lee Honglak, 2008, ADV NEURAL INFORM PR, V20; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055; Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39; Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762; Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717; Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146; Qin C, 2015, NEUROCOMPUTING, V168, P609, DOI 10.1016/j.neucom.2015.05.064; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366; Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30; Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426; Vapnik V.N, 1998, STAT LEARNING THEORY; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596; Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144; Wang H., 2014, P BRIT MACH VIS C; Wang HX, 2016, IEEE IMAGE PROC, P769, DOI 10.1109/ICIP.2016.7532461; Wang HX, 2016, LECT NOTES COMPUT SC, V9908, P405, DOI 10.1007/978-3-319-46493-0_25; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Wang Y, 2016, MABS-AUSTIN, V8, P1477, DOI 10.1080/19420862.2016.1226715; Wang Z, 2016, INT CONF SOFTW ENG, P369, DOI 10.1109/ICSESS.2016.7883088; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022; Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xie JY, 2016, PR MACH LEARN RES, V48; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556; Ye J., 2007, P IEEE C COMP VIS PA, P1, DOI [10.1109/CVPR.2007.383103, DOI 10.1109/CVPR.2007.383103]; Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16; Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113; Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng W.-S., 2009, BMVC, V2, P6; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405	91	76	80	2	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					956	973		10.1109/TPAMI.2018.2886878	http://dx.doi.org/10.1109/TPAMI.2018.2886878			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30571615	Green Submitted			2022-12-18	WOS:000526541100012
J	Tran, L; Yin, X; Liu, XM				Tran, Luan; Yin, Xi; Liu, Xiaoming			Representation Learning by Rotating Your Faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; Gallium nitride; Generators; Generative adversarial networks; Image generation; Image quality; Task analysis; Representation learning; generative adversarial network; pose-invariant face recognition; face rotation and frontalization	QUALITY MEASURES; RECOGNITION	The large pose discrepancy between two face images is one of the fundamental challenges in automatic face recognition. Conventional approaches to pose-invariant face recognition either perform face frontalization on, or learn a pose-invariant representation from, a non-frontal face image. We argue that it is more desirable to perform both tasks jointly to allow them to leverage each other. To this end, this paper proposes a Disentangled Representation learning-Generative Adversarial Network (DR-GAN) with three distinct novelties. First, the encoder-decoder structure of the generator enables DR-GAN to learn a representation that is both generative and discriminative, which can be used for face image synthesis and pose-invariant face recognition. Second, this representation is explicitly disentangled from other face variations such as pose, through the pose code provided to the decoder and pose estimation in the discriminator. Third, DR-GAN can take one or multiple images as the input, and generate one unified identity representation along with an arbitrary number of synthetic face images. Extensive quantitative and qualitative evaluation on a number of controlled and in-the-wild databases demonstrate the superiority of DR-GAN over the state of the art in both learning representations and rotating large-pose face images.	[Tran, Luan; Yin, Xi; Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Liu, XM (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	tranluan@msu.edu; yinxi1@msu.edu; liuxm@cse.msu.edu		liu, xiaoming/0000-0003-3215-8753				Abaza A, 2014, IET BIOMETRICS, V3, P314, DOI 10.1049/iet-bmt.2014.0022; Abdalmageed W., 2016, CORR, P1, DOI DOI 10.1109/WACV.2016.7477555; Abdel-Mottaleb M, 2007, IEEE COMPUT INTELL M, V2, P10, DOI 10.1109/MCI.2007.353416; Abiantun R, 2014, IEEE T PATTERN ANAL, V36, P2061, DOI 10.1109/TPAMI.2014.2313124; [Anonymous], 2016, P INT C MACH LEARN W; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Berthelot D., 2017, BEGAN BOUNDARY EQUIL; Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; Chen JC, 2016, IEEE WINT CONF APPL; Chen JC, 2016, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2016.7532906; Chen X, 2016, ADV NEUR IN, V29; Chen Y, 2006, LECT NOTES COMPUT SC, V3832, P373; Denton E, 2015, DEEP GENERATIVE IMAG, DOI DOI 10.5555/; Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089; Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347; Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243; Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434; Kingma D.P., 2015, ICLR, P1; Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Krichen E., 2007, P 1 IEEE INT C BIOM, P1; Kulkarni TD, 2015, ADV NEUR IN, V28; Kwak H., 2016, P C NEUR INF PROC SY; Li SX, 2012, LECT NOTES COMPUT SC, V7572, P102, DOI 10.1007/978-3-642-33718-5_8; Liu F, 2016, LECT NOTES COMPUT SC, V9909, P545, DOI 10.1007/978-3-319-46454-1_33; Liu X, 2006, INT GEOSCI REMOTE SE, P1431, DOI 10.1109/IGARSS.2006.369; Liu XM, 2005, PROC CVPR IEEE, P502; Makhzani A., 2015, P INT C LEARN REPR W; Marchionatti R, 2007, ROUTL STUD HIST ECON, P1; Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Matovski DS, 2012, INT C PATT RECOG, P3272; Mirza M., 2014, ARXIV PREPRINT ARXIV; Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577; Odena A, 2017, PR MACH LEARN RES, V70; Ozay Necmiye, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P134, DOI 10.1109/CVPR.2009.5204299; Radford A., 2016, P INT C LEARN REPR; Reed S, 2016, PR MACH LEARN RES, V48; Roth J, 2017, IEEE T PATTERN ANAL, V39, P2127, DOI 10.1109/TPAMI.2016.2636829; Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441; Salimans T., 2016, ADV NEUR IN, P2234; Sankaranarayanan S., 2016, P IEEE INT C BIOMETR, P1; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Tabassi E., 2005, IM PROC 2005 ICIP 20; Taha ZQ, 2006, IEEE ICC, P1071; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Teixeira RFS, 2017, IEEE T PATTERN ANAL, V39, P1905, DOI 10.1109/TPAMI.2016.2631529; Tong Yan, 2010, IEEE COMP SOC C COMP, P53; Tran L., 2018, P IEEE C COMP VIS PA; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166; Wei DM, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278040; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Yang Jimei, 2015, NIPS; Yi D, 2014, ARXIV PREPRINT ARXIV; Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667; Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430; Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830; Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20; Zhang YZ, 2013, IEEE I CONF COMP VIS, P2416, DOI 10.1109/ICCV.2013.300; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679; Zhu Z., 2014, NIPS, P217; Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21	74	76	78	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					3007	3021		10.1109/TPAMI.2018.2868350	http://dx.doi.org/10.1109/TPAMI.2018.2868350			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30183620	Green Submitted			2022-12-18	WOS:000498677600016
J	Shang, FH; Cheng, J; Liu, YY; Luo, ZQ; Lin, ZC				Shang, Fanhua; Cheng, James; Liu, Yuanyuan; Luo, Zhi-Quan; Lin, Zhouchen			Bilinear Factor Matrix Norm Minimization for Robust PCA: Algorithms and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust principal component analysis; rank minimization; Schatten-p quasi-norm; l(p)-norm; double nuclear norm penalty; Frobenius/nuclear norm penalty; alternating direction method of multipliers (ADMM)	LOW-RANK; VARIABLE SELECTION; LEAST-SQUARES; SUBSPACE; NONCONVEX; COMPLETION; REGULARIZATION; FACTORIZATION; RECOGNITION; RECOVERY	The heavy-tailed distributions of corrupted outliers and singular values of all channels in low-level vision have proven effective priors for many applications such as background modeling, photometric stereo and image alignment. And they can be well modeled by a hyper-Laplacian. However, the use of such distributions generally leads to challenging non-convex, non-smooth and non-Lipschitz problems, and makes existing algorithms very slow for large-scale applications. Together with the analytic solutions to 'p-norm minimization with two specific values of p, i.e., p = 1/2 and p = 2/3, we propose two novel bilinear factor matrix norm minimization models for robust principal component analysis. We first define the double nuclear norm and Frobenius/nuclear hybrid norm penalties, and then prove that they are in essence the Schatten-1/2 and 2/3 quasi-norms, respectively, which lead to much more tractable and scalable Lipschitz optimization problems. Our experimental analysis shows that both our methods yield more accurate solutions than original Schatten quasi-norm minimization, even when the number of observations is very limited. Finally, we apply our penalties to various low-level vision problems, e.g., text removal, moving object detection, image alignment and inpainting, and show that our methods usually outperform the state-of-the-art methods.	[Shang, Fanhua; Cheng, James; Liu, Yuanyuan] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Luo, Zhi-Quan] Chinese Univ Hong Kong, Shenzhen Res Inst Big Data, Shenzhen, Peoples R China; [Luo, Zhi-Quan] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Lin, Zhouchen] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China	Chinese University of Hong Kong; Chinese University of Hong Kong, Shenzhen; University of Minnesota System; University of Minnesota Twin Cities; Peking University; Shanghai Jiao Tong University	Shang, FH; Liu, YY (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.	fhshang@cse.cuhk.edu.hk; jcheng@cse.cuhk.edu.hk; yyliu@cse.cuhk.edu.hk; luozq@cuhk.edu.cn; zlin@pku.edu.cn		Liu, Yuanyuan/0000-0001-8646-8533	Hong Kong RGC [CUHK 14206715, 14222816]; ITF - Research Committee of CUHK [6904079, 3132821]; National Science Foundation (NSF) [CCF-1526434]; National Natural Science Foundation of China [61571384, 61731018]; Leading Talents of Guang Dong Province program [00201510]; National Basic Research Program of China (973 Program) [2015CB352502]; National Natural Science Foundation (NSF) of China [61731018, 61625301, 61231002]; Qualcomm	Hong Kong RGC(Hong Kong Research Grants Council); ITF - Research Committee of CUHK; National Science Foundation (NSF)(National Science Foundation (NSF)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Leading Talents of Guang Dong Province program; National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); Qualcomm	Fanhua Shang, James Cheng and Yuanyuan Liu were supported in part by Grants (CUHK 14206715 & 14222816) from the Hong Kong RGC, ITF 6904079, Grant 3132821 funded by the Research Committee of CUHK. Zhi-Quan Luo was supported in part by the National Science Foundation (NSF) under Grant CCF-1526434, the National Natural Science Foundation of China under Grants 61571384 and 61731018, and the Leading Talents of Guang Dong Province program, Grant No. 00201510. Zhouchen Lin was supported by National Basic Research Program of China (973 Program) (grant no. 2015CB352502), National Natural Science Foundation (NSF) of China (grant nos. 61625301, 61731018, and 61231002), and Qualcomm. Fanhua Shang and Yuanyuan Liu are the corresponding authors.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bian W, 2015, MATH PROGRAM, V149, P301, DOI 10.1007/s10107-014-0753-5; Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Cai JF, 2013, METHODS APPL ANAL, V20, P335, DOI 10.4310/MAA.2013.v20.n4.a2; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cao WF, 2013, J VIS COMMUN IMAGE R, V24, P31, DOI 10.1016/j.jvcir.2012.10.006; Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793; Chen CH, 2016, MATH PROGRAM, V155, P57, DOI 10.1007/s10107-014-0826-5; Chen Y., 2011, PROC 28 INT C MACHIN, P873; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding ZM, 2015, IEEE T IMAGE PROCESS, V24, P4322, DOI 10.1109/TIP.2015.2462023; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Golub G., 2013, MATRIX COMPUTATIONS; Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Gu ZH, 2012, INT C PATT RECOG, P1213; Hong MY, 2016, SIAM J OPTIMIZ, V26, P337, DOI 10.1137/140990309; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Jiang FY, 2015, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2015.7298870; Jin KH, 2015, IEEE T IMAGE PROCESS, V24, P3498, DOI 10.1109/TIP.2015.2446943; Ke QF, 2005, PROC CVPR IEEE, P739; Keshavan RH, 2009, ANN ALLERTON CONF, P1216, DOI 10.1109/ALLERTON.2009.5394534; Kim E, 2015, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2015.7298693; Krishnan D., 2009, ADV NEURAL INFORM PR, V22, P1033; Lai MJ, 2013, SIAM J NUMER ANAL, V51, P927, DOI 10.1137/110840364; Larsen R., 2005, PROPACK SOFTWARE LAR; Lin Z., 2009, UILUENG092215 DC247; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2012, NEURAL COMPUT, V24, P3371, DOI 10.1162/NECO_a_00369; Liu YY, 2013, PATTERN RECOGN, V46, P163, DOI 10.1016/j.patcog.2012.07.003; Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526; Lu CY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380155; Luo L, 2015, PATTERN RECOGN, V48, P3811, DOI 10.1016/j.patcog.2015.06.012; Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mazumder R, 2010, J MACH LEARN RES, V11, P2287; MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331; Nie FP, 2012, IEEE DATA MINING, P566, DOI 10.1109/ICDM.2012.160; Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956; Oh TH, 2015, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR.2015.7299078; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Shahid N, 2015, IEEE I CONF COMP VIS, P2812, DOI 10.1109/ICCV.2015.322; Shang F., 2014, P 23 ACM INT C C INF, P1149, DOI DOI 10.1145/2661829.2662083; Shang FH, 2016, AAAI CONF ARTIF INTE, P2016; Shang FH, 2016, JMLR WORKSH CONF PRO, V51, P620; Shang FH, 2015, INFORM SCIENCES, V307, P53, DOI 10.1016/j.ins.2015.02.026; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Shenlong Wang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P231, DOI 10.1007/978-3-642-37431-9_18; Shu XB, 2014, PROC CVPR IEEE, P3874, DOI 10.1109/CVPR.2014.495; Srebro Nathan, 2004, ADV NEURAL INFORM PR, V17, P1329; Sun RY, 2016, IEEE T INFORM THEORY, V62, P6535, DOI 10.1109/TIT.2016.2598574; Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894; Toh KC, 2010, PAC J OPTIM, V6, P615; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; von Neumann J., 1937, TOMSK U REV, V1, P286; Wright J, 2013, INF INFERENCE, V2, P32, DOI 10.1093/imaiai/iat002; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; XIAO SJ, 2015, PROC CVPR IEEE, P4612; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156; Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412; Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170; Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235; Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhang HY, 2015, AAAI CONF ARTIF INTE, P3143; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828; Zhou T., 2011, P 28 INT C MACH LEAR, P33; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132; Zuo WM, 2013, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2013.34	82	76	79	7	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2066	2080		10.1109/TPAMI.2017.2748590	http://dx.doi.org/10.1109/TPAMI.2017.2748590			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28880159	hybrid, Green Submitted			2022-12-18	WOS:000440868400003
J	Biswas, S; Aggarwal, G; Flynn, PJ; Bowyer, KW				Biswas, Soma; Aggarwal, Gaurav; Flynn, Patrick J.; Bowyer, Kevin W.			Pose-Robust Recognition of Low-Resolution Face Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; low-resolution matching; multidimensional scaling; iterative majorization	SUPERRESOLUTION	Face images captured by surveillance cameras usually have poor resolution in addition to uncontrolled poses and illumination conditions, all of which adversely affect the performance of face matching algorithms. In this paper, we develop a completely automatic, novel approach for matching surveillance quality facial images to high-resolution images in frontal pose, which are often available during enrollment. The proposed approach uses multidimensional scaling to simultaneously transform the features from the poor quality probe images and the high-quality gallery images in such a manner that the distances between them approximate the distances had the probe images been captured in the same conditions as the gallery images. Tensor analysis is used for facial landmark localization in the low-resolution uncontrolled probe images for computing the features. Thorough evaluation on the Multi-PIE dataset [1] and comparisons with state-of-the-art super-resolution and classifier-based approaches are performed to illustrate the usefulness of the proposed approach. Experiments on surveillance imagery further signify the applicability of the framework. We also show the usefulness of the proposed approach for the application of tracking and recognition in surveillance videos.	[Biswas, Soma; Aggarwal, Gaurav; Flynn, Patrick J.; Bowyer, Kevin W.] Univ Notre Dame, Dept Comp Sci & Engn, Comp Vis Res Lab, Notre Dame, IN 46556 USA	University of Notre Dame	Biswas, S (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Comp Vis Res Lab, Notre Dame, IN 46556 USA.	sbiswas@nd.edu; gaggarwa@nd.edu; flynn@nd.edu; kwb@nd.edu		Bowyer, Kevin/0000-0002-7562-4390	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL)	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL)	This research was funded by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL). The views and conclusions contained in this document are those of the authors and should not be interpreted as representing official policies, either expressed or implied, of IARPA, the ODNI, the Army Research Laboratory, or the US Government. The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alex M, 2002, LECT NOTES COMPUT SC, V2350, P447; [Anonymous], P 4 IEEE INT C AUT F; Arandjelovic O., 2007, P IEEE INT C COMP VI; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Biswas S., 2011, P INT JOINT C BIOM; Biswas S., 2011, P IEEE C COMP VIS PA; Biswas S., 2010, P IEEE INT C BIOM TH; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346; Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043; Dreuw P., 2009, P BRIT MACH VIS C, P71; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Gross  R., 2007, TR0708 CMU ROB I; Guillaumin M., 2009, P IEEE INT C COMP VI; Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513; Hennings-Yeomans P.H., 2008, 2008 IEEE C COMP VIS, P1; Hennings-Yeomans PH, 2009, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2009.5413920; Hwang W, 2011, COMP VIS PATT REC WO, P15; Jia K, 2005, IEEE I CONF COMP VIS, P1683; Kanade T, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P954; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu W, 2005, PROC CVPR IEEE, P478; Marciniak T, 2012, COMM COM INF SC, V287, P220; Milborrow S., 2008, P EUR C COMP VIS; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; Nishiyama M, 2009, PROC CVPR IEEE, P1115, DOI 10.1109/CVPRW.2009.5206750; Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72; Phillips PJ, 2005, PROC CVPR IEEE, P947; Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48; Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WEBB AR, 1995, PATTERN RECOGN, V28, P753, DOI 10.1016/0031-3203(94)00135-9; Weinberger KQ, 2008, P 25 INT C MACH LEAR, P1160, DOI DOI 10.1145/1390156.1390302; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8	40	76	83	0	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					3037	3049		10.1109/TPAMI.2013.68	http://dx.doi.org/10.1109/TPAMI.2013.68			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136439				2022-12-18	WOS:000326502200018
J	Cashman, TJ; Fitzgibbon, AW				Cashman, Thomas J.; Fitzgibbon, Andrew W.			What Shape Are Dolphins? Building 3D Morphable Models from 2D Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Morphable model; shape from silhouette; subdivision surfaces; image-based modeling; single-view reconstruction	MOTION	3D morphable models are low-dimensional parameterizations of 3D object classes which provide a powerful means of associating 3D geometry to 2D images. However, morphable models are currently generated from 3D scans, so for general object classes such as animals they are economically and practically infeasible. We show that, given a small amount of user interaction (little more than that required to build a conventional morphable model), there is enough information in a collection of 2D pictures of certain object classes to generate a full 3D morphable model, even in the absence of surface texture. The key restriction is that the object class should not be strongly articulated, and that a very rough rigid model should be provided as an initial estimate of the "mean shape." The model representation is a linear combination of subdivision surfaces, which we fit to image silhouettes and any identifiable key points using a novel combined continuous-discrete optimization strategy. Results are demonstrated on several natural object classes, and show that models of rather high quality can be obtained from this limited information.	[Cashman, Thomas J.] Univ Lugano, Fac Informat, CH-6904 Lugano, Switzerland; [Fitzgibbon, Andrew W.] Microsoft Res Ltd, Cambridge CB3 0FB, England	Universita della Svizzera Italiana; Microsoft	Cashman, TJ (corresponding author), Univ Lugano, Fac Informat, Via Giuseppe Buffi 13, CH-6904 Lugano, Switzerland.	thomas.cashman@usi.ch; awf@microsoft.com		Cashman, Tom/0000-0001-7975-8567	SNF [200021-134639]	SNF	This work was partially supported by the SNF under project number 200021-134639. We thank the following copyright holders for permission to reproduce their photographs in this paper: Tim Nicholson for all dolphins except the leftmost and rightmost images in Fig. 1; Peter Asprey<SUP>1</SUP> for the leftmost image in Fig. 1; Arnaud Clerget for the rightmost image in Fig. 1; Helen White for all photographs of pigeons; Colin Burnett for Fig. 14 (left)<SUP>2</SUP>; Trisha Shears for Fig. 14 (middle); Pcb21 for Fig. 14 (right)<SUP>2</SUP>.	Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; [Anonymous], 2004, P OPTICAL SENSING; Appleton B, 2003, PATTERN RECOGN, V36, P2513, DOI 10.1016/S0031-3203(03)00122-5; BALAN AO, 2008, P EUR C COMP VIS 2, V5303, P15; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Chen Y, 2010, LECT NOTES COMPUT SC, V6313, P300; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; Furukawa Y, 2006, IEEE T PATTERN ANAL, V28, P302, DOI 10.1109/TPAMI.2006.41; Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1618494, 10.1145/1618452.1616494]; Grassia F.S., 1998, J GRAPH TOOLS, V3, P29, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]; Gu XF, 2002, ACM T GRAPHIC, V21, P355; Halstead M., 1993, Computer Graphics Proceedings, P35, DOI 10.1145/166117.166121; Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233; Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602; Ilic S, 2007, INT J COMPUT VISION, V72, P159, DOI 10.1007/s11263-006-8595-0; Karpenko OA, 2006, ACM T GRAPHIC, V25, P589, DOI 10.1145/1141911.1141928; Kobbelt L, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P43; KRAEVOY V., 2009, P 6 EUR S SKETCH BAS, P37, DOI DOI 10.1145/1572741.1572749]; Loop C., 1987, SMOOTH SUBDIVISION S; McIlroy P., 2009, P BRIT MACH VIS C, P1; Nealen A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239492, 10.1145/1276377.1276429]; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; PRASAD M, 2006, P IND C COMP VIS GRA; Prasad M., 2010, P IEEE C COMP VIS PA; Prasad M., 2006, P IEEE C COMP VIS PA; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Stam J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P395, DOI 10.1145/280814.280945; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tosun E., 2008, THESIS NEW YORK U; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863; Zorin D., 2006, P 4 EUR S GEOM PROC, P31	39	76	84	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					232	244		10.1109/TPAMI.2012.68	http://dx.doi.org/10.1109/TPAMI.2012.68			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22392707				2022-12-18	WOS:000311127700020
J	Kim, SJ; Lin, HT; Lu, Z; Susstrunk, S; Lin, S; Brown, MS				Kim, Seon Joo; Lin, Hai Ting; Lu, Zheng; Suesstrunk, Sabine; Lin, Stephen; Brown, Michael S.			A New In-Camera Imaging Model for Color Computer Vision and Its Application	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Radiometric calibration; in-camera image processing; gamut mapping; white balance	RADIOMETRIC CALIBRATION; ALGORITHM	We present a study of in-camera image processing through an extensive analysis of more than 10,000 images from over 30 cameras. The goal of this work is to investigate if image values can be transformed to physically meaningful values, and if so, when and how this can be done. From our analysis, we found a major limitation of the imaging model employed in conventional radiometric calibration methods and propose a new in-camera imaging model that fits well with today's cameras. With the new model, we present associated calibration procedures that allow us to convert sRGB images back to their original CCD RAW responses in a manner that is significantly more accurate than any existing methods. Additionally, we show how this new imaging model can be used to build an image correction application that converts an sRGB input image captured with the wrong camera settings to an sRGB output image that would have been recorded under the correct settings of a specific camera.	[Kim, Seon Joo] SUNY Korea, Inchon 406840, South Korea; [Lin, Hai Ting; Lu, Zheng; Brown, Michael S.] Natl Univ Singapore, Sch Comp, Singapore 117416, Singapore; [Suesstrunk, Sabine] Ecole Polytech Fed Lausanne, IC, IVRG, CH-1015 Lausanne, Switzerland; [Lin, Stephen] Microsoft Res Asia, Beijing 100080, Peoples R China	National University of Singapore; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Microsoft; Microsoft Research Asia	Kim, SJ (corresponding author), SUNY Korea, 187 Songdo Dong, Inchon 406840, South Korea.	seonjookim@sunykorea.ac.kr; linhait@comp.nus.edu.sg; luzheng@comp.nus.edu.sg; sabine.susstrunk@epfl.ch; stevelin@microsoft.com; brown@comp.nus.edu.sg	Lu, Zheng/B-1537-2009; Süsstrunk, Sabine/I-2466-2013	Lu, Zheng/0000-0003-4098-2486; LU, Zheng/0000-0002-7799-1776	NUS Young Investigator Award [R-252-000-379-101]	NUS Young Investigator Award	This work was supported in part by the NUS Young Investigator Award, R-252-000-379-101.	Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Buhmann MD:, 2003, CAMBRIDGE MONOGRAPHS, V12)., DOI 10.1017/CBO9780511543241; Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266; Chakrabarti A., 2009, P BRIT MACHINE VISIO; Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933; Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884; Finlayson G, 2000, IEEE T IMAGE PROCESS, V9, P1774, DOI 10.1109/83.869188; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Gijsenij A., 2007, CVPR, P1; GREENGARD L, 1987, J COMPUT PHYS, V73, P325, DOI 10.1016/0021-9991(87)90140-9; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; Haber T., 2008, P IEEE C COMP VIS PA, P1; Hiscocks P. D., 2010, MEASURING CAMERA SHU; Holm J., 2002, COLOUR ENG ACHIEVING, P79; *ISO, 2004, 2202812004 ISO; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Kuthirummal S, 2008, LECT NOTES COMPUT SC, V5305, P74, DOI 10.1007/978-3-540-88693-8_6; Lalonde JF, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618477; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Lin H., 2011, P IEEE INT C COMPUTE; Lin S, 2005, PROC CVPR IEEE, P66; Lin S, 2004, PROC CVPR IEEE, P938; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Morovic J, 2001, J IMAGING SCI TECHN, V45, P283; Pal C, 2004, PROC CVPR IEEE, P173; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; Shapira L, 2009, COMPUT GRAPH FORUM, V28, P629, DOI 10.1111/j.1467-8659.2009.01403.x; Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172	33	76	80	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2289	2302		10.1109/TPAMI.2012.58	http://dx.doi.org/10.1109/TPAMI.2012.58			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22371428	Green Published			2022-12-18	WOS:000309913700001
J	Salzmann, M; Fua, P				Salzmann, Mathieu; Fua, Pascal			Linear Local Models for Monocular Reconstruction of Deformable Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deformable surfaces; monocular shape recovery; deformation models	MOTION; SHAPE	Recovering the 3D shape of a nonrigid surface from a single viewpoint is known to be both ambiguous and challenging. Resolving the ambiguities typically requires prior knowledge about the most likely deformations that the surface may undergo. It often takes the form of a global deformation model that can be learned from training data. While effective, this approach suffers from the fact that a new model must be learned for each new surface, which means acquiring new training data, and may be impractical. In this paper, we replace the global models by linear local models for surface patches, which can be assembled to represent arbitrary surface shapes as long as they are made of the same material. Not only do they eliminate the need to retrain the model for different surface shapes, they also let us formulate 3D shape reconstruction from correspondences as either an algebraic problem that can be solved in closed form or a convex optimization problem whose solution can be found using standard numerical packages. We present quantitative results on synthetic data, as well as qualitative results on real images.	[Salzmann, Mathieu] Toyota Technol Inst, Chicago, IL 60637 USA; [Fua, Pascal] Ecole Polytech Fed EPFL, Sch Comp & Commun Sci, CVLab, IC CVLab,Stn 14, CH-1015 Lausanne, Switzerland	Toyota Technological Institute - Chicago; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Salzmann, M (corresponding author), Toyota Technol Inst, Chicago, IL 60637 USA.	mathieu.salzmann@a3.epfl.ch; pascal.fua@epfl.ch	Fua, Pascal/H-3928-2011	Fua, Pascal/0000-0002-6702-9970; Salzmann, Mathieu/0000-0002-8347-8637	Swiss National Science Foundation	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work was supported in part by the Swiss National Science Foundation.	AANAES H, 2002, P IEEE INT C COMP VI; [Anonymous], 1987, ACM SIGGRAPH COMPUTE, DOI [10.1145/37402.37427, DOI 10.1145/37402.37427]; BARTOLI A, 2005, P IEEE INT C COMP VI; BHAT KS, 2003, P ACM S COMP AN; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Boyd S, 2004, CONVEX OPTIMIZATION; BRAND M, 2001, P IEEE CS C COMP VIS; BREGLER C, 2000, P IEEE CS C COMP VIS; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; ECKER A, 2008, P EUR C COMP VISI OC; Gumerov N.A., 2004, P EUR C COMP VIS MAY; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; Lawrence N. D., 2004, NEURAL INFORM PROCES; Liang J, 2005, PROC CVPR IEEE, P338; LLADO X, 2005, P BRIT MACH VIS C SE; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; McInerney T., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P518, DOI 10.1109/ICCV.1993.378169; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; MORENONOGUER F, 2007, P 11 IEEE INT C COMP; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PERRIOLLAT M, 2007, P TOW BENCHM AUT CAL; Perriollat M., 2008, P BRIT MACH VIS C; Salzmann M., 2008, P IEEE C COMP VIS PA; Salzmann M., 2007, P IEEE C COMP VIS PA; SALZMANN M, 2009, P IEEE C COMP VIS PA; SALZMANN M, 2008, P EUR C COMP VIS; Salzmann M, 2007, IEEE T PATTERN ANAL, V29, P1481, DOI 10.1109/TPAMI.2007.1080; STURM JF, 1999, USING SEDUMI 102 MAT; Taylor J., 2010, P IEEE C COMP VIS PA; TORRESANI L, 2003, ADV NEURAL INFORM PR; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007; URTASUN R, 2005, P 10 IEEE INT C COMP; VAROL A, 2009, P IEEE INT C COMP VI; VIDAL R, 2008, P EUR C COMP VIS OCT; XIAO J, 2005, P 10 IEEE INT C COMP	39	76	76	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					931	944		10.1109/TPAMI.2010.158	http://dx.doi.org/10.1109/TPAMI.2010.158			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20733216	Green Submitted			2022-12-18	WOS:000288677800006
J	Dalitz, C; Droettboom, M; Pranzas, B; Fujinaga, I				Dalitz, Christoph; Droettboom, Michael; Pranzas, Bastian; Fujinaga, Ichiro			A comparative study of staff removal algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document page segmentation; OMR; performance evaluation; performance metric; pixel classification	PERFORMANCE EVALUATION; MUSIC; METHODOLOGY	This paper presents a quantitative comparison of different algorithms for the removal of stafflines from music images. It contains a survey of previously proposed algorithms and suggests a new skeletonization-based approach. We define three different error metrics, compare the algorithms with respect to these metrics, and measure their robustness with respect to certain image defects. Our test images are computer-generated scores on which we apply various image deformations typically found in real-world data. In addition to modern western music notation, our test set also includes historic music notation such as mensural notation and lute tablature. Our general approach and evaluation methodology is not specific to staff removal but applicable to other segmentation problems as well.	[Dalitz, Christoph; Pranzas, Bastian] Hsch Niederrhein, Fachbereich Electrotechn & Informat, D-47805 Krefeld, Germany; [Droettboom, Michael] Space Telescope Sci Inst, Baltimore, MD 21218 USA; [Fujinaga, Ichiro] McGill Univ, Schulich Sch Music, Montreal, PQ H3A 1E3, Canada	Space Telescope Science Institute; McGill University	Dalitz, C (corresponding author), Hsch Niederrhein, Fachbereich Electrotechn & Informat, Reinarzstr 49, D-47805 Krefeld, Germany.	christoph.dalitz@hs-niederrhein.de; com.mdroe@stsci.edu; ba.czerwinski@gmail.com; ich@music.mcgill.ca	Fujinaga, Ichiro/Q-7220-2019	Dalitz, Christoph/0000-0002-7004-5584				Bainbridge D., 1997, P 6 INT C IM PROC IT, P756; Carter N., 1992, STRUCTURED DOCUMENT, P454; DALITZETAL C, 2005, STAFF LINE REMOVAL T; DROETTBOOM M, 2003, GAMERA PROJECT HOMEP; Fujisawa S, 2004, J LIPOSOME RES, V14, P39, DOI 10.1081/LPR-120039662; GALIL Z, 1986, COMPUT SURV, V18, P23, DOI 10.1145/6462.6502; HASTINGS WK, 1970, BIOMETRIKA, V57, P1; Ho T.K., 1995, P 4 ANN S DOC AN INF, P413; Kanai J, 1996, INT J IMAG SYST TECH, V7, P363, DOI 10.1002/(SICI)1098-1098(199624)7:4<363::AID-IMA11>3.0.CO;2-X; Kanungo T, 2000, IEEE T PATTERN ANAL, V22, P1209, DOI 10.1109/34.888707; Mao S, 2001, IEEE T PATTERN ANAL, V23, P242, DOI 10.1109/34.910877; MARTIN P, 1991, P 1 INT C DOC AN REC, P417; MCPHERSON JR, 2002, P 3 INT C MUS INF RE, P259; Miyao H., 2004, J ADV COMPUTATIONAL, V8, P208, DOI DOI 10.20965/JACIII.2004.P0208; Ng K, 2002, LECT NOTES COMPUT SC, V2390, P330; Prerau D, 1992, STRUCTURED DOCUMENT, P405; Pugin L., 2006, ISMIR, P53; Randriamahefa R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P898, DOI 10.1109/ICDAR.1993.395592; ROACH JW, 1988, PATTERN RECOGN, V21, P33, DOI 10.1016/0031-3203(88)90069-6; Stuckelberg M. V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P115, DOI 10.1109/ICDAR.1999.791738; Szwoch M, 2005, LECT NOTES COMPUT SC, V3691, P701; TANG YY, 1995, IEEE T SYST MAN CYB, V25, P738, DOI 10.1109/21.376488; Thulke M, 1999, LECT NOTES COMPUT SC, V1655, P43	23	76	79	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					753	766		10.1109/TPAMI.2007.70749	http://dx.doi.org/10.1109/TPAMI.2007.70749			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369247				2022-12-18	WOS:000253879700001
J	Nenadic, Z				Nenadic, Zoran			Information discriminant analysis: Feature extraction with an information-theoretic objective	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction; information theory; mutual information; entropy; classification; linear discriminant analysis; Bayes error	DIMENSIONALITY REDUCTION; HADAMARD PRODUCT; SELECTION; LDA; ALGORITHM; ERROR	Using elementary information-theoretic tools, we develop a novel technique for linear transformation from the space of observations into a low-dimensional ( feature) subspace for the purpose of classification. The technique is based on a numerical optimization of an information-theoretic objective function, which can be computed analytically. The advantages of the proposed method over several other techniques are discussed and the conditions under which the method reduces to linear discriminant analysis are given. We show that the novel objective function enjoys many of the properties of the mutual information and the Bayes error and we give sufficient conditions for the method to be Bayes-optimal. Since the objective function is maximized numerically, we show how the calculations can be accelerated to yield feasible solutions. The performance of the method compares favorably to other linear discriminant-based feature extraction methods on a number of simulated and real-world data sets.	Univ Calif Irvine, Dept Biomed Engn, Irvine, CA 92697 USA; Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA	University of California System; University of California Irvine; University of California System; University of California Irvine	Nenadic, Z (corresponding author), Univ Calif Irvine, Dept Biomed Engn, 3120 Nat Sci 2, Irvine, CA 92697 USA.	znenadic@uci.edu	Nenadic, Zoran/A-9816-2008; Nenadic, Zoran/P-8772-2019					[Anonymous], 1999, NUMERICAL OPTIMIZATI; BALAKRISHNAN AV, 1987, KALMAN FILTERING THE; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Brookes M., 2005, MATRIX REFERENCE MAN; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; DECELL HP, 1972, P PURD C MACH PROC R; Devijver PA, 1982, PATTERN RECOGNITION; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; DWYER PS, 1967, J AM STAT ASSOC, V62, P607, DOI 10.2307/2283988; EFFRON B, 1983, J AM STAT ASS; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hettich S., 1998, UCI REPOSITORY MACHI; Horn R. A., 1986, MATRIX ANAL; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Hyvarinen A., 1999, Neural Computing Surveys, V2; JOHNSON CR, 1978, J RES NAT BUR STAND, V83, P585, DOI 10.6028/jres.083.039; Johnson D.H., 1993, ARRAY SIGNAL PROCESS; Jolliffe L.T, 1986, PRINCIPAL COMPONENT; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kittler J., 1978, Pattern Recognition and Signal Processing, P41; Kohavi R., 1995, IJCAI, P1137; Kumar N, 1998, SPEECH COMMUN, V26, P283, DOI 10.1016/S0167-6393(98)00061-2; LEWIS PM, 1962, IRE T INFORM THEOR, V8, P171, DOI 10.1109/TIT.1962.1057691; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; Padmanabhan M, 2005, IEEE T SPEECH AUDI P, V13, P512, DOI 10.1109/TSA.2005.848876; PRINCIPE JC, 2000, UNSUPERVISED ADAPTIV; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Renyi A., 1961, P 4 BERKELEY S MATH, V1; Rizzuto DS, 2005, NAT NEUROSCI, V8, P415, DOI 10.1038/nn1424; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saon G, 2001, ADV NEUR IN, V13, P800; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Torkkola K., 2003, Journal of Machine Learning Research, V3, P1415, DOI 10.1162/153244303322753742; Torkkola K, 2002, INT C PATT RECOG, P472, DOI 10.1109/ICPR.2002.1044765; Visick G, 2000, LINEAR ALGEBRA APPL, V304, P45, DOI 10.1016/S0024-3795(99)00187-1; Wang XG, 2004, PROC CVPR IEEE, P564; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	47	76	77	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1394	1407		10.1109/TPAMI.2007.1156	http://dx.doi.org/10.1109/TPAMI.2007.1156			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568143	Green Submitted			2022-12-18	WOS:000247186500008
J	Garcia-Pedrajas, N; Ortiz-Boyer, D				Garcia-Pedrajas, N; Ortiz-Boyer, D			Improving multiclass pattern recognition by the combination of two strategies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiclass; classification; one-vs-one; one-vs-all; neural networks; support vector machines	CLASSIFICATION	We present a new method of multiclass classification based on the combination of one- vs- all method and a modification of one- vs- one method. This combination of one- vs- all and one- vs- one methods proposed enforces the strength of both methods. A study of the behavior of the two methods identifies some of the sources of their failure. The performance of a classifier can be improved if the two methods are combined in one, in such a way that the main sources of their failure are partially avoided.	Univ Rabanales, Dept Comp & Numer Anal, Cordoba 14071, Spain	Universidad de Cordoba	Garcia-Pedrajas, N (corresponding author), Univ Rabanales, Dept Comp & Numer Anal, 3A Planta,Campus Univ Rabanales, Cordoba 14071, Spain.	npedrajas@uco.es; dortiz@uco.es	Domingo, Ortiz-Boyer/L-7286-2014; Garcia-Pedrajas, Nicolas E./H-6806-2015	Garcia-Pedrajas, Nicolas E./0000-0002-4488-6849; Ortiz-Boyer, Domingo/0000-0003-3966-283X				Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444; Clark P., 1991, P 5 EUR WORK SESS LE, P151, DOI [DOI 10.1007/BFB0017011, 10.1007/bfb0017011]; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263; Friedman J.H., 1996, ANOTHER APPROACH POL; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Hastie T, 1998, ANN STAT, V26, P451; Hettich S., 1998, UCI REPOSITORY MACHI; Knerr S., 1990, NEUROCOMPUTING, V68, DOI [10.1007/978-3-642-76153-9_5, DOI 10.1007/978-3-642-76153-9_5]; Kong EB, 1995, WHY ERROR CORRECTING; MOREIRA M, 1997, P 10 EUR C MACH LEAR; Platt JC, 2000, ADV NEUR IN, V12, P547; Rifkin R, 2004, J MACH LEARN RES, V5, P101; SCHAPIRE RE, 1997, P 14 INT C MACH LEAR, P313; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Windeatt T., 2003, Information Fusion, V4, P11, DOI 10.1016/S1566-2535(02)00101-X	17	76	77	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					1001	1006		10.1109/TPAMI.2006.123	http://dx.doi.org/10.1109/TPAMI.2006.123			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724593	Green Submitted			2022-12-18	WOS:000236734400013
J	Ahmed, M; Ward, R				Ahmed, M; Ward, R			A rotation invariant rule-based thinning algorithm for character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; thinning; skeletonization	SYSTEM; SPEED	This paper presents a novel rule-based system for thinning. The unique feature that distinguishes our thinning system is that it thins symbols to their central lines. This means that the shape of the symbol is preserved. It also means that the method is rotation invariant. The system has 20 rules in its inference engine. These rules are applied simultaneously to each pixel in the image. Therefore, the system has the advantages of symmetrical thinning and speed. The results show that the system is very efficient in preserving the topology of symbols and letters written in any language.	Wilfrid Laurier Univ, Phys & Comp Dept, Waterloo, ON N2L 3C5, Canada; Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada	Wilfrid Laurier University; University of British Columbia	Ahmed, M (corresponding author), Wilfrid Laurier Univ, Phys & Comp Dept, Waterloo, ON N2L 3C5, Canada.							Ahmed M, 2000, PATTERN RECOGN, V33, P1975, DOI 10.1016/S0031-3203(99)00191-0; Ahmed M, 1998, J ELECTRON IMAGING, V7, P111, DOI 10.1117/1.482632; AHMED M, 1999, P IEEE PAC RIM C COM, P197; ALTUWAIJRI M, 1995, P IEEE INT S CIRCUIT, V3, P1824; Amin A, 2000, INT J PATTERN RECOGN, V14, P369, DOI 10.1142/S0218001400000246; Arcelli C., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1077, DOI 10.1142/S0218001493000546; ARCELLI C, 1992, P IEEE INT C TENCON, V1, P66; Gonzalez R.C, 2002, DIGITAL IMAGE PROCES; HALL RW, 1989, COMMUN ACM, V32, P124, DOI 10.1145/63238.63248; Han N. H., 1997, P IEEE INT C DOC AN, V1, P137; He R, 2000, PATTERN RECOGN LETT, V21, P817, DOI 10.1016/S0167-8655(00)00039-8; HOLT CM, 1987, COMMUN ACM, V30, P156, DOI 10.1145/12527.12531; KIM YS, 1992, IEEE T CONSUM ELECTR, V38, P762, DOI 10.1109/30.179963; LAM L, 1995, IEEE T PATTERN ANAL, V17, P914, DOI 10.1109/34.406659; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LIN JY, 1995, PATTERN RECOGN, V28, P493, DOI 10.1016/0031-3203(94)00122-3; RAJU G, 1991, P IEEE INT C SYSTEMS, V3, P661; Suzuki T., 1994, THINNING METHODOLOGI; ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023; ZHANG YY, 1996, P 13 INT C PATT REC, V4, P457	20	76	85	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1672	1678		10.1109/TPAMI.2002.1114862	http://dx.doi.org/10.1109/TPAMI.2002.1114862			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA					2022-12-18	WOS:000179444600013
J	Senior, A				Senior, A			A combination fingerprint classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Henry fingerprint classification; hidden Markov models; decision trees; neural networks; NIST database	RECOGNITION SYSTEM; FEATURES	Fingerprint classification is an important indexing method for any large scale fingerprint recognition system or database as a method for reducing the number of fingerprints that need to be searched when looking for a matching print. Fingerprints are generally classified into broad categories based on global characteristics. This paper describes novel methods of classification using hidden Markov models (HMMs) and decision trees to recognize the ridge structure of the print, without needing to detect singular points. The methods are compared and combined with a standard fingerprint classification algorithm and results for the combination are presented using a standard database of fingerprint images. The paper also describes a method for achieving any level of accuracy required of the system by sacrificing the efficiency of the classifier. The accuracy of the combination classifier is shown to be higher than that of two state-of-the-art systems tested under the same conditions.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	International Business Machines (IBM)	Senior, A (corresponding author), IBM Corp, Thomas J Watson Res Ctr, POB 704, Yorktown Hts, NY 10598 USA.							AGAZZI O, 1993, P IEEE INT C AC SPEE, V5, P113; Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; BLUE JL, 1994, PATTERN RECOGN, V27, P485, DOI 10.1016/0031-3203(94)90031-0; Bolle R., 1999, US Patent, Patent No. [5,963,656, 5963656]; Candela G. T., 1995, PCASYSA PATTERN LEVE; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; *FED BUR INV, 1984, SCI FING CLASS US, P12; Fitz AP, 1996, PATTERN RECOGN, V29, P1587, DOI 10.1016/0031-3203(96)00018-0; Halici U, 1996, P IEEE, V84, P1497, DOI 10.1109/5.537114; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Kamei T, 1998, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.1998.698714; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; KAWAGOE M, 1984, PATTERN RECOGN, V17, P295, DOI 10.1016/0031-3203(84)90079-7; Lumini A, 1997, PATTERN RECOGN LETT, V18, P1027, DOI 10.1016/S0167-8655(97)00127-X; Maio D., 1996, P 13 INT C PATT REC, V3, P578, DOI DOI 10.1109/ICPR.1996.547013; MANDAL DP, 1992, IEEE T SYST MAN CYB, V22, P607, DOI 10.1109/21.156575; NATHAN KS, 1996, P IEEE INT C AC SPEE, V6, P3503; OHTERU S, 1974, P 2 INT C PATT REC C, P185; Olshen R., 1984, CLASSIFICATION REGRE; Pal SK, 1996, FUZZY SET SYST, V80, P121, DOI 10.1016/0165-0114(95)00192-1; Perrone M. P., 2000, P 7 INT WORKSH FRONT, P229; RABINOWICZ E, 1986, TRIBOLOGY MECHANICS, V3, P1; RAO CVK, 1980, IEEE T PATTERN ANAL, V2, P223; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; SENIOR A, 1997, P AS C SIGN SYST COM; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; WATSON C, 1992, NIST SPECIAL DATABAS, V4; WILS JA, 1993, EUR J CANCER, V29A, P203, DOI 10.1016/0959-8049(93)90175-F; WOODLAND PC, 1994, P IEEE INT C AC SPEE, V2, P125	29	76	83	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1165	1174		10.1109/34.954606	http://dx.doi.org/10.1109/34.954606			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600010
J	Sebe, N; Lew, MS; Huijsmans, DP				Sebe, N; Lew, MS; Huijsmans, DP			Toward improved ranking metrics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						maximum likelihood; ranking metrics; content-based retrieval; color indexing; stereo matching; motion tracking	STEREO ALGORITHM; COLOR	In many computer vision algorithms, a metric or similarity measure is used to determine the distance between two features. The Euclidean or SSD (sum of the squared differences) metric is prevalent and justified from a maximum likelihood perspective when the additive noise distribution is Gaussian. Based on real noise distributions measured from international test sets, we have found that the Gaussian noise distribution assumption is often invalid. This implies that other metrics, which have distributions closer to the real noise distribution, should be used. In this paper, we consider three different applications: content-based retrieval in image databases, stereo matching, and motion tracking. In each of them, we experiment with different modeling functions for the noise distribution and compute the accuracy of the methods using the corresponding distance measures. In our experiments, we compared the SSD metric, the SAD (sum of the absolute differences) metric, the Cauchy metric, and the Kullback relative information. For several algorithms from the research literature which used the SSD or SAD, we showed that greater accuracy could be obtained by using the Cauchy metric instead.	Leiden Inst Adv Comp Sci, NL-2333 CA Leiden, Netherlands	Leiden University	Sebe, N (corresponding author), Leiden Inst Adv Comp Sci, Niels Bohrweg 1, NL-2333 CA Leiden, Netherlands.	nicu@liacs.nl; mlew@liacs.nl; huijsman@liacs.nl	Huijsmans, Nies/C-6329-2009	Huijsmans, Nies/0000-0002-5594-7934; Sebe, Niculae/0000-0002-6597-7248				BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; Black M, 1992, THESIS YALE U; BOIE RA, 1992, IEEE T PATTERN ANAL, V14, P671, DOI 10.1109/34.141557; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; Hampel FR., 2011, WILEY SERIES PROBABI; HARALICK R, 1993, COMPUTER ROBOT VISIO, pR2; Hirotugu Akaike, 1973, P 2 INT S INF THEOR, P267, DOI 10.1007/978-1-4612-1694-0; Huber P., 1981, ROBUST STAT; HUIJSMANS DP, 1997, LECT NOTES COMPUTER, V1, P22; HUIJSMANS DP, 1996, P 13 INT C PATT REC, V3, P104; Kelly P. M., 1994, Proceedings. Seventh International Working Conference on Scientific and Statistical Database Management (Cat. No.94TH0689-0), P252, DOI 10.1109/SSDM.1994.336943; KELLY PM, 1995, P SPIE STOR RETR IM, V2, P238; KELLY PM, 1996, P SPIE STOR RETR IM, V2, P42; KULLBACK S, 1968, INFORMATION THEORY S; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; LUO W, 1990, P INT C PATT REC, V1, P60; MARR D, 1976, P ROYAL SOC LOND, V204, P301; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SAWHNEY HS, 1994, P IEEE INT C IM PROC, V2, P66, DOI DOI 10.1109/ICIP.1994.413532; Sebe N, 1998, INT C PATT RECOG, P265, DOI 10.1109/ICPR.1998.711132; STONE HS, 1996, P SPIE EL IM SCI TEC; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TANG L, 1994, P NSF ARPA WORKSH PE, P218	30	76	78	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1132	1143		10.1109/34.879793	http://dx.doi.org/10.1109/34.879793			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100006
J	Wang, YM; Staib, LH				Wang, YM; Staib, LH			Boundary finding with prior shape and smoothness models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						boundary finding; correspondence; statistical shape models; smoothness models; deformable models; prior knowledge; Bayesian formulation		We propose a unified framework for boundary finding, where a Bayesian formulation, based on prior knowledge and the edge information of the input image (likelihood), is employed. The prior knowledge in our framework is based on principal component analysis of four different covariance matrices corresponding to independence, smoothness, statistical shape. and combined models, respectively. indeed, snakes. modal analysis, Fourier descriptors, and point distribution models can be derived from or linked to our approaches of different prior models. When the true training set does not contain enough variability to express the full range of deformations, a mixed covariance matrix uses a combined prior of the smoothness and statistical variation modes. It adapts gradually to use more statistical modes of variation as larger data sets are available.	Yale Univ, Dept Elect Engn & Diagnost Radiol, New Haven, CT 06520 USA	Yale University	Wang, YM (corresponding author), Yale Univ, Dept Elect Engn & Diagnost Radiol, POB 208042, New Haven, CT 06520 USA.	wang@noodle.med.yale.edu; staib@noodle.med.yale.edu		Staib, Lawrence/0000-0002-9516-5136				CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cootes T., 1996, P 7 BRIT MACH VIS C, P383; COOTES TF, 1995, IMAGE VISION COMPUT, V13, P403, DOI 10.1016/0262-8856(95)99727-I; COOTES TF, 1993, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION : PROCEEDINGS, P242; HASLAM J, 1994, P BRIT MACH VIS C, P33; Jolliffe IT., 1986, PRINCIPAL COMPONENT; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Snedecor GW, 1980, STAT METHODS, V7th; WANG Y, 1999, THESIS YALE U MAY; WANG Y, 1998, 1 INT C MED IM COMP, P1162; Wang YM, 1998, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1998.698628; Xiao Y, 2000, IEEE IC COMP COM NET, P644, DOI 10.1109/ICCCN.2000.885558	16	76	78	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2000	22	7					738	743		10.1109/34.865192	http://dx.doi.org/10.1109/34.865192			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347LV					2022-12-18	WOS:000088931800009
J	Demigny, D; Kamle, T				Demigny, D; Kamle, T			A discrete expression of Canny's criteria for step edge detector performances evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; Canny criteria; edge operators; localization criterion		On one hand, optimal filters used for edge detection are usually developed in the continuous domain and then transposed by sampling to the discrete domain. On the other hand, the simpler filters like the Sobel filler are directly defined in the discrete domain. Most of the previous works on edge detection were made to elaborate optimal filters. But, few works present methods to compare them. In this paper, we define criteria to compare the performances of different filters in their application area: the discrete domain. Canny has defined three criteria to derive the equation of an optimal filter for step edge detection: (1) good detection, (2) good localization, and (3) low-responses multiplicity. These criteria seem to be good candidates for filters comparison. Unfortunately, they have been developed in the continuous domain, and their analytical expressions cannot be used in the discrete domain. Unlike previous works, our approach is based on a direct computation in the discrete domain. We establish three criteria with the same meaning as Canny's. Some comparisons with experimental results confirm the validity of our approach. This study highlighted the existence of two classes of derivative operators that are distinguished by whether or not the impulse response of the filter in continuous space domain is continuous on its center. These classes exhibit very different properties for the second and third criteria. We extend the use of the first and third criteria to the smoothing filters. We also define an optimal continuous filter according to the continuous third criterion and an optimal discrete filter according to the discrete third criterion. We compare the performances of the sampled version of the continuous filter to those of the optimal discrete filter. It appears that the sampled version of the continuous optimal filter is not optimal for the sampled data even in the case where the spectrum overlapping due to the sampling is reduced.			Demigny, D (corresponding author), ENSEA,ETIS,6 AVE PONCEAU,F-95014 CERGY,FRANCE.							ABRAMOWITZ, 1970, HDB MATH FUNCTIONS, P936; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CANNY JF, 1983, 720 MIT; DEMIGNY D, 1996, P IEEE INT C IMAGE P, V1, P829; DERICHE R, 1990, IEEE T PATTERN ANAL, V12, P78, DOI 10.1109/34.41386; DERICHE R, 1987, INT J COMPUT VISION, P167; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490; RICE SO, 1945, AT&T TECH J, V24, P46, DOI 10.1002/j.1538-7305.1945.tb00453.x; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI [10.1109/34.62607, 10.1117/12.19530]; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	15	76	87	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1199	1211		10.1109/34.632980	http://dx.doi.org/10.1109/34.632980			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500002
J	Irani, M; Rousso, B; Peleg, S				Irani, M; Rousso, B; Peleg, S			Recovery of ego-motion using region alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; ego motion; video stabilization; plane-plus-parallax		A method for computing the 3D camera motion (the ego-motion) in a static scene is described, where initially a detected 2D motion between two frames is used to align corresponding image regions. We prove that such a 2D registration removes all effects of camera rotation, even for those image regions that remain misaligned. The resulting residual parallax displacement field between the two region-aligned images is an epipolar field centered at the FOE (Focus-of-Expansion). The 3D camera translation is recovered from the epipolar field. The 3D camera rotation is recovered from the computed 3D translation and the detected 2D motion. The decomposition of image motion into a 2D parametric motion and residual epipolar parallax displacements avoids many of the inherent ambiguities and instabilities associated with decomposing the image motion into its rotational and translational components, and hence makes the computation of ego-motion or 3D structure estimation more robust.	HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL	Hebrew University of Jerusalem	Irani, M (corresponding author), WEIZMANN INST SCI,DEPT APPL MATH & COMP SCI,IL-76100 REHOVOT,ISRAEL.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AYER S, 1995, ICCV, P777; BENEZRA M, 1994, P ARPA IU WORKSH NOV; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, 2ND P EUR C COMP VIS, P237; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Chipolla R., 1993, INT C COMP VIS BERL, P374; Daniilidis K., 1993, IEEE C COMP VIS PATT, P188; HANNA KJ, 1991, IEEE WORKSH VIS MOT, P156; HEEGER DJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96; Horn B. K. P., 1990, INT J COMPUT VISION, V4, P58; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; IRANI M, 1992, 2ND P EUR C COMP VIS, P282; Irani M., 1994, IEEE C COMP VIS PATT, P454; IRANI M, 1996, EUR C COMP VIS CAMBR, P1; KUMAR R, 1994, P 12 ICPR; LAWN JM, 1993, BMVC93; Lawton D.T., 1983, ARPA IU WORKSH JUN, P78; LEE CH, 1988, INT C COMP VIS, P158; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; LUSTMAN F, 1987, P 1 INT C COMP VIS L, P25; NEGAHDARIPOUR S, 1991, IEEE WORKSH VIS MOT, P132; SAWHNEY H, 1994, IEEE C COMP VIS PATT; SHASHUA A, 1994, IEEE C COMP VIS PATT, P483	26	76	87	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					268	272		10.1109/34.584105	http://dx.doi.org/10.1109/34.584105			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582		Green Published			2022-12-18	WOS:A1997WR58200009
J	BRAULT, JJ; PLAMONDON, R				BRAULT, JJ; PLAMONDON, R			SEGMENTING HANDWRITTEN SIGNATURES AT THEIR PERCEPTUALLY IMPORTANT POINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						CORNER DETECTION; HANDWRITTEN CURVE PARTITIONING; HANDWRITTEN SIGNATURE; PERCEPTUAL IMPORTANCE OF AN ANGLE; SEGMENTATION		This correspondence describes a new algorithm for segmenting continuous handwritten signatures sampled by a digitizer. The segmentation points are found by means of a two-step procedure. The principal step is to construct a function that weights the perceptual importance of every signature point according to its specific neighboring points. The second step points out the various local maxima of this function that correspond where the signature should be segmented. The method is well illustrated and tested on a number of signatures that require different kinds of segmentation decisions.			BRAULT, JJ (corresponding author), ECOLE POLYTECH,DEPT GENIE ELECT & GENIE INFORMAT,SCRIBENS LAB,MONTREAL H3C 3A7,QUEBEC,CANADA.		Plamondon, Réjean/O-3214-2015	Plamondon, Réjean/0000-0002-4903-7539				BRAULT JJ, 1989, 1989 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, P127; BRAULT JJ, 1988, THESIS ECOLE POLYTEC; BRAULT JJ, 1987, 3RD P INT S HANDW CO, P56; BRAULT JJ, 1993, IEEE T SYST MAN CYBE, V23; FISHLER A, 1986, IEEEE T PATT ANAL MA, V8, P100; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; KRUSE B, 1978, 4 INT JOINT C PATT R, P642; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; PLAMONDON R, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P303, DOI 10.1109/ICPR.1992.201778; Plamondon R., 1992, TUTORIALS MOTOR BEHA, VII, P55	11	76	81	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					953	957		10.1109/34.232079	http://dx.doi.org/10.1109/34.232079			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600010
J	WUESCHER, DM; BOYER, KL				WUESCHER, DM; BOYER, KL			ROBUST CONTOUR DECOMPOSITION USING A CONSTANT CURVATURE CRITERION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONTOUR PARTITIONING; CURVATURE; DISCRETE CURVATURE; IMAGE PROCESSING; NONLINEAR FILTERS; SEQUENTIAL SEGMENT EXTRACTION; SHAPE ANALYSIS; STEREOPSIS; VOTING METHODS	DIGITAL CURVES; EDGE-DETECTION; VISION	In many computer vision paradigms it is necessary to decompose an extended boundary or contour into simple primitives. Such decompositions are necessary for further structural or syntactic analysis and concise description of the contour shape. We address this problem with particular emphasis on Laplacian-of-Gaussian (LoG) zero crossing contours. We introduce a novel technique for partitioning such contours into constant curvature segments. In doing so, we present a nonlinear "blip" filter matched to the impairment signature of the curvature computation process, an overlapped voting scheme, and a sequential contiguous segment extraction mechanism. This technique is insensitive to reasonable changes in algorithm parameters and robust to noise and minor viewpoint-induced distortions in the contour shape such as those encountered between stereo image pairs, an application of special interest. The results vary smoothly with the data and local perturbations induce only local changes in the result. Robustness and insensitivity are experimentally verified.	OHIO STATE UNIV, DEPT ELECT ENGN, SIGNAL ANAL & MACHINE PERCEPT LAB, COLUMBUS, OH 43210 USA	University System of Ohio; Ohio State University	WUESCHER, DM (corresponding author), INTERGRAPH CORP, HUNTSVILLE, AL 35807 USA.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; BOYER KL, 1988, P SPIE OPTICS ILLUMI, V3; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; Lowe D. G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P558, DOI 10.1109/CCV.1988.590036; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483; RICHARDS W, 1986, HUMAN MACHINE VISION, V2, P207; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	19	76	80	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					41	51		10.1109/34.67629	http://dx.doi.org/10.1109/34.67629			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EX773					2022-12-18	WOS:A1991EX77300004
J	STANSFIELD, SA				STANSFIELD, SA			ANGY - A RULE-BASED EXPERT SYSTEM FOR AUTOMATIC SEGMENTATION OF CORONARY VESSELS FROM DIGITAL SUBTRACTED ANGIOGRAMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,LINCOLN LAB,TECH STAFF,LEXINGTON,MA 02173	Lincoln Laboratory; Massachusetts Institute of Technology (MIT)	STANSFIELD, SA (corresponding author), UNIV PENN,DEPT COMP SCI,PHILADELPHIA,PA 19104, USA.							ALLEN H, 1883, SYSTEM HUMAN ANATOMY; Ballard D.H., 1982, COMPUTER VISION; Barr A, 1981, HDB ARTIFICIAL INTEL, VI; BRADY M, 1984, P IEEE INT C ROB, P256; Buchanan B. G., 1982, PRINCIPLES RULE BASE; CANNY J, 1983, FINDING LINES EDGES; DANE C, 1974, THESIS U PENNSYLVANI; Forgy C.L., 1981, CMUCS81135; HERMAN G, 1984, CARDIOVASCULAR SYSTE; KENEPP D, 1983, CARDIAC ANATOMY PHYS; KIRSH R, 1971, COMPUTER BIOMEDICAL, P119; Luttgen K., 1982, KINESIOLOGY SCI BASI, V7th; MATSUYAMA T, 1984, EVIDENCE ACCUMULATIO; McKeown D. M.  Jr., 1984, Proceedings of the IEEE Workshop on Principles of Knowledge-Based Systems (Cat. No. 84CH2104-8), P145; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570; PICK P, 1974, GRAYS ANATOMY; POTCHEN E, 1971, PRINCIPLES DIAGNOSTI; ROELLINGER F, 1973, COMPUTER GRAPHICS IM, P232; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENTHAL DA, 1981, INQUIRY DRIVEN VISIO; SHANI U, 1980, THESIS U ROCHESTER R; SLOAN K, 1978, THESIS U PENNSYLVANI; SQUIRE L, 1972, EXERCISES DIAGNOSTIC, V2; SQUIRE L, 1970, EXERCISES DIANOSTIC, V1; STANSFIELD S, 1984, THESIS U PENNSYLVANI; TALTON D, 1984, FORMULATION IMPLEMEN; TSOTSOS JK, 1981, AUG P INT JOINT C AR, P900; TSUJI S, 1981, AUG P INT JOINT C AR, P710; [No title captured]	29	76	80	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					188	199		10.1109/TPAMI.1986.4767772	http://dx.doi.org/10.1109/TPAMI.1986.4767772			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869337				2022-12-18	WOS:A1986A107300006
J	MEDIONI, G; NEVATIA, R				MEDIONI, G; NEVATIA, R			MATCHING IMAGES USING LINEAR FEATURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90089	University of Southern California	MEDIONI, G (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN,ITELLIGENT SYST GRP,LOS ANGELES,CA 90089, USA.							Ballard D.H., 1982, COMPUTER VISION; BERZTISS A, 1973, J ACM            JUL; BOLLES R, 1979, 6TH P IJCAI TOK; Bron  Coen, 1973, COMMUN ACM; BROOKS RA, 1981, AIM343 STANF ART INT; CLARK C, 1979, P S DIGITAL PROCESSI, V186, P54; CLARK C, 1978, P NATO ADV STUDY I P; CORNEIL D, 1970, J ACM            JAN; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P633, DOI 10.1109/TPAMI.1981.4767164; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; KAUFMANN P, 1983, P COMPUT VISION PATT; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NEVATIA R, 1982, MACHINE PERCEPTION; OSTEEN R, 1973, INT J COMPUT INF DEC; PRICE K, 1982, AUG P IEEE WORKSH CO, P105; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3; ULLMAN J, 1976, J ACM            JAN; Waltz D. L, 1972, THESIS MIT CAMBRIDGE; [No title captured]	21	76	89	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					675	685		10.1109/TPAMI.1984.4767592	http://dx.doi.org/10.1109/TPAMI.1984.4767592			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499649				2022-12-18	WOS:A1984TX36100002
J	Zhang, DW; Han, JW; Zhang, Y; Xu, D				Zhang, Dingwen; Han, Junwei; Zhang, Yu; Xu, Dong			Synthesizing Supervision for Learning Deep Saliency Network without Human Annotation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Detectors; Training; Knowledge engineering; Task analysis; Semantics; Feature extraction; Salient object detection; supervision synthesis; annotation-free; weakly supervised semantic segmentation	OBJECT DETECTION; DRIVEN	Recently, the research field of salient object detection is undergoing a rapid and remarkable development along with the wide usage of deep neural networks. Being trained with a large number of images annotated with strong pixel-level ground-truth masks, the deep salient object detectors have achieved the state-of-the-art performance. However, it is expensive and time-consuming to provide the pixel-level ground-truth masks for each training image. To address this problem, this paper proposes one of the earliest frameworks to learn deep salient object detectors without requiring any human annotation. The supervisory signals used in our learning framework are generated through a novel supervision synthesis scheme, in which the key insights are "knowledge source transition" and "supervision by fusion". Specifically, in the proposed learning framework, both the external knowledge source and the internal knowledge source are explored dynamically to provide informative cues for synthesizing supervision required in our approach, while a two-stream fusion mechanism is also established to implement the supervision synthesis process. Comprehensive experiments on four benchmark datasets demonstrate that the deep salient object detector trained by our newly proposed learning framework often works well without requiring any human annotated masks, which even approaches to its upper-bound obtained under the fully supervised learning fashion (within only 3 percent performance gap). Besides, we also apply the salient object detector learnt with our annotation-free learning framework to assist the weakly supervised semantic segmentation task, which demonstrates that our approach can also alleviate the heavy supplementary supervision required in the existing weakly supervised semantic segmentation framework.	[Zhang, Dingwen] Xidian Univ, Sch Mechanoelect Engn, Xian 710071, Peoples R China; [Zhang, Dingwen; Han, Junwei; Zhang, Yu] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia	Xidian University; Northwestern Polytechnical University; University of Sydney	Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.	zhangdingwen2006yyy@gmail.com; junweihan2010@gmail.com; zhangyuygss@mail.nwpu.edu.cn; dong.xu@sydney.edu.au	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730	National Key RAMP;D Program of China [2017YFB0502904]; National Science Foundation of China [61876140]; China Postdoctoral Support Scheme for Innovative Talents [BX20180236]; Australian Research Council Future Fellowship [FT180100116]	National Key RAMP;D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Support Scheme for Innovative Talents; Australian Research Council Future Fellowship(Australian Research Council)	This work was supported in part by the "National Key R&D Program of China" (2017YFB0502904), the National Science Foundation of China under Grants 61876140, and the China Postdoctoral Support Scheme for Innovative Talents under Grant BX20180236. This research is also partially supported by the Australian Research Council Future Fellowship under Grant FT180100116.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gan C, 2017, IEEE I CONF COMP VIS, P1829, DOI 10.1109/ICCV.2017.201; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775; Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264; Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471; Han LF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1816; Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349; Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563; Hou YT, 2007, IEEE INFOCOM SER, P1, DOI 10.1109/INFCOM.2007.9; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158; Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306; Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Li Y, 2016, PROC CVPR IEEE, P1619, DOI 10.1109/CVPR.2016.179; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Long Y, 2017, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2017.653; MAI L, 2013, PROC CVPR IEEE, P1131, DOI DOI 10.1109/CVPR.2013.150; Mai L, 2014, LECT NOTES COMPUT SC, V8691, P76, DOI 10.1007/978-3-319-10578-9_6; Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847; Movahedi Vida, 2010, P IEEE C COMP VIS PA, P49, DOI DOI 10.1109/CVPRW.2010.5543739; Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pathak D., 2014, 14127144 ARXIV; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6; Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Roy A, 2017, PROC CVPR IEEE, P7282, DOI 10.1109/CVPR.2017.770; Rumelhart DE, 1985, TECHNICAL REPORT, DOI 10.1016/b978-1-4832-1446-7.50035-2; Saleh F, 2016, LECT NOTES COMPUT SC, V9912, P413, DOI 10.1007/978-3-319-46484-8_25; Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256; Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938; Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Whitehill J, 2009, ADV NEURAL INFORM PR, P2035; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4; Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P475, DOI 10.1109/TPAMI.2018.2881114; Zhang DW, 2017, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2017.436; Zhang DW, 2017, PROC CVPR IEEE, P3587, DOI 10.1109/CVPR.2017.382; Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844; Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165; Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187; Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360	73	75	75	6	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1755	1769		10.1109/TPAMI.2019.2900649	http://dx.doi.org/10.1109/TPAMI.2019.2900649			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	30794509				2022-12-18	WOS:000542967200018
J	Berman, D; Treibitz, T; Avidan, S				Berman, Dana; Treibitz, Tali; Avidan, Shai			Single Image Dehazing Using Haze-Lines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image color analysis; Atmospheric modeling; Cameras; Clustering algorithms; Estimation; Channel estimation; Image restoration; Single image dehazing; haze removal	VISIBILITY; FRAMEWORK; VISION; POINT	Haze often limits visibility and reduces contrast in outdoor images. The degradation varies spatially since it depends on the objects' distances from the camera. This dependency is expressed in the transmission coefficients, which control the attenuation. Restoring the scene radiance from a single image is a highly ill-posed problem, and thus requires using an image prior. Contrary to methods that use patch-based image priors, we propose an algorithm based on a non-local prior. The algorithm relies on the assumption that colors of a haze-free image are well approximated by a few hundred distinct colors, which form tight clusters in RGB space. Our key observation is that pixels in a given cluster are often non-local, i.e., spread over the entire image plane and located at different distances from the camera. In the presence of haze these varying distances translate to different transmission coefficients. Therefore, each color cluster in the clear image becomes a line in RGB space, that we term a haze-line. Using these haze-lines, our algorithm recovers the atmospheric light, the distance map and the haze-free image. The algorithm has linear complexity, requires no training, and performs well on a wide variety of images compared to other state-of-the-art methods.	[Berman, Dana; Avidan, Shai] Tel Aviv Univ, Sch Elect Engn, IL-6997801 Tel Aviv, Israel; [Treibitz, Tali] Univ Haifa, Sch Marine Sci, IL-3498838 Haifa, Israel	Tel Aviv University; University of Haifa	Berman, D (corresponding author), Tel Aviv Univ, Sch Elect Engn, IL-6997801 Tel Aviv, Israel.	danamena@post.tau.ac.il; ttreibitz@univ.haifa.ac.il; avidan@eng.tau.ac.il			Leona M. and Harry B. Helmsley Charitable Trust; Maurice Hatter Foundation; ISF [1917/2015]; Apple Graduate Fellowship	Leona M. and Harry B. Helmsley Charitable Trust; Maurice Hatter Foundation; ISF(Israel Science Foundation); Apple Graduate Fellowship	TT was supported by the The Leona M. and Harry B. Helmsley Charitable Trust and The Maurice Hatter Foundation. Part of this research was supported by ISF grant 1917/2015. DB was supported by Apple Graduate Fellowship.	Altman A, 1999, OPTIM METHOD SOFTW, V11-2, P275, DOI 10.1080/10556789908805754; Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119; Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284; Ancuti C, 2016, IEEE IMAGE PROC, P2256, DOI 10.1109/ICIP.2016.7532760; Bahat Y, 2016, IEEE INT CONF COMPUT, P34; Berman D, 2017, IEEE INT CONF COMPUT, P115; Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502; Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362; Gibson KB, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-37; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; LAGENDIJK RL, 1988, IEEE T ACOUST SPEECH, V36, P1874, DOI 10.1109/29.9032; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li Y, 2017, COMPUT VIS IMAGE UND, V165, P1, DOI 10.1016/j.cviu.2017.09.003; Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34; Lin HT, 2011, IEEE I CONF COMP VIS, P129, DOI 10.1109/ICCV.2011.6126234; MARSAGLIA G, 1972, ANN MATH STAT, V43, P645, DOI 10.1214/aoms/1177692644; Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82; Middleton W., 1952, VISION ATMOSPHERE; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874; Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1; Omer I., 2004, P 2004 IEEE COMP SOC, V2, pII; ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Schechner YY, 2001, PROC CVPR IEEE, P325; Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Sulami M, 2014, IEEE INT CONF COMPUT; Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643; Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383; Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251; Treibitz T, 2012, J OPT SOC AM A, V29, P1516, DOI 10.1364/JOSAA.29.001516; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Zickler T., 2009, P BRIT MACH VIS C, V1, P4	36	75	78	7	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					720	734		10.1109/TPAMI.2018.2882478	http://dx.doi.org/10.1109/TPAMI.2018.2882478			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30475710				2022-12-18	WOS:000525365300015
J	Mao, XD; Li, Q; Xie, HR; Lau, RYK; Wang, Z; Smolley, SP				Mao, Xudong; Li, Qing; Xie, Haoran; Lau, Raymond Y. K.; Wang, Zhen; Smolley, Stephen Paul			On the Effectiveness of Least Squares Generative Adversarial Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gallium nitride; Training; Generators; Linear programming; Task analysis; Generative adversarial networks; Stability analysis; Least squares GANs; < inline-formula xmlns:ali="http:; www; niso; org; schemas; ali; 1; 0; " xmlns:mml="http:; www; w3; org; 1998; Math; MathML" xmlns:xlink="http:; www; w3; org; 1999; xlink" xmlns:xsi="http:; www; w3; org; 2001; XMLSchema-instance"> < tex-math notation="LaTeX">$\chi <^>2$<; tex-math > < alternatives > < mml:math > < mml:msup > < mml:mi >chi <; mml:mi > < mml:mn > 2 <; mml:mn > <; mml:msup > <; mml:math > < inline-graphic xlink:href="mao-ieq3-2872043; gif" xlink:type="simple"; > <; alternatives > <; inline-formula > divergence; generative model; image generation		Unsupervised learning with generative adversarial networks (GANs) has proven to be hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss for both the discriminator and the generator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson $\chi <^>2$& x03C7;2 divergence. We also show that the derived objective function that yields minimizing the Pearson $\chi <^>2$& x03C7; 2 divergence performs better than the classical one of using least squares for classification. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stably during the learning process. For evaluating the image quality, we conduct both qualitative and quantitative experiments, and the experimental results show that LSGANs can generate higher quality images than regular GANs. Furthermore, we evaluate the stability of LSGANs in two groups. One is to compare between LSGANs and regular GANs without gradient penalty. We conduct three experiments, including Gaussian mixture distribution, difficult architectures, and a newly proposed method & x2014; datasets with small variability, to illustrate the stability of LSGANs. The other one is to compare between LSGANs with gradient penalty (LSGANs-GP) and WGANs with gradient penalty (WGANs-GP). The experimental results show that LSGANs-GP succeed in training for all the difficult architectures used in WGANs-GP, including 101-layer ResNet.	[Mao, Xudong; Li, Qing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Xie, Haoran] Educ Univ Hong Kong, Dept Math & Informat Technol, Hong Kong, Peoples R China; [Lau, Raymond Y. K.] City Univ Hong Kong, Dept Informat Syst, Kowloon, Hong Kong, Peoples R China; [Wang, Zhen] Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning, Xian 710072, Shaanxi, Peoples R China; [Wang, Zhen] Northwestern Polytech Univ, Sch Mech Engn, Xian 710072, Shaanxi, Peoples R China; [Smolley, Stephen Paul] CodeHatch Corp, Edmonton, AB, Canada	City University of Hong Kong; Education University of Hong Kong (EdUHK); City University of Hong Kong; Northwestern Polytechnical University; Northwestern Polytechnical University	Xie, HR (corresponding author), Educ Univ Hong Kong, Dept Math & Informat Technol, Hong Kong, Peoples R China.	xudong.xdmao@gmail.com; itqli@cityu.edu.hk; hrxie2@gmail.com; raylau@cityu.edu.hk; zhenwang0@gmail.com; steve@codehatch.com	Xie, Haoran/AFS-3515-2022; Xie, Haoran/AAW-8845-2020	Xie, Haoran/0000-0003-0965-3617; Lau, Raymond/0000-0002-5751-4550	Hong Kong Research Grants Council [CityU 11211417]; City University of Hong Kong [9610367]	Hong Kong Research Grants Council(Hong Kong Research Grants Council); City University of Hong Kong(City University of Hong Kong)	The work described in this paper has been supported by a grant from the Hong Kong Research Grants Council (project number: CityU 11211417), and a research grant from the City University of Hong Kong (project number: 9610367).	Abadi Martin, 2016, arXiv; Bishop CM, 2006, PATTERN RECOGNITION; Bottou L., 2017, ARXIV170107875STATML; Che Tong, 2016, ARXIV161202136; Dai Z., 2017, CORR; Denton Emily L, 2015, NEURIPS, V2, P4; Dieng A. B., 2017, ADV NEURAL INFORM PR, P2732; Donahue J., 2016, ARXIV160509782; Dumoulin Vincent, 2016, ARXIV E PRINTS; Fedus W., 2017, CORR; Ganin Y, 2016, J MACH LEARN RES, V17; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Gulrajani I, 2017, P NIPS 2017; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hensel M, 2017, ADV NEUR IN, V30; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202; Huszar Ferenc, 2015, CORR; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Kheirkhah P, 2017, IEEE IJCNN, P4467, DOI 10.1109/IJCNN.2017.7966422; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P., 2013, AUTO ENCODING VARIAT; Kodali Naveen, 2017, ARXIV170507215; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li Chunyuan, 2017, NIPS; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Mescheder Lars, 2017, ADV NEURAL INFORM PR, P1825; Metz Luke, 2016, CORR; Mirza M., 2014, ARXIV; Netzer Y, 2011, NIPS WORKSH DEEP LEA, P2011, DOI DOI 10.2118/18761-MS; Nguyen XL, 2010, IEEE T INFORM THEORY, V56, P5847, DOI 10.1109/TIT.2010.2068870; Nowozin S, 2016, ADV NEUR IN, V29; Qi G-J, 2017, CORR; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Reed S, 2016, PR MACH LEARN RES, V48; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rupprecht T, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1772, DOI 10.1145/2976749.2989041; Salakhutdinov R, 2009, ADV NEURAL INFORM PR; Salakhutdinov Ruslan, 2009, ARTIF INTELL, P448, DOI DOI 10.1109/CVPR.2009.5206577; Salimans T, 2016, ADV NEUR IN, V29; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Zhang WW, 2008, LECT NOTES COMPUT SC, V5305, P802, DOI 10.1007/978-3-540-88693-8_59; Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614	48	75	79	2	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2947	2960		10.1109/TPAMI.2018.2872043	http://dx.doi.org/10.1109/TPAMI.2018.2872043			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30273144	Green Submitted			2022-12-18	WOS:000498677600012
J	Xu, C; Zhang, LL; Cheng, L; Koch, R				Xu, Chi; Zhang, Lilian; Cheng, Li; Koch, Reinhard			Pose Estimation from Line Correspondences: A Complete Analysis and a Series of Solutions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Perspective-3-Line; perspective-n-line; configuration analysis; camera pose estimation	POINT; 2-D	In this paper we deal with the camera pose estimation problem from a set of 2D/3D line correspondences, which is also known as PnL (Perspective-n-Line) problem. We carry out our study by comparing PnL with the well-studied PnP (Perspective-n-Point) problem, and our contributions are three-fold: (1) We provide a complete 3D configuration analysis for P3L, which includes the well-known P3P problem as well as several existing analyses as special cases. (2) By exploring the similarity between PnL and PnP, we propose a new subset-based PnL approach as well as a series of linear-formulation-based PnL approaches inspired by their PnP counterparts. (3) The proposed linear-formulation-based methods can be easily extended to deal with the line and point features simultaneously.	[Xu, Chi; Cheng, Li] ASTAR, Bioinformat Inst, Singapore 138632, Singapore; [Zhang, Lilian] Natl Univ Def Technol, Coll Mechatron & Automat, Dept Automat Control, Changsha 410073, Hunan, Peoples R China; [Koch, Reinhard] Univ Kiel, Inst Comp Sci, D-24118 Kiel, Germany	Agency for Science Technology & Research (A*STAR); A*STAR - Bioinformatics Institute (BII); National University of Defense Technology - China; University of Kiel	Xu, C (corresponding author), ASTAR, Bioinformat Inst, Singapore 138632, Singapore.	xuchi@bii.a-star.edu.sg; lilianzhang@nudt.edu.cn; chengli@bii.a-star.edu.sg; rk@mip.informatik.uni-kiel.de	Cheng, Li/AAU-6734-2020	Cheng, Li/0000-0003-3261-3533; Xu, Chi/0000-0002-5301-9376; Koch, Reinhard/0000-0003-4398-1569	National Natural Science Foundation of China [61503403, 61573371]; A*STAR JCO [1431AFG120]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); A*STAR JCO(Agency for Science Technology & Research (A*STAR))	Lilian Zhang is supported by National Natural Science Foundation of China (No. 61503403, No. 61573371). Chi Xu and Li Cheng are partially supported by A*STAR JCO grant 1431AFG120. The authors would like to thank the anonymous reviewers for their help comments and suggestions. The authors would like to thank Prof. Xavier Binefa and Luis Ferraz for their helpful discussion. Lilian Zhang is the corresponding author.	Abdel-Aziz Y., 1971, ASP S CLOS RANG PHOT; Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992; CAGLIOTI V, 1993, PATTERN RECOGN, V26, P1603, DOI 10.1016/0031-3203(93)90016-P; CHEN HH, 1991, IEEE T PATTERN ANAL, V13, P530, DOI 10.1109/34.87340; Christy S, 1999, COMPUT VIS IMAGE UND, V73, P137, DOI 10.1006/cviu.1998.0717; Cox D. A., 2005, USING ALGEBRAIC GEOM, V185; DeMenthon Daniel F., INT J COMPUT VISION, V15, P123; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; Dornaika F, 1999, REAL-TIME IMAGING, V5, P215, DOI 10.1006/rtim.1997.0117; Ferraz L, 2014, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2014.71; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Hartley R., 2004, ROBOTICA; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266; Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464; Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9; Kneip L, 2013, IEEE INT CONF ROBOT, P3770, DOI 10.1109/ICRA.2013.6631107; KUMAR R, 1994, CVGIP-IMAG UNDERSTAN, V60, P313, DOI 10.1006/ciun.1994.1060; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41; Li SQ, 2011, INT J PATTERN RECOGN, V25, P627, DOI 10.1142/S0218001411008774; Li SQ, 2011, COMPUT ANIMAT VIRT W, V22, P47, DOI 10.1002/cav.385; Lilian Zhang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P217, DOI 10.1007/978-3-642-37431-9_17; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; Mirzaei F. M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5581, DOI 10.1109/ICRA.2011.5980272; Mirzaei FM, 2011, IEEE I CONF COMP VIS, P2454, DOI 10.1109/ICCV.2011.6126530; Navab N., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P254, DOI 10.1109/CVPR.1993.340981; PHONG TQ, 1995, INT J COMPUT VISION, V15, P225, DOI 10.1007/BF01451742; Pribyl B., 2015, P BRIT MACH VIS C SW, P451; Qin Li-Juan, 2008, Acta Automatica Sinica, V34, P130; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; SHUSTER MD, 1993, J ASTRONAUT SCI, V41, P439; Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034; Zhang LL, 2016, INT J COMPUT VISION, V117, P111, DOI 10.1007/s11263-015-0854-5; Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291; Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	42	75	80	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1209	1222		10.1109/TPAMI.2016.2582162	http://dx.doi.org/10.1109/TPAMI.2016.2582162			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27333597				2022-12-18	WOS:000401091200012
