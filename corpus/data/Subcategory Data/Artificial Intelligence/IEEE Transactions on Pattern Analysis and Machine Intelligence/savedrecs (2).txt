PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Kittler, J; Alkoot, FM				Kittler, J; Alkoot, FM			Sum versus vote fusion in multiple classifier systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple classifiers; fusion rules; estimation error	HANDWRITING RECOGNITION; DECISION COMBINATION	Amidst the conflicting experimental evidence of superiority of one over the other, we investigate the Sum and majority Vote combining rules in a two class case, under the assumption of experts being of equal strength and estimation errors conditionally independent and identically distributed. We show, analytically, that, for Gaussian estimation error distributions, Sum always outperforms Vote. For heavy tail distributions, we demonstrate by simulation that Vote may outperform Sum. Results on synthetic data confirm the theoretical predictions. Experiments on real data support the general findings, but also show the effect of the usual assumptions of conditional independence, identical error distributions, and common target outputs of the experts not being fully satisfied.	Univ Surrey, Sch Elect Comp & Math, Ctr Vis Speech & Signal Proc, Surrey GU2 7XH, England; Publ Author Appl Educ & Training, Telecommun & Navigat Inst, Shuwaikh, Kuwait	University of Surrey; Public Authority for Applied Education & Training (PAAET) - Kuwait	Kittler, J (corresponding author), Univ Surrey, Sch Elect Comp & Math, Ctr Vis Speech & Signal Proc, Surrey GU2 7XH, England.	j.kittler@eim.surrey.ac.uk; f_alkoot@yahoo.com	Alkoot, Fuad M/E-8249-2015	Alkoot, Fuad M/0000-0002-0583-507X				ALKOOT FM, 1999, PATTERN RECOGN, V20, P11; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; DIETTERICH T, 1998, MACH LEARN, P1; Duin RPW, 2000, LECT NOTES COMPUT SC, V1857, P16; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Matagne P, 2000, CMES-COMP MODEL ENG, V1, P1; Rahman AFR, 1999, IEE P-VIS IMAGE SIGN, V146, P40, DOI 10.1049/ip-vis:19990015; SUEN CY, 1993, PATTERN RECOGN LETT, V14, P303, DOI 10.1016/0167-8655(93)90096-V; Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7; TURNER K, 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; 2002, EXTENDED M2VTS DATAB	15	164	170	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					110	115		10.1109/TPAMI.2003.1159950	http://dx.doi.org/10.1109/TPAMI.2003.1159950			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300009
J	Silva, L; Bellon, ORP; Boyer, KL				Silva, L; Bellon, ORP; Boyer, KL			Precision range image registration using a robust surface interpenetration measure and enhanced genetic algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						range image registration; genetic algorithms; robust methods; stochastic search	MODEL; RECOGNITION	This paper addresses the range image registration problem for views having low overlap and which may include substantial noise. The current state of the art in range image registration is best represented by the well-known iterative closest point ( ICP) algorithm and numerous variations on it. Although this method is effective in many domains, it nevertheless suffers from two key limitations: It requires prealignment of the range surfaces to a reasonable starting point and it is not robust to outliers arising either from noise or low surface overlap. This paper proposes a new approach that avoids these problems. To that end, there are two key, novel contributions in this work: a new, hybrid genetic algorithm ( GA) technique, including hillclimbing and parallel-migration, combined with a new, robust evaluation metric based on surface interpenetration. Up to now, interpenetration has been evaluated only qualitatively; we define the first quantitative measure for it. Because they search in a space of transformations, GAs are capable of registering surfaces even when there is low overlap between them and without need for prealignment. The novel GA search algorithm we present offers much faster convergence than prior GA methods, while the new robust evaluation metric ensures more precise alignments, even in the presence of significant noise, than mean squared error or other well-known robust cost functions. The paper presents thorough experimental results to show the improvements realized by these two contributions.	Univ Fed Parana, Dept Informat, BR-81531980 Curitiba, Parana, Brazil; Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA	Universidade Federal do Parana; University System of Ohio; Ohio State University	Silva, L (corresponding author), Univ Fed Parana, Dept Informat, Caixa Postal 19092, BR-81531980 Curitiba, Parana, Brazil.	luciano@inf.ufpr.br; olga@inf.ufpr.br; kim@ece.osu.edu	Silva, Luciano/A-4812-2010; Bellon, Olga/E-6564-2011	Silva, Luciano/0000-0001-6341-1323; 				Ahmed M, 1997, PROC CVPR IEEE, P646, DOI 10.1109/CVPR.1997.609394; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Brunnstrom K., 1996, P 13 INT C PATT REC, V4, P689; CHALERMWAT P, 1999, P IEEE INT C IM PROC, V2, P452; Champleboux G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P83, DOI 10.1109/CVPR.1992.223223; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819; DAGOSTINO RB, 1986, TESTS NORMAL DISTRIB, P367; Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986; Dalley G, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P246, DOI 10.1109/IM.2001.924446; Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; Goldberg DE, 1989, GENETIC ALGORITHMS S; GOTARDO PFU, 2004, IEEE T SYSTEMS MAN B; GOTARDO PFU, 2003, P IEEE C COMP VIS PA; Holland J.H., 1975, ADAPTATION NATURAL A, DOI DOI 10.7551/MITPRESS/1090.001.0001; Huber DF, 2003, PROC CVPR IEEE, P858; IKEUCHI K., 2001, MODELING REALITY; INGBER L, 1989, MATH COMPUT MODEL, V12, P967, DOI 10.1016/0895-7177(89)90202-1; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609; Masuoka S., 1995, Journal of Sensory Studies, V10, P295, DOI 10.1111/j.1745-459X.1995.tb00021.x; Park S., 2001, P SPIE C, V4567, P65; Reed MK, 1999, IMAGE VISION COMPUT, V17, P99, DOI 10.1016/S0262-8856(98)00114-0; Renders JM, 1996, IEEE T SYST MAN CY B, V26, P243, DOI 10.1109/3477.485836; Robertson C, 2002, COMPUT VIS IMAGE UND, V87, P39, DOI 10.1006/cviu.2002.0981; Rodrigues M, 2002, COMPUT VIS IMAGE UND, V87, P1, DOI 10.1006/cviu.2002.0978; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sappa A. D., 2001, P 9 INT S INT ROB SY, P167; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Simon D A, 1995, J Image Guid Surg, V1, P17, DOI 10.3109/10929089509106822; Stoddart A. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P40, DOI 10.1109/ICPR.1996.546720; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Wyngaerd JV, 2002, COMPUT VIS IMAGE UND, V87, P8, DOI 10.1006/cviu.2002.0979; Yamany S. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1098, DOI 10.1109/ICCV.1999.790402; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	45	163	186	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					762	776		10.1109/TPAMI.2005.108	http://dx.doi.org/10.1109/TPAMI.2005.108			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875797				2022-12-18	WOS:000227569300009
J	Zivkovic, Z; van der Heijden, F				Zivkovic, Z; van der Heijden, F			Recursive unsupervised learning of finite mixture models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						online (recursive) estimation; unsupervised learning; finite mixtures; model selection; EM-algorithm	INCOMPLETE DATA; EM ALGORITHM	There are two open problems when finite mixture densities are used to model multivariate data: the selection of the number of components and the initialization. In this paper, we propose an online (recursive) algorithm that estimates the parameters of the mixture and that simultaneously selects the number of components. The new algorithm starts with a large number of randomly initialized components. A prior is used as a bias for maximally structured models. A stochastic approximation recursive learning algorithm is proposed to search for the maximum a posteriori (MAP) solution and to discard the irrelevant components.	Univ Amsterdam, Inst Informat, NL-1098 SJ Amsterdam, Netherlands; Univ Twente, Lab Measurement & Instrumentat, NL-7500 AE Enschede, Netherlands	University of Amsterdam; University of Twente	Zivkovic, Z (corresponding author), Univ Amsterdam, Inst Informat, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	zivkovic@science.uva.nl; f.vanderheijden@utwente.nl	Popirlan, Claudiu Ionut/O-7997-2019; Dupac, Mihai/J-1865-2019; Popirlan, Claudiu Ionut/B-2762-2011	Popirlan, Claudiu Ionut/0000-0003-3194-4613; Dupac, Mihai/0000-0002-3922-6299; Popirlan, Claudiu Ionut/0000-0003-3194-4613; van der Heijden, Ferdinand/0000-0001-8065-8053				AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Anderson E., 1935, B AM IRIS SOC, V59; Brand M, 1999, NEURAL COMPUT, V11, P1155, DOI 10.1162/089976699300016395; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; FABIAN V, 1978, ANN STAT, V6, P854, DOI 10.1214/aos/1176344259; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gelman A, 2013, BAYESIAN DATA ANAL, P16; McLachlan G. J., 2000, FINITE MIXTURE MODEL; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223; SACKS J, 1958, ANN MATH STAT, V29, P373, DOI 10.1214/aoms/1177706619; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; TITTERINGTON DM, 1984, J ROY STAT SOC B MET, V46, P257; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088; Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0; VERBEEK JJ, 2003, NEURAL COMPUTATION, V15; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240	20	163	184	4	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					651	656		10.1109/TPAMI.2004.1273970	http://dx.doi.org/10.1109/TPAMI.2004.1273970			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460286	Green Submitted			2022-12-18	WOS:000220756400010
J	Negahdaripour, S				Negahdaripour, S			Revised definition of optical flow: Integration of radiometric and geometric cues for dynamic scene analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion vision; optical flow; time-varying image analysis; dynamic visual cues; integration of radiometric and geometric cues	IMAGE SEQUENCES; DISPLACEMENT	Optical flow has been commonly defined as the apparent motion of image brightness patterns in an image sequence. In this paper, we propose a revised definition to overcome shortcomings in interpreting optical flow merely as a geometric transformation field. The new definition is a complete representation of geometric and radiometric variations in dynamic imagery. We argue that this is more consistent with the common interpretation of optical flow induced by various scene events. This leads to a general framework for the investigation of problems in dynamic scene analysis, based on the integration and unified treatment of both geometric and radiometric cues in time-varying imagery. We discuss selected models, including the generalized dynamic image model in [21], for the estimation of optical flow. We show how various 3D scene information are encoded in, and thus may be extracted from, the geometric and radiometric components of optical flow. We provide selected examples based on experiments with real images.	Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA	University of Miami	Negahdaripour, S (corresponding author), Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.							BALLARD DH, 1983, CVGIP, V22; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARON JL, 1994, INT J COMPUTER VISIO, V12; BLAKE A, 1992, PHYSICS BASED VISION; BRUSS AR, 1983, CVGIP, V21; COLEMAN EN, 1992, PHYSICS BASED VISION; CORNELIUS N, 1983, ACM SIGGRAPH SIGART; Grimson W. E. L, IMAGES SURFACES COMP; GRIMSON WEL, 1992, PHYSICS BASED VISION; HILDRETH E, 1983, MEASUREMENT VISUAL M; Horn B., 1986, ROBOT VISION, P1; Horn B, 1981, ARTIFICIAL INTELLIGE, V17; KEARNEY JK, IEEE T PATTERN ANAL, V9; KENDER JR, 1992, PHYSICS BASED VISION; LONGUETHIGGINS HC, 1980, P ROYAL SOC LONDON B, V208; MATTHIES L, 1988, P COMP VIS PATT REC; MUKAWA N, 1990, P INT C COMP VIS 90; NAGEL HH, 1989, IEEE T PATTERN ANAL, V11, P13, DOI 10.1109/34.23110; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NEGAHDARIPOUR S, 1989, P ICIP 89 SING SEP; NEGAHDARIPOUR S, 1995, P ISCV COR GABL FLA; NEGAHDARIPOUR S, 1993, P INT C COMP VIS GER; PENTLAND A, 1990, P ICCV90 OS SEP; SCHUNCK BG, 1985, P COMP VIS PATT REC; SPOERRI A, 1987, P ICCV LOND JUN; THOMPSON WB, 1987, P INT C COMP VIS JUN; TISTARELLI M, 1995, P INT C COMP VIS BOS; URAS S, 1988, BIO CYBERNETICS, V60; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WOLFF LB, 1989, P COMP VIS PATT REC; Woodham R. J., 1980, OPTICAL ENG, V19; WOODHAM RJ, 1990, INT C COMP VIS OS DE; YU CH, 1992, J OPTICAL SOC AM, V9; ZHENG JY, 1995, P INT C COMP VIS BOS; ZISSERMAN A, 1989, IMAGE VISION COMPUTI, V7	35	163	171	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					961	979		10.1109/34.713362	http://dx.doi.org/10.1109/34.713362			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500005
J	MARZAL, A; VIDAL, E				MARZAL, A; VIDAL, E			COMPUTATION OF NORMALIZED EDIT DISTANCE AND APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDITING; LEVENSHTEIN DISTANCE; NORMALIZED EDIT DISTANCE; OPTICAL CHARACTER RECOGNITION; PATTERN RECOGNITION; SPEECH RECOGNITION; SPELLING CORRECTION; STRING CORRECTION		Given two strings X and Y over a finite alphabet, the normalized edit distance between X and Y, d(X, Y) is defined as the minimum of W(P)/L(P), where P is an editing path between X and Y, W(P) is the sum of the weights of the elementary edit operations of P, and L(P) is the number of these operations (length of P). In this paper, it is shown that in general, d(X, Y) cannot be computed by first obtaining the conventional (unnormalized) edit distance between X and Y and then normalizing this value by the length of the corresponding editing path. In order to compute normalized edit distances, a new algorithm that can be implemented to work in O(m . n2) time and O(n2) memory space is proposed, where m and n are the lengths of the strings under consideration, and m greater-than-or-equal-to n. Experiments in hand-written digit recognition are presented, revealing that the normalized edit distance consistently provides better results than both unnormalized or post-normalized classical edit distances.			MARZAL, A (corresponding author), UNIV POLITECN VALENCIA, DEPT SISTEMAS INFORMAT & COMPUTAC, VALENCIA, SPAIN.							[Anonymous], [No title captured]; CASACUBERTA F, 1987, RECONOMCIMIENTO AUTO; FU KS, 1982, SYNTACTIC PATTERN RE; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; KITAZUME Y, 1985, IEEE T ACOUST SPEECH, V33, P1, DOI 10.1109/TASSP.1985.1164510; Kruskal J.B., 1983, TIME WARPS STRING ED; MARZAL A, DSICII151991 U POL V; MASEK WJ, 1980, J COMPUT SYST SCI, V20, P18, DOI 10.1016/0022-0000(80)90002-1; RABINER L, 1981, IEEE T COMMUN, V29, P6251; RULOT H, 1987, PATTERN RECOGN, P451; Sellers P., 1980, J ALGORITHMS, V1, P359, DOI DOI 10.1016/0196-6774(80)90016-4; VIDAL E, 1988, SPEECH COMMUN, V7, P67, DOI 10.1016/0167-6393(88)90022-2; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; YANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080	14	163	168	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					926	932		10.1109/34.232078	http://dx.doi.org/10.1109/34.232078			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600006
J	DEANS, SR				DEANS, SR			HOUGH TRANSFORM FROM THE RADON-TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DEANS, SR (corresponding author), UNIV MINNESOTA,SCH MATH,MINNEAPOLIS,MN 55455, USA.							BROOKS RA, 1976, PHYS MED BIOL, V21, P689, DOI 10.1088/0031-9155/21/5/001; BUDINGER TF, 1974, IEEE T NUCL SCI, VNS21, P2, DOI 10.1109/TNS.1974.6499234; DEANS SR, 1979, SIAM J MATH ANAL, V10, P577, DOI 10.1137/0510054; DEANS SR, UNPUBLISHED; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GORDON R, 1974, INT REV CYTOL, V38, P111, DOI 10.1016/S0074-7696(08)60925-0; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Lighthill M.J., 1958, INTRO FOURIER ANAL G; LUDWIG D, 1966, COMMUN PUR APPL MATH, V19, P49; MERSEREAU RM, 1974, P IEEE, V62, P1319, DOI 10.1109/PROC.1974.9625; Pratt W. K., 1978, DIGITAL IMAGE PROCES; Radon J., 1917, SITZBER SACHS AKAD W, V69, P262, DOI DOI 10.1109/TMI.1986.4307775; SCHWARTZ L, 1966, MATH PHYSICAL SCI, P26; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHAPIRO SD, 1978, COMPUT VISION GRAPH, V8, P219, DOI 10.1016/0146-664X(78)90050-3; SHAPIRO SD, 1979, IEEE T PATTERN ANAL, V1, P310, DOI 10.1109/TPAMI.1979.4766929; SHEPP LA, 1978, AM MATH MON, V85, P420, DOI 10.2307/2320062; SNYDER DL, 1977, RECONSTRUCTION TOMOG, P3; [No title captured]	19	163	174	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					185	188		10.1109/TPAMI.1981.4767076	http://dx.doi.org/10.1109/TPAMI.1981.4767076			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868933				2022-12-18	WOS:A1981MN96800008
J	Xu, YC; Fu, MT; Wang, QM; Wang, YK; Chen, K; Xia, GS; Bai, X				Xu, Yongchao; Fu, Mingtao; Wang, Qimeng; Wang, Yukang; Chen, Kai; Xia, Gui-Song; Bai, Xiang			Gliding Vertex on the Horizontal Bounding Box for Multi-Oriented Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Feature extraction; Proposals; Detectors; Electronic mail; Benchmark testing; Runtime; Object detection; R-CNN; multi-oriented object; aerial image; scene text; pedestrian detection		Object detection has recently experienced substantial progress. Yet, the widely adopted horizontal bounding box representation is not appropriate for ubiquitous oriented objects such as objects in aerial images and scene texts. In this paper, we propose a simple yet effective framework to detect multi-oriented objects. Instead of directly regressing the four vertices, we glide the vertex of the horizontal bounding box on each corresponding side to accurately describe a multi-oriented object. Specifically, We regress four length ratios characterizing the relative gliding offset on each corresponding side. This may facilitate the offset learning and avoid the confusion issue of sequential label points for oriented objects. To further remedy the confusion issue for nearly horizontal objects, we also introduce an obliquity factor based on area ratio between the object and its horizontal bounding box, guiding the selection of horizontal or oriented detection for each object. We add these five extra target variables to the regression head of faster R-CNN, which requires ignorable extra computation time. Extensive experimental results demonstrate that without bells and whistles, the proposed method achieves superior performances on multiple multi-oriented object detection benchmarks including object detection in aerial images, scene text detection, pedestrian detection in fisheye images.	[Xu, Yongchao; Fu, Mingtao; Wang, Qimeng; Wang, Yukang; Bai, Xiang] Huazhong Univ Sci & Technol HUST, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China; [Chen, Kai] Wuhan Univ, LIEMARS, Wuhan 430072, Hubei, Peoples R China; [Xia, Gui-Song] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China; [Xia, Gui-Song] Onyou Inc, Shenzhen 518057, Guangdong, Peoples R China	Huazhong University of Science & Technology; Wuhan University; Shanghai Jiao Tong University	Bai, X (corresponding author), Huazhong Univ Sci & Technol HUST, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.	yongchaoxu@hust.edu.cn; mingtaofu@hust.edu.cn; qimengwang@hust.edu.cn; wangyk@hust.edu.cn; kchen@sjtu.edu.cn; guisong.xia@whu.edu.cn; xbai@hust.edu.cn	Wang, Yukang/AAK-7775-2020	Wang, Yukang/0000-0003-0173-6880; Doloriel, Chandler Timm/0000-0003-3820-7317; wang, qimeng/0000-0002-9715-836X; Bai, Xiang/0000-0002-3449-5940; Xia, Gui-Song/0000-0001-7660-6090	Major Project for New Generation of AI [2018AAA0100400]; NSFC [61703171]; NSF of Hubei Province of China [2018CFB199]; Young Elite Scientists Sponsorship Program by CAST; Program for HUST Academic Frontier Youth Team [2017QYTD08]	Major Project for New Generation of AI; NSFC(National Natural Science Foundation of China (NSFC)); NSF of Hubei Province of China; Young Elite Scientists Sponsorship Program by CAST; Program for HUST Academic Frontier Youth Team	This work was supported in part by the Major Project for New Generation of AI under Grant no. 2018AAA0100400, in part by NSFC 61703171, and in part by NSF of Hubei Province of China under Grant 2018CFB199, Dr. Yongchao Xu was supported by the Young Elite Scientists Sponsorship Program by CAST and Dr. Xiang Bai was supported by the Program for HUST Academic Frontier Youth Team 2017QYTD08.	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; [Anonymous], 2017, MIRROR WORLDS CHALLE; Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959; Dai JF, 2016, ADV NEUR IN, V29; Ding J, 2019, PROC CVPR IEEE, P2844, DOI 10.1109/CVPR.2019.00296; DOLLAR P, 2012, PAMI, V34, P743, DOI DOI 10.1109/TPAMI.2011.155; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; He K., 2017, P IEEE INT C COMP VI, P2961, DOI DOI 10.1109/ICCV.2017.322; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; He WH, 2018, IEEE T IMAGE PROCESS, V27, P5406, DOI 10.1109/TIP.2018.2855399; Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45; Li Zeming, 2017, ARXIV171107264; Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619; Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin Tsung-Yi, 2017, ARXIV170802002, P2980, DOI [DOI 10.1109/ICCV.2017.324, DOI 10.1109/TPAMI.2018.2858826]; Liu L., 2017, LEARNING ROTATION IN; Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368; Liu ZC, 2018, PROC CVPR IEEE, P6936, DOI 10.1109/CVPR.2018.00725; Liu ZK, 2017, IEEE IMAGE PROC, P900; Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788; Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Seidel R., 2018, ARXIV 180508503; SHI B, 2017, IEEE T IMAGE PROCESS, V1, P1429; Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371; Tamura M, 2019, IEEE WINT CONF APPL, P1989, DOI 10.1109/WACV.2019.00216; Wang XB, 2019, PROC CVPR IEEE, P6442, DOI 10.1109/CVPR.2019.00661; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589; Xue CH, 2018, LECT NOTES COMPUT SC, V11220, P370, DOI 10.1007/978-3-030-01270-0_22; Yang X., 2018, ARXIV 181107126; YAO C, 2014, PROC CVPR IEEE, V23, P4737; Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787; Zhang CQ, 2019, PROC CVPR IEEE, P10544, DOI 10.1109/CVPR.2019.01080; Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982; Zhang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P1745, DOI 10.1109/LGRS.2018.2856921; Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871; Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283	48	162	173	62	219	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1452	1459		10.1109/TPAMI.2020.2974745	http://dx.doi.org/10.1109/TPAMI.2020.2974745			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	32086194	Green Submitted			2022-12-18	WOS:000626525300025
J	Zaragoza, J; Chin, TJ; Tran, QH; Brown, MS; Suter, D				Zaragoza, Julio; Chin, Tat-Jun; Tran, Quoc-Huy; Brown, Michael S.; Suter, David			As-Projective-As-Possible Image Stitching with Moving DLT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image stitching; image alignment; projective warps; direct linear transformation; moving least squares		The success of commercial image stitching tools often leads to the impression that image stitching is a "solved problem". The reality, however, is that many tools give unconvincing results when the input photos violate fairly restrictive imaging assumptions; the main two being that the photos correspond to views that differ purely by rotation, or that the imaged scene is effectively planar. Such assumptions underpin the usage of 2D projective transforms or homographies to align photos. In the hands of the casual user, such conditions are often violated, yielding misalignment artifacts or "ghosting" in the results. Accordingly, many existing image stitching tools depend critically on post-processing routines to conceal ghosting. In this paper, we propose a novel estimation technique called Moving Direct Linear Transformation (Moving DLT) that is able to tweak or fine-tune the projective warp to accommodate the deviations of the input data from the idealized conditions. This produces as-projective-as-possible image alignment that significantly reduces ghosting without compromising the geometric realism of perspective image stitching. Our technique thus lessens the dependency on potentially expensive postprocessing algorithms. In addition, we describe how multiple as-projective-as-possible warps can be simultaneously refined via bundle adjustment to accurately align multiple images for large panorama creation.	[Zaragoza, Julio; Chin, Tat-Jun; Tran, Quoc-Huy; Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Brown, Michael S.] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore	University of Adelaide; National University of Singapore	Zaragoza, J (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	jzaragoza@cs.adelaide.edu.au; tjchin@cs.adelaide.edu.au; huy@cs.adelaide.edu.au; brown@comp.nus.edu.sg; dsuter@cs.adelaide.edu.au		Suter, David/0000-0001-6306-3023	Singapore NRF under its IRC@SG Funding Initiative	Singapore NRF under its IRC@SG Funding Initiative(National Research Foundation, Singapore)	The authors express their gratitude to R. Hill and A. Eriksson for helpful discussions on using ceres [31]. This research was carried out in part at the SeSaMe Centre, supported by the Singapore NRF under its IRC@SG Funding Initiative and administered by the IDMPO.	Agarwala A., 2006, P ACM SIGGRAPH; AGARWALA A, 2004, P ACM SIGGRAPH; Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; Dornaika F, 2004, SIGNAL PROCESS-IMAGE, V19, P771, DOI 10.1016/j.image.2004.06.008; Eden A., 2006, P IEEE CVPR; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gao J., 2011, P IEEE C CVPR PROV R; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276406, 10.1145/1239451.1239474]; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323; Jia JY, 2008, IEEE T PATTERN ANAL, V30, P617, DOI 10.1109/TPAMI.2007.70729; Kang E.-Y., 2000, P 15 ICPR BARC SPAIN; Lin W.-Y., 2011, P IEEE C CVPR PROV R; Lin W.-Y., 2012, P IEEE C CVPR PROV R; Liu F., 2009, P ACM SIGGRAPH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marzotto R., P 2004 IEEE COMP SOC; Mynorenko A., 2007, P NIPS; Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794; PEREZ P., 2003, P ACM SIGGRAPH; Schaefer S., 2006, P SIGGRAPH; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Stange P., 2008, APP MATH MECH, V8, P10827, DOI DOI 10.1002/PAMM.200810827; Szeliski R., 2004, HDB MATH MODELS COMP, P273; Tran Q.-H., 2012, P 12 ECCV FLOR IT; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Zaragoza J., 2013, P CVPR; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	31	162	183	10	97	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1285	1298		10.1109/TPAMI.2013.247	http://dx.doi.org/10.1109/TPAMI.2013.247			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353303	Green Published			2022-12-18	WOS:000338209900001
J	Wu, XD; Yu, K; Ding, W; Wang, H; Zhu, XQ				Wu, Xindong; Yu, Kui; Ding, Wei; Wang, Hao; Zhu, Xingquan			Online Feature Selection with Streaming Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; streaming features; supervised learning	CAUSAL DISCOVERY; CONSISTENCY	We propose a new online feature selection framework for applications with streaming features where the knowledge of the full feature space is unknown in advance. We define streaming features as features that flow in one by one over time whereas the number of training examples remains fixed. This is in contrast with traditional online learning methods that only deal with sequentially added observations, with little attention being paid to streaming features. The critical challenges for Online Streaming Feature Selection (OSFS) include 1) the continuous growth of feature volumes over time, 2) a large feature space, possibly of unknown or infinite size, and 3) the unavailability of the entire feature set before learning starts. In the paper, we present a novel Online Streaming Feature Selection method to select strongly relevant and nonredundant features on the fly. An efficient Fast-OSFS algorithm is proposed to improve feature selection performance. The proposed algorithms are evaluated extensively on high-dimensional datasets and also with a real-world case study on impact crater detection. Experimental results demonstrate that the algorithms achieve better compactness and higher prediction accuracy than existing streaming feature selection algorithms.	[Wu, Xindong; Yu, Kui; Wang, Hao] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China; [Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA; [Ding, Wei] Univ Massachusetts, Dept Comp Sci, Coll Sci & Math, Boston, MA 02125 USA; [Zhu, Xingquan] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Quantum Computat & Intelligent Syst, Broadway, NSW 2007, Australia	Hefei University of Technology; University of Vermont; University of Massachusetts System; University of Massachusetts Boston; University of Technology Sydney	Wu, XD (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.	xwu@cs.uvm.edu; ykui713@gmail.com; ding@cs.umb.edu; jsjxwangh@hfut.edu.cn; xqzhu@it.uts.edu.au	ZOU, Fengcai/ABE-4598-2021; Wu, Xindong/AAB-6713-2022	ZOU, Fengcai/0000-0002-9613-3734; Wu, Xindong/0000-0003-2396-1704; Ding, Wei/0000-0002-3383-551X; Zhu, Xingquan/0000-0003-4129-9611; YU, KUI/0000-0003-2442-4572	National 973 Program of China [2013CB329604]; National 863 Program of China [2012AA011005]; National Natural Science Foundation of China [NSFC 61229301, 61070131, 61175051, 61005007]; US National Science Foundation [NSF CCF-0905337]; US NASA [NNX09AK86G]; Australian Research Council (ARC) [FT100100971]	National 973 Program of China(National Basic Research Program of China); National 863 Program of China(National High Technology Research and Development Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); US National Science Foundation(National Science Foundation (NSF)); US NASA(National Aeronautics & Space Administration (NASA)); Australian Research Council (ARC)(Australian Research Council)	This work is supported by the National 973 Program of China under grant 2013CB329604, the National 863 Program of China (2012AA011005), the National Natural Science Foundation of China (NSFC 61229301, 61070131, 61175051, and 61005007), the US National Science Foundation (NSF CCF-0905337), a US NASA Research Award (NNX09AK86G), and the Australian Research Council (ARC) Future Fellowship (FT100100971). The authors would like to thank the anonymous reviewers for their valuable and constructive comments on improving the paper.	Agresti A., 1990, CATEGORICAL DATA ANA, pXV; [Anonymous], 2010, SPIDER A MATLAB MACH; Aphinyanaphongs Y, 2006, J AM MED INFORM ASSN, V13, P446, DOI 10.1197/jamia.M2031; Bontempi G., 2010, PROC INTL CONF MACHI; Clopinet, 2003, NIPS 2003; Clopinet, 2006, WCCI 2006; Clopinet, 2008, WCCI 2008; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Dhillon P.S., 2010, PROC INTL CONF ARTIF; Ding W, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1989734.1989743; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670; Glocer K., 2005, PROC INTL CONF MACHI; Guyon I, 2008, CH CRC DATA MIN KNOW, P63; Joachims T, 2002, LEARNING TO CLASSIFY; John G.H., 1994, MACHINE LEARNING P 1, DOI 10.1016/B978-1-55860-335-6.50023-4; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P284; Langley P., 1994, AAAI FALL S REL, P140; Loscalzo S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P567; Mani S, 1999, J AM MED INFORM ASSN, P315; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Omidiran D, 2010, J MACH LEARN RES, V11, P2361; Perkins S., 2003, P 20 INT C MACH LEAR, P592; Rodriguez-Lujan I, 2010, J MACH LEARN RES, V11, P1491; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Song L., 2007, P 24 INT C MACHINE L, P823, DOI [10.1145/1273496.1273600, DOI 10.1145/1273496.1273600]; Spirtes P., 2000, CAUSATION PREDICTION; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tuv E, 2009, J MACH LEARN RES, V10, P1341; Ungar L., 2005, PROC 10TH INTL WORKS; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Weston J, 2001, ADV NEUR IN, V13, P668; Wu X., 2010, 27 INT C MACHINE LEA, P1159; Yu L, 2004, J MACH LEARN RES, V5, P1205; Yu L., 2008, P 14 ACM SIGKDD INT, DOI DOI 10.1145/1401890.1401986; Zhang T, 2009, J MACH LEARN RES, V10, P555; Zhang Z, 2011, KNOWL INF SYST, V27, P473, DOI 10.1007/s10115-010-0306-z; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhao Z, 2009, INTELL DATA ANAL, V13, P207, DOI 10.3233/IDA-2009-0364; Zhou J., 2005, P 11 ACM SIGKDD INT, P384, DOI DOI 10.1145/1081870.1081914; Zhou J, 2006, J MACH LEARN RES, V7, P1861; Zhu XQ, 2011, KNOWL INF SYST, V28, P523, DOI 10.1007/s10115-010-0331-y	46	162	183	6	86	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1178	1192		10.1109/TPAMI.2012.197	http://dx.doi.org/10.1109/TPAMI.2012.197			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520258	Green Submitted			2022-12-18	WOS:000316126800012
J	Liu, CJ				Liu, CJ			A Bayesian Discriminating Features Method for face detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes classifier; Bayesian Discriminating Features (BDF); discriminating feature analysis; face detection; statistical modeling; support nonfaces	OBJECT DETECTION; RECOGNITION; IMAGES	This paper presents a novel Bayesian Discriminating Features (BDF) method for multiple frontal face detection. The BDF method, which is trained on images from only one database, yet works on test images from diverse sources, displays robust generalization performance. The novelty of this paper comes from the integration of the discriminating feature analysis of the input image, the statistical modeling of face and nonface classes, and the Bayes classifier for multiple frontal face detection. First, feature analysis derives a discriminating feature vector by combining the input image, its 1 D Harr wavelet representation, and its amplitude projections. While the Harr wavelets produce an effective representation for object detection, the amplitude projections capture the vertical symmetric distributions and the horizontal characteristics of human face images. Second, statistical modeling estimates the conditional probability density functions, or PDFs, of the face and nonface classes, respectively. While the face class is usually modeled as a multivariate normal distribution, the nonface class is much more difficult to model due to the fact that it includes "the rest of the world." The estimation of such a broad category is, in practice, intractable. However, one can still derive a subset of the nonfaces that lie closest to the face class, and then model this particular subset as a multivariate normal distribution. Finally, the Bayes classifier applies the estimated conditional PDFs to detect multiple frontal faces in an image. Experimental results using 887 images (containing a total of 1,034 faces) from diverse image sources show the feasibility of the BDF method. In particular, the novel BDF method achieves 98.5 percent face detection accuracy with one false detection.	New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA	New Jersey Institute of Technology	Liu, CJ (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.	liu@cs.njit.edu						CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Dass SC, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P680, DOI 10.1109/ICCV.2001.937692; Fukunaga K., 1991, INTRO STAT PATTERN R, Vsecond; HEISELE B, 2000, AIM1687 MIT ART INT; HO P, 2001, AIM2001010 MIT ART I; Hsu RL, 2001, IEEE IMAGE PROC, P1046, DOI 10.1109/ICIP.2001.959228; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604; Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Qian RJ, 1997, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.1997.609318; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; SUNG KK, 1996, THESIS MIT; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; YANG MH, 2000, P 4 INT C AUT FAC GE, P70; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59	28	162	179	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					725	740		10.1109/TPAMI.2003.1201822	http://dx.doi.org/10.1109/TPAMI.2003.1201822			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP					2022-12-18	WOS:000182961300007
J	Tefas, A; Kotropoulos, C; Pitas, I				Tefas, A; Kotropoulos, C; Pitas, I			Using support vector machines to enhance the performance of elastic graph matching for frontal face authentication	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face authentication; elastic graph matching; Fisher's discriminant ratio; constrained least-squares optimization; Support Vector Machines	OBJECT RECOGNITION; EIGENFACES	A novel method for enhancing the performance of elastic graph matching in frontal face authentication is proposed. The starting point is to weigh the local similarity values at the nodes of an elastic graph according to their discriminatory power. Powerful and well-established optimization techniques are used to derive the weights of the linear combination. More specifically, we propose a novel approach that reformulates Fisher's discriminant ratio to a quadratic optimization problem subject to a set of inequality constraints by combining statistical pattern recognition and Support Vector Machines. Both linear and nonlinear Support Vector Machines are then constructed to yield the optimal separating hyperplanes and the optimal polynomial decision surfaces, respectively. The method has been applied to frontal face authentication on the M2VTS database. Experimental results indicate that the performance of morphological elastic graph matching is highly improved by using the proposed weighting technique.	Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54006, Greece	Aristotle University of Thessaloniki	Tefas, A (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Box 451, Thessaloniki 54006, Greece.	tefas@zeus.csd.auth.gr; costas@zeus.csd.auth.gr; pitas@zeus.csd.auth.gr	Tefas, Anastasios/F-1899-2010; Kotropoulos, Constantine/AAI-2364-2019; Kotropoulos, Constantine L/B-7928-2010; Tefas, Anastasios/ABA-2328-2020	Tefas, Anastasios/0000-0003-1288-3667; Kotropoulos, Constantine/0000-0001-9939-7930; Kotropoulos, Constantine L/0000-0001-9939-7930; 				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COTTRELL GW, 1990, P INT NEUR NETW C PA, V1, P322; Devijver PA, 1982, PATTERN RECOGNITION; Duc B, 1999, IEEE T IMAGE PROCESS, V8, P504, DOI 10.1109/83.753738; Etemad K, 1997, LECT NOTES COMPUT SC, V1206, P127; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; FLETCHER R, 1987, PRATICAL METHODS OPT; GUNN SR, 1998, MPTR9805 U SOUTH IM; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Kotropoulos C, 1997, INT CONF ACOUST SPEE, P2537, DOI 10.1109/ICASSP.1997.595305; Kotropoulos C, 2000, IEEE T IMAGE PROCESS, V9, P555, DOI 10.1109/83.841933; Kotropoulos C, 2000, PATTERN RECOGN, V33, P1935, DOI 10.1016/S0031-3203(99)00185-5; Kotropoulos CL, 2000, IEEE T MULTIMEDIA, V2, P14, DOI 10.1109/6046.825791; Kruger N, 1997, IEEE T PATTERN ANAL, V19, P764, DOI 10.1109/34.598233; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162; Osuna E., 1997, AIM1602 MIT ART INT; Phillips PJ, 1998, IEEE T IMAGE PROCESS, V7, P1150, DOI 10.1109/83.704308; Pigeon S, 1997, LECT NOTES COMPUT SC, V1206, P403, DOI 10.1007/BFb0016021; Pigeon S, 1998, SIGNAL PROCESS, V69, P59, DOI 10.1016/S0165-1684(98)00087-5; Schalkoff R, 1992, PATTERN RECOGN; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vapnik V.N, 1998, STAT LEARNING THEORY; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wiskott L, 1997, PATTERN RECOGN, V30, P837, DOI 10.1016/S0031-3203(96)00132-X; Wurtz RP, 1997, IEEE T PATTERN ANAL, V19, P769, DOI 10.1109/34.598234; YANG MS, 1994, COMPUT MATH APPL, V27, P1, DOI 10.1016/0898-1221(94)90071-X; Zhang J, 1997, P IEEE, V85, P1423, DOI 10.1109/5.628712	35	162	178	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2001	23	7					735	746		10.1109/34.935847	http://dx.doi.org/10.1109/34.935847			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	449TV					2022-12-18	WOS:000169704000004
J	Kim, G; Govindaraju, V				Kim, G; Govindaraju, V			A lexicon driven approach to handwritten word recognition for real-time applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten word recognition; segmentation algorithm; variable duration; chain code representation; dynamic programming	HIDDEN MARKOV MODEL; ALGORITHM; NETWORK; SEARCH	A fast method of handwritten word recognition suitable for real time applications is presented in this paper. Preprocessing, segmentation and feature extraction are implemented using a chain code representation of the word contour. Dynamic matching between characters of a lexicon entry and segment(s) of the input word image is used to rank the lexicon entries in order of best match. Variable duration for each character is defined and used during the matching. Experimental results prove that our approach using the variable duration outperforms the method using fixed duration in terms of both accuracy and speed. Speed of the entire recognition process is about 200 msec on a single SPARC-IO platform and the recognition accuracy is 96.8 percent are achieved for lexicon size of 10, on a database of postal words captured at 212 dpi.			Kim, G (corresponding author), SUNY BUFFALO,DEPT COMP SCI,CEDAR,520 LEE ENTRANCE,AMHERST,NY 14228, USA.							BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; Breuel T. M., 1994, P C DOC AN SYST KAIS, P109; BROWN MK, 1983, PATTERN RECOGN, V16, P447, DOI 10.1016/0031-3203(83)90049-3; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; CHEN MY, 1993, 3RD P INT WORKSH FRO, P82; COHEN E, 1994, IEEE T PATTERN ANAL, V16, P1049, DOI 10.1109/34.329003; Duda R.O., 1973, J ROYAL STAT SOC SER; FAVATA JT, 1993, THESIS STATE U NEW Y; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FREEMAN H, 1961, P NAT EL C, V17, P412; GILLIES A, 1992, 5TH P USPS ADV TECHN, P557; GOVINDARAJU V, 1993, 3 INT WORKSH FRONT H, P197; Guillevic D., 1994, 4 INT WORKSH FRONT H, P216; KALTENMEIER A, 1993, INT C DOC AN REC TSU, P139; Kim GH, 1996, P SOC PHOTO-OPT INS, V2660, P262, DOI 10.1117/12.234708; LEE CH, 1989, IEEE T ACOUST SPEECH, V37, P1649, DOI 10.1109/29.46547; LU CC, 1991, IEEE T COMMUN, V39, P1511, DOI 10.1109/26.103046; MADHVANATH S, 1995, 3 INT C DOC AN REC I, P82; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P284, DOI 10.1109/TASSP.1981.1163527; NEY H, 1992, IEEE T PATTERN ANAL, V14, P586, DOI 10.1109/34.134063; Rabiner L., 1993, FUNDAMENTALS SPEECH; SAKOE H, 1979, IEEE T ACOUST SPEECH, V27, P588, DOI 10.1109/TASSP.1979.1163310; SCHURMANN J, 1992, P IEEE, V80, P1101, DOI 10.1109/5.156473; Simon J. C., 1994, P C DOC AN SYST KAIS, P135; SIMON JC, 1992, P IEEE, V80, P1150, DOI 10.1109/5.156476; SRIHARI SN, 1992, P IEEE, V80, P1121; SRIHARI SN, 1995, 3 INT C DOC AN REC I, P5	28	162	169	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					366	379		10.1109/34.588017	http://dx.doi.org/10.1109/34.588017			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122		Green Published			2022-12-18	WOS:A1997WW12200007
J	WANDELL, BA				WANDELL, BA			THE SYNTHESIS AND ANALYSIS OF COLOR IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WANDELL, BA (corresponding author), STANFORD UNIV,DEPT PSYCHOL,STANFORD,CA 94305, USA.							Boynton R. M., 1979, HUMAN COLOR VISION; BUCHSBAUM G, 1984, J OPT SOC AM A, V1, P885, DOI 10.1364/JOSAA.1.000885; BUCHSBAUM G, 1980, J FRANKLIN I, V310; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; Cornsweet T., 1970, VISUAL PERCEPTION; Helson H, 1938, J EXP PSYCHOL, V23, P439, DOI 10.1037/h0060971; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; HORN BKP, 1984, COMPUT VISION GRAPH, V26, P135, DOI 10.1016/0734-189X(84)90180-4; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; MALONEY LT, 1984, THESIS STANFORD U ST; MALONEY LT, 1986, J OPT SOC AM, V1, P29; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; SALLSTROM P, 1973, 7309 I PHYS REP; SMITH VC, 1975, VISION RES, V15, P161, DOI 10.1016/0042-6989(75)90203-5; STILES WS, 1962, J OPT SOC AM, V52, P313, DOI 10.1364/JOSA.52.000313; STILES WS, 1977, J OPT SOC AM, V67, P779, DOI 10.1364/JOSA.67.000779; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; TORRANCE KE, 1966, J OPT SOC AM, V56, P916, DOI 10.1364/JOSA.56.000916; WANDELL B, 1984, P OSA ANN M, P21; WITKIN A, 1984, J OPT SOC AM, V12, pA1261	21	162	167	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					2	13		10.1109/TPAMI.1987.4767868	http://dx.doi.org/10.1109/TPAMI.1987.4767868			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869373	Green Submitted			2022-12-18	WOS:A1987F378500001
J	Lagorce, X; Orchard, G; Galluppi, F; Shi, BE; Benosman, RB				Lagorce, Xavier; Orchard, Garrick; Galluppi, Francesco; Shi, Bertram E.; Benosman, Ryad B.			HOTS: A Hierarchy of Event-Based Time-Surfaces for Pattern Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neuromorphic sensing; event-based vision; feature extraction	DRIVEN; SENSOR	This paper describes novel event-based spatio-temporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a four class canonical dynamic card pip task, achieving near 100 percent accuracy on each. We introduce a new seven class moving face recognition task, achieving 79 percent accuracy.	[Lagorce, Xavier; Galluppi, Francesco; Benosman, Ryad B.] Inst Natl Sante & Rech Med, Vis & Nat Computat Grp, F-75012 Paris, France; [Lagorce, Xavier; Galluppi, Francesco; Benosman, Ryad B.] Univ Paris 06, Inst Vis, Sorbonne Univ, F-75012 Paris, France; [Lagorce, Xavier; Galluppi, Francesco; Benosman, Ryad B.] CNRS, F-75012 Paris, France; [Orchard, Garrick] Natl Univ Singapore, Singapore Inst Neurotechnol SINAPSE, Singapore 119077, Singapore; [Shi, Bertram E.] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China; [Shi, Bertram E.] Hong Kong Univ Sci & Technol, Div Biomed Engn, Kowloon, Hong Kong, Peoples R China	Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Paris Cite; National University of Singapore; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology	Lagorce, X (corresponding author), Inst Natl Sante & Rech Med, Vis & Nat Computat Grp, F-75012 Paris, France.	xavier.lagorce@ens-cachan.fr; garrickorchard@nus.edu.sg; francesco.galluppi@inserm.fr; eebert@ust.hk; ryad.benosman@upmc.fr	Orchard, Garrick/M-7727-2014	Orchard, Garrick/0000-0002-1243-2711	French state funds; ANR within the Investissements d'Avenir programme [ANR-11-IDEX-0004-02]; European Union [604102]; Merlion Programme of the Institut Franais de Singapour; National University of Singapore	French state funds; ANR within the Investissements d'Avenir programme(French National Research Agency (ANR)); European Union(European Commission); Merlion Programme of the Institut Franais de Singapour; National University of Singapore(National University of Singapore)	This work was performed in the frame of the LABEX LIFE-SENSES [ANR-10-LABX-65] and was supported by French state funds managed by the ANR within the Investissements d'Avenir programme [ANR-11-IDEX-0004-02]. XL has been supported by the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement no 604102 (HBP). Franco-Singaporean collaboration on this project was supported by the Merlion Programme of the Institut Franais de Singapour, under administrative supervision of the French Ministry of Foreign Affairs and the National University of Singapore. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressly or implied, of the French Ministry of Foreign Affairs. The authors would also like to acknowledge discussion at the US National Science Foundation Telluride Neuromorphic Cognition Engineering Workshop.	Akolkar H, 2015, NEURAL COMPUT, V27, P561, DOI 10.1162/NECO_a_00703; Lenero-Bardallo JA, 2011, IEEE J SOLID-ST CIRC, V46, P1443, DOI 10.1109/JSSC.2011.2118490; Perez-Carrasco JA, 2013, IEEE T PATTERN ANAL, V35, P2706, DOI 10.1109/TPAMI.2013.71; Ballard DH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00254; Bhaskaran V., 1997, IMAGE VIDEO COMPRESS; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Boahen K. A., 1991, ADV NEURAL INFORMATI, V4, P764; Boahen KA, 2000, IEEE T CIRCUITS-II, V47, P416, DOI 10.1109/82.842110; Cao YQ, 2015, INT J COMPUT VISION, V113, P54, DOI 10.1007/s11263-014-0788-3; Chen SS, 2012, IEEE T PATTERN ANAL, V34, P302, DOI 10.1109/TPAMI.2011.120; Dean J., 2012, NIPS 12, V1, P1223; Folowosele F, 2011, IEEE J EM SEL TOP C, V1, P516, DOI 10.1109/JETCAS.2012.2183409; Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638; Ghosh R, 2014, BIOMED CIRC SYST C, P544, DOI 10.1109/BioCAS.2014.6981783; Gollisch T, 2010, NEURON, V65, P150, DOI 10.1016/j.neuron.2009.12.009; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Jaeger H, 2001, BONN GER GER NATL RE, V148, P13; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Lagorce X, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00046; Lagorce X, 2013, IEEE INT C INT ROBOT, P4214, DOI 10.1109/IROS.2013.6696960; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MAHOWALD MA, 1991, SCI AM, V264, P76, DOI 10.1038/scientificamerican0591-76; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; MEAD C, 1990, P IEEE, V78, P1629, DOI 10.1109/5.58356; O'Connor P, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00178; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Orchard G, 2015, IEEE T PATTERN ANAL, V37, P2028, DOI 10.1109/TPAMI.2015.2392947; Posch C, 2008, IEEE INT SYMP CIRC S, P2130, DOI 10.1109/ISCAS.2008.4541871; Posch C, 2014, P IEEE, V102, P1470, DOI 10.1109/JPROC.2014.2346153; Posch C, 2011, IEEE J SOLID-ST CIRC, V46, P259, DOI 10.1109/JSSC.2010.2085952; Reinhard E., 2010, HIGH DYNAMIC RANGE I; Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653; Serrano-Gotarredona T, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00481; Serrano-Gotarredona T, 2013, IEEE J SOLID-ST CIRC, V48, P827, DOI 10.1109/JSSC.2012.2230553; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Stocker AA, 2006, ANALOG INTEGR CIRC S, V46, P121, DOI 10.1007/s10470-005-0439-2; Tapson JC, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00153	39	161	166	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1346	1359		10.1109/TPAMI.2016.2574707	http://dx.doi.org/10.1109/TPAMI.2016.2574707			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27411216				2022-12-18	WOS:000402744400006
J	Yu, QY; Clausi, DA				Yu, Qiyao; Clausi, David A.			IRGS: Image Segmentation Using Edge Penalties and Region Growing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random field (MRF); Gaussian mixture; hybrid region and edge; region growing; Region Adjacency Graph (RAG)	UNSUPERVISED SEGMENTATION; MRF MODEL; WATERSHEDS; ALGORITHM; SELECTION; SNAKES; NOISY	This paper proposes an image segmentation method named iterative region growing using semantics (IRGS), which is characterized by two aspects. First, it uses graduated increased edge penalty (GIEP) functions within the traditional Markov random field (MRF) context model in formulating the objective functions. Second, IRGS uses a region growing technique in searching for the solutions to these objective functions. The proposed IRGS is an improvement over traditional MRF-based approaches in that the edge strength information is utilized and a more stable estimation of model parameters is achieved. Moreover, the IRGS method provides the possibility of building a hierarchical representation of the image content and allows various region features and even domain knowledge to be incorporated in the segmentation process. The algorithm has been successfully tested on several artificial images and synthetic aperture radar (SAR) images.	[Yu, Qiyao] Eutrovision Inc, Shanghai 20030, Peoples R China; [Clausi, David A.] Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	University of Waterloo	Yu, QY (corresponding author), Eutrovision Inc, Room 13E,468 Caoxi N, Shanghai 20030, Peoples R China.	qiyao.yu@eutrovision.com; dclausi@engmail.uwaterloo.ca	Clausi, David A/J-4613-2013		NSERC Networks of Centres of Excellence (NCE); Canadian Icer Service (CIS); CRYSYS (CRYospheric SYStern in Canada)	NSERC Networks of Centres of Excellence (NCE)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Icer Service (CIS); CRYSYS (CRYospheric SYStern in Canada)	RADARSAT images are copyright the Canadian Space Agency (CSA). The authors thank CIS for image and data provision and Professor Paul Fieguth for enlightening suggestions and discussions. This work has been supported by the NSERC Networks of Centres of Excellence (NCE) called GEOIDE (Geomantics for Informed Decisions), Canadian Icer Service (CIS), as well as CRYSYS (CRYospheric SYStern in Canada).	ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Alexander SK, 2003, IEEE IMAGE PROC, P249; Andrey P, 1998, IEEE T PATTERN ANAL, V20, P252, DOI 10.1109/34.667883; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; BESAG J, 1986, J R STAT SOC B, V48, P259; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CHENG L, 2003, P 16 INT C VIS INT J; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deng HW, 2004, PATTERN RECOGN, V37, P2323, DOI [10.1016/S0031-3203(04)00195-5, 10.1016/j.patcog.2004.04.015]; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Descombes X, 1999, IEEE T IMAGE PROCESS, V8, P954, DOI 10.1109/83.772239; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380; He XM, 2004, PROC CVPR IEEE, P695; Hernandez SE, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICIP.2000.899239; Huang R, 2004, PROC CVPR IEEE, P739; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kato T, 2001, NEOPLASIA, V3, P4, DOI 10.1038/sj.neo.7900132; Kato Z, 1996, GRAPH MODEL IM PROC, V58, P18, DOI 10.1006/gmip.1996.0002; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; Li S. Z., 2001, COMP SCI W; Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433; MCCANE B, 1997, P 1 INT C KNOWL BAS, V1, P72; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Rignot E, 1992, IEEE T IMAGE PROCESS, V1, P281, DOI 10.1109/83.148603; SAMADANI R, 1995, IEEE T IMAGE PROCESS, V4, P1182, DOI 10.1109/83.403427; Sarkar A, 2000, IEEE T IMAGE PROCESS, V9, P801, DOI 10.1109/83.841527; Sonka M., 1998, IMAGE PROCESSING ANA; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WESOLKOWSKI S, 2004, P INT C IM AN REC; Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945; WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; YU Q, 2005, P 2 CAN C COMP ROB V; YU Q, 2007, IEEE T GEOSCIENCE RE, V45; YUE B, 2001, THESIS U WATERLOO; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	49	161	187	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2126	2139		10.1109/TPAMI.2008.15	http://dx.doi.org/10.1109/TPAMI.2008.15			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988947				2022-12-18	WOS:000260033900005
J	MAVER, J; BAJCSY, R				MAVER, J; BAJCSY, R			OCCLUSIONS AS A GUIDE FOR PLANNING THE NEXT VIEW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ACTIVE SENSING; AUTONOMOUS EXPLORATION; LASER RANGE FINDER; NEXT VIEW PLANNING; OCCLUSIONS; ROBOT VISION; SCENE ANALYSIS; 3-D SCENES		To resolve the ambiguities that are caused by occlusions in images, we need to take sensor measurements from several different views. The task addressed in this paper deals with a strategy for acquiring 3-D data of an unknown scene. We must first answer this question: What knowledge is adequate to perform a specific task? Thinking in the spirit of purposive vision, to accomplish its task, a system does not need to understand the complete scene but must be able to recognize patterns and situations that are necessary for accomplishing the task. We have limited ourselves to range images obtained by a light stripe range finder. A priori knowledge given to the system is the knowledge of the sensor geometry. The foci of attention are occluded regions, i.e., only the scene at the borders of the occlusions is modeled to compute the next move. Since the system has knowledge of the sensor geometry, it can resolve the appearance of occlusions by analyzing them. The problem of 3-D data acquisition is divided into two subproblems due to two types of occlusions. An occlusion arises either when the reflected laser light does not reach the camera or when the directed laser light does not reach the scene surface. After taking the range image of a scene, the regions of no data due to the first kind of occlusion are extracted. The missing data are acquired by rotating the sensor system in the scanning plane, which is defined by the first scan. After a complete image of the surface illuminated from the first scanning plane has been built, the regions of missing data due to the second kind of occlusions are located. Then, the directions of the next scanning planes for further 3-D data acquisition are computed.	UNIV PENN,DEPT COMP & INFORMAT SCI,PHILADELPHIA,PA 19104	University of Pennsylvania	MAVER, J (corresponding author), UNIV LJUBLJANA,DEPT ELECT ENGN & COMP SCI,COMP VIS LAB,LJUBLJANA,SLOVENIA.							AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; ALOIMONOS J, 1990, 10TH P INT C PATT RE, P346; CONNOLLY C, 1985, IEEE INT C ROB AUT, P432; COWAN CK, 1989, IEEE T ROBOTIC AUTOM, P509; FISK S, 1978, J COMB THEORY B, V24, P374, DOI 10.1016/0095-8956(78)90059-X; HUTCHINSON SA, 1989, IEEE T ROBOTIC AUTOM, V5, P765, DOI 10.1109/70.88098; KAHN J, 1980, IBM RJ3021 RES REP; MAVER J, 1991, MSCIS9127 GRASP LAB, P257; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; Sakane S., 1987, Advanced Robotics, V2, P149, DOI 10.1163/156855387X00138; SAKANE S, 1987, 3RD P INT C ADV ROB, P163; SHIN SY, 1989, IEEE T ROBOTIC AUTOM, V5, P202, DOI 10.1109/70.88040; TARABANIS K, 1989, MAY P IMAG UND WORKS, P893; TOUSSAINT GT, 1983, NOV P ROB INT PROD C; TSIKOS CJ, 1989, LASER RANGE IMAGING; Whaite P., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P690, DOI 10.1109/ICCV.1990.139620	17	161	178	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					417	433		10.1109/34.211463	http://dx.doi.org/10.1109/34.211463			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470		Green Submitted			2022-12-18	WOS:A1993LB47000001
J	Li, ZC; Tang, JH; Mei, T				Li, Zechao; Tang, Jinhui; Mei, Tao			Deep Collaborative Embedding for Social Image Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image understanding; embedding; deep learning; tag completion; image retrieval	NONNEGATIVE MATRIX FACTORIZATION; TAG COMPLETION; RETRIEVAL; ANNOTATION; OBJECTS; SPACE	In this work, we investigate the problem of learning knowledge from the massive community-contributed images with rich weakly-supervised context information, which can benefit multiple image understanding tasks simultaneously, such as social image tag refinement and assignment, content-based image retrieval, tag-based image retrieval and tag expansion. Towards this end, we propose a Deep Collaborative Embedding (DCE) model to uncover a unified latent space for images and tags. The proposed method incorporates the end-to-end learning and collaborative factor analysis in one unified framework for the optimal compatibility of representation learning and latent space discovery. A nonnegative and discrete refined tagging matrix is learned to guide the end-to-end learning. To collaboratively explore the rich context information of social images, the proposed method integrates the weakly-supervised image-tag correlation, image correlation and tag correlation simultaneously and seamlessly. The proposed model is also extended to embed new tags in the uncovered space. To verify the effectiveness of the proposed method, extensive experiments are conducted on two widely-used social image benchmarks for multiple social image understanding tasks. The encouraging performance of the proposed method over the state-of-the-art approaches demonstrates its superiority.	[Li, Zechao; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, 200 Xiaolingwei Rd, Nanjing 210094, Jiangsu, Peoples R China; [Mei, Tao] North Star Century Ctr, JD AI Res, Bldg A,8 Beichen West St, Beijing 100105, Peoples R China	Nanjing University of Science & Technology	Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, 200 Xiaolingwei Rd, Nanjing 210094, Jiangsu, Peoples R China.	zechao.li@njust.edu.cn; jinhuitang@njust.edu.cn; tmei@jd.com	Mei, Tao/GQZ-0596-2022	Mei, Tao/0000-0002-5990-7307	973 Program [2014CB347600]; National Natural Science Foundation of China [61522203, 61772275, 61732007]; Natural Science Foundation of Jiangsu Province [BK20170033]	973 Program(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province)	This work was partially supported by the 973 Program (Project No. 2014CB347600), the National Natural Science Foundation of China (Grant No. 61522203, 61772275 and 61732007) and the Natural Science Foundation of Jiangsu Province (Grant BK20170033).	Andrew G., 2013, INT C MACH LEARN, p1247?1255; [Anonymous], 2010, P 16 ACM SIGKDD INT; [Anonymous], 2008, 16 INT C MULT MM 08; [Anonymous], 2008, P 25 INT C MACH LEAR; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chen L, 2012, IEEE T MULTIMEDIA, V14, P1057, DOI 10.1109/TMM.2012.2187435; Cheng Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1111, DOI 10.1145/2733373.2806294; Chiang K Y, 2015, ADV NEURAL INFORM PR, P3447; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Feng LN, 2016, IEEE T PATTERN ANAL, V38, P785, DOI 10.1109/TPAMI.2015.2469281; Feng ZY, 2014, LECT NOTES COMPUT SC, V8695, P424, DOI 10.1007/978-3-319-10584-0_28; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hong S, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487982; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3; Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459; Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525; Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598; Li XW, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.00039; Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725; Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140; Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035; Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461; Li Zheng, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1187, DOI 10.1145/1873951.1874183; Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212; Liu D, 2011, IEEE T MULTIMEDIA, V13, P702, DOI 10.1109/TMM.2011.2134078; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Liu J, 2010, INT CONF COMPUT AUTO, P491, DOI 10.1109/ICCAE.2010.5451908; Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Rasiwasia N, 2010, P 18 ACM INT C MULT, P251; Rodriguez-Vaamonde S, 2015, IEEE T PATTERN ANAL, V37, P1274, DOI 10.1109/TPAMI.2014.2366761; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Sharma G, 2015, IEEE I CONF COMP VIS, P1296, DOI 10.1109/ICCV.2015.153; Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160; Tang J., 2011, ACM T INTEL SYST TEC, P14, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]; Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882; Trigeorgis G, 2017, IEEE T PATTERN ANAL, V39, P417, DOI 10.1109/TPAMI.2016.2554555; Ulges A, 2011, IEEE T MULTIMEDIA, V13, P330, DOI 10.1109/TMM.2010.2101051; Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10; Wong RCF, 2008, IEEE T PATTERN ANAL, V30, P1933, DOI 10.1109/TPAMI.2008.125; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Xiao-YongWei Chong-Wah, 2007, P ACM INT C MULT, P981, DOI DOI 10.1145/1291233.1291447; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Zha Z.-J., 2009, P 17 ACM INT C MULT, P15, DOI DOI 10.1145/1631272.1631278; Zhu G., 2010, ACM MULT, P461	60	160	168	6	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2070	2083		10.1109/TPAMI.2018.2852750	http://dx.doi.org/10.1109/TPAMI.2018.2852750			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994391				2022-12-18	WOS:000480343900003
J	Zhang, JM; Sclaroff, S				Zhang, Jianming; Sclaroff, Stan			Exploiting Surroundedness for Saliency Detection: A Boolean Map Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency detection; Boolean map; eye fixation prediction; minimum barrier distance	VISUAL-ATTENTION; IMAGE-ANALYSIS; GAZE; SEGMENTATION; ALGORITHMS; TRANSFORM; CONTRAST; MODEL; SHAPE	We demonstrate the usefulness of surroundedness for eye fixation prediction by proposing a Boolean Map based Saliency model (BMS). In our formulation, an image is characterized by a set of binary images, which are generated by randomly thresholding the image's feature maps in a whitened feature space. Based on a Gestalt principle of figure-ground segregation, BMS computes a saliency map by discovering surrounded regions via topological analysis of Boolean maps. Furthermore, we draw a connection between BMS and the Minimum Barrier Distance to provide insight into why and how BMS can properly captures the surroundedness cue via Boolean maps. The strength of BMS is verified by its simplicity, efficiency and superior performance compared with 10 state-of-the-art methods on seven eye tracking benchmark datasets.	[Zhang, Jianming; Sclaroff, Stan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	Boston University	Zhang, JM; Sclaroff, S (corresponding author), Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.	jmzhang@bu.edu; sclaroff@cs.bu.edu	Zhang, Jianming/B-1665-2017	Zhang, Jianming/0000-0002-9954-6294	US National Science Foundation [1059218, 1029430]; Div Of Information & Intelligent Systems [1029430] Funding Source: National Science Foundation	US National Science Foundation(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This research was supported in part through US National Science Foundation grants 1059218 and 1029430. The authors thank Dr. Zhe Lin, Dr. Xiaohui Shen, Dr. Brian Price and Dr. Radomir Mech for helpful discussions regarding this work.	Baylis GC, 2001, NAT NEUROSCI, V4, P937, DOI 10.1038/nn0901-937; Borji A., 2014, ARXIV E PRINTS; Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Cerf M., 2008, ADV NEURAL INFORM PR, V20, P241, DOI DOI 10.1145/2185520.2185525; CHEN L, 1982, SCIENCE, V218, P699, DOI 10.1126/science.7134969; Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401; Ciesielski KC, 2014, COMPUT VIS IMAGE UND, V123, P53, DOI 10.1016/j.cviu.2014.03.007; Devroye L., 1986, NONUNIFORM RANDOM VA, P61; Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676; Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Gopalakrishnan V, 2009, PROC CVPR IEEE, P1698, DOI 10.1109/CVPRW.2009.5206767; Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028; Han X., 2014, P INCF JAP NOD INT W; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Huang LQ, 2007, PSYCHOL REV, V114, P599, DOI 10.1037/0033-295X.114.3.599; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; ITTI L, 2009, VISION RES, V49, P1295, DOI DOI 10.1016/J.VISRES.2008.09.007; Judd T., 2012, MIT CSAIL TR; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kienzle W, 2007, ADV NEURAL INFORM PR, P689; Kimchi R, 2008, PSYCHOL SCI, V19, P660, DOI 10.1111/j.1467-9280.2008.02140.x; Koffka K., 1935, PRINCIPLES GESTALT P; Kootstra G., 2008, PROC BRIT MACH VIS C, P1; Kourtzi Z, 2001, SCIENCE, V293, P1506, DOI 10.1126/science.1061133; Kummerer M., 2015, P ICLR WORKSH; Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147; Lu SJ, 2014, IEEE T PATTERN ANAL, V36, P195, DOI 10.1109/TPAMI.2013.158; Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573; MARAGOS P, 1990, IEEE T PATTERN ANAL, V12, P498, DOI 10.1109/34.55110; Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60; Mazza V, 2005, PSYCHOL RES-PSYCH FO, V69, P201, DOI 10.1007/s00426-004-0174-9; Palmer S.E., 1999, VISION SCI PHOTONS P; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Rosenholtz R, 2001, PERCEPT PSYCHOPHYS, V63, P476, DOI 10.3758/BF03194414; Rubin E., 1958, READINGS PERCEPTION, P194; Rutishauser U, 2004, PROC CVPR IEEE, P37; Saha PK, 2002, COMPUT VIS IMAGE UND, V86, P171, DOI 10.1006/cviu.2002.0974; Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Strand R, 2013, COMPUT VIS IMAGE UND, V117, P429, DOI 10.1016/j.cviu.2012.10.011; Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yun KW, 2013, PROC CVPR IEEE, P739, DOI 10.1109/CVPR.2013.101; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhu WH, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.4.043006	61	160	166	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					889	902		10.1109/TPAMI.2015.2473844	http://dx.doi.org/10.1109/TPAMI.2015.2473844			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26336114	hybrid			2022-12-18	WOS:000374164700005
J	Lin, YY; Liu, TL; Fuh, CS				Lin, Yen-Yu; Liu, Tyng-Luh; Fuh, Chiou-Shann			Multiple Kernel Learning for Dimensionality Reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; multiple kernel learning; object categorization; image clustering; face recognition	OBJECT RECOGNITION; CLASSIFICATION; ILLUMINATION; SCALE; SHAPE	In solving complex visual learning tasks, adopting multiple descriptors to more precisely characterize the data has been a feasible way for improving performance. The resulting data representations are typically high-dimensional and assume diverse forms. Hence, finding a way of transforming them into a unified space of lower dimension generally facilitates the underlying tasks such as object recognition or clustering. To this end, the proposed approach (termed MKL-DR) generalizes the framework of multiple kernel learning for dimensionality reduction, and distinguishes itself with the following three main contributions: First, our method provides the convenience of using diverse image descriptors to describe useful characteristics of various aspects about the underlying data. Second, it extends a broad set of existing dimensionality reduction techniques to consider multiple kernel learning, and consequently improves their effectiveness. Third, by focusing on the techniques pertaining to dimensionality reduction, the formulation introduces a new class of applications with the multiple kernel learning framework to address not only the supervised learning problems but also the unsupervised and semi-supervised ones.	[Lin, Yen-Yu; Liu, Tyng-Luh] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan; [Fuh, Chiou-Shann] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Academia Sinica - Taiwan; National Taiwan University	Lin, YY (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.	yylin@iis.sinica.edu.tw; liutyng@iis.sinica.edu.tw; fuh@csie.ntu.edu.tw		Fuh, Chiou-Shann/0000-0002-6174-2556; Lin, Yen-Yu/0000-0002-7183-6070	 [95-2221-E-001-031-MY3];  [97-2221-E-001-019-MY3]	; 	The authors would like to thank the anonymous reviewers for their comments. This work is supported in part by grants 95-2221-E-001-031-MY3 and 97-2221-E-001-019-MY3.	[Anonymous], 2007, PASCAL VISUAL OBJECT; Bach F.R., 2004, P INT C MACH LEARN; Berg AC, 2005, PROC CVPR IEEE, P26; Berg AC, 2001, PROC CVPR IEEE, P607; Boiman O., 2008, P IEEE C COMP VIS PA; BOSCH A., 2007, P IEEE INT C COMP VI; Cai D, 2007, P IEEE INT C COMP VI; Carreira J., 2010, P IEEE C COMP VIS PA; Chen CP, 2005, IEEE I CONF COMP VIS, P1089; Chen HT, 2005, PROC CVPR IEEE, P846; Christoudias, 2009, BAYESIAN LOCALIZED M; Cox T. F., 1994, MULTIDIMENTIONAL SCA; DUECK D, 2007, P IEEE INT C COMP VI; Fei-Fei L., 2004, P IEEE COMP VIS PATT; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Frome A., 2007, P IEEE INT C COMP VI; Frome A., 2006, NIPS, P417; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Gehler P.V., 2009, P IEEE INT C COMP VI; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10; Gu┬nen M., 2008, P 25 INT C MACH LEAR, P352, DOI DOI 10.1145/1390156.1390201; He X., 2003, ADV NEURAL INFORM PR; Holub AD, 2005, IEEE I CONF COMP VIS, P136; Janardan R., 2004, ADV NEURAL INF PROCE, V17; Joliffe I. T., 1986, PRINCIPAL COMPONENT; Kapoor A, 2010, INT J COMPUT VISION, V88, P169, DOI 10.1007/s11263-009-0268-3; Kim SJ, 2006, P 23 INT C MACH LEAR, P465, DOI DOI 10.1145/1143844.1143903; KUMAR A, 2007, P IEEE INT C COMP VI; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lin Y., 2007, P IEEE C COMP VIS PA; Lin Y.-Y., 2008, ADV NEURAL INFORM PR, P961; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Mutch J, 2006, P IEEE C COMP VIS PA, P11, DOI [10.1109/CVPR.2006.200, DOI 10.1109/CVPR.2006.200]; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Rakotomamonjy A., 2007, P 24 INT C MACH LEAR, V227, P775, DOI DOI 10.1145/1273496.1273594; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Serre T, 2005, PROC CVPR IEEE, P994; Shechtman E, 2007, P IEEE C COMP VIS PA; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TODOROVIC S, 2008, P IEEE C COMP VIS PA; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; VARMA M, 2007, P IEEE INT C COMP VI; VEDALDI A., 2009, P IEEE INT C COMP VI; Wang Hao, 2007, P IEEE C COMP VIS PA; Wu M, 2006, ADV NEURAL INFORM PR, P1529; Yang J., 2009, P IEEE INT C COMP VI; Ye J., 2004, P 10 ACM SIGKDD INT, P354, DOI DOI 10.1145/1014052.1014092; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]; ZHU J, 2005, MULTICLASS ADABOOST	59	160	170	0	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1147	1160		10.1109/TPAMI.2010.183	http://dx.doi.org/10.1109/TPAMI.2010.183			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20921580	Green Submitted			2022-12-18	WOS:000289524000006
J	Kulis, B; Jain, P; Grauman, K				Kulis, Brian; Jain, Prateek; Grauman, Kristen			Fast Similarity Search for Learned Metrics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Metric learning; similarity search; locality-sensitive hashing; LogDet divergence; kernel learning; image search	KERNEL	We introduce a method that enables scalable similarity search for learned metrics. Given pairwise similarity and dissimilarity constraints between some examples, we learn a Mahalanobis distance function that captures the examples' underlying relationships well. To allow sublinear time similarity search under the learned metric, we show how to encode the learned metric parameterization into randomized locality-sensitive hash functions. We further formulate an indirect solution that enables metric learning and hashing for vector spaces whose high dimensionality makes it infeasible to learn an explicit transformation over the feature dimensions. We demonstrate the approach applied to a variety of image data sets, as well as a systems data set. The learned metrics improve accuracy relative to commonly used metric baselines, while our hashing construction enables efficient indexing with learned distances and very large databases.	[Kulis, Brian] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Kulis, Brian] Univ Calif Berkeley, Int Comp Sci Inst, Berkeley, CA 94720 USA; [Jain, Prateek; Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of Texas System; University of Texas Austin	Kulis, B (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, 387 Soda Hall, Berkeley, CA 94720 USA.	kulis@eecs.berkeley.edu; pjain@cs.utexas.edu; grauman@cs.utexas.edu			US National Science Foundation (NSF) [0747356, EIA-0303609]; Microsoft Research; US Defense Advanced Research Projects Agency (DARPA) VIRAT; Henry Luce Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Microsoft Research(Microsoft); US Defense Advanced Research Projects Agency (DARPA) VIRAT(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Henry Luce Foundation	The authors would like to thank Yong Jae Lee and Greg Shakhnarovich for helpful discussions and for sharing the Flickr and Poser data, and Simon Winder, Matthew Brown, and Gang Hua for making the patch image data available. This research was supported in part by the US National Science Foundation (NSF) CAREER 0747356, Microsoft Research, US Defense Advanced Research Projects Agency (DARPA) VIRAT, NSF EIA-0303609, and the Henry Luce Foundation.	ATHITSOS V, 2003, P IEEE C COMP VIS PA, P3; ATHITSOS V, 2004, P IEEE C COMP VIS PA; BADOIU M, 2004, P 20 S COMP GEOM; Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; BEIS J, 1997, P IEEE C COMP VIS PA; Bosch A., 2007, P 6 ACM INT C IM VID, P30; CHARIKAR M, 2002, P ACM ANN S THEOR CO; CRAMMER K, 2002, ADV NEURAL INFORM PR; Datar M., 2004, P ANN S COMP GEOM; Davis J.V., 2007, P INT C MACH LEARN; Duda R.O., 2001, PATTERN CLASSIFICATI; Friedman J. H., 1977, ACM T MATH SOFTWARE, V3, P209, DOI DOI 10.1145/355744.355745; Frome A., 2007, P IEEE INT C COMP VI; FROME A, 2007, ADV NEURAL INFORM PR, V19; GEORGESCU B, 2003, P IEEE C COMP VIS PA; Globerson A., 2005, ADV NEURAL INFORM PR; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Goldberger J, 2004, ADV NEURAL INF PROCE, V17; GRAUMAN K, 2007, ADV NEURAL INFORM PR; GRAUMAN K, 2007, P IEEE C COMP VIS PA; GRAUMAN K, 2005, P IEEE C COMP VIS; Grauman K, 2007, J MACH LEARN RES, V8, P725; HA J, 2007, P C PROGR LANG DES I; Hadsell R, 2006, IEEE C COMP VIS PATT, V2, P1735; HERTZ T, 2004, P IEEE C COMP VIS PA; HERTZ T, 2006, P INT C MACH LEARN; Hua G, 2007, P IEEE INT C COMP VI; INDYK P, 2003, P INT WORKSH STAT CO; INDYK P, 1998, P 30 ANN S THEOR COM; Jain P., 2008, P IEEE C COMP VIS PA; JAIN P, 2007, LEARNING DISCRIMINAT; Lazebnik S., 2006, P IEEE C COMP VIS PA; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; LING H, 2007, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Muja M., 2009, P INT C COMP VIS THE; Nister D., 2006, P 2006 IEEE COMP SOC; Odone F, 2005, IEEE T IMAGE PROCESS, V14, P169, DOI 10.1109/TIP.2004.840701; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schultz M., 2003, ADV NEURAL INFORM PR; Shakhnarovich G., 2003, P IEEE INT C COMP VI; SIVIC J, 2004, P IEEE C COMP VIS PA; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; TAYCHER L, 2006, P IEEE C COMP VIS PA; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Torralba A., 2008, P IEEE C COMP VIS PA; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VARMA M, 2007, P IEEE INT C COMP VI; Weinberger K., 2006, ADV NEURAL INFORM PR; Xing E., 2002, P ADV NEUR INF PROC, V15, P1; ZHANG H, 2006, P IEEE C COMP VIS PA	55	160	178	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2143	2157		10.1109/TPAMI.2009.151	http://dx.doi.org/10.1109/TPAMI.2009.151			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834137				2022-12-18	WOS:000271140100004
J	Schomaker, L; Bulacu, M				Schomaker, L; Bulacu, M			Automatic writer identification using connected-component contours and edge-based features of uppercase western script	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						writer identification; connected-component contours; edge-orientation features; stochastic allograph emission model	ONLINE; SKILL	In this paper, a new technique for offline writer identification is presented, using connected-component contours (COCOCOs or CO(3)s) in uppercase handwritten samples. In our model, the writer is considered to be characterized by a stochastic pattern generator, producing a family of connected components for the uppercase character set. Using a codebook of CO(3)s from an independent training set of 100 writers, the probability-density function (PDF) of CO(3)s was computed for an independent test set containing 150 unseen writers. Results revealed a high-sensitivity of the CO3 PDF for identifying individual writers on the basis of a single sentence of uppercase characters. The proposed automatic approach bridges the gap between image-statistics approaches on one end and manually measured allograph features of individual characters on the other end. Combining the CO3 PDF with an independent edge-based orientation and curvature PDF yielded very high correct identification rates.	Univ Groningen, AI Inst, NL-9712 TS Groningen, Netherlands	University of Groningen	Schomaker, L (corresponding author), Univ Groningen, AI Inst, Grote Kuisstr 2-1, NL-9712 TS Groningen, Netherlands.	schomaker@ai.rug.nl; bulacu@ai.rug.nl	Schomaker, Lambert RB/A-9489-2008; Schomaker, Lambert/GYU-5840-2022	Schomaker, Lambert RB/0000-0003-2351-930X; 				Benecke M, 1997, NATURWISSENSCHAFTEN, V84, P181, DOI 10.1007/s001140050375; BROEDER A, 2003, THESIS LEIDEN U, P349; Bulacu M, 2003, PROC INT CONF DOC, P937; Bulacu M, 2003, LECT NOTES COMPUT SC, V2756, P460; Crettez J.-P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P489, DOI 10.1109/ICDAR.1995.599041; Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4; DAVIS G, 1998, APPL COMPUTATIONAL C, V1; DEVLIN B, 1992, J AM STAT ASSOC, V87, P337; Doermann D. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P162, DOI 10.1109/CVPR.1992.223211; DOOIJES EH, 1983, ACTA PSYCHOL, V54, P99, DOI 10.1016/0001-6918(83)90026-4; Francks C, 2003, AM J HUM GENET, V72, P499, DOI 10.1086/367548; Francois J, 1998, MICROSCOPIC ANATOMY OF INVERTEBRATES, VOL 11 A-C, P17; Franke K., 2001, International Journal on Document Analysis and Recognition, V3, P218, DOI 10.1007/PL00013565; Gulcher JR, 1997, NAT GENET, V17, P84, DOI 10.1038/ng0997-84; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; JEAN G, 1997, WRITING STORY ALPHAB; Kohonen T., 1988, SELF ORG ASS MEMORY; KONDO S, 1986, P 8 INT C PATT REC P, P562; MAARSE F, 1988, HUMAN COMPUTER INTER, P353; MAARSE FJ, 1983, ACTA PSYCHOL, V54, P131, DOI 10.1016/0001-6918(83)90028-8; Marti UV, 2001, PROC INT CONF DOC, P101, DOI 10.1109/ICDAR.2001.953763; Moler E, 1998, J FORENSIC SCI, V43, P689; MORITZ E, 1990, P IEEE INT C SYST MA, P256; Plamondon R, 1998, BIOL CYBERN, V78, P119, DOI 10.1007/s004220050419; PLAMONDON R, 1989, IEEE T SYST MAN CYB, V19, P1060, DOI 10.1109/21.44021; Said HES, 2000, PATTERN RECOGN, V33, P149, DOI 10.1016/S0031-3203(99)00006-0; SCHMIDT RA, 1975, PSYCHOL REV, V82, P225, DOI 10.1037/h0076770; Schomaker L., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P585; Schomaker L, 2003, IEEE IMAGE PROC, P545; Schomaker L, 1998, ELECTRON COMMUN ENG, V10, P93, DOI 10.1049/ecej:19980302; SCHOMAKER L, 1993, PATTERN RECOGN, V26, P443, DOI 10.1016/0031-3203(93)90171-R; SCHOMAKER L, 1994, P EUR WORKSH HANDW A, P4; SCHOMAKER L, 1991, THESIS U NIJMEGEN NE; Schomaker L.R.B., 1989, COMPUTER RECOGNITION, P153, DOI [10.1142/9789814434195_0012, DOI 10.1142/9789814434195_0012]; SCHOMAKER LRB, 1990, BIOL CYBERN, V63, P277, DOI 10.1007/BF00203451; Srihari S., 2002, J FORENSIC SCI, V47, P1, DOI DOI 10.1520/JFS15447J; VANERP M, 2003, P 11 C INT GRAPH SOC, P282; VANGALEN GP, 1993, ACTA PSYCHOL, V82, P161, DOI 10.1016/0001-6918(93)90010-O; Vuurpijl L., 2003, International Journal on Document Analysis and Recognition, V5, P213, DOI 10.1007/s10032-003-0104-1; Vuurpijl L, 1997, PROC INT CONF DOC, P387, DOI 10.1109/ICDAR.1997.619876; Zhu Y, 2000, INT C PATT RECOG, P797, DOI 10.1109/ICPR.2000.906196	41	160	164	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					787	798		10.1109/TPAMI.2004.18	http://dx.doi.org/10.1109/TPAMI.2004.18			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579938	Green Submitted			2022-12-18	WOS:000220756500011
J	ROACH, JW; AGGARWAL, JK				ROACH, JW; AGGARWAL, JK			DETERMINING THE MOVEMENT OF OBJECTS FROM A SEQUENCE OF IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS,DEPT ELECT ENGN,AUSTIN,TX 78712	University of Texas System; University of Texas Austin	ROACH, JW (corresponding author), UNIV TEXAS,DEPT COMP SCI,AUSTIN,TX 78712, USA.							AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; BADLER N, 1975, TR80 U TOR; BADLER NI, 1975, THESIS U TORONTO TOR; BRAUNSTEIN M, 1976, DEPTH PERCEPTION MOT; BROWN KM, 1972, NUMER MATH, V18, P289; CHOW WK, 1977, IEEE T COMPUT, V26, P179, DOI 10.1109/TC.1977.5009299; COFFIN J, 1911, VECTOR ANAL; Duda R. O, PATTERN CLASSIFICATI, V01; Endlich R.M., 1971, J APPL METEOROL CLIM, V10, P105; FLETCHER R, 1963, COMPUT J, V6, P163, DOI 10.1093/comjnl/6.2.163; GANAPATHY S, 1975, AIM272 STANF U; GANAPATHY S, 1975, THESIS STANFORD U ST; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; Leese J.A., 1971, J APPL METEOR, V10, P118, DOI [10.1175/1520-0450(1971)0102.0.CO;2, DOI 10.1175/1520-0450(1971)0102.0.CO;2]; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; MARQUARDT DW, 1963, J SIAM, V11; MARTIN WN, 1979, PATTERN RECOGN, V11, P169, DOI 10.1016/0031-3203(79)90004-9; NEWMAN WM, 1973, PRINCIPLES INTERACTI; QUAM LH, 1974, AIM254 STANF U; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; ROBERTS LG, 1977, COMPUTER METHODS IMA, P285; SOBEL I, AIJ, V5, P185; Thompson M., 1966, MANUAL PHOTOGRAMMETR, V3rd; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, 1976, AI476 MIT ART INT LA; WILLIAMS TD, 1979, APR WORKSH COMP AN T; YAKIMOVSKY Y, COMPUT GRAPHICS IMAG, V7, P195	28	160	171	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					554	562		10.1109/TPAMI.1980.6447703	http://dx.doi.org/10.1109/TPAMI.1980.6447703			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200009
J	Zhang, XY; Yin, F; Zhang, YM; Liu, CL; Bengio, Y				Zhang, Xu-Yao; Yin, Fei; Zhang, Yan-Ming; Liu, Cheng-Lin; Bengio, Yoshua			Drawing and Recognizing Chinese Characters with Recurrent Neural Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Recurrent neural network; LSTM; GRU; discriminative model; generative model; handwriting	HANDWRITING RECOGNITION; ONLINE; ORDER	Recent deep learning based approaches have achieved great success on handwriting recognition. Chinese characters are among the most widely adopted writing systems in the world. Previous research has mainly focused on recognizing handwritten Chinese characters. However, recognition is only one aspect for understanding a language, another challenging and interesting task is to teach a machine to automatically write (pictographic) Chinese characters. In this paper, we propose a framework by using the recurrent neural network (RNN) as both a discriminative model for recognizing Chinese characters and a generative model for drawing (generating) Chinese characters. To recognize Chinese characters, previous methods usually adopt the convolutional neural network (CNN) models which require transforming the online handwriting trajectory into image-like representations. Instead, our RNN based approach is an end-to-end system which directly deals with the sequential structure and does not require any domain-specific knowledge. With the RNN system (combining an LSTM and GRU), state-of-the-art performance can be achieved on the ICDAR-2013 competition database. Furthermore, under the RNN framework, a conditional generative model with character embedding is proposed for automatically drawing recognizable Chinese characters. The generated characters (in vector format) are human-readable and also can be recognized by the discriminative RNN model with high accuracy. Experimental results verify the effectiveness of using RNNs as both generative and discriminative models for the tasks of drawing and recognizing Chinese characters.	[Zhang, Xu-Yao; Yin, Fei; Zhang, Yan-Ming; Liu, Cheng-Lin] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China; [Liu, Cheng-Lin] Univ Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100049, Peoples R China; [Bengio, Yoshua] Univ Montreal, MILA Lab, Montreal, PQ H3T 1J4, Canada	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Universite de Montreal	Zhang, XY (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.	xyz@nlpr.ia.ac.cn; fyin@nlpr.ia.ac.cn; ymzhang@nlpr.ia.ac.cn; liucl@nlpr.ia.ac.cn; yoshua.bengio@umontreal.ca		Zhang, Xu-Yao/0000-0001-9260-188X	Strategic Priority Research Program of the Chinese Academy of Sciences [XDB02060009]; National Natural Science Foundation of China [61403380, 61573355]	Strategic Priority Research Program of the Chinese Academy of Sciences(Chinese Academy of Sciences); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the Strategic Priority Research Program of the Chinese Academy of Sciences under Grant XDB02060009, and the National Natural Science Foundation of China under Grants 61403380 and 61573355.	[Anonymous], 2015, GENERATING OFFLINE C; [Anonymous], 2015, GENERATING ONLINE FA; Bastien F., 2012, DEEP LEARN UNS FEAT; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y., 2014, ARXIV14061078; Bengio Y., 1994, P ADV NEUR INF PROC, P937; Bergstra J., 2010, P PYTH SCI COMP C SC, V4, P1, DOI DOI 10.25080/MAJORA-92BF1922-003; Bouthillier X., 2015, ARXIV150608700; Chen L, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P695, DOI 10.1109/ACPR.2015.7486592; Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044; Chung Junyoung, 2014, NIPS 2014 WORKSH DEE; Ciresan D., 2013, MULTICOLUMN DEEP NEU; Denton Emily L, 2015, NEURIPS, V2, P4; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Graham B., 2013, ARXIV13080371; Graves A., 2014, ARXIV14105401; Graves A., 2006, P 23 INT C MACH LEAR, P369; Graves A, 2013, ARXIV13080850; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Im D., 2016, GENERATING IMAGES RE; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; Kato Y, 2000, IEEE T PATTERN ANAL, V22, P938, DOI 10.1109/34.877517; Kim IJ, 2015, INT J DOC ANAL RECOG, V18, P1, DOI 10.1007/s10032-014-0229-4; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P., 2013, AUTO ENCODING VARIAT; Lamb A., 2016, ARXIV160203220; Larochelle H., 2011, INT C ART INT STAT; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021; Liu CL, 2011, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2011.291; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu CH, 2010, IEEE ICC; Liu CL, 2005, PATTERN RECOGN, V38, P2242, DOI 10.1016/j.patcog.2005.04.019; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182; Messina R, 2015, PROC INT CONF DOC, P171; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Qiao Y, 2006, IEEE T PATTERN ANAL, V28, P1724, DOI 10.1109/TPAMI.2006.216; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264; Weston J., 2015, PROCEEDING 3 INT C L, P1; Wu CP, 2014, INT CONF FRONT HAND, P291, DOI 10.1109/ICFHR.2014.56; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang W, 2015, ARXIV150804945; Yang W., 2015, ARXIV150505354; Yang WX, 2015, PROC INT CONF DOC, P546, DOI 10.1109/ICDAR.2015.7333821; Yin F, 2013, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2013.218; Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005; Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881; Zhou XD, 2013, IEEE T PATTERN ANAL, V35, P2413, DOI 10.1109/TPAMI.2013.49	59	159	169	19	189	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					849	862		10.1109/TPAMI.2017.2695539	http://dx.doi.org/10.1109/TPAMI.2017.2695539			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28436845	Green Submitted			2022-12-18	WOS:000426687100006
J	Gijsenij, A; Gevers, T				Gijsenij, Arjan; Gevers, Theo			Color Constancy Using Natural Image Statistics and Scene Semantics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; illuminant estimation; natural image statistics; scene semantics; computer vision	TRANSFORMATIONS; ALGORITHMS; SHAPE	Existing color constancy methods are all based on specific assumptions such as the spatial and spectral characteristics of images. As a consequence, no algorithm can be considered as universal. However, with the large variety of available methods, the question is how to select the method that performs best for a specific image. To achieve selection and combining of color constancy algorithms, in this paper natural image statistics are used to identify the most important characteristics of color images. Then, based on these image characteristics, the proper color constancy algorithm (or best combination of algorithms) is selected for a specific image. To capture the image characteristics, the Weibull parameterization (e.g., grain size and contrast) is used. It is shown that the Weibull parameterization is related to the image attributes to which the used color constancy methods are sensitive. An MoG-classifier is used to learn the correlation and weighting between the Weibull-parameters and the image attributes (number of edges, amount of texture, and SNR). The output of the classifier is the selection of the best performing color constancy method for a certain image. Experimental results show a large improvement over state-of-the-art single algorithms. On a data set consisting of more than 11,000 images, an increase in color constancy performance up to 20 percent (median angular error) can be obtained compared to the best-performing single algorithm. Further, it is shown that for certain scene categories, one specific color constancy algorithm can be used instead of the classifier considering several algorithms.	[Gijsenij, Arjan; Gevers, Theo] Univ Amsterdam, Fac Sci, NL-1098 XH Amsterdam, Netherlands	University of Amsterdam	Gijsenij, A (corresponding author), Univ Amsterdam, Fac Sci, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.	a.gijsenij@uva.nl; th.gevers@uva.nl		Gijsenij, Arjan/0000-0003-4926-3672				Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529; Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; Bishop C.M., 1996, NEURAL NETWORKS PATT, P1; Brainard DH, 2004, J VISION, V4, pII, DOI 10.1167/4.9.i; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P311; Cho JW, 2007, I S WORLD WIREL MOBI, P1; Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160; DZMURA M, 1995, GEOMETRIC REPRESENTATIONS OF PERCEPTUAL PHENOMENA, P187; Ebner M., 2007, COMPUTER VISION; Ebner M, 2006, PATTERN RECOGN LETT, V27, P1220, DOI 10.1016/j.patrec.2005.07.020; Fairchild M.D., 2005, COLOR APPEARANCE MOD; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson GD, 2006, INT J COMPUT VISION, V67, P93, DOI 10.1007/s11263-006-4100-z; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Foster DH, 2006, VISUAL NEUROSCI, V23, P341, DOI 10.1017/S0952523806233455; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Funt BV, 2000, J OPT SOC AM A, V17, P2108, DOI 10.1364/JOSAA.17.002108; Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7; GEUSEBROEK JM, 2006, P BRIT MACH VIS ASS, V3, P1029; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; Gijsenij A., 2007, CVPR, P1; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226; Lam KM., 1985, THESIS U BRADFORD; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; MORONEY N, 2002, P IS T SID 10 COL IM, P23; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036; Schaefer G, 2005, PROC CVPR IEEE, P148; Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; VANDEWEIJER J, 2007, P INT C COMP VIS; VANGEMERT JC, 2006, P IEEE CVPR WORKSH S; Von Kries J., 1905, HDB PHYSIOLOGIE MENS, V3, P109; WEST G, 1982, J MATH BIOL, V15, P249, DOI 10.1007/BF00275077; YANG J, 1998, P C HUM FACT COMP SY, P140	46	159	180	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					687	698		10.1109/TPAMI.2010.93	http://dx.doi.org/10.1109/TPAMI.2010.93			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20421672				2022-12-18	WOS:000287370400003
J	Soille, P				Soille, Pierre			Constrained connectivity for hierarchical image partitioning and simplification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						connectivity; partition; image segmentation; region growing; multiscale image representation; hierarchy; graph; connectivity index; clustering; single linkage	SCALE-SPACE REPRESENTATION; PICTURE SEGMENTATION; GRAPH; ALGORITHMS; EXTRACTION	This paper introduces an image partitioning and simplification method based on the constrained connectivity paradigm. According to this paradigm, two pixels are said to be connected if they satisfy a series of constraints defined in terms of simple measures such as the maximum gray-level differences over well-defined pixel paths and regions. The resulting connectivity relation generates a unique partition of the image definition domain. The simplification of the image is then achieved by setting each segment of the partition to the mean value of the pixels falling within this segment. Fine to coarse partition hierarchies ( and, therefore, images of increasing degree of simplification) are produced by varying the threshold value associated with each connectivity constraint. The paper also includes a generalization to multichannel images, application examples, a review of related image segmentation techniques, and pseudocode for an implementation based on queue and stack data structures.	Commiss European Communities, Joint Res Ctr, Inst Environm & Sustainabil, Spatial Data Infrastruct Unit, I-21020 Ispra, VA, Italy	European Commission Joint Research Centre; EC JRC ISPRA Site	Soille, P (corresponding author), Commiss European Communities, Joint Res Ctr, Inst Environm & Sustainabil, Spatial Data Infrastruct Unit, Via Enr Fermi 1,TP 262, I-21020 Ispra, VA, Italy.	Pierre.Soille@jrc.it						ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Ahuja N, 1995, ACM COMPUT SURV, V27, P304, DOI 10.1145/212094.212099; Baraldi A, 1996, IEEE T GEOSCI REMOTE, V34, P137, DOI 10.1109/36.481899; BEAULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150, DOI 10.1109/34.16711; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BISTER M, 1990, PATTERN RECOGN LETT, V11, P605, DOI 10.1016/0167-8655(90)90013-R; BLOCH I, 1993, PATTERN RECOGN LETT, V14, P483, DOI 10.1016/0167-8655(93)90028-C; Braga-Neto U, 2005, IEEE T PATTERN ANAL, V27, P892, DOI 10.1109/TPAMI.2005.124; Braga-Neto U, 2004, IEEE T IMAGE PROCESS, V13, P1567, DOI 10.1109/TIP.2004.837514; BRAGANETO U, 1996, P INT S MATH MORPH I, V5, P139; BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; Brunner D, 2007, IMAGE VISION COMPUT, V25, P1352, DOI 10.1016/j.imavis.2006.09.002; Cho KJ, 1997, COMPUT VIS IMAGE UND, V68, P72, DOI 10.1006/cviu.1997.0546; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CORAY G, 1975, COMPUTER GRAPHICS IM, V4, P120; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X; DELIMA VN, 21757 EUR EN JOINT R; DELLEPIANE S, 1995, PATTERN RECOGN LETT, V16, P313, DOI 10.1016/0167-8655(94)00088-K; Dellepiane SG, 1996, IEEE T IMAGE PROCESS, V5, P429, DOI 10.1109/83.491317; Duda R.O., 2000, PATTERN CLASSIFICATI; ESTABROOK GF, 1966, J THEOR BIOL, V12, P297, DOI 10.1016/0022-5193(66)90144-5; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594; GOWER JC, 1969, APPL STATIST, V18, P54, DOI DOI 10.2307/2346439; Guigues L, 2003, PATTERN RECOGN LETT, V24, P1059, DOI 10.1016/S0167-8655(02)00252-0; HAMBRUSCH S, 1994, J PARALLEL DISTR COM, V20, P56, DOI 10.1006/jpdc.1994.1005; Hambrusch S., 1992, SPAA '92. 4th Annual ACM Symposium on Parallel Algorithms and Architectures, P100, DOI 10.1145/140901.140912; Horowitz S.L., 1974, P 2 INT JOINT C PATT, P424; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; KROPATSCH W, 2004, P 16 IS T SPIE ANN S, P193; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396, DOI 10.1109/34.895974; LI M, 1982, COMPUT VISION GRAPH, V20, P72, DOI 10.1016/0146-664X(82)90074-0; LINDEBERG T, 1993, IEEE T PATTERN ANAL, V15, P1068, DOI 10.1109/34.254063; Marfil R, 2006, PATTERN RECOGN, V39, P1430, DOI 10.1016/j.patcog.2006.02.017; Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1; Meyer F, 1999, LECT NOTES COMPUT SC, V1682, P187; Meyer F, 2000, J VIS COMMUN IMAGE R, V11, P245, DOI 10.1006/jvci.1999.0447; MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566; NAGAO M, 1979, COMPUT VISION GRAPH, V10, P195, DOI 10.1016/0146-664X(79)90001-7; Nagao M., 1980, STRUCTURAL ANAL COMP; Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110; PARANJAPE RB, 1992, CVGIP-GRAPH MODEL IM, V54, P259, DOI 10.1016/1049-9652(92)90056-4; ROSENFELD A, 1984, PATTERN RECOGN LETT, V2, P311, DOI 10.1016/0167-8655(84)90018-7; ROSENFELD A, 1983, PATTERN RECOGN, V16, P47, DOI 10.1016/0031-3203(83)90007-9; ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Schoenmakers R.P.H.M., 1995, THESIS KATHOLIEKE U; SERRA J, 1993, P SOC PHOTO-OPT INS, V2030, P65, DOI 10.1117/12.146672; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Soille P, 1996, J ELECTRON IMAGING, V5, P252, DOI 10.1117/12.240258; Soille P, 2006, IEEE T PATTERN ANAL, V28, P673, DOI 10.1109/TPAMI.2006.99; Sutcliffe J. P., 1994, NEW APPROACHES CLASS, P55; Tanimoto S. L., 1976, Computer Graphics and Image Processing, V5, P333, DOI 10.1016/S0146-664X(76)80012-3; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wang Y, 1996, PATTERN RECOGN, V29, P1359, DOI 10.1016/0031-3203(95)00159-X; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7; [No title captured]	62	159	164	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1132	1145		10.1109/TPAMI.2007.70817	http://dx.doi.org/10.1109/TPAMI.2007.70817			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550898				2022-12-18	WOS:000256294100002
J	Gross, R; Matthews, I; Baker, S				Gross, R; Matthews, I; Baker, S			Appearance-based face recognition and light-fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						appearance-based object recognition; face recognition; light-fields; eigen light-fields; face recognition across pose	FRAMEWORK	Arguably the most important decision to be made when developing an object recognition algorithm is selecting the scene measurements or features on which to base the algorithm. In appearance-based object recognition, the features are chosen to be the pixel intensity values in an image of the object. These pixel intensities correspond directly to the radiance of light emitted from the object along certain rays in space. The set of all such radiance values over all possible rays is known as the plenoptic function or light-field. In this paper, we develop a theory of appearance-based object recognition from light-fields. This theory leads directly to an algorithm for face recognition across pose that uses as many images of the face as are available, from one upwards. All of the pixels, whichever image they come from, are treated equally and used to estimate the (eigen) light-field of the object. The eigen light-field is then used as the set of features on which to base recognition, analogously to how the pixel intensities are used in appearance-based face and object recognition.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Gross, R (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	rgross@cs.smu.edu; iainm@cs.smu.edu; simonb@cs.smu.edu						Adelson E., 1991, PLENOPTIC FUNCTION E; Baker S, 2003, IEEE T PATTERN ANAL, V25, P100, DOI 10.1109/TPAMI.2003.1159949; Belhumeur P. N., 1998, INT J COMPUT VISION, V28, P1; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BEYMER D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P500, DOI 10.1109/ICCV.1995.466898; BLACKBURN DM, 2000, FACIAL RECOGNITION V; Blackwood E, 1998, J HOMOSEXUAL, V36, P101, DOI 10.1300/J082v36n01_07; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Georghiades A. S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P277, DOI 10.1109/AFGR.2000.840647; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Gross R., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P481; Gross R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P3, DOI 10.1109/AFGR.2002.1004122; Jacobs DW, 1998, PROC CVPR IEEE, P610, DOI 10.1109/CVPR.1998.698668; Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; MATTHEWS I, 2003, CMURITR9302; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Riklin-Raviv T., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P566, DOI 10.1109/CVPR.1999.784968; Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; SIM T, 2003, IEEE T PATTERN ANAL, V25; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Vasilescu MAO, 2002, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2002.1048350; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230	30	159	171	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					449	465		10.1109/TPAMI.2004.1265861	http://dx.doi.org/10.1109/TPAMI.2004.1265861			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382650				2022-12-18	WOS:000220102800002
J	Lin, TY; RoyChowdhury, A; Maji, S				Lin, Tsung-Yu; RoyChowdhury, Aruni; Maji, Subhransu			w Bilinear Convolutional Neural Networks for Fine-Grained Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fine-grained recognition; texture representations; second order pooling; bilinear models; convolutional networks		We present a simple and effective architecture for fine-grained recognition called Bilinear Convolutional Neural Networks (B-CNNs). These networks represent an image as a pooled outer product of features derived from two CNNs and capture localized feature interactions in a translationally invariant manner. B-CNNs are related to orderless texture representations built on deep features but can be trained in an end-to-end manner. Our most accurate model obtains 84.1, 79.4, 84.5 and 91.3 percent per-image accuracy on the Caltech-UCSD birds [1], NABirds [2], FGVC aircraft [3], and Stanford cars [4] dataset respectively and runs at 30 frames-per-second on a NVIDIA Titan X GPU. We then present a systematic analysis of these networks and show that (1) the bilinear features are highly redundant and can be reduced by an order of magnitude in size without significant loss in accuracy, (2) are also effective for other image classification tasks such as texture and scene recognition, and (3) can be trained from scratch on the ImageNet dataset offering consistent improvements over the baseline architecture. Finally, we present visualizations of these models on various datasets using top activations of neural units and gradient-based inversion techniques. The source code for the complete system is available at http://vis-www.cs.umass.edu/bcnn.	[Lin, Tsung-Yu; RoyChowdhury, Aruni; Maji, Subhransu] Univ Massachusetts, Coll Informat & Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Lin, TY (corresponding author), Univ Massachusetts, Coll Informat & Comp Sci, Amherst, MA 01003 USA.	tsungyulin@cs.umass.edu; arunirc@cs.umass.edu; smaji@cs.umass.edu		Lin, Tsung-Yu/0000-0002-1332-646X	Office of the Director of National Intelligence (ODNI); Intelligence Advanced Research Projects Activity (IARPA) [2014-14071600010]; National Science Foundation [IIS-1617917]	Office of the Director of National Intelligence (ODNI); Intelligence Advanced Research Projects Activity (IARPA); National Science Foundation(National Science Foundation (NSF))	This research was supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA) under contract number 2014-14071600010, National Science Foundation grant IIS-1617917, and a gift from Facebook. The GPUs used in this research were generously donated by NVIDIA.	Adelson E, 2009, J VISUAL-JAPAN, V9, P784, DOI DOI 10.1167/9.8.784; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Ba J., 2015, P BRIT MACH VIS C; Ba J., 2015, ICLR 2015 C TRACK P; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Donahue J, 2013, P 31 INT C MACH LEAR; Everingham Mark, 2010, IJCV; Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fukui Akira, 2016, ARXIV160601847; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; Gatys L. A., 2015, ADV NEURAL INFORM PR, V28, P262, DOI DOI 10.1016/0014-5793(76)80724-7; Gatys LA., 2015, PROC CVPR IEEE, V16, P326, DOI [10.1167/16.12.326, DOI 10.1109/CVPR.2016.265]; Gens R., 2012, 26 ADV NEURAL INFORM, P3239; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Gosselin PH, 2014, PATTERN RECOGN LETT, V49, P92, DOI 10.1016/j.patrec.2014.06.011; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Lin TY, 2016, PROC CVPR IEEE, P2791, DOI 10.1109/CVPR.2016.305; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2305, DOI 10.1109/TPAMI.2016.2637921; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8; Maji S., 2013, P BRIT MACH VIS C; Maji Subhransu, 2013, ARXIV13065151; Mnih V, 2014, ADV NEUR IN, V27; Pham N, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P239, DOI 10.1145/2487575.2487591; Parkhi OM, 2014, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2014.219; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Pirsiavash H., 2009, P ADV NEUR INF PROC, P1482; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Scholkopf B., 2001, LEARNING KERNELS SUP; Scholkopf B., 2001, ARXIV150408289; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; USTYUZHANINOV I, 2016, ARXIV160600021; Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wah C., 2011, TECH REP; Wah C., 2011, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.128; Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; ZHANG N, 2016, PROC WORKSHOP INT CO; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364	69	158	186	6	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1309	1322		10.1109/TPAMI.2017.2723400	http://dx.doi.org/10.1109/TPAMI.2017.2723400			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28692962	hybrid			2022-12-18	WOS:000431524700003
J	Toet, A				Toet, Alexander			Computational versus Psychophysical Bottom-Up Image Saliency: A Comparative Evaluation Study	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency; image analysis; visual search	SELECTIVE VISUAL-ATTENTION; EYE-MOVEMENTS; BACKGROUND ELEMENTS; OBJECT RECOGNITION; LOW-LEVEL; SEARCH; CONSPICUOUSNESS; TARGET; MODEL; REAL	The predictions of 13 computational bottom-up saliency models and a newly introduced Multiscale Contrast Conspicuity (MCC) metric are compared with human visual conspicuity measurements. The agreement between human visual conspicuity estimates and model saliency predictions is quantified through their rank order correlation. The maximum of the computational saliency value over the target support area correlates most strongly with visual conspicuity for 12 of the 13 models. A simple multiscale contrast model and the MCC metric both yield the largest correlation with human visual target conspicuity (>0.84). Local image saliency largely determines human visual inspection and interpretation of static and dynamic scenes. Computational saliency models therefore have a wide range of important applications, like adaptive content delivery, region-of-interest-based image compression, video summarization, progressive image transmission, image segmentation, image quality assessment, object recognition, and content-aware image scaling. However, current bottom-up saliency models do not incorporate important visual effects like crowding and lateral interaction. Additional knowledge about the exact nature of the interactions between the mechanisms mediating human visual saliency is required to develop these models further. The MCC metric and its associated psychophysical saliency measurement procedure are useful tools to systematically investigate the relative contribution of different feature dimensions to overall visual target saliency.	[Toet, Alexander] Univ Amsterdam, NL-1098 SJ Amsterdam, Netherlands; [Toet, Alexander] TNO, NL-3769 DE Soesterberg, Netherlands	University of Amsterdam; Netherlands Organization Applied Science Research	Toet, A (corresponding author), Univ Amsterdam, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	lex.toet@tno.nl	Toet, Alexander/E-6733-2016	Toet, Alexander/0000-0003-1051-5422	NWO-VICI [639.023.705]	NWO-VICI(Netherlands Organization for Scientific Research (NWO))	The author wishes to thank Radhakrishna Achanta, Peng Bian, Neil D. Bruce, Pedro F. Felzenszwalb, Anton Garcia-Diaz, Chenlei Guo, Jonathan Harel, Daniel P. Huttenlocher, Nicolas Le Bihan, Matei Mancas, Ruth Rosenholtz, Paul L. Rosin, Steve Sangwine, Eero P. Simoncelli, John K. Tsotsos, Dirk B. Walther, and Lingyun Zhang for sharing their software and for helpful suggestions, and Hae Jong Seo and Peyman Milanfar for calculating the saliency maps for his images with their model and for sharing their software. He is also indebted to the referees for their valuable suggestions and comments on earlier versions of this manuscript. This research was supported by NWO-VICI grant 639.023.705 "Color in Computer Vision."	Achanta R., 2009, P IEEE INT C COMP VI; Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66; Acik A, 2009, VISION RES, V49, P1541, DOI 10.1016/j.visres.2009.03.011; ALKHATEEB W F, 1990, Spatial Vision, V5, P129, DOI 10.1163/156856890X00039; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53; Baddeley RJ, 2006, VISION RES, V46, P2824, DOI 10.1016/j.visres.2006.02.024; Bian P, 2009, LECT NOTES COMPUT SC, V5506, P251, DOI 10.1007/978-3-642-02490-0_31; Bijl P., 2003, ENCY OPTICAL ENG, P2929; BLOOMFIELD JR, 1972, HUM FACTORS, V14, P139, DOI 10.1177/001872087201400203; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BOWLER YM, 1990, VISUAL SEARCH, P303; Bruce N, 2004, INT C PATT RECOG, P616, DOI 10.1109/ICPR.2004.1334223; Bruce N. D. B., 2009, ADV NEURAL INFORM PR, V18, P155; Bruce NDB, 2005, NEUROCOMPUTING, V65, P125, DOI 10.1016/j.neucom.2004.10.065; BRUCE NDB, 2008, P 4 INT WORKSH ATT C, P171; BRUCE NDB, 2009, P IEEE INT C IM PROC, V3, P289; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863; Carmi R, 2006, VISION RES, V46, P4333, DOI 10.1016/j.visres.2006.08.019; Chen X, 2006, VISION RES, V46, P4118, DOI 10.1016/j.visres.2006.08.008; Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468; Clarke ADF, 2008, VISION RES, V48, P2193, DOI 10.1016/j.visres.2008.06.019; COLE BL, 1984, VISION RES, V24, P261, DOI 10.1016/0042-6989(84)90129-9; Cooke K. J., 1995, VISION MODELS TARGET, P135; COOKE KJ, 1992, JS12020 BAE SRC; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; Ecker AS, 2010, SCIENCE, V327, P584, DOI 10.1126/science.1179867; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955; ENGEL FL, 1977, VISION RES, V17, P95, DOI 10.1016/0042-6989(77)90207-3; ENGEL FL, 1974, VISION RES, V14, P459, DOI 10.1016/0042-6989(74)90034-0; ENGEL FL, 1971, VISION RES, V11, P563, DOI 10.1016/0042-6989(71)90077-0; Fecteau JH, 2006, TRENDS COGN SCI, V10, P382, DOI 10.1016/j.tics.2006.06.011; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Foulsham T, 2007, PERCEPTION, V36, P1123, DOI 10.1068/p5659; Foulsham T, 2008, J VISION, V8, DOI 10.1167/8.2.6; FRINTROP S, 2007, P 5 INT C COMP VIS S; GAO D, 2007, P NEUR INF PROC SYST, P497; Gao DS, 2009, NEURAL COMPUT, V21, P239, DOI 10.1162/neco.2009.11-06-391; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Garcia-Diaz A, 2009, LECT NOTES COMPUT SC, V5807, P343; GARCIADIAZ A, 2009, P 13 INT C COMP AN I, P261; GEISLER WS, 1995, PSYCHOL REV, V102, P356, DOI 10.1037/0033-295X.102.2.356; Guo C., 2008, P CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587715; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028; Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034; Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049; Harding G, 2010, J VISION, V10, DOI 10.1167/10.2.8; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Henderson John M., 2007, P537, DOI 10.1016/B978-008044980-7/50027-6; HU Y, 2005, ADV MULTIMEDIA INFOR, P993; Huang LQ, 2005, VISION RES, V45, P1909, DOI 10.1016/j.visres.2005.01.013; Intriligator J, 2001, COGNITIVE PSYCHOL, V43, P171, DOI 10.1006/cogp.2001.0755; Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Itti L, 2001, OPT ENG, V40, P1784, DOI 10.1117/1.1389063; Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677; ITTI L, 1999, SPIE HUMAN VISION EL, V4, P473; Itti L, 2006, VIS COGN, V14, P959, DOI 10.1080/13506280500195672; JENKINS SE, 1982, VISION RES, V22, P1241, DOI 10.1016/0042-6989(82)90136-5; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138; Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Koene A, 2007, J VISION, V7, DOI 10.1167/7.11.14; KOVESI P, 1999, J COMPUTER VISION RE, V1, P1; Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719; Levi DM, 2008, VISION RES, V48, P635, DOI 10.1016/j.visres.2007.12.009; Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821; Liu T., 2007, P IEEE C COMP VIS PA, P1; Lotufo RA, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P100, DOI 10.1109/SIBGRAPI.2001.963043; Ma Q, 2008, LECT NOTES COMPUT SC, V5226, P1124; Ma Q, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3302129; MA YF, 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094; MANCAS M., 2007, COMPUTATIONAL ATTENT; Mancas M., 2007, P 5 INT C COMP VIS S; MANCAS M, 2009, P 4 INT SUMM WORKSH, P73; Mancas M, 2006, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2006.312489; Mancas Matei, 2008, P INT WORKSH ATT PER, P94; Mancebon M.J., 2007, J OPERATIONAL RES SO, p1 ; Marat S., 2007, P 15 EUR SIGN PROC C, P1784; Masciocchi CM, 2009, J VISION, V9, DOI 10.1167/9.11.25; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; Mukerjee A, 2006, 3 CAN C COMP ROB VIS, P13; NIASSI A, 2007, P IEEE INT C IM PROC, V2, P169; Niebur E, 1998, ATTENTIVE BRAIN, P163; Nilsson D, 1998, STAT COMPUT, V8, P159, DOI 10.1023/A:1008990218483; NOTHDURFT HC, 1993, VISION RES, V33, P839, DOI 10.1016/0042-6989(93)90202-8; NOTHDURFT HC, 1992, PERCEPT PSYCHOPHYS, V52, P355, DOI 10.3758/BF03206697; NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M; NOTHDURFT HC, 1993, VISION RES, V33, P1937, DOI 10.1016/0042-6989(93)90020-W; NOTHDURFT HC, 1993, SPATIAL VISION, V7, P341, DOI 10.1163/156856893X00487; Nystrom M, 2008, J EYE MOVEMENT RES, V2; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Poirier FJAM, 2008, J VISION, V8, DOI 10.1167/8.15.14; Pomplun M, 2001, VISION RES, V41, P2757, DOI 10.1016/S0042-6989(01)00145-6; Pratt W, 1991, DIGITAL IMAGE PROCES; Rajashekar U, 2007, VISION RES, V47, P3160, DOI 10.1016/j.visres.2007.07.015; Rapantzikos K, 2009, SIGNAL PROCESS-IMAGE, V24, P557, DOI 10.1016/j.image.2009.03.002; Rodriguez-Sanchez R, 2004, PATTERN RECOGN, V37, P281, DOI 10.1016/j.patcog.2003.06.004; Roggeman C, 2010, NEUROIMAGE, V52, P1005, DOI 10.1016/j.neuroimage.2010.01.060; Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; SEO HJ, 2009, P IEEE CS C COMP VIS; Serra J, 1982, IMAGE ANAL MATH MORP; SHANNON CE, 1948, BELL SYST TECH J, V27, P93; Shi H, 2007, APPL MATH COMPUT, V188, P1671, DOI 10.1016/j.amc.2006.11.036; Stirk JA, 2007, J VISION, V7, DOI 10.1167/7.10.3; Straube S, 2011, BRAIN COGNITION, V75, P29, DOI 10.1016/j.bandc.2010.10.004; Straube S, 2010, BRAIN RES, V1307, P89, DOI 10.1016/j.brainres.2009.10.043; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; Thompson KG, 2005, PROG BRAIN RES, V147, P251, DOI 10.1016/S0079-6123(04)47019-8; TOET A, 1992, VISION RES, V32, P1349, DOI 10.1016/0042-6989(92)90227-A; Toet A, 1998, OPT ENG, V37, P1969, DOI 10.1117/1.601903; Toet A, 2000, OPT ENG, V39, P1344, DOI 10.1117/1.602503; Toet A, 2001, OPT ENG, V40, P1760, DOI 10.1117/1.1388608; TRAVNIKOVA NP, 1977, SOV J OPT TECHNOL+, V44, P166; TRAVNIKOVA NP, 1984, SOV J OPT TECHNOL+, V51, P63; TRAVNIKOVA NP, 1984, EFFICIENCY VISUAL SE; Underwood G, 2008, CONSCIOUS COGN, V17, P159, DOI 10.1016/j.concog.2006.11.008; Underwood G, 2006, Q J EXP PSYCHOL, V59, P1931, DOI 10.1080/17470210500416342; Underwood G, 2009, VIS COGN, V17, P812, DOI 10.1080/13506280902771278; van Zoest W, 2005, VIS COGN, V12, P353, DOI 10.1080/13506280444000229; van Zoest W, 2004, PERCEPTION, V33, P927, DOI 10.1068/p5158; WALDMAN G, 1991, IEEE T SYST MAN CYB, V21, P596, DOI 10.1109/21.97453; WALDMAN G, 1993, ELECTROOPTICAL SYSTE; Walther D, 2005, COMPUT VIS IMAGE UND, V100, P41, DOI 10.1016/j.cviu.2004.09.004; Walther D, 2006, THESIS CALTECH; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wertheim AH, 2010, ERGONOMICS, V53, P421, DOI 10.1080/00140130903483705; Wertheim AH, 2006, EXP BRAIN RES, V170, P387, DOI 10.1007/s00221-005-0221-9; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32	140	158	171	2	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2131	2146		10.1109/TPAMI.2011.53	http://dx.doi.org/10.1109/TPAMI.2011.53			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	820MM	21422490				2022-12-18	WOS:000294910000002
J	Zeng, H; Cheung, YM				Zeng, Hong; Cheung, Yiu-Ming			Feature Selection and Kernel Learning for Local Learning-Based Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						High-dimensional data; local learning-based clustering; feature selection; kernel learning; sparse weighting	MODEL SELECTION; CLASSIFICATION; PREDICTION; MATRIX; CANCER	The performance of the most clustering algorithms highly relies on the representation of data in the input space or the Hilbert space of kernel methods. This paper is to obtain an appropriate data representation through feature selection or kernel learning within the framework of the Local Learning-Based Clustering (LLC) (Wu and Scholkopf 2006) method, which can outperform the global learning-based ones when dealing with the high-dimensional data lying on manifold. Specifically, we associate a weight to each feature or kernel and incorporate it into the built-in regularization of the LLC algorithm to take into account the relevance of each feature or kernel for the clustering. Accordingly, the weights are estimated iteratively in the clustering process. We show that the resulting weighted regularization with an additional constraint on the weights is equivalent to a known sparse-promoting penalty. Hence, the weights of those irrelevant features or kernels can be shrunk toward zero. Extensive experiments show the efficacy of the proposed methods on the benchmark data sets.	[Zeng, Hong] Southeast Univ, Sch Instrument Sci & Engn, RSCL, Nanjing, Peoples R China; [Zeng, Hong; Cheung, Yiu-Ming] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Southeast University - China; Hong Kong Baptist University	Cheung, YM (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	hzeng@seu.edu.cn; ymc@comp.hkbu.edu.hk	Cheung, Yiu-ming/E-2050-2015; Zeng, Hong/T-8447-2019	Cheung, Yiu-ming/0000-0001-7629-4648; Zeng, Hong/0000-0002-4587-6263	Research Grant Council of Hong Kong SAR [HKBU 210306, HKBU 210309]; Hong Kong Baptist University [FRG/07-08/II-54, FRG2/08-09/122]	Research Grant Council of Hong Kong SAR(Hong Kong Research Grants Council); Hong Kong Baptist University	The work described in this paper was jointly supported by grants from the Research Grant Council of Hong Kong SAR (Project Nos. HKBU 210306 and HKBU 210309) and a Faculty Research Grant of Hong Kong Baptist University under Project Nos. FRG/07-08/II-54 and FRG2/08-09/122. Yiu-Ming Cheung is the corresponding author for this paper.	Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Argyriou A., 2007, NIPS, V19, P41, DOI DOI 10.1007/S10994-007-5040-8; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bach FR, 2006, J MACH LEARN RES, V7, P1963; BAKIR G, 2005, MAXIMUM MARGIN FEATU; Blake C., 1998, UCI REPOSITORY MACHI; CALAMAI PH, 1987, MATH PROGRAM, V39, P93, DOI 10.1007/BF02592073; Chapelle O, 2000, ADV NEUR IN, V12, P230; CHAPELLE O, 2002, MACH LEARN, V26, P131; CHEN JH, 2007, P 13 ACM SIGKDD INT, P123; Cheung YM, 2009, IEEE T KNOWL DATA EN, V21, P1798, DOI 10.1109/TKDE.2009.23; Chong EK., 2013, INTRO OPTIMIZATION; Dash M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P115, DOI 10.1109/ICDM.2002.1183893; Dy JG, 2004, J MACH LEARN RES, V5, P845; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; He X., 2005, P ADV NEUR INF PROC, P507; Karypis G., 2002, CLUTO CLUSTERING TOO; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lange T., 2006, ADV NEURAL INFORM PR, V18, P723; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; LAW MHC, 2003, ADV NEURAL INFORM PR, V15, P609; Liu, 2007, P 24 INT C MACH LEAR, P1151, DOI [DOI 10.1145/1273496.1273641, 10.1145/1273496.1273641]; Long B., 2008, P 8 SIAM INT C DAT M, DOI DOI 10.1137/1.9781611972788.74; Micchelli CA, 2005, J MACH LEARN RES, V6, P1099; Micchelli CA, 2007, MACH LEARN, V66, P297, DOI 10.1007/s10994-006-0679-0; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Ng AY, 2002, ADV NEUR IN, V14, P849; Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI, VUnabridged edition; Rakotomamonjy A., 2007, P 24 INT C MACH LEAR, V227, P775, DOI DOI 10.1145/1273496.1273594; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Roth V, 2004, ADV NEUR IN, V16, P473; Scholkopf B., 2001, LEARNING KERNELS SUP; Scholkopf B., 2007, P ADV NEUR INF PROC, V19, P1529, DOI DOI 10.7551/MITPRESS/7503.003.0196; Shortreed S, 2005, P 21 C UNC ART INT, P534; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Valizadegan H, 2007, ADV NEURAL INF PROCE, P1417; WANG F, 2007, P 2 INT C INT INF MA, P95; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Wolf L, 2005, J MACH LEARN RES, V6, P1855; Ye JP, 2008, J MACH LEARN RES, V9, P719; Yeung DY, 2007, PATTERN RECOGN, V40, P2021, DOI 10.1016/j.patcog.2006.12.031; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zha HY, 2002, ADV NEUR IN, V14, P1057; ZHOU D, 2007, P 24 INT C MACH LEAR, P1159, DOI DOI 10.1145/1273496.1273642	49	158	166	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1532	1547		10.1109/TPAMI.2010.215	http://dx.doi.org/10.1109/TPAMI.2010.215			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21135434	Green Submitted			2022-12-18	WOS:000291807200004
J	Palaniappan, R; Mandic, DP				Palaniappan, Ramaswamy; Mandic, Danilo P.			Biometrics from brain electrical activity: A machine learning approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; EEG gamma band; Elman neural network; MUSIC; k-nearest neighbors; visual evoked potential	RECOGNITION	The potential of brain electrical activity generated as a response to a visual stimulus is examined in the context of the identification of individuals. Specifically, a framework for the Visual Evoked Potential (VEP)-based biometrics is established, whereby energy features of the gamma band within VEP signals were of particular interest. A rigorous analysis is conducted which unifies and extends results from our previous studies, in particular, with respect to 1) increased bandwidth, 2) spatial averaging, 3) more robust power spectrum features, and 4) improved classification accuracy. Simulation results on a large group of subject support the analysis.	Univ Essex, Dept Comp Sci, Colchester CO4 3SQ, Essex, England; Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2BT, England	University of Essex; Imperial College London	Palaniappan, R (corresponding author), Univ Essex, Dept Comp Sci, Colchester CO4 3SQ, Essex, England.	rpalan@essex.ac.uk; d.mandic@imperial.ac.uk	Ramaswamy, Palaniappan/E-9637-2015; Ramaswamy, Palaniappan/H-2937-2012	Ramaswamy, Palaniappan/0000-0001-5296-8396; Ramaswamy, Palaniappan/0000-0001-5296-8396				AKAY M, 1996, DETECTION ESTIMATION; Basar E., 2004, MEMORY BRAIN DYNAMIC; Bechtel J., 2001, INT J COMPUTATIONAL, V2, P131; Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458; Caspary O, 1997, P IEEE EMBS, V18, P976, DOI 10.1109/IEMBS.1996.652668; CASPARY O, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P1232, DOI 10.1109/IEMBS.1994.415408; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hurley DJ, 2005, COMPUT VIS IMAGE UND, V98, P491, DOI 10.1016/j.cviu.2004.11.001; KOROTKAYA Z, 2003, BIOMETRICS PERSON AU; Palaniappan R, 2004, IEE P-SCI MEAS TECH, V151, P16, DOI 10.1049/ip-smt:20040003; Palaniappan R, 2002, ELECTRON LETT, V38, P1634, DOI 10.1049/el:20021104; PALANIAPPAN R, 2005, P INT C ART NEUR NET, P735; Paranjape RB, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1363, DOI 10.1109/CCECE.2001.933649; POULOS M, 1999, P 6 IEEE INT C EL CI, V1, P283; POULOS M, 1999, P IEEE INT C EL CIRC, V2, P1005; Prabhakar S., 2003, HDB FINGERPRINT RECO; Riedmiller M., 1993, IEEE INT C NEUR NETW, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; Roberts WJJ, 2005, IEEE T SPEECH AUDI P, V13, P211, DOI 10.1109/TSA.2004.838536; Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796; SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174; WAYMAN J, 2004, BIOMETRICS SYSTEMS T; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669; Yi JY, 2005, IEEE T SIGNAL PROCES, V53, P776, DOI 10.1109/TSP.2004.839914; ZHANG XL, 1995, BRAIN RES BULL, V38, P531, DOI 10.1016/0361-9230(95)02023-5	26	158	167	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					738	742		10.1109/TPAMI.2007.1013	http://dx.doi.org/10.1109/TPAMI.2007.1013			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299228				2022-12-18	WOS:000244855600019
J	Tan, TN				Tan, TN			Rotation invariant texture features and their use in automatic script identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture; rotation invariance; Gabor filtering; script and language recognition; document image processing	CHARACTER-RECOGNITION; SPATIAL-FREQUENCY; FILTERS; SEGMENTATION	This paper concerns the extraction of rotation invariant texture features and the use of such features in script identification from document images. Rotation invariant texture features are computed based on an extension of the popular multi-channel Gabor filtering technique, and their effectiveness is tested with 300 randomly rotated samples of 15 Brodatz textures. These features are then used in an attempt to solve a practical but hitherto mostly overlooked problem in document image processing-the identification of the script of a machine printed document. Automatic script and language recognition is an essential front-end process for the efficient and correct use of OCR and language translation products in a multilingual environment. Six languages (Chinese, English, Greek, Russian, Persian, and Malayalam) are chosen to demonstrate the potential of such a texture-based approach in script identification.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Tan, TN (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100080, Peoples R China.	tnt@prlsun2.ia.ac.cn						Baird H. S, 1995, SKEW ANGLE PRINTED D, P204; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DING J, P ICDAR97, P1023; FOUNTAIN SR, 1997, P IEEE INT C IM PROC, V3, P197; Fukunaga K., 1972, INTRO STAT PATTERN R; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; GREENSPAN H, 1994, INT C PATT RECOG, P162, DOI 10.1109/ICPR.1994.576896; Haley G. M., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P262, DOI 10.1109/ICIP.1995.529696; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; Lee D. S., 1996, P IAPR WORKSH DOC AN, P76; LEUNG MM, 1992, P 26 AS C SIGN SYST, V1, P461; MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3; Muthusamy YK, 1994, IEEE SIGNAL PROC MAG, V11, P33, DOI 10.1109/79.317925; O'Gorman L., 1995, DOCUMENT IMAGE ANAL; Peake G.S., 1997, P 8 BRIT MACH VIS C, V2, P230, DOI DOI 10.1109/DIA.1997.627086; POLLEN DA, 1983, IEEE T SYST MAN CYB, V13, P907, DOI 10.1109/TSMC.1983.6313086; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; TAN TN, 1995, P SOC PHOTO-OPT INS, V2488, P475, DOI 10.1117/12.212001; TAN TN, 1992, P 11 IAPR INT C PATT, pC607; TAN TN, 1994, P 12 EUR SIGN PROC C, P1377; TAN TN, 1996, P IEEE ICIP96, V3, P185; TAN TN, 1993, P CIE P IEEE INT C S; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; Wood S. L., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P428, DOI 10.1109/ICIP.1995.537663	30	158	166	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					751	756		10.1109/34.689305	http://dx.doi.org/10.1109/34.689305			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930					2022-12-18	WOS:000074677200007
J	FUKUNAGA, K; MANTOCK, JM				FUKUNAGA, K; MANTOCK, JM			NONPARAMETRIC DISCRIMINANT-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									AEROSPACE CORP,LOS ANGELES,CA 90009	Aerospace Corporation - USA	FUKUNAGA, K (corresponding author), PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907, USA.							BALL GH, 1965, AD699616; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; FUKUNAGA K, 1972, INTRO STATISTICAL PA; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171, DOI 10.1109/TC.1972.5008922; PETERSON DW, 1966, IEEE T INFORM THEORY, V12, P380, DOI 10.1109/TIT.1966.1053913; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403	9	158	163	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					671	678		10.1109/TPAMI.1983.4767461	http://dx.doi.org/10.1109/TPAMI.1983.4767461			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869158				2022-12-18	WOS:A1983RV48800018
J	Yu, S; Tranchevent, LC; Liu, XH; Glanzel, W; Suykens, JAK; De Moor, B; Moreau, Y				Yu, Shi; Tranchevent, Leon-Charles; Liu, Xinhai; Glanzel, Wolfgang; Suykens, Johan A. K.; De Moor, Bart; Moreau, Yves			Optimized Data Fusion for Kernel k-Means Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; data fusion; multiple kernel learning; Fisher discriminant analysis; least-squares support vector machine	DISCRIMINANT-ANALYSIS; CONSENSUS	This paper presents a novel optimized kernel k-means algorithm (OKKC) to combine multiple data sources for clustering analysis. The algorithm uses an alternating minimization framework to optimize the cluster membership and kernel coefficients as a nonconvex problem. In the proposed algorithm, the problem to optimize the cluster membership and the problem to optimize the kernel coefficients are all based on the same Rayleigh quotient objective; therefore the proposed algorithm converges locally. OKKC has a simpler procedure and lower complexity than other algorithms proposed in the literature. Simulated and real-life data fusion applications are experimentally studied, and the results validate that the proposed algorithm has comparable performance, moreover, it is more efficient on large-scale data sets. (The Matlab implementation of OKKC algorithm is downloadable from http://homes.esat.kuleuven.be/similar to sistawww/bio/syu/okkc.html.)	[Yu, Shi] Univ Chicago, Inst Genom & Syst Biol, Dept Med, Knapp Ctr Biomed Discovery, Chicago, IL 60637 USA; [Tranchevent, Leon-Charles; Liu, Xinhai; De Moor, Bart; Moreau, Yves] Katholieke Univ Leuven, ESAT SCD, Dept Elect Engn, B-3001 Louvain, Belgium; [Glanzel, Wolfgang] Katholieke Univ Leuven, Dept Managerial Econ Strategy & Innovat, Ctr R&D Monitoring ECOOM, B-3000 Louvain, Belgium	University of Chicago; KU Leuven; KU Leuven	Yu, S (corresponding author), Univ Chicago, Inst Genom & Syst Biol, Dept Med, Knapp Ctr Biomed Discovery, 900 E 57th St,Room 10148, Chicago, IL 60637 USA.		Glanzel, Wolfgang/AAE-4395-2021; Glänzel, Wolfgang/A-6280-2008; Suykens, Johan A.K./C-9781-2014	Glänzel, Wolfgang/0000-0001-7529-5198; Suykens, Johan A.K./0000-0002-8846-6352; Tranchevent, Leon-Charles/0000-0002-1257-4824; Moreau, Yves/0000-0002-4647-6560	Research Council KUL: ProMeta, GOA Ambiorics, GOA MaNet, START 1, Optimization in Engineering (OPTEC), IOF-SCORES4CHEM [CoEEF/05/006, PFV/10/016]; FWO: research communities (ICCoS, ANMMM, MLDM) [G.0302.07, G.0318.05, G.0553.06, G.0733.09, G.082409]; IWT: Eureka-Flite+, Silicos; SBOBioFrame, SBO-MoKa, SBO LeCoPro, SBO Climaqs, SBO POM, TBM-IOTA3, OO-Dsquare; Belgian Federal Science Policy Office [IUAP P6/25, 2007C2011, IUAP P6/04]; FOD: Cancer plans; the Centre for R&D Monitoring of the Flemish Government; EU-RTD: ERNSI: European Research Network on System Identification; FP7-HEALTH CHeartED; FP7-HD-MPC, COST intelli-CIS, FP7-EMBOCON [INFSO-ICT-223854, ICT-248940]	Research Council KUL: ProMeta, GOA Ambiorics, GOA MaNet, START 1, Optimization in Engineering (OPTEC), IOF-SCORES4CHEM; FWO: research communities (ICCoS, ANMMM, MLDM); IWT: Eureka-Flite+, Silicos; SBOBioFrame, SBO-MoKa, SBO LeCoPro, SBO Climaqs, SBO POM, TBM-IOTA3, OO-Dsquare; Belgian Federal Science Policy Office(Belgian Federal Science Policy Office); FOD: Cancer plans; the Centre for R&D Monitoring of the Flemish Government; EU-RTD: ERNSI: European Research Network on System Identification; FP7-HEALTH CHeartED; FP7-HD-MPC, COST intelli-CIS, FP7-EMBOCON	The work was supported by the Research Council KUL: ProMeta, GOA Ambiorics, GOA MaNet, CoEEF/05/006, PFV/10/016 SymBioSys, START 1, Optimization in Engineering (OPTEC), IOF-SCORES4CHEM, several PhD/postdoc & fellow grants; FWO: G.0302.07 (SVM/Kernel), G.0318.05 (subfunctionalization), G.0553.06 (VitamineD), research communities (ICCoS, ANMMM, MLDM); G.0733.09 (3UTR), G.082409 (EGFR); IWT: PhD Grants, Eureka-Flite+, Silicos; SBOBioFrame, SBO-MoKa, SBO LeCoPro, SBO Climaqs, SBO POM, TBM-IOTA3, O & O-Dsquare; the Belgian Federal Science Policy Office: IUAP P6/25 (BioMaGNet, Bioinformatics and Modeling: from Genomes to Networks, 2007C2011), IUAP P6/04 (DYSCO, Dynamical systems, control and optimization, 2007-2011); FOD: Cancer plans; the Centre for R&D Monitoring of the Flemish Government; EU-RTD: ERNSI: European Research Network on System Identification; FP7-HEALTH CHeartED; FP7-HD-MPC (INFSO-ICT-223854), COST intelli-CIS, FP7-EMBOCON (ICT-248940).	Andersen E., 2000, HIGH PERFORMANCE OPT, P197, DOI DOI 10.1007/978-1-4757-3216-0_8; Ayad HG, 2008, IEEE T PATTERN ANAL, V30, P160, DOI 10.1109/TPAMI.2007.1138; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bhatia Rajendra, 1997, MATRIX ANAL, DOI 10.1007/978-1-4612-0653-8; Bishop C.M, 2006, PATTERN RECOGN; Boyd S, 2004, CONVEX OPTIMIZATION; Brabanter J.D., 2002, LEAST SQUARES SUPPOR, DOI DOI 10.1142/9789812776655; Chaudhuri K., 2009, P 26 ANN INT C MACH; Chen J., 2007, P 13 ACM SIGKDD INT; Csiszar I., 1984, STAT DECISIONS, V1, P205; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Ding C., 2004, P 21 ST INT C MACHIN, P29, DOI DOI 10.1145/1015330.1015408; Ding C, 2004, P 21 INT C MACHINE L; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Garey M.R., 1979, COMPUTERS INTRACTABI; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kloft M., 2009, ADV NEURAL INFORM PR, P997; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Lange T., 2005, P ADV NEUR INF PROC; Liang YX, 2007, PATTERN RECOGN, V40, P3606, DOI 10.1016/j.patcog.2007.03.030; Liu X., 2009, P SIAM INT C DAT MIN; Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P103, DOI 10.1109/TNN.2008.2004625; Ma JS, 2003, IEEE SIGNAL PROC LET, V10, P196, DOI 10.1109/LSP.2003.813680; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Park CH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P243, DOI 10.1109/ICDM.2003.1250926; Sanguinetti G, 2008, IEEE T PATTERN ANAL, V30, P535, DOI 10.1109/TPAMI.2007.70819; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Stewart G.W., 1999, MATRIX PERTURBATION; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tang W., 2009, P IEEE 9 INT C DAT M; Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Ye J., 2007, P ADV NEUR INF PROC; Ye JP, 2008, J MACH LEARN RES, V9, P719; Yu S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-309; Yu S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-28; Zha HY, 2002, ADV NEUR IN, V14, P1057; Zhou D., 2007, P 24 INT C MACH LEAR; Zipf G. K., 1949, HUMAN BEHAVIOUR PRIN	51	157	174	3	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					1031	1039		10.1109/TPAMI.2011.255	http://dx.doi.org/10.1109/TPAMI.2011.255			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22442124				2022-12-18	WOS:000301747400016
J	Shechtman, E; Caspi, Y; Irani, M				Shechtman, E; Caspi, Y; Irani, M			Space-time super-resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						super-resolution; space-time analysis; temporal resolution; motion blur; motion aliasing; high-quality video; fast cameras	RESOLUTION	We propose a method for constructing a video sequence of high space-time resolution by combining information from multiple low-resolution video sequences of the same dynamic scene. Super-resolution is performed simultaneously in time and in space. By "temporal super-resolution," we mean recovering rapid dynamic events that occur faster than regular frame-rate. Such dynamic events are not visible ( or else are observed incorrectly) in any of the input sequences, even if these are played in "slow-motion." The spatial and temporal dimensions are very different in nature, yet are interrelated. This leads to interesting visual trade-offs in time and space and to new video applications. These include: 1) treatment of spatial artifacts (e.g., motion-blur) by increasing the temporal resolution and 2) combination of input sequences of different space-time resolutions (e.g., NTSC, PAL, and even high quality still images) to generate a high quality video sequence. We further analyze and compare characteristics of temporal super-resolution to those of spatial super-resolution. These include: How many video cameras are needed to obtain increased resolution? What is the upper bound on resolution improvement via super-resolution? What is the temporal analogue to the spatial "ringing" effect?	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel	Weizmann Institute of Science; Tel Aviv University	Shechtman, E (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, Ziskind Bldg,Room 36, IL-76100 Rehovot, Israel.	eli.shechtman@weizmann.ac.il; caspiy@tau.ac.il; michal.irani@weizmann.ac.il	Shechtman, Eli/B-2736-2012					Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BLAKE A, 1996, P EUR C COMP VIS, P312; Borman S., 1998, SPATIAL RESOLUTION E; Born M., 1968, PRINCIPLES OPTICS; Capel D, 2000, INT C PATT RECOG, P600, DOI 10.1109/ICPR.2000.905409; Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709; Capel D., 2001, THESIS U OXFORD; Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148; de Haan G, 2000, IEEE T CONSUM ELECTR, V46, P449, DOI 10.1109/30.883392; ELAD M, 1996, THESIS TECHNION ISRA; Greenspan H, 2002, MAGN RESON IMAGING, V20, P437, DOI 10.1016/S0730-725X(02)00511-8; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Laude V, 1999, OPT COMMUN, V163, P72, DOI 10.1016/S0030-4018(99)00105-4; LIN Z, 2001, P IEEE C COMP VIS PA; Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592; PRICE JR, 2001, SPIE VISUAL COMM IMA, V4310; *RET, REALVIZ; SHECHTMAN E, 2002, P 7 EUR C COMP VIS, V1, P753; SHECHTMAN E, 2003, THESIS WEIZMANN I SC; TROTTENBER U, 2000, MULTIGRID; Tsai, 1984, ADV COMPUTER VISION, V1, P317	23	157	171	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					531	545		10.1109/TPAMI.2005.85	http://dx.doi.org/10.1109/TPAMI.2005.85			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794159	Green Submitted			2022-12-18	WOS:000226845700005
J	Yitzhaky, Y; Peli, E				Yitzhaky, Y; Peli, E			A method for objective edge detection evaluation and detector parameter selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection evaluation; detector parameters; receiver operating characteristics	DETECTION ALGORITHMS; PERFORMANCE	Subjective evaluation by human observers is usually used to analyze and select an edge detector parametric setup when real-world images are considered. In this paper, we propose a statistical objective performance analysis and detector parameter selection, using detection results produced by different detector parameters. Using the correspondence between the different detection results, an estimated best edge map, utilized as an estimated ground truth (EGT), is obtained. This is done using both a receiver operating characteristics (ROC) analysis and a Chi-square test, and considers the trade off between information and noisiness in the detection results. The best edge detector parameter set (PS) is then selected by the same statistical approach, using the EGT. Results are demonstrated for several edge detection techniques, and compared to published subjective evaluation results. The method developed here suggests a general tool to assist in practical implementations of parametric edge detectors where an automatic process is required.	Harvard Univ, Sch Med, Schepens Eye Res Inst, Boston, MA 02114 USA	Harvard University; Harvard Medical School; Schepens Eye Research Institute	Yitzhaky, Y (corresponding author), Harvard Univ, Sch Med, Schepens Eye Res Inst, 20 Stanford St, Boston, MA 02114 USA.		Yitzhaky, Yitzhak/AAD-6839-2022; YITZHAKY, YITZHAK/F-1446-2012	Peli, Eli/0000-0002-1340-9257; yitzhaky, yitzhak/0000-0002-4974-9683				BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; EVERINGHAM MR, 2002, P 7 EUR C COMP VIS M, pR4; FARM JR, 1975, IEEE T COMPUT, V24, P616; HARALICK RM, 1990, PATTERN RECOGN, V23, P1, DOI 10.1016/0031-3203(90)90045-M; Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587; Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893; KANUNGO T, 1995, IEEE T IMAGE PROCESS, V4, P1667, DOI 10.1109/83.475516; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; Kraemer H. C., 1992, EVALUATING MED TESTS; Lindeberg T., 1994, SCALE SPACE THEORY C; Macmillan NA., 2005, DETECTION THEORY USE, VSecond; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Peli E, 2002, P IEEE, V90, P78, DOI 10.1109/5.982407; PELI T, 1982, COMPUT VISION GRAPH, V20, P1, DOI 10.1016/0146-664X(82)90070-3; SHAH M, 1986, COMPUT VISION GRAPH, V34, P321, DOI 10.1016/S0734-189X(86)80046-9; SHIN M, 1998, EMPIRICAL EVALUATION, P235; Shin MC, 2001, COMPUT VIS IMAGE UND, V84, P160, DOI 10.1006/cviu.2001.0932; Zhu QM, 1996, IMAGE VISION COMPUT, V14, P21, DOI 10.1016/0262-8856(95)01036-X; ZIOUAND D, 1997, 195 U SHERBR DEP MAT	21	157	179	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					1027	1033		10.1109/TPAMI.2003.1217608	http://dx.doi.org/10.1109/TPAMI.2003.1217608			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ					2022-12-18	WOS:000184249800009
J	Saha, PK; Udupa, JK				Saha, PK; Udupa, JK			Optimum image thresholding via class uncertainty and region homogeneity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; thresholding; uncertainty; scale; homogeneity; threshold energy; segmented image information	FUZZY-CONNECTEDNESS; SELECTION METHOD; SEGMENTATION; ENTROPY; QUANTIFICATION; DEFINITION; ALGORITHMS	Thresholding is a popular image segmentation method that converts a gray-level image into a binary image. The selection of optimum thresholds has remained a challenge over decades. Besides being a segmentation tool on its own, often it is also a step in many advanced image segmentation techniques in spaces other than the image space. Most of the thresholding methods reported to date are based on histogram analysis using information-theoretic approaches. These methods have not harnessed the information captured in image morphology. Here, we introduce a novel thresholding method that accounts for both intensity-based class uncertainty-a histogram-based property-and region homogeneity-an image morphology-based property. A scale-based formulation is used for region homogeneity computation. At any threshold, intensity-based class uncertainty is computed by fitting a Gaussian to the intensity distribution of each of the two regions segmented at that threshold. The theory of the optimum thresholding method is based on the postulate that objects manifest themselves with fuzzy boundaries in any digital image acquired by an imaging device. The main idea here is to select that threshold at which pixels with high class uncertainty accumulate mostly around object boundaries. To achieve this, a new threshold energy criterion is formulated using class-uncertainty and region homogeneity such that, at any image location, a high energy is created when both class uncertainty and region homogeneity are high or both are low. Finally, the method selects that threshold which corresponds to the minimum overall energy. The method has been compared to a recently published maximum segmented image information (MSII) method. Superiority of the proposed method was observed both qualitatively on clinical medical images as well as quantitatively on 250 realistic phantom images generated by adding different degrees of blurring, noise, and background variation to real objects segmented from clinical images.	Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA	University of Pennsylvania	Saha, PK (corresponding author), Univ Penn, Dept Radiol, Med Image Proc Grp, 4th Floor,Blockley Hall,423 Guardian Dr, Philadelphia, PA 19104 USA.	saha.@mipg.upenn.edu; jay@mipg.upenn.edu	Saha, Punam K/F-8833-2011	Saha, Punam/0000-0003-1576-118X				ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; Brink A., 1994, Journal of Computing and Information Technology - CIT, V2, P77; CHENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683; DOYLE W, 1962, J ACM, V9, P259, DOI 10.1145/321119.321123; Duda R.O., 1973, J ROYAL STAT SOC SER; DUNN SM, 1984, IEEE T PATTERN ANAL, V6, P742, DOI 10.1109/TPAMI.1984.4767597; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; GLASBEY CA, 1993, P GRAPHICAL MODELS I, V5, P532; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kaufmann A., 1975, INTRO THEORY FUZZY S; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X; Leung CK, 1998, GRAPH MODEL IM PROC, V60, P57, DOI 10.1006/gmip.1997.0455; LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PAL NR, 1991, IEEE T SYST MAN CYB, V21, P1260, DOI 10.1109/21.120079; PAL NR, 1989, SIGNAL PROCESS, V16, P97, DOI 10.1016/0165-1684(89)90090-X; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563; PREWITT JMS, 1966, ANN NY ACAD SCI, V128, P1035; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039; Ronser B., 1995, FUNDAMENTALS BIOSTAT; Saha PK, 2000, PROC SPIE, V3979, P180, DOI 10.1117/12.387665; Saha PK, 2000, PROC SPIE, V3979, P735, DOI 10.1117/12.387736; Saha PK, 1999, P SOC PHOTO-OPT INS, V3661, P246, DOI 10.1117/12.348579; Saha PK, 1999, PROC SPIE, V3661, P266, DOI 10.1117/12.348581; Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Sarkar A, 2000, IEEE T IMAGE PROCESS, V9, P801, DOI 10.1109/83.841527; Shannon C.E., 1964, MATH THEORY COMMUNIC; Singh M, 1993, FDN MED IMAGING; TRUSSELL HJ, 1979, IEEE T SYST MAN CYB, V9, P311, DOI 10.1109/TSMC.1979.4310204; TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; VELTHUIZEN RP, 1995, JMRI-J MAGN RESON IM, V5, P594, DOI 10.1002/jmri.1880050520; WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351	39	157	167	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2001	23	7					689	706		10.1109/34.935844	http://dx.doi.org/10.1109/34.935844			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	449TV					2022-12-18	WOS:000169704000001
J	Samson, C; Blanc-Feraud, L; Aubert, G; Zerubia, J				Samson, C; Blanc-Feraud, L; Aubert, G; Zerubia, J			A variational model for image classification and restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variational model; classification; labeling; phase transition theory; edge-preserving regularization; minimization; satellite images	EDGE-PRESERVING REGULARIZATION; MINIMAL INTERFACE CRITERION; PHASE-TRANSITIONS; LOCAL MINIMIZERS; BOUNDARY MOTION; GRADIENT THEORY; RANDOM-FIELDS; EM ALGORITHM; SEGMENTATION; RECOVERY	Herein, we present a variational model devoted to image classification coupled with an edge-preserving regularization process. The discrete nature of classification (i.e., to attribute a label to each pixel) has led to the development of many probabilistic image classification models, but rarely to variational ones. In the last decade, the variational approach has proven its efficiency in the field of edge-preserving restoration. In this paper, we add a classification capability which contributes to provide images composed of homogeneous regions with regularized boundaries, a region being defined as a set of pixels belonging to the same class. The soundness of our model is based on the works developed on the phase transition theory in mechanics. The proposed algorithm is fast, easy to implement, and efficient. We compare our results on both synthetic and satellite images with the ones obtained by a stochastic model using a Potts regularization.	INRIA Sophia Antipolis, Projet Ariana, F-06902 Sophia Antipolis, France; Univ Nice, UNSA, Lab JA Dieudonne, UMR 6621 CNRS, F-06108 Nice 2, France	UDICE-French Research Universities; Universite Cote d'Azur	Samson, C (corresponding author), INRIA Sophia Antipolis, Projet Ariana, 2004 Route Lucioles,BP 93, F-06902 Sophia Antipolis, France.							ALLEN SM, 1979, ACTA METALL MATER, V27, P1085, DOI 10.1016/0001-6160(79)90196-2; ALVAREZ J, 1992, J ASTHMA, V29, P3, DOI 10.3109/02770909209110635; AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805; AMBROSIO L, 1992, B UNIONE MAT ITAL, V6B, P105; ANGENENT S, 1989, ARCH RATIONAL MECH A, V108, P333; Aubert G, 1997, SIAM J NUMER ANAL, V34, P1948, DOI 10.1137/S003614299529230X; BALDO S, 1990, ANN I H POINCARE-AN, V7, P67; BARLES G, 1992, ANN I H POINCARE-AN, V9, P479, DOI 10.1016/S0294-1449(16)30228-1; BELLETTINI G, 1991, CALCOLO, V27, P251; Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6; BLAKE A, 1994, IEEE T IMAGE PROCESS, V3, P162; BRONSARD L, 1993, ARCH RATION MECH AN, V124, P355, DOI 10.1007/BF00375607; CAGINALP G, 1989, PHYS REV A, V39, P5887, DOI 10.1103/PhysRevA.39.5887; CAHN JW, 1958, J CHEM PHYS, V28, P258, DOI 10.1063/1.1744102; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1997, INT J COMPUT VISION, V22, P6; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; De Giorgi E., 1979, P INT M REC METH NON; Descombes X., 1997, Traitement du Signal, V14, P373; DESCOMBES X, 1999, IEEE T IMAGE PROCESS; FONSECA I, 1989, P ROY SOC EDINB A, V111, P89, DOI 10.1017/S030821050002504X; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN S, 1985, P AM STAT ASS STAT C, P11; Giusti E., 1984, MONOGRAPHS MATH; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; HEBERT T, 1989, IEEE T MED IMAGING, V8, P194, DOI 10.1109/42.24868; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KATO Z, 1994, THESIS U NICE SOPHIA; Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MALLADI R, 1994, P 3 EUR C COMP VIS, P3; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; March R, 1997, IMAGE VISION COMPUT, V15, P705, DOI 10.1016/S0262-8856(97)00002-4; MARCH R, 1992, IMAGE VISION COMPUT, V10, P30, DOI 10.1016/0262-8856(92)90081-D; MODICA L, 1987, ARCH RATION MECH AN, V98, P123, DOI 10.1007/BF00251230; Morel J.-M., 1995, VARIATIONAL METHODS; MUMFORD D., 1985, P IEEE C COMP VIS PA; OWEN NC, 1991, NONLINEAR ANAL-THEOR, V16, P705, DOI 10.1016/0362-546X(91)90177-3; PAVLIDIS T, 1988, P IEEE COMP VIS PATT; Reitich F, 1996, P ROY SOC EDINB A, V126, P837, DOI 10.1017/S0308210500023106; RUBINSTEIN J, 1989, SIAM J APPL MATH, V49, P116, DOI 10.1137/0149007; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SAMSON C, 1998, RR3523 INRIA; STERNBERG P, 1994, P ROY SOC EDINB A, V124, P1059, DOI 10.1017/S0308210500030110; STERNBERG P, 1991, ROCKY MT J MATH, V21, P799, DOI 10.1216/rmjm/1181072968; Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189; Teo PC, 1997, IEEE T MED IMAGING, V16, P852, DOI 10.1109/42.650881; Tikhonov A., 1977, SOLUTIONS ILL POSED; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	49	157	164	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					460	472		10.1109/34.857003	http://dx.doi.org/10.1109/34.857003			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500004
J	REISS, TH				REISS, TH			THE REVISED FUNDAMENTAL THEOREM OF MOMENT INVARIANTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MOMENT INVARIANTS; FEATURE EXTRACTION; PATTERN RECOGNITION; INVARIANCE; LINEAR TRANSFORMATIONS; ALGEBRAIC INVARIANTS	IMAGE-ANALYSIS; RECOGNITION; IDENTIFICATION	The theory of moment invariants for pattern recognition was first introduced by Hu in 1962 [2], when he stated the fundamental theorem of moment invariants. The theorem in the original paper [2] is in fact incorrect; as a result, the four absolute moment invariants under general linear transformations in [2] are in error. This correspondence presents the revised fundamental theorem and gives the corresponding absolute moment invariants under general linear transformations. New invariants based on these but also invariant to changes in illumination are presented.			REISS, TH (corresponding author), UNIV CAMBRIDGE,DEPT ENGN,SIGNAL PROC & COMMUN LAB,CAMBRIDGE,ENGLAND.							ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617; ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; Chen K., 1990, Pattern Recognition, V23, P109, DOI 10.1016/0031-3203(90)90053-N; CYGANSKI D, 1985, IEEE T PATTERN ANAL, V7, P662, DOI 10.1109/TPAMI.1985.4767722; DIRILTEN H, 1977, IEEE T COMPUT, V26, P314, DOI 10.1109/TC.1977.1674832; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; GUREVICH GB, 1964, F THEORY ALGEBRAIC I; HATAMIAN M, 1986, IEEE T ACOUST SPEECH, V34, P546, DOI 10.1109/TASSP.1986.1164853; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HU MK, 1961, P IRE, V49, P1428; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063; LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836; MAITRA S, 1979, P IEEE, V67, P697, DOI 10.1109/PROC.1979.11309; SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990; SALMON G, 1885, LESSONS INTRO MODERN, P111; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8	20	157	175	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					830	834		10.1109/34.85675	http://dx.doi.org/10.1109/34.85675			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200010
J	BLEHA, S; SLIVINSKY, C; HUSSIEN, B				BLEHA, S; SLIVINSKY, C; HUSSIEN, B			COMPUTER-ACCESS SECURITY SYSTEMS USING KEYSTROKE DYNAMICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											BLEHA, S (corresponding author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65211, USA.							ALMUALLIM H, 1987, IEEE T PATTERN ANAL, V9; Bailey R. W., 1982, HUMAN PERFORMANCE EN; BAIRD HS, 1986, COMPUTER VISION PATT; BILLS G, 1985, P IEEE C FRONTIERS E; BLEHA S, 1988, THESIS U MISSOURI CO; Duda R.O., 1973, J ROYAL STAT SOC SER; EDEN M, 1962, IRE T INFORM THEOR, V8, P160, DOI 10.1109/TIT.1962.1057695; HAN KS, 1973, IEEE T SYST MAN CYB, VSMC3, P410; HERBST NM, 1977, IBM J RES DEV, P245; Hicks CR., 1966, FUNDAMENTAL CONCEPTS; Hoaglin D.C., 1983, UNDERSTANDING ROBUST; HUSSIEN B, 1989, PATTERN RECOGN LETT, V9, P39, DOI 10.1016/0167-8655(89)90026-3; LAMARCHE F, 1984, 7TH P INT C PATT REC; LEW JS, 1980, IBM J RES DEV, V24, P496, DOI 10.1147/rd.244.0496; LIU CN, 1979, IEEE T SYST MAN CYBE, V9; LORETTE G, 1984, 7TH P INT C PATT REC; MCLAREN R, 1972, BIOMEDICAL S C P SAN; O'Shaughnessy D., 1986, IEEE ASSP Magazine, V3, P4, DOI 10.1109/MASSP.1986.1165388; Rabiner L., 1978, DIGITAL PROCESSING S; TAPPERT C, 1984, 7TH P INT C PATT REC; TERZOPOULOS D, 1985, IEEE T ACOUST SPEECH, V33, P5, DOI 10.1109/TASSP.1985.1164511; Tou J.T., 1981, PATTERN RECOGNITION; TOU JT, 1982, P IEEE C IMAGE PROCE; VERDENBREGT J, 1971, PHILLIPS TECH REV, V32, P73; ZIMMERMANN KP, 1978, 1978 P CARN C CRIM C, P153	25	157	168	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1217	1222		10.1109/34.62613	http://dx.doi.org/10.1109/34.62613			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000012
J	SIEW, LH; HODGSON, RM; WOOD, EJ				SIEW, LH; HODGSON, RM; WOOD, EJ			TEXTURE MEASURES FOR CARPET WEAR ASSESSMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SIEW, LH (corresponding author), UNIV CANTERBURY,DEPT ELECT & ELECTR ENGN,CHRISTCHURCH 1,NEW ZEALAND.							BAILEY DG, 1985, THESIS U CANTERBURY; CARNABY GA, 1978, TEXT RES J, V48, P234, DOI 10.1177/004051757804800406; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; DURRANT PJ, 1984, WRONZ C93 COMM; Ehrler P, 1974, TEXTIL PRAXIS, V29, P446; Galloway MM., 1975, COMPUT GRAPHICS IMAG, V4, DOI DOI 10.1016/S0146-664X(75)80008-6; GOOL LV, 1985, COMPUTER VISION GRAP, V29, P336; HARALICK RM, 1973, IEEE T GEOSCI REMOTE, VGE11, P171, DOI 10.1109/TGE.1973.294312; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; LUNING R, 1979, TEXTILBETRIEB, V97, P41; ROSS DA, 1986, TEXTILE HORIZONS FEB, P29; ROSS DP, 1984, THESIS U MARYLAND; SIEW LH, 1987, THESIS U CANTERBURY; Sun C., 1982, COMPUT VIS IMAGE PRO, V23, P341; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; WOOD EJ, 1987, C105 WOOL RES ORG NZ; 1983, BCTC1 BRIT CARP TECH; 1966, ASTM D240167 DES	19	157	166	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					92	105		10.1109/34.3870	http://dx.doi.org/10.1109/34.3870			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600009
J	KAHAN, S; PAVLIDIS, T; BAIRD, HS				KAHAN, S; PAVLIDIS, T; BAIRD, HS			ON THE RECOGNITION OF PRINTED CHARACTERS OF ANY FONT AND SIZE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									AT&T BELL LABS,MURRAY HILL,NJ 07974	AT&T; Nokia Corporation; Nokia Bell Labs	KAHAN, S (corresponding author), UNIV WASHINGTON,DEPT COMP SCI,SEATTLE,WA 98195, USA.							ALDEFELD B, 1980, AT&T TECH J, V59, P1343, DOI 10.1002/j.1538-7305.1980.tb03367.x; BADIE K, 1985, 4TH P SCAND IM AN C, V2, P655; Baird H. S., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P150; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BENTLEY JL, 1979, COMPUT SURV, V11, P397, DOI 10.1145/356789.356797; BLEY H, 1984, COMPUT VISION GRAPH, V28, P271, DOI 10.1016/S0734-189X(84)80008-0; COX CH, 1982, PATTERN RECOGN, V15, P11, DOI 10.1016/0031-3203(82)90056-5; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; HATTICH W, 1978, 4TH P INT C PATT REC, P786; KAHAN S, 1985, THESIS U CALIFORNIA; LAM S, 1986, ATT126 BELL LABS COM; MCILROY MD, 1982, IEEE T COMMUN, V30, P91, DOI 10.1109/TCOM.1982.1095395; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Nagy G, 1982, HDB STATISTICS, V2, P621; PAVLIDIS T, 1986, IN PRESS COMPUTER VI, V35; SCHILLMAN RJ, 1974, THESIS MIT; SCHURMANN J, 1982, 1982 P INT C PATT RE, P1031; SRIHARI S, 1984, COMPUTER TEXT RECOGN; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; Ullmann J. R., 1976, Digital picture analysis, P295; YAMAMOTO K, 1978, 4TH P C PATT REC KYO, P794	22	157	166	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					274	288		10.1109/TPAMI.1987.4767901	http://dx.doi.org/10.1109/TPAMI.1987.4767901			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869397				2022-12-18	WOS:A1987G163300008
J	Pan, JS; Hu, Z; Su, ZX; Yang, MH				Pan, Jinshan; Hu, Zhe; Su, Zhixun; Yang, Ming-Hsuan			L-0-Regularized Intensity and Gradient Prior for Deblurring Text Images and Beyond	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image deblurring; L-0-regularized prior; text images; low-illumination images; natural images	CAMERA SHAKE; REMOVAL	We propose a simple yet effective L-0-regularized prior based on intensity and gradient for text image deblurring. The proposed image prior is based on distinctive properties of text images, with which we develop an efficient optimization algorithm to generate reliable intermediate results for kernel estimation. The proposed algorithm does not require any heuristic edge selection methods, which are critical to the state-of-the-art edge-based deblurring methods. We discuss the relationship with other edge-based deblurring methods and present how to select salient edges more principally. For the final latent image restoration step, we present an effective method to remove artifacts for better deblurred results. We show the proposed algorithm can be extended to deblur natural images with complex scenes and low illumination, as well as non-uniform deblurring. Experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art image deblurring methods.	[Pan, Jinshan; Su, Zhixun] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China; [Pan, Jinshan; Hu, Zhe; Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA 95344 USA; [Su, Zhixun] Natl Engn Res Ctr Digital Life, Guangzhou 510006, Guangdong, Peoples R China	Dalian University of Technology; University of California System; University of California Merced	Pan, JS (corresponding author), Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China.; Pan, JS (corresponding author), Univ Calif, Sch Engn, Merced, CA 95344 USA.	sdluran@gmail.com; zhu@ucmerced.edu; zxsu@dlut.edu.cn; mhyang@ucmerced.edu	Pan, Jinshan/S-3658-2019; Hu, Zhe/AAE-7207-2021; Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019; Pan, Jinshan/AAO-2258-2021	Yang, Ming-Hsuan/0000-0003-4848-2304; 	National Science Foundation CAREER [1149783]	National Science Foundation CAREER(National Science Foundation (NSF))	This work is supported in part by the National Science Foundation CAREER Grant 1149783.	Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413; Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954; Chen XG, 2011, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2011.5995568; Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; HaCohen Y, 2013, IEEE I CONF COMP VIS, P2384, DOI 10.1109/ICCV.2013.296; Harmeling S., 2010, ADV NEURAL INFORM PR, V23, P829; Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276; Hu Z, 2014, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2014.370; Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432; Hu Z, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.136; Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5; Jia J., 2014, MATH MODELS PRACTICA; Jia J., 2007, IEEE C COMP VIS PATT, P1; Jinshan Pan, 2013, IEEE Signal Processing Letters, V20, P841, DOI 10.1109/LSP.2013.2261986; Joshi N., 2008, CVPR, P1; Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392; Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D., 2011, CVPR, P2657; Krishnan D., 2009, ADV NEURAL INFORM PR, V22, P1033; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A., 2006, IEEE C COMP VIS PATT; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li TH, 2002, IEEE T IMAGE PROCESS, V11, P847, DOI 10.1109/TIP.2002.801127; Li X, 2012, IEEE C COMP INTEL FI, P1, DOI 10.1109/CIFEr.2012.6327833; Lou YF, 2011, J MATH IMAGING VIS, V39, P1, DOI 10.1007/s10851-010-0220-8; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Shan Q, 2007, IEEE I CONF COMP VIS, P738; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Whyte Oliver, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P745; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; [张华 ZHANG Hua], 2011, [高分子通报, Polymer Bulletin], P1; Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	50	156	176	7	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					342	355		10.1109/TPAMI.2016.2551244	http://dx.doi.org/10.1109/TPAMI.2016.2551244			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27071160	hybrid			2022-12-18	WOS:000395553400010
J	Vogiatzis, G; Hernandez, C; Torr, PHS; Cipolla, R				Vogiatzis, George; Hernandez, Carlos; Torr, Philip H. S.; Cipolla, Roberto			Multiview stereo via volumetric graph-cuts and occlusion robust photo-consistency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D/stereo scene analysis; shape; graph algorithms; global optimization	ENERGY MINIMIZATION; RECONSTRUCTION; ALGORITHMS	This paper presents a volumetric formulation for the multiview stereo problem which is amenable to a computationally tractable global optimization using Graph- cuts. Our approach is to seek the optimal partitioning of 3D space into two regions labeled as "object" and "empty" under a cost functional consisting of the following two terms: 1) A term that forces the boundary between the two regions to pass through photo- consistent locations and 2) a ballooning term that inflates the "object" region. To take account of the effect of occlusion on the first term, we use an occlusion robust photo- consistency metric based on Normalized Cross Correlation, which does not assume any geometric knowledge about the reconstructed object. The globally optimal 3D partitioning can be obtained as the minimum cut solution of a weighted graph.	Toshiba Res Europe Ltd, Cambridge CB4 0GZ, England; Oxford Brookes Univ, Dept Comp, Brookes Comp Vis Grp, Oxford OX33 1HX, England; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Toshiba Corporation; Oxford Brookes University; University of Cambridge	Vogiatzis, G (corresponding author), Toshiba Res Europe Ltd, 208 Cambridge Sci Pk,Milton Rd, Cambridge CB4 0GZ, England.	george.vogiatzis@crl.toshiba.co.uk; carlos.hernandez@crl.toshiba.co.uk; philiptorr@brookes.ac.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Vogiatzis, George/0000-0002-3226-0603; Cipolla, Roberto/0000-0002-8999-2151				Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; BOYKOV Y, 2006, P BRIT MACH VIS C, P1149; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; FURUKAWA Y, 2006, P EUR C COMP VIS, V1, P564; GOESELE M, 2006, P IEEE C COMP VIS PA, V2, P2402; Hernandez C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42; Hornung A., 2006, COMP VIS PATT REC 20, V1, P503, DOI 10.1109/CVPR.2006.135; KOLMOGOROV V, 2002, IEEE T PATTERN ANAL, V3, P82; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Lempitsky V, 2006, LECT NOTES COMPUT SC, V3953, P226, DOI 10.1007/11744078_18; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; ROY S, 1998, P ICCV 1998, P735; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; STARCK J, 2006, P BRIT MACH VIS C, V3, P1189; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; Sun J, 2002, LECT NOTES COMPUT SC, V2351, P510; TRAN S, 2006, P EUR C COMP VIS, V2, P218; Vogiatzis G, 2005, PROC CVPR IEEE, P391	28	156	165	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2241	2246		10.1109/TPAMI.2007.70712	http://dx.doi.org/10.1109/TPAMI.2007.70712			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934232	Green Submitted			2022-12-18	WOS:000250087900015
J	Cohen, I; Cozman, FG; Sebe, N; Cirelo, MC; Huang, TS				Cohen, I; Cozman, FG; Sebe, N; Cirelo, MC; Huang, TS			Semisupervised learning of classifiers: Theory, algorithms, and their application to human-computer interaction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						semisupervised learning; generative models; facial expression recognition; face detection; unlabeled data; Bayesian network classifiers	MAXIMUM-LIKELIHOOD; DISCRIMINANT-ANALYSIS; FACIAL EXPRESSIONS; BAYESIAN NETWORKS; EFFICIENCY; SAMPLES	Automatic classification is one of the basic tasks required in any pattern recognition and human computer interaction application. In this paper, we discuss training probabilistic classifiers with labeled and unlabeled data. We provide a new analysis that shows under what conditions unlabeled data can be used in learning to improve classification performance. We also show that, if the conditions are violated, using unlabeled data can be detrimental to classification performance. We discuss the implications of this analysis to a specific type of probabilistic classifiers, Bayesian networks, and propose a new structure learning algorithm that can utilize unlabeled data to improve classification. Finally, we show how the resulting algorithms are successfully employed in two applications related to human-computer interaction and pattern recognition: facial expression recognition and face detection.	Hewlett Packard Labs, Palo Alto, CA 94304 USA; Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil; Univ Amsterdam, Fac Sci, NL-1012 WX Amsterdam, Netherlands; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Hewlett-Packard; Universidade de Sao Paulo; University of Amsterdam; University of Illinois System; University of Illinois Urbana-Champaign	Cohen, I (corresponding author), Hewlett Packard Labs, 1501 Page Mill Rd, Palo Alto, CA 94304 USA.	ira.cohen@hp.com; fgcozman@usp.br; nicu@science.uva.nl; marcelo.cirelo@poli.usp.br; huang@ifp.uiuc.edu		Gagliardi Cozman, Fabio/0000-0003-4077-4935; Sebe, Niculae/0000-0002-6597-7248				AHMED SW, 1977, CLASSIFICATION CLUST, P331; Allen T.V., 2000, P 17 INT C MACH LEAR, P1047; BALUJA S, 1998, P NEUR INF PROC SYST, P854; Bennett KP, 1999, ADV NEUR IN, V11, P368; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; BRUCE R, 2001, P INT JOINT C AI WOR; CASTELLI V, 1994, THESIS STANFORD U PA; Chen L., 2000, THESIS U ILLINOIS UR; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Cheng J, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P101; CHHIKARA RS, 1984, J AM STAT ASSOC, V79, P899, DOI 10.2307/2288722; CHITTINENI C, 1981, PATTERN RECOGN, V12, P271; Cohen I, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA121; Cohen I., 2003, THESIS U ILLINOIS UR; COHEN I, 2002, HPL2002140; COLLINS M, 2000, P INT C MACH LEARN, P327; COOPER DB, 1970, IEEE T COMPUT, VC 19, P1055, DOI 10.1109/T-C.1970.222832; CORDUNEANU A, 2002, P UNC ART INT UAI, P111; Cozman F. G., 2003, P 20 INT C MACH LEAR, P99; Cozman F. G., 2002, P 15 INT FLOR ART IN, P327; COZMAN FG, EFFECT MODELING ERRO; De Comite F, 1999, LECT NOTES ARTIF INT, V1720, P219; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268; Ekman P., 2002, FACIAL ACTION CODING; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRIEDMAN N, 1998, P 14 C UNC ART INT, P129; GANESALINGAM S, 1978, BIOMETRIKA, V65, P658, DOI 10.2307/2335925; Garg A, 2003, P IEEE, V91, P1355, DOI 10.1109/JPROC.2003.817119; Ghani R., 2002, P 19 INT C MACH LEAR, V2, P187; GOLDMAN S, 2000, P 17 INT C MACH LEAR, P327; Greiner K, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P167; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; HOSMER DW, 1973, BIOMETRICS, V29, P761, DOI 10.2307/2529141; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; KOHAVI R, 1996, P 2 INT C KNOWL DISC, P202; KRISHNAN T, 1990, PATTERN RECOGN, V23, P529, DOI 10.1016/0031-3203(90)90073-T; KRISHNAN T, 1990, PATTERN RECOGN, V23, P1275, DOI 10.1016/0031-3203(90)90121-Z; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MEILA M, 1999, THESIS MIT BOSTON; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Miller D. J., 1996, ADV NEURAL INFORM PR, V9, P571; *MIT CTR BIOL COMP, 2002, MIT CBCL FAC DAT 1; Mitchell T. M., 1999, P 6 INT C COGN SCI; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; OLIVER N, 2002, P IN C MULT INT ICMI; ONEILL TJ, 1978, J AM STAT ASSOC, V73, P821, DOI 10.2307/2286287; PAL SK, 2002, PATTERN RECOGNITION; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Pearl J., 2009, CAUSALITY MODELS REA, DOI [DOI 10.1017/CBO9780511803161, 10.1017/CBO9780511803161]; Ratsaby J., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, P412, DOI 10.1145/225298.225348; Roth D, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P898; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Spirtes P., 2000, CAUSATION PREDICTION; Tao H, 1998, PROC CVPR IEEE, P735, DOI 10.1109/CVPR.1998.698685; WHITE H, 1982, ECONOMETRICA, V50, P1, DOI 10.2307/1912526; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Zhang Tong, 2000, P 17 INT C MACHINE L, P1191	63	156	169	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1553	1567		10.1109/TPAMI.2004.127	http://dx.doi.org/10.1109/TPAMI.2004.127			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573817	Green Submitted			2022-12-18	WOS:000224388700002
J	KOENDERINK, JJ; VANDOORN, AJ				KOENDERINK, JJ; VANDOORN, AJ			GENERIC NEIGHBORHOOD OPERATORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BLURRING; EDGE FINDERS; GABOR FUNCTIONS; NEIGHBORHOOD OPERATORS; SCALE SPACE; SECTOR FILTER; SELF SIMILARITY	SIMPLE RECEPTIVE-FIELDS; CAT STRIATE CORTEX; VISUAL-SYSTEM; SCALE-SPACE; MODEL; REPRESENTATION	Linear neighborhood operators are fundamental tools for a large part of image processing. We present a method that treats such operators within a unified framework. This framework enables one to treat linear combinations, concatenations, resolution changes, or rotations of operators in a canonical manner. Various families of operators with special kinds of symmetries (such as translation, rotation, magnification) are explicitly constructed in 1-D, 2-D, and 3-D. A concept of "order" is defined, and finite orthonormal bases of functions closely connected with the operators of various orders are constructed. Linear transformations between the various representations are considered. One particular representation enables one to compile differential geometrical expressions immediately into local algorithms (e.g., for edge curvature). In this representation, the "order" is an order of derivation in a certain precisely defined sense. The method is based on two fundamental assumptions: First, a decrease of resolution should not introduce spurious detail (the basic requirement for a "scale space"), and second, the local operators should be self-similar under changes of resolution. These assumptions merely sum up the even more general need for homogeneity, isotropy, scale invariance, and separability of independent dimensions of front end processing in the absence of a priori information.			KOENDERINK, JJ (corresponding author), UTRECHT BIOPHYS RES INST,UTRECHT,NETHERLANDS.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BIJL P, 1989, VISION RES, V29, P447, DOI 10.1016/0042-6989(89)90008-4; BURTON GJ, 1986, BIOL CYBERN, V53, P397, DOI 10.1007/BF00318205; CANNY JF, 1983, MIT720 TECH REP; COGGINS JM, 1986, COMPUT METH PROG BIO, V22, P69, DOI 10.1016/0169-2607(86)90095-7; COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4; Gradshteyn IS., 2001, TABLES INTEGRALS SER; HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6; JONES JP, 1987, J NEUROPHYSIOL, V58, P1187, DOI 10.1152/jn.1987.58.6.1187; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; KOENDERINK JJ, 1988, J OPT SOC AM A, V5, P1136, DOI 10.1364/JOSAA.5.001136; KOENDERINK JJ, 1989, IEEE T PATTERN ANAL, V11, P1222, DOI 10.1109/34.42861; KOENDERINK JJ, 1988, BIOL CYBERN, V58, P163, DOI 10.1007/BF00364136; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; KOENDERINK JJ, 1978, BIOL CYBERN, V30, P157, DOI 10.1007/BF00337144; LOW KC, IN PRESS MULTISCALE; POWELL JL, 1961, QUANTUM MECHANICS; WATSON AB, 1987, J OPT SOC AM A, V4, P2401, DOI 10.1364/JOSAA.4.002401; YOUNG RA, 1985, GMR4920 GEN MOT RES; YUILLE AL, 1985, J OPT SOC AM A, V5, P683; ZUCKER SW, 1986, HUM NEUROBIOL, V5, P121	22	156	161	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					597	605		10.1109/34.141551	http://dx.doi.org/10.1109/34.141551			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600001
J	Gui, J; Liu, TL; Sun, ZN; Tao, DC; Tan, TN				Gui, Jie; Liu, Tongliang; Sun, Zhenan; Tao, Dacheng; Tan, Tieniu			Fast Supervised Discrete Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fast supervised discrete hashing; supervised discrete hashing; learning-based hashing; least squares regression	ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH; IMAGE; SCENE	Learning-based hashing algorithms are "hot topics" because they can greatly increase the scale at which existing methods operate. In this paper, we propose a new learning-based hashing method called "fast supervised discrete hashing" (FSDH) based on "supervised discrete hashing" (SDH). Regressing the training examples (or hash code) to the corresponding class labels is widely used in ordinary least squares regression. Rather than adopting this method, FSDH uses a very simple yet effective regression of the class labels of training examples to the corresponding hash code to accelerate the algorithm. To the best of our knowledge, this strategy has not previously been used for hashing. Traditional SDH decomposes the optimization into three sub-problems, with the most critical sub-problem - discrete optimization for binary hash codes - solved using iterative discrete cyclic coordinate descent (DCC), which is time-consuming. However, FSDH has a closed-form solution and only requires a single rather than iterative hash code-solving step, which is highly efficient. Furthermore, FSDH is usually faster than SDH for solving the projection matrix for least squares regression, making FSDH generally faster than SDH. For example, our results show that FSDH is about 12-times faster than SDH when the number of hashing bits is 128 on the CIFAR-10 data base, and FSDH is about 151-times faster than FastHash when the number of hashing bits is 64 on the MNIST data-base. Our experimental results show that FSDH is not only fast, but also outperforms other comparative methods.	[Gui, Jie] Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Anhui, Peoples R China; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, UBTech Sydney Artificial Intelligence Inst, Fac Engn & Informat Technol, J12 Cleveland St, Darlington, NSW 2008, Australia; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Sch Informat Technol, Fac Engn & Informat Technol, J12 Cleveland St, Darlington, NSW 2008, Australia; [Sun, Zhenan; Tan, Tieniu] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Sun, Zhenan; Tan, Tieniu] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS; University of Sydney; University of Sydney; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences	Gui, J (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Anhui, Peoples R China.	guijie@ustc.edu; tliang.liu@gmail.com; znsun@nlpr.ia.ac.cn; dacheng.tao@sydney.edu.au; tnt@nlpr.ia.ac.cn	Liu, Tongliang/AAA-1506-2021	Liu, Tongliang/0000-0002-9640-6472; Wang, Yunlong/0000-0002-3535-308X	National Science Foundation of China [61572463, 61573360]; "Thirteenth Five-Year" National Key Research and Development Program of China [2016YFD0702002]; grant of Strategic Priority Research Program of the Chinese Academy of Sciences [XDB02080007]; grant of the Open Project Program of the National Laboratory of Pattern Recognition (NLPR) [201700027]; grant of the Open Project Program of the State Key Lab of CADCG [A1709]; Zhejiang University; grant of the Shanghai Key Laboratory of Intelligent Information Processing, China [IIPL-2016-003]; grant of Australian Research Council Projects [FT-130101457, DP-140102164, LP-150100671]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); "Thirteenth Five-Year" National Key Research and Development Program of China; grant of Strategic Priority Research Program of the Chinese Academy of Sciences; grant of the Open Project Program of the National Laboratory of Pattern Recognition (NLPR); grant of the Open Project Program of the State Key Lab of CADCG; Zhejiang University; grant of the Shanghai Key Laboratory of Intelligent Information Processing, China; grant of Australian Research Council Projects(Australian Research Council)	This work was supported in part by the grant of the National Science Foundation of China under Grant 61572463 and Grant 61573360, in part by the "Thirteenth Five-Year" National Key Research and Development Program of China under Grant 2016YFD0702002, in part by the grant of Strategic Priority Research Program of the Chinese Academy of Sciences under Grant XDB02080007, in part by the grant of the Open Project Program of the National Laboratory of Pattern Recognition (NLPR) under Grant 201700027, in part by the grant of the Open Project Program of the State Key Lab of CAD&CG under Grant A1709, Zhejiang University, in part by the grant of the Shanghai Key Laboratory of Intelligent Information Processing, China under Grant IIPL-2016-003, and in part by the grant of Australian Research Council Projects under Grant FT-130101457, Grant DP-140102164, and Grant LP-150100671. All correspondence should be directed to Zhenan Sun. Jie Gui and Tongliang Liu contribute equally to this paper.	Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gui J, 2018, IEEE T NEUR NET LEAR, V29, P608, DOI 10.1109/TNNLS.2016.2636870; Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634; Korman S, 2016, IEEE T PATTERN ANAL, V38, P1099, DOI 10.1109/TPAMI.2015.2477814; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Li W., 2016, INT JOINT C ARTIFICI, P1711; Lin GS, 2015, IEEE T PATTERN ANAL, V37, P2317, DOI 10.1109/TPAMI.2015.2404776; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin K, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301269; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu H, 2016, AAAI CONF ARTIF INTE, P1258; Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Liu XL, 2016, IEEE T CYBERNETICS, V46, P2252, DOI 10.1109/TCYB.2015.2474742; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ou MD, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P230; Phillips J.J., 2005, PROC CVPR IEEE, V1, P947, DOI DOI 10.1109/CVPR.2005.268; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rastegari M., 2013, ICML; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925; Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225; Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315; Zhou WG, 2016, IEEE T PATTERN ANAL, V38, P159, DOI 10.1109/TPAMI.2015.2430329	38	155	160	0	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					490	496		10.1109/TPAMI.2017.2678475	http://dx.doi.org/10.1109/TPAMI.2017.2678475			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28287956	hybrid, Green Submitted			2022-12-18	WOS:000422706000017
J	Kembhavi, A; Harwood, D; Davis, LS				Kembhavi, Aniruddha; Harwood, David; Davis, Larry S.			Vehicle Detection Using Partial Least Squares	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vehicle detection; partial least squares; feature selection	CAR DETECTION; CLASSIFICATION; STRATEGY	Detecting vehicles in aerial images has a wide range of applications, from urban planning to visual surveillance. We describe a vehicle detector that improves upon previous approaches by incorporating a very large and rich set of image descriptors. A new feature set called Color Probability Maps is used to capture the color statistics of vehicles and their surroundings, along with the Histograms of Oriented Gradients feature and a simple yet powerful image descriptor that captures the structural characteristics of objects named Pairs of Pixels. The combination of these features leads to an extremely high-dimensional feature set (approximately 70,000 elements). Partial Least Squares is first used to project the data onto a much lower dimensional subspace. Then, a powerful feature selection analysis is employed to improve the performance while vastly reducing the number of features that must be calculated. We compare our system to previous approaches on two challenging data sets and show superior performance.	[Kembhavi, Aniruddha] Microsoft Corp, Aniruddk, City Ctr 16503, Redmond, WA 98052 USA; [Harwood, David; Davis, Larry S.] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	Microsoft; University System of Maryland; University of Maryland College Park	Kembhavi, A (corresponding author), Microsoft Corp, Aniruddk, City Ctr 16503, 1 Microsoft Way, Redmond, WA 98052 USA.	anikem@umd.edu; harwood@umiacs.umd.edu; lsd@cs.umd.edu						Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BERG A, 2001, P IEEE CS C COMP VIS; Boulesteix AL, 2007, BRIEF BIOINFORM, V8, P32, DOI 10.1093/bib/bb1016; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; CHOI JY, 2008, P 3 PAC RIM S ADV IM; Dalal N., 2005, P IEEE CS C COMP VIS; Eikvil L, 2009, ISPRS J PHOTOGRAMM, V64, P65, DOI 10.1016/j.isprsjprs.2008.09.005; Everingham M., 2008, PASCAL VISUAL OBJECT; GARTHWAITE PH, 1994, J AM STAT ASSOC, V89, P122, DOI 10.2307/2291207; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Grabner H, 2008, ISPRS J PHOTOGRAMM, V63, P382, DOI 10.1016/j.isprsjprs.2007.10.005; HEITZ G, 2008, P EUR C COMP VIS; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; HINZ S, 2003, P INT C IM PROC; Lazebnik S., 2006, P IEEE CS C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2009, P IEEE INT C COMP VI; Maji S., 2008, P IEEE C COMP VIS PA; Moon H, 2002, IMAGE VISION COMPUT, V20, P1, DOI 10.1016/S0262-8856(01)00059-2; Moon H, 2002, IEEE T IMAGE PROCESS, V11, P1209, DOI 10.1109/TIP.2002.800896; Morariu V. I., 2008, ADV NEURAL INFORM PR, V21; RAYKAR VC, 2006, P SIAM INT C DAT MIN; Reinikainen SP, 2003, J CHEMOMETR, V17, P130, DOI 10.1002/cem.770; SCHLOSSER C, 2003, P 2 GRSS ISPRS JOINT; Tanner F., 2009, P IEEE APPL IM PATT; Teofilo RF, 2009, J CHEMOMETR, V23, P32, DOI 10.1002/cem.1192; Viola P., 2002, INT J COMPUTER VISIO; Wold H., 1985, ENCY STAT SCI, DOI DOI 10.1002/0471667196; Wold H., 1966, MULTIVARIATE ANAL; Yue ZF, 2009, IEEE T CIRC SYST VID, V19, P77, DOI 10.1109/TCSVT.2008.2009243; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhao T, 2003, IMAGE VISION COMPUT, V21, P693, DOI 10.1016/S0262-8856(03)00064-7; ZHENG H, 2006, P INT C NEUR INF PRO; ZHU Q, 2006, P IEEE CS C COMP VIS	35	155	163	0	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1250	1265		10.1109/TPAMI.2010.182	http://dx.doi.org/10.1109/TPAMI.2010.182			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20921579				2022-12-18	WOS:000289524000013
J	Kim, SJ; Pollefeys, M				Kim, Seon Joo; Pollefeys, Marc			Robust radiometric calibration and vignetting correction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						radiometric response function; vignetting; radiometric image alignment; high dynamic range imaging	HIGH DYNAMIC-RANGE; CAMERA RESPONSE; IMAGE	In many computer vision systems, it is assumed that the image brightness of a point directly reflects the scene radiance of the point. However, the assumption does not hold in most cases due to nonlinear camera response function, exposure changes, and vignetting. The effects of these factors are most visible in image mosaics and textures of 3D models where colors look inconsistent and notable boundaries exist. In this paper, we propose a full radiometric calibration algorithm that includes robust estimation of the radiometric response function, exposures, and vignetting. By decoupling the effect of vignetting from the response function estimation, we approach each process in a manner that is robust to noise and outliers. We verify our algorithm with both synthetic and real data, which shows significant improvement compared to existing methods. We apply our estimation results to radiometrically align images for seamless mosaics and 3D model textures. We also use our method to create high dynamic range (HDR) mosaics that are more representative of the scene than normal mosaics.	[Kim, Seon Joo; Pollefeys, Marc] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA	University of North Carolina; University of North Carolina Chapel Hill	Kim, SJ (corresponding author), Univ N Carolina, Dept Comp Sci, Campus Box 3175, Chapel Hill, NC 27599 USA.	sjkim@cs.unc.edu; marc@cs.unc.edu	Pollefeys, Marc/I-7607-2013					Agathos A, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P139, DOI 10.1109/IM.2003.1240243; Aggarwal M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P472, DOI 10.1109/ICCV.2001.937554; ASADA N, 2001, P IEEE INT C PATT RE, P186; BASTUSCHECK CM, 1987, OPT ENG, V26, P1257, DOI 10.1117/12.7977165; Beauchesne E, 2003, PROC CVPR IEEE, P166; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; CHEN YP, 1986, P ACM SIGGRAPH, V12, P293; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Eden Ashley, 2006, 2006 IEEE COMPUTER S, V2, P2498; Goldman DB, 2005, IEEE I CONF COMP VIS, P899; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; Horn B., 1986, ROBOT VISION, P1; Jia JY, 2005, IEEE T PATTERN ANAL, V27, P36, DOI 10.1109/TPAMI.2005.20; Kang S.B., 2000, P ECCV, P640; Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270; Kim SJ, 2004, PROC CVPR IEEE, P645; LEVIN A, 2004, P EUR C COMP VIS, P377; Lin S, 2005, PROC CVPR IEEE, P66; Lin S, 2004, PROC CVPR IEEE, P938; Litvinov A, 2005, PROC CVPR IEEE, P52; Litvinov A, 2005, J OPT SOC AM A, V22, P839, DOI 10.1364/JOSAA.22.000839; Mann S, 2001, PROC CVPR IEEE, P842; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Pal C, 2004, PROC CVPR IEEE, P173; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; SAWCHUK AA, 1977, IEEE T COMPUT, V26, P34, DOI 10.1109/TC.1977.5009271; Schechner YY, 2003, INT J COMPUT VISION, V53, P245, DOI 10.1023/A:1023082924255; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; Uyttendaele M, 2004, IEEE COMPUT GRAPH, V24, P52, DOI 10.1109/MCG.2004.1297011; Yu W, 2004, IEEE T CONSUM ELECTR, V50, P975, DOI 10.1109/TCE.2004.1362487; Yu WP, 2004, INT C PATT RECOG, P666, DOI 10.1109/ICPR.2004.1334617; Zheng Y., 2006, P IEEE C COMP VIS PA, P461	37	155	171	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					562	576		10.1109/TPAMI.2007.70732	http://dx.doi.org/10.1109/TPAMI.2007.70732			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276964				2022-12-18	WOS:000253135600002
J	Hu, WM; Zhou, X; Tan, TN; Lou, JG; Maybank, S				Hu, WM; Zhou, X; Tan, TN; Lou, JG; Maybank, S			Principal axis-based correspondence between multiple cameras for people tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						correspondence between multiple cameras; principal axes; people tracking	MOTION; SURVEILLANCE	Visual surveillance using multiple cameras has attracted increasing interest in recent years. Correspondence between multiple cameras is one of the most important and basic problems which visual surveillance using multiple cameras brings. In this paper, we propose a simple and robust method, based on principal axes of people, to match people across multiple cameras. The correspondence likelihood reflecting the similarity of pairs of principal axes of people is constructed according to the relationship between "ground-points" of people detected in each camera view and the intersections of principal axes detected in different camera views and transformed to the same view. Our method has the following desirable properties: 1) Camera calibration is not needed. 2) Accurate motion detection and segmentation are less critical due to the robustness of the principal axis-based feature to noise. 3) Based on the fused data derived from correspondence results, positions of people in each camera view can be accurately located even when the people are partially occluded in all views. The experimental results on several real video sequences from outdoor environments have demonstrated the effectiveness, efficiency, and robustness of our method.	Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China; Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; University of London; Birkbeck University London	Hu, WM (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, POB 2728, Beijing 100080, Peoples R China.	wmhu@nlpr.ia.ac.cn; xzhou@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn; jglou@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk		Wang, Yunlong/0000-0002-3535-308X				BLACK J, 2001, P IEEE INT WORKSH PE, P68; Bradshaw KJ, 1997, IEEE T PATTERN ANAL, V19, P219, DOI 10.1109/34.584099; Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119; CHANG TH, 2000, P BRIT MACH VIS C, P566; Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341; Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340; Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617; FUENTES LM, 2001, P IEEE INT WORKSH PE, P20; Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Harwood D., 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; Kelly P. H, 1995, P ACM C MULT, P201; Kettnaker V., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P253, DOI 10.1109/CVPR.1999.784638; Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912; Khandkar MZH, 2001, J MATER PROCESS MANU, V10, P91, DOI 10.1177/1062065602010002613; Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852; Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678; McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870; Mittal A, 2002, LECT NOTES COMPUT SC, V2350, P18; Orwell J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P14, DOI 10.1109/VS.1999.780264; Pavlidis A, 2001, P IEEE, V89, P1478, DOI 10.1109/5.959342; SENIOR A, 2002, P ECCV WORKSH PERF E, P48; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Stein G. P., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P521, DOI 10.1109/CVPR.1999.786987; Stillman S., 1999, P INT C AUD VID BAS, P96; Tsutsui H, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P91, DOI 10.1109/MFI.2001.1013514; Utsumi A, 1998, INT C PATT RECOG, P597, DOI 10.1109/ICPR.1998.711214; Utsumi A, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P498, DOI 10.1109/AFGR.1998.670997; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; YANG YH, 1992, MACH VISION APPL, V5, P17; Zhao T, 2001, PROC CVPR IEEE, P194; Zhou Q., 2001, P IEEE INT WORKSH PE, P52	33	155	180	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					663	671		10.1109/TPAMI.2006.80	http://dx.doi.org/10.1109/TPAMI.2006.80			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566515	Green Submitted			2022-12-18	WOS:000235253300016
J	Grossberg, MD; Nayar, SK				Grossberg, MD; Nayar, SK			Modeling the space of camera response functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						radiometric response function; camera response function; calibration; real-world response curves; empirical modeling; high-dynamic range; recovery of radiometry; nonlinear response; gamma correction; photometry; sensor modeling	CALIBRATION; SHAPE	Many vision applications require precise measurement of scene radiance. The function relating scene radiance to image intensity of an imaging system is called the camera response. We analyze the properties that all camera responses share. This allows us to find the constraints that any response function must satisfy. These constraints determine the theoretical space of all possible camera responses. We have collected a diverse database of real-world camera response functions (DoRF). Using this database, we show that real-world responses occupy a small part of the theoretical space of all possible responses. We combine the constraints from our theoretical space with the data from DoRF to create a low-parameter empirical model of response (EMoR). This response model allows us to accurately interpolate the complete response function of a camera from a small number of measurements obtained using a standard chart. We also show that the model can be used to accurately estimate the camera response from images of an arbitrary scene taken using different exposures. The DoRF database and the EMoR model can be downloaded at http://www.cs.columbia.edu/CAVE.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Grossberg, MD (corresponding author), Columbia Univ, Dept Comp Sci, 500 W 120th St,Room 450, New York, NY 10027 USA.	mdog@cs.columbia.edu; nayar@cs.columbia.edu						ASADA N, 1996, P INT C PATT REC; Basri R, 2001, PROC CVPR IEEE, P374; Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222; Cabral B, 1999, COMP GRAPH, P165, DOI 10.1145/311535.311553; Chang YC, 1996, IEEE T IMAGE PROCESS, V5, P1414, DOI 10.1109/83.536890; Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864; Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884; Duda R.O., 2000, PATTERN CLASSIFICATI; *EASTM KOD, 2002, STUD FILMM HDB; Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; GILL PE, 1984, ACM T MATH SOFTWARE, V10, P282, DOI 10.1145/1271.1276; Gill PE, 1991, NUMERICAL LINEAR ALG, V1; GROSSBERG M, 2002, P ECCV, P189; GROSSBERG M, 2003, P IEEE C COMP VIS PA; HEALEY G, 1992, SPIE, V1614, P121; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Horn B.K.P., 1989, SHAPE SHADING; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Luong QT, 2002, IEEE T PATTERN ANAL, V24, P19, DOI 10.1109/34.982882; MADDEN BC, 1993, 366 U PENNS GRASP LA; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434; MANN S, 2001, P C COMP VIS PATT RE; Marschner SR, 2000, APPL OPTICS, V39, P2592, DOI 10.1364/AO.39.002592; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Narasimhan SG, 2001, PROC CVPR IEEE, P186; NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Yu YZ, 1999, COMP GRAPH, P215; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZICKLER T, 2002, P EUR C COMP VIS	34	155	167	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1272	1282		10.1109/TPAMI.2004.88	http://dx.doi.org/10.1109/TPAMI.2004.88			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641715				2022-12-18	WOS:000223140200003
J	Bobick, AF; Wilson, AD				Bobick, AF; Wilson, AD			A state-based approach to the representation and recognition of gesture	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						gesture recognition; state-based representation; gesture prototype; motion-based recognition	IMAGE SEQUENCES; MOTION; MODEL	A state-based technique for the representation and recognition of gesture is presented. We define a gesture to be a sequence of states in a measurement or configuration space. For a given gesture, these states are used to capture both the repeatability and variability evidenced in a training set of example trajectories. Using techniques for computing a prototype trajectory of an ensemble of trajectories, we develop methods for defining configuration states along the prototype and for recognizing gestures from an unsegmented, continuous stream of sensor data. The approach is illustrated by application to a range of gesture-related sensory data: the two-dimensional movements of a mouse input device, the movement of the hand measured by a magnetic spatial position and orientation sensor, and, lastly, the changing eigenvector projection coefficients computed from an image sequence.			Bobick, AF (corresponding author), MIT,MEDIA LAB,VIS & MODELING GRP,20 AMES ST,CAMBRIDGE,MA 02159, USA.							BOBICK A, 1995, P INT C COMP VIS; BREGLER C, 1994, ADV NEURAL INFORMATI, V6, P43; Catmull Edwin, 1974, COMPUT AIDED GEOM D, P317, DOI 10.1016/B978-0-12-079050-0.50020-5; CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K; CUI Y, 1995, P INT WORKSH AUT FAC; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109; DAVIS J, 1994, P EUR C COMP VIS STO, P331; Gould K., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P79, DOI 10.1109/CVPR.1989.37831; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Kendon A., 1988, CROSS CULTURAL PERSP; LIPSCOMB JS, 1991, PATTERN RECOGN, V24, P895, DOI 10.1016/0031-3203(91)90009-T; MARDIA KV, 1993, IMAGE VISION COMPUT, V11, P283, DOI 10.1016/0262-8856(93)90006-3; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; MURASE H, 1993, P IEEE 2 QUAL VIS WO; Polana R., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P77, DOI 10.1109/MNRAO.1994.346251; Rabiner L., 1993, FUNDAMENTALS SPEECH; RANGARAJAN K, 1993, PATTERN RECOGN, V26, P595, DOI 10.1016/0031-3203(93)90113-B; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; Schlenzig J., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P187, DOI 10.1109/ACV.1994.341308; SCHLENZIG J, 1994, P 28 AS C SIGN SYST; SPERLING G, 1985, COMPUT VISION GRAPH, V31, P335, DOI 10.1016/0734-189X(85)90034-9; STARNER T, 1995, P INT WORKSH AUT FAC; TEW AI, 1993, J BIOMED ENG, V15, P181, DOI 10.1016/0141-5425(93)90113-D; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wilson AD, 1997, PROC CVPR IEEE, P948, DOI 10.1109/CVPR.1997.609442; WILSON AD, 1995, P IEEE INT S COMP VI; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161	28	155	179	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1325	1337		10.1109/34.643892	http://dx.doi.org/10.1109/34.643892			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100002
J	Cehovin, L; Kristan, M; Leonardis, A				Cehovin, Luka; Kristan, Matej; Leonardis, Ales			Robust Visual Tracking Using an Adaptive Coupled-Layer Visual Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing and computer vision; tracking	KERNEL TRACKING	This paper addresses the problem of tracking objects which undergo rapid and significant appearance changes. We propose a novel coupled-layer visual model that combines the target's global and local appearance by interlacing two layers. The local layer in this model is a set of local patches that geometrically constrain the changes in the target's appearance. This layer probabilistically adapts to the target's geometric deformation, while its structure is updated by removing and adding the local patches. The addition of these patches is constrained by the global layer that probabilistically models the target's global visual properties, such as color, shape, and apparent local motion. The global visual properties are updated during tracking using the stable patches from the local layer. By this coupled constraint paradigm between the adaptation of the global and the local layer, we achieve a more robust tracking through significant appearance changes. We experimentally compare our tracker to 11 state-of-the-art trackers. The experimental results on challenging sequences confirm that our tracker outperforms the related trackers in many cases by having a smaller failure rate as well as better accuracy. Furthermore, the parameter analysis shows that our tracker is stable over a range of parameter values.	[Cehovin, Luka; Kristan, Matej; Leonardis, Ales] Univ Ljubljana, Fac Comp & Informat Sci, SI-1001 Ljubljana, Slovenia; [Kristan, Matej] Univ Ljubljana, Fac Elect Engn, SI-1001 Ljubljana, Slovenia; [Leonardis, Ales] Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England; [Leonardis, Ales] Univ Birmingham, Ctr Computat Neurosci & Cognit Robot, Birmingham B15 2TT, W Midlands, England	University of Ljubljana; University of Ljubljana; University of Birmingham; University of Birmingham	Cehovin, L (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SI-1001 Ljubljana, Slovenia.	luka.cehovin@fri.uni-lj.si; matej.kristan@fri.uni-lj.si; a.leonardis@cs.bham.ac.uk		Cehovin Zajc, Luka/0000-0003-2823-272X	ARRS projects [J2-3607, J2-2221, J2-4284]; EU project CogX [FP7-ICT215181-IP]	ARRS projects; EU project CogX	The authors would like to thank the authors of [5], [6], [7], [8], [9], [13], [16], [31] for providing the reference implementations of their trackers. This research was supported in part by: ARRS projects J2-3607, J2-2221, and J2-4284 and EU project CogX (FP7-ICT215181-IP).	Adam A., 2006, IEEE C COMP VIS PATT; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Badrinarayanan V, 2007, IEEE I CONF COMP VIS, P1000; Bar -Shalom Y., 2001, ESTIMATION APPL TRAC; Cai D., 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/ICCV.2007.4408856; Cehovin L., 2011, P 13 IEEE INT C COMP; Chang WY, 2009, IEEE T SYST MAN CY B, V39, P375, DOI 10.1109/TSMCB.2008.2005417; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Fan ZM, 2007, IEEE T PATTERN ANAL, V29, P1268, DOI 10.1109/TPAMI.2007.1034; Godec M., 2011, P 13 IEEE INT C COMP; Grabner H., 2006, P BRIT MACH VIS, P47; Hager GD, 2004, PROC CVPR IEEE, P790; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HOEY J, 2006, P BRIT MACH VIS C; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kolsch M., 2004, IEEE WORKSH REAL TIM, P158, DOI DOI 10.1109/CVPR.2004.345; Kristan M, 2009, PATTERN RECOGN, V42, P2160, DOI 10.1016/j.patcog.2009.01.002; Kristan M, 2011, PATTERN RECOGN, V44, P2630, DOI 10.1016/j.patcog.2011.03.019; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502; Li XR, 2003, IEEE T AERO ELEC SYS, V39, P1333, DOI 10.1109/TAES.2003.1261132; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Martinez B, 2008, PATTERN RECOGN, V41, P3682, DOI 10.1016/j.patcog.2008.06.001; Nejhum SMS, 2010, COMPUT VIS IMAGE UND, V114, P901, DOI 10.1016/j.cviu.2010.04.002; Oisel L., 2008, P INT WORKSH VIS SUR; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Porikli F., 2006, TECHNICAL REPORT; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Rubinstein RY, 1997, EUR J OPER RES, V99, P89, DOI 10.1016/S0377-2217(96)00385-2; Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445; Stenger Bjorn, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2647, DOI 10.1109/CVPRW.2009.5206634; Wang Q., 2011, SPIE IMAGE SIGNAL PR, V8138; Yin Z., 2007, 2007 IEEE C COMPUTER, P1, DOI DOI 10.1109/CVPR.2007.383237	35	154	165	0	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					941	953		10.1109/TPAMI.2012.145	http://dx.doi.org/10.1109/TPAMI.2012.145			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22802114				2022-12-18	WOS:000314931000013
J	Wu, L; Jin, R; Jain, AK				Wu, Lei; Jin, Rong; Jain, Anil K.			Tag Completion for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tag completion; matrix completion; tag-based image retrieval; image annotation; image retrieval; metric learning	ANNOTATION; RELEVANCE; MODELS	Many social image search engines are based on keyword/tag matching. This is because tag-based image retrieval (TBIR) is not only efficient but also effective. The performance of TBIR is highly dependent on the availability and quality of manual tags. Recent studies have shown that manual tags are often unreliable and inconsistent. In addition, since many users tend to choose general and ambiguous tags in order to minimize their efforts in choosing appropriate words, tags that are specific to the visual content of images tend to be missing or noisy, leading to a limited performance of TBIR. To address this challenge, we study the problem of tag completion, where the goal is to automatically fill in the missing tags as well as correct noisy tags for given images. We represent the image-tag relation by a tag matrix, and search for the optimal tag matrix consistent with both the observed tags and the visual similarity. We propose a new algorithm for solving this optimization problem. Extensive empirical studies show that the proposed algorithm is significantly more effective than the state-of-the-art algorithms. Our studies also verify that the proposed algorithm is computationally efficient and scales well to large databases.	[Wu, Lei] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA; [Jin, Rong; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Michigan State University	Wu, L (corresponding author), Univ Pittsburgh, Dept Comp Sci, Room 5421,Sennott Sq Bldg,210 S Bouquet St, Pittsburgh, PA 15260 USA.	leiwu@live.com; rongjin@cse.msu.edu; jain@cse.msu.edu			US National Science Foundation (NSF) [IIS-0643494]; US Army Research [W911NF-11-1-0383]; US Office of Navy Research [N000141210431]; World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Army Research(United States Department of DefenseUS Army Research Laboratory (ARL)); US Office of Navy Research; World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea	This, work was supported in part by the US National Science Foundation (NSF) (IIS-0643494), US Army Research (W911NF-11-1-0383), and US Office of Navy Research (Award N000141210431). Part of Anil Jam's research was supported by the World Class University (WCU) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008).	Akbas E., 2007, P C COMP VIS CVPR 20, P1; [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.58; [Anonymous], 2009, GERONTOLOGY; Bao BK, 2011, PATTERN RECOGN, V44, P598, DOI 10.1016/j.patcog.2010.10.001; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Cartis C, 2011, SIAM J OPTIMIZ, V21, P1721, DOI 10.1137/11082381X; Chen G, 2009, PROC CVPR IEEE, P1658, DOI 10.1109/CVPRW.2009.5206813; Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Datta R., 2006, P 14 ANN ACM INT C M, P977; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Feng SL, 2004, PROC CVPR IEEE, P1002; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P148; Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170; Goldberg A., 2010, P NIPS, V23, P757; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Guo Y., 2011, PROC 22 INT JOINT C, P1300, DOI DOI 10.5591/978-1-57735-516-8/IJCA111-220; Halpin H, 2007, P 16 INT C WORLD WID, P211, DOI [10.1145/1242572.1242602, DOI 10.1145/1242572.1242602]; Hariharan B., 2010, P INT C MACH LEARN; Haruechaiyasak C, 2010, LECT NOTES COMPUT SC, V6102, P212, DOI 10.1007/978-3-642-13654-2_26; Heymann P., 2008, P INT C WEB SEARCH W, P195, DOI DOI 10.1145/1341531.1341558; Hoi S., 2006, P IEEE COMP SOC C CO, V2, P2072, DOI DOI 10.1109/CVPR.2006.167; Ioffe A., 1990, ANAL OPTIMIZATION SY, V144, P442; Jiang Y G, 2007, P 6 ACM INT C IM VID, P494, DOI DOI 10.1145/1282280.1282352; Jin R., 2004, P 12 ANN ACM INT C M, P892, DOI [DOI 10.1145/1027527.1027732, 10.1145/1027527.1027732]; Ke Y, 2004, PROC CVPR IEEE, P506; Kipp MEI, 2006, P AM SOC INFORM SCI, V43, P1; Lavrenko V, 2003, P ADV NEUR INF PROC; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847; Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Liu Y., 2006, AAAI, P421; Liu YM, 2011, IEEE T PATTERN ANAL, V33, P1022, DOI 10.1109/TPAMI.2010.142; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24; Metzler D, 2004, LECT NOTES COMPUT SC, V3115, P42; Monay F, 2004, P 12 ANN ACM INT C M, P348, DOI DOI 10.1145/1027527.1027608; RAKHLIN A, 2006, THESIS MIT; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shalev-Shwartz S., 2008, P 25 INT C MACH LEAR, V307, P928, DOI DOI 10.1145/1390156.1390273; Sigurbjornsson B., 2008, P 17 INT C WORLD WID, P327, DOI [10.1145/1367497.1367542, DOI 10.1145/1367497.1367542]; Singhal A., 2001, IEEE DATA ENG B, V24, P35; Tirilly P., 2008, P 2008 INT C CONT BA, P249; Wang G, 2009, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2009.5459167; Wang H, 2010, IEEE IMAGE PROC, P2337, DOI 10.1109/ICIP.2010.5649863; Wright MH, 2005, B AM MATH SOC, V42, P39; Wu L, 2009, P 17 ACM INT C MULT; Wu L., 2007, P INT WORKSH MULT IN, P115; Wu P., 2011, P 4 ACM INT C WEB SE, P197, DOI [DOI 10.1145/1935826.1935865, 10.1145/1935826.1935865]; Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111; Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273; Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507; Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204; Zhu G., 2010, ACM MULT, P461; Zhuang J., 2011, PROC INT C WEB SEARC, P625; Zobel J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132956.1132959	61	154	163	0	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					716	727		10.1109/TPAMI.2012.124	http://dx.doi.org/10.1109/TPAMI.2012.124			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22641703	Green Submitted			2022-12-18	WOS:000314792900015
J	Valenti, R; Gevers, T				Valenti, Roberto; Gevers, Theo			Accurate Eye Center Location through Invariant Isocentric Patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Eye center location; isophotes; facial features detection	FACE-RECOGNITION; TRACKING	Locating the center of the eyes allows for valuable information to be captured and used in a wide range of applications. Accurate eye center location can be determined using commercial eye-gaze trackers, but additional constraints and expensive hardware make these existing solutions unattractive and impossible to use on standard (i.e., visible wavelength), low-resolution images of eyes. Systems based solely on appearance are proposed in the literature, but their accuracy does not allow us to accurately locate and distinguish eye centers movements in these low-resolution settings. Our aim is to bridge this gap by locating the center of the eye within the area of the pupil on low-resolution images taken from a webcam or a similar device. The proposed method makes use of isophote properties to gain invariance to linear lighting changes (contrast and brightness), to achieve in-plane rotational invariance, and to keep low-computational costs. To further gain scale invariance, the approach is applied to a scale space pyramid. In this paper, we extensively test our approach for its robustness to changes in illumination, head pose, scale, occlusion, and eye rotation. We demonstrate that our system can achieve a significant improvement in accuracy over state-of-the-art techniques for eye center location in standard low-resolution imagery.	[Valenti, Roberto; Gevers, Theo] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 XG Amsterdam, Netherlands	University of Amsterdam	Valenti, R (corresponding author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Sci Pk 107, NL-1098 XG Amsterdam, Netherlands.	r.valenti@uva.nl; th.gevers@uva.nl		Valenti, Roberto/0000-0002-3774-4092				[Anonymous], 2001, BIOID FAC DAT; [Anonymous], 2005, 2005 IEEE COMP VIS P; Asadifard M., 2010, P INT MULT ENG COMP; ASTERIADIS S, 2006, P INT S CONTR COMM S; Bai L, 2006, INT C PATT RECOG, P511; Bates R., 2005, P COGAIN C COMM GAZ; Bohme M., 2006, P C COMM GAZ INT; CAMPADELLI P., 2006, P BRIT MACH VIS C; COGAIN, 2006, COMM GAZ INT GAZ FUT; Colombo C, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1314303.1314305; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2006, P BRIT MACH VIS C; CRISTINACCE D., 2004, P BRIT MACH VIS C, P277; DAM EB, 2003, FRONT END VISION MUL; Duchowski AT, 2007, EYE TRACKING METHODO; Duffner S., 2008, THESIS ALBERT LUDWIG; Duin R., 2000, P SPIE; Froba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Geusebroek JM, 2002, LECT NOTES COMPUT SC, V2350, P99; Ghinea G, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1314303.1314304; Gross R., 2008, P C FORM GRAMM; Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179; Hendee W. R., 1997, PERCEPTION VISUAL IN; Huang J, 2000, IEEE T EVOLUT COMPUT, V4, P73, DOI 10.1109/4235.843496; Jesorsky O., 1992, AUDIO VIDEO BIOM PER, P90; Kervrann C., 2002, International Journal of Computer Vision, V50, P63, DOI 10.1023/A:1020276319925; Kim S, 2007, PROC WRLD ACAD SCI E, V19, P483; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Kroon B., 2008, P INT C CONT BAS IM; Lichtenauer J, 2005, PROC CVPR IEEE, P649; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010; NIU Z, 2006, P 18 INT C PATT REC; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Reale MJ, 2011, IEEE T MULTIMEDIA, V13, P474, DOI 10.1109/TMM.2011.2120600; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Stavens D., 2010, P IEEE C COMP VIS PA; Timm F., 2011, P 6 INT C COMP VIS T; Turkan M., 2007, P C COMP VIS THEOR A; VALENTI R., 2008, P IEEE C COMP VIS PA; van Ginkel M., 1999, P SCAND C IM AN; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang J, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1314303.1314306; Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008; Wechsler H, 2005, COMPUT VIS IMAGE UND, V98, P1, DOI 10.1016/j.cviu.2004.07.006; Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006; Zhu ZW, 2005, COMPUT VIS IMAGE UND, V98, P124, DOI 10.1016/j.cviu.2004.07.012	49	154	173	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1785	1798		10.1109/TPAMI.2011.251	http://dx.doi.org/10.1109/TPAMI.2011.251			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22813958				2022-12-18	WOS:000306409100011
J	Li, P; Fu, Y; Mohammed, U; Elder, JH; Prince, SJD				Li, Peng; Fu, Yun; Mohammed, Umar; Elder, James H.; Prince, Simon J. D.			Probabilistic Models for Inference about Identity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computing methodologies; pattern recognition; applications; face and gesture recognition	FACE RECOGNITION; SCALE	Many face recognition algorithms use "distance-based" methods: Feature vectors are extracted from each face and distances in feature space are compared to determine matches. In this paper, we argue for a fundamentally different approach. We consider each image as having been generated from several underlying causes, some of which are due to identity (latent identity variables, or LIVs) and some of which are not. In recognition, we evaluate the probability that two faces have the same underlying identity cause. We make these ideas concrete by developing a series of novel generative models which incorporate both within-individual and between-individual variation. We consider both the linear case, where signal and noise are represented by a subspace, and the nonlinear case, where an arbitrary face manifold can be described and noise is position-dependent. We also develop a "tied" version of the algorithm that allows explicit comparison of faces across quite different viewing conditions. We demonstrate that our model produces results that are comparable to or better than the state of the art for both frontal face recognition and face recognition under varying pose.	[Li, Peng; Fu, Yun; Mohammed, Umar; Prince, Simon J. D.] UCL, Dept Comp Sci, London WC1E 6BT, England; [Elder, James H.] York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada	University of London; University College London; York University - Canada	Li, P (corresponding author), UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.	p.li@cs.ucl.ac.uk; y.fu@cs.ucl.ac.uk; u.mohammed@cs.ucl.ac.uk; jelder@yorku.ca; s.prince@cs.ucl.ac.uk	YAGOUB, UMAR/W-8037-2018; Mohammed, Umar/AHE-4079-2022	Mohammed, Umar/0000-0001-8662-9229	Engineering and Physical Sciences Research Council [EP/E065872/1] Funding Source: researchfish; EPSRC [EP/E065872/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Blanz V, 2005, PROC CVPR IEEE, P454; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; Cai D., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383054; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Everingham M, 2006, P BRIT MACHINE VISIO, V4, P6; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; Ferencz A, 2008, INT J COMPUT VISION, V77, P3, DOI 10.1007/s11263-007-0093-5; Fergus R, 2003, PROC CVPR IEEE, P264; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gharamani Z., 1996, CRGTR961 U TOR DEP C; Gross R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P3, DOI 10.1109/AFGR.2002.1004122; Guillaumin Matthieu, 2009, P INT C COMP VIS; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Huang G.B., 2008, WORKSHOP FACESREAL L; Ioffe S, 2006, LECT NOTES COMPUT SC, V3954, P531; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jones E, 2005, IEEE I CONF COMP VIS, P1097; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; KUMAR N, 2009, P IEEE 12 INT C COMP; Li P., 2010, P BRIT MACH VIS C; Li Z., 2004, P IEEE C COMP VIS PA, P259; Liu CJ, 1998, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.1998.698700; Lucey S., 2006, P IEEE CS C COMP VIS, V1, P909; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Nguyen H.V., 2010, P 10 AS C COMP VIS; Nowak E, 2007, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2007.382969; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011; Pinto N., 2011, P INT C AUT FAC GEST; Prince S.J.D., 2007, P IEEE 11 INT C COMP; Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Taigman Y., 2009, P BRIT MACH VIS C; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Wang X., 2003, P ACM SIGMM WORKSH B, P70; Wang XG, 2004, PROC CVPR IEEE, P564; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Wolf L., 2008, P EUR C COMP VIS; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou SK, 2004, PROC CVPR IEEE, P805	46	154	168	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					144	157		10.1109/TPAMI.2011.104	http://dx.doi.org/10.1109/TPAMI.2011.104			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576751				2022-12-18	WOS:000297069900010
J	Hall, P; Marshall, D; Martin, R				Hall, P; Marshall, D; Martin, R			Merging and splitting eigenspace models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						eigenspace models; principal component analysis; model merging; model splitting; Gaussian mixture models	ALGORITHM	We present new deterministic methods that given two eigenspace models-each representing a set of n-dimensional observations-will: 1) merge the models to yield a representation of the union of the sets and 2) split one model from another to represent the difference between the sets. As this is done. we accurately keep track of the mean. Here, we give a theoretical derivation of the methods, empirical results relating to the efficiency and accuracy of the techniques, and three general applications, including the construction of Gaussian mixture models that are dynamically updateable.	Univ Bath, Sch Math Sci, Bath BA2 7AY, Avon, England; Univ Wales Coll Cardiff, Dept Comp Sci, Cardiff CF2 3XF, S Glam, Wales	University of Bath; Cardiff University	Hall, P (corresponding author), Univ Bath, Sch Math Sci, Bath BA2 7AY, Avon, England.	maspmh@maths.bath.ac.uk; dave@cs.cf.ac.uk; ralph@cs.cf.ac.uk	Martin, Ralph R/D-2366-2010					BOROTSCHNIG H, 1998, P BRIT MACH VIS C, P629; BUNCH JR, 1978, NUMER MATH, V31, P111, DOI 10.1007/BF01397471; Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425; Chaudhuri S, 1996, COMPUT VIS IMAGE UND, V64, P434, DOI 10.1006/cviu.1996.0070; CHIEN YT, 1967, IEEE T INFORM THEORY, V13, P518, DOI 10.1109/TIT.1967.1054021; Cootes T., 1992, P BRIT MACH VIS C, P9, DOI DOI 10.1007/978-1-4471-3201-1_2; DEGROAT RD, 1990, IEEE T ACOUST SPEECH, V38, P301, DOI 10.1109/29.103066; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HALL P, 1998, P BRIT MACH VIS C, V1, P286; HEAP T, 1997, P BRIT MACH VIS C, P80; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519	16	154	166	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					1042	1049		10.1109/34.877525	http://dx.doi.org/10.1109/34.877525			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY		Green Accepted			2022-12-18	WOS:000089741300010
J	PERONA, P				PERONA, P			DEFORMABLE KERNELS FOR EARLY VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STEERABLE FILTERS; WAVELETS; EARLY VISION; MULTIRESOLUTION IMAGE ANALYSIS; MULTIRATE FILTERING; DEFORMABLE FILTERS; SCALE-SPACE	STEERABLE-SCALABLE KERNELS; EDGE-DETECTION; TEXTURE-DISCRIMINATION; SPATIAL-FREQUENCY; JUNCTION ANALYSIS; FILTERS; ORIENTATION; ENERGY; MODEL; MECHANISMS	Early vision algorithms often have a first stage of linear-filtering that 'extracts' from the image information at multiple scales of resolution and multiple orientations. A common difficulty in the design and implementation of such schemes is that one feels compelled to discretize coarsely the space of scales and orientations in order to reduce computation and storage costs. This discretization produces anisotropies due to a loss of translation-, rotation-, and scaling-invariance that makes early vision algorithms less precise and more difficult to design. This need not be so: one can compute and store efficiently the response of families of linear filters defined on a continuum of orientations and scales. A technique is presented that allows 1) computing the best approximation of a given family using linear combinations of a small number of 'basis' functions; 2) describing all finite-dimensional families, i.e., the families of filters for which a finite dimensional representation is possible with no error. The technique is based on singular value decomposition and may be applied to generating filters in arbitrary dimensions and subject to arbitrary deformations; the relevant functional analysis results are reviewed and precise conditions for the decomposition to be feasible are stated. Experimental results are presented that demonstrate the applicability of the technique to generating multi-orientation multi-scale 2D edge-detection kernels. The implementation issues are also discussed.	UNIV PADUA, DIPARTIMENTO ELETRON & INFORMAT, PADUA, ITALY	University of Padua	PERONA, P (corresponding author), CALTECH, DEPT ENGN & APPL SCI 116 81, PASADENA, CA 91125 USA.							ABRAMATIC JF, 1982, IEEE T ACOUST SPEECH, V30, P1, DOI 10.1109/TASSP.1982.1163840; ADELSON E, 1990, MIT TR148 MED LAB; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHOQUET G, 1969, LECTURES ANAL, V1; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DERICHE R, 1982, P ICASSP; DIEUDONNE J, 1969, F MODERN ANAL; DONGARRA JJ, 1972, LINPACK USERS GUIDE; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; FREEMAN W, 1990, MIT126 MED LAB TECHN; FREEMAN W, 1989, JUN TOP M IM UND MAC, V14; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; FREEMAN WT, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P406; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L; HORN B, 1971, MIT285 AI LAB MEM; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308; HUECKEL M, 1973, J ACM, V20, P643; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; JONES D, 1991, UCBCSD91657 UC BERK; JONES D G, 1990, Investigative Ophthalmology and Visual Science, V31, P529; JONES DG, 1992, LECT NOTES COMPUT SC, V588, P395; JONES DG, 1991, INVEST OPHTH VIS SCI, V32, P710; KASS M, 1983, JUN P IM UND WORKSH, P54; Knutsson H., 1983, 1983 IEEE Computer Society Workshop on Computer Architecture for Pattern Analysis and Image Database Management Proceedings, P206; KNUTTSON H, 1982, THESIS LINKOPING I T; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Landy M.S., 1991, COMPUTATIONAL MODELS; LENZ R, 1990, LECTURE NOTES COMPUT, V413; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MALIK J, 1991, INVEST OPHTH VIS SCI, V32, P715; MALIK J, 1991, COMPUTER VISION ADV; MORRONE M, 1990, ROBOTS BIOL SYSTEMS; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0; OUNG R, 1985, GMR4920 GEN MOT RES; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PERONA P, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P52; PERONA P, 1992, LECT NOTES COMPUT SC, V588, P3, DOI 10.1016/0262-8856(92)90011-Q; PERONA P, 1991, JUN IEEE C COMP VIS, P222; PERONA P, 1990, 90034 INT COMP SCI I; PERONA P, 1992, APR P SPIE C APPL AR, V1708; PERONA P, 1990, UCBCSD90590 EE UC BE; PERONA P, 1991, LIDSMIT2039 TECH REP; PINKUS A, 1985, N WIDTHS APROXIMATIO; PRATT WK, 1979, P SPIE TECHN S SAN D, V27; Press WH, 1988, NUMERICAL RECIPES C; ROMENY BMT, 1991, LECT NOTES COMPUT SC, V511, P239, DOI 10.1007/BFb0033757; ROSENTHALER L, 1991, 130 ETH ZUER IKT IMA; Rudin W., 1973, FUNCTIONAL ANAL; SIMONCELLI E, IEEE T INFORMATION T, V38, P587; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; TREITEL S, 1971, IEEE T GEOSCI ELECT, VGE 9, P10, DOI 10.1109/TGE.1971.271457; TURNER MR, 1986, BIOL CYBERN, V55, P71; ZHONG S, 1990, 3RD P INT C COMP VIS	68	154	160	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					488	499		10.1109/34.391394	http://dx.doi.org/10.1109/34.391394			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394		Green Submitted, Green Accepted			2022-12-18	WOS:A1995QW39400004
J	Gao, LL; Li, XP; Song, JK; Shen, HT				Gao, Lianli; Li, Xiangpeng; Song, Jingkuan; Shen, Heng Tao			Hierarchical LSTMs with Adaptive Attention for Visual Captioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Feature extraction; Task analysis; Decoding; Adaptation models; Natural language processing; Video captioning; image captioning; adaptive attention; hierarchical structure		Recent progress has been made in using attention based encoder-decoder framework for image and video captioning. Most existing decoders apply the attention mechanism to every generated word including both visual words (e.g., "gun" and "shooting") and non-visual words (e.g., "the", "a"). However, these non-visual words can be easily predicted using natural language model without considering visual signals or attention. Imposing attention mechanism on non-visual words could mislead and decrease the overall performance of visual captioning. Furthermore, the hierarchy of LSTMs enables more complex representation of visual data, capturing information at different scales. Considering these issues, we propose a hierarchical LSTM with adaptive attention (hLSTMat) approach for image and video captioning. Specifically, the proposed framework utilizes the spatial or temporal attention for selecting specific regions or frames to predict the related words, while the adaptive attention is for deciding whether to depend on the visual information or the language context information. Also, a hierarchical LSTMs is designed to simultaneously consider both low-level visual information and high-level language context information to support the caption generation. We design the hLSTMat model as a general framework, and we first instantiate it for the task of video captioning. Then, we further instantiate our hLSTMarefine it and apply it to the imioning task. To demonstrate the effectiveness of our proposed framework, we test our method on both video and image captioning tasks. Experimental results show that our approach achieves the state-of-the-art performance for most of the evaluation metrics on both tasks. The effect of important components is also well exploited in the ablation study.	[Gao, Lianli; Li, Xiangpeng; Song, Jingkuan; Shen, Heng Tao] Univ Elect Sci & Technol China, Future Media Ctr, Chengdu 611731, Peoples R China; [Gao, Lianli; Li, Xiangpeng; Song, Jingkuan; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China	Song, JK; Shen, HT (corresponding author), Univ Elect Sci & Technol China, Future Media Ctr, Chengdu 611731, Peoples R China.; Song, JK; Shen, HT (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.	lianli.gao@uestc.edu.cn; xiangpengli@std.uestc.edu.cn; jingkuan.song@gmail.com; shenhengtao@hotmail.com	Shen, Heng Tao/ABD-5331-2021		Fundamental Research Funds for the Central Universities [ZYGX2014J063, ZYGX2014Z007]; National Natural Science Foundation of China [61502080, 61632007, 61602049]	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by the Fundamental Research Funds for the Central Universities (Grant No. ZYGX2014J063, No. ZYGX2014Z007) and the National Natural Science Foundation of China (Grant No. 61502080, No. 61632007, No. 61602049).	Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Chen David, 2011, P 49 ANN M ASS COMP, P190; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044; Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Gan C, 2016, LECT NOTES COMPUT SC, V9907, P849, DOI 10.1007/978-3-319-46487-9_52; Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127; Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019; Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hermans M., 2013, P ADV NEUR INF PROC, V26, P190; Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1191, DOI 10.1145/2733373.2806314; Lin Chin-Yew, 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.2307/3105454; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100; Long Xiang, 2018, T ASS COMPUTATIONAL, V6, P173, DOI DOI 10.1162/TACL_A_00013; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Luo RT, 2018, PROC CVPR IEEE, P6964, DOI 10.1109/CVPR.2018.00728; Luong M., 2015, P 2015 C EMP METH NA, P1412, DOI [10.18653/v1/D15-1166, DOI 10.18653/V1/D15-1166]; Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117; Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111; Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Ramanishka V., 2016, P 24 ACM INT C MULT, P1092, DOI DOI 10.1145/2964284.2984066; Ranzato MarcAurelio, 2015, ARXIV151106732; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren Zhou, 2017, PROC CVPR IEEE, P290, DOI DOI 10.1109/CVPR.2017.128; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1; Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940; Shetty R., 2015, CORR; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077; Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344; Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Torabi Atousa, 2015, ARXIV150301070; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Venugopalan S., 2015, P C N AM CHAPT ASS C, P1494, DOI 10.3115/v1/N15-1173; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159; Weinberger KQ, 2014, ADV NEURAL INFORM PR, P1889; Xia Yingce, 2017, ADV NEURAL INFORM PR, P1784; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu R, 2015, AAAI CONF ARTIF INTE, P2346; Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422; Yang Z, 2016, INT CONF ACOUST SPEE, P3236, DOI 10.1109/ICASSP.2016.7472275; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512; Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496; Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347; Zeiler M.D., 2012, ADADELTA ADAPTIVE LE, DOI DOI 10.48550/ARXIV.1212.5701	69	153	155	23	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1112	1131		10.1109/TPAMI.2019.2894139	http://dx.doi.org/10.1109/TPAMI.2019.2894139			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30668467	Green Submitted			2022-12-18	WOS:000523685800008
J	Lian, CF; Liu, MX; Zhang, J; Shen, DG				Lian, Chunfeng; Liu, Mingxia; Zhang, Jun; Shen, Dinggang			Hierarchical Fully Convolutional Network for Joint Atrophy Localization and Alzheimer's Disease Diagnosis Using Structural MRI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer-aided alzheimer's disease diagnosis; fully convolutional networks; discriminative atrophy localization; weakly-supervised learning; structural MRI	VOXEL-BASED MORPHOMETRY; NEURAL-NETWORK; CLASSIFICATION; IMAGES; SEGMENTATION; AD; PATTERNS; FEATURES; FUSION	Structural magnetic resonance imaging (sMRI) has been widely used for computer-aided diagnosis of neurodegenerative disorders, e.g., Alzheimer's disease (AD), due to its sensitivity to morphological changes caused by brain atrophy. Recently, a few deep learning methods (e.g., convolutional neural networks, CNNs) have been proposed to learn task-oriented features from sMRI for AD diagnosis, and achieved superior performance than the conventional learning-based methods using hand-crafted features. However, these existing CNN-based methods still require the pre-determination of informative locations in sMRI. That is, the stage of discriminative atrophy localization is isolated to the latter stages of feature extraction and classifier construction. In this paper, we propose a hierarchical fully convolutional network (H-FCN) to automatically identify discriminative local patches and regions in the whole brain sMRI, upon which multi-scale feature representations are then jointly learned and fused to construct hierarchical classification models for AD diagnosis. Our proposed H-FCN method was evaluated on a large cohort of subjects from two independent datasets (i.e., ADNI-1 and ADNI-2), demonstrating good performance on joint discriminative atrophy localization and brain disease diagnosis.	[Lian, Chunfeng; Liu, Mingxia; Zhang, Jun; Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA; [Lian, Chunfeng; Liu, Mingxia; Zhang, Jun; Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA; [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea	University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; Korea University	Shen, DG (corresponding author), Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA.; Shen, DG (corresponding author), Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.; Shen, DG (corresponding author), Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea.	chunfeng_lian@med.unc.edu; mxliu@med.unc.edu; xdzhangjun@gmail.com; dgshen@med.unc.edu		Lian, Chunfeng/0000-0002-9319-6633; Liu, Mingxia/0000-0002-0166-0807	NIH [EB008374, AG041721, AG042599, EB022880]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This study was supported by NIH grants (EB008374, AG041721, AG042599, EB022880). Data used in this paper were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. The investigators within the ADNI did not participate in analysis or writing of this study. A complete list of ADNI investigators can be found online. C. Lain and M. Liu are co-first authors of this paper.	Adeli E, 2019, IEEE T PATTERN ANAL, V41, P515, DOI 10.1109/TPAMI.2018.2794470; Amores J, 2013, ARTIF INTELL, V201, P81, DOI 10.1016/j.artint.2013.06.003; [Anonymous], 2010, P 13 INT C ART INT S; Arbabshirani MR, 2017, NEUROIMAGE, V145, P137, DOI 10.1016/j.neuroimage.2016.02.079; Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582; Baron JC, 2001, NEUROIMAGE, V14, P298, DOI 10.1006/nimg.2001.0848; Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007; Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y; Bhatia Kanwal K, 2014, IEEE Trans Med Imaging, V33, P444, DOI 10.1109/TMI.2013.2287121; Buckner RL, 2004, NEURON, V44, P195, DOI 10.1016/j.neuron.2004.09.006; Cao XH, 2018, IEEE T BIO-MED ENG, V65, P1900, DOI 10.1109/TBME.2018.2822826; Cho Y, 2012, NEUROIMAGE, V59, P2217, DOI 10.1016/j.neuroimage.2011.09.085; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Coupe P, 2012, NEUROIMAGE-CLIN, V1, P141, DOI 10.1016/j.nicl.2012.10.002; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Fan Y, 2007, IEEE T MED IMAGING, V26, P93, DOI 10.1109/TMI.2006.886812; Frisoni GB, 2010, NAT REV NEUROL, V6, P67, DOI 10.1038/nrneurol.2009.215; Galton CJ, 2001, NEUROLOGY, V57, P216, DOI 10.1212/WNL.57.2.216; Ghesu FC, 2019, IEEE T PATTERN ANAL, V41, P176, DOI 10.1109/TPAMI.2017.2782687; Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224; Hinrichs C, 2009, NEUROIMAGE, V48, P138, DOI 10.1016/j.neuroimage.2009.05.056; Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Jagust W, 2013, NEURON, V77, P219, DOI 10.1016/j.neuron.2013.01.002; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099; Khvostikov A., 2018, ARXIV PREPRINT ARXIV; Kloppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319; Koikkalainen J, 2011, NEUROIMAGE, V56, P1134, DOI 10.1016/j.neuroimage.2011.03.029; Korolev S, 2017, I S BIOMED IMAGING, P835, DOI 10.1109/ISBI.2017.7950647; Li SY, 2014, J NEUROSCI, V34, P10541, DOI 10.1523/JNEUROSCI.4356-13.2014; Lian CF, 2018, MED IMAGE ANAL, V46, P106, DOI 10.1016/j.media.2018.02.009; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu MH, 2014, HUM BRAIN MAPP, V35, P1305, DOI 10.1002/hbm.22254; Liu MX, 2018, MED IMAGE ANAL, V43, P157, DOI 10.1016/j.media.2017.10.005; Liu MX, 2016, IEEE T MED IMAGING, V35, P1463, DOI 10.1109/TMI.2016.2515021; Liu MX, 2016, IEEE T PATTERN ANAL, V38, P2335, DOI 10.1109/TPAMI.2015.2430325; Liu SQ, 2015, IEEE T BIO-MED ENG, V62, P1132, DOI 10.1109/TBME.2014.2372011; Liu X, 2013, NEUROIMAGE, V83, P148, DOI 10.1016/j.neuroimage.2013.06.033; Livni R, 2014, ADV NEUR IN, V27; Lu DH, 2018, MED IMAGE ANAL, V46, P26, DOI 10.1016/j.media.2018.02.002; Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x; Moller C, 2016, RADIOLOGY, V279, P838, DOI 10.1148/radiol.2015150220; Ranzato M., 2007, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/mitpress/7503.003.0147; Rathore S, 2017, NEUROIMAGE, V155, P530, DOI 10.1016/j.neuroimage.2017.03.057; Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042; Salvatore C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00307; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698; Sorensen L, 2016, HUM BRAIN MAPP, V37, P1148, DOI 10.1002/hbm.23091; Suk HI, 2014, NEUROIMAGE, V101, P569, DOI 10.1016/j.neuroimage.2014.06.077; Tian H., 2017, ARXIV PREPRINT ARXIV; Tong T, 2014, MED IMAGE ANAL, V18, P808, DOI 10.1016/j.media.2014.04.006; Wang L, 2007, IEEE T MED IMAGING, V26, P462, DOI 10.1109/TMI.2006.887380; Wang L, 2018, HUM BRAIN MAPP, V39, P2609, DOI 10.1002/hbm.24027; Wang YP, 2011, LECT NOTES COMPUT SC, V6893, P635, DOI 10.1007/978-3-642-23626-6_78; Xue Z, 2006, NEUROIMAGE, V30, P388, DOI 10.1016/j.neuroimage.2005.09.054; Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008; Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106; Zhang J, 2016, IEEE T MED IMAGING, V35, P2524, DOI 10.1109/TMI.2016.2582386; Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008; Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616; Zou L, 2017, IEEE ACCESS, V5, P23626, DOI 10.1109/ACCESS.2017.2762703	71	153	158	41	174	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2020	42	4					880	893		10.1109/TPAMI.2018.2889096	http://dx.doi.org/10.1109/TPAMI.2018.2889096			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QY7GV	30582529	Green Accepted			2022-12-18	WOS:000630206500001
J	Wang, GT; Zuluaga, MA; Li, WQ; Pratt, ROSL; Patel, PA; Aertsen, M; Doel, T; David, AL; Deprest, J; Ourselin, S; Vercauteren, T				Wang, Guotai; Zuluaga, Maria A.; Li, Wenqi; Pratt, Rosalind; Patel, Premal A.; Aertsen, Michael; Doel, Tom; David, Anna L.; Deprest, Jan; Ourselin, Sebastien; Vercauteren, Tom			DeeplGeoS: A Deep Interactive Geodesic Framework for Medical Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interactive image segmentation; convolutional neural network; geodesic distance; conditional random fields	TUMOR SEGMENTATION	Accurate medical image segmentation is essential for diagnosis, surgical planning and many other applications. Convolutional Neural Networks (CNNs) have become the state-of-the-art automatic segmentation methods. However, fully automatic results may still need to be refined to become accurate and robust enough for clinical use. We propose a deep learning-based interactive segmentation method to improve the results obtained by an automatic CNN and to reduce user interactions during refinement for higher accuracy. We use one CNN to obtain an initial automatic segmentation, on which user interactions are added to indicate mis-segmentations. Another CNN takes as input the user interactions with the initial segmentation and gives a refined result. We propose to combine user interactions with CNNs through geodesic distance transforms, and propose a resolution-preserving network that gives a better dense prediction. In addition, we integrate user interactions as hard constraints into a back-propagatable Conditional Random Field. We validated the proposed framework in the context of 2D placenta segmentation from fetal MRI and 3D brain tumor segmentation from FLAIR images. Experimental results show our method achieves a large improvement from automatic CNNs, and obtains comparable and even higher accuracy with fewer user interventions and less time compared with traditional interactive methods.	[Wang, Guotai; Zuluaga, Maria A.; Li, Wenqi; Pratt, Rosalind; Patel, Premal A.; Doel, Tom; Ourselin, Sebastien; Vercauteren, Tom] UCL, Translat Imaging Grp, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London WC1E 6BT, England; [Pratt, Rosalind; David, Anna L.] UCL, Inst Womens Hlth, London WC1E 6BT, England; [Aertsen, Michael] Katholieke Univ Leuven, Univ Hosp, Dept Radiol, B-3000 Leuven, Belgium; [Deprest, Jan] Katholieke Univ Leuven, Dept Obstet, Univ Hosp, B-3000 Leuven, Belgium	UK Research & Innovation (UKRI); Engineering & Physical Sciences Research Council (EPSRC); University of London; University College London; University of London; University College London; KU Leuven; KU Leuven	Wang, GT (corresponding author), UCL, Translat Imaging Grp, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London WC1E 6BT, England.	guotai.wang.14@ucl.ac.uk; maria.zuluaga@gmail.com; wengi.li@ucl.ac.uk; rosalind.pratt@ucl.ac.uk; premal.patel@ucl.ac.uk; michaelaertsen@gmail.com; t.doel@ucl.ac.uk; a.david@ucl.ac.uk; Jan.Deprest@uzleuven.be; s.ourselin@ucl.ac.uk; t.vercauteren@ucl.ac.uk	Vercauteren, Tom K/I-7290-2013; Zuluaga, Maria A./AAP-4923-2020; Doel, Tom/D-4619-2011; Li, Wenqi/U-6825-2019; Ourselin, Sebastien/K-6960-2015	Vercauteren, Tom K/0000-0003-1794-0456; Zuluaga, Maria A./0000-0002-1147-766X; Doel, Tom/0000-0001-8092-9378; Li, Wenqi/0000-0003-1081-2830; Ourselin, Sebastien/0000-0002-5694-5340; Deprest, Jan/0000-0002-4920-945X; David, Anna/0000-0002-0199-6140	Innovative Engineering for Health - Wellcome Trust [WT101957]; Engineering and Physical Sciences Research Council (EPSRC) [NS/A000027/1, EP/H046410/1, EP/J020990/1, EP/K005278]; Wellcome/EPSRC [203145Z/16/Z]; National Institute for Health Research University College London Hospitals Biomedical Research Centre (NIHR BRC UCLH/UCL); Royal Society [RG160569]; UCL Overseas Research Scholarship; UCL Graduate Research Scholarship; EPSRC [EP/H046410/1, EP/J020990/1] Funding Source: UKRI	Innovative Engineering for Health - Wellcome Trust; Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Wellcome/EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); National Institute for Health Research University College London Hospitals Biomedical Research Centre (NIHR BRC UCLH/UCL); Royal Society(Royal Society of London); UCL Overseas Research Scholarship; UCL Graduate Research Scholarship; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported through an Innovative Engineering for Health award by the Wellcome Trust (WT101957); Engineering and Physical Sciences Research Council (EPSRC) (NS/A000027/1, EP/H046410/1, EP/J020990/1, EP/K005278), Wellcome/EPSRC [203145Z/16/Z], the National Institute for Health Research University College London Hospitals Biomedical Research Centre (NIHR BRC UCLH/UCL), the Royal Society [RG160569], a UCL Overseas Research Scholarship and a UCL Graduate Research Scholarship, hardware donated by NVIDIA and of Emerald, a GPU-accelerated High Performance Computer, made available by the Science & Engineering South Consortium operated in partnership with the STFC Rutherford-Appleton Laboratory.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x; Alansary Amir, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P589, DOI 10.1007/978-3-319-46723-8_68; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Armstrong CJ, 2007, COMPUT GRAPH-UK, V31, P212, DOI 10.1016/j.cag.2006.11.015; Bai XM, 2007, J IND ECOL, V11, P1, DOI 10.1162/jie.2007.1296; Barinova O., 2012, P INT WORKSH EXP EC, P1; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Cates JE, 2004, MED IMAGE ANAL, V8, P217, DOI 10.1016/j.media.2004.06.022; Chen L.-C., ARXIV14127062; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; Deprest JA, 2010, PRENATAL DIAG, V30, P653, DOI 10.1002/pd.2571; diaeresis>ahenb <spacing diaeresis>uhl Philipp Kr<spacing, 2013, P 30 INT C MACH LEAR, P513; Domke J, 2013, IEEE T PATTERN ANAL, V35, P2454, DOI 10.1109/TPAMI.2013.31; Fidon L., 2017, INT C MED IM COMP CO, P285, DOI DOI 10.1007/978-3-319-66179-7_33; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Guotai Wang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P352, DOI 10.1007/978-3-319-46723-8_41; Haider SA, 2015, I S BIOMED IMAGING, P1139, DOI 10.1109/ISBI.2015.7164073; Hamamci A, 2012, IEEE T MED IMAGING, V31, P790, DOI 10.1109/TMI.2011.2181857; Han DF, 2011, LECT NOTES COMPUT SC, V6801, P245, DOI 10.1007/978-3-642-22092-0_21; Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Keraudren K, 2014, NEUROIMAGE, V101, P633, DOI 10.1016/j.neuroimage.2014.07.023; Kirillov A., ARXIV151105067; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Kontschieder P, 2013, PROC CVPR IEEE, P65, DOI 10.1109/CVPR.2013.16; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lea C, 2016, LECT NOTES COMPUT SC, V9915, P47, DOI 10.1007/978-3-319-49409-8_7; Li WQ, 2017, LECT NOTES COMPUT SC, V10265, P348, DOI 10.1007/978-3-319-59050-9_28; Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344; LIN GS, 2016, PROC CVPR IEEE, P3194, DOI DOI 10.1109/CVPR.2016.348; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu F., 2014, P IEEE C COMP VIS PA, P5162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luengo I, 2017, J STRUCT BIOL, V198, P43, DOI 10.1016/j.jsb.2017.02.007; Menze Bjoern H, 2015, IEEE Trans Med Imaging, V34, P1993, DOI 10.1109/TMI.2014.2377694; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Ondruska P., ARXIV160405091; Orlando JI, 2014, LECT NOTES COMPUT SC, V8673, P634, DOI 10.1007/978-3-319-10404-1_79; Payet N., 2010, P NEUR INF PROC SYST, P1885; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Rajchl Martin, 2017, IEEE Trans Med Imaging, V36, P674, DOI 10.1109/TMI.2016.2621185; Ronneberger O, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777; Szummer M, 2008, LECT NOTES COMPUT SC, V5303, P582, DOI 10.1007/978-3-540-88688-4_43; Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351; Wang GT, 2016, MED IMAGE ANAL, V34, P137, DOI 10.1016/j.media.2016.04.009; Withey DJ, 2007, 2007 JOINT MEETING OF THE 6TH INTERNATIONAL SYMPOSIUM ON NONINVASIVE FUNCTIONAL SOURCE IMAGING OF THE BRAIN AND HEART AND THE INTERNATIONAL CONFERENCE ON FUNCTIONAL BIOMEDICAL IMAGING, P143; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47; Yu F., 2016, P ICLR 2016; Yuan J, 2010, PROC CVPR IEEE, P2217, DOI 10.1109/CVPR.2010.5539903; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhao F., 2013, ANN BMVA, V2013, P1; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	65	153	162	19	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1559	1572		10.1109/TPAMI.2018.2840695	http://dx.doi.org/10.1109/TPAMI.2018.2840695			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29993532	Green Accepted, Green Published, Green Submitted, hybrid			2022-12-18	WOS:000470972300003
J	Maji, S; Berg, AC; Malik, J				Maji, Subhransu; Berg, Alexander C.; Malik, Jitendra			Efficient Classification for Additive Kernel SVMs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image classification; support vector machines; efficient classifiers; additive kernels	SUPPORT VECTOR MACHINES; FACE DETECTION; FEATURES	We show that a class of nonlinear kernel SVMs admits approximate classifiers with runtime and memory complexity that is independent of the number of support vectors. This class of kernels, which we refer to as additive kernels, includes widely used kernels for histogram-based image comparison like intersection and chi-squared kernels. Additive kernel SVMs can offer significant improvements in accuracy over linear SVMs on a wide variety of tasks while having the same runtime, making them practical for large-scale recognition or real-time detection tasks. We present experiments on a variety of datasets, including the INRIA person, Daimler-Chrysler pedestrians, UIUC Cars, Caltech-101, MNIST, and USPS digits, to demonstrate the effectiveness of our method for efficient evaluation of SVMs with additive kernels. Since its introduction, our method has become integral to various state-of-the-art systems for PASCAL VOC object detection/image classification, ImageNet Challenge, TRECVID, etc. The techniques we propose can also be applied to settings where evaluation of weighted additive kernels is required, which include kernelized versions of PCA, LDA, regression, k-means, as well as speeding up the inner loop of SVM classifier training algorithms.	[Maji, Subhransu] Toyota Technol Inst, Chicago, IL 60637 USA; [Berg, Alexander C.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Malik, Jitendra] Univ Calif Berkeley, Berkeley, CA 94720 USA	Toyota Technological Institute - Chicago; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; University of California System; University of California Berkeley	Maji, S (corresponding author), Toyota Technol Inst, 6045 S Kenwood Ave, Chicago, IL 60637 USA.	smaji@ttic.edu; aberg@cs.stonybrook.edu; malik@eecs.berkeley.edu			US Army Research Office MURI [W911NF-06-1-0076]; US Office of Naval Research MURI [N00014-06-1-0734]; Google fellowship; Stony Brook University	US Army Research Office MURI(MURI); US Office of Naval Research MURI(MURIOffice of Naval Research); Google fellowship(Google Incorporated); Stony Brook University	Subhransu Maji was supported by US Army Research Office MURI W911NF-06-1-0076, US Office of Naval Research MURI N00014-06-1-0734, and a Google fellowship. Alexander C. Berg acknowledges Stony Brook University start-up funding.	Agarwal S., 2002, P EUR C COMP VIS; Belongie S., 2002, P EUR C COMP VIS; Boughorbel S., 2005, P IEEE C IM PROC; Bourdev L., 2005, P IEEE C COMP VIS PA; Burges C., 1997, P NEUR INF PROC SYST; Burges C.J.C., 1996, P INT C MACH LEARN; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Chum O., 2007, PASC VIS REC CHALL W; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dalal N., 2005, HISTOGRAMS ORIENTED; de Sande K. Van, 2011, P 13 IEEE INT C COMP; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Deng W.J., 2009, P IEEE C COMP VIS PA; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Fergus R., 2003, P IEEE C COMP VIS PA; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Garg A., 2002, P INT C PATT REC; Grauman K., 2006, P IEEE C COMP VIS PA; Grauman K, 2005, P IEEE INT C COMP VI; Grauman K, 2007, J MACH LEARN RES, V8, P725; Hastie T.J., 1990, GEN ADDITIVE MODELS, V43; Heisele B, 2003, PATTERN RECOGN, V36, P2007, DOI 10.1016/S0031-3203(03)00062-1; Herbster M, 2001, LECT NOTES ARTIF INT, V2111, P444; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; INDYK P, 2003, P 3 INT WORKSH STAT; Joachims T, 2006, P ACM SIGKDD INT C K; Keerthi SS, 2006, J MACH LEARN RES, V7, P1493; LAMPERT C. H., 2008, P IEEE C COMP VIS PA; Lazebnik S., 2006, P IEEE C COMP VIS PA; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Maji S., 2009, P IEEE C COMP VIS PA; Maji S., 2009, P 12 IEEE INT C COMP; Maji S., 2008, P IEEE C COMP VIS PA; Maji S., 2009, UCBEECS2009159; Mika S., 1999, P IEEE SIGN PROC SOC; Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217; MUTCH J., 2006, P IEEE C COMP VIS PA; Odone F, 2005, IEEE T IMAGE PROCESS, V14, P169, DOI 10.1109/TIP.2004.840701; Osuna E., 1997, P IEEE C COMP VIS PA; Osuna EE, 1999, ADVANCES IN KERNEL METHODS, P271; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Perronnin F., 2010, P IEEE C COMP VIS PA; Rahimi A., 2007, P NEUR INF PROC SYST; Romdhani S., 2001, P 8 IEEE INT C COMP; Schapire R., 1999, P INT JOINT C ART IN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2001, LEARNING KERNELS SUP; Shalev-Shwartz Shai, 2007, P INT C MACH LEARN; Shang L., 2010, P ACM INT C MULT; Smeaton A.F., 2006, MIR 2006 P 8 ACM INT, P321, DOI DOI 10.1145/1178677.1178722; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Torralba A., 2004, P IEEE C COMP VIS PA; VARMA M, 2007, P 11 IEEE INT C COMP; Vedaldi A., 2010, P IEEE C COMP VIS PA; Vedaldi A., 2009, P 12 IEEE INT C COMP; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walk S., 2010, P IEEE C COMP VIS PA; Wang G., 2009, P 12 IEEE INT C COMP; Wu J., 2009, P 12 IEEE INT C COMP; Yang C., 2003, P 9 IEEE INT C COMP; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang W., 2007, P 11 IEEE INT C COMP	67	153	176	3	88	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					66	77		10.1109/TPAMI.2012.62	http://dx.doi.org/10.1109/TPAMI.2012.62			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22392703				2022-12-18	WOS:000311127700008
J	Alzate, C; Suykens, JAK				Alzate, Carlos; Suykens, Johan A. K.			Multiway Spectral Clustering with Out-of-Sample Extensions through Weighted Kernel PCA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spectral clustering; kernel principal component analysis; out-of-sample extensions; model selection	COMPONENT ANALYSIS; EIGENVECTORS; MATRICES	A new formulation for multiway spectral clustering is proposed. This method corresponds to a weighted kernel principal component analysis (PCA) approach based on primal-dual least-squares support vector machine (LS-SVM) formulations. The formulation allows the extension to out-of-sample points. In this way, the proposed clustering model can be trained, validated, and tested. The clustering information is contained on the eigendecomposition of a modified similarity matrix derived from the data. This eigenvalue problem corresponds to the dual solution of a primal optimization problem formulated in a high-dimensional feature space. A model selection criterion called the Balanced Line Fit (BLF) is also proposed. This criterion is based on the out-of-sample extension and exploits the structure of the eigenvectors and the corresponding projections when the clusters are well formed. The BLF criterion can be used to obtain clustering parameters in a learning framework. Experimental results with difficult toy problems and image segmentation show improved performance in terms of generalization to new samples and computation times.	[Alzate, Carlos; Suykens, Johan A. K.] Katholieke Univ Leuven, Dept Elect Engn, ESAT, SCD,SISTA, B-3001 Heverlee, Leuven, Belgium	KU Leuven	Alzate, C (corresponding author), Katholieke Univ Leuven, Dept Elect Engn, ESAT, SCD,SISTA, Kasteelpk Arenberg 10, B-3001 Heverlee, Leuven, Belgium.	carlos.alzate@esat.kuleuven.be; johan.suykens@esat.kuleuven.be	Suykens, Johan A.K./C-9781-2014	Suykens, Johan A.K./0000-0002-8846-6352	Research Council K. U. Leuven [GOA-Mefisto 666, GOA-Ambiorics]; Flemish Government FWO [G.0240.99, G.0211.05, G.0407.02, G.0197.02, G.0080.01, G.0141.03, G.0491.03, G.0120.03, G.0452.04, G .0499.04, G.0226.06, G.0302.07]; ICCoS; ANMMM; AWI; IWT; GBOU (McKnow) Soft4s; Belgian Federal Government (Belgian Federal Science Policy Office [IUAP V-22, PODO-II (CP/01/40]; EU; Contracts Research/Agreements (ISMC/IPCOS, Data4s, TML, Elia, LMS, IPCOS, Mastercard).	Research Council K. U. Leuven(KU Leuven); Flemish Government FWO(FWO); ICCoS; ANMMM; AWI; IWT(Institute for the Promotion of Innovation by Science and Technology in Flanders (IWT)); GBOU (McKnow) Soft4s; Belgian Federal Government (Belgian Federal Science Policy Office(Belgian Federal Science Policy Office); EU(European Commission); Contracts Research/Agreements (ISMC/IPCOS, Data4s, TML, Elia, LMS, IPCOS, Mastercard).	This work was supported by grants and projects for the Research Council K. U. Leuven (GOA-Mefisto 666, GOA-Ambiorics, several PhD/Postdocs and fellow grants), the Flemish Government FWO: PhD/Postdocs grants, projects G.0240.99, G.0211.05, G.0407.02, G.0197.02, G.0080.01, G.0141.03, G.0491.03, G.0120.03, G.0452.04, G.0499.04, G.0226.06, G.0302.07, ICCoS, ANMMM; AWI; IWT: PhD grants, GBOU (McKnow) Soft4s, the Belgian Federal Government (Belgian Federal Science Policy Office: IUAP V-22; PODO-II (CP/01/40), the EU(FP5-Quprodis, ERNSI, Eureka 2063-Impact; Eureka 2419-FLiTE) and Contracts Research/Agreements (ISMC/IPCOS, Data4s, TML, Elia, LMS, IPCOS, Mastercard). The scientific responsibility is assumed by its authors.	ALZATE C, 1944, P INT JOINT C NEUR N, P138; Alzate C, 2008, IEEE T NEURAL NETWOR, V19, P1583, DOI 10.1109/TNN.2008.2000443; BACH FR, 2004, ADV NEURAL INFORM PR, V16; Bach FR, 2006, J MACH LEARN RES, V7, P1963; Baker C., 1977, NUMERICAL TREATMENT; Belkin M, 2002, ADV NEUR IN, V14, P585; Bengio Y, 2004, ADV NEURAL INFORM PR, V16; Brabanter J.D., 2002, LEAST SQUARES SUPPOR, DOI DOI 10.1142/9789812776655; CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Cristianini N, 2002, ADV NEUR IN, V14, P649; CRISTIANINI N, 2002, ADV NEURAL INFORM PR, V14; DAVIS C, 1970, SIAM J NUMER ANAL, V7, P1, DOI 10.1137/0707001; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263; DING C, 2004, P 21 INT C MACH LEAR, P30, DOI DOI 10.1145/1015330.1015407; FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652; FIEDLER M, 1975, CZECH MATH J, V25, P619; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; GU M, 2001, CSE01007 PENNS STAT; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Ham J., 2004, P 21 INT C MACH LEAR, P47, DOI [10.1145/1015330.1015417, DOI 10.1145/1015330.1015417]; HE X, 2004, ADV NEURAL INFORM PR, V16; Hein M, 2007, J MACH LEARN RES, V8, P1325; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martine T, 2004, INC, V26, P20; Meila M., 2003, MULTIWAY CUTS SPECTR; MEILA M, 2001, P INT C ART INT STAT; Ng AY, 2002, ADV NEUR IN, V14, P849; POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030; Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Suykens JAK, 2003, IEEE T NEURAL NETWOR, V14, P447, DOI 10.1109/TNN.2003.809414; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Van Rijsbergen CJ, 1979, INFORM RETRIEVAL; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Williams C, 2001, ADV NEURAL INFORM PR, V13; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zha H., 2002, ADV NEURAL INFORM PR	43	153	163	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					335	347		10.1109/TPAMI.2008.292	http://dx.doi.org/10.1109/TPAMI.2008.292			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075462				2022-12-18	WOS:000272741500011
J	Ayad, HG; Kamel, MS				Ayad, Hanan G.; Kamel, Mohamed S.			Cumulative voting consensus method for partitions with a variable number of clusters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						cluster analysis; consensus clustering; ensemble methods; voting	MODELS	Over the past few years, there has been a renewed interest in the consensus clustering problem. Several new methods have been proposed for finding a consensus partition for a set of n data objects that optimally summarizes an ensemble. In this paper, we propose new consensus clustering algorithms with linear computational complexity in n. We consider clusterings generated with a random number of clusters, which we describe by categorical random variables. We introduce the idea of cumulative voting as a solution for the problem of cluster label alignment, where unlike the common one-to-one voting scheme, a probabilistic mapping is computed. We seek a first summary of the ensemble that minimizes the average squared distance between the mapped partitions and the optimal representation of the ensemble, where the selection criterion of the reference clustering is defined based on maximizing the information content as measured by the entropy. We describe cumulative vote weighting schemes and corresponding algorithms to compute an empirical probability distribution summarizing the ensemble. Given the arbitrary number of clusters of the input partitions, we formulate the problem of extracting the optimal consensus as that of finding a compressed summary of the estimated distribution that preserves the maximum relevant information. An efficient solution is obtained using an agglomerative algorithm that minimizes the average generalized Jensen-Shannon divergence within the cluster. The empirical study demonstrates significant gains in accuracy and superior performance compared to several recent consensus clustering algorithms.	Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada	University of Waterloo	Ayad, HG (corresponding author), Univ Waterloo, Dept Elect & Comp Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.	hanan@pami.uwaterloo.ca; mkamel@pami.uwaterloo.ca	Kamel, Mohamed S/D-9323-2011	Kamel, Mohamed/0000-0001-6173-8082				ARABIE P, 1973, J MATH PSYCHOL, V17, P31; Ayad H, 2004, LECT NOTES COMPUT SC, V3077, P144; Ayad H, 2003, LECT NOTES COMPUT SC, V2709, P166; Ayad HG, 2005, LECT NOTES COMPUT SC, V3541, P236; BARTHELEMY JP, 1981, MATH SOC SCI, V1, P235; BARTLETT B, 1995, AUST J PUBLIC HEALTH, V19, P3; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI 10.1002/0471200611; CRISTOFOR ED, 2002, THESIS U MASSACHUSET; DAY WHE, 1986, J CLASSIF, V3, P183, DOI 10.1007/BF01894187; DAY WHE, 1981, MATH SOC SCI, V1, P269, DOI 10.1016/0165-4896(81)90042-1; DAY WHE, 2003, AXIOMATIC CONSENSUS, V39; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, P1265, DOI 10.1162/153244303322753661; Dimitriadou E, 2002, INT J PATTERN RECOGN, V16, P901, DOI 10.1142/S0218001402002052; Duda R.O., 2001, PATTERN CLASSIFICATI; Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; Fred A., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P442; Fred A., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096), P309; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450; Freund Y., 1995, COMPUTATIONAL LEARNI, V904, P23, DOI [10.1007/3-540-59119-2_166, DOI 10.1007/3-540-59119-2_166]; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GHOSH J, 2002, P 3 INT WORKSH MULT, P1; GONDEK D, 2005, P ACM SIGKDD INT C K; Gordon AD, 2001, PSYCHOMETRIKA, V66, P229, DOI 10.1007/BF02294837; Hastie T, 2009, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kuncheva L., 2014, COMBINING PATTERN CL; Kuncheva LI, 2004, IEEE SYS MAN CYBERN, P1214; LECLERC B, 1984, MATH SOC SCI, V8, P45, DOI 10.1016/0165-4896(84)90060-X; LIN M, 1995, IMMUNOTECHNOLOGY, V1, P151, DOI 10.1016/1380-2933(95)00016-X; Merugu S, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P211; Minaei-Bidgoli B, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P188, DOI 10.1109/ITCC.2004.1286629; Mirkin B, 2001, MACH LEARN, V45, P219, DOI 10.1023/A:1010924920739; Mirkin B. G., 1975, QUANTITATIVE SOCIOLO, P441; MONJARDET B, 1990, MATH SOC SCI, V20, P51, DOI 10.1016/0165-4896(90)90077-K; NEUMANN DA, 1986, J CLASSIF, V3, P281, DOI 10.1007/BF01894191; REGNIER S, 1983, MATH SCI HUMAINES, V82, P85; REGNIER S, 1983, MATH SCI HUMAINES, V82, P13; Slonim N, 2000, ADV NEUR IN, V12, P617; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tishby N., 1999, P 37 ANN ALL C COMM, P368; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; Topchy A, 2004, SIAM PROC S, P379; Topchy A, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P331; Topchy AP, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P225, DOI 10.1109/ICDM.2004.10100; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193	52	153	163	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					160	173		10.1109/TPAMI.2007.1138	http://dx.doi.org/10.1109/TPAMI.2007.1138			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000332				2022-12-18	WOS:000250843500013
J	Zhang, L; Samaras, D				Zhang, L; Samaras, D			Face recognition from a single training image under arbitrary unknown lighting using spherical harmonics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; spherical harmonics illumination representation; 3D face morphable models; illumination invariance		In this paper, we propose two novel methods for face recognition under arbitrary unknown lighting by using spherical harmonics illumination representation, which require only one training image per subject and no 3D shape information. Our methods are based on the recent result which demonstrated that the set of images of a convex Lambertian object obtained under a wide variety of lighting conditions can be approximated accurately by a low-dimensional linear subspace. We provide two methods to estimate the spherical harmonic basis images spanning this space from just one image. Our first method builds the statistical model based on a collection of 2D basis images. We demonstrate that, by using the learned statistics, we can estimate the spherical harmonic basis images from just one image taken under arbitrary illumination conditions if there is no pose variation. Compared to the first method, the second method builds the statistical models directly in 3D spaces by combining the spherical harmonic illumination representation and a 3D morphable model of human faces to recover basis images from images across both poses and illuminations. After estimating the basis images, we use the same recognition scheme for both methods: we recognize the face for which there exists a weighted combination of basis images that is the closest to the test face image. We provide a series of experiments that achieve high recognition rates, under a wide range of illumination conditions, including multiple sources of illumination. Our methods achieve comparable levels of accuracy with methods that have much more onerous training data requirements. Comparison of the two methods is also provided.	SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Zhang, L (corresponding author), SUNY Stony Brook, Dept Comp Sci, 2429 Comp Sci, Stony Brook, NY 11794 USA.	lzhang@cs.sunysb.edu; samaras@cs.sunysb.edu						Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; BERGEN JR, 1990, HIERARCHICAL MOTION; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BLANZ V, 1999, P SIGGRAPH; BLANZ V, 2004, P EUROGRAPHICS; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827; Foley JD, 1984, SYSTEMS PROGRAMMING; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GROSS R, 2004, HDB FACE RECOGNITION; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hwang BW, 2000, INT C PATT RECOG, P838, DOI 10.1109/ICPR.2000.906205; Kruger V, 2002, IMAGE VISION COMPUT, V20, P665, DOI 10.1016/S0262-8856(02)00056-2; Lee KC, 2001, PROC CVPR IEEE, P519; Li SZ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P635, DOI 10.1109/ICCV.2001.937578; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; ROMDHANI S, 2002, P EUR C COMP VIS; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; SHASHUA A, 1991, P ADV NEUR INF PROC, V4; Sherrah J., 1999, P IEEE INT WORKSH RE; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Sim T., 2001, P CVPR WORKSH MOD VE; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG H, 2003, P ICCV WORKSH AN MOD; WU H, 1998, P INT C PATT REC; Zhang L, 2003, PROC CVPR IEEE, P19; Zhang MJ, 2004, REAL-TIME IMAGING, V10, P23, DOI 10.1016/j.rti.2003.11.001; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZHAO W, 2000, CARTR948 CFAR U MAR; Zhao WY, 2000, PROC CVPR IEEE, P286, DOI 10.1109/CVPR.2000.855831; ZHOU S, 2004, P EUR C COMP VIS; ZHOU S, 2004, P 6 IEEE INT C AUT F	39	153	164	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					351	363		10.1109/TPAMI.2006.53	http://dx.doi.org/10.1109/TPAMI.2006.53			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526422				2022-12-18	WOS:000234517900002
J	Navigli, R; Velardi, P				Navigli, R; Velardi, P			Structural semantic interconnections: A knowledge-based approach to word sense disambiguation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						natural language processing; ontology learning; structural pattern matching; word sense disambiguation		Word Sense Disambiguation ( WSD) is traditionally considered an AI- hard problem. A break- through in this field would have a significant impact on many relevant Web- based applications, such as Web information retrieval, improved access to Web services, information extraction, etc. Early approaches to WSD, based on knowledge representation techniques, have been replaced in the past few years by more robust machine learning and statistical techniques. The results of recent comparative evaluations of WSD systems, however, show that these methods have inherent limitations. On the other hand, the increasing availability of large- scale, rich lexical knowledge resources seems to provide new challenges to knowledge- based approaches. In this paper, we present a method, called structural semantic interconnections ( SSI), which creates structural specifications of the possible senses for each word in a context and selects the best hypothesis according to a grammar G, describing relations between sense specifications. Sense specifications are created from several available lexical resources that we integrated in part manually, in part with the help of automatic procedures. The SSI algorithm has been applied to different semantic disambiguation problems, like automatic ontology population, disambiguation of sentences in generic texts, disambiguation of words in glossary definitions. Evaluation experiments have been performed on specific knowledge domains ( e. g., tourism, computer networks, enterprise interoperability), as well as on standard disambiguation test sets.	Univ Roma La Sapienza, Dipartimento Informat, I-00198 Rome, Italy	Sapienza University Rome	Navigli, R (corresponding author), Univ Roma La Sapienza, Dipartimento Informat, Via Saleria 113, I-00198 Rome, Italy.	navigli@di.uniroma.it; velardi@di.uniroma.it		Navigli, Roberto/0000-0003-3831-9706; Velardi, Paola/0000-0003-0884-1499				[Anonymous], 1992, P 14 INT C COMP LING; BERNERSLEE T, 2001, SCI AM           MAY; Bunke H., 1990, SYNTACTIC STRUCTURAL; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; FU KS, 1982, SYNTACTIC PATTERN RE; Gale W.A., 1992, P 4 DARPA SPEECH NAT, P233; GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984; GONZALO J, 1998, P COLING ACL 98 WORK; Guarino N, 2002, COMMUN ACM, V45, P61, DOI 10.1145/503124.503150; Ide N, 1998, COMPUT LINGUIST, V24, P1; KROVETZ R, 1989, SIGIR FORUM, V23, P127, DOI 10.1145/75335.75349; Lea D., 2002, OXFORD COLLOCATIONS; Litkowski K, 2004, P SENSEVAL 3 3 INT W, P13; LONGMAN K, 2003, LONGMAN LANGUAGE ACT; Magnini B., 2000, P 2 INT C LANG RES E; McCarthy Diana, 2004, P 42 ANN M ASS COMP; MIHALCEA R, 2001, P WORKSH WORDN OTH L; Mihalcea R. F., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, P5, DOI 10.1142/S0218213001000398; Miller George A., 1994, P WORKSH HUM LANG TE, P240, DOI DOI 10.3115/1075812.1075866; NAVIGLI R, 2005, P 18 FLAIRS INT C MA; NAVIGLI R, 2004, COMPUTATIONAL LINGUI; NAVIGLI R, 2005, P AAI SPR S; Navigli Roberto, 2003, P WORKSH AD TEXT EXT; NG HT, 1996, P 34 ANN M ASS COMP; Resnik P., 1995, P INT JOINT C ART IN; Schank R., 1977, SCRIPTS PLANS GOALS; WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8; Witten IH, 1999, DATA MINING PRACTICA; 2004, 2 GLOB WORDN C   JAN; 2004, P EKAW04 WORKSH COR	30	153	169	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1075	1086		10.1109/TPAMI.2005.149	http://dx.doi.org/10.1109/TPAMI.2005.149			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013755	Green Submitted			2022-12-18	WOS:000229024300007
J	SAHA, PK; CHAUDHURI, BB				SAHA, PK; CHAUDHURI, BB			DETECTION OF 3-D SIMPLE POINTS FOR TOPOLOGY PRESERVING TRANSFORMATIONS WITH APPLICATION TO THINNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						3-D DIGITAL TOPOLOGY; TUNNEL; SIMPLE POINT; BINARY TRANSFORMATION; 3-D THINNING; SURFACE-SKELETON	3-DIMENSIONAL SKELETONIZATION; DIGITAL-TOPOLOGY	The problems of 3-D digital topology preservation under binary transformations and 3-D object thinning are considered in this correspondence. At first, we establish the conditions under which transformation of an object voxel to a non-object voxel, or its inverse does not affect the image topology. An efficient algorithm to detect a simple point has been proposed on the basis of those conditions. In this connection, some other interesting properties of 3-D digital geometry are also discussed. Using these properties and the simple point detection algorithm, we have proposed an algorithm to generate surface-skeleton so that the topology of the original image is preserved, the shape of the image is maintained as much as possible, and the results are less affected by noise.			SAHA, PK (corresponding author), INDIAN STAT INST,ELECTR & COMMUN SCI UNIT,203 BARRACKPUR TRUNK RD,CALCUTTA 700035,W BENGAL,INDIA.		Saha, Punam K/F-8833-2011	Saha, Punam/0000-0003-1576-118X				HAFFORD KJ, 1984, COMPUT VISION GRAPH, V27, P78, DOI 10.1016/0734-189X(84)90083-5; KONG TY, 1992, TOPOL APPL, V46, P219, DOI 10.1016/0166-8641(92)90016-S; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; LOBREGT S, 1980, IEEE T PATTERN ANAL, V2, P75, DOI 10.1109/TPAMI.1980.4766974; MORGENTHALER DG, 1981, TR1005 U MARYL COMP; SAHA P, 1991, TRKBCS291 NCKBCS LIB; SAHA PK, PATTERN RECOGNITION; SAHA PK, 1993, TRKBCS193 NCKBCS LIB; TORIWAKI JI, 1982, 6TH P INT C PATT REC, P414; TSAO YF, 1981, COMPUT VISION GRAPH, V17, P315, DOI 10.1016/0146-664X(81)90011-3; TSAO YF, 1982, P IEEE PATTERN RECOG, P678	11	153	158	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					1028	1032		10.1109/34.329007	http://dx.doi.org/10.1109/34.329007			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700006
J	ISHIGURO, H; YAMAMOTO, M; TSUJI, S				ISHIGURO, H; YAMAMOTO, M; TSUJI, S			OMNIDIRECTIONAL STEREO	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACTIVE VISION; BINOCULAR STEREO; CAMERA CONTROL; GLOBAL MAP; OMNIDIRECTIONAL STEREO; PRECISE OMNIDIRECTIONAL VIEW; RANGE INFORMATION		Omni-directional views of an indoor environment at different locations are integrated into a global map. A single camera swiveling about the vertical axis takes consecutive images and arranges them into a panoramic representation, which provides rich information around the observation point; a precise omni-directional view of the environment and coarse ranges to objects in it. Using the coarse map, the system autonomously plans consecutive observations at the intersections of lines connecting object points, where the directions of the imaging are estimated easily and precisely. From two panoramic views at the two planned locations, a modified binocular stereo method yields a more precise, but with direction-dependent uncertainties, local map. New observation points are selected to decrease the uncertainty, and another local map is yielded, which is then integrated into a more reliable global representation of the world with the adjacent local maps.			ISHIGURO, H (corresponding author), OSAKA UNIV,DEPT CONTROL ENGN,OSAKA,JAPAN.							ALOIMONOS J, 1987, 1ST P INT C COMP VIS, P35; AYACHE N, 1987, 1ST P INT C COMP VIS, P73; BALLARD DH, 1989, P INT JOINT C ART IN, P1635; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; ISHIGURO H, 1991, P IEEE INT C ROBOTIC; JARVIS RA, 1988, 4TH P INT S ROB RES, P497; LUI Y, 1986, 8TH P INT C PATT REC, P306; MITICHE, 1986, 8TH P INT C PATT REC, P1110; Morita T., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P422, DOI 10.1109/CVPR.1989.37881; OH SJ, 1987, P SPIE, V852; SANDINI G, 1990, IEEE T PATTERN ANAL, V12; SARACHIK KB, 1989, IEEE INT C ROB AUT, P984; SUGIHARA K, 1988, COMPUT VISION GRAPH, V42, P112, DOI 10.1016/0734-189X(88)90145-4; Yagi Y., 1990, Proceedings. IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90. Towards a New Frontier of Applications (Cat. No.90TH0332-7), P181, DOI 10.1109/IROS.1990.262385; ZHENG JY, 1990, 10TH P INT C PATT RE, P161	15	153	164	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					257	262		10.1109/34.121792	http://dx.doi.org/10.1109/34.121792			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900011
J	Wang, LW; Li, Y; Huang, J; Lazebnik, S				Wang, Liwei; Li, Yin; Huang, Jing; Lazebnik, Svetlana			Learning Two-Branch Neural Networks for Image-Text Matching Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; cross-modal retrieval; image-sentence retrieval; phrase localization; visual grounding		Image-language matching tasks have recently attracted a lot of attention in the computer vision field. These tasks include image-sentence matching, i.e., given an image query, retrieving relevant sentences and vice versa, and region-phrase matching or visual grounding, i.e., matching a phrase to relevant regions. This paper investigates two-branch neural networks for learning the similarity between these two data modalities. We propose two network structures that produce different output representations. The first one, referred to as an embedding network, learns an explicit shared latent embedding space with a maximum-margin ranking loss and novel neighborhood constraints. Compared to standard triplet sampling, we perform improved neighborhood sampling that takes neighborhood information into consideration while constructing mini-batches. The second network structure, referred to as a similarity network, fuses the two branches via element-wise product and is trained with regression loss to directly predict a similarity score. Extensive experiments show that our networks achieve high accuracies for phrase localization on the Flickr30K Entities dataset and for bi-directional image-sentence retrieval on Flickr30K and MSCOCO datasets.	[Wang, Liwei; Huang, Jing; Lazebnik, Svetlana] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Li, Yin] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA	University of Illinois System; University of Illinois Urbana-Champaign; University System of Georgia; Georgia Institute of Technology	Wang, LW (corresponding author), Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.	lwang97@illinois.edu; yli440@gatech.edu; jhuang81@illinois.edu; slazebni@illinois.edu		Huang, Jing/0000-0001-9301-9410	National Science Foundation [CIF-1302438, IIS-1563727]; Xerox UAC; Sloan Foundation	National Science Foundation(National Science Foundation (NSF)); Xerox UAC; Sloan Foundation(Alfred P. Sloan Foundation)	This material is based upon work supported by the National Science Foundation under Grants CIF-1302438 and IIS-1563727, Xerox UAC, and the Sloan Foundation. We would like to thank Bryan Plummer for providing features for region-phrase experiments, and Kevin Shih for thoughtful discussions on the similarity network and help with building the region-phrase experimental environment.	Andrew G, 2013, INT C MACH LEARN; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483; Ba L.J, 2016, P C WORKSH NEUR INF; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Chen X, 2015, CORR, V1504, P325; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Eisenschtat A, 2017, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2017.201; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Frome Andrea, 2013, NEURIPS; Fukui A., 2016, EMNLP; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Karpathy A., 2014, P 28 INT C NEUR INF, P889; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Kingma D.P, P 3 INT C LEARNING R; Kiros R., 2014, P 29 INT C MACH LEAR; Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073; Krishna R., 2016, VISUAL GENOME CONNEC; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301; Ma Z, 2015, PR MACH LEARN RES, V37, P169; Mao J, 2014, DEEP CAPTIONING MULT; Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Richard S. Zemel, 2014, Arxiv, DOI arXiv:1411.2539; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shaw B, 2011, ADV NEURAL INFORM PR, P1899; Shaw B, 2009, INT C MACH LEARN, P937, DOI DOI 10.1145/1553374.1553494; Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI DOI 10.1162/TACL_A_00177; Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI [DOI 10.1162/NEC0_A_00311, DOI 10.1109/CVPR.2013.49]; Vendrov I, 2015, ARXIV151106361; Venugopalan S., 2015, P C N AM CHAPT ASS C, P1494; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Wang MZ, 2016, LECT NOTES COMPUT SC, V9912, P696, DOI 10.1007/978-3-319-46484-8_42; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Weston Jason, 2011, 22 INT JOINT C ART I; Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966; Young Peter, 2014, T ASSOC COMPUT LING, V2, P67; Yu LC, 2017, PROC CVPR IEEE, P3521, DOI 10.1109/CVPR.2017.375; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	66	152	157	5	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					394	407		10.1109/TPAMI.2018.2797921	http://dx.doi.org/10.1109/TPAMI.2018.2797921			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994350	hybrid, Green Accepted			2022-12-18	WOS:000456150600010
J	Komodakis, N; Paragios, N; Tziritas, G				Komodakis, Nikos; Paragios, Nikos; Tziritas, Georgios			MRF Energy Minimization and Beyond via Dual Decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Discrete optimization; linear programming; Markov random fields; graphical models; message-passing; graph-cuts	BELIEF-PROPAGATION; PRIMAL SOLUTIONS; ALGORITHM	This paper introduces a new rigorous theoretical framework to address discrete MRF-based optimization in computer vision. Such a framework exploits the powerful technique of Dual Decomposition. It is based on a projected subgradient scheme that attempts to solve an MRF optimization problem by first decomposing it into a set of appropriately chosen subproblems, and then combining their solutions in a principled way. In order to determine the limits of this method, we analyze the conditions that these subproblems have to satisfy and demonstrate the extreme generality and flexibility of such an approach. We thus show that by appropriately choosing what subproblems to use, one can design novel and very powerful MRF optimization algorithms. For instance, in this manner we are able to derive algorithms that: 1) generalize and extend state-of-the-art message-passing methods, 2) optimize very tight LP-relaxations to MRF optimization, and 3) take full advantage of the special structure that may exist in particular MRFs, allowing the use of efficient inference techniques such as, e g., graph-cut-based methods. Theoretical analysis on the bounds related with the different algorithms derived from our framework and experimental results/comparisons using synthetic and real data for a variety of tasks in computer vision demonstrate the extreme potentials of our approach.	[Komodakis, Nikos; Tziritas, Georgios] Univ Crete, Dept Comp Sci, Iraklion 71409, Greece; [Paragios, Nikos] Ecole Cent Paris, INRIA Saclay Ile De France, F-92295 Chatenay Malabry, France	University of Crete; UDICE-French Research Universities; Universite Paris Saclay	Komodakis, N (corresponding author), Univ Crete, Dept Comp Sci, POB 2208, Iraklion 71409, Greece.	komod@csd.uoc.gr; nikos.paragios@ecp.fr; tziritas@csd.uoc.gr	Tziritas, Georgios/AAO-5855-2021					Barahona F, 2000, MATH PROGRAM, V87, P385, DOI 10.1007/s101070050002; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; BERTSEKAS DP, 1973, SIAM J CONTROL, V11, P637, DOI 10.1137/0311049; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Braunstein A, 2005, RANDOM STRUCT ALGOR, V27, P201, DOI 10.1002/rsa.20057; Camerini P.M., 1975, NONDIFFERENTIABLE OP, P26; Chekuri C, 2001, SIAM PROC S, P109; DUCHI J, 2006, ADV NEURAL INFORM PR; Elidan G, 2006, P 22 C UNC AI; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FREY BJ, 1998, ADV NEURAL INFORM PR; Globerson A., 2008, ADV NEURAL INFORM PR, P553; Heskes T., 2003, ADV NEURAL INFORM PR, P359; Heskes T., 2003, ADV NEURAL INFORM PR, P438; Heskes T, 2006, J ARTIF INTELL RES, V26, P153, DOI 10.1613/jair.1933; Johnson J., 2007, P ALL C COMM CONTR C; Jordan M. I., 1999, LEARNING GRAPHICAL M; Kim J., 2003, P IEEE INT C COMP VI; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; KOLMOGOROV V, 2005, P C UNC ART INT; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; KOMODAKIS N, 2006, P IEEE C COMP VIS PA; KOMODAKIS N, 2007, P IEEE INT C COMP VI; KOMODAKIS N, 2007, P IEEE C COMP VIS PA; Komodakis Nikos, 2008, P EUR C COMP VIS; KUMAR MP, 2007, ADV NEURAL INFORM PR; KWATRA V, 2003, P ACM SIGGRAPH; Larsson T, 1999, MATH PROGRAM, V86, P283, DOI 10.1007/s101070050090; MELTZER T, 2005, P IEEE INT C COMP VI; Nedic A, 2001, SIAM J OPTIMIZ, V12, P109, DOI 10.1137/S1052623499362111; Nedic A, 2009, SIAM J OPTIMIZ, V19, P1757, DOI 10.1137/070708111; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; RAJ A, 2006, P IEEE C COMP VIS PA; RAVIKUMAR P, 2008, P INT C MACH LEARN, P800; ROTH S, 2005, P IEEE C COMP VIS PA; Rother C., 2007, P IEEE C COMP VIS PA; SCHLESINGER M, 1976, KIBERNETIKA, V4, P113; SCHLESINGER M, 2007, CONTROL SYSTEMS COMP, V1, P3; Sherali HD, 1996, OPER RES LETT, V19, P105, DOI 10.1016/0167-6377(96)00019-3; SHOR NZ, 1985, MINIMIZATION METHODS; SONTAG D, 2008, P C UNC ART INT; Sontag D., 2008, ADV NEURAL INFORM PR; SUDDERTH EB, 2003, P IEEE C COMP VIS PA; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; TON P. H. S., 2005, P IEEE C COMP VIS PA; Torresani L., 2008, P EUR C COMP VIS; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Weiss Y, 2001, NEURAL COMPUT, V13, P2173, DOI 10.1162/089976601750541769; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; WEISS Y, 2007, P 22 C UNC AI, P22; WERNER T, 2008, P IEEE C COMP VIS PA; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Yanover C, 2006, J MACH LEARN RES, V7, P1887; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085	57	152	159	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					531	552		10.1109/TPAMI.2010.108	http://dx.doi.org/10.1109/TPAMI.2010.108			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20479493				2022-12-18	WOS:000286204700008
J	Koelstra, S; Pantic, M; Patras, I				Koelstra, Sander; Pantic, Maja; Patras, Ioannis (Yiannis)			A Dynamic Texture-Based Approach to Recognition of Facial Actions and Their Temporal Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial image analysis; facial expression; dynamic texture; motion	EXPRESSION	In this work, we propose a dynamic texture-based approach to the recognition of facial Action Units (AUs, atomic facial gestures) and their temporal models (i.e., sequences of temporal segments: neutral, onset, apex, and offset) in near-frontal-view face videos. Two approaches to modeling the dynamics and the appearance in the face region of an input video are compared: an extended version of Motion History Images and a novel method based on Nonrigid Registration using Free-Form Deformations (FFDs). The extracted motion representation is used to derive motion orientation histogram descriptors in both the spatial and temporal domain. Per AU, a combination of discriminative, frame-based GentleBoost ensemble learners and dynamic, generative Hidden Markov Models detects the presence of the AU in question and its temporal segments in an input image sequence. When tested for recognition of all 27 lower and upper face AUs, occurring alone or in combination in 264 sequences from the MMI facial expression database, the proposed method achieved an average event recognition accuracy of 89.2 percent for the MHI method and 94.3 percent for the FFD method. The generalization performance of the FFD method has been tested using the Cohn-Kanade database. Finally, we also explored the performance on spontaneous expressions in the Sensitive Artificial Listener data set.	[Koelstra, Sander; Patras, Ioannis (Yiannis)] Queen Mary Univ London, London E1 4NS, England; [Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England	University of London; Queen Mary University London; Imperial College London	Koelstra, S (corresponding author), Queen Mary Univ London, Mile End Rd, London E1 4NS, England.	sander.koelstra@elec.qmul.ac.uk; m.pantic@imperial.ac.uk; i.patras@elec.qmul.ac.uk		Patras, Ioannis/0000-0003-3913-4738	Seventh Framework Programme [FP7-216444]; EC [FP7/2007-2013, 211486]; European Research Council [ERC-2007-StG-203143]; EPSRC [EP/G033935/1]; Engineering and Physical Sciences Research Council [EP/G033935/1] Funding Source: researchfish	Seventh Framework Programme(European Commission); EC(European CommissionEuropean Commission Joint Research Centre); European Research Council(European Research Council (ERC)European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank Jeffrey Cohn of the University of Pittsburgh for providing the Cohn-Kanade database. The research of Sander Koelstra has received funding from the Seventh Framework Programme under grant agreement no. FP7-216444 (PetaMedia). This work has been funded first in part by the EC's Seventh Framework Programme [FP7/2007-2013] under grant agreement no 211486 (SEMAINE). The current research of Maja Pantic is funded by the European Research Council under the ERC Starting Grant agreement no. ERC-2007-StG-203143 (MAH-NOB). The research of Ioannis Patras has been partially supported by EPSRC Grant No EP/G033935/1.	AARTS E, 2005, ACM INTERACTIONS, V12, P66; Anderson DF, 2006, ROCKY MT J MATH, V36, P1, DOI 10.1216/rmjm/1181069485; [Anonymous], IEEE INT C AUT FAC G; [Anonymous], 2007, FACE RECOGNITION, DOI [10.5772/4847, DOI 10.5772/4847]; Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55; Bartlett MS, 2005, PROC CVPR IEEE, P568; Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006; Chetverikov D, 2005, ADV SOFT COMP, P17; Cohen I, 2003, PROC CVPR IEEE, P595; Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439; Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 2005, WHAT FACE REVEALS BA, DOI DOI 10.1093/ACPROF:OSO/9780195179644.001.0001; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gokturk SB, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P287, DOI 10.1109/AFGR.2002.1004168; Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Lu Zongqing, 2005, WACVMOTION, P241; Lucey S., 2007, FACE RECOGNITION, P275; Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424; Pantic M, 2005, IEEE SYS MAN CYBERN, P3358; Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Polana R., 1997, MOTION BASED RECOGNI, P87; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Saisan P, 2001, PROC CVPR IEEE, P58; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Valstar M, 2004, IEEE SYS MAN CYBERN, P635; VALSTAR M, 2006, P IEEE C COMP VIS PA, V3; Valstar MF, 2007, LECT NOTES COMPUT SC, V4796, P118; Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692; Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646; Whitehill J, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P97; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zeng ZH, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P126; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018	44	152	157	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					1940	1954		10.1109/TPAMI.2010.50	http://dx.doi.org/10.1109/TPAMI.2010.50			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847386	Green Submitted			2022-12-18	WOS:000281990900002
J	Komodakis, N; Tziritas, G				Komodakis, Nikos; Tziritas, Georgios			Approximate labeling via graph cuts based on linear programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						global optimization; graph-theoretic methods; linear programming; Markov Random Fields; pixel classification; graph labeling; graph algorithms; early vision; stereo; motion; image restoration		A new framework is presented for both understanding and developing graph-cut-based combinatorial algorithms suitable for the approximate optimization of a very wide class of Markov Random Fields (MRFs) that are frequently encountered in computer vision. The proposed framework utilizes tools from the duality theory of linear programming in order to provide an alternative and more general view of state-of-the-art techniques like the alpha-expansion algorithm, which is included merely as a special case. Moreover, contrary to alpha-expansion, the derived algorithms generate solutions with guaranteed optimality properties for a much wider class of problems, for example, even for MRFs with nonmetric potentials. In addition, they are capable of providing per-instance suboptimality bounds in all occasions, including discrete MRFs with an arbitrary potential function. These bounds prove to be very tight in practice ( that is, very close to 1), which means that the resulting solutions are almost optimal. Our algorithms' effectiveness is demonstrated by presenting experimental results on a variety of low-level vision tasks, such as stereo matching, image restoration, image completion, and optical flow estimation, as well as on synthetic problems.	Univ Crete, Dept Comp Sci, Iraklion 71409, Greece	University of Crete	Komodakis, N (corresponding author), Univ Crete, Dept Comp Sci, POB 2208, Iraklion 71409, Greece.	komod@csd.uoc.gr; tziritas@csd.uoc.gr	Tziritas, Georgios/AAO-5855-2021					ARCHER A, 2004, P 15 ANN ACM SIAM S; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Chekuri C, 2001, SIAM PROC S, P109; Gupta A., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, P652, DOI 10.1145/335305.335397; ISHIKAWA H, 1998, P C COMP VIS PATT RE; Kleinberg J, 2002, J ACM, V49, P616, DOI 10.1145/585265.585268; KOLMOGOROV V, 2005, P 10 INT WORKSH ART; KOLMOGOROV V, 2002, P EUR C COMP VIS, P82; KOMODAKIS N, 2005, P 10 IEEE INT C COMP; KOMODAKIS N, 2005, CSDTR0501; MELTZER T, 2005, P 10 IEEE INT C COMP; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Rother C., 2005, P C COMP VIS PATT RE; ROY S, 1998, P 6 IEEE INT C COMP; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; VEKSLER O, 1999, THESIS CORNELL U; WAINWRIGHT MJ, 2002, P 40 ANN ALL C COMM; Zabih R, 2004, PROC CVPR IEEE, P437	23	152	159	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1436	1453		10.1109/TPAMI.2007.1061	http://dx.doi.org/10.1109/TPAMI.2007.1061			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568146				2022-12-18	WOS:000247186500011
J	Davis, J; Nehab, D; Ramamoorthi, R; Rusinkiewicz, S				Davis, J; Nehab, D; Ramamoorthi, R; Rusinkiewicz, S			Spacetime stereo: A unifying framework for depth from triangulation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						depth from triangulation; stereo; spacetime stereo		Depth from triangulation has traditionally been investigated in a number of independent threads of research, with methods such as stereo, laser scanning, and coded structured light considered separately. In this paper, we propose a common framework called spacetime stereo that unifies and generalizes many of these previous methods. To show the practical utility of the framework, we develop two new algorithms for depth estimation: depth from unstructured illumination change and depth estimation in dynamic scenes. Based on our analysis, we show that methods derived from the spacetime stereo framework can be used to recover depth in situations in which existing methods perform poorly.	USA, Honda Res Inst, Mountain View, CA 94041 USA; Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Honda Motor Company; Princeton University; Columbia University	Davis, J (corresponding author), USA, Honda Res Inst, 800 Calif St,Suite 300, Mountain View, CA 94041 USA.	jedavis@ieee.org; diego@cs.princeton.edu; ravir@cs.columbia.edu; smr@cs.princeton.edu	Nehab, Diego/AAV-2002-2020	Rusinkiewicz, Szymon/0000-0002-4253-2588				ARAKI K, 1987, P SPIE OPTICS ILLUMI, V850; Batlle J, 1998, PATTERN RECOGN, V31, P963, DOI 10.1016/S0031-3203(97)00074-5; Besl P.J., 1989, ADV MACHINE VISION, P1, DOI [10.1007/978-1-4612-4532-21, DOI 10.1007/978-1-4612-4532-21]; Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Borghese NA, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.674970; Bouguet JY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P43, DOI 10.1109/ICCV.1998.710699; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1; CURLESS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P987, DOI 10.1109/ICCV.1995.466772; CURLESS B, 1999, P SIGGRAPH 99 COURS; DAVIS J, 2001, P 3 INT C 3D DIG IM; DAVIS J, 2003, P IEEE CS C COMP VIS; Dhond U.R., 1989, IEEE T SYSTEMS MAN C, V19; Hall-Holt O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P359, DOI 10.1109/ICCV.2001.937648; Inokuchi S., 1984, P INT C PATT REC, P806; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KANADE T, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1322, DOI 10.1109/ROBOT.1991.131796; KANG SB, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P88, DOI 10.1109/ICCV.1995.466802; MEDIONI G, 1987, OPTICAL SOC AM TECHN, V12, P34; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1992, INT J COMPUTER VISIO, V7; Poussart D., 1989, ADV MACHINE VISION, P122; Pulli K, 1998, INT C PATT RECOG, P11, DOI 10.1109/ICPR.1998.711067; Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600; SAINTMARC P, 1991, IEEE T ROBOTIC AUTOM, V7, P250, DOI 10.1109/70.75907; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SCHARSTEIN D, 2003, P COMPUTER VISION PA; SHECHTMAN E, 2002, P EUROPEAN C COMPUTE; STRAND TC, 1985, OPT ENG, V24, P33, DOI 10.1117/12.7973422; ZHANG L, 2002, IEEE 3D DATA PROCESS; ZHANG L, 2003, P COMPUTER VISION PA	33	152	167	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					296	302		10.1109/TPAMI.2005.37	http://dx.doi.org/10.1109/TPAMI.2005.37			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688568				2022-12-18	WOS:000225689300014
J	Jiang, XY; Munger, A; Bunke, H				Jiang, XY; Munger, A; Bunke, H			On median graphs: Properties, algorithms, and applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						median graph; graph distance; graph matching; genetic algorithm; learning	PATTERN-RECOGNITION; SEARCH	In object prototype learning and, similar tasks, median computation is an important technique for capturing the essential information of a given: set of patterns. In this paper, we extend the median concept to the domain of graphs. In terms of graph distance, we introduce the novel concepts of set median and generalized median of a set of graphs. We study properties of both types of median graphs. For the more complex task of computing generalized median graphs, a genetic search algorithm is developed. Experiments conducted on randomly generated graphs demonstrate the advantage of generalized median graphs compared to set median graphs and the ability of our genetic algorithm to find approximate generalized median graphs in: reasonable time. Application examples with both synthetic and nonsynthetic, data are shown to illustrate the practical usefulness of the concept of median graphs.	Univ Bern, Dept Comp Sci, CH-3012 Bern, Switzerland	University of Bern	Jiang, XY (corresponding author), Univ Bern, Dept Comp Sci, CH-3012 Bern, Switzerland.		Jiang, Xiaoyi/A-3958-2013; Jiang, Xiaoyi/AAA-3532-2022	Jiang, Xiaoyi/0000-0001-7678-9528				BHANU B, 1994, IEEE T PATTERN ANAL, V16, P865; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; Bunke H, 1999, IEEE T PATTERN ANAL, V21, P917, DOI 10.1109/34.790431; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; de la Higuera C, 2000, THEOR COMPUT SCI, V230, P39, DOI 10.1016/S0304-3975(97)00240-5; DEJONG KA, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P124; Fernandez ML, 2001, PATTERN RECOGN LETT, V22, P753, DOI 10.1016/S0167-8655(01)00017-4; Glover F., 1997, TABU SEARCH; HUTCHINSON A, 1994, ALGORITHMIC LEARNING; JIANG X, 2000, GRAPHICS RECOGNITION, P183; JIANG X, 1999, P 2 IAPR WORKSH GRAP, P115; Juan A., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P905, DOI 10.1007/BFb0033318; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Klein P.N., 1998, P 6 ANN EUR S ALG ES, P91; LEE JP, 1990, EYE, V4, P1; Lopresti D, 1997, COMPUT VIS IMAGE UND, V67, P39, DOI 10.1006/cviu.1996.0502; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; MICHALSKI SR, 1992, P NFS ARPA WORKSH MA; Mitchell M., 1998, INTRO GENETIC ALGORI; PEARCE A, 1994, PATTERN RECOGN, V27, P1231, DOI 10.1016/0031-3203(94)90007-8; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SCHWARTZ SR, 1994, HDB PATTERN RECOGNIT, P319; SHAPIRA R, 1985, IEEE T PATTERN ANAL, V7, P1, DOI 10.1109/TPAMI.1985.4767614; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; Wallis WD, 2001, PATTERN RECOGN LETT, V22, P701, DOI 10.1016/S0167-8655(01)00022-8; Wang JTL, 1998, IEEE T PATTERN ANAL, V20, P889, DOI 10.1109/34.709622; WANG JTL, 1995, INFORM SCIENCES, V82, P45, DOI 10.1016/0020-0255(94)00057-I; Wang YK, 1997, IEEE T SYST MAN CY B, V27, P588, DOI 10.1109/3477.604100; WONG C, 1992, CHINESE ECON STUD, V25, P3, DOI 10.2753/CES1097-147525043; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1	34	152	156	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1144	1151						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600008
J	Sun, CM; Sherrah, J				Sun, CM; Sherrah, J			3D symmetry detection using the extended Gaussian image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symmetry detection; reflectional and rotational symmetry; extended Gaussian image; sphere tessellation; orientation histogram; principal axis	OBJECTS	Symmetry detection is important in the area of computer vision. A 3D symmetry detection algorithm is presented in this correspondence. The symmetry detection problem is converted to the correlation of the Gaussian image. Once the Gaussian image of the object has been obtained, the algorithm is independent of the input format. The algorithm can handle different kinds of images or objects. Simulated and real images have been tested in a variety of formats, and the results show that the symmetry can be determined using the Gaussian image.	UNIV ADELAIDE,DEPT ELECT & ELECT ENGN,ADELAIDE,SA 5005,AUSTRALIA	University of Adelaide	Sun, CM (corresponding author), CSIRO,DIV MATH & STAT,LOCKED BAG 17,N RYDE,NSW 2113,AUSTRALIA.		Sun, Changming/A-3276-2008	Sun, Changming/0000-0001-5943-1989				ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; BROU P, 1984, INT J ROBOT RES, V3, P89, DOI 10.1177/027836498400300406; BROWN CM, 1977, TR13 U ROCH COMP SCI; Burel G, 1995, GRAPH MODEL IM PROC, V57, P400, DOI 10.1006/gmip.1995.1034; Fisher NI., 1987, STAT ANAL SPHERICAL, DOI [10.1017/CBO9780511623059, DOI 10.1017/CBO9780511623059]; Horn B., 1986, ROBOT VISION, P1; IKEUCHI K, 1981, IJCAI           0824, P595; ISHIKAWA S, 1992, IAPR WORKSH MACH VIS, P375; JIANG XY, 1992, CVGIP-GRAPH MODEL IM, V54, P91, DOI 10.1016/1049-9652(92)90037-X; KANG SB, 1993, IEEE T PATTERN ANAL, V15, P707, DOI 10.1109/34.221171; KORN MR, 1987, PATTERN RECOGN, V20, P91, DOI 10.1016/0031-3203(87)90020-3; MINOVIC P, 1993, IEEE T PATTERN ANAL, V15, P507, DOI 10.1109/34.211472; MINOVIC P, 1992, 21 KYUSH I TECHN; PARRYBARWICK S, 1993, DIGITAL IMAGE COMPUT, V1, P39; Wolter J., 1985, VISUAL COMPUT, V1, P37; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZABRODSKY H, 1992, P INT C PATT REC, V3, P9	17	152	164	7	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					164	168		10.1109/34.574800	http://dx.doi.org/10.1109/34.574800			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800011
J	KUO, SS; AGAZZI, OE				KUO, SS; AGAZZI, OE			KEYWORD SPOTTING IN POORLY PRINTED DOCUMENTS USING PSEUDO-2D HIDDEN MARKOV-MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						OPTICAL CHARACTER RECOGNITION; KEYWORD RECOGNITION; 2-D HIDDEN MARKOV MODEL; DYNAMIC PROGRAMMING	SPEECH RECOGNITION	An algorithm for robust machine recognition of keywords embedded in a poorly printed document is presented. For each keyword, two statistical models, named pseudo 2-D Hidden Markov Models, are created for representing the actual keyword and all the other extraneous words, respectively. Dynamic programming is then used for matching an unknown input word with the two models and for making a maximum likelihood decision. Although the models are pseudo 2-D in the sense that they are not fully connected 2-D networks, they are shown to be general enough in characterizing printed words efficiently. These models facilitate a nice ''elastic matching'' property in both horizontal and vertical directions, which makes the recognizer not only independent of size and slant but also tolerant of highly deformed and noisy words. The system is evaluated on a synthetically created database that contains about 26000 words. Currently, we achieve the recognition accuracy of 99% when words in testing and training sets are or the same font size, and 96% when they are in different sizes. In the latter case, the conventional 1-D HMM achieves only a 70% accuracy rate.	AT&T BELL LABS,SIGNAL PROC RES DEPT,MURRAY HILL,NJ 07974	AT&T; Nokia Corporation; Nokia Bell Labs	KUO, SS (corresponding author), AT&T BELL LABS,SOMERSET,NJ 08873, USA.							AGAZZI OE, 1993, PATTERN RECOGN, V26, P1813, DOI 10.1016/0031-3203(93)90178-Y; AGAZZI OE, 1993, P ICASSP 93; BAIRD HS, 1992, P IEEE, V80, P1059, DOI 10.1109/5.156469; BELAID A, 1991, 5TH P INT S APPL STO; BOSE C, 1992, 11TH P INT C PATT RE; CHEN F, 1993, P ICASSP 93; HE Y, 1992, P ICASSP 92; KUO S, 1994, IN PRESS J VISUAL CO, V5; LEVIN E, 1992, P ICASSP 92; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626	11	152	172	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					842	848		10.1109/34.308482	http://dx.doi.org/10.1109/34.308482			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500012
J	JOLION, JM; MEER, P; BATAOUCHE, S				JOLION, JM; MEER, P; BATAOUCHE, S			ROBUST CLUSTERING WITH APPLICATIONS IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CLUSTERING; FEATURE SPACE; HOUGH TRANSFORM; MULTITHRESHOLDING; RANGE IMAGE SEGMENTATION; ROBUST ESTIMATION	HOUGH TRANSFORM; SEGMENTATION; RECOGNITION; MODEL	A novel clustering algorithm based on the minimum volume ellipsoid (MVE) robust estimator recently introduced in statistics is proposed. The MVE estimator identifies the least volume region containing h percent of the data points. The clustering algorithm iteratively partitions the space into clusters without a priori information about their number. At each iteration, the MVE estimator is applied several times with values of h decreasing from 0.5. A cluster is hypothesised for each ellipsoid. The shapes of these clusters are compared with shapes corresponding to a known unimodal distribution by the Kolmogorov-Smirnov test. The best fitting cluster is then removed from the space, and a new iteration starts. Constrained random sampling keeps the amount of computation low. The clustering algorithm was successfully applied to several computer vision problems formulated in the feature space paradigm: multithresholding of gray level images, analysis of the Hough space, range image segmentation.	RUTGERS STATE UNIV,DEPT ELECT & COMP ENGN,PISCATAWAY,NJ 08855; UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	Rutgers State University New Brunswick; University System of Maryland; University of Maryland College Park	JOLION, JM (corresponding author), LAB INFORMAT UNIV,VILLEURBANNE,FRANCE.							BERGEN JR, 1989, UNPUB J ALGORITHMS; Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Duda R.O., 1973, J ROYAL STAT SOC SER; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HAMPEL FR, 1986, ROBUST STATISTICS AP; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; JOLION JM, 1990, CARTR485 U MARYL COM; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; KIRYATI N, 1989, 6TH P SCAND C IM AN, P621; MEER P, 1990, SEP P DARPA IM UND W, P231; MEER P, 1990, JUL P AAAI 90 WORKSH, P111; OROURKE J, 1984, IEEE T PATTERN ANAL, V6, P266, DOI 10.1109/TPAMI.1984.4767519; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Press W. H., 1988, NUMERICAL RECIPES; RISSE T, 1989, COMPUT VISION GRAPH, V46, P327, DOI 10.1016/0734-189X(89)90036-4; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1990, J AM STAT ASSOC, V85, P633, DOI 10.2307/2289995; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; YOKOYA N, 1989, IEEE T PATTERN ANAL, V11, P643, DOI 10.1109/34.24798; [No title captured]	29	152	166	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					791	802		10.1109/34.85669	http://dx.doi.org/10.1109/34.85669			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200004
J	Bae, SH; Yoon, KJ				Bae, Seung-Hwan; Yoon, Kuk-Jin			Confidence-Based Data Association and Discriminative Deep Appearance Learning for Robust Online Multi-Object Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-object tracking; tracking-by-detection; tracklet confidence; confidence-based data association; deep appearance learning; online transfer learning; surveillance system	MULTITARGET TRACKING; MULTIPLE	Online multi-object tracking aims at estimating the tracks of multiple objects instantly with each incoming frame and the information provided up to the moment. It still remains a difficult problem in complex scenes, because of the large ambiguity in associating multiple objects in consecutive frames and the low discriminability between objects appearances. In this paper, we propose a robust online multi-object tracking method that can handle these difficulties effectively. We first define the tracklet confidence using the detectability and continuity of a tracklet, and decompose a multi-object tracking problem into small subproblems based on the tracklet confidence. We then solve the online multi-object tracking problem by associating tracklets and detections in different ways according to their confidence values. Based on this strategy, tracklets sequentially grow with online-provided detections, and fragmented tracklets are linked up with others without any iterative and expensive association steps. For more reliable association between tracklets and detections, we also propose a deep appearance learning method to learn a discriminative appearance model from large training datasets, since the conventional appearance learning methods do not provide rich representation that can distinguish multiple objects with large appearance variations. In addition, we combine online transfer learning for improving appearance discriminability by adapting the pre-trained deep model during online tracking. Experiments with challenging public datasets show distinct performance improvement over other state-of-the-arts batch and online tracking methods, and prove the effect and usefulness of the proposed methods for online multi-object tracking.	[Bae, Seung-Hwan] Incheon Natl Univ, Dept Comp Sci & Engn, 119 Acad Ro, Incheon 22012, South Korea; [Yoon, Kuk-Jin] Gwangju Inst Sci & Technol, Sch Informat & Commun, 261 Cheomdan Gwagiro, Gwangju 500712, South Korea	Incheon National University; Gwangju Institute of Science & Technology (GIST)	Bae, SH (corresponding author), Incheon Natl Univ, Dept Comp Sci & Engn, 119 Acad Ro, Incheon 22012, South Korea.	shbae@inu.ac.kr; kjyoon@gist.ac.kr	Yoon, Kuk-Jin/F-4329-2018	yun, gugjin/0000-0002-1634-2756	National Research Foundation of Korea (NRF) grant - Korea government (MSIP) [NRF-2015R1A2A1A01005455]; ICT R&D program of MSIP/IITP [B0101-15-0266]	National Research Foundation of Korea (NRF) grant - Korea government (MSIP)(National Research Foundation of Korea); ICT R&D program of MSIP/IITP(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea)	This work was supported by the ICT R&D program of MSIP/IITP [No. B0101-15-0266, Development of High Performance Visual BigData Discovery Platform] and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) [No. NRF-2015R1A2A1A01005455]. Kuk-Jin Yoon is the corresponding author.	Ahuja R. K., 1993, NETWORK FLOWS THEORY; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2009, C DATASET; [Anonymous], 2009, P DATASET; Avidan S, 2005, PROC CVPR IEEE, P494; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P2820, DOI 10.1109/TIP.2014.2320821; Ban Y., 2016, ECCVW, P52; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107; Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Fagot-Bouquet L, 2016, LECT NOTES COMPUT SC, V9912, P774, DOI 10.1007/978-3-319-46484-8_47; Fowlkes C. C., 2015, P BRIT MACH VIS C; Glorot X., 2010, PROC MACH LEARN RES, P249; Grabner H, 2006, IEEE C COMP VIS PATT, P260; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Huang C, 2013, IEEE T PATTERN ANAL, V35, P898, DOI 10.1109/TPAMI.2012.159; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; Leal-Taixe L., 2015, COMPUTING RES REPOSI; Li H., 2014, P BMVC, P1, DOI DOI 10.5244/C.28.56; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Milan A., 2016, COMPUTING RES REPOSI; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Poiesi F, 2013, COMPUT VIS IMAGE UND, V117, P1257, DOI 10.1016/j.cviu.2012.08.008; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7; Sanjoy D., 2013, INT C MACH LEARN, P1319, DOI DOI 10.5555/3042817.3043084; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Simard P. Y., 2012, NEURAL NETWORKS TRIC; Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48; Wang N, 2013, ADV NEURAL INFORM PR, DOI DOI 10.5555/2999611.2999702; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892	58	151	158	3	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					595	610		10.1109/TPAMI.2017.2691769	http://dx.doi.org/10.1109/TPAMI.2017.2691769			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28410099				2022-12-18	WOS:000424465900007
J	Lin, Z; Davis, LS				Lin, Zhe; Davis, Larry S.			Shape-Based Human Detection and Segmentation via Hierarchical Part-Template Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generic human detector; part-template tree; hierarchical part-template matching; pose-adaptive descriptor; occlusion analysis	OBJECT DETECTION	We propose a shape-based, hierarchical part-template matching approach to simultaneous human detection and segmentation combining local part-based and global shape-template-based schemes. The approach relies on the key idea of matching a part-template tree to images hierarchically to detect humans and estimate their poses. For learning a generic human detector, a pose-adaptive feature computation scheme is developed based on a tree matching approach. Instead of traditional concatenation-style image location-based feature encoding, we extract features adaptively in the context of human poses and train a kernel-SVM classifier to separate human/nonhuman patterns. Specifically, the features are collected in the local context of poses by tracing around the estimated shape boundaries. We also introduce an approach to multiple occluded human detection and segmentation based on an iterative occlusion compensation scheme. The output of our learned generic human detector can be used as an initial set of human hypotheses for the iterative optimization. We evaluate our approaches on three public pedestrian data sets (INRIA, MIT-CBCL, and USC-B) and two crowded sequences from Caviar Benchmark and Munich Airport data sets.	[Lin, Zhe] Adobe Syst Inc, Adv Technol Labs, San Jose, CA 95110 USA; [Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Adobe Systems Inc.; University System of Maryland; University of Maryland College Park	Lin, Z (corresponding author), Adobe Syst Inc, Adv Technol Labs, 345 Pk Ave, San Jose, CA 95110 USA.	zlin@adobe.com; lsd@cs.umd.edu			US Defense Advanced Research Projects Agency (DARPA)	US Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	The support of the US Defense Advanced Research Projects Agency (DARPA) under project VIRAT (subcontractor to Kitware, Inc.) is gratefully acknowledged. The authors would like to thank Siemens Corporate Research for providing the Munich Airport Surveillance Video data set for experiments.	Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dollar P, 2008, LECT NOTES COMPUT SC, V5303, P211, DOI 10.1007/978-3-540-88688-4_16; Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2003, PROC CVPR IEEE, P264; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Hoiem D, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.232; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Kumar MP, 2005, PROC CVPR IEEE, P18; Leibe B, 2005, PROC CVPR IEEE, P878; LIN Z, 2008, P EUR C COMP VIS, V4, P423; Maji S, 2008, PROC CVPR IEEE, P2245; Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575; PANG J, 2008, P EUR C COMP VIS, V4, P541; Papageorgiou C., 1998, P INT VEH, P241; Rittscher J, 2005, PROC CVPR IEEE, P486; Sabzmeydani P., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383134; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; SEEMANN E, 2006, P IEEE INT C COMP VI, V2, P1582; Sharma V, 2007, IEEE I CONF COMP VIS, P1610; Shet V.D., 2007, P IEEE C COMP VIS PA, P1; Shotton J, 2005, IEEE I CONF COMP VIS, P503; Smith K, 2005, PROC CVPR IEEE, P962; Tao H, 1999, P WORKSH VIS ALG, P53; TRAN D, 2007, P C ADV NEUR INF PRO; TRAN S, 2007, P CLEAR WORKSH, P179; Tran S, 2007, IEEE I CONF COMP VIS, P944; TUZEL O, 2007, P IEEE C COMP VIS PA, P1; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Winn J., 2006, CVPR; Wu B, 2005, IEEE I CONF COMP VIS, P90; Wu B, 2008, PROC CVPR IEEE, P3168; Wu Y, 2005, PROC CVPR IEEE, P1023; Zhao DL, 2007, IEEE I CONF COMP VIS, P206; Zhao L, 2005, IEEE I CONF COMP VIS, P454; Zhao Q, 2006, INT C PATT RECOG, P450; Zhao T, 2004, PROC CVPR IEEE, P406; Zhu Qiang, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.119	48	151	168	3	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					604	618		10.1109/TPAMI.2009.204	http://dx.doi.org/10.1109/TPAMI.2009.204			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224118				2022-12-18	WOS:000274548800004
J	Ben Ayed, I; Mitiche, A; Belhadj, Z				Ben Ayed, I; Mitiche, A; Belhadj, Z			Multiregion level-set partitioning of synthetic aperture radar images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; active contours; level sets; statistical modeling; synthetic aperture radar	SAR IMAGES; SEGMENTATION; MODEL; DETECTOR	The purpose of this study is to investigate Synthetic Aperture Radar (SAR) image segmentation into a given but arbitrary number of gamma homogeneous regions via active contours and level sets. The segmentation of SAR images is a difficult problem due to the presence of speckle which can be modeled as strong, multiplicative noise. The proposed algorithm consists of evolving simple closed planar curves within an explicit correspondence between the interiors of curves and regions of segmentation to minimize a criterion containing a term of conformity of data to a speckle model of noise and a term of regularization. Results are shown on both synthetic and real images.	INRS EMT, Montreal, PQ H5A 1K6, Canada; Ecole Super Commun Tunis SUP COM, Tunis 2083, Tunisia	University of Quebec; Institut national de la recherche scientifique (INRS)	Ben Ayed, I (corresponding author), INRS EMT, 800 Gauchetiere Ouest, Montreal, PQ H5A 1K6, Canada.	benayedi@inrs-emt.uquebec.ca; mitchie@inrs-emt.uquebec.ca; ziad.belhadj@supcom.rnu.tn						Belhadj Z, 2002, INT J REMOTE SENS, V23, P2263, DOI 10.1080/01431160110070762; BOVIK AC, 1988, IEEE T ACOUST SPEECH, V36, P1618, DOI 10.1109/29.7550; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; Fjortoft R, 1998, IEEE T GEOSCI REMOTE, V36, P793, DOI 10.1109/36.673672; FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223; Galland F, 2003, IEEE T IMAGE PROCESS, V12, P995, DOI 10.1109/TIP.2003.816005; Germain O, 2000, IEEE T GEOSCI REMOTE, V38, P1455, DOI 10.1109/36.843041; Germain O, 2001, PATTERN RECOGN LETT, V22, P1125, DOI 10.1016/S0167-8655(01)00037-X; Germain O, 2001, IEEE T IMAGE PROCESS, V10, P72, DOI 10.1109/83.892444; Goodman J. W., 1975, Laser speckle and related phenomena, P9; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LeToan T, 1997, IEEE T GEOSCI REMOTE, V35, P41, DOI 10.1109/36.551933; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mansouri AR, 2004, IEEE IMAGE PROC, P2721; MANSOURI AR, 2004, P REC FORM INT ART J; Moreels P, 2003, IEEE T IMAGE PROCESS, V12, P740, DOI 10.1109/TIP.2003.814254; Oliver CJ, 1995, P SOC PHOTO-OPT INS, V2584, P152, DOI 10.1117/12.227124; Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337; Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214; Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Sethian J. A., 1999, LEVEL SET METHODS FA; Smith DM, 1996, INT J REMOTE SENS, V17, P2043, DOI 10.1080/01431169608948758; TOUZI R, 1988, IEEE T GEOSCI REMOTE, V26, P764, DOI 10.1109/36.7708; Tupin F, 1998, IEEE T GEOSCI REMOTE, V36, P434, DOI 10.1109/36.662728; Vazquez C, 2004, IEEE IMAGE PROC, P3467; VAZQUEZ C, 2004, P REC FORM INT ART J; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WHITE RG, 1991, INT J REMOTE SENS, V12, P339, DOI 10.1080/01431169108929656; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	32	151	175	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					793	800		10.1109/TPAMI.2005.106	http://dx.doi.org/10.1109/TPAMI.2005.106			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875799				2022-12-18	WOS:000227569300011
J	Yang, MS; Wu, KL				Yang, MS; Wu, KL			A similarity-based robust clustering method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust clustering algorithm; fuzzy clustering; alternating optimization algorithm; total similarity; noise	COMPUTER VISION; FUZZY; ALGORITHMS; ESTIMATOR; VALIDITY	This paper presents an alternating optimization clustering procedure called a similarity-based clustering method (SCM). It is an effective and robust approach to clustering on the basis of a total similarity objective function related to the approximate density shape estimation. We show that the data points in SCM can self-organize local optimal cluster number and volumes without using cluster validity functions or a variance-covariance matrix. The proposed clustering method is also robust to noise and outliers based on the influence function and gross error sensitivity analysis. Therefore, SCM exhibits three robust clustering characteristics: 1) robust to the initialization (cluster number and initial guesses), 2) robust to cluster volumes (ability to detect different volumes of clusters), and 3) robust to noise and outliers. Several numerical data sets and actual data are used in the SCIVI to show these good aspects. The computational complexity of SCM is also analyzed. Some experimental results of comparing the proposed SCM with the existing methods show the superiority of the SCM method.	Chung Yuan Christian Univ, Dept Appl Math, Chungli 32023, Taiwan; Kun Shan Univ Technol, Dept Informat Management, Tainan 71023, Taiwan	Chung Yuan Christian University	Yang, MS (corresponding author), Chung Yuan Christian Univ, Dept Appl Math, Chungli 32023, Taiwan.	msyang@math.cycu.edu.tw; klwu@mail.ksut.edu.tw						Barni M, 1996, IEEE T FUZZY SYST, V4, P393, DOI 10.1109/91.531780; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Bezdek James C., 1974, J CYBERNETICS, V3, P58, DOI [DOI 10.1080/01969727308546047, 10.1080/01969727308546047]; Bickel P.J., 2001, MATH STAT; Chiu S.L., 1994, J INTELL FUZZY SYST, V2, P267, DOI DOI 10.3233/IFS-1994-2306; DAVE RN, 1991, PATTERN RECOGN LETT, V12, P657, DOI 10.1016/0167-8655(91)90002-4; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Duda R.O., 1973, J ROYAL STAT SOC SER; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GROSSBERG S, 1976, BIOL CYBERN, V23, P121, DOI 10.1007/BF00344744; Gustafson E. E., 1979, P IEEE CDC SAN DIEG, P761; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Huber P., 1981, ROBUST STAT; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; Kaufman L., 2009, FINDING GROUPS DATA; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387; KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P29, DOI 10.1109/91.366564; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; McLachlan, 1997, EM ALGORITHM EXTENSI; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; TSAO ECK, 1994, PATTERN RECOGN, V27, P757, DOI 10.1016/0031-3203(94)90052-3; Wu KL, 2002, PATTERN RECOGN, V35, P2267, DOI 10.1016/S0031-3203(01)00197-2; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; YANG MS, 1993, MATH COMPUT MODEL, V18, P1, DOI 10.1016/0895-7177(93)90202-A; ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1; ZHUANG XH, 1992, IEEE T PATTERN ANAL, V14, P19, DOI 10.1109/34.107011	33	151	170	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					434	448		10.1109/TPAMI.2004.1265860	http://dx.doi.org/10.1109/TPAMI.2004.1265860			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382649				2022-12-18	WOS:000220102800001
J	Worthington, PL; Hancock, ER				Worthington, PL; Hancock, ER			New constraints on data-closeness and needle map consistency for shape-from-shading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape-from-shading; hard constraints; curvature consistency; gradient consistency; robust statistics	SURFACE	This paper makes two contributions to the problem of needle-map recovery using shape-from-shading. First, we provide a geometric update procedure which allows the image irradiance equation to be satisfied as a hard constraint. This not only improves the data closeness of the recovered needle-map, but also removes the necessity for extensive parameter tuning. Second, we exploit the improved ease of control of the new shape-from-shading process to investigate various types of needle-map consistency constraint. The first set of constraints are based on needle-map smoothness. The second avenue of investigation is to use curvature information to impose topographic constraints. Third, we explore ways in which the needle-map is recovered so as to be consistent with the image gradient field. In each case we explore a variety of robust error measures and consistency weighting schemes that can be used to impose the desired constraints on the recovered needle-map. We provide an experimental assessment of the new shape-from-shading framework on both real world images and synthetic images with known ground truth surface normals. The main conclusion drawn from our analysis is that the data-closeness constraint improves the efficiency of shape-from-shading and that both the topographic and gradient consistency constraints improve the fidelity of the recovered needle-map.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England	University of York - UK	Worthington, PL (corresponding author), Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England.	plw@cs.york.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin R/C-6071-2008; Hancock, Edwin/N-7548-2019	Hancock, Edwin R/0000-0003-4496-2028; Hancock, Edwin/0000-0003-4496-2028				ANGELOPOULOU E, 1999, P IEEE WORKSH PHOT M; Belhumeur PN, 1996, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.1996.517085; Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150; BROOKS MJ, 1985, P INT JOINT C ART IN, P932; BRUCKSTEIN AM, 1988, COMPUT VISION GRAPH, V44, P139, DOI 10.1016/S0734-189X(88)80002-1; FERRIE FP, 1990, P IEEE INT C PATT RE, V1, P70; HILBERT D, 1953, METHODS MATH; Hoaglin D.C., 1983, UNDERSTANDING ROBUST; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; Huber P., 1981, ROBUST STAT; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; Koenderink JJ, 1996, PERCEPTION, V25, P1009, DOI 10.1068/p251009; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; KOENDERINK JJ, 1995, IMAGE VISION COMPUT, V13, P321, DOI 10.1016/0262-8856(95)99719-H; LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247; LI SZ, 1995, IMAGE VISION COMPUT, V13, P227, DOI 10.1016/0262-8856(95)90842-V; Marr D., 1982, VISION; Oliensis J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P692, DOI 10.1109/ICCV.1993.378145; Oliensis J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P559, DOI 10.1109/CVPR.1991.139753; PARENT P, 1985, J OPT SOC AM A, V2, P5; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Sethian J., 1996, LEVEL SET METHODS; SZELISKI R, 1991, CVGIP-IMAG UNDERSTAN, V53, P129, DOI 10.1016/1049-9660(91)90023-I; TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7; Worthington P. L., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P911, DOI 10.1109/ICCV.1999.790319; Worthington PL, 1999, IMAGE VISION COMPUT, V17, P545, DOI 10.1016/S0262-8856(98)00173-5; WORTHINGTON PL, 1999, P IEEE C COMP VIS PA, V1, P287; WORTHINGTON PL, 1997, P IEEE INT C DIG SIG; WORTHINGTON PL, 1997, P BRIT MACH VIS C, V1, P31; ZHANG R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P377, DOI 10.1109/CVPR.1994.323854; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	37	151	156	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1250	1267		10.1109/34.817406	http://dx.doi.org/10.1109/34.817406			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG		Green Accepted, Green Submitted			2022-12-18	WOS:000084828100001
J	Lopez, AM; Lumbreras, F; Serrat, J; Villanueva, JJ				Lopez, AM; Lumbreras, F; Serrat, J; Villanueva, JJ			Evaluation of methods for ridge and valley detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						creases; separatrices; drainage patterns; comparative analysis	IMAGES; SCALE; SEGMENTATION	Ridges and valleys are useful geometric features for image analysis. Different characterizations have been proposed to formalize the intuitive notion of ridge/valley. In this paper, we review their principal characterizations and propose a new one. Subsequently, we evaluate these characterizations with respect to a list of desirable properties and their purpose in the context of representative image analysis tasks.	Univ Autonoma Barcelona, Comp Vis Ctr, Cardanyola 08193, Spain; Univ Autonoma Barcelona, Dept Comp Sci, Cardanyola 08193, Spain	Autonomous University of Barcelona; Centre de Visio per Computador (CVC); Autonomous University of Barcelona	Lopez, AM (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Edifici O, Cardanyola 08193, Spain.	antonio@cvc.uab.es; felipe@cvc.uab.es; joans@cvc.uab.es; villanueva@cvc.uab.es	Lumbreras, Felipe/L-9387-2014; López, Antonio M/L-5303-2014; Serrat, Joan/L-4735-2014	Lumbreras, Felipe/0000-0003-2887-8053; López, Antonio M/0000-0002-6979-5783; Serrat, Joan/0000-0002-4554-199X				Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; CAYLEY A, 1859, PHILOS MAG, V18, P264; de Saint-Venant M., 1852, B SOC PHILOMATHEMATI, P24; Desmet PJJ, 1996, INT J GEOGR INF SYST, V10, P311, DOI 10.1080/026937996138061; Eberly D., 1994, Journal of Mathematical Imaging and Vision, V4, P353, DOI 10.1007/BF01262402; GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P635, DOI 10.1109/34.216734; GRIFFIN LD, 1992, IMAGE VISION COMPUT, V10, P389, DOI 10.1016/0262-8856(92)90025-X; GRIFFIN LD, 1995, IMAGE VISION COMPUT, V13, P543, DOI 10.1016/0262-8856(95)91145-4; HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P28, DOI 10.1016/0734-189X(83)90094-4; JAHNE B, 1993, LECT NOTES COMPUTER, V751, P143; JORDAN C, 1872, CR HEBD ACAD SCI, V75, P1023; KOENDERINK JJ, 1993, GEOMETRIC METHODS CO, V2031, P2; LLORET D, 1998, NOBL WORKSH NONL MOD, P15; LOPEZ A, 1998, LECT NOTES COMPUTER, V1407, P156; LOPEZ A, 1997, 26 U AUT BARC CTR VI; Lumbreras F, 1996, OPT ENG, V35, P2864, DOI 10.1117/1.600972; Maintz JBA, 1996, IEEE T PATTERN ANAL, V18, P353, DOI 10.1109/34.491617; Maxwell JC., 1870, LONDON EDINBURGH DUB, V40, P421, DOI [10.1080/14786447008640422, DOI 10.1080/14786447008640422]; NACKMAN LR, 1984, IEEE T PATTERN ANAL, V6, P442, DOI 10.1109/TPAMI.1984.4767549; NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0; OCALLAGHAN JF, 1984, COMPUT VISION GRAPH, V28, P323, DOI [10.1016/S0734-189X(84)80011-0, 10.1016/0734-189X(89)90053-4]; Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563; Rieger JH, 1997, INT J COMPUT VISION, V23, P79, DOI 10.1023/A:1007915908780; ROSIN PL, 1995, J VIS COMMUN IMAGE R, V6, P228, DOI 10.1006/jvci.1995.1020; Rothe R., 1915, SITZUNGSBERICHTE BER, V14, P51; Soille P., 1994, Journal of Visual Communication and Image Representation, V5, P181, DOI 10.1006/jvci.1994.1017; Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930; THIRION JP, 1995, COMPUT VIS IMAGE UND, V61, P190, DOI 10.1006/cviu.1995.1015; VANDENELSEN PA, 1995, IEEE T MED IMAGING, V14, P384, DOI 10.1109/42.387719; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344	30	151	155	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					327	335		10.1109/34.761263	http://dx.doi.org/10.1109/34.761263			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL					2022-12-18	WOS:000079781200004
J	Barzohar, M; Cooper, DB				Barzohar, M; Cooper, DB			Automatic finding of main roads in aerial images by using geometric-stochastic models and estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric-probabilistic models; Gibbs distributions; maximum a posteriori probability estimation; road geometry model; Gaussian driving noise; dynamic programming; model-based segmentation		This paper presents an automated approach to finding main roads in aerial images. The approach is to build geometric-probabilistic models for road image generation. We use Gibbs Distributions. Then, given an image, roads are found by map (maximum a posteriori probability) estimation. The map estimation is handled by partitioning an image into windows, realizing the estimation in each window through the use of dynamic programming, and then, starting with the windows containing high confidence estimates, using dynamic programming again to obtain optimal global estimates of the roads present. The approach is model-based from the outset and is completely different than those appearing in the published literature. It produces two boundaries for each road, or four boundaries when a mid-road barrier is present.	BROWN UNIV,DIV ENGN,PROVIDENCE,RI 02912	Brown University	Barzohar, M (corresponding author), RAFAEL,COMP VIS GRP,DEPT 39,POB 31021,IL-31021 HAIFA,ISRAEL.							AVIAD Z, 1988, CMUCS88157; BARZOHAR M, 1993, IEEE CVPR        JUL; BARZOHAR M, 1993, BROWNLEMS118; Boggess J.E., 1993, IDENTIFICATION ROADS; COOPER D, 1979, IEEE T PATTERN ANAL; COOPER DB, 1983, IEEE T PATTERN ANAL; Duda R.O., 1973, J ROYAL STAT SOC SER; FISCHLER JM, 1981, CGIP, P201; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; GEMAN D, 1994, ACTIVE TESTING MODEL; GRAFFINE C, 1989, MODELISATION RESEAUX; KESTNER W, 1978, RES I INFORMATION PR; MCKEOWN DM, 1988, CVPR; NEVATIA R, 1980, IEEE CGIP, P257; QUAM L, 1978, P DARP IM UND WORKSH, P51	15	151	190	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					707	721		10.1109/34.506793	http://dx.doi.org/10.1109/34.506793			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700003
J	SMITH, SM; BRADY, JM				SMITH, SM; BRADY, JM			ASSET-2 - REAL-TIME MOTION SEGMENTATION AND SHAPE TRACKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MOTION SEGMENTATION; OPTIC FLOW; MOVING OBJECT TRACKING		This paper describes a system for detecting and tracking moving objects in a moving world. The feature-based optic flow field is segmented into clusters with affine internal motion which are tracked over time. The system runs in real-time, and is accurate and reliable.	DEPT ENGN SCI,ROBOT RES GRP,OXFORD,ENGLAND	University of Oxford	SMITH, SM (corresponding author), DEF RES AGCY,LSFI,DRA CHERTSEY,CHOBHAM LANE,CHERTSEY,SURREY,ENGLAND.			Smith, Stephen/0000-0001-8166-069X				BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; Brady M., 1987, P ALVEY VISION C, P259; Duda R.O., 1973, J ROYAL STAT SOC SER; HARRIS C, 1988, 4 ALV VIS C, P147; IRANI M, 1992, 2ND P EUR C COMP VIS, P282; KASS M, 1987, 1ST P INT C COMP VIS, P259; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042; SMITH SM, 1994, ENG APPL ARTIF INTEL, V7, P191, DOI 10.1016/0952-1976(94)90023-X; SMITH SM, 1992, 3RD P BRIT MACH VIS; SMITH SM, 1992, THESIS OXFORD U	10	151	187	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					814	820		10.1109/34.400573	http://dx.doi.org/10.1109/34.400573			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035					2022-12-18	WOS:A1995RL03500009
J	VUYLSTEKE, P; OOSTERLINCK, A				VUYLSTEKE, P; OOSTERLINCK, A			RANGE IMAGE ACQUISITION WITH A SINGLE BINARY-ENCODED LIGHT PATTERN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CATHOLIC UNIV LEUVEN,FAC ENGN,ELECTR SYST AUTOMAT & TECHNOL LAB,B-3000 LOUVAIN,BELGIUM	KU Leuven								AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; ALTSCHULER MD, 1979, P SOC PHOTO-OPT INS, V182, P187; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; BERLEKAMP ER, 1968, ALGEBRAIC CODING THE; BICKEL G, 1985, OPT ENG, V24, P975, DOI 10.1117/12.7973610; BOLLES RC, 1981, SRI249 TECH NOT; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; CARRIHILL B, 1985, COMPUT VISION GRAPH, V32, P337, DOI 10.1016/0734-189X(85)90056-8; GOLOMB SW, 1967, SHIFT REGISTER SEQUE; HARDING KG, 1986, P SOC PHOTOOPT INSTR, V728, P132; HAUGEN PR, 1984, P SOC PHOTO-OPT INS, V521, P258; Idesawa M., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P902; Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806; Kiessling A., 1976, 3rd International Joint Conference on Pattern Recognition, P586; LABUZ J, 1986, P SOC PHOTOOPT INSTR, V728, P227; MACWILLIAMS FJ, 1976, P IEEE, V64, P1715, DOI 10.1109/PROC.1976.10411; MACWILLIAMS FJ, 1978, THEORY ERROR CORRECT, pCH14; Minou M., 1981, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE64, P521; MORGAN CG, 1983, P SPIE INT SOC OPT E, V449, P390; OOMEN GL, 1983, P SPIE INT SOC OPT E, V449, P62; PETERSON WW, 1972, ERROR CORRECTING COD, P124; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; RIOUX M, 1986, J OPT SOC AM A, V3, P1518, DOI 10.1364/JOSAA.3.001518; ROCKER F, 1975, 4TH P INT JOINT C AR, P669; ROGERS DF, 1976, MATH ELEMENTS COMPUT, P81; Sato K., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1168; SATO Y, 1982, IEEE T PATTERN ANAL, V4, P641, DOI 10.1109/TPAMI.1982.4767318; STOCKMAN G, 1986, JUN P IEEE C COMP VI, P602; TAJIMA J, 1987, FEB P IEEE WORKSH IN, P381; TIO JBK, 1982, JUN C PATT REC IM P, P370; VANRANST P, 1987, THESIS KATHOLIEKE U; VUYLSTEKE P, 1987, THESIS KATHOLIEKE U	32	151	178	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					148	164		10.1109/34.44402	http://dx.doi.org/10.1109/34.44402			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282					2022-12-18	WOS:A1990CL28200004
J	MICHALSKI, RS				MICHALSKI, RS			PATTERN-RECOGNITION AS RULE-GUIDED INDUCTIVE INFERENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MICHALSKI, RS (corresponding author), UNIV ILLINOIS,DEPT COMP SCI,URBANA,IL 61801, USA.							BANERJI RB, 1977, LEARNING STRUCTURAL; BANERJI RB, 1960, INFORMATION PROCESSI, V5; BRAYER JM, 1975, TREE751 PURD U SCH E; BUCHANAN BG, 1977, STANCS77597 STANF U; COHEN BL, 1977, ARTIFICIAL INTELL, V9; COULON D, 1978, PATTERN RECOGN, V10, P19, DOI 10.1016/0031-3203(78)90044-4; DIETTERICH T, 1978, INDUCE 1 1 PROGRAM D; FELDMAN JA, 1969, CS125 STANF U DEP CO; FIKES R, 1972, ARTIFICIAL INTELL, V3; GAINES BR, 1976, INT J MAN MACH STUD, V8, P337, DOI 10.1016/S0020-7373(76)80005-3; HAYESROTH, 1978, COMMUN ASS COMPUT MA, V21, P401; HEDRICK CL, 1974, THESIS CARNEGIE MELL; JOUANNAUD TP, 1977, 5TH P INT J C ART IN, V1, P412; LARSON J, 1977, UIUCDCSR77876 U ILL; LARSON J, 1977, MAY P WORKSH PATT DI; LARSON J, 1977, SIGART NEWSLETTE JUN; LARSON J, 1976, 6TH P ANN INT S MULT; LARSON JB, 1977, THESIS U ILLINOIS UR; Lenat D. B., 1976, STANCS76570 STANF U; MICHALSKI RS, 1972, GRAPHIC LANGUAGES; MICHALSKI RS, 1980, INT J MAN MACHINE ST; MICHALSKI RS, 1973, 1ST P INT JOINT C PA; MICHALSKI RS, 1977, 5TH INT JOINT C ART; MORGAN CG, 1975, 4TH INT JOINT C ART, V1, P351; Plotkin G. D, 1971, MACHINE INTELLIGENCE, V6; SHAW DE, 1975, 4TH P INT JOINT C AR, P351; SIMON HA, 1972, PSYCHOL REV, V79, P369, DOI 10.1037/h0033118; SOLOWAY EM, 1977, 5TH P INT JOINT C AR; STOFFEL JC, 1974, INFORMATION PROCESSI, P702; VERE S, 1975, 4TH P INT JOINT C AR, P351; WATERMAN DA, 1974, 285 CARN MELL U DEP; WINSTON PH, 1970, AITR231 MIT AI LAB T; YAU KC, 1978, 8TH P ANN EIA S AUT; ZAGORUIKO NG, 1979, EMPIRICHESKOIE PREDS	34	151	152	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					349	361		10.1109/TPAMI.1980.4767034	http://dx.doi.org/10.1109/TPAMI.1980.4767034			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JZ206	21868911				2022-12-18	WOS:A1980JZ20600008
J	de La Gorce, M; Fleet, DJ; Paragios, N				de La Gorce, Martin; Fleet, David J.; Paragios, Nikos			Model-Based 3D Hand Pose Estimation from Monocular Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hand tracking; model based shape from shading; generative modeling; pose estimation; variational formulation; gradient descent		A novel model-based approach to 3D hand tracking from monocular video is presented. The 3D hand pose, the hand texture, and the illuminant are dynamically estimated through minimization of an objective function. Derived from an inverse problem formulation, the objective function enables explicit use of temporal texture continuity and shading information while handling important self-occlusions and time-varying illumination. The minimization is done efficiently using a quasi-Newton method, for which we provide a rigorous derivation of the objective function gradient. Particular attention is given to terms related to the change of visibility near self-occlusion boundaries that are neglected in existing formulations. To this end, we introduce new occlusion forces and show that using all gradient terms greatly improves the performance of the method. Qualitative and quantitative experimental results demonstrate the potential of the approach.	[de La Gorce, Martin] Image Metr, Manchester M1 3BE, Lancs, England; [Fleet, David J.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3H5, Canada; [Paragios, Nikos] Ecole Cent Paris, Med Imaging & Comp Vis Grp, Dept Appl Math, Chatenay Malabry, France	University of Toronto; UDICE-French Research Universities; Universite Paris Saclay	de La Gorce, M (corresponding author), Image Metr, 1 Portland St, Manchester M1 3BE, Lancs, England.	martin.delagorce@gmail.com; fleet@cs.toronto.edu; nikos.paragios@ecp.fr		/0000-0003-0734-7114	NSERC Canada; Canadian Institute for Advanced Research (CIfAR)	NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institute for Advanced Research (CIfAR)(Canadian Institute for Advanced Research (CIFAR))	This work was financially supported by grants to David J. Fleet from NSERC Canada and the Canadian Institute for Advanced Research (CIfAR). Martin de La Gorce was with the Ecole Centrale de Paris during the time in which this work was performed.	[Anonymous], 2006, PROC IEEE COMPUT SOC; Athitsos V, 2003, PROC CVPR IEEE, P432; Balan AO, 2007, IEEE I CONF COMP VIS, P1379; BLANZ V, 1999, P 26 ANN C COMP GRAP, P187, DOI DOI 10.1145/311535.311556; Bray M., 2004, 1 EUR C VIS MED PROD, P59; BRUBAKER M, 2009, HDB AMBIENT INTELLIG; Carpenter L., 1984, Computers & Graphics, V18, P103; Conn A.R., 2000, TRUST REGION METHODS, DOI [10.1137/1.9780898719857, DOI 10.1137/1.9780898719857]; Crow F. C., 1981, IEEE Computer Graphics and Applications, V1, P40, DOI 10.1109/MCG.1981.1673810; de La Gorce M, 2010, COMPUT VIS IMAGE UND, V114, P363, DOI 10.1016/j.cviu.2009.09.004; DELAUNOY A, 2008, P BRIT MACH VIS C; Gargallo P, 2007, IEEE I CONF COMP VIS, P1364; Griewank A., 2000, EVALUATING DERIVATIV; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heap T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P140, DOI 10.1109/AFGR.1996.557255; HERNANDEZ C., 2004, THESIS ECOLE NATL SU; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862; Lu S, 2003, PROC CVPR IEEE, P443; Magnenat-Thalmann N., 1988, P GRAPHICS INTERFACE; OUHADDI H, 1999, P INT WORKSH SYNTH N, P70; PARAGIOS N, 1999, P IEEE INT C COMP VI, V2, P926; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; SANDER PV, 2001, P S INT 3D GRAPH, P167, DOI DOI 10.1145/364338.364390; Shimada N, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P23, DOI 10.1109/RATFG.2001.938906; Sidenbladh H., 2000, LNCS, V2, P702; Soucy M, 1996, VISUAL COMPUT, V12, P503, DOI 10.1007/s003710050082; Stenger B., 2001, P BRIT MACH VIS C MA, VI, P63, DOI DOI 10.5244/C.15.8; Stenger B.D.R., 2004, THESIS U CAMBRIDGE; Sudderth E., 2004, P IEEE C COMP VIS PA, P189; Unal G, 2005, INT J COMPUT VISION, V62, P199, DOI 10.1007/s11263-005-4880-6; Wang CH, 2009, IEEE I CONF COMP VIS, P747; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P426, DOI 10.1109/ICCV.2001.937656	34	150	159	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1793	1805		10.1109/TPAMI.2011.33	http://dx.doi.org/10.1109/TPAMI.2011.33			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21339527	Green Submitted			2022-12-18	WOS:000292740000007
J	Ghosh, D; Dube, T; Shivaprasad, AP				Ghosh, Debashis; Dube, Tulika; Shivaprasad, Adamane P.			Script Recognition-A Review	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Document analysis; optical character recognition; script identification; multiscript document	CHARACTER-RECOGNITION; IDENTIFICATION; TEXTURE; CLASSIFICATION; LANGUAGE; FEATURES	A variety of different scripts are used in writing languages throughout the world. In a multiscript, multilingual environment, it is essential to know the script used in writing a document before an appropriate character recognition and document analysis algorithm can be chosen. In view of this, several methods for automatic script identification have been developed so far. They mainly belong to two broad categories-structure-based and visual-appearance-based techniques. This survey report gives an overview of the different script identification methodologies under each of these categories. Methods for script identification in online data and video-texts are also presented. It is noted that the research in this field is relatively thin and still more research is to be done, particularly in the case of handwritten documents.	[Ghosh, Debashis] Indian Inst Technol, Dept Elect & Comp Engn, Roorkee 247667, Uttarakhand, India; [Dube, Tulika] Indian Inst Management, Ahmadabad 380015, Gujarat, India; [Shivaprasad, Adamane P.] Sambhram Inst Technol, Dept Elect & Commun Engn, Bangalore 560054, Karnataka, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Roorkee; Indian Institute of Management (IIM System); Indian Institute of Management Ahmedabad	Ghosh, D (corresponding author), Indian Inst Technol, Dept Elect & Comp Engn, Roorkee 247667, Uttarakhand, India.	ghoshfec@iitr.ernet.in; 9tulikad@iimahd.ernet.in; apshivaprasad@yahoo.com						Ablavsky V, 2003, PROC INT CONF DOC, P750; Bunke H., 1997, HDB CHARACTER RECOGN; Busch A, 2005, IEEE T PATTERN ANAL, V27, P1720, DOI 10.1109/TPAMI.2005.227; BUSCH A, 2006, P ICIAR, P844; Chan W, 2001, PATTERN RECOGN, V34, P2523, DOI 10.1016/S0031-3203(00)00155-2; Chanda S., 2005, P INT C DOC AN REC, P538; Chanda S., 2004, SPEECH LANGUAGE SYST, P244; Chanda S., 2006, P NAT C REC TRENDS I, P184; CHAUDHURI BB, 1999, P INT WORKSH PERF EV; Chaudhury S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P657, DOI 10.1109/ICDAR.1999.791873; CHENG J, 2006, P INT C INN COMP INF, V3, P178; Chi Z, 2003, PATTERN RECOGN, V36, P2483, DOI 10.1016/S0031-3203(03)00128-6; Coulmas F., 1996, BLACKWELL ENCY WRITI; CUMBEE CS, 2006, Patent No. 7020338; DHANDRA BV, 2006, P IEEE INT C PATT RE, V2, P950; Dhanya D, 2002, LECT NOTES COMPUT SC, V2423, P13; Dhanya D, 2002, SADHANA-ACAD P ENG S, V27, P73, DOI 10.1007/BF02703313; Elgammal A. M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1100, DOI 10.1109/ICDAR.2001.953956; Ghosh D, 1999, PATTERN RECOGN, V32, P907, DOI 10.1016/S0031-3203(98)00114-9; Ghosh D., 2000, J INDIAN I SCI, V80, P215; Gllavata J, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY (ISSPIT), VOLS 1 AND 2, P589; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hochberg J., 1999, International Journal on Document Analysis and Recognition, V2, P45, DOI 10.1007/s100320050036; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; HOCHBERG J, 1997, P S DOC IM UND TECHN, P258; Jaeger S, 2005, PROC INT CONF DOC, P416, DOI 10.1109/ICDAR.2005.134; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; Jawahar CV, 2003, PROC INT CONF DOC, P408; JOSHI GD, 2006, P IAPR INT WORKSH DO, P255; Kanoun S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P309, DOI 10.1109/IWFHR.2002.1030928; Kanungo T, 2005, COMMUN ACM, V48, P124, DOI 10.1145/1064830.1064837; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387; KUMAR R, 2003, P INT C ADV PATT REC, P289; Lam L, 1998, INT J PATTERN RECOGN, V12, P63, DOI 10.1142/S0218001498000063; LEE CA, 1995, HAEMOPHILIA, V1, P28, DOI 10.1111/j.1365-2516.1995.tb00100.x; Lee D. S., 1996, P IAPR WORKSH DOC AN, P76; Lee JJ, 1998, IEICE T INF SYST, VE81D, P881; LEE JJ, 1993, P KISS ANN C OCT, V20, P317; Liu YH, 2005, PROC INT CONF DOC, P630; LU S, 2006, P 6 IAPR WORKSH DOC, P232; Ma HF, 2003, PROC INT CONF DOC, P968; Malaviya A, 2000, PATTERN RECOGN, V33, P119, DOI 10.1016/S0031-3203(99)00034-5; MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3; MOALLA I, 2004, P C ART INT SOFT COM; MOALLA I, 2002, P IEEE INT C SYST MA; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; MUIR DW, 2000, Patent No. 6064767; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; Nakanishi A., 1980, WRITING SYSTEMS WORL; Namboodiri AM, 2004, IEEE T PATTERN ANAL, V26, P124, DOI 10.1109/TPAMI.2004.1261096; Namboodiri AM, 2002, INT C PATT RECOG, P736, DOI 10.1109/ICPR.2002.1048081; O'Gorman L., 1995, DOCUMENT IMAGE ANAL; PADMA MC, 2003, P 2 NAT C DOC AN REC, P252; Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003; Pal U, 2003, PROC INT CONF DOC, P880; Pal U, 2002, IMAGE VISION COMPUT, V20, P945, DOI 10.1016/S0262-8856(02)00101-4; Pal U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P406, DOI 10.1109/ICDAR.1999.791810; PAL U, 2006, J VIVEK, V16, P26; Pan WM, 2005, PROC INT CONF DOC, P883, DOI 10.1109/ICDAR.2005.206; Pati PB, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P123; PATI PB, 2006, P INT WORKSH DOC AN, P380; Patil SB, 2002, SADHANA-ACAD P ENG S, V27, P83, DOI 10.1007/BF02703314; PEAKE GS, 1998, P AS C COMP VIS JAN, P97; Peng LG, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P126; Ronse C, 1984, CONNECTED COMPONENTS; Roy K, 2005, 2005 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, PROCEEDINGS, P240, DOI 10.1109/ICISIP.2005.1529455; Roy K, 2005, PROC INT CONF DOC, P1060, DOI 10.1109/ICDAR.2005.259; ROY K, 2004, P NAT WORKSH COMP VI, P5; ROY K, 2006, PIN CODE EXTRACTION, P192; Roy K, 2006, 10 INT WORKSH FRONT, P521; Singhal V, 2003, PR GR LAK SYMP VLSI, P47, DOI 10.1109/RIDE.2003.1249845; SINHA S, 2004, P IAPR INT WORKSH DO, P310; Spitz A. L., 1994, P 3 ANN S DOC AN INF, P229; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; SPITZ AL, 1994, P IAPR WORKSH DOC AN, P16; SPITZ AL, 1990, P INT C EL PUBL DOC, P193; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; TAN CL, 1999, P INT S INT MULT DIS, P59; Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305; Tao Y, 2001, PROC INT CONF DOC, P1115, DOI 10.1109/ICDAR.2001.953959; Waked B, 1998, IEEE SYS MAN CYBERN, P4470, DOI 10.1109/ICSMC.1998.727554; Wood SL, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC428; Zhou LJ, 2006, LECT NOTES COMPUT SC, V3872, P243	84	150	159	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2142	2161		10.1109/TPAMI.2010.30	http://dx.doi.org/10.1109/TPAMI.2010.30			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20975114				2022-12-18	WOS:000283558700003
J	Liu, YX; Collins, RT; Tsin, YH				Liu, YX; Collins, RT; Tsin, YH			A computational model for periodic pattern perception based on frieze and wallpaper groups	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						periodic pattern; frieze group; wallpaper group; symmetry group; lattice; tiles; motifs; gait analysis	SYMMETRY; FEATURES	We present a computational model for periodic pattern perception based on the mathematical theory of crystallographic groups. In each N-dimensional Euclidean space, a finite number of symmetry groups can characterize the structures of an infinite variety of periodic patterns. In 2D space, there are seven frieze groups describing monochrome patterns that repeat along one direction and 17 wallpaper groups for patterns that repeat along two linearly independent directions to tile the plane. We develop a set of computer algorithms that "understand" a given periodic pattern by automatically finding its underlying lattice, identifying its symmetry group, and extracting its representative motifs. We also extend this computational model for near-periodic patterns using geometric AIC. Applications of such a computational model include pattern indexing, texture synthesis, image compression, and gait analysis.	Carnegie Mellon Univ, Sch Comp Sci, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Liu, YX (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	yanxi@cs.cmu.edu; rcollins@cs.cmu.edu; tsin@cs.cmu.edu						CONNERS RW, 1980, COMPUT VISION GRAPH, V12, P224, DOI 10.1016/0146-664X(80)90013-1; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; EFROS AA, 2001, P SIGGRAPH, P35; ENRICH R, 1978, P C COMP GRAPH IM PR, V8, P174; GALLIAN JA, 1986, CONT ABSTR ALG; Gr?nbaum B., 1987, TILINGS PATTERNS; GROSS AD, 1994, INT J COMPUT VISION, V13, P91, DOI 10.1007/BF01420797; Gross R, 2001, CMURITR0118; HAMEY LGC, 1989, P IM UND WORKSH, P1076; Henry N. F., 1969, INT TABLES XRAY CRYS, VI; Jones Owen, 1856, GRAMMAR ORNAMENT; KAHN JI, 1986, J EXP PSYCHOL HUMAN, V12, P422; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANADE T, 1987, READINGS COMPUTER VI, P257; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P246, DOI 10.1109/34.584101; Kanatani K., 1996, STAT OPTIMIZATION GE, V18; Kazhdan M, 2002, LECT NOTES COMPUT SC, V2351, P642; Leung T., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P546, DOI 10.1007/BFb0015565; Leyton M., 1992, SYMMETRY CAUSALITY M; Lin HC, 1997, PATTERN RECOGN LETT, V18, P433, DOI 10.1016/S0167-8655(97)00030-5; Liu J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P123, DOI 10.1109/CVPR.1993.341000; Liu Y., 1998, CMURITR9837; LIU Y, 2002, P 7 EUR C COMP VIS; LIU Y, 2003, P 3 INT WORKSH TEXT; LIU Y, 2003, IN PRESS INT J COMPU; Liu YX, 2001, PROC CVPR IEEE, P872; LIU YX, 1994, INT J ROBOT RES, V13, P148, DOI 10.1177/027836499401300205; Liu YX, 2000, PROC CVPR IEEE, P537, DOI 10.1109/CVPR.2000.855866; Loy G, 2002, LECT NOTES COMPUT SC, V2350, P358; LU SY, 1978, COMPUT VISION GRAPH, V7, P303, DOI 10.1016/S0146-664X(78)80001-X; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; Miller W., 1972, SYMMETRY GROUPS THEI; PEI SC, 1994, PATTERN RECOGN, V27, P1193, DOI 10.1016/0031-3203(94)90005-1; RAO AR, 1993, CVGIP-GRAPH MODEL IM, V55, P218, DOI 10.1006/cgip.1993.1016; Russ J. C., 2016, IMAGE PROCESSING HDB; SCHAFFALITZKY F, 1999, SHAPE CONTOUR GROUPI; SCHATTSCHNEIDER D, 1978, AM MATH MON, V85, P439, DOI 10.2307/2320063; SCHATTSCHNEIDER D, 1999, COMMUNICATION; Schwarzenberger R.L.E., 1974, MATH GAZ, V58, P123, DOI DOI 10.2307/3617798; Selkainaho K., 1988, P 9 INT C PATT REC R, P1221; Shubnikov A., 1974, SYMMETRY SCI ART; Starovoitov VV, 1998, IEEE T SYST MAN CY A, V28, P839, DOI 10.1109/3468.725354; STEVENS P, 1987, HDB REGULAR PATTERNS; Sun CM, 1997, OPT ENG, V36, P1073, DOI 10.1117/1.601290; Tuytelaars T, 2003, IEEE T PATTERN ANAL, V25, P418, DOI 10.1109/TPAMI.2003.1190569; VanGool L, 1996, PROC CVPR IEEE, P285, DOI 10.1109/CVPR.1996.517087; Washburn D, 1999, AM ANTHROPOL, V101, P547, DOI 10.1525/aa.1999.101.3.547; Washburn D.K., 1991, SYMMETRIES CULTURE T; Weeks J., 1995, PROGRAMS CAN AUTOMAT; YIP RKK, 1994, PATTERN RECOGN LETT, V15, P919, DOI 10.1016/0167-8655(94)90154-6; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZUCKER SW, 1980, COMPUT VISION GRAPH, V12, P286, DOI 10.1016/0146-664X(80)90016-7; [No title captured]	53	150	165	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					354	371		10.1109/TPAMI.2004.1262332	http://dx.doi.org/10.1109/TPAMI.2004.1262332			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376882	Green Submitted			2022-12-18	WOS:000188949400006
J	Denzler, J; Brown, CM				Denzler, J; Brown, CM			Information theoretic sensor data selection for active object recognition and, state estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; active camera control; state estimation; information theory		We introduce a formalism for optimal sensor parameter selection for iterative state estimation in static systems. Our optimality criterion is the reduction of uncertainty in the state estimation process, rather than an estimator-specific metric (e.g., minimum mean squared estimate error). The claim is that state estimation becomes more reliable if the uncertainty and ambiguity in the estimation process can be reduced. We use Shannon's information theory to select information-gathering actions that maximize mutual information, thus optimizing the information that the data conveys about the true state of the system. The technique explicitly takes into account the a priori probabilities governing the computation of the mutual information. Thus, a sequential decision process can be formed by treating the a priori probability at a certain time step in the decision process as the a posteriori probability of the previous time step. We demonstrate the benefits of our approach in an object recognition application using an active camera for sequential gaze control and viewpoint selection. We describe experiments with discrete and continuous density representations that suggest the effectiveness of the approach.	Univ Erlangen Nurnberg, Lehrstuhl Mustererkennung, D-91058 Erlangen, Germany; Univ Rochester, Comp Sci Dept, Rochester, NY 14627 USA	University of Erlangen Nuremberg; University of Rochester	Denzler, J (corresponding author), Univ Erlangen Nurnberg, Lehrstuhl Mustererkennung, Martensstr 3, D-91058 Erlangen, Germany.	denzler@informatik.uni-erlangen.de; brown@cs.rochester.edu						ARBEL T, 1999, P 7 INT C COMP VIS; Borotschnig H, 2000, IMAGE VISION COMPUT, V18, P715, DOI 10.1016/S0262-8856(99)00075-X; BOROTSCHNIG H, 1998, P 9 BRIT MACH VIS C, V2, P629; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DEINZER F, 2000, P IEEE SW S IM AN IN, P209; DENZLER J, 2000, TR7322 U ROCH COMP S; FISHER J, 1997, P DEF ADV RES PROJ A; FOX D, 1998, ACTIVE MARKOV LOCALI; Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549; Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; MANYIKA JM, 1992, PROCEEDINGS OF THE 31ST IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-4, P3506, DOI 10.1109/CDC.1992.371006; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NIEMANN H, 1990, PATTERN ANAL UNDERST, V4; NOONAN CA, 1996, P IEE C TARG TRACK D; Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2; Paletta L, 2000, INT C PATT RECOG, P695, DOI 10.1109/ICPR.2000.905482; SCHIELE B, 1998, P 6 INT C COMP VIS; Sutton Richard S, 1998, INTRO REINFORCEMENT, V2; Tanner M. A, 1993, TOOLS STAT INFERENCE; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; VIOLA PA, 1995, 1548 MIT ART INT LAB; WILKES D, 1994, RBCVTR9445 U TOR DEP; YE Y, 1997, THESIS U TORONTO	26	150	157	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					145	157		10.1109/34.982896	http://dx.doi.org/10.1109/34.982896			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC					2022-12-18	WOS:000173535700001
J	Kadyrov, A; Petrou, M				Kadyrov, A; Petrou, M			The trace transform and its applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						radon transform; trace transform; invariant features; image database search; change detection	REGISTRATION; RETRIEVAL; IMAGE	The Trace transform proposed, a generalization of the Radon transform, consists of tracing an image with straight lines along which certain functionals of the image function are calculated. Different functionals that can be used may be invariant to different transformations of the image. The paper presents the properties the functionals must have in order to be useful in three different applications of the method: construction of invariant features to rotation, translation and scaling of the image, construction of sensitive features to the parameters of rotation, translation and scaling of the image, and construction of features that may correlate well with a certain phenomenon we wish to monitor.	Univ Surrey, Sch Elect Comp & Math, Guildford GU2 7XH, Surrey, England	University of Surrey	Kadyrov, A (corresponding author), Univ Surrey, Sch Elect Comp & Math, Guildford GU2 7XH, Surrey, England.							Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147; Abbasi S, 2000, IMAGE VISION COMPUT, V18, P199, DOI 10.1016/S0262-8856(99)00019-0; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; Costa CE, 2000, MACH VISION APPL, V11, P225, DOI 10.1007/s001380050105; Deans S., 1983, RADON TRANSFORM SOME; DEANS SR, 1981, IEEE T PATTERN ANAL, V3, P185, DOI 10.1109/TPAMI.1981.4767076; FEDOTOV NG, 1990, MOSCOW RADIO COMM; KUGLIN CD, 1979, SPIE DIGITAL PROCESS, V186, P21; NOVIKOFF ABJ, 1961, T U ILL S SELF ORG, P347; PETROU M, 1998, STAT ANAL BINARY SLI; SCHAEL M, 1998, P WORKSH TEXT AN SEP; SIGGELKOW S, 1997, 397 A LUDW U I INF; Song KY, 1996, IMAGE VISION COMPUT, V14, P667, DOI 10.1016/0262-8856(96)84491-X; Toft P., 1996, THESIS TU DENMARK	15	150	183	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					811	828		10.1109/34.946986	http://dx.doi.org/10.1109/34.946986			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300003
J	Hu, JY; Brown, MK; Turin, W				Hu, JY; Brown, MK; Turin, W			HMM based on-line handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						on-line handwriting recognition; hidden Markov models; subcharacter models; evolutional grammar; invariant features; segmental features		Hidden Markov Model (HMM) based recognition of handwriting is now quite common, but the incorporation of HMM's into a complex stochastic language model for handwriting recognition is still in its infancy. We have taken advantage of developments in the speech processing field to build a more sophisticated handwriting recognition system. The pattern elements of the handwriting model are subcharacter stroke types modeled by HMM's. These HMM's are concatenated to form letter models, which are further embedded in a stochastic language model. In addition to better language modeling, we introduce new handwriting recognition features of various kinds. Some of these features have invariance properties, and some are segmental, covering a larger region of the input pattern. We have achieved a writer independent recognition rate of 94.5% on 3,823 unconstrained handwritten word samples from 18 writers covering a 32 word vocabulary.			Hu, JY (corresponding author), AT&T BELL LABS,LUCENT TECHNOL,700 MT AVE,MURRAY HILL,NJ 07974, USA.							BERCU S, 1993, 3RD P INT WORKSH FRO, P385; BROWN MK, 1991, IEEE T SIGNAL PROCES, V39, P17, DOI 10.1109/78.80761; BROWN MK, 1994, P ICLSP 94 YOK JAP S, V2, P779; BRUCKSTEIN AM, 1993, CVGIP-IMAG UNDERSTAN, V58, P49, DOI 10.1006/ciun.1993.1031; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; GUBERMAN SA, 1976, AUTOMAT REM CONTR+, V37, P751; HU J, 1995, P ICIAP 95 SANR IT S, P588; KUNDU A, 1988, P ICASSP 88, V2, P928; Lowerre B., 1980, TRENDS SPEECH RECOGN, P340; MAKHOUL J, 1994, P ICASSP 94 AD AUSTR, pV125; MILLER GL, 1994, Patent No. 53373539; NAG R, 1986, P ICASSP 86, P2071; NATHAN KS, 1995, P ICASSP 95 DETR MIC, P2619; Rabiner L., 1993, FUNDAMENTALS SPEECH; SCHENKEL M, 1995, SPECIAL ISSUE MACHIN; SINDEN F, 1994, Patent No. 5333209; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; [No title captured]	18	150	160	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1039	1045		10.1109/34.541414	http://dx.doi.org/10.1109/34.541414			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100009
J	LAVALLEE, S; SZELISKI, R				LAVALLEE, S; SZELISKI, R			RECOVERING THE POSITION AND ORIENTATION OF FREE-FORM OBJECTS FROM IMAGE CONTOURS USING 3D DISTANCE MAPS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						REGISTRATION; 3D 2D MATCHING; OCTREE SPLINE; LINE-TO-SURFACE DISTANCE; X-RAY PROJECTIONS; NONLINEAR LEAST SQUARES MINIMIZATION	3-D OBJECTS; MODELS; REGISTRATION	The accurate matching of 3D anatomical surfaces with sensory data such as 2D X-ray projections is a basic problem in Computer and Robot Assisted Surgery. In model-based vision, this problem can be formulated as the estimation of the spatial pose (position and orientation) of a 3D smooth object from 2D video images. We present a new method for determining the rigid body transformation that describes this match. Our method performs a least squares minimization of the energy necessary to bring the set of the camera-contour projection lines tangent to the surface. To correctly deal with projection lines that penetrate the surface, we consider the minimum signed distance to the surface along each line (i.e., distances inside the object are negative). To quickly and accurately compute distances to the surface, we introduce a precomputed distance map represented using an octree spline whose resolution increases near the surface. This octree structure allows us to quickly find the minimum distance along each line using best-first search. Experimental results for 3D surface to 2D projection matching are presented for both simulated and real data. The combination of our problem formulation in 3D, our computation of line to surface distances with the octree-spline distance map, and our simple minimization technique based on the Levenberg-Marquardt algorithm results in a method that solves the 3D/2D matching problem for arbitrary smooth shapes accurately and quickly.	DIGITAL EQUIPMENT CORP,CAMBRIDGE RES LAB,CAMBRIDGE,MA 02139		LAVALLEE, S (corresponding author), FAC MED GRENOBLE,IMAG,TIMC,CNRS,F-38706 LA TRONCHE,FRANCE.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; Ayache N, 1991, ARTIFICIAL VISION MO; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BRUNIE L, 1992, JUN INT S 3D SCOL DE, P11; CHAMPLEBOUX G, 1992, JUN IEEE CS C COMP V; CHAMPLEBOUX G, 1992, MAY IEEE INT C ROB A, P1552; DEMAZEAU Y, 1986, THESIS GRENOBLE U; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; Forsey D. R., 1988, Computer Graphics, V22, P205, DOI 10.1145/378456.378512; GARCIA G., 1989, THESIS NANTES U; GLACHET R, 1992, LECT NOTES COMPUT SC, V588, P681; GRANGER C, 1985, RECONNAISSANCE OBJET; GRIMSON WEL, 1994, JUN IEEE COMP SOC C, P430; GUEZIEC A, 1992, LECT NOTES COMPUT SC, V588, P620; Herzen B. V, 1987, COMPUT GRAPH, V21, P103; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; KALL BA, 1987, SPIE MED IMAGING, V767, P27; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; LAVALLEE S, 1991, SPIE, V1570, P322; LAVALLEE S, 1995, COMPUTER INTEGRATED; LEITNER S, 1991, CURVES SURFACES; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; MARQUE L, 1990, THESIS GRENOBLE U FR; MARTINS HA, 1981, COMPUT VISION GRAPH, V17, P173, DOI 10.1016/0146-664X(81)90024-1; MONGA O, 1991, JUN IEEE COMP SOC C, P644; MONGA O, 1990, 1 EUR C COMP VIS, P56; PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Press WH, 1986, NUMERICAL RECIPES C, V818; Samet H, 1989, DESIGN ANAL SPATIAL; SAUTOT P, 1992, 14TH IEEE ENG MED BI, P1071; SCHIERS C, 1989, COMPUTER ASSISTED RA, P667; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; SZELISKI R, 1994, JUN IEEE WORKSH BIOM, P144; Taylor R. H., 1995, COMPUTER INTEGRATED; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1991, JUN IEEE COMP SOC C, P70; TSAI RY, 1989, ROBOTICS REV, P147; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108; [No title captured]	45	150	163	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					378	390		10.1109/34.385980	http://dx.doi.org/10.1109/34.385980			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800005
J	NAZIF, AM; LEVINE, MD				NAZIF, AM; LEVINE, MD			LOW-LEVEL IMAGE SEGMENTATION - AN EXPERT SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MCGILL UNIV,DEPT ELECT ENGN,COMP VIS & ROBOT LAB,MONTREAL H3A 2T5,QUEBEC,CANADA	McGill University	NAZIF, AM (corresponding author), UNIV CAIRO,DEPT ELECT ENGN,CAIRO,EGYPT.							BROOKS RA, 1978, 4TH P IJCAI KYOT, P105; BULLOCK BL, 1977, CS1 HUGH RES LAB COM; DAVIS R, 1980, ARTIF INTELL, V15, P179, DOI 10.1016/0004-3702(80)90043-0; Hanson A., 1978, COMPUTER VISION SYST; Koffka K., 1963, PRINCIPLES GESTALT P, V2nd; Kohler W., 1969, TASK GESTALT PSYCHOL; Levine M., 1982, MULTICOMPUTERS IMAGE, P149; LEVINE MD, 1981, IEEE T PATTERN ANAL, V3, P540, DOI 10.1109/TPAMI.1981.4767147; LEVINE MD, 1982, TR821 MCG U DEP EL E; LEVINE MD, 1983, NATO ASI SERIES F, V2, P663; LEVINE MD, 1983, TR836 MCG U DEP EL E; LEVINE MD, 1983, TR839 MCG U DEP EL E; LEVINE MD, VISION MAN MACHINE; MORAN TP, 1973, 3RD INT JOINT C ART, P472; Muerle J.L., 1968, PICTORIAL PATTERN RE, V1, P3; NAZIF A, 1983, TR835 MCG U COMP VIS; NAZIF AM, 1983, THESIS MCGILL U MONT; OHLANDER R, 1975, THESIS CARNEGIE MELL; RISEMAN EM, 1977, COMPUT VISION GRAPH, V6, P221, DOI 10.1016/S0146-664X(77)80028-2; SLOAN K, 1977, THESIS U PENNSYLVANI; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TSOTSOS JK, 1982, 6TH P INT JOINT C PA, P654; TSUJI S, 1973, COMPUTER GRAPHICS IM, V2, P216; Wertheimer M, 1938, LAWS ORG PERCEPTUAL; ZUCKER SW, 1975, 4TH P INT JOINT C AR, P716	25	150	170	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					555	577		10.1109/TPAMI.1984.4767570	http://dx.doi.org/10.1109/TPAMI.1984.4767570			23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869225				2022-12-18	WOS:A1984TM81300002
J	Zhang, PF; Lan, CL; Xing, JL; Zeng, WJ; Xue, JR; Zheng, NN				Zhang, Pengfei; Lan, Cuiling; Xing, Junliang; Zeng, Wenjun; Xue, Jianru; Zheng, Nanning			View Adaptive Neural Networks for High Performance Skeleton-Based Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						View adaptation; skeleton; action recognition; RNN; CNN; consistent	CLASSIFICATION; MOTION; ROBUST	Skeleton-based human action recognition has recently attracted increasing attention thanks to the accessibility and the popularity of 3D skeleton data. One of the key challenges in action recognition lies in the large variations of action representations when they are captured from different viewpoints. In order to alleviate the effects of view variations, this paper introduces a novel view adaptation scheme, which automatically determines the virtual observation viewpoints over the course of an action in a learning based data driven manner. Instead of re-positioning the skeletons using a fixed human-defined prior criterion, we design two view adaptive neural networks, i.e., VA-RNN and VA-CNN, which are respectively built based on the recurrent neural network (RNN) with the Long Short-term Memory (LSTM) and the convolutional neural network (CNN). For each network, a novel view adaptation module learns and determines the most suitable observation viewpoints, and transforms the skeletons to those viewpoints for the end-to-end recognition with a main classification network. Ablation studies find that the proposed view adaptive models are capable of transforming the skeletons of various views to much more consistent virtual viewpoints. Therefore, the models largely eliminate the influence of the viewpoints, enabling the networks to focus on the learning of action-specific features and thus resulting in superior performance. In addition, we design a two-stream scheme (referred to as VA-fusion) that fuses the scores of the two networks to provide the final prediction, obtaining enhanced performance. Moreover, random rotation of skeleton sequences is employed to improve the robustness of view adaptation models and alleviate overfitting during training. Extensive experimental evaluations on five challenging benchmarks demonstrate the effectiveness of the proposed view-adaptive networks and superior performance over state-of-the-art approaches.	[Zhang, Pengfei] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China; [Xue, Jianru; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China; [Lan, Cuiling] Microsoft Res Asia, Beijing 100080, Peoples R China; [Zeng, Wenjun] Microsoft Res Asia, Senior Leadership Team, Beijing 100080, Peoples R China; [Xing, Junliang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China	Xi'an Jiaotong University; Xi'an Jiaotong University; Microsoft; Microsoft Research Asia; Microsoft; Microsoft Research Asia; Chinese Academy of Sciences; Institute of Automation, CAS	Xue, JR (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.; Lan, CL (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.	zpengfei@stu.xjtu.edu.cn; culan@microsoft.com; jlxing@nlpr.ia.ac.cn; wezeng@microsoft.com; jrxue@mail.xjtu.edu.cn; nnzheng@mail.xjtu.edu.cn	Xing, Junliang/HGE-9630-2022	Xing, Junliang/0000-0001-6801-0510; Xue, Jianru/0000-0002-4994-9343	National Key Research and Development Program of China [2016YFB1001004]; Natural Science Foundation of China [61672519]	National Key Research and Development Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Jianru Xue is supported by National Key Research and Development Program of China under Grant 2016YFB1001004, Natural Science Foundation of China under Grant 61773311, and Grant 61751308. Junliang Xing is supported by the Natural Science Foundation of China (Grant No. 61672519). This work was mostly done while P. Zhang was an intern with Microsoft Research Asia.	Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011; Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588; Bashir FI, 2006, MULTIMEDIA SYST, V12, P45, DOI 10.1007/s00530-006-0024-2; Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569; Du Y, 2016, IEEE T IMAGE PROCESS, V25, P3010, DOI 10.1109/TIP.2016.2552404; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772; Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13; Feng JG, 2015, FRONT INFORM TECH EL, V16, P917, DOI 10.1631/FITEE.1500080; Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139; Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HU JF, 2015, PROC CVPR IEEE, P5344; Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17; Iosifidis A, 2012, IEEE T NEUR NET LEAR, V23, P412, DOI 10.1109/TNNLS.2011.2181865; Jia LW, 2012, RES ASTRON ASTROPHYS, V12, P411, DOI 10.1088/1674-4527/12/4/005; Jiang M, 2015, SIGNAL PROCESS-IMAGE, V33, P29, DOI 10.1016/j.image.2015.02.004; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22; Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li B, 2017, EUR MICROW CONF, P608; Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011; Li W, 2017, IEEE I CONF COMP VIS, P1453, DOI 10.1109/ICCV.2017.161; Liu J., 2017, PROC CVPR IEEE, P1647, DOI DOI 10.1109/CVPR.2017.391; Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030; Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Mahasseni B, 2013, IEEE I CONF COMP VIS, P3128, DOI 10.1109/ICCV.2013.388; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Qadir O, 2011, IEEE C EVOL COMPUTAT, P208; Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621; Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389; Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860; Rao C, 2001, PROC CVPR IEEE, P316; Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312; Shen Y., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587755; Shen YP, 2009, IEEE T PATTERN ANAL, V31, P1898, DOI 10.1109/TPAMI.2009.41; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Song SJ, 2017, AAAI CONF ARTIF INTE, P4263; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang J, 2014, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-04561-0_2; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191; Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Wu XX, 2013, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2013.81; Yun Kiwon, 2012, 2012 IEEE COMP SOC C, P28; Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019; Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI 10.1109/ICCV.2017.233; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24; Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347; Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394; Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885	59	149	157	11	85	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1963	1978		10.1109/TPAMI.2019.2896631	http://dx.doi.org/10.1109/TPAMI.2019.2896631			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30714909	Green Submitted			2022-12-18	WOS:000473598800013
J	Urbach, ER; Roerdink, JBTM; Wilkinson, MHF				Urbach, Erik R.; Roerdink, Jos B. T. M.; Wilkinson, Michael H. F.			Connected shape-size pattern spectra for rotation and scale-invariant classification of gray-scale images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; connected filters; scale spaces; multiscale analysis; shape filters; rotation; invariance; diatoms; Brodatz textures; COIL-100 object library	OPERATORS; SEGMENTATION; RECOGNITION; ALGORITHM; DILATION; OPENINGS; EROSION; FILTERS	In this paper, we describe a multiscale and multishape morphological method for pattern-based analysis and classification of gray-scale images using connected operators. Compared with existing methods, which use structuring elements, our method has three advantages. First, in our method, the time needed for computing pattern spectra does not depend on the number of scales or shapes used, i.e., the computation time is independent of the dimensions of the pattern spectrum. Second, size and strict shape attributes can be computed, which we use for the construction of joint 2D shape-size pattern spectra. Third, our method is significantly less sensitive to noise and is rotation-invariant. Although rotation invariance can also be approximated by methods using structuring elements at different angles, this tends to be computationally intensive. The classification performance of these methods is discussed using four image sets: Brodatz, COIL-20, COIL-100, and diatoms. The new method obtains better or equal classification performance to the best competitor with a 5 to 9-fold speed gain.	Univ Groningen, Inst Math & Comp Sci, NL-9700 AV Groningen, Netherlands	University of Groningen	Urbach, ER (corresponding author), Univ Groningen, Inst Math & Comp Sci, POB 800, NL-9700 AV Groningen, Netherlands.	erikurbach@yahoo.com; j.b.t.m.roerdink@rug.nl; m.h.f.wilkinson@rug.nl	Wilkinson, Michael/Q-2847-2019; Urbach, Erik/E-7083-2010; Wilkinson, Michael H.F./C-2386-2009; Wilkinson, Michael/AAA-8471-2020; Roerdink, Jos B.T.M/B-3631-2008	Wilkinson, Michael/0000-0001-6258-1128; Wilkinson, Michael H.F./0000-0001-6258-1128; 				Batman S, 1997, OPT ENG, V36, P1518, DOI 10.1117/1.601340; Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552; DUBUF JMH, 2002, SERIES MACHINE PERCE; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Ghosh P, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P476, DOI 10.1109/SIBGRA.1998.722795; Gil J, 2002, IEEE T PATTERN ANAL, V24, P1606, DOI 10.1109/TPAMI.2002.1114852; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jalba AC, 2004, PATTERN RECOGN, V37, P901, DOI 10.1016/j.patcog.2003.09.009; Jalba AC, 2004, MICROSC RES TECHNIQ, V65, P72, DOI 10.1002/jemt.20111; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Matheron G., 1975, RANDOM SETS INTEGRAL; Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556; Meijster A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P668, DOI 10.1109/ICIP.2001.958207; Nacken P. F. M., 1994, Journal of Mathematical Imaging and Vision, V4, P233, DOI 10.1007/BF01254101; Nacken PFM, 1996, J MATH IMAGING VIS, V6, P235, DOI 10.1007/BF00119841; OUZOUNIS GK, 2005, P INT S MATH MORPH I, P65; Quinlan J.R, 1993, C45 PROGRAMS MACHINE; RAGNEMALM I, 1992, PATTERN RECOGN LETT, V13, P161, DOI 10.1016/0167-8655(92)90055-5; Ronneberger O, 2002, INT C PATT RECOG, P290, DOI 10.1109/ICPR.2002.1048297; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Sand F., 1992, Journal of Mathematical Imaging and Vision, V1, P121, DOI 10.1007/BF00122207; Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Sivakumar K, 2000, REAL-TIME IMAGING, V6, P223, DOI 10.1006/rtim.1999.0172; Sofou A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1087, DOI 10.1109/ICIP.2001.958316; Soille P, 2001, IEEE T PATTERN ANAL, V23, P1313, DOI 10.1109/34.969120; Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646; Stoermer E F, 1999, DIATOMS APPL ENV EAR; Urbach ER, 2004, INT C PATT RECOG, P688, DOI 10.1109/ICPR.2004.1334269; Urbach ER, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P305; VANHERK M, 1992, PATTERN RECOGN LETT, V13, P517, DOI 10.1016/0167-8655(92)90069-C; Vincent L., 2000, Fundamenta Informaticae, V41, P57; WILKINSON M, 2001, P INT C MED IM COMP, P770	41	149	155	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					272	285		10.1109/TPAMI.2007.28	http://dx.doi.org/10.1109/TPAMI.2007.28			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170480	Green Submitted			2022-12-18	WOS:000242826900008
J	Mika, S; Ratsch, G; Weston, J; Scholkopf, B; Smola, A; Muller, KR				Mika, S; Ratsch, G; Weston, J; Scholkopf, B; Smola, A; Muller, KR			Constructing descriptive and discriminative nonlinear features: Rayleigh coefficients in kernel feature spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fisher's discriminant; nonlinear feature extraction; support vector machine; kernel functions; Rayleigh coefficient; oriented PCA		We incorporate prior knowledge to construct nonlinear algorithms for invariant feature extraction and discrimination. Employing a unified framework in terms of a nonlinearized variant of the Rayleigh coefficient, we propose nonlinear generalizations of Fisher's discriminant and oriented PCA using support vector kernel functions. Extensive simulations show the utility of our approach.	Fraunhofer FIRST, D-12489 Berlin, Germany; Univ Potsdam, D-14469 Potsdam, Germany; Australian Natl Univ, Canberra, ACT 0200, Australia; Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany	Fraunhofer Gesellschaft; Fraunhofer Institute Center Schloss Birlinghoven; University of Potsdam; Australian National University; Max Planck Society	Mika, S (corresponding author), Fraunhofer FIRST, Kekulestr 7, D-12489 Berlin, Germany.	Sebastian.Mika@first.fhg.de; Gunnar.Raetsch@anu.edu.au; Jason.Weston@tuebingen.mpg.de; Bernhard.Schoelkopf@tuebingen.mpg.de; Alex.Smola@anu.edu.au; Klaus-Robert.Mueller@first.fhg.de	Mueller, Klaus-Robert/Y-3547-2019; Muller, Klaus R/C-3196-2013; Schölkopf, Bernhard/A-7570-2013; Rätsch, Gunnar/O-5914-2017	Mueller, Klaus-Robert/0000-0002-3861-7685; Schölkopf, Bernhard/0000-0002-8177-0925; Rätsch, Gunnar/0000-0001-5486-8532				[Anonymous], 2002, LEARNING KERNELS; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bishop, 1995, NEURAL NETWORKS PATT; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Diamantaras K.I., 1996, PRINCIPAL COMPONENT; Duda R.O., 1973, J ROYAL STAT SOC SER; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GESTEL TV, 2001, BAYESIAN FRAMEWORK L; GRAEPEL T, 1999, P ICANN 99, V1, P304; KEERTHI SS, 2002, CD0208 NATL U SING; Mika S, 2001, ADV NEUR IN, V13, P591; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Mika S, 2001, P AISTATS, P98; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Ratsch G, 2002, MACH LEARN, V48, P189, DOI 10.1023/A:1013907905629; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; Roth V, 2000, ADV NEUR IN, V12, P568; Saunders C., 1998, P 15 INT C MACH LEAR, P515; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHOLKOPF B, 2001, P 14 ANN C COMP LEAR, P416; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tipping ME, 2000, ADV NEUR IN, V12, P652; Vapnik V.N, 1998, STAT LEARNING THEORY; 2002, BENCHMARK REPOSITORY	30	149	156	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					623	628		10.1109/TPAMI.2003.1195996	http://dx.doi.org/10.1109/TPAMI.2003.1195996			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300008
J	Ratsch, G; Mika, S; Scholkopf, B; Muller, KR				Ratsch, G; Mika, S; Scholkopf, B; Muller, KR			Constructing boosting algorithms from SVMs: An application to one-class classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						boosting; SVMs; one-class classification; unsupervised learning; novelty detection	SUPPORT	We show via an equivalence of mathematical programs that a support vector (SV) algorithm can be translated into an equivalent boosting-like algorithm and vice versa. We exemplify this translation procedure for a new algorithm-one-class leveraging-starting from the one-class support vector machine (1-SVIM). This is a first step toward unsupervised learning in a boosting framework. Building on so-called barrier methods known from the theory of constrained optimization, it returns a function, written as a convex combination of base hypotheses, that characterizes whether a given test point is likely to have been generated from the distribution underlying the training data. Simulations on one-class classification problems demonstrate the usefulness of our approach.	Australian Natl Univ, RSISE, Canberra, ACT 0200, Australia; Fraunhofer FIRST, D-12489 Berlin, Germany; Univ Potsdam, Dept Comp Sci, D-14482 Potsdam, Germany; Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany	Australian National University; Fraunhofer Gesellschaft; Fraunhofer Institute Center Schloss Birlinghoven; University of Potsdam; Max Planck Society	Ratsch, G (corresponding author), Australian Natl Univ, RSISE, Canberra, ACT 0200, Australia.	Gunnar.Raetsch@anu.edu.au; Sebastian.Mika@first.fraunhofer.de; Bernhard.Schoelkopf@tuebingen.mpg.de	Rätsch, Gunnar/B-8182-2009; Schölkopf, Bernhard/A-7570-2013; Muller, Klaus R/C-3196-2013; Rätsch, Gunnar/O-5914-2017; Mueller, Klaus-Robert/Y-3547-2019	Schölkopf, Bernhard/0000-0002-8177-0925; Rätsch, Gunnar/0000-0001-5486-8532; Mueller, Klaus-Robert/0000-0002-3861-7685				[Anonymous], 2002, LEARNING KERNELS; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bennett K.P., 1992, OPT MET SOFTW, V1, P23; Bishop, 1995, NEURAL NETWORKS PATT; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Bradley PS, 1998, COMPUT OPTIM APPL, V11, P5, DOI 10.1023/A:1018361916442; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Campbell C, 2001, ADV NEUR IN, V13, P395; Censor Y, 1997, NUMERICAL MATH SCI C; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Collins M., 2000, P 13 ANN C COMP LEAR, P158; COMINETTI R, 1994, J APPL THEORY OPTIMI, V83; Cristianini N., 2000, INTRO SUPPORT VECTOR; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; DEMIRIZ A, 2001, J MACHINE LEARNING; Dietterich T., 1999, MACHINE LEARNING, V40; Doljansky M, 1998, SIAM J OPTIMIZ, V9, P1, DOI 10.1137/S1052623496309405; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P705, DOI 10.1142/S0218001493000352; Duffy N, 1999, LECT NOTES ARTIF INT, V1572, P18; Duffy N., 2000, P 13 ANN C COMP LEAR, P208; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, P325, DOI 10.1145/238061.238163; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771; FREUND Y, 1994, P EUROCOLT EUR C COM; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Grove A., 1998, P 15 NAT C ART INT; Haykin S, 1998, NEURAL NETWORKS COMP, V2nd; Hayton P, 2001, ADV NEUR IN, V13, P946; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, P134, DOI 10.1145/307400.307424; LECUN Y, 1995, P INT C ART NEUR NET, V2, P53; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; Maclin R., 1997, PROC NATL CONF ARTIF, V1997, P546; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; Mangasarian OL, 1997, DATA MIN KNOWL DISC, V1, P183, DOI 10.1023/A:1009735908398; Mason L, 2000, ADV NEUR IN, P221; MOSHEYEV L, 1999, OPTIMIZATION METHODS; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Nash S.G., 1996, LINEAR NONLINEAR PRO; Orr G. B., 1998, LECT NOTES COMPUTER, V1524; POGGIO T, 1990, AIM1167 MIT AI LAB; Ratsch G, 2002, MACH LEARN, V48, P189, DOI 10.1023/A:1013907905629; Ratsch G, 2000, ADV NEUR IN, P207; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Ratsch G., 2000, P 13 ANN C COMP LEAR; RATSCH G, 2001, CONVERGENCE LEVERAGI; RATSCH G, 2001, THESIS U POTSDAM; RATSCH G, 2001, 97 ROY HOLL COLL; Salzberg SL, 1997, COMPUT APPL BIOSCI, V13, P365; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHAPIRE RE, 1992, THESIS MIT; Schatten G, 1998, J LAW MED ETHICS, V26, P29, DOI 10.1111/j.1748-720X.1998.tb01903.x; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf Bernhard, 1997, SUPPORT VECTOR LEARN; SCHWENK H, 1997, P ICANN 97 INT C ART, V1327, P967; SMOLA AJ, 1998, THESIS TECHNISCHE U; SONNENBURG S, 2002, IN PRESS P INT C ART; TAX DMJ, 1999, P EUR S ART NEUR NET, P251; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vapnik V.N, 1998, STAT LEARNING THEORY; ZHANG T, 2002, IN PRESS ADV NEURAL, V14	65	149	161	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1184	1199		10.1109/TPAMI.2002.1033211	http://dx.doi.org/10.1109/TPAMI.2002.1033211			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW					2022-12-18	WOS:000177640500003
J	Matsakis, P; Wendling, L				Matsakis, P; Wendling, L			A new way to represent the relative position between areal objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; parameter extraction; spatial relationships; fuzzy subsets	IMAGES	The fuzzy qualitative evaluation of directional spatial relationships (such as "to the right of," "to the south of...,") between areal objects often relies on the computation of a histogram of angles, which is considered to provide a good representation of the relative position of an object with regard to another. In this paper, the notion of the histogram of forces is introduced. It generalizes and may supersede the histogram of angles. The objects (2D entities) are handled as longitudinal sections (1D entities), not as points (0D entities). It is thus possible to fully benefit from the power of integral calculus and, so, ensure rapid processing of raster data, as well as of vector data, explicitly considering both angular and metric information.	Univ Toulouse 3, Inst Rech & Informat, F-31062 Toulouse, France	Universite de Toulouse; Universite Toulouse III - Paul Sabatier	Matsakis, P (corresponding author), Univ Toulouse 3, Inst Rech & Informat, 118 Route Narbonne, F-31062 Toulouse, France.	matsakis@irit.fr; wendling@irit.fr						BLOCH I, 1996, P IEEE INT C IMAGE P, V2, P987; DUBOIS D, 1987, PATTERN RECOGN LETT, V6, P251, DOI 10.1016/0167-8655(87)90085-7; DUBOIS D, 1980, MATH SCI ENG, V144, P40; Dutta S., 1991, International Journal of Approximate Reasoning, V5, P307, DOI 10.1016/0888-613X(91)90015-E; Freeman J., 1975, COMPUT VISION GRAPH, V4, P156, DOI [DOI 10.1016/S0146-664X(75)80007-4, 10.1016/S0146-664X(75)80007-4]; GAPP KP, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1393; KELLER J, 1990, P 1 INT S UNC MOD AN, P207; KELLER JM, 1996, P IEEE 5 INT C FUZZ; KELLER JM, 1995, ISUMA NAFIPS 95, P679; KOCZY LT, 1988, PATTERN RECOGN LETT, V8, P21, DOI 10.1016/0167-8655(88)90019-0; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P222, DOI 10.1109/91.236554; LEE SY, 1992, PATTERN RECOGN, V25, P305, DOI 10.1016/0031-3203(92)90112-V; LEVITT TS, 1990, ARTIF INTELL, V44, P305, DOI 10.1016/0004-3702(90)90027-W; Matsakis P., 1998, Traitement du Signal, V15, P25; MATSAKIS P, 1998, THESIS I RECHERCHE I; MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3; PEUQUET DJ, 1987, PATTERN RECOGN, V20, P65, DOI 10.1016/0031-3203(87)90018-5; RETZSCHMIDT G, 1988, AI MAG, V9, P95; Rogers D. F., 1985, PROCEDURAL ELEMENTS, P34; ROHRIG R, 1997, P KI 97 KUNSTL INT 9, P219; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2, P263; SCHLIEDER C, 1993, QUALITATIVE REASONING AND DECISION TECHNOLOGIES, P523; Sharma J, 1995, LECT NOTES COMPUT SC, V951, P279; Wendling L, 1998, COMP SUPPL, V12, P63; Winston P. H., 1975, PSYCHOL COMPUTER VIS; WORBOYS MF, 1995, GIS COMPUTING PERSPE, P120	26	149	155	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					634	643		10.1109/34.777374	http://dx.doi.org/10.1109/34.777374			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT					2022-12-18	WOS:000081472600006
J	De Lange, M; Aljundi, R; Masana, M; Parisot, S; Jia, X; Leonardis, A; Slabaugh, G; Tuytelaars, T				De Lange, Matthias; Aljundi, Rahaf; Masana, Marc; Parisot, Sarah; Jia, Xu; Leonardis, Ales; Slabaugh, Greg; Tuytelaars, Tinne			A Continual Learning Survey: Defying Forgetting in Classification Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Knowledge engineering; Neural networks; Training; Training data; Learning systems; Interference; Continual learning; lifelong learning; task incremental learning; catastrophic forgetting; classification; neural networks	NEURAL-NETWORKS	Artificial neural networks thrive in solving the classification problem for a particular rigid task, acquiring knowledge through generalized learning behaviour from a distinct training phase. The resulting network resembles a static entity of knowledge, with endeavours to extend this knowledge without targeting the original task resulting in a catastrophic forgetting. Continual learning shifts this paradigm towards networks that can continually accumulate knowledge over different tasks without the need to retrain from scratch. We focus on task incremental classification, where tasks arrive sequentially and are delineated by clear boundaries. Our main contributions concern: (1) a taxonomy and extensive overview of the state-of-the-art; (2) a novel framework to continually determine the stability-plasticity trade-off of the continual learner; (3) a comprehensive experimental comparison of 11 state-of-the-art continual learning methods; and (4) baselines. We empirically scrutinize method strengths and weaknesses on three benchmarks, considering Tiny Imagenet and large-scale unbalanced iNaturalist and a sequence of recognition datasets. We study the influence of model capacity, weight decay and dropout regularization, and the order in which the tasks are presented, and qualitatively compare methods in terms of required memory, computation time, and storage.	[De Lange, Matthias; Aljundi, Rahaf; Tuytelaars, Tinne] Ctr Proc Speech & Images, Dept Elect Engn, B-3001 Leuven, Belgium; [Masana, Marc] UAB, Comp Vis Ctr, Barcelona 08193, Spain; [Parisot, Sarah; Jia, Xu; Leonardis, Ales; Slabaugh, Greg] Huawei, Montreal, PQ H3N 1X9, Canada	Autonomous University of Barcelona; Centre de Visio per Computador (CVC); Huawei Technologies	De Lange, M (corresponding author), Ctr Proc Speech & Images, Dept Elect Engn, B-3001 Leuven, Belgium.	de.lange.matthias@gmail.com; rahaf.aljundi@gmail.com; marc.masana@cvc.uab.es; sarah.parisot@huawei.com; jiayushenyang@gmail.com; ales.leonardis@huawei.com; greg.slabaugh@gmail.com; tinne.tuytelaars@esat.kuleuven.be	; Tuytelaars, Tinne/B-4319-2015	Masana Castrillo, Marc/0000-0003-3254-3096; Tuytelaars, Tinne/0000-0003-3307-9723	Huawei; Generalitat de Catalunya [2019-FI_B2-00189]; FWO Scholarship	Huawei(Huawei Technologies); Generalitat de Catalunya(Generalitat de Catalunya); FWO Scholarship(FWO)	The authors would like to thank Huawei for funding this research. The work of Marc Masana was supported by the Generalitat de Catalunya under Grant 2019-FI_B2-00189. The work of Rahaf Aljundi was supported by the FWO Scholarship.	Ahn H, 2019, ADV NEUR IN, V32; Aljundi R., 2019, PROC INT C LEARN REP; Aljundi R, 2019, ADV NEUR IN, V32; Aljundi R, 2019, PROC CVPR IEEE, P11246, DOI 10.1109/CVPR.2019.01151; Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9; Aljundi R, 2017, PROC CVPR IEEE, P7120, DOI 10.1109/CVPR.2017.753; Alquier P, 2017, PR MACH LEARN RES, V54, P261; [Anonymous], 2010, CALIFORNIA I TECHNOL; [Anonymous], 2018, NAT DAT FGVC5 WORKSH; Ans B, 1997, CR ACAD SCI III-VIE, V320, P989, DOI 10.1016/S0764-4469(97)82472-9; Atkinson C., 2018, ARXIV 180203875; Balcan, 2015, C LEARN THEOR, P191; Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799; Bengio Y., 2014, P INT C LEARN REPR; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33; Chaudhry Arslan, 2019, CONTINUAL LEARNING T; Chaudhry Arslan, 2018, ARXIV181200420, V2, P6; Chen Z, 2018, SYNTHESIS LECT ARTIF, V12, P1, DOI [10.2200/S00737ED1V01Y201610AIM033, DOI 10.2200/S00737ED1V01Y201610AIM033]; Chung C., AM J HEALTH-SYST PH, V2018; Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1; de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Farquhar S., 2019, ARXIV 180509733; Fernando C., 2017, ARXIV 170108734; French R. M., 1992, Connection Science, V4, P365, DOI 10.1080/09540099208946624; French R. M., 1997, Connection Science, V9, P353, DOI 10.1080/095400997116595; French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2; FRENCH RM, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P335; Gepperth A, 2016, COGN COMPUT, V8, P924, DOI 10.1007/s12559-016-9389-5; Goodfellow I.J., 2015, STATISTICAL, DOI DOI 10.48550/ARXIV.1412.6572; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow Ian J., 2015, EMPIRICAL INVESTIGAT, DOI 10.48550/arXiv.1312.6211; Grossberg S., 1982, BOSTON COLL STUD PH, V70, DOI 10.1007/978-94-009-7758-7; Gupta P, 2020, PR MACH LEARN RES, V119; Hinton G., 2015, ARXIV150302531; Hinton G.E., 2012, ARXIV; Hsu Y.-C., 2018, ARXIV 181012488; Huszar F, 2018, P NATL ACAD SCI USA, V115, pE2496, DOI 10.1073/pnas.1717042115; Isele D, 2018, AAAI CONF ARTIF INTE, P3302; Jung Heechul, 2016, ARXIV160700122; Kemker R, 2018, AAAI CONF ARTIF INTE, P3390; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kruschke J. K., 1993, Connection Science, V5, P3, DOI 10.1080/09540099308915683; KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037/0033-295X.99.1.22; Lang M., 2020, PROC INT C LEARN REP, P1; Lange M. D., 2020, P IEEE CVF C COMP VI, P14463; Lavda F., 2018, ARXIV 181010612; Lee CS, 2020, LANCET DIGIT HEALTH, V2, pE279, DOI 10.1016/S2589-7500(20)30102-3; Lee SW, 2017, ADV NEUR IN, V30; Lesort T, 2020, INFORM FUSION, V58, P52, DOI 10.1016/j.inffus.2019.12.004; Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37; Liu XL, 2018, INT C PATT RECOG, P2262, DOI 10.1109/ICPR.2018.8545895; Lopez-Paz D, 2017, ADV NEUR IN, V30; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Maji Subhransu, 2013, ARXIV 13065151; Mallya A, 2018, LECT NOTES COMPUT SC, V11208, P72, DOI 10.1007/978-3-030-01225-0_5; Mallya A, 2018, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2018.00810; Martens J, 2020, J MACH LEARN RES, V21; Masana M., 2020, ARXIV 201015277; Masana M., 2020, ARXIV 200108714; MCNAUGHTON BL, 1983, EXP BRAIN RES, V52, P41; Netzer Y., 2011, P NIPS WORKSH DEEP L; Nguyen C.V., 2018, INT C LEARNING REPRE; Nguyen C. V., 2019, ARXIV 190801091; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Pascanu Razvan, 2013, ARXIV13013584; Pentina A., 2015, ADV NEURAL INFORM PR, V1, P1540; Pentina A, 2014, PR MACH LEARN RES, V32, P991; Pf_ulb B., 2019, PROC INT C LEARN REP; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Ramapuram J, 2020, NEUROCOMPUTING, V404, P381, DOI 10.1016/j.neucom.2020.02.115; Rannen A, 2017, IEEE I CONF COMP VIS, P1329, DOI 10.1109/ICCV.2017.148; Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587; Robins A., 1995, Connection Science, V7, P123, DOI 10.1080/09540099550039318; Rolnick D., 2019, ADV NEURAL INFORM PR; Rosenfeld A, 2020, IEEE T PATTERN ANAL, V42, P651, DOI 10.1109/TPAMI.2018.2884462; Rueckl J, 1993, COGNITIVE SCI, P866; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Rusu A. A., 2016, ARXIV160604671; Saad D, 1999, ON LINE LEARNING NEU, P9, DOI DOI 10.1017/CBO9780511569920.003; Schwarz J, 2018, PR MACH LEARN RES, V80; Serra J, 2018, PR MACH LEARN RES, V80; Shalev-Shwartz S, 2012, FOUND TRENDS MACH LE, V4, P107, DOI 10.1561/2200000018; Shin H, 2017, ADV NEUR IN, V30; Shmelkov K, 2017, IEEE I CONF COMP VIS, P3420, DOI 10.1109/ICCV.2017.368; Silver Daniel L, 2002, C CAN SOC COMP STUD, P90, DOI DOI 10.1007/3-540-47922-8_8; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; Sloman Steven A, 1992, ESSAYS HONOR WK ESTE, V1, P227; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stanford, TIN IMAG CHALL CS23I; Xu H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3413, DOI 10.1145/3308558.3313644; Xu J, 2018, ADV NEUR IN, V31; Zenke F, 2017, PR MACH LEARN RES, V70; Zeno C., 2019, ARXIV 180310123; Zhang JT, 2020, IEEE WINT CONF APPL, P1120, DOI 10.1109/WACV45572.2020.9093365; Zhang Y., 2017, ARXIV 170708114	102	148	148	39	71	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3366	3385		10.1109/TPAMI.2021.3057446	http://dx.doi.org/10.1109/TPAMI.2021.3057446			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33544669	Green Submitted, Green Published			2022-12-18	WOS:000805820500005
J	Endres, I; Hoiem, D				Endres, Ian; Hoiem, Derek			Category-Independent Object Proposals with Diverse Ranking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object segmentation; object recognition		We propose a category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects. Our key objectives are completeness and diversity: Every object should have at least one good proposed region, and a diverse set should be top-ranked. Our approach is to generate a set of segmentations by performing graph cuts based on a seed region and a learned affinity function. Then, the regions are ranked using structured learning based on various cues. Our experiments on the Berkeley Segmentation Data Set and Pascal VOC 2011 demonstrate our ability to find most objects within a small bag of proposed regions.	[Endres, Ian; Hoiem, Derek] Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA	University of Illinois System; University of Illinois Urbana-Champaign	Endres, I (corresponding author), Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA.	iendres2@uiuc.edu						Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chum 0., 2007, P IEEE C COMP VIS PA; Everingham M., 2013, PASCAL VISUAL OBJECT; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farhadi A., 2009, P IEEE C COMP VIS PA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; GOODALE MA, 1991, NATURE, V349, P154, DOI 10.1038/349154a0; Gould S., 2009, P 12 IEEE INT C COMP; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Hoiem D., 2005, P 10 IEEE INT C COMP; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4; Lampert C. H., 2009, P IEEE C COMP VIS PA; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693; Malisiewicz T., 2007, P BRIT MACH VIS C BM; Martin D., 2002, P ANN C NEUR INF PRO; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Russell B. C., 2006, P IEEE C COMP VIS PA; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sharon E., 2006, NATURE           JUN; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Stein A., 2008, P IEEE C COMP VIS PA; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; VEDALDI A., 2009, P IEEE INT C COMP VI; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001	31	148	161	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					222	234		10.1109/TPAMI.2013.122	http://dx.doi.org/10.1109/TPAMI.2013.122			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356345				2022-12-18	WOS:000328899500002
J	Iam-On, N; Boongoen, T; Garrett, S; Price, C				Iam-On, Natthakan; Boongoen, Tossapon; Garrett, Simon; Price, Chris			A Link-Based Approach to the Cluster Ensemble Problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; cluster ensembles; cluster relations; link-based similarity; data mining	CLASS DISCOVERY; CONSENSUS; GRAPH	Cluster ensembles have recently emerged as a powerful alternative to standard cluster analysis, aggregating several input data clusterings to generate a single output clustering, with improved robustness and stability. From the early work, these techniques held great promise; however, most of them generate the final solution based on incomplete information of a cluster ensemble. The underlying ensemble-information matrix reflects only cluster-data point relations, while those among clusters are generally overlooked. This paper presents a new link-based approach to improve the conventional matrix. It achieves this using the similarity between clusters that are estimated from a link network model of the ensemble. In particular, three new link-based algorithms are proposed for the underlying similarity assessment. The final clustering result is generated from the refined matrix using two different consensus functions of feature-based and graph-based partitioning. This approach is the first to address and explicitly employ the relationship between input partitions, which has not been emphasized by recent studies of matrix refinement. The effectiveness of the link-based approach is empirically demonstrated over 10 data sets (synthetic and real) and three benchmark evaluation measures. The results suggest the new approach is able to efficiently extract information embedded in the input clusterings, and regularly illustrate higher clustering quality in comparison to several state-of-the-art techniques.	[Iam-On, Natthakan] Mae Fah Luang Univ, Sch Informat Technol, Muang 57100, Chiang Rai, Thailand; [Boongoen, Tossapon] Royal Thai AF Acad, Bangkok 10220, Thailand; [Garrett, Simon] Aispire Consulting Ltd, Aberystwyth SY23 3PG, Dyfed, Wales; [Price, Chris] Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3DB, Ceredigion, Wales	Mae Fah Luang University; Aberystwyth University	Iam-On, N (corresponding author), Mae Fah Luang Univ, Sch Informat Technol, Muang 57100, Chiang Rai, Thailand.	nt.iamon@gmail.com; turtletoss@hotmail.com; s.garrett@aispire.co.uk; cjp@aber.ac.uk	Iam-on, Natthakan/AAO-7084-2020; Boongoen, Tossapon/AAO-7089-2020; IAM-ON, NATTHAKAN/AAY-9833-2020	IAM-ON, NATTHAKAN/0000-0003-4623-645X; Boongoen, Tossapon/0000-0002-2874-1922				Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1; [Anonymous], 2004, P 2 C AS PAC BIOINF; Asuncion A, 2007, UCI MACHINE LEARNING; Ayad H, 2003, LECT NOTES COMPUT SC, V2709, P166; Boongoen T, 2010, ARTIF INTELL LAW, V18, P77, DOI 10.1007/s10506-010-9085-9; Boulis C, 2004, LECT NOTES ARTIF INT, V3202, P63; Cristofor D, 2002, J UNIVERS COMPUT SCI, V8, P153; Domeniconi C., 2009, ACM T KNOWL DISCOV D, V2, P1; Domeniconi C, 2007, DATA MIN KNOWL DISC, V14, P63, DOI 10.1007/s10618-006-0060-8; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038; Fern XZ, 2003, P INT C MACH LEARN, V20, P186; Fern XZ, 2004, P 21 INT C MACHINE L, P36; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46; Fred A., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096), P309; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450; Getoor L., 2005, ACM SIGKDD EXPLORATI, V7, P3, DOI [DOI 10.1145/1117454.1117456, 10.1145/1117454.1117456]; Ghosh J., 2007, ADV FUZZY CLUSTERING, P69; Gionis A, 2005, PROC INT CONF DATA, P341; Hadjitodorov ST, 2006, INFORM FUSION, V7, P264, DOI 10.1016/j.inffus.2005.01.008; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Iam-On N, 2008, LECT NOTES COMPUT SC, V5255, P222, DOI 10.1007/978-3-540-88411-8_22; Jeh G, 2002, P 8 ACM SIGKDD INT C, V02, P538; Karypis G, 1998, J PARALLEL DISTR COM, V48, P96, DOI 10.1006/jpdc.1997.1404; Karypis G, 1999, IEEE T VLSI SYST, V7, P69, DOI 10.1109/92.748202; Kaufman L., 2009, FINDING GROUPS DATA; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2004, IEEE SYS MAN CYBERN, P1214; Kuncheva LI, 2006, IEEE T PATTERN ANAL, V28, P1798, DOI 10.1109/TPAMI.2006.226; Law MHC, 2004, PROC CVPR IEEE, P424; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2; Lin ZJ, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P687, DOI 10.1109/WI.2006.127; Minaei-Bidgoli B, 2004, IC-AI '04 & MLMTA'04 , VOL 1 AND 2, PROCEEDINGS, P939; Minkov E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P27, DOI 10.1145/1148170.1148179; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; Ng AY, 2002, ADV NEUR IN, V14, P849; Nguyen N, 2007, IEEE DATA MINING, P607, DOI 10.1109/ICDM.2007.73; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Reuther P., 2006, International Journal of Metadata, Semantics and Ontologies, V1, P89, DOI 10.1504/IJMSO.2006.011006; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Struyf A, 1997, COMPUT STAT DATA AN, V26, P17, DOI 10.1016/S0167-9473(97)00020-0; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; Topchy A, 2004, SIAM PROC S, P379; Topchy A, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P331; Xue H, 2009, PATTERN RECOGN, V42, P93, DOI 10.1016/j.patcog.2008.07.010; Yu ZW, 2007, BIOINFORMATICS, V23, P2888, DOI 10.1093/bioinformatics/btm463	50	148	156	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2396	2409		10.1109/TPAMI.2011.84	http://dx.doi.org/10.1109/TPAMI.2011.84			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21576752				2022-12-18	WOS:000295980000007
J	Ma, ZY; Leijon, A				Ma, Zhanyu; Leijon, Arne			Bayesian Estimation of Beta Mixture Models with Variational Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian estimation; maximum likelihood estimation; beta distribution; mixture modeling; variational inference; factorized approximation	MAXIMUM-LIKELIHOOD-ESTIMATION	Bayesian estimation of the parameters in beta mixture models (BMM) is analytically intractable. The numerical solutions to simulate the posterior distribution are available, but incur high computational cost. In this paper, we introduce an approximation to the prior/posterior distribution of the parameters in the beta distribution and propose an analytically tractable (closed form) Bayesian approach to the parameter estimation. The approach is based on the variational inference (VI) framework. Following the principles of the VI framework and utilizing the relative convexity bound, the extended factorized approximation method is applied to approximate the distribution of the parameters in BMM. In a fully Bayesian model where all of the parameters of the BMM are considered as variables and assigned proper distributions, our approach can asymptotically find the optimal estimate of the parameters posterior distribution. Also, the model complexity can be determined based on the data. The closed-form solution is proposed so that no iterative numerical calculation is required. Meanwhile, our approach avoids the drawback of overfitting in the conventional expectation maximization algorithm. The good performance of this approach is verified by experiments with both synthetic and real data.	[Ma, Zhanyu; Leijon, Arne] KTH Royal Inst Technol, Sch Elect & Engn, Sound & Image Proc Lab, SE-10044 Stockholm, Sweden	Royal Institute of Technology	Ma, ZY (corresponding author), KTH Royal Inst Technol, Sch Elect & Engn, Sound & Image Proc Lab, Osquldas 10, SE-10044 Stockholm, Sweden.	zhanyu@kth.se; leijon@kth.se						[Anonymous], 1990, ACOUSTIC PHONETIC CO; Attias H, 2000, ADV NEUR IN, V12, P209; AZNAVEH MM, 2008, P IEEE INT MULT SYST, P1; Beckman R. J., 1978, Journal of Statistical Computation and Simulation, V7, P253, DOI 10.1080/00949657808810232; Bernardo J. M., 1994, BAYESIAN THEORY; Bickel PJ, 2007, MATH STAT BASIC IDEA; Bishop C.M, 2006, PATTERN RECOGN; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Blei David M, 2004, MACH LEARN P 21 INT; BLEI DM, 2006, ADV NEURAL INFORM PR; Bouguila N, 2006, STAT COMPUT, V16, P215, DOI 10.1007/s11222-006-8451-7; Boyd S, 2004, CONVEX OPTIMIZATION; Brand J, 2000, INT C PATT RECOG, P1056, DOI 10.1109/ICPR.2000.905653; Brown D. A., 2001, P BRIT MACH VIS C; Cribari-Neto F, 2002, J STAT COMPUT SIM, V72, P107, DOI 10.1080/00949650212144; DIACONIS P, 1979, ANN STAT, V7, P269, DOI 10.1214/aos/1176344611; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GNANADESIKAN R, 1967, TECHNOMETRICS, V9, P607, DOI 10.2307/1266199; Gupta A. K., 2004, HDB BETA DISTRIBUTIO; Hedelin P, 2000, IEEE T SPEECH AUDI P, V8, P385, DOI 10.1109/89.848220; Hoffman M.D., 2010, P 27 INT C MACH LEAR; Jaakkola TS, 2001, NEU INF PRO, P129; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JEDYNAK B, 2002, P IND C COMP VIS GRA, P276; Ji Y, 2005, BIOINFORMATICS, V21, P2118, DOI 10.1093/bioinformatics/bti318; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Jordan M. I., 1999, LEARNING GRAPHICAL M; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Lee J. Y., 2002, P INT C IM SCI SYST; Lee JC, 1999, J STAT COMPUT SIM, V63, P73, DOI 10.1080/00949659908811950; Lindblom J, 2003, IEEE T SPEECH AUDI P, V11, P88, DOI 10.1109/TSA.2002.805639; MA Z, 2009, P INT C IM PROC; MA Z, 2010, P 11 ANN C INT SPEEC; MA Z, 2010, P 18 EUR SIGN PROC C; McLachlan, 1997, EM ALGORITHM EXTENSI; Mclachlan G., 2000, WILEY SER PROB STAT; Olkin I, 2003, STAT PROBABIL LETT, V62, P407, DOI 10.1016/S0167-7152(03)00048-8; PALMER JA, 2003, RELATIVE CONVEXITY; SAVCHUK VP, 1994, IEEE T RELIAB, V43, P138, DOI 10.1109/24.285128; Ueda N, 2002, NEURAL NETWORKS, V15, P1223, DOI 10.1016/S0893-6080(02)00040-0; WAGLE B, 1968, J ROY STAT SOC B, V30, P511; Webb A.R., 2003, STAT PATTERN RECOGNI	47	148	155	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2160	2173		10.1109/TPAMI.2011.63	http://dx.doi.org/10.1109/TPAMI.2011.63			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21422484				2022-12-18	WOS:000294910000004
J	Kahl, F; Hartley, R				Kahl, Fredrik; Hartley, Richard			Multiple-view geometry under the L-infinity-norm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						quasi-convex functions; convex optimization; SOCP; triangulation; projective geometry		This paper presents a new framework for solving geometric structure and motion problems based on the L-infinity-norm. Instead of using the common sum-of-squares cost function, that is, the L-2-norm, the model-fitting errors are measured using the L-infinity-norm. Unlike traditional methods based on L-2, our framework allows for the efficient computation of global estimates. We show that a variety of structure and motion problems, for example, triangulation, camera resectioning, and homography estimation, can be recast as quasi-convex optimization problems within this framework. These problems can be efficiently solved using second-order cone programming (SOCP), which is a standard technique in convex optimization. The methods have been implemented in Matlab and the resulting toolbox has been made publicly available. The algorithms have been validated on real data in different settings on problems with small and large dimensions and with excellent performance.	[Kahl, Fredrik] Lund Univ, Ctr Math Sci, SE-22100 Lund, Sweden; [Hartley, Richard] Australian Natl Univ, RSISE, Comp Vis Grp, Canberra, ACT 0200, Australia	Lund University; Australian National University	Kahl, F (corresponding author), Lund Univ, Ctr Math Sci, POB 118, SE-22100 Lund, Sweden.	fredrik@maths.lth.se; richard.hartley@anu.edu.au		Hartley, Richard/0000-0002-5005-0191				AGARWAL S, 2006, P 9 EUR C COMP VIS G, P592; Boyd S, 2004, CONVEX OPTIMIZATION; Fusiello A, 2004, IEEE T PATTERN ANAL, V26, P1633, DOI 10.1109/TPAMI.2004.125; Govindu VM, 2004, PROC CVPR IEEE, P684; Hartley R, 2004, PROC CVPR IEEE, P504; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Heyden A, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P963; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; KE Q, 2006, P IEEE C COMP VIS PA, P1199; Ke QF, 2005, IEEE I CONF COMP VIS, P986; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Nister D., 2001, THESIS ROYAL I TECHN; Rother C, 2002, INT J COMPUT VISION, V49, P117, DOI 10.1023/A:1020189404787; Sim K., 2006, P IEEE C COMP VIS PA, V1, P1230, DOI 10.1109/CVPR.2006.247; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; Stewenius H, 2005, IEEE I CONF COMP VIS, P686; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 2004, IEEE T PATTERN ANAL, V26, P648, DOI 10.1109/TPAMI.2004.1273967; TRIGGS B, 1999, P ICCV WORKSH VIS AL, V298, P372; Uyttendaele M, 2004, IEEE COMPUT GRAPH, V24, P52, DOI 10.1109/MCG.2004.1297011; Wolf L, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P412, DOI 10.1109/ICCV.2001.937547	26	148	161	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1603	1617		10.1109/TPAMI.2007.70824	http://dx.doi.org/10.1109/TPAMI.2007.70824			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617718				2022-12-18	WOS:000257504400008
J	Ben-Arie, J; Wang, ZQ; Pandit, P; Rajaram, S				Ben-Arie, J; Wang, ZQ; Pandit, P; Rajaram, S			Human activity recognition using multidimensional indexing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						human activity recognition; multidimensional indexing; sequence recognition; human body part tracking; EXpansion Matching (EXM)	TRACKING; MOTION; IMAGE	In this paper, we develop a novel method for view-based recognition of human action/activity from videos. By observing just a few frames, we can identify the activity that takes place in a video sequence. The basic idea of our method is that activities can be positively identified from a sparsely sampled sequence of a few body poses acquired from videos. In our approach, an activity is represented by a set of pose and velocity vectors for the major body parts (hands, legs, and torso) and stored in a set of multidimensional hash tables. We develop a theoretical foundation that shows that robust recognition of a sequence of body pose vectors can be achieved by a method of indexing and sequencing and it requires only a few pose vectors (i.e., sampled body poses in video frames). We find that the probability of false alarm drops exponentially with the increased number of sampled body poses. So, matching only a few body poses guarantees high probability for correct recognition. Our approach is parallel, i.e., all possible model activities are examined at one indexing operation since all of the model activities are stored in the same set of hash tables. In addition, our method is robust to partial occlusion since each body part is indexed separately. We use a sequence-based voting approach to recognize the activity invariant to the activity speed. Experiments performed with videos having eight different activities show robust recognition with our method. The method is also robust in conditions of varying view angle in the range of 30 degrees.	Univ Illinois, ECE Dept, Chicago, IL 60607 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Ben-Arie, J (corresponding author), Univ Illinois, ECE Dept, MC 154,851 S Morgan St, Chicago, IL 60607 USA.	benarie@ece.uic.edu; zwang@RCTanalytics.com; purvin@ieee.org; srajaram@ece.uic.edu						Barron C, 2000, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2000.855884; Ben-Arie J, 1993, IEEE T CIRC SYST VID, V3, P71, DOI 10.1109/76.180691; BENARIE J, 1994, MACH VISION APPL, V7, P69, DOI 10.1007/BF01215803; Bobick A, 1996, P 13 INT C PATT REC; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Di Bernardo E., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P622, DOI 10.1109/ICPR.1996.547021; FUJIYOSHI H, 1998, P WORKSH APPL COMP V; Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; La Cascia M, 1998, PROC CVPR IEEE, P508, DOI 10.1109/CVPR.1998.698653; LEUNG MK, 1995, IEEE T PATTERN ANAL, V17, P359, DOI 10.1109/34.385981; LIPTON A, 1998, P 1998 DARPA IM UND; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; MOON T.K., 2000, MATH METHODS ALGORIT; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; POLANA R, 1994, INT C PATT RECOG, P815, DOI 10.1109/ICPR.1994.576454; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; ROHR K, 1994, CVGIP IMAGE UNDERSTA, V59; Sawasaki N., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P478, DOI 10.1109/ICPR.1996.546993; SCHLENZIG J, 1994, P 28 AS C SIGN SYST; Wang ZQ, 1996, IEEE T PATTERN ANAL, V18, P1092, DOI 10.1109/34.544078; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161; YANG MH, 1999, P IEEE C COMP VIS PA, P466	28	148	153	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1091	1104		10.1109/TPAMI.2002.1023805	http://dx.doi.org/10.1109/TPAMI.2002.1023805			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100007
J	Jacobs, DW; Weinshall, D; Gdalyahu, Y				Jacobs, DW; Weinshall, D; Gdalyahu, Y			Classification with nonmetric distances: Image retrieval and class representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonmetric; image retrieval; classification; supervised learning; median; condensing; nearest-neighbor; triangle inequality; robust distance; representation	COMPUTER VISION; SIMILARITY; ALGORITHMS; NETWORKS; MOTION	One of the key problems in appearance-based vision is understanding how to use a set of labeled images to classify new images. Classification systems that can model human performance, or that use robust image matching methods, often make use of similarity judgments that are nonmetric; but when the triangle inequality is not obeyed, most existing pattern recognition techniques are not applicable. We note that exemplar-based (or nearest-neighbor) methods can be applied naturally when using a wide class of nonmetric similarity functions. The key issue, however, is to find methods for choosing good representatives of a class that accurately characterize it. We show that existing condensing techniques for finding class representatives are ill-suited to deal with nonmetric dataspaces. We then focus on developing techniques for solving this problem, emphasizing two points: First, we show that the distance between two images is not a good measure of how well one image can represent another in nonmetric spaces. Instead, we use the vector correlation between the distances from each image to other previously seen images. Second, we show that in nonmetric spaces, boundary points are less significant for capturing the structure of a class than they are in Euclidean spaces. We suggest that atypical points may be more important in describing classes. We demonstrate the importance of these ideas to learning that generalizes from experience by improving performance using both synthetic and real images. In addition, we suggest ways of applying parametric techniques to supervised learning problems that involve a specific nonmetric distance functions, showing in particular how to generalize the idea of linear discriminant functions in a way that may be more useful in nonmetric spaces.	NEC Res Inst, Princeton, NJ 08540 USA; Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel; IBM Res Corp, Haifa Lab, MATAM, Haifa, Israel	NEC Corporation; Hebrew University of Jerusalem; International Business Machines (IBM)	Jacobs, DW (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.	dwj@research.nj.nec.com; daphna@cs.huji.ac.il; yoramg@il.ibm.com						Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Blatt M, 1996, ADV NEUR IN, V8, P416; BRAND M, 1996, 406 MIT MED LAB; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COX I, 1996, P INT C PATT REC, V100, P361; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115, DOI 10.1109/TPAMI.1984.4767485; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; Graepel T, 1999, ADV NEUR IN, V11, P438; Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; HINTON GE, 1992, ADV NEUR IN, V4, P512; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Huttenlocher D. P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P93, DOI 10.1109/ICCV.1993.378231; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Kapur J., 1992, ENTROPY OPTIMIZATION; KLOCK H, 1997, P INT WORKSH EN MIN, P245; LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; Little RJA, 1987, STAT ANAL MISSING DA; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; ORNSTEIN LEONARD, 1965, J MOUNT SINAI HOSP, V32, P437; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Puzicha J., 1999, P IEEE INT C COMP VI, P1165, DOI DOI 10.1109/ICCV.1999.790412; Royden H.L., 1968, REAL ANAL; Santini S, 1996, PROC CVPR IEEE, P646, DOI 10.1109/CVPR.1996.517141; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; Williams P., 1997, THESIS YALE U; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; YOSHIDA K, 1982, IEEE T CONSUM ELECTR, V28, P202, DOI 10.1109/TCE.1982.353911	44	148	156	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					583	600		10.1109/34.862197	http://dx.doi.org/10.1109/34.862197			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700004
J	Elad, M; Feuer, A				Elad, M; Feuer, A			Super-resolution reconstruction of image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image restoration; super resolution; dynamic estimation; Kalman filter; adaptive filters; recursive least squares (RLS); least mean squares (LMS); steepest descent (SD)		In an earlier work, we have introduced the problem of reconstructing a super-resolution image sequence from a given low resolution sequence. We proposed two iterative algorithms, the R-SD and the R-LMS, to generate the desired image sequence. These algorithms assume the knowledge of the blur, the down-sampling, the sequences motion, and the measurements noise characteristics, and apply a sequential reconstruction process. It has been shown that the computational complexity of these two algorithms makes both of them practically applicable. In this paper, we rederive these algorithms as approximations of the Kalman filter and then carry out a thorough analysis of their performance. For each algorithm, we calculate a bound on its deviation from the Kalman filter performance. We also show that the propagated information matrix within the R-SD algorithm remains sparse in time, thus ensuring the applicability of this algorithm. To support these analytical results we present some computer simulations on synthetic sequences, which also show the computational feasibility of these algorithms.	Technion Israel Inst Technol, HP Labs Israel, IL-32000 Haifa, Israel; Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology; Technion Israel Institute of Technology	Elad, M (corresponding author), Technion Israel Inst Technol, HP Labs Israel, IL-32000 Haifa, Israel.	elad@hpli.hpl.hp.com; feuer@ee.technion.ac.il	, Miki/AAH-4640-2019					BERTSEKAS D, 1995, NONLINEAR PROGRAMMIN; CHEESEMAN P, 1994, FIA9412 NASA AM RES; CHUI CK, 1990, KLAMAN FILTERING; Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118; Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893; Hageman L.A., 1981, APPL ITERATIVE METHO; Haykin S., 1986, ADAPTIVE FILTER THEO; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; KATSAGGELOS AK, 1989, P SOC PHOTO-OPT INS, V1199, P61, DOI 10.1117/12.970019; Maybeck P. S., 1982, STOCHASTIC MODELS ES; PATTI AJ, 1994, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.1994.413332; PATTI T, 1991, P SPIE INT SOC OPTIC, V1903, P59; Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915; Shekarforoush H, 1996, INT J COMPUT VISION, V19, P289, DOI 10.1007/BF00055148	15	148	174	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					817	834		10.1109/34.790425	http://dx.doi.org/10.1109/34.790425			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600001
J	Neverova, N; Wolf, C; Taylor, G; Nebout, F				Neverova, Natalia; Wolf, Christian; Taylor, Graham; Nebout, Florian			ModDrop: Adaptive Multi-Modal Gesture Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gesture recognition; convolutional neural networks; multi-modal learning; deep learning	POSE; MODELS	We present a method for gesture detection and localisation based on multi-scale and multi-modal deep learning. Each visual modality captures spatial information at a particular spatial scale (such as motion of the upper body or a hand), and the whole system operates at three temporal scales. Key to our technique is a training strategy which exploits: i) careful initialization of individual modalities; and ii) gradual fusion involving random dropping of separate channels (dubbed ModDrop) for learning cross-modality correlations while preserving uniqueness of each modality-specific representation. We present experiments on the ChaLearn 2014 Looking at People Challenge gesture recognition track, in which we placed first out of 17 teams. Fusing multiple modalities at several spatial and temporal scales leads to a significant increase in recognition rates, allowing the model to compensate for errors of the individual classifiers as well as noise in the separate channels. Futhermore, the proposed ModDrop training technique ensures robustness of the classifier to missing signals in one or several channels to produce meaningful predictions from any number of available modalities. In addition, we demonstrate the applicability of the proposed fusion scheme to modalities of arbitrary nature by experiments on the same dataset augmented with audio.	[Neverova, Natalia; Wolf, Christian] INSA Lyon, LIRIS, UMR5205, F-69621 Villeurbanne, France; [Taylor, Graham] Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada; [Nebout, Florian] Awabot, Villeurbanne, Rhone Alpes, France	Institut National des Sciences Appliquees de Lyon - INSA Lyon; University of Guelph	Neverova, N (corresponding author), INSA Lyon, LIRIS, UMR5205, F-69621 Villeurbanne, France.	natalia.neverova@liris.cnrs.fr; christian.wolf@liris.cnrs.fr; gwtaylor@uoguelph.ca; florian.nebout@awabot.com						Alexandre LA, 2001, PATTERN RECOGN LETT, V22, P1283, DOI 10.1016/S0167-8655(01)00073-3; [Anonymous], 2014, 2 INT C LEARN REPR I; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Baccouche M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.124; Bach F.R., 2004, P 21 INT C MACH LEAR, P6, DOI DOI 10.1145/1015330.1015424; Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004; Bergstra J., 2010, P PYTH SCI COMP C SC, V4, P1, DOI DOI 10.25080/MAJORA-92BF1922-003; Camgoz N. C., 2014, EUR C COMP VIS, P579; Chang JY, 2014, WORKSH EUR C COMP VI, P503; Chen B., 2010, P NEUR INF PROC SYST; Chen G., 2014, P EUR C COMP VIS WOR, P608; Chen X, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2522848.2532591; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Couprie C., 2014, P INT C LEARN REPR; Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32; Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42; Fang GL, 2007, IEEE T SYST MAN CY A, V37, P1, DOI 10.1109/TSMCA.2006.886347; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1; Goodfellow I., 2013, ARXIV13024389V4; Hernandez-Vela A, 2014, PATTERN RECOGN LETT, V50, P112, DOI 10.1016/j.patrec.2013.09.009; Hinton G.E., 2012, ARXIV; Jain A, 2015, LECT NOTES COMPUT SC, V9004, P302, DOI 10.1007/978-3-319-16808-1_21; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kahou SE, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P543, DOI 10.1145/2522848.2531745; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee A., 2001, P EUR, P1691; Lehmann E. L., 1999, ELEMENTS LARGE SAMPL, P631; Monnier C, 2015, LECT NOTES COMPUT SC, V8925, P491, DOI 10.1007/978-3-319-16178-5_34; Nandakumar K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P475, DOI 10.1145/2522848.2532593; Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814; Neverova N, 2015, LECT NOTES COMPUT SC, V9005, P687, DOI 10.1007/978-3-319-16811-1_45; Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33; Neverova N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P484, DOI 10.1109/ICCVW.2013.69; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101; PENG X, 2014, WORKSH EUR C COMP VI, P518; Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40; Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145; Ranzato M.A., 2007, IEEE C COMP VIS PATT, P1; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simonyan K., 2014, ARXIV14062199V1; Srivastava N., 2013, NIPS, P2231; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490; Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wu D., 2014, COMP VIS ECCV 2014 W, P552; Wu ZX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P167, DOI 10.1145/2647868.2654931; Ye GN, 2012, PROC CVPR IEEE, P3021, DOI 10.1109/CVPR.2012.6248032; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137	64	147	154	1	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1692	1706		10.1109/TPAMI.2015.2461544	http://dx.doi.org/10.1109/TPAMI.2015.2461544			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO		Green Submitted			2022-12-18	WOS:000379926200016
J	Gillis, N; Vavasis, SA				Gillis, Nicolas; Vavasis, Stephen A.			Fast and Robust Recursive Algorithms for Separable Nonnegative Matrix Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonnegative matrix factorization; algorithms; separability; robustness; hyperspectral unmixing; linear mixing model; pure-pixel assumption	SPARSE; MODEL	In this paper, we study the nonnegative matrix factorization problem under the separability assumption ( that is, there exists a cone spanned by a small subset of the columns of the input nonnegative data matrix containing all columns), which is equivalent to the hyperspectral unmixing problem under the linear mixing model and the pure-pixel assumption. We present a family of fast recursive algorithms and prove they are robust under any small perturbations of the input data matrix. This family generalizes several existing hyperspectral unmixing algorithms and hence provides for the first time a theoretical justification of their better practical performance.	[Gillis, Nicolas] Univ Mons, Dept Math & Operat Res, Fac Polytech, B-7000 Mons, Hainaut, Belgium; [Vavasis, Stephen A.] Univ Waterloo, Dept Combinator & Optimizat, Waterloo, ON N2L 3G1, Canada	University of Mons; University of Waterloo	Gillis, N (corresponding author), Univ Mons, Dept Math & Operat Res, Fac Polytech, Rue Houdain 9, B-7000 Mons, Hainaut, Belgium.	nicolas.gillis@umons.ac.be; vavasis@math.uwaterloo.ca		Gillis, Nicolas/0000-0001-6423-6897	US Air Force Office of Scientific Research; Natural Sciences and Engineering Research Council (Canada)	US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); Natural Sciences and Engineering Research Council (Canada)(Natural Sciences and Engineering Research Council of Canada (NSERC))	The authors would like to thank the reviewers for their feedback which helped improve the paper significantly. This work was supported in part by a grant from the US Air Force Office of Scientific Research and a Discovery Grant from the Natural Sciences and Engineering Research Council (Canada).	Ambikapathi A, 2011, INT CONF ACOUST SPEE, P1369; Araujo MCU, 2001, CHEMOMETR INTELL LAB, V57, P65, DOI 10.1016/S0169-7439(01)00119-8; Arora S, 2012, STOC'12: PROCEEDINGS OF THE 2012 ACM SYMPOSIUM ON THEORY OF COMPUTING, P145; Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696; BITTORF V., 2012, P ADV NEURAL INFORM, V25, P1223; BOARDMAN JW, 1994, INT GEOSCI REMOTE SE, P2369, DOI 10.1109/IGARSS.1994.399740; Businger P., 1965, NUMER MATH, V7, P269, DOI DOI 10.1007/BF01436084; Chan TH, 2011, IEEE T GEOSCI REMOTE, V49, P4177, DOI 10.1109/TGRS.2011.2141672; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P2804, DOI 10.1109/TGRS.2006.881803; Civril A, 2013, ALGORITHMICA, V65, P159, DOI 10.1007/s00453-011-9582-6; Civril A, 2009, THEOR COMPUT SCI, V410, P4801, DOI 10.1016/j.tcs.2009.06.018; CRAIG MD, 1994, IEEE T GEOSCI REMOTE, V32, P542, DOI 10.1109/36.297973; Donoho D., 2003, P ADV NEUR INF PROC, V16; Elhamifar E., 2012, P IEEE C COMP VIS PA; Esser E, 2012, IEEE T IMAGE PROCESS, V21, P3239, DOI 10.1109/TIP.2012.2190081; Gillis N, 2013, SIAM J MATRIX ANAL A, V34, P1189, DOI 10.1137/120900629; Gillis N, 2012, J MACH LEARN RES, V13, P3349; Golub G. H., 1996, MATRIX COMPUTATION; Grant M., 2011, CVX MATLAB SOFTWARE; Hiriart-Urruty J. B., 2001, FUNDAMENTALS CONVEX; Juditsky A., 2008, ARXIV08090813V1; Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293; Ren H, 2003, IEEE T AERO ELEC SYS, V39, P1232, DOI 10.1109/TAES.2003.1261124; Sun YC, 2011, SIAM J SCI COMPUT, V33, P2063, DOI 10.1137/100788434; Thurau C, 2012, DATA MIN KNOWL DISC, V24, P325, DOI 10.1007/s10618-011-0216-z; Winter ME, 1999, P SOC PHOTO-OPT INS, V3753, P266, DOI 10.1117/12.366289; Wu CS, 2007, SCI TECHNOL WELD JOI, V12, P1, DOI 10.1179/174329307X160548; Zhang J, 2008, SENSORS-BASEL, V8, P1321, DOI 10.3390/s8021321	30	147	149	2	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					698	714		10.1109/TPAMI.2013.226	http://dx.doi.org/10.1109/TPAMI.2013.226			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353194	Green Submitted			2022-12-18	WOS:000334109000006
J	Wilson, RC; Hancock, ER; Luo, B				Wilson, RC; Hancock, ER; Luo, B			Pattern vectors from algebraic graph theory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph matching; graph features; spectral methods	EIGENVALUES; FRAMEWORK; ALGORITHM; SHAPE	Graphstructures have proven computationally cumbersome for pattern analysis. The reason for this is that, before graphs can be converted to pattern vectors, correspondences must be established between the nodes of structures which are potentially of different size. To overcome this problem, in this paper, we turn to the spectral decomposition of the Laplacian matrix. We show how the elements of the spectral matrix for the Laplacian can be used to construct symmetric polynomials that are permutation invariants. The coefficients of these polynomials can be used as graph features which can be encoded in a vectorial manner. We extend this representation to graphs in which there are unary attributes on the nodes and binary attributes on the edges by using the spectral decomposition of a Hermitian property matrix that can be viewed as a complex analogue of the Laplacian. To embed the graphs in a pattern space, we explore whether the vectors of invariants can be embedded in a low- dimensional space using a number of alternative strategies, including principal components analysis ( PCA), multidimensional scaling ( MDS), and locality preserving projection ( LPP). Experimentally, we demonstrate that the embeddings result in well- defined graph clusters. Our experiments with the spectral representation involve both synthetic and real- world data. The experiments with synthetic data demonstrate that the distances between spectral feature vectors can be used to discriminate between graphs on the basis of their structure. The real- world experiments show that the method can be used to locate clusters of graphs.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England; Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230039, Peoples R China	University of York - UK; Anhui University	Wilson, RC (corresponding author), Univ York, Dept Comp Sci, Heslington, York YO1 5DD, N Yorkshire, England.	wilson@cs.york.ac.uk; erh@cs.york.ac.uk; luobin@ahu.edu.cn	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008; Luo, Bin/Y-1233-2018	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028; Luo, Bin/0000-0001-5948-5055				Bagdanov AD, 2003, PATTERN RECOGN, V36, P1311, DOI 10.1016/S0031-3203(02)00227-3; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Biggs N, 1993, ALGEBRAIC GRAPH THEO, V2nd; BOTTI P, 1993, J GRAPH THEOR, V17, P467, DOI 10.1002/jgt.3190170404; Bunke H, 1999, PATTERN RECOGN LETT, V20, P1271, DOI 10.1016/S0167-8655(99)00094-X; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Chung F., 1997, AM MATH SOC, V92; Cox T.F., 1994, MULTIDIMENSIONAL SCA; Cvetkovic D. M., 1997, ENCY MATH ITS APPL, V66; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HE X, 2003, ADV NEURAL INFORMATI, V16; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kannan R, 2000, ANN IEEE SYMP FOUND, P367, DOI 10.1109/SFCS.2000.892125; KESSELMAN Y, 2003, P IEEE C COMP VIS PA, P850; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KOSINOV S, 2002, P JOINT IAPR INT WOR, P133; Lovasz L, 1993, BOLYAI MATH STUD, V1, P9; Luo B, 2001, PROC CVPR IEEE, P912; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; LUO B, 2002, INT J IMAGE GRAPHICS, V2, P247; MOHAR B, 1992, DISCRETE MATH, V109, P171, DOI 10.1016/0012-365X(92)90288-Q; Pavan M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P362; PERONA P, 1998, P EUR C COMP VIS, P655; Rizzi S, 1998, PATTERN RECOGN LETT, V19, P1293, DOI 10.1016/S0167-8655(98)00110-X; Robles-Kelly A, 2002, IMAGE VISION COMPUT, V20, P725, DOI 10.1016/S0262-8856(02)00062-8; ROBLESKELLY A, 2003, P 9 IEEE INT C COMP, V1, P127; ROWEIS S, 2002, SCIENCE, V299, P2323; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; SCOTT JS, 1990, J MED VIROL, V30, P103, DOI 10.1002/jmv.1890300205; SEGEN J, 1988, P 5 INT C MACH LEARN, P29; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TORSELLO A, 2001, P 4 INT WORKSH VIS F, P594; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Wyk BJ, 2003, PATTERN RECOGN, V36, P2019, DOI 10.1016/S0031-3203(03)00009-8; WONG AKC, 1990, SYNTACTIC STRUCTURAL	40	147	153	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1112	1124		10.1109/TPAMI.2005.145	http://dx.doi.org/10.1109/TPAMI.2005.145			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013758	Green Submitted, Green Accepted			2022-12-18	WOS:000229024300010
J	Wixson, L				Wixson, L			Detecting salient motion by accumulating directionally-consistent flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion defection; optical flow; vegetation; motion salience	IMAGE SEQUENCES	Motion detection can play an important role in many Vision tasks. Yet image motion can arise from "uninteresting" events as well as interesting ones. In this paper, salient motion is defined as motion that is likely to result from a typical surveillance target (e.g.. a person or vehicle traveling with a sense of direction through a scene) as opposed to other distracting motions (e.g., the scintillation of specularities on water, the oscillation of vegetation in the wind). We propose an algorithm for detecting this salient motion that is based on intermediate-stage vision integration of optical flow. Empirical results are presented that illustrate the applicability of the preposed methods to real-world video. Unlike many motion detection schemes. no knowledge about expected object size or shape is necessary for rejecting the distracting motion.	ParentWatch Inc, New York, NY 10018 USA		Wixson, L (corresponding author), ParentWatch Inc, 49 West 37th St, New York, NY 10018 USA.							ANDERSON C, 1985, SPIE INTELLIGENT ROB, V579, P72; Bergen J.R., 1992, P EUR C COMP VIS; BOULT T, 1998, P DARPA IM UND WORKS; BURT PJ, 1989, P IEEE WORKSH MOT MA; COLLINS R, 1997, IEEE C COMP VIS PATT; Craig JJ., 2018, INTRO ROBOTICS MECH; Crimson W., 1998, P IEEE C COMP VIS PA; CUTLER R, 1998, P INT C PATT REC; DONOHOE GW, 1988, P INT C AC SPEECH SI, P1084; EVELAND C, 1998, P IEEE C COMP VIS PA; FUA P, 1993, MACHINE VISION APPL, V6; HALEVI G, 1997, P IEEE C COMP VIS PA; HSU YZ, 1984, COMPUT VISION GRAPH, V26, P73, DOI 10.1016/0734-189X(84)90131-2; KAHN P, 1985, IEEE T PATTERN ANAL, V7, P402, DOI 10.1109/TPAMI.1985.4767679; KAHN P, 1988, P IEEE C COMP VIS PA; KARMANN KP, 1990, P SIGNAL PROCESSING, P951; Letang J. M., 1993, P INT C COMP VIS; Lipton A., 1998, P WORKSH APPL COMP V; LITTLE JJ, 1990, P EUR C COMP VIS; LIU F, 1998, P INT C COMP VIS; LUCAS BD, 1981, P DARPA IM UND WORKS; MEYER F, 1994, CVGIP IMAGE UNDERSTA, V60; NIYOGI SA, 1994, P IEEE C COMP VIS PA; PLESS R, 1999, IEEE C COMP VIS PATT; RIDDER C, 1995, P INT C REC ADV MECH, P193; SKIFSTAD K, 1989, COMPUT VISION GRAPH, V46, P387, DOI 10.1016/0734-189X(89)90039-X; TODOROVIC P, 1992, PROBABILITY ITS APPL; WEBER J, 1993, P INT C COMP VIS; WILDES R, 1998, P DARPA IM UND WORKS; WILDES RP, 1998, P IEEE INT C IM PROC; WILLIAMS L, 1998, P EUR C COMP VIS; Wolberg G., 1992, DIGITAL IMAGE WARPIN; Wren Christopher Richard, 1997, IEEE T PATTERN ANAL, V19; YALAMANCHILI S, 1982, COMPUT VISION GRAPH, V18, P188, DOI 10.1016/0146-664X(82)90171-X	34	147	175	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					774	780		10.1109/34.868680	http://dx.doi.org/10.1109/34.868680			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN		Green Published			2022-12-18	WOS:000089321500005
J	Cross, ADJ; Hancock, ER				Cross, ADJ; Hancock, ER			Graph matching with a dual-step EM algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EM algorithm; graph-matching; affine geometry; perspective geometry; relational constraints; Delaunay graph; discrete relaxation	DELAUNAY TRIANGULATION; WEAK-PERSPECTIVE; SHAPE MODELS; POINT; POSE; RECOGNITION; IMAGES; PARAPERSPECTIVE; REPRESENTATION; PATTERNS	This paper describes a new approach to matching geometric structure in 2D point-sets. The novel feature is to unify the tasks of estimating transformation geometry and identifying point-correspondence matches. Unification is realized by constructing a mixture model over the bipartite graph representing the correspondence match and by affecting optimization using the EM algorithm. According to our EM framework, the probabilities of structural correspondence gate contributions to the expected likelihood function used to estimate maximum likelihood transformation parameters. These gating probabilities measure the consistency of the matched neighborhoods in the graphs. The recovery of transformational geometry and hard correspondence matches are interleaved and are realized by applying coupled update operations to the expected log-likelihood function. In this way, the two processes bootstrap one another. This provides a means of rejecting structural outliers. We evaluate the technique on two real-world problems. The first involves the matching of different perspective views of 3.5-inch floppy discs. The second example is furnished by the matching of a digital map against aerial images that are subject to severe barrel distortion due to a line-scan sampling process. We complement these experiments with a sensitivity study based on synthetic data.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England	University of York - UK	Cross, ADJ (corresponding author), Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England.	adjc@minster.york.ac.uk; erh@minster.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				AHUJA N, 1985, COMPUT VISION GRAPH, V29, P286, DOI 10.1016/0734-189X(85)90126-4; AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; ALTER TD, 1994, IEEE T PATTERN ANAL, V16, P802, DOI 10.1109/34.308475; Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; BEARDSLEY PA, 1994, P 3 EUR C COMP VIS, P85; BOISSONNAT JD, 1984, ACM T GRAPHIC, V3, P266, DOI 10.1145/357346.357349; COOTES TF, 1995, IMAGE VISION COMPUT, V13, P403, DOI 10.1016/0262-8856(95)99727-I; Cross ADJ, 1998, ADV NEUR IN, V10, P780; DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; FAUGERAS OD, 1990, ARTIF INTELL, V44, P41, DOI 10.1016/0004-3702(90)90098-K; Finch AM, 1998, NEURAL COMPUT, V10, P1873, DOI 10.1162/089976698300017188; Gold S, 1996, NEURAL COMPUT, V8, P787, DOI 10.1162/neco.1996.8.4.787; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; HEMPEL F, 1986, ROBUST STAT APPROACH; Horaud R, 1997, INT J COMPUT VISION, V22, P173, DOI 10.1023/A:1007940112931; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; Jacobs D. W., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P269, DOI 10.1109/CVPR.1991.139700; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; McReynolds DP, 1996, IEEE T PATTERN ANAL, V18, P1174, DOI 10.1109/34.546255; Moss S, 1997, IMAGE VISION COMPUT, V15, P637, DOI 10.1016/S0262-8856(97)00014-0; Oberkampf D, 1996, COMPUT VIS IMAGE UND, V63, P495, DOI 10.1006/cviu.1996.0037; OGAWA H, 1986, PATTERN RECOGN, V19, P35, DOI 10.1016/0031-3203(86)90029-4; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; Pollefeys M, 1997, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.1997.609357; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; SHAPIRO LS, 1995, PHILOS T ROY SOC A, V350, P403; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; TUCERYAN M, 1991, PATTERN RECOGN, V24, P361, DOI 10.1016/0031-3203(91)90050-F; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; UMEYAMA S, 1993, IEEE T PATTERN ANAL, V15, P136, DOI 10.1109/34.192485; UTANS J, 1993, TR93004 ICSI BERK; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; Wilson RC, 1998, COMPUT VIS IMAGE UND, V72, P21, DOI 10.1006/cviu.1997.0656	45	147	154	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1236	1253		10.1109/34.730557	http://dx.doi.org/10.1109/34.730557			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX		Green Accepted, Green Submitted			2022-12-18	WOS:000076990100009
J	CHING, JY; WONG, AKC; CHAN, KCC				CHING, JY; WONG, AKC; CHAN, KCC			CLASS-DEPENDENT DISCRETIZATION FOR INDUCTIVE LEARNING FROM CONTINUOUS AND MIXED-MODE DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						INDUCTIVE LEARNING; CLASSIFICATION; DISCRETIZATION; CONTINUOUS ATTRIBUTES; MIXED-MODE ATTRIBUTES; MAXIMUM ENTROPY; MUTUAL INFORMATION; UNCERTAINTY	GENERATION; INFERENCE	Inductive learning systems can be effectively used to acquire classification knowledge from examples. Many existing symbolic learning algorithms can be applied in domains with continuous attributes when integrated with a discretization algorithm to transform the continuous attributes into ordered discrete ones. In this paper, a new information theoretic discretization method optimized for supervised learning is proposed and described. This approach seeks to maximize the mutual dependence as measured by the interdependence redundancy between the discrete intervals and the class labels, and can automatically determine the most preferred number of intervals for an inductive learning application. The method has been tested in a number of inductive learning examples to show that the class-dependent discretizer can significantly improve the classification performance of many existing learning algorithms in domains containing numeric attributes.	HONG KONG POLYTECH UNIV,DEPT COMP,KOWLOON,HONG KONG; UNIV WESTERN ONTARIO,LONDON,ON N6A 3K7,CANADA	Hong Kong Polytechnic University; Western University (University of Western Ontario)	CHING, JY (corresponding author), UNIV WATERLOO,INST COMP RES,DEPT SYST DESIGN ENGN,PATTERN ANAL & MACHINE INTELLIGENCE LAB,WATERLOO,ON N2L 3G1,CANADA.			Keith, Chan/0000-0001-7296-873X; Chan, Keith C C/0000-0003-1709-2637				BRATKO I, 1987, INTERACTIONS ARTIFIC; CAELLI T, 1993, PATTERN RECOGN, V26, P733, DOI 10.1016/0031-3203(93)90126-H; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Chan K. C. C., 1991, Knowledge discovery in databases, P107; CHAN KCC, 1990, COMPUTATIONAL INTELL, V6; CHAN KCC, 1992, 5TH P IEEE COMP BAS; CHAN KCC, 1992, P C ARTIFICIAL INTEL; CHING JY, 1992, THESIS U WATERLOO CA; Duda R.O., 1973, J ROYAL STAT SOC SER; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176; Hartigan J.A., 1975, CLUSTERING ALGORITHM; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349, DOI 10.1109/TPAMI.1980.4767034; MICHALSKI RS, 1986, IUUCDCSR861260 U ILL; MICHALSKI RS, 1993, MACHINE LEARNING, V1; MURPHY PM, 1991, UCI REPOSITORY MACHI; Niblett T., 1987, PROGR MACHINE LEARNI; NIBLETT T, 1987, PROGR MACHINE LEARNI; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan R., 1987, APPL EXPERT SYSTEMS, P157; REAVEN GM, 1979, DIABETOLOGIA, V16, P17, DOI 10.1007/BF00423145; STASHUK DW, 1992, IEEE T BIOMEDICA JUN; WONG AKC, 1987, PATTERN RECOGN, V20, P245, DOI 10.1016/0031-3203(87)90058-6; WONG AKC, 1975, IEEE T COMPUT, VC 24, P158, DOI 10.1109/T-C.1975.224183; WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796, DOI 10.1109/TPAMI.1987.4767986	26	147	163	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					641	651		10.1109/34.391407	http://dx.doi.org/10.1109/34.391407			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400001
J	BARSHAN, B; KUC, R				BARSHAN, B; KUC, R			DIFFERENTIATING SONAR REFLECTIONS FROM CORNERS AND PLANES BY EMPLOYING AN INTELLIGENT SENSOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BARSHAN, B (corresponding author), YALE UNIV,DEPT ELECT ENGN,INTELLIGENT SENSORS LAB,NEW HAVEN,CT 06520, USA.			Barshan, Billur/0000-0001-6783-6572				BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; CROWLEY JL, 1985, IEEE T ROBOTIC AUTOM, P128; ELFES A, 1987, P IEEE C DECISION CO; JOHNSON LW, 1982, NUMERICAL ANAL, P518; KRIEGMAN D, 1987, IEEE T ROBOTIC AUTOM, P402; KUC R, 1987, IEEE T PATTERN ANAL, V9, P766, DOI 10.1109/TPAMI.1987.4767983; KUC R, 1986, P INT C INTELLIGENT; KUC R, 1989, IEEE INT C ROB AUT, P1422; MORAVEC HP, 1986, IEEE J ROBOTIC AUTOM, P116; Morse P. M., 1968, THEORETICAL ACOUSTIC; SCHWARTZ M, 1975, SIGNAL PROCESSING DI; TACHI S, 1984, 2ND P INT S ROB KYOT; WEAST RC, 1973, CRC HDB CHEM PHYSICS, pE49; Wells P N T, 1977, BIOMEDICAL ULTRASONI; 1982, ULTRASONIC RANGE FIN	15	147	150	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					560	569		10.1109/34.56192	http://dx.doi.org/10.1109/34.56192			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300005
J	Hu, J; Shen, L; Albanie, S; Sun, G; Wu, EH				Hu, Jie; Shen, Li; Albanie, Samuel; Sun, Gang; Wu, Enhua			Squeeze-and-Excitation Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Squeeze-and-excitation; image representations; attention; convolutional neural networks	VISUAL-ATTENTION; MODEL	The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the "Squeeze-and-Excitation" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251 percent, surpassing the winning entry of 2016 by a relative improvement of similar to 25 percent. Models and code are available at https://github.com/hujie-frank/SENet.	[Hu, Jie; Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China; [Hu, Jie; Wu, Enhua] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Hu, Jie; Sun, Gang] Momenta, Dongsheng Plaza A,8 Zhongguancun East Rd, Beijing 100083, Peoples R China; [Wu, Enhua] Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China; [Wu, Enhua] Univ Macau, AI Ctr, Taipa, Macao, Peoples R China; [Sun, Gang] Chinese Acad Sci, Inst Automat, LIAMA NLPR, Beijing 100190, Peoples R China; [Shen, Li; Albanie, Samuel] Univ Oxford, Visual Geometry Grp, Oxford OX1 2JD, England	Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of Macau; University of Macau; Chinese Academy of Sciences; Institute of Automation, CAS; University of Oxford	Shen, L (corresponding author), Univ Oxford, Visual Geometry Grp, Oxford OX1 2JD, England.	hujie@ios.ac.cn; lishen@robots.ox.ac.uk; albanie@robots.ox.ac.uk; sungang@momenta.ai; ehwu@umac.mo	Albanie, Samuel/AAC-9729-2020	Albanie, Samuel/0000-0003-1732-9198	NSFC [61632003, 61620106003, 61672502, 61571439]; National Key R&D Program of China [2017YFB1002701]; Macao FDCT Grant [068/2015/A2]; EPSRC AIMS CDT [EP/L015897/1]	NSFC(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; Macao FDCT Grant; EPSRC AIMS CDT(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank Chao Li and Guangyuan Wang from Momenta for their contributions in the training system optimisation and experiments on CIFAR dataset. We would also like to thank Andrew Zisserman, Aravindh Mahendran and Andrea Vedaldi for many helpful discussions. The work is supported in part by NSFC Grants (61632003, 61620106003, 61672502, 61571439), National Key R&D Program of China (2017YFB1002701), and Macao FDCT Grant (068/2015/A2). Samuel Albanie is supported by EPSRC AIMS CDT EP/L015897/1.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Baker B., 2018, P INT C LEARN REPR W; Baker Bowen, 2017, ICLR; Bayer J, 2009, LECT NOTES COMPUT SC, V5769, P755, DOI 10.1007/978-3-642-04277-5_76; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bluche Thdodore, 2016, ADV NEURAL INFORM PR, P838, DOI DOI 10.5555/3157096.3157190; Brock A., 2018, ICLR, P1; Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Chen Y, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1467, DOI 10.1109/ICISCE.2017.306; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367; Cubuk Ekin D, 2018, P IEEE C COMP VIS PA; Elsken Thomas, 2019, INT C LEARN REPR; Gastaldi Xavier, 2017, ARXIV170507485; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Howard A.G., 2017, MOBILENETS EFFICIENT; Hu JS, 2018, IEEE ICC; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Ioannou Y, 2017, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2017.633; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Larochelle H., 2010, ADV NEURAL INFORM PR, P1243; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Li WC, 2017, INT CONF ACOUST SPEE, P3156, DOI 10.1109/ICASSP.2017.7952738; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C., 2018, P EUR C COMP VIS ECC, P19, DOI DOI 10.1007/978-3-030-01246-5_2; Liu Hanxiao, 2018, ICLR; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12; Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241; Miech Antoine, 2017, P IEEE C COMP VIS PA; MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379; Mnih V, 2014, ADV NEUR IN, V27; Morcos A. S., 2018, ICLR POSTER; Nair V, 2010, P 27 INT C MACHINE L, P807; Negrinho R., 2017, ARXIV170408792; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700; Pham H, 2018, PR MACH LEARN RES, V80; Real E., 2018, ARXIV180201548, DOI [DOI 10.1609/AAAI.V33I01.33014780, 10.1609/aaai.v33i01.33014780]; Real E, 2017, PR MACH LEARN RES, V70; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Santurkar S., 2018, STATISTICS, P2483; Shen L., 2016, PLACES401 PLACES365; Shen L, 2016, LECT NOTES COMPUT SC, V9911, P467, DOI 10.1007/978-3-319-46478-7_29; Shen L, 2015, IEEE T IMAGE PROCESS, V24, P3109, DOI 10.1109/TIP.2015.2438548; Srivastava Rupesh Kumar, 2015, ADV NEURAL INFORM PR, P2377; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu X, 2015, IEEE ICC, P2048, DOI 10.1109/ICC.2015.7248627; Yang J, 2009, INT C INTEL HUM MACH, P343, DOI 10.1109/IHMSC.2009.94; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	84	146	147	178	336	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					2011	2023		10.1109/TPAMI.2019.2913372	http://dx.doi.org/10.1109/TPAMI.2019.2913372			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR		Green Submitted			2022-12-18	WOS:000545415400015
J	Haines, TSF; Xiang, T				Haines, Tom S. F.; Xiang, Tao			Background Subtraction with Dirichlet Process Mixture Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Background subtraction; Dirichlet processes; non-parametric Bayesian methods; confidence capping; video analysis	DENSITY-ESTIMATION; VIDEO	Video analysis often begins with background subtraction. This problem is often approached in two steps-a background model followed by a regularisation scheme. A model of the background allows it to be distinguished on a per-pixel basis from the foreground, whilst the regularisation combines information from adjacent pixels. We present a new method based on Dirichlet process Gaussian mixture models, which are used to estimate per-pixel background distributions. It is followed by probabilistic regularisation. Using a non-parametric Bayesian method allows per-pixel mode counts to be automatically inferred, avoiding over-/under-fitting. We also develop novel model learning algorithms for continuous update of the model in a principled fashion as the scene changes. These key advantages enable us to outperform the state-of-the-art alternatives on four benchmarks.	[Haines, Tom S. F.] UCL, Dept Comp Sci, London WC1E 6BT, England; [Xiang, Tao] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; University College London; University of London; Queen Mary University London	Haines, TSF (corresponding author), UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.	thaines@cs.ucl.ac.uk; txiang@eecs.qmul.ac.uk		Haines, Tom/0000-0002-7181-3223	EPSRC [EP/G063974/1]; Engineering and Physical Sciences Research Council [EP/G063974/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Both authors are funded by EPSRC under the EP/G063974/1 grant.	Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brutzer S., 2011, P IEEE C COMP VIS PA; Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886; Cohen S, 2005, IEEE I CONF COMP VIS, P1034; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Cui X., 2012, P 12 EUR C COMP VIS; Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861; Elqursh A., 2012, P 12 EUR C COMP VIS; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Evangelio R. H., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P71, DOI 10.1109/AVSS.2011.6027297; Evangelio RH, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P300, DOI 10.1109/AVSS.2012.69; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Gelman A., 2004, BAYESIAN DATA ANAL, V2nd, DOI DOI 10.1007/S13398-014-0173-7.2; Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919; Haines T.S.F., 2012, P 12 EUR C COMP VIS; Harville M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P90, DOI 10.1109/ICIP.2001.958058; Harwood D., 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48; He J., 2012, P IEEE C COMP VIS PA; He Y, 2011, PROC SPIE, V8009, DOI 10.1117/12.896509; Hernandez-Lopez F., MACHINE VISION UNPUB; Herrero S, 2009, LECT NOTES COMPUT SC, V5807, P33; Karaman M, 2005, PROC SPIE, V5960, P2140, DOI 10.1117/12.633437; Kato J, 2002, IEEE T PATTERN ANAL, V24, P1291, DOI 10.1109/TPAMI.2002.1033221; Kim K, 2004, IEEE IMAGE PROC, P3061; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102; Li L., 2003, P 11 ACM INT C MULT, P2, DOI DOI 10.1145/957013.957017; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5; Maddalena L., 2012, PROC IEEE COMPUT SOC, P21; Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285; Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8; Migdal J., 2005, P 7 IEEE WORKSH APPL, P58, DOI DOI 10.1109/ACVM0T.2005.33; Morde A., 2012, P IEEE COMP SOC C CO, P15; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Parks Donovan H., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P192, DOI 10.1109/AVSS.2008.19; Salmon J. K., 2011, SC 11 P 2011 INT C H, P1, DOI [10.1145/2063384.2063405, DOI 10.1145/2063384.2063405]; Schick A., 2012, IEEE COMP SOC C COMP, P27; Seidel F., 2013, PROST SMOOTHED UNPUB; Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213; Stauffer C., 1999, IEEE COMP SOC C COMP, V2, P637; Teh Y. W., 2010, HIERARCHICAL BAYESIA; Tiefenbacher P, 2012, P IEEE COMP SOC C CO, P38, DOI DOI 10.1109/CVPRW.2012.6238925; Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228; Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005	47	146	153	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					670	683		10.1109/TPAMI.2013.239	http://dx.doi.org/10.1109/TPAMI.2013.239			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353192	Green Submitted, Green Published			2022-12-18	WOS:000334109000004
J	Vu, HH; Labatut, P; Pons, JP; Keriven, R				Hoang-Hiep Vu; Labatut, Patrick; Pons, Jean-Philippe; Keriven, Renaud			High Accuracy and Visibility-Consistent Dense Multiview Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dense multiview stereo; surface reconstruction; large-scale scenes; minimum s-t cut; deformable mesh	SURFACE RECONSTRUCTION; ROBUST; SHAPE	Since the initial comparison of Seitz et al. [48], the accuracy of dense multiview stereovision methods has been increasing steadily. A number of limitations, however, make most of these methods not suitable to outdoor scenes taken under uncontrolled imaging conditions. The present work consists of a complete dense multiview stereo pipeline which circumvents these limitations, being able to handle large-scale scenes without sacrificing accuracy. Highly detailed reconstructions are produced within very reasonable time thanks to two key stages in our pipeline: a minimum s-t cut optimization over an adaptive domain that robustly and efficiently filters a quasidense point cloud from outliers and reconstructs an initial surface by integrating visibility constraints, followed by a mesh-based variational refinement that captures small details, smartly handling photo-consistency, regularization, and adaptive resolution. The pipeline has been tested over a wide range of scenes: from classic compact objects taken in a laboratory setting, to outdoor architectural scenes, landscapes, and cultural heritage sites. The accuracy of its reconstructions has also been measured on the dense multiview benchmark proposed by Strecha et al. [59], showing the results to compare more than favorably with the current state-of-the-art methods.	[Hoang-Hiep Vu] Univ Paris Est, Ecole Ponts ParisTech, IMAGINE CSTB, F-77455 Champs Sur Marne 2, Marne La Vallee, France; [Labatut, Patrick] Nokia, F-75005 Paris, France; [Pons, Jean-Philippe; Keriven, Renaud] Acute3D Ctr Int Commun, F-06560 Sophia Antipolis, France	Ecole des Ponts ParisTech; Universite Gustave-Eiffel; Nokia Corporation	Vu, HH (corresponding author), Univ Paris Est, Ecole Ponts ParisTech, IMAGINE CSTB, 19 Rue Alfred Nobel Cite Descartes, F-77455 Champs Sur Marne 2, Marne La Vallee, France.	hoang.vu@polytechnique.org; patrick.labatut@normalesup.org; jean-philippe.pons@acute3D.com; renaud.keriven@acute3D.com						Agarwal  S., 2009, P 12 IEEE INT C COMP; Banno A, 2008, INT J COMPUT VISION, V78, P207, DOI 10.1007/s11263-007-0104-6; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov Y., 2006, P BRIT MACH VIS C, V3, P1149; BRADLEY D, 2008, P IEEE C COMP VIS PA; Broadhurst A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P388, DOI 10.1109/ICCV.2001.937544; Campbell Neill D. F., 2008, ECCV; Delaunoy A., 2008, P 19 BRIT MACH VIS C; Duan Y, 2004, LECT NOTES COMPUT SC, V3023, P238; Eckstein Ilya, 2007, P 5 EUR S GEOM PROC, P183; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Ford L. R. J., 1962, FLOWS NETWORKS; Frahm J.-M., 2010, P EUR C COMP VIS; Furukawa Y., 2010, P IEEE C COMP VIS PA; Furukawa Y., 2008, P IEEE C COMP VIS PA; Furukawa Y, 2006, LECT NOTES COMPUT SC, V3951, P564; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Yasutaka, 2007, P IEEE C COMP VIS PA; Gargallo P, 2005, PROC CVPR IEEE, P885; Giesen Joachim, 2006, EFFECTIVE COMPUTATIO, P231, DOI DOI 10.1007/978-3-540-33259-6_6; GOESELE, 2006, P IEEE COMP SOC C CO, V2, P2402; Goesele M., 2007, P IEEE INT C COMP VI; Hartley R., 2004, ROBOTICA; Hernandez C., 2007, P IEEE C COMP VIS PA; Hornung A., 2006, P EUR C COMP VIS; Hornung A., 2006, COMP VIS PATT REC 20, V1, P503, DOI 10.1109/CVPR.2006.135; Jancosek M., 2009, P IEEE INT WORKSH 3D; Jancosek M., 2009, P COMP VIS WINT WORK; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kobbelt L., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P105, DOI 10.1145/280814.280831; Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Labatut P, 2009, COMPUT GRAPH FORUM, V28, P2275, DOI 10.1111/j.1467-8659.2009.01530.x; Labatut P., 2007, P IEEE INT C COMP VI; Labatut P., 2009, P IEEE INT WORKSH 3D; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lempitsky V, 2006, LECT NOTES COMPUT SC, V3953, P226, DOI 10.1007/11744078_18; Lempitsky V., 2007, P IEEE C COMP VIS PA; Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44; MERRELL P, 2007, P IEEE INT C COMP VI; POLLEFEYS M., 2007, P IEEE INT C COMP VI; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Salman N., 2009, P INT WORKSH REPR MO; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; Slabaugh G, 2005, PROC CVPR IEEE, P84; Snavely N., 2008, P IEEE C COMP VIS PA; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Starck Jonathan, 2006, P BRIT MACH VIS C, P1189; Strecha C, 2004, PROC CVPR IEEE, P552; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; Strecha C., 2008, P IEEE C COMP VIS PA; Strecha C., 2006, COMP VIS PATT REC 20, P2394, DOI [DOI 10.1109/CVPR.2006.78, 10.1109/CVPR.2006.78]; Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473; Tran S, 2006, LECT NOTES COMPUT SC, V3952, P219; Tylecek R., 2010, INT J VIRTUAL REAL, V9, P45; Tylecek R., 2009, P COMP VIS WINT WORK; VOGIATZIS, 2005, P IEEE COMP SOC C CO, V2, P391; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; VU H, 2009, P IEEE C COMP VIS PA; Yang RG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P576, DOI 10.1109/ICCV.2003.1238399; Yang RG, 2003, PROC CVPR IEEE, P211, DOI 10.1109/ISCS.2003.1239980; Yu T., 2006, P IEEE C COMP VIS PA, V2, P2269; Yvinec, 2000, P 16 ANN S COMP GEOM, P11, DOI DOI 10.1145/336154.336165; Zach C., 2007, P IEEE INT C COMP VI; Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166	71	146	165	4	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					889	901		10.1109/TPAMI.2011.172	http://dx.doi.org/10.1109/TPAMI.2011.172			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21844631				2022-12-18	WOS:000301747400005
J	Kim, J; Choi, J; Yi, J; Turk, M				Kim, J; Choi, J; Yi, J; Turk, M			Effective representation using ICA for face recognition robust to local distortion and partial occlusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; part-based local representation; ICA; LS-ICA		The performance of face recognition methods using subspace projection is directly related to the characteristics of their basis images, especially in the cases of local distortion or partial occlusion. In order for a subspace projection method to be robust to local distortion and partial occlusion, the basis images generated by the method should exhibit a part-based local representation. We propose an effective part-based local representation method named locally salient ICA (LS-ICA) method for face recognition that is robust to local distortion and partial occlusion. The LS-ICA method only employs locally salient information from important facial parts in order to maximize the benefit of applying the idea of "recognition by parts." It creates part-based local basis images by imposing additional localization constraint in the process of computing ICA architecture I basis images. We have contrasted the LS-ICA method with other part-based representations such as LNMF (Localized Nonnegative Matrix Factorization) and LFA (Local Feature Analysis). Experimental results show that the LS-ICA method performs better than PCA, ICA architecture I, ICA architecture II, LFA, and LNMF methods, especially in the cases of partial occlusions and local distortions.	Sungkyunkwan Univ, Sch Informat & Commun Engn, Biometr Engn Res Ctr, Suwon, South Korea; Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA	Sungkyunkwan University (SKKU); University of California System; University of California Santa Barbara	Kim, J (corresponding author), Sungkyunkwan Univ, Sch Informat & Commun Engn, Biometr Engn Res Ctr, Suwon, South Korea.	jskim@ece.skku.ac.kr; jmchoi@ece.skku.ac.kr; jhyi@ece.skku.ac.kr; mturk@cs.ucsb.edu						Bartlett M. S., 2001, FACE IMAGE ANAL UNSU; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; BELHUMEUR P, 1999, IEEE PAMI, V19, P711; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8; Hyvarinen A, 1999, NEURAL PROCESS LETT, V10, P1, DOI 10.1023/A:1018647011077; Hyvarinen A., 1999, INDEPENDENT COMPONEN; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Li SZ, 2001, PROC CVPR IEEE, P207; MARTINEZ AM, 1998, CVC TECH; Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WILD S, 2003, P 8 SIM C APPL LIN A	15	146	159	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1977	1981		10.1109/TPAMI.2005.242	http://dx.doi.org/10.1109/TPAMI.2005.242			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355663	Green Submitted			2022-12-18	WOS:000232532600011
J	Sawhney, HS; Kumar, R				Sawhney, HS; Kumar, R			True multi-image alignment and its application to mosaicing and lens distortion correction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image sequence analysis; video mosaics; lens distortion correction	OPTICAL-FLOW; RECONSTRUCTION	Multiple images of a scene are related through 2D/3D view transformations and linear and non-linear camera transformations. In the traditional techniques to compute these transformations, especially the ones relying on direct intensity gradients, one image and its coordinate system have been assumed to be ideal and distortion free. in this paper, we present an algorithm for true multi-image alignment that does not rely on the measurements of a reference image being distortion free. The algorithm is developed to specifically align and mosaic images using parametric transformations in the presence of lens distortion. When lens distortion is present, none of the images can be assumed to be ideal. In our formulation, all the images are modeled as intensity measurements represented in their respective coordinate systems. each of which is related to an ideal coordinate system through an interior camera transformation and an exterior View transformation. The goal of the accompanying algorithm is to compute an image in the ideal coordinate system while solving for the transformations that relate the ideal system with each of the data images. Key advantages of the technique presented in this paper are: (i) no reliance on one distortion free image, (ii) ability to register images and compute coordinate transformations even when the multiple images are of an extended scene with no overlap between the first and last frame of the sequence, and (iii) ability to handle linear and nonlinear transformations within the same framework. Results of applying the algorithm are presented for the correction of lens distortion, and creation of video mosaics.	Sarnoff Corp, Princeton, NJ 08530 USA	Sarnoff Corporation	Sawhney, HS (corresponding author), Sarnoff Corp, CN5300, Princeton, NJ 08530 USA.	hsawhney@sarnoff.com; rkumar@sarnoff.com						AYER S, 1995, P INT C COMP VIS, P777; BERGEN JR, 1992, P EUR C COMP VIS, P237; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; HANNA KJ, 1993, P INT C COMP VIS, P357, DOI DOI 10.1109/ICCV.1993.378192; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HSU S, 1994, INT C PATT RECOG, P743, DOI 10.1109/ICPR.1994.576427; HSU S, 1998, WACV 98 PRINC NJ OCT, P154; IRANI M, 1995, P 5 INT C COMP VIS, P605; IRANI M, 1992, ECCV, P282; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; KUMAR R, 1995, P IEEE WORKSH REPR V; MANN S, 1994, ICIP; PELEG S, 1997, CVPR, P338; SAWHNEY H, 1994, P INT C PATT REC, pA403; Sawhney H. S., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P583, DOI 10.1109/ICCV.1995.466886; SAWHNEY HS, 1998, ECCV, P103; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; SHUM H, 1998, P INT C COMP VIS; Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387; SZELISKI R, 1994, IEEE WORKSH APPL COM, P44; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; ZHANG Z, 1996, P INT C PATT REC, V1, P407	24	146	176	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					235	243		10.1109/34.754589	http://dx.doi.org/10.1109/34.754589			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000005
J	Caselles, V; Kimmel, R; Sapiro, G				Caselles, V; Kimmel, R; Sapiro, G			Minimal surfaces based object segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D segmentation; minimal surfaces; deformable models; mean curvature motion; medical images	ACTIVE CONTOUR MODELS; PLANE-CURVES; 3-D IMAGES; LEVEL; DEFORMATIONS; PROPAGATION; BALLOONS; SHAPE; SPACE	A geometric approach for 3D object segmentation and representation is presented. The segmentation is obtained by deformable surfaces moving towards the objects to be detected in the 3D image. The model is based on curvature motion and the computation of surfaces with minimal areas, better known as minimal surfaces. The space where the surfaces are computed is induced from the 3D image (volumetric data) in which the objects are to be detected. The model links between classical deformable surfaces obtained via energy minimization, and intrinsic ones derived from curvature based flows. The new approach is stable, robust, and automatically handles changes in the surface topology during the deformation.	UNIV CALIF BERKELEY, LAWRENCE BERKELEY LAB, BERKELEY, CA 94720 USA; HEWLETT PACKARD CORP, PALO ALTO, CA 94304 USA	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; University of California System; University of California Berkeley; Hewlett-Packard	Caselles, V (corresponding author), UNIV ILLES BALEARS, DEPT MATH & INFORMAT, E-07071 PALMA DE MALLORCA, SPAIN.		Sbert, Catalina/K-8768-2014	Sbert, Catalina/0000-0003-1219-4474				ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; ALVAREZ L, 1993, ARCHITECTURE RATIONA, V123; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, IN PRESS SIAM J APPL; Caselles V., 1995, IEEE INT C COMP VIS, P694; CASELLES V, 1995, MINIMAL SURFACES 3 D; CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; COHEN LD, 1996, IN PRESS P CVPR 96; Fua P., 1990, Machine Vision and Applications, V3, P45, DOI 10.1007/BF01211451; GAGE M, 1986, J DIFFER GEOM, V23, P69; GRAYSON MA, 1987, J DIFFER GEOM, V26, P285; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; KICHENASSAMY S, IN PRESS ARCH RATION; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MALLADI R, 1996, P MATH METH BIOM IM; MCINERNEY T, 1995, P 5 INT C COMP VIS I, P840; OLVER PJ, IN PRESS SIAM J APPL; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osserman R., 1986, SURVEY MINIMAL SURFA; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; SAPIRO G, 1995, P SPIE VISION GEOMET; Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P82, DOI 10.1109/CVPR.1993.340975; TEK H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P156, DOI 10.1109/ICCV.1995.466792; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; WHITAKER RT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P822, DOI 10.1109/ICCV.1995.466853; YEZZI A, IN PRESS IEEE T MED; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909; [No title captured]	36	146	152	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					394	398		10.1109/34.588023	http://dx.doi.org/10.1109/34.588023			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200009
J	UCHIYAMA, T; ARBIB, MA				UCHIYAMA, T; ARBIB, MA			COLOR IMAGE SEGMENTATION USING COMPETITIVE LEARNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							PICTURE SEGMENTATION; ALGORITHM	This paper presents a color image segmentation method which divides color space into clusters. Competitive learning is used as a tool for clustering color space based on the least sum of squares criterion. We show that competitive learning converges to approximate the optimum solution based on this criterion theoretically and experimentally. We applied this method to various color scenes and show its efficiency as a color image segmentation method. We also show the effects of using different color coordinates to be clustered by some experimental results.	UNIV SO CALIF,CTR NEURAL ENGN,LOS ANGELES,CA 90089	University of Southern California	UCHIYAMA, T (corresponding author), NTT DATA COMMUN SYST CORP,SAIWAI KU,66-2 HORIKAWA CHO,KAWASAKI,KANAGAWA 210,JAPAN.							ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BRYANT J, 1979, PATTERN RECOGN, V11, P115, DOI 10.1016/0031-3203(79)90057-8; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; FUKADA Y, 1980, PATTERN RECOGN, V12, P395, DOI 10.1016/0031-3203(80)90015-1; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HERTZ JA, 1991, INTRO THEORY NEURAL, P222; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; ISMAIL MA, 1989, PATTERN RECOGN, V22, P75, DOI 10.1016/0031-3203(89)90040-X; KOSKO B, 1991, IEEE T NEURAL NETWOR, V2, P522, DOI 10.1109/72.134289; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PRATT WK, 1991, DIGITAL IMAGE PROCES, P62; RISEMAN EM, 1977, COMPUT VISION GRAPH, V6, P221, DOI 10.1016/S0146-664X(77)80028-2; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478; SPATH H, 1980, CLUSTER ANAL ALGORIT, P59; TOMINAGA S, 1992, COLOR RES APPL, V17, P230, DOI 10.1002/col.5080170405; UCHIYAMA T, 1991, P SPIE SPSES ELECTRO; ZHANG QW, 1991, PATTERN RECOGN, V24, P835, DOI 10.1016/0031-3203(91)90003-N	25	146	152	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1197	1206		10.1109/34.387488	http://dx.doi.org/10.1109/34.387488			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500004
J	CHOU, PA				CHOU, PA			OPTIMAL PARTITIONING FOR CLASSIFICATION AND REGRESSION TREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CLUSTERING; DECISION TREES; INFORMATION DIVERGENCE; TEXT-TO-SPEECH	DECISION TREES; VECTOR QUANTIZATION; INFORMATION-THEORY; DESIGN; RECOGNITION; CONVERSION; ALGORITHM; TABLES	In designing a decision tree for classification or regression, one selects at each node a feature to be tested, and partitions the range of that feature into a small number of bins, each bin corresponding to a child of the node. When the feature's range is discrete with N unordered outcomes, the optimal partition, that is, the partition minimizing an expected loss, is usually found by an exhaustive search through all possible partitions. Since the number of possible partitions grows exponentially in N, this approach is impractical when N is larger than about 10 or 20. In this paper, we present an iterative algorithm that finds a locally optimal partition for an arbitrary loss function, in time linear in N for each iteration. The algorithm is a K-means like clustering algorithm that uses as its distance measure a generalization of Kullback's information divergence. Moreover, we prove that the globally optimal partition must satisfy a nearest neighbor condition using divergence as the distance measure. These results generalize similar results of Breiman et al. to an arbitrary number of classes or regression variables and to an arbitrary number of bins. We also provide experimental results on a text-to-speech example, and we suggest additional applications of the algorithm, including the design of variable combinations, surrogate splits, composite nodes, and decision graphs.	STANFORD UNIV, DEPT ELECT ENGN, STANFORD, CA 94305 USA	Stanford University	CHOU, PA (corresponding author), XEROX CORP, PALO ALTO RES CTR, PALO ALTO, CA 94304 USA.							BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bayes A. J., 1973, Australian Computer Journal, V5, P77; BECKER MH, 1989, STATISTICAL SOFTWARE; Becker R.A., 1988, PACKAGE MAPS; BRANDMAN Y, 1987, CSLTR87325 COMP SYST; BURSHTEIN D, 1989, IBM RC14754 TEC REP; BURSHTEIN D, 1989, UNPUB ANN STAT   AUG; BUZO A, 1980, IEEE T ACOUST SPEECH, V28, P562, DOI 10.1109/TASSP.1980.1163445; CHENG J, 1988, 5TH P INT C MACH LEA, P100; CHOU P, 1990, JAN P INT S INF THEO; CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498; CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124; CHOU PA, 1988, THESIS STANFORD U ST; Clark P., 1989, Machine Learning, V3, P261, DOI 10.1007/BF00116835; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Duda R.O., 1973, J ROYAL STAT SOC SER; EGLER JF, 1963, COMMUN ACM, V6, P510, DOI 10.1145/367593.367595; EQUITZ W, 1987, APR P INT C AC SPEEC; FIELDING A, 1977, EXPLORING DATA STRUC, V1, P221; FISHER WD, 1958, J AM STAT ASSOC, V53, P789, DOI 10.2307/2281952; FORGY EW, 1965, BIOMETRICS, V21, P768; GANAPATHY S, 1973, COMMUN ACM, V16, P532, DOI 10.1145/362342.362348; Garey M.R., 1979, COMPUTERS INTRACTABI; Gray Jr A. H., 1976, LINEAR PREDICTION SP; GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421; GRAY RM, 1981, IEEE T INFORM THEORY, V27, P708, DOI 10.1109/TIT.1981.1056410; GRAY RM, 1985, IST8509860 APPLICATI; HARTMANN CRP, 1982, IEEE T INFORM THEORY, V28, P565, DOI 10.1109/TIT.1982.1056522; HENRICHON JEG, 1969, IEEE T COMPUT, V18, P604; Hunt E., 1966, EXPT INDUCTION; Hyafil L., 1976, Information Processing Letters, V5, P15, DOI 10.1016/0020-0190(76)90095-8; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Knuth D. E., 1971, Acta Informatica, V1, P14, DOI 10.1007/BF00264289; KULLBACK S, 1959, INFORMATION THEORY S; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; LUCASSEN JM, 1984, MAR P INT C AC SPEEC; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; MARTELLI A, 1978, COMMUN ACM, V21, P1025, DOI 10.1145/359657.359664; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; Mingers J., 1989, Machine Learning, V3, P319, DOI 10.1007/BF00116837; MONTALBANO M, 1962, IBM SYST J, V1, P51, DOI 10.1147/sj.11.0051; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P1414, DOI 10.1109/TASSP.1985.1164728; Olshen R., 1984, CLASSIFICATION REGRE; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905, DOI 10.1109/TC.1977.1674938; PAYNE RW, 1980, J ROY STAT SOC A STA, V143, P253, DOI 10.2307/2982129; POLLACK SL, 1965, COMMUN ACM, V8, P677, DOI 10.1145/365660.365681; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Quinlan J.R., 1986, MACH LEARN ARTIF INT, V2, P149; QUINLAN JR, 1989, INFORM COMPUT, V80, P227, DOI 10.1016/0890-5401(89)90010-2; QUINLAN JR, 1979, HPP7914 STANF U TECH; REINWALD LT, 1967, J ACM, V14, P742, DOI 10.1145/321420.321433; RISSANEN J, 1986, IEEE T INFORM THEORY, V32, P526, DOI 10.1109/TIT.1986.1057210; SCHUMACHER H, 1976, COMMUN ACM, V19, P343, DOI 10.1145/360238.360245; SEJNOWSKI TJ, 1987, COMPLEX SYST, V1, P144; SETHI IK, 1977, PATTERN RECOGN, V9, P197, DOI 10.1016/0031-3203(77)90004-8; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441, DOI 10.1109/TPAMI.1982.4767278; SHORE JE, 1982, IEEE T PATTERN ANAL, V4, P11, DOI 10.1109/TPAMI.1982.4767189; SHWAYDER K, 1971, COMMUN ACM, V14, P69, DOI 10.1145/362515.362518; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972; WEISS SM, 1987, P 6 NAT C ART INT SE, P521; WONG DY, 1982, IEEE T ACOUST SPEECH, V30, P770, DOI 10.1109/TASSP.1982.1163960	65	146	161	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					340	354		10.1109/34.88569	http://dx.doi.org/10.1109/34.88569			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600004
J	WINDHAM, MP				WINDHAM, MP			CLUSTER VALIDITY FOR THE FUZZY C-MEANS CLUSTERING-ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WINDHAM, MP (corresponding author), UTAH STATE UNIV,DEPT MATH,LOGAN,UT 84322, USA.							Anderson E., 1935, B AM IRIS SOC, V59, P2; Bezdek J.C., 1973, FUZZY MATH PATTERN C; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964; BEZDEK JC, 1973, J CYERBNETICS, V3, P58; BEZDEK JC, 1975, 8 INT C NUM TAX SAN, P143; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046; WINDHAM MP, 1981, FUZZY SET SYST, V5, P177, DOI 10.1016/0165-0114(81)90015-4; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	9	146	156	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					357	363		10.1109/TPAMI.1982.4767266	http://dx.doi.org/10.1109/TPAMI.1982.4767266			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869049				2022-12-18	WOS:A1982NT73500001
J	Tang, P; Wang, XG; Bai, S; Shen, W; Bai, X; Liu, WY; Yuille, A				Tang, Peng; Wang, Xinggang; Bai, Song; Shen, Wei; Bai, Xiang; Liu, Wenyu; Yuille, Alan			PCL: Proposal Cluster Learning for Weakly Supervised Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Proposals; Training; Streaming media; Detectors; Object detection; Electronic mail; Convolutional neural networks; Object detection; weakly supervised learning; convolutional neural network; multiple instance learning; proposal cluster	CONVOLUTIONAL NETWORKS; LOCALIZATION	Weakly Supervised Object Detection (WSOD), using only image-level annotations to train object detectors, is of growing importance in object recognition. In this paper, we propose a novel deep network for WSOD. Unlike previous networks that transfer the object detection problem to an image classification problem using Multiple Instance Learning (MIL), our strategy generates proposal clusters to learn refined instance classifiers by an iterative process. The proposals in the same cluster are spatially adjacent and associated with the same object. This prevents the network from concentrating too much on parts of objects instead of whole objects. We first show that instances can be assigned object or background labels directly based on proposal clusters for instance classifier refinement, and then show that treating each cluster as a small new bag yields fewer ambiguities than the directly assigning label method. The iterative instance classifier refinement is implemented online using multiple streams in convolutional neural networks, where the first is an MIL network and the others are for instance classifier refinement supervised by the preceding one. Experiments are conducted on the PASCAL VOC, ImageNet detection, and MS-COCO benchmarks for WSOD. Results show that our method outperforms the previous state of the art significantly.	[Tang, Peng; Wang, Xinggang; Bai, Xiang; Liu, Wenyu] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China; [Bai, Song] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England; [Shen, Wei] Shanghai Univ, Sch Commun & Informat Engn, Shanghai Inst Adv Commun & Data Sci, Key Lab Specialty Fiber Opt & Opt Access Network, Shanghai 200444, Peoples R China; [Yuille, Alan] Johns Hopkins Univ, Dept Cognit Sci, Baltimore, MD 21218 USA; [Yuille, Alan] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Huazhong University of Science & Technology; University of Oxford; Shanghai University; Johns Hopkins University; Johns Hopkins University	Wang, XG (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.	pengtang@hust.edu.cn; xgwang@hust.edu.cn; songbai.site@gmail.com; shenwei1231@gmail.com; xbai@hust.edu.cn; liuwy@hust.edu.cn; alan.l.yuille@gmail.com	Liu, Wenyu/AAG-1426-2019	Liu, Wenyu/0000-0002-4582-7488; Yuille, Alan L./0000-0001-5207-9249; Wang, Xinggang/0000-0001-6732-7823	NSFC [61733007, 61572207, 61876212, 61672336]; ONR [N00014-15-1-2356]; Hubei Scientific and Technical Innovation Key Project; National Program for Support of Topnotch Young Professionals; Program for HUST Academic Frontier Youth Team	NSFC(National Natural Science Foundation of China (NSFC)); ONR(Office of Naval Research); Hubei Scientific and Technical Innovation Key Project; National Program for Support of Topnotch Young Professionals; Program for HUST Academic Frontier Youth Team	This work was supported by NSFC (No. 61733007, No. 61572207, No. 61876212, No. 61672336), ONR with grant N00014-15-1-2356, Hubei Scientific and Technical Innovation Key Project, the National Program for Support of Topnotch Young Professionals, and the Program for HUST Academic Frontier Youth Team.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrews S., 2003, ADV NEURAL INFORM PR, P577; [Anonymous], 2015, ICLR; [Anonymous], 2017, P IEEE INT C COMP VI; [Anonymous], P INT C LEARN REPR W; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shi ZY, 2015, IEEE T PATTERN ANAL, V37, P1959, DOI 10.1109/TPAMI.2015.2392769; Simonyan K, 2015, 3 INT C LEARN REPR I; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Song X, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1637, DOI 10.1109/ICMA.2014.6885945; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Tang P, 2017, PATTERN RECOGN, V71, P446, DOI 10.1016/j.patcog.2017.05.001; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; Wang XG, 2018, PATTERN RECOGN, V74, P15, DOI 10.1016/j.patcog.2017.08.026; Wang XG, 2015, IEEE I CONF COMP VIS, P1224, DOI 10.1109/ICCV.2015.145; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Zhang C, 2006, ADV NEURAL INFORM PR, P1417; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhang XL, 2018, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2018.00144; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609; Zhou K, 2016, DESTECH TRANS COMP; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	61	145	148	12	100	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					176	191		10.1109/TPAMI.2018.2876304	http://dx.doi.org/10.1109/TPAMI.2018.2876304			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30334780	Green Submitted			2022-12-18	WOS:000502294300014
J	Wang, TQ; Gong, SG; Zhu, XT; Wang, SJ				Wang, Taiqing; Gong, Shaogang; Zhu, Xiatian; Wang, Shengjin			Person Re-Identification by Discriminative Selection in Video Ranking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Person re-identification; sequence matching; discriminative selection; multi-instance ranking; video ranking	RECOGNITION	Current person re-identification (ReID) methods typically rely on single-frame imagery features, whilst ignoring space-time information from image sequences often available in the practical surveillance scenarios. Single-frame (single-shot) based visual appearance matching is inherently limited for person ReID in public spaces due to the challenging visual ambiguity and uncertainty arising from non-overlapping camera views where viewing condition changes can cause significant people appearance variations. In this work, we present a novel model to automatically select the most discriminative video fragments from noisy/incomplete image sequences of people from which reliable space-time and appearance features can be computed, whilst simultaneously learning a video ranking function for person ReID. Using the PRID2011, iLIDS-VID, and HDA+ image sequence datasets, we extensively conducted comparative evaluations to demonstrate the advantages of the proposed model over contemporary gait recognition, holistic image sequence matching and state-of-the-art single-/multi-shot ReID methods.	[Wang, Taiqing; Wang, Shengjin] Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing, Peoples R China; [Gong, Shaogang; Zhu, Xiatian] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England	Tsinghua University; University of London; Queen Mary University London	Wang, TQ (corresponding author), Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing, Peoples R China.	wangtq09@mails.tsinghua.edu.cn; s.gong@qmul.ac.uk; xiatian.zhu@qmul.ac.uk; wgsgj@tsinghua.edu.cn	Zhu, Xiatian/Y-1601-2019	Zhu, Xiatian/0000-0002-9284-2955	National Science and Technology Grant [2013BAK02B04]; Tsinghua Initiative Scientific Research Grant [20141081253]; EPSRC [EP/E028594/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/E028594/1] Funding Source: researchfish	National Science and Technology Grant; Tsinghua Initiative Scientific Research Grant; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We shall thank Dario Figueira of IST for providing the HDA+ dataset and for assisting in extracting the person bounding boxes; Martin Hirzer, Peter Roth and Csaba Beleznai of AIT for providing the raw videos of PRID2011. S. Gong and S. Wang are corresponding authors. This work was partially supported by National Science and Technology Grant No. 2013BAK02B04 and Tsinghua Initiative Scientific Research Grant No. 20141081253.	Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027; Bedagkar-Gala A, 2012, PATTERN RECOGN LETT, V33, P1908, DOI 10.1016/j.patrec.2011.09.005; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Bergeron C., 2008, P 25 INT C MACH LEAR, P48; Bergeron C, 2012, IEEE T PATTERN ANAL, V34, P1068, DOI 10.1109/TPAMI.2011.194; Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779; Cancela B., 2014, P BRIT MACH VIS C, P1; Chapelle O, 2010, INFORM RETRIEVAL, V13, P201, DOI 10.1007/s10791-009-9109-9; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Figueira D., 2014, ECCV; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Gilbert A, 2009, IEEE I CONF COMP VIS, P925, DOI 10.1109/ICCV.2009.5459335; Gong DNT, 2009, LECT NOTES COMPUT SC, V5716, P179, DOI 10.1007/978-3-642-04146-4_21; Gong SG, 2011, VISUAL ANALYSIS OF BEHAVIOUR: FROM PIXELS TO SEMANTICS, P1, DOI 10.1007/978-0-85729-670-2; Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1; Gray D., 2007, IEEE INT WORKSH PERF, V3, P1; Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9; Hu Y, 2008, PROC CVPR IEEE, P85; John V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.55; Kanaujia A., 2007, P IEEE C COMP VIS PA, P1; Karaman S, 2012, LECT NOTES COMPUT SC, V7583, P443, DOI 10.1007/978-3-642-33863-2_44; Ke Y, 2010, INT J COMPUT VISION, V88, P339, DOI 10.1007/s11263-009-0308-z; Klaser Alexander, 2008, BMVC; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461; Li YL, 2015, PATTERN RECOGN, V48, P3542, DOI 10.1016/j.patcog.2015.04.018; Lin Z, 2009, IEEE I CONF COMP VIS, P444; LIU C, 2012, LECT NOTES COMPUT SC, P391; Liu CX, 2014, PATTERN RECOGN, V47, P1602, DOI 10.1016/j.patcog.2013.11.001; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Martin-Felez R, 2012, LECT NOTES COMPUT SC, V7572, P328, DOI 10.1007/978-3-642-33718-5_24; Nakajima C, 2003, PATTERN RECOGN, V36, P1997, DOI 10.1016/S0031-3203(03)00061-X; Nixon M.S., 2010, HUMAN IDENTIFICATION, V4; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Rabiner L R, 1993, FUNDAMENTALS SPEECH, V14; Sapienza M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.123; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Scovanner P., 2007, ACM MM, P357; Simonnet D, 2012, LECT NOTES COMPUT SC, V7583, P423, DOI 10.1007/978-3-642-33863-2_42; Sobral A., 2013, P 9 WORKSH VIS COMP; UK Home Office, 2008, I LIDS MULT CAM TRAC; Wang H, 2009, J OPTOELECTRON BIOME, V1, P1; Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45; WATERS RL, 1972, J ANAT, V111, P191; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Xu YL, 2013, IEEE I CONF COMP VIS, P3152, DOI 10.1109/ICCV.2013.391; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23	62	145	151	2	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2501	2514		10.1109/TPAMI.2016.2522418	http://dx.doi.org/10.1109/TPAMI.2016.2522418			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26829777	Green Submitted			2022-12-18	WOS:000387984700012
J	Ge, TZ; He, KM; Ke, QF; Sun, J				Ge, Tiezheng; He, Kaiming; Ke, Qifa; Sun, Jian			Optimized Product Quantization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vector quantization; nearest neighbor search; image retrieval; compact encoding; inverted indexing	SCENE	Product quantization (PQ) is an effective vector quantization method. A product quantizer can generate an exponentially large codebook at very low memory/time cost. The essence of PQ is to decompose the high-dimensional vector space into the Cartesian product of subspaces and then quantize these subspaces separately. The optimal space decomposition is important for the PQ performance, but still remains an unaddressed issue. In this paper, we optimize PQ by minimizing quantization distortions w.r.t the space decomposition and the quantization codebooks. We present two novel solutions to this challenging optimization problem. The first solution iteratively solves two simpler sub-problems. The second solution is based on a Gaussian assumption and provides theoretical analysis of the optimality. We evaluate our optimized product quantizers in three applications: (i) compact encoding for exhaustive ranking [ 1], (ii) building inverted multi-indexing for non-exhaustive search [ 2], and (iii) compacting image representations for image retrieval [ 3]. In all applications our optimized product quantizers outperform existing solutions.	[Ge, Tiezheng] Univ Sci & Technol China, Hefei 230026, Peoples R China; [He, Kaiming; Sun, Jian] Microsoft Res Asia, Visual Comp Grp, Beijing, Peoples R China; [Ke, Qifa] Microsoft Bing, Sunnyvale, CA USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Microsoft; Microsoft Research Asia	Ge, TZ (corresponding author), Univ Sci & Technol China, Hefei 230026, Peoples R China.	getzh@mail.ustc.edu.cn; kahe@microsoft.com; qke@microsoft.com; jiansun@microsoft.com						Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; Boiman O., 2008, P IEEE C COMP VIS PA; Brandt J., 2010, P IEEE C COMP VIS PA; Cauchy AL, 1821, COURS ANAL ECOLE ROY; Cover T., 1991, ELEMENTS INFORM THEO, V13, P348; Dong W., 2008, P 31 ANN INT ACM SIG; Ge T., 2013, P IEEE C COMP VIS PA; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gordo A, 2014, IEEE T PATTERN ANAL, V36, P33, DOI 10.1109/TPAMI.2013.101; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; He K., 2013, P IEEE C COMP VIS PA; Horn R.A., 1990, MATRIX ANAL, V7, P478; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Li W.-J., 2012, P ADV NEUR INF PROC, P1646; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Mertens S., 2006, COMPUTATIONAL COMPLE, V125; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Norouzi M., 2013, P IEEE C COMP VIS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perronnin F, 2007, P IEEE C COMP VIS PA; Sandhawalia H, 2010, INT CONF ACOUST SPEE, P1242, DOI 10.1109/ICASSP.2010.5495403; SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Weiss Y., 2008, ADV NEURAL INFORM PR, V21, P1753; Weiss Y., 2012, P 12 EUR C COMP VIS; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1	34	145	155	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					744	755		10.1109/TPAMI.2013.240	http://dx.doi.org/10.1109/TPAMI.2013.240			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353197	Green Submitted			2022-12-18	WOS:000334109000009
J	Salakhutdinov, R; Tenenbaum, JB; Torralba, A				Salakhutdinov, Ruslan; Tenenbaum, Joshua B.; Torralba, Antonio			Learning with Hierarchical-Deep Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep networks; deep Boltzmann machines; hierarchical Bayesian models; one-shot learning	OBJECT	We introduce HD (or "Hierarchical-Deep") models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.	[Salakhutdinov, Ruslan] Univ Toronto, Dept Stat & Comp Sci, Toronto, ON M5S 3G3, Canada; [Tenenbaum, Joshua B.] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA; [Torralba, Antonio] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	University of Toronto; Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Salakhutdinov, R (corresponding author), Univ Toronto, Dept Stat & Comp Sci, Toronto, ON M5S 3G3, Canada.	rsalakhu@utstat.toronto.edu; jbt@mit.edu; torralba@mit.edu			NSERC; ONR (MURI) [1015GNA126]; ONR [N00014-07-1-0937]; ARO [W911NF-08-1-0242]; Qualcomm	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); ONR (MURI)(MURIOffice of Naval Research); ONR(Office of Naval Research); ARO; Qualcomm	This research was supported by NSERC, ONR (MURI Grant 1015GNA126), ONR N00014-07-1-0937, ARO W911NF-08-1-0242, and Qualcomm.	[Anonymous], 2010, BAYESIAN NONPARAMETR; Babenko B., 2009, P IEEE INT C COMP VI; Bart E, 2005, PROC CVPR IEEE, P672; Barthe E, 2009, POLICE PRACT RES, V10, P255, DOI 10.1080/15614260802381067; Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Canini K.R., 2009, P NIPS WORKSH NONP B; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen B., 2011, P 28 INT C MACH LEAR, P361; Coates A., 2011, P 11 INT C DOC AN RE; Courville A., 2011, P 28 INT C MACH LEAR, P1145; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P448; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kemp C., 2006, DEVELOPMENTAL SCI, V10, P307; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Lake B., 2011, P ANN M COGN SCI SOC; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin Y., 2011, P ADV NEUR INF PROC, V23; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, P ADV NEUR INF PROC, V21; Perfors A. Perfors, 2009, P 31 ANN C COGN SCI, P136; Ranzato M.A., 2008, P ADV NEUR INF PROC; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rodriguez A, 2008, J AM STAT ASSOC, V103, P1131, DOI 10.1198/016214508000000553; Salakhutdinov R. R., 2010, P ADV NEUR INF PROC, V22; Salakhutdinov R.R., 2009, P INT C ART INT STAT, V12; Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403; Socher R., 2011, P 28 INT C INT C MAC, P129; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Taylor G., 2006, P ADV NEUR INF PROC; Taylor G.W., 2010, P 11 EUR C COMP VIS; Teh Y.W., 2001, P ADV NEUR INF PROC, V13; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torralba A, 2006, LECT NOTES COMPUT SC, V4170, P345; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L., 2000, CONVERGENCE MARKOVIA; Yuille A.L., 2004, P ADV NEUR INF PROC	44	145	151	0	111	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1958	1971		10.1109/TPAMI.2012.269	http://dx.doi.org/10.1109/TPAMI.2012.269			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787346	Green Submitted			2022-12-18	WOS:000320381400011
J	Hadjidemetriou, E; Grossberg, MD; Nayar, SK				Hadjidemetriou, E; Grossberg, MD; Nayar, SK			Multiresolution histograms and their use for recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiresolution histogram; scale-space; image sharpness; Fisher information; shape feature; texture feature; histogram matching; histogram bin width; feature parameter sensitivity; feature comparison	TEXTURE CLASSIFICATION; ENTROPY; SCALE; COLOR; SEGMENTATION	The histogram of image intensities is used extensively for recognition and for retrieval of images and video from visual databases. A single image histogram, however, suffers from the inability to encode spatial image variation. An obvious way to extend this feature is to compute the histograms of multiple resolutions of an image to form a multiresolution histogram. The multiresolution histogram shares many desirable properties with the plain histogram including that they are both fast to compute, space efficient, invariant to rigid motions, and robust to noise. In addition, the multiresolution histogram directly encodes spatial information. We describe a simple yet novel matching algorithm based on the multiresolution histogram that uses the differences between histograms of consecutive image resolutions. We evaluate it against five widely used image features. We show that with our simple feature we achieve or exceed the performance obtained with more complicated features. Further, we show our algorithm to be the most efficient and robust.	Yale Univ, Sch Med, Yale Image Proc & Anal Grp, Dept Diagnost Radiol, New Haven, CT 06520 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Yale University; Columbia University	Hadjidemetriou, E (corresponding author), Yale Univ, Sch Med, Yale Image Proc & Anal Grp, Dept Diagnost Radiol, Brady Mem Lab Room 332,310 Cedar St,POB 208042, New Haven, CT 06520 USA.	stathis@noodle.med.yale.edu; mdog@cs.columbia.edu; nayar@columbia.edu	Hadjidemetriou, Stathis/B-8283-2009					[Anonymous], 1985, GM RES LABS TECHN PU; Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785; Ballard D. H., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P2, DOI 10.1109/WQV.1993.262955; BARRON AR, 1986, ANN PROBAB, V14, P336, DOI 10.1214/aop/1176992632; BLACHMAN NM, 1965, IEEE T INFORM THEORY, V11, P267, DOI 10.1109/TIT.1965.1053768; BONET JD, 1997, P SIGGRAPH 97, P361; BONET JD, 1998, P SPIE, V3370; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; CARLEN EA, 1991, COMMUN MATH PHYS, V140, P339, DOI 10.1007/BF02099503; CARLOTTO M, 1984, P INT JAP C PATT REC, P93; CARLOTTO MJ, 1987, IEEE T PATTERN ANAL, V9, P121, DOI 10.1109/TPAMI.1987.4767877; CHANG T, 1993, IEEE T IMAGE PROCESS, V4, P863; COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; DEVROYE L, 1985, NONPARAMETRIC DENSIT; Engel J, 1997, METRIKA, V46, P41, DOI 10.1007/BF02717165; EVANS AC, 1993, P 4 BRIT MACH VIS C, P429; Faugeras O. D., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P549; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; GREENSPAN H, 1994, INT C PATT RECOG, P162, DOI 10.1109/ICPR.1994.576896; Griffin LD, 1997, IMAGE VISION COMPUT, V15, P369, DOI 10.1016/S0262-8856(97)87979-6; Hadjidemetriou E, 2001, PROC CVPR IEEE, P702; Hadjidemetriou E, 2001, INT J COMPUT VISION, V45, P5, DOI 10.1023/A:1012356022268; Hadjidemetriou E, 2002, USE HISTOGRAMS RECOG; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Heeger D.J., 1995, P 22 ANN C COMP GRAP, P229, DOI DOI 10.1145/218380.218446; Helstrom C.W., 1991, PROBABILITY STOCHAST, V2rd; Hsu W., 1995, P ACM MULT, P305; Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226; Huet B, 1999, IEEE T PATTERN ANAL, V21, P1363, DOI 10.1109/34.817414; JAGERSAND M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P195, DOI 10.1109/ICCV.1995.466786; Jain AK, 1997, PATTERN RECOGN, V30, P295, DOI 10.1016/S0031-3203(96)00068-4; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Johnson O, 2000, STOCH PROC APPL, V88, P291, DOI 10.1016/S0304-4149(00)00006-5; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; LAKSHMANAN S, 1993, MARKOV RANDOM FIELDS, P131; LEE JW, 1994, P SOC PHOTO-OPT INS, V2185, P162, DOI 10.1117/12.171773; Leow WK, 2001, PROC CVPR IEEE, P234; LOWITZ GE, 1983, PATTERN RECOGN, V16, P141, DOI 10.1016/0031-3203(83)90017-1; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MANTHALKAR R, 2002, P 2 INT WORKSH TEXT, P87; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Noble B., 1988, APPL LINEAR ALGEBRA; OOMES A, 1996, P COP WORKSH GAUSS S, V96, P48; Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008; Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125; Pennini F, 1997, PHYSICA A, V247, P559, DOI 10.1016/S0378-4371(97)00395-6; Plastino A, 1997, PHYSICA A, V235, P577, DOI 10.1016/S0378-4371(96)00386-X; POPOVIC M, 1999, P IEEE TELSIKS, P149; PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910; Puzicha J, 1999, PATTERN RECOGN LETT, V20, P899, DOI 10.1016/S0167-8655(99)00056-2; Ravela S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P608, DOI 10.1109/ICCV.1998.710780; Rubner Y., 1997, P ARPA IM UND WORKSH; SABLAK S, 1999, P IASTED INT C SIGN; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605; Smith J., 1996, P SOC PHOTO-OPT INS, V2670, P1630; Sporring J, 1999, IEEE T INFORM THEORY, V45, P1051, DOI 10.1109/18.761342; SPORRING J, 2000, P ICIP, V1, P920; Stam A. J., 1959, INFORM CONTROL, V2, P101, DOI DOI 10.1016/S0019-9958(59)90348-1; Stricker M, 1996, P SOC PHOTO-OPT INS, V2670, P29, DOI 10.1117/12.234802; STRICKER M, 1995, P SOC PHOTO-OPT INS, V2420, P381; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tanaka M, 1999, P SOC PHOTO-OPT INS, V3811, P273, DOI 10.1117/12.364102; TAYLOR CC, 1987, BIOMETRIKA, V74, P636, DOI 10.2307/2336704; Tsallis C, 1999, BRAZ J PHYS, V29, P1, DOI 10.1590/S0103-97331999000100002; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Zhang H. J., 1993, MULTIMEDIA SYSTEMS, V1, P10, DOI DOI 10.1007/BF01210504; ZHANG HJ, 1995, P ACM MULT 95 SAN FR, P15, DOI DOI 10.1145/217279.215068	81	145	159	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					831	847		10.1109/TPAMI.2004.32	http://dx.doi.org/10.1109/TPAMI.2004.32			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579943				2022-12-18	WOS:000221323900002
J	Bhanu, B; Tan, XJ				Bhanu, B; Tan, XJ			Fingerprint indexing based on novel features of minutiae triplets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint identification; indexing performance; NIST-4 database; triangle features	CLASSIFICATION	This paper is concerned with accurate and efficient indexing of fingerprint images. We present a model-based approach, which efficiently retrieves correct hypotheses using novel features of triangles formed by the triplets of minutiae as the basic representation unit. The triangle features that we use are its angles, handedness, type, direction, and maximum side. Geometric constraints based on other characteristics of minutiae are used to eliminate false correspondences. Experimental results on live-scan fingerprint images of varying quality and NIST special database 4 (NIST-4) show that our indexing approach efficiently narrows down the number of candidate hypotheses in the presence of translation, rotation, scale, shear, occlusion, and clutter. We also perform scientific experiments to compare the performance of our approach with another prominent indexing approach and show that the performance of our approach is better for both the live scan database and the ink based database NIST-4.	Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	University of California System; University of California Riverside	Bhanu, B (corresponding author), Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.	bhanu@cris.ucr.edu; xtan@cris.ucr.edu		Bhanu, Bir/0000-0001-8971-6416				Bhanu B, 2001, PROC CVPR IEEE, P591; Boshra M, 2000, IEEE T PATTERN ANAL, V22, P956, DOI 10.1109/34.877519; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Germain RS, 1997, IEEE COMPUT SCI ENG, V4, P42, DOI 10.1109/99.641608; Halici U, 1996, P IEEE, V84, P1497, DOI 10.1109/5.537114; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jones G, 1999, IEEE T PATTERN ANAL, V21, P603, DOI 10.1109/34.777371; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; Kovacs-Vajna ZM, 2000, IEEE T PATTERN ANAL, V22, P1266, DOI 10.1109/34.888711; Lamdan Y., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P22, DOI 10.1109/CVPR.1991.139655; Senior A, 2001, IEEE T PATTERN ANAL, V23, P1165, DOI 10.1109/34.954606; WATSON C, 1992, NIST SPECIAL DATABAS, V4; Wayman JL, 1999, IEEE ROBOT AUTOM MAG, V6, P35, DOI 10.1109/100.755813	14	145	150	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					616	622		10.1109/TPAMI.2003.1195995	http://dx.doi.org/10.1109/TPAMI.2003.1195995			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300007
J	Bunke, H				Bunke, H			Error correcting graph matching: On the influence of the underlying cost function	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph; subgraph; maximum common subgraph; graph isomorphism; subgraph isomorphism; graph matching; error correcting graph matching; cost function; edit operation; graph edit distance	SUBGRAPH ISOMORPHISM; PATTERN-RECOGNITION; EDIT DISTANCE; ALGORITHM	This paper investigates the influence of the cost function on the optimal match between two graphs. It is shown that, for a given cost function, there are an infinite number of other cost functions that lead, for any given pair of graphs, to the same optimal error correcting matching. Furthermore, it is shown that well-known concepts from graph theory, such as graph isomorphism, subgraph isomorphism, and maximum common subgraph, are special cases of optimal error correcting graph matching under particular cost functions.	Univ Bern, Inst Informat & Angew Math, CH-3012 Bern, Switzerland	University of Bern	Bunke, H (corresponding author), Univ Bern, Inst Informat & Angew Math, Neubruckstr 10, CH-3012 Bern, Switzerland.							Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; LEE JP, 1990, EYE, V4, P1; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; PEARCE A, 1994, PATTERN RECOGN, V27, P1231, DOI 10.1016/0031-3203(94)90007-8; Rice SV, 1997, ALGORITHMICA, V18, P271, DOI 10.1007/BF02526038; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wang YK, 1997, IEEE T SYST MAN CY B, V27, P588, DOI 10.1109/3477.604100; WONG C, 1992, CHINESE ECON STUD, V25, P3, DOI 10.2753/CES1097-147525043; XU L, 1990, LECT NOTES COMPUT SC, V412, P151; [No title captured]	17	145	148	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					917	922		10.1109/34.790431	http://dx.doi.org/10.1109/34.790431			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600007
J	Bazzi, I; Schwartz, R; Makhoul, J				Bazzi, I; Schwartz, R; Makhoul, J			An omnifont open-vocabulary OCR system for English and Arabic	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	4th International Conference on Document Analysis and Recognition (ICDAR 97)	AUG 18-20, 1997	ULM, GERMANY	Int Assoc Pattern Recognit, TC 10 & 11, Int Graphonom Soc, German Assoc Comp Sci, German Assoc Informat Technol		optical character recognition; speech recognition; hidden Markov Models; omnifont OCR; language modeling; Arabic OCR; segmentation-free recognition	HIDDEN MARKOV-MODELS; SPEECH RECOGNITION; SEGMENTATION-FREE; TEXT RECOGNITION	We present an omnifont, unlimited-vocabulary OCR system for English and Arabic. The system is based on Hidden Markov Models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition. In this paper we focus on two aspects of the OCR system. First, we address the issue of how to perform OCR on omnifont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The mettled includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1 percent on data from the University of Washington English Document Image Database and 3.3 percent on data from the DARPA Arabic OCR Corpus.	GTE Internetworking, BBN Technol, Cambridge, MA 02138 USA	Raytheon Technologies; Raytheon BBN Technologies	Bazzi, I (corresponding author), GTE Internetworking, BBN Technol, Cambridge, MA 02138 USA.	ibazzi@bbn.com						Aas K, 1996, PATTERN RECOGN, V29, P977, DOI 10.1016/0031-3203(95)00133-6; ALBADR B, 1995, SIGNAL PROCESS, V41, P49, DOI 10.1016/0165-1684(94)00090-M; ALLAM M, 1995, P SOC PHOTO-OPT INS, V2422, P228, DOI 10.1117/12.205825; BAZZI I, 1997, P INT C DOC AN REC U, V2, P842; BELLEGARDA J, 1989, IEEE INT C AC SPEECH, V1, P13; BENAMARA N, 1996, 13 INT C PATT REC VI, V2, P220; BOSE CB, 1994, PATTERN RECOGN, V27, P1345, DOI 10.1016/0031-3203(94)90069-8; Cho WY, 1995, PATTERN RECOGN, V28, P1941, DOI 10.1016/0031-3203(95)00041-0; Elms A. J., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P504, DOI 10.1109/ICDAR.1995.599044; Hopley R. L., 1997, P S DOC IM UND TECHN, P303; Kaltenmeier A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P139, DOI 10.1109/ICDAR.1993.395764; KORNAI A, 1997, P INT C AC SPEECH SI, V4, P3177; MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340; MAKHOUL J, 1995, P NATL ACAD SCI USA, V92, P9956, DOI 10.1073/pnas.92.22.9956; MAKHOUL J, 1996, DOC AN SYST WORKSH M, P99; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; NGUYEN L, 1995, P ARPA SPOK LANG SYS, P77; Phillips I. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P478, DOI 10.1109/ICDAR.1993.395691; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Schwartz R., 1996, AUTOMATIC SPEECH SPE, P429; SCHWARTZ R, 1996, P INT C PATT REC VIE, P99; Starner T., 1994, ICASSP-94. 1994 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.94CH3387-8), pV/125, DOI 10.1109/ICASSP.1994.389432; YARMANVURAL FT, 1996, P SPIE 2, V2, P725	23	145	148	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					495	504		10.1109/34.771314	http://dx.doi.org/10.1109/34.771314			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	205KD					2022-12-18	WOS:000080819100002
J	Wu, HY; Chen, Q; Yachida, M				Wu, HY; Chen, Q; Yachida, M			Face detection from color images using a fuzzy pattern matching method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face detection; fuzzy pattern matching; perceptually uniform color space; skin color similarity; hair color similarity; head shape model	RECOGNITION	This paper describes a new method to detect faces in color images based on the fuzzy theory. We make two fuzzy models to describe the skin color and hair color, respectively. In these models, we use a perceptually uniform color space to describe the color information to increase the accuracy and stableness. We use the two models to extract the skin color regions and the hair color regions, and then comparing them with the prebuilt head-shape models by using a fuzzy theory based pattern-matching method to detect face candidates.	Kyoto Inst Technol, Dept Mech & Syst Engn, Sakyo Ku, Kyoto 6068585, Japan; Wakayama Univ, Fac Syst Engn, Dept Design & Informat Sci, Wakayama 6408510, Japan; Osaka Univ, Grad Sch Engn Sci, Dept Syst & Human Sci, Toyonaka, Osaka 5608531, Japan	Kyoto Institute of Technology; Wakayama University; Osaka University	Wu, HY (corresponding author), Kyoto Inst Technol, Dept Mech & Syst Engn, Sakyo Ku, Kyoto 6068585, Japan.							CHEN Q, 1995, P 5 INT C COMP VIS, P591; Colmenarez AJ, 1997, PROC CVPR IEEE, P782, DOI 10.1109/CVPR.1997.609415; Dai Y, 1996, PATTERN RECOGN, V29, P1007, DOI 10.1016/0031-3203(95)00139-5; JIA XG, 1995, IEEE T PATTERN ANAL, V17, P1167, DOI 10.1109/34.476509; Juell P, 1996, PATTERN RECOGN, V29, P781, DOI 10.1016/0031-3203(95)00129-8; KWON YH, 1994, INT C PATT RECOG, P764; LANITIS A, 1995, P INT WORKSH AUT FAC, P98; Lee CH, 1996, PATTERN RECOGN, V29, P1877, DOI 10.1016/0031-3203(96)00036-2; Lee SY, 1996, PATTERN RECOGN, V29, P1863, DOI 10.1016/0031-3203(96)00030-1; LEUNG T, 1995, ICCV, P637; LEW M, 1996, ICPR 96, P601; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; ROWLEY HA, 1996, CVPR 96, P203; SABER E, 1996, ICPR 96, P654; Sinha P., 1994, INVEST OPHTHALMOL, V35, P1735; Vaillant R., 1994, IEEE P VIS IM SIGN P, V141; Wyszecki G., 1967, COLOR SCI	17	145	171	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					557	563		10.1109/34.771326	http://dx.doi.org/10.1109/34.771326			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD					2022-12-18	WOS:000080819100007
J	Lam, KM; Yan, H				Lam, KM; Yan, H			An analytic-to-holistic approach for face recognition based on a single frontal view	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; facial feature detection; head model; point matching; correlation	FEATURE-EXTRACTION; DEFORMABLE TEMPLATES; IDENTIFICATION; COMPUTER; IMAGE	In this paper, we propose an analytic-to-holistic approach which can identify faces at different perspective variations. The database for the test consists of 40 frontal-view faces. The first step is to locate 15 feature points on a face. A head model is proposed, and the rotation of the face can be estimated using geometrical measurements. The positions of the feature points are adjusted so that their corresponding positions for the frontal view are approximated. These feature points are then compared with the feature points of the faces in a database using a similarity transform. In the second step, we set up windows for the eyes, nose, and mouth. These feature windows are compared with those in the database by correlation. Results show that this approach can achieve a similar level of performance from different viewing directions of a face. Under different perspective variations, the overall recognition rates are over 84 percent and 96 percent for the first and the first three likely matched faces, respectively.	Hong Kong Polytech Univ, Dept Elect Engn, Kowloon, Peoples R China; Univ Sydney, Dept Elect Engn, Sydney, NSW 2006, Australia	Hong Kong Polytechnic University; University of Sydney	Lam, KM (corresponding author), Hong Kong Polytech Univ, Dept Elect Engn, Kowloon, Peoples R China.	enkmlam@encserver.en.polyu.edu.hk	Kan, Kin-Man/A-9352-2014	Kan, Kin-Man/0000-0002-0422-8454; YAN, Hong/0000-0001-9661-3095				BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; BRUNELLI R, 1995, PATTERN RECOGN, V28, P833, DOI 10.1016/0031-3203(94)00170-Q; BUHMANN J, 1989, P IJCNN 89, V1, P155; CHENG YQ, 1993, PATTERN RECOGN, V26, P115, DOI 10.1016/0031-3203(93)90093-C; Ching-Wen Chen, 1992, International Journal of Pattern Recognition and Artificial Intelligence, V6, P571, DOI 10.1142/S021800149200031X; HARMON LD, 1981, PATTERN RECOGN, V13, P97, DOI 10.1016/0031-3203(81)90008-X; HARMON LD, 1978, PATTERN RECOGN, V10, P301, DOI 10.1016/0031-3203(78)90001-8; HONG ZQ, 1991, PATTERN RECOGN, V24, P211, DOI 10.1016/0031-3203(91)90063-B; KAMEL MS, 1994, PATTERN RECOGN, P877; KANADE T, 1973, PICTURE PROCESSING C; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lam K.-M., 1994, Journal of Electronic Imaging, V3, P351, DOI 10.1117/12.183806; Lam KM, 1996, PATTERN RECOGN, V29, P771, DOI 10.1016/0031-3203(95)00119-0; LAM KM, 1994, ELECTRON LETT, V30, P21, DOI 10.1049/el:19940040; LAM KM, 1994, P INT S INF THEOR IT, P167; LAM KM, 1996, ICPR 96, pC411; Mirhosseini AR, 1998, OPT ENG, V37, P869, DOI 10.1117/1.601920; NAKAMURA O, 1991, PATTERN RECOGN, V24, P263, DOI 10.1016/0031-3203(91)90068-G; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Werman M., 1995, IEEE T PATTERN ANAL, V17; WU CJ, 1990, PATTERN RECOGN, V23, P255, DOI 10.1016/0031-3203(90)90013-B; XIE X, 1993, PATTERN RECOGN, V26, P1235, DOI 10.1016/0031-3203(93)90208-E; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169	27	145	163	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					673	686		10.1109/34.689299	http://dx.doi.org/10.1109/34.689299			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930		Green Published			2022-12-18	WOS:000074677200001
J	TAYLOR, CJ; KRIEGMAN, DJ				TAYLOR, CJ; KRIEGMAN, DJ			STRUCTURE AND MOTION FROM LINE SEGMENTS IN MULTIPLE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STRUCTURE FROM MOTION; STRAIGHT LINES; 3-DIMENSIONAL RECONSTRUCTION; PERSPECTIVE PROJECTION; NUMERICAL MINIMIZATION	CORRESPONDENCES; ALGORITHM; SHAPE	This paper presents a new method for recovering the three dimensional structure of a scene composed of straight line segments using the image data obtained from a moving camera. The recovery algorithm is formulated in terms of an objective function which measures the total squared distance in the image plane between the observed edge segments and the projections (perspective) of the reconstructed lines. This objective function is minimized with respect to the line parameters and the camera positions to obtain an estimate for the structure of the scene. The effectiveness of this approach is demonstrated quantitatively through extensive simulations and qualitatively with actual image sequences. The implementation is being made publicly available.	YALE UNIV,CTR SYST SCI,DEPT ELECT ENGN,NEW HAVEN,CT 06520	Yale University	TAYLOR, CJ (corresponding author), UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,BERKELEY,CA 94720, USA.							Canny J., 1986, IEEE T PATTERN ANAL, P679; CRAIG JJ, 1989, INTRO ROBOTICS MECHA; CROWLEY JL, 1992, INT J COMPUT VISION, V8, P29, DOI 10.1007/BF00126399; FAUGERAS OD, 1987, JUN P ICCV, P25; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GIAICHECA B, 1992, 1992 P IEEE INT S IN, P341; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; HU XP, 1993, IMAGE VISION COMPUT, V11, P549, DOI 10.1016/0262-8856(93)90021-8; JEZOUIN JL, 1990, DEC P INT C COMP VIS, P441; Kumar R., 1989, P WORKSHOP INTERPRET, P52; Liu Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P82, DOI 10.1109/CVPR.1988.196218; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; NAVAB N, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P513; Smith S.T., 1993, THESIS HARVARD U CAM; SPETSAKIS M, 1992, CVGIP IMAGE UNDERSTA, V56; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; Taylor C. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P242, DOI 10.1109/WVM.1991.212801; Taylor CJ, 1994, 9405 YAL U CTR SYST; Thompson M., 1966, MANUAL PHOTOGRAMMETR, V3rd; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VIEVILLE T, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P517; VIEVILLE T, 1990, 1ST P ECCV ANT, P281; WENG J, 1988, P IEEE C COMP VIS PA, P387; Weng J., 1993, SPRINGER SERIES INFO; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779	30	145	167	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1021	1032		10.1109/34.473228	http://dx.doi.org/10.1109/34.473228			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400001
J	SIMCHONY, T; CHELLAPPA, R; SHAO, M				SIMCHONY, T; CHELLAPPA, R; SHAO, M			DIRECT ANALYTICAL METHODS FOR SOLVING POISSON EQUATIONS IN COMPUTER VISION PROBLEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST SIGNAL & IMAGE PROC,DEPT ELECT ENGN,LOS ANGELES,CA 90089; UNIV SO CALIF,DEPT MATH,LOS ANGELES,CA 90089	University of Southern California; University of Southern California			Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012					BLAKE A, 1986, CSR20586 U ED DEP CO; BROOKS MJ, 1985, AUG P INT JOINT C AR, P932; BRUSS A, 1983, AUG P INT JOINT C AR; BUZBEE BL, 1970, SIAM J NUMER ANAL, V7, P627, DOI 10.1137/0707049; BUZBEE BL, 1971, SIAM J NUMER ANAL, V8, P722, DOI 10.1137/0708066; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IKEUCHI K, 1983, MIT AIM744 ART INT L; LEE D, 1985, DEC P DARPA IM UND W, P489; POGGIO T, 1984, MIT AIM773 ART INT L; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; SHAO M, 1988, JUN P COMP VIS PATT; Smith G. D., 1978, NUMERICAL SOLUTION P, V2nd; STRANG G, 1976, LINEAR ALGEBRA ITS A; STRAT M, 1979, THESIS MIT CAMBRIDGE; SWARZTRAUBER PN, 1977, SIAM REV, V19, P490, DOI 10.1137/1019071; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; Tikhonov A., 1977, SOLUTIONS ILL POSED	22	145	149	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1990	12	5					435	446		10.1109/34.55103	http://dx.doi.org/10.1109/34.55103			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DA035					2022-12-18	WOS:A1990DA03500002
J	CANNY, J				CANNY, J			COLLISION DETECTION FOR MOVING POLYHEDRA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CANNY, J (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.							BOYSE JW, 1979, COMMUN ACM, V22, P3, DOI 10.1145/359046.359048; BROOKS RA, IJCAI 83, P799; COLLINS GE, 1982, COMPUTER ALGEBRA CS, V4, P83; DONALD BR, 1984, MIT TR791 ART INT LA; ERDMANN MA, 1984, MIT TR810 ART INT LA; Hamilton W.R., 1969, ELEMENTS QUATERNIONS; LOZANOPEREZ T, 1983, IEEE T COMPUT, V32, P108, DOI 10.1109/TC.1983.1676196; PERVIN E, 1982, CS82150 CARN MELL U; SALAMIN E, 1979, APPLICATION QUATERNI; SCHWARTZ JT, 1982, 41 NEW YORK U DEP CO; YANG AT, 1964, APPLICATIONS QUATERN; [No title captured]	12	145	157	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					200	209		10.1109/TPAMI.1986.4767773	http://dx.doi.org/10.1109/TPAMI.1986.4767773			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869338	Green Submitted			2022-12-18	WOS:A1986A107300007
J	Wei, YC; Liang, XD; Chen, YP; Shen, XH; Cheng, MM; Feng, JS; Zhao, Y; Yan, SC				Wei, Yunchao; Liang, Xiaodan; Chen, Yunpeng; Shen, Xiaohui; Cheng, Ming-Ming; Feng, Jiashi; Zhao, Yao; Yan, Shuicheng			STC: A Simple to Complex Framework for Weakly-Supervised Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic segmentation; weakly-supervised learning; convolutional neural network	SALIENT OBJECT DETECTION	Recently, significant improvement has been made on semantic object segmentation due to the development of deep convolutional neural networks (DCNNs). Training such a DCNN usually relies on a large number of images with pixel-level segmentation masks, and annotating these images is very costly in terms of both finance and human effort. In this paper, we propose a simple to complex (STC) framework in which only image-level annotations are utilized to learn DCNNs for semantic segmentation. Specifically, we first train an initial segmentation network called Initial-DCNN with the saliency maps of simple images (i.e., those with a single category of major object(s) and clean background). These saliency maps can be automatically obtained by existing bottom-up salient object detection techniques, where no supervision information is needed. Then, a better network called Enhanced DCNN is learned with supervision from the predicted segmentation masks of simple images based on the Initial-DCNN as well as the image-level annotations. Finally, more pixel-level segmentationmasks of complex images (two or more categories of objects with cluttered background), which are inferred by using Enhanced-DCNN and image-level annotations, are utilized as the supervision information to learn the Powerful-DCNN for semantic segmentation. Our method utilizes 40K simple images from Flickr.com and 10K complex images from PASCAL VOC for step-wisely boosting the segmentation network. Extensive experimental results on PASCAL VOC 2012 segmentation benchmark well demonstrate the superiority of the proposed STC framework compared with other state-of-the-arts.	[Wei, Yunchao; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China; [Liang, Xiaodan] Sun Yat Sen Univ, Guangzhou 510275, Guangdong Sheng, Peoples R China; [Shen, Xiaohui] Adobe Res, San Jose, CA 95110 USA; [Cheng, Ming-Ming] Nankai Univ, CCCE, Tianjin 300071, Peoples R China; [Chen, Yunpeng; Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore	Beijing Jiaotong University; Sun Yat Sen University; Adobe Systems Inc.; Nankai University; National University of Singapore	Zhao, Y (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.	wychao1987@gmail.com; xdliang328@gmail.com; qw.2080@gmail.com; xshen@adobe.com; cmm@nankai.edu.cn; elefjia@nus.edu.sg; yzhao@bjtu.edu.cn; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022; Feng, Jiashi/AGX-6209-2022; Cheng, Ming-Ming/A-2527-2009	Cheng, Ming-Ming/0000-0001-5550-8758	National Key Research and Development of China [2016YFB0800404]; National Natural Science Foundation of China [61532005, 61210006, 61402268, 61572264]; CAST young talents plan	National Key Research and Development of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CAST young talents plan	This work was sponsored by the National Key Research and Development of China (NO. 2016YFB0800404), the National Natural Science Foundation of China (NO. 61532005, NO. 61210006, NO. 61402268, NO. 61572264), and CAST young talents plan.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Chen L.-C., 2014, ARXIV PREPRINT ARXIV; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang L, 2014, ADV NEUR IN, V27; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536; Liu S, 2012, IEEE T MULTIMEDIA, V14, P361, DOI 10.1109/TMM.2011.2174780; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Maron O, 1998, ADV NEUR IN, V10, P570; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pathak D., 2014, 14127144 ARXIV; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7; Saleh F, 2016, LECT NOTES COMPUT SC, V9912, P413, DOI 10.1007/978-3-319-46484-8_25; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tang K., 2012, ADV NEURAL INFORM PR; Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Xia W, 2013, IEEE I CONF COMP VIS, P2176, DOI 10.1109/ICCV.2013.271; Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002; Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	47	144	147	10	146	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2314	2320		10.1109/TPAMI.2016.2636150	http://dx.doi.org/10.1109/TPAMI.2016.2636150			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114002	Green Submitted			2022-12-18	WOS:000412028600016
J	Jain, AK; Feng, JJ				Jain, Anil K.; Feng, Jianjiang			Latent Fingerprint Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint; minutiae; latent; descriptor; matching; forensics; extended features	RECOGNITION	Latent fingerprint identification is of critical importance to law enforcement agencies in identifying suspects: Latent fingerprints are inadvertent impressions left by fingers on surfaces of objects. While tremendous progress has been made in plain and rolled fingerprint matching, latent fingerprint matching continues to be a difficult problem. Poor quality of ridge impressions, small finger area, and large nonlinear distortion are the main difficulties in latent fingerprint matching compared to plain or rolled fingerprint matching. We propose a system for matching latent fingerprints found at crime scenes to rolled fingerprints enrolled in law enforcement databases. In addition to minutiae, we also use extended features, including singularity, ridge quality map, ridge flow map, ridge wavelength map, and skeleton. We tested our system by matching 258 latents in the NIST SD27 database against a background database of 29,257 rolled fingerprints obtained by combining the NIST SD4, SD14, and SD27 databases. The minutiae-based baseline rank-1 identification rate of 34.9 percent was improved to 74 percent when extended features were used. In order to evaluate the relative importance of each extended feature, these features were incrementally used in the order of their cost in marking by latent experts. The experimental results indicate that singularity, ridge quality map, and ridge flow map are the most effective features in improving the matching accuracy.	[Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Feng, Jianjiang] Tsinghua Univ, Inst Informat Proc, Dept Automat, Beijing 100084, Peoples R China	Michigan State University; Tsinghua University	Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	jain@cse.msu.edu; jfeng@tsinghua.edu.cn	Feng, Jianjiang/I-3386-2012		ARO [W911NF-06-1-0418]; NIJ [2007-RG-CX-K183]; Ministry of Education, Science and Technology [R31-2008-000-10008-0]	ARO; NIJ; Ministry of Education, Science and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea)	The authors would like to acknowledge the assistance of Lt. Gregoire Michaud and Sgt. Scott Hrcka of the Michigan State Police Forensic Science Division and Austin Hicklin of Noblis. This work was supported by ARO grant W911NF-06-1-0418 and NIJ grant 2007-RG-CX-K183. The work of the first author was partially supported by the World Class University (WCU) program through the National Research Foundation of Korea funded by the Ministry of Education, Science and Technology (R31-2008-000-10008-0) to the Department of Brain & Cognitive Engineering, Korea University. A preliminary version of this paper is contained in [1].	*ANSI INCITS, 2004, 3782004 ANSI INCITS; *ANSI NIST ITL, 2005, 12000 ANSI NIST ITL; Anthonioz A., 2008, J FORENSIC IDENTIF, V58, P562; Ashbaugh D.R, 1999, CRC SER PR CRIM; Bazen AM, 2002, INT C PATT RECOG, P985, DOI 10.1109/ICPR.2002.1048471; Champod C., 2017, FINGERPRINTS OTHER R, P136; Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597; Cole SA, 2005, J CRIM LAW CRIM, V95, P985; Dvornychenko V. N., 2006, 7377 NISTIR; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Feng JJ, 2006, PATTERN RECOGN, V39, P2131, DOI 10.1016/j.patcog.2006.05.001; Feng JJ, 2009, LECT NOTES COMPUT SC, V5558, P695, DOI 10.1007/978-3-642-01793-3_71; Gu JW, 2006, IEEE T IMAGE PROCESS, V15, P1952, DOI 10.1109/TIP.2006.873443; HARA M, 2007, Patent No. 7295688; *IBG, 2008, AN LEV 3 FEAT HIGH R; Indovina M., 2009, 7577 NISTIR; *INN PROJ, 2010, CAS PROF; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain AK, 2007, IEEE T PATTERN ANAL, V29, P15, DOI 10.1109/TPAMI.2007.250596; Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416; Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016; Komarinski P, 2005, AUTOMATED FINGERPRIN; Kovacs-Vajna ZM, 2000, IEEE T PATTERN ANAL, V22, P1266, DOI 10.1109/34.888711; Lee HC, 2001, ADV FINGERPRINT TECH; LO P, 1999, Patent No. 5960101; LO P, 2008, Patent No. 20080273769; Maltoni D., 2009, HDB FINGERPRINT RECO; MCCABE RM, 2005, 7242 NISTIR; MOENSSENS AA, 1999, IS FINGERPRINT IDENF; *NAS COMM ID NEEDS, 2009, STRENGTH FOR SCI US; *NAT RES COUNC COM, 1996, EV FOR DNA EVID; *NEUR INC, 2010, VERIFINGER; *NIST, 2007, SUMM RES ELFT07 PHAS; *NIST, 2010, NIST MIN INT EXCH TE; *NIST, 2010, NIST SPEC DAT 27; *NIST, 2010, NIST PROPR FING TEMP; *NIST, 2010, NIST SPEC DAT 14; *NIST, 2010, NIST SPEC DAT 4; Office of the Inspector General, 2006, REV FBIS HANDL BRAND; Saks MJ, 2005, SCIENCE, V309, P892, DOI 10.1126/science.1111565; STOSZ JD, 1994, P SOC PHOTO-OPT INS, V2277, P210, DOI 10.1117/12.191885; TABASSI E, 2004, 7151 NISTIR; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Wan DR, 2006, IEEE T IMAGE PROCESS, V15, P1690, DOI 10.1109/TIP.2006.873442; Wilson C, 2004, 7123 NISTIR; Yonghua Cheng, 2007, 2007 European Conference on Power Electronics and Applications, P1; Zhou J, 2009, PATTERN RECOGN, V42, P896, DOI 10.1016/j.patcog.2008.09.011; 2010, CDEFFS ANIS NIST COM; 2008, CDEFFS DATA IN PRESS; 2007, EVALUATION LATENT FI	50	144	149	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					88	100		10.1109/TPAMI.2010.59	http://dx.doi.org/10.1109/TPAMI.2010.59			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088321	Green Published, Green Submitted			2022-12-18	WOS:000284277600007
J	Hollingsworth, KP; Bowyer, KW; Flynn, PJ				Hollingsworth, Karen P.; Bowyer, Kevin W.; Flynn, Patrick J.			The Best Bits in an Iris Code	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	1st IEEE International Conference on Biometrics - Theory, Applications and Systems (BTAS 07)	SEP 27-29, 2007	Crystal City, VA	IEEE Syst, Man & Cybernet Soc		Iris biometrics; iris code; texture filter; false reject rate	RECOGNITION	Iris biometric systems apply filters to iris images to extract information about iris texture. Daugman's approach maps the filter output to a binary iris code. The fractional Hamming distance between two iris codes is computed and decisions about the identity of a person are based on the computed distance. The fractional Hamming distance weights all bits in an iris code equally. However, not all of the bits in an iris code are equally useful. Our research is the first to present experiments documenting that some bits are more consistent than others. Different regions of the iris are compared to evaluate their relative consistency and, contrary to some previous research, we find that the middle bands of the iris are more consistent than the inner bands. The inconsistent-bit phenomenon is evident across genders and different filter types. Possible causes of inconsistencies, such as segmentation, alignment issues, and different filters, are investigated. The inconsistencies are largely due to the coarse quantization of the phase response. Masking iris code bits corresponding to complex filter responses near the axes of the complex plane improves the separation between the match and nonmatch Hamming distance distributions.	[Hollingsworth, Karen P.; Bowyer, Kevin W.; Flynn, Patrick J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	University of Notre Dame	Hollingsworth, KP (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, 384 Fitzpatrick Hall, Notre Dame, IN 46556 USA.	kholling@nd.edu; kwb@cse.nd.edu; flynn@nd.edu	Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X; Bowyer, Kevin/0000-0002-7562-4390				Bolle RM, 2004, INT C PATT RECOG, P927, DOI 10.1109/ICPR.2004.1334411; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; Broussard R. P., 2008, P SPIE, V6944; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DU Y, 2005, P IEEE INT C AC SPEE, V2, P961; Glenstrup A.J., 1995, THESIS U COPENHAGEN; HOLLINGSWORTH K, 2007, P IEEE INT C BIOM TH; Krichen E., 2008, OSIRIS OPEN SOURCE I; Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118; Ma L, 2004, PATTERN RECOGN, V37, P1287, DOI 10.1016/j.patcog.2004.02.001; Miyazawa K, 2005, IEEE IMAGE PROC, P2001; *NAT I STAND TECH, 2008, IR CHALL EV 2005 WOR; Phillips P.J., 2007, 7408 NISTIR; THORNTON J, 2007, P IEEE INT C BIOM TH; Tisse C., 2002, P VIS INT, P294; WILDES R, 2005, BIOMETRIC SYSTEMS, P63	17	144	156	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					964	973		10.1109/TPAMI.2008.185	http://dx.doi.org/10.1109/TPAMI.2008.185			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	431YF	19372603				2022-12-18	WOS:000265100000001
J	Mirmehdi, M; Petrou, M				Mirmehdi, M; Petrou, M			Segmentation of color textures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color segmentation; probabilistic relaxation; perceptual smoothing	MARKOV RANDOM-FIELD; IMAGE SEGMENTATION; FEATURE-EXTRACTION; PERCEPTION; RELAXATION; VISION; FLOW	This paper describes an approach to perceptual segmentation of color image textures. A multiscale representation of the texture image, generated by a multiband smoothing algorithm based on human psychophysical measurements of color appearance is used as the input. Initial segmentation is achieved by applying a clustering algorithm to the image at the coarsest level of smoothing. The segmented clusters are then restructured in order to isolate core clusters, i.e., patches in which the pixels are definitely associated with the same region. The image pixels representing the core clusters are used to form 3D color histograms which are then used for probabilistic assignment of all other pixels to the core clusters to form larger clusters and categorise the rest of the image. The process of setting up color histograms and probabilistic reassignment of the pixels to the clusters is then propagated through finer levels of smoothing until a full segmentation is achieved at the highest level of resolution.	Univ Bristol, Dept Comp Sci, Bristol, Avon, England; Sch Elect Engn Informat Technol & Math, Guildford GU2 5XH, Surrey, England	University of Bristol	Mirmehdi, M (corresponding author), Univ Bristol, Dept Comp Sci, Bristol, Avon, England.	M.Mirmehdi@cs.bris.ac.uk; m.petrou@ee.surrey.ac.uk						BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641; CAMPBELL NW, 1996, P 7 BRIT MACH VIS C, V1, P222; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; CROWLEY JL, 1987, IEEE T PATTERN ANAL, V9, P113, DOI 10.1109/TPAMI.1987.4767876; GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712; GLAZER F, 1984, MULTIRESOLUTION IMAG, P312; GOOL LV, 1985, COMPUTER VISION GRAP, V29, P336; Hancock E. R., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems, P140, DOI 10.1109/ICPR.1992.201740; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12, P165, DOI 10.1109/34.44403; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HEITZ F, 1994, CVGIP-IMAG UNDERSTAN, V59, P125, DOI 10.1006/ciun.1994.1008; HUANG CL, 1992, PATTERN RECOGN, V25, P1217, DOI 10.1016/0031-3203(92)90023-C; JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI 10.1016/0031-3203(91)90143-S; JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x; Kashi RS, 1996, INT J IMAG SYST TECH, V7, P85, DOI 10.1002/(SICI)1098-1098(199622)7:2<85::AID-IMA3>3.0.CO;2-O; KLINKER GJ, 1993, PHYSICAL APPROACH CO; Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696; LAM SWC, 1994, PATTERN RECOGN LETT, V15, P691, DOI 10.1016/0167-8655(94)90073-6; LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949; Ma WY, 1997, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.1997.609409; MALIK J, 1989, CSD89491 U CAL; MATALAS I, 1996, P SIGN PROC 8 THEOR, V3, P1495; MIRMEHDI M, 1998, P INT C SIGN PROC CO, P136; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; Panjwani D. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P776, DOI 10.1109/CVPR.1993.341170; Papathomas TV, 1997, IEEE T SYST MAN CY B, V27, P428, DOI 10.1109/3477.584950; Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557; PEREZ P, 1992, P INT C AC SPEECH SI, P61; RAO AR, 1993, CVGIP-GRAPH MODEL IM, V55, P218, DOI 10.1006/cgip.1993.1016; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; ROAN SJ, 1987, PATTERN RECOGN, V20, P17, DOI 10.1016/0031-3203(87)90014-8; SCHARCANSKI J, 1994, PATTERN RECOGN LETT, V15, P191, DOI 10.1016/0167-8655(94)90048-5; Skarbek W, 1994, COLOUR IMAGE SEGMENT; Song KY, 1996, IMAGE VISION COMPUT, V14, P667, DOI 10.1016/0262-8856(96)84491-X; STODDART A, 1998, J MATH VISION; SWAIN MJ, 1990, THESIS U ROCHESTER; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; TAN SC, 1993, P 8 SCAND C IM PROC; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466; WANDELL BA, 1996, P 9 WORKSH IM MULT S, P11; WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C; ZHANG D, 1988, P INT C PATT REC, P712; ZHANG X, 1996, P SOC INF DISPL S	47	144	158	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					142	159		10.1109/34.825753	http://dx.doi.org/10.1109/34.825753			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400002
J	Dorai, C; Wang, G; Jain, AK; Mercer, C				Dorai, C; Wang, G; Jain, AK; Mercer, C			Registration and integration of multiple object views for 3D model construction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic 3D object modeling; free-form objects; registration; view integration; range images; digital interferometry	RANGE VIEWS	Automatic 3D object model construction is important in applications ranging from manufacturing to entertainment, since CAD models of existing objects may be either unavailable or unusable. We describe a prototype system for automatically registering and integrating multiple views of objects from range data. The results can then be used to construct geometric models of the objects. New techniques for handling key problems such as robust estimation of transformations relating multiple views and seamless integration of registered data to form an unbroken surface have been proposed and implemented in the system. Experimental results on real surface data acquired using a digital interferometric sensor as well as a laser range scanner demonstrate the good performance of our system.	Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA; NASA, Lewis Res Ctr, Opt Technol Branch, Cleveland, OH 44135 USA	Michigan State University; National Aeronautics & Space Administration (NASA); NASA Glenn Research Center	Dorai, C (corresponding author), Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA.	dorai@cps.msu.edu; wanggang@cps.msu.edu; jain@cps.msu.edu; cmercer@lerc.nasa.gov						AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; BERGEVIN R, 1995, COMPUT VIS IMAGE UND, V61, P1, DOI 10.1006/cviu.1995.1001; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; DORAI C, IN PRESS IEEE T PATT; MERCER CR, 1990, HOLOGRAM INTERFEROME, P210; POTMESIL M, 1983, P 8 INT JOINT C ART, P1089; RUTISHAUSER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P573, DOI 10.1109/CVPR.1994.323797; SHUM HY, 1994, P IEEE C COMP VIS PA, P560; SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982; SZELISKI R, 1988, P 2 INT C COMP VIS T, P207; THOMPSON WB, 1995, UUCS95010 DEP COM SC; TURK G, 1994, SIGGRAPH, V94, P311; Vemuri B. C., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P435	17	144	167	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1998	20	1					83	89		10.1109/34.655652	http://dx.doi.org/10.1109/34.655652			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YV876					2022-12-18	WOS:000071872400008
J	COCHRAN, SD; MEDIONI, G				COCHRAN, SD; MEDIONI, G			3-D SURFACE DESCRIPTION FROM BINOCULAR STEREO	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AREA-BASED MATCHING; BINOCULAR STEREO; FEATURE-BASED MATCHING; SURFACE SEGMENTATION	VISION	We present a stereo vision system that attempts to achieve robustness with respect to scene characteristics, from textured outdoor scenes to environments composed of highly regular man-made objects. Unlike most stereo approaches, it integrates "area-based" and "feature-based" primitives. This allows it to take advantage of the unique attributes of each of these techniques. The area-based processing provides a dense disparity map, and the feature-based processing provides an accurate location of discontinuities. We are able to generate a disparity map that is sufficiently accurate to allow us to detect depth and surface orientation discontinuities, provided that the resolution is fine enough. We use an area-based cross correlation along with an ordering constraint and a weak surface smoothness assumption to produce an initial disparity map. Unlike other approaches, however, a match is accepted only if both views agree on a correlation peak and if this peak is strong enough. This disparity map is only a blurred version of the true one because of the smoothing introduced by the cross correlation. The problem is most acute at depth discontinuities but can be reduced by introducing the edge information: The disparity map is smoothed (subject to the constraint that the disparity at edgels is fixed) and the unsupported points removed. It is important to note that this method gives an active role to edgels parallel to the epipolar lines, whereas they are discarded in most feature-based systems. We have obtained very good results on complex scenes in different domains and have been able to locate visible surfaces, penumbral and off-the-edge areas, and depth and orientation discontinuities in the images.	UNIV SO CALIF, DEPT COMP SCI, INST ROBOT & INTELLIGENT SYST, LOS ANGELES, CA 90089 USA; UNIV SO CALIF, DEPT ELECT ENGN, LOS ANGELES, CA 90089 USA	University of Southern California; University of Southern California	COCHRAN, SD (corresponding author), CARNEGIE MELLON UNIV, SCH COMP SCI, DEPT COMP SCI, DIGITAL MAPPING LAB, PITTSBURGH, PA 15213 USA.							ARNOLD RD, 1983, AIM351 TECH REP; ARNOLD RD, 1978, MAY P DARPA IM UND W, P65; BAKER HH, 1982, AIM347 TECH REP; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Boult T. E., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P118, DOI 10.1109/CCV.1988.589980; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FLYNN PJ, 1989, JUN P C COMP VIS PAT, P110; GAMBLE EB, 1991, JUN P DARPA IM UND W, P757; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1981, IMAGES SURFACES; Hannah M., 1985, DEC P DARPA IM UND W, P149; Hannah M. J., 1974, STANCS74438 STANF U; HANNAH MJ, 1980, APR P IM UND WORKSH, P201; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; MARR D, 1977, MIT451 ART INT LAB A; MARROQUIN JL, 1987, JUN P IEEE INT C COM; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; Mori K., 1973, COMPUT GRAPHICS IMAG, V2, P393; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NEVATIA R, 1982, MACHINE PERCEPTION; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; POGGIO T, 1988, SCIENCE, V242, P436, DOI 10.1126/science.3175666; QUAM L, 1984, OCT P DARPA IM UND W, P149; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SAINTMARC P, 1989, JUN P C COMP VIS PAT, P618; SINHA SS, 1989, JUN P IEEE C COMP VI, P229; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908	29	144	150	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1992	14	10					981	994		10.1109/34.159902	http://dx.doi.org/10.1109/34.159902			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR944					2022-12-18	WOS:A1992JR94400002
J	KUC, R; SIEGEL, MW				KUC, R; SIEGEL, MW			PHYSICALLY BASED SIMULATION-MODEL FOR ACOUSTIC SENSOR ROBOT NAVIGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University	KUC, R (corresponding author), YALE UNIV,DEPT ELECT ENGN,NEW HAVEN,CT 06520, USA.		Siegel, Mel/J-2424-2013					Crowley J., 1985, PROC IEEE INT C ROBO, P128; ELFES A, COMMUNICATION; Gradshteyn I. S., 2014, TABLE INTEGRALS SERI; Moravec H., 1985, P 1985 IEEE INT C RO, P116; Morse P. M., 1968, THEORETICAL ACOUSTIC; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; SCHWARZ R, 1964, LINEAR SYSTEM THEORY; Wells P N T, 1977, BIOMEDICAL ULTRASONI; 1982, ULTRASONIC RANGE FIN	9	144	146	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					766	778		10.1109/TPAMI.1987.4767983	http://dx.doi.org/10.1109/TPAMI.1987.4767983			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869438				2022-12-18	WOS:A1987K673500004
J	Afouras, T; Chung, JS; Senior, A; Vinyals, O; Zisserman, A				Afouras, Triantafyllos; Chung, Joon Son; Senior, Andrew; Vinyals, Oriol; Zisserman, Andrew			Deep Audio-Visual Speech Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; Lips; Speech recognition; Visualization; Videos; Feeds; Training; Lip reading; audio visual speech recognition; deep learning	NETWORKS	The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem - unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) we compare two models for lip reading, one using a CTC loss, and the other using a sequence-to-sequence loss. Both models are built on top of the transformer self-attention architecture; (2) we investigate to what extent lip reading is complementary to audio speech recognition, especially when the audio signal is noisy; (3) we introduce and publicly release a new dataset for audio-visual speech recognition, LRS2-BBC, consisting of thousands of natural sentences from British television. The models that we train surpass the performance of all previous work on a lip reading benchmark dataset by a significant margin.	[Afouras, Triantafyllos; Chung, Joon Son; Zisserman, Andrew] Univ Oxford, Oxford OX1 2JD, England; [Senior, Andrew; Vinyals, Oriol; Zisserman, Andrew] Google DeepMind, London N1C 4AG, England	University of Oxford; Google Incorporated	Chung, JS (corresponding author), Univ Oxford, Oxford OX1 2JD, England.	afourast@robots.ox.ac.uk; joon@robots.ox.ac.uk; vinyals@google.com; andrewsenior@google.com; az@robots.ox.ac.uk		Zisserman, Andrew/0000-0002-8945-8573	EPSRC Programme Grant [Seebibyte EP/M013774/1]; EPSRC CDT in Autonomous Intelligent Machines and Systems; Oxford-Google DeepMind Graduate Scholarship	EPSRC Programme Grant(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC CDT in Autonomous Intelligent Machines and Systems; Oxford-Google DeepMind Graduate Scholarship(Google Incorporated)	Funding for this research is provided by the EPSRC Programme Grant Seebibyte EP/M013774/1, the EPSRC CDT in Autonomous Intelligent Machines and Systems, and the Oxford-Google DeepMind Graduate Scholarship. We are very grateful to Rob Cooper and Matt Haynes at BBC Research for help in obtaining the dataset. We would like to thank Ankush Gupta for helpful comments and discussion. Triantafyllos Afouras and Joon Son Chung contributed equally to this work.	Abadi M., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467; Afouras T, 2018, INTERSPEECH, P3514, DOI 10.21437/Interspeech.2018-1943; Andrew Zisserman, 2018, Arxiv, DOI arXiv:1809.00496; Assael Y., 2018, ARXIV; Brendan Shillingford, 2016, Arxiv, DOI arXiv:1611.01599; Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621; Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774; Cho K., 2014, P 2014 C EMP METH NA, P1724; Chorowski J., 2014, P NIPS WORKSH DEEP L; Chorowski J, 2015, ADV NEUR IN, V28; Chung J. S., 2017, P BRIT MACH VIS C; Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19; Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367; Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6; Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005; Czyzewski A, 2017, J INTELL INF SYST, V49, P167, DOI 10.1007/s10844-016-0438-z; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Gabriel Synnaeve, 2019, Arxiv, DOI arXiv:1712.09444; Galatas G, 2012, EUR SIGNAL PR CONF, P2714; Graves A, 2012, ICML WORKSHOP REPRES; Graves A., 2006, P INT C MACH LEARN I; Graves A, 2014, PR MACH LEARN RES, V32, P1764; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; J.Zico Kolter, 2018, Arxiv, DOI arXiv:1803.01271; Kannan A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5824; King DE, 2009, J MACH LEARN RES, V10, P1755; Kingma D.P, 2015, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1412.6980; Koller O, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P477, DOI 10.1109/ICCVW.2015.69; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lienhart R., INT J IMAGE GRAPH, V1, P469, DOI DOI 10.1142/S021946780100027X; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Maas A. L., 2015, PROC N AM CHAPTER AS, P345; Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347; Noda K, 2014, INTERSPEECH, P1149; Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7; Petridis S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6548; Petridis S, 2016, INT CONF ACOUST SPEE, P2304, DOI 10.1109/ICASSP.2016.7472088; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sak H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1468; Simonyan K., 2015, VERY DEEP CONVOLUTIO; Songbai Pu, 2017, Arxiv, DOI arXiv:1702.07793; Stafylakis T, 2017, INTERSPEECH, P3652, DOI 10.21437/Interspeech.2017-85; Sutskever I, 2014, ADV NEUR IN, V27; Szegedy C., 2015, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2015.7298594; Tamura S, 2015, ASIAPAC SIGN INFO PR, P575, DOI 10.1109/APSIPA.2015.7415335; Vaswani A., 2017, P 31 INT C NEUR INF, P5998, DOI DOI 10.5555/3295222.3295349; Wand M, 2016, INT CONF ACOUST SPEE, P6115, DOI 10.1109/ICASSP.2016.7472852; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700; Zeghidour N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5509; Zhang Y, 2016, INTERSPEECH, P410, DOI 10.21437/Interspeech.2016-1446; Zhifeng Chen, 2016, ARXIV; Zhou ZH, 2014, IMAGE VISION COMPUT, V32, P590, DOI 10.1016/j.imavis.2014.06.004	56	143	146	7	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					8717	8727		10.1109/TPAMI.2018.2889052	http://dx.doi.org/10.1109/TPAMI.2018.2889052			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	30582526	Green Submitted			2022-12-18	WOS:000880661400015
J	Kobyzev, I; Prince, SJD; Brubaker, MA				Kobyzev, Ivan; Prince, Simon J. D.; Brubaker, Marcus A.			Normalizing Flows: An Introduction and Review of Current Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Estimation; Jacobian matrices; Mathematical model; Training; Computational modeling; Context modeling; Random variables; Generative models; normalizing flows; density estimation; variational inference; invertible neural networks	DENSITY-ESTIMATION	Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.	[Kobyzev, Ivan; Prince, Simon J. D.; Brubaker, Marcus A.] Borealis AI, Montreal, PQ H2S 3H1, Canada		Kobyzev, I (corresponding author), Borealis AI, Montreal, PQ H2S 3H1, Canada.	ivan.kobyzev@borealisai.com; simon.prince@borealisai.com; mab@eecs.yorku.ca		Brubaker, Marcus/0000-0002-7892-9026				Abdelhamed A, 2019, IEEE I CONF COMP VIS, P3165, DOI 10.1109/ICCV.2019.00326; Agnelli JP, 2010, MULTISCALE MODEL SIM, V8, P1784, DOI 10.1137/100783522; [Anonymous], 2017, COMMUN MATH STAT; Arango J., 2002, AEQUATIONES MATH, V64, P304; Arjovsky M, 2017, PR MACH LEARN RES, V70; Arnold V., 1978, ORDINARY DIFFERENTIA; Atanov A., 2019, ARXIV190500505; Behrmann J, 2019, PR MACH LEARN RES, V97; Bengio Yoshua, 2013, ARXIV; Bogachev VI, 2005, SB MATH+, V196, P309, DOI 10.1070/SM2005v196n03ABEH000882; Bose AJ, 2020, PR MACH LEARN RES, V119; Bowman Samuel R, 2016, SIGNLL C COMP NAT LA, DOI DOI 10.18653/V1/K16-1002; Chang B., 2019, INT C LEARN REPR; Chang B, 2018, AAAI CONF ARTIF INTE, P2811; Chen C., 2018, PROC INT C MACH LEAR; Chen RTQ, 2019, ADV NEUR IN, V32; Chen T.Q., 2018, ADV NEURAL INFORM PR; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Das H. P., 2019, ARXIV190801686; Dinh L, 2017, 5 INT C LEARN REPR I; Dinh L., 2019, P INT C LEARN REPR W; Dinh Laurent, 2015, ICLR WORKSH; Dua D., 2017, UCI MACHINE LEARNING, DOI DOI 10.1002/JCC.23219; Dupont Emilien, 2019, ARXIV190401681; Durkan C., 2019, ARXIV PREPRINT ARXIV; Durkan C, 2019, ADV NEUR IN, V32; Esling Philippe, 2019, ARXIV190700971; Falorsi L, 2019, PR MACH LEARN RES, V89; Finlay C, 2020, PR MACH LEARN RES, V119; Gemici M. C., 2016, P NEURIPS WORKSH BAY; Germain M, 2015, PR MACH LEARN RES, V37, P881; Gomez Aidan N, 2017, ADV NEURAL INFORM PR, P2214; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grathwohl W., 2019, P INT C LEARN REPR; GREGORY JA, 1982, IMA J NUMER ANAL, V2, P123, DOI 10.1093/imanum/2.2.123; Grover A, 2018, AAAI CONF ARTIF INTE, P3069; Haber E., 2018, P AAAI C ART INT; Hasenclever L., 2017, WORKSH BAY DEEP LEAR; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Ho Jonathan, 2019, ICML; Hoogeboom E., 2020, ARXIV200111235; Hoogeboom E, 2019, ADV NEUR IN, V32; Hoogeboom E, 2019, PR MACH LEARN RES, V97; Huang CW, 2018, PR MACH LEARN RES, V80; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jacobsen J orn-Henrik, 2018, P ICLR; Jaini P., 2019, ARXIV190704481; Jaini P, 2019, PR MACH LEARN RES, V97; Jankowiak M, 2018, PR MACH LEARN RES, V80; Kanwar G, 2020, PHYS REV LETT, V125, DOI 10.1103/PhysRevLett.125.121601; Katok A., INTRO MODERN THEORY; Kim Sungwon, 2018, ARXIV181102155; Kingma D. P., ARXIV190602691, V2019; Kingma D. P, 2014, ARXIV13126114; Kingma DP, 2018, ADV NEUR IN, V31; Kingma DP., 2016, ADV NEURAL INFORM PR, V29, P4743; Kohler J., 2019, ARXIV191000753; Koller D., 2009, PROBABILISTIC GRAPHI; Kumar M., 2019, ARXIV190301434; Laurence P. M., 2014, P WOLFG PAUL I C EN, P259; Li XC, 2020, PR MACH LEARN RES, V108, P3870; Liutkus A, 2019, PR MACH LEARN RES, V97; Maas A. L., 2013, P 30 INT C MACH LEAR, P3; Madhawa Kaushalya, 2019, ARXIV190511600; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mazoure Bogdan, 2020, ARXIV190506893, P430; Medvedev K. V., 2008, THEORY STOCHASTIC PR, V14, P95; Muller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156; Noe F, 2019, SCIENCE, V365, P1001, DOI 10.1126/science.aaw1147; Oksendal B., 1992, STOCHASTIC DIFFERENT, V3rd; Ovinnikov I., 2018, WORKSH BAYES DEEP LE; Papamakarios George, 2019, ARXIV191202762; Papamakarios George, 2017, ARXIV170507057; Peluchetti S., 2019, ARXIV190511065; Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI 10.1109/ICASSP.2019.8683143; Rezende D. J., 2020, PROC ICML; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Rippel O., 2013, HIGH DIMENSIONAL PRO; Salimans T., 2016, ADV NEUR IN, P2234; Salimans T, 2015, PR MACH LEARN RES, V37, P1218; Salman H., 2018, ARXIV181003256; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Spantini A., 2017, J MACH LEARN RES, V19, P2639; Spivak M., 1965, CALCULUS MANIFOLDS M; Suykens JAK, 1998, NEURAL PROCESS LETT, V7, P81, DOI 10.1023/A:1009632428145; Tabak EG, 2013, COMMUN PUR APPL MATH, V66, P145, DOI 10.1002/cpa.21423; Tabak EG, 2010, COMMUN MATH SCI, V8, P217; Tomczak J. M., 2017, BENELEARN; Tomczak Jakub M, 2016, ARXIV161109630; Touati A., 2019, P C UNC ART INT; Tran D, 2019, ADV NEUR IN, V32; Trippe B. L., 2017, WORKSH BAYES DEEP LE; Tzen B., 2019, NEURAL STOCHASTIC DI; van den Berg R, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P393; van den Oord A., 2017, PARALLEL WAVENET FAS, P3918; Villani C., 2003, GRAD STUD MATH, V58; Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583; Wang P. Z., 2019, ARXIV190402399; Ward P. Nadeem, 2019, WORKSH INV NEUR NETS; Wehenkel A, 2019, ADV NEUR IN, V32; Welling M., 2011, P 28 INT C INT C MAC, P681, DOI DOI 10.4310/CIS.2012.V12.N3.A3; Wirnsberger P, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0018903; Wong KWK, 2020, PHYS REV D, V101, DOI 10.1103/PhysRevD.101.123005; Zhang H., 2019, ARXIV190712998; Zheng G., 2018, ICML WORKSH THEOR FD; Ziegler ZM, 2019, PR MACH LEARN RES, V97	108	143	145	21	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3964	3979		10.1109/TPAMI.2020.2992934	http://dx.doi.org/10.1109/TPAMI.2020.2992934			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32396070	Green Submitted			2022-12-18	WOS:000702649700020
J	Taha, AA; Hanbury, A				Taha, Abdel Aziz; Hanbury, Allan			An Efficient Algorithm for Calculating the Exact Hausdorff Distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hausdorff distance; algorithm; evaluation; runtime analysis; computational complexity	LINEAR-TIME ALGORITHM; SIMILARITY	The Hausdorff distance (HD) between two point sets is a commonly used dissimilarity measure for comparing point sets and image segmentations. Especially when very large point sets are compared using the HD, for example when evaluating magnetic resonance volume segmentations, or when the underlying applications are based on time critical tasks, like motion detection, then the computational complexity of HD algorithms becomes an important issue. In this paper we propose a novel efficient algorithm for computing the exact Hausdorff distance. In a runtime analysis, the proposed algorithm is demonstrated to have nearly-linear complexity. Furthermore, it has efficient performance for large point set sizes as well as for large grid size; performs equally for sparse and dense point sets; and finally it is general without restrictions on the characteristics of the point set. The proposed algorithm is tested against the HD algorithm of the widely used national library of medicine insight segmentation and registration toolkit (ITK) using magnetic resonance volumes with extremely large size. The proposed algorithm outperforms the ITK HD algorithm both in speed and memory required. In an experiment using trajectories from a road network, the proposed algorithm significantly outperforms an HD algorithm based on R-Trees.	[Taha, Abdel Aziz; Hanbury, Allan] Vienna Univ Technol, Inst Software Technol & Interact Syst, A-1040 Vienna, Austria	Technische Universitat Wien	Taha, AA (corresponding author), Vienna Univ Technol, Inst Software Technol & Interact Syst, A-1040 Vienna, Austria.	taha@ifs.tuwien.ac.at; hanbury@ifs.tuwien.ac.at		Taha, Abdel Aziz/0000-0002-7604-9041	European Union [318068]	European Union(European Commission)	The authors would like to thank Bjoern Menze, Computer Aided Medical Procedures, Technical University of Munich for providing the MRI brain segmentations from MICCAI 12 BRATS challenge to be used as test data. The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement 318068 (VISCERAL). Abdel Aziz Taha is the corresponding author.	Alt H., 1991, P 7 ANN S COMP GEOM, P186; ATALLAH MJ, 1983, INFORM PROCESS LETT, V17, P207, DOI 10.1016/0020-0190(83)90042-X; Babalola KO, 2008, LECT NOTES COMPUT SC, V5241, P409, DOI 10.1007/978-3-540-85988-8_49; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Ciesielski KC, 2011, J MATH IMAGING VIS, V39, P193, DOI 10.1007/s10851-010-0232-4; Eric B., 2008, INSIGHT J, P1; Gerig G, 2001, LECT NOTES COMPUTER, V2208, P516; GROLLER E, 1993, VISUALIZATION AND INTELLIGENT DESIGN IN ENGINEERING AND ARCHITECTURE, P61; Guthe M., 2005, J WSCG, V13, P41; Hossain MJ, 2012, CIRC SYST SIGNAL PR, V31, P389, DOI 10.1007/s00034-011-9284-y; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Indyk P, 2003, COMP GEOM-THEOR APPL, V24, P115, DOI 10.1016/S0925-7721(02)00095-0; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Khotanlou H, 2009, FUZZY SET SYST, V160, P1457, DOI 10.1016/j.fss.2008.11.016; Kim HS, 2012, MED PHYS, V39, P6779, DOI 10.1118/1.4754802; Langs Georg, 2013, Medical Content-Based Retrieval for Clinical Decision Support. Third MICCAI International Workshop, MCBR-CDS 2012. Revised Selected Papers, P92, DOI 10.1007/978-3-642-36678-9_9; Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156; Morain-Nicolier F, 2007, P ANN INT IEEE EMBS, P5597, DOI 10.1109/IEMBS.2007.4353615; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Nutanong S, 2011, PROC VLDB ENDOW, V4, P506, DOI 10.14778/2002974.2002978; Papadias D, 2005, ACM T DATABASE SYST, V30, P529, DOI 10.1145/1071610.1071616; Russakoff DB, 2004, LECT NOTES COMPUT SC, V3023, P596; Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923; Tustison N. J., 2006, INSIGHT J, P1	25	143	148	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2153	2163		10.1109/TPAMI.2015.2408351	http://dx.doi.org/10.1109/TPAMI.2015.2408351			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440258				2022-12-18	WOS:000362411000001
J	Huang, XL; Shi, L; Suykens, JAK				Huang, Xiaolin; Shi, Lei; Suykens, Johan A. K.			Support Vector Machine Classifier with Pinball Loss	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification; support vector machine; pinball loss	MARGIN; RISK; ROBUSTNESS	Traditionally, the hinge loss is used to construct support vector machine (SVM) classifiers. The hinge loss is related to the shortest distance between sets and the corresponding classifier is hence sensitive to noise and unstable for re-sampling. In contrast, the pinball loss is related to the quantile distance and the result is less sensitive. The pinball loss has been deeply studied and widely applied in regression but it has not been used for classification. In this paper, we propose a SVM classifier with the pinball loss, called pin-SVM, and investigate its properties, including noise insensitivity, robustness, and misclassification error. Besides, insensitive zone is applied to the pin-SVM for a sparse model. Compared to the SVM with the hinge loss, the proposed pin-SVM has the same computational complexity and enjoys noise insensitivity and re-sampling stability.	[Huang, Xiaolin; Shi, Lei; Suykens, Johan A. K.] Katholieke Univ Leuven, Dept Elect Engn ESAT STADIUS, B-3001 Louvain, Belgium; [Shi, Lei] Fudan Univ, Sch Math Sci, Shanghai 200433, Peoples R China	KU Leuven; Fudan University	Huang, XL (corresponding author), Katholieke Univ Leuven, Dept Elect Engn ESAT STADIUS, B-3001 Louvain, Belgium.	huangxl06@mails.tsinghua.edu.cn; leishi@fudan.edu.cn; johan.suykens@esat.kuleuven.be	Suykens, Johan A.K./C-9781-2014; Shi, Lei/P-1989-2018	Suykens, Johan A.K./0000-0002-8846-6352; Shi, Lei/0000-0002-9512-5273; Huang, Xiaolin/0000-0003-4285-6520	Research Council KUL [GOA/11/05, GOA/10/09, CoE EF/05/006, IOF-SCORES4CHEM]; Flemish Government: FWO [G0226.06, G.0302.07, G.0320.08, G.0558.08, G.0557.08, G.0588.09, G.0377.09, G.0377.12]; IWT; Eureka-Flite+; SBO LeCoPro; SBO Climaqs; SBO POM; OO-Dsquare; Belgian Federal Science PolicyOffice [IUAPP6/04]; IBBT; EU: ERNSI; ERC AdG A-DATADRIVE-B [INFSO-ICT-223854]; COST intelliCIS [ICT-248940]; National Natural Science Foundation of China [11201079]	Research Council KUL(KU Leuven); Flemish Government: FWO(FWO); IWT(Institute for the Promotion of Innovation by Science and Technology in Flanders (IWT)); Eureka-Flite+; SBO LeCoPro; SBO Climaqs; SBO POM; OO-Dsquare; Belgian Federal Science PolicyOffice(Belgian Federal Science Policy OfficeEuropean Commission); IBBT; EU: ERNSI; ERC AdG A-DATADRIVE-B; COST intelliCIS(European Cooperation in Science and Technology (COST)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors are grateful to the anonymous reviewers for insightful comments. This work was supported by Research Council KUL: GOA/11/05 Ambiorics, GOA/10/09 MaNet, CoE EF/05/006 Optimization in Engineering (OPTEC), IOF-SCORES4CHEM, several PhD/postdoc & fellow grants; Flemish Government: FWO: PhD/postdoc grants, projects: G0226.06 (cooperative systems and optimization), G.0302.07 (SVM/Kernel), G.0320.08 (convex MPC), G.0558.08 (Robust MHE), G.0557.08 (Glycemia2), G.0588.09 (Brain-machine) Research Communities (WOG: ICCoS, ANMMM, MLDM); G.0377.09 (Mechatronics MPC), G.0377.12 (Structured models), IWT: PhD Grants, Eureka-Flite+, SBO LeCoPro, SBO Climaqs, SBO POM, O & O-Dsquare; Belgian Federal Science PolicyOffice: IUAPP6/04 (DYSCO, Dynamical systems, control, and optimization, 2007-2011); IBBT; EU: ERNSI; ERC AdG A-DATADRIVE-B, FP7-HD-MPC (INFSO-ICT-223854), in part by COST intelliCIS, FP7-EMBOCON (ICT-248940); Contract Research: AMINAL; Other: Helmholtz: viCERP, ACCM, Bauknecht, Hoerbiger. L. Shi is also supported by the National Natural Science Foundation of China (11201079). J. A. K. Suykens is a Professor at KU Leuven, Belgium.	Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Bishop, 1995, NEURAL NETWORKS PATT; Brabanter J.D., 2002, LEAST SQUARES SUPPOR, DOI DOI 10.1142/9789812776655; Christmann A, 2004, J MACH LEARN RES, V5, P1007; Christmann A., 2007, ADV NEURAL INFORM PR, P305; Feng JF, 2001, IEEE T NEURAL NETWOR, V12, P1255, DOI 10.1109/72.950155; Guyon I., 1996, ADV KNOWLEDGE DISCOV, P181; Herbrich R, 1999, IEE CONF PUBL, P880, DOI 10.1049/cp:19991223; Hu WJ, 2004, IEEE T CIRCUITS-II, V51, P234, DOI 10.1109/TCSII.2004.824044; Jin B, 2007, INFORM SCIENCES, V177, P476, DOI 10.1016/j.ins.2006.03.015; Jumutc V., 2013, P INT JOINT C NEUR N, P1122; Koenker R., 2005, QUANTILE REGRESSION, DOI DOI 10.1017/CBO9780511754098; Lanckriet G. R. G., 2003, Journal of Machine Learning Research, V3, P555, DOI 10.1162/153244303321897726; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; Lingras P, 2007, INFORM SCIENCES, V177, P3782, DOI 10.1016/j.ins.2007.03.028; Mason L, 2000, ADV NEUR IN, V12, P512; Nock R, 2009, IEEE T PATTERN ANAL, V31, P2048, DOI 10.1109/TPAMI.2008.225; Reid MD, 2011, J MACH LEARN RES, V12, P731; Shivaswamy PK, 2006, J MACH LEARN RES, V7, P1283; Song Q, 2002, IEEE T SYST MAN CY C, V32, P440, DOI 10.1109/TSMCC.2002.807277; Steinwart I., 2008, SUPPORT VECTOR MACHI; Steinwart I, 2011, BERNOULLI, V17, P211, DOI 10.3150/10-BEJ267; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Van Gestel T, 2002, NEURAL COMPUT, V14, P1115, DOI 10.1162/089976602753633411; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wu YC, 2007, J AM STAT ASSOC, V102, P974, DOI 10.1198/016214507000000617; Xu H, 2009, J MACH LEARN RES, V10, P1485; Xuegong Zhang, 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P3, DOI 10.1109/NNSP.1999.788117; Yoon M, 2003, IEEE IJCNN, P2049; Zhang J. B. T., 2004, ADV NEURAL INF PROCE, V17, P161; Zhang JH, 2008, INFORM SCIENCES, V178, P2204, DOI 10.1016/j.ins.2007.12.012; Zhang T, 2004, J MACH LEARN RES, V5, P1225	33	143	154	10	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					984	997		10.1109/TPAMI.2013.178	http://dx.doi.org/10.1109/TPAMI.2013.178			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353231				2022-12-18	WOS:000336054200012
J	Oreifej, O; Li, X; Shah, M				Oreifej, Omar; Li, Xin; Shah, Mubarak			Simultaneous Video Stabilization and Moving Object Detection in Turbulence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-term decomposition; turbulence mitigation; rank optimization; moving object detection; particle advection; restoring force	RESTORATION; COMPONENTS	Turbulence mitigation refers to the stabilization of videos with nonuniform deformations due to the influence of optical turbulence. Typical approaches for turbulence mitigation follow averaging or dewarping techniques. Although these methods can reduce the turbulence, they distort the independently moving objects, which can often be of great interest. In this paper, we address the novel problem of simultaneous turbulence mitigation and moving object detection. We propose a novel three-term low-rank matrix decomposition approach in which we decompose the turbulence sequence into three components: the background, the turbulence, and the object. We simplify this extremely difficult problem into a minimization of nuclear norm, Frobenius norm, and l(1) norm. Our method is based on two observations: First, the turbulence causes dense and Gaussian noise and therefore can be captured by Frobenius norm, while the moving objects are sparse and thus can be captured by l(1) norm. Second, since the object's motion is linear and intrinsically different from the Gaussian-like turbulence, a Gaussian-based turbulence model can be employed to enforce an additional constraint on the search space of the minimization. We demonstrate the robustness of our approach on challenging sequences which are significantly distorted with atmospheric turbulence and include extremely tiny moving objects.	[Oreifej, Omar; Li, Xin; Shah, Mubarak] Univ Cent Florida, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Oreifej, O (corresponding author), Univ Cent Florida, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	oreifej@eecs.ucf.edu; xli@math.ucf.edu; shah@eecs.ucf.edu	Li, Xin/V-7387-2017	Shah, Mubarak/0000-0001-6172-5572	Night Vision and Electronic Sensors Directorate (NVESD) [W15P7T-08-D-P417]	Night Vision and Electronic Sensors Directorate (NVESD)	This work was supported by the Night Vision and Electronic Sensors Directorate (NVESD) under contract number W15P7T-08-D-P417. The authors thank Teresa Pace from NVESD for introducing them to the problem, providing the dataset, and conducting useful discussions. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of NVESD.	Agarwal A., 2011, TECHNICAL REPORT; Ali S., 2007, P IEEE C COMP VIS PA; [Anonymous], 2009, TECHNICAL REPORT; Aubailly G.C.M., 2009, P SOC PHOTO-OPT INS, V7463; Bertsekas D. P., 2004, NONLINEAR PROGRAMMIN; Bjorck A., 1996, NUMERICAL METHODS LE; Branover H., 1994, PROGR TURBULENCE RES; Buades Antoni, 2005, CVPR; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes E.J., 2009, P IEEE SENS ARR MULT; Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229; Chang MPJL, 2007, PROC SPIE, V6551, DOI 10.1117/12.718257; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Donate A., 2006, P 18 INT C PATT REC; Efros A., 2004, P NEUR INF PROC SYST; Elgammal A., 1999, P 6 IEEE INT C COMP; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; Glowinski R., 1975, REV FRANCAISE AUTOMA; Goldfarb D., 2009, PREPRINT; Goodman J. W., 2000, STAT OPTICS; Goodman J. W., 2017, INTRO FOURIER OPTICS, V4th; He B., 2011, LINEARIZED ALTERNATI; ISICHENKO MB, 1994, PHYS PLASMAS, V1, P1802, DOI 10.1063/1.870634; Ji H., 2010, P IEEE C COMP VIS PA; Joshi N., 2010, P IEEE INT C COMP PH; Li DL, 2007, IEEE GEOSCI REMOTE S, V4, P340, DOI 10.1109/LGRS.2007.895691; Liu C., 2010, P 11 EUR C COMP VIS; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Oreifej Omar, 2011, P IEEE C COMP VIS PA; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Roggemann Michael C, 1996, IMAGING TURBULENCE; Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894; Tian Y., 2009, P 12 IEEE INT C COMP; Tian Y., 2010, P IEEE C COMP VIS PA; Wen Z., 2007, P IEEE INT C IM PROC; Wu S., 2011, P 12 IEEE INT C COMP; Wu S., 2010, P IEEE C COMP VIS PA; Yitzhaky Y, 1997, OPT ENG, V36, P3064, DOI 10.1117/1.601526; Yu Y., 2011, P C UNC ART INT; Zhang Y, 2010, ALTERNATING DIRECTIO; Zhu X., 2010, P SOC PHOTO-OPT INS, V7543, p75430S; Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992; [No title captured]; [No title captured]	46	143	152	3	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					450	462		10.1109/TPAMI.2012.97	http://dx.doi.org/10.1109/TPAMI.2012.97			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22529321	Green Submitted			2022-12-18	WOS:000312560600016
J	Espana-Boquera, S; Castro-Bleda, MJ; Gorbe-Moya, J; Zamora-Martinez, F				Espana-Boquera, Salvador; Jose Castro-Bleda, Maria; Gorbe-Moya, Jorge; Zamora-Martinez, Francisco			Improving Offline Handwritten Text Recognition with Hybrid HMM/ANN Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Handwriting recognition; offline handwriting; hybrid HMM/ANN; HMM; neural networks; multilayer perceptron; image normalization	DOCUMENT ANALYSIS; NEURAL-NETWORKS; LINE; ONLINE; CHARACTER	This paper proposes the use of hybrid Hidden Markov Model (HMM)/Artificial Neural Network (ANN) models for recognizing unconstrained offline handwritten texts. The structural part of the optical models has been modeled with Markov chains, and a Multilayer Perceptron is used to estimate the emission probabilities. This paper also presents new techniques to remove slope and slant from handwritten text and to normalize the size of text images with supervised learning methods. Slope correction and size normalization are achieved by classifying local extrema of text contours with Multilayer Perceptrons. Slant is also removed in a nonuniform way by using Artificial Neural Networks. Experiments have been conducted on offline handwritten text lines from the IAM database, and the recognition rates achieved, in comparison to the ones reported in the literature, are among the best for the same task.	[Espana-Boquera, Salvador; Jose Castro-Bleda, Maria; Gorbe-Moya, Jorge; Zamora-Martinez, Francisco] Univ Politecn Valencia, Dept Sistemas Informat & Computac, Valencia 46022, Spain; [Zamora-Martinez, Francisco] Univ CEU Cardenal Herrera, Dept Ciencias Fis Matemat & Computac, Valencia, Spain	Universitat Politecnica de Valencia; Universidad CEU Cardenal Herrera	Espana-Boquera, S (corresponding author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Camino Vera S-N, Valencia 46022, Spain.	sespana@dsic.upv.es; mcastro@dsic.upv.es; jgorbe@dsic.upv.es; fzamora@dsic.upv.es	Castro-Bleda, M. J./H-2372-2011		Spanish Ministerio de Educacion y Ciencia [TIN2006-12767]; Conselleria d'Empresa, Universitat i Ciencia, Generalitat Valenciana [06/250]	Spanish Ministerio de Educacion y Ciencia(Spanish Government); Conselleria d'Empresa, Universitat i Ciencia, Generalitat Valenciana(Center for Forestry Research & Experimentation (CIEF))	The authors acknowledge the valuable help provided by Moises Pastor, Juan Miguel Vilar, Alex Graves, and Marcus Liwicki. Thanks are also due to the reviewers and the Editor-in-Chief for their many valuable comments and suggestions. This work has been partially supported by the Spanish Ministerio de Educacion y Ciencia (TIN2006-12767) and by the BPFI 06/250 Scholarship from the Conselleria d'Empresa, Universitat i Ciencia, Generalitat Valenciana.	Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845; Bauer L., 1993, MANUAL INFORM ACCOMP; BENGIO Y, 1995, NEURAL COMPUT, V7, P1289, DOI 10.1162/neco.1995.7.6.1289; Bengio Y., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P647, DOI 10.1142/S0218001493000327; Bengio Y., 2009, FDN TRENDS MACHINE L, V2; Bengio Y, 2006, P 19 INT C NEUR INF, P153; Bertolami R, 2008, PATTERN RECOGN, V41, P3452, DOI 10.1016/j.patcog.2008.04.003; Bertolami R, 2008, LECT NOTES COMPUT SC, V4768, P265, DOI 10.1007/978-3-540-78199-8_16; Bishop, 1995, NEURAL NETWORKS PATT; Bourlard H., 1994, CONNECTIONIST SPEECH; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; Bunke H, 2003, PROC INT CONF DOC, P448; BURGES C, 1992, P INT JOINT C NEUR N, V3, P165; Burges C. J. C., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P689, DOI 10.1142/S0218001493000340; Burr D. J., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1027; Caillault E, 2007, INT J PATTERN RECOGN, V21, P117, DOI 10.1142/S0218001407005338; CASTRO MJ, 1999, P 6 EUR C SPEECH COM, V3, P1299; CASTRO MJ, 2000, P 5 IB S PATT REC, P797; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; ESPANABOQUERA S, 2007, P 2 INT WORK C INT 1, P327; ESPANABOQUERA S, 2007, P INT C ADV NONL SPE, P179; Francis W. N., 1979, DEP LINGUISTICS; Fujisawa H, 2008, PATTERN RECOGN, V41, P2435, DOI 10.1016/j.patcog.2008.03.015; GEMELLOVO R, 2008, HYBRID HMM NEURAL NE; Gorbe-Moya J, 2008, PATTERN RECOGNITION IN INFORMATION SYSTEMS, PROCEEDINGS, P164; Graves A., 2008, ADV NEURAL INFORM PR, V20, P1; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Hidalgo JL, 2005, LECT NOTES COMPUT SC, V3522, P376; JAEGER S, 2000, P 7 INT WORKSH FRONT, P249; Jelinek Frederick, 1997, STAT METHODS SPEECH; Johansson S., 1986, TAGGED LOB CORPUS US; Kim JH, 2000, PATTERN ANAL APPL, V3, P314, DOI 10.1007/s100440070003; Knerr S, 1998, INT C PATT RECOG, P1518, DOI 10.1109/ICPR.1998.711996; Koerich AL, 2003, PATTERN ANAL APPL, V6, P97, DOI 10.1007/s10044-002-0169-3; Koerich AL, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P99, DOI 10.1109/IWFHR.2002.1030893; Marinai S, 2005, IEEE T PATTERN ANAL, V27, P23, DOI 10.1109/TPAMI.2005.4; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886; Vilar JM, 2008, INT CONF ACOUST SPEE, P5101, DOI 10.1109/ICASSP.2008.4518806; Pastor M, 2004, LECT NOTES COMPUT SC, V3212, P183; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rabiner L., 1993, FUNDAMENTALS SPEECH; ROMERO V, 2006, P 6 IASTED INT C VIS, P389; SCHENK J, 2008, P INT C FRONT HANDW, P540; SCHENKEL M, 1995, MACH VISION APPL, V8, P215, DOI 10.1007/BF01219589; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; Simard PY, 2005, PROC INT CONF DOC, P1182, DOI 10.1109/ICDAR.2005.143; Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040; Stolcke Andreas, 2002, P INT, P901; Tay YH, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P1190; Toselli AH, 2004, INT J PATTERN RECOGN, V18, P519, DOI 10.1142/S0218001404003344; Uchida S, 2001, PROC INT CONF DOC, P434, DOI 10.1109/ICDAR.2001.953827; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7; Vinciarelli A, 2001, PATTERN RECOGN LETT, V22, P1043, DOI 10.1016/S0167-8655(01)00042-3; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; Young S.J., 1993, HTK HIDDEN MARKOV MO; Zamora-Martinez F, 2010, LECT NOTES ARTIF INT, V5988, P61, DOI 10.1007/978-3-642-14264-2_7	59	143	147	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					767	779		10.1109/TPAMI.2010.141	http://dx.doi.org/10.1109/TPAMI.2010.141			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20714016				2022-12-18	WOS:000287370400009
J	Ross, A; Shah, J; Jain, AK				Ross, Arun; Shah, Jidnya; Jain, Anil K.			From template to image: Reconstructing fingerprints from minutiae points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprints; minutiae; templates; security; fingerprint reconstruction; line integral convolution; streamlines		Most fingerprint-based biometric systems store the minutiae template of a user in the database. It has been traditionally assumed that the minutiae template of a user does not reveal any information about the original fingerprint. In this paper, we challenge this notion and show that three levels of information about the parent fingerprint can be elicited from the minutiae template alone, viz., 1) the orientation field information, 2) the class or type information, and 3) the friction ridge structure. The orientation estimation algorithm determines the direction of local ridges using the evidence of minutiae triplets. The estimated orientation field, along with the given minutiae distribution, is then used to predict the class of the fingerprint. Finally, the ridge structure of the parent fingerprint is generated using streamlines that are based on the estimated orientation field. Line Integral Convolution is used to impart texture to the ensuing ridges, resulting in a ridge map resembling the parent fingerprint. The salient feature of this noniterative method to generate ridges is its ability to preserve the minutiae at specified locations in the reconstructed ridge map. Experiments using a commercial fingerprint matcher suggest that the reconstructed ridge structure bears close resemblance to the parent fingerprint.	W Virginia Univ, Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA; L1 Identity Solut Corp Res Ctr, Jersey City, NJ 07302 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	West Virginia University; Michigan State University	Ross, A (corresponding author), W Virginia Univ, Dept Comp Sci & Elect Engn, POB 6109, Morgantown, WV 26506 USA.	arun.ross@mail.wvu.edu; jidnya@gmail.com; jain@cse.msu.edu						ADLER A, 2003, P BIOM CONS C SEPT; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Cabral B., 1993, P 20 ANN C COMP GRAP, P263, DOI DOI 10.1145/166117.166151>; Candela G. T., 1995, 5647 NIST TR; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586; Champod C., 1996, P INT S FING DET ID, P305; CHO B, 2000, P 15 INT C PATT REC, V2, P863; Chong MMS, 1997, PATTERN RECOGN, V30, P1475, DOI 10.1016/S0031-3203(96)00178-1; Galton Francis, 1892, FINGER PRINTS; Henry ER., 1900, CLASSIFICATION USES; Hill C.J., 2001, THESIS AUSTR NATL U; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; HONG L, 1999, P 11 SCAND C IM AN J; *IB GROUP, 2002, GEN IM TEMPL; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jain AK, 2002, INT C PATT RECOG, P469, DOI 10.1109/ICPR.2002.1048340; JOBARD B, 1997, P EUR WORKSH VIS SCI; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; KINGSTON CR, 1964, THESIS U CALIFORNIA; Laidlaw DH, 2005, IEEE T VIS COMPUT GR, V11, P59, DOI 10.1109/TVCG.2005.4; Moenssens A.A., 1971, FINGERPRINT TECHNIQU; Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896; Prabhakar S., 2003, HDB FINGERPRINT RECO; RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3; Ross A, 2005, PROC SPIE, V5779, P68, DOI 10.1117/12.604477; ROXBURGH T, 1993, SANKHYA INDIAN J STA, P189; SADARJOEN A, 1994, P 5 EUR WORKSH VIS S; Senior A, 2001, IEEE T PATTERN ANAL, V23, P1165, DOI 10.1109/34.954606; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; Stoney D.A., 1985, THESIS U CALIFORNIA; Verma V, 2000, IEEE VISUAL, P163, DOI 10.1109/VISUAL.2000.885690; Wilson C. L., 1994, Journal of Artificial Neural Networks, V1, P203; Yao Y, 2001, LECT NOTES COMPUT SC, V2091, P253	34	143	164	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					544	560		10.1109/TPAMI.2007.1018	http://dx.doi.org/10.1109/TPAMI.2007.1018			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299213				2022-12-18	WOS:000244855600004
J	Nadimi, S; Bhanu, B				Nadimi, S; Bhanu, B			Physical models for moving shadow and object detection in video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						detecting moving objects; dichromatic reflection model; physics-based segmentation; shadows in video; spatio-temporal albedo ratio		Current moving object detection systems typically detect shadows cast by the moving object as part of the moving object. In this paper, the problem of separating moving cast shadows from the moving objects in an outdoor environment is addressed. Unlike previous work, we present an approach that does not rely on any geometrical assumptions such as camera location and ground surface/object geometry. The approach is based on a new spatio-temporal albedo test and dichromatic reflection model and accounts for both the sun and the sky illuminations. Results are presented for several video sequences representing a variety of ground materials when the shadows are cast on different surface types. These results show that our approach is robust to widely different background and foreground materials, and illuminations.	Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	University of California System; University of California Riverside	Nadimi, S (corresponding author), Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.	sohail@cris.ucr.edu; bhanu@cris.ucr.edu		Bhanu, Bir/0000-0001-8971-6416				Cucchiara R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P334, DOI 10.1109/ITSC.2001.948679; Das S, 1998, PATTERN RECOGN, V31, P465, DOI 10.1016/S0031-3203(97)00061-7; GERSHON R, 1986, J OPT SOC AM A, V3, P1700, DOI 10.1364/JOSAA.3.001700; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Horprasert T, 1999, P IEEE C COMP VIS KE, P1; Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1; Mikic I., 1998, P INT C PATTERN RECO, V1, P321; Nadimi S, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P317, DOI 10.1109/MFI.2001.1013554; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; Onoguchi E, 1998, INT C PATT RECOG, P583, DOI 10.1109/ICPR.1998.711210; Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520; SCANLAN JM, 1990, P INT C AC SPEECH SI, V4, P2057; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SONADA Y, 1998, P INT C SIGNAL PROCE, V2, P1261; Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677	16	143	186	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1079	1087		10.1109/TPAMI.2004.51	http://dx.doi.org/10.1109/TPAMI.2004.51			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641737	Green Submitted			2022-12-18	WOS:000221872400011
J	Egnal, G; Wildes, RP				Egnal, G; Wildes, RP			Detecting binocular half-occlusions: Empirical comparisons of five approaches	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo matching; binocular half-occlusions; three-dimensional vision; empirical comparisons	OCCLUDING CONTOURS; STEREOPSIS	Binocular half-occlusion points are those that are visible in one of the two views provided by a binocular imaging system. Due to their importance in binocular matching as well as, subsequent interpretation tasks, a number of approaches have been developed for dealing with such points. In the current paper, we consider five methods that explicitly detect half-occlusions and report on a more uniform comparison than has previously been performed. Taking a disparity image and its associated match goodness image as input, we generate images that show the half-occluded points in the underlying scene. We quantitatively and qualitatively compare these methods under a variety of conditions.				gegnal@gradient.cis.upenn.edu; wildes@cs.yorku.ca						ANDERSON BL, 1994, PSYCHOL REV, V101, P414, DOI 10.1037/0033-295X.101.3.414; BAKER HH, 1981, P 7 INT JOINT C ART, P631; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; BOLLES RC, 1993, P DARPA IM UND WORKS, P263; *CARN MELL U, 2001, VASC IM DAT      JAN; Chang C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P722, DOI 10.1109/CVPR.1991.139799; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Egnal G, 2000, PROC CVPR IEEE, P466, DOI 10.1109/CVPR.2000.854883; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; GILLAM B, 1988, PERCEPTION, V17, P603, DOI 10.1068/p170603; Howard I.P., 1995, BINOCULAR VISION STE; INTILLE SS, 1994, P 3 EUR C COMP VIS, P179; Konolige Kurt, 1997, P INT S ROB RES; KROL JD, 1982, PERCEPTION, V11, P615, DOI 10.1068/p110615; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAWSON RB, 1967, VISION RES, V7, P271, DOI 10.1016/0042-6989(67)90091-0; LITTLE J, 1990, P EUR C COMP VIS, P336; LUO A, 1995, INT J COMPUT VISION, V15, P171, DOI 10.1007/BF01451740; NAKAYAMA K, 1990, VISION RES, V30, P1811, DOI 10.1016/0042-6989(90)90161-D; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; RICHTER J, 1977, SELECTIONS NOTEBOOKS; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; SMITLEY T, 1984, P INT JOINT C PATT R, P405; Spoerri A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P209; SZELISKI R, 1999, P INT WORKSH VIS ALG, P1; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; TRAPP R, 1998, P ECCV, P17; WENG J, 1988, P INT C COMP VIS, P64; WILDES RP, 1991, IEEE T PATTERN ANAL, V13, P761, DOI 10.1109/34.85667; YUILLE AL, 1984, GEN ORDERING CONSTRA	35	143	155	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1127	1133		10.1109/TPAMI.2002.1023808	http://dx.doi.org/10.1109/TPAMI.2002.1023808			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100010
J	Lotlikar, R; Kothari, R				Lotlikar, R; Kothari, R			Fractional-step dimensionality reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; classification; Fisher's Linear Discriminant		Linear projections for dimensionality reduction, computed using linear discriminant analysis (LDA), are commonly based on optimization of certain separability criteria in the output space. The resulting optimization problem is linear, but these separability criteria are not directly related to the classification accuracy in the output space. Consequently, a trial and error procedure has to be invoked, experimenting with different separability criteria that differ in the weighting function used and selecting the one that performed best on the training set. Often, even the best weighting function among the trial choices results in poor classification of data in the subspace. In this short paper, we introduce the concept of fractional dimensionality and develop an incremental procedure, called the fractional-step LDA (F-LDA) to reduce the dimensionality in fractional steps. The F-LDA algorithm is more robust to the selection of weighting function and for any given weighting function, it finds a subspace in which the classification accuracy is higher than that obtained using LDA.	Univ Cincinnati, Dept Elect & Comp Engn, Artificial Neural Syst Lab, Cincinnati, OH 45221 USA	University System of Ohio; University of Cincinnati	Lotlikar, R (corresponding author), Univ Cincinnati, Dept Elect & Comp Engn, Artificial Neural Syst Lab, Cincinnati, OH 45221 USA.	rlotlika@ececs.uc.edu; ravi.kothari@uc.edu						BUTUROVIC LJ, 1994, IEEE T PATTERN ANAL, V16, P420, DOI 10.1109/34.277596; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kohonen T., 1995, SELF ORG MAPS; Lotlikar R, 2000, IEEE T NEURAL NETWOR, V11, P452, DOI 10.1109/72.839014; Merz C., 1996, UCI REPOSITORY MACHI; RIPLEY BD, RTP ARCH; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678	9	143	157	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					623	627		10.1109/34.862200	http://dx.doi.org/10.1109/34.862200			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700007
J	Ueda, N				Ueda, N			Optimal linear combination of neural networks for improving classification performance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; ensemble learning; linear combination; minimum classification error discriminant; neural network	RECOGNITION	With a focus on classification problems, this paper presents a new method for linearly combining multiple neural network classifiers based on statistical pattern recognition theory. In our approach. several neural networks are first selected based on which works best for each class in terms of minimizing classification errors. Then, they are linearly combined to form an ideal classifier that exploits the strengths of the individual classifiers. In this approach, the minimum classification error (MCE) criterion is utilized to estimate the optimal linear weights. In this formulation, because the classification decision rule is incorporated into the cost function a more suitable better combination of weights for the classification objective could be obtained. Experimental results using artificial and real data sets show that the proposed method can construct a better combined classifier that outperforms the best single classifier in terms of overall classification errors for test data.	Nippon Telegraph & Tel Corp, Commun Sci Labs, Kyoto 6190237, Japan	Nippon Telegraph & Telephone Corporation	Ueda, N (corresponding author), Nippon Telegraph & Tel Corp, Commun Sci Labs, Seika Cho, Kyoto 6190237, Japan.	ueda@cslab.kecl.ntt.co.jp						Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191; Bishop, 1995, NEURAL NETWORKS PATT; BLUM JR, 1954, ANN MATH STAT, V25, P382, DOI 10.1214/aoms/1177728794; Breiman L, 1996, MACH LEARN, V24, P49; BREIMAN L, 1996, 460 TR U CAL DEP STA; BREIMAN L, 1994, 421 TR U CAL DEP STA; CHAPLIN WG, 1967, COMPUTER INFORMATION, V2, P337; Duda R.O., 1973, J ROYAL STAT SOC SER; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Komori T., 1992, Journal of the Acoustical Society of Japan (E), V13, P341, DOI 10.1250/ast.13.341; Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231; *MATHW INC, 1996, OPT TOOB US GUID; MCDERMOTT E, 1994, APPL INTELL, V4, P245, DOI 10.1007/BF00872091; PERRONE M, 1993, THESIS BROWN U; PRECHELT L, 1994, 21 TR U KARLSR; Saito K, 1997, NEURAL COMPUT, V9, P123, DOI 10.1162/neco.1997.9.1.123; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9, P127, DOI 10.1080/02331887808801414; Tresp V., 1995, Advances in Neural Information Processing Systems 7, P419; TURNER K, 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; UEDA N, 1997, P IEEE C NEUR NETW S, P365; UEDA N, 1996, P INT C NEUR NETW, P90; Watanabe H, 1997, IEEE T SIGNAL PROCES, V45, P2655, DOI 10.1109/78.650091; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	25	143	151	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					207	215		10.1109/34.825759	http://dx.doi.org/10.1109/34.825759			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400008
J	BERGEN, JR; BURT, PJ; HINGORANI, R; PELEG, S				BERGEN, JR; BURT, PJ; HINGORANI, R; PELEG, S			A 3-FRAME ALGORITHM FOR ESTIMATING 2-COMPONENT IMAGE MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							MOVING-OBJECTS; OPTICAL-FLOW	A fundamental assumption made in formulating optical-flow algorithms is that motion at any point in an image can be represented as a single pattern component undergoing a simple translation; even complex motion will appear as a uniform displacement when viewed through a sufficiently small window. This assumption fails for a number of situations that commonly occur in real-world images. For example, transparent surfaces moving past one another yield two motion components at a point. More important, it fails along the boundary between two differently moving image regions. Even local motion analysis must be performed within a window of finite size. This window contains two motion components when it falls on a motion boundary. We propose an alternative formulation of the local motion assumption in which there may be two distinct patterns undergoing coherent (e.g., affine) motion within a given local analysis region. We then present an algorithm for the analysis of two-component motion in which tracking and nulling mechanisms applied to three consecutive image frames separate and estimate the individual components. Precise results are obtained even for components that differ only slightly in velocity as well as for a faint component in the presence of a dominant, masking component. We demonstrate that the algorithm provides precise motion estimates for a set of elementary two-motion configurations and show that it is robust in the presence of noise.	AT&T BELL LABS,HDTV SYST DEV DEPT,MURRAY HILL,NJ 07974; HEBREW UNIV JERUSALEM,DEPT COMP SCI,JERUSALEM,ISRAEL	AT&T; Nokia Corporation; Nokia Bell Labs; Hebrew University of Jerusalem	BERGEN, JR (corresponding author), DAVID SARNOFF RES CTR,PRINCETON,NJ 08543, USA.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1987, MAY INT C COMP VIS L, P219; BERGEN JR, 1987, J OPT SOC AM A, V4, P35; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; BURT PJ, 1983, JUN P IEEE C COMP VI, P246; BURT PJ, 1989, IEEE MOTION WORKSHOP, P2; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Girod B., 1989, Image Understanding and Machine Vision 1989. Technical Digest Series, Vol.14. Conference Edition, P73; Heeger D. J., 1988, INT J COMPUT VISION, V1, P279; HILDRETH E, 1983, MEASUREMENT VISUAL M; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; KEREN D, 1988, JUN P IEEE C COMP VI, P742; Limb J. O., 1975, Computer Graphics and Image Processing, V4, P311, DOI 10.1016/0146-664X(75)90001-5; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; Pavlidis T., 1977, STRUCTURAL PATTERN R; PELEG S, 1990, JUN P INT C PATT REC, V1, P109; SHIZAWA M, 1990, JUN INT C PATT REC A, P274	21	143	171	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1992	14	9					886	896		10.1109/34.161348	http://dx.doi.org/10.1109/34.161348			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JL924					2022-12-18	WOS:A1992JL92400002
J	TURK, MA; MORGENTHALER, DG; GREMBAN, KD; MARRA, M				TURK, MA; MORGENTHALER, DG; GREMBAN, KD; MARRA, M			VITS - A VISION SYSTEM FOR AUTONOMOUS LAND VEHICLE NAVIGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MARTIN MARIETTA AEROSP,ADV AUTOMAT TECHNOL SECT,DENVER,CO 80201; MARTIN MARIETTA AEROSP,AUTONOMOUS LAND VEHICLE PROGRAM,DENVER,CO 80201; CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University								BARNARD S, 1986, OCT P SPIE MOB ROB C, P143; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; COLEMAN GB, 1979, P IEEE, V67, P872; Crowley J. L., 1985, IEEE Journal of Robotics and Automation, VRA-1, P31, DOI 10.1109/JRA.1985.1087002; DAILY MJ, 1987, FEB DET OBST RANG IM, P87; DEMENTHON D, 1987, APR P IEEE INT C ROB, P1444; DESAINTVINCENT AR, 1986, APR P IEEE INT C ROB, P1105; DICKMANNS ED, 1986, OCT P SPIE MOB ROB C, P161; Duda R.O., 1973, J ROYAL STAT SOC SER; DUNLAY RT, 1986, 2ND T SME WORLD C RO; DUNLAY RT, 1986, OCT P SPIE MOB ROB C, P110; GERSHON R, 1986, RBCVTR869 U TOR DEP; GOTO Y, 1987, APR P IEEE INT C ROB, P99; GROSS T, 1985, MAR IEEE INT C ROB A, P790; Hanson A., 1978, COMPUTER VISION SYST; HEBERT M, 1986, APR P IEEE COMP SOC, P1426; Horn B., 1986, ROBOT VISION, P1; INIGO RM, 1984, IEEE T PATTERN ANAL, V6, P820, DOI 10.1109/TPAMI.1984.4767606; JULLIERE M, 1983, 13TH P INT S IND ROB; KUAN D, 1986, AUG P AAAI 86 PHIL; KUAN D, 1987, APR P IEEE INT C ROB, P416; KUHNERT K, 1986, OCT P SPIE MOB ROB C, P267; LAWTON DT, 1986, APR P IEEE INT C ROB, P2043; Lowrie James W., 1985, P SPIE INTELLIGENT R, P336; Moravec H., 1980, THESIS STANFORD U ST; MORAVEC HP, 1983, P IEEE, V71, P872, DOI 10.1109/PROC.1983.12684; MORAVEC HP, 1986, MIND CHILDREN; MORGENTHALER D, 1986, HILL DALE GEOMETRY; MYSLIWETZ B, 1986, DEC P INT AUT SYST A; OLIN KE, 1987, FEB P DARPA IM UND W, P78; POGGIO T, 1985, COMPUT VISION GRAPH, V31, P139, DOI 10.1016/S0734-189X(85)80003-7; THOMPSON AM, 1977, 5TH P INT JOINT C AR, P749; THORPE CE, 1984, THESIS CARNEGIEMELLO; TSUGAWA S, 1979, 6TH P INT JOINT C AR, P893; TSUJI S, 1986, APR P IEEE INT C ROB, P1594; TURK MA, 1986, OCT P SPIE MOB ROB C, P136; WALLACE R, P IJCAI 85; WALLACE R, 1986, APR P IEEE INT C RON, P1426; WALLACE RS, P AAAI 86; WAXMAN AM, 1987, IEEE T ROBOTIC AUTOM, V3, P124, DOI 10.1109/JRA.1987.1087089; WAXMAN AM, 1985, MAR P IEEE INT C ROB	41	143	170	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					342	361		10.1109/34.3899	http://dx.doi.org/10.1109/34.3899			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700006
J	KELLER, JM; HUNT, DJ				KELLER, JM; HUNT, DJ			INCORPORATING FUZZY MEMBERSHIP FUNCTIONS INTO THE PERCEPTRON ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KELLER, JM (corresponding author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65201, USA.							Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Duda R.O., 1973, J ROYAL STAT SOC SER; Gupta MM, 1979, ADV FUZZY SET THEORY; KAUFMAN A, 1975, INTRO THEORY FUZZY S, V1; LEE ET, 1969, INFORM SCIENCES, V1, P421, DOI 10.1016/0020-0255(69)90025-5; ROSENBLATT F, 1957, PARA854601 CORN U CO; Tou JT, 1974, PATTERN RECOGN; Wang P, 1980, FUZZY SETS THEORY AP; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	9	143	147	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					693	699		10.1109/TPAMI.1985.4767725	http://dx.doi.org/10.1109/TPAMI.1985.4767725			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869307				2022-12-18	WOS:A1985ATG0500007
J	Ma, C; Huang, JB; Yang, XK; Yang, MH				Ma, Chao; Huang, Jia-Bin; Yang, Xiaokang; Yang, Ming-Hsuan			Robust Visual Tracking via Hierarchical Convolutional Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Terms-Hierarchical convolutional features; correlation filters; visual tracking	OBJECT TRACKING; GRADIENTS	Visual tracking is challenging as target objects often undergo significant appearance changes caused by deformation, abrupt motion, background clutter and occlusion. In this paper, we propose to exploit the rich hierarchical features of deep convolutional neural networks to improve the accuracy and robustness of visual tracking. Deep neural networks trained on object recognition datasets consist of multiple convolutional layers. These layers encode target appearance with different levels of abstraction. For example, the outputs of the last convolutional layers encode the semantic information of targets and such representations are invariant to significant appearance variations. However, their spatial resolutions are too coarse to precisely localize the target. In contrast, features from earlier convolutional layers provide more precise localization but are less invariant to appearance changes. We interpret the hierarchical features of convolutional layers as a nonlinear counterpart of an image pyramid representation and explicitly exploit these multiple levels of abstraction to represent target objects. Specifically, we learn adaptive correlation filters on the outputs from each convolutional layer to encode the target appearance. We infer the maximum response of each layer to locate targets in a coarse-to-fine manner. To further handle the issues with scale estimation and re-detecting target objects from tracking failures caused by heavy occlusion or out-of-the-view movement, we conservatively learn another correlation filter, that maintains a long-term memory of target appearance, as a discriminative classifier. We apply the classifier to two types of object proposals: (1) proposals with a small step size and tightly around the estimated location for scale estimation; and (2) proposals with large step size and across the whole image for target re-detection. Extensive experimental results on large-scale benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art tracking methods.	[Ma, Chao; Yang, Xiaokang] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China; [Ma, Chao] Univ Adelaide, Australian Ctr Robot Vis, Adelaide, SA 5005, Australia; [Huang, Jia-Bin] Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA 24061 USA; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Shanghai Jiao Tong University; Australian Centre for Robotic Vision; University of Adelaide; Virginia Polytechnic Institute & State University; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif Merced, Sch Engn, Merced, CA 95344 USA.	chaoma@sjtu.edu.cn; jbhuang@vt.edu; xkyang@sjtu.edu.cn; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Yang, Xiaokang/C-6137-2009; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Yang, Xiaokang/0000-0003-4029-3322; 	National Key Research and Development Program of China [2016YFB1001003]; NSFC [61527804, 61521062]; 111 Program [B07022]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); 111 Program(Ministry of Education, China - 111 Project)	This work is supported in part by the National Key Research and Development Program of China (2016YFB1001003), NSFC (61527804, 61521062) and the 111 Program (B07022).	[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Boddeti VN, 2013, PROC CVPR IEEE, P2291, DOI 10.1109/CVPR.2013.297; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Danelljan M, 2014, BRIT MACHINE VISION; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duy-Nguyen Ta, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2937, DOI 10.1109/CVPRW.2009.5206831; Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286; Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381; Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13; Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675; Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354; Hua Y, 2014, LECT NOTES COMPUT SC, V8694, P172, DOI 10.1007/978-3-319-10599-4_12; Huang D., 2015, P BRIT MACH VIS C SW; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li H, 2014, P BRIT MACH VIS C, DOI 10.5244/c.28.56; Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Ma CQ, 2020, IEEE T SYST MAN CY-S, V50, P1976, DOI 10.1109/TSMC.2018.2819703; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Park IS, 2015, PROC IEEE MICR ELECT, P1059, DOI 10.1109/MEMSYS.2015.7051145; Pernici F, 2012, LECT NOTES COMPUT SC, V7585, P597, DOI 10.1007/978-3-642-33885-4_61; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Simonyan K, 2015, 3 INT C LEARN REPR I; Smeulders A. W. M., 2014, IEEE T PATTERN ANAL, V37, DOI DOI 10.1109/TPAMI.2013.230; Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Vedaldi A., 2014, ARXIV14124564; Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang N., 2013, P 26 INT C NEUR INF, P809; Wang N., 2015, ARXIV150104587; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283; Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26; Zou W.Y., 2012, ADV NEURAL INFORM PR, V25, P3203	79	142	154	9	152	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2709	2723		10.1109/TPAMI.2018.2865311	http://dx.doi.org/10.1109/TPAMI.2018.2865311			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30106709	Green Submitted			2022-12-18	WOS:000489838200011
J	Queirolo, CC; Silva, L; Bellon, ORP; Segundo, MP				Queirolo, Chaua C.; Silva, Luciano; Bellon, Olga R. P.; Segundo, Mauricio Pamplona			3D Face Recognition Using Simulated Annealing and the Surface Interpenetration Measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D face recognition; Surface Interpenetration Measure (SIM); range image registration	REGISTRATION	This paper presents a novel automatic framework to perform 3D face recognition. The proposed method uses a Simulated Annealing-based approach (SA) for range image registration with the Surface Interpenetration Measure (SIM), as similarity measure, in order to match two face images. The authentication score is obtained by combining the SIM values corresponding to the matching of four different face regions: circular and elliptical areas around the nose, forehead, and the entire face region. Then, a modified SA approach is proposed taking advantage of invariant face regions to better handle facial expressions. Comprehensive experiments were performed on the FRGC v2 database, the largest available database of 3D face images composed of 4,007 images with different facial expressions. The experiments simulated both verification and identification systems and the results compared to those reported by state-of-the-art works. By using all of the images in the database, a verification rate of 96.5 percent was achieved at a False Acceptance Rate (FAR) of 0.1 percent. In the identification scenario, a rank-one accuracy of 98.4 percent was achieved. To the best of our knowledge, this is the highest rank-one score ever achieved for the FRGC v2 database when compared to results published in the literature.	[Queirolo, Chaua C.; Silva, Luciano; Bellon, Olga R. P.; Segundo, Mauricio Pamplona] Univ Fed Parana, Dept Informat, BR-81531980 Curitiba, Parana, Brazil	Universidade Federal do Parana	Queirolo, CC (corresponding author), Univ Fed Parana, Dept Informat, Caixa Postal 19092, BR-81531980 Curitiba, Parana, Brazil.	chaua@inf.ufpr.br; luciano@inf.ufpr.br; olga@inf.ufpr.br; mauricio@inf.ufpr.br	Silva, Luciano/A-4812-2010; Incod, Inct/J-8375-2013; Pamplona Segundo, Mauricio/D-3283-2013; Bellon, Olga/E-6564-2011	Silva, Luciano/0000-0001-6341-1323; Pamplona Segundo, Mauricio/0000-0003-4529-5757; 	CNPq; CAPES; FINEP	CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); CAPES(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); FINEP(Financiadora de Inovacao e Pesquisa (Finep))	The authors gratefully acknowledge CNPq, CAPES, and FINEP for financial support. Also, the authors would like to thank Dr. Jonathon Phillips, Dr. Kevin Bowyer, and Dr. Patrick Flynn for allowing them to use the images.	Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018; Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0; Bellon O, 2006, IEEE IMAGE PROC, P2661, DOI 10.1109/ICIP.2006.313057; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bolle R., 2003, GUIDE BIOMETRICS; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; Cook J, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P502, DOI 10.1109/TDPVT.2004.1335279; Cook J, 2006, P IEEE INT C VID SIG, P83; Dalley G, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P246, DOI 10.1109/IM.2001.924446; DROVETTO S, 2008, P VISAPP, V2, P67; FALTEMIER T, 2007, P INT C BIOM THEOR A, V1, P1; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; FLYNN PJ, 2008, HDB BIOMETRICS, P211; Gelfand N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P260, DOI 10.1109/IM.2003.1240258; Huang J, 2003, LECT NOTES COMPUT SC, V2688, P27; HUSKEN M, 2005, P IEEE COMP SOC C CO, P174; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lin WY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P727; Lu X, 2006, P IEEE COMP SOC C CO, P1377, DOI DOI 10.1109/CVPR..96; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; LUNDY M, 1986, MATH PROGRAM, V34, P111, DOI 10.1007/BF01582166; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Maurer T, 2005, P IEEE C COMP VIS PA, P154, DOI DOI 10.1109/CVPR.2005.581; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Phillips PJ, 2005, PROC CVPR IEEE, P947; Queirolo C, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P171, DOI 10.1109/ICIAP.2007.4362775; Rayward-Smith V., 1996, MODERN HEURISTIC SEA; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Segundo MP, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P431, DOI 10.1109/ICIAP.2007.4362816; Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108; SILVA L, 2005, ROBUST RANGE IMAGE R, V60; SILVA L, 2003, P 10 IEEE INT C IM P, V2, P711; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; 2009, IMAGO RES GROUP 3D F	38	142	147	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					206	219		10.1109/TPAMI.2009.14	http://dx.doi.org/10.1109/TPAMI.2009.14			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075453				2022-12-18	WOS:000272741500002
J	Haasdonk, B				Haasdonk, B			Feature space interpretation of SVMs with indefinite kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						support vector machine; indefinite kernel; pseudo-Euclidean space; separation of convex hulls; pattern recognition	CLASSIFICATION	Kernel methods are becoming increasingly popular for various kinds of machine learning tasks, the most famous being the support vector machine (SVM) for classification. The SVM is well understood when using conditionally positive definite (cpd) kernel functions. However, in practice, non-cpd kernels arise and demand application in SVMs. The procedure of "plugging" these indefinite kernels in SVMs often yields good empirical classification results. However, they are hard to interpret due to missing geometrical and theoretical understanding. In this paper, we provide a step toward the comprehension of SVM classifiers in these situations. We give a geometric interpretation of SVMs with indefinite kernel functions. We show that such SVMs are optimal hyperplane classifiers not by margin maximization, but by minimization of distances between convex hulls in pseudo-Euclidean spaces. By this, we obtain a sound framework and motivation for indefinite SVMs. This interpretation is the basis for further theoretical analysis, e. g., investigating uniqueness, and for the derivation of practical guidelines like characterizing the suitability of indefinite SVMs.	Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany	University of Freiburg	Haasdonk, B (corresponding author), Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany.	haasdonk@informatik.uni-freiburg.de						[Anonymous], 1999, UCSCRL9910; [Anonymous], 2003, NEURAL COMPUT; [Anonymous], 2002, LEARNING KERNELS; Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883; Bennett K.P., 2000, ICML, P57; Burges CJC, 2000, ADV NEUR IN, V12, P223; Chang C.-C., LIBSVM LIB SUPPORT V; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Chapelle O, 2000, ADV NEUR IN, V12, P230; Cortes C., 2003, P ADV NEUR INF PROC, V15; Cristianini N., 2000, INTRO SUPPORT VECTOR; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Goldfarb L., 1985, PROGR PATTERN RECOGN, V2, P241; Graepel T, 1999, ADV NEUR IN, V11, P438; Graepel T, 1999, IEE CONF PUBL, P304, DOI 10.1049/cp:19991126; Haasdonk B, 2004, LECT NOTES COMPUT SC, V3175, P220; Haasdonk B, 2002, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2002.1048439; Hein M, 2003, LECT NOTES ARTIF INT, V2777, P72, DOI 10.1007/978-3-540-45167-9_7; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; MARY X, 2003, THESIS INSA ROUEN; Moreno PJ, 2004, ADV NEUR IN, V16, P1385; Pardalos P.M.., 1987, CONSTRAINED GLOBAL O; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; RONNEBERGER O, 2004, LIBSVMTL SUPPORT VEC; SCHOLKOPF B, 2000, 200051 MSR; Sellathurai M, 1999, INT CONF ACOUST SPEE, P1021, DOI 10.1109/ICASSP.1999.759878; Shimodaira H, 2002, ADV NEUR IN, V14, P921; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd	29	142	145	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					482	492		10.1109/TPAMI.2005.78	http://dx.doi.org/10.1109/TPAMI.2005.78			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794155	Green Submitted			2022-12-18	WOS:000226845700001
J	Fischer, B; Buhmann, JM				Fischer, B; Buhmann, JM			Path-based clustering for grouping of smooth curves and texture segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; perceptual grouping; texture Segmentation; resampling		Perceptual Grouping organizes image parts in clusters based on psychophysically plausible similarity measures. We propose a novel grouping method in this paper, which stresses connectedness of image elements via mediating elements rather than favoring high mutual similarity. This grouping principle yields superior clustering results when objects are distributed on low-dimensional extended manifolds in a feature space, and not as local point clouds. In addition to extracting connected structures, objects are singled out as outliers when they are too far away from any cluster structure. The objective function for this perceptual organization principle is optimized by a fast agglomerative algorithm. We report on perceptual organization experiments where small edge elements are grouped to smooth curves. The generality of the method is emphasized by results from grouping textured images with texture gradients in an unsupervised fashion.	Univ Bonn, Dept Comp Sci 3, D-53117 Bonn, Germany	University of Bonn	Fischer, B (corresponding author), Univ Bonn, Dept Comp Sci 3, Romerstr 164, D-53117 Bonn, Germany.	fischerb@cs.uni-bonn.de; jb@cs.uni-bonn.de	Fischer, Bernd/E-7461-2011	Fischer, Bernd/0000-0001-9437-2099				Amir A, 1998, IEEE T PATTERN ANAL, V20, P186, DOI 10.1109/34.659936; Amir A, 1999, COMPUT VIS IMAGE UND, V76, P7, DOI 10.1006/cviu.1999.0786; BUHMANN JM, 2002, HDB BRAIN THEORY NEU, P308; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; *COR CORP, 1998, COR GALL; Fischer B, 2001, LECT NOTES COMPUT SC, V2134, P235; FISCHER B, 2001, TRIAI20027 RHEIN F W; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Malishevskii AS, 2001, PHYS SOLID STATE+, V43, P1, DOI 10.1134/1.1340176; Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854; Puzicha J, 1999, PATTERN RECOGN LETT, V20, P899, DOI 10.1016/S0167-8655(99)00056-2; SHASHUA A, 1988, P INT C COMP VIS; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; WILLIAMS L, 1997, NEURAL COMPUT, V9, P849; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026	19	142	160	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					513	518						6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100012
J	Ramamoorthi, R				Ramamoorthi, R			Analytic PCA construction for theoretical analysis of lighting variability in images of a Lambertian object	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						illumination; radiance; irradiance; Lambertian; recognition; principal component analysis; spherical harmonics	ILLUMINATION; RECOGNITION	We analyze theoretically the subspace best approximating images of a convex Lambertian object taken from the same viewpoint, but under different distant illumination conditions. Since the lighting is an arbitrary function, the space of all possible images is formally infinite-dimensional. However, previous empirical work has shown that images of largely diffuse objects actually lie very close to a five-dimensional subspace. In this paper, we analytically construct the principal component analysis for images of a convex Lambertian object, explicitly taking attached shadows into account, and find the principal eigenmodes and eigenvalues with respect to lighting variability. Our analysis makes use of an analytic formula for the irradiance in terms of spherical-harmonic coefficients of the illumination and shows, under appropriate assumptions, that the principal components or eigenvectors are identical to the spherical harmonic basis functions evaluated at the surface normal vectors. Our main contribution is in extending these results to the single-viewpoint case, showing how the principal eigenmodes and eigenvalues are affected when only a limited subset (the upper hemisphere) of normals is available and the spherical harmonics are no longer orthonormal over the restricted domain. Our results are very close, both qualitatively and quantitatively, to previous empirical observations and represent the first essentially complete theoretical explanation of these observations. Our analysis is also likely to be of interest in other areas of computer vision and image-based rendering. In particular, our results indicate that using complex illumination for photometric problems in computer vision is not significantly more difficult than using directional sources.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Ramamoorthi, R (corresponding author), Columbia Univ, Dept Comp Sci, 1214 Amsterdam Ave,MC 0401, New York, NY 10027 USA.	ravir@cs.columbia.edu						Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651; BASRI R, 2001, P COMP VIS PATT REC; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Cabral B., 1987, P 14 ANN C COMPUTER, P273, DOI [10.1145/37401.37434, DOI 10.1145/37401.37434]; Epstein R., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P108, DOI 10.1109/PBMCV.1995.514675; Georghiades A. S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P277, DOI 10.1109/AFGR.2000.840647; Georghiades AS, 1998, PROC CVPR IEEE, P52, DOI 10.1109/CVPR.1998.698587; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; LEVIN A, IN PRESS P EUR C COM; MacRobert T., 1948, SPHERICAL HARMONICS; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; MOSES Y, 1994, P EUR C COMP VIS, P286; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; RAMAMOORTHI R, 2001, P COMP VIS PATT REC, P48; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; SILLION FX, 1991, COMP GRAPH, V25, P187, DOI 10.1145/127719.122739; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317; Zhao L, 1999, PATTERN RECOGN, V32, P547, DOI 10.1016/S0031-3203(98)00119-8	23	142	148	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1322	1333		10.1109/TPAMI.2002.1039204	http://dx.doi.org/10.1109/TPAMI.2002.1039204			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300003
J	ALMOHAMAD, HA; DUFFUAA, SO				ALMOHAMAD, HA; DUFFUAA, SO			A LINEAR-PROGRAMMING APPROACH FOR THE WEIGHTED GRAPH MATCHING PROBLEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						GRAPH MATCHING; HUNGARIAN METHOD; LINEAR PROGRAMMING; OPTIMIZATION; RECOGNITION; STRUCTURAL PATTERN		A linear programming (LP) approach is proposed for the weighted graph matching problem. A linear program is obtained by formulating the graph matching problem in L1 norm and then transforming the resulting quadratic optimization problem to a linear one. The linear program is solved using a Simplex-based algorithm. Then, approximate 0-1 integer solutions are obtained by applying the Hungarian method on the real solutions of the linear program. The complexity of the proposed algorithm is polynomial time, and it is O(n6 L) for matching graphs of size n. The developed algorithm is compared to two other algorithms. One is based on an eigendecomposition approach and the other on a symmetric polynomial transform. Experimental results showed that the LP approach is superior in matching graphs than both other methods.			ALMOHAMAD, HA (corresponding author), KING FAHD UNIV PETR & MINERALS,COLL COMP SCI & ENGN,DEPT SYST ENGN,DHAHRAN,SAUDI ARABIA.		Duffuaa, Salih O./F-8131-2015					ALMOHAMAD HA, 1991, J APPLIED MATH MODEL, V15; BAZARAA MS, 1990, LINEAR PROGRAMMING N; CHARNES A, 1963, MANAGEMENT MODELS IN, V1; Dubois D., 1980, FUZZY SET SYST; GAREY M, 1984, COMPUTER INTERACTABI; GONZAGA CC, 1988, PROGR MATH PROGRAMMI; KITCHEN L, 1980, IEEE T SYST MAN CYB, V10, P96; KITCHEN L, 1979, IEEE T SYST MAN CYB, V9, P869; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; You M., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P316	12	142	149	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					522	525		10.1109/34.211474	http://dx.doi.org/10.1109/34.211474			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470		Green Submitted			2022-12-18	WOS:A1993LB47000012
J	Liu, XW; Zhu, XZ; Li, MM; Wang, L; Zhu, E; Liu, TL; Kloft, M; Shen, DG; Yin, JP; Gao, W				Liu, Xinwang; Zhu, Xinzhong; Li, Miaomiao; Wang, Lei; Zhu, En; Liu, Tongliang; Kloft, Marius; Shen, Dinggang; Yin, Jianping; Gao, Wen			Multiple Kernel k-Means with Incomplete Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Clustering algorithms; Optimization; Pattern analysis; Information technology; Prediction algorithms; Multiple kernel clustering; multiple view learning; incomplete kernel learning		Multiple kernel clustering (MKC) algorithms optimally combine a group of pre-specified base kernel matrices to improve clustering performance. However, existing MKC algorithms cannot efficiently address the situation where some rows and columns of base kernel matrices are absent. This paper proposes two simple yet effective algorithms to address this issue. Different from existing approaches where incomplete kernel matrices are first imputed and a standard MKC algorithm is applied to the imputed kernel matrices, our first algorithm integrates imputation and clustering into a unified learning procedure. Specifically, we perform multiple kernel clustering directly with the presence of incomplete kernel matrices, which are treated as auxiliary variables to be jointly optimized. Our algorithm does not require that there be at least one complete base kernel matrix over all the samples. Also, it adaptively imputes incomplete kernel matrices and combines them to best serve clustering. Moreover, we further improve this algorithm by encouraging these incomplete kernel matrices to mutually complete each other. The three-step iterative algorithm is designed to solve the resultant optimization problems. After that, we theoretically study the generalization bound of the proposed algorithms. Extensive experiments are conducted on 13 benchmark data sets to compare the proposed algorithms with existing imputation-based methods. Our algorithms consistently achieve superior performance and the improvement becomes more significant with increasing missing ratio, verifying the effectiveness and advantages of the proposed joint imputation and clustering.	[Liu, Xinwang; Li, Miaomiao; Zhu, En] Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China; [Zhu, Xinzhong] Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China; [Zhu, Xinzhong] Ningbo Cixing Co Ltd, Res Inst, Ningbo 315336, Peoples R China; [Wang, Lei] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia; [Liu, Tongliang] Univ Sydney, Fac Engn & Informat Technol, UBTECH Sydney Artificial Intelligence Ctr, Sch Informat Technol, J12 Cleveland St, Darlington, NSW 2008, Australia; [Kloft, Marius] Tech Univ Kaiserslautern, Dept Comp Sci, D-67653 Kaiserslautern, Germany; [Kloft, Marius] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA; [Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA; [Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA; [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea; [Yin, Jianping] Dongguan Univ Technol, Dongguan 511700, Guangdong, Peoples R China; [Gao, Wen] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China	National University of Defense Technology - China; Zhejiang Normal University; University of Wollongong; University of Sydney; University of Kaiserslautern; University of Southern California; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; Korea University; Dongguan University of Technology; Peking University	Zhu, E (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China.; Zhu, XZ (corresponding author), Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.	xinwangliu@nudt.edu.cn; zxz@zjnu.edu.cn; miaomiaolinudt@gmail.com; leiw@uow.edu.au; enzhu@nudt.edu.cn; tongliang.liu@sydney.edu.au; kloft@usc.edu; dgshen@med.unc.edu; jpyin@dgut.edu.cn; wgao@pku.edu.cn	Liu, Tongliang/AAA-1506-2021; Wang, Lei/D-9079-2013; LIU, Xinwang/L-8089-2019; Shen, Dinggang/ABF-6812-2020	Liu, Tongliang/0000-0002-9640-6472; Wang, Lei/0000-0002-0961-0441; LIU, Xinwang/0000-0001-9066-1475; Shen, Dinggang/0000-0002-7934-5698	National Key RAMP;D Program of China [2018YFB1003203]; Natural Science Foundation of China [61701451, 61672528]; German Research Foundation (DFG) [KL 2698/2-1, GRK1589/2]; Federal Ministry of Science and Education (BMBF) [031L0023A, 01IS18051A]	National Key RAMP;D Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); German Research Foundation (DFG)(German Research Foundation (DFG)); Federal Ministry of Science and Education (BMBF)(Federal Ministry of Education & Research (BMBF))	This work was supported by National Key R&D Program of China 2018YFB1003203, the Natural Science Foundation of China (project no. 61701451 and 61672528), the German Research Foundation (DFG) awards KL 2698/2-1 and GRK1589/2 and the Federal Ministry of Science and Education (BMBF) awards 031L0023A, 01IS18051A. The authors wish to gratefully acknowledge Prof. Huiying Xu from Zhejiang Normal University for her help in the proofreading of this paper. Xinzhong Zhu and Xinwang Liu equally contributed to the paper.	Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; Bhadra S, 2017, MACH LEARN, V106, P713, DOI 10.1007/s10994-016-5618-0; Cortes C, 2012, J MACH LEARN RES, V13, P795; Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476; Ghahramani Z., 1993, ADV NEURAL INFORM PR, P120; Gonen M., 2014, NIPS, P1305; Grant M., 2014, CVX MATLAB SOFTWARE; Jegelka S, 2009, LECT NOTES ARTIF INT, V5803, P144, DOI 10.1007/978-3-642-04617-9_19; Kang Z, 2020, IEEE T CYBERNETICS, V50, P1833, DOI 10.1109/TCYB.2018.2887094; Kang Z, 2019, KNOWL-BASED SYST, V163, P510, DOI 10.1016/j.knosys.2018.09.009; Kang Z, 2017, NEUROCOMPUTING, V267, P210, DOI 10.1016/j.neucom.2017.06.005; Kloft M, 2011, J MACH LEARN RES, V12, P953; Kumar R, 2013, I S BIOMED IMAGING, P764; Li M., 2016, IJCAI, P1704; Li SY, 2014, AAAI CONF ARTIF INTE, P1968; Liu TL, 2016, NEURAL COMPUT, V28, P2213, DOI 10.1162/NECO_a_00872; Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108; Liu XW, 2017, AAAI CONF ARTIF INTE, P2259; Liu XW, 2016, AAAI CONF ARTIF INTE, P1888; Liu XW, 2014, IEEE T NEUR NET LEAR, V25, P1083, DOI 10.1109/TNNLS.2013.2287275; Liu XW, 2013, IEEE T CYBERNETICS, V43, P557, DOI 10.1109/TSMCB.2012.2212243; Lovasz L., 1986, MATH STUDIES; Maurer A, 2010, IEEE T INFORM THEORY, V56, P5839, DOI 10.1109/TIT.2010.2069250; Nie FP, 2017, AAAI CONF ARTIF INTE, P2408; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Rostamizadeh A., 2009, P 25 C UNC ART INT, P109, DOI DOI 10.5555/1795114.1795128; Shao WX, 2015, LECT NOTES ARTIF INT, V9284, P318, DOI 10.1007/978-3-319-23528-8_20; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Xiang S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P185; Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539; Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255; Zhao B, 2009, IEEE DATA MINING, P637, DOI 10.1109/ICDM.2009.37; Zhao H., 2016, PROC INT JOINT C ART, P2392	34	141	143	12	96	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1191	1204		10.1109/TPAMI.2019.2892416	http://dx.doi.org/10.1109/TPAMI.2019.2892416			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30640600	Green Accepted			2022-12-18	WOS:000523685800013
J	Khan, SH; Bennamoun, M; Sohel, F; Togneri, R				Khan, Salman H.; Bennamoun, Mohammed; Sohel, Ferdous; Togneri, Roberto			Automatic Shadow Detection and Removal from a Single Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature learning; Bayesian shadow removal; conditional random field; convnets; shadow detection; shadow matting	BAYESIAN-APPROACH; MOVING SHADOWS; ILLUMINATION	We present a framework to automatically detect and remove shadows in real world scenes from a single image. Previous works on shadow detection put a lot of effort in designing shadow variant and invariant hand-crafted features. In contrast, our framework automatically learns the most relevant features in a supervised manner using multiple convolutional deep neural networks (ConvNets). The features are learned at the super-pixel level and along the dominant boundaries in the image. The predicted posteriors based on the learned features are fed to a conditional random field model to generate smooth shadow masks. Using the detected shadow masks, we propose a Bayesian formulation to accurately extract shadow matte and subsequently remove shadows. The Bayesian formulation is based on a novel model which accurately models the shadow generation process in the umbra and penumbra regions. The model parameters are efficiently estimated using an iterative optimization procedure. Our proposed framework consistently performed better than the state-of-the-art on all major shadow databases collected under a variety of conditions.	[Khan, Salman H.; Bennamoun, Mohammed; Sohel, Ferdous] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia; [Sohel, Ferdous] Murdoch Univ, Sch Engn & Informat Technol, 90 South St, Murdoch, WA 6150, Australia; [Togneri, Roberto] Univ Western Australia, Sch Elect Elect & Comp Engn, 35 Stirling Highway, Crawley, WA 6009, Australia	University of Western Australia; Murdoch University; University of Western Australia	Khan, SH; Bennamoun, M; Sohel, F (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.; Sohel, F (corresponding author), Murdoch Univ, Sch Engn & Informat Technol, 90 South St, Murdoch, WA 6150, Australia.; Togneri, R (corresponding author), Univ Western Australia, Sch Elect Elect & Comp Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	salman.khan@uwa.edu.au; mohammed.bennamoun@uwa.edu.au; f.sohel@murdoch.edu.au; roberto.togneri@uwa.edu.au	Bennamoun, Mohammed/C-2789-2013; Sohel, Ferdous/C-2428-2013; Khan, Salman/M-4834-2016	Bennamoun, Mohammed/0000-0002-6603-3257; Sohel, Ferdous/0000-0003-1557-4907; Khan, Salman/0000-0002-9502-1749; Togneri, Roberto/0000-0002-3778-4633	IPRS - The University of Western Australia; Australian Research Council (ARC) [DP110102166, DP150100294, DE120102960]	IPRS - The University of Western Australia; Australian Research Council (ARC)(Australian Research Council)	The authors would like to thank the anonymous reviewers for their valuable comments and suggestions to improve the quality of the paper. This research was supported by the IPRS awarded by The University of Western Australia and the Australian Research Council (ARC) grants DP110102166, DP150100294 and DE120102960. The Flickr images are used under a Creative Commons license from Flickr users: mountaintrekker2001, Ulrich J and Kanshian.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Arbel E, 2011, IEEE T PATTERN ANAL, V33, P1202, DOI 10.1109/TPAMI.2010.157; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Barrow H., 1978, COMPUT VIS SYST, V2, P2; Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chuang YY, 2001, PROC CVPR IEEE, P264; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; da Vinci L., 2008, NOTEBOOKS; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823; Finlayson G, 2007, IEEE I CONF COMP VIS, P2041; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; FREDEMBACH C, 2005, BRIT MACH VIS C, V2, P502, DOI DOI 10.5244/C.19.51; Guo Ruiqi, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P2956, DOI 10.1109/TPAMI.2012.214; Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Huerta I, 2009, IEEE I CONF COMP VIS, P1499, DOI 10.1109/ICCV.2009.5459280; Jiang XY, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.87; Joshi AJ, 2008, IEEE T PATTERN ANAL, V30, P2055, DOI 10.1109/TPAMI.2008.150; Kersten D, 1996, NATURE, V379, P31, DOI 10.1038/379031a0; Khan SH, 2015, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR.2015.7299091; Khan SH, 2014, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2014.249; Khan SH, 2014, LECT NOTES COMPUT SC, V8689, P679, DOI 10.1007/978-3-319-10590-1_44; Kwatra V., 2012, COMP PHOT ICCP 2012, P1, DOI DOI 10.1109/ICCPHOT.2012.6215222; Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24; LeCun Y, 2012, LECT NOTES COMPUT SC, V7700, P9, DOI DOI 10.1007/3-540-49430-8_; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106; Liu F, 2008, LECT NOTES COMPUT SC, V5305, P437; Matsushita Y, 2004, IEEE T PATTERN ANAL, V26, P1336, DOI 10.1109/TPAMI.2004.86; Mohan A, 2007, IEEE COMPUT GRAPH, V27, P23, DOI 10.1109/MCG.2007.30; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Panagopoulos A., 2010, EUR C COMP VIS, P1; Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008; Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093; Shor Y, 2008, COMPUT GRAPH FORUM, V27, P577, DOI 10.1111/j.1467-8659.2008.01155.x; Su YF, 2010, IEEE T IMAGE PROCESS, V19, P2749, DOI 10.1109/TIP.2010.2050626; Szummer M, 2008, LECT NOTES COMPUT SC, V5303, P582, DOI 10.1007/978-3-540-88688-4_43; Vazquez E, 2011, IEEE T PATTERN ANAL, V33, P917, DOI 10.1109/TPAMI.2010.146; Vicente TFY, 2015, LECT NOTES COMPUT SC, V8927, P309, DOI 10.1007/978-3-319-16199-0_22; Wu TP, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243982; Wu TP, 2005, IEEE I CONF COMP VIS, P480; Xiao CX, 2013, COMPUT GRAPH FORUM, V32, P207, DOI 10.1111/cgf.12198; Yang QX, 2012, IEEE T IMAGE PROCESS, V21, P4361, DOI 10.1109/TIP.2012.2208976; Zhu J, 2010, ASIA S PACIF DES AUT, P220	54	141	155	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					431	446		10.1109/TPAMI.2015.2462355	http://dx.doi.org/10.1109/TPAMI.2015.2462355			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046489	Green Published			2022-12-18	WOS:000370738900002
J	Berretti, S; Del Bimbo, A; Pala, P				Berretti, Stefano; Del Bimbo, Alberto; Pala, Pietro			3D Face Recognition Using Isogeodesic Stripes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D face recognition; 3D face model; isogeodesic stripe partitioning; 3D weighted walkthroughs; 3D face matching; performance evaluation		In this paper, we present a novel approach to 3D face matching that shows high effectiveness in distinguishing facial differences between distinct individuals from differences induced by nonneutral expressions within the same individual. The approach takes into account geometrical information of the 3D face and encodes the relevant information into a compact representation in the form of a graph. Nodes of the graph represent equal width isogeodesic facial stripes. Arcs between pairs of nodes are labeled with descriptors, referred to as 3D Weighted Walkthroughs (3DWWs), that capture the mutual relative spatial displacement between all the pairs of points of the corresponding stripes. Face partitioning into isogeodesic stripes and 3DWWs together provide an approximate representation of local morphology of faces that exhibits smooth variations for changes induced by facial expressions. The graph-based representation permits very efficient matching for face recognition and is also suited to being employed for face identification in very large data sets with the support of appropriate index structures. The method obtained the best ranking at the SHREC 2008 contest for 3D face recognition. We present an extensive comparative evaluation of the performance with the FRGC v2.0 data set and the SHREC08 data set.	[Berretti, Stefano; Del Bimbo, Alberto; Pala, Pietro] Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy	University of Florence	Berretti, S (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, I-50139 Florence, Italy.	berretti@dsi.unifi.it; delbimbo@dsi.unifi.it; pala@dsi.unifi.it	Berretti, Stefano/U-9004-2019	Berretti, Stefano/0000-0003-1219-4386; PALA, PIETRO/0000-0001-5670-3774; DEL BIMBO, ALBERTO/0000-0002-1052-8322				Amberg B, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P253, DOI 10.1109/SMI.2008.4547993; Berretti S, 2003, IEEE T MULTIMEDIA, V5, P52, DOI 10.1109/TMM.2002.802833; Berretti S, 2001, PATTERN ANAL APPL, V4, P83, DOI 10.1007/s100440170009; Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600; Berretti S., 2006, P 8 ACM INT WORKSH M, P13; Berretti S, 2008, INT WORK CONTENT MUL, P241; Beumier C, 2001, PATTERN RECOGN LETT, V22, P1321, DOI 10.1016/S0167-8655(01)00077-0; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940; Bronstein AM, 2006, LECT NOTES COMPUT SC, V3953, P396, DOI 10.1007/11744078_31; Bronstein AM, 2009, INT J COMPUT VISION, V84, P163, DOI 10.1007/s11263-008-0147-3; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; COOK JA, 2006, P 17 BR MACH VIS C B, V2, P769; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Daoudi M., 2008, SHREC 08 SHAPE RETRI; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Faltemier TC, 2008, COMPUT VIS IMAGE UND, V112, P114, DOI 10.1016/j.cviu.2008.01.004; Farkas L G, 1987, ANTHROPOMETRIC FACIA; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Gordon G. G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P808, DOI 10.1109/CVPR.1992.223253; Hesher C., 2002, P INT C IM SCI SYST; HUSKEN M, 2005, P IEEE WORKSH FAC RE; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; Lee J. C., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P722, DOI 10.1109/ICCV.1990.139627; Lu X, 2006, P IEEE COMP SOC C CO, P1377, DOI DOI 10.1109/CVPR..96; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; MAURER T, 2005, P IEEE WORKSH FAC RE; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Moreno A.B., 2003, P IR MACH VIS IM PRO; Nair P, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P257, DOI 10.1109/SMI.2008.4547995; PAN G, 2005, P IEEE C COMP VIS PA, V3, P175; Passalis G., 2005, P IEEE WORKSH FAC RE, P171, DOI DOI 10.1109/CVPR.2005.573; Phillips P. J., 2007, FRVT 2006 ICE 2006 L; Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15; Phillips PJ, 2005, PROC CVPR IEEE, P947; PHILLIPS PJ, 2003, 6965 NISTIR; Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235; Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8; SUMMERFIELD Q, 1983, ANAL SYNTHESIS PERCE; ter Haar FB, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P103, DOI 10.1109/SMI.2008.4547956; Tsalakanidou F, 2003, PATTERN RECOGN LETT, V24, P1427, DOI 10.1016/S0167-8655(02)00383-5; WANG S, 2006, P C COMP VIS PATT RE, V2, P2453; Wang YJ, 2005, IMAGE VISION COMPUT, V23, P1018, DOI 10.1016/j.imavis.2005.07.005; Wang YL, 2005, IEEE I CONF COMP VIS, P527; Xu D, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P261, DOI 10.1109/SMI.2008.4547997; Yan P, 2007, COMPUT VIS IMAGE UND, V107, P195, DOI 10.1016/j.cviu.2006.11.001; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	49	141	156	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2162	2177		10.1109/TPAMI.2010.43	http://dx.doi.org/10.1109/TPAMI.2010.43			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20975115				2022-12-18	WOS:000283558700004
J	Wang, L				Wang, Lei			Feature selection with kernel class separability	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel class separability; feature selection; Support Vector Machines; Kernel Fisher Discriminant Analysis; pattern classification		Classification can often benefit from efficient feature selection. However, the presence of linearly nonseparable data, quick response requirement, small sample problem, and noisy features makes the feature selection quite challenging. In this work, a class separability criterion is developed in a high-dimensional kernel space, and feature selection is performed by the maximization of this criterion. To make this feature selection approach work, the issues of automatic kernel parameter tuning, numerical stability, and regularization for multiparameter optimization are addressed. Theoretical analysis uncovers the relationship of this criterion to the radius- margin bound of the Support Vector Machines (SVMs), the Kernel Fisher Discriminant Analysis (KFDA), and the kernel alignment criterion, thus providing more insight into feature selection with this criterion. This criterion is applied to a variety of selection modes using different search strategies. Extensive experimental study demonstrates its efficiency in delivering fast and robust feature selection.	Australian Natl Univ, Res Sch Informat Sci & Engn, Dept Informat Engn, Canberra, ACT 0200, Australia	Australian National University	Wang, L (corresponding author), Australian Natl Univ, Res Sch Informat Sci & Engn, Dept Informat Engn, Bldg 115, Canberra, ACT 0200, Australia.	Lei.Wang@mail.rsise.anu.edu.au	Wang, Lei/AAL-9684-2020; Wang, Lei/D-9079-2013	Wang, Lei/0000-0002-0961-0441				AN LTH, 2002, P 1 INT WORKSH GLOB, P131; Bo LF, 2006, NEURAL COMPUT, V18, P961, DOI 10.1162/089976606775774642; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; CHANG CC, 2001, LIBSVM LIB SUPPORT V, P15; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Haykin S., 1999, NEURAL NETWORKS COMP; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Press WH, 1988, NUMERICAL RECIPES C; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Scholkopf B., 2001, LEARNING KERNELS SUP; Theodoridis S., 2008, PATTERN RECOGN; Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Webb A.R., 2003, STAT PATTERN RECOGNI; Weston J, 2001, ADV NEUR IN, V13, P668; XU L, 2006, P 21 NATL C ART INT	20	141	154	3	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1534	1546		10.1109/TPAMI.2007.70799	http://dx.doi.org/10.1109/TPAMI.2007.70799			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617713	Green Submitted			2022-12-18	WOS:000257504400003
J	Yu, SX; Shi, JB				Yu, SX; Shi, JB			Segmentation given partial grouping constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						grouping; image segmentation; graph partitioning; bias; spatial attention; semisupervised clustering; partially labeled classification	IMAGE SEGMENTATION; RESTORATION	We consider data clustering problems where partial grouping is known a priori. We formulate such biased grouping problems as a constrained optimization problem, where structural properties of the data define the goodness of a grouping and partial grouping cues define the feasibility of a grouping. We enforce grouping smoothness and fairness on labeled data points so that sparse partial grouping information can be effectively propagated to the unlabeled data. Considering the normalized cuts criterion in particular, our formulation leads to a constrained eigenvalue problem. By generalizing the Rayleigh-Ritz theorem to projected matrices, we find the global optimum in the relaxed continuous domain by eigendecomposition, from which a near-global optimum to the discrete labeling problem can be obtained effectively. We apply our method to real image segmentation problems, where partial grouping priors can often be derived based on a crude spatial attentional map that binds places with common salient features or focuses on expected object locations. We demonstrate not only that it is possible to integrate both image structures and priors in a single grouping process, but also that objects can be segregated from the background without specific object knowledge.	Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA; Univ Penn, Dept Comp & Informat Sci, Grasp Lab, Philadelphia, PA 19104 USA	University of California System; University of California Berkeley; University of Pennsylvania	Yu, SX (corresponding author), Univ Calif Berkeley, Dept Comp Sci, 549 Soda Hall, Berkeley, CA 94720 USA.	stellayu@cs.berkeley.edu; jshi@cis.upenn.edu						Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; AMIR A, 1996, P EUR C COMP VIS, P371; BOYKOV Y, 1999, P INT COMP VIS; FERRARI PA, 1995, J ROY STAT SOC B MET, V57, P485; GANDER W, 1989, LINEAR ALGEBRA APPL, V114, P815, DOI 10.1016/0024-3795(89)90494-1; GDALYAHU Y, 1998, NEURAL INFORMATION P, P424; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; JAAKKOLA T, 1999, NEURAL INFORMATION P, V12; Joachims T., 1999, P INT C MACH LEARN; KOLMOGOROV V, 2002, P EUR C COMP VIS; Malik J., 2001, INT J COMPUTER VISIO; Marr D., 1982, VISION; MARTIN D, 2001, INT J COMPUTER VISIO; MEILA M, 2001, NEURAL INFORMATION P; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; Nigam K., 1999, MACH LEARN, P1; PERONA P, 1998, P EUR C COMP VIS, P655; ROBLESKELLY A, 2001, P BRIT MACH VIS C, P123; ROY S, 1998, P INT C COMP VIS; Sharon E, 2000, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2000.855801; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SZUMMER M, 2001, NEURAL INFORMATION P, V14; Wagstaff K., 2001, P INT C MACH LEARN; WAGSTAFF K, 2000, P INT C MACH LEARN; WITKIN A, 1983, ROLE STRUCTURE VISIO; Yu S., 2003, P INT C COMP VIS; YU SX, 2001, NEURAL INFORMATION P; YU SX, 2001, CMURITR0122; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZHU SC, 1999, IEEE T PATT ANAL MAC, V21; [No title captured]; [No title captured]; [No title captured]	37	141	160	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					173	183		10.1109/TPAMI.2004.1262179	http://dx.doi.org/10.1109/TPAMI.2004.1262179			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376893	Green Submitted, Green Published			2022-12-18	WOS:000187954300004
J	Llados, J; Marti, E; Villanueva, JJ				Llados, J; Marti, E; Villanueva, JJ			Symbol recognition by error-tolerant subgraph matching between region adjacency graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph isomorphism; subgraph isomorphism; graph matching; inexact graph matching; graph edit distance; symbol recognition	PATTERN-RECOGNITION; NEURAL NETWORKS; ALGORITHM; ISOMORPHISM; MODEL	In this paper, we propose an error-tolerant subgraph isomorphism algorithm formulated in terms of Region Adjacency Graphs (RAG). A set of edit operations to transform one RAG into another one are defined. Regions are represented by polylines and string matching techniques are used to measure their similarity. The algorithm follows a branch and bound approach driven by the RAG edit operations. This formulation allows matching computing under distorted inputs and also reachong a solution in a near polynomial time. The algorithm has been used for recognizing symbols in hand drawn diagrams.	Univ Autonoma Barcelona, Dept Informat Edifici O, Comp Vis Ctr, Bellaterra 08193, Barcelona, Spain	Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Llados, J (corresponding author), Univ Autonoma Barcelona, Dept Informat Edifici O, Comp Vis Ctr, Bellaterra 08193, Barcelona, Spain.	josep@cvc.uab.es; enric@cvc.uab.es; juanjo@cvc.uab.es		Llados, Josep/0000-0002-4533-4739				AHSOON C, 1998, THESIS I NATL POLYTE; ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; AMANN HP, 1991, P SPIE C INT ROB SYS, V1609, P134; Bunke H, 1997, INT J PATTERN RECOGN, V11, P169, DOI 10.1142/S0218001497000081; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; Eshera M. A., 1984, P 7 INT C PATT REC, P75; Finch AM, 1997, PATTERN RECOGN, V30, P123, DOI 10.1016/S0031-3203(96)00060-X; FORD GP, 1991, P SPIE C INT ROB  10, V1607, P559; GMUR E, 1989, STRUCTURAL PATTERN A, P131; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HABACHA AH, 1991, P 1 INT C DOC AN REC, P170; Henderson TC, 1990, DISCRETE RELAXATION; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; JIANG X, 2000, GRAPHICS RECOGNITION, P183; Kuner P., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P527, DOI 10.1142/S0218001488000303; LEE JP, 1990, EYE, V4, P1; LLADOS J, 1997, THESIS U AUTONOMA BA; MAES M, 1991, PATTERN RECOGN, V24, P433, DOI 10.1016/0031-3203(91)90056-B; MEHLHORN K, 1984, GRAPH ALGORITHMS NP; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MOHR R, 1986, ARTIF INTELL, V28, P225, DOI 10.1016/0004-3702(86)90083-4; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SEONG DS, 1994, PATTERN RECOGN LETT, V15, P321, DOI 10.1016/0167-8655(94)90079-5; SHAPIRO L, 1993, HDB PATTERN RECOGNIT, P475; Sossa H., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P811, DOI 10.1109/CVPR.1992.223252; SUGANTHAN PN, 1995, IMAGE VISION COMPUT, V13, P45, DOI 10.1016/0262-8856(95)91467-R; SUGANTHAN PN, 1995, PATTERN RECOGN, V28, P997, DOI 10.1016/0031-3203(94)00166-J; Tombre K., 2000, Graphics Recognition. Recent Advances. Third International Workshop, GREC'99. Selected Papers (Lecture Notes in Computer Science Vol.1941), P3; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WANG CH, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P440, DOI 10.1109/ICCV.1995.466906; WANG JTL, 1994, INT C PATT RECOG, P284, DOI 10.1109/ICPR.1994.576921; Wilson RC, 1996, PATTERN RECOGN LETT, V17, P263, DOI 10.1016/0167-8655(95)00115-8; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WONG C, 1992, CHINESE ECON STUD, V25, P3, DOI 10.2753/CES1097-147525043; Yih-Tay Tsay, 1989, International Journal of Pattern Recognition and Artificial Intelligence, V3, P159, DOI 10.1142/S0218001489000140	39	141	152	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1137	1143		10.1109/34.954603	http://dx.doi.org/10.1109/34.954603			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600007
J	Madhvanath, S; Govindaraju, V				Madhvanath, S; Govindaraju, V			The role of holistic paradigms in handwritten word recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting recognition; holistic paradigms; analytical methods; reading theory; pattern recognition	IDENTIFICATION; SHAPE	The Holistic paradigm in handwritten word recognition treats the word as a single, indivisible entity and attempts to recognize words from their overall shape, as opposed to their character contents. In this survey, we have attempted to take a fresh look at the potential role of the Holistic paradigm in handwritten word recognition. The survey begins with an overview of studies of reading which provide evidence for the existence of a parallel holistic reading process in both developing and skilled readers. In what we believe is a fresh perspective on handwriting recognition, approaches to recognition are characterized as forming a continuous spectrum based on the visual complexity of the unit of recognition employed and an attempt is made to interpret well-known paradigms of word recognition in this framework. An overview of features, methodologies, representations, and matching techniques employed by holistic approaches is presented.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; SUNY Buffalo, Dept Comp Sci & Engn, Ctr Excellence Document Anal & Recognit, Amherst, NY 14260 USA	International Business Machines (IBM); State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Madhvanath, S (corresponding author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.							BERTILLE J, 1993, P 3 INT WORKSH FRONT, P417; BRAMALL PE, 1993, P 3 INT WORKSH FRONT, P295; BROADBENT DE, 1977, ATTENTION PERFORMANC, V6; BROCKLEHURST ER, 1988, PREPROCESSING CURSIV; Brown M. K., 1980, Proceedings of the International Conference on Cybernetics and Society, P47; CAMILLERAPP J, 1992, PIXELS FEATURES, V3, P273; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Cattell James M. K., 1886, MIND, V11, P220, DOI DOI 10.1093/MIND/OS-XI.42.220; Dodel J.-P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P15, DOI 10.1109/ICDAR.1995.598934; DOWNTON AC, 1990, P 10 INT C PATT REC, P469; Dzuba G, 1998, P 6 INT WORKSH FRONT, P99; EARNEST LD, 1962, P IFIP C, P462; EDELMAN S, 1990, INT J COMPUT VISION, V5, P303, DOI 10.1007/BF00126503; FARAG R, 1979, IEEE T COMPUTERS, V28; FRISHKOPF LS, 1961, P 4 LOND S INF THEOR; GORSKY ND, 1993, FUNDAMENTALS HANDWRI, P199; Guillevic D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P11, DOI 10.1109/ICDAR.1995.598933; HABER LR, 1983, READ RES QUART, V18, P165, DOI 10.2307/747516; HABER RN, 1981, J EXP PSYCHOL HUMAN, V7, P573, DOI 10.1037/0096-1523.7.3.573; HARMON LD, 1972, P IEEE, V60, P1165, DOI 10.1109/PROC.1972.8878; Henderson L., 1982, ORTHOGRAPHY WORD REC; HENDRAWAN A, 1993, FUNDAMENTALS HANDWRI, P313; HENDRAWAN A, 1993, P 3 INT WORKSH FRONT, P207; HO TK, 1992, THESIS STATE U NEW Y; HOWARD D, 1987, COGNITIVE NEUROPSYCH; HULL JJ, 1991, P 1 INT C DOC AN REC, P905; HUMPHREYS GW, 1990, COGNITIVE PSYCHOL, V22, P517, DOI 10.1016/0010-0285(90)90012-S; JACKEL LD, 1989, VLSI ARCHITECTURE BI, P275; Kim G, 1997, INT J PATTERN RECOGN, V11, P657, DOI 10.1142/S0218001497000287; Leroux M., 1991, P 1 INT C DOC AN REC, P774; LINDGREN N, 1965, IEEE SPECTRUM    MAY; Madhvanath S, 1997, INT J PATTERN RECOGN, V11, P933, DOI 10.1142/S0218001497000421; MADHVANATH S, 1996, P 8 SPIE INT S EL IM; MADHVANATH S, 1999, IEEE T PATT AN MACH, V21; MADHVANATH S, 1993, P 3 INT WORKSH FRONT, P71; MCCLELLAND JL, 1976, J EXP PSYCHOL HUMAN, V2, P80, DOI 10.1037/0096-1523.2.1.80; MILLER GM, 1971, P IFIP C AUG, P218; MONK AF, 1983, MEM COGNITION, V11, P16, DOI 10.3758/BF03197657; MOREAU J, 1991, INT WORKSH FRONT HAN, P121; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; NASRABADI N, 1994, P IEEE COMP VIS PATT; Olivier C., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P19, DOI 10.1109/ICDAR.1995.598935; Paquet T., 1991, P 1 INT C DOC AN REC, P749; REICHER GM, 1969, J EXP PSYCHOL, V81, P274, DOI DOI 10.1037/H0027768; SAYRE KM, 1973, PATTERN RECOGN, V5, P213, DOI 10.1016/0031-3203(73)90044-7; SCHOMAKER L, 1999, ADV HANDWRITING RECO, V34; SEYMOUR P, 1990, COGNITIVE PSYCHOL IN; SIMON JC, 1989, CR ACAD SCI II, V309, P1901; SIMON JC, 1994, P IAPR WORKSH DOC AN, P265; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12; THEIOS J, 1977, WORD IDENTIFICATION, V2; UNDERWOOD G, 1982, COGNITION, V12, P197, DOI 10.1016/0010-0277(82)90012-9; WHEELER DD, 1970, COGNITIVE PSYCHOL, V1, P59, DOI 10.1016/0010-0285(70)90005-8; [No title captured]; [No title captured]; [No title captured]	56	141	148	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					149	164		10.1109/34.908966	http://dx.doi.org/10.1109/34.908966			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	401NJ		Green Submitted			2022-12-18	WOS:000166933500005
J	SIDDIQI, K; KIMIA, BB				SIDDIQI, K; KIMIA, BB			PARTS OF VISUAL FORM - COMPUTATIONAL ASPECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PARTS; RECOGNITION; INVARIANCE; ROBUSTNESS; STABILITY; SALIENCE; SCALE	3-DIMENSIONAL SHAPES; RECOGNITION; OBJECTS; DECOMPOSITION	Underlying recognition is an organization of objects and their parts into classes and hierarchies. A representation of parts for recognition requires that they be invariant to rigid transformations, robust in the presence of occlusions, stable with changes in viewing geometry, and be arranged in a hierarchy. These constraints are captured in a general framework using notions of a PART-LINE and a PARTITIONING SCHEME. A proposed general principle of ''form from function'' motivates a particular partitioning scheme involving two types of parts, NECK-BASED and LIMB-BASED, whose psychophysical relevance was demonstrated in [39]. Neck-based parts arise from narrowings in shape, or the local minima in distance between two points on the boundary, while limb-based parts arise from a pair of negative curvature minima which have ''co-circular'' tangents. In this paper, we present computational support for the limb-based and neck-based parts by showing that they are invariant, robust, stable and yield a hierarchy of parts. Examples illustrate that the resulting decompositions are robust in the presence of occlusion and clutter for a range of man-made and natural objects, and lead to natural and intuitive parts which can be used for recognition.	BROWN UNIV,MAN MACHINE SYST LAB,PROVIDENCE,RI 02912	Brown University	SIDDIQI, K (corresponding author), BROWN UNIV,DIV ENGN,PROVIDENCE,RI 02912, USA.			Siddiqi, Kaleem/0000-0002-7347-9716				ASADA H, 1983, IEEE PAMI, V45, P2; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BAJCSY R, 1987, 1ST P INT C COMP VIS, P231; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BINFORD TO, 1971, DEC IEEE C SYSTEM CO; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Brady M, 1980, AAAI, P15; BRAUNSTEIN ML, 1989, PERCEPTION, V18, P817, DOI 10.1068/p180817; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GUZMAN A, 1969, AUTOMATIC INTERPRETA; HOFFMAN DD, 1985, COGNITION, V18, P65; HORN BKP, 1983, ACM T MATH SOFTWARE, V5, P442; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; KIMIA BB, 1991, ENTROPY SCALE SPACE, P333; KIMIA BB, 1992, TR9215 MCGILL U RES; KIMIA BB, 1994, IN PRESS INT J COMPU; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2; LEYTON M, 1989, COGNITIVE SCI, V13, P357, DOI 10.1207/s15516709cog1303_2; Leyton M., 1992, SYMMETRY CAUSALITY M; LINNER A, 1988, GEOMETRIC ANAL COMPU, P127; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; Nitzberg M., 1993, FILTERING SEGMENTATI; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PENTLAND A, 1987, 1ST INT C COMP VIS L; Pentland A, 1989, NEURAL COMPUT, V1, P82, DOI 10.1162/neco.1989.1.1.82; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483; RICHARDS W, 1985, COMPUTER VISION GRAP, V31, P156; RICHARDS WA, 1987, J OPT SOC AM A, V4, P1168, DOI 10.1364/JOSAA.4.001168; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SIDDIQI K, 1992, LEMS104 BROWN U TECH; ULLMAN S, 1976, BIOL CYBERN, V25, P1; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; 1987, 1ST INT C COMP VIS L	41	141	150	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					239	251		10.1109/34.368189	http://dx.doi.org/10.1109/34.368189			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000002
J	DUCHENE, J; LECLERCQ, S				DUCHENE, J; LECLERCQ, S			AN OPTIMAL TRANSFORMATION FOR DISCRIMINANT AND PRINCIPAL COMPONENT ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DUCHENE, J (corresponding author), COMPIEGNE UNIV,DEPT BIOMED ENGN,BP 649,F-60206 COMPIEGNE,FRANCE.							ANDERSON TW, 1962, ANN MATH STAT, V33, P420, DOI 10.1214/aoms/1177704568; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; CHIEN Y, 1978, INTERACTIVE PATTERN; DUCHENE J, 1986, IEEE T PATTERN ANAL, V8, P557, DOI 10.1109/TPAMI.1986.4767823; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Mardia KV, 1979, MULTIVARIATE ANAL; OKADA T, 1985, PATTERN RECOGN, V18, P139, DOI 10.1016/0031-3203(85)90037-8; Rao C.R., 1964, SANKHY INDIAN J STAT, V26, P329; Romeder J. M., 1973, METHODES PROGRAMMES; SAMMON JW, 1970, IEEE T COMPUT, VC 19, P826, DOI 10.1109/T-C.1970.223047; Spath H., 1980, CLUSTER ANAL ALGORIT; SWAS GB, 1981, IEEE T PATTERN ANAL, V3, P701	15	141	178	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					978	983		10.1109/34.9121	http://dx.doi.org/10.1109/34.9121			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100021
J	Yao, BP; Fei-Fei, L				Yao, Bangpeng; Fei-Fei, Li			Recognizing Human-Object Interactions in Still Images by Modeling the Mutual Context of Objects and Human Poses	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mutual context; action recognition; human pose estimation; object detection; conditional random field		Detecting objects in cluttered scenes and estimating articulated human body parts from 2D images are two challenging problems in computer vision. The difficulty is particularly pronounced in activities involving human-object interactions (e.g., playing tennis), where the relevant objects tend to be small or only partially visible and the human body parts are often self-occluded. We observe, however, that objects and human poses can serve as mutual context to each other-recognizing one facilitates the recognition of the other. In this paper, we propose a mutual context model to jointly model objects and human poses in human-object interaction activities. In our approach, object detection provides a strong prior for better human pose estimation, while human pose estimation improves the accuracy of detecting the objects that interact with the human. On a six-class sports data set and a 24-class people interacting with musical instruments data set, we show that our mutual context model outperforms state of the art in detecting very difficult objects and estimating human poses, as well as classifying human-object interaction activities.	[Yao, Bangpeng; Fei-Fei, Li] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Stanford University	Yao, BP (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	bangpeng@cs.stanford.edu; feifeili@cs.stanford.edu			US National Science Foundation (NSF) [IIS-0845230]; US Office of Naval Research MURI grant; DARPA VIRAT program; DARPA Mind's Eye program; Google research award; Microsoft Research Fellowship; SAP Stanford Graduate Fellowship	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Office of Naval Research MURI grant; DARPA VIRAT program; DARPA Mind's Eye program; Google research award(Google Incorporated); Microsoft Research Fellowship(Microsoft); SAP Stanford Graduate Fellowship	Li Fei-Fei is partially supported by US National Science Foundation (NSF) CAREER grant (IIS-0845230), a US Office of Naval Research MURI grant, the DARPA VIRAT program, the DARPA Mind's Eye program, a Google research award, and a Microsoft Research Fellowship. Bangpeng Yao is partially supported by an SAP Stanford Graduate Fellowship. The authors would like to thank Nityananda J for help annotating human body parts in the PPMI data set. They also would like to thank all the external reviewers for helpful suggestions to this work.	Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Bach P, 2005, J EXP PSYCHOL HUMAN, V31, P465, DOI 10.1037/0096-1523.31.3.465; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Bourdev L., 2009, P 12 IEEE INT C COMP; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brubaker M., 2009, P 12 IEEE INT C COMP; Bub DN, 2006, APHASIOLOGY, V20, P1112, DOI 10.1080/02687030600741667; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, P IEEE CS C COMP VIS; Delaitre V., 2010, RECOGNIZING HUMAN AC; Desai C., 2009, P 12 IEEE INT C COMP; Desai C., 2010, P IEEE CS C COMP VIS; Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Eichner M., 2009, P BRIT MACH VIS C; Everingham M., 2008, PASCAL VOC2008 RESUL; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Gupta A., 2008, P IEEE C COMP VIS PA; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Harzallah H., 2009, P 12 IEEE INT C COMP; HEITZ G, 2008, P EUR C COMP VIS; Helbig HB, 2006, EXP BRAIN RES, V174, P221, DOI 10.1007/s00221-006-0443-5; Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006; HOIEM D, 2006, P IEEE CS C COMP VIS; Jie L., 2009, ADV NEUR INF PROC SY; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Kjellstrom H., 2010, P IEEE C COMP VIS PA; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; LAMPERT C. H., 2008, P IEEE C COMP VIS PA; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lazebnik S., 2006, P IEEE CS C COMP VIS; LEIBE B., 2004, P ECCV WORKSH STAT L; Liebelt J, 2008, PROC CVPR IEEE, P2118; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995631; Marszalek M., 2009, P IEEE C COMP VIS PA; Murphy K., 2003, P ADV NEUR INF PROC; Niebles J, 2010, P EUR C COMP VIS; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Rabinovich A., 2007, P 11 IEEE INT C COMP; Ramanan D., 2006, NIPS, P1129; Ren X., 2005, P 10 IEEE INT C COMP; Rosenhahn B., 2008, P S GERM ASS PATT RE; Sadeghi M. A., 2011, P IEEE C COMP VIS PA; Sapp B., 2010, P EUR C COMP VIS; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Singh V., 2010, P IEEE CS C COMP VIS; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang Y., 2008, P EUR C COMP VIS; Wang Y., 2006, P IEEE CS C COMP VIS; Yang WL, 2010, PROC CVPR IEEE, P2030, DOI 10.1109/CVPR.2010.5539879; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao B., 2011, P INT C MACH LEARN; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235	57	140	148	3	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1691	1703		10.1109/TPAMI.2012.67	http://dx.doi.org/10.1109/TPAMI.2012.67			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22392710				2022-12-18	WOS:000306409100004
J	Fischer, B; Buhmann, JM				Fischer, B; Buhmann, JM			Bagging for path-based clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	3rd International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	SEP 03-05, 2001	SOPHIA ANTIPOLIS, FRANCE	INRIA, Int Assoc Pattern Recognit, Conseil Gen Alpes Maritimes		clustering; resampling; color segmentation	SEGMENTATION	A resampling scheme for clustering with similarity to bootstrap aggregation (bagging) is presented. Bagging is used to improve the quality of path-based clustering, a data clustering method that can extract elongated structures from data in a noise robust way. The results of an agglomerative optimization method are influenced by small fluctuations of the input data. To increase the reliability of clustering solutions. a stochastic resampling method is developed to infer consensus clusters. A related reliability measure allows us to estimate the number of clusters, based on the stability of an optimized cluster solution under resampling. The quality of path-based clustering with resampling is evaluated on a large image data set of human segmentations.	Univ Bonn, Dept Comp Sci 3, D-53117 Bonn, Germany	University of Bonn	Fischer, B (corresponding author), Univ Bonn, Dept Comp Sci 3, Romerstr 164, D-53117 Bonn, Germany.	fischerb@cs.uni-bonn.de; jb@cs.uni-bonn.de	Fischer, Bernd/E-7461-2011	Fischer, Bernd/0000-0001-9437-2099				Blatt M, 1997, NEURAL COMPUT, V9, P1805, DOI 10.1162/neco.1997.9.8.1805; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P513, DOI 10.1109/TPAMI.2003.1190577; Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450; Fred ALN, 2000, INT C PATT RECOG, P190, DOI 10.1109/ICPR.2000.906045; FRIDLYAND J, 2001, 600 U CAL DIV BIOST; Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Karger DR, 1996, J ACM, V43, P601, DOI 10.1145/234533.234534; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Levine E, 2001, NEURAL COMPUT, V13, P2573, DOI 10.1162/089976601753196030; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Meila M, 2001, ADV NEUR IN, V13, P873; PEREIRA F, 1993, P IEEE C COMP VIS PA, P638; Puzicha J, 1999, PATTERN RECOGN LETT, V20, P899, DOI 10.1016/S0167-8655(99)00056-2; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tishby N, 2001, ADV NEUR IN, V13, P640; [No title captured]	21	140	151	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1411	1415		10.1109/TPAMI.2003.1240115	http://dx.doi.org/10.1109/TPAMI.2003.1240115			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800006
J	El-Yacoubi, A; Gilloux, M; Sabourin, R; Suen, CY				El-Yacoubi, A; Gilloux, M; Sabourin, R; Suen, CY			An HMM-based approach for off-line unconstrained handwritten word modeling and recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting modeling; preprocessing; segmentation; feature extraction; hidden Markov models; word recognition; rejection	HIDDEN MARKOV-MODELS; SPEECH RECOGNITION	This paper describes a hidden Markov model-based approach designed to recognize off-line unconstrained handwritten words for large vocabularies. After preprocessing, a word image is segmented into letters or pseudoletters and represented by two feature sequences of equal length, each consisting of an alternating sequence of shape-symbols and segmentation-symbols, which are both explicitly modeled. The word model is made up of the concatenation of appropriate letter models consisting of elementary HMMs and an HMM-based interpolation technique is used to optimally combine the two feature sets. Two rejection mechanisms are considered depending on whether or not the word image is guaranteed to belong to the lexicon. Experiments carried out on real-life data show that the proposed approach can be successfully used for handwritten word recognition.	Concordia Univ, Dept Comp Sci, Ctr Pattern Recognit & Machine Intelligence, Montreal, PQ H3G 1M8, Canada; Pontificia Univ Catolica Parana, Dept Informat, BR-80215901 Curitiba, Parana, Brazil; Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, Montreal, PQ H3C 1K3, Canada; Serv Rech Tech La Poste, Dept Reconnaissance Modelisat & Optimasat, F-44063 Nantes 02, France	Concordia University - Canada; Pontificia Universidade Catolica do Parana; University of Quebec; Ecole de Technologie Superieure - Canada	El-Yacoubi, A (corresponding author), Concordia Univ, Dept Comp Sci, Ctr Pattern Recognit & Machine Intelligence, 1455 Maisonneuve Blvd W,Suite GM-606, Montreal, PQ H3G 1M8, Canada.	yacoubi@ppgia.pucpr.br	Sabourin, Robert/J-7642-2012; Yacoubi, Mounîm A. M.A. EL/C-1348-2017	Sabourin, Robert/0000-0002-9098-1011; Yacoubi, Mounîm A. M.A. EL/0000-0002-7383-0588				BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; Bercu S., 1993, P 3 INT WORKSH FRONT, P385; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; Cho WY, 1995, PATTERN RECOGN, V28, P1941, DOI 10.1016/0031-3203(95)00041-0; ELYACOUBI A, 1998, INT C PATT REC AUG, P16; ELYACOUBI A, 1994, P 4 INT WORKSH FRONT, P378; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GILLIES A, 1992, P US POST SERV ADV T, P557; GILLOUX M, 1995, MACH VISION APPL, V8, P197, DOI 10.1007/BF01219587; GILLOUX M, 1992, P USPS 5 ADV TECHN C, P545; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; HA JY, 1995, INT J PATTERN RECOGN, V9, P535, DOI 10.1142/S0218001495000511; Huang X. D., 1989, Computer Speech and Language, V3, P239, DOI 10.1016/0885-2308(89)90020-X; JELINEK F, 1992, ADV SPEECH SIGNAL PR, P651; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; KNERR S, 1996, P INT WORKSH DOC AN, P431; LIPORACE LA, 1982, IEEE T INFORM THEORY, V28, P729, DOI 10.1109/TIT.1982.1056544; MAGDI M, 1996, IEEE T PATTERN ANAL, V18, P548; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; Nag R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P2071; Picone J., 1990, IEEE ASSP Magazine, V7, P26, DOI 10.1109/53.54527; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SCHUKATTALAMAZZ.EG, 1991, MUST 13 DAGM S, P251; Suen CY, 1996, INT J IMAG SYST TECH, V7, P392, DOI 10.1002/(SICI)1098-1098(199624)7:4<392::AID-IMA14>3.0.CO;2-Y; YANG L, 1995, PATTERN RECOGN, V28, P161, DOI 10.1016/0031-3203(94)00092-Z	28	140	145	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					752	760		10.1109/34.784288	http://dx.doi.org/10.1109/34.784288			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF		Green Submitted			2022-12-18	WOS:000081993000006
J	Senior, AW; Robinson, AJ				Senior, AW; Robinson, AJ			An off-line cursive handwriting recognition system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						off-line cursive handwriting recognition; optical handwritten character recognition; preprocessing; feature extraction; recurrent neural networks; hidden Markov models; out-of-vocabulary word models		This paper describes a complete system for the recognition of off-line handwriting. Preprocessing techniques are described, including segmentation and normalization of word images to give invariance to scale, slant, slope and stroke thickness. Representation of the image is discussed and the skeleton and stroke features used are described. A recurrent neural network is used to estimate probabilities for the characters represented in the skeleton. The operation of the hidden Markov model that calculates the best word in the lexicon is also described. Issues of vocabulary choice, rejection, and out-of-vocabulary word recognition are discussed.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	International Business Machines (IBM); University of Cambridge	Senior, AW (corresponding author), IBM Corp, Thomas J Watson Res Ctr, POB 704, Yorktown Hts, NY 10598 USA.	aws@watson.ibm.com; ajr4@cam.ac.uk						BELLEGARDA JB, 1994, INT C AC SPEECH SIGN, V5, P149; BENGIO Y, 1994, ADV NEURAL INFORMATI, V6, P937; BOUMA H, 1971, VISION RES, V11, P459, DOI 10.1016/0042-6989(71)90087-3; Bourlard H., 1993, CONNECTIONIST SPEECH; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; CAESAR T, 1993, 3RD P INT WORKSH FRO, P409; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASEY RG, 1995, INT C DOCUMENT ANAL, V2, P1028; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; DAVIES ER, 1990, MICROELECTRICS SIGNA, V9; EDELMAN S, 1990, INT J COMPUT VISION, V5, P303, DOI 10.1007/BF00126503; GILLOUX M, 1993, 3 INT WORKSH FRONT H, P417; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; JOHANSSON S, 1986, TAGGED LOB CORPUS TE; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; SCHENKEL M, 1994, INT C AC SPEECH SIGN, V2, P637; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Senior A, 1996, ADV NEUR IN, V8, P743; SENIOR AW, 1994, THESIS CAMBRIDGE U; SENIOR AW, 1993, INT C DOC AN REC, P305; Waibel Alexander, 1990, READINGS SPEECH RECO; WOODLAND PC, 1994, P IEEE INT C AC SPEE, V2, P125; YANIKOGLU BA, 1993, PCSTR93192 DARTM COL; [No title captured]	24	140	148	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					309	321		10.1109/34.667887	http://dx.doi.org/10.1109/34.667887			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400007
J	Spitz, AL				Spitz, AL			Determination of the script and language content of document images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multilingual; script classification; machine printed OCR; language classification; Han-based languages; Latin-based languages; Asian scripts		Most document recognition work to date has been performed on English text. Because of the large overlap of the character sets found in English and major Western European languages such as French and German, some extensions of the basic English capability to those languages have taken place. However, automatic language identification prior to optical character recognition is not commonly available and adds utility to such systems. Languages and their scripts have attributes that make it possible to determine the language of a document automatically. Detection of the values of these attributes requires the recognition of particular features of the document image and, in the case of languages using Latin-based symbols, the character syntax of the underlying language. We have developed techniques for distinguishing which language is represented in an image of text. This work is restricted to a small but important subset of the world's languages. The method first classifies the script into two broad classes: Han-based and Latin-based. This classification is based on the spatial relationships of features related to the upward concavities in character structures. Language identification within the Han script class (Chinese, Japanese, Korean) is performed by analysis of the distribution of optical density in the text images. We handle 23 Latin-based languages using a technique based on character shape codes, a representation of Latin text that is inexpensive to compute.			Spitz, AL (corresponding author), DAIMLER BENZ AG,RES & TECHNOL CTR,1510 PAGE MILL RD,PALO ALTO,CA 94304, USA.							BAIRD H, 1993, P 2 INT C DOC AN REC, P336; Cavnar W. B., 1994, P 3 ANN S DOC AN INF, P1, DOI DOI 10.1.1.53.9367; DUNNING T., 1994, MCCS94273 CRL; Hochberg J., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P378, DOI 10.1109/ICDAR.1995.599017; HULL J, 1992, P INT C PATT REC HAG, pB665; HUNTER R, 1980, P IEEE, V68, P854, DOI 10.1109/PROC.1980.11751; ITTNER D, 1992, P S DOC AN INF RETR, P123; ITTNER D, 1995, DOCUMENT ANAL SYSTEM, P76; KANAI J, 1990, P IAPR WORKSH SYNT S, P182; Nakanishi A., 1980, WRITING SYSTEMS WORL; Nakayama T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P159, DOI 10.1109/ICDAR.1993.395759; Ronse C, 1984, CONNECTED COMPONENTS; SCHURMANN J, 1992, P IEEE, V80, P1101, DOI 10.1109/5.156473; Sibun P., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval, P125; Sibun P., 1994, P 4 C APPL NAT LANG, P15; Souter Clive, 1994, HERMES J LANGUAGE CO, V13, P183; SPITZ A, 1995, DOCUMENT ANAL SYSTEM, P16; Spitz A. L., 1990, EP90 Proceedings of the International Conference on Electronic Publishing, Document Manipulation and Typography, P193; Spitz A. L., 1994, P 3 ANN S DOC AN INF, P229; SPITZ AL, 1993, P IMAGE ANAL P, V3, P377; SPITZ AL, 1992, P 1 S DOC AN INF RET, P11; SPITZ AL, 1994, P DOCUMENT RECOGNITI, P97; TANAKA Y, 1988, P RIAO 88, P248; WOOD S, 1995, INT C IM PROC OCT, P428	24	140	160	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					235	245		10.1109/34.584100	http://dx.doi.org/10.1109/34.584100			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200004
J	RAO, AR; JAIN, RC				RAO, AR; JAIN, RC			COMPUTERIZED FLOW FIELD ANALYSIS - ORIENTED TEXTURE FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							OPTICAL-FLOW; MOTION; DEFECTS	A central issue in computer vision is the problem of signal-to-symbol transformation. This problem has two components: first, the choice of symbols to be derived and, second, the exact method used to transform the given image into this set of symbols. The objective of this paper is to develop an approach to the solution of signal-to-symbol transformation in the domain of flow fields, such as oriented texture fields and velocity vector fields. We use the geometric theory of differential equations to derive a symbol set based on the visual appearance of phase portraits. Phase portraits are a geometric representation of the solution curves of a system of differential equations. In the linear 2-D case, only a finitely different number of phase portraits is possible. This theory provides a machinery to describe flow fields both qualitatively and quantitatively. An attractive feature of this symbol set is that it is domain independent. We also provide the computational framework to start with a given flow field and derive its symbolic representation. In the case of texture, this is done by computing an orientation field and then using a nonlinear least squares technique over successive windows to determine the changing spatial behavior of the texture. Specifically, we segment the given texture, derive its symbolic representation, and perform a quantitative reconstruction of the salient features of the original texture based on the symbolic descriptors. We present results of applying this technique to several real texture images. This technique is useful in describing complex flow visualization pictures, defects in lumber processing, defects in semiconductor wafer inspection, and optical flow fields.	UNIV MICHIGAN,ARTIFICIAL INTELLIGENCE LAB,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan								Andronov A.A., 1966, QUALITATIVE THEORY 2; [Anonymous], 2009, QUATERN INT, DOI DOI 10.1016/j.quaint.2008.03.011; Arnol'd V I, 1973, ORDINARY DIFFERENTIA; ARROWSMITH DK, 1982, ORDINAR DIFFERENTIAL; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1986, THESIS U MICHIGAN; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; BOVIK AC, 1987, IEEE T PATTERN ANAL, V9, P181, DOI 10.1109/TPAMI.1987.4767894; CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573, DOI 10.1109/TPAMI.1983.4767446; CORE HA, 1979, WOOD STRUCTURE IDENT; DAHM WJA, 1989, 7TH S TURB SHEAR FLO; De Zeeuw C., 1964, TXB WOOD TECHNOLOGY; Erteld W, 1964, DEFECTS WOOD; GARBOW BS, 1980, DOCUMENTATION MINIPA; GODINEZ PA, 1987, INSPECTION SURFACE F, P27; GOPAL N, 1989, P IEEE INT C ACOUSTI, P1643; HAMEY LGC, 1988, THESIS CARNEGIE MELL; Hanson A., 1978, COMPUTER VISION SYST; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Heeger D. J., 1988, INT J COMPUT VISION, V1, P279; HELMAN J, 1989, COMPUTER, P27; Hirsch M. W., 1974, DIFF EQUAT+; HUANG TS, 1990, JUN INT C PATT REC; HUNTLEY I, 1979, LINEAR NONLINEAR DIF; IMAICHI K, 1983, J FLUID MECH, V129, P283, DOI 10.1017/S0022112083000774; IMAICHI K, 1983, 3RD P INT S FLOW VIS, P365; IWASKI I, 1983, 3TH P INT S FLOW VIS, P681; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAIN R, 1987, JAN P SPIE; JAIN R, 1989, MACHINE VISION INSPE; KANATANI K, 1987, COMPUT VISION GRAPH, V38, P122, DOI 10.1016/S0734-189X(87)80133-0; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KNUTSSON H, 1983, OCT P IEEE WKSHP COM; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; Lefschetz, 1963, DIFFERENTIAL EQUATIO; LEYMARIE J, 1968, QUI ETAIT VANGOGH; MEIERAN ES, 1987, P IEEE, V75, P908, DOI 10.1109/PROC.1987.13826; Merzkirch W., 1974, FLOW VISUALIZATION; MORE JJ, 1977, LECTURE NOTES MATH, V630; NOTO K, 1983, 3TH P INT S FLOW VIS, P120; Palis J., 1982, GEOMETRIC THEORY DYN; PRAZDNY K, 1983, COMPUT VISION GRAPH, V22, P239, DOI 10.1016/0734-189X(83)90067-1; QINGHAN X, 1986, 8TH INT C PATT REC, P663; RAO A, 1990, TAXONOMY TEXTURE DES; RAO AR, 1990, J CRYST GROWTH, V103, P398, DOI 10.1016/0022-0248(90)90217-9; RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S; RAO AR, 1987, JUN VIS 87 C DETR; RAO AR, 1988, IEEE EXPERT, P67; RAO AR, 1988, VISION 88; SALLAM T, 1983, 3TH P INT S FLOW VIS, P125; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; VILNROTTER FM, 1986, IEEE T PATTERN ANAL, V8, P76, DOI 10.1109/TPAMI.1986.4767754; VOORT V, 1986, APPLIED METALLOGRAPH; WECHSLER H, 1980, SIGNAL PROCESS, V2, P271, DOI 10.1016/0165-1684(80)90024-9; YIP K, 1989, THESIS MIT CAMBRIDGE; METALS HDB, V9; [No title captured]	59	140	150	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1992	14	7					693	709		10.1109/34.142908	http://dx.doi.org/10.1109/34.142908			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JB675					2022-12-18	WOS:A1992JB67500001
J	ZUCKER, SW; HUMMEL, RA				ZUCKER, SW; HUMMEL, RA			A 3-DIMENSIONAL EDGE OPERATOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									NYU,COURANT INST MATH SCI,NEW YORK,NY 10012	New York University	ZUCKER, SW (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,COMP VIS & GRAPH LAB,MONTREAL H3C 3G1,QUEBEC,CANADA.							BADLER N, 1978, COMPUT GRAPHICS, V12, P153; BROWN JL, 1960, SIAM J, V8, P20; Duda R.O., 1973, J ROYAL STAT SOC SER; GORDON R, 1975, SCI AM, V233, P56, DOI 10.1038/scientificamerican1075-56; HERSKOVITS A, 1970, MIT183 ART INT LAB M; Heuckel M., 1973, J ASSOC COMPUT MACH, V20, P634; HEUCKEL MH, 1971, J ASSOC COMPUT MACH, V18, P113; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; Naylor A., 1971, LINEAR OPERATOR THEO; PRESTON K, 1978, P US JAPAN SEMINAR R; Rosenfeld A., 1976, DIGITAL IMAGE PROCES; STROKE GW, 1974, ULTRASONIC IMAGING H; SUNGUROFF A, 1978, COMPUT GRAPHICS; TANAKA K, 1978, P US JAPAN SEMINAR R; Tou JT, 1974, PATTERN RECOGN; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848	18	140	143	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					324	331		10.1109/TPAMI.1981.4767105	http://dx.doi.org/10.1109/TPAMI.1981.4767105			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN969	21868953				2022-12-18	WOS:A1981MN96900009
J	Geng, CX; Huang, SJ; Chen, SC				Geng, Chuanxing; Huang, Sheng-Jun; Chen, Songcan			Recent Advances in Open Set Recognition: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Testing; Task analysis; Semantics; Face recognition; Data visualization; Open set recognition; classification; open world recognition; zero-short learning; one-shot learning	SUPPORT VECTOR MACHINE; FACE RECOGNITION; SPARSE REPRESENTATION; CLASSIFICATION; CLASSIFIERS; MODELS; STEPS	In real-world recognition/classification tasks, limited by various objective factors, it is usually difficult to collect training samples to exhaust all classes when training a recognizer or classifier. A more realistic scenario is open set recognition (OSR), where incomplete knowledge of the world exists at training time, and unknown classes can be submitted to an algorithm during testing, requiring the classifiers to not only accurately classify the seen classes, but also effectively deal with unseen ones. This paper provides a comprehensive survey of existing open set recognition techniques covering various aspects ranging from related definitions, representations of models, datasets, evaluation criteria, and algorithm comparisons. Furthermore, we briefly analyze the relationships between OSR and its related tasks including zero-shot, one-shot (few-shot) recognition/learning techniques, classification with reject option, and so forth. Additionally, we also review the open world recognition which can be seen as a natural extension of OSR. Importantly, we highlight the limitations of existing approaches and point out some promising subsequent research directions in this field.	[Geng, Chuanxing; Huang, Sheng-Jun; Chen, Songcan] Nanjing Univ Aeronaut & Astronaut NUAA, Coll Comp Sci & Technol, MIIT Key Lab Pattern Anal & Machine Intelligence, Nanjing 211106, Peoples R China	Nanjing University of Aeronautics & Astronautics	Chen, SC (corresponding author), Nanjing Univ Aeronaut & Astronaut NUAA, Coll Comp Sci & Technol, MIIT Key Lab Pattern Anal & Machine Intelligence, Nanjing 211106, Peoples R China.	gengchuanxing@nuaa.edu.cn; huangsj@nuaa.edu.cn; s.chen@nuaa.edu.cn		Geng, Chuanxing/0000-0001-6345-5385	NSFC [61672281]; Key Program of NSFC [61732006]; Postgraduate Research & Practice Innovation Program of Jiangsu Province	NSFC(National Natural Science Foundation of China (NSFC)); Key Program of NSFC(National Natural Science Foundation of China (NSFC)); Postgraduate Research & Practice Innovation Program of Jiangsu Province	The authors would like to thank the support from NSFC under Grant No. 61672281, the Key Program of NSFC under Grant No. 61732006 and the Postgraduate Research & Practice Innovation Program of Jiangsu Province under grant no. KYCX18_0306.	Aiolli F, 2008, LECT NOTES COMPUT SC, V5163, P305, DOI 10.1007/978-3-540-87536-9_32; Amit Y., 2007, ICML 07 P 24 INT C M, P17, DOI DOI 10.1145/1273496.1273499; Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; [Anonymous], 2015, REP; Baktashmotlagh M., 2018, LEARNING FACTORIZED; Bargi A, 2018, IEEE T NEUR NET LEAR, V29, P3953, DOI 10.1109/TNNLS.2017.2742058; Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173; Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799; Bengio Y., 2009, ADV NEURAL INFORM PR, V21; Bertinetto Luca, 2016, NIPS; Bilenko M, 2004, ICML; Bodesheim P, 2013, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2013.433; Bouchard Guillaume, 2004, 16 IASC INT S COMP S, P721; Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88; Cai WL, 2010, IEEE T NEURAL NETWOR, V21, P185, DOI 10.1109/TNN.2009.2034741; Cardoso DO, 2017, MACH LEARN, V106, P1547, DOI 10.1007/s10994-017-5646-4; Cardoso DO, 2015, IEEE IJCNN, DOI 10.1109/PVSC.2015.7356437; Cauwenberghs G, 2001, ADV NEUR IN, V13, P409; Cevikalp H., 2013, 2013 10 IEEE INT C W, P1; Cevikalp H, 2017, IEEE INT CONF COMP V, P1564, DOI 10.1109/ICCVW.2017.184; Cevikalp H, 2017, PROC CVPR IEEE, P4114, DOI 10.1109/CVPR.2017.438; Cevikalp H, 2017, IEEE T PATTERN ANAL, V39, P1076, DOI 10.1109/TPAMI.2016.2587647; Cevikalp H, 2012, PROC CVPR IEEE, P3138, DOI 10.1109/CVPR.2012.6248047; Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4; Chen Z., 2018, SEMANTIC FEATURE AUG; Cherkassky V, 2011, IEEE T NEURAL NETWOR, V22, P1241, DOI 10.1109/TNN.2011.2157522; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Neira MAC, 2018, IEEE ACCESS, V6, P21242, DOI 10.1109/ACCESS.2018.2824240; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K, 2006, J MACH LEARN RES, V7, P551; Cruz S., 2017, PROC IEEE INT S TECH, P1; Da Q, 2014, AAAI CONF ARTIF INTE, P1760; Dhamija A. R., 2018, ADV NEURAL INFORM PR, P9175; Dietterich TG, 2017, AI MAG, V38, P3, DOI 10.1609/aimag.v38i3.2756; Doan T., 2017, 2017 IEEE 7 ANN COMP, P1; Dong H., 2018, LEARNING SEPARATE DO; Fan WT, 2013, IEEE T NEUR NET LEAR, V24, P1850, DOI 10.1109/TNNLS.2013.2268461; Fei G, 2016, P 2016 C N AM CHAPT, P506, DOI DOI 10.18653/V1/N16-1061; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2; Fink M., 2006, P 23 INT C MACH LEAR, P313, DOI DOI 10.1145/1143844.1143884; Fischer L, 2016, NEUROCOMPUTING, V214, P445, DOI 10.1016/j.neucom.2016.06.038; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Fu Y., 2017, VOCABULARY INFORM EX; Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441; Fu YW, 2016, PROC CVPR IEEE, P5337, DOI 10.1109/CVPR.2016.576; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Fumera G, 2002, LECT NOTES COMPUT SC, V2388, P68; Garg A., 2003, ICML, P210; Gasimov RN, 2006, OPTIM METHOD SOFTW, V21, P527, DOI 10.1080/10556780600723252; Ge Z, 2017, GENERATIVE OPENMAX M; Geng C., 2018, COLLECTIVE DECISION; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gershman SJ, 2012, J MATH PSYCHOL, V56, P1, DOI 10.1016/j.jmp.2011.08.004; Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459; Gornitz N, 2018, IEEE T NEUR NET LEAR, V29, P3994, DOI 10.1109/TNNLS.2017.2737941; Goodfellow I., 2016, ARXIV; Goodfellow I.J., 2015, STATISTICAL, DOI DOI 10.48550/ARXIV.1412.6572; Guadarrama S, 2014, ROBOTICS SCI SYSTEMS, V2, P6; Guadarrama S, 2016, INT J ROBOT RES, V35, P265, DOI 10.1177/0278364915602059; Gunther M, 2017, IEEE COMPUT SOC CONF, P573, DOI 10.1109/CVPRW.2017.85; Hassen M., 2018, LEARNING NEURAL NETW; Heflin B., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P31, DOI 10.1109/BTAS.2012.6374555; Henrydoss J, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1089, DOI 10.1109/ICMLA.2017.000-3; Herbei R, 2006, CAN J STAT, V34, P709, DOI 10.1002/cjs.5550340410; Jain LP, 2014, LECT NOTES COMPUT SC, V8691, P393, DOI 10.1007/978-3-319-10578-9_26; Jin HL, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P457; Jo I, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2686; Kardan N, 2017, IEEE IJCNN, P518, DOI 10.1109/IJCNN.2017.7965897; Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188; Kotz S, 2000, EXTREME VALUE DISTRI; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Kuzborskij I, 2013, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2013.431; Lake B.M., 2013, ADV NEURAL INFORM PR; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lasserre J.A., 2006, IEEE COMP SOC C COMP, P87, DOI DOI 10.1109/CVPR.2006.227; Le Y., 2015, TINY IMAGENET VISUAL, V7, P3; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu HF, 2016, IEEE DATA MINING, P1059, DOI [10.1109/ICDM.2016.38, 10.1109/ICDM.2016.0136]; Liu S., 2018, OPEN CATEGORY DETECT; Liu ZY, 2019, AAAI CONF ARTIF INTE, P4416; Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264; Lonij V.P.A., 2017, OPEN WORLD VISUAL RE; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Masana M., 2018, METRIC LEARNING NOVE; Mendes PR, 2017, MACH LEARN, V106, P359, DOI 10.1007/s10994-016-5610-8; Mensink T., 2016, ONLINE OPEN WORLD RE; Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83; Mu X, 2017, IEEE T KNOWL DATA EN, V29, P1605, DOI 10.1109/TKDE.2017.2691702; Muhlbaier MD, 2009, IEEE T NEURAL NETWOR, V20, P152, DOI 10.1109/TNN.2008.2008326; Naylor AR, 2010, SURG-J R COLL SURG E, V8, P79, DOI 10.1016/j.surge.2010.01.006; Neal L, 2018, LECT NOTES COMPUT SC, V11210, P620, DOI 10.1007/978-3-030-01231-1_38; Nene, 1996, CUCS00596 COL U DEP; Netzer Yuval, 2011, NEURIPS WORKSH, V2, P6; Oza P, 2019, PROC CVPR IEEE, P2302, DOI 10.1109/CVPR.2019.00241; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Papa J. P., 2009, SUPERVISED PATTERN C; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059; Pelckmans K., 2008, P INT C NEUR INF PRO, V20, P1137; Peng JT, 2019, IEEE T NEUR NET LEAR, V30, P1790, DOI 10.1109/TNNLS.2018.2874432; Pentina A, 2014, PR MACH LEARN RES, V32, P991; Pham T., 2018, BAYESIAN SEMANTIC IN; Phillips P. J., 2005, HDB FACE RECOGNITION; Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026; Prakhya, 2017, P 14 INT C NAT LANG, P1; Pritsos Dimitrios A., 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P207, DOI 10.1007/978-3-642-36973-5_18; Qi ZQ, 2012, NEURAL NETWORKS, V36, P112, DOI 10.1016/j.neunet.2012.09.004; Qian Q, 2012, PATTERN RECOGN, V45, P2227, DOI 10.1016/j.patcog.2011.11.027; Reed WJ, 2001, ECON LETT, V74, P15, DOI 10.1016/S0165-1765(01)00524-9; Reyzin L., 2006, PROC 23 INT C MACH L, P753, DOI DOI 10.1145/1143844.1143939; Ristin M, 2014, PROC CVPR IEEE, P3654, DOI 10.1109/CVPR.2014.467; Rozsa A., 2017, ADVERSARIAL ROBUSTNE; Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551; Rudd EM, 2018, IEEE T PATTERN ANAL, V40, P762, DOI 10.1109/TPAMI.2017.2707495; Rudd EM, 2017, IEEE COMMUN SURV TUT, V19, P1145, DOI 10.1109/COMST.2016.2636078; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saito K., 2018, OPEN SET DOMAIN ADAP; Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720; Sattar H, 2015, PROC CVPR IEEE, P981, DOI 10.1109/CVPR.2015.7298700; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Scherreik MD, 2016, IEEE T AERO ELEC SYS, V52, P632, DOI 10.1109/TAES.2015.150027; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900; Shu L., 2017, DOC DEEP OPEN CLASS; Shu L., 2018, ARXIV PREPRINT ARXIV; Shu Y, 2018, IEEE INT CON MULTI; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Socher Richard, 2013, NEURIPS; Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Sun S, 2015, SURVEY MULTISOURCE D; Szegedy C, 2014, INTRIGUING PROPERTIE, P6; Tax DMJ, 2008, PATTERN RECOGN LETT, V29, P1565, DOI 10.1016/j.patrec.2008.03.010; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; THRUN S, 1995, ROBOT AUTON SYST, V15, P25, DOI 10.1016/0921-8890(95)00004-Y; Torralba A, 2010, COMMUN ACM, V53, P107, DOI 10.1145/1666420.1666446; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vareto R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P634; Vignotto E., 2018, EXTREME VALUE THEORY; Vinyals Oriol, 2016, ARXIV160604080, P3630; Vyas A., 2018, OUT OF DISTRIBUTION; Wang LP, 2017, PATTERN RECOGN, V63, P182, DOI 10.1016/j.patcog.2016.10.004; Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083; Wang Yu-Chiang Frank, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P3281, DOI 10.1109/IJCNN.2009.5178670; Wegkamp M, 2007, ELECTRON J STAT, V1, P155, DOI 10.1214/07-EJS058; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Weston J., 2006, P 23 INT C MACHINE L, P1009; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu MR, 2009, IEEE T PATTERN ANAL, V31, P2088, DOI 10.1109/TPAMI.2009.24; Wu Q, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS, P34; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xu H., 2018, LEARNING ACCEPT NEW; Yamada M, 2014, INT J COMPUT VISION, V109, P126, DOI 10.1007/s11263-013-0689-x; Yang Y, 2019, PATTERN RECOGN, V85, P60, DOI 10.1016/j.patcog.2018.07.030; Yeh T, 2008, PROC CVPR IEEE, P61; Yoshihashi R, 2019, PROC CVPR IEEE, P4011, DOI 10.1109/CVPR.2019.00414; YOUDEN WJ, 1950, CANCER-AM CANCER SOC, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3; Yu H., 2018, UNSUPERVISED DOMAIN; Yu Y., 2017, OPEN CATEGORY CLASSI; Yuan M, 2010, J MACH LEARN RES, V11, P111; Zhang H, 2017, IEEE T PATTERN ANAL, V39, P1690, DOI 10.1109/TPAMI.2016.2613924; Zhang R., 2006, P BRIT MACH VIS C, P1209; Zhao H, 2017, IEEE I CONF COMP VIS, P2021, DOI 10.1109/ICCV.2017.221; Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984; Zhu XX, 2014, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2014.122	176	139	141	44	125	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3614	3631		10.1109/TPAMI.2020.2981604	http://dx.doi.org/10.1109/TPAMI.2020.2981604			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32191881	Green Submitted			2022-12-18	WOS:000692232400026
J	Kouw, WM; Loog, M				Kouw, Wouter M.; Loog, Marco			A Review of Domain Adaptation without Target Labels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Sociology; Statistics; Machine learning; Pattern recognition; Hospitals; Image recognition; Pattern analysis; Machine learning; pattern recognition; domain adaptation; transfer learning; covariate shift; sample selection bias	COVARIATE SHIFT ADAPTATION; LEARNING-METHODS; KERNEL; CLASSIFICATION; ALGORITHM; BIAS	Domain adaptation has become a prominent problem setting in machine learning and related fields. This review asks the question: How can a classifier learn from a source domain and generalize to a target domain? We present a categorization of approaches, divided into, what we refer to as, sample-based, feature-based, and inference-based methods. Sample-based methods focus on weighting individual observations during training based on their importance to the target domain. Feature-based methods revolve around on mapping, projecting, and representing features such that a source classifier performs well on the target domain and inference-based methods incorporate adaptation into the parameter estimation procedure, for instance through constraints on the optimization procedure. Additionally, we review a number of conditions that allow for formulating bounds on the cross-domain generalization error. Our categorization highlights recurring ideas and raises questions important to further research.	[Kouw, Wouter M.] Univ Copenhagen, Datal Inst, Machine Learning Grp, DK-1165 Copenhagen, Denmark; [Loog, Marco] Delft Univ Technol, Pattern Recognit Lab, NL-2628 Delft, Netherlands; [Loog, Marco] Univ Copenhagen, Datal Inst, DK-1165 Copenhagen, Denmark	University of Copenhagen; Delft University of Technology; University of Copenhagen	Kouw, WM (corresponding author), Univ Copenhagen, Datal Inst, Machine Learning Grp, DK-1165 Copenhagen, Denmark.	wmkouw@gmail.com; m.loog@tudelft.nl	Kouw, Wouter/T-9432-2019	Kouw, Wouter/0000-0002-0547-4817	Niels Stensen Fellowship	Niels Stensen Fellowship	This paper is made possible through the support of the Niels Stensen Fellowship. The authors thank Marcel Reinders, Tom Viering, and Soufiane Mouragui for insightful discussions, and the reviewers for their constructive feedback.	Aljundi R, 2015, PROC CVPR IEEE, P56, DOI 10.1109/CVPR.2015.7298600; Anandkumar A., 2019, P INT C LEARN REPR N; Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2014, ADV NEURAL INFORM PR; [Anonymous], 2009, ADV NEURAL INFORM PR; Arnold A., 2007, PROC 7 IEEE INT C DA, P77, DOI DOI 10.1109/ICDMW.2007.109; Bacchiani M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P224; Baktashmotlagh M, 2016, J MACH LEARN RES, V17; Baktashmotlagh M, 2014, PROC CVPR IEEE, P2481, DOI 10.1109/CVPR.2014.318; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Ben-David Shai, 2012, Algorithmic Learning Theory. 23rd International Conference (ALT 2012). Proceedings, P139, DOI 10.1007/978-3-642-34106-9_14; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Ben-David Shai, 2007, NEURIPS, P7; Bian W, 2012, IEEE T SYST MAN CY B, V42, P298, DOI 10.1109/TSMCB.2011.2166761; Bickel S, 2009, J MACH LEARN RES, V10, P2137; Bickel Steffen, 2007, P 24 INT C MACH LEAR, DOI DOI 10.1145/1273496.1273507; Bishop C.M, 2006, PATTERN RECOGN; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Blitzer J., 2007, ADV NEURAL INFORM PR, V20, P129; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Blitzer J., 2011, PROC INT C ARTIF INT, P173; Bousmalis K, 2018, IEEE INT CONF ROBOT, P4243; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Bruzzone L, 2009, IEEE T GEOSCI REMOTE, V47, P1108, DOI 10.1109/TGRS.2008.2007741; Caseiro R, 2015, PROC CVPR IEEE, P3846, DOI 10.1109/CVPR.2015.7299009; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chen D, 2019, AAAI CONF ARTIF INTE, P493; Chen M, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON APAC 2011; Chen M., 2011, ADV NEURAL INF PROCE, P2456; Chen QC, 2018, PROC CVPR IEEE, P7976, DOI 10.1109/CVPR.2018.00832; Chen XL, 2016, JMLR WORKSH CONF PRO, V51, P1270; Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009; Cheplygina V, 2018, IEEE J BIOMED HEALTH, V22, P1486, DOI 10.1109/JBHI.2017.2769800; COCHRAN WG, 1973, SANKHYA SER A, V35, P417; Cortes C., 2010, PROC ADV NEURAL INF, V10, P442; Cortes C, 2008, LECT NOTES ARTIF INT, V5254, P38, DOI 10.1007/978-3-540-87987-9_8; Cortes C, 2014, THEOR COMPUT SCI, V519, P103, DOI 10.1016/j.tcs.2013.09.027; Courty N, 2017, ADV NEUR IN, V30; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; Cover T.M., 2012, ELEMENTS INFORM THEO, DOI DOI 10.1002/047174882X; Cranmer K, 2017, ADV NEURAL INFORM PR, V30, P981; Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1_1; Damodaran BB, 2018, LECT NOTES COMPUT SC, V11208, P467, DOI 10.1007/978-3-030-01225-0_28; Das D, 2018, IEEE IMAGE PROC, P3758, DOI 10.1109/ICIP.2018.8451152; Das D, 2018, LECT NOTES COMPUT SC, V11141, P342, DOI 10.1007/978-3-030-01424-7_34; Das D, 2018, ENG APPL ARTIF INTEL, V73, P80, DOI 10.1016/j.engappai.2018.05.001; Deng J, 2014, IEEE SIGNAL PROC LET, V21, P1068, DOI 10.1109/LSP.2014.2324759; Ditzler G., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence in Dynamic and Uncertain Environments (CIDUE 2011), P41, DOI 10.1109/CIDUE.2011.5948491; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Dua D., 2017, UCI MACHINE LEARNING; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P1667, DOI 10.1109/TPAMI.2011.265; Elkan C., 2001, INT JOINT C ART INT, P973; Fan W, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P320; Fare TL, 2003, ANAL CHEM, V75, P4672, DOI 10.1021/ac034241b; Fernando B, 2015, PATTERN RECOGN LETT, V65, P60, DOI 10.1016/j.patrec.2015.07.009; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Finkel Jenny Rose, 2009, P HUM LANG TECHN 200, P602, DOI DOI 10.3115/1620754.1620842; Frermann L., 2014, P 14 C EUR CHAPT ASS, P49; Friedler SA, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P329, DOI 10.1145/3287560.3287589; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Gedik E, 2017, PERS UBIQUIT COMPUT, V21, P723, DOI 10.1007/s00779-017-1006-4; Gelman A., 2013, TEXTS STAT SCI SERIE, Vthird, DOI 10.1201/b16018; Germain P., 2013, INT C MACH LEARN, P738; Germain P., 2007, ADV NEURAL INFORM PR, V19, P449; Germain P, 2016, PR MACH LEARN RES, V48; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Gieseke Fabian, 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P352, DOI 10.1109/ICMLA.2010.59; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gong Boqing, 2013, P ADV NEUR INF PROC, P1286; Gong MM, 2016, PR MACH LEARN RES, V48; Gopalan R, 2012, FOUND TRENDS COMPUT, V8, P285, DOI 10.1561/0600000057; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A, 2009, NEURAL INF PROCESS S, P131; GRONAU R, 1974, J POLIT ECON, V82, P1119, DOI 10.1086/260267; Gu QQ, 2009, IEEE DATA MINING, P159, DOI 10.1109/ICDM.2009.32; Habrard A, 2016, KNOWL INF SYST, V47, P45, DOI 10.1007/s10115-015-0839-2; Habrard A, 2013, INT J ARTIF INTELL T, V22, DOI 10.1142/S0218213013600051; Hachiya H, 2012, NEUROCOMPUTING, V80, P93, DOI 10.1016/j.neucom.2011.09.016; Hardt M., 2016, EQUALITY OPPORTUNITY, P3315, DOI 10.1109/ICCV.2015.169; HECKMAN J, 1990, AM ECON REV, V80, P313; HECKMAN JJ, 1979, ECONOMETRICA, V47, P153, DOI 10.2307/1912352; Hernan MA, 2006, J EPIDEMIOL COMMUN H, V60, P578, DOI 10.1136/jech.2004.029496; Hoffman J, 2016, FCNS WILD PIXELLEVEL; Hoffman J, 2014, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2014.116; Hu WH, 2018, PR MACH LEARN RES, V80; Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081; Imbens GW, 2015, CAUSAL INFERENCE FOR STATISTICS, SOCIAL, AND BIOMEDICAL SCIENCES: AN INTRODUCTION, P1, DOI 10.1017/CBO9781139025751; Izbicki R, 2017, ANN APPL STAT, V11, P698, DOI 10.1214/16-AOAS1013; Jacobusse G, 2016, LECT NOTES ARTIF INT, V9956, P325, DOI 10.1007/978-3-319-46307-0_21; Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924; Jiang W, 2008, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2008.4711716; Johnson WE, 2007, BIOSTATISTICS, V8, P118, DOI 10.1093/biostatistics/kxj037; Kamnitsas K, 2017, LECT NOTES COMPUT SC, V10265, P597, DOI 10.1007/978-3-319-59050-9_47; Kanamori T, 2012, MACH LEARN, V86, P335, DOI 10.1007/s10994-011-5266-3; Kanamori T, 2009, J MACH LEARN RES, V10, P1391; Kanazawa S, 2004, PSYCHOL REV, V111, P512, DOI 10.1037/0033-295X.111.2.512; Kato Tsuyoshi, 2012, P188, DOI 10.4018/978-1-4666-1785-8.ch011; Kouw W. M., 2018, ARXIV180609463; Kouw W, 2018, INT C PATT RECOG, P1468, DOI 10.1109/ICPR.2018.8546186; Kouw WM, 2019, LECT NOTES COMPUT SC, V11492, P360, DOI 10.1007/978-3-030-20351-1_27; Kouw WM, 2016, J MACH LEARN RES, V17; Kremer J, 2015, ASTRON COMPUT, V12, P67, DOI 10.1016/j.ascom.2015.06.005; Kulis B., 2018, P INT C LEARN REPR W; Lee J., 2019, ARXIV190110654; LEE J, 2018, ADV NEURAL INFORM PR, P2687; Leek JT, 2010, NAT REV GENET, V11, P733, DOI 10.1038/nrg2825; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Li XC, 2007, Proceedings of the 2007 Chinese Control and Decision Conference, P275; Lipton Zachary, 2018, ARXIV180203916, P3122; Little R., 2014, STAT ANAL MISSING DA, V2; Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Loog M, 2018, MACHINE LEARNING TEC, P113; Loog M, 2012, IEEE INT WORKS MACH; Madras D, 2018, PR MACH LEARN RES, V80; Madry A., 2018, P INT C LEARN REPR V; Mahmud MMH, 2009, THEOR COMPUT SCI, V410, P1826, DOI 10.1016/j.tcs.2009.01.013; Mansour Y., 2009, P C LEARN THER MONTR; Mansour Y., 2009, P 25 C UNC ART INT, P367; Mansour Y, 2014, ANN MATH ARTIF INTEL, V71, P365, DOI 10.1007/s10472-013-9391-5; Marco Alonso, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1557, DOI 10.1109/ICRA.2017.7989186; Margolis A., 2011, RAPPORT TECHNIQUE; MCLACHLAN GJ, 1975, J AM STAT ASSOC, V70, P365; McNamara D, 2017, PR MACH LEARN RES, V70; Mei SY, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-44; MELINO A, 1982, REV ECON STUD, V49, P151, DOI 10.2307/2297148; Miller EG, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P297; Mohri M., 2018, FDN MACHINE LEARNING; Mooij J.M., 2018, P 32 INT C NEUR INF; Moreno-Torres JG, 2012, PATTERN RECOGN, V45, P521, DOI 10.1016/j.patcog.2011.06.019; Morvant E, 2015, PATTERN RECOGN LETT, V51, P37, DOI 10.1016/j.patrec.2014.08.013; Muandet Krikamol, 2013, ICML; Pan S.J., 2008, AAAI; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan Sinno Jialin, 2010, P 19 INT C WORLD WID, P751; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059; Peddinti VMK, 2011, P 5 AAAI C ANALYZING, P44; Perez O, 2007, LECT NOTES COMPUT SC, V4507, P178; Quadrianto N., 2017, ADV NEURAL INFORM SY, P677; Quinonero-Candela J, 2009, NEURAL INF PROCESS S, pXI; Raina R., 2006, PROC 23 INT C MACH L, P713, DOI DOI 10.1145/1143844.1143934; Redko I, 2017, LECT NOTES ARTIF INT, V10535, P737, DOI 10.1007/978-3-319-71246-8_45; Rojas-Carulla M, 2018, J MACH LEARN RES, V19; Rosenstein Michael T, 2005, NIPS 2005 WORKSH TRA, V898, P1; Rostamizadeh A., 2009, ADV NEURAL INFORM PR, P1041; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Scholkopf Bernhard, 2012, ICML; Sha, 2013, P INT C MACH LEARN; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Shen J., 2018, P AAAI C ART INT PAL; Shepstone SE, 2016, IEEE-ACM T AUDIO SPE, V24, P504, DOI 10.1109/TASLP.2016.2515506; Shi Y., 2012, P 29 INT C INT C MAC, P1275; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Shu R, 2018, P INT C LEARN REPR V; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Srivastava Nitish, 2013, NIPS; Stonnington CM, 2008, NEUROIMAGE, V39, P1180, DOI 10.1016/j.neuroimage.2007.09.066; Storkey A, 2009, NEURAL INF PROCESS S, P3; Sugiyama M, 2005, LECT NOTES COMPUT SC, V3697, P235; Sugiyama M, 2012, DENSITY RATIO ESTIMATION IN MACHINE LEARNING, P1, DOI 10.1017/CBO9781139035613; Sugiyama M., 2008, NIPS, P1433; Sugiyama M, 2007, J MACH LEARN RES, V8, P985; Sugiyama M, 2005, STATIST RISK MODEL, V23, P249, DOI 10.1524/stnd.2005.23.4.249; Sugiyama M, 2012, ANN I STAT MATH, V64, P1009, DOI 10.1007/s10463-011-0343-8; Sun B, 2015, BMVC; Sun SL, 2015, INFORM FUSION, V24, P84, DOI 10.1016/j.inffus.2014.12.003; Sun SN, 2017, NEUROCOMPUTING, V257, P79, DOI 10.1016/j.neucom.2016.11.063; Sun Z, 2013, IEEE GEOSCI REMOTE S, V10, P1224, DOI 10.1109/LGRS.2012.2236818; Szepesvari C., 2012, P INT C MACH LEARN, P1147; Tai L, 2017, IEEE INT C INT ROBOT, P31; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Trung L., ARXIV181106199V3; Tsuboi Y., 2009, J INF PROCESS, V17, P138, DOI DOI 10.2197/IPSJJIP.17.138; Tucker J., 2011, J ACCOUNT LIT, V29, P31; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van Erven T, 2014, IEEE T INFORM THEORY, V60, P3797, DOI 10.1109/TIT.2014.2320500; van Kasteren TLM, 2010, LECT NOTES COMPUT SC, V6030, P283, DOI 10.1007/978-3-642-12654-3_17; van Laarhoven T., 2017, ARXIV170605335; van Laarhoven T., 2018, ARXIV180307634; van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792; Vella F, 1998, J HUM RESOUR, V33, P127, DOI 10.2307/146317; Vilalta R, 2013, ASTRON COMPUT, V2, P46, DOI 10.1016/j.ascom.2013.07.002; Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150; Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083; Wang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4889; Wang ZR, 2019, PROC CVPR IEEE, P11285, DOI 10.1109/CVPR.2019.01155; Wen JF, 2014, PR MACH LEARN RES, V32, P631; WHITE H, 1981, J AM STAT ASSOC, V76, P419, DOI 10.2307/2287845; Widmer C, 2010, LECT N BIOINFORMAT, V6282, P98, DOI 10.1007/978-3-642-16001-1_9; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; Wulfmeier M, 2017, IEEE INT C INT ROBOT, P1551; Xu H, 2012, MACH LEARN, V86, P391, DOI 10.1007/s10994-011-5268-1; Xu Q, 2011, J COMPUT SCI ENG, V5, P257, DOI DOI 10.5626/JCSE.2011.5.3.257; Zadrozny B., 2004, P 21 INT C MACH LEAR, P114, DOI DOI 10.1145/1015330.1015425; Zellinger W., 2017, P INT C LEARN REPR; Zellinger W, 2019, INFORM SCIENCES, V483, P174, DOI 10.1016/j.ins.2019.01.025; Zhang K, 2015, AAAI CONF ARTIF INTE, P3150; Zhang L, 2013, PROCEEDINGS OF 2013 CHINA INTERNATIONAL CONFERENCE ON INSURANCE AND RISK MANAGEMENT, P819; Zheng JJ, 2012, INT C PATT RECOG, P2095; Zhong EH, 2010, LECT NOTES ARTIF INT, V6323, P547, DOI 10.1007/978-3-642-15939-8_35	214	139	139	63	211	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					766	785		10.1109/TPAMI.2019.2945942	http://dx.doi.org/10.1109/TPAMI.2019.2945942			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QE6IS	31603771	Green Submitted			2022-12-18	WOS:000616309900002
J	Zhao, R; Oyang, WL; Wang, XG				Zhao, Rui; Oyang, Wanli; Wang, Xiaogang			Person Re-Identification by Saliency Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Person re-identification; person saliency; patch matching; video surveillance	MODEL	Human eyes can recognize person identities based on small salient regions, i.e., person saliency is distinctive and reliable in pedestrian matching across disjoint camera views. However, such valuable information is often hidden when computing similarities of pedestrian images with existing approaches. Inspired by our user study result of human perception on person saliency, we propose a novel perspective for person re-identification based on learning person saliency and matching saliency distribution. The proposed saliency learning and matching framework consists of four steps: (1) To handle misalignment caused by drastic viewpoint change and pose variations, we apply adjacency constrained patch matching to build dense correspondence between image pairs. (2) We propose two alternative methods, i.e., K-Nearest Neighbors and One-class SVM, to estimate a saliency score for each image patch, through which distinctive features stand out without using identity labels in the training procedure. (3) saliency matching is proposed based on patch matching. Matching patches with inconsistent saliency brings penalty, and images of the same identity are recognized by minimizing the saliency matching cost. (4) Furthermore, saliency matching is tightly integrated with patch matching in a unified structural Rank SVM learning framework. The effectiveness of our approach is validated on the four public datasets. Our approach outperforms the state-of-the-art person re-identification methods on all these datasets.	[Zhao, Rui; Oyang, Wanli; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Zhao, R (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.	rzhao@ee.cuhk.edu.hk; wlouyang@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk	Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761	General Research Fund - Research Grants Council of Hong Kong [CUHK14206114, CUHK14205615, CUHK417011, CUHK419412, CUHK 14203015, CUHK14207814]; National Natural Science Foundation of China (NSFC) [61371192]	General Research Fund - Research Grants Council of Hong Kong(Hong Kong Research Grants Council); National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work is supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project Nos. CUHK14206114, CUHK14205615, CUHK417011, CUHK419412, CUHK 14203015, and CUHK14207814) and National Natural Science Foundation of China (NSFC NO. 61371192).	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38; Avraham T, 2014, ADV COMPUT VIS PATT, P231, DOI 10.1007/978-1-4471-6296-4_11; Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34; Baltieri D., 2011, P 2011 JOINT ACMWORK, P59, DOI DOI 10.1145/2072572.2072590; Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001; Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711; Byers S, 1998, J AM STAT ASSOC, V93, P577, DOI 10.2307/2670109; Carterette B., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P629, DOI 10.1145/1148170.1148289; Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946; Cheng DS, 2014, ADV COMPUT VIS PATT, P139, DOI 10.1007/978-1-4471-6296-4_7; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Gong S., 2013, PERSON REIDENTIFICAT; Gray D., 2007, P 10 IEEE INT WORKSH; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Heller Katherine A., 2003, P ICDM WORKSH DAT MI; Hirzer M, 2012, IEEE IMAGE PROC, P1617, DOI 10.1109/ICIP.2012.6467185; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Javed O., 2008, IEEE TPAMI, V109, P146, DOI [10.1016/j.cviu.2007.01.003, DOI 10.1109/TPAMI.2014.2369055]; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Joachims Thorsten, 2005, ICML, DOI DOI 10.1145/1102351.1102399; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24; Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40; Li AN, 2014, ADV COMPUT VIS PATT, P119, DOI 10.1007/978-1-4471-6296-4_6; Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803; Li HS, 2014, IEEE T PATTERN ANAL, V36, P2407, DOI 10.1109/TPAMI.2014.2324568; Li S, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2155; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu CX, 2013, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2013.62; Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39; Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019; Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736; Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57; Ma BP, 2014, ADV COMPUT VIS PATT, P23, DOI 10.1007/978-1-4471-6296-4_2; Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41; Martinel N, 2015, IEEE T PATTERN ANAL, V37, P1656, DOI 10.1109/TPAMI.2014.2377748; Mcfee B., 2010, P 27 ANN INT C MACH; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Prosser B., 2008, P BMVC, V8, P164; Prosser B.J., 2010, BRIT MACH VIS C AB B, P1, DOI DOI 10.5244/C.24.21; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046; Vaquero D. A., 2009, PROC WORKSHOP APPL C, P1; Vedaldi A., 2008, MATLAB WRAPPER SVMST; Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Wei L, 2015, AAAI CONF ARTIF INTE, P1882; Xu YL, 2013, IEEE I CONF COMP VIS, P3152, DOI 10.1109/ICCV.2013.391; Yang Wu, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P408, DOI 10.1109/AVSS.2011.6027363; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531; Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984; Zheng WS, 2014, ADV COMPUT VIS PATT, P183, DOI 10.1007/978-1-4471-6296-4_9; Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23	72	139	147	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					356	370		10.1109/TPAMI.2016.2544310	http://dx.doi.org/10.1109/TPAMI.2016.2544310			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019470	Green Submitted			2022-12-18	WOS:000395553400011
J	Navigli, R; Lapata, M				Navigli, Roberto; Lapata, Mirella			An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Word sense disambiguation; graph connectivity; semantic networks; social network analysis	CENTRALITY	Word sense disambiguation (WSD), the task of identifying the intended meanings (senses) of words in context, has been a long-standing research objective for natural language processing. In this paper, we are concerned with graph-based algorithms for large-scale WSD. Under this framework, finding the right sense for a given word amounts to identifying the most "important" node among the set of graph nodes representing its senses. We introduce a graph-based WSD algorithm which has few parameters and does not require sense-annotated data for training. Using this algorithm, we investigate several measures of graph connectivity with the aim of identifying those best suited for WSD. We also examine how the chosen lexicon and its connectivity influences WSD performance. We report results on standard data sets and show that our graph-based approach performs comparably to the state of the art.	[Navigli, Roberto] Univ Roma La Sapienza, Dipartimento Informat, I-00198 Rome, Italy; [Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Sapienza University Rome; University of Edinburgh	Navigli, R (corresponding author), Univ Roma La Sapienza, Dipartimento Informat, Via Salaria 113, I-00198 Rome, Italy.	navigli@di.uniroma1.it; mlap@inf.ed.ac.uk		Navigli, Roberto/0000-0003-3831-9706	EPSRC [EP/C538447/1]; Engineering and Physical Sciences Research Council [EP/C538447/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors are grateful to the anonymous referees whose feedback helped to substantially improve the present paper. This work was supported by EPSRC (grant EP/C538447/1) and the Royal Society of Edinburgh. A preliminary version was published in the proceedings of IJCAI 2007.	AGIRRE E, 2007, WORD SENSE DISAMBIGU; Agirre E., 2006, P 2006 C EMP METH NA, P585, DOI DOI 10.3115/1610075.1610157; [Anonymous], 1997, TEXT KRITIK, V133, P10; [Anonymous], 1998, PROC SODA; Balmin A., 2004, VLDB, V4, P564; Banerjee Satanjeev., 2003, P 18 INT JOINT C ART, P805; BONACICH P, 1972, J MATH SOCIOL, V2, P113, DOI 10.1080/0022250X.1972.9989806; BOTAFOGO RA, 1992, ACM T INFORM SYST, V10, P142, DOI 10.1145/146802.146826; Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249; Brin S., 1998, COMPUT NETW ISDN SYS, V30, P107, DOI [DOI 10.1016/S0169-7552(98)00110-X, 10.1016/s0169-7552(98)00110-x]; Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Cowie J., 1992, P 14 INT C COMP LING, V1, P359; Decadt Bart, 2004, P 3 INT WORKSH EV SY, P108; Edmonds P, 2001, P 2 INT WORKSH EV WO, V2, P1; Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523; Esuli A., 2007, P 45 ANN M ASS COMP, P424; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Feng Donghui, 2006, P HUMAN LANGUAGE TEC, P208; FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7; Gale W.A., 1992, P 4 DARPA SPEECH NAT, P233; GALLEY M, 2003, P 18 INT JOINT C ART, P1486; HAGE P, 1995, SOC NETWORKS, V17, P57, DOI 10.1016/0378-8733(94)00248-9; JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993; Lea D., 2002, OXFORD COLLOCATIONS; Lesk M., 1986, ANN INT C SYSTEMS DO, P24, DOI DOI 10.1145/318723.318728; McCarthy D, 2004, P 42 ANN M ASS COMP, P280; Mihalcea R., 2004, COLING 2004 P 20 INT, P1126; Mihalcea R, 2004, P 2004 C EMP METH NA, P404, DOI 10.5555/1613715; Mihalcea R., 2005, P C HUM LANG TECHN E, P411, DOI DOI 10.3115/1220575.1220627; Miller George A., 1993, P WORKSH HUM LANG TE, P303; Mitchell M., 1998, INTRO GENETIC ALGORI; Navigli R, 2005, IEEE T PATTERN ANAL, V27, P1075, DOI 10.1109/TPAMI.2005.149; Navigli R, 2004, COMPUT LINGUIST, V30, P151, DOI 10.1162/089120104323093276; Navigli Roberto, 2005, P 18 FLOR ART INT RE, P548; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Ng H.T., 1997, P ACL SIGLEX WORKSH, P1; NG HT, 1996, P ACL, V34, P40; Niu Z., 2005, P 43 ANN M ASS COMP, P395, DOI DOI 10.3115/1219840.1219889; Otterbacher Jahna, 2005, P HUMAN LANGUAGE TEC, P915; PEDERSEN T, 2005, 200525 UMSI; Pianta E., 2002, P 1 INT C GLOB WORDN; Pradhan Sameer, 2007, P 4 INT WORKSH SEM E, P87; RAMAKRISHNAN G, 2003, P ACL 2003 WORKSHOP, P1; Rigau G., 1998, P 36 ANN M ASS COMP, V2, P1103; Russell S. J., 2010, ARTIF INTELL, V3rd; SABIDUSSI G, 1966, PSYCHOMETRIKA, V31, P581, DOI 10.1007/BF02289527; Schutze H, 1998, COMPUT LINGUIST, V24, P97; SNOW R, 2006, P 21 INT C COMP LING, P801; Snyder Benjamin, 2004, SENSEVAL 3, P41; Stokoe C., 2005, P C HUM LANG TECHN E, P403; STRAPPARAVA C, 2004, P SENSEVAL 3 3 INT W, P229; TRATZS SANFILIPPOA, 2007, P 4 INT WORKSH SEM E, P264; Upstill T., 2003, P AUSTR DOC COMP S A, P31; Veronis J, 2004, COMPUT SPEECH LANG, V18, P223, DOI 10.1016/j.csl.2004.05.002; Vickrey David, 2005, P C HUM LANG TECHN E, P771, DOI DOI 10.3115/1220575.1220672; Vossen P., 1998, EUROWORDNET MULTILIN; Wan Xiaojun, 2006, P HUM LANG TECHN C N, P181; Wasserman S., 1994, SOCIAL NETWORK ANAL, DOI DOI 10.1017/CBO9780511815478; Yarowsky D., 2002, Natural Language Engineering, V8, P293, DOI 10.1017/S135132490200298X; Yarowsky David, 1993, P ARPA HUM LANG TECH, P266; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	80	139	147	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					678	692		10.1109/TPAMI.2009.36	http://dx.doi.org/10.1109/TPAMI.2009.36			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	555XA	20224123				2022-12-18	WOS:000274548800009
J	Williams, O; Blake, A; Cipolla, R				Williams, O; Blake, A; Cipolla, R			Sparse Bayesian learning for efficient visual tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						probabilistic algorithms; robust regression; tracking; object recognition	MODELS	This paper extends the use of statistical learning algorithms for object localization. It has been shown that object recognizers using kernel-SVMs can be elegantly adapted to localization by means of spatial perturbation of the SVM. While this SVM applies to each frame of a video independently of other frames, the benefits of temporal fusion of data are well-known. This is addressed here by using a fully probabilistic Relevance Vector Machine (RVM) to generate observations with Gaussian distributions that can be fused over time. Rather than adapting a recognizer, we build a displacement expert which directly estimates displacement from the target region. An object detector is used in tandem, for object verification, providing the capability for automatic initialization and recovery. This approach is demonstrated in real-time tracking systems where the sparsity of the RVM means that only a fraction of CPU time is required to track at frame rate. An experimental evaluation compares this approach to the state of the art showing it to be a viable method for long-term region tracking.	Univ Cambridge, Dept Engn, Machine Intelligence Lab, Cambridge CB2 1PZ, England; Microsoft Res, Cambridge CB3 0FB, England; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Cambridge; Microsoft; University of Cambridge		omcw2@cam.ac.uk; ablake@microsoft.com; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151				AVIDAN S, 2001, P C COMP VIS PATT RE; BLACK MJ, 1996, P EUR C COMP VIS, V1, P329; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; BLAKE A, 1994, P ACM SIGGRAPH, P185; Cipolla R., 1998, COMPUTER VISION HUMA; Comaniciu D., 2000, P C COMP VIS PATT RE; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; ISARD M, 1996, P EUR C COMP VIS, P343; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JEBARA TS, 1997, P C COMP VIS PATT RE; Jepson AD, 2001, PROC CVPR IEEE, P415; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Lewis J.P., 1995, VISION INTERFACE; LI SZ, 2002, P EUR C COMP VIS; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; ROMDHANI S, 2001, P INT C COMP VIS, V2, P524; Scholkopf B., 1998, ADV KERNEL METHODS S; Tipping E., 2003, P 9 INT WORKSH ART I; Tipping ME, 2000, ADV NEUR IN, V12, P652; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vacchetti L., 2003, P C COMP VIS PATT RE; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; VIOLA P, 2001, P C COMP VIS PATT RE; YUILLE A, 1992, ACTIVE VISION, P20	30	139	154	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1292	1304		10.1109/TPAMI.2005.167	http://dx.doi.org/10.1109/TPAMI.2005.167			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119267				2022-12-18	WOS:000229700900009
J	Dong, JX; Krzyzak, A; Suen, CY				Dong, JX; Krzyzak, A; Suen, CY			Fast SVM training algorithm with decomposition on very large data sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						support vector machines (SVMs); algorithm design and analysis; algorithm efficiency; machine learning; handwritten character recognition	SUPPORT VECTOR MACHINES; SMO ALGORITHM; MIXTURE	Training a support vector machine on a data set of huge size with thousands of classes is a challenging problem. This paper proposes an efficient algorithm to solve this problem. The key idea is to introduce a parallel optimization step to quickly remove most of the nonsupport vectors, where block diagonal matrices are used to approximate the original kernel matrix so that the original problem can be split into hundreds of subproblems which can be solved more efficiently. In addition, some effective strategies such as kernel caching and efficient computation of kernel matrix are integrated to speed up the training process. Our analysis of the proposed algorithm shows that its time complexity grows linearly with the number of classes and size of the data set. In the experiments, many appealing properties of the proposed algorithm have been investigated and the results show that the proposed algorithm has a much better scaling capability than Libsvm, SVMlight, and SVMTorch. Moreover, the good generalization performances on several large databases have also been achieved.	Concordia Univ, Dept Comp Sci & Software Engn, Ctr Pattern Recognit & Machine Intelligence, Montreal, PQ H3G 1M8, Canada	Concordia University - Canada	Dong, JX (corresponding author), Concordia Univ, Dept Comp Sci & Software Engn, Ctr Pattern Recognit & Machine Intelligence, 1455 Maisonneuve Blvd W,Suite GM-606, Montreal, PQ H3G 1M8, Canada.	jdong@cenparmi.concordia.ca; krzyzak@cs.concordia.ca; suen@cenparmi.concordia.ca						[Anonymous], P ICNN PERTH WA AUST; [Anonymous], 2002, LEARNING KERNELS; Ben-Hur A, 2002, J COMPLEXITY, V18, P51, DOI 10.1006/jcom.2001.0581; Bishop, 1995, NEURAL NETWORKS PATT; Blackard JA, 1999, COMPUT ELECTRON AGR, V24, P131, DOI 10.1016/S0168-1699(99)00046-0; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, 460 U CAL STAT DEP; CHANG C.C., 2003, LIBSVM LIB SUPPORT V; Collobert R, 2003, INT J PATTERN RECOGN, V17, P349, DOI 10.1142/S0218001403002411; Collobert R, 2002, NEURAL COMPUT, V14, P1105, DOI 10.1162/089976602753633402; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Cristianini N., 2000, INTRO SUPPORT VECTOR; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dong JX, 2003, INT J PATTERN RECOGN, V17, P367, DOI 10.1142/S0218001403002423; DONG JX, 2003, P INT WORKSH ART NEU; DONGARRA JJ, 1990, ACM T MATH SOFTWARE, V16, P1, DOI 10.1145/77626.79170; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Flake GW, 2002, MACH LEARN, V46, P271, DOI 10.1023/A:1012474916001; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gnedenko B. V., 1969, MATH METHODS RELIABI; *INT CORP, 2002, 248966 INT CORP; *INT CORP, 2002, 245470 INT CORP; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kuhn H., 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Patterson D. A., 1996, COMPUTER ARCHITECTUR; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; RIDA A, 1999, P 7 INT WORKSH AI ST; SCHOLKOPF B, 1995, P 1 INT C KNOWL DISC, P252; Schwaighofer A, 2001, LECT NOTES COMPUT SC, V2130, P411; Staddon JE., 1983, ADAPTIVE BEHAV LEARN; Tresp V, 2000, NEURAL COMPUT, V12, P2719, DOI 10.1162/089976600300014908; Vapnik V.N, 1998, STAT LEARNING THEORY; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; WHALEY RC, 1998, P HIGH PERF NETW COM; WHALEY RC, 2000, AUTOMATED EMPIRICAL	42	139	156	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					603	618		10.1109/TPAMI.2005.77	http://dx.doi.org/10.1109/TPAMI.2005.77			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794164				2022-12-18	WOS:000226845700010
J	Shafique, K; Shah, M				Shafique, K; Shah, M			A noniterative greedy algorithm for multiframe point correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						point correspondence; target tracking; motion; occlusion; point trajectory; data association; bipartite graph matching; path cover of directed graph	MOTION CORRESPONDENCE; 3-DIMENSIONAL MOTION; MULTIPLE TARGETS; DATA ASSOCIATION; TRACKING; TRAJECTORIES; IMAGES	This paper presents a framework for finding point correspondences in monocular image sequences over multiple frames. The general problem of multiframe point correspondence is NP-hard for three or more frames. A polynomial time algorithm for a restriction of this problem is presented and is used as the basis of the proposed greedy algorithm for the general problem. The greedy nature of the proposed algorithm allows it to be used in real-time systems for tracking and surveillance, etc. In addition, the proposed algorithm deals with the problems of occlusion, missed detections, and false positives by using a single noniterative greedy optimization scheme and, hence, reduces the complexity of the overall algorithm as compared to most existing approaches where multiple heuristics are used for the same purpose. While most greedy algorithms for point tracking do not allow for entry and exit of the points from the scene, this is not a limitation for the proposed algorithm. Experiments with real and synthetic data over a wide range of scenarios and system parameters are presented to validate the claims about the performance of the proposed algorithm.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Shafique, K (corresponding author), Univ Cent Florida, Sch Comp Sci, Comp Sci Bldg No 54,4000 Cent Florida Blvd, Orlando, FL 32816 USA.	khurram@cs.ucf.edu; shah@cs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572				ASADA M, 1983, COMPUT VISION GRAPH, V21, P118, DOI 10.1016/S0734-189X(83)80031-0; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BOESCH FT, 1977, J ACM, V24, P192, DOI 10.1145/322003.322005; Chetverikov D, 1999, COMPUTING, V62, P321, DOI 10.1007/s006070050027; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; COX IJ, 1995, IEEE T AERO ELEC SYS, V32, P486; Danchicka R., 1993, IEEE T AERO ELEC SYS, V29, P555; DAWSON MRW, 1991, PSYCHOL REV, V98, P569, DOI 10.1037/0033-295X.98.4.569; Deb S, 1997, IEEE T AERO ELEC SYS, V33, P523, DOI 10.1109/7.575891; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Gibson J., 1979, ECOLOGICAL APPROACH; Hopcroft J. E., 1973, SIAM Journal on Computing, V2, P225, DOI 10.1137/0202019; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JAVED O, 2002, P EUR C COMP VIS, pR4; Javed O., 2003, P 9 IEEE INT C COMP; Jenkin M.R.M., 1983, P WORKSHOP MOTION RE, P66; JOHANSSON G, 1976, PSYCHOL RES-PSYCH FO, V38, P379, DOI 10.1007/BF00309043; Johnson D. S, 1979, COMPUTERS INTRACTABI; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Marr D., 1982, VISION COMPUTATIONAL; Neisser U., 1976, COGNITION REALITY PR; POORE A, 1995, PARTITIONING DATA SE, P169; Poore A. B., 1999, Proceedings of the Second International Conference on Information Fusion. FUSION '99, P1037; RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z; RASHID RF, 1980, IEEE T PATTERN ANAL, V2, P574, DOI 10.1109/TPAMI.1980.6447705; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; SALARI V, 1990, IEEE T PATTERN ANAL, V12, P87, DOI 10.1109/34.41387; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SHEA PJ, 1990, IEEE T PATTERN ANAL, V12, P87; SHI J, 1994, P IEEE C COMP VIS PA, P593, DOI DOI 10.1109/CVPR.1994.323794; TODD JT, 1982, J EXP PSYCHOL HUMAN, V8, P238, DOI 10.1037/0096-1523.8.2.238; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946; Verestoy J, 2000, P WORKSH EV VAL COMP, P183; West D.B., 1996, INTRO GRAPH THEORY; YACHIDA M, 1981, IEEE T PATTERN ANAL, V3, P12, DOI 10.1109/TPAMI.1981.4767046	38	139	147	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					51	65		10.1109/TPAMI.2005.1	http://dx.doi.org/10.1109/TPAMI.2005.1			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628268				2022-12-18	WOS:000225028200006
J	Nguyen, HT; Worring, M; van den Boomgaard, R				Nguyen, HT; Worring, M; van den Boomgaard, R			Watersnakes: Energy-driven watershed segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						watershed segmentation; energy-based segmentation; topographical distance; snakes	CONTOURS; DISTANCE; IMAGES; SNAKES	The watershed algorithm from mathematical morphology is powerful for segmentation. However, it does not allow incorporation of a priori information as segmentation methods that are based on energy minimization. In particular, there is no control of the smoothness of the segmentation result. In this paper, we show how to represent watershed segmentation as an energy minimization problem using the distance-based definition of the watershed line. A priori considerations about smoothness can then be imposed by adding the contour length to the energy function. This leads to a new segmentation method called watersnakes, integrating the strengths of watershed segmentation and energy based segmentation. Experimental results show that, when the original watershed segmentation has noisy boundaries or wrong limbs attached to the object of interest, the proposed method overcomes those drawbacks and yields a better segmentation.	Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst Grp, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	Nguyen, HT (corresponding author), Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst Grp, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	tat@science.uva.nl; worring@science.uva.nl; rein@science.uva.nl						ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; BEUCHER S, 1992, MATH MORPHOLOGY IMAG, P43; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Lions P. L., 1982, GEN SOLUTIONS HAMILT; LIONS PL, 1993, NUMER MATH, V64, P323, DOI 10.1007/BF01388692; LOWE DG, 1988, P 2 INT C COMP VIS, P558; Maragos P, 1998, COMP IMAG VIS, V12, P167; Marcotegui B, 1997, ANN TELECOMMUN, V52, P397; MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4; Meyer F, 2000, COMPUT IMAGING VIS, V18, P189; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; NGUYEN HT, 2000, 12 U AMST INT SENS I; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PARDAS M, 1994, P EUSIPCO 94 7 EUR S, P18; PRETEUX F, 1992, MATH MORPHOLOGY IMAG, P323; Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187; SALEMBIER P, 1994, SIGNAL PROCESS, V38, P359, DOI 10.1016/0165-1684(94)90155-4; Serra J, 1982, IMAGE ANAL MATH MORP; TEK H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P156, DOI 10.1109/ICCV.1995.466792; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	30	139	156	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					330	342						13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL					2022-12-18	WOS:000181071300005
J	Kegl, B; Krzyak, A				Kegl, B; Krzyak, A			Piecewise linear skeletonization using principal curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						skeletonization; principal curves; feature extraction; image processing	SHAPE-DESCRIPTION; ALGORITHM; IMAGES	We propose an algorithm to find plecewise linear skeletons of handwritten characters by using principal curves. The development of the method was inspired by the apparent similarity between the definition of principal curves (smooth curves which pass through the "middle" of a cloud of points) and the medial axis (smooth curves that go equidistantly from the contours of a character image). The central fitting-and-smoothing step of the algorithm is an extension of the polygonal line algorithm [1], [2] which approximates principal curves of data sets by plecewise linear curves. The polygonal line algorithm is extended to find principal graphs and complemented with two steps specific to the task of skeletonization: an initialization method to capture the approximate topology of the character, and a collection of restructuring operations to improve the structural quality of the skeleton produced by the initialization method. An advantage of our approach over existing methods is that we optimize the skeleton graph by minimizing an intuitive and explicit objective function that captures the two competing criteria of smoothing the skeleton and fitting it closely to the pixels of the character image. We tested the algorithm on isolated handwritten digits and images of continuous handwriting. The results indicate that the proposed algorithm finds a smooth medial axis of the great majority of a wide variety of character templates and substantially improves the pixe/wise skeleton obtained by traditional thinning methods.	Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada; Concordia Univ, Dept Comp Sci, Montreal, PQ H3G 1M8, Canada	Universite de Montreal; Concordia University - Canada	Kegl, B (corresponding author), Univ Montreal, Dept Comp Sci & Operat Res, CP 6128 Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.							ALCORN TM, 1969, MARCONI REV, V32, P61; BANFIELD JD, 1992, J AM STAT ASSOC, V87, P7, DOI 10.2307/2290446; BEZDEK JC, 1975, IEEE T COMPUT, V24, P835, DOI 10.1109/T-C.1975.224317; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Datta A, 1997, PATTERN RECOGN LETT, V18, P335, DOI 10.1016/S0167-8655(97)00020-2; DEMPSTER AP, 1997, J ROYAL STAT SOC B, V39, P1; Deseilligny MP, 1998, IEEE T PATTERN ANAL, V20, P505, DOI 10.1109/34.682180; DEUTSCH ES, 1968, P IEE NPL C PATT REC, P179; Dinneen G., 1955, P W JOINT COMP C, P94, DOI DOI 10.1145/1455292.1455311; EU D, 1994, CVGIP-GRAPH MODEL IM, V56, P231, DOI 10.1006/cgip.1994.1021; FORTUNE S, 1987, ALGORITHMICA, V2, P153, DOI 10.1007/BF01840357; Grother PJ, 1995, HANDPRINTED FORMS CH, P10; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hastie T., 1984, THESIS STANFORD U; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; KEGL B, 1999, THESIS CONCORDIA U M; KIRSCH RA, 1957, P EASTERN JOINT COMP, P221; Kohonen T., 1997, SELF ORG MAP; LEE SW, 1993, PATTERN RECOGN, V7, P1203; LINDE Y, 1980, IEEE T COMMUN, V28, P1; Luttrell S P, 1990, IEEE Trans Neural Netw, V1, P229, DOI 10.1109/72.80234; MAHMOUD SA, 1991, PATTERN RECOGN, V24, P453, DOI 10.1016/0031-3203(91)90058-D; NACCACHE NJ, 1984, IEEE T SYSTEMS MAN C, V14; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; ROWEIS S, 1998, ADV NEURAL INFORMATI, V10; Singh R, 2000, IEEE T NEURAL NETWOR, V11, P241, DOI 10.1109/72.822527; SUZUKI S, 1986, P 8 INT C PATT REC, P289; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1158, DOI 10.1109/34.809109	29	139	164	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					59	74		10.1109/34.982884	http://dx.doi.org/10.1109/34.982884			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ					2022-12-18	WOS:000172960300004
J	Morano, RA; Ozturk, C; Conn, R; Dubin, S; Zietz, S; Nissanov, J				Morano, RA; Ozturk, C; Conn, R; Dubin, S; Zietz, S; Nissanov, J			Structured light using pseudorandom codes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D imaging; structured light; perfect maps; pseudorandom arrays; active stereo vision; correspondence	PERFECT MAPS	We solve the correspondence problem in active stereo vision using a novel pseudorandom coded structured light (SL). This coding scheme performs well in the presence of occlusion. In settings where color coding is feasible, 3D information can be obtained using a single image.	Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA 19104 USA; Drexel Univ, Imaging & Comp Vis Ctr, Philadelphia, PA 19104 USA; Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA	Drexel University; Drexel University; Drexel University	Morano, RA (corresponding author), Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA 19104 USA.		Ozturk, Cengizhan/A-6177-2016	Ozturk, Cengizhan/0000-0002-6966-0774				ALTSCHULER M, 1987, 3 DIMENSIONAL MACHIN; AMIR I, 1991, SPIE, V1614; Ballard D.H., 1982, COMPUTER VISION; BARNARD ST, 1982, ACM COMPUTING SURVEY, V14; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; CARRIHILL B, 1985, COMPUT VISION GRAPH, V32, P337, DOI 10.1016/0734-189X(85)90056-8; DUNN SM, 1989, IEEE T SYST MAN CYB, V19, P1350, DOI 10.1109/21.44059; ETZION T, 1988, IEEE T INFORM THEORY, V34, P1308, DOI 10.1109/18.21260; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; LLARIO V, 1992, COMPUTER VISION THEO; MORANO RA, 1994, THESIS DREXEL U PHIL; OZTURK C, IN PRESS P AM MATH S; PATERSON KG, 1994, IEEE T INFORM THEORY, V40, P743, DOI 10.1109/18.335886; Penna M.A., 1986, PROJECTIVE GEOMETRY; Peterson W. W., 1972, ERROR CORRECTING COD, V2nd; WANG YF, 1987, IEEE T PATTERN ANAL, V9, P129, DOI 10.1109/TPAMI.1987.4767878	16	139	185	3	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					322	327		10.1109/34.667888	http://dx.doi.org/10.1109/34.667888			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400008
J	DAVIS, LS				DAVIS, LS			SHAPE MATCHING USING RELAXATION TECHNIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DAVIS, LS (corresponding author), UNIV TEXAS,DEPT COMP SCI,AUSTIN,TX 78712, USA.		Rohlf, F J/A-8710-2008					AMBLER AP, 1973, 3RD P INT JOINT C AR, P298; BARROW HG, 1976, TN121 STANF RES I AI; DAVIS L, 1978, JUN P PATT REC IM PR, P275; Davis L. S., 1976, 3rd International Joint Conference on Pattern Recognition, P591; DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812; DAVIS LS, 1976, TR480 U MAR COMP SCI; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; FEDER J, 1965, AD619525; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Fu K.S., 1974, MATH SCI ENG; PAVLIDIS T, 1976, CS216 PRINC U TECH R; Pavlidis T., 1977, STRUCTURAL PATTERN R; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	19	139	139	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					60	72		10.1109/TPAMI.1979.4766876	http://dx.doi.org/10.1109/TPAMI.1979.4766876			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HA303	21868831				2022-12-18	WOS:A1979HA30300007
J	Orchard, G; Meyer, C; Etienne-Cummings, R; Posch, C; Thakor, N; Benosman, R				Orchard, Garrick; Meyer, Cedric; Etienne-Cummings, Ralph; Posch, Christoph; Thakor, Nitish; Benosman, Ryad			HFirst: A Temporal Approach to Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neuromorphic computing; computer vision; object recognition; neural nets	EVENT; NETWORK; SYSTEM; ARCHITECTURE; LATENCY; DRIVEN; CHIP	This paper introduces a spiking hierarchical model for object recognition which utilizes the precise timing information inherently present in the output of biologically inspired asynchronous address event representation (AER) vision sensors. The asynchronous nature of these systems frees computation and communication from the rigid predetermined timing enforced by system clocks in conventional systems. Freedom from rigid timing constraints opens the possibility of using true timing to our advantage in computation. We show not only how timing can be used in object recognition, but also how it can in fact simplify computation. Specifically, we rely on a simple temporal-winner-take-all rather than more computationally intensive synchronous operations typically used in biologically inspired neural networks for object recognition. This approach to visual computation represents a major paradigm shift from conventional clocked systems and can find application in other sensory modalities and computational tasks. We showcase effectiveness of the approach by achieving the highest reported accuracy to date (97.5% +/- 3.5%) for a previously published four class card pip recognition task and an accuracy of 84.9% +/- 1.9% for a new more difficult 36 class character recognition task.	[Orchard, Garrick; Thakor, Nitish] Natl Univ Singapore, Singapore Inst Neurotechnol SINAPSE, Singapore 117548, Singapore; [Meyer, Cedric; Posch, Christoph; Benosman, Ryad] Univ Paris 06, Inst Vis, Paris, France; [Etienne-Cummings, Ralph] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA	National University of Singapore; UDICE-French Research Universities; Sorbonne Universite; Johns Hopkins University	Orchard, G (corresponding author), Natl Univ Singapore, Singapore Inst Neurotechnol SINAPSE, Singapore 117548, Singapore.	garrickorchard@nus.edu.sg; meyer.cece@gmail.com; retienne@jhu.edu; cposch@yahoo.com; eletnv@nus.edu.sg; ryad.benosman@upmc.fr	Orchard, Garrick/M-7727-2014; Thakor, Nitish V/A-5878-2008	Orchard, Garrick/0000-0002-1243-2711; 	Merlion Programme of the Institut Franais de Singapour; National University of Singapore; SINAPSE startup grant from the National University of Singapore; Singapore Ministry of Defence	Merlion Programme of the Institut Franais de Singapour; National University of Singapore(National University of Singapore); SINAPSE startup grant from the National University of Singapore(National University of Singapore); Singapore Ministry of Defence(Ministry of Defence, Singapore)	The authors thank Bernabe Linares-Barranco for supplying the card pip data, discussions at the Telluride Neuromorphic Cognition Engineering Workshop for helping to formulate these ideas, and the Merlion programme of the Institut Francais de Singapour for facilitating ongoing collaboration on this project. The collaboration on this work was supported by the Merlion Programme of the Institut Franais de Singapour, under administrative supervision of the French Ministry of Foreign Affairs and the National University of Singapore. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressly or implied, of the French Ministry of Foreign Affairs. This research was funded by the SINAPSE startup grant from the National University of Singapore and Singapore Ministry of Defence. Garrick Orchard is the corresponding author.	Alivisatos AP, 2012, NEURON, V74, P970, DOI 10.1016/j.neuron.2012.06.006; Perez-Carrasco JA, 2013, IEEE T PATTERN ANAL, V35, P2706, DOI 10.1109/TPAMI.2013.71; Bengio, 2011, ADV NEURAL INFORM PR, P666, DOI DOI 10.5555/2986459.2986534; Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565; Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001; Benosman R, 2011, IEEE T NEURAL NETWOR, V22, P1723, DOI 10.1109/TNN.2011.2167239; Bishop, 1995, NEURAL NETWORKS PATT; Chen SS, 2012, IEEE T PATTERN ANAL, V34, P302, DOI 10.1109/TPAMI.2011.120; Chen SS, 2009, IEEE INT SYMP CIRC S, P775, DOI 10.1109/ISCAS.2009.5117864; Culurciello E, 2003, IEEE J SOLID-ST CIRC, V38, P281, DOI 10.1109/JSSC.2002.807412; Davison Andrew P, 2008, Front Neuroinform, V2, P11, DOI 10.3389/neuro.11.011.2008; Delbruck T, 2007, IEEE INT SYMP CIRC S, P845, DOI 10.1109/ISCAS.2007.378038; Delbruck T, 2010, IEEE INT SYMP CIRC S, P2426, DOI 10.1109/ISCAS.2010.5537149; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Eliasmith C., 2004, NEURAL ENG COMPUTATI; Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908; Folowosele F, 2011, IEEE J EM SEL TOP C, V1, P516, DOI 10.1109/JETCAS.2012.2183409; Folowosele F, 2008, 2008 IEEE BIOMEDICAL CIRCUITS AND SYSTEMS CONFERENCE - INTELLIGENT BIOMEDICAL SYSTEMS (BIOCAS), P181, DOI 10.1109/BIOCAS.2008.4696904; Gawne TJ, 1996, J NEUROPHYSIOL, V76, P1356, DOI 10.1152/jn.1996.76.2.1356; Goldberg DH, 2001, NEURAL NETWORKS, V14, P781, DOI 10.1016/S0893-6080(01)00057-0; Goodman Dan, 2008, Front Neuroinform, V2, P5, DOI 10.3389/neuro.11.005.2008; Greschner M, 2006, J NEUROPHYSIOL, V96, P2845, DOI 10.1152/jn.01131.2005; Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337; Liu SC, 2010, CURR OPIN NEUROBIOL, V20, P288, DOI 10.1016/j.conb.2010.03.007; Mahowald M., 1994, KLUWER INT SERIES EN; Markram H, 2011, PROCEDIA COMPUT SCI, V7, P39, DOI 10.1016/j.procs.2011.12.015; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; Masters T., 1993, PRACTICAL NEURAL NET; Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642; Orchard G, 2014, P IEEE, V102, P1520, DOI 10.1109/JPROC.2014.2346763; Orchard G, 2013, IEEE T NEUR NET LEAR, V24, P1239, DOI 10.1109/TNNLS.2013.2253563; Painkras E, 2013, IEEE J SOLID-ST CIRC, V48, P1943, DOI 10.1109/JSSC.2013.2259038; Park J, 2012, IEEE INT SYMP CIRC S, P707; Posch C, 2011, IEEE J SOLID-ST CIRC, V46, P259, DOI 10.1109/JSSC.2010.2085952; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Rogister P, 2012, IEEE T NEUR NET LEAR, V23, P347, DOI 10.1109/TNNLS.2011.2180025; Schemmel Johannes, 2012, 2012 IEEE International Symposium on Circuits and Systems - ISCAS 2012, DOI 10.1109/ISCAS.2012.6272131; Schraml S., 2010, PROC IEEE COMPUT SOC, P57; Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653; Serrano-Gotarredona T, 2013, IEEE J SOLID-ST CIRC, V48, P827, DOI 10.1109/JSSC.2012.2230553; Serre T., 2006, THESIS MIT CAMBRIDGE; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Vogelstein R. J., 2005, ADV NEURAL INFORM PR, P1457; Vogelstein RJ, 2007, NEURAL COMPUT, V19, P2281, DOI 10.1162/neco.2007.19.9.2281; Vogelstein RJ, 2007, IEEE T NEURAL NETWOR, V18, P253, DOI 10.1109/TNN.2006.883007; Zaghloul KA, 2004, IEEE T BIO-MED ENG, V51, P657, DOI 10.1109/TBME.2003.821039	49	138	147	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2028	2040		10.1109/TPAMI.2015.2392947	http://dx.doi.org/10.1109/TPAMI.2015.2392947			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353184	Green Submitted			2022-12-18	WOS:000360813400007
J	Rudin, C; Waltz, D; Anderson, RN; Boulanger, A; Salleb-Aouissi, A; Chow, M; Dutta, H; Gross, PN; Huang, B; Ierome, S; Isaac, DF; Kressner, A; Passonneau, RJ; Radeva, A; Wu, L				Rudin, Cynthia; Waltz, David; Anderson, Roger N.; Boulanger, Albert; Salleb-Aouissi, Ansaf; Chow, Maggie; Dutta, Haimonti; Gross, Philip N.; Huang, Bert; Ierome, Steve; Isaac, Delfina F.; Kressner, Arthur; Passonneau, Rebecca J.; Radeva, Axinia; Wu, Leon			Machine Learning for the New York City Power Grid	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Applications of machine learning; electrical grid; smart grid; knowledge discovery; supervised ranking; computational sustainability; reliability	KNOWLEDGE DISCOVERY; RANKING	Power companies can benefit from the use of knowledge discovery methods and statistical machine learning for preventive maintenance. We introduce a general process for transforming historical electrical grid data into models that aim to predict the risk of failures for components and systems. These models can be used directly by power companies to assist with prioritization of maintenance and repair work. Specialized versions of this process are used to produce 1) feeder failure rankings, 2) cable, joint, terminator, and transformer rankings, 3) feeder Mean Time Between Failure (MTBF) estimates, and 4) manhole events vulnerability rankings. The process in its most general form can handle diverse, noisy, sources that are historical (static), semi-real-time, or real-time, incorporates state-of-the-art machine learning algorithms for prioritization (supervised ranking or MTBF), and includes an evaluation of results via cross-validation and blind test. Above and beyond the ranked lists and MTBF estimates are business management interfaces that allow the prediction capability to be integrated directly into corporate planning and decision support; such interfaces rely on several important properties of our general modeling approach: that machine learning features are meaningful to domain experts, that the processing of data is transparent, and that prediction results are accurate enough to support sound decision making. We discuss the challenges in working with historical electrical grid data that were not designed for predictive purposes. The "rawness" of these data contrasts with the accuracy of the statistical models that can be obtained from the process; these models are sufficiently accurate to assist in maintaining New York City's electrical grid.	[Rudin, Cynthia] MIT, Alfred P Sloan Sch Management, Cambridge, MA 02139 USA; [Rudin, Cynthia; Waltz, David; Anderson, Roger N.; Boulanger, Albert; Salleb-Aouissi, Ansaf; Dutta, Haimonti; Huang, Bert; Passonneau, Rebecca J.; Radeva, Axinia; Wu, Leon] Columbia Univ, Ctr Computat Learning Syst, Interchurch Ctr 850, New York, NY 10115 USA; [Kressner, Arthur] Consolidated Edison Co New York Inc, Grid Connect LLC, New York, NY 10003 USA; [Gross, Philip N.] Google Inc, New York, NY 10011 USA	Massachusetts Institute of Technology (MIT); Columbia University; Google Incorporated	Rudin, C (corresponding author), MIT, Alfred P Sloan Sch Management, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	rudin@mit.edu; waltz@ccls.columbia.edu; anderson@ldeo.columbia.edu; aboulanger@ldeo.columbia.edu; ansaf@ccls.columbia.edu; chowm@coned.com; haimonti@ccls.columbia.edu; phil@philgross.com; bert@cs.columbia.edu; ieromes@coned.com; isaacd@coned.com; grid.connections@gmail.com; becky@cs.columbia.edu; axinia@ccls.columbia.edu; leon@ccls.columbia.edu	Huang, Bert/E-2576-2016	Huang, Bert/0000-0002-8548-7246; Boulanger, Albert/0000-0003-0789-8709; Passonneau, Rebecca/0000-0001-8626-811X				Amin S.M., 2011, IEEE SPECTRUM    JAN; [Anonymous], 2003, GRID 2030 NATL VIS E; Azevedo A., 2008, IADIS EUROPEAN C DAT, P182; Becker H, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P86; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1983, CART CLASSIFICATION; Chen HC, 2004, COMPUTER, V37, P50, DOI 10.1109/MC.2004.1297301; Chupka M.W., 2008, TRANSFORMING AM POWE; Cornelusse B., 2007, P IEEE LAUS POW TECH; COX DR, 1972, J R STAT SOC B, V34, P187; Cunningham H, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P168; Dalal S.R., 2003, STAT IND HDB STAT, V22; Drucker H, 1997, ADV NEUR IN, V9, P155; Dutta H., 2008, P WORKSH GEOV DYN MO; FRAWLEY WJ, 1992, AI MAG, V13, P57; Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI DOI 10.1162/JMLR.2003.4.6.933; Geurts P., 1998, P ICMLAAAI 98 WORKSH, P21; Gross P., 2009, P INT C MACH LEARN A, P725; Gross P., 2006, P 18 C INN APPL ART; Harding JA, 2006, J MANUF SCI E-T ASME, V128, P969, DOI 10.1115/1.2194554; Hatziargyriou N., 2001, Machine learning and its applications. Advanced lectures, P308; Hsu W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P430, DOI 10.1145/347090.347180; Joachims T., 2005, P INT C MACH LEARN; Katsigiannis YA, 2006, LECT NOTES COMPUT SC, V3955, P105; Kohavi R, 2004, MACH LEARN, V57, P83, DOI 10.1023/B:MACH.0000035473.11134.83; North American Electric Reliability Corporation (NERC), 2007, RES 2007 SURV REL IS; Passonneau R., 2009, P 10 INT C COMP LING; Radeva A., 2009, P INT C MACH LEARN A; ROSENBAUM PR, 1983, BIOMETRIKA, V70, P41, DOI 10.1093/biomet/70.1.41; Rudin C, 2010, MACH LEARN, V80, P1, DOI 10.1007/s10994-009-5166-y; Rudin C, 2009, J MACH LEARN RES, V10, P2193; Rudin C, 2009, J MACH LEARN RES, V10, P2233; Saramourtsis A., 2001, P WORKSH MACH LEARN, P308; Shivaswamy P., 2007, P INT C DAT MIN; Ukil A, 2007, POWER SYST, P1; Wehenkel L., 2006, P 2 CARN MELL C EL P; Wehenkel L. A., 1998, KLUW POWER	39	138	157	2	74	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					328	345		10.1109/TPAMI.2011.108	http://dx.doi.org/10.1109/TPAMI.2011.108			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21576741	Green Submitted			2022-12-18	WOS:000298105500011
J	Wei, HL; Billings, SA				Wei, Hua-Liang; Billings, Stephen A.			Feature subset selection and ranking for data dimensionality reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; feature selection; high-dimensional data	UNSUPERVISED FEATURE-SELECTION; IDENTIFICATION; RECOGNITION; VARIABLES; SYSTEMS	A new unsupervised forward orthogonal search (FOS) algorithm is introduced for feature selection and ranking. In the new algorithm, features are selected in a stepwise way, one at a time, by estimating the capability of each specified candidate feature subset to represent the overall features in the measurement space. A squared correlation function is employed as the criterion to measure the dependency between features and this makes the new algorithm easy to implement. The forward orthogonalization strategy, which combines good effectiveness with high efficiency, enables the new algorithm to produce efficient feature subsets with a clear physical interpretation.	Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S1 3JD, S Yorkshire, England	University of Sheffield	Wei, HL (corresponding author), Univ Sheffield, Dept Automat Control & Syst Engn, Mapping St, Sheffield S1 3JD, S Yorkshire, England.	w.hualiang@sheffield.ac.uk; s.billings@sheffield.ac.uk	Wei, Hua-liang/AAX-4771-2020	Wei, Hua-liang/0000-0002-4704-7346				Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; BILLINGS SA, 1989, INT J CONTROL, V49, P2157, DOI 10.1080/00207178908559767; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; CARREIRAPERPINA.MA, 2001, THESIS U SHEFFIELD S; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Fodor I, 2002, UCRLID148494; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JEFFERS JNR, 1967, APPLIED STATISTICS, V16, P225; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; JOLLIFFE IT, 1973, APPL STATIST, V22, P21, DOI DOI 10.2307/2346300; JOLLIFFE IT, 1972, APPL STAT, V21, P160, DOI DOI 10.2307/2346488; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KORENBERG M, 1988, INT J CONTROL, V48, P193, DOI 10.1080/00207178808906169; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; KRZANOWSKI WJ, 1987, APPL STAT-J ROY ST C, V36, P22; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; Mao KZ, 2005, IEEE T SYST MAN CY B, V35, P339, DOI 10.1109/TSMCB.2004.843269; MCCABE GP, 1984, TECHNOMETRICS, V26, P137, DOI 10.2307/1268108; Miller A., 1990, SUBSET SELECTION REG; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Pal SK, 2000, IEEE T NEURAL NETWOR, V11, P366, DOI 10.1109/72.839007; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Webb A.R., 2003, STAT PATTERN RECOGNI; Wei HL, 2004, INT J CONTROL, V77, P86, DOI 10.1080/00207170310001639640; [No title captured]	27	138	148	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					162	166		10.1109/TPAMI.2007.250607	http://dx.doi.org/10.1109/TPAMI.2007.250607			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108391	Green Published			2022-12-18	WOS:000241988300013
J	Hofmann, T; Puzicha, J; Buhmann, JM				Hofmann, T; Puzicha, J; Buhmann, JM			Unsupervised texture segmentation in a deterministic annealing framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; pairwise clustering; deterministic annealing; EM algorithm; Gabor filters	MARKOV RANDOM-FIELDS; VECTOR QUANTIZATION; GABOR FILTERS; OPTIMIZATION; CLASSIFICATION; DISTRIBUTIONS; ALGORITHM	We present a novel optimization framework for unsupervised texture segmentation that relies on statistical tests as a measure of homogeneity. Texture segmentation is formulated as a data clustering problem based on sparse proximity data. Dissimilarities of pairs of textured regions are computed from a multiscale Gabor filter image representation. We discuss and compare a class of clustering objective functions which is systematically derived from invariance principles. As a general optimization framework, we propose deterministic annealing based on a mean-field approximation. The canonical way to derive clustering algorithms within this framework as well as an efficient implementation of mean-field annealing and the closely related Gibbs sampler are presented. We apply both annealing variants to Brodatz-like microtexture mixtures and real-word images.	MIT, Dept Brain & Cognit Sci, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA; Univ Bonn, Inst Informat 3, D-53117 Bonn, Germany	Massachusetts Institute of Technology (MIT); University of Bonn	Hofmann, T (corresponding author), MIT, Dept Brain & Cognit Sci, Ctr Biol & Computat Learning, E25-618, Cambridge, MA 02139 USA.	hofmann@ai.mit.edu; jan@cs.uni-bonn.de; jb@cs.uni-bonn.de						BESAG J, 1986, J R STAT SOC B, V48, P259; BILBRO G, 1989, J OPTICAL SOC AM, V8; BILBRO GL, 1992, IEEE T NEURAL NETWOR, V3, P131, DOI 10.1109/72.105426; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; BUHMANN J, 1993, IEEE T INFORM THEORY, V39, P1133, DOI 10.1109/18.243432; Buhmann J., 1995, AI MAGAZINE, V16; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; FLORACK L, 1992, P 2 EUR C COMP VIS, P19; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEIGER D, 1990, ADV NEURAL INFORMATI, V2, P660; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Hofmann T, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P213, DOI 10.1109/ICIP.1997.632061; Hofmann T, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P137, DOI 10.1109/ICIP.1996.560389; HOFMANN T, 1996, IAITR962 I INF 3; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LEE TS, 1992, P EUR C COMP VIS, P165; Lindgren B. W., 1976, STAT THEORY; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; NAVARRO R, 1994, 52 I OPT DAZ VALD MA; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Peterson C., 1989, International Journal of Neural Systems, V1, P3, DOI 10.1142/S0129065789000414; Peterson C., 1987, Complex Systems, V1, P995; Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331; PUZICHA J, 1997, P 15 IMACS WORLD C S; ROMENY H, 1994, GEOMETRY DRIVEN DIFF; ROSE K, 1992, IEEE T INFORM THEORY, V38, P1249, DOI 10.1109/18.144705; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; Van den Bout D E, 1990, IEEE Trans Neural Netw, V1, P192, DOI 10.1109/72.80231; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1; ZERUBIA J, 1993, IEEE T NEURAL NETWOR, V4, P703, DOI 10.1109/72.238324; Zhang J, 1996, IEEE T IMAGE PROCESS, V5, P1662, DOI 10.1109/83.544573; Zhang J, 1996, IEEE T IMAGE PROCESS, V5, P1208, DOI 10.1109/83.502411; Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863	45	138	142	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					803	818		10.1109/34.709593	http://dx.doi.org/10.1109/34.709593			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700004
J	Xie, Q; Zhao, Q; Meng, DY; Xu, ZB				Xie, Qi; Zhao, Qian; Meng, Deyu; Xu, Zongben			Kronecker-Basis-Representation Based Tensor Sparsity and Its Applications to Tensor Recovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor sparsity; tucker decomposition; CANDECOMP/PARAFAC decomposition; tensor completion; multi-spectral image restoration	LOW-RANK; MATRIX FACTORIZATION; IMAGE-RESTORATION; COMPLETION	As a promising way for analyzing data, sparse modeling has achieved great success throughout science and engineering. It is well known that the sparsity/low-rank of a vector/matrix can be rationally measured by nonzero-entries-number (l(0) norm)/nonzero-singular-values-number (rank), respectively. However, data from real applications are often generated by the interaction of multiple factors, which obviously cannot be sufficiently represented by a vector/matrix, while a high order tensor is expected to provide more faithful representation to deliver the intrinsic structure underlying such data ensembles. Unlike the vector/matrix case, constructing a rational high order sparsity measure for tensor is a relatively harder task. To this aim, in this paper we propose a measure for tensor sparsity, called Kronecker-basis-representation based tensor sparsity measure (KBR briefly), which encodes both sparsity insights delivered by Tucker and CANDECOMP/PARAFAC (CP) low-rank decompositions for a general tensor. Then we study the KBR regularization minimization (KBRM) problem, and design an effective ADMM algorithm for solving it, where each involved parameter can be updated with closed-form equations. Such an efficient solver makes it possible to extend KBR to various tasks like tensor completion and tensor robust principal component analysis. A series of experiments, including multispectral image (MSI) denoising, MSI completion and background subtraction, substantiate the superiority of the proposed methods beyond state-of-the-arts.	[Xie, Qi; Zhao, Qian; Meng, Deyu; Xu, Zongben] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Xie, Qi; Zhao, Qian; Meng, Deyu; Xu, Zongben] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China	Xi'an Jiaotong University; Xi'an Jiaotong University	Meng, DY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.; Meng, DY (corresponding author), Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China.	xq.liwu@stu.xjtu; timmy.zhaoqian@mail.xjtu.edu.cn; dymeng@mail.xjtu.edu.cn; zbxu@mail.xjtu.edu.cn			National Natural Science Foundation of China [61661166011, 61373114, 11690011, 61603292]; 973 Program of China [2013CB329404]; Macau Science and Technology Development Funds [003/2016/AFJ]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); 973 Program of China(National Basic Research Program of China); Macau Science and Technology Development Funds	This work was supported by the National Natural Science Foundation of China under Grant No. 61661166011, 61373114, 11690011, 61603292, the 973 Program of China under Grant No. 2013CB329404 and Macau Science and Technology Development Funds under Grant No. 003/2016/AFJ.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.187; Babacan SD, 2012, IEEE T SIGNAL PROCES, V60, P3964, DOI 10.1109/TSP.2012.2197748; Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Buchanan AM, 2005, PROC CVPR IEEE, P316; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262; Cao WF, 2015, NEUROCOMPUTING, V152, P261, DOI 10.1016/j.neucom.2014.10.069; Chen Alex, 2012, P SOC PHOTO-OPT INS, P85371; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Ding XH, 2011, IEEE T IMAGE PROCESS, V20, P3419, DOI 10.1109/TIP.2011.2156801; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Eriksson A., 2010, P IEEE C COMP VIS PA, P13; Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Golbabaee M, 2012, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2012.6467014; Golbabaee M, 2012, INT CONF ACOUST SPEE, P2741, DOI 10.1109/ICASSP.2012.6288484; Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010; Gong P. H., 2013, P 30 INT C MACH LEAR; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; He W, 2016, IEEE T GEOSCI REMOTE, V54, P176, DOI 10.1109/TGRS.2015.2452812; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457; Ke QF, 2005, PROC CVPR IEEE, P739; Kenny J. P., 2005, 5 IEEE INT C DAT MIN, P8; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin Z., 2009, P IEEE INT WORKSH CO; Lin Z., 2010, 100920105055 ARXIV, P1, DOI DOI 10.1016/J.JSB.2012.10.010; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Liu J, 2009, IEEE I CONF COMP VIS, P2114; Liu XF, 2012, IEEE T GEOSCI REMOTE, V50, P3717, DOI 10.1109/TGRS.2012.2187063; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Lu CY, 2015, AAAI CONF ARTIF INTE, P1805; Maggioni M., 2012, P SOC PHOTO-OPT INS; Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725; Manjon JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003; Meng DY, 2013, IEEE I CONF COMP VIS, P1337, DOI 10.1109/ICCV.2013.169; MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331; Parvaresh F, 2008, IEEE J-STSP, V2, P275, DOI 10.1109/JSTSP.2008.924384; Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343; Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377; Raychaudhuri S, 2000, Pac Symp Biocomput, P455; Renard N, 2008, IEEE GEOSCI REMOTE S, V5, P138, DOI 10.1109/LGRS.2008.915736; Richard E, 2013, P ICML, V3, P1157; Richard E., 2012, ARXIV12066474; Romera-Paredes B., 2013, ADV NEURAL INFORM PR, V2, P2967; Rup M., 2008, ALGORITHMS SPARSE NO; Sauve AC, 1999, IEEE T NUCL SCI, V46, P2075, DOI 10.1109/23.819285; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Srebro N., 2003, P 20 INT C MACHINE L, P720; Taheri O, 2011, INT CONF ACOUST SPEE, P2864; Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Wald L., 2002, DATA FUSION DEFINITI; Wang H, 2014, AAAI CONF ARTIF INTE, P2846; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xu YY, 2015, INVERSE PROBL IMAG, V9, P601, DOI 10.3934/ipi.2015.9.601; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485; Zhao Q, 2014, PR MACH LEARN RES, V32, P55; Zhao XL, 2013, IEEE T GEOSCI REMOTE, V51, P4045, DOI 10.1109/TGRS.2012.2227764	76	137	140	5	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1888	1902		10.1109/TPAMI.2017.2734888	http://dx.doi.org/10.1109/TPAMI.2017.2734888			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28783623				2022-12-18	WOS:000437271100008
J	Ben Amor, B; Su, JY; Srivastava, A				Ben Amor, Boulbaba; Su, Jingyong; Srivastava, Anuj			Action Recognition Using Rate-Invariant Analysis of Skeletal Shape Trajectories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; Riemannian geometry; manifold trajectories; depth sensors; skeletal data	ENSEMBLE; LATENCY	We study the problem of classifying actions of human subjects using depth movies generated by Kinect or other depth sensors. Representing human body as dynamical skeletons, we study the evolution of their (skeletons') shapes as trajectories on Kendall's shape manifold. The action data is typically corrupted by large variability in execution rates within and across subjects and, thus, causing major problems in statistical analyses. To address that issue, we adopt a recently-developed framework of Su et al. [1], [2] to this problem domain. Here, the variable execution rates correspond to re-parameterizations of trajectories, and one uses a parameterization-invariant metric for aligning, comparing, averaging, and modeling trajectories. This is based on a combination of transported square-root vector fields (TSRVFs) of trajectories and the standard Euclidean norm, that allows computational efficiency. We develop a comprehensive suite of computational tools for this application domain: smoothing and denoising skeleton trajectories using median filtering, up-and down-sampling actions in time domain, simultaneous temporal-registration of multiple actions, and extracting invertible Euclidean representations of actions. Due to invertibility these Euclidean representations allow both discriminative and generative models for statistical analysis. For instance, they can be used in a SVM-based classification of original actions, as demonstrated here using MSR Action-3D, MSR Daily Activity and 3D Action Pairs datasets. Using only the skeletal information, we achieve state-of-the-art classification results on these datasets.	[Ben Amor, Boulbaba] Inst Mines Telecom Telecom Lille, CRIStAL UMR 9189, Lille, France; [Su, Jingyong] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Srivastava, Anuj] Texas Tech Univ, Dept Math & Stat, Lubbock, TX 79409 USA	State University System of Florida; Florida State University; Texas Tech University System; Texas Tech University	Ben Amor, B (corresponding author), Inst Mines Telecom Telecom Lille, CRIStAL UMR 9189, Lille, France.	benamor@telecom-lille.fr; anuj@stat.fsu.edu; jingyong.su@ttu.edu	Ben Amor, Boulbaba/K-7066-2018; Srivastava, Anuj/L-4705-2019	Ben Amor, Boulbaba/0000-0002-4176-9305; Srivastava, Anuj/0000-0001-7406-0338	Institut Mines-Telecom; MAGNUM project (BPI); NSF [DMS 1208959, 1217515]; Fulbright scholar grant; MAGNUM project (Region Nord-Pas de Calais); Direct For Computer & Info Scie & Enginr [1217515] Funding Source: National Science Foundation; Division of Computing and Communication Foundations [1320267, 1319658] Funding Source: National Science Foundation	Institut Mines-Telecom(Centre National de la Recherche Scientifique (CNRS)); MAGNUM project (BPI); NSF(National Science Foundation (NSF)); Fulbright scholar grant; MAGNUM project (Region Nord-Pas de Calais)(Region Hauts-de-France); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE)); Division of Computing and Communication Foundations(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This research was performed during B. Ben Amor's visit to the Florida State University during 2013-2014. It was supported in part by Institut Mines-Telecom, the MAGNUM project (BPI and Region Nord-Pas de Calais) to BB, and NSF grants DMS 1208959 and 1217515, and a Fulbright scholar grant to AS.	Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006; Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013; Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7; Gritai A, 2009, INT J COMPUT VISION, V84, P325, DOI 10.1007/s11263-009-0239-8; Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088; Koppula H., 2013, INT C MACHINE LEARNI, P792, DOI DOI 10.1177/0278364913478446; Li W., 2010, P IEEE INT WORKSH CV, P914; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; MEHRABIAN A, 1967, J PERS SOC PSYCHOL, V6, P109, DOI 10.1037/h0024532; Mualler M., 2006, P 2006 ACM SIGGRAPH, P137; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Slama R, 2014, INT C PATT RECOG, P3499, DOI 10.1109/ICPR.2014.602; Srivastava A, 2012, IMAGE VISION COMPUT, V30, P398, DOI 10.1016/j.imavis.2012.03.006; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Su JY, 2014, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2014.86; Su JY, 2014, ANN APPL STAT, V8, P530, DOI 10.1214/13-AOAS701; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Sutskever I., 2011, P 28 INT C MACH LEAR, P1033, DOI DOI 10.1145/346152.346166; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Veeraraghavan A, 2006, 2006 IEEE COMPUTER S, V1, P959; Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Yang X., 2012, P 20 ACM INT C MULTI, P1057, DOI [10.1145/2393347.2396382, DOI 10.1145/2393347.2396382]; Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24	36	137	142	0	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					1	13		10.1109/TPAMI.2015.2439257	http://dx.doi.org/10.1109/TPAMI.2015.2439257			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	27030844				2022-12-18	WOS:000366669200001
J	Lazebnik, S; Raginsky, M				Lazebnik, Svetlana; Raginsky, Maxim			Supervised Learning of Quantizer Codebooks by Information Loss Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern recognition; information theory; quantization; clustering; computer vision; scene analysis; segmentation	IMAGE COMPRESSION; CLASSIFICATION	This paper proposes a technique for jointly quantizing continuous features and the posterior distributions of their class labels based on minimizing empirical information loss such that the quantizer index of a given feature vector approximates a sufficient statistic for its class label. Informally, the quantized representation retains as much information as possible for classifying the feature vector correctly. We derive an alternating minimization procedure for simultaneously learning codebooks in the euclidean feature space and in the simplex of posterior class distributions. The resulting quantizer can be used to encode unlabeled points outside the training set and to predict their posterior class distributions, and has an elegant interpretation in terms of lossless source coding. The proposed method is validated on synthetic and real data sets and is applied to two diverse problems: learning discriminative visual vocabularies for bag-of-features image classification and image segmentation.	[Lazebnik, Svetlana] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA; [Raginsky, Maxim] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	University of North Carolina; University of North Carolina Chapel Hill; Duke University	Lazebnik, S (corresponding author), Univ N Carolina, Dept Comp Sci, CB 3175,Sitterson Hall, Chapel Hill, NC 27599 USA.	lazebnik@cs.unc.edu; m.raginsky@duke.edu			France Telecom; US National Science Foundation [IIS-0535152/0535166]; Beckman Foundation Fellowship	France Telecom; US National Science Foundation(National Science Foundation (NSF)); Beckman Foundation Fellowship	The authors would like to thank the anonymous reviewers and the editor for comments that helped them to improve this paper. At the time of completing this work, Svetlana Lazebnik was supported by France Telecom and the US National Science Foundation under grant Toward CategoryLevel Object Recognition, J. Ponce (PI) and Y. LeCun, IIS-0535152/0535166. Maxim Raginsky was supported by the Beckman Foundation Fellowship.	Aiyer A, 2005, SIGNAL PROCESS-IMAGE, V20, P459, DOI 10.1016/j.image.2005.03.003; [Anonymous], [No title captured]; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Berger T., 1971, RATE DISTORTION THEO; Bishop, 1995, NEURAL NETWORKS PATT; Blackwell D., 1954, THEORY GAMES STAT DE, pXI, 355; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Csurka G., 2004, P ECCV WORKSH STAT L; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, P1265, DOI 10.1162/153244303322753661; Fei-Fei L., 2005, 2005 IEEE COMP SOC C; Gersho A., 1992, VECTOR QUANTIZATION; Grunwald P. D., 2007, MINIMUM DESCRIPTION; Hastie T, 2009, ELEMENTS STAT LEARNI; Heiler M, 2005, INT J COMPUT VISION, V63, P5, DOI 10.1007/s11263-005-4944-7; HUANG J, 1999, P IEEE C COMP VIS PA, V1, P541; KOHONEN T, 1986, TKKFA601 HELS I TECH; Kohonen T., 2000, SELF ORGANIZING MAPS; KULLBACK S, 1968, INFORM THEORY STAT; LARLUS D, 2005, P BRIT MACH VIS C; Lazebnik S., 2006, P IEEE C COMP VIS PA; LAZEBNIK S, 2007, P 11 INT C ART INT S; Linder T., 2001, PRINCIPLES NONPARAME; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McCallum A., 1998, AAAI 98 WORKSHOP LEA, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426; Moosmann F., 2006, ADV NEURAL INF PROCE, V19; ODONE F, 1992, IEEE T PATTERN ANAL, V14, P169; OEHLER KL, 1995, IEEE T PATTERN ANAL, V17, P461, DOI 10.1109/34.391396; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Rao A, 1996, INT CONF ACOUST SPEE, P2032, DOI 10.1109/ICASSP.1996.544855; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Robert CP., 2001, BAYESIAN CHOICE; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Salton G., 1986, INTRO MODERN INFORM; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Slonim N, 2005, P NATL ACAD SCI USA, V102, P18297, DOI 10.1073/pnas.0507432102; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tishby N., 1999, P 37 ANN ALL C COMM, P368; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; [No title captured]	43	137	144	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1294	1309		10.1109/TPAMI.2008.138	http://dx.doi.org/10.1109/TPAMI.2008.138			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443926				2022-12-18	WOS:000266188900012
J	Li, MK; Sethi, IK				Li, Mingkun; Sethi, Ishwar K.			Confidence-based active learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active learning; error estimation; pattern classification; support vector machines	CHOICE	This paper proposes a new active learning approach, confidence- based active learning, for training a wide range of classifiers. This approach is based on identifying and annotating uncertain samples. The uncertainty value of each sample is measured by its conditional error. The approach takes advantage of current classifiers' probability preserving and ordering properties. It calibrates the output scores of classifiers to conditional error. Thus, it can estimate the uncertainty value for each input sample according to its output score from a classifier and select only samples with uncertainty value above a user- defined threshold. Even though we cannot guarantee the optimality of the proposed approach, we find it to provide good performance. Compared with existing methods, this approach is robust without additional computational effort. A new active learning method for support vector machines ( SVMs) is implemented following this approach. A dynamic bin width allocation method is proposed to accurately estimate sample conditional error and this method adapts to the underlying probabilities. The effectiveness of the proposed approach is demonstrated using synthetic and real data sets and its performance is compared with the widely used least certain active learning method.	Lawrence Berkeley Natl Lab, DOE Joint Genome Inst, Walnut Creek, CA 94598 USA; Oakland Univ, Dept Comp Sci & Engn, Rochester, MI 48309 USA	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; Oakland University	Li, MK (corresponding author), Lawrence Berkeley Natl Lab, DOE Joint Genome Inst, 2800 Mitchell Dr, Walnut Creek, CA 94598 USA.	mli@lbl.gov; isethi@oakland.edu		Sethi, Ishwar/0000-0002-2578-111X				[Anonymous], 2000, P 17 INT C MACH LEAR; [Anonymous], 2002, P 8 INT C KNOWL DISC; BAIN LJ, 1991, INTRO PROBABILITY MA; Baram Y, 2004, J MACH LEARN RES, V5, P255; Bazaraa MS., 2013, NONLINEAR PROGRAMMIN; Blum A, 1998, LECT NOTES COMPUT SC, V1442, P306, DOI 10.1007/BFb0029575; Brinker K., 2003, ICML, P59; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAMPBELL C, 2000, P 17 INT C MACH LEAR; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; DIETTERICH TG, 2002, LECT NOTES COMPUTER; Duda R.O., 2000, PATTERN CLASSIFICATI; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Fukumizu K, 2000, IEEE T NEURAL NETWOR, V11, P17, DOI 10.1109/72.822506; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Joachims T., 1999, ADV KERNEL METHOD SU; KONG EG, 1997, P INT C ART INT SOFT; Lewis David D, 1994, P 11 INT C MACH LEAR, P148, DOI [10.1016/b978-1-55860-335-6.50026-x, DOI 10.1016/B978-1-55860-335-6.50026-X]; LI M, 2005, THESIS OAKLAND U; LI M, 2004, P 17 INT C PATT REC; Li M, 2006, PATTERN RECOGN, V39, P1230, DOI 10.1016/j.patcog.2006.01.010; Luo T, 2005, J MACH LEARN RES, V6, P589; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Mitra P, 2004, IEEE T PATTERN ANAL, V26, P413, DOI 10.1109/TPAMI.2004.1262340; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Park JM, 2004, IEEE T PATTERN ANAL, V26, P1197, DOI 10.1109/TPAMI.2004.61; PATHAK AP, 1990, PATTERN RECOGN, V23, P325, DOI 10.1016/0031-3203(90)90020-L; Platt J., 1999, ADV LARGE MARGIN CLA; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Roy Nicholas, 2001, P 18 INT C MACH LEAR, P441; SASSANO M, 2002, P 40 ANN M ASS COMP; Sethi IK, 2001, MASSIVE COMP, V3, P1; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Vapnik V.N., 1999, NATURE STAT LEARNING; Vapnik V.N, 1998, STAT LEARNING THEORY; Wand MP, 1997, AM STAT, V51, P59, DOI 10.2307/2684697	40	137	143	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1251	1261		10.1109/TPAMI.2006.156	http://dx.doi.org/10.1109/TPAMI.2006.156			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886861				2022-12-18	WOS:000238162400007
J	BOLLE, RM; VEMURI, BC				BOLLE, RM; VEMURI, BC			ON 3-DIMENSIONAL SURFACE RECONSTRUCTION METHODS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EXPLICIT FUNCTIONS; IMPLICIT FUNCTIONS; LEAST SQUARES MINIMIZATION; PARAMETRIC SURFACES; RANGE DATA; SHAPE PRIMITIVES; SURFACE RECONSTRUCTION; VARIATIONAL PRINCIPLES; VIEWPOINT INVARIANCE	RANGE DATA; SHAPE; REPRESENTATION; RECOGNITION; VISION	Three-dimensional surface reconstruction is an important intermediate goal of many vision systems. In this paper, we survey some of the surface reconstruction methods that can be found in the literature; we will focus on a small, recent, and important subset of the published reconstruction techniques. The techniques are classified based on the surface representation used, implicit versus explicit functions. We study some important aspects of the surface reconstruction techniques. A first aspect is viewpoint invariance of the methods. This is an important property if object recognition is the ultimate objective. We give some indication of the robustness of the various methods. Also, we determine whether the parameter estimates are biased and touch upon the sensitivity to obscuration. The latter two aspects are in particular important for fitting functions in the implicit form. We describe, in detail, a parametric reconstruction method for three-dimensional object surfaces that involves numeric grid generation techniques and variational principle formulations. This technique is invariant to rigid motion in three-space.	UNIV FLORIDA,DEPT COMP & INFORMAT SCI,GAINESVILLE,FL 32611	State University System of Florida; University of Florida	BOLLE, RM (corresponding author), IBM CORP,THOMAS J WATSON RES CTR,DEPT AI,EXPLORATORY COMP VIS GRP,YORKTOWN HTS,NY 10598, USA.							AGIN GJ, 1976, 3RD P INT JOINT C AR, P629; BAJCSY R, 1982, 6TH IEEE P INT C PAT, P351; BAJCSY R, 1987, 1ST P INT C COMP VIS, P231; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BARROW HG, 1981, P IEEE, V69, P572, DOI 10.1109/PROC.1981.12026; BARSKY BA, 1981, THESIS U UTAH SALT L; Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; BINFORD TO, 1971, DEC IEEE C SYST CONT; BLAKE A, 1984, P NAT C ARTIFICIAL I, P23; BLAKE A, 1985, JUL P IEEE C COMP VI, P62; Bolle R. M., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P324; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6, P418, DOI 10.1109/TPAMI.1984.4767547; BOLLE RM, 1989, IEEE C COMPUTER VISI; BOLLE RM, 1989, IBM1988 TECH REP; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BOULT TE, 1987, NOV P SPIE INT ROB C, P358; BOULT TE, 1986, JUN P IEEE C COMP VI, P68; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; CERNUSCHIFRIAS B, 1984, THESIS BROWN U; CHOI DJ, 1988, JUN P IEEE C COMP VI, P189; CLINE AK, 1973, 3 NAT CTR ATM RES TE; CLINE AK, 1980, CNA169 U TEX AUST CT; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; COURANT R, 1962, METHODS MATH PHYSICS, V2; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Dresden A., 1964, SOLID ANAL GEOMETRY; DUCHON J, 1976, REV FRANC AUT INF RE, P5; FARIN G, 1987, GEOMETRIC MODELING; FAUGERAS OD, 1983, P IEEE C PATTERN REC; GARDINER M, 1965, SCI AM           SEP; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOLDMAN RN, 1987, GEOMETRIC MODELING A, P69; GRIMSON WEL, 1982, PHILOS T ROY SOC B, V298, P395, DOI 10.1098/rstb.1982.0088; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V6, P39; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; HACKBUSCH W, 1981, MULTIGRID METHODS; Hakala H. R., 1980, AUTOFACT W P, V1, P363; HALL EL, 1982, IEEE COMPUT      DEC, P42; HARRIS JG, 1986, THEISIS MIT CAMBRIDG; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IKEUCHI K, 1981, 7TH P INT JOINT C AR, P595; Jou J.-Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P138, DOI 10.1109/CVPR.1988.196227; KENDER JR, 1985, OCT P IEEE WORKSH CO, P157; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; Lagrange J. L., 1788, MECANIQUE ANALITIQUE; Lawson CL, 1977, MATH SOFTWARE, P161, DOI [10.1016/B978-0-12-587260-7.50011-X, DOI 10.1016/B978-0-12-587260-7.50011-X]; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MARR D, 1982, VISION, P295; MARROQUIN JL, 1985, THESIS MIT CAMBRIDGE; Meagher D, 1980, IPLTR80111 RENSS POL; Meinguet J., 1979, J APPL MATH PHYS, V30, P292; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; NAGEL HH, 1983, AUG P INT JOINT C AR, P945; NARAYANAN KA, 1982, IEEE T SYST MAN CYB, V12, P91; NEVATIA R, 1982, MACHINE PERCEPTION; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; PENTLAND AP, 1988, MIT104 MED LAB VIS S; PILCHER DT, 1973, THESIS U UTAH SALT L; PONCE J, 1987, INT J COMP VISION, V1; RALSTON A, 1987, 1ST COURSE NUMERICAL; Rao K., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P256; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; Requicha A. G., 1980, ACM COMPUT SURV, P437; SCALES LE, 1985, INT NONLINEAR OPTIMI; Schumaker LL, 1976, APPROXIMATION THEORY, VII, P203; Shafer S. A., 1985, SHADOWS SILHOUETTES; SOLINA F, 1987, THESIS U PENNSYLVANI; SZELISKI RS, 1988, THESIS CARNEGIEMELLO; TAUBIN G, 1988, IBM RC13873 TJ WATS; TAUBIN G, LEMS43 BROWN U DIV E; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; THOMPSON J. F., 1985, NUMERICAL GRID GENER; Tukey J., 1960, CONTRIBUTIONS PROBAB; TUKEY JW, 1962, ANN MATH STAT, V33, P1, DOI 10.1214/aoms/1177704711; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; VEMURI BC, 1987, THESIS U TEXAS AUST; [No title captured]	91	137	142	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					1	13		10.1109/34.67626	http://dx.doi.org/10.1109/34.67626			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	EX773					2022-12-18	WOS:A1991EX77300001
J	Prest, A; Schmid, C; Ferrari, V				Prest, Alessandro; Schmid, Cordelia; Ferrari, Vittorio			Weakly Supervised Learning of Interactions between Humans and Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; weakly supervised learning; object detection		We introduce a weakly supervised approach for learning human actions modeled as interactions between humans and objects. Our approach is human-centric: We first localize a human in the image and then determine the object relevant for the action and its spatial relation with the human. The model is learned automatically from a set of still images annotated only with the action label. Our approach relies on a human detector to initialize the model learning. For robustness to various degrees of visibility, we build a detector that learns to combine a set of existing part detectors. Starting from humans detected in a set of images depicting the action, our approach determines the action object and its spatial relation to the human. Its final output is a probabilistic model of the human-object interaction, i.e., the spatial relation between the human and the object. We present an extensive experimental evaluation on the sports action data set from [1], the PASCAL Action 2010 data set [2], and a new human-object interaction data set.	[Prest, Alessandro; Ferrari, Vittorio] ETH, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland; [Prest, Alessandro; Schmid, Cordelia] INRIA Rhone Alpes, LEAR Team, F-38334 Montbonnot St Martin, Saint Ismier, France	Swiss Federal Institutes of Technology Domain; ETH Zurich	Prest, A (corresponding author), ETH, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland.	prest@vision.ee.ethz.ch; Cordelia.Schmid@inrialpes.fr; ferrari@vision.ee.ethz.ch			QUAERO; OSEO; French State Agency for innovation; Microsoft/INRIA; Swiss National Science Foundation	QUAERO; OSEO; French State Agency for innovation; Microsoft/INRIA; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work was partially funded by the QUAERO project supported by OSEO, the French State Agency for innovation, the joint Microsoft/INRIA project, and the Swiss National Science Foundation.	Alexe B., 2010, P IEEE C COMP VIS PA; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2007, PASCAL VISUAL OBJECT; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Botev Z., 2007, U QUEENSLAND POSTGRA; Comaniciu D., 2001, P 8 IEEE INT C COMP; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C., 2010, P IEEE CS C COMP VIS; Desai C., 2007, P 12 IEEE INT C COMP; Deselaers T., 2010, P 11 EUR C COMP VIS; Dollar P., 2005, P 2 IEEE JOINT INT W; Eichner M., 2009, P BRIT MACH VIS C; Everingham M., 2008, PASCAL VISUAL OBJECT; Everingham M., 2010, PASCAL VISUAL OBJECT; Fergus R., 2003, P IEEE CS C COMP VIS; FERGUS R, 2003, CALTECH OBJECT CATEG; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Gehler P, 2009, P 12 IEEE INT C COMP; Grubinger M., 2006, P INT C LANG RES EV; Gupta A., 2008, P IEEE C COMP VIS PA; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; HEUSCH G, 2006, P 7 IEEE INT C AUT F; Ikizler-Cinbis N., 2009, P 12 IEEE INT C COMP; Ikizler-Cinbis N., 2010, P 11 EUR C COMP VIS; Johansson R., 2008, P 12 C COMP NAT LANG; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Laptev I., 2007, P 11 IEEE INT C COMP; Li L.J., 2007, P 11 IEEE INT C COMP; Mikolajczyk K., 2008, P IEEE C COMP VIS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rodriguez Y., 2006, THESIS EPF LAUSANNE; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Sullivan J., 2002, P 7 EUR C COMP VIS; Thurau C., 2008, P IEEE C COMP VIS PA; Viola P., 2001, IEEE COMP SOC C COMP; WILLEMS G, 2009, P BRIT MACH VIS C; Winn J., 2005, P 10 IEEE INT C COMP; Yao B., 2010, P IEEE C COMP VIS PA; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	39	136	142	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					601	614		10.1109/TPAMI.2011.158	http://dx.doi.org/10.1109/TPAMI.2011.158			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808083	Green Submitted, Green Published			2022-12-18	WOS:000299381600014
J	Yap, PT; Paramesran, R; Ong, SH				Yap, Pew-Thian; Paramesran, Raveendran, Sr.; Ong, Seng-Huat			Image analysis using Hahn moments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hahn polynomials; Hahn moments; discrete orthogonal polynomials; normalized convolution		This paper shows how Hahn moments provide a unified understanding of the recently introduced Chebyshev and Krawtchouk moments. The two latter moments can be obtained as particular cases of Hahn moments with the appropriate parameter settings and this fact implies that Hahn moments encompass all their properties. The aim of this paper is twofold: 1) To show how Hahn moments, as a generalization of Chebyshev and Krawtchouk moments, can be used for global and local feature extraction and 2) to show how Hahn moments can be incorporated into the framework of normalized convolution to analyze local structures of irregularly sampled signals.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur 50603, Malaysia; Univ Malaya, Fac Sci, Inst Math Sci, Kuala Lumpur 50603, Malaysia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Universiti Malaya; Universiti Malaya	Yap, PT (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	pewthian@ntu.edu.sg; ravee@um.edu.my; ongsh@um.edu.my	ONG, Seng Huat/B-9454-2010; Paramesran, Raveendran/AAA-1895-2019; Yap, Pew-Thian/G-3292-2012	ONG, Seng Huat/0000-0002-4288-7637; Paramesran, Raveendran/0000-0001-5093-7027				Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hahn W., 1949, MATH NACHR, V2, P263, DOI [10.1002/mana.19490020504, 10.1002/mana.19490020103]; Knutsson H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P515, DOI 10.1109/CVPR.1993.341081; Kreyszig E., 1988, ADV ENG MATH; Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; Wiederhold Gio, 1997, INT J DIGITAL LIB, P311; Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019; YAP PT, 2003, THESIS U MALAYA MALA; YAP PT, 2006, THESIS U MALAYA MALA; Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65	11	136	146	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					2057	2062		10.1109/TPAMI.2007.70709	http://dx.doi.org/10.1109/TPAMI.2007.70709			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848784				2022-12-18	WOS:000249343900014
J	Constantinopoulos, C; Titsias, MK; Likas, A				Constantinopoulos, C; Titsias, MK; Likas, A			Bayesian feature and model selection for Gaussian mixture models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mixture models; feature selection; model selection; Bayesian approach; variational training		We present a Bayesian method for mixture model training that simultaneously treats the feature selection and the model selection problem. The method is based on the integration of a mixture model formulation that takes into account the saliency of the features and a Bayesian approach to mixture learning that can be used to estimate the number of mixture components. The proposed learning algorithm follows the variational framework and can simultaneously optimize over the number of components, the saliency of the features, and the parameters of the mixture model. Experimental results using high- dimensional artificial and real data illustrate the effectiveness of the method.	Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece; Univ Edinburgh, Sch Informat, Edinburgh EH1 2QL, Midlothian, Scotland	University of Ioannina; University of Edinburgh	Constantinopoulos, C (corresponding author), Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.	ccostas@cs.uoi.gr; M.Titsias@sms.ed.ac.uk; arly@cs.uoi.gr						ATTIAS H, 2000, ADV NEURAL INFORMATI, V12; Carbonetto P., 2003, P 9 INT C ART INT ST; Corduneanu A., 2001, P 8 INT C ART INT ST, P27; Dy JG, 2004, J MACH LEARN RES, V5, P845; Friedman JH, 2004, J R STAT SOC B, V66, P815, DOI 10.1111/j.1467-9868.2004.02059.x; Hoff PD, 2006, BAYESIAN ANAL, V1, P321, DOI 10.1214/06-BA111; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; Liu JS, 2003, BAYESIAN STATISTICS 7, P249; MCLACHLAN BG, 2000, FINITE MIXTURE MODEL; Newman C. B. D., 1998, UCI REPOSITORY MACHI	12	136	141	2	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					1013	U1		10.1109/TPAMI.2006.111	http://dx.doi.org/10.1109/TPAMI.2006.111			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724595	Green Submitted			2022-12-18	WOS:000236734400015
J	Kim, JS; Gurdjos, P; Kweon, IS				Kim, JS; Gurdjos, P; Kweon, IS			Geometric and algebraic constraints of projected concentric circles and their applications to camera calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						imaging geometry; concentric circles; projective plane; circular points; camera calibration	RECONSTRUCTION	We investigate the projective properties of the feature consisting of two concentric circles. We demonstrate there exist geometric and algebraic constraints on its projection. We show how these constraints greatly simplify the recoveries of the affine and Euclidean structures of a 3D plane. As an application, we assess the performances of two camera calibration algorithms.	Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea; Univ Toulouse 3, Inst Rech Informat Toulouse, INPT, F-31062 Toulouse, France	Korea Advanced Institute of Science & Technology (KAIST); Universite de Toulouse; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite Toulouse III - Paul Sabatier; Institut National Polytechnique de Toulouse; Universite Toulouse 1 Capitole; Universite de Toulouse - Jean Jaures; Centre National de la Recherche Scientifique (CNRS)	Kim, JS (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea.	jskim@rcv.kaist.ac.kr; Pierre.Gurdjos@irit.fr; iskweon@kaist.ac.kr	Kweon, In So/C-2023-2011					Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; CHEN Q, 2004, P EUR C COMP VIS, V3, P521; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; FREMONT V, 2002, P INT C ART REAL TEL, P93; Golub G. H., 1996, MATRIX COMPUTATION; GURDJOS P, 2002, P EUR C COMP VIS, V4, P252; Hartley R., 2003, MULTIPLE VIEW GEOMET; Heikkila J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788; Hu R, 2001, IEEE INT CONF ROBOT, P2191, DOI 10.1109/ROBOT.2001.932948; Jiang G, 2004, IEEE T PATTERN ANAL, V26, P721, DOI 10.1109/TPAMI.2004.4; KANATANI K, 1993, CVGIP-IMAG UNDERSTAN, V58, P286, DOI 10.1006/ciun.1993.1043; KIM JS, 2002, P AS C COMP VIS, V2, P515; MA SD, 1993, INT J COMPUT VISION, V10, P7; Meng XQ, 2003, PATTERN RECOGN, V36, P1155, DOI 10.1016/S0031-3203(02)00225-X; Quan L, 1996, IEEE T PATTERN ANAL, V18, P151, DOI 10.1109/34.481540; Semple J. G, 1952, OXFORD CLASSIC SERIE; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Tarel J.-P., 1995, Traitement du Signal, V12, P177; Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Wu Y. H., 2004, P EUR C COMP VIS, V1, P190, DOI [10.1007/978-3-540-24670-1_15, DOI 10.1007/978-3-540-24670-1_15]; Yang CJ, 2000, INT C PATT RECOG, P555, DOI 10.1109/ICPR.2000.905398; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	25	136	158	4	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					637	642		10.1109/TPAMI.2005.80	http://dx.doi.org/10.1109/TPAMI.2005.80			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794168				2022-12-18	WOS:000226845700014
J	Elgammal, A; Duraiswami, R; Davis, LS				Elgammal, A; Duraiswami, R; Davis, LS			Efficient kernel density estimation using the fast gauss transform with applications to color modeling and tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical methods; kernel density estimation; fast Gauss transform; color modeling; tracking		Many vision algorithms depend on the estimation of a probability density function from observations. Kernel density estimation techniques are quite general and powerful methods for this problem, but have a significant disadvantage in that they are computationally intensive. In this paper, we explore the use of kernel density estimation with the fast Gauss transform (FGT) for problems in vision. The FGT allows the summation of a mixture of M Gaussians at N evaluation points in O(M + N) time, as opposed to O(M N) time for a naive evaluation and can be used to considerably speed up kernel density estimation. We present applications of the technique to problems from image segmentation and tracking and show that the algorithm allows application of advanced statistical techniques to solve practical vision problems in real-time with today's computers.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; Univ Maryland, Comp Vis Lab, College Pk, MD 20742 USA	Rutgers State University New Brunswick; University System of Maryland; University of Maryland College Park	Elgammal, A (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.	elgammal@cs.rutgers.edu; ramani@umiacs.und.edu; lsd@cs.umd.edu	Duraiswami, Ramani/J-6070-2012	Duraiswami, Ramani/0000-0002-5596-8460				AJA Y, 1998, P 5 EUR C COMP VIS; Birchfield S., 1998, P IEEE C COMP VIS PA; CHENG Y, 1985, IEEE T PATTERN ANAL, V7, P592, DOI 10.1109/TPAMI.1985.4767706; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; DUA RO, 2000, PATTERN CLASSIFICATI; ELGAMMAL A, 2001, P IEEE 2 INT WORKSH; ELGAMMAL A, 2001, P IEEE C COMP VIS PA; ELGAMMAL A, 2001, P IEEE 8 INT C COMP; Fieguth P., 1997, P IEEE C COMP VIS PA; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; Greengard L., 1998, P INT C MATH, V3, P575; Jones Michael J., 1999, P IEEE C COMP VIS PA; Lambert CG, 1999, ALGORITHMICA, V25, P37, DOI 10.1007/PL00009282; MARTIN J, 1998, P IEEE ITN C AUT FAC; McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8; McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; STRAIN J, 1991, SIAM J SCI STAT COMP, V12, P1131, DOI 10.1137/0912059; WERN CR, 1997, IEEE T PATTERN ANAL, V19	22	136	155	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1499	1504		10.1109/TPAMI.2003.1240123	http://dx.doi.org/10.1109/TPAMI.2003.1240123			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG		Green Submitted			2022-12-18	WOS:000186006800014
J	Haussecker, HW; Fleet, DJ				Haussecker, HW; Fleet, DJ			Computing optical flow with physical models of brightness variation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; physics-based brightness variation; total least squares		Although most optical flow techniques presume brightness constancy, it is well-known that this constraint is often violated, producing poor estimates of image motion. This paper describes a generalized formulation of optical flow estimation based on models of brightness variations that are caused by time-dependent physical processes. These include changing surface orientation with respect to a directional illuminant, motion of the illuminant, and physical models of heat transport in infrared images. With these models, we simultaneously estimate the 2D image motion and the relevant physical parameters of the brightness change model. The estimation problem is formulated using total least squares (TLS), with confidence bounds on the parameters. Experiments in four domains, with both synthetic and natural inputs, show how this formulation produces superior estimates of the 2D image motion.	Xerox Corp, Palo Alto Res Ctr, Palo Alto, CA 94304 USA	Xerox	Haussecker, HW (corresponding author), Xerox Corp, Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	hhaussec@parc.xerox.com; fleet@parc.xerox.com		/0000-0003-0734-7114				ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, P EUR C COMP VIS, P237; Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705; Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825; CORNELIUS N, 1983, ACM WORKSH MOT TOR, P50; DUC B, 1997, THESIS ECOLE POLYTEC; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FLEET DJ, 1995, IEEE T PATTERN ANAL, V17, P61, DOI 10.1109/34.368151; FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844; FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X; Fleet DJ, 2000, INT J COMPUT VISION, V36, P171, DOI 10.1023/A:1008156202475; Florack L, 1998, INT J COMPUT VISION, V27, P263, DOI 10.1023/A:1007922215235; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HAUSSECKER H, 1999, HDB COMPUTER VISION, P309; HAUSSECKER HW, 2000, P INT S GAS TRANSF W; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JAHNE B, 1998, P ECCV, V2, P322; Lucas Bruce D, 1981, P 7 INT JOINT C ART, DOI DOI 10.1042/CS0730285; MACLEAN WJ, 1999, P 7 INT C COMP VIS C, V2, P753; Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727; Michel J, 1997, IEEE T PATTERN ANAL, V19, P41, DOI 10.1109/34.566809; MUHLICH M, 1998, P 5 EUR C COMP VIS, V2, P305; MUHLICH M, 2000, CONSIDERABLE IMPROVE; MUKAWA N, 1990, P IEEE INT C COMP VI, P207; MURRAY DW, 1990, EXPT MACHINE INTERPR; Nagel H-H, 1990, P 1 EUR C COMP VIS, P139; NAGEL HH, 1989, IEEE T PATTERN ANAL, V11, P13, DOI 10.1109/34.23110; NAGEL HH, 1995, INT J COMPUT VISION, V15, P271, DOI 10.1007/BF01451744; Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; Nestares O, 2000, PROC CVPR IEEE, P523, DOI 10.1109/CVPR.2000.855864; Ohta N, 1996, IEICE T INF SYST, VE79D, P951; SCHARR H, 1997, MUSTERERKENNUNG 1997, P367; Stewart GW, 1997, SIAM PROC S, P3; Van Huffel S., 1991, TOTAL LEAST SQUARES; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WANG S, 1992, P SPIE SIGN DAT PROC, P42; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; Wildes RP, 2000, COMPUT VIS IMAGE UND, V80, P246, DOI 10.1006/cviu.2000.0874	41	136	140	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					661	673		10.1109/34.927465	http://dx.doi.org/10.1109/34.927465			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC		Green Submitted			2022-12-18	WOS:000169037600009
J	Azencott, R; Wang, JP; Younes, L				Azencott, R; Wang, JP; Younes, L			Texture classification using windowed Fourier filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture attributes and classification; windowed Fourier filters; Gabor filters; Gaussian random fields; spectral density; Kullback distance; distance between textures; segmentation of textured images	RANDOM FIELD MODELS; FEATURE-EXTRACTION; IMAGES; SEGMENTATION; COMPRESSION	We define a distance between textures for texture classification from texture features based on windowed Fourier filters. The definition of the distance relies on an interpretation of our texture attributes in terms of spectral density when the texture can be considered as a Gaussian random field. The distance between textures is then defined as a symmetrized Kullback distance which is a simple function of the attributes and does not require any normalization. An experimental analysis using Gabor filters, and in particular a comparison to quadratic distances, shows the efficiency and robustness of the method.			Azencott, R (corresponding author), ECOLE NORMALE CACHAN,61 AV PRESIDENT WILSON,F-94235 CACHAN,FRANCE.		Younes, E. Laurent/A-3349-2010	Younes, Laurent/0000-0003-2017-9565				Azencott R., 1986, SERIES IRREGULAR OBS, V1st; AZENCOTT R, 1988, P INT C IND APPL MAT; BESAG J, 1986, J R STAT SOC B, V48, P259; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V15, P298, DOI 10.1109/TSMC.1985.6313361; CHEN CH, 1982, 6TH P INT C PATT REC, P1074; CHEN JL, 1993, P INT C AC SPEECH SI, pV21; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; FAUGERAS OD, 1980, IEEE T PATTERN ANAL, V2, P323, DOI 10.1109/TPAMI.1980.4767031; GAGALOWICZ A, 1988, P 9 INT C PATT REC R; Galloway MM., 1975, COMPUT GRAPHICS IMAG, V4, DOI DOI 10.1016/S0146-664X(75)80008-6; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; Rosenblatt M., 1985, STATIONARY SEQUENCES; Royden H., 1963, REAL ANAL; WANG JP, 1994, THESIS PARIS SUD U; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777	27	136	140	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					148	153		10.1109/34.574796	http://dx.doi.org/10.1109/34.574796			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800008
J	MOKHTARIAN, F				MOKHTARIAN, F			SILHOUETTE-BASED ISOLATED OBJECT RECOGNITION THROUGH CURVATURE SCALE-SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						OBJECT RECOGNITION SYSTEM; LIGHT-BOX SETUP; BOUNDARY CONTOURS; CURVATURE SCALE SPACE REPRESENTATION; MAXIMA OF CURVATURE ZERO-CROSSING CONTOURS; COARSE-TO-FINE MATCHING STRATEGY; TRANSFORMATION PARAMETER OPTIMIZATION	FOURIER DESCRIPTORS; PLANAR CURVES	A complete, fast and practical isolated object recognition system has been developed which is very robust with respect to scale, position and orientation changes of the objects as web as noise and Local deformations of shape (due to perspective projection, segmentation errors and nonrigid material used in some objects). The system has been tested on a wide variety of three-dimensional objects with different shapes and material and surface properties. A light-box setup is used to obtain silhouette images which are segmented to obtain the physical boundaries of the objects which are classified as either convex or concave. Convex curves are recognized using their four high-scale curvature extrema points. Curvature Scale Space (CSS) Representations are computed for concave curves. The CSS representation is a multi-scale organization of the natural, invariant features of a curve (curvature zero-crossings or extrema) and useful for very reliable recognition of the correct model since it places no constraints on the shape of objects. A three-stage, coarse-to-fine matching algorithm prunes the search space in stage one by applying the CSS aspect ratio test. The maxima of contours in CSS representations of the surviving models are used for fast CSS matching in stage two. Finally, stage three verifies the best match and resolves any ambiguities by determining the distance between the image and model curves. Transformation parameter optimization is then used to find the best fit of the input object to the correct model.			MOKHTARIAN, F (corresponding author), UNIV SURREY,DEPT ELECT & ELECTR ENGN,GUILDFORD GU2 5XH,SURREY,ENGLAND.							HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012; HUM HU, 1961, P IRE, V49; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P269, DOI 10.1109/CVPR.1989.37860; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; MOKHTARIAN F, 1993, P 4 INT C COMP VIS, P269; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; STANSFIELD JL, 1980, MIT601 AI LAB AI MEM; TEH CH, 1980, IEEE T PATTERN ANAL, V10, P496; WALLACE TP, 1980, IEEE T PATTERN ANAL, V2, P583, DOI 10.1109/TPAMI.1980.6447707; WINSTON PH, 1979, ARTIFICIAL INTELLIGE; WITKIN AP, 1983, P IJCAI KARLSRUHE	14	136	148	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					539	544		10.1109/34.391387	http://dx.doi.org/10.1109/34.391387			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394		Green Submitted			2022-12-18	WOS:A1995QW39400011
J	MARDIA, KV; HAINSWORTH, TJ				MARDIA, KV; HAINSWORTH, TJ			A SPATIAL THRESHOLDING METHOD FOR IMAGE SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MARDIA, KV (corresponding author), UNIV LEEDS,DEPT STAT,LEEDS LS2 9JT,W YORKSHIRE,ENGLAND.							BESAG J, 1986, J R STAT SOC B, V48, P259; David M., 1977, GEOSTATISTICAL ORE R; Duda R.O., 1973, J ROYAL STAT SOC SER; DUNN SM, 1984, IEEE T PATTERN ANAL, V6, P742, DOI 10.1109/TPAMI.1984.4767597; Dunn S, 1983, PATTERN RECOGN LETT, V1, P169, DOI 10.1016/0167-8655(83)90058-2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443; Kittler J., 1984, Image and Vision Computing, V2, P13, DOI 10.1016/0262-8856(84)90040-4; LLOYD DE, 1985, RAE IDN AW126 REP; MARDIA KV, 1984, COMMUN STAT-THEOR M, V13, P2181, DOI 10.1080/03610928408828822; Mardia KV, 1979, MULTIVARIATE ANAL; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; SWITZER P, 1980, J INT ASS MATH GEOL, V12, P367, DOI 10.1007/BF01029421; SWITZER P, 1983, B INT STAT I, V50, P962; VELASCO FRD, 1980, IEEE T SYST MAN CYB, V10, P771, DOI DOI 10.1109/TSMC.1980.4308400	18	136	146	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					919	927		10.1109/34.9113	http://dx.doi.org/10.1109/34.9113			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100013
J	MCKEOWN, DM; HARVEY, WA; MCDERMOTT, J				MCKEOWN, DM; HARVEY, WA; MCDERMOTT, J			RULE-BASED INTERPRETATION OF AERIAL IMAGERY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MCKEOWN, DM (corresponding author), CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213, USA.							Binford T. O., 1982, INT J ROBOT RES, V1, P18; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; Brownston L., 1985, PROGRAMMING EXPERT S; BULLOCK BL, 1982, P DARPA IMAGE UNDERS, P29; FISCHLER MA, 1981, COMPUTER GRAPHICS IM, V14, P201; Forgy C.L., 1981, CMUCS81135; Froesch Charles, 1946, AIRPORT PLANNING; HANSON AR, 1978, VISIONS COMPUTER SYS, P303; HORONJEFF R, 1983, PLANNING DESIGN AIRP; HWANG SSV, 1984, THESIS U MARYLAND CO; MATSUYAMA T, 1980, THESIS; McKeown D. M.  Jr., 1984, New Applications of Data Bases. Based on Proceedings of a Workshop, P19; MCKEOWN DM, 1983, JUN P DARPA IM UND W, P105; MCKEOWN DM, 1985, UNPUB IMAGE ANAL USI; MCKEOWN DM, 1985, JUN P IEEE COMP VIS; MCKEOWN DM, 1984, 2ND P IEEE COMP SOC; MCVAY CA, 1985, UNPUB STEREO VERIFIC; NAGAO M, 1979, 6TH P INT JOINT C AR, P610; Nagao M., 1980, STRUCTURAL ANAL COMP; OHTA Y, 1980, THESIS KYOTO U KYOTO; SELFRIDGE PG, 1982, 103 U ROCH TECH REP; TENNENBAUM JM, 1977, ARTIF INTELL, V8, P241	22	136	208	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					570	585		10.1109/TPAMI.1985.4767704	http://dx.doi.org/10.1109/TPAMI.1985.4767704			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AQH94	21869294				2022-12-18	WOS:A1985AQH9400008
J	Akhter, I; Sheikh, Y; Khan, S; Kanade, T				Akhter, Ijaz; Sheikh, Yaser; Khan, Sohaib; Kanade, Takeo			Trajectory Space: A Dual Representation for Nonrigid Structure from Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonrigid structure from motion; 3D reconstruction; motion and tracking	SHAPE; SCENE	Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes. These bases are object dependent and therefore have to be estimated anew for each video sequence. In contrast, we propose a dual approach to describe the evolving 3D structure in trajectory space by a linear combination of basis trajectories. We describe the dual relationship between the two approaches, showing that they both have equal power for representing 3D structure. We further show that the temporal smoothness in 3D trajectories alone can be used for recovering nonrigid structure from a moving camera. The principal advantage of expressing deforming 3D structure in trajectory space is that we can define an object independent basis. This results in a significant reduction in unknowns and corresponding stability in estimation. We propose the use of the Discrete Cosine Transform (DCT) as the object independent basis and empirically demonstrate that it approaches Principal Component Analysis (PCA) for natural motions. We report the performance of the proposed method, quantitatively using motion capture data, and qualitatively on several video sequences exhibiting nonrigid motions, including piecewise rigid motion, partially nonrigid motion (such as a facial expressions), and highly nonrigid motion (such as a person walking or dancing).	[Akhter, Ijaz; Khan, Sohaib] Lahore Univ Management Sci, Dept Comp Sci, LUMS Sch Sci & Engn, DHA, Lahore Cantt 54792, Pakistan; [Sheikh, Yaser; Kanade, Takeo] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Lahore University of Management Sciences; Carnegie Mellon University	Akhter, I (corresponding author), Lahore Univ Management Sci, Dept Comp Sci, LUMS Sch Sci & Engn, DHA, Lahore Cantt 54792, Pakistan.	akhter@lums.edu.pk; yaser@cs.cmu.edu; sohaib@lums.edu.pk; tk@cs.cmu.edu			Higher Education Commission of Pakistan	Higher Education Commission of Pakistan(Higher Education Commission of Pakistan)	This research was partly supported by a grant from the Higher Education Commission of Pakistan. The authors acknowledge Fernando De La Torre for useful discussions. The authors also thank Jing Xiao, Lourdes Agapito, Iain Matthews, and Lorenzo Torresani for making their code or data available. The motion capture data used in this project were obtained from http://mocap.cs.cmu.edu. Yaser Sheikh was supported by US National Science Foundation grant IIS-0916272.	AKHTER I, 2009, P IEEE CS C COMP VIS; AKHTER I, 2008, P NEUR INF PROC SYST; BARTOLI A, 2008, P IEEE CS C COMP VIS; BRAND M, 2005, P IEEE CS C COMP VIS, V2; BRAND M, 2001, P IEEE CS C COMP VIS, V2; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; BUE AD, 2006, P IEEE CS C COMP VIS; BUE AD, 2008, P IEEE CS C COMP VIS; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; CHEN S, 1985, P IEEE COMPUTER SOC, P105; CHEN SS, 1986, COMPUT VISION GRAPH, V36, P175, DOI 10.1016/0734-189X(86)90075-7; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Del Bue A, 2007, IMAGE VISION COMPUT, V25, P297, DOI 10.1016/j.imavis.2005.10.004; Golub G., 1965, J SOC IND APPL MATH, V2, P205, DOI [10.1137/0702016, DOI 10.1137/0702016]; Gruber A, 2004, PROC CVPR IEEE, P707; Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707; Han M, 2004, INT J COMPUT VISION, V59, P285, DOI 10.1023/B:VISI.0000025801.70038.c7; Hartley R., 2004, ROBOTICA; HARTLEY R, 2008, P 10 EUR C COMP VIS; Huang J, 2000, IEEE T SPEECH AUDI P, V8, P747, DOI 10.1109/89.876314; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Kontsevich L. L., 1987, Optoelectronics, Instrumentation and Data Processing, P76; Li Y, 2002, ACM T GRAPHIC, V21, P465; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Ma Y., 2003, INVITATION 3 D VISIO; Olsen SI, 2008, J MATH IMAGING VIS, V31, P233, DOI 10.1007/s10851-007-0060-3; PALADINI M, 2009, P IEEE CS C COMP VIS; Park LAF, 2005, IEEE T PATTERN ANAL, V27, P130, DOI 10.1109/TPAMI.2005.2; RABAUD V, 2008, P IEEE CS C COMP VIS; RABAUD V, 2009, P IEEE CS C COMP VIS; SHASHUA A, 1997, P INT WORKSH ALG FRA; SHULMAN D, 1988, PROC R SOC SER B-BIO, V233, P217, DOI 10.1098/rspb.1988.0020; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2001, PROC CVPR IEEE, P493; TORRESANI L, 2005, P 19 ANN C NEUR INF; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; TRESADERN P, 2005, P IEEE CS C COMP VIS; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; Vidal R, 2004, PROC CVPR IEEE, P310; Vidal R., 2006, P EUR C COMP VIS; WHITE R, 2007, P ACM SIGGRAPH; Wolf L, 2002, INT J COMPUT VISION, V48, P53, DOI 10.1023/A:1014855311993; Xiao J, 2005, IEEE I CONF COMP VIS, P1075; Xiao J, 2004, PROC CVPR IEEE, P668; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; YAN J, 2005, P IEEE C COMP VIS PA, V2, P815; YAN J, 2006, P IEEE CS C COMP VIS, V2; ZELINSKI R, 1977, IEEE T ACOUST SPEECH, V25, P299, DOI 10.1109/TASSP.1977.1162974; ZELNIKMANOR L, 2004, P 8 EUR C COMP VIS; 2003, CARNEGIE MELLON MOCA	53	135	142	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1442	1456		10.1109/TPAMI.2010.201	http://dx.doi.org/10.1109/TPAMI.2010.201			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21079275				2022-12-18	WOS:000290574000012
J	Ortega-Garcia, J; Fierrez, J; Alonso-Fernandez, F; Galbally, J; Freire, MR; Gonzalez-Rodriguez, J; Garcia-Mateo, C; Alba-Castro, JL; Gonzalez-Agulla, E; Otero-Muras, E; Garcia-Salicetti, S; Allano, L; Ly-Van, B; Dorizzi, B; Kittler, J; Bourlai, T; Poh, N; Deravi, F; Ng, MWR; Fairhurst, M; Hennebert, J; Humm, A; Tistarelli, M; Brodo, L; Richiardi, J; Drygajlo, A; Ganster, H; Sukno, FM; Pavani, SK; Frangi, A; Akarun, L; Savran, A				Ortega-Garcia, Javier; Fierrez, Julian; Alonso-Fernandez, Fernando; Galbally, Javier; Freire, Manuel R.; Gonzalez-Rodriguez, Joaquin; Garcia-Mateo, Carmen; Alba-Castro, Jose-Luis; Gonzalez-Agulla, Elisardo; Otero-Muras, Enrique; Garcia-Salicetti, Sonia; Allano, Lorene; Ly-Van, Bao; Dorizzi, Bernadette; Kittler, Josef; Bourlai, Thirimachos; Poh, Norman; Deravi, Farzin; Ng, Ming W. R.; Fairhurst, Michael; Hennebert, Jean; Humm, Andreas; Tistarelli, Massimo; Brodo, Linda; Richiardi, Jonas; Drygajlo, Andrzej; Ganster, Harald; Sukno, Federico M.; Pavani, Sri-Kaushik; Frangi, Alejandro; Akarun, Lale; Savran, Arman			The Multiscenario Multienvironment BioSecure Multimodal Database (BMDB)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal; biometrics; database; evaluation; performance; benchmark; face; voice; speaker; signature; fingerprint; hand; iris	ONLINE SIGNATURE VERIFICATION; BASE-LINE CORPUS	A new multimodal biometric database designed and acquired within the framework of the European BioSecure Network of Excellence is presented. It is comprised of more than 600 individuals acquired simultaneously in three scenarios: 1) over the Internet, 2) in an office environment with desktop PC, and 3) in indoor/outdoor environments with mobile portable hardware. The three scenarios include a common part of audio/video data. Also, signature and fingerprint data have been acquired both with desktop PC and mobile portable hardware. Additionally, hand and iris data were acquired in the second scenario using desktop PC. Acquisition has been conducted by 11 European institutions. Additional features of the BioSecure Multimodal Database (BMDB) are: two acquisition sessions, several sensors in certain modalities, balanced gender and age distributions, multimodal realistic scenarios with simple and quick tasks per modality, cross-European diversity, availability of demographic data, and compatibility with other multimodal databases. The novel acquisition conditions of the BMDB allow us to perform new challenging research and evaluation of either monomodal or multimodal biometric systems, as in the recent BioSecure Multimodal Evaluation campaign. A description of this campaign including baseline results of individual modalities from the new database is also given. The database is expected to be available for research purposes through the BioSecure Association during 2008.	[Ortega-Garcia, Javier; Fierrez, Julian] Univ Autonoma Madrid, Escuela Politecn Super, ATVS Biometr Recognit Grp, E-28049 Madrid, Spain; [Gonzalez-Rodriguez, Joaquin] Univ Autonoma Madrid, Dept Comp Sci, E-28049 Madrid, Spain; [Garcia-Salicetti, Sonia; Dorizzi, Bernadette] TELECOM & Management SudParis Inst TELECOM, Multimedia Res Team, Paris, France; [Bourlai, Thirimachos] Univ Houston, Houston, TX 77004 USA; [Kittler, Josef] Univ Surrey, Fac Engn & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 5XH, Surrey, England; [Deravi, Farzin; Fairhurst, Michael] Univ Kent, Dept Elect, Canterbury, Kent, England; [Ng, Ming W. R.] Loughborough Univ Technol, Loughborough LE11 3TU, Leics, England; Univ Kent, Dept Elect, Canterbury, Kent, England; [Hennebert, Jean] Univ Appl Sci Western Switzerland, Inst Business Informat Syst, Sierre, Switzerland; [Humm, Andreas] Univ Fribourg, Dept Comp Sci, CH-1700 Fribourg, Switzerland; [Brodo, Linda] Univ Sassari, Fac Foreign Languages & Literatures, I-07100 Sassari, Italy; [Richiardi, Jonas] Swiss Fed Inst Technol, Signal Proc Inst, CH-1015 Lausanne, Switzerland; [Drygajlo, Andrzej] Swiss Fed Inst Technol, Speech Proc & Biometr Grp, CH-1015 Lausanne, Switzerland; [Ganster, Harald] Joanneum Res, Inst Digital Image Proc, Graz, Austria; [Frangi, Alejandro] Pompeu Fabra Univ, Dept Informat & Commun Technol, Barcelona, Spain; [Akarun, Lale] Bogazici Univ, Dept Comp Engn, TR-80815 Bebek, Turkey; [Savran, Arman] Bogazici Univ, Dept Elect & Elect Engn, TR-80815 Bebek, Turkey	Autonomous University of Madrid; Autonomous University of Madrid; IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; University of Houston System; University of Houston; University of Surrey; University of Kent; Loughborough University; University of Kent; University of Applied Sciences & Arts Western Switzerland; University of Fribourg; University of Sassari; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Pompeu Fabra University; Bogazici University; Bogazici University	Fierrez, J (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, ATVS Biometr Recognit Grp, Avda Francisco Tomas y Valiente 11,Campus Cantobl, E-28049 Madrid, Spain.	julian.fierrez@uam.es	Allano, Lorene/D-9208-2012; Garcia-Mateo, Carmen/I-4144-2015; Frangi, Alejandro F/C-6500-2008; Savran, Arman/AAS-6577-2020; Gonzalez-Rodriguez, Joaquin/B-2629-2009; Poh, Norman/Y-8261-2019; Akarun, Lale/AAR-7734-2020; Ortega-Garcia, Javier/J-7065-2012; Richiardi, Jonas/G-2989-2012; Deravi, Farzin/E-7190-2013; Sukno, Federico/AAM-4440-2021; Fierrez, Julian/A-1884-2008; Tistarelli, Massimo/AAH-9437-2021; Castro, José Luis Alba/D-3949-2009; Alonso-Fernandez, Fernando/AAG-3239-2021	Garcia-Mateo, Carmen/0000-0001-6856-939X; Frangi, Alejandro F/0000-0002-2675-528X; Savran, Arman/0000-0001-5142-6384; Gonzalez-Rodriguez, Joaquin/0000-0003-0910-2575; Ortega-Garcia, Javier/0000-0003-0557-1948; Deravi, Farzin/0000-0003-0885-437X; Sukno, Federico/0000-0002-2029-1576; Fierrez, Julian/0000-0002-6343-5656; Tistarelli, Massimo/0000-0002-3406-3048; Castro, José Luis Alba/0000-0001-6319-5915; Alonso-Fernandez, Fernando/0000-0002-1400-346X; Hennebert, Jean/0000-0002-5616-6830; Richiardi, Jonas/0000-0002-6975-5634; Bourlai, Thirimachos/0000-0001-8751-0836; Akarun, Lale/0000-0002-8813-8084; GALBALLY, JAVIER/0000-0002-2009-0256; GONZALEZ AGULLA, ELISARDO/0000-0002-2925-7892	European Network of Excellence (NoE) BioSecure-Biometrics for Secure Authentication; Spanish Ministry of Science and Technology [TEC2006-13141-C03-03, TEC2006-03617/TCM, TIC2002-04495-C02, TEC200-507212]; Italian Ministry of Research; Marie Curie Outgoing International Fellowship; Comunidad de Madrid; Spanish MEC; Swiss National Science Foundation [PA0022_121477]; EU [IST-214324]; Swiss National Science Foundation	European Network of Excellence (NoE) BioSecure-Biometrics for Secure Authentication; Spanish Ministry of Science and Technology(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); Italian Ministry of Research(Ministry of Education, Universities and Research (MIUR)); Marie Curie Outgoing International Fellowship(European Commission); Comunidad de Madrid(Comunidad de Madrid); Spanish MEC(Spanish Government); Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); EU(European Commission); Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work has been supported by the European Network of Excellence (NoE) BioSecure-Biometrics for Secure Authentication-and by the National Projects of the Spanish Ministry of Science and Technology (TEC2006-13141-C03-03, TEC2006-03617/TCM, TIC2002-04495-C02, and TEC200-507212) and the Italian Ministry of Research. The postdoctoral research of author J. Fierrez is supported by a Marie Curie Outgoing International Fellowship. The authors F. Alonso-Fernandez and M. R. Freire are supported by FPI Fellowships from Comunidad de Madrid. The author J. Galbally is supported by an FPU Fellowship from Spanish MEC. Authors Josef Kittler and Norman Poh are supported by the Advanced Researcher Fellowship PA0022_121477 of the Swiss National Science Foundation and by the EU-funded Mobio project grant IST-214324. The author J. Richiardi is supported by the Swiss National Science Foundation. The authors also thank the support and assistance of (in alphabetical order): Dr. Manuele Bicego (UNISS), Prof. Enrico Grosso (UNISS), Dr. Andrea Lagorio (UNISS), Aurelien Mayoue (TELECOM & Management SudParis), Dijana Petrovska (TELECOM & Management SudParis), Ms. Ajita Rattani (UNISS), Florian Verdet (UNIFRI). The authors would also like to thank the anonymous donors who have contributed to this database.	Alonso-Fernandez F, 2007, IEEE T INF FOREN SEC, V2, P734, DOI 10.1109/TIFS.2007.908228; ALONSOFERNANDEZ F, 2005, P INT WORKSH BIOM RE, P180; ALONSOFERNANDEZ F, 2006, P IEEE INT C CONTR A, P422; Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; *BIOSEC, 2004, IST2002001766 FP6 IP; *BIOSECURE, 2004, IST2002507634 FP6 NO; Chen Y, 2005, LECT NOTES COMPUT SC, V3546, P160; CHIBELUSHI C, 1999, P IEE C INT AUD VIS; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Dessimoz D, 2007, FORENSIC SCI INT, V167, P154, DOI 10.1016/j.forsciint.2006.06.037; DUMAS B, 2005, P COST 275 WORKSH BI; Faundez-Zanuy M, 2006, IEEE AERO EL SYS MAG, V21, P29, DOI 10.1109/MAES.2006.1703234; FIERREZ J, 2009, PATTERN ANAL APPL; Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012; Fierrez J, 2007, PATTERN RECOGN, V40, P1389, DOI 10.1016/j.patcog.2006.10.014; Fierrez-Aguilar J, 2005, PATTERN RECOGN, V38, P777, DOI 10.1016/j.patcog.2004.11.012; FLYNN P, 2008, HDB BIOMETRICS, P529; GALBALLYHERRERO J, 2006, P IEEE INT CARN C SE; Garcia-Salicetti S, 2003, LECT NOTES COMPUT SC, V2688, P845; Garcia-Salicetti S, 2007, ANN TELECOMMUN, V62, P36; GONZALEZRODRIGU.J, 2008, HDB BIOMETRICS, P151; GROTHER P, 2005, 7296 NISTIR; Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019; Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; MAITRE G., 1999, P 2 INT C AUD VID BA; Mansfield, 2002, BEST PRACTICES TESTI; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; MASEK L, 2003, THESIS U W AUSTR; MENG H, 2006, P WORKSH MULT US AUT; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; PETROVSKADELACR.D, 2008, GUIDE BIOMETRIC REFE; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ross A, 2008, IEEE T KNOWL DATA EN, V20, P1097, DOI 10.1109/TKDE.2007.190696; SCHIEL F, 2002, P INT C LANG RES EV; Sickler NC, 2005, CAR C SECUR, P68, DOI 10.1109/CCST.2005.1594817; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Uludag U, 2004, PATTERN RECOGN, V37, P1533, DOI 10.1016/j.patcog.2003.11.012; Van BL, 2007, IEEE T SYST MAN CY B, V37, P1237, DOI 10.1109/TSMCB.2007.895323; WATSON C, 2004, USERS GUIDE FINGERPR; WAYMAN J, 2006, P IEEE INT C AC PSEE, P14; 2006, NIST SRE NIST SPEAKE; 2007, BMEC BIOSECURE MULTI; 2006, FRVT FACE RECOGNITIO; 2006, ICE IRIS CHALLENGE E; 2006, FVC2006 FINGERPRINT; 2009, SVC SIGNATURE VERIFI	48	135	135	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1097	1111		10.1109/TPAMI.2009.76	http://dx.doi.org/10.1109/TPAMI.2009.76			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431134	Green Submitted, Green Published			2022-12-18	WOS:000276671900011
J	Perronnin, F				Perronnin, Florent			Universal and adapted vocabularies for Generic Visual Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image categorization; bag-of-words; Gaussian mixture model; expectation-maximization; Bayesian adaptation		Generic Visual Categorization (GVC) is the pattern classification problem that consists in assigning labels to an image based on its semantic content. This is a challenging task as one has to deal with inherent object/scene variations, as well as changes in viewpoint, lighting, and occlusion. Several state-of-the-art GVC systems use a vocabulary of visual terms to characterize images with a histogram of visual word counts. We propose a novel practical approach to GVC based on a universal vocabulary, which describes the content of all the considered classes of images, and class vocabularies obtained through the adaptation of the universal vocabulary using class-specific data. The main novelty is that an image is characterized by a set of histograms-one per class-where each histogram describes whether the image content is best modeled by the universal vocabulary or the corresponding class vocabulary. This framework is applied to two types of local image features: low-level descriptors such as the popular SIFT and high-level histograms of word co-occurrences in a spatial neighborhood. It is shown experimentally on two challenging data sets (an in-house database of 19 categories and the PASCAL VOC 2006 data set) that the proposed approach exhibits state-of-the-art performance at a modest computational cost.	Xerox Res Ctr Europe, F-38240 Meylan, France	Xerox	Perronnin, F (corresponding author), Xerox Res Ctr Europe, 6 Chemin Maupertuis, F-38240 Meylan, France.	Florent.Perronnin@xrce.xerox.com						AGARWAL A, 2006, P 9 EUR C COMP VIS; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bilmes J.A., 1998, INT COMPUT SCI I, V4, P126; Bosch A., 2006, P 9 EUR C COMP VIS; CARBONETTO P, 2004, P 8 EUR C COMP VIS; Csurka G., 2004, P EUR C COMP VIS WOR; CSURKA G, 2005, P 13 INT C IM AN PRO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Everingham M., 2006, SEL P 1 PASCAL CHALL; FARQUHAR J, 2005, IMPROVING  BAG KEYPO; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Joachims T., 1999, ADV KERNEL METHODS S; JURIE F, 2005, P 10 IEEE INT SUPP V; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; LARLUS D, 2006, P 17 BRIT MACH VIS C; Leung T., 1999, P 7 IEEE INT C COMP; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maree R, 2005, PROC CVPR IEEE, P34; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; MONAY F, 2005, CONSTRUCTING VISUAL; MOOSMANN F, 2006, P EUR C COMP VIS WOR; NOVAK E, 2006, P 9 EUR C COMP VIS; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Salton G., 1983, INTRO MODERN INFORM; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sivic J., 2005, P 10 IEEE INT C COMP; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Winn J., 2005, P 10 IEEE INT C COMP; WOODLAND PC, 1999, P IEEE WORKSH AUT SP; Young S, 2002, HTK BOOK, V3; ZHANG J, 2005, LOCAL FEATURES KERNE; 2006, PASCAL VISUAL OBJECT	37	135	142	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1243	1256		10.1109/TPAMI.2007.70755	http://dx.doi.org/10.1109/TPAMI.2007.70755			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550906				2022-12-18	WOS:000256294100010
J	Qiu, HJ; Hancock, ER				Qiu, Huaijun John; Hancock, Edwin R.			Clustering and embedding using commute times	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						commute time; clustering; embedding; spectral graph theory; image segmentation; motion tracking	DIMENSIONALITY REDUCTION; MULTIBODY; FACTORIZATION; GRAPH	This paper exploits the properties of the commute time between nodes of a graph for the purposes of clustering and embedding and explores its applications to image segmentation and multibody motion tracking. Our starting point is the lazy random walk on the graph, which is determined by the heat kernel of the graph and can be computed from the spectrum of the graph Laplacian. We characterize the random walk using the commute time ( that is, the expected time taken for a random walk to travel between two nodes and return) and show how this quantity may be computed from the Laplacian spectrum using the discrete Green's function. Our motivation is that the commute time can be anticipated to be a more robust measure of the proximity of data than the raw proximity matrix. In this paper, we explore two applications of the commute time. The first is to develop a method for image segmentation using the eigenvector corresponding to the smallest eigenvalue of the commute time matrix. We show that our commute time segmentation method has the property of enhancing the intragroup coherence while weakening intergroup coherence and is superior to the normalized cut. The second application is to develop a robust multibody motion tracking method using an embedding based on the commute time. Our embedding procedure preserves commute time and is closely akin to kernel PCA, the Laplacian eigenmap, and the diffusion map. We illustrate the results on both synthetic image sequences and real-world video sequences and compare our results with several alternative methods.	Univ London, Queen Mary, Dept Comp Sci, Queen Mary Vis Lab, London E1 4NS, England; Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	University of London; Queen Mary University London; University of York - UK	Qiu, HJ (corresponding author), Univ London, Queen Mary, Dept Comp Sci, Queen Mary Vis Lab, London E1 4NS, England.	john@dcs.qmul.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin R/C-6071-2008; Hancock, Edwin/N-7548-2019	Hancock, Edwin R/0000-0003-4496-2028; Hancock, Edwin/0000-0003-4496-2028				Anandan P, 2002, INT J COMPUT VISION, V49, P101, DOI 10.1023/A:1020137420717; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Chung F, 2000, J COMB THEORY A, V91, P191, DOI 10.1006/jcta.2000.3094; Chung F., 1997, AM MATH SOC, V92; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Fan ZM, 2004, PROC CVPR IEEE, P661; Fan ZM, 2004, PROC CVPR IEEE, P776; FISCHER I, 2005, AMPLIFYING BLOCK MAT; FOUSS F, 2006, P 6 IEEE INT C DAT M; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Gruber A, 2004, PROC CVPR IEEE, P707; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; HE X, 1933, P NEUR INF PROC SYST, V24, P417; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Ichimura N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P600, DOI 10.1109/ICCV.1999.791279; Kanazawa Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCV.2001.937640; Kondor R.I., 2002, P 19 INT C MACH LEAR, V11; Kruskal JosephB., 1978, MULTIDIMENSIONAL SCA, DOI [10.4135/9781412985130, DOI 10.4135/9781412985130]; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Meila M, 2001, ADV NEUR IN, V13, P873; Nadler B., 2005, P NEUR INF PROC SYST; Ng A.Y., 2001, P NEUR INF PROC SYST; Park JH, 2004, LECT NOTES COMPUT SC, V2034, P390; Pavan M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P362; Pavan M, 2003, PROC CVPR IEEE, P145; PERONA P, 1998, P EUR C COMP VIS, P655; Qiu H., 2005, P 16 BRIT MACH VIS C, P929; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saerens M, 2004, LECT NOTES COMPUT SC, V3201, P371; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scott G.L., 1990, BMVC, P1; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SRAKAR S, 1996, P IEEE CS C COMP VIS, P478; Sugaya Y, 2004, IEICE T INF SYST, VE87D, P1935; Sugaya Y, 2003, IEICE T INF SYST, VE86D, P1095; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Wu Y, 2001, PROC CVPR IEEE, P252; ZASS R, 2005, P 10 IEEE INT C COMP; Zelnik-Manor L, 2003, PROC CVPR IEEE, P287	45	135	143	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1873	1890		10.1109/TPAMI.2007.1103	http://dx.doi.org/10.1109/TPAMI.2007.1103			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848771	Green Published			2022-12-18	WOS:000249343900001
J	DUBOIS, SR; GLANZ, FH				DUBOIS, SR; GLANZ, FH			AN AUTOREGRESSIVE MODEL APPROACH TO TWO-DIMENSIONAL SHAPE CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV NEW HAMPSHIRE,DEPT ELECT ENGN & COMP SCI,DURHAM,NH 03824	University System Of New Hampshire; University of New Hampshire	DUBOIS, SR (corresponding author), MIT,DEPT ELECT ENGN & COMP SCI,CAMBRIDGE,MA 02139, USA.		Rohlf, F J/A-8710-2008					Castleman KR., 1979, DIGITAL IMAGE PROCES; Devijver PA, 1982, PATTERN RECOGNITION; DUBOIS SR, THESIS U NEW HAMPSHI; Duda R.O., 1973, J ROYAL STAT SOC SER; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; FUKUNAGA K, 1972, INTRO STATISTICAL PA; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KELLEY RB, 1983, P IEEE, V71, P803, DOI 10.1109/PROC.1983.12680; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; RUMMEL P, 1984, PATTERN RECOGN, V17, P141, DOI 10.1016/0031-3203(84)90041-4; Sebestyen G., 1962, DECISION MAKING PROC, V227, P413; YACHIDA M, 1977, IEEE T COMPUT, V26, P882, DOI 10.1109/TC.1977.1674936; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; 1984, BUSINESS WEEK    JAN, P118	15	135	144	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					55	66		10.1109/TPAMI.1986.4767752	http://dx.doi.org/10.1109/TPAMI.1986.4767752			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869323				2022-12-18	WOS:A1986AWT8600007
J	PAL, SK; KING, RA				PAL, SK; KING, RA			ON EDGE-DETECTION OF X-RAY IMAGES USING FUZZY-SETS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									INDIAN STAT INST,ELECTR & COMMUN SCI UNIT,CALCUTTA 700035,W BENGAL,INDIA	Indian Statistical Institute; Indian Statistical Institute Kolkata	PAL, SK (corresponding author), UNIV LONDON IMPERIAL COLL SCI & TECHNOL,DEPT ELECT ENGN,LONDON SW7 2AZ,ENGLAND.							AGARWAL JK, 1977, COMPUTER METHODS IMA; ALLEN AD, 1974, IEEE T SYST MAN CYB, VSMC4, P66, DOI 10.1109/TSMC.1974.5408522; [Anonymous], 1975, FUZZY SETS THEIR APP, DOI DOI 10.1016/B978-0-12-775260-0.50021-9; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; NAKAGAWA Y, 1978, IEEE T SYST MAN CYB, V8, P632; PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494; PAL SK, 1981, ELECTRON LETT, V17, P302, DOI 10.1049/el:19810212; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; PAL SK, 1978, THESIS CALCUTTA U CA; PAL SK, 1982, THESIS U LONDON LOND; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Tanner JM, 1975, ASSESSMENT SKELETAL; Wang P, 1980, FUZZY SETS THEORY AP; 1980, IEE P COMPUTER DIGIT, V127, P5; 1980, IEEE T PATTERN ANAL, V2, P5	15	135	215	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					69	77		10.1109/TPAMI.1983.4767347	http://dx.doi.org/10.1109/TPAMI.1983.4767347			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869086				2022-12-18	WOS:A1983PZ84400010
J	Liao, SC; Jain, AK; Li, SZ				Liao, Shengcai; Jain, Anil K.; Li, Stan Z.			Partial Face Recognition: Alignment-Free Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Partial face recognition; alignment free; keypoint descriptor; sparse representation; open-set identification	ROBUST; SCALE	Numerous methods have been developed for holistic face recognition with impressive performance. However, few studies have tackled how to recognize an arbitrary patch of a face image. Partial faces frequently appear in unconstrained scenarios, with images captured by surveillance cameras or handheld devices (e.g., mobile phones) in particular. In this paper, we propose a general partial face recognition approach that does not require face alignment by eye coordinates or any other fiducial points. We develop an alignment-free face representation method based on Multi-Keypoint Descriptors (MKD), where the descriptor size of a face is determined by the actual content of the image. In this way, any probe face image, holistic or partial, can be sparsely represented by a large dictionary of gallery descriptors. A new keypoint descriptor called Gabor Ternary Pattern (GTP) is also developed for robust and discriminative face recognition. Experimental results are reported on four public domain face databases (FRGCv2.0, AR, LFW, and PubFig) under both the open-set identification and verification scenarios. Comparisons with two leading commercial face recognition SDKs (PittPatt and FaceVACS) and two baseline algorithms (PCA+LDA and LBP) show that the proposed method, overall, is superior in recognizing both holistic and partial faces without requiring alignment.	[Liao, Shengcai; Li, Stan Z.] Chinese Acad Sci, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Liao, Shengcai; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Inst Automat, Beijing 100190, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; Michigan State University	Liao, SC (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, 1218 Automat Bldg,95 Zhongguancun East Rd, Beijing 100190, Peoples R China.	scliao@nlpr.ia.ac.cn; jain@cse.msu.edu; szli@cbsr.ia.ac.cn		Liao, Shengcai/0000-0001-8941-2295	Chinese Academy of Sciences [2011T1G18]; NSFC [61203267]; World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]	Chinese Academy of Sciences(Chinese Academy of Sciences); NSFC(National Natural Science Foundation of China (NSFC)); World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea	This research was supported by the Chinese Academy of Sciences Visiting Professorship for Senior International Scientists Grant No. 2011T1G18, and partly supported by NSFC #61203267. Part of Anil Jain's research was supported by the World Class University (WCU) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008). All correspondence should be directed to Anil K. Jain.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; [Anonymous], 2012, CSU FACE IDENTIFICAT; [Anonymous], 2012, PITTPATT SOFTW DEV K; [Anonymous], 2012, POLICE USE FACIAL RE; [Anonymous], 2012, FACEVACS SOFTW DEV K; [Anonymous], 2012, FACE RECOGNITION TEC; [Anonymous], P IEEE C COMP VIS PA; Awais M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.60; Beymer D., 1995, P INT C COMP VIS; BEYMER DJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P756, DOI 10.1109/CVPR.1994.323893; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cardinaux F, 2006, IEEE T SIGNAL PROCES, V54, P361, DOI 10.1109/TSP.2005.861075; CARDINAUX F, 2003, P 4 INT C AUD VID BA; Chan CH, 2010, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2010.5651933; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Csurka G., 2004, P ECCV WORKSH STAT L; Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958; Ekenel H., 2009, P IAPR IEEE 3 INT C; Graham DB, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P348, DOI 10.1109/AFGR.1998.670973; Gross R., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P481; Gutta S, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P33, DOI 10.1109/AFGR.2002.1004126; Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0; Hotta K, 2008, IMAGE VISION COMPUT, V26, P1490, DOI 10.1016/j.imavis.2008.04.008; Hua G, 2011, IEEE T PATTERN ANAL, V33, P1921, DOI 10.1109/TPAMI.2011.182; Huang G.B., 2008, WORKSHOP FACESREAL L; Jia H., 2009, P IEEE C COMP VIS PA; Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242; Kisku D., 2007, P IEEE WORKSH AUT ID; Kumar N., 2009, P IEEE INT C COMP VI; Li S., 2001, P IEEE C COMP VIS PA; Li Z., 2010, P 20 INT C PATT REC; Liao S., 2011, P IAPR IEEE INT JOIN; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu D, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL II, P29, DOI 10.1109/ISECS.2009.15; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUCEY S, 2004, P IEEE C COMP VIS PA; Luo J., 2007, P IEEE C AC SPEECH S; Martinez A., 1998, AR FACE DATABASE CVC; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K., 2002, P EUR C COMP VIS; Min R., 2011, P IEEE C AUT FAC GES; Musser DR, 1997, SOFTWARE PRACT EXPER, V27, P983, DOI 10.1002/(SICI)1097-024X(199708)27:8<983::AID-SPE117>3.0.CO;2-#; Oh HJ, 2008, IMAGE VISION COMPUT, V26, P1515, DOI 10.1016/j.imavis.2008.04.016; Pan K., 2007, P IEEE INT WORKSH OB; Park U., 2009, P IEEE 3 INT C BIOM; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Phillips P.J., 2005, P IEEE C COMP VIS PA; Phillips P. Jonathon, 2011, HDB FACE RECOGNITION, P551, DOI DOI 10.1007/978-0-85729-932-1_21.; Pinto N., 2009, P IEEE C COMP VIS PA; Sanderson C, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P997, DOI 10.1109/ICIP.2002.1039143; Sato K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P288, DOI 10.1109/AFGR.1998.670963; Tan X., 2007, P IEEE INT WORKSH AN; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xu H, 2012, IEEE T PATTERN ANAL, V34, P187, DOI 10.1109/TPAMI.2011.177; Yang J., 2009, P IAPR IEEE 3 INT C; Yi D., 2007, P IAPR IEEE 2 INT C; Yi D., 2009, P IAPR IEEE 3 INT C; Yin Q, 2011, P IEEE C COMP VIS PA; Zhang L., 2011, P IEEE INT C COMP VI; 2012, SCALE AFFINE INVARIA	72	134	145	1	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1193	1205		10.1109/TPAMI.2012.191	http://dx.doi.org/10.1109/TPAMI.2012.191			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520259	Green Submitted			2022-12-18	WOS:000316126800013
J	Horaud, R; Forbes, F; Yguel, M; Dewaele, G; Zhang, J				Horaud, Radu; Forbes, Florence; Yguel, Manuel; Dewaele, Guillaume; Zhang, Jian			Rigid and Articulated Point Registration with Expectation Conditional Maximization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point registration; feature matching; articulated object tracking; hand tracking; object pose; robust statistics; outlier detection; expectation maximization; EM; ICP; Gaussian mixture models; convex optimization; SDP relaxation	MAXIMUM-LIKELIHOOD-ESTIMATION; HUMAN MOTION TRACKING; EM; ALGORITHM; MIXTURE; ALIGNMENT	This paper addresses the issue of matching rigid and articulated shapes through probabilistic point registration. The problem is recast into a missing data framework where unknown correspondences are handled via mixture models. Adopting a maximum likelihood principle, we introduce an innovative EM-like algorithm, namely, the Expectation Conditional Maximization for Point Registration (ECMPR) algorithm. The algorithm allows the use of general covariance matrices for the mixture model components and improves over the isotropic covariance case. We analyze in detail the associated consequences in terms of estimation of the registration parameters, and propose an optimal method for estimating the rotational and translational parameters based on semidefinite positive relaxation. We extend rigid registration to articulated registration. Robustness is ensured by detecting and rejecting outliers through the addition of a uniform component to the Gaussian mixture model at hand. We provide an in-depth analysis of our method and compare it both theoretically and experimentally with other robust methods for point registration.	[Horaud, Radu; Forbes, Florence; Yguel, Manuel; Dewaele, Guillaume] INRIA Grenoble Rhone Alpes, 655 Ave Europe, F-38330 Montbonnot St Martin, France; [Zhang, Jian] Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam, Hong Kong, Peoples R China	University of Hong Kong	Horaud, R (corresponding author), INRIA Grenoble Rhone Alpes, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	radu.horaud@inrialpes.fr; florence.forbes@inrialpes.fr; manuel.yguel@inrialpes.fr; guillaume.dewaele@gmail.com; jzhang@eee.hku.hk	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				[Anonymous], 2004, EMERGING TOPICS COMP; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M, 2006, PATTERN RECOGN; Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; DELAGORCE M, 2008, P IEEE INT C COMP VI; DEMIRDJIAN D, 2004, P EUR C COMP VIS, P183; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dewaele G, 2004, LECT NOTES COMPUT SC, V3021, P495; DEWAELE G, 2006, P 9 EUR C COMP VIS M, P578; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; Hamer Henning, 2009, P IEEE INT C COMP VI; HATHAWAY RJ, 1985, ANN STAT, V13, P795, DOI 10.1214/aos/1176349557; Hennig C, 2004, ANN STAT, V32, P1313, DOI 10.1214/009053604000000571; Hennig C., 2007, P 31 ANN C GERM CLAS; Horaud R, 2009, IEEE T PATTERN ANAL, V31, P158, DOI 10.1109/TPAMI.2008.108; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Ingrassia S, 2007, COMPUT STAT DATA AN, V51, P5339, DOI 10.1016/j.csda.2006.10.011; Jian B., 2005, P 10 IEEE INT C COMP; Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978; Knossow D, 2008, INT J COMPUT VISION, V79, P247, DOI 10.1007/s11263-007-0116-2; Lemarechal C., 1999, 3710 INRIA; Liu YG, 2005, PATTERN RECOGN, V38, P1615, DOI 10.1016/j.patcog.2005.01.008; Liu YH, 2007, PATTERN RECOGN, V40, P2418, DOI 10.1016/j.patcog.2006.11.025; Luo B, 2003, COMPUT VIS IMAGE UND, V92, P26, DOI 10.1016/S1077-3142(03)00097-3; McCarthy J.M., 1990, INTRO THEORETICAL KI; McLachlan, 1997, EM ALGORITHM EXTENSI; MUNDERMAN L, 2007, P IEEE 11 INT C COMP; Oustry C., 2001, ADV CONVEX ANAL GLOB, V54, P119; Pellegrini S., 2008, P BRIT MACH VIS C SE; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Rousseeuw P., 1999, COMPUTING SCI STAT, V31, P451; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; RUSINKIEWICZ S, 2001, P IEEE 3 INT C 3D DI; Schlkopf B., 2006, ADV NEURAL INFORM PR, P1009; Sharp GC, 2008, IEEE T PATTERN ANAL, V30, P120, DOI 10.1109/TPAMI.2007.1130; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; SOFKA M, 2007, P IEEE C COMP VIS PA; Thiesson B, 2001, MACH LEARN, V45, P279, DOI 10.1023/A:1017986506241; TSIN Y, 2004, P 8 EUR C COMP VIS M; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Verbeek JJ, 2006, DATA MIN KNOWL DISC, V13, P291, DOI 10.1007/s10618-005-0033-3; WANG F, 2006, P 9 EUR C COMP VIS M; Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710; Williams J, 2000, IEICE T INF SYST, VE83D, P1662; YUILLE AL, 1994, NEURAL COMPUT, V6, P334, DOI 10.1162/neco.1994.6.2.334; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	58	134	144	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					587	602		10.1109/TPAMI.2010.94	http://dx.doi.org/10.1109/TPAMI.2010.94			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20421669	Green Submitted			2022-12-18	WOS:000286204700011
J	Petrakis, EGM; Diplaros, A; Milios, E				Petrakis, EGM; Diplaros, A; Milios, E			Matching and retrieval of distorted and occluded shapes using dynamic programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image database; shape retrieval; query by example; dynamic programming; relevance judgments	IMAGE RETRIEVAL; RECOGNITION; CURVES; COLOR	We propose an approach for matching distorted and possibly occluded shapes using Dynamic Programming (DP). We distinguish among various cases of matching such as cases where the shapes are scaled with respect to each other and cases where an open shape matches the whole or only a part of another open or closed shape. Our algorithm treats noise and shape distortions by allowing matching of merged sequences of consecutive small segments in a shape with larger segments of another shape, while being invariant to translation, scale, orientation, and starting point selection. We illustrate the effectiveness of our algorithm in retrieval of shapes on two data sets of two-dimensional open and closed shapes of marine life species. We demonstrate the superiority of our approach over traditional approaches to shape matching and retrieval based on Fourier descriptors and moments. We also compare our method with SQUID, a well-known method which is available on the Internet. Our evaluation is based on human relevance judgments following a well-established methodology from the information retrieval field.	Tech Univ Crete, Dept Elect & Comp Engn, GR-73100 Khania, Crete, Greece; Univ Amsterdam, Fac Sci, Informat Inst, NL-1098 SJ Amsterdam, Netherlands; Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada	Technical University of Crete; University of Amsterdam; Dalhousie University	Petrakis, EGM (corresponding author), Tech Univ Crete, Dept Elect & Comp Engn, GR-73100 Khania, Crete, Greece.	petrakis@ced.tuc.gr; diplaros@science.uva.nl; eem@cs.dal.ca	Petrakis, Euripides G.M./F-6741-2018; Milios, Evangelos/A-3008-2008	Petrakis, Euripides G.M./0000-0001-7436-5852; Milios, Evangelos/0000-0001-5549-4675				ANSARI N, 1990, IEEE T PATTERN ANAL, V12, P470, DOI 10.1109/34.55107; BAID J, 1996, VISION INTERFACE; Bebis G, 1999, PATTERN RECOGN, V32, P1175, DOI 10.1016/S0031-3203(98)00159-9; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; FLOREBY L, 1996, IEEE INT C PATTERN R, P884; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; GORMAN JW, 1988, IEEE T PATTERN ANAL, V10, P257, DOI 10.1109/34.3887; GOTTSCHALK PG, 1989, INT J ROBOT RES, V8, P110, DOI 10.1177/027836498900800608; GURTA L, 1987, PATTERN RECOGN, V20, P267; HAN MH, 1990, PATTERN RECOGN, V23, P21, DOI 10.1016/0031-3203(90)90046-N; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOCH MW, 1989, PATTERN RECOGN LETT, V10, P297, DOI 10.1016/0167-8655(89)90032-9; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MEHROTRA R, 1989, IEEE T ROBOTIC AUTOM, V5, P70, DOI 10.1109/70.88019; Mehtre BM, 1998, INFORM PROCESS MANAG, V34, P109, DOI 10.1016/S0306-4573(97)00049-6; Milios E, 2000, IEEE T IMAGE PROCESS, V9, P141, DOI 10.1109/83.817606; MILIOS E, 1998, CS199811 YORK U DEP; MILIOS EE, 1989, COMPUT VISION GRAPH, V47, P203, DOI 10.1016/S0734-189X(89)80007-6; MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; Mokhtarian F., 1996, P INT WORKSH IM DAT, P35; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; RAO Z, 1999, THESIS YORK U; SAUND E, 1990, IEEE T PATTERN ANAL, V12, P817, DOI 10.1109/34.57672; SHAPIRO L, 1980, IEEE T PATTERN ANAL, V2; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; SMITH AR, 1983, SIGGRAPHS 83 84; SMITH AR, 1983, 77 COMP DIV; SUETENS P, 1992, COMPUT SURV, V24, P5, DOI 10.1145/128762.128763; Tagare HD, 1997, IEEE T MED IMAGING, V16, P108, DOI 10.1109/42.552060; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954; VEMURI B, 1993, IEEE T PATTERN ANAL, V15; VOORHEES E, 1998, NIST SPECIAL PUBLICA, P1; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629	49	134	143	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1501	1516		10.1109/TPAMI.2002.1046166	http://dx.doi.org/10.1109/TPAMI.2002.1046166			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY					2022-12-18	WOS:000178846400007
J	Camastra, F; Vinciarelli, A				Camastra, F; Vinciarelli, A			Estimating the intrinsic dimension of data with a fractal-based method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian information criterion; correlation integral; Grassberger-Procaccia's algorithm; intrinsic dimension; nonlinear principal component analysis; box-counting dimension; fractal dimension; Kolmogorov capacity	STRANGE ATTRACTORS; LIMITATIONS; DYNAMICS; CHAOS	In this paper, the problem of estimating the intrinsic dimension of a data set is investigated A fractal-based approach using the Grassberger-Procaccia algorithm is proposed. Since the Grassberger-Procaccia algorithm performs badly on sets of high dimensionality, an empirical procedure that improves the original algorithm has been developed The procedure has been tested on data sets of known dimensionality and on time series of Santa Fe competition.	Univ Genoa, INFM DISI, I-16146 Genoa, Italy; Inst Dalle Molle Intelligence Artificielle Percep, CH-1920 Martigny, Switzerland	University of Genoa	Camastra, F (corresponding author), Univ Genoa, INFM DISI, Via Dodecaneso 35, I-16146 Genoa, Italy.	camastra@disi.unige.it; vincia@idiap.ch	; Vinciarelli, Alessandro/C-1651-2012	Camastra, Francesco/0000-0003-4439-7583; Vinciarelli, Alessandro/0000-0002-9048-0524				Bishop, 1995, NEURAL NETWORKS PATT; Broomhead DS, 2000, SIAM J APPL MATH, V60, P2114, DOI 10.1137/S0036139998338583; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Conway J. H., 1988, GRUNDLEHREN MATH WIS, V290; ECKMANN JP, 1985, REV MOD PHYS, V57, P617, DOI 10.1103/RevModPhys.57.617; ECKMANN JP, 1992, PHYSICA D, V56, P185, DOI 10.1016/0167-2789(92)90023-G; Fotheringhame D, 1997, BIOL CYBERN, V77, P283, DOI 10.1007/s004220050389; FRISCONE F, 1995, P INT C ART NEUR NET; Fukunaga K., 1976, IEEE T COMPUT, V20, P165; Fukunaga K., 1982, HDB STAT, V2, P347; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; HAYKIN S, 1995, P IEEE, V83, P95, DOI 10.1109/5.362751; HUANG Q, 1994, PATTERN RECOGN, V27, P339, DOI 10.1016/0031-3203(94)90112-0; HUBNER U, 1994, SFI S SCI C, V15, P73; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KAPLAN D, 1995, UNDERSTANDING NONLIN; Kirby M, 2001, GEOMETRIC DATA ANAL; Malthouse EC, 1998, IEEE T NEURAL NETWOR, V9, P165, DOI 10.1109/72.655038; Mandelbrot B.B., 1977, FRACTALS FORM CHANCE; MARTINETZ T, 1994, NEURAL NETWORKS, V7, P507, DOI 10.1016/0893-6080(94)90109-0; Ott E., 1993, CHAOS DYNAMICAL SYST; PINEDA FJ, 1994, SFI S SCI C, V15, P367; SCHEINKMAN JA, 1989, J BUS, V62, P311, DOI 10.1086/296465; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SMITH LA, 1988, PHYS LETT A, V133, P283, DOI 10.1016/0375-9601(88)90445-8; SMITH RL, 1992, NONLINEAR MODELING F, V12, P115; TAKENS F, 1985, P GRON 1984 DYN SYST, P99; THEILER J, 1990, PHYS REV A, V41, P3038, DOI 10.1103/PhysRevA.41.3038; THEILER J, 1988, PHYS LETT A, V133, P195, DOI 10.1016/0375-9601(88)91016-X; Tirsch WS, 2000, BIOL CYBERN, V82, P1, DOI 10.1007/PL00007957; Vapnik V.N, 1998, STAT LEARNING THEORY; [No title captured]	32	134	147	3	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1404	1407		10.1109/TPAMI.2002.1039212	http://dx.doi.org/10.1109/TPAMI.2002.1039212			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF		Green Submitted			2022-12-18	WOS:000178196300011
J	Whaite, P; Ferrie, FP				Whaite, P; Ferrie, FP			Autonomous exploration: Driven by uncertainty	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						autonomous exploration; active vision; visual servoing; artificial perception; unstructured environments; volumetric models; superellipsoids; next best view; theory of optimal experiments	PERCEPTION	Passively accepting measurements of the world is not enough, as the data we obtain is always incomplete, and the inferences made from it uncertain to a degree which is often unacceptable. If we are to build machines that operate autonomously, they will always be faced with this dilemma, and can only be successful if they play a much more active role. This paper presents such a machine. It deliberately seeks out those parts of the world which maximize the fidelity of its internal representations, and keeps searching until those representations are acceptable. We call this paradigm autonomous exploration, and the machine an autonomous explorer. This paper has two major contributions. The first is a theory that tells us how to explore, and which confirms the intuitive ideas we have put forward previously. The second is an implementation of that theory. In our laboratory, we have constructed a working autonomous explorer and here, for the first time, show it in action. The system is entirely bottom-up and does not depend on any a priori knowledge of the environment. To our knowledge, it is the first to have successfully closed the loop between gaze planning and the inference of complex 3D models.			Whaite, P (corresponding author), MCGILL UNIV, CTR INTELLIGENT MACHINES, ARTIFICIAL PRECEPT LAB, 3480 UNIV, MONTREAL, PQ H3A 2A7, CANADA.							AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; ALOIMONOS J, 1987, IEEE 1 INT C COMP VI, P35; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BAJCSY R, 1992, CVGIP-IMAG UNDERSTAN, V56, P31, DOI 10.1016/1049-9660(92)90083-F; BIRNBAUM L, 1993, ICCV93, P49; CHEUNG W, 1992, P CAN C IND AUT MONT; CHOI TH, 1990, P 4 ANN SPAC OP APPL; CONNOLLY C, 1985, IEEE INT C ROB AUT, P432; Fedorov V.V., 1972, THEORY OPTIMAL EXPT; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; FERRIE FP, 1993, 3D OBJECT RECOGNITIO; Hager G.D., 1990, TASK DIRECTED SENSOR; KUTULAKOS KN, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P331, DOI 10.1109/CVPR.1994.323848; Lejeune A, 1996, COMPUT VIS IMAGE UND, V64, P230, DOI 10.1006/cviu.1996.0056; MacKay D. J., 1992, BAYESIAN METHODS ADA; MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463; MOOD AM, 1963, INTRO THEORY STATIST; PENTLAND AP, 1987, IEEE P 1 INT C COMP, P612; Sorenson HW., 1985, KALMAN FILTERING THE; SOUCY G, 1992, THESIS MCGILL U; TARABANIS K, 1993, P IEEE CS C COMP VIS, P152; Whaite P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P3, DOI 10.1109/CVPR.1992.223235; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237; WHAITE P, 1993, TRCIM9411 MCGILL U M; WHAITE P, 1993, TRCIM9317 MCGILL U C; WHAITE P, 1993, IEEE 4 INT C COMP VI, P41; 1993, P 4 INT C COMP VIS B; 1987, P 1 INT C COMP VIS L	28	134	139	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					193	205		10.1109/34.584097	http://dx.doi.org/10.1109/34.584097			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200001
J	LIFSHITZ, LM; PIZER, SM				LIFSHITZ, LM; PIZER, SM			A MULTIRESOLUTION HIERARCHICAL APPROACH TO IMAGE SEGMENTATION BASED ON INTENSITY EXTREMA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV N CAROLINA,DEPT COMP SCI & RADIOL,CHAPEL HILL,NC 27514	University of North Carolina; University of North Carolina Chapel Hill	LIFSHITZ, LM (corresponding author), UNIV MASSACHUSETTS,SCH MED,BIOMED IMAGING GRP,WORCESTER,MA 01655, USA.							BEAULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150, DOI 10.1109/34.16711; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CHENG YC, 1985, IEEE T PATTERN ANAL, V7, P299, DOI 10.1109/TPAMI.1985.4767658; COHEN MA, 1984, PERCEPT PSYCHOPHYS, V36, P428, DOI 10.3758/BF03207497; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; HONG TH, 1982, IEEE T SYST MAN CYB, V12, P611, DOI 10.1109/TSMC.1982.4308880; John F., 1991, PARTIAL DIFFERENTIAL; LEE JKT, 1983, COMPUTED BODY TOMOGR; LIFSHITZ LM, 1987, THESIS U N CAROLINA; LU Y, 1989, IEEE T PATTERN ANAL, V11, P337, DOI 10.1109/34.19032; PIZER SM, 1986, 9TH P C INF PROC MED; TANIMOTO SL, 1989, IEEE T PATTERN ANAL, V11, P673; TOET L, 1986, TREATMENT IMAGE BOUN; [No title captured]	16	134	138	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					529	540		10.1109/34.56189	http://dx.doi.org/10.1109/34.56189			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300002
J	PERSOON, E; FU, KS				PERSOON, E; FU, KS			SHAPE-DISCRIMINATION USING FOURIER DESCRIPTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus								AMBLER AP, 1975, ARTIF INTELL, V6, P129, DOI 10.1016/0004-3702(75)90006-5; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; BRILL EL, 1968, 25 WESCON SESS QUAL; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HUSSAIN ABS, 1972, IEEE T COMPUTERS, V21, P269; Lipkin BS, 1970, PICTURE PROCESSING P, P241; MOTHSMITH JC, 1970, PICTURE PROCESSING P, P267; MUNSON JH, 1968, 1968 FALL JOINT COMP, V33, P1125; NCGHEE RB, 1973, 2ND US JAP SEM LEARN; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V6, P610; PERSOON E, INTERDISCIPLINARY SY; PERSOON E, 1974, 2ND INT JOINT C PATT; PERSOON E, 1976, APR MILW S AUT CONTR; PERSOON E, 1974, TREE7430 PURD U REPT; PHILBRICK O, 1968, PICTORIAL PATTERN RE, P395; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; ROSEN C, 1974, EXPLORATORY RES ADV; SIDHU GS, 1972, IEEE T COMPUT, VC 21, P1206, DOI 10.1109/T-C.1972.223478; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	20	134	151	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					388	397		10.1109/TPAMI.1986.4767799	http://dx.doi.org/10.1109/TPAMI.1986.4767799			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C0841	21869355				2022-12-18	WOS:A1986C084100008
J	Yang, WH; Tan, RT; Feng, JS; Guo, ZM; Yan, SC; Liu, JY				Yang, Wenhan; Tan, Robby T.; Feng, Jiashi; Guo, Zongming; Yan, Shuicheng; Liu, Jiaying			Joint Rain Detection and Removal from a Single Image with Contextualized Deep Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Rain; Shape; Atmospheric modeling; Image restoration; Deep learning; Degradation; Computer vision; Rain removal; rain detection; deep learning; rain accumulation; contextualized dilated network	QUALITY ASSESSMENT; SUPERRESOLUTION; VISION; MODEL	Rain streaks, particularly in heavy rain, not only degrade visibility but also make many computer vision algorithms fail to function properly. In this paper, we address this visibility problem by focusing on single-image rain removal, even in the presence of dense rain streaks and rain-streak accumulation, which is visually similar to mist or fog. To achieve this, we introduce a new rain model and a deep learning architecture. Our rain model incorporates a binary rain map indicating rain-streak regions, and accommodates various shapes, directions, and sizes of overlapping rain streaks, as well as rain accumulation, to model heavy rain. Based on this model, we construct a multi-task deep network, which jointly learns three targets: the binary rain-streak map, rain streak layers, and clean background, which is our ultimate output. To generate features that can be invariant to rain steaks, we introduce a contextual dilated network, which is able to exploit regional contextual information. To handle various shapes and directions of overlapping rain streaks, our strategy is to utilize a recurrent process that progressively removes rain streaks. Our binary map provides a constraint and thus additional information to train our network. Extensive evaluation on real images, particularly in heavy rain, shows the effectiveness of our model and architecture.	[Yang, Wenhan; Guo, Zongming; Liu, Jiaying] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China; [Tan, Robby T.] Natl Univ Singapore, Yale NUS Coll, Singapore 119077, Singapore; [Tan, Robby T.; Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Yan, Shuicheng] Qihoo 360 Co, Beijing, Peoples R China	Peking University; National University of Singapore; Yale NUS College; National University of Singapore	Liu, JY (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.	yangwenhan@pku.edu.cn; tanrobby@gmail.com; elefjia@nus.edu.sg; guozongming@pku.edu.cn; eleyans@nus.edu.sg; liujiaying@pku.edu.cn	Feng, Jiashi/AGX-6209-2022; Tan, Robby T./F-8826-2017; Yan, Shuicheng/HCI-1431-2022	Tan, Robby T./0000-0001-7532-6919; 	National Natural Science Foundation of China [61772043]; Beijing Natural Science Foundation [L182002, 4192025]; NVIDIA Corporation; Yale-NUS College Start-Up Grant	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation); NVIDIA Corporation; Yale-NUS College Start-Up Grant	This work was supported by National Natural Science Foundation of China under contract No. 61772043 and Beijing Natural Science Foundation under contract No. L182002 and No. 4192025. We also gratefully acknowledge the support of NVIDIA Corporation with the GPU for this research. R.T. Tan's research is supported in part by Yale-NUS College Start-Up Grant.	ANCUTI C, 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2; Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7; Brewer N, 2008, LECT NOTES COMPUT SC, V5342, P451, DOI 10.1007/978-3-540-89689-0_49; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247; Deng LJ, 2018, APPL MATH MODEL, V59, P662, DOI 10.1016/j.apm.2018.03.001; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fang YM, 2018, MULTIMED TOOLS APPL, V77, P29829, DOI 10.1007/s11042-018-5805-z; Finlayson GD, 2005, PROC CVPR IEEE, P1079; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Garg K, 2005, IEEE I CONF COMP VIS, P1067; GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077; Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6; Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985; Gatys LA., 2015, PROC CVPR IEEE, V16, P326, DOI [10.1167/16.12.326, DOI 10.1109/CVPR.2016.265]; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gu SH, 2017, IEEE I CONF COMP VIS, P1717, DOI 10.1109/ICCV.2017.189; Hu YS, 2017, IEEE T IND APPL, V53, P4526, DOI 10.1109/TIA.2017.2707330; Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759; Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522; Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838; Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057; Kim JH, 2013, IEEE IMAGE PROC, P914, DOI 10.1109/ICIP.2013.6738189; Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299; Liu J., 2018, P BRIT MECH VIS C, P1; Liu JY, 2019, IEEE T IMAGE PROCESS, V28, P2140, DOI 10.1109/TIP.2018.2882923; Liu JY, 2018, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2018.00341; Liu JY, 2019, IEEE T IMAGE PROCESS, V28, P699, DOI 10.1109/TIP.2018.2869722; Liu Q, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P412, DOI 10.1109/Cybermatics_2018.2018.00095; Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008; Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119; Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; Ning MY, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P164; Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263; Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186; Santhaseelan V, 2015, INT J COMPUT VISION, V112, P71, DOI 10.1007/s11263-014-0759-8; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shen L, 2018, ARXIVABS180106769; Sun SH, 2014, IEEE IMAGE PROC, P4482, DOI 10.1109/ICIP.2014.7025909; Tian YD, 2009, IEEE I CONF COMP VIS, P2303, DOI 10.1109/ICCV.2009.5459440; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xia SF, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351165; Xia SF, 2018, IEEE DATA COMPR CONF, P127, DOI 10.1109/DCC.2018.00021; Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI [10.1109/TIP.2016.2621478, 10.1109/TIP.2017.2689999]; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Yang Ji, 2017, Biodiversity Science, V25, P1255, DOI 10.17520/biods.2018007; Yang WH, 2018, COMPUT VIS IMAGE UND, V168, P79, DOI 10.1016/j.cviu.2017.09.002; Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183; Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403; Yang W, 2019, INT J HYPERTHER, V36, P9, DOI 10.1080/02656736.2018.1528390; Yu F., 2016, P ICLR 2016; Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407; Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079; Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572; Zhang XS, 2018, IEEE IMAGE PROC, P390, DOI 10.1109/ICIP.2018.8451694; Zhang XF, 2019, IEEE T IMAGE PROCESS, V28, P1163, DOI 10.1109/TIP.2018.2874283	73	133	142	10	105	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1377	1393		10.1109/TPAMI.2019.2895793	http://dx.doi.org/10.1109/TPAMI.2019.2895793			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30703011				2022-12-18	WOS:000535615700007
J	Ghesu, FC; Georgescu, B; Zheng, YF; Grbic, S; Maier, A; Hornegger, J; Comaniciu, D				Ghesu, Florin-Cristian; Georgescu, Bogdan; Zheng, Yefeng; Grbic, Sasa; Maier, Andreas; Hornegger, Joachim; Comaniciu, Dorin			Multi-Scale Deep Reinforcement Learning for Real-Time 3D-Landmark Detection in CT Scans	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; deep reinforcement learning; medical image analysis; multi-scale; scale-space modeling; three-dimensional (3D) object detection; real-time detection; intelligent localization	AUTOMATIC SEGMENTATION; LOCALIZATION; SHAPE; REGRESSION; MODELS	Robust and fast detection of anatomical structures is a prerequisite for both diagnostic and interventional medical image analysis. Current solutions for anatomy detection are typically based on machine learning techniques that exploit large annotated image databases in order to learn the appearance of the captured anatomy. These solutions are subject to several limitations, including the use of suboptimal feature engineering techniques and most importantly the use of computationally suboptimal search-schemes for anatomy detection. To address these issues, we propose a method that follows a new paradigm by reformulating the detection problem as a behavior learning task for an artificial agent. We couple the modeling of the anatomy appearance and the object search in a unified behavioral framework, using the capabilities of deep reinforcement learning and multi-scale image analysis. In other words, an artificial agent is trained not only to distinguish the target anatomical object from the rest of the body but also how to find the object by learning and following an optimal navigation path to the target object in the imaged volumetric space. We evaluated our approach on 1487 3D-CT volumes from 532 patients, totaling over 500,000 image slices and show that it significantly outperforms state-of-the-art solutions on detecting several anatomical structures with no failed cases from a clinical acceptance perspective, while also achieving a 20-30 percent higher detection accuracy. Most importantly, we improve the detection-speed of the reference methods by 2-3 orders of magnitude, achieving unmatched real-time performance on large 3D-CT scans.	[Ghesu, Florin-Cristian; Georgescu, Bogdan; Zheng, Yefeng; Grbic, Sasa; Comaniciu, Dorin] Siemens Healthineers, Med Imaging Technol, Princeton, NJ 08540 USA; [Ghesu, Florin-Cristian; Maier, Andreas; Hornegger, Joachim] Friedrich Alexander Univ Erlangen Nurnberg, Pattern Recognit Lab, D-91058 Erlangen, Germany	Siemens AG; University of Erlangen Nuremberg	Ghesu, FC (corresponding author), Siemens Healthineers, Med Imaging Technol, Princeton, NJ 08540 USA.; Ghesu, FC (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Pattern Recognit Lab, D-91058 Erlangen, Germany.	florin.c.ghesu@fau.de; bogdan.georgescu@siemens.com; yefeng.zheng@siemens.com; sasa.grbic@siemens.com; andreas.maier@fau.de; joachim.hornegger@fau.de; dorin.comaniciu@siemens.com	Hornegger, Joachim/H-2465-2017; Maier, Andreas/AAV-6505-2021; Zheng, Yefeng/ABG-7053-2020	Hornegger, Joachim/0000-0002-1834-8844; Maier, Andreas/0000-0002-9550-5284; Zheng, Yefeng/0000-0003-2195-2847				BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34; Bellver M., 2016, COMPUT RES REPOSITOR; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Cebral JR, 2005, IEEE T MED IMAGING, V24, P468, DOI 10.1109/TMI.2005.844172; Chien PC, 2009, DENTOMAXILLOFAC RAD, V38, P262, DOI 10.1259/dmfr/81889955; Chu C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123108; Ciresan Dan, 2012, ADV NEURAL INFORM PR, P2843, DOI DOI 10.5555/2999325.2999452; Criminisi A., 2013, DECISION FORESTCOM, P193; Criminisi A, 2011, LECT NOTES COMPUT SC, V6533, P106, DOI 10.1007/978-3-642-18421-5_11; Cuingnet R, 2012, LECT NOTES COMPUT SC, V7512, P66, DOI 10.1007/978-3-642-33454-2_9; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Donner R, 2013, MED IMAGE ANAL, V17, P1304, DOI 10.1016/j.media.2013.02.004; Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276; Fenchel M, 2008, LECT NOTES COMPUT SC, V5241, P576, DOI 10.1007/978-3-540-85988-8_69; Gauriau R, 2015, MED IMAGE ANAL, V23, P70, DOI 10.1016/j.media.2015.04.007; Ghesu FC, 2016, IEEE T MED IMAGING, V35, P1217, DOI 10.1109/TMI.2016.2538802; Ghesu Florin C., 2016, MEDICAL IMAGE COMPUT, P229, DOI [10.1007/978-3-319-46726-9_27, DOI 10.1007/978-3-319-46726-9_27]; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Glocker B, 2014, LECT NOTES COMPUT SC, V8673, P251, DOI 10.1007/978-3-319-10404-1_32; Hatt CR, 2015, LECT NOTES COMPUT SC, V9349, P290, DOI 10.1007/978-3-319-24553-9_36; Hess EP, 2014, J PATIENT SAF, V10, P52, DOI 10.1097/PTS.0b013e3182948b1a; Isgum I, 2009, IEEE T MED IMAGING, V28, P1000, DOI 10.1109/TMI.2008.2011480; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jie ZQ, 2016, ADV NEUR IN, V29; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lin L, 1992, THESIS; Lindeberg T., 1994, SCALE SPACE THEORY C, P101; Lindner C, 2015, IEEE T PATTERN ANAL, V37, P1862, DOI 10.1109/TPAMI.2014.2382106; Liu D, 2010, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2010.5540016; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Pauly O, 2011, LECT NOTES COMPUT SC, V6893, P239, DOI 10.1007/978-3-642-23626-6_30; Payer Christian, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P230, DOI 10.1007/978-3-319-46723-8_27; Potesil V, 2015, INT J COMPUT VISION, V111, P29, DOI 10.1007/s11263-014-0731-7; Pouch AM, 2014, MED IMAGE ANAL, V18, P118, DOI 10.1016/j.media.2013.10.001; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49; Rumelhart DE, 1985, TECHNICAL REPORT, DOI 10.1016/b978-1-4832-1446-7.50035-2; Russell SJ, 1995, ARTIF INTELL, V4th; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Stern Darko, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P221, DOI 10.1007/978-3-319-46723-8_26; Sutton R.S., 1998, INTRO REINFORCEMENT, DOI [10.1109/TNN.1998.712192, DOI 10.1109/TNN.1998.712192]; Theano Development Team, 2016, ARXIV160502688 THEAN; Tu ZW, 2005, IEEE I CONF COMP VIS, P1589; Victor J, 2009, KNEE, V16, P358, DOI 10.1016/j.knee.2009.01.001; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang N, 2013, ADV NEURAL INFORM PR, DOI DOI 10.5555/2999611.2999702; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wolterink J. M., 2016, P MED IM IM PROC, P9784; Yang L, 2011, IEEE T MED IMAGING, V30, P1921, DOI 10.1109/TMI.2011.2158440; Zhan YQ, 2008, LECT NOTES COMPUT SC, V5241, P313, DOI 10.1007/978-3-540-85988-8_38; Zhang D., 2017, COMPUT RES REPOSITOR; Zheng YF, 2008, IEEE T MED IMAGING, V27, P1668, DOI 10.1109/TMI.2008.2004421; Zheng YF, 2015, LECT NOTES COMPUT SC, V9349, P565, DOI 10.1007/978-3-319-24553-9_69; Zhu Y., 2016, COMPUT RES REPOSITOR, Vabs/1609.05143	64	133	134	18	167	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					176	189		10.1109/TPAMI.2017.2782687	http://dx.doi.org/10.1109/TPAMI.2017.2782687			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990011				2022-12-18	WOS:000452434800014
J	Marquez-Neila, P; Baumela, L; Alvarez, L				Marquez-Neila, Pablo; Baumela, Luis; Alvarez, Luis			A Morphological Approach to Curvature-Based Evolution of Curves and Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; mathematical morphology; curve evolution; level-sets; morphological snakes	ACTIVE CONTOUR MODELS; LEVEL SET METHODS; TRACKING; MOTION; SEGMENTATION; DIFFUSION; ALGORITHM	We introduce new results connecting differential and morphological operators that provide a formal and theoretically grounded approach for stable and fast contour evolution. Contour evolution algorithms have been extensively used for boundary detection and tracking in computer vision. The standard solution based on partial differential equations and level-sets requires the use of numerical methods of integration that are costly computationally and may have stability issues. We present a morphological approach to contour evolution based on a new curvature morphological operator valid for surfaces of any dimension. We approximate the numerical solution of the curve evolution PDE by the successive application of a set of morphological operators defined on a binary level-set and with equivalent infinitesimal behavior. These operators are very fast, do not suffer numerical stability issues, and do not degrade the level set function, so there is no need to reinitialize it. Moreover, their implementation is much easier since they do not require the use of sophisticated numerical algorithms. We validate the approach providing a morphological implementation of the geodesic active contours, the active contours without borders, and turbopixels. In the experiments conducted, the morphological implementations converge to solutions equivalent to those achieved by traditional numerical solutions, but with significant gains in simplicity, speed, and stability.	[Marquez-Neila, Pablo; Baumela, Luis] Univ Politecn Madrid, Dept Inteligencia Artificial, E-28040 Madrid, Spain; [Alvarez, Luis] Univ Palmas Gran Canaria, Dept Informat & Sistemas, Madrid, Spain	Universidad Politecnica de Madrid; Universidad de Las Palmas de Gran Canaria	Marquez-Neila, P (corresponding author), Univ Politecn Madrid, Dept Inteligencia Artificial, E-28040 Madrid, Spain.	p.mneila@upm.es; lbaumela@fi.upm.es; lalvarez@dis.ulpgc.es	Baumela, Luis/F-8867-2013; Alvarez, Luis/A-9190-2009	Alvarez, Luis/0000-0002-6953-9587	Cajal Blue Brain Project	Cajal Blue Brain Project	The authors would like to thank the anonymous reviewers for their valuable comments and constructive suggestions. The authors are also grateful to Javier de Felipe and the Cajal Cortical Circuit Lab for providing the dendrite and the EM brain tissue images. This research was funded by the Cajal Blue Brain Project.	Alvarez L., 1993, ARCH RATION MECH AN, V123, P200; Alvarez L, 2010, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2010.5539900; Appleton B, 2005, J MATH IMAGING VIS, V23, P67, DOI 10.1007/s10851-005-4968-1; Barles G, 1998, ARCH RATION MECH AN, V141, P237, DOI 10.1007/s002050050077; Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CATTE F, 1995, SIAM J NUMER ANAL, V32, P1895, DOI 10.1137/0732085; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen S, 1997, J COMPUT PHYS, V135, P8, DOI 10.1006/jcph.1997.5721; Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; Guichard F., 2004, CONTRAST INVARIANT I; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kimmel R., 2003, NUMERICAL GEOMETRY O; LAX PD, 1965, AM MATH MON, V72, P74, DOI 10.2307/2313313; Lenglet C, 2009, NEUROIMAGE, V45, pS111, DOI 10.1016/j.neuroimage.2008.10.054; Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96; Mishra AK, 2011, IEEE T PATTERN ANAL, V33, P310, DOI 10.1109/TPAMI.2010.83; Mitzel D, 2010, LECT NOTES COMPUT SC, V6311, P397, DOI 10.1007/978-3-642-15549-9_29; Morales J, 2011, FRONT NEUROANAT, V5, DOI 10.3389/fnana.2011.00018; Nilsson B, 2003, PATTERN RECOGN LETT, V24, P1331, DOI 10.1016/S0167-8655(02)00374-4; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2003, LEVEL SET METHODS AN; Pan YS, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P350, DOI 10.1109/MMSP.2006.285328; Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Pock T, 2008, LECT NOTES COMPUT SC, V5304, P792, DOI 10.1007/978-3-540-88690-7_59; Pock T, 2009, IEEE I CONF COMP VIS, P1133, DOI 10.1109/ICCV.2009.5459348; Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Shi YG, 2005, PROC CVPR IEEE, P34; Shi Y, 2008, IEEE T IMAGE PROCESS, V17, P645, DOI 10.1109/TIP.2008.920737; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; Tsai R., 2003, COMMUN MATH SCI, V1, P1, DOI DOI 10.4310/CMS.2003.V1.N4.AL; VANDENBOOMGAARD R, 1994, IEEE T PATTERN ANAL, V16, P1101, DOI 10.1109/34.334389; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Zimmer C, 2005, IEEE T PATTERN ANAL, V27, P1838, DOI 10.1109/TPAMI.2005.214	47	133	142	3	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					2	17		10.1109/TPAMI.2013.106	http://dx.doi.org/10.1109/TPAMI.2013.106			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231862				2022-12-18	WOS:000327965100002
J	Bian, W; Tao, DC				Bian, Wei; Tao, Dacheng			Max-Min Distance Analysis by Using Sequential SDP Relaxation for Dimension Reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fisher's linear discriminant analysis; dimension reduction; convex relaxation; data visualization; pattern classification	DISCRIMINANT-ANALYSIS; SUBSPACE	We propose a new criterion for discriminative dimension reduction, max-min distance analysis (MMDA). Given a data set with C classes, represented by homoscedastic Gaussians, MMDA maximizes the minimum pairwise distance of these C classes in the selected low-dimensional subspace. Thus, unlike Fisher's linear discriminant analysis (FLDA) and other popular discriminative dimension reduction criteria, MMDA duly considers the separation of all class pairs. To deal with general case of data distribution, we also extend MMDA to kernel MMDA (KMMDA). Dimension reduction via MMDA/KMMDA leads to a nonsmooth max-min optimization problem with orthonormal constraints. We develop a sequential convex relaxation algorithm to solve it approximately. To evaluate the effectiveness of the proposed criterion and the corresponding algorithm, we conduct classification and data visualization experiments on both synthetic data and real data sets. Experimental results demonstrate the effectiveness of MMDA/KMMDA associated with the proposed optimization algorithm.	[Bian, Wei; Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	University of Technology Sydney	Bian, W (corresponding author), Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.	wei.bian@student.uts.edu.au; dacheng.tao@uts.edu.au	Tao, Dacheng/A-5449-2012					ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; [Anonymous], 2008, CONVEX OPTIMIZATION; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BIAN W, 2009, ADV NEURAL INFORM PR; Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223; Bian W, 2008, INT C PATT RECOG, P160, DOI 10.1109/ICPR.2008.4760987; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Fazel M, 2003, P AMER CONTR CONF, P2156, DOI 10.1109/acc.2003.1243393; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FUJISAWA K., 2000, B359 TOK I TECHN; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Globerson A., 2005, ADV NEURAL INFORM PR; Graham D., 1998, FACE RECOGNITION, V163, P446, DOI DOI 10.1007/978-3-642-72201-1_25; Grant M., 2014, CVX MATLAB SOFTWARE; Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7; Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kim SJ, 2006, P 23 INT C MACH LEAR, P465, DOI DOI 10.1145/1143844.1143903; KUMAR K, 2006, REV ACCOUNTING FINAN, V5; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Lotlikar R, 2000, IEEE T PATTERN ANAL, V22, P623, DOI 10.1109/34.862200; Masip D, 2005, PATTERN ANAL APPL, V8, P227, DOI 10.1007/sl0044-005-0002-x; MIKA S, 1999, P IEEE WORKSH NEUR N; Newman C. B. D., 1998, UCI REPOSITORY MACHI; OVERTON ML, 1992, SIAM J MATRIX ANAL A, V13, P41, DOI 10.1137/0613006; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pochet N, 2004, BIOINFORMATICS, V20, P3185, DOI 10.1093/bioinformatics/bth383; Potamianos G, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P221, DOI 10.1109/MMSP.1998.738938; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Salakhutdinov R, 2005, NEURAL INF PROCESS S, P513; SCHERVISH MJ, 1984, J STAT PLAN INFER, V10, P167, DOI 10.1016/0378-3758(84)90068-5; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Sim T., 2001, CMURIT0102; Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005; Tian XM, 2010, IEEE T IMAGE PROCESS, V19, P805, DOI 10.1109/TIP.2009.2035866; TIANYI Z, 2010, DATA MINING KNOWLEDG; Weinberger K., 2006, ADV NEURAL INFORM PR; Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929, DOI 10.1109/TPAMI.2005.110; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37; You D, 2011, IEEE T PATTERN ANAL, V33, P631, DOI 10.1109/TPAMI.2010.173; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212; Zhu ML, 2008, IEEE T NEURAL NETWOR, V19, P148, DOI 10.1109/TNN.2007.904040; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	49	133	137	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					1037	1050		10.1109/TPAMI.2010.189	http://dx.doi.org/10.1109/TPAMI.2010.189			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	21436468				2022-12-18	WOS:000288677800013
J	Fiala, M				Fiala, Mark			Designing Highly Reliable Fiducial Markers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Augmented reality; fiducial marker systems; computer vision		Fiducial markers are artificial landmarks added to a scene to facilitate locating point correspondences between images, or between images and a known model. Reliable fiducials solve the interest point detection and matching problems when adding markers is convenient. The proper design of fiducials and the associated computer vision algorithms to detect them can enable accurate pose detection for applications ranging from augmented reality, input devices for HCI, to robot navigation. Marker systems typically have two stages, hypothesis generation from unique image features and verification/identification. A set of criteria for high robustness and practical use are identified and then optimized to produce the ARTag fiducial marker system. An edge-based method robust to lighting and partial occlusion is used for the hypothesis stage, and a reliable digital coding system is used for the identification and verification stage. Using these design criteria large gains in performance are achieved by ARTag over conventional ad hoc designs.	Ryerson Univ, Dept Comp Sci, Toronto, ON M5B 2K3, Canada	Toronto Metropolitan University	Fiala, M (corresponding author), Ryerson Univ, Dept Comp Sci, 350 Victoria St, Toronto, ON M5B 2K3, Canada.	mark.fiala@ryerson.ca						Boulanger P, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P320, DOI 10.1109/CCCRV.2004.1301462; CREASE M, 2007, P IEEE INT WORKSH HA, P43; Dudek G, 2007, IEEE INT CONF ROBOT, P2507, DOI 10.1109/ROBOT.2007.363842; Fiala M, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P180; Fiala M, 2005, PROC CVPR IEEE, P590; FIALA M, 2005, P IEEE INT WORKSH HA, P147; FIALA M, 2004, NATL RES COUNCIL PUB; FIALA M, 2007, MACHINE VISION APPL; FIALA M, 2007, P ACM SIGGRAPH 07, P152; Flohr D., 2007, P EUR S VIRT ENV, P59; HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x; Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809; KLINKER G, 1999, P INT S MIX REAL, P97; KNYAZ V, 1998, P INT C COMP GRAPH V; Naimark L, 2002, P IEEE ACM INT S MIX; OWEN CB, 2002, P 1 IEEE INT AUGM RE; Rekimoto J, 1998, 3RD ASIA PACIFIC COMPUTER HUMAN INTERACTION, PROCEEDINGS, P63, DOI 10.1109/APCHI.1998.704151; Rekimoto J., 2000, P DARE 2000 DES AUGM, P1, DOI DOI 10.1145/354666.354667; Rice A. C., 2006, P 4 ANN IEEE INT C P, P10; Rohs M., 2004, ADV PERVASIVE COMPUT, P265; Stricker D, 1999, AUGMENTED REALITY, P129; Wagner D., 2007, ARTOOLKITPLUS POSE T; Zhang X, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P97, DOI 10.1109/ISMAR.2002.1115078; [No title captured]	24	133	146	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1317	1324		10.1109/TPAMI.2009.146	http://dx.doi.org/10.1109/TPAMI.2009.146			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489233				2022-12-18	WOS:000277649100013
J	Jegou, H; Schmid, C; Harzallah, H; Verbeek, J				Jegou, Herve; Schmid, Cordelia; Harzallah, Hedi; Verbeek, Jakob			Accurate Image Search Using the Contextual Dissimilarity Measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image search; image retrieval; distance regularization	MATRICES	This paper introduces the contextual dissimilarity measure, which significantly improves the accuracy of bag-of-features-based image search. Our measure takes into account the local distribution of the vectors and iteratively estimates distance update terms in the spirit of Sinkhorn's scaling algorithm, thereby modifying the neighborhood structure. Experimental results show that our approach gives significantly better results than a standard distance and outperforms the state of the art in terms of accuracy on the Nister-Stewenius and Lola data sets. This paper also evaluates the impact of a large number of parameters, including the number of descriptors, the clustering method, the visual vocabulary size, and the distance measure. The optimal parameter choice is shown to be quite context-dependent. In particular, using a large number of descriptors is interesting only when using our dissimilarity measure. We have also evaluated two novel variants: multiple assignment and rank aggregation. They are shown to further improve accuracy at the cost of higher memory usage and lower efficiency.	[Jegou, Herve; Schmid, Cordelia; Harzallah, Hedi; Verbeek, Jakob] INRIA Grenoble, F-38334 Saint Ismier, France		Jegou, H (corresponding author), INRIA Grenoble, 655 Ave Europe, F-38334 Saint Ismier, France.	herve.jegou@inria.fr; cordelia.schmid@inria.fr; hedi.harzallah@inria.fr; jakob.verbeek@inria.fr						Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Fagin R., 2003, P 2003 ACM SIGMOD IN, P301, DOI [10.1145/872757.872795, DOI 10.1145/872757.872795]; Frome A., 2007, ADV NEURAL INFORM PR, V19, P417; GOLDBERGER J, 2005, P ADV NEUR INF PROC, P513; Horster E., 2007, P 6 ACM INT C IM VID, P17; Johnson CR, 2005, LINEAR ALGEBRA APPL, V397, P253, DOI 10.1016/j.laa.2004.10.023; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Philbin J, 2007, CVPR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Stewenius H., OBJECT RECOGNITION B, P2374; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Zobel J, 1998, ACM T DATABASE SYST, V23, P453, DOI 10.1145/296854.277632; [No title captured]	20	133	140	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					2	11		10.1109/TPAMI.2008.285	http://dx.doi.org/10.1109/TPAMI.2008.285			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926895	Green Submitted			2022-12-18	WOS:000271826700002
J	Buddharaju, P; Pavlidis, IT; Tsiamyrtzis, P; Bazakos, M				Buddharaju, Pradeep; Pavlidis, Ioannis T.; Tsiamyrtzis, Panagiotis; Bazakos, Mike			Physiology-based face recognition in the thermal infrared spectrum	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; biometrics; physiology; thermal infrared; vascular network		The current dominant approaches to face recognition rely on facial characteristics that are on or over the skin. Some of these characteristics have low permanency can be altered, and their phenomenology varies significantly with environmental factors (e. g., lighting). Many methodologies have been developed to address these problems to various degrees. However, the current framework of face recognition research has a potential weakness due to its very nature. We present a novel framework for face recognition based on physiological information. The motivation behind this effort is to capitalize on the permanency of innate characteristics that are under the skin. To establish feasibility, we propose a specific methodology to capture facial physiological patterns using the bioheat information contained in thermal imagery. First, the algorithm delineates the human face from the background using the Bayesian framework. Then, it localizes the superficial blood vessel network using image morphology. The extracted vascular network produces contour shapes that are characteristic to each individual. The branching points of the skeletonized vascular network are referred to as Thermal Minutia Points (TMPs) and constitute the feature database. To render the method robust to facial pose variations, we collect for each subject to be stored in the database five different pose images ( center, midleft profile, left profile, midright profile, and right profile). During the classification stage, the algorithm first estimates the pose of the test image. Then, it matches the local and global TMP structures extracted from the test image with those of the corresponding pose images in the database. We have conducted experiments on a multipose database of thermal facial images collected in our laboratory, as well as on the time-gap database of the University of Notre Dame. The good experimental results show that the proposed methodology has merit, especially with respect to the problem of low permanence over time. More importantly, the results demonstrate the feasibility of the physiological framework in face recognition and open the way for further methodological and experimental research in the area.	Univ Houston, Dept Comp Sci, Houston, TX 77204 USA; Athens Univ Econ & Business, Dept Stat, Athens 10434, Greece; Honeywell Technol Ctr, Minneapolis, MN 55418 USA	University of Houston System; University of Houston; Athens University of Economics & Business; Honeywell	Buddharaju, P (corresponding author), Univ Houston, Dept Comp Sci, 501 Philip G Hoffman, Houston, TX 77204 USA.	braju@cs.uh.edu; ipavlidi@central.uh.edu; pt@aueb.gr; Mike.Bazakos@Honeywell.com	Pavlidis, Ioannis/AAH-3817-2019; Tsiamyrtzis, Panagiotis/AAE-8878-2022	Pavlidis, Ioannis/0000-0001-8025-2600; Tsiamyrtzis, Panagiotis/0000-0002-3180-4090				[Anonymous], BIOMEDICAL ENG HDB; BUDDHARAJU P, 2005, P IEEE C ADV VID SIG, P354; Buddharaju P., 2006, P 2006 IEEE C COMP V, P53, DOI [DOI 10.1109/CVPRW.2006.160, 10.1109/CVPRW.2006.160]; Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001; Chen X, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P127; Cutler R., 1996, FACE RECOGNITION USI; DEGEEF S, 2006, FORENSIC SCI, V159, pS126; Ding Y, 2005, 2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings, P2106; Garbey M, 2004, PROC CVPR IEEE, P356; GYAOUROVA A, 2004, P 8 EUR C COMP VIS M; Jain A., 1999, BIOMETRICS PERSONAL; JANG BK, 1992, IEEE T PATTERN ANAL, V14, P1129, DOI 10.1109/34.166630; Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252; Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001; Li SZ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P455; Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005; Oliveira MD, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P122; Pankanti S, 2002, IEEE T PATTERN ANAL, V24, P1010, DOI 10.1109/TPAMI.2002.1023799; Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pinar YA, 2006, SURG RADIOL ANAT, V28, P248, DOI 10.1007/s00276-006-0094-z; Prabhakar S., 2003, HDB FINGERPRINT RECO; Prokoski F, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P5, DOI 10.1109/CVBVS.2000.855245; ROWELL LB, 1977, J INVEST DERMATOL, V69, P154, DOI 10.1111/1523-1747.ep12497938; Socolinsky DA, 2004, PROC CVPR IEEE, P1012; Socolinsky DA, 2001, PROC CVPR IEEE, P527; Socolinsky DA, 2002, INT C PATT RECOG, P217, DOI 10.1109/ICPR.2002.1047436; SOCOLINSKY DA, 2004, P 17 INT C PATT REC, V4, P23; Srivastava A, 2003, IMAGE VISION COMPUT, V21, P651, DOI 10.1016/S0262-8856(03)00061-1; *U NOTR DAM COMP V, 2002, BIOM DAT DISTR; Wang JG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P638; Wilder J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P182, DOI 10.1109/AFGR.1996.557262; Yang ZG, 2004, INT C PATT RECOG, P322; Zhao SY, 2005, LECT NOTES ARTIF INT, V3587, P437; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zou X., 2005, P 2005 BRIT MACH VIS; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	43	133	135	4	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					613	626		10.1109/TPAMI.2007.1007	http://dx.doi.org/10.1109/TPAMI.2007.1007			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299219				2022-12-18	WOS:000244855600010
J	Gorelick, L; Galun, M; Sharon, E; Basri, R; Brandt, A				Gorelick, Lena; Galun, Meirav; Sharon, Eitan; Basri, Ronen; Brandt, Achi			Shape representation and classification using the Poisson equation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; shape; Poisson equation; silhouette classification	RECOGNITION; ORGANIZATION	We present a novel approach that allows us to reliably compute many useful properties of a silhouette. Our approach assigns, for every internal point of the silhouette, a value reflecting the mean time required for a random walk beginning at the point to hit the boundaries. This function can be computed by solving Poisson's equation, with the silhouette contours providing boundary conditions. We show how this function can be used to reliably extract various shape properties including part structure and rough skeleton, local orientation and aspect ratio of different parts, and convex and concave sections of the boundaries. In addition to this, we discuss properties of the solution and show how to efficiently compute this solution using multigrid algorithms. We demonstrate the utility of the extracted properties by using them for shape classification and retrieval.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; Brown Univ, Div Appl Math, Providence, RI 02912 USA	Weizmann Institute of Science; Brown University	Gorelick, L (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, POB 26, IL-76100 Rehovot, Israel.	lena.gorelick@weizmann.ac.il; meirav.galun@weizmann.ac.il; eitans@dam.brown.edu; ronen.basri@weizmann.ac.il; achi.brandt@weizmann.ac.il						AGARWAL S, 2002, P EUROPEAN C COMPUTE, V2, P113; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; August J, 2003, IEEE T PATTERN ANAL, V25, P387, DOI 10.1109/TPAMI.2003.1190567; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BLANK M, 2005, P IEEE INT C COMPUTE; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; Bober M., 2001, IEEE T CIRCUITS SYST, V1; Bober M., 2003, CURVATURE SCALE SPAC; BORENSTEIN E, 2004, P IEEE WORKSHOP PERC; BRANDT A, 1969, ISRAEL J MATH, V7, P95, DOI 10.1007/BF02771657; Briggs W.L., 2000, MULTIGRID TUTORIAL; CARLSSON S, 1999, P INT WORKSH SHAP CO, P1681; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DOUGLIS A, 1955, COMMUN PUR APPL MATH, V8, P503, DOI 10.1002/cpa.3160080406; Duci A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P656; Duda R.O., 1973, J ROYAL STAT SOC SER; Elad M., 2001, PROC 6 EUROPGRAPHICS, P97; Fergus R, 2003, PROC CVPR IEEE, P264; Frenkel M, 2003, LECT NOTES COMPUT SC, V2683, P35; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; Geiger D, 1996, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.1996.517068; GIUDICI M, 2002, P ESANN BRUG BELG, P289; Gorelick L, 2004, PROC CVPR IEEE, P61; Grother P., 1995, 19 NIST; Keysers D, 2004, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2004.1333823; KEYSERS D, 2004, USPS DATABASE HANDWR; KIM WY, 1999, MPEG99M5472 ISOIEC; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; LAI SH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P9, DOI 10.1109/CVPR.1994.323804; LeCun Y., 1995, Neural Networks: The Statistical Mechanics Perspective. Proceedings of the CTP-PBSRI. Joint Workshop on Theoretical Physics, P261; Leibe B., 2004, EUROPEAN C COMPUTER, P17; LI J, 2001, P IEEE ICIP, V3, P1067; LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686, DOI 10.1109/TPAMI.1987.4767963; MAILA M, 2001, AI STATISTICS; Manjunath B. S., 2002, INTRO MPEG 7 MULTIME; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; Osher S., 2003, GEOMETRIC LEVEL SET; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; SEBASTIAN T, 2002, P EUR C COMP VIS, V3, P731; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sharon E, 2004, PROC CVPR IEEE, P350; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Simard PY, 2003, PROC INT CONF DOC, P958; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; TROTTENBERG U., 2000, MULTIGRID; ULLMAN S, 2001, P 4 INT WORKSH VIS F; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; ZHANG H, 2003, J ECHOCARDIOGR, V1, P15; ZULIANI M, 2004, P BRIT MACH VIS C SE; 2005, MPEX 7 XM SOFTWARE R	57	133	145	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					1991	2005		10.1109/TPAMI.2006.253	http://dx.doi.org/10.1109/TPAMI.2006.253			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108372	Green Submitted			2022-12-18	WOS:000241195700008
J	Paredes, R; Vidal, E				Paredes, R; Vidal, E			Learning weighted metrics to minimize nearest-neighbor classification error	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						weighted distances; nearest neighbor; leaving-one-out; error minimization; gradient descent	REDUCTION	In order to optimize the accuracy of the Nearest-Neighbor classification rule, a weighted distance is proposed, along with algorithms to automatically learn the corresponding weights. These weights may be specific for each class and feature, for each individual prototype, or for both. The learning algorithms are derived by (approximately) minimizing the Leaving-One-Out classification error of the given training set. The proposed approach is assessed through a series of experiments with UCI/STATLOG corpora, as well as with a more specific task of text classification which entails very sparse data representation and huge dimensionality. In all these experiments, the proposed approach shows a uniformly good behavior, with results comparable to or better than state-of-the-art results published with the same data so far.	Univ Politecn Valencia, Inst Informat Technol, Dept Sistemas Informat & Computac, Valencia, Spain	Universitat Politecnica de Valencia	Paredes, R (corresponding author), Univ Politecn Valencia, Inst Informat Technol, Dept Sistemas Informat & Computac, Valencia, Spain.	rparedes@iti.upv.es; evidal@iti.upv.es	Paredes, Roberto/T-6152-2017	Paredes, Roberto/0000-0002-5192-0021				Cramer J.S., 2003, ORIGINS LOGISTIC REG; Craven M, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P509; de Ridder D, 2004, INT C PATT RECOG, P295, DOI 10.1109/ICPR.2004.1334176; DERIDDER D, 2003, P JOINT C ART NEUR N; Devijver PA, 1982, PATTERN RECOGNITION; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; Hastie T, 1996, ADV NEUR IN, V8, P409; HOWE N, 1997, P 2 INT C CAS BAS RE, P455; KOHAVI R, 1997, P 9 EUR C MACH LEARN; KONONENKO I, 1993, ESTIMATING ATTRIBUTE; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; McCallum A, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P662; Merz C.J., 1997, UCI REPOSITORY MACHI; Michie Donald, 1994, MACHINE LEARNING NEU, P2; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Paredes R, 2004, INT C PATT RECOG, P442, DOI 10.1109/ICPR.2004.1334561; Paredes R, 2002, INT C PATT RECOG, P48, DOI 10.1109/ICPR.2002.1047397; Paredes R, 2000, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2000.906011; PAREDES R, 2004, LEARNING WEIGHTED ME; PAREDES R, 2003, P 8 EUR C SPEECH COM; PAREDES R, 2003, THESIS U POLITECNICA; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656, DOI 10.1109/TPAMI.2004.1273978; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Schapire RE, 1998, ANN STAT, V26, P1651; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P81; Stanfill C., 1986, Communications of the ACM, V29, P1213, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121, DOI 10.1109/TSMC.1976.5409182; VILAR D, 2004, P 4 INT WORKSH PATT, P108; Wilson D. R., 1996, Proceedings of the IASTED International Conference. Artificial Intelligence, Expert Systems and Neural Networks, P11; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yang Yiming, 1997, P 14 INT C MACHINE L, P412, DOI DOI 10.1016/J.ESWA.2008.05.026	38	133	137	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1100	1110		10.1109/TPAMI.2006.145	http://dx.doi.org/10.1109/TPAMI.2006.145			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792099				2022-12-18	WOS:000237424400007
J	Moscheni, F; Bhattacharjee, S; Kunt, M				Moscheni, F; Bhattacharjee, S; Kunt, M			Spatiotemporal segmentation based on region merging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic spatiotemporal segmentation; object segmentation; region merging; modified Kolmogorov-Smirnov test; weighted directed graph	MOVING-OBJECTS; IMAGE SEQUENCE; MOTION; SCENE	This paper proposes a technique for spatiotemporal segmentation to identify the objects present in the scene represented in a video sequence. This technique processes two consecutive frames at a time. A region-merging approach is used to identify the objects in the scene. Starting from an oversegmentation of the current frame, the objects are formed by iteratively merging regions together. Regions are merged based on their mutual spatiotemporal similarity. The spatiotemporal similarity measure takes both temporal and spatial Information into account, the emphasis being on the former. We propose a Modified Kolmogorov-Smirnov test for estimating the temporal similarity. This;est efficiently uses temporal information in both the residual distribution and the motion parametric representation. The region-merging process is based on a weighted, directed graph. Two complementary graph-based clustering rules are proposed, namely, the strong rule and the weak rule. These rules take advantage of the natural structures present in the graph. Also, the rules take into account the possible errors and uncertainties reported in the graph. The weak rule is applied after the strong rule. Each rile is applied iteratively and the graph is updated after each iteration. Experimental results on different types of scenes demonstrate the ability of the proposed technique to automatically partition the scene into its constituent objects.	Swiss Fed Inst Technol, Signal Proc Lab, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Moscheni, F (corresponding author), Swiss Fed Inst Technol, Signal Proc Lab, CH-1015 Lausanne, Switzerland.			Kunt, Murat/0000-0001-9398-5096				ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALLMEN M, 1993, CVGIP-IMAG UNDERSTAN, V58, P338, DOI 10.1006/ciun.1993.1046; Anandan P., 1993, MOTION ANAL IMAGE SE, P1; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; AYER S, 1993, IEEE WORKSH IM MULT, P122; AYER S, 1993, TIME VARYING IMAGE P; AYER S, 1994, ECCV94, V2, P316; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BLACK MJ, 1992, 2 EUR C COMP VIS SAN, P485; BLACK MJ, 1993, ICCV, P231; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; BOUTHEMY P, 1987, ICCV87, P463; BURT PJ, 1989, IEEE MOTION WORKSHOP, P2; BURT PJ, 1991, IEEE WORKSH VIS MOT, P187; DUC B, 1995, 6 INT C COMP AN IM P, P238; Dufaux F., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P306, DOI 10.1109/ICIP.1995.529707; DUFAUX F, 1995, VIDEO CODING 2 GENER, P219; DUFAUX F, 1996, P IEEE INT C IM PROC, V1, P673; GU C, 1996, THESIS SWISS FED I T; Gu HS, 1996, IEEE T PATTERN ANAL, V18, P58, DOI 10.1109/34.476012; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; IRANI M, 1992, 2ND P EUR C COMP VIS, P282; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; Kaufman L., 2009, FINDING GROUPS DATA; KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MOSCHENI F, 1995, P INT C AC SPEECH SI, V4, P2261; MOSCHENI F, 1997, THESIS ECOLE POLYTEC; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; MUSMANN HG, 1989, IMAGE COMMUN, V1, P117; Papoulis A., 1991, COMMUNICATIONS SIGNA, V3; PARK JW, 1996, P ICIP96, V2, P501; PRESS WH, 1992, NUMERICAL RECIPES C, VS; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SALEMBIER P, 1995, P IEEE, V83, P843, DOI 10.1109/5.387088; SCHREINER GE, 1994, NEPHROL DIAL TRANSPL, V9, P1; SCHUTZ M, 1996, P ICIP 96, V2, P509; Szeliski R, 1996, IEEE T PATTERN ANAL, V18, P1199, DOI 10.1109/34.546257; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; THOMPSON WB, 1990, INT J COMPUT VISION, V4, P39, DOI 10.1007/BF00137442; Wandell B.A., 1995, FDN VISION; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WANG JYA, 1994, SPIE P IM VID PROC 2, V2182, P1; Wu S. F., 1993, Journal of Visual Communication and Image Representation, V4, P25, DOI 10.1006/jvci.1993.1003; ZHENG HY, 1995, IEEE T IMAGE PROCESS, V4, P1223, DOI 10.1109/83.413167	49	133	149	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					897	915		10.1109/34.713358	http://dx.doi.org/10.1109/34.713358			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500001
J	LIU, HC; SRINATH, MD				LIU, HC; SRINATH, MD			PARTIAL SHAPE CLASSIFICATION USING CONTOUR MATCHING IN DISTANCE TRANSFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SO METHODIST UNIV,DEPT ELECT ENGN,DALLAS,TX 75275	Southern Methodist University	LIU, HC (corresponding author), INST NUCL ENERGY RES,POB 3-11,LUNGTAN,TAIWAN.							BOLLES RC, 1984, ROBOT VISION; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BORGEFOS G, 1984, P INT C PATTERN RECO; BORGEFOS G, COMPUT VISION GRAPH, V34, P344; Canny J. F., 1983, THESIS MIT CAMBRIDGE; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; GORMAN JW, 1988, IEEE T PATTERN ANAL, V10, P257, DOI 10.1109/34.3887; GUPTA L, 1986, THESIS SO METHODIST; KNOLL TF, 1986, IEEE T ROBOTIC AUTOM, V2, P3, DOI 10.1109/JRA.1986.1087031; LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686, DOI 10.1109/TPAMI.1987.4767963; MITCHELL OR, 1984, OPT ENG, V23, P484, DOI 10.1117/12.7973326; MORGAN TA, 1983, THESIS PURDUE U W LA; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PRICE KE, 1984, 1984 P IEEE WORKSH C, P130; SINGER PF, 1985, P IEEE C COMPUT VISI; TEJWANI YJ, 1985, IEEE T SYST MAN CYB, V12, P504; [No title captured]	17	133	155	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1072	1079		10.1109/34.61706	http://dx.doi.org/10.1109/34.61706			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700004
J	Azizpour, H; Razavian, AS; Sullivan, J; Maki, A; Carlsson, S				Azizpour, Hossein; Razavian, Ali Sharif; Sullivan, Josephine; Maki, Atsuto; Carlsson, Stefan			Factors of Transferability for a Generic ConvNet Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural networks; transfer learning; representation learning; deep learning; visual recognition		Evidence is mounting that Convolutional Networks (ConvNets) are the most effective representation learning method for visual recognition tasks. In the common scenario, a ConvNet is trained on a large labeled dataset (source) and the feed-forward units activation of the trained network, at a certain layer of the network, is used as a generic representation of an input image for a task with relatively smaller training set (target). Recent studies have shown this form of representation transfer to be suitable for a wide range of target visual recognition tasks. This paper introduces and investigates several factors affecting the transferability of such representations. It includes parameters for training of the source ConvNet such as its architecture, distribution of the training data, etc. and also the parameters of feature extraction such as layer of the trained ConvNet, dimensionality reduction, etc. Then, by optimizing these factors, we show that significant improvements can be achieved on various (17) visual recognition tasks. We further show that these visual recognition tasks can be categorically ordered based on their similarity to the source task such that a correlation between the performance of tasks and their similarity to the source task w.r.t. the proposed factors is observed.	[Azizpour, Hossein; Razavian, Ali Sharif; Sullivan, Josephine; Maki, Atsuto; Carlsson, Stefan] Royal Inst Technol KTH, Comp Vis & Act Percept Lab, SE-10044 Stockholm, Sweden	Royal Institute of Technology	Azizpour, H (corresponding author), Royal Inst Technol KTH, Comp Vis & Act Percept Lab, SE-10044 Stockholm, Sweden.	azizpour@csc.kth.se; razavian@csc.kth.se; sullivan@csc.kth.se; atsuto@csc.kth.se; stefanc@csc.kth.se		Azizpour, Hossein/0000-0001-5211-6388	Swedish Foundation for Strategic Research (SSF) within project VINST	Swedish Foundation for Strategic Research (SSF) within project VINST	The authors gratefully acknowledge the NVIDIA Corporation for their donation of the Tesla K40 GPUs used in this research. This work has been funded by the Swedish Foundation for Strategic Research (SSF) within the project VINST. The manuscript is an extended version of the CVPR Workshops DeepVision 2015 paper "From Generic to Specific Deep Representations for Visual Recognition".	Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2013, IMAGENET LARGE SCALE; Arandjelovic R, 2011, IEEE I CONF COMP VIS, P375, DOI 10.1109/ICCV.2011.6126265; Argyriou A., 2006, ADV NEURAL INFORM PR, P41; Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Donahue J, 2014, PR MACH LEARN RES, V32; Everingham M., 2012, PASCAL VISUAL OBJECT; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215; Girshick R., 2015, ICCV; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; jia Li L., 2010, NIPS, DOI [10.1184/R1/6475985.v1, DOI 10.1184/R1/6475985.V1]; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Koniusz P., 2013, TECH REP; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lenc K, 2015, ARXIV150606981; Lin D, 2014, PROC CVPR IEEE, P3726, DOI 10.1109/CVPR.2014.476; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [DOI 10.1007/978-3-030-28954-6_10, 10.1109/CVPR.2012.6248092, DOI 10.1109/CVPR.2012.6248092]; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Philbin J, 2008, PROC CVPR IEEE, P2285; Pratt L. Y., 1992, ADV NEURAL INFORM PR, V5; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Sharif Razavian A., 2015, P ICLR WORKSH; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Tsagkatakis G., 2010, ECCV WORKSH, P29; Welinder P., 2010, CNSTR2010001 CALTECH; Xiao J., 2014, IJCV; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yosinski Jason, 2014, ARXIV14111792CSLG; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhao WL, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.99; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhu XX, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.80	56	132	136	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1790	1802		10.1109/TPAMI.2015.2500224	http://dx.doi.org/10.1109/TPAMI.2015.2500224			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26584488	Green Submitted			2022-12-18	WOS:000381432700006
J	Isola, P; Xiao, JX; Parikh, D; Torralba, A; Oliva, A				Isola, Phillip; Xiao, Jianxiong; Parikh, Devi; Torralba, Antonio; Oliva, Aude			What Makes a Photograph Memorable?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; image memorability; global image features; attributes	LONG-TERM-MEMORY; SCENE; RECOGNITION; PICTURES; OLDER	When glancing at a magazine, or browsing the Internet, we are continuously exposed to photographs. Despite this overflow of visual information, humans are extremely good at remembering thousands of pictures along with some of their visual details. But not all images are equal in memory. Some stick in our minds while others are quickly forgotten. In this paper, we focus on the problem of predicting how memorable an image will be. We show that memorability is an intrinsic and stable property of an image that is shared across different viewers, and remains stable across delays. We introduce a database for which we have measured the probability that each picture will be recognized after a single view. We analyze a collection of image features, labels, and attributes that contribute to making an image memorable, and we train a predictor based on global image descriptors. We find that predicting image memorability is a task that can be addressed with current computer vision techniques. While making memorable images is a challenging task in visualization, photography, and education, this work is a first attempt to quantify this useful property of images.	[Isola, Phillip; Xiao, Jianxiong; Torralba, Antonio; Oliva, Aude] MIT, Cambridge, MA 02139 USA; [Parikh, Devi] Virginia Polytech Inst & State Univ, Blacksburg, VA 24061 USA	Massachusetts Institute of Technology (MIT); Virginia Polytechnic Institute & State University	Isola, P (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	phillipi@mit.edu; jxiao@mit.edu; parikh@vt.edu; torralba@mit.edu; oliva@mit.edu			National Science Foundation [1016862]; NSF CAREER Award [0747120]; Intelligence Advanced Research Projects Activity via Department of the Interior [D10PC20023]; ONR MURI [N000141010933]; Google; Xerox; National Science Foundation; Google U.S./Canada	National Science Foundation(National Science Foundation (NSF)); NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); Intelligence Advanced Research Projects Activity via Department of the Interior; ONR MURI(MURIOffice of Naval Research); Google(Google Incorporated); Xerox; National Science Foundation(National Science Foundation (NSF)); Google U.S./Canada(Google Incorporated)	The authors would like to thank T. Brady and T. Konkle for helpful discussions and advice. This work was supported in part by the National Science Foundation under Grant 1016862 to A. Oliva, in part by the NSF CAREER Award 0747120, in part by Intelligence Advanced Research Projects Activity via Department of the Interior contract D10PC20023, and in part by ONR MURI N000141010933 to A. Torralba, as well as Google and Xerox Awards to A. Oliva and A. Torralba. P. Isola is supported by a National Science Foundation Graduate Research Fellowship. J. Xiao is supported by a Google U.S./Canada Ph.D. Fellowship.	Bainbridge WA, 2013, J EXP PSYCHOL GEN, V142, P1323, DOI 10.1037/a0033872; Berg A., 2012, P IEEE C CVPR PROV R; Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105; Brady TF, 2013, J EXP PSYCHOL GEN, V142, P791, DOI 10.1037/a0029649; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Charles ST, 2003, J EXP PSYCHOL GEN, V132, P310, DOI 10.1037/0096-3445.132.2.310; Choi M. J., 2010, P IEEE C CVPR SAN FR; Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933; Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922; CROSS JF, 1971, PERCEPT PSYCHOPHYS, V10, P393, DOI 10.3758/BF03210319; D'Argembeau A, 2003, COGNITION EMOTION, V17, P609, DOI 10.1080/02699930302303; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, P IEEE COMP SOC C CV; Dhar S., 2011, P IEEE C CVPR PROV R; Eysenck MW, 1979, LEVELS PROCESSING HU; Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133; Gooch B., 2001, P 12 EUR WORKSH REND; Hunt R.R., 2006, DISTINCTIVENESS MEMO, P3, DOI [https://doi.org/10.1093/acprof:oso/9780195169669.003.0001, DOI 10.1093/ACPROF:OSO/9780195169669.003.0001, 10.1093/acprof:oso/9780195169669.003.0001]; Isola P., 2011, P IEEE C CVPR; Isola P., 2011, P NIPS; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Khosla A., 2012, P NIPS; Konkle T, 2010, PSYCHOL SCI, V21, P1551, DOI 10.1177/0956797610385359; Konkle T, 2010, J EXP PSYCHOL GEN, V139, P558, DOI 10.1037/a0019165; Koutstaal W, 1997, J MEM LANG, V37, P555, DOI 10.1006/jmla.1997.2529; LAZEBNIK S, 2006, P IEEE COMP SOC C CV; Leyvand T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360637; Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x; Luo Y., 2008, P 10 ECCV MARS FRANC; Marchesotti L., 2011, P ICCV; Murray N., 2012, P IEEE C CVPR PROV R; Nairne J. S., 2006, DISTINCTIVENESS MEMO; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rawson KA, 2008, J MEM LANG, V58, P646, DOI 10.1016/j.jml.2007.08.004; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; SCHMIDT SR, 1985, J EXP PSYCHOL LEARN, V11, P565, DOI 10.1037/0278-7393.11.3.565; Shechtman E., 2007, P IEEE C CVPR MINN M; Spain M., 2008, P 10 ECCV MARS FRANC; STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340; TVERSKY B, 1985, MEM COGNITION, V13, P45, DOI 10.3758/BF03198442; Vogt S, 2007, EXP PSYCHOL, V54, P298, DOI 10.1027/1618-3169.54.4.298; Xiao J., 2010, P IEEE C CVPR SAN FR	42	132	135	2	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1469	1482		10.1109/TPAMI.2013.200	http://dx.doi.org/10.1109/TPAMI.2013.200			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AK1WS	26353315	Green Submitted			2022-12-18	WOS:000338209900013
J	He, ZS; Cichocki, A; Xie, SL; Choi, K				He, Zhaoshui; Cichocki, Andrzej; Xie, Shengli; Choi, Kyuwan			Detecting the Number of Clusters in n-Way Probabilistic Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiway clustering; probabilistic clustering; hypergraph; parallel factor analysis (PARAFAC); model order selection; multiway array; higher order tensor; supersymmetric tensors; affinity arrays; enumeration of clusters; estimation of PARAFAC components; principal components enumeration	DATA SET; COMPONENTS; CRITERION; SELECTION; MODELS	Recently, there has been a growing interest in multiway probabilistic clustering. Some efficient algorithms have been developed for this problem. However, not much attention has been paid on how to detect the number of clusters for the general n-way clustering (n >= 2). To fill this gap, this problem is investigated based on n-way algebraic theory in this paper. A simple, yet efficient, detection method is proposed by eigenvalue decomposition (EVD), which is easy to implement. We justify this method. In addition, its effectiveness is demonstrated by the experiments on both simulated and real-world data sets.	[He, Zhaoshui; Cichocki, Andrzej] RIKEN, Brain Sci Inst, Lab Adv Brain Signal Proc, Wako, Saitama 3510198, Japan; [He, Zhaoshui; Xie, Shengli] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China; [Cichocki, Andrzej] Polish Acad Sci, Syst Res Inst, PL-00901 Warsaw, Poland; [Cichocki, Andrzej] Warsaw Univ Technol, Dept Elect Engn, PL-00661 Warsaw, Poland; [Choi, Kyuwan] ATR Computat Neurosci Labs, Dept Computat Brain Imaging, Seika, Kyoto 6190288, Japan	RIKEN; South China University of Technology; Polish Academy of Sciences; Systems Research Institute of the Polish Academy of Sciences; Warsaw University of Technology	He, ZS (corresponding author), RIKEN, Brain Sci Inst, Lab Adv Brain Signal Proc, 2-1 Hirosawa, Wako, Saitama 3510198, Japan.	he_shui@tom.com; cia@brain.riken.jp; adshlxie@scut.edu.cn; kyuwanchoi@gmail.com	Cichocki, Andrzej/A-1545-2015; liu, yi/GXE-9662-2022; Cichocki, Andrzej/AAI-4209-2020; Xie, Shengli/AAZ-6354-2020	Cichocki, Andrzej/0000-0002-8364-7226; 	National Natural Science Foundation of China [U0635001, 60874061]; National Basic Research Program of China (973 Program) [2010CB731800]; Fundamental Research Funds for Central Univresity, SCUT [x2xD2102070]; CPSF [20070410237, 200801248]; National Institute of Information and Communications Technology	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Fundamental Research Funds for Central Univresity, SCUT; CPSF(China Postdoctoral Science Foundation); National Institute of Information and Communications Technology	The authors would like to thank the anonymous reviewers. Due to their comments and suggestions, both the technical quality and readability of this paper have been improved. The work is supported in part by the National Natural Science Foundation of China (Grants U0635001 and 60874061), National Basic Research Program of China (973 Program 2010CB731800), the Fundamental Research Funds for Central Univresity, SCUT (Grant x2xD2102070), and CPSF (Grants 20070410237, 200801248). Kyuwan Choi's work was partially supported by a grant from the National Institute of Information and Communications Technology project entitled "Multimodal integration for brain imaging measurements."	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Andersson CA, 2000, CHEMOMETR INTELL LAB, V52, P1, DOI 10.1016/S0169-7439(00)00071-X; BANERJEE A, 2007, P SIAM C DAT MIN; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Berge C., 1989, HYPERGRAPHS; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Bro R, 2003, J CHEMOMETR, V17, P274, DOI 10.1002/cem.801; Bro R, 1997, CHEMOMETR INTELL LAB, V38, P149, DOI 10.1016/S0169-7439(97)00032-4; BUHMANN JM, 1994, INT C PATT RECOG, P207, DOI 10.1109/ICPR.1994.576905; Calinski T., 1974, COMMUN STAT-THEOR M, V3, P1, DOI [DOI 10.1080/03610927408827101, 10.1080/03610927408827101]; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Ceulemans E, 2006, BRIT J MATH STAT PSY, V59, P133, DOI 10.1348/000711005X64817; Cichocki Andrzej, 2009, NONNEGATIVE MATRIX T, P2; Comon P, 2008, INT CONF ACOUST SPEE, P3313, DOI 10.1109/ICASSP.2008.4518359; Cuevas A, 2000, CAN J STAT, V28, P367, DOI 10.2307/3315985; da Costa JPCL, 2008, PR IEEE SEN ARRAY, P511; da Costa JPCL, 2007, CONFERENCE RECORD OF THE FORTY-FIRST ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1-5, P412; De Lathauwer L, 2006, SIAM J MATRIX ANAL A, V28, P642, DOI 10.1137/040608830; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808; FELLER W, 1991, INTRO PROBABILITY TH, V2; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Grouffaud J, 1996, INT CONF ACOUST SPEE, P2463, DOI 10.1109/ICASSP.1996.547962; Guo P, 2002, IEEE T NEURAL NETWOR, V13, P757, DOI 10.1109/TNN.2002.1000144; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Harshman R. A., 1972, UCLA WORKING PAPERS, V22, P111; Harshman R. A., 1972, UCLA WORKING PAPERS, V22; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HASTAD J, 1990, J ALGORITHMS, V11, P644, DOI 10.1016/0196-6774(90)90014-6; Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; HOFMANN T, 1995, P INT C ART NEUR NET, P197; Hu X., 2004, NEURAL INFORM PROCES, V4, P1; Kaufman L., 2005, FINDING GROUPS DATA; Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I; Kiers HAL, 2003, BRIT J MATH STAT PSY, V56, P119, DOI 10.1348/000711003321645386; Kofidis E, 2002, SIAM J MATRIX ANAL A, V23, P863, DOI 10.1137/S0895479801387413; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kroonenberg P. M., 1987, KWANTITATIEVE METHOD, V8, P117; KRUSKAL J. B., 1989, RANK DECOMPOSITION U; KRZANOWSKI WJ, 1988, BIOMETRICS, V44, P23, DOI 10.2307/2531893; Kyrgyzov IO, 2007, LECT NOTES ARTIF INT, V4571, P203; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; MINKA TP, 2001, ADV NEURAL INFORM PR, P556; Piccione F, 2006, CLIN NEUROPHYSIOL, V117, P531, DOI 10.1016/j.clinph.2005.07.024; Quinlan A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/71953; Radoi E, 2004, EURASIP J APPL SIG P, V2004, P1177, DOI 10.1155/S1110865704401097; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCLOVE SL, 1994, P 1 US JAP C FRONT S, V2, P37; Shashua A, 2006, LECT NOTES COMPUT SC, V3954, P595; Smilde A., 2005, MULTIWAY ANAL APPL C; Sugar CA, 2003, J AM STAT ASSOC, V98, P750, DOI 10.1198/016214503000000666; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Timmerman ME, 2000, BRIT J MATH STAT PSY, V53, P1, DOI 10.1348/000711000159132; Ulfarsson MO, 2008, IEEE T SIGNAL PROCES, V56, P5804, DOI 10.1109/TSP.2008.2005865; Yan M, 2007, BIOMETRICS, V63, P1031, DOI 10.1111/j.1541-0420.2007.00784.x; Zass R, 2005, IEEE I CONF COMP VIS, P294; ZASS R, 2007, ADV NEURAL INFORM PR, V19, P1569; Zhou D, 2006, P 2006 C ADV NEURAL, V19, DOI 10.7551/mitpress/7503.003.0205	63	132	139	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2006	2021		10.1109/TPAMI.2010.15	http://dx.doi.org/10.1109/TPAMI.2010.15			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847390				2022-12-18	WOS:000281990900006
J	Peleg, S; Rousso, B; Rav-Acha, A; Zomet, A				Peleg, S; Rousso, B; Rav-Acha, A; Zomet, A			Mosaicing on adaptive manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mosaicing; motion analysis; image alignment	REPRESENTATION; PROJECTION	Image mosaicing is commonly used to increase the visual field of view by pasting together many images or video frames. Existing mosaicing methods are based on projecting all images onto a predetermined single manifold: A plane is commonly used for a camera translating sideways, a cylinder is used for a panning camera, and a sphere is used for a camera which is both panning and tilting. While different mosaicing methods should therefore be used for different types of camera motion, more general types of camera motion, such as forward motion, are practically impossible for traditional mosaicing. A new methodology to allow image mosaicing in more general cases of camera motion is presented. Mosaicing is performed by projecting thin strips from the images onto manifolds which are adapted to the camera motion. While the limitations of existing mosaicing techniques are a result of using predetermined manifolds, the use of more general manifolds overcomes these limitations.	Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Peleg, S (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel.	peleg@cs.huji.ac.il; Bennyr@Impulse.co.il; alexis@ac.huji.ac.il; zomet@ac.huji.ac.il	Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				BERGEN JR, 1992, P EUR C COMP VIS, P237; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; BURT PJ, 1994, P DARPA IM UND WORKS, P424; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395; HANSEN M, 1994, P ARPA IM UND WORKSH, P457; HARTLEY R, 1994, P 3 EUR C COMP VIS M, P555; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; JAILLON P, 1994, INT C PATT RECOG, P253, DOI 10.1109/ICPR.1994.576267; Krishnan A, 1996, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.1996.517100; Kumar R., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P10, DOI 10.1109/WVRS.1995.476847; Loop C., 1999, 1999 IEEE COMP SOC C, V1, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]; MANN S, 1994, IEEE IMAGE PROC, P363, DOI 10.1109/ICIP.1994.413336; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; MILGRAM DL, 1977, IEEE T COMPUT, V26, P1175, DOI 10.1109/TC.1977.1674772; Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369; Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346; PELEG S, 1981, COMPUT VISION GRAPH, V16, P90, DOI 10.1016/0146-664X(81)90094-0; Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871; Rousso B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P945, DOI 10.1109/ICCV.1998.710830; ROUSSO B, 1997, P DARPA IM UND WORKS, P255; Roy S, 1997, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.1997.609355; SAWHNEY HS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P583; SEITZ S, 1995, P IEEE WORKSH REPR V, P19; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859; ZHENG JY, 1992, INT J COMPUT VISION, V9, P55; Zheng JY, 1998, COMPUT VIS IMAGE UND, V72, P237, DOI 10.1006/cviu.1998.0678; Zomet A, 2000, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2000.854881	32	132	155	3	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1144	1154		10.1109/34.879794	http://dx.doi.org/10.1109/34.879794			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ		Green Submitted			2022-12-18	WOS:000165067100007
J	SOUCY, M; LAURENDEAU, D				SOUCY, M; LAURENDEAU, D			A GENERAL SURFACE APPROACH TO THE INTEGRATION OF A SET OF RANGE VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RANGE VIEWS; SURFACE INTEGRATION; TRIANGULATION; VENN DIAGRAM; VIEW INTEGRATION	REPRESENTATION	This paper presents a new and general solution to the problem of range view integration. The integration problem consists in computing a connected surface model from a set of registered range images acquired from different viewpoints. The proposed method does not impose constraints on the topology of the observed surfaces, the position of the viewpoints, or the number of views that can lie merged. The integrated surface model is piecewise estimated by a set of triangulations modeling each canonical subset of the Venn diagram of the set of range views. The connection of these local models by constrained Delaunay triangulations yields a non-redundant surface triangulation describing all surface elements sampled by the set of range views. Experimental results show that the integration technique can be used to build connected surface models of free-form objects. No integrated models built from objects of such complexity have yet been reported in the literature. It is assumed that accurate range views are available and that frame transformations between all pairs of views can be reliably computed.	UNIV LAVAL,QUEBEC CITY,PQ,CANADA	Laval University	SOUCY, M (corresponding author), INNOVMETR SOFTWARE INC,QUEBEC CITY,PQ,CANADA.							BERALDIN JA, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P163, DOI 10.1109/ICPR.1992.201532; BERGEVIN R, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P478, DOI 10.1109/ICPR.1992.201604; BESL PJ, 1988, SURFACES RANGE IMAGE; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BOISSONNAT JD, 1984, ACM T GRAPHIC, V3, P266, DOI 10.1145/357346.357349; CHEN Y, 1991, APR P IEEE INT C ROB, P2724; CHINN WG, 1966, 1ST CONCEPTS TOPOLOG, P16; De Floriani L., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P566, DOI 10.1109/ICPR.1988.28293; DEFLORIANI L, 1989, IEEE COMPUT GRAP MAR, P67; GAGNON H, 1994, JUN P IEEE C CVPR, P581; HOFFMANN CM, 1989, GEOMETRIC SOLID MODE, P13; HOPPE H, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011; HORN BKP, 1986, ROBOT VISION, P202; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KNUTH DE, 1975, ART COMPUTER PROGRAM, V3; LAURENDEAU D, 1987, IEEE T ROBOTIC AUTOM, V3, P459, DOI 10.1109/JRA.1987.1087125; Murdoch Joseph B, 1985, ILLUMINATION ENG; POTMESIL M, 1983, 8TH P INT JOINT C AI, P1089; Poussart D., 1989, ADV MACHINE VISION, P122; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; SIBSON R, 1978, COMPUT J, V21, P243, DOI 10.1093/comjnl/21.3.243; SOUCY M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P449, DOI 10.1109/ICPR.1992.201597; SOUCY M, 1992, MAY P IEEE INT C ROB, P1701; SOUCY M, 1991, P SPIE C INTELLIGENT, V10, P85; Soucy M., 1992, THESIS LAVAL U QUEBE; SOUCY M, 1992, JUN P IEEE C CVPR, P348; SZELISKI R, 1993, JUN P IEEE C CVPR, P82; VEMURI BC, 1986, JUN P C COMP VIS PAT, P435; Walsh J. W. T, 1958, PHOTOMETRY; YOKOYA N, 1989, IEEE T PATTERN ANAL, V11, P643, DOI 10.1109/34.24798	30	132	142	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					344	358		10.1109/34.385982	http://dx.doi.org/10.1109/34.385982			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800003
J	Hu, YQ; Mian, AS; Owens, R				Hu, Yiqun; Mian, Ajmal S.; Owens, Robyn			Face Recognition Using Sparse Approximated Nearest Points between Image Sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image set classification; face recognition; sparse modeling; convex optimization	PRINCIPAL ANGLES; FRAMEWORK	We propose an efficient and robust solution for image set classification. A joint representation of an image set is proposed which includes the image samples of the set and their affine hull model. The model accounts for unseen appearances in the form of affine combinations of sample images. To calculate the between-set distance, we introduce the Sparse Approximated Nearest Point (SANP). SANPs are the nearest points of two image sets such that each point can be sparsely approximated by the image samples of its respective set. This novel sparse formulation enforces sparsity on the sample coefficients and jointly optimizes the nearest points as well as their sparse approximations. Unlike standard sparse coding, the data to be sparsely approximated are not fixed. A convex formulation is proposed to find the optimal SANPs between two sets and the accelerated proximal gradient method is adapted to efficiently solve this optimization. We also derive the kernel extension of the SANP and propose an algorithm for dynamically tuning the RBF kernel parameter while matching each pair of image sets. Comprehensive experiments on the UCSD/Honda, CMU MoBo, and YouTube Celebrities face datasets show that our method consistently outperforms the state of the art.	[Hu, Yiqun; Mian, Ajmal S.; Owens, Robyn] Univ Western Australia, Sch Comp Sci & Software Engn M002, Nedlands, WA 6009, Australia	University of Western Australia	Hu, YQ (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn M002, 35 Stirling Highway, Nedlands, WA 6009, Australia.	yiqun@csse.uwa.edu.au; ajmal@csse.uwa.edu.au; robyn.owens@uwa.edu.au		Mian, Ajmal/0000-0002-5206-3842	ARC [DP1096801, DP0881813, DP110102399]	ARC(Australian Research Council)	This research was supported by ARC grants DP1096801, DP0881813, and DP110102399. The authors thank T. Kim for sharing the source code of DCC and R. Wang for sharing the source code of MMD and the cropped faces of the Honda/UCSD dataset. They also thank H. Cevikalp for sharing the source code of AHISD/CHISD and providing the LBP features for the Mobo dataset.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Arandjelovic O, 2005, PROC CVPR IEEE, P581; Arandjelovic O, 2009, COMPUT VIS IMAGE UND, V113, P113, DOI 10.1016/j.cviu.2008.07.010; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge JR, 2009, IEEE T PATTERN ANAL, V31, P351, DOI 10.1109/TPAMI.2008.200; Boiman O., 2008, P IEEE INT C COMP VI; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chin TJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P461; Fan W., 2006, IEEE COMP SOC C COMP, V2, P1384; Fitzgibbon AW, 2003, PROC CVPR IEEE, P26; Fukui K, 2006, LECT NOTES COMPUT SC, V3852, P315; Fukui K, 2007, LECT NOTES COMPUT SC, V4844, P467; Gross R, 2001, CMURITR0118; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hu Y., 2011, P IEEE INT C COMP VI; Juyang Weng, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P251, DOI 10.1109/AFGR.2000.840643; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Kim T. K., 2005, P BRIT MACH VIS C, P779; Kim TK, 2007, PATTERN RECOGN, V40, P2475, DOI 10.1016/j.patcog.2006.12.030; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kim TK, 2010, IEEE T IMAGE PROCESS, V19, P1067, DOI 10.1109/TIP.2009.2038621; KIM TK, 2006, P BRIT MACH VIS C, P559; Lee H, 2016, ADV NEURAL INFORM PR, V19; Lee KC, 2003, PROC CVPR IEEE, P313; Li X, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1132; Liu XM, 2003, PROC CVPR IEEE, P340; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Mika S., 2000, P ANN C NEUR INF PRO, P801; Nesterov Y E, 2007, 2007076 U CATH LOUV; Nishiyama M, 2005, LECT NOTES COMPUT SC, V3546, P71; Nishiyama M., 2007, P IEEE C COMP VIS PA, P1; OJA E, 1983, SUBSPACE METHODS PAT; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Vapnik V.N, 1998, STAT LEARNING THEORY; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WANG R, 2008, P IEEE INT C COMP VI; Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850; Wang TS, 2009, PATTERN RECOGN LETT, V30, P1161, DOI 10.1016/j.patrec.2009.06.002; Wolf L, 2004, J MACH LEARN RES, V4, P913, DOI 10.1162/1532443041827934; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xi Li, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P323; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968; Zhou SH, 2002, LECT NOTES COMPUT SC, V2352, P681	49	131	146	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1992	2004		10.1109/TPAMI.2011.283	http://dx.doi.org/10.1109/TPAMI.2011.283			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22213765				2022-12-18	WOS:000307522700010
J	Prince, SJD; Elder, JH; Warrell, J; Felisberti, FM				Prince, Simon J. D.; Elder, James H.; Warrell, Jonathan; Felisberti, Fatima M.			Tied factor analysis for face recognition across large pose differences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computing methodologies; pattern recognition; applications; face and gesture recognition		Face recognition algorithms perform very unreliably when the pose of the probe face is different from the gallery face: typical feature vectors vary more with pose than with identity. We propose a generative model that creates a one-to-many mapping from an idealized "identity" space to the observed data space. In identity space, the representation for each individual does not vary with pose. We model the measured feature vector as being generated by a pose-contingent linear transformation of the identity variable in the presence of Gaussian noise. We term this model "tied" factor analysis. The choice of linear transformation (factors) depends on the pose, but the loadings are constant (tied) for a given individual. We use the EM algorithm to estimate the linear transformations and the noise parameters from training data. We propose a probabilistic distance metric that allows a full posterior over possible matches to be established. We introduce a novel feature extraction process and investigate recognition performance by using the FERET, XM2VTS, and PIE databases. Recognition performance compares favorably with contemporary approaches.	[Prince, Simon J. D.; Warrell, Jonathan] UCL, Dept Comp Sci, London WC1E 6BT, England; [Elder, James H.] York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada; [Felisberti, Fatima M.] Kingston Univ, Dept Psychol, Kingston upon Thames KT1 2EE, Surrey, England	University of London; University College London; York University - Canada; Kingston University	Prince, SJD (corresponding author), UCL, Dept Comp Sci, London WC1E 6BT, England.	s.prince@cs.ucl.ac.uk; j.warrell@cs.ucl.ac.uk; jelder@yorku.ca; f.felisberti@kingston.ac.uk	Felisberti, Fatima M/F-3166-2010	Felisberti, Fatima M/0000-0002-8703-4400				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beymer D., 1993, AIM1461 MIT; BEYMER D, 1995, AIM1536 MIT; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Blanz V, 2005, PROC CVPR IEEE, P454; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Elder JH, 2007, INT J COMPUT VISION, V72, P47, DOI 10.1007/s11263-006-8892-7; Fukui K., 2003, P INT S ROB RES, P192; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Kanade T, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P954; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; LI Y, 2001, P IEEE C COMP VIS PA, V2, P258; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66; Lucey S., 2006, P IEEE INT C COMP VI, P17; MACKAY D, 2003, INFORM THEORY LEARNI; MAURER T, 1995, P INT WORKHS AUT FAC, P80; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011; PHILLIPS P, 2003, FRVT EVALUATION REPO; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Prince SJD, 2005, PROC CVPR IEEE, P446; ROMDHANI S, 2002, P 7 EUR C COMP VIS; Sanderson C, 2006, PATTERN RECOGN, V39, P288, DOI 10.1016/j.patcog.2005.07.001; Sim T, 2001, CMURITR0102; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Vasilescu MAO, 2002, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2002.1048350; VIOLA P, 2004, INT J COMPUT VISION, V57, P1473; Wallhoff F, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P149, DOI 10.1109/RATFG.2001.938924; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; YAMBOR W, 2000, P 2 WORKSH EMP EV ME; YANG M, 2002, P 5 IEEE INT C FAC G; Zhang L, 2004, P ECCV INT WORKSH BI; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHAO W, 2002, P INT C AUT FAC GEST, P285; ZHOU S, 2002, P IEEE INT C COMP VI, V2, P805	43	131	144	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					970	984		10.1109/TPAMI.2008.48	http://dx.doi.org/10.1109/TPAMI.2008.48			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421104	Green Accepted			2022-12-18	WOS:000254872500004
J	Quelhas, P; Monay, F; Odobez, JM; Gatica-Perez, D; Tuytelaars, T				Quelhas, Pedro; Monay, Florent; Odobez, Jean-Marc; Gatica-Perez, Daniel; Tuytelaars, Tinne			A thousand words in a scene	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image representation; scene classification; object recognition; quantized local descriptors; latent aspect modeling		This paper presents a novel approach for visual scene modeling and classification, investigating the combined use of text modeling methods and local invariant features. Our work attempts to elucidate 1) whether a textlike bag-of-visterms (BOV) representation (histogram of quantized local visual features) is suitable for scene (rather than object) classification, 2) whether some analogies between discrete scene representations and text documents exist, and 3) whether unsupervised, latent space models can be used both as feature extractors for the classification task and to discover patterns of visual co-occurrence. Using several data sets, we validate our approach, presenting and discussing experiments on each of these issues. We first show, with extensive experiments on binary and multiclass scene classification tasks using a 9,500-image data set, that the BOV representation consistently outperforms classical scene classification approaches. In other data sets, we show that our approach competes with or outperforms other recent more complex methods. We also show that Probabilistic Latent Semantic Analysis (PLSA) generates a compact scene representation, is discriminative for accurate classification, and is more robust than the BOV representation when less labeled training data is available. Finally, through aspect-based image ranking experiments, we show the ability of PLSA to automatically extract visually meaningful scene patterns, making such representation useful for browsing image collections.	IDIAP, Res Inst, CH-1920 Martigny, Switzerland; ESAT PSI, B-3001 Louvain, Belgium		Quelhas, P (corresponding author), IDIAP, Res Inst, Rue Simplon 4,Case Postale 592, CH-1920 Martigny, Switzerland.	pedro.quelhas@idiap.ch; florent.monay@idiap.ch; jean-marc.odobez@idiap.ch; gatica@idiap.ch; Tinne.Tuytelaars@esat.kuleuven.be	Odobez, Jean-Marc/B-1426-2010; Tuytelaars, Tinne/B-4319-2015	Tuytelaars, Tinne/0000-0003-3307-9723				Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BLEI D, 2003, P 26 INT C RES DEV I; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; DORKO G, 2003, P IEEE INT C COMP VI; FAUQUEUR J, 2003, P INT C IM PROC OCT; Fei-Fei L., 2004, P IEEE INT C COMP VI; FEIFEI L, 2003, P IEEE INT C COMP VI; Feifei L., 2005, 2005 IEEE COMP SOC C, P524, DOI [10.1109/CVPR.2005.16, DOI 10.1109/CVPR.2005.16]; FERGUS R, 2003, P IEEE INT C COMP VI; GORKANI M, 1994, P INT C PATT REC SEP; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Kumar S., 2003, P IEEE INT C COMP VI; Leibe B, 2003, P BRIT MACH VIS C SE; LIM JH, 2004, P EUR C COMP VIS ECC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; MIKOLAJCZYK K, 2003, P IEEE INT C COMP VI; MONAY F, 2004, P ACM INT C MULT OCT; MONAY F, 2005, P PATT AN STAT MOD C; MONAY F, 2003, P ACM INT C MULT NOV; Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; OPELT A, 2004, P IEEE EUR C COMP VI; PAEK S, 2000, P IEEE INT C MULT EX; Quelhas P, 2005, IEEE I CONF COMP VIS, P883; SCHAFFALITZKY F, 2002, P INT C PATT REC AUG; SHAO H, 2003, P IEEE INT C IM PROC; SIVIC J, 2004, P IEEE INT C COMP VI; Sivic J, 2003, P IEEE INT C COMP VI; SMEATON A, 2002, P TEXT RETR C NOV; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Sophia T., 2005, THESIS J GUTENBERG U; Szummer M., 1998, P IEEE INT WORKSH CO; TORRALBA A, 2003, P IEEE INT C COMP VI; TUYTELAARS T, 1999, P VIS 99 JUN; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; VOGEL J, 2004, P INT C IM VID RETR; Weston J., 1998, CSDTR9804 U LOND DEP; WILLAMOWSKI J, 2004, P LEARN AD VIS SYST; ZHANG R, 2004, P C COMP VIS PATT RE	43	131	151	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1575	1589		10.1109/TPAMI.2007.1155	http://dx.doi.org/10.1109/TPAMI.2007.1155			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627045	Green Submitted, Green Accepted			2022-12-18	WOS:000247965600007
J	Miyazaki, D; Kagesawa, M; Ikeuchi, K				Miyazaki, D; Kagesawa, M; Ikeuchi, K			Transparent surface modeling from a pair of polarization images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; computer vision	ORIENTATIONS; REFLECTANCE; OBJECTS	We propose a method for measuring surface shapes of transparent objects by using a polarizing filter. Generally, the light reflected from an object is partially polarized. The degree of polarization depends upon the incident angle, which, in turn, depends upon the surface normal. Therefore, we can obtain surface normals of objects by observing the degree of polarization at each surface point. Unfortunately, the correspondence between the degree of polarization and the surface normal is not one to one. Hence, to obtain the correct surface normal, we have to solve the ambiguity problem. In this paper, we introduce a method to solve the ambiguity by comparing the polarization data in two objects, i.e., normal position and tilted with small angle position. We also discuss the geometrical features of the object surface and propose a method for matching two sets of polarization data at identical points on the object surface.	Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan	University of Tokyo	Miyazaki, D (corresponding author), Univ Tokyo, Inst Ind Sci, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	miyazaki@cvl.iis.u-tokyo.ac.jp; kagesazva@cvl.iis.u-tokyo.ac.jp; ki@cvl.iis.u-tokyo.ac.jp						BALLARD DH, 1982, COMPUTER VISION, P523; Born M., 1959, PRINCIPLE OPTICS, P803; Chuang YY, 2000, COMP GRAPH, P121, DOI 10.1145/344779.344844; DOCARMO MP, 1976, DIFFERENTIAL GEOMETR, P503; GONZALEZ RC, 1993, DIGITAL IMAGE PROCES, P716; Horn B. K. P., 1986, ROBOT VISION, P509; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; IKEUCHI K, 1984, P INT C PATT REC, P736; Koshikawa K., 1987, Advanced Robotics, V2, P137, DOI 10.1163/156855387X00129; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Rahmann S, 2001, PROC CVPR IEEE, P149; Saito M, 1999, J OPT SOC AM A, V16, P2286, DOI 10.1364/JOSAA.16.002286; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; Schechner Y. Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P814, DOI 10.1109/ICCV.1999.790305; SHACKELFORD JF, 1994, CRC MAT SCI ENG HDB, P883; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WATUSIK W, 2002, P EUROGRAPHICS WORKS, P267; WEXLER Y, 2002, P EUR WORKSH REND, P289; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705; Zongker DE, 1999, COMP GRAPH, P205, DOI 10.1145/311535.311558; [No title captured]	25	131	139	4	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					73	82		10.1109/TPAMI.2004.1261080	http://dx.doi.org/10.1109/TPAMI.2004.1261080			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382687	Green Submitted			2022-12-18	WOS:000187161400006
J	CROWLEY, JL; PARKER, AC				CROWLEY, JL; PARKER, AC			A REPRESENTATION FOR SHAPE BASED ON PEAKS AND RIDGES IN THE DIFFERENCE OF LOW-PASS TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90007	University of Southern California	CROWLEY, JL (corresponding author), CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213, USA.							ABRAMATIC JF, 1982, IEEE T ACOUST SPEECH, V30, P1, DOI 10.1109/TASSP.1982.1163840; AGIN GJ, 1971, THESIS STANFORD U; AHO AV, 1974, COMPUTER SCI INFORMA; BARROW HG, 1978, 153 SRI INT TECH NOT; BINFORD TO, 1982, ROBOTICS RES, V1, P18; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; BURT PJ, 1980, TR860 U MAR COMP VIS; CAMPBELL FW, 1974, TRANSMISSION SPATIAL; CAMPBELL FW, 1971, J PHYSL, P551; Crowley J., 1980, Issues in Digital Image Processing. Proceedings of the NATO Advanced Study Institute on Digital Image Processing and Analysis, P3; CROWLEY JL, UNPUB IEEE T PATTERN; CROWLEY JL, 1978, JUN P C PATT REC IM, P372; Crowley JL, 1981, THESIS CARNEGIE MELL; HALL EL, 1976, 1976 P IEEE C DEC CO, P791; HANSON AR, 1978, COMPUTER VISION SYST, P758; Kelly M., 1971, MACHINE INTELLIGENCE; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1979, P ROYAL SOC LONDON B; Marr D., 1982, VISION; MORAVEC HP, 1980, THESIS STANFORD U; Nyquist H, 1924, BELL SYST TECH J, V3, P324, DOI 10.1002/j.1538-7305.1924.tb01361.x; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; Paley R.E.A.C., 1934, FOURIER TRANSFORMS C; PAPOULIS A, 1968, SYSTEMS SCI SYSTEMS; PRATT WK, 1978, DIGITAL IMAGE PROCES, P322; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; SACHS MB, 1971, J OPT SOC AM, V61, P1176, DOI 10.1364/JOSA.61.001176; TANIMOTO SL, 1975, COMPUT GRAPHICS IMAG, V4, P165; THOMAS JP, 1975, SPATIAL RESOLUTION S; UHR L, 1972, IEEE T COMPUT, VC 21, P758, DOI 10.1109/T-C.1972.223579	32	131	137	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					156	170		10.1109/TPAMI.1984.4767500	http://dx.doi.org/10.1109/TPAMI.1984.4767500			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869180	Green Published			2022-12-18	WOS:A1984SF59100003
J	Zitnik, M; Zupan, B				Zitnik, Marinka; Zupan, Blaz			Data Fusion by Matrix Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data fusion; intermediate data integration; matrix factorization; data mining; bioinformatics; cheminformatics	INFORMATION FUSION; DISCOVERY; NETWORKS; KNOWLEDGE; FRAMEWORK; MODULES; CANCER	For most problems in science and engineering we can obtain data sets that describe the observed system from various perspectives and record the behavior of its individual components. Heterogeneous data sets can be collectively mined by data fusion. Fusion can focus on a specific target relation and exploit directly associated data together with contextual data and data about system's constraints. In the paper we describe a data fusion approach with penalized matrix tri-factorization (DFMF) that simultaneously factorizes data matrices to reveal hidden associations. The approach can directly consider any data that can be expressed in a matrix, including those from feature-based representations, ontologies, associations and networks. We demonstrate the utility of DFMF for gene function prediction task with eleven different data sources and for prediction of pharmacologic actions by fusing six data sources. Our data fusion algorithm compares favorably to alternative data integration approaches and achieves higher accuracy than can be obtained from any single data source alone.	[Zitnik, Marinka; Zupan, Blaz] Univ Ljubljana, Fac Comp & Informat Sci, SI-1000 Ljubljana, Slovenia; [Zupan, Blaz] Baylor Coll Med, Dept Mol & Human Genet, Houston, TX 77030 USA	University of Ljubljana; Baylor College of Medicine	Zitnik, M (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SI-1000 Ljubljana, Slovenia.	marinka.zitnik@fri.uni-lj.si; blaz.zupan@fri.uni-lj.si	Zupan, Blaz/L-1595-2019		ARRS [P2-0209, J2-5480]; NIH [P01-HD39691]; EU [Health-F5-2010-242038]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT [P01HD039691] Funding Source: NIH RePORTER	ARRS(Slovenian Research Agency - Slovenia); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); EU(European Commission); EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD))	The authors thank Janez Demsar and Gad Shaulsky for their comments on the early version of this manuscript. They also acknowledge the support for their work from the ARRS (P2-0209, J2-5480), NIH (P01-HD39691), and EU (Health-F5-2010-242038).	Aerts S, 2006, NAT BIOTECHNOL, V24, P537, DOI 10.1038/nbt1203; Albright R., 2006, 81706 N CAR STAT U D; Alexeyenko A, 2009, GENOME RES, V19, P1107, DOI 10.1101/gr.087528.108; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Bach F.R., 2004, P 21 INT C MACHINE L, P6, DOI 10.1145/ 1015330.1015424; Bostrom H, 2007, DEFINITION INFORM FU; Boulesteix AL, 2008, BIOINFORMATICS, V24, P1698, DOI 10.1093/bioinformatics/btn262; Boutsidis C, 2008, PATTERN RECOGN, V41, P1350, DOI 10.1016/j.patcog.2007.09.010; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Carpenter GA, 2005, NEURAL NETWORKS, V18, P287, DOI 10.1016/j.neunet.2004.12.003; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; Chen Z, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002956; Debnath R, 2004, IEICE T INF SYST, VE87D, P2903; Gevaert O, 2006, BIOINFORMATICS, V22, pE184, DOI 10.1093/bioinformatics/btl230; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Greene D, 2009, LECT NOTES ARTIF INT, V5781, P423, DOI 10.1007/978-3-642-04180-8_45; Hua Wang, 2012, Research in Computational Molecular Biology. Proceedings 16th Annual International Conference, RECOMB 2012, P314, DOI 10.1007/978-3-642-29627-7_33; Hutchins LN, 2008, BIOINFORMATICS, V24, P2684, DOI 10.1093/bioinformatics/btn526; Huttenhower C, 2009, BIOINFORMATICS, V25, P3267, DOI 10.1093/bioinformatics/btp588; Iorio F, 2010, P NATL ACAD SCI USA, V107, P14621, DOI 10.1073/pnas.1000138107; Kanehisa M, 2014, NUCLEIC ACIDS RES, V42, pD199, DOI 10.1093/nar/gkt1076; Klami A, 2008, NEUROCOMPUTING, V72, P39, DOI 10.1016/j.neucom.2007.12.044; Kloft M, 2011, J MACH LEARN RES, V12, P953; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; Lange T., 2005, P ADV NEUR INF PROC, P723; Law V, 2014, NUCLEIC ACIDS RES, V42, pD1091, DOI 10.1093/nar/gkt1068; Lee D. D., 2000, NIPS, V13, P535; Leskovec J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1361; Li W.-j., 2007, P 20 INT JOINT C ART, P1126; Lopes HF, 2011, COMPUT STAT DATA AN, V55, P1319, DOI 10.1016/j.csda.2010.09.020; Luttinen J., 2009, ADV NEURAL INFORM PR, P1177; Marius K., 2009, NIPS, P997; Mostafavi S, 2012, PROTEOMICS, V12, P1687, DOI 10.1002/pmic.201100607; Nickel M., 2011, INT C INT C MACH LEA, P809, DOI DOI 10.5555/3104482.3104584; Notebaart RA, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-2-r19; Pandey G, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000928; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; Parikh A, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-3-r35; Parikh D, 2007, IEEE T SYST MAN CY B, V37, P437, DOI 10.1109/TSMCB.2006.883873; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Radivojac P, 2013, NAT METHODS, V10, P221, DOI [10.1038/NMETH.2340, 10.1038/nmeth.2340]; Rappaport SM, 2010, SCIENCE, V330, P460, DOI 10.1126/science.1192603; Rendle S, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P635; Rettinger A, 2012, SOC NETW ANAL MIN, V2, P373, DOI 10.1007/s13278-012-0069-5; Savage RS, 2010, BIOINFORMATICS, V26, pi158, DOI 10.1093/bioinformatics/btq210; Singh A., 2010, P UAI, P556; Singh A.P., 2008, PROC PROC 14 ACM SIG, P650; Singh AP, 2008, LECT NOTES ARTIF INT, V5212, P358, DOI 10.1007/978-3-540-87481-2_24; Sutskever I., 2009, P 22 INT C NEURAL IN, P1821; Tang L, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P244, DOI 10.1109/MINES.2009.194; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; Van Benthem MH, 2004, J CHEMOMETR, V18, P441, DOI 10.1002/cem.889; van Vliet MH, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040358; Wang H., 2011, P 20 ACM INT C INFOR, P279; Wang YL, 2009, NUCLEIC ACIDS RES, V37, pW623, DOI 10.1093/nar/gkp456; Xing CH, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002110; Ye JP, 2008, J MACH LEARN RES, V9, P719; Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255; Yu S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-309; Zhang C., 2008, SDM, P1, DOI DOI 10.1137/1.9781611972788.1; Zhang SH, 2012, NUCLEIC ACIDS RES, V40, P9379, DOI 10.1093/nar/gks725; Zhang SH, 2011, BIOINFORMATICS, V27, pI401, DOI 10.1093/bioinformatics/btr206; Zhang YM, 2006, IEEE T SYST MAN CY B, V36, P467, DOI 10.1109/TSMCB.2005.859081; Zhou D., 2007, P 24 INT C MACHINE L, P1159, DOI DOI 10.1145/1273496.1273642	68	130	131	1	88	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					41	53		10.1109/TPAMI.2014.2343973	http://dx.doi.org/10.1109/TPAMI.2014.2343973			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353207	Green Submitted			2022-12-18	WOS:000346970600005
J	Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC				Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC			Probabilistic finite-state machines - Part I	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automata; classes defined by grammars or automata; machine learning; language acquisition; language models; language parsing and understanding; machine translation; speech recognition and synthesis; structural pattern recognition; syntactic pattern recognition	HIDDEN MARKOV-MODELS; GRAMMATICAL INFERENCE; GRAMMARS	Probabilistic finite- state machines are used today in a variety of areas in pattern recognition, or in fields to which pattern recognition is linked: computational linguistics, machine learning, time series analysis, circuit testing, computational biology, speech recognition, and machine translation are some of them. In Part I of this paper, we survey these generative objects and study their definitions and properties. In Part II, we will study the relation of probabilistic finite- state automata with other well- known devices that generate strings as hidden Markov models and n- grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.	Univ Politecn Valencia, Dept Sistemas Informat & Computac, E-46071 Valencia, Spain; Univ Politecn Valencia, Inst Informat Technol, E-46071 Valencia, Spain; EURISE, Fac Sci & Tech, FR-42023 St Etienne, France; Univ Alicante, Dept Lenguajes & Sistemas Informat, E-03071 Alicante, Spain	Universitat Politecnica de Valencia; Universitat Politecnica de Valencia; Universitat d'Alacant	Vidal, E (corresponding author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Camino Vera S-N, E-46071 Valencia, Spain.	evidal@iti.upv.es; Franck.Thollard@univ-st-etienne.fr; Colin.Delahiguera@univ-st-etienne.fr; fcn@iti.upv.es; carrasco@dlsi.ua.es	Casacuberta, Francisco/T-3667-2017	Casacuberta, Francisco/0000-0002-8497-5598; , Colin/0000-0002-1703-9572				Abe H, 2001, ARTIF CELL BLOOD SUB, V29, P275, DOI 10.1081/BIO-100104230; ABE N, 1998, P 3 WORKSH COMP LEAR, P52; Alshawi H., 2000, Machine Translation, V15, P105, DOI 10.1023/A:1011187330969; ALSHAWI H, 2000, COMPUTATIONAL LINGUI, V26; Amengual J. C., 2000, Machine Translation, V15, P75, DOI 10.1023/A:1011116115948; Angluin D, 1988, YALEUDCSRR614; [Anonymous], 1998, STAT METHODS SPEECH; [Anonymous], 1994, INTRO COMPUTATIONAL; BANGALORE S, 2001, P NORTH AM ASS C MAY; Bangalore S., 2000, P WORKSH EMB MACH TR, P52; Bengio Y, 2001, IEEE T NEURAL NETWOR, V12, P113, DOI 10.1109/72.896800; Blondel VD, 2003, THEOR COMPUT SYST, V36, P231, DOI 10.1007/s00224-003-1061-2; Brehelin L, 2001, IEEE T PATTERN ANAL, V23, P997, DOI 10.1109/34.955112; Brown P. F., 1992, Computational Linguistics, V18, P467; CARRASCO R, 1994, P 2 INT C GRAMM INF, P139; Carrasco RC, 1999, RAIRO-INF THEOR APPL, V33, P1, DOI 10.1051/ita:1999102; Carrasco RC, 1997, RAIRO-INF THEOR APPL, V31, P437, DOI 10.1051/ita/1997310504371; Casacuberta F, 2000, LECT NOTES ARTIF INT, V1891, P15; CASACUBERTA F, 1990, IEEE T PATTERN ANAL, V12, P691, DOI 10.1109/34.56212; CASACUBERTA F, 2003, COMPUTER SPEECH LANG; COOK C, 1974, NATO ASI COMPUTER OR, P157; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DelaHiguera C, 1997, MACH LEARN, V27, P125, DOI 10.1023/A:1007353007695; DELAHIGUERA C, 2003, 0301 EURISE U SAINTE; DUPONT P, 2004, PATTERN RECOGNITION; FORNEY GD, 1973, IEEE P, V3, P268, DOI DOI 10.1109/PR0C.1973.9030; Fred ALN, 2000, LECT NOTES ARTIF INT, V1891, P103; Fu K.S., 1974, MATH SCI ENG; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FU KS, 1982, SYNTACTIC PATTERN RE; GALLEGUER RG, 1996, DISCRETE STOCHASTIC; Goodman J. T., 2001, BIT PROGR LANGUAGE M; Harrison M. A., 1978, INTRO FORMAL LANGUAG; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, P433, DOI 10.1145/73007.73049; Kearns M., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, P273, DOI 10.1145/195058.195155; Kneser Reinhard, 1993, P EUR C SPEECH COMM, P973; Knill K, 1997, TEXT SPEECH LANG TEC, V2, P27; LUCAS S, 1994, P 2 INT C GRAMM INF, P168; LYNGSO RB, 1999, P INTELLIGENT SYSTEM; LYNGSO RB, 2001, P 12 ANN INT S ALG C; MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2111, DOI 10.1109/78.134449; Merhav N., 1991, Computer Speech and Language, V5, P327, DOI 10.1016/0885-2308(91)90002-8; MICHLET L, 1987, STRUCTURAL METHODS P; Mohri M, 1997, COMPUT LINGUIST, V23, P269; Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6; Ney H, 1997, TEXT SPEECH LANG TEC, V2, P174; NEY H, 1992, P NATO ADV STUDY I, P313; PAREDAENS JJ, 1974, COMPUTING, V13, P93, DOI 10.1007/BF02246610; Paz A., 1971, INTRO PROBABILISTIC; RABIN MO, 1963, INFORM CONTROL, V6, P230, DOI 10.1016/S0019-9958(63)90290-0; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RON D, 1995, MACH LEARN, V18, P149, DOI 10.1007/BF00993409; Ron D., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, P31, DOI 10.1145/225298.225302; Ron D., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, P35, DOI 10.1145/180139.181006; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; SAUL L, 1997, P 2 C EMP METH NAT L, P81; THOMASON MG, 1976, CS7617 U TENNESSEE C; TZENG WG, 1992, SIAM J COMPUT, V21, P216, DOI 10.1137/0221017; Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1026, DOI 10.1109/TPAMI.2005.148; Vidal E., 1998, P INT C GRAMM INF, P211; WETHERELL C, 1980, COMPUTING SURVEYS, V12; Young-Lai M, 2000, MACH LEARN, V40, P111, DOI 10.1023/A:1007653929870	63	130	136	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1013	1025		10.1109/TPAMI.2005.147	http://dx.doi.org/10.1109/TPAMI.2005.147			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013750	Green Submitted			2022-12-18	WOS:000229024300002
J	Robles-Kelly, A; Hancock, ER				Robles-Kelly, A; Hancock, ER			Graph edit distance from spectral seriation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph edit distance; graph seriation; maximum a posteriori probability (MAP); graph-spectral methods	OBJECT RECOGNITION; ALGORITHM; SHAPE; RELAXATION	This paper is concerned with computing graph edit distance. One of the criticisms that can be leveled at existing methods for computing graph edit distance is that they lack some of the formality and rigor of the computation of string edit distance. Hence, our aim is to convert graphs to string sequences so that string matching techniques can be used. To do this, we use a graph spectral seriation method to convert the adjacency matrix into a string or sequence order. We show how the serial ordering can be established using the leading eigenvector of the graph adjacency matrix. We pose the problem of graph-matching as a maximum a posteriori probability (MAP) alignment of the seriation sequences for pairs of graphs. This treatment leads to an expression in which the edit cost is the negative logarithm of the a posteriori sequence alignment probability. We compute the edit distance by finding the sequence of string edit operations which minimizes the cost of the path traversing the edit lattice. The edit costs are determined by the components of the leading eigenvectors of the adjacency matrix and by the edge densities of the graphs being matched. We demonstrate the utility of the edit distance on a number of graph clustering problems.	Natl ICT Australia, Canberra Lab, Canberra, ACT 2601, Australia; Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	NICTA; University of York - UK	Robles-Kelly, A (corresponding author), Natl ICT Australia, Canberra Lab, Canberra, ACT 2601, Australia.	Antonio.Robles-Kelly@nicta.com.us; erh@cs.york.ac.uk	Hancock, Edwin R/C-6071-2008; Robles-Kelly, Antonio/A-2459-2009; Hancock, Edwin/N-7548-2019	Hancock, Edwin R/0000-0003-4496-2028; Robles-Kelly, Antonio/0000-0002-2465-5971; Hancock, Edwin/0000-0003-4496-2028				Atkins JE, 1998, SIAM J COMPUT, V28, P297, DOI 10.1137/S0097539795285771; Bagdanov AD, 2003, PATTERN RECOGN, V36, P1311, DOI 10.1016/S0031-3203(02)00227-3; Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3; Bunke H, 1999, PATTERN RECOGN LETT, V20, P1271, DOI 10.1016/S0167-8655(99)00094-X; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1139, DOI 10.1109/34.625116; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; Finch AM, 1998, NEURAL COMPUT, V10, P1873, DOI 10.1162/089976698300017188; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Horaud R, 1995, PATTERN RECOGN, V28, P1855, DOI 10.1016/0031-3203(95)00048-8; Huet B, 2002, PATTERN RECOGN, V35, P1895, DOI 10.1016/S0031-3203(01)00172-8; Keuchel J, 2003, IEEE T PATTERN ANAL, V25, P1364, DOI 10.1109/TPAMI.2003.1240111; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; LOVASZ L, 1993, BOLYAI SOC MATH STUD, V2, P1; Luo B, 2003, PATTERN RECOGN, V36, P2213, DOI 10.1016/S0031-3203(03)00084-0; Luo B, 1999, PATTERN RECOGN LETT, V20, P635, DOI 10.1016/S0167-8655(99)00028-8; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; Mardia K.V., 2000, DIRECTIONAL STAT; MOHAR B, 1997, NATO ASI SER C-MATH, P272; Myers R, 2000, IEEE T PATTERN ANAL, V22, P628, DOI 10.1109/34.862201; Robles-Kelly A, 2004, INT J PATTERN RECOGN, V18, P315, DOI 10.1142/S0218001404003277; Robles-Kelly A, 2004, PATTERN RECOGN, V37, P1387, DOI 10.1016/j.patcog.2003.10.017; Robles-Kelly A, 2002, INT C PATT RECOG, P639, DOI 10.1109/ICPR.2002.1048383; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SELMAN B, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P337; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; SHAPIRO LS, 1991, P 2 BRIT MACH VIS C, P78; SHOKOUFANDEH A, 1998, P COMP VIS PATT REC, P491; STEINMANN O, 1997, P ADV ARTIFICIAL INT, P337; Stewart G., 1990, MATRIX PERTURBATION; TUCERYAN M, 1991, PATTERN RECOGN, V24, P361, DOI 10.1016/0031-3203(91)90050-F; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Varga R.S., 2000, MATRIX ITERATIVE ANA; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; Wilson RC, 1996, PATTERN RECOGN LETT, V17, P263, DOI 10.1016/0167-8655(95)00115-8; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; Yin PY, 1998, PATTERN RECOGN LETT, V19, P31, DOI 10.1016/S0167-8655(97)00154-2	45	130	141	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					365	378		10.1109/TPAMI.2005.56	http://dx.doi.org/10.1109/TPAMI.2005.56			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747792	Green Submitted, Green Accepted			2022-12-18	WOS:000226300200006
J	Girolami, M; He, C				Girolami, M; He, C			Probability density estimation from optimally condensed data samples	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel density estimation; Parzen window; data condensation; sparse representation	KERNEL; SUPPORT	The requirement to reduce the computational cost of evaluating a point probability density estimate when employing a Parzen window estimator is a well-known problem. This paper presents the Reduced Set Density Estimator that provides a kernel-based density estimator which employs a small percentage of the available data sample and is optimal in the L-2 sense. While only requiring O(N-2) optimization routines to estimate the required kernel weighting coefficients, the proposed method provides similar levels of performance accuracy and sparseness of representation as Support Vector Machine density estimation, which requires optimization routines, and which has previously been shown to consistently outperform Gaussian Mixture Models. It is also demonstrated that the proposed density estimator consistently provides superior density estimates for similar levels of data reduction to that provided by the recently proposed Density-Based Multiscale Data Condensation algorithm and, in addition, has comparable computational scaling. The additional advantage of the proposed method is that no extra free parameters are introduced such as regularization, bin width, or condensation ratios, making this method a very simple and straightforward approach to providing a reduced set density estimator with comparable accuracy to that of the full sample Parzen density estimator.	Univ Paisley, Sch Informat & Commun Technol, Appl Computat Intelligence Res Unit, Paisley PA1 2BE, Renfrew, Scotland	University of West Scotland	Girolami, M (corresponding author), Univ Paisley, Sch Informat & Commun Technol, Appl Computat Intelligence Res Unit, High St, Paisley PA1 2BE, Renfrew, Scotland.	mark.girolami@paisley.ac.uk; chao.he@paisley.uk		Girolami, Mark/0000-0003-3008-253X				ASTRAHAN MM, 1970, SPEECH ANAL CLUSTERI; Babich GA, 1996, IEEE T PATTERN ANAL, V18, P567, DOI 10.1109/34.494647; Bishop, 1995, NEURAL NETWORKS PATT; ELGAMMAL E, 2000, P 6 EUR C COMP VIS, P751; FUKUDA K, 1989, TRENDS PHARM SCI S, V11, P4; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115, DOI 10.1109/TPAMI.1984.4767485; Girolami M, 2002, NEURAL COMPUT, V14, P669, DOI 10.1162/089976602317250942; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Holmstrom L, 2000, J MULTIVARIATE ANAL, V72, P264, DOI 10.1006/jmva.1999.1863; HOLMSTROM L, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P417, DOI 10.1109/ICNN.1993.298593; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; JEON BW, 1994, IEEE T PATTERN ANAL, V16, P950, DOI 10.1109/34.310693; KIM D, 1995, THESIS VIRGINIA POLY; Kohonen T., 1995, SELF ORG MAPS; Lambert CG, 1999, ALGORITHMICA, V25, P37, DOI 10.1007/PL00009282; Lehmann E, 1975, NONPARAMETRIC STAT M; Mclachlan G., 2000, WILEY SER PROB STAT; Mitra P, 2002, IEEE T PATTERN ANAL, V24; MUKHERJEE S, 1999, 170 CBCL; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Priebe CE, 2000, COMPUT STAT DATA AN, V35, P43, DOI 10.1016/S0167-9473(00)00003-7; Roberts SJ, 2000, IEE P-SCI MEAS TECH, V147, P363, DOI 10.1049/ip-smt:20000841; SAIN SR, 1994, THESIS RICE U; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scott D.W., 1999, COMPUT SCI STAT, P104; SCOTT DW, 1985, COMMUN STAT-THEOR M, V14, P1353, DOI 10.1080/03610928508828980; SCOTT DW, TECNOMETRICS, V43, P323; SHA F, 2002, MSCIS0219 U PENNS; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; SILVERMAN BW, 1982, APPL STAT-J ROY ST C, V31, P93, DOI 10.2307/2347084; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Vapnik V.N, 1998, STAT LEARNING THEORY; Vapnik VN, 2000, ADV NEUR IN, V12, P659; WESTON J, 1999, ADV KERNEL METHODS	35	130	153	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1253	1264		10.1109/TPAMI.2003.1233899	http://dx.doi.org/10.1109/TPAMI.2003.1233899			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE		Green Submitted, Green Accepted			2022-12-18	WOS:000185460800005
J	Lhuillier, M; Quan, L				Lhuillier, M; Quan, L			Match propagation for image-based modeling and rendering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						quasi-dense matching; stereo vision; image-based modeling; rendering	ALGORITHM; STEREO; POINTS	This paper presents a quasi-dense matching algorithm between images based on the match propagation principle. The algorithm starts from a set of sparse seed matches, then propagates to the neighboring pixels by the best-first strategy, and produces a quasi-dense disparity map. The quasi-dense matching aims at broad modeling and visualization applications which rely heavily on matching information. Our algorithm is robust to initial sparse match outliers due to the best-first strategy. It is efficient in time and space as it is only output sensitive. It handles half-occluded areas because of the simultaneous enforcement of newly introduced discrete 2D gradient disparity limit and the uniqueness constraint. The properties of the algorithm are discussed and empirically demonstrated. The quality of quasi-dense matching are validated through intensive real examples.	HKUST, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Hong Kong University of Science & Technology	Lhuillier, M (corresponding author), HKUST, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	maxime@cs.ust.hk; quan@cs.ust.hk						ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Avidan S, 1997, PROC CVPR IEEE, P1034, DOI 10.1109/CVPR.1997.609457; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BOYKOV Y, 1998, P C COMP VIS PATT RE, P470; BURT P, 1980, SCIENCE, V208, P615, DOI 10.1126/science.7367885; CHEN Q, 1999, P C COMP VIS PATT RE, P29; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FALKENHAGEN L, 1994, P WORKSH IM PROC BRO, P115; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; FITZGIBBON AW, 1998, P ECCV 98 WORKSH 3D, P154; FUA P, 1991, P 12 INT JOINT C ART; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; INTILLE SS, 1994, P 3 EUR C COMP VIS, P179; Izquierdo E, 1998, COMPUT VIS IMAGE UND, V71, P231, DOI 10.1006/cviu.1998.0706; KOSCHAN A, 1993, 9322 U BERL DEP COMP; LAVEAU S, 1994, 2205 INRIA; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lhuillier M, 2000, INT C PATT RECOG, P968, DOI 10.1109/ICPR.2000.905620; LHUILLIER M, 1999, P C COMP VIS PATT RE, V2, P139; LHUILLIER M, 1998, P 9 BRIT MACH VIS C, P700; LHUILLIER M, 2000, P C COMP VIS PATT RE, V2, P218; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Moravec H.P., 1977, PROC INT JOINT C ART, P584; Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; OTTO GP, 1989, IMAGE VISION COMPUT, V7, P83, DOI 10.1016/0262-8856(89)90001-2; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; QUENOT GM, 1992, P INT C AC SPEECH SI; Scharstein D, 1996, PROC CVPR IEEE, P852, DOI 10.1109/CVPR.1996.517171; Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196; Shashua A., 1994, P 3 EUR C COMP VIS, P479; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SZELISKI R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P757, DOI 10.1109/ICCV.1995.466862; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; ZHANG Z, 2000, P 2 WORKSH STRUCT MU, P26; ZHANG Z, 1994, AI J, V78, P87	43	130	149	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1140	1146		10.1109/TPAMI.2002.1023810	http://dx.doi.org/10.1109/TPAMI.2002.1023810			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY		Green Submitted			2022-12-18	WOS:000177115100012
J	Bishop, CM; Tipping, ME				Bishop, CM; Tipping, ME			A hierarchical latent variable model for data visualization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						latent variables; data visualization; EM algorithm; hierarchical mixture model; density estimation; principal component analysis; factor analysis; maximum likelihood; clustering; statistics	EM ALGORITHM	Visualization has proven to be a powerful and widely-applicable tool for the analysis and interpretation of multivariate data. Most visualization algorithms aim to find a projection from the data space down to a two-dimensional visualization space. However, for complex data sets living in a high-dimensional space, it is unlikely that a single two-dimensional projection can reveal all of the interesting structure. We therefore introduce a hierarchical visualization algorithm which allows the complete data set to be visualized at the top level, with clusters and subclusters of data points visualized at deeper levels. The algorithm is based on a hierarchical mixture of latent variable models, whose parameters are estimated using the expectation-maximization algorithm. We demonstrate the principle of the approach on a toy data set, and we then apply the algorithm to the visualization of a synthetic data set in 12 dimensions obtained from a simulation of multiphase flows in oil pipelines, and to data in 36 dimensions derived from satellite images. A Matlab software implementation of the algorithm is publicly available from the World Wide Web.	Microsoft Res, Cambridge CB2 3NH, England; Aston Univ, Neural Comp Res Grp, Birmingham B4 7ET, W Midlands, England	Microsoft; Aston University	Bishop, CM (corresponding author), Microsoft Res, St George House,1 Guildhall St, Cambridge CB2 3NH, England.	cmbishop@microsoft.com; m.e.tipping@aston.ac.uk						Bishop, 1995, NEURAL NETWORKS PATT; BISHOP CM, 1993, NUCL INSTRUM METH A, V327, P580, DOI 10.1016/0168-9002(93)90728-Z; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Buja A., 1996, J COMPUTATIONAL GRAP, V5, P78, DOI 10.1080/10618600.1996.10474696; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Everitt B., 1984, INTRO LATENT VARIABL; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kohonen T., 1995, SELF ORG MAPS; Krzanowski W. J., 1994, MULTIVARIATE ANAL 2; MALTSON RL, 1965, IBM J, V9, P294; Michie Donald, 1994, MACHINE LEARNING NEU, P2; MIIKULAINEN R, 1990, CONNECT SCI, V2, P80; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; Tipping ME, 1997, IEE CONF PUBL, P13, DOI 10.1049/cp:19970694; TIPPING ME, 1997, NCRG97003 AST U NEUR; VERSINO C, 1996, LECT NOTES COMPUTER, V1112, P221	18	130	138	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					281	293		10.1109/34.667885	http://dx.doi.org/10.1109/34.667885			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156		Green Accepted			2022-12-18	WOS:000073078400005
J	ROSIN, PL; WEST, GAW				ROSIN, PL; WEST, GAW			NONPARAMETRIC SEGMENTATION OF CURVES INTO VARIOUS REPRESENTATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2D; 3D; CURVE REPRESENTATION; SEGMENTATION; CIRCULAR; ELLIPTIC; SUPERELLIPTICAL; PARABOLIC ARCS; LEAST SQUARE ELLIPSE FITTING; MULTISTAGE; SIGNIFICANCE; NONPARAMETRIC	PIECEWISE LINEAR-APPROXIMATION; PLANAR CURVES; PERCEPTUAL ORGANIZATION; IMAGE CURVES; RECOGNITION; EXTRACTION; ELLIPSES; POINTS; MODELS; PARTS	This paper describes and demonstrates the operation and performance of an algorithm for segmenting connected points into a combination of representations such as lines, circular, elliptical and superelliptical arts, and polynomials. The algorithm has a number of interesting properties including being scale invariant, nonparametric, general purpose, and efficient.	CURTIN UNIV TECHNOL,SCH COMP,PERTH,WA 6001,AUSTRALIA	Curtin University	ROSIN, PL (corresponding author), BRUNEL UNIV,DEPT COMP SCI & INFORMAT SYST,KINGSTON LANE,UXBRIDGE UB8 3PH,MIDDX,ENGLAND.							AGIN G, 1981, CMURITR815 CARN U RO; ALBANO A, 1974, COMPUT GRAPHICS IMAG, V5, P23; ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O; AOYAMA H, 1991, CVGIP-GRAPH MODEL IM, V53, P435, DOI 10.1016/1049-9652(91)90028-I; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611; BENDTSEN H, 1992, FITTING ELLIPSES NOI; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; COOPER DB, 1975, NASA NSG50361 BROWN; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; ELLIS TJ, 1992, IMAGE VISION COMPUT, P271; FISCHLER MA, 1994, IEEE T PATTERN ANAL, V16, P113, DOI 10.1109/34.273737; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FORSYTH DA, 1990, 1ST P EUR C COMP VIS, P427; GANDER W, 1994, TR217 ETH I WISS LIC; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; GUEZIEC A, 1992, 2ND P EUR C COMP VIS, P620; GUPTA A, 1992, INT C PATT REC, V1, P158; Haralick RM., 1992, COMPUTER ROBOT VISIO; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HUANG CL, 1989, PATTERN RECOGN LETT, V10, P93, DOI 10.1016/0167-8655(89)90073-1; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; KEHTARNAVAZ N, 1988, IEEE T PATTERN ANAL, V10, P707, DOI 10.1109/34.6780; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; LEONARDIS A, 1992, 2ND P EUR C COMP VIS, P653; LIAO YZ, 1981, C PATTERN RECOGNITIO, P224; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; MEDIONI G, 1987, COMPUTER VISION GRAP, P267; Mokhtarian F., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P298, DOI 10.1109/CVPR.1988.196252; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P133, DOI 10.1016/0031-3203(79)90059-1; PATERSON AM, 1994, 11TH P INT S AUT ROB, P657; PAVLIDIS T, 1983, ACM T GRAPHIC, V2, P1, DOI 10.1145/357314.357315; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pollard S., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P39; PORRILL J, 1990, IMAGE VISION COMPUT, V8, P37, DOI 10.1016/0262-8856(90)90054-9; Press WH, 1988, NUMERICAL RECIPES C; PRIDMORE AP, 1987, IMAGE VISION COMPUT, V5, P132, DOI 10.1016/0262-8856(87)90040-0; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; ROSENFELD A, 1973, IEEE T COMPUT, V2, P875; ROSIN PL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P75; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P661, DOI 10.1016/0167-8655(93)90052-F; ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; ROSIN PL, 1993, DEC AUSTR NZ C INT I, P530; ROSIN PL, 1994, INT J PATTERN RECOGN, V8; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SAFEERAD R, 1991, CVGIP-IMAG UNDERSTAN, V54, P259; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W; SHIRAI Y, 1978, COMPUTER VISION SYST, P353; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; THOMAS SM, 1989, COMPUT VISION GRAPH, V45, P362, DOI 10.1016/0734-189X(89)90088-1; TSUJI S, 1979, IEEE T COMPUT, V27, P777; WANG R, 1988, 9 ICPR, P508; WEST GAW, 1991, PATTERN RECOGN, V24, P643, DOI 10.1016/0031-3203(91)90031-Y; WU J, 1988, C VISION INTERFACES, P21; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; YI SK, 1994, MACH VISION APPL, V7, P93, DOI 10.1007/BF01215805; YOKOYA N, 1992, INT C PATTERN RECOGN, V1, P168	65	130	150	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1140	1153		10.1109/34.476507	http://dx.doi.org/10.1109/34.476507			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500002
J	MATUS, F; FLUSSER, J				MATUS, F; FLUSSER, J			IMAGE REPRESENTATIONS VIA A FINITE RADON-TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FINITE RADON TRANSFORM; FOURIER TRANSFORM; IMAGE COMPRESSION; IMAGE REPRESENTATIONS; ITERATIVE RECONSTRUCTION; RADON PROJECTIONS; TRANSFORM CODING	INVERSION	This paper presents a model of finite Radon transforms composed of Radon projections. The model generalizes to finite group projections in the classical Radon transform theory. The Radon projector averages a function on a group over cosets of a subgroup. Reconstruction formulae that were formally similar to the convolved backprojection ones are derived, and an iterative reconstruction technique is found to converge after a finite number of steps. Applying these results to the group Z(p)2, new computationally favorable image representations have been obtained. A numerical study of the transform coding aspects is attached.			MATUS, F (corresponding author), ACAD SCI CZECH REPUBL, INST INFORMAT THEORY & AUTOMAT, PRAGUE, CZECH REPUBLIC.		Flusser, Jan/F-6209-2014	Flusser, Jan/0000-0003-3747-9214				Ahmed N., 1975, ORTHOGONAL TRANSFORM, P86; Bolker E. D., 1987, CONTEMP MATH, V63, P27, DOI DOI 10.1090/CONM/063/876312; Curtis C.W., 1962, REPRESENTATION THEOR; DIACONIS P, 1985, PAC J MATH, V118, P323, DOI 10.2140/pjm.1985.118.323; ENOMOTO H, 1971, IEEE T ELECTROMAGN C, VEM13, P11, DOI 10.1109/TEMC.1971.303101; Helgason S., 1980, RADON TRANSFORM; Herman G, 1980, IMAGE RECONSTRUCTION; JAIN AK, 1981, P IEEE, V69, P349, DOI 10.1109/PROC.1981.11971; JAIN AK, 1977, SIAM REV, P201; KEINERT F, 1989, SIAM REV, V31, P273, DOI 10.1137/1031051; Kung J. P. S., 1988, Nuclear Physics B, Proceedings Supplements, V5A, P44, DOI 10.1016/0920-5632(88)90011-4; MATUS F, 1988, KYBERNETIKA, V24, P36; MATUS F, 1988, THESIS PRAGUE; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PRATT WK, 1974, IEEE T COMMUN, VCO22, P1075, DOI 10.1109/TCOM.1974.1092335; Sanz J. L., 1988, RADON PROJECTION TRA; STRICHARTZ RS, 1982, AM MATH MON, V89, P377, DOI 10.2307/2321649	18	130	151	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					996	1006		10.1109/34.254058	http://dx.doi.org/10.1109/34.254058			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775					2022-12-18	WOS:A1993MD77500003
J	WOLFSON, HJ				WOLFSON, HJ			ON CURVE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									TEL AVIV UNIV, SACKLER SCH MED, DEPT COMP SCI, TEL AVIV, ISRAEL	Tel Aviv University; Sackler Faculty of Medicine	WOLFSON, HJ (corresponding author), NYU, COURANT INST MATH SCI, ROBOT RES LAB, 715 BROADWAY, 12TH FLOOR, NEW YORK, NY 10003 USA.		Wolfson, Haim/A-1837-2011	Wolfson, Haim/0000-0002-7600-2702				AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; ERNST MD, 1989, MAR AAAI ROB NAV S; FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9; FREEMAN H, 1964, IEEE T COMPUT, VEC13, P118, DOI 10.1109/PGEC.1964.263781; HONG J, 1988, NOV P ICPR ROM, P72; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KISHON E, 1987, OCT P AAAI WORKSH SP, P250; LEE DT, 1984, NETWORKS, V14, P393, DOI 10.1002/net.3230140304; RADACK GM, 1982, COMPUT VISION GRAPH, V19, P1, DOI 10.1016/0146-664X(82)90111-3; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Stoker JJ, 1969, DIFFERENTIAL GEOMETR; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; Weiner P., 1973, 14th Annual Symposium on Switching Automata Theory, P1; Wolfson H., 1988, Annals of Operations Research, V12, P51, DOI 10.1007/BF02186360; WOLFSON H, 1987, NOV P IEEE COMP SOC, P307	16	130	145	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1990	12	5					483	489		10.1109/34.55108	http://dx.doi.org/10.1109/34.55108			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DA035					2022-12-18	WOS:A1990DA03500007
J	FAN, TJ; MEDIONI, G; NEVATIA, R				FAN, TJ; MEDIONI, G; NEVATIA, R			RECOGNIZING 3-D OBJECTS USING SURFACE DESCRIPTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,SCH ENGN,INST ROBOT & INTELLIGENT SYST,DEPT ELECT ENGN,LOS ANGELES,CA 90089; UNIV SO CALIF,SCH ENGN,INST ROBOT & INTELLIGENT SYST,DEPT COMP SCI,LOS ANGELES,CA 90089	University of Southern California; University of Southern California								Ayache N., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P492; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BOLLES RC, 1982, INT J ROBOT RES, V1, P637; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; BRADY M, 1985, 2ND P INT S ROB RES; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CHIN RT, 1986, ACM COMPUT SURV, V18, P67; FAN TJ, 1987, IEEE J ROBOTIC A DEC, P527; FAN TJ, 1988, THESIS U SO CALIFORN; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; GRIMSON W, 1987, IEEE T PATTERN ANAL, V9; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; Gunnarsson K.T., 1987, THESIS CARNEGIE MELL; HORAUD P, 1984, MAR P INT C ROB ATL, P78; HORN BKP, 1984, SCI AM, V251, P100, DOI 10.1038/scientificamerican0884-100; HORN BKP, 1984, P IEEE, V72, P1656; IKEUCHI K, 1981, 7TH P INT JOINT C AR, P595; IKEUCHI K, 1987, FEB P DARPA IM UND W, P321; JEZOUIN JL, 1988, JUN P IEEE C COMP VI; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; OSHIMA M, 1979, PATTERN RECOGN, V11, P9, DOI 10.1016/0031-3203(79)90024-4; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; Paul R. P., 1984, ROBOT MANIPULATORS M; RAO K, 1986, JUN P IEEE C COMP VI, P256; [No title captured]	28	130	141	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1140	1157		10.1109/34.42853	http://dx.doi.org/10.1109/34.42853			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600002
J	HARALICK, RM; SHAPIRO, LG				HARALICK, RM; SHAPIRO, LG			CONSISTENT LABELING PROBLEM .1.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									KANSAS STATE UNIV AGR & APPL SCI, DEPT COMP SCI, MANHATTAN, KS 66506 USA	Kansas State University	HARALICK, RM (corresponding author), VIRGINIA POLYTECH INST & STATE UNIV, DEPT ELECT ENGN, BLACKSBURG, VA 24061 USA.		Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				BARROW HG, 1976, AI121 SRI STANF RES; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Cook S.A., 1971, P 3 ANN ACM S THEORY, P151, DOI [10.1145/800157.805047, DOI 10.1145/800157.805047]; DAVIS LS, 1976, TR480 U MAR COMP SCI; DEUTSCH JPA, 1966, BRIT JOINT COMPUT C; FIKES RE, 1970, ARTIF INTELL, V1, P27, DOI 10.1016/0004-3702(70)90003-2; FREUDER EC, 1978, COMMUN ASS COMPUT MA, V21; GASCHING J, 1974, 12TH ANN ALL C CIRC; GINZBERG A, 1968, ALGEBRAIC THEORY AUT; Guzman A., 1969, AUTOMATIC INTERPRETA, P243; HANSON A, 1977, JUN MACH VIS WORKSH; HARALICK RM, 1978, IEEE T SYST MAN CYB, V8, P600, DOI 10.1109/TSMC.1978.4310036; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; HARALICK RM, 1978, MACHINE VISION; HARALICK RM, 1978, GENERAL SYST J, V4, P113; Harary F., 1994, GRAPH THEORY; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KOWALSKI R, 1975, J ACM, V22, P572, DOI 10.1145/321906.321919; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1975, IEEE T SYST MAN CYB, VSMC5, P380, DOI 10.1109/TSMC.1975.5408418; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; ULLMANN JR, 1966, INFORM CONTROL, V9, P583, DOI 10.1016/S0019-9958(66)80017-7; VANDERBRUG G, 1976, JUN LARS S P MACH PR; WHITEHEAD EG, 1972, COMBINATORIAL ALGORI; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1977, TR543 U MAR TECH REP; [No title captured]	30	130	132	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					173	184		10.1109/TPAMI.1979.4766903	http://dx.doi.org/10.1109/TPAMI.1979.4766903			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868846	Green Published			2022-12-18	WOS:A1979HA30400007
J	Liang, XD; Gong, K; Shen, XH; Lin, L				Liang, Xiaodan; Gong, Ke; Shen, Xiaohui; Lin, Liang			Look into Person: Joint Body Parsing & Pose Estimation Network and a New Benchmark	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human parsing; pose estimation; context modeling; convolutional neural networks		Human parsing and pose estimation have recently received considerable interest due to their substantial application potentials. However, the existing datasets have limited numbers of images and annotations and lack a variety of human appearances and coverage of challenging cases in unconstrained environments. In this paper, we introduce a new benchmark named "Look into Person (LIP)" that provides a significant advancement in terms of scalability, diversity, and difficulty, which are crucial for future developments in human-centric analysis. This comprehensive dataset contains over 50,000 elaborately annotated images with 19 semantic part labels and 16 body joints, which are captured from a broad range of viewpoints, occlusions, and background complexities. Using these rich annotations, we perform detailed analyses of the leading human parsing and pose estimation approaches, thereby obtaining insights into the successes and failures of these methods. To further explore and take advantage of the semantic correlation of these two tasks, we propose a novel joint human parsing and pose estimation network to explore efficient context modeling, which can simultaneously predict parsing and pose with extremely high quality. Furthermore, we simplify the network to solve human parsing by exploring a novel self-supervised structure-sensitive learning approach, which imposes human pose structures into the parsing results without resorting to extra supervision. The datasets, code and models are available at http://www.sysu-hcp.net/lip/.	[Liang, Xiaodan; Gong, Ke; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China; [Shen, Xiaohui] Adobe Res, San Jose, CA 95110 USA	Sun Yat Sen University; Adobe Systems Inc.	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China.	xdliang328@gmail.com; kegong936@gmail.com; xshen@adobe.com; linliang@ieee.org	Gong, Ke/AAI-8783-2020	Liang, Lin/0000-0003-2248-3755; Gong, Ke/0000-0002-8036-2348	State Key Development Program [2016YFB1001004]; National Natural Science Foundation of China [61622214, U1611461]; Guangdong Natural Science Foundation Project for Research Teams [2017A030312006]; Guangdong Science and Technology Planning Program [2017B010116001]	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Natural Science Foundation Project for Research Teams; Guangdong Science and Technology Planning Program	This work was supported by State Key Development Program under Grant 2016YFB1001004, the National Natural Science Foundation of China under Grant 61622214 and Grant U1611461, the Guangdong Natural Science Foundation Project for Research Teams under Grant 2017A030312006, and the Guangdong Science and Technology Planning Program under Grant 2017B010116001. Xiaodan Liang and Ke Gong contribute equally to this paper.	Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen L.-C., 2015, COMPUT SCI; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601; Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391; Dong J, 2014, PROC CVPR IEEE, P843, DOI 10.1109/CVPR.2014.113; Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Gan C, 2016, AAAI CONF ARTIF INTE, P3487; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; Johnson S., 2010, BMVC, DOI [10.5244/C.24.12, DOI 10.5244/C.24.12.CITESEER]; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Kalantidis Y., 2013, P 3 ACM C INT C MULT, P105, DOI DOI 10.1145/2461466.2461485; Liang XD, 2018, IEEE T PATTERN ANAL, V40, P2978, DOI 10.1109/TPAMI.2017.2775623; Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347; Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360; Lin L, 2018, IEEE T PATTERN ANAL, V40, P7, DOI 10.1109/TPAMI.2017.2652459; Lin Tsung-Yi, 2014, CORR; Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu W., 2014, P BRIT MACH VIS C; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299; Park S, 2018, IEEE T PATTERN ANAL, V40, P1555, DOI 10.1109/TPAMI.2017.2731842; Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Simo-Serra E., 2014, AS C COMP VIS ACCV S, P64; Simo-Serra E, 2015, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2015.7298688; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Wang HY, 2015, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2015.7298788; Wang L, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P599; Wang P, 2015, IEEE I CONF COMP VIS, P1573, DOI 10.1109/ICCV.2015.184; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Xia FT, 2016, AAAI CONF ARTIF INTE, P3632; Xia FT, 2016, LECT NOTES COMPUT SC, V9909, P648, DOI 10.1007/978-3-319-46454-1_39; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	52	129	139	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					871	885		10.1109/TPAMI.2018.2820063	http://dx.doi.org/10.1109/TPAMI.2018.2820063			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29994083				2022-12-18	WOS:000460583500007
J	Jiang, XD; Lai, J				Jiang, Xudong; Lai, Jian			Sparse and Dense Hybrid Representation via Dictionary Decomposition for Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse representation; classification; dictionary learning; low-rank matrix recovery; face recognition	FEATURE-EXTRACTION; SIGNAL RECOVERY; EIGENFACES; ALGORITHM; SUBSPACES; FRAMEWORK; PATTERN	Sparse representation provides an effective tool for classification under the conditions that every class has sufficient representative training samples and the training data are uncorrupted. These conditions may not hold true in many practical applications. Face identification is an example where we have a large number of identities but sufficient representative and uncorrupted training images cannot be guaranteed for every identity. A violation of the two conditions leads to a poor performance of the sparse representation-based classification (SRC). This paper addresses this critic issue by analyzing the merits and limitations of SRC. A sparse-and dense-hybrid representation (SDR) framework is proposed in this paper to alleviate the problems of SRC. We further propose a procedure of supervised low-rank (SLR) dictionary decomposition to facilitate the proposed SDR framework. In addition, the problem of the corrupted training data is also alleviated by the proposed SLR dictionary decomposition. The application of the proposed SDR-SLR approach in face recognition verifies its effectiveness and advancement to the field. Extensive experiments on benchmark face databases demonstrate that it consistently outperforms the state-of-the-art sparse representation based approaches and the performance gains are significant in most cases.	[Jiang, Xudong; Lai, Jian] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Jiang, XD (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	exdjiang@ntu.edu.sg; jlai1@ntu.edu.sg	Jiang, Xudong/B-1555-2008	Jiang, Xudong/0000-0002-9104-2315				Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Barsi R, 2003, IEEE T PATTERN ANAL, V25, P218; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bertsekas DP., 1996, CONSTRAINED OPTIMIZA, V1st edn; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; El Shafey L, 2013, IEEE T PATTERN ANAL, V35, P1788, DOI 10.1109/TPAMI.2013.38; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; GANESH A, 2009, 2009 3 IEEE INT, P213; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332; Jiang XD, 2006, ELECTRON LETT, V42, P1089, DOI 10.1049/el:20062035; Jiang XD, 2009, MACH VISION APPL, V20, P35, DOI 10.1007/s00138-007-0103-1; Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708; Jiang XD, 2011, IEEE SIGNAL PROC MAG, V28, P16, DOI 10.1109/MSP.2010.939041; Jiang XD, 2009, IEEE T PATTERN ANAL, V31, P931, DOI 10.1109/TPAMI.2008.258; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Lai J, 2012, IEEE SIGNAL PROC LET, V19, P571, DOI 10.1109/LSP.2012.2207112; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702; Lin Z., 2009, UILUENG092215 DEP EL; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu YN, 2010, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2010.5539934; Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J., 2008, ADV NEURAL INFORM PR, P1033; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; MARTINEZ AM, 1998, 24 PURD U COMP VIS C; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964; Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976; Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313; Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123; Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677; Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33; Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849; Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286; Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhang YMZ, 2013, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2013.93; Zhao P, 2006, J MACH LEARN RES, V7, P2541	63	129	137	1	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1067	1079		10.1109/TPAMI.2014.2359453	http://dx.doi.org/10.1109/TPAMI.2014.2359453			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353329				2022-12-18	WOS:000352533000013
J	Yang, QX				Yang, Qingxiong			Stereo Matching Using Tree Filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; minimum spanning tree; bilateral filtering; edge-preserving smoothing	COST AGGREGATION	Matching cost aggregation is one of the oldest and still popular methods for stereo correspondence. While effective and efficient, cost aggregation methods typically aggregate the matching cost by summing/averaging over a user-specified, local support region. This is obviously only locally-optimal, and the computational complexity of the full-kernel implementation usually depends on the region size. In this paper, the cost aggregation problem is re-examined and a non-local solution is proposed. The matching cost values are aggregated adaptively based on pixel similarity on a tree structure derived from the stereo image pair to preserve depth edges. The nodes of this tree are all the image pixels, and the edges are all the edges between the nearest neighboring pixels. The similarity between any two pixels is decided by their shortest distance on the tree. The proposed method is non-local as every node receives supports from all other nodes on the tree. The proposed method can be naturally extended to the time domain for enforcing temporal coherence. Unlike previous methods, the non-local property guarantees that the depth edges will be preserved when the temporal coherency between all the video frames are considered. A non-local weighted median filter is also proposed based on the non-local cost aggregation algorithm. It has been demonstrated to outperform all local weighted median filters on disparity/depth upsampling and refinement.	City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	City University of Hong Kong	Yang, QX (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	qiyang@cityu.edu.hk	Yang, Qingxiong/K-1729-2015	Yang, Qingxiong/0000-0002-4378-2335	Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 122212, CityU 21201914]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	This work was supported by two grants from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. CityU 122212 and CityU 21201914).	Bader DA, 2005, J PARALLEL DISTR COM, V65, P994, DOI 10.1016/j.jpdc.2005.03.011; Bleyer M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P415; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cheriton D., 1976, SIAM Journal on Computing, V5, P724, DOI 10.1137/0205051; Crow F. C., 1984, Computers & Graphics, V18, P207; Fog Agner, 2011, OPTIMIZING SOFTWARE; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gallup D., 2007 IEEE C COMP VIS, P1; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705; MATSUI T, 1995, DISCRETE APPL MATH, V58, P91, DOI 10.1016/0166-218X(94)00095-U; Min DB, 2013, IEEE T PATTERN ANAL, V35, P2539, DOI 10.1109/TPAMI.2013.15; Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Perreault S, 2007, IEEE T IMAGE PROCESS, V16, P2389, DOI 10.1109/TIP.2007.902329; Porikli F., 2008, P IEEE C COMP VIS PA, P1; Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D., 2005, MIDDLEBURY STEREO EV; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Veksler O, 2005, PROC CVPR IEEE, P384; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Yang QX, 2012, LECT NOTES COMPUT SC, V7572, P399, DOI 10.1007/978-3-642-33718-5_29; Yang QX, 2014, IEEE T PATTERN ANAL, V36, P1026, DOI 10.1109/TPAMI.2013.186; Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827; Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542; Yin L, 1996, IEEE T CIRCUITS-II, V43, P157, DOI 10.1109/82.486465; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70	34	129	147	3	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					834	846		10.1109/TPAMI.2014.2353642	http://dx.doi.org/10.1109/TPAMI.2014.2353642			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353297				2022-12-18	WOS:000351213400010
J	Zhang, ZY; Zhao, KK				Zhang, Zhenyue; Zhao, Keke			Low-Rank Matrix Approximation with Manifold Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Matrix factorization; graph regularization; classification; clustering; manifold learning	FACTORIZATIONS	This paper proposes a new model of low-rank matrix factorization that incorporates manifold regularization to the matrix factorization. Superior to the graph-regularized nonnegative matrix factorization, this new regularization model has globally optimal and closed-form solutions. A direct algorithm (for data with small number of points) and an alternate iterative algorithm with inexact inner iteration (for large scale data) are proposed to solve the new model. A convergence analysis establishes the global convergence of the iterative algorithm. The efficiency and precision of the algorithm are demonstrated numerically through applications to six real-world datasets on clustering and classification. Performance comparison with existing algorithms shows the effectiveness of the proposed method for low-rank factorization in general.	[Zhang, Zhenyue; Zhao, Keke] Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China; [Zhang, Zhenyue] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China	Zhejiang University; Zhejiang University	Zhang, ZY (corresponding author), Zhejiang Univ, Dept Math, Yuquan Campus, Hangzhou 310027, Peoples R China.	zyzhang@zju.edu.cn; kkzhao@zju.edu.cn			NSFC [11071218, 91230112]; National Basic Research Program of China (973 Program) [2009CB320804]	NSFC(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China)	The work of Zhenyue Zhang was supported in part by NSFC projects 11071218 and 91230112, and the National Basic Research Program of China (973 Program) 2009CB320804.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; [Anonymous], P 20 INT C MACH LEAR; [Anonymous], 2009, P ACM C REC SYST NEW; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Canny J., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P122, DOI 10.1145/1008992.1009016; COHEN JE, 1993, LINEAR ALGEBRA APPL, V190, P149, DOI 10.1016/0024-3795(93)90224-C; Dong B., 2013, NONNEGATIVE RANK FAC; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496; He X., 2004, ADV NEUR INF PROC SY; Kim J, 2011, SIAM J SCI COMPUT, V33, P3261, DOI 10.1137/110821172; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI DOI 10.1145/1401890.1401944; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Kuang D., 2012, PROC 2012 SIAM INT C, P106, DOI DOI 10.1137/1.9781611972825.10; Lee DD, 2001, ADV NEUR IN, V13, P556; Li W., 2009, P 21 INT JOINT C ART; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saad Y., 2003, ITERATIVE METHODS SP, Vsecond, DOI DOI 10.1137/1.9780898718003; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Wen Y., SIGNAL PROC IN PRESS; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Zha HY, 2009, SIAM REV, V51, P545, DOI 10.1137/060676829; Zhang JY, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P32, DOI 10.1109/ISISE.2009.113; Zhang ZY, 2012, NEUROCOMPUTING, V97, P52, DOI 10.1016/j.neucom.2012.05.010; Zhang Zhifei, 2019, P IEEE C COMP VIS PA; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhou D., 2008, P 17 INT C WORLD WID, P141; Zhu S., 2007, P 30 ANN INT ACM SIG	31	129	135	4	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1717	1729		10.1109/TPAMI.2012.274	http://dx.doi.org/10.1109/TPAMI.2012.274			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681998				2022-12-18	WOS:000319060600014
J	Woodford, O; Torr, P; Reid, I; Fitzgibbon, A				Woodford, Oliver; Torr, Philip; Reid, Ian; Fitzgibbon, Andrew			Global Stereo Reconstruction under Second-Order Smoothness Priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; second-order prior; discrete optimization; graph cuts	MARKOV RANDOM-FIELDS; ENERGY MINIMIZATION; BAYESIAN-APPROACH	Second-order priors on the smoothness of 3D surfaces are a better model of typical scenes than first-order priors. However, stereo reconstruction using global inference algorithms, such as graph cuts, has not been able to incorporate second-order priors because the triple cliques needed to express them yield intractable (nonsubmodular) optimization problems. This paper shows that inference with triple cliques can be effectively performed. Our optimization strategy is a development of recent extensions to alpha-expansion, based on the "QPBO" algorithm. The strategy is to repeatedly merge proposal depth maps using a novel extension of QPBO. Proposal depth maps can come from any source, for example, frontoparallel planes as in alpha-expansion, or indeed any existing stereo algorithm, with arbitrary parameter settings.	[Woodford, Oliver; Reid, Ian] Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England; [Torr, Philip] Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England; [Fitzgibbon, Andrew] Microsoft Res Ltd, Cambridge CB3 0FB, England	University of Oxford; Oxford Brookes University; Microsoft	Woodford, O (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.	ojw@robots.ox.ac.uk; philiptorr@brookes.ac.uk; ian@robots.ox.ac.uk; awf@microsoft.com		Reid, Ian/0000-0001-7790-6423	EPSRC [EP/C007220/1, EP/C006631/1]; Royal Society Wolfson Merit Award; Engineering and Physical Sciences Research Council [EP/C006631/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Royal Society Wolfson Merit Award(Royal Society of London); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors thank Vladimir Kolmogorov for making available his QPBO software and also for discussing graph-cut stereo with us. They also thank Yuri Boykov, Pushmeet Kohli, Carsten Rother, and Ali Shahrokni for their helpful comments. Research funded by EPSRC grants EP/C007220/1 and EP/C006631/1(P). Oliver Woodford is sponsored by the EPSRC CASE studentship with Sharp. Philip Torr is sponsored by the Royal Society Wolfson Merit Award.	Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482; Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BHUSNURMATH A, 2008, P 4 INT S 3D DAT PRO, P321; BILLIONNET A, 1989, OPER RES LETT, V8, P161, DOI 10.1016/0167-6377(89)90043-6; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Bleyer M, 2004, IEEE IMAGE PROC, P2997; Bleyer M, 2007, SIGNAL PROCESS-IMAGE, V22, P127, DOI 10.1016/j.image.2006.11.012; Boros E., 2006, 102006 RRR; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2006, HDB MATH MODELS COMP; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; Gamble E. B., 1987, 970 MIT ART INT LAB; Gargallo P, 2005, PROC CVPR IEEE, P885; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; GENNERT MA, 1988, P INT C COMP VIS, P139; GRIMSON WEL, 1981, IMAGES SURFACES COMP; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Hong L, 2004, PROC CVPR IEEE, P74; Horn B., 1986, ROBOT VISION, P1; Isard M, 2003, PROC CVPR IEEE, P613; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; ISHIKAWA H, 1998, P EUR C COMP VIS, P232; Klaus A, 2006, INT C PATT RECOG, P15; KOHLI P, 2007, THESIS OXFORD BROOKE; KOHLI P, 2007, P IEEE C COMP VIS PA; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; KOLMOGOROV V, 2006, MSRTR2006100; KOLMOGOROV V, 2006, P EUR C COMP VIS, V2, P1; LEMPITSKY V, 2007, P INT C COMP VIS; Lempitsky V. S., 2008, P IEEE C COMP VIS PA; LI G, 2006, P CVPR, P2355; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; POTETZ B, 2007, P IEEE C COMP VIS PA; RAJ A, 2006, P IEEE CVPR, P1061; Rother C, 2005, PROC CVPR IEEE, P589; Rother C., 2007, P IEEE C COMP VIS PA; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2007, P IEEE C COMP VIS PA; SCHLENKER B, 2006, EUR UROL, V6, P1; Strecha C, 2004, PROC CVPR IEEE, P552; Sudderth EB, 2003, PROC CVPR IEEE, P605; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Sun J., 2005, P IEEE C COMP VIS PA; Szeliski R, 2004, IEEE T PATTERN ANAL, V26, P419, DOI 10.1109/TPAMI.2004.1262341; SZELISKI R, 1999, P CVPR, V1, P157; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; VEKSLER O, 2007, P IEEE C COMP VIS PA; Wei YC, 2005, PROC CVPR IEEE, P902; Winn J., 2006, P IEEE C COMP VIS PA; WOODFORD O, 2006, P BMVC, V3, P1109; Woodford O. J., 2007, PROC BRIT MACH VIS C, P1120; WOODFORD OJ, 2008, P IEEE C COMP VIS PA; WOODFORD OJ, 2007, P IEEE C COMP VIS PA; YANG Q, 2006, CVPR, P2347	66	129	150	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2115	2128		10.1109/TPAMI.2009.131	http://dx.doi.org/10.1109/TPAMI.2009.131			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834135	Green Submitted			2022-12-18	WOS:000271140100002
J	Xu, CJ; Liu, JZ; Tang, XO				Xu, Chunjing; Liu, Jianzhuang; Tang, Xiaoou			2D Shape Matching by Contour Flexibility	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2D shape; contour flexibility; matching	NONRIGID SHAPES; RECOGNITION; SIMILARITY	In computer vision, shape matching is a challenging problem, especially when articulation and deformation of parts occur. These variations may be insignificant for human recognition but often cause a matching algorithm to give results that are inconsistent with our perception. In this paper, we propose a novel shape descriptor of planar contours, called contour flexibility, which represents the deformable potential at each point along a contour. With this descriptor, the local and global features can be obtained from the contour. We then present a shape matching scheme based on the features obtained. Experiments with comparisons to recently published algorithms show that our algorithm performs best.	[Xu, Chunjing; Liu, Jianzhuang; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong	Xu, CJ (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	cjxu6@ie.cuhk.edu.hk; jzliu@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012		Research Grants Council of Hong Kong [CUHK 414306]	Research Grants Council of Hong Kong(Hong Kong Research Grants Council)	The work described in this paper was supported by a grant from the Research Grants Council of Hong Kong (Project CUHK 414306) and a CUHK Direct Grant.	Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776; Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009; ATTNEAVE F, 1950, AM J PSYCHOL, V63, P516, DOI 10.2307/1418869; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bookstein FL., 1986, STAT SCI, V1, P181, DOI [DOI 10.1214/SS/1177013696, 10.1214/ss/1177013696]; CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C; Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Felzenszwalb P. F., 2007, P IEEE INT C COMP VI, V1, P1; GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HONG BW, 2006, P 2006 IEEE COMP SOC, V1, P833; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Kunttu I, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P536, DOI 10.1109/ICIAP.2003.1234105; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Ling HB, 2005, PROC CVPR IEEE, P719; MARDIA KV, 1989, ADV APPL PROBAB, V21, P742, DOI 10.2307/1427764; Marques JS, 1997, PATTERN RECOGN LETT, V18, P49, DOI 10.1016/S0167-8655(96)00120-1; MCNEILL G, 2006, P IEEE C COMP VIS PA, V1, P885; Milios E, 2000, IEEE T IMAGE PROCESS, V9, P141, DOI 10.1109/83.817606; Mokhtarian F., 2003, CURVATURE SCALE SPAC; PEI SC, 1995, IMAGE VISION COMPUT, V13, P711, DOI 10.1016/0262-8856(95)98753-G; Rabiner L., 1993, FUNDAMENTALS SPEECH; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; SIDDIQI K, 1993, P IEEE C COMP VIS PA, V1, P75; SUPER BJ, 2004, P IEEE WORKSH LEARN, V6, P93; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9	35	129	151	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					180	186		10.1109/TPAMI.2008.199	http://dx.doi.org/10.1109/TPAMI.2008.199			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029556				2022-12-18	WOS:000260889700016
J	Xie, XH; Mirmehdi, M				Xie, Xianghua; Mirmehdi, Majid			MAC: Magnetostatic active contour model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contours; deformable model; object segmentation; magnetostatic forces	GRADIENT VECTOR FLOW; IMAGE SEGMENTATION; REGION; SHAPE; SNAKES; MOTION	We propose an active contour model using an external force field that is based on magnetostatics and hypothesized magnetic interactions between the active contour and object boundaries. The major contribution of the method is that the interaction of its forces can greatly improve the active contour in capturing complex geometries and dealing with difficult initializations, weak edges, and broken boundaries. The proposed method is shown to achieve significant improvements when compared against six well-known and state-of-the-art shape recovery methods, including the geodesic snake, the generalized version of gradient vector flow (GVF) snake, the combined geodesic and GVF snake, and the charged particle model.	[Xie, Xianghua] Univ Wales Swansea, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales; [Mirmehdi, Majid] Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England	Swansea University; University of Bristol	Xie, XH (corresponding author), Univ Wales Swansea, Dept Comp Sci, Faraday Tower,Singleton Pk, Swansea SA2 8PP, W Glam, Wales.	majid@cs.bris.ac.uk		Xie, Xianghua/0000-0002-2701-8660; Mirmehdi, Majid/0000-0002-6478-1403				Adalsteinsson D, 1999, J COMPUT PHYS, V148, P2, DOI 10.1006/jcph.1998.6090; Ardon R, 2006, INT J COMPUT VISION, V69, P127, DOI 10.1007/sM263-006-6850-z; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Brigger P, 2000, IEEE T IMAGE PROCESS, V9, P1484, DOI 10.1109/83.862624; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Clark AA, 2001, PROC CVPR IEEE, P290; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; GIL D, 2003, P EMMCVPR, P357; HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867; Jalba AC, 2004, IEEE T PATTERN ANAL, V26, P1320, DOI 10.1109/TPAMI.2004.84; Juan O, 2006, INT J COMPUT VISION, V69, P7, DOI 10.1007/s11263-006-6849-5; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOEPFLER G, 1994, SIAM J NUMER ANAL, V31, P282, DOI 10.1137/0731015; Li B, 2006, IEEE IMAGE PROC, P1637, DOI 10.1109/ICIP.2006.312619; Li CM, 2005, PROC CVPR IEEE, P162; Morse BS, 2005, PROC CVPR IEEE, P285; Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Pollock EL, 1996, COMPUT PHYS COMMUN, V95, P93, DOI 10.1016/0010-4655(96)00043-4; Ray N, 2004, IEEE T MED IMAGING, V23, P1466, DOI 10.1109/TMI.2004.835603; Sethian JA, 1996, LEVEL SET METHODS EV; Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193; Suri JS, 2001, IEEE ENG MED BIOL, V20, P84, DOI 10.1109/51.940054; Tschumperle D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z; Wang X, 2004, INT J COMPUT VISION, V59, P87, DOI 10.1023/B:VISI.0000020672.14006.ad; Wang ZZ, 2004, LECT NOTES COMPUT SC, V2034, P304; WOLF D, 2001, ESSENTIALS ELECTROMA; Xiang Y, 2005, PROC CVPR IEEE, P452; XIE X, 2006, P 17 BRIT MACH VIS C, P127; Xie XH, 2004, IEEE T IMAGE PROCESS, V13, P640, DOI 10.1109/TIP.2004.826124; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6; Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003; Yang RH, 2006, LECT NOTES COMPUT SC, V4179, P173; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	38	129	140	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					632	646		10.1109/TPAMI.2007.70737	http://dx.doi.org/10.1109/TPAMI.2007.70737			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276969				2022-12-18	WOS:000253135600007
J	Wu, JX; Brubaker, SC; Mullin, MD; Rehg, JM				Wu, Jianxin; Brubaker, S. Charles; Mullin, Matthew D.; Rehg, James M.			Fast asymmetric learning for cascade face detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face detection; cascade classifier; asymmetry; feature selection	SUPPORT VECTOR MACHINES; OBJECT DETECTION; CLASSIFIERS; HIERARCHY; FEATURES	A cascade face detector uses a sequence of node classifiers to distinguish faces from nonfaces. This paper presents a new approach to design node classifiers in the cascade detector. Previous methods used machine learning algorithms that simultaneously select features and form ensemble classifiers. We argue that if these two parts are decoupled, we have the freedom to design a classifier that explicitly addresses the difficulties caused by the asymmetric learning goal. There are three contributions in this paper: The first is a categorization of asymmetries in the learning goal and why they make face detection hard. The second is the Forward Feature Selection (FFS) algorithm and a fast precomputing strategy for AdaBoost. FFS and the fast AdaBoost can reduce the training time by approximately 100 and 50 times, in comparison to a naive implementation of the AdaBoost feature selection method. The last contribution is a Linear Asymmetric Classifier ( LAC), a classifier that explicitly handles the asymmetric learning goal as a well-defined constrained optimization problem. We demonstrated experimentally that LAC results in an improved ensemble classifier performance.	[Wu, Jianxin; Brubaker, S. Charles; Mullin, Matthew D.; Rehg, James M.] Georgia Inst Technol, Coll Comp, Sch Interact Comp, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Wu, JX (corresponding author), Georgia Inst Technol, Coll Comp, Sch Interact Comp, 85 5th St NW, Atlanta, GA 30332 USA.	wujx@cc.gatech.edu; brubaker@cc.gatech.edu; mdmullin@cc.gatech.edu; rehg@cc.gatech.edu	Wu, Jianxin/B-8539-2012; Rehg, James/AAM-6888-2020; Wu, Jianxin/A-3700-2011	Rehg, James/0000-0003-1793-5462; 				Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Anthony M, 2004, J MACH LEARN RES, V5, P189; AVIDAN S, 2005, ADV NEURAL INFORM PR, V17, P57; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Blanchard G, 2005, ANN STAT, V33, P1155, DOI 10.1214/009053605000000174; BRUBAKER S, 2005, GITGVU0528 GVC CTR G; Carmichael O, 2003, PROC CVPR IEEE, P401; Chen XR, 2004, PROC CVPR IEEE, P366; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; Fan W, 1999, MACHINE LEARNING, PROCEEDINGS, P97; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; GaryWeiss M., 2004, SIGKDD EXPLOR NEWSL, V6, P7, DOI DOI 10.1145/1007730.1007734; Heisele B, 2001, PROC CVPR IEEE, P18; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; JONES MJ, 2003, TR200396 MITS ELECT; Karakoulas G, 1999, ADV NEUR IN, V11, P253; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; Kim S., 2006, P 23 INT C MACH LEAR, P473; Lanckriet G. R. G., 2003, Journal of Machine Learning Research, V3, P555, DOI 10.1162/153244303321897726; Levi K, 2004, PROC CVPR IEEE, P53; LI S, 2003, ADV NEURAL INFORM PR, V15, P993; Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297; Liu C, 2003, PROC CVPR IEEE, P587; Mason L, 2000, ADV NEUR IN, P221; OSADCHY R, 2005, ADV NEURAL INFORM PR, V17, P1017; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; Ren L, 2005, ACM T GRAPHIC, V24, P1303, DOI 10.1145/1095878.1095882; Rivest R. L., 1987, Machine Learning, V2, P229, DOI 10.1023/A:1022607331053; Romdhani S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P695, DOI 10.1109/ICCV.2001.937694; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sahbi H, 2006, J MACH LEARN RES, V7, P2087; Schapire R. E., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P215, DOI 10.1145/290941.290996; Schapire RE, 1998, ANN STAT, V26, P1651; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Sun J, 2004, PROC CVPR IEEE, P276; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Ting Kai Ming, 2000, P 17 INT C MACH LEAR, P983; Torralba A, 2004, PROC CVPR IEEE, P762; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P, 2002, ADV NEUR IN, V14, P1311; Webb A., 1999, STAT PATTERN RECOGNI; Wu JX, 2004, ADV NEUR IN, V16, P1523; Xiao R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P709; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Yang MH, 2000, ADV NEUR IN, V12, P862	48	129	151	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					369	382		10.1109/TPAMI.2007.1181	http://dx.doi.org/10.1109/TPAMI.2007.1181			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195433	Green Submitted			2022-12-18	WOS:000252286100001
J	Huang, XL; Paragios, N; Metaxas, DN				Huang, Xiaolei; Paragios, Nikos; Metaxas, Dimitris N.			Shape registration in implicit spaces using information theory and free form deformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape registration; mutual information; free form deformations; correspondences; implicit shape representation; distance transforms; partial differential equations	IMAGE; ALGORITHMS; CURVES; SPEED	We present a novel, variational and statistical approach for shape registration. Shapes of interest are implicitly embedded in a higher- dimensional space of distance transforms. In this implicit embedding space, registration is formulated in a hierarchical manner: the Mutual Information criterion supports various transformation models and is optimized to perform global registration; then, a B- spline- based Incremental Free Form Deformations ( IFFD) model is used to minimize a Sum- of- Squared- Differences ( SSD) measure and further recover a dense local nonrigid registration field. The key advantage of such framework is twofold: 1) it naturally deals with shapes of arbitrary dimension ( 2D, 3D, or higher) and arbitrary topology ( multiple parts, closed/ open) and 2) it preserves shape topology during local deformation and produces local registration fields that are smooth, continuous, and establish one- to- one correspondences. Its invariance to initial conditions is evaluated through empirical validation, and various hard 2D/ 3D geometric shape registration examples are used to show its robustness to noise, severe occlusion, and missing parts. We demonstrate the power of the proposed framework using two applications: one for statistical modeling of anatomical structures, another for 3D face scan registration and expression tracking. We also compare the performance of our algorithm with that of several other well- known shape registration algorithms.	Rutgers State Univ, Ctr Computat Biomed Imaging & Modeling, Div Comp & Informat Sci, Piscataway, NJ 08854 USA; Ecole Cent Paris, Appl Math & Syst Lab MAS, F-92295 Chatenay Malabry, France	Rutgers State University New Brunswick; UDICE-French Research Universities; Universite Paris Saclay	Huang, XL (corresponding author), Rutgers State Univ, Ctr Computat Biomed Imaging & Modeling, Div Comp & Informat Sci, Piscataway, NJ 08854 USA.	xiaolei@cs.rutgers.edu; nikos.paragios@ecp.fr; dnm@cs.rutgers.edu						Belongie S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P454, DOI 10.1109/ICCV.2001.937552; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chefd'Hotel C, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P21, DOI 10.1109/VLSM.2001.938877; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; DAVIES RH, 2002, P EUR C COMP VIS 3, P3; Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; Fornefett M., 1999, P IEEE C COMP VIS PA, V1, P1402; Forsey D. R., 1988, Computer Graphics, V22, P205, DOI 10.1145/378456.378512; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; Hartkens T., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P565; Huang PS, 1999, OPT ENG, V38, P1065, DOI 10.1117/1.602151; Huang X, 2004, P 3 IEEE WORKSH ART; Huang XL, 2003, LECT NOTES COMPUT SC, V2879, P926; Ilic S, 2002, LECT NOTES COMPUT SC, V2351, P704; Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400; Laskov P, 2003, IEEE T PATTERN ANAL, V25, P1349, DOI 10.1109/TPAMI.2003.1233911; Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502; Lee SY, 1996, J VISUAL COMP ANIMAT, V7, P3, DOI 10.1002/(SICI)1099-1778(199601)7:1<3::AID-VIS131>3.0.CO;2-U; LEVENTON M, 2001, P IEEE C COMP VIS PA, P316; Metaxas D, 1996, PHYS BASED DEFORMABL; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; SEBASTIAN TB, 2001, LECT NOTES COMPUTER, V2059, P606; Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903; Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0; VELTKAMP R, 1995, COMPUTER VISION IMAG, V61, P38; VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930; Zhang L, 2003, PROC CVPR IEEE, P367; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; ZHU W, 2003, 0308 U CAL; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	37	129	144	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1303	1318		10.1109/TPAMI.2006.171	http://dx.doi.org/10.1109/TPAMI.2006.171			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886865				2022-12-18	WOS:000238162400011
J	Tordoff, BJ; Murray, DW				Tordoff, BJ; Murray, DW			Guided-MLESAC: Faster image transform estimation by using matching priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						random sampling; correspondence; image transformation; maximum-likelihood estimation		MLESAC is an established algorithm for maximum-likelihood estimation by random sampling consensus, devised for computing multiview entities like the fundamental matrix from correspondences between image features. A shortcoming of the method is that it assumes that little is known about the prior probabilities of the validities of the correspondences. This paper explains the consequences of that omission and describes how the algorithm's theoretical standing and practical performance can be enhanced by deriving estimates of these prior probabilities. Using the priors in guided-MLESAC is found to give an order of magnitude speed increase for problems where the correspondences are described by one image transformation and clutter. This paper describes two further modifications to guided-MLESAC. The first shows how all putative matches, rather than just the best, from a particular feature can be taken forward into the sampling stage, albeit at the expense of additional computation. The second suggests how to propagate the output from one frame forward to successive frames. The additional information makes guided-MLESAC computationally realistic at video-rates for correspondence sets modeled by two transformations and clutter.	Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England; Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	University of Cambridge; University of Oxford	Tordoff, BJ (corresponding author), Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.	bjt21@cam.ac.uk; dwm@robots.ox.ac.uk						Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Chum O., 2004, P AS C COMP VIS; DEAGAPITO L, 1989, P IEEE C COM VIS PAT, P15; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HARTLEY R, 1994, P 3 EUR C COMP VIS S, pA471; HUBER PJ, 1985, ROBUST STAT; Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055; MICUSIK B, 2003, P 8 COMP VIS WINT WO; Okabe T, 2003, PROC CVPR IEEE, P221; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SHAPIRO LS, 1995, AFFINE ANAL IMAGE SE; Tordoff B., 2002, THESIS U OXFORD; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; TORR PHS, 1993, IMAGE VISION COMPUT, V11, P180, DOI 10.1016/0262-8856(93)90034-E; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]	17	129	141	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1523	1535		10.1109/TPAMI.2005.199	http://dx.doi.org/10.1109/TPAMI.2005.199			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16237989				2022-12-18	WOS:000231086700002
J	PEDRYCZ, W				PEDRYCZ, W			NEUROCOMPUTATIONS IN RELATIONAL SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						FUZZY SET STRUCTURES; LEARNING ALGORITHMS; NEURAL COMPUTATIONS; RELATIONAL STRUCTURES	FUZZY	Artificial neural nets create a form of new high parallel computational structures used in many areas of applications. Fuzzy sets with all their conceptual capabilities and schemes of knowledge representation are considered as an interesting platform to cope with ambiguity present in human activity, especially decision processes. Relational structures in particular, forming a natural extension of boolean relational systems, play a significant role in building formal relational models of reality. In this correspondence we will indicate strong analogies between relational structures involving some composition operators and a certain class of neural networks. The problem of learning of connections of the structure is addressed and relevant learning procedures are proposed. An optimized performance index proposed here has a strong logical flavor. Some significant implementation details are studied as well.			PEDRYCZ, W (corresponding author), UNIV MANITOBA,DEPT ELECT & COMP ENGN,WINNIPEG R3T 2N2,MANITOBA,CANADA.							ASAI K, 1972, AUTOMATICA, V8, P101, DOI 10.1016/0005-1098(72)90014-3; Di Nola A., 1989, FUZZY RELATION EQUAT; Dubois D., 1980, FUZZY SET SYST; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V5, P836; GROSSBERG S, 1988, NEURAL NETWORKS NATU; Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]; MENGER K, 1942, P NAT ACAD SCI, V28, P353; PEDRYCZ W, 1989, PATTERN RECOGN LETT, V9, P305, DOI 10.1016/0167-8655(89)90058-5; Pedrycz W., 1989, FUZZY CONTROL FUZZY; PEDRYCZ W, 1990, FUZZY SETS SYSTEMS, V34, P233; SANCHEZ E, 1976, INFORM CONTROL, V30, P38, DOI 10.1016/S0019-9958(76)90446-0; SERIZAWA M, 1973, J NUCL SCI TECHNOL, V10, P195, DOI [10.3327/jnst.10.195, 10.1080/18811248.1973.9735405]; Sugeno M., 1977, Kybernetes, V6, P157, DOI 10.1108/eb005448; WEE WG, 1969, IEEE T SYST SCI CYB, VSSC5, P215, DOI 10.1109/TSSC.1969.300263; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575	15	129	130	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1991	13	3					289	297		10.1109/34.75517	http://dx.doi.org/10.1109/34.75517			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FG360					2022-12-18	WOS:A1991FG36000009
J	MAROLA, G				MAROLA, G			ON THE DETECTION OF THE AXES OF SYMMETRY OF SYMMETRIC AND ALMOST SYMMETRIC PLANAR IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MAROLA, G (corresponding author), UNIV PISA,IST ELETTR & TELECOMUNICAZ,I-56126 PISA,ITALY.							ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; Childs L, 1979, CONCRETE INTRO HIGHE; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X	3	129	136	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					104	108		10.1109/34.23119	http://dx.doi.org/10.1109/34.23119			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474					2022-12-18	WOS:A1989R447400009
J	Oksuz, K; Cam, BC; Kalkan, S; Akbas, E				Oksuz, Kemal; Cam, Baris Can; Kalkan, Sinan; Akbas, Emre			Imbalance Problems in Object Detection: A Review	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Object detection; Taxonomy; Feature extraction; Deep learning; Pipelines; Neural networks; Pattern analysis; Object detection; imbalance; class imbalance; scale imbalance; spatial imbalance; objective imbalance	FACE DETECTION	In this paper, we present a comprehensive review of the imbalance problems in object detection. To analyze the problems in a systematic manner, we introduce a problem-based taxonomy. Following this taxonomy, we discuss each problem in depth and present a unifying yet critical perspective on the solutions in the literature. In addition, we identify major open issues regarding the existing imbalance problems as well as imbalance problems that have not been discussed before. Moreover, in order to keep our review up to date, we provide an accompanying webpage which catalogs papers addressing imbalance problems, according to our problem-based taxonomy. Researchers can track newer studies on this webpage available at: https://github.com/kemaloksuz/ObjectDetectionImbalance.	[Oksuz, Kemal; Cam, Baris Can; Kalkan, Sinan; Akbas, Emre] Middle East Tech Univ METU, Dept Comp Engn, TR-06800 Ankara, Turkey	Middle East Technical University	Oksuz, K (corresponding author), Middle East Tech Univ METU, Dept Comp Engn, TR-06800 Ankara, Turkey.	kemal.oksuz@metu.edu.tr; can.cam@metu.edu.tr; skalkan@metu.edu.tr; emre@ceng.metu.edu.tr	Akbas, Emre/B-6857-2008	Akbas, Emre/0000-0002-3760-6722; Oksuz, Kemal/0000-0002-0066-1517; Cam, Baris Can/0000-0001-8480-4636	Scientific and Technological Research Council of Turkey (TUBITAK) through the project titled "Object Detection in Videos with Deep Neural Networks" [117E054]; TUBITAK 2211-A National Scholarship Programme	Scientific and Technological Research Council of Turkey (TUBITAK) through the project titled "Object Detection in Videos with Deep Neural Networks"(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK)); TUBITAK 2211-A National Scholarship Programme(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK))	This work was supported in part by the Scientific and Technological Research Council of Turkey (TUBITAK) through the project titled "Object Detection in Videos with Deep Neural Networks" (grant number 117E054). The work of Kemal Oksuz was supported by the TUBITAK 2211-A National Scholarship Programme for Ph.D. students. Sinan Kalkan and Emre Akbas contributed equally to this work.	Adelson E.H., 1984, RCA ENG, V29, P33; Agarwal S., 2018, ARXIV PREPRINT ARXIV; Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bozcan I, 2019, ROBOT AUTON SYST, V113, P132, DOI 10.1016/j.robot.2018.12.009; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Cao JL, 2019, IEEE I CONF COMP VIS, P9704, DOI 10.1109/ICCV.2019.00980; Cao Y., 2019, ARXIV190404821; Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647; Chen, 2019, ARXIV PREPRINT ARXIV; Chen Joya, 2019, ARXIV190904868; Chen K, ARXIV190607155, V2019; Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526; Chen Y., 2019, DETNAS NEURAL ARCHIT, P6638; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Dai XR, 2019, SIGNAL PROCESS-IMAGE, V70, P79, DOI 10.1016/j.image.2018.09.002; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Du G., 2019, ARXIV190506658; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Dvornik N, 2018, LECT NOTES COMPUT SC, V11216, P375, DOI 10.1007/978-3-030-01258-8_23; Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fernandez A., 2018, LEARNING IMBALANCED, DOI DOI 10.1007/978-3-319-98074-4; Fu C. -Y., 2017, ARXIV170106659; Fu ZH, 2019, IEEE T IMAGE PROCESS, V28, P6077, DOI 10.1109/TIP.2019.2922095; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Gidaris Spyros, 2016, ARXIV160604446; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Goldman E, 2019, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR.2019.00537; Guo M., 2018, P ECCV, P282; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300; Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13; Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2; Howard A.G, 2017, ARXIV170404861; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jaeger P. F, 2019, MACH LEARN HLTH WORK; Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48; Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5; Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169; Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656; Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11; Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557; Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1; Lee SG, 2018, LECT NOTES COMPUT SC, V11071, P693, DOI 10.1007/978-3-030-00934-2_77; Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6; Li BY, 2019, AAAI CONF ARTIF INTE, P8577; Li HY, 2019, INT J COMPUT VISION, V127, P225, DOI 10.1007/s11263-018-1101-7; Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508; Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615; Li Z., 2019, ARXIV191205190; Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI 10.1007/978-3-030-01240-3_21; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Newell A., 2017, P ADV NEUR INF PROC, P2277; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie J, 2019, IEEE I CONF COMP VIS, P9536, DOI 10.1109/ICCV.2019.00963; Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982; Oksuz K, 2018, LECT NOTES COMPUT SC, V11211, P521, DOI 10.1007/978-3-030-01234-2_31; Oksuz K, 2020, IEEE WINT CONF APPL, P883, DOI 10.1109/WACV45572.2020.9093503; Ouyang WL, 2016, PROC CVPR IEEE, P864, DOI 10.1109/CVPR.2016.100; Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091; Pang YW, 2019, PROC CVPR IEEE, P7328, DOI 10.1109/CVPR.2019.00751; Qi Qian, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12161, DOI 10.1109/CVPR42600.2020.01218; Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Redmon J., 2016, P IEEE C COMPUTER VI, P779, DOI DOI 10.1109/CVPR.2016.91; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Rowley HA, 1996, ADV NEUR IN, V8, P875; Seferbekov S, 2018, IEEE COMPUT SOC CONF, P272, DOI 10.1109/CVPRW.2018.00051; Sermanet P., 2014, INT C LEARN REPR ICL, P1, DOI DOI 10.1016/J.VISRES.2006.11.009; Seung-Wook Kim, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11209), P239, DOI 10.1007/978-3-030-01228-1_15; Shao S, 2019, IEEE I CONF COMP VIS, P8429, DOI 10.1109/ICCV.2019.00852; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Singh B, 2018, ADV NEUR IN, V31; Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377; Song Y, 2016, PR MACH LEARN RES, V48; Sun YQ, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P297, DOI [10.1109/BigMM.2019.000-7, 10.1109/BigMM.2019.00055]; Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PR MACH LEARN RES, V97; Tan ZY, 2019, IEEE I CONF COMP VIS, P8272, DOI 10.1109/ICCV.2019.00836; Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038; Tripathi S, 2019, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2019.00055; Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang H., 2019, ABS190600358 CORR; Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xu H, 2019, IEEE I CONF COMP VIS, P6648, DOI 10.1109/ICCV.2019.00675; Yang T, 2018, ADV NEUR IN, V31; Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765; Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321; Yu F., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1006/JMBI.1990.9999; Yu Jiahui., 2016, ACM MM, DOI DOI 10.1145/2964284.2967274; Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhang XS, 2019, ADV NEUR IN, V32; Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993; Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062; Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094; Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907; Zou Z., 2018, ARXIV190505055	135	128	133	152	367	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3388	3415		10.1109/TPAMI.2020.2981890	http://dx.doi.org/10.1109/TPAMI.2020.2981890			28	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32191882	Green Submitted			2022-12-18	WOS:000692232400012
J	Cappelli, R; Ferrara, M; Maltoni, D				Cappelli, Raffaele; Ferrara, Matteo; Maltoni, Davide			Fingerprint Indexing Based on Minutia Cylinder-Code	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Terms-Fingerprints; identification; indexing; locality-sensitive hashing; minutiae cylinder-code	CLASSIFICATION; IDENTIFICATION; RETRIEVAL	This paper proposes a new hash-based indexing method to speed up fingerprint identification in large databases. A Locality-Sensitive Hashing (LSH) scheme has been designed relying on Minutiae Cylinder-Code (MCC), which proved to be very effective in mapping a minutiae-based representation (position/angle only) into a set of fixed-length transformation-invariant binary vectors. A novel search algorithm has been designed thanks to the derivation of a numerical approximation for the similarity between MCC vectors. Extensive experimentations have been carried out to compare the proposed approach against 15 existing methods over all the benchmarks typically used for fingerprint indexing. In spite of the smaller set of features used (top performing methods usually combine more features), the new approach outperforms existing ones in almost all of the cases.	[Cappelli, Raffaele; Ferrara, Matteo; Maltoni, Davide] Univ Bologna, DEIS, I-47521 Cesena, FC, Italy	University of Bologna	Cappelli, R (corresponding author), Univ Bologna, DEIS, Via Sacchi 3, I-47521 Cesena, FC, Italy.	raffaele.cappelli@unibo.it; matteo.ferrara@unibo.it; davide.maltoni@unibo.it	FERRARA, MATTEO/AAG-2654-2019	FERRARA, MATTEO/0000-0002-4020-1419; Cappelli, Raffaele/0000-0003-3054-9363				[Anonymous], 2005, 1979422005 ISO IEC; Bhanu B, 2003, IEEE T PATTERN ANAL, V25, P616, DOI 10.1109/TPAMI.2003.1195995; *BIOLAB, 2009, FVC2006 WEB SIT; Candela G. T., 1995, PCASYSA PATTERN LEVE; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Cappelli R, 2002, PATTERN ANAL APPL, V5, P136, DOI 10.1007/s100440200012; Cappelli R, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P183, DOI 10.1007/0-387-21685-5_9; Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52; de Boer J., 2001, P WORKSH CIRC SYST S, P300; FENG J, 2006, P INT C PATT REC; Germain RS, 1997, IEEE COMPUT SCI ENG, V4, P42, DOI 10.1109/99.641608; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gyaourova A., 2008, P 7 INT WORKSH STAT; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jiang XD, 2006, IEEE T INF FOREN SEC, V1, P532, DOI 10.1109/TIFS.2006.885021; LEE S, 2005, P AUDIO VIDEO BASED; LI J, 2006, P 18 INT C PATT REC, V1; LIANG X, 2006, P 3 INT S VOR DIAGR; Liang XF, 2007, IEEE T INF FOREN SEC, V2, P721, DOI 10.1109/TIFS.2007.910242; LIU M, 2006, P 18 INT C PATT REC, V1; Lumini A, 1997, PATTERN RECOGN LETT, V18, P1027, DOI 10.1016/S0167-8655(97)00127-X; Maeda T, 2001, IEICE T INF SYST, VE84D, P819; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; MAIO D, 2002, P INT C PATT REC, V16; Maltoni D., 2009, HDB FINGERPRINT RECO; MIMAROGLU S, 2008, P INT C DAT MIN; Shuai X, 2008, 19 INT C PATT REC 20, P1; Watson C. I., 1993, NIST SPECIAL DATABAS	30	128	136	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					1051	1057		10.1109/TPAMI.2010.228	http://dx.doi.org/10.1109/TPAMI.2010.228			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	21173446				2022-12-18	WOS:000288677800014
J	Feng, JJ; Jain, AK				Feng, Jianjiang; Jain, Anil K.			Fingerprint Reconstruction: From Minutiae to Phase	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint synthesis; fingerprint reconstruction; interoperability; minutiae; phase image; orientation field; singularity; AM-FM	IMAGE; MODEL	Fingerprint matching systems generally use four types of representation schemes: grayscale image, phase image, skeleton image, and minutiae, among which minutiae-based representation is the most widely adopted one. The compactness of minutiae representation has created an impression that the minutiae template does not contain sufficient information to allow the reconstruction of the original grayscale fingerprint image. This belief has now been shown to be false; several algorithms have been proposed that can reconstruct fingerprint images from minutiae templates. These techniques try to either reconstruct the skeleton image, which is then converted into the grayscale image, or reconstruct the grayscale image directly from the minutiae template. However, they have a common drawback: Many spurious minutiae not included in the original minutiae template are generated in the reconstructed image. Moreover, some of these reconstruction techniques can only generate a partial fingerprint. In this paper, a novel fingerprint reconstruction algorithm is proposed to reconstruct the phase image, which is then converted into the grayscale image. The proposed reconstruction algorithm not only gives the whole fingerprint, but the reconstructed fingerprint contains very few spurious minutiae. Specifically, a fingerprint image is represented as a phase image which consists of the continuous phase and the spiral phase (which corresponds to minutiae). An algorithm is proposed to reconstruct the continuous phase from minutiae. The proposed reconstruction algorithm has been evaluated with respect to the success rates of type-I attack (match the reconstructed fingerprint against the original fingerprint) and type-II attack (match the reconstructed fingerprint against different impressions of the original fingerprint) using a commercial fingerprint recognition system. Given the reconstructed image from our algorithm, we show that both types of attacks can be successfully launched against a fingerprint recognition system.	[Feng, Jianjiang] Tsinghua Univ, Inst Informat Proc, Dept Automat, Beijing 100084, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Jain, Anil K.] Korea Univ, Dept Brain & Cognit Engn, WCU Project, Seoul, South Korea	Tsinghua University; Michigan State University; Korea University	Feng, JJ (corresponding author), Tsinghua Univ, Inst Informat Proc, Dept Automat, Beijing 100084, Peoples R China.	jfeng@tsinghua.edu.cn; jain@cse.msu.edu	Feng, Jianjiang/I-3386-2012		ARO [W911NF-06-1-0418]; NIJ [2007-RG-CX-K183]; Ministry of Education, Science, and Technology [R31-2008- 000-10008-0]	ARO; NIJ; Ministry of Education, Science, and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea)	The authors would like to thank Dr. Kieran G. Larkin, Canon Information Systems Research Australia (CiSRA), for his help in generating the synthetic fingerprint in Fig. 8. This work was supported by ARO grant W911NF-06-1-0418 and NIJ grant 2007-RG-CX-K183. Author Anil Jain's work was partially supported by the World Class University (WCU) program through the National Research Foundation of Korea funded by the Ministry of Education, Science, and Technology (R31-2008- 000-10008-0) to the Department of Brain and Cognitive Engineering, Korea University. A preliminary version of this paper is contained in [1].	Araque JL, 2002, INT C PATT RECOG, P422, DOI 10.1109/ICPR.2002.1048329; ASAI K, 1987, Patent No. 4646352; Bazen A. M., 2000, P WORKSH CIRC SYST S, P205; Bazen AM, 2003, PATTERN RECOGN, V36, P1859, DOI 10.1016/S0031-3203(03)00036-0; BICZ W, 2003, IDEA DESCRIPTION REC; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; Cappelli R, 2007, IEEE T PATTERN ANAL, V29, P1489, DOI 10.1109/TPAMI.2007.1087; Cummins H, 1961, FINGER PRINTS PALMS; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Feng JJ, 2006, PATTERN RECOGN, V39, P2131, DOI 10.1016/j.patcog.2006.05.001; Feng JJ, 2009, LECT NOTES COMPUT SC, V5558, P544, DOI 10.1007/978-3-642-01793-3_56; Ghiglia D.C., 1998, 2 DIMENSIONAL PHASE; GOLDSTEIN RM, 1988, RADIO SCI, V23, P713, DOI 10.1029/RS023i004p00713; HARA M, 2007, Patent No. 7295688; Hill C.J., 2001, THESIS AUSTR NATL U; Kucken M, 2005, J THEOR BIOL, V235, P71, DOI 10.1016/j.jtbi.2004.12.020; LARKIN KG, 2001, P 4 INT WORKSH AUT P; Larkin KG, 2007, OPT EXPRESS, V15, P8667, DOI 10.1364/OE.15.008667; Maltoni D., 2009, HDB FINGERPRINT RECO; Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165; *NEUR INC, 2010, VERIFINGER; *NIST, 2010, NIST MIN INT EXCH TE; *NIST, 2010, NIST SPEC DAT 4 NIST; Nixon KA, 2005, P SOC PHOTO-OPT INS, V5779, P214, DOI 10.1117/12.606643; NOVIKOV SO, 1997, P SPIE INT WORKSH DI, P270; Ratha NK, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; Thebaud L. R., 1999, U. S. Patent, Patent No. [5909501 A, 5909501]; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9; WITKIN A, 1991, COMP GRAPH, V25, P299, DOI 10.1145/127719.122750; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; 2010, FVC2004 3 INT FING V; 2010, FVC2002 2 INT FINGER	35	128	149	1	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					209	223		10.1109/TPAMI.2010.77	http://dx.doi.org/10.1109/TPAMI.2010.77			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	21193805	Green Submitted			2022-12-18	WOS:000285313200001
J	Yang, L; Jin, R; Mummert, L; Sukthankar, R; Goode, A; Zheng, B; Hoi, SCH; Satyanarayanan, M				Yang, Liu; Jin, Rong; Mummert, Lily; Sukthankar, Rahul; Goode, Adam; Zheng, Bin; Hoi, Steven C. H.; Satyanarayanan, Mahadev			A Boosting Framework for Visuality-Preserving Distance Metric Learning and Its Application to Medical Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; image retrieval; distance metric learning; boosting	COMPUTER-AIDED DETECTION; BREAST MASSES; SIMILARITY; DIAGNOSIS	Similarity measurement is a critical component in content-based image retrieval systems, and learning a good distance metric can significantly improve retrieval performance. However, despite extensive study, there are several major shortcomings with the existing approaches for distance metric learning that can significantly affect their application to medical image retrieval. In particular, "similarity" can mean very different things in image retrieval: resemblance in visual appearance (e. g., two images that look like one another) or similarity in semantic annotation (e. g., two images of tumors that look quite different yet are both malignant). Current approaches for distance metric learning typically address only one goal without consideration of the other. This is problematic for medical image retrieval where the goal is to assist doctors in decision making. In these applications, given a query image, the goal is to retrieve similar images from a reference library whose semantic annotations could provide the medical professional with greater insight into the possible interpretations of the query image. If the system were to retrieve images that did not look like the query, then users would be less likely to trust the system; on the other hand, retrieving images that appear superficially similar to the query but are semantically unrelated is undesirable because that could lead users toward an incorrect diagnosis. Hence, learning a distance metric that preserves both visual resemblance and semantic similarity is important. We emphasize that, although our study is focused on medical image retrieval, the problem addressed in this work is critical to many image retrieval systems. We present a boosting framework for distance metric learning that aims to preserve both visual and semantic similarities. The boosting framework first learns a binary representation using side information, in the form of labeled pairs, and then computes the distance as a weighted Hamming distance using the learned binary representation. A boosting algorithm is presented to efficiently learn the distance function. We evaluate the proposed algorithm on a mammographic image reference library with an Interactive Search-Assisted Decision Support (ISADS) system and on the medical image data set from ImageCLEF. Our results show that the boosting framework compares favorably to state-of-the-art approaches for distance metric learning in retrieval accuracy, with much lower computational cost. Additional evaluation with the COREL collection shows that our algorithm works well for regular image data sets.	[Yang, Liu] Carnegie Mellon Univ, Sch Comp Sci, Machine Learning Dept, Pittsburgh, PA 15231 USA; [Jin, Rong] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Mummert, Lily; Sukthankar, Rahul] Intel Res, Pittsburgh, PA 15213 USA; [Zheng, Bin] Univ Pittsburgh, Dept Radiol, Med Ctr, Pittsburgh, PA 15213 USA; [Hoi, Steven C. H.] Nanyang Technol Univ, Sch Comp Engn, Div Informat Syst, Singapore 639798, Singapore	Carnegie Mellon University; Michigan State University; Intel Corporation; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Yang, L (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Machine Learning Dept, 5000 Forbes Ave, Pittsburgh, PA 15231 USA.	liuy@cs.cmu.edu; rongjin@cse.msu.edu; lily.b.mummert@intel.com; rahuls@cs.cmu.edu; agoode@andrew.cmu.edu; zengb@upmc.edu; chhoi@ntu.edu.sg; satya@cs.cmu.edu	HOI, Steven C. H./A-3736-2011	Hoi, Steven/0000-0002-4584-3453; Satyanarayanan, Mahadev/0000-0002-2187-2049	US National Science Foundation (NSF) [IIS-0643494]; National Center for Research Resources (NCRRs) [1 UL1 RR024153]; NATIONAL CENTER FOR RESEARCH RESOURCES [UL1RR024153] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); National Center for Research Resources (NCRRs)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))	This work was supported by the US National Science Foundation (NSF) under grant IIS-0643494 and by the National Center for Research Resources (NCRRs) under grant No. 1 UL1 RR024153. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF, NCRR, Intel, Michigan State University, or Carnegie Mellon University.	AGARWAL S, 2007, P INT C ART INT STAT; Alto H, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1902996; BABENKO B, 2007, P INT C COMP VIS; Belkin M., 2007, ADV NEURAL INFORM PR; BOIMAN O, 2007, ADV NEURAL INFORM PR; Croskerry P., 2005, CAN J ANAESTH, V52, pR1, DOI [10.1007/BF03023077, DOI 10.1007/BF03023077]; Davis J.V., 2007, P INT C MACH LEARN; DILLON J, 2007, P C UNC ART INT; DOLLAR P, 2007, P INT C MACH LEARN; El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601; Freer TW, 2001, RADIOLOGY, V220, P781, DOI 10.1148/radiol.2203001282; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Frome A., 2007, ADV NEURAL INFORM PR; Giger ML, 2002, PROC SPIE, V4684, P768, DOI 10.1117/12.467222; Goldberger J., 2005, NEURIPS; Gur D, 2004, J NATL CANCER I, V96, P717, DOI 10.1093/jnci/djh129; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HERTZ T, 2006, P INT C MACH LEARN; HERTZ T, 2004, P INT C MACH LEARN; HILLEL AB, 2003, P INT C MACH LEARN; HILLEL AB, 2007, P INT C MACH LEARN; HOI SCH, 2006, P IEEE CS C COMP VIS; KE Y, 2005, P IEEE CS C COMP VIS; Khoo LAL, 2005, RADIOLOGY, V237, P444, DOI 10.1148/radiol.2372041362; Kim H, 2005, J MACH LEARN RES, V6, P37; Kim T.-K., 2007, P IEEE C COMP VIS PA; Ko JM, 2006, AM J ROENTGENOL, V187, P1483, DOI 10.2214/AJR.05.1582; KWOK JT, 2003, P INT C MACH LEARN; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LI F, 2007, P INT C MACH LEARN; MOGHADDHAM B, 2000, P INT C FAC GEST REC; Muramatsu C, 2005, MED PHYS, V32, P2295, DOI 10.1118/1.1944913; Nishikawa RM, 2006, MED PHYS, V33, P811, DOI 10.1118/1.2168063; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; Salakhutdinov R., 2003, P C UNC ART INT; Schapire R. E., 1999, P INT C ALG LEARN TH; Schultz M., 2004, ADV NEURAL INFORM PR; Shakhnarovich G., 2005, THESIS MIT; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SUGIYAMA M, 2006, P INT C MACH LEARN; TAO Y, 2007, P SPIE C MED IM 07; Torresani L., 2007, NEURIPS; Tourassi GD, 2007, MED PHYS, V34, P140, DOI 10.1118/1.2401667; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; WANG H, 2007, P INT C MACH LEARN; Wei CH, 2005, PROC SPIE, V5748, P134, DOI 10.1117/12.594929; Weinberger K., 2006, ADV NEURAL INFORM PR; Weinberger K. Q., 2007, ADV NEURAL INFORM PR; WOZNICA A, 2007, P INT C MACH LEARN; Xing EP., 2003, ADV NIPS; Yang L., 2006, DISTANCE METRIC LEAR; YANG L, 2006, P NATL C ART INT; YANG L, 2007, P SPIE C MED IM; Yang L, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.280; ZHANG J, 2007, P INT C MACH LEARN; ZHANG W, 2007, P INT C MACH LEARN; Zhang Z., 2007, ADV NEURAL INFORM PR; Zheng B, 2006, MED PHYS, V33, P111, DOI 10.1118/1.2143139; Zheng B, 2004, AM J ROENTGENOL, V182, P579, DOI 10.2214/ajr.182.3.1820579; Zheng B, 2007, ACAD RADIOL, V14, P917, DOI 10.1016/j.acra.2007.04.012; Zhou D., 2007, ADV NEURAL INFORM PR; ZHOU S, 2006, P IEEE CS C COMP VIS; IMAGECLEF	63	128	136	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					30	44		10.1109/TPAMI.2008.273	http://dx.doi.org/10.1109/TPAMI.2008.273			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926897	Green Submitted, Green Accepted			2022-12-18	WOS:000271826700004
J	Yang, HD; Sclaroff, S; Lee, SW				Yang, Hee-Deok; Sclaroff, Stan; Lee, Seong-Whan			Sign Language Spotting with a Threshold Model Based on Conditional Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sign language recognition; sign language spotting; conditional random field; threshold model	RECOGNITION; TIME	Sign language spotting is the task of detecting and recognizing signs in a signed utterance, in a set vocabulary. The difficulty of sign language spotting is that instances of signs vary in both motion and appearance. Moreover, signs appear within a continuous gesture stream, interspersed with transitional movements between signs in a vocabulary and nonsign patterns (which include out-of-vocabulary signs, epentheses, and other movements that do not correspond to signs). In this paper, a novel method for designing threshold models in a conditional random field (CRF) model is proposed which performs an adaptive threshold for distinguishing between signs in a vocabulary and nonsign patterns. A short-sign detector, a hand appearance-based sign verification method, and a subsign reasoning method are included to further improve sign language spotting accuracy. Experiments demonstrate that our system can spot signs from continuous data with an 87.0 percent spotting rate and can recognize signs from isolated data with a 93.5 percent recognition rate versus 73.5 percent and 85.4 percent, respectively, for CRFs without a threshold model, short-sign detection, subsign reasoning, and hand appearance-based sign verification. Our system can also achieve a 15.0 percent sign error rate (SER) from continuous data and a 6.4 percent SER from isolated data versus 76.2 percent and 14.5 percent, respectively, for conventional CRFs.	[Yang, Hee-Deok; Lee, Seong-Whan] Korea Univ, Dept Comp Sci & Engn, Seoul 136713, South Korea; [Sclaroff, Stan] Boston Univ, Dept Comp Sci, Coll Arts & Sci, Boston, MA 02215 USA	Korea University; Boston University	Yang, HD (corresponding author), Korea Univ, Dept Comp Sci & Engn, Asan Sci Bldg,Room 238, Seoul 136713, South Korea.	hdyang@image.korea.ac.kr; sclaroff@cs.bu.edu; swlee@image.korea.ac.kr	Lee, Seong-Whan/C-7928-2012; Yang, Hee-Deok/I-3157-2013	Yang, Hee-Deok/0000-0001-7726-1442	Ministry of Education, Science and Technology, Republic of Korea [R31-2008-000-10008-0]; Development of Context Adaptive Cognition Technology [2008-F-038-01]; US National Science Foundation [0329009, 0705749]	Ministry of Education, Science and Technology, Republic of Korea(Ministry of Education, Science & Technology (MEST), Republic of Korea); Development of Context Adaptive Cognition Technology; US National Science Foundation(National Science Foundation (NSF))	This research was supported by World Class University Project funded by the Ministry of Education, Science and Technology, Republic of Korea (R31-2008-000-10008-0). This work was also supported by the IT R&D program of MKE/IITA (2008-F-038-01, Development of Context Adaptive Cognition Technology). Stan Sclaroff was supported in part by the US National Science Foundation under Grant 0329009 and Grant 0705749. The authors would like to thank the National Center for Sign Language and Gesture Resources, Boston University for providing the SignStream database.	Alon J, 2005, LECT NOTES COMPUT SC, V3766, P189, DOI 10.1007/11573425_19; ALON J, 2005, P IEEE WORKSH MOT VI, P254; ALON J, 2006, THESIS BOSTON U; Battison R, 1978, LEXICAL BORROWING AM; Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332; BOWDEN R, 2004, P 8 EUR C COMP VIS M, P391; BRAFFORT A, 1996, PROGR GESTURAL INTER, P17; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; COLE RA, 1997, SURVEY STATE ART HUM; *CUR LABS, 2004, POSER5 REF MAN; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dietterich T.G., 2002, P JOINT IAPR INT WOR, V2396, P15; FARHADI A, 2006, P CVPR, P1471; FORSSTROM A., 2007, P IEEE C COMP VIS PA, P1; Gao W, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P553; GUNAWARDANA A, 2005, P INT, P1117; Holden EJ, 2005, MACH VISION APPL, V16, P312, DOI 10.1007/s00138-005-0003-1; IMAGAWA K, 2000, P 4 IEEE INT C AUT F, P849; JELINEK J, 1997, STAT METHODS SPEECH; KASTURI R, 1991, COMPUTER VISION PRIN; Kudo T., 2005, CRF YET ANOTHER CRF; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904; McCallum Andrew, 2000, P 17 INT C MACH LEAR, P591; Morency L. -P., 2007, P I C COMP VI PATT R, P1, DOI DOI 10.1109/CVPR.2007.383299; NAYAK S, 2005, P IEEE WORKSH VIS HU, P81; Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROSE RC, 1992, P IEEE INT C AC SPEE, P105; Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Stokoe WC, 2005, J DEAF STUD DEAF EDU, V10, P3, DOI 10.1093/deafed/eni001; Szummer M, 2005, PROC INT CONF DOC, P1188, DOI 10.1109/ICDAR.2005.151; Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895; Wallach H.M, 2004, MSCIS0421 U PENNS; Wilcox L. D., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P97, DOI 10.1109/ICASSP.1992.226111; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Xi DH, 2003, LECT NOTES COMPUT SC, V2688, P199; Yang E, 2006, J PHYCOL, V42, P18; Yang HD, 2007, IEEE T ROBOT, V23, P256, DOI 10.1109/TRO.2006.889491; Yang HD, 2006, INT J PATTERN RECOGN, V20, P377, DOI 10.1142/S0218001406004715; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803	43	128	128	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1264	1277		10.1109/TPAMI.2008.172	http://dx.doi.org/10.1109/TPAMI.2008.172			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443924				2022-12-18	WOS:000266188900010
J	Triesch, J; von der Malsburg, C				Triesch, J; von der Malsburg, C			A system for person-independent hand posture recognition against complex backgrounds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; human computer interaction; human robot interaction; hand posture recognition; gesture recognition; object recognition; segmentation; complex backgrounds; elastic graph matching; Gabor wavelets	GESTURE	A computer vision system for person-independent recognition of hand postures against complex backgrounds is presented. The system Is based on Elastic Graph Matching (EGM), which was extended to allow for combinations of different feature types at the graph nodes.	Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA; Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany; Univ So Calif, Lab Computat & Biol Vis, Los Angeles, CA 90089 USA	University of California System; University of California San Diego; Ruhr University Bochum; University of Southern California	Triesch, J (corresponding author), Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA.							Becker M, 1999, AUTON ROBOT, V6, P203, DOI 10.1023/A:1008839628783; BICHSEL M, 1995, P INT WORKSH AUT FAC; CUI Y, 1995, P INT WORKSH AUT FAC, P201; CUI Y, 1996, P 2 INT C AUT FAC GE; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freeman W T, 1995, P INT WORKSH AUT FAC, P296; HUNTER E, 1995, P INT WORKSH AUT FAC, P290; KAVANAUGH ME, 1996, P 2 INT C AUT FAC GE; KOHLER M, 1997, 638 U DORTM INF VII; KRUGER N, 1998, THESIS U BIELEFELD G; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Maggioni C., 1995, P INT WORKSH AUT FAC; Min BW, 1999, J VISUAL LANG COMPUT, V10, P291, DOI 10.1006/jvic.1999.0117; NOKER C, 1997, GESTER SIGN LANGUAGE, P209; Pavlovic V. I., 1997, IEEE T PATTERN ANAL, V19; STORMS P, 1998, P 3 INT C AUT FAC GE; TITSWORTH FM, 2000, P 4 INT C AUT FAC GE; TRIESCH J, 1998, P 2 INT C AUT FAC GE; Verri A., 1995, P INT WORKSH AUT FAC, P116; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; WISKOTT L, 1995, REIHE PHYSIK, V53	21	128	133	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1449	1453		10.1109/34.977568	http://dx.doi.org/10.1109/34.977568			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY		Green Published			2022-12-18	WOS:000172634700010
J	FLEET, DJ; JEPSON, AD				FLEET, DJ; JEPSON, AD			STABILITY OF PHASE INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AFFINE DEFORMATION; BANDPASS FILTERS; BINOCULAR DISPARITY; INSTANTANEOUS FREQUENCY; OPTICAL FLOW; PHASE; PHASE SINGULARITIES	IMAGES; COMPUTATION; FILTERS; VISION	This paper concerns the robustness of local phase information for measuring image velocity and binocular disparity. It addresses the dependence of phase behavior on the initial filters as well as the image variations that exist between different views of a 3-D scene. We are particularly interested in the stability of phase with respect to geometric deformations, and its linearity as a function of spatial position. These properties are important to the use of phase information, and are shown to depend on the form of the filters as well as their frequency bandwidths. Phase instabilities are also discussed using the model of phase singularities described by Jepson and Fleet. In addition to phase-based methods, these results are directly relevant to differential optical flow methods and zero-crossing tracking.	UNIV TORONTO, DEPT COMP SCI, TORONTO M5S 1A4, ONTARIO, CANADA	University of Toronto	FLEET, DJ (corresponding author), QUEENS UNIV, DEPT COMP & INFORMAT SCI, KINGSTON K7L 3N6, ONTARIO, CANADA.			/0000-0003-0734-7114				BARRON JL, RPLTR9207 QUEENS U K; BARRON JL, IN PRESS INT J COMPU; BOASHASH B, 1992, P IEEE, V80, P520, DOI 10.1109/5.135376; BURT PJ, 1989, IEEE MOTION WORKSHOP, P2; Davenport WB, 1958, INTRO THEORY RANDOM; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M; Fleet DJ, 1992, MEASUREMENT IMAGE VE; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GIROD B, 1989, P OPT SOC AM M UND M, P73; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; JENKIN M, 1988, COMPUTATIONAL PROCES; Jepson A. D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P398, DOI 10.1109/CVPR.1989.37877; JEPSON AD, 1991, IMAGE VISION COMPUT, V9, P338, DOI 10.1016/0262-8856(91)90039-R; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; Langley K., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P846, DOI 10.1109/CVPR.1992.223242; LANGLEY K, 1990, 1ST P EUR C COMP VIS, P315; MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MAXMAN AM, 1988, P IEEE CVPR ANN ARBO, P717; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; OGLE KN, 1956, RES BINOCULAR VISION; Olson T. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P404, DOI 10.1109/CVPR.1989.37878; Papoulis A., 2002, PROBABILITY RANDOM V; SANGER TD, 1988, BIOL CYBERN, V59, P405, DOI 10.1007/BF00336114; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; WENG J, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P200; WESTELIUS CJ, 1992, THESIS LINKOPING U S, P14; WIKLUND J, 1992, LITHISYI1327 LINK U; Wilson R., 1989, Third International Conference on Image Processing and its Applications (Conf. Publ. No.307), P19; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	36	128	134	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1253	1268		10.1109/34.250844	http://dx.doi.org/10.1109/34.250844			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600004
J	Zhang, C; Butepage, J; Kjellstrom, H; Mandt, S				Zhang, Cheng; Butepage, Judith; Kjellstrom, Hedvig; Mandt, Stephan			Advances in Variational Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Variational inference; approximate Bayesian inference; reparameterization gradients; structured variational approximations; scalable inference; inference networks	MONTE-CARLO; MODELS; APPROXIMATIONS; DIVERGENCE; SELECTION	Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully applied to various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.	[Zhang, Cheng] Microsoft Res, Cambridge CB1 2FB, England; [Butepage, Judith; Kjellstrom, Hedvig] KTH Royal Inst Technol, S-11428 Stockholm, Sweden; [Mandt, Stephan] Univ Calif Irvine, Irvine, CA 92697 USA	Microsoft; Royal Institute of Technology; University of California System; University of California Irvine	Zhang, C (corresponding author), Microsoft Res, Cambridge CB1 2FB, England.	cheng.zhang@microsoft.com; butepage@kth.se; hedvig@kth.se; stephan.mandt@gmail.com		Mandt, Stephan/0000-0001-7836-7839				Ahn S., 2012, P 29 INT C MACH LEAR, P123; Alemi Alex, 2017, ICLR; ALI SM, 1966, J ROY STAT SOC B, V28, P131; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Amari S., 1985, DIFFERENTIAL GEOMETR, V28; Amari SI, 2009, IEEE T INFORM THEORY, V55, P4925, DOI 10.1109/TIT.2009.2030485; Arenz O, 2018, PR MACH LEARN RES, V80; Azevedo-Filho A., 1994, Uncertainty in Artificial Intelligence. Proceedings of the Tenth Conference (1994), P28; Balan Anoop Korattikara, 2015, ADV NEURAL INFORM PR, P3; Balles L, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017); Bamler R., 2017, P INT C MACH LEARN W; Bamler R, 2017, ADV NEUR IN, V30; Bamler R, 2017, PR MACH LEARN RES, V70; Bishop CM, 2006, PATTERN RECOGNITION; Blei D., 2006, NIPS, V18, P147, DOI [10.5555/2976248.2976267, DOI 10.5555/2976248.2976267, DOI 10.1145/1143844.1143859]; Blei D.M., 2006, ICML, V25-29, P113; Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Bowman Samuel R, 2016, SIGNLL C COMP NAT LA, DOI DOI 10.18653/V1/K16-1002; BOYLE PP, 1977, J FINANC ECON, V4, P323, DOI 10.1016/0304-405X(77)90005-8; Broderick T., 2013, ADV NEURAL INFORM PR, V26, P1727; Brooks S, 2011, CH CRC HANDB MOD STA, pXIX; Buchholz A, 2018, PR MACH LEARN RES, V80; Bui T. D., 2016, STAT-US, V23, P1; Burda Yuri, 2016, 4 INT C LEARN REPR I; Byrd RH, 2012, MATH PROGRAM, V134, P127, DOI 10.1007/s10107-012-0572-5; Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01; Chen X., 2017, P ICLR; Cremer C., 2017, P INT C LEARN REPR W; Cremer C, 2018, PR MACH LEARN RES, V80; CSIBA D, 2018, JMLR, V19, P1; Csiszar I., 1964, MAGYER TUD AKAD MAT, V8, P95; Dai Z., 2016, INT C LEARN REPR; Damianou Andreas, 2013, ARTIF INTELL, P207, DOI DOI 10.1002/NME.1296; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; De S., 2017, P 20 INT C ART INT S, P718; Deng ZW, 2017, PROC CVPR IEEE, P6014, DOI 10.1109/CVPR.2017.637; Dieng A. B., 2017, ADV NEURAL INFORM PR, P2732; Dinh L., 2015, ICLR WS; Dinh L, 2017, 5 INT C LEARN REPR I; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Duvenaud D, 2016, JMLR WORKSH CONF PRO, V51, P1070; Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X; Foti N., 2014, ADV NEURAL INFORM PR, P3599; Friedlander MP, 2012, SIAM J SCI COMPUT, V34, pA1380, DOI 10.1137/110830629; Fu TF, 2017, PR MACH LEARN RES, V54, P841; Gal Y., 2016, THESIS, V1, P3; Gal Yarin, 2014, ADV NEURAL INF PROCE, V2, P3257; Geiger, 2017, P 31 INT C NEUR INF, P1826; Gershman S.J., 2012, P 29 INT C MACH LEAR, P235; Gershman SJ, 2014, P 36 ANN C COGN SCI; Ghahramani Z, 2015, NATURE, V521, P452, DOI 10.1038/nature14541; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gopalan Prem K, 2012, ADV NEURAL INFORM PR, P2249; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Gulrajani I., 2017, INT C LEARN REPR; Guo F. J., 2016, NEURIPS WS ADV APPRO; Han J, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017); Heinrich G., 2008, PARAMETER ESTIMATION; Hennig P., 2011, THESIS; Hensman J., 2012, ADV NEURAL INFORM PR, V25, P2888; Hensman J., 2013, P INT C UNC ART INT, P272; Hernandez-Lobato JM, 2016, PR MACH LEARN RES, V48; Hoffman MD, 2015, JMLR WORKSH CONF PRO, V38, P361; Hoffman MD, 2013, J MACH LEARN RES, V14, P1303; Hogg R.V., 1995, INTRO MATH STAT; Honkela Antti, 2007, Neural Information Processing. 14th International Conference, ICONIP 2007, P305; Honkela A., 2003, 4 INT S IND COMP AN, P803; Honkela A, 2010, J MACH LEARN RES, V11, P3235; Huszar F., 2017, ARXIV170208235; Jaakkola T, 1996, ADV NEUR IN, V8, P528; Jaakkola T. S., 2000, NATO ASI D, V89, P528; Jang E., 2015, P INT C LEARN REPR; Johnson M., 2014, P 31 INT C MACH LEAR; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kappen H. J., 2001, P 13 INT C NEUR INF, P220; Karaletsos T., 2016, P 30 C NEUR INF PROC; Khan M. E., 2015, ADV NEURAL INFORM PR, P3402; Khan ME, 2018, PR MACH LEARN RES, V80; King NJ, 2006, LECT NOTES COMPUT SC, V4212, P270; Kingma D.P, P 3 INT C LEARNING R; Kingma DP., 2016, ADV NEURAL INFORM PR, V29, P4743; Knowles D. A., 2011, ADV NEURAL INFORM PR, V24, P1701; Knowles D. A., 2015, STOCHASTIC GRADIENT; Krishnan R. G., 2015, P C NEUR INF PROC SY; Kucukelbir A, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P444; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kurihara K, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2796; Lacoste-Julien S, 2011, P 14 INT C ARTIFICIA, P416; Laplace PS, 1986, STAT SCI, V1, P621, DOI DOI 10.1214/SS/1177013621; Lazaro-Gredilla M., 2000, PATTERN RECOGN, V45, P1386; Lazaro-Gredilla M., 2011, P INT C MACH LEARN M, P841; Le Cam L., 2012, ASYMPTOTIC METHODS S; Levine Sergey, 2013, P 26 INT C NEUR INF, P207; Levine Sergey, 2018, ARXIV180500909; Li Y., 2017, ARXIV170208343; Li Y, 2018, THESIS; Li Y., 2016, P 30 INT C NEUR INF, P1081; Li Yingzhen, 2015, ADV NEURAL INFORM PR, V28, P2323, DOI DOI 10.17863/CAM.21346; Lin  Wu, 2018, ARXIV180305589; Liu Q., 2016, ADV NEURAL INFORM PR, V29, P2378; Liu Q., 2016, ARXIV161200081; Liu Q, 2016, PR MACH LEARN RES, V48; Liu Y., 2017, P INT C UNC ART INT; Lu SC, 2016, 9TH INTERNATIONAL CONFERENCE ON MICROWAVE AND MILLIMETER WAVE TECHNOLOGY (ICMMT 2016) PROCEEDINGS, VOL 2, P829, DOI 10.1109/ICMMT.2016.7762457; Maddison Chris J, 2017, ICLR; Mandt S, 2014, ADV NEURAL INFORM PR, P2438; Mandt S, 2016, PR MACH LEARN RES, V48; Mandt S, 2016, JMLR WORKSH CONF PRO, V51, P704; Marino J, 2018, PR MACH LEARN RES, V80; McInerney J, 2015, ADV NEUR IN, V28; Mescheder L, 2017, PR MACH LEARN RES, V70; Mezard M., 1990, SPIN GLASS THEORY, V9; Miao YS, 2016, PR MACH LEARN RES, V48; Miller A., 2017, ADV NEURAL INFORM PR, P3708; Miller AC, 2017, PR MACH LEARN RES, V70; Minka, 2005, DIVERGENCE MEASURES; Minka T., 2014, INFER NET 2 6; MINKA T, 2004, MSRTR2004149; Minka T.P., 2001, P 17 C UNC ART INT, P362; Mohamed Shakir, 2016, ARXIV161003483; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Naesseth CA, 2017, PR MACH LEARN RES, V54, P489; Nakajima S, 2007, NEURAL COMPUT, V19, P1112, DOI 10.1162/neco.2007.19.4.1112; Nalisnick Eric, 2017, INT C LEARN REPR ICL; Nallapati Ramesh, 2007, P INT C DAT MIN WORK, P349; Neal RM, 1993, CRGTR931 U TOR DEP C; Neal RM, 1996, LECT NOTES STAT, V118; Neiswanger W., 1999, ARXIV151004163; Nowozin S., 2018, P INT C LEARN REPR; Oates CJ, 2017, J R STAT SOC B, V79, P695, DOI 10.1111/rssb.12185; Opper, 2014, ARXIV14096179; Opper M., 2015, P C NEUR INF PROC SY; Opper M., 1996, ADV NIPS, P225; Opper M, 2001, ADV MEAN FIELD METHO; Opper M, 2013, J MACH LEARN RES, V14, P2857; Paisley J., 2012, ARXIV12066430; Perekrestenko D, 2017, PR MACH LEARN RES, V54, P869; Peterson C., 1987, Complex Systems, V1, P995; PLEFKA T, 1982, J PHYS A-MATH GEN, V15, P1971, DOI 10.1088/0305-4470/15/6/035; Porteous I., 2008, P 14 ACM SIGKDD INT, P569; Rainforth T, 2018, PR MACH LEARN RES, V80; Ranganath R., 2014, ARTIFICIAL INTELLIGE, P814; Ranganath R., 2013, P 30 INT C MACH LEAR; Ranganath R., 2016, P 33 INT C MACH LEAR, P2568; Ranganath R, 2016, ADV NEUR IN, V29; Rezende D. J., 2014, P 31 INT C MACH LEAR; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Roeder G., 2017, P INT C NEUR INF PRO, P6925; Rolfe Jason Tyler, 2017, P INT C LEARN REPR; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; Ross SM., 2006, SIMULATION; Ruiz F.J.R., 2016, UNCERTAINTY ARTIFICI, P647; Ruiz Francisco R, 2016, ADV NEURAL INFORM PR, P460; Saeedi A., 2017, AISTATS, P1309; Salimans T, 2015, PR MACH LEARN RES, V37, P1218; Sato M, 2001, NEURAL COMPUT, V13, P1649, DOI 10.1162/089976601750265045; Saul LK, 1996, J ARTIF INTELL RES, V4, P61, DOI 10.1613/jair.251; Schulman J, 2015, PR MACH LEARN RES, V37, P1889; Shah A, 2015, PR MACH LEARN RES, V37, P1594; Shi Jiaxin, 2017, ARXIV170905870; Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1259; Sonderby C., 2016, P 33 INT C MACH LEAR; Sriperumbudur B. K., 2009, ARXIV PREPRINT ARXIV; Srivastava Akash, 2017, ARXIV170301488; Stein C., 1972, PROC 6 BERKELEY S MA, VII, p583?602; Sung J, 2008, IEEE T PATTERN ANAL, V30, P2236, DOI 10.1109/TPAMI.2008.157; Sutton RS, 1998, REINFORCEMENT LEARNI, V1; Tan LSL, 2017, STAT COMPUT, V27, P237, DOI 10.1007/s11222-015-9618-x; Tanaka T, 2000, NEURAL COMPUT, V12, P1951, DOI 10.1162/089976600300015213; Tanaka T, 1998, ICONIP'98: THE FIFTH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING JOINTLY WITH JNNS'98: THE 1998 ANNUAL CONFERENCE OF THE JAPANESE NEURAL NETWORK SOCIETY - PROCEEDINGS, VOLS 1-3, P554; Tanaka T, 1999, ADV NEUR IN, V11, P351; Teh Y., 2006, ADV NEURAL INFORM PR, V19, P1353; Teh Y.W., 2005, WORKSH ART INT STAT, V2005, P333; Theis L, 2015, PR MACH LEARN RES, V37, P2503; THOULESS DJ, 1977, PHILOS MAG, V35, P593, DOI 10.1080/14786437708235992; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; Tishby Naftali, 2000, PHYSICS0004057 ARXIV; Titsias M. K., 2009, ARTIF INTELL STAT, V3; Titsias M.K., 2017, ARXIV170801529; Titsias MK, 2015, ADV NEUR IN, V28; Tolpin D., 2016, IFL; Tran D., 2016, STAT, V1050; Tran D, 2017, ADV NEUR IN, V30; Tran Dustin, 2015, P NIPS 15, P3564; Tran Dustin, 2016, ARXIV161009787; Tucker G, 2017, ADV NEUR IN, V30; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P2313, DOI 10.1109/TIT.2005.850091; Wang C., 2011, P 14 INT C ART INT S, V15, P752, DOI DOI 10.1007/978-3-642-25832-9; Wang C., 2013, ADV NEURAL INFORM PR, P181; Wang CL, 2009, IEEE T COMMUN, V57, P1903, DOI 10.1109/TCOMM.2009.07.070156; Wang C, 2013, J MACH LEARN RES, V14, P1005; Wang D., 2016, ARXIV161101722; Wang Y., 2017, P 34 INT C MACHINE L, P3684; Wang Y, 2018, J MICROENCAPSUL, V35, P494, DOI 10.1080/02652048.2018.1538265; Welling M., 2011, P 28 INT C INT C MAC, P681, DOI DOI 10.4310/CIS.2012.V12.N3.A3; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Winn J, 2005, J MACH LEARN RES, V6, P661; Yin MZ, 2018, PR MACH LEARN RES, V80; Zeiler Matthew D, 2012, ARXIV12125701; Zhai K, 2012, P 21 INT C WORLD WID, P879; Zhang, 2013, ADV NEURAL INFORM PR, P315; ZHANG C, 2016, THESIS; Zhang C., 2011, ARXIV180402772; Zhang C, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017); Zhang C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P254, DOI 10.1109/ICCVW.2013.41; Zhao P., 2014, ARXIV14053080; Zhao SS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3490; Zhaoguang Pan, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7285868; Zhe S. D., 2016, P 30 C NEUR INF PROC; Zhou X, 2017, CHIN CONTR CONF, P6466, DOI 10.23919/ChiCC.2017.8028384; ZHU H, 1995, NCRG4350 AST U	225	127	127	15	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					2008	2026		10.1109/TPAMI.2018.2889774	http://dx.doi.org/10.1109/TPAMI.2018.2889774			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30596568	Green Submitted, Bronze			2022-12-18	WOS:000473598800016
J	Masci, J; Bronstein, MM; Bronstein, AM; Schmidhuber, J				Masci, Jonathan; Bronstein, Michael M.; Bronstein, Alexander M.; Schmidhuber, Juergen			Multimodal Similarity-Preserving Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Similarity-sensitive hashing; metric learning; feature descriptor; neural network	DIMENSIONALITY REDUCTION	We introduce an efficient computational framework for hashing data belonging to multiple modalities into a single representation space where they become mutually comparable. The proposed approach is based on a novel coupled siamese neural network architecture and allows unified treatment of intra-and inter-modality similarity learning. Unlike existing cross-modality similarity learning approaches, our hashing functions are not limited to binarized linear projections and can assume arbitrarily complex forms. We show experimentally that our method significantly outperforms state-of-the-art hashing approaches on multimedia retrieval tasks.	[Masci, Jonathan; Schmidhuber, Juergen] Swiss Lab IDSIA, Manno, Switzerland; [Masci, Jonathan; Schmidhuber, Juergen] Univ Lugano USI, Fac Informat, Lugano, Switzerland; [Masci, Jonathan] SUPSI, Manno, Switzerland; [Bronstein, Michael M.] Univ Lugano USI, Inst Computat Sci, Fac Informat, Lugano, Switzerland; [Bronstein, Alexander M.] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel	Universita della Svizzera Italiana; Universita della Svizzera Italiana; Universita della Svizzera Italiana; Tel Aviv University	Masci, J (corresponding author), Swiss Lab IDSIA, Manno, Switzerland.				ERC [335491, 307047]	ERC(European Research Council (ERC)European Commission)	A.M. Bronstein was supported by the ERC Starting Grant no. 335491. M. M. Bronstein was supported by the ERC Starting Grant no. 307047.	Andoni A., 2006, P IEEE 47 ANN S FDN; Bach F. R., 2004, P 21 INT C MACH LEAR; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Bromley J., 1994, P ADV NEUR INF PROC; Bronstein M.M., 2010, P IEEE C COMP VIS PA; Chua T.S., 2009, P INT C IM VID RETR; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Davis, 2007, P 24 INT C MACH LEAR; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong Y., 2012, P ADV NEUR INF PROC; Gong Y., 2011, P IEEE C COMP VIS PA; Hadsell Raia, 2006, IEEE CVPR; Johnson R. A., 2002, APPL MULTIVARIATE ST, V4; Korman S., 2011, P IEEE INT C COMP VI; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Kulis B., 2009, P IEEE C COMP VIS PA; Kulis B., 2009, NIPS; Le Q., 2011, P INT C MACH LEARN I; Lee D. C., 2009, P IEEE C COMP VIS PA; Linnainmaa S., 1970, REPRESENTATION CUMUL; Liu W., 2012, P IEEE C COMP VIS PA; Liu W., 2011, P INT C MACH LEARN I; Masci J., 2011, ARXIV11126291; McFee B., 2009, P INT C MACH LEARN I; McFee B, 2011, J MACH LEARN RES, V12, P491; Mika S., 1999, P NEUR NETW SIGN PRO; Norouzi M., 2011, MINIMAL LOSS HASHING; Norouzi M., 2012, ADV NEURAL INFORM PR, P1; Qi G.-J., 2011, P IEEE C COMP VIS PA; Rasiwasia N., 2010, P ACM MULT; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; SCHMIDHUBER J, 1993, NEURAL COMPUT, V5, P625, DOI 10.1162/neco.1993.5.4.625; Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217; Shakhnarovich G., 2003, P IEEE C COMP VIS PA; Sharma A., 2012, P IEEE C COMP VIS PA; Shen C., 2009, P ADV NEUR INF PROC; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Taylor G.W., 2011, P IEEE C COMP VIS PA; Torralba A., 2008, P IEEE C COMP VIS PA; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wang J., P INT C MACH LEARN I; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Weiss Y., 2008, P ADV NEUR INF PROC; Werbos P.J., 1982, SYST MOD OPT P IFIP; Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3; Xing E., 2002, P ADV NEUR INF PROC	50	127	133	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					824	830		10.1109/TPAMI.2013.225	http://dx.doi.org/10.1109/TPAMI.2013.225			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353203	Green Submitted			2022-12-18	WOS:000334109000015
J	Yang, X; Cheng, KT				Yang, Xin; Cheng, Kwang-Ting (Tim)			Local Difference Binary for Ultrafast and Distinctive Feature Description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary feature descriptor; mobile devices; object recognition; tracking; augmented reality		The efficiency and quality of a feature descriptor are critical to the user experience of many computer vision applications. However, the existing descriptors are either too computationally expensive to achieve real-time performance, or not sufficiently distinctive to identify correct matches from a large database with various transformations. In this paper, we propose a highly efficient and distinctive binary descriptor, called local difference binary (LDB). LDB directly computes a binary string for an image patch using simple intensity and gradient difference tests on pairwise grid cells within the patch. A multiple-gridding strategy and a salient bit-selection method are applied to capture the distinct patterns of the patch at different spatial granularities. Experimental results demonstrate that compared to the existing state-of-the-art binary descriptors, primarily designed for speed, LDB has similar construction efficiency, while achieving a greater accuracy and faster speed for mobile object recognition and tracking tasks.	[Yang, Xin; Cheng, Kwang-Ting (Tim)] Univ Calif Santa Barbara, Elect & Comp Engn Dept, Santa Barbara, CA 93106 USA	University of California System; University of California Santa Barbara	Yang, X (corresponding author), Univ Calif Santa Barbara, Elect & Comp Engn Dept, Harold Frank Hall,Rm 4109, Santa Barbara, CA 93106 USA.	xinyang@umail.ucsb.edu; timcheng@ece.ucsb.edu		Cheng, Kwang-Ting Tim/0000-0002-3885-4912				Alahi A., 2012, P IEEE C COMP VIS PA; Bay H., 2006, ECCV; Calonder M., 2010, P EUR C COMP VIS ECC, P6; Calonder M., 2009, P IEEE INT C COMP VI; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gionis A., 2004, P INT C VER LARG DAT; Ke Y., 2004, P IEEE C COMP VIS PA; Leutengger S., 2011, P IEEE INT C COMP VI; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Philbin J, 2007, CVPR; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Rublee E., 2011, ORB EFFICIENT ALTERN, P2564; Schechtman E., 2007, P IEEE C COMP VIS PA; Simard P., 1998, P NEUR INF PROC SYST; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wagner D., 2009, P INT S MIX AUGM REA; Wagner D., 2008, P INT S MIX AUGM REA; Winder S., 2009, P IEEE C COMP VIS PA; Yang X., 2011, P ACM INT C MULT RET; Yang X., 2012, P INT S MIX AUGM REA	23	127	141	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					188	194		10.1109/TPAMI.2013.150	http://dx.doi.org/10.1109/TPAMI.2013.150			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231876				2022-12-18	WOS:000327965100016
J	Chenouard, N; Bloch, I; Olivo-Marin, JC				Chenouard, Nicolas; Bloch, Isabelle; Olivo-Marin, Jean-Christophe			Multiple Hypothesis Tracking for Cluttered Biological Image Sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Particle tracking; biological imaging; multiple hypothesis tracking; target perceivability; cluttered images	SINGLE-PARTICLE TRACKING; FEATURE POINT TRACKING; PERFORMANCE EVALUATION; OBJECT TRACKING; ALGORITHM; IMPLEMENTATION	In this paper, we present a method for simultaneously tracking thousands of targets in biological image sequences, which is of major importance in modern biology. The complexity and inherent randomness of the problem lead us to propose a unified probabilistic framework for tracking biological particles in microscope images. The framework includes realistic models of particle motion and existence and of fluorescence image features. For the track extraction process per se, the very cluttered conditions motivate the adoption of a multiframe approach that enforces tracking decision robustness to poor imaging conditions and to random target movements. We tackle the large-scale nature of the problem by adapting the multiple hypothesis tracking algorithm to the proposed framework, resulting in a method with a favorable tradeoff between the model complexity and the computational cost of the tracking procedure. When compared to the state-of-the-art tracking techniques for bioimaging, the proposed algorithm is shown to be the only method providing high-quality results despite the critically poor imaging conditions and the dense target presence. We thus demonstrate the benefits of advanced Bayesian tracking techniques for the accurate computational modeling of dynamical biological processes, which is promising for further developments in this domain.	[Chenouard, Nicolas; Olivo-Marin, Jean-Christophe] Inst Pasteur, Quantitat Image Anal Unit, F-75724 Paris 15, France; [Chenouard, Nicolas; Olivo-Marin, Jean-Christophe] CNRS, URA 2582, Paris, France; [Bloch, Isabelle] Telecom ParisTech, CNRS LTCI, F-75634 Paris 13, France	Le Reseau International des Instituts Pasteur (RIIP); Institut Pasteur Paris; Centre National de la Recherche Scientifique (CNRS); Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris	Chenouard, N (corresponding author), Inst Pasteur, Quantitat Image Anal Unit, 25 Rue Dr Roux, F-75724 Paris 15, France.	niclas.chenouard@gmail.com	Olivo-Marin, Jean-Christophe/K-4428-2015	Olivo-Marin, Jean-Christophe/0000-0001-6796-0696; Bloch, Isabelle/0000-0002-6984-1532	Institut Pasteur; CNRS; Programme C'Nano of the Region IdF; Programme C'Nano	Institut Pasteur(European Commission); CNRS(Centre National de la Recherche Scientifique (CNRS)); Programme C'Nano of the Region IdF; Programme C'Nano	The authors are thankful to Prof. Karin Luby-Phelps for providing the Golgi image sequences and to Dr. Khuloud Jaqaman for having accepted to process the benchmark data with the methods presented in [20]. They are also thankful to the reviewers and the associate editor, whose constructive criticism and detailed suggestions have led to a much improved version of the paper. They are very much appreciative of the time and effort that the reviewers generously dedicated to help them strengthen the manuscript. This work was supported in part by the Institut Pasteur, the CNRS, and the Programme C'Nano of the Region IdF. Nicolas Chenouard received the PhD fellowship from the Programme C'Nano.	Arhel N, 2006, NAT METHODS, V3, P817, DOI 10.1038/nmeth928; Bar-Shalom Y., 2001, ESTIMATION APPL TRAC; BARSHALOM Y, 2000, MULTITARGET MULTISEN, V3; Berkelaar M., 2010, LP SOLVE VERSION 5 5; Blackman S. S., 1999, DESIGN ANAL MODERN T; Blackman SS, 2004, IEEE AERO EL SYS MAG, V19, P5, DOI 10.1109/MAES.2004.1263228; Blackman SS, 2001, PROC SPIE, V4473, P470, DOI 10.1117/12.492756; BLOM HAP, 1988, IEEE T AUTOMAT CONTR, V33, P780, DOI 10.1109/9.1299; Bonneau S, 2005, IEEE T IMAGE PROCESS, V14, P1384, DOI 10.1109/TIP.2005.852794; Brandenburg B, 2007, NAT REV MICROBIOL, V5, P197, DOI 10.1038/nrmicro1615; Cheezum MK, 2001, BIOPHYS J, V81, P2378, DOI 10.1016/S0006-3495(01)75884-5; Chen D.S., 2010, APPL INTEGER PROGRAM; Chenouard N., 2010, THESIS TELECOM PARIS; Chetverikov D, 1999, COMPUTING, V62, P321, DOI 10.1007/s006070050027; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; de Chaumont F, 2012, NAT METHODS, V9, P690, DOI [10.1038/NMETH.2075, 10.1038/nmeth.2075]; Doucet A, 2001, STAT ENG IN, P3; Guerriero M., 2010, 2010 IEEE INT C WIR, P1; Jaqaman K, 2008, NAT METHODS, V5, P695, DOI 10.1038/nmeth.1237; Kurien T., 1990, MULTITARGET MULTISEN; Li N, 2001, IEEE T SIGNAL PROCES, V49, P2588, DOI 10.1109/78.960406; Li N, 2001, IEEE T AERO ELEC SYS, V37, P214, DOI 10.1109/7.913680; Mahler R., 2007, STAT MULTISOURCE MUL; Mahler R, 2007, IEEE T AERO ELEC SYS, V43, P1523, DOI 10.1109/TAES.2007.4441756; Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119; MOREFIELD CL, 1977, IEEE T AUTOMAT CONTR, V22, P302, DOI 10.1109/TAC.1977.1101500; Musicki D, 2005, IEEE DECIS CONTR P, P1228; Nicolas E, 2009, MOL BIOL CELL, V20, P556, DOI 10.1091/mbc.E08-04-0360; Olivo-Marin JC, 2002, PATTERN RECOGN, V35, P1989, DOI 10.1016/S0031-3203(01)00127-3; Poore AB, 1997, COMPUT OPTIM APPL, V8, P129, DOI 10.1023/A:1008669120497; Racine V, 2007, J MICROSC-OXFORD, V225, P214, DOI 10.1111/j.1365-2818.2007.01723.x; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ristic B., 2004, KALMAN FILTER; Ristic B, 2011, IEEE T SIGNAL PROCES, V59, P3452, DOI 10.1109/TSP.2011.2140111; Sage D, 2005, IEEE T IMAGE PROCESS, V14, P1372, DOI 10.1109/TIP.2005.852787; Saxton MJ, 1997, ANNU REV BIOPH BIOM, V26, P373, DOI 10.1146/annurev.biophys.26.1.373; Sbalzarini IF, 2005, J STRUCT BIOL, V151, P182, DOI 10.1016/j.jsb.2005.06.002; Schuhmacher D, 2008, IEEE T SIGNAL PROCES, V56, P3447, DOI 10.1109/TSP.2008.920469; Smal I, 2008, MED IMAGE ANAL, V12, P764, DOI 10.1016/j.media.2008.03.004; Smal I, 2008, IEEE T MED IMAGING, V27, P789, DOI 10.1109/TMI.2008.916964; Smal I, 2010, IEEE T MED IMAGING, V29, P282, DOI 10.1109/TMI.2009.2025127; Svensson L, 2011, IEEE T SIGNAL PROCES, V59, P4677, DOI 10.1109/TSP.2011.2161294; Thomann D, 2002, J MICROSC-OXFORD, V208, P49, DOI 10.1046/j.1365-2818.2002.01066.x; Vermaak J., 2005, P INT C INF FUS JUL, V1; Vo BT, 2007, IEEE T SIGNAL PROCES, V55, P3553, DOI 10.1109/TSP.2007.894241; Vonesch C, 2006, IEEE SIGNAL PROC MAG, V23, P20, DOI 10.1109/MSP.2006.1628875	46	127	129	0	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2736	2750		10.1109/TPAMI.2013.97	http://dx.doi.org/10.1109/TPAMI.2013.97			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051732				2022-12-18	WOS:000324830900013
J	Gaidon, A; Harchaoui, Z; Schmid, C				Gaidon, Adrien; Harchaoui, Zaid; Schmid, Cordelia			Temporal Localization of Actions with Actoms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; video analysis; temporal localization; actoms		We address the problem of localizing actions, such as opening a door, in hours of challenging video data. We propose a model based on a sequence of atomic action units, termed "actoms," that are semantically meaningful and characteristic for the action. Our actom sequence model (ASM) represents an action as a sequence of histograms of actom-anchored visual features, which can be seen as a temporally structured extension of the bag-of-features. Training requires the annotation of actoms for action examples. At test time, actoms are localized automatically based on a nonparametric model of the distribution of actoms, which also acts as a prior on an action's temporal structure. We present experimental results on two recent benchmarks for action localization "Coffee and Cigarettes" and the "DLSBP" dataset. We also adapt our approach to a classification-by-localization set-up and demonstrate its applicability on the challenging "Hollywood 2" dataset. We show that our ASM method outperforms the current state of the art in temporal action localization, as well as baselines that localize actions with a sliding window method.	[Gaidon, Adrien] Xerox Res Ctr Europe, F-38240 Meylan, France; [Harchaoui, Zaid; Schmid, Cordelia] INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, France	Xerox	Gaidon, A (corresponding author), Xerox Res Ctr Europe, 6 Chemin Maupertuis, F-38240 Meylan, France.	adrien.gaidon@xrce.xerox.com			MSR/INRIA joint project; European integrated project AXES; PASCAL 2 Network of Excellence	MSR/INRIA joint project; European integrated project AXES; PASCAL 2 Network of Excellence	This work was partially funded by the MSR/INRIA joint project, the European integrated project AXES and the PASCAL 2 Network of Excellence. The authors would like to thank Ivan Laptev for the "DLSBP" dataset.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2009, BMVC 2009 BRIT MACH; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2002, LEARNING KERNELS; Blank M., 2005, P IEEE C COMP VIS PA; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685; Brand M., 1997, P IEEE C COMP VIS PA; Brendel W., 2010, P 11 EUR C COMP VIS; Chen C.-C., 2011, PROC CVPR IEEE; Chomat O., 1999, P IEEE C COMP VIS PA, P0; Cohn J., 2006, HDB EMOTION ELICITAT; Csurka G., 2004, P EUR C COMP VIS WOR; Dalal N., 2005, HISTOGRAMS ORIENTED; DARRELL T, 1993, P IEEE C COMP VIS PA; Dollar P., 2005, P IEEE INT WORKSH VI; Duchenne O., 2009, P IEEE INT C COMP VI; EFROS AA, 2003, P 9 IEEE INT C COMP; Ekman P., 2002, FACIAL ACTION CODING; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gaidon A., 2009, P BRIT MACH VIS C; Gaidon A, 2011, PROC CVPR IEEE; Gaidon A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.30; Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Han D., 2009, P 12 IEEE INT C COMP; Hein M., 2005, P INT C ART INT STAT; Ikizler-Cinbis N., 2009, P 12 IEEE INT C COMP; Ke Y, 2010, INT J COMPUT VISION, V88, P339, DOI 10.1007/s11263-009-0308-z; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Klaser A., 2010, P INT C SIGN GEST AC; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2011, SPATIO TEMPORAL INTE; Laptev I., 2007, P 11 IEEE INT C COMP; Laxton B., 2007, P IEEE C COMP VIS PA; Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6; Lin Y, 2002, MACH LEARN, V48, P115, DOI 10.1023/A:1013951620650; Liu J., 2009, P IEEE C COMP VIS PA; Lovegrove S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.93; LV F, 2007, P IEEE C COMP VIS PA; Maji S., 2008, P IEEE C COMP VIS PA; Marszalek M., 2009, P IEEE C COMP VIS PA; Hoai M, 2011, PROC CVPR IEEE; Niebles J.C., 2010, P 11 EUR C COMP VIS; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Nowozin S., 2007, P 11 IEEE INT C COMP; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Platt J. C., 2000, ADV LARGE MARGIN CLA; POLANA R, 1994, P IEEE WORKSH NONR A; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001; Raptis M., 2012, P IEEE C COMP VIS PA; Rodriguez M.D., 2008, P 2008 IEEE C COMP V; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Satkin S., 2010, P 11 EUR C COMP VIS; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Shechtman E., 2005, P IEEE C COMP VIS PA; Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0; Simon T., 2010, P IEEE C COMP VIS PA; Sivic Josef, 2003, P 9 IEEE INT C COMP; Tang K., 2012, P IEEE C COMP VIS PA; Wang H, 2011, PROC CVPR IEEE; Wasserman L., 2004, ALL STAT CONCISE COU; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Willems G, 2008, P 10 EUR C COMP VIS; WILLEMS G, 2009, P BRIT MACH VIS C; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; YAMATO J, 1992, P IEEE C COMP VIS PA; Yao A., 2010, P IEEE C COMP VIS PA; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; ZELNIKMANOR L, 2001, P IEEE C COMP VIS PA	75	127	129	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2782	2795		10.1109/TPAMI.2013.65	http://dx.doi.org/10.1109/TPAMI.2013.65			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051735	Green Submitted			2022-12-18	WOS:000324830900016
J	Fan, B; Wu, FC; Hu, ZY				Fan, Bin; Wu, Fuchao; Hu, Zhanyi			Rotationally Invariant Descriptors Using Intensity Order Pooling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local image descriptor; rotation invariance; monotonic intensity invariance; image matching; intensity orders; SIFT	TEXTURE; REPRESENTATION; CLASSIFICATION; FEATURES	This paper proposes a novel method for interest region description which pools local features based on their intensity orders in multiple support regions. Pooling by intensity orders is not only invariant to rotation and monotonic intensity changes, but also encodes ordinal information into a descriptor. Two kinds of local features are used in this paper, one based on gradients and the other on intensities; hence, two descriptors are obtained: the Multisupport Region Order-Based Gradient Histogram (MROGH) and the Multisupport Region Rotation and Intensity Monotonic Invariant Descriptor (MRRID). Thanks to the intensity order pooling scheme, the two descriptors are rotation invariant without estimating a reference orientation, which appears to be a major error source for most of the existing methods, such as Scale Invariant Feature Transform (SIFT), SURF, and DAISY. Promising experimental results on image matching and object recognition demonstrate the effectiveness of the proposed descriptors compared to state-of-the-art descriptors.	[Fan, Bin; Wu, Fuchao; Hu, Zhanyi] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Automat Bldg,95 Zhongguancun E Rd, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Fan, B (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Automat Bldg,95 Zhongguancun E Rd, Beijing 100190, Peoples R China.	bfan@nlpr.ia.ac.cn; fcwu@nlpr.ia.ac.cn; huzy@nlpr.ia.ac.cn	Fan, Bin/AAD-8307-2019	fan, bin/0000-0002-1155-467X	National Science Foundation of China [60835003, 61075038]	National Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by the National Science Foundation of China under the grant Nos. 60835003 and 61075038. Thanks for the anonymous suggestions by the reviewers. Thanks for the helpful discussions with Prof. Shiming Xiang and Prof. Michael Werman.	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Agarwal S, 2010, COMPUTER, V43, P40, DOI 10.1109/MC.2010.175; Baumberg A., 2000, P IEEE C COMP VIS PA, V1; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Belongie S, 2001, ADV NEUR IN, V13, P831; Berg AC, 2001, PROC CVPR IEEE, P607; Chen J., 2008, P IEEE C COMP VIS PA; Cheng H., 2008, P IEEE C COMP VIS PA; Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385; Feng Tang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2631, DOI 10.1109/CVPRW.2009.5206550; Forssen P.-E., 2007, PROC IEEE 11TH INTL; Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; GUPTA R, 2007, P IEEE 11 INT C COMP; Gupta R, 2008, LECT NOTES COMPUT SC, V5303, P265, DOI 10.1007/978-3-540-88688-4_20; Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195; Harada T, 2010, LECT NOTES COMPUT SC, V6314, P736, DOI 10.1007/978-3-642-15561-1_53; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Heikkila M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Joliffe I. T., 1986, PRINCIPAL COMPONENT; Ke Y, 2004, PROC CVPR IEEE, P506; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Mittal A., 2006, 2006 IEEE COMP SOC C, V1, P849; Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1; MORTENSEN EN, 2005, PROC CVPR IEEE, P184, DOI DOI 10.1109/CVPR.2005.45; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009; TOLA E, 2008, P IEEE C COMP VIS PA; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574; Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839; Winder SAJ, 2007, PROC CVPR IEEE, P17; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	44	127	157	1	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					2031	2045		10.1109/TPAMI.2011.277	http://dx.doi.org/10.1109/TPAMI.2011.277			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22201063				2022-12-18	WOS:000307522700013
J	Rathi, Y; Vaswani, N; Tannenbaum, A; Yezzi, A				Rathi, Yogesh; Vaswani, Namrata; Tannenbaum, Allen; Yezzi, Anthony			Tracking deforming objects using particle filtering for geometric active contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; particle filters; geometric active contours	VELOCITY; MOTION	Tracking deforming objects involves estimating the global motion of the object and its local deformations as a function of time. Tracking algorithms using Kalman filters or particle filters have been proposed for finite dimensional representations of shape, but these are dependent on the chosen parametrization and cannot handle changes in curve topology. Geometric active contours provide a framework which is parametrization independent and allow for changes in topology. In the present work, we formulate a particle filtering algorithm in the geometric active contour framework that can be used for tracking moving and deforming objects. To the best of our knowledge, this is the first attempt to implement an approximate particle filtering algorithm for tracking on a ( theoretically) infinite dimensional state space.	Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA	University System of Georgia; Georgia Institute of Technology; Iowa State University	Rathi, Y (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, VL E392B, Atlanta, GA 30332 USA.	Yogesh.rathi@gatech.edu; Namrata@iastate.edu; tannenba@gatech.edu; ayezzi@ece.gatech.edu	Yezzi, Anthony/AAB-4235-2020		NCRR NIH HHS [P41 RR-13218, P41 RR013218] Funding Source: Medline; NIBIB NIH HHS [U54 EB005149, U54 EB005149] Funding Source: Medline; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB005149] Funding Source: NIH RePORTER	NCRR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NIBIB NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cremers D, 2002, LECT NOTES COMPUT SC, V2351, P93; CREMERS D, 2003, P IEEE WORKSH VAR GE; Doucet A., 2001, SEQUENTIAL MONTE CAR; DOUCET A, 1998, 310 CUEDFINFENGTR CA; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JACKSON J, 2004, P IEEE C DEC CONTR; KATSH SM, 2001, J APP PRAC PROCESS, V3, P290; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374; Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NIETHAMMER M, 2004, P CVPR, V1, P660; OKUMA K, 2004, BOOSTED PARTICLE FIL; Osher S, 2003, LEVEL SET METHODS DY; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; PARAGIOS N, 2005, P C COMP VIS IM UND; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Peterfreund N, 1999, IEEE T PATTERN ANAL, V21, P564, DOI 10.1109/34.771328; Peterfreund N, 1999, COMPUT VIS IMAGE UND, V73, P346, DOI 10.1006/cviu.1998.0732; RATHI Y, 2005, P C COMP VIS PATT RE; ROUSSON M, 2002, P EUR C COMP VIS, P78; Sethian J. A., 1999, LEVEL SET METHODS FA; SHI Y, 2005, P C COMP VIS PATT RE; TAO H, 1999, P INT C COMP VIS ALG; Terzopoulos D., 1992, ACTIVE VISION, P3; Tweed D., 2002, P BRIT MACH VIS C, P283; VANDERMERWE R, 2001, ADV NEURAL INFORM PR, V13; VASWANI N, 2006, P INT C AC SPEECH SI; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96; ZHANG T, 2003, P 9 IEEE INT C COMP, P1950; [No title captured]	37	127	145	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1470	1475		10.1109/TPAMI.2007.1081	http://dx.doi.org/10.1109/TPAMI.2007.1081			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568149	Green Submitted, Green Accepted			2022-12-18	WOS:000247186500014
J	Caelli, T; Kosinov, S				Caelli, T; Kosinov, S			An eigenspace projection clustering method for inexact graph matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						inexact multisubgraph matching; eigendecom position; eigenspace projections; correspondence clustering; shape matching; random graphs		In this paper, we show how inexact graph matching (that is, the correspondence between sets of vertices of pairs of graphs) can be solved using the renormalization of projections of the vertices (as defined in this case by their connectivities) into the joint eigenspace of a pair of graphs and a form of relational clustering. An important feature of this eigenspace renormalization projection clustering (EPC) method is its ability to match graphs with different number of vertices. Shock graph-based shape matching is used to illustrate the model and a more objective method for evaluating the approach using random graphs is explored with encouraging results.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2H1, Canada	University of Alberta	Caelli, T (corresponding author), Univ Alberta, Dept Comp Sci, Room 252E,Athabasca Hall, Edmonton, AB T6G 2H1, Canada.	tcaelli@ualberta.ca		Caelli, Terry/0000-0001-9281-2556				DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; IDE JS, 2002, P BRAZ S ART INT; Kumar V., 2000, COMP DOCUMENT CLUSTE; LEE SW, 1989, PATTERN RECOGN LETT, V9, P137, DOI 10.1016/0167-8655(89)90046-9; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; PELILLO M, 2001, LECT NOTES COMPUTER, V2059, P583; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Scott G., 1991, P ROYAL SOC LONDON B; SHAPIRO L, 1992, P INT VER HDL C, V10; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; SIDDIQI K, IN PRESS INT J COMPU; van Wyk MA, 2002, IEEE T PATTERN ANAL, V24, P988, DOI 10.1109/TPAMI.2002.1017624; WU S, 1991, PATTERN RECOGN, V24, P617; Zwick W. R., 1986, PSYCHOL B, V99	15	127	135	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					515	519		10.1109/TPAMI.2004.1265866	http://dx.doi.org/10.1109/TPAMI.2004.1265866			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382655				2022-12-18	WOS:000220102800007
J	Kato, N; Suzuki, M; Omachi, S; Aso, H; Nemoto, Y				Kato, N; Suzuki, M; Omachi, S; Aso, H; Nemoto, Y			A handwritten character recognition system using directional element feature and asymmetric mahalanobis distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten Chinese and Japanese character; recognition; directional element feature; city block distance with deviation; asymmetric Mahalanobis distance; ETL9B		This paper presents a precise system for handwritten Chinese and Japanese character recognition. Before extracting directional element feature (DEF) from each character image, transformation based on partial inclination detection (TPID) is used to reduce undesired effects of degraded images. In the recognition process, city block distance with deviation (CBDD) and asymmetric Mahalanobis distance (AMD) are proposed for rough classification and fine classification. With this recognition system, the experimental result of the database ETL9B reaches to 99.42%.	Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 9808579, Japan; Tokyo Natl Coll Technol, Dept Comp Sci, Hachioji, Tokyo 1938610, Japan; Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan	Tohoku University; National Institute of Technology Tokyo College; Tohoku University	Kato, N (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 9808579, Japan.		KATO, NEI/T-5892-2019	KATO, NEI/0000-0001-8769-302X				CASEY R, 1966, IEEE TRANS ELECTRON, VEC15, P91, DOI 10.1109/PGEC.1966.264379; Cheng FH, 1998, PATTERN RECOGN, V31, P401, DOI 10.1016/S0031-3203(97)00053-8; Ejima T., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P789; Guo J., 1993, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ76D-II, P835; Hao HW, 1997, PATTERN RECOGN, V30, P1321, DOI 10.1016/S0031-3203(96)00152-5; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; KATO H, 1995, PRU953 IEICE; Kato N., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ79D-II, P45; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; SAITO T, 1985, IEICE T D, V68, P757; SARUTA K, 1996, T IEICE D, V79, P516; Shimada Y., 1995, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ78D-II, P1460; SHIONO M, 1981, T IEICE D, V64, P387; SUN F, 1996, T IEICE D, V79, P510; SUN N, 1995, IEICE T D, V78, P922; SUZUKI M, 1996, T IEICE D, V79, P504; Takeshita T., 1987, Transactions of the Institute of Electronics, Information and Communication Engineers D, VJ70D, P567; TSUKUMO J, 1990, PRU9020 IEICE; Wakabayashi T., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ79D-II, P765; YAMADA H, 1984, IEICE T D, V67, P1379; Yasuda M., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P830, DOI 10.1109/ICDAR.1993.395609	21	127	163	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					258	262		10.1109/34.754617	http://dx.doi.org/10.1109/34.754617			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000008
J	SHASHUA, A				SHASHUA, A			ALGEBRAIC-FUNCTIONS FOR RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						VISUAL RECOGNITION; ALIGNMENT; REPROJECTION; PROJECTIVE GEOMETRY; ALGEBRAIC AND GEOMETRIC INVARIANTS	RELATIVE ORIENTATION; MOTION; SURFACES; OBJECTS	In the general case, a trilinear relationship between three perspective views is shown to exist, The trilinearity result is shown to be of much practical use in visual recognition by alignment-yielding a direct reprojection method that cuts through the computations of camera transformation, scene structure and epipolar geometry. Moreover, the direct method is linear and sets a new lower theoretical bound on the minimal number of points that are required for a linear solution for the task of reprojection. The proof of the central result may be of further interest as it demonstrates certain regularities across homographies of the plane and introduces new view invariants. Experiments on simulated and real image data were conducted, including a comparative analysis with epipolar intersection and the linear combination methods, with results indicating a greater degree of robustness in practice and a higher level of performance in reprojection tasks.	MIT, ARTIFICIAL INTELLIGENCE LAB, CAMBRIDGE, MA 02139 USA; MIT, CTR BIOL COMPUTAT LEARNING, CAMBRIDGE, MA 02139 USA; HEBREW UNIV JERUSALEM, INST COMP SCI, JERUSALEM, ISRAEL	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Hebrew University of Jerusalem	SHASHUA, A (corresponding author), TECHNION ISRAEL INST TECHNOL, DEPT COMP SCI, IL-32000 HAIFA, ISRAEL.							ADELSON EH, 1993, JUN P IEEE C COMP VI, P361; ADELSON EH, 1991, MIT181 MED LAB TECHN; ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ANANDAN P, 1987, FEB P IM UND WORKSH, P219; BACHELDER IA, 1992, P IMAGE UNDERSTANDIN; BARRETT EB, 1992, APPLICATIONS INVARIA; BERGEN JR, 1990, HIERARCHICAL MOTION; DEMEY S, 1992, OCT P BRIT MACH VIS; DUTTA R, 1990, DEC P INT C COMP VIS, P106; FAUGERAS O, 1992, JUN P EUR C COMP VIS, P563; FAUGERAS OD, 1993, WHAT CAN 2 IMAGES TE; GRIMSON WEL, 1993, AI1435 MIT ART INT L; HARTLEY R, 1992, JUN P IEEE C COMP VI, P761; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Longuet-Higgins H. C., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P395; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LUONG QT, 1993, DETERMINING FUNDAMEN; LUONG QT, 1993, CANONICAL REPRESENTA; MAYBANK SJ, 1990, PHILOS T ROY SOC A, V332, P1, DOI 10.1098/rsta.1990.0099; Mundy J., 1992, GEOMETRIC INVARIANCE; MUNDY JL, 1992, JAN P IM UND WORKSH, P727; SHASHUA A, 1994, IEEE T PATTERN ANAL, V16, P778, DOI 10.1109/34.308472; SHASHUA A, 1993, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION : PROCEEDINGS, P583; SHASHUA A, 1992, MIT AITR1401 ART INT; SHASHUA A, 1994, MAY P EUR C COMP VIS; SHASHUA A, 1994, P IEEE C COMPUTER VI; SHASHUA A, 1993, 2ND EUR WORKSH INV P; Shashua A., 1992, ADV NEUR IN, V4, P404; SHASHUA A, 1991, AI1327 MIT ART INT L; TOMASI C, 1991, SEP IEEE WORKSH VIS, P21; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, 1989, MIT AI1052 MEM; ULLMAN S, 1986, MIT AI931 MEM; WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845	40	127	141	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					779	789		10.1109/34.400567	http://dx.doi.org/10.1109/34.400567			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035		Green Submitted			2022-12-18	WOS:A1995RL03500004
J	DICKINSON, SJ; PENTLAND, AP; ROSENFELD, A				DICKINSON, SJ; PENTLAND, AP; ROSENFELD, A			3-D SHAPE RECOVERY USING DISTRIBUTED ASPECT MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ASPECT MODELING; GEONS; RECOGNITION BY PARTS; 3-D OBJECT RECOGNITION; 3-D SHAPE RECOVERY; VOLUMETRIC OBJECT MODELING PRIMITIVES	PERCEPTUAL ORGANIZATION; OBJECT RECOGNITION; CURVED OBJECTS; REPRESENTATION; SEGMENTATION; VISION; MODELS	We present an approach to the recovery of 3-D volumetric primitives from a single 2-D image. The approach first takes a set of 3-D volumetric modeling primitives and generates a hierarchical aspect representation based on the projected surfaces of the primitives; conditional probabilities capture the ambiguity of mappings between levels of the hierarchy [15]. From a region segmentation of the input image, we present a novel formulation of the recovery problem based on the grouping of the regions into aspects. No domain-dependent heuristics are used; we exploit only the probabilities inherent in the aspect hierarchy. Once the aspects are recovered, we use the aspect hierarchy to infer a set of volumetric primitives and their connectivity. As a front end to an object recognition system, the approach provides the indexing power of complex 3-D object-centered primitives while exploiting the convenience of 2-D viewer-centered aspect matching. However, unlike traditional aspect matching paradigms that represent the entire object with a set of aspects, we use aspects to represent a finite vocabulary of 3-D parts from which objects can be constructed. Thus, the size of our aspect set is fixed and, more important, independent of the size of the object database. The method not only fully accommodates occlusion but uses the aspect hierarchy to overcome image segmentation errors. We describe the approach in detail and demonstrate its application to both synthetic line drawings and real images.	MIT,MEDIA LAB,VIS & MODELING GRP,CAMBRIDGE,MA 02139; UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742; UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742; UNIV MARYLAND,COLL ENGN,COLLEGE PK,MD 20742; UNIV MARYLAND,DEPT PSYCHOL,COLLEGE PK,MD 20742; UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742	Massachusetts Institute of Technology (MIT); University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park								AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BERGEVIN R, 1988, TRCIM8824 MCGILL U C; BERGEVIN R, 1988, TRCIM8825 MCGILL U M; BERGEVIN R, 1989, NOV P IEEE WORKSH IN, P68; BERMAN F, 1990, J ALGORITHM, V11, P153, DOI 10.1016/0196-6774(90)90001-U; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; Binford T. O., 1982, INT J ROBOT RES, V1, P18; BINFORD TO, 1971, P IEEE C SYST CONTR; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHAKRAVARTY I, 1982, MAY P SPIE C ROB VIS, P37; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; DICKINSON S, 1990, VISION CONVERGENCE D; DICKINSON SJ, 1991, JUN P IEEE WORKSH CA; DICKINSON SJ, 1990, CARTR453 U MARYL CEN; Fan T. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P474; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; Gardiner M., 1965, SCI AM, V213, P222; Garey M. R., 1979, COMPUTERS INTRACTABI, P193; GIGUS Z, 1988, UCBCSD88432 U CAL CO; GIGUS Z, 1988, UCBCSD88402 U CAL CO; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KIRPATRICK DG, 1978, 10TH P ANN ACM S THE, P240; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; LAMDAN Y, 1988, APR P IEEE INT C ROB, P1407; LIAO YZ, 1981, P PATTERN RECOGNITIO, P224; MEER P, 1990, P DARPA IMAGE UNDERS; MOHAN R, 1989, P DARPA IMAGE UNDERS, P415; Mulgaonkar P. G., 1984, Image and Vision Computing, V2, P85, DOI 10.1016/0262-8856(84)90003-9; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NILSSON NJ, 1980, PRINCIPLES ARTIFICIA, pCH2; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Pentland A., 1989, Computer Graphics, V23, P215, DOI 10.1145/74334.74355; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; PENTLAND A, IN PRESS IEEE T PATT; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; PENTLAND AP, 1987, P SPIE C MACHINE VIS; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; Roberts L, 1965, MACHINE PERCEPTION 3; ROSENFELD A, 1987, P DARPA IMAGE UNDERS, P620; SAINTMARC P, 1988, 1988 P DARPA IM UND, P1100; Shapiro L. G., 1990, Machine Vision and Applications, V3, P143, DOI 10.1007/BF01214427; SOLINA F, 1987, MSCIS87111 U PENNS T; SRIPRADISVARAKU.T, 1989, P IEEE WORKSH INT 3D, P109; Stark L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P501, DOI 10.1109/CCV.1988.590030; Stewman J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P494, DOI 10.1109/CCV.1988.590029; STEWMAN JH, 1990, COMPUT VISION GRAPH, V51, P20, DOI 10.1016/S0734-189X(05)80060-X; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; THOMPSON D, 1987, P DARPA IMAGE UNDERS, P93; ULLMAN S, 1989, MIT1152 ART INT LAB; [No title captured]; [No title captured]	59	127	128	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					174	198		10.1109/34.121788	http://dx.doi.org/10.1109/34.121788			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900007
J	Wang, YM; Liu, JZ; Tang, XO				Wang, Yueming; Liu, Jianzhuang; Tang, Xiaoou			Robust 3D Face Recognition by Local Shape Difference Boosting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D shape matching; collective shape difference classifier; face recognition; signed shape difference map	MODEL	This paper proposes a new 3D face recognition approach, Collective Shape Difference Classifier (CSDC), to meet practical application requirements, i.e., high recognition performance, high computational efficiency, and easy implementation. We first present a fast posture alignment method which is self-dependent and avoids the registration between an input face against every face in the gallery. Then, a Signed Shape Difference Map (SSDM) is computed between two aligned 3D faces as a mediate representation for the shape comparison. Based on the SSDMs, three kinds of features are used to encode both the local similarity and the change characteristics between facial shapes. The most discriminative local features are selected optimally by boosting and trained as weak classifiers for assembling three collective strong classifiers, namely, CSDCs with respect to the three kinds of features. Different schemes are designed for verification and identification to pursue high performance in both recognition and computation. The experiments, carried out on FRGC v2 with the standard protocol, yield three verification rates all better than 97.9 percent with the FAR of 0.1 percent and rank-1 recognition rates above 98 percent. Each recognition against a gallery with 1,000 faces only takes about 3.6 seconds. These experimental results demonstrate that our algorithm is not only effective but also time efficient.	[Wang, Yueming; Liu, Jianzhuang; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Wang, Yueming] Zhejiang Univ, Qiushi Acad Adv Studies, Hangzhou, Zhejiang, Peoples R China; [Liu, Jianzhuang; Tang, Xiaoou] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 100864, Peoples R China; [Tang, Xiaoou] Chinese Univ Hong Kong, Fac Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong; Zhejiang University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese University of Hong Kong	Wang, YM (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	ymingwang@gmail.com; jzliu@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012		Natural Science Foundation of China [60975029]; Microsoft Research Asia; Research Grants Council of the Hong Kong SAR, China [CUHK 414306, 415408]; Shenzhen Bureau of Science Technology & Information, China [JC200903180635A]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Microsoft Research Asia(Microsoft); Research Grants Council of the Hong Kong SAR, China(Hong Kong Research Grants Council); Shenzhen Bureau of Science Technology & Information, China	This work was supported by grants from the Natural Science Foundation of China (No. 60975029), Microsoft Research Asia, the Research Grants Council of the Hong Kong SAR, China (Project No. CUHK 414306, 415408), and the Shenzhen Bureau of Science Technology & Information (No. JC200903180635A), China.	Achermann B, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P129, DOI 10.1109/VSMM.1997.622339; Achermann B, 2000, INT C PATT RECOG, P809, DOI 10.1109/ICPR.2000.906199; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9; Boehnen C, 2009, LECT NOTES COMPUT SC, V5558, P12, DOI 10.1007/978-3-642-01793-3_2; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; BRONSTEIN A, 2003, P AUD VID BAS BIOM P, P62; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Chang K, 2005, PROC SPIE, V5779, P132, DOI 10.1117/12.604171; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640; Cook J, 2006, P IEEE INT C VID SIG, P83; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Gordon G. G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P808, DOI 10.1109/CVPR.1992.223253; GUPTA S, 2007, P IEEE C COMP VIS PA; Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; HUSKEN M, 2005, P IEEE WORKSH FAC RE; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; Lee YH, 2004, IEEE IMAGE PROC, P1429; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lu X, 2006, P IEEE COMP SOC C CO, P1377, DOI DOI 10.1109/CVPR..96; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784; MAURER T, 2005, P IEEE WORKSH FAC RE; Medioni G, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P232; Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Moreno A.B., 2003, P IR MACH VIS IM PRO; NAGAMINE T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P324, DOI 10.1109/ICPR.1992.201567; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Pan G, 2003, IEEE IJCNN, P2169; PASSALIS G, 2005, P IEEE WORKSH FAC RE; Phillips P.J., 2006, FRVT 2006 ICE 2006 L; Phillips PJ, 2005, PROC CVPR IEEE, P947; PHILLIPS PJ, 2002, FRVT 2002 OVERVIEW S; RUSS T, 2006, P 2006 IEEE COMP SOC, P1391; RUSS TD, 2005, P IEEE WORKSH FAC RE; Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Scheenstra A, 2005, LECT NOTES COMPUT SC, V3546, P891; Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Wang Y., 2007, P IEEE C COMP VIS PA; Wang YM, 2006, LECT NOTES COMPUT SC, V3851, P581; Wang YM, 2008, LECT NOTES COMPUT SC, V5302, P603, DOI 10.1007/978-3-540-88682-2_46; Wu ZH, 2004, IEEE IMAGE PROC, P2003; XU C, 2006, P EUR C COMP VIS, P416; Xu CH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P308; Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHONG C, 2007, P IEEE C COMP VIS PA	54	126	139	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1858	1870		10.1109/TPAMI.2009.200	http://dx.doi.org/10.1109/TPAMI.2009.200			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724762	Green Submitted			2022-12-18	WOS:000281000700011
J	Lempitsky, V; Rother, C; Roth, S; Blake, A				Lempitsky, Victor; Rother, Carsten; Roth, Stefan; Blake, Andrew			Fusion Moves for Markov Random Field Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; computer vision; combinatorial algorithms; graph algorithms; stereo; motion; image restoration	ENERGY MINIMIZATION	The efficient application of graph cuts to Markov Random Fields (MRFs) with multiple discrete or continuous labels remains an open question. In this paper, we demonstrate one possible way of achieving this by using graph cuts to combine pairs of suboptimal labelings or solutions. We call this combination process the fusion move. By employing recently developed graph-cut-based algorithms (so-called QPBO-graph cut), the fusion move can efficiently combine two proposal labelings in a theoretically sound way, which is in practice often globally optimal. We demonstrate that fusion moves generalize many previous graph-cut approaches, which allows them to be used as building blocks within a broader variety of optimization schemes than were considered before. In particular, we propose new optimization schemes for computer vision MRFs with applications to image restoration, stereo, and optical flow, among others. Within these schemes the fusion moves are used 1) for the parallelization of MRF optimization into several threads, 2) for fast MRF optimization by combining cheap-to-compute solutions, and 3) for the optimization of highly nonconvex continuous-labeled MRFs with 2D labels. Our final example is a nonvision MRF concerned with cartographic label placement, where fusion moves can be used to improve the performance of a standard inference method (loopy belief propagation).	[Lempitsky, Victor; Rother, Carsten; Blake, Andrew] Microsoft Res, Cambridge CB3 0FB, England; [Roth, Stefan] Tech Univ Darmstadt, GRIS, D-64283 Darmstadt, Germany	Microsoft; Technical University of Darmstadt	Lempitsky, V (corresponding author), Microsoft Res, 7 JJ Thomson Ave, Cambridge CB3 0FB, England.	victlem@microsoft.com; carrot@microsoft.com; sroth@cs.tu-darmstadt.de; ablake@microsoft.com		Roth, Stefan/0000-0001-9002-9832				Baker S., 2007, P INT C COMP VIS; BESAG J, 1986, J R STAT SOC B, V48, P259; BILLIONNET A, 1985, DISCRETE APPL MATH, V12, P1, DOI 10.1016/0166-218X(85)90035-6; Birchfield ST, 2007, IMAGE VISION COMPUT, V25, P1329, DOI 10.1016/j.imavis.2006.08.001; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boros E., 2006, 102006 RUTCOR RRR; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CHRISTIANI K, 1995, NERVENHEILKUNDE, V14, P3; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; HAMMER PL, 1965, OPER RES, V13, P388; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Jung H. Y., 2008, P EUR C COMP VIS; KOHLI P, 2008, P INT C MACH LEARN; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; KOLMOGOROV V, 2005, P C UNC ART INT; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; KOMODAKIS N, 2007, P IEEE C COMP VIS PA; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; LEMPITSKY V, 2007, P INT C COMP VIS; Lempitsky V. S., 2008, P IEEE C COMP VIS PA; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; RASMUSSEN CE, 2006, MINIMIZE M; Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x; Rother C, 2005, PROC CVPR IEEE, P589; Rother C., 2007, P IEEE C COMP VIS PA; Scharstein D, 2007, P IEEE C COMP VIS PA; SCHLENKER B, 2006, EUR UROL, V6, P1; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; TROBIN W, 2008, P EUR C COMP VIS; VEKSLER O, 2007, P IEEE C COMP VIS PA; VEKSLER O, 1999, THESIS CORNELL U; Winn J., 2006, CVPR; Wolff A., 2009, MAP LABELING BIBLIO; WOODFORD OJ, 2008, P IEEE C COMP VIS PA; Woodford OJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.32; Yedidia J., 2003, EXPLORING ARTIFICIAL, V8, P236	41	126	132	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1392	1405		10.1109/TPAMI.2009.143	http://dx.doi.org/10.1109/TPAMI.2009.143			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558873				2022-12-18	WOS:000278858600004
J	Ng, MK; Li, MJ; Huang, JZ; He, ZY				Ng, Michael K.; Li, Mark Junjie; Huang, Joshua Zhexue; He, Zengyou			On the impact of dissimilarity measure in k-modes clustering algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; clustering; k-modes algorithm; categorical data		This correspondence describes extensions to the k-modes algorithm for clustering categorical data. By modifying a simple matching dissimilarity measure for categorical objects, a heuristic approach was developed in [4], [12] which allows the use of the k- modes paradigm to obtain a cluster with strong intrasimilarity and to efficiently cluster large categorical data sets. The main aim of this paper is to rigorously derive the updating formula of the k- modes clustering algorithm with the new dissimilarity measure and the convergence of the algorithm under the optimization framework.	Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China; Univ Hong Kong, E Business Technol Inst, Hong Kong, Hong Kong, Peoples R China; Harbin Inst Technol, Dept Comp Sci & Engn, Harbin 150001, Peoples R China	Hong Kong Baptist University; University of Hong Kong; Harbin Institute of Technology	Ng, MK (corresponding author), Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China.	mng@math.hkbu.edu.hk; jjli@math.hkbu.edu.hk; jhuang@eti.hku.hk; zengyouhe@yahoo.com	Ng, Michael/B-7189-2009; NG, Michael/AAG-9117-2020	Ng, Michael/0000-0001-6833-5227; He, Zengyou/0000-0001-9526-8816				Andreopoulos B., 2005, WSEAS Transactions on Information Science and Applications, V2, P1625; Chaturvedi A, 2001, J CLASSIF, V18, P35, DOI 10.1007/s00357-001-0004-3; GOWDA KC, 1991, PATTERN RECOGN, V24, P567, DOI 10.1016/0031-3203(91)90022-W; He ZY, 2005, LECT NOTES ARTIF INT, V3801, P157; Huang C, 1997, POLYM REACT ENG, V5, P1; Huang Z., 1999, IEEE T FUZZY SYSTEMS, V7; Huang ZX, 2003, J CLASSIF, V20, P257, DOI 10.1007/s00357-003-0014-4; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; JAIN AK, 1977, ALGORITHMS CLUSTERIN; Kaufman L., 2009, FINDING GROUPS DATA; Manganaro V, 2005, CURR MED CHEM, V12, P1149, DOI 10.2174/0929867053764626; Ohn Mar San, 2004, International Journal of Applied Mathematics and Computer Science, V14, P241	12	126	144	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					503	507		10.1109/TPAMI.2007.53	http://dx.doi.org/10.1109/TPAMI.2007.53			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224620				2022-12-18	WOS:000243420500012
J	Samir, C; Srivastava, A; Daoudi, M				Samir, Chafik; Srivastava, Anuj; Daoudi, Mohamed			Three-dimensional face recognition using shapes of facial curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						facial curves; shape analysis; geodesic paths; 3D face recognition; range images		We study shapes of facial surfaces for the purpose of face recognition. The main idea is to 1) represent surfaces by unions of level curves, called facial curves, of the depth function and 2) compare shapes of surfaces implicitly using shapes of facial curves. The latter is performed using a differential geometric approach that computes geodesic lengths between closed curves on a shape manifold. These ideas are demonstrated using a nearest-neighbor classifier on two 3D face databases: Florida State University and Notre Dame, highlighting a good recognition performance.	USTL, LIFL, UMR 8022, CNRS, F-59658 Villeneuve Dascq, France; Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Centre National de la Recherche Scientifique (CNRS); Universite de Lille - ISITE; Universite de Lille; State University System of Florida; Florida State University	Samir, C (corresponding author), USTL, LIFL, UMR 8022, CNRS, Telecom Lille 1,Rue G Marconi,Cite Sci, F-59658 Villeneuve Dascq, France.	chafik@enic.fr; anuj@stat.fsu.edu; daoudi@enic.fr	Srivastava, Anuj/L-4705-2019; Srivastava, Anuj/F-7417-2011; Daoudi, Mohammed/H-5935-2013	samir, chafik/0000-0003-0619-5040; Daoudi, Mohammed/0000-0003-4219-7860				BEUMIER C, 1998, P BRIT MACH VIS C; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Hallinan P. W., 1999, 2 3 DIMENSIONAL PATT; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; MAURER T, 2005, P IEEE C COMP VIS PA, P15; Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37; Yoshizawa S., 2005, P ACM S SOL PHYS MOD, P227, DOI [DOI 10.1145/1060244.1060270, 10.1145/1060244.1060270]	9	126	137	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1858	U1		10.1109/TPAMI.2006.235	http://dx.doi.org/10.1109/TPAMI.2006.235			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063689				2022-12-18	WOS:000240443400012
J	Koninckx, TP; Van Gool, L				Koninckx, TP; Van Gool, L			Real-time range acquisition by adaptive structured light	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						imaging geometry; depth cues; range data; shape; real-time systems		The goal of this paper is to provide a '' self-adaptive '' system for real-time range acquisition. Reconstructions are based on a single frame structured light illumination. Instead of using generic, static coding that is supposed to work under all circumstances, system adaptation is proposed. This occurs on-the-fly and renders the system more robust against instant scene variability and creates suitable patterns at startup. A continuous trade-off between speed and quality is made. A weighted combination of different coding cues-based upon pattern color, geometry, and tracking-yields a robust way to solve the correspondence problem. The individual coding cues are automatically adapted within a considered family of patterns. The weights to combine them are based on the average consistency with the result within a small time-window. The integration itself is done by reformulating the problem as a graph cut. Also, the camera-projector configuration is taken into account for generating the projection patterns. The correctness of the range maps is not guaranteed, but an estimation of the uncertainty is provided for each part of the reconstruction. Our prototype is implemented using unmodified consumer hardware only and, therefore, is cheap. Frame rates vary between 10 and 25 fps, dependent on scene complexity.	Katholieke Univ Leuven, ESAT PSI, B-3001 Heverlee, Belgium	KU Leuven	Koninckx, TP (corresponding author), Katholieke Univ Leuven, ESAT PSI, Kasteelpk Arenberg 10, B-3001 Heverlee, Belgium.	tkoninck@esat.kuleuven.be; luc.vangool@esat.kuleuven.be						ALTSCHULER MD, 1987, 3 DIMENSIONAL MACHIN, V87, P97; Batlle J, 1998, PATTERN RECOGN, V31, P963, DOI 10.1016/S0031-3203(97)00074-5; Blais F, 2004, J ELECTRON IMAGING, V13, P231, DOI 10.1117/1.1631921; Blais F, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P251, DOI 10.1109/IM.2003.1240257; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177; Forest J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P73, DOI 10.1109/IRDS.2002.1041365; GRIFFIN PM, 1992, PATTERN RECOGN, V25, P609, DOI 10.1016/0031-3203(92)90078-W; Horn E, 1999, IMAGE VISION COMPUT, V17, P87, DOI 10.1016/S0262-8856(98)00113-9; Jaeggli T., 2003, P IEEE INT WORKSH PR; Je C, 2004, LECT NOTES COMPUT SC, V3021, P95; KONINCKX T, 2003, P SPIE EI PHOTOMETRI, P26; Koninckx TP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P293, DOI 10.1109/IM.2003.1240262; KONINCKX TP, 2005, THESIS CATHOLIC U LE; MARUYAMA M, 1993, IEEE T PATTERN ANAL, V15, P647, DOI 10.1109/34.216735; Proesmans M, 1997, P SOC PHOTO-OPT INS, V3023, P50, DOI 10.1117/12.269762; RUSINKIEWICZ S, 2002, P SIGGRAPH, P438; Scharstein D, 2003, PROC CVPR IEEE, P195; Strat AV, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P483, DOI 10.1109/IM.2003.1240285; VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	24	126	133	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					432	445		10.1109/TPAMI.2006.62	http://dx.doi.org/10.1109/TPAMI.2006.62			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526428				2022-12-18	WOS:000234517900008
J	Hjaltason, GR; Samet, H				Hjaltason, GR; Samet, H			Properties of embedding methods for similarity searching in metric spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						embedding methods; metric spaces; similarity search; multimedia databases; contractiveness; distortion; quality; Lipschitz embeddings; singular value decomposition (SVID); SparseMap; FastMap; MetricMap	STATISTICAL VARIABLES; NEIGHBOR; ALGORITHM; COMPLEX; TIME	Complex data types-such as images, documents, DNA sequences, etc-are becoming increasingly important in modern database applications. A typical query in many of these applications seeks to find objects that are similar to some target object, where (dis)similarity is defined by some distance function. Often, the cost of evaluating the distance between two objects is very high. Thus, the number of distance evaluations should be kept at a minimum, while (ideally) maintaining the quality of the result. One way to approach this goal is to embed the data objects in a vector space so that the distances of the embedded objects approximates the actual distances. Thus, queries can be performed (for the most part) on the embedded objects. In this paper, we are especially interested in examining the issue of whether or not the embedding methods will ensure that no relevant objects are left out (i.e., there are no false dismissals and, hence, the correct result is reported). Particular attention is paid to the SparseMap, FastMap, and MetricMap embedding methods. SparseMap is a variant of Lipschitz embeddings, while FastMap and MetricMap are inspired by dimension reduction methods for Euclidean spaces (using KILT or the related PCA and SVD). We show that, in general, none of these embedding methods guarantee that queries on the embedded objects have no false dismissals, while also demonstrating the limited cases in which the guarantee does hold. Moreover, we describe a variant of SparseMap that allows queries with no false dismissals. In addition, we show that with FastMap and MetricMap, the distances of the embedded objects can be much greater than the actual distances. This makes it impossible (or at least impractical) to modify FastMap and MetricMap to guarantee no false dismissals.	Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada; Univ Maryland, Ctr Automat Res, Dept Comp Sci, College Pk, MD 20742 USA; Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	University of Waterloo; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Hjaltason, GR (corresponding author), Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.	gisli@db.uwaterloo.ca; hjs@cs.umd.edu						Achlioptas D., 2001, P TWENTIETHACMSIGMOD, P274, DOI DOI 10.1145/375551.375608; Agrawal R., 1993, Foundations of Data Organization and Algorithms. 4th International Conference. FODO '93 Proceedings, P69; Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Barros J, 1996, P SOC PHOTO-OPT INS, V2670, P392, DOI 10.1117/12.234778; BERN M, 1993, INFORM PROCESS LETT, V45, P95, DOI 10.1016/0020-0190(93)90222-U; Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI DOI 10.1145/502512.502546; Burrus C.S., 1997, INTRO WAVELETS WAVEL; Chan KP, 1999, PROC INT CONF DATA, P126, DOI 10.1109/ICDE.1999.754915; Cowen LJ, 1997, ADV APPL MATH, V19, P319, DOI 10.1006/aama.1997.0532; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gershenfeld N., 1999, NATURE MATH MODELING; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; Hjaltason GR, 1999, ACM T DATABASE SYST, V24, P265, DOI 10.1145/320248.320255; Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83; HJALTASON GR, 2000, TR4102 U MAR; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Korn F, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P215; Kruskal JosephB., 1978, MULTIDIMENSIONAL SCA, DOI [10.4135/9781412985130, DOI 10.4135/9781412985130]; Linial M, 1997, J MOL BIOL, V268, P539, DOI 10.1006/jmbi.1997.0948; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; LINIAL N, 1994, FOCS, V35, P577; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Samet H., 1990, DESIGN ANAL SPATIAL, V85; Samet Hanan, 1990, DESIGN ANAL SPATIAL, P2; SEIDL T, 1998, P ACM SIGMOD INT C M, P154, DOI DOI 10.1145/276304.276319; SHAPIRO M, 1977, COMMUN ACM, V20, P339, DOI 10.1145/359581.359599; Vetterli M., 1995, WAVELETS SUBBAND COD; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, P145, DOI 10.1016/0167-8655(86)90013-9; Vleugels J, 2002, PATTERN RECOGN, V35, P69, DOI 10.1016/S0031-3203(00)00120-5; WANG TL, 1990, P 16 INT C VER LARG, P602; WANG X, 2000, KNOWL INF SYST, V2, P161; YANG Y, 1998, P 9 ANN S COMB PATT, P104; Young N., 2012, INTRO HILBERT SPACE; ZHANG K, 2000, UNPUB COMMUNICAT JUL; Zhang K., 1999, P ACM KDD SAN DIEG C, P307; [No title captured]; [No title captured]	45	126	128	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					530	549		10.1109/TPAMI.2003.1195989	http://dx.doi.org/10.1109/TPAMI.2003.1195989			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY		Green Submitted			2022-12-18	WOS:000182342300001
J	Oliveira, LS; Sabourin, R; Bortolozzi, F; Suen, CY				Oliveira, LS; Sabourin, R; Bortolozzi, F; Suen, CY			Automatic recognition of handwritten numerical strings: A recognition and verification strategy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten numerical string recognition; segmentation and recognition of numerals; recognition and verification; feature extraction; probabilistic model	OFF-LINE; SEGMENTATION	A modular system to recognize handwritten numerical strings is proposed. It uses a segmentation-based recognition approach and a Recognition and Verification strategy. The approach combines the outputs from different levels such as segmentation, recognition, and postprocessing in a probabilistic model. A new verification scheme which contains two verifiers to deal with the problems of oversegmentation and undersegmentation is presented. A new feature set is also introduced to feed the oversegmentation verifier. A postprocessor based on a deterministic automaton is used and the global decision module makes an accept/reject decision. Finally, experimental results on two databases are presented: numerical amounts on Brazilian bank checks and NIST SD19. The latter aims at validating the concept of modular system and showing the robustness of the system using a well-known database.	Ecole Technol Super, LIVIA, Montreal, PQ H3C 1K3, Canada; Concordia Univ, CENPARMI, Montreal, PQ H3G 1M8, Canada; Pontificia Univ Catolica Parana, PPGIA, BR-80215901 Curitiba, Parana, Brazil	University of Quebec; Ecole de Technologie Superieure - Canada; Concordia University - Canada; Pontificia Universidade Catolica do Parana	Oliveira, LS (corresponding author), Ecole Technol Super, LIVIA, 1100 Rue Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada.	soares@cenparmi.concordia.ca; sabourin@gpa.etsmtl.ca; fborto@ppgia.pucpr.br; suen@cenparmi.concordia.ca	Sabourin, Robert/J-7642-2012; Bortolozzi, Flavio/K-4458-2017	Sabourin, Robert/0000-0002-9098-1011; Bortolozzi, Flavio/0000-0003-0517-1127; Soares de Oliveira, Luiz Eduardo/0000-0002-0595-5370				*BANC CENTR BRAS, 1990, 001825 BANC CENTR BR; Bishop, 1995, NEURAL NETWORKS PATT; BOURLARD H, 1991, NEURAL NETWORKS ADV; Bridle J. S., 1990, PROC 2 INT C NEURAL, P211, DOI [10.5555/2969830, DOI 10.5555/2969830]; Britto A.  Jr., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P396, DOI 10.1109/ICDAR.2001.953820; BRUEL TM, 1994, P 12 INT C PATT REC, V2, P129; Cai JH, 1999, IEEE T PATTERN ANAL, V21, P263, DOI 10.1109/34.754622; Chen YK, 2000, IEEE T PATTERN ANAL, V22, P1304, DOI 10.1109/34.888715; CHO SJ, 2000, P 7 INT WORKSH FRONT, P219; de Oliveira LES, 2000, INT C PATT RECOG, P323, DOI 10.1109/ICPR.2000.906078; Dimauro G, 1997, INT J PATTERN RECOGN, V11, P467, DOI 10.1142/S0218001497000214; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Fumera G, 2000, PATTERN RECOGN, V33, P2099, DOI 10.1016/S0031-3203(00)00059-5; Grother PJ, 1995, HANDPRINTED FORMS CH, P10; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P535, DOI 10.1109/34.589216; Ha TM, 1998, PATTERN RECOGN, V31, P257, DOI 10.1016/S0031-3203(97)00050-2; Heutte L., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P167, DOI 10.1109/ICDAR.1993.395757; Heutte L, 1997, INT J PATTERN RECOGN, V11, P595, DOI 10.1142/S0218001497000251; Kaufmann G, 2000, PATTERN ANAL APPL, V3, P132, DOI 10.1007/s100440070018; Knerr S, 1997, INT J PATTERN RECOGN, V11, P505, DOI 10.1142/S0218001497000226; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lee SW, 1999, IEEE T SYST MAN CY C, V29, P285, DOI 10.1109/5326.760572; Lethelier E., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P92, DOI 10.1109/ICDAR.1995.598951; LEUNG HC, 1991, P EUROSPEECH 91 GEN, P931; LIPPMANN RP, 1989, IEEE COMMUN MAG, V27, P47, DOI 10.1109/35.41401; MATAN O, 1991, P INT JOINT C NEUR N, P504; Oliveira LS, 2001, PROC INT CONF DOC, P389, DOI 10.1109/ICDAR.2001.953819; Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461; SHRIDHAR M, 1986, PATTERN RECOGN, V19, P1, DOI 10.1016/0031-3203(86)90025-7; TAKAHASHI H, 1993, P 2 INT C DOC AN REC, P585; ZHOU J, 2000, P 7 INT WORKSH FONT, P179	32	126	129	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1438	1454		10.1109/TPAMI.2002.1046154	http://dx.doi.org/10.1109/TPAMI.2002.1046154			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY					2022-12-18	WOS:000178846400003
J	Yamany, SM; Farag, AA				Yamany, SM; Farag, AA			Surface signatures: An orientation independent free-form surface representation scheme for the purpose of objects registration and matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface signatures; object registration; object matching; free-form surface representation	RANGE VIEWS; RECOGNITION; CURVES; IMAGES; SCENES	This paper introduces a new free-form surface representation scheme for the purpose of fast and accurate registration and matching. Accurate registration of surfaces is a common task in computer vision. The proposed representation scheme captures the surface curvature information (seen from certain points) and produces images, called "surface signatures," at these points. Matching signatures of different surfaces enables the recovery of the transformation parameters between these surfaces. We propose using template matching to compare the signature images. To enable partial matching, another criterion, the overlap ratio is used. This representation scheme can be used as a global representation of the surface as well as a local one and performs near real-time registration. We show that the signature representation can be used to recover scaling transformation as well as matching objects in 3D scenes in the presence of clutter and occlusion. Applications presented include: free-form object matching, multimodal medical volumes registration, and dental teeth reconstruction from intraoral images.	Cairo Univ, Dept Syst & Biomed Engn, Cairo, Egypt; Univ Louisville, Comp Vis & Image Proc Lab, CVIP Lab, Louisville, KY 40292 USA	Egyptian Knowledge Bank (EKB); Cairo University; University of Louisville	Yamany, SM (corresponding author), Cairo Univ, Dept Syst & Biomed Engn, Cairo, Egypt.	yamany@ieee.org; farag@cairo.spd.louisville.edu						Ahmed M, 1997, PROC CVPR IEEE, P646, DOI 10.1109/CVPR.1997.609394; BERGEVIN R, 1995, COMPUT VIS IMAGE UND, V61, P1, DOI 10.1006/cviu.1995.1001; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; DELINGETTE H, 1992, IMAGE VISION COMPUT, V10, P132, DOI 10.1016/0262-8856(92)90065-B; DELINGETTE H, 1994, 2214 INRIA; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Duda R.O., 1973, J ROYAL STAT SOC SER; GUEZIEC A, 1994, INT J COMPUT VISION, V12, P79, DOI 10.1007/BF01420985; HEBERT M, 1995, IEEE T PATTERN ANAL, V17, P681, DOI 10.1109/34.391410; IKEUCHI K., 2001, MODELING REALITY; Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980; MOSTAFA MGH, 1999, P IEEE INT C COMP VI; OPERA J, 1997, DIFFERENTIAL GEOMETR; SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; THIRION JP, 1994, P IEEE C COMP VIS PA; Wells W M 3rd, 1996, Med Image Anal, V1, P35; Yamany S. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1098, DOI 10.1109/ICCV.1999.790402; Yamany SM, 1999, PATTERN RECOGN, V32, P1817, DOI 10.1016/S0031-3203(99)00060-6; YAMANY SM, 1999, THESIS U LOUISVILLE; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	25	126	134	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1105	1120		10.1109/TPAMI.2002.1023806	http://dx.doi.org/10.1109/TPAMI.2002.1023806			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100008
J	Bailey, RR; Srinath, M				Bailey, RR; Srinath, M			Orthogonal moment features for use with parametric and non-parametric classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						orthogonal moments; Zernike moments; feature selection; handwritten character recognition; shape recognition; statistical classifiers; neural network classifiers	IMAGE-ANALYSIS; RECOGNITION	This research examines a variety of approaches for using two-dimensional orthogonal polynomials for the recognition of handwritten Arabic numerals. it also makes use of parametric and non-parametric statistical and neural network classifiers. Polynomials, including Legendre, Zernike, and pseudo-Zernike, are used to generate moment-based features which are invariant to location, size, and (optionally) rotation. An efficient method for computing the moments via geometric moments is presented. A side effect of this method also yields scale invariance. A new approach to location invariance using a minimum bounding circle is presented, and a detailed analysis of the rotational properties of the moments is given. Data partitioning tests are performed to evaluate the various feature types and classifiers. For rotational invariant character recognition, the highest percentage of correctly classified characters was 91.7%, and for non-rotational invariant recognition it was 97.6%. This compares with a previous effort, using the same data and test conditions, of 94.8%. The techniques developed here should also be applicable to other areas of shape recognition.	SO METHODIST UNIV, DALLAS, TX 75275 USA	Southern Methodist University	Bailey, RR (corresponding author), NATL TAIWAN NORMAL UNIV, TAIPEI, TAIWAN.							ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; BAILEY RR, 1993, THESIS SO METHODIST; BELKASIM SO, 1990, PATT REC C JUN; BHATIA AB, 1954, P CAMB PHILOS SOC, V50, P40, DOI 10.1017/S0305004100029066; DUREN RW, 1991, THESIS SO METHODIST; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; Hoaglin D.C., 1983, UNDERSTANDING ROBUST; Hoaglin D. C., 1985, EXPLORING DATA TABLE; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063; KHOTANZAD A, 1988, 9 ICPR ROM IT NOV; PAETH AW, 1990, GRAPHICS GEMS; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; REEVES AP, 1981, P PRIP, P171; Stewart G., 1973, INTRO MATRIX COMPUTA; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913	20	126	131	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					389	399		10.1109/34.491620	http://dx.doi.org/10.1109/34.491620			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500004
J	STEWART, CV				STEWART, CV			MINPRAN - A NEW ROBUST ESTIMATOR FOR COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SURFACE RECONSTRUCTION; ROBUST ESTIMATION; RANGE DATA; PARAMETER ESTIMATION; OUTLIERS	SQUARES REGRESSION; HOUGH TRANSFORM	MINPRAN is a new robust estimator capable of finding good fits in data sets containing more than 50% outliers, Unlike other techniques that handle large outlier percentages, MINPRAN does not rely on a known error bound for the good data. Instead, it assumes the bad data are randomly distributed within the dynamic range of the sensor, Based on this, MINPRAN uses random sampling to search for the fit and the inliers to the fit that are least likely to have occurred randomly, It runs in time O(N-2 + SN log N), where S is the number of random samples and N is the number of data points, We demonstrate analytically that MINPRAN distinguished good fits to random data and MINPRAN finds accurate fits and nearly the correct number of inliers, regardless of the percentage of true inliers, We confirm MINPRAN's properties experimentally on synthetic data and show it compares favorably to least median of squares, Finally, we apply MINPRAN to fitting planar surface patches and eliminating outliers in range data taken from complicated scenes.			STEWART, CV (corresponding author), RENSSELAER POLYTECH INST, DEPT COMP SCI, TROY, NY 12180 USA.							Abramowitz M., 1968, HDB MATH FUNCTIONS; Ballard D.H., 1982, COMPUTER VISION; Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BOULT T, 1990, IEEE T ROBOTIC AUTOM, P232; BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P987, DOI 10.1109/34.329010; DAVID HA, 1970, ORDER STATISTICS; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KUMAT R, 1994, CVGIP IMAGE UNDERSTA; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; Madarasmi S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P774, DOI 10.1109/CVPR.1993.341169; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MINTZ D, 1991, CARTR576 U MAR CTR A; MORRISON DF, 1983, APPLIED LINEAR STATI; Papoulis A., 2002, PROBABILITY RANDOM V; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SATO K, 1987, 1ST P ICCV, P657; SCHUNCK BG, 1990, P INT WORKSHOP ROBUS, P1; SILVEY SD, 1975, STATISTICAL INFERENC; SINHA SS, 1992, IEEE T PATTERN ANAL, V14, P36, DOI 10.1109/34.107012; SOUVAINE DL, 1987, J AM STAT ASSOC, V82, P794, DOI 10.2307/2288788; Stein A., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P540, DOI 10.1109/CVPR.1992.223138; STEWART CV, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P167, DOI 10.1109/CVPR.1994.323825; STEWART CV, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P1, DOI 10.1109/CVPR.1994.323951; STEWART CV, 1993, 9324 RENSS POL I DEP; STEWART CV, 1994, 9410 RENSS POL I DEP; STEWART CV, 1993, 9321 RENSS POL I DEP; ZHUANG X, 1990, P INT WORKSHOP ROBUS, P19; ZHUANG XH, 1992, IEEE T PATTERN ANAL, V14, P19, DOI 10.1109/34.107011	34	126	133	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1995	17	10					925	938		10.1109/34.464558	http://dx.doi.org/10.1109/34.464558			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RX289					2022-12-18	WOS:A1995RX28900001
J	BLOSTEIN, SD; HUANG, TS				BLOSTEIN, SD; HUANG, TS			ERROR ANALYSIS IN STEREO DETERMINATION OF 3-D POINT POSITIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BLOSTEIN, SD (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							AYACHE N, 1985, 3RD P WORKSH COMP VI; BARNARD S, 1982, COMPUT SURVEYS, V14; BLOSTEIN SD, 1985, THESIS U ILLINOIS UR; DRAKE KC, 1985, IEEE T PATTERN ANAL, V7, P485, DOI 10.1109/TPAMI.1985.4767687; Duda R.O., 1973, J ROYAL STAT SOC SER; FAUGERAS OD, 1986 P IEEE ROB AUT, P1433; GENNERY DB, 1980, APR P IM UND WORKSH, P161; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5; KAK AC, 1983, TREE8344 PURD U TECH; MCVEY ES, 1982, IEEE T PATTERN ANAL, V4, P646, DOI 10.1109/TPAMI.1982.4767319; MORAVEC HP, 1981, 7TH P IJCAI, V2, P785; SOLINA F, 1985, MSCIS8534 U PENNS TE; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; THOMAS JB, 1971, INTRO APPLIED PROBAB; VERRI A, 1986, J OPT SOC AM A, V3, P297, DOI 10.1364/JOSAA.3.000297; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0; 1966, MANUAL PHOTOGRAMMETR	17	126	138	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					752	765		10.1109/TPAMI.1987.4767982	http://dx.doi.org/10.1109/TPAMI.1987.4767982			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869437				2022-12-18	WOS:A1987K673500003
J	ABUMOSTAFA, YS; PSALTIS, D				ABUMOSTAFA, YS; PSALTIS, D			IMAGE NORMALIZATION BY COMPLEX MOMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ABUMOSTAFA, YS (corresponding author), CALTECH,DIV ENGN & APPL SCI,PASADENA,CA 91125, USA.							ABUMOSTAFA Y, 1984, IEEE T PATTERN A NOV, P698; CASASENT D, 1977, P IEEE, V65, P77, DOI 10.1109/PROC.1977.10432; CORMACK AM, 1963, J APPL PHYS, V34, P2722, DOI 10.1063/1.1729798; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; MAITRA S, 1979, P IEEE, V67, P697, DOI 10.1109/PROC.1979.11309; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920	6	126	133	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					46	55		10.1109/TPAMI.1985.4767617	http://dx.doi.org/10.1109/TPAMI.1985.4767617			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869239	Green Accepted, Green Published			2022-12-18	WOS:A1985ABF0900004
J	Oh, TH; Tai, YW; Bazin, JC; Kim, H; Kweon, IS				Oh, Tae-Hyun; Tai, Yu-Wing; Bazin, Jean-Charles; Kim, Hyeongwoo; Kweon, In So			Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust principal component analysis; rank minimization; sparse and low-rank decomposition; truncated nuclear norm; alternating direction method of multipliers	PHOTOMETRIC STEREO; MATRIX; FACTORIZATION; MOTION; SHAPE	Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint. Our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g., high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.	[Oh, Tae-Hyun; Tai, Yu-Wing; Kim, Hyeongwoo; Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon, South Korea; [Bazin, Jean-Charles] Swiss Fed Inst Technol, Dept Comp Sci, Comp Graph Lab & Comp Vis & Geometry Grp, Zurich, Switzerland	Korea Advanced Institute of Science & Technology (KAIST); Swiss Federal Institutes of Technology Domain; ETH Zurich	Oh, TH; Tai, YW; Kim, H; Kweon, IS (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon, South Korea.; Bazin, JC (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Comp Graph Lab & Comp Vis & Geometry Grp, Zurich, Switzerland.	thoh.kaist.ac.kr@gmail.com; yuwing@gmail.com; jebazin@inf.ethz.ch; hyeongwoo.kim@kaist.ac.kr; iskweon77@kaist.ac.kr	Kweon, In So/C-2023-2011; Bazin, Jean-Charles/M-5124-2017; Tai, Yu Wing/C-2047-2011; Oh, Tae-Hyun/D-7854-2016	Tai, Yu Wing/0000-0002-3148-0380; Oh, Tae-Hyun/0000-0003-0468-1571	National Research Foundation of Korea (NRF) - Korea government (MSIP) [2010-0028680]	National Research Foundation of Korea (NRF) - Korea government (MSIP)(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	The authors would like to thank the reviewers and associate editor for their valuable comments. We also thank Steve Seitz and Dan Goldman for the photometric stereo dataset. The work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680). In So Kweon is the corresponding author.	Agarwal A., 2011, P 28 INT C MACH LEAR, P1129; Bach Francis, 1869, ARXIV08121869; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793; Chen K, 2013, BIOMETRIKA, V100, P901, DOI 10.1093/biomet/ast036; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; DESA EM, 1994, LINEAR ALGEBRA APPL, V198, P429; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626; Eckstein J., 2011, FDN TRENDS MACH LEAR, V3, P1, DOI DOI 10.1561/2200000016; Eriksson A, 2012, IEEE T PATTERN ANAL, V34, P1681, DOI 10.1109/TPAMI.2012.116; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gaiffas S, 2011, ARXIV11071638; Gallo O., 2009, COMP PHOT ICCP 2009, P1; Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; Jain P, 2010, P ADV NEUR INF PROC, P937; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Ke QF, 2005, PROC CVPR IEEE, P739; Lin Z, 2009, UILUENG092215 UIUC; Malik J., 2008, P 24 ANN C COMPUTER, P31, DOI DOI 10.1145/1401132.1401174; Oh TH, 2015, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR.2015.7299078; Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338; Oh TH, 2013, IEEE I CONF COMP VIS, P145, DOI 10.1109/ICCV.2013.25; Oh TH, 2013, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2013.6738163; Oh TH, 2012, IEEE IMAGE PROC, P2381, DOI 10.1109/ICIP.2012.6467376; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Recht B, 2008, IEEE DECIS CONTR P, P3065, DOI 10.1109/CDC.2008.4739332; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wright J., 2012, LOW RANK MATRIX RECO; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Wu Y., 2012, P ADV NEUR INF PROC, p[1745, 1754]; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828	48	125	132	2	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					744	758		10.1109/TPAMI.2015.2465956	http://dx.doi.org/10.1109/TPAMI.2015.2465956			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26353362	Green Submitted			2022-12-18	WOS:000372549700011
J	Proenca, H				Proenca, Hugo			Iris Recognition: On the Segmentation of Degraded Images Acquired in the Visible Wavelength	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Iris segmentation; biometrics; noncooperative image acquisition; visible-light iris images; covert recognition	METHODOLOGY; ALGORITHM	Iris recognition imaging constraints are receiving increasing attention. There are several proposals to develop systems that operate in the visible wavelength and in less constrained environments. These imaging conditions engender acquired noisy artifacts that lead to severely degraded images, making iris segmentation a major issue. Having observed that existing iris segmentation methods tend to fail in these challenging conditions, we present a segmentation method that can handle degraded images acquired in less constrained conditions. We offer the following contributions: 1) to consider the sclera the most easily distinguishable part of the eye in degraded images, 2) to propose a new type of feature that measures the proportion of sclera in each direction and is fundamental in segmenting the iris, and 3) to run the entire procedure in deterministically linear time in respect to the size of the image, making the procedure suitable for real-time applications.	[Proenca, Hugo] Univ Beira Interior, Dept Informet, P-6201001 Covilha, Portugal	Universidade da Beira Interior	Proenca, H (corresponding author), Univ Beira Interior, Dept Informet, Rua Marqus DAvila e Bolama, P-6201001 Covilha, Portugal.	hugomcp@di.ubi.pt	Proença, Hugo/F-9499-2010	Proença, Hugo/0000-0003-2551-8570	FCT-Fundacao para a Cincia e Tecnologia; FEDER [PTDC/EIA/69106/2006]; US Department of Defense Counterdrug Technology Development Program Office	FCT-Fundacao para a Cincia e Tecnologia(Portuguese Foundation for Science and Technology); FEDER(European Commission); US Department of Defense Counterdrug Technology Development Program Office(United States Department of Defense)	The financial support given by "FCT-Fundacao para a Cincia e Tecnologia" and "FEDER" in the scope of the PTDC/EIA/69106/2006 research project "BIOREC: Non-Cooperative Biometric Recognition" is acknowledged. Portions of the research in this paper use the FERET database of facial images collected under the FERET program, sponsored by the US Department of Defense Counterdrug Technology Development Program Office.	*AM NAT STAND I, 1988, Z1362 ANSI; [Anonymous], 2006, IR CHALL EV; ARVACHEH E, 2006, THESIS U WATERLOO; Basil A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P23, DOI 10.1109/ICMV.2007.4469267; BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141; Boddeti N., 2008, 2008 IEEE 2 INT C BI, P1; Boyce C., 2006, 2006 C COMP VIS PATT, P51; Broussard RP, 2007, IEEE IJCNN, P1283, DOI 10.1109/IJCNN.2007.4371143; *COMM INT ECL, 1999, 638 TC COMM INT ECL; Daugman J, 1998, FACE RECOGNITION THE, P108; Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540; Dennis J.E., 1983, NUMERICAL METHODS UN; Dobes M, 2006, OPTIK, V117, P468, DOI 10.1016/j.ijleo.2005.11.008; Fancourt C, 2005, LECT NOTES COMPUT SC, V3546, P1; FLETCHER R, 1964, COMPUT J, V7, P149, DOI 10.1093/comjnl/7.2.149; HASKELL KH, 1981, MATH PROGRAM, V21, P98, DOI 10.1007/BF01584232; He X, 2007, PATTERN RECOGN, V40, P1326, DOI 10.1016/j.patcog.2006.08.009; He YQ, 2006, INT C PATT RECOG, P557; He ZF, 2006, INT C PATT RECOG, P366; HONEYWELL INT INC, 2007, Patent No. 20070036397; HONEYWELL INT INC, 2007, Patent No. 20070211924; IMAI F, 2000, PRELIMINARY EXPT SPE; Kennell LR, 2006, IEEE IMAGE PROC, P293, DOI 10.1109/ICIP.2006.313183; Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118; Matey J.R., 2007, ADV BIOMETRICS SENSO, P107; Meredith P, 2006, PIGM CELL RES, V19, P572, DOI 10.1111/j.1600-0749.2006.00345.x; Morimoto CH, 2005, SIBGRAPI 2005: XVIII Brazilian Symposium on Computer Graphics and Image Processing, Conference Proceedings, P37; Narayanswamy R, 2005, APPL OPTICS, V44, P701, DOI 10.1364/AO.44.000701; Nemati B, 1996, APPL OPTICS, V35, P3321, DOI 10.1364/AO.35.003321; Park KR, 2005, IEEE T SYST MAN CY C, V35, P441, DOI 10.1109/TSMCC.2005.848168; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Poursaberi A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36751; POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790; Proenca H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213; PROENCA H, 2007, P IEEE 1 INT C BIOM, P27; Puhan NB, 2007, 2007 6TH INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS & SIGNAL PROCESSING, VOLS 1-4, P904; Ross A., 2006, BIOMETRIC CONSORTIUM, P1, DOI DOI 10.1109/BCC.2006.4341625; Ross A., 2004, P 2004 BIOM CONS C S; Schuckers SAC, 2007, IEEE T SYST MAN CY B, V37, P1176, DOI 10.1109/TSMCB.2007.904831; Smith KEI, 2007, INDIGEN PEOPLE POLIT, P1, DOI 10.1155/2007/62467; TAN T, ELSEVIER IM IN PRESS; VANLOAN C, 1985, SIAM J NUMER ANAL, V22, P851, DOI 10.1137/0722051; Vatsa M, 2008, IEEE T SYST MAN CY B, V38, P1021, DOI 10.1109/TSMCB.2008.922059; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Xu ZF, 2006, INT C PATT RECOG, P437; Yoon SW, 2007, LECT NOTES COMPUT SC, V4642, P653; ZAIM A, 2005, P IEEE INT C IM PROC, V3, P11; Zheng ZL, 2005, PATTERN RECOGN LETT, V26, P2252, DOI 10.1016/j.patrec.2005.03.033; ZUO J, 2006, P BIOM CONS C, P1	50	125	131	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1502	1516		10.1109/TPAMI.2009.140	http://dx.doi.org/10.1109/TPAMI.2009.140			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558880				2022-12-18	WOS:000278858600011
J	Wang, HZ; Suter, D; Schindler, K; Shen, CH				Wang, Hanzi; Suter, David; Schindler, Konrad; Shen, Chunhua			Adaptive object tracking based on an effective appearance filter	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						particle filters; mixture of Gaussians; appearance model; similarity measure; color histogram; visual tracking; occlusion	VISUAL TRACKING	We propose a similarity measure based on a Spatial-color Mixture of Gaussians (SMOG) appearance model for particle filters. This improves on the popular similarity measure based on color histograms because it considers not only the colors in a region but also the spatial layout of the colors. Hence, the SMOG-based similarity measure is more discriminative. To efficiently compute the parameters for SMOG, we propose a new technique with which the computational time is greatly reduced. We also extend our method by integrating multiple cues to increase the reliability and robustness. Experiments show that our method can successfully track objects in many difficult situations.	Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia; Natl ICT Australia, Canberra, ACT 2601, Australia	Johns Hopkins University; Monash University; NICTA	Wang, HZ (corresponding author), Johns Hopkins Univ, Dept Comp Sci, 3400 N Charles St, Baltimore, MD 21218 USA.	hwang@cs.jhu.edu; d.suter@eng.monash.edu.au; konrad.schindler@eng.monash.edu.au; chunhua.shen@nicta.com.au	Wang, Hanzi/F-8796-2012	Pauldurai, Jona/0000-0002-7217-0872; Suter, David/0000-0001-6306-3023				Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Elgammal A, 2003, PROC CVPR IEEE, P781; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kanhere NK, 2005, PROC CVPR IEEE, P1152; Khan S., 2000, P AS C COMP VIS, P263; Lichtenauer J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P767, DOI 10.1109/AFGR.2004.1301627; Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4; Perez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang HZ, 2006, LECT NOTES COMPUT SC, V3953, P606, DOI 10.1007/11744078_47; Wang JJ, 2006, T NONFERR METAL SOC, V16, P892, DOI 10.1016/S1003-6326(06)60346-4; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd; Yang CJ, 2005, IEEE I CONF COMP VIS, P212; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	21	125	148	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1661	1667		10.1109/TPAMI.2007.1112	http://dx.doi.org/10.1109/TPAMI.2007.1112			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627053				2022-12-18	WOS:000247965600015
J	Proenca, H; Alexandre, LA				Proenca, Hugo; Alexandre, Luis A.			Toward noncooperative iris recognition: A classification approach using multiple signatures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						iris classification; noncooperative iris recognition; biometrics		This paper focus on noncooperative iris recognition, i.e., the capture of iris images at large distances, under less controlled lighting conditions, and without active participation of the subjects. This increases the probability of capturing very heterogeneous images ( regarding focus, contrast, or brightness) and with several noise factors ( iris obstructions and reflections). Current iris recognition systems are unable to deal with noisy data and substantially increase their error rates, especially the false rejections, in these conditions. We propose an iris classification method that divides the segmented and normalized iris image into six regions, makes an independent feature extraction and comparison for each region, and combines each of the dissimilarity values through a classification rule. Experiments show a substantial decrease, higher than 40 percent, of the false rejection rates in the recognition of noisy iris images.	Univ Beira Interior, Dept Informat, P-6201001 Covilha, Portugal	Universidade da Beira Interior	Proenca, H (corresponding author), Univ Beira Interior, Dept Informat, Rua Marques Davila & Bolama, P-6201001 Covilha, Portugal.	hugomcp@di.ubi.pt; lfbaa@di.ubi.pt	Alexandre, Luís/E-8770-2013; Proença, Hugo/F-9499-2010	Alexandre, Luís/0000-0002-5133-5025; Proença, Hugo/0000-0003-2551-8570				[Anonymous], 2004, MMU IR IM DAT; [Anonymous], 2006, IR CHALL EV; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Camus TA, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1044732; *CHIN AC SCI I AUT, 2004, CASIA IR IM DAT; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Dobes M., 2004, UPOL IRIS IMAGE DATA; Dorairaj V., 2005, IM PROC 2005 ICIP 20, V3, P11; Flom L., 1987, US Patent, Patent No. [4,641,349, 4641349, 4641394]; Huang YP, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P450; IBG: International biometric group, 2005, INT BIOM GROUP IND T; KALKA N, 2006, P SPIE C BIOM TECHN, V6202, P263; Ma L, 2004, PATTERN RECOGN, V37, P1287, DOI 10.1016/j.patcog.2004.02.001; Ma L, 2002, INT C PATT RECOG, P414, DOI 10.1109/ICPR.2002.1048327; Proenca H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213; Proenca H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119; Ross A., 2004, P 2004 BIOM CONS C S; University of Bath, 2004, U BATH IR IM DAT; VATSA M, 2005, INT J SIGNAL PROCESS, V2, P66; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669	20	125	142	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					607	612		10.1109/TPAMI.2007.1016	http://dx.doi.org/10.1109/TPAMI.2007.1016			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299218	Green Submitted			2022-12-18	WOS:000244855600009
J	Bartolini, I; Ciaccia, P; Patella, M				Bartolini, I; Ciaccia, P; Patella, M			WARP: Accurate retrieval of shapes using phase of Fourier descriptors and time warping distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape matching; Dynamic Time Warping distance; discrete Fourier transform	EFFICIENT RETRIEVAL; SIMILARITY	Effective and efficient retrieval of similar shapes from large image databases is still a challenging problem in spite of the high relevance that shape information can have in describing image contents. In this paper, we propose a novel Fourier-based approach, called WARP, for matching and retrieving similar shapes. The unique characteristics of WARP are the exploitation of the phase of Fourier coefficients and the use of the Dynamic Time Warping ( DTW) distance to compare shape descriptors. While phase information provides a more accurate description of object boundaries than using only the amplitude of Fourier coefficients, the DTW distance permits us to accurately match images even in the presence of ( limited) phase shiftings. In terms of classical precision/recall measures, we experimentally demonstrate that WARP can gain, say, up to 35 percent in precision at a 20 percent recall level with respect to Fourier-based techniques that use neither phase nor DTW distance.	Univ Bologna, DEIS, I-40136 Bologna, Italy; IEIIT BO CNR, I-40136 Bologna, Italy	University of Bologna; Consiglio Nazionale delle Ricerche (CNR); Istituto di Elettronica e di Ingegneria dell'Informazione e delle Telecomunicazioni (IEIIT-CNR)	Bartolini, I (corresponding author), Univ Bologna, DEIS, Viale Risorgimento 2, I-40136 Bologna, Italy.	ibartolini@deis.unibo.it; picaccia@deis.unibo.it; mpatella@deis.unibo.it	BARTOLINI, ILARIA/AAA-9455-2019	BARTOLINI, ILARIA/0000-0002-8074-1129; CIACCIA, PAOLO/0000-0002-1794-6244				ABBASI S, 1997, SQUID DEMO DATASET 1; Ardizzoni S., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P167, DOI 10.1109/DEXA.1999.795161; BARTOLINI I, 2002, IEIITBO0302 CNR; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berndt D. J., 1994, P 3 INT C KNOWL DISC, P359; Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058; Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Ciaccia P, 2002, ACM T DATABASE SYST, V27, P398, DOI 10.1145/582410.582412; Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010; KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; LATECKI LJ, 2002, SHAPE DATA MPEG 7 CO; Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F., 1996, P BRIT MACH VIS C, P53; Ngu AHH, 2001, VLDB J, V9, P279, DOI 10.1007/s007780100028; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; Rafiei D, 2002, VLDB J, V11, P17, DOI 10.1007/s007780100059; RUI Y, 1996, P 1 INT WORKSH IM DA, P22; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; Yi BK, 1998, PROC INT CONF DATA, P201, DOI 10.1109/ICDE.1998.655778; Zhang D., 2002, P 5 AS C COMP VIS AC, P646	26	125	139	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					142	147		10.1109/TPAMI.2005.21	http://dx.doi.org/10.1109/TPAMI.2005.21			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628276				2022-12-18	WOS:000225028200014
J	Nguyen, HT; Smeulders, AWM				Nguyen, HT; Smeulders, AWM			Fast occluded object tracking by a robust appearance filter	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object tracking; occlusions; appearance tracking; robust Kalman filter	MODELS; COLOR	We propose a new method for object tracking in image sequences using template matching. To update the template, appearance features are smoothed temporally by robust Kalman filters, one to each pixel. The resistance of the resulting template to partial occlusions enables the accurate detection and handling of more severe occlusions. Abrupt changes of lighting conditions can also be handled, especially when photometric invariant color features are used. The method has only a few parameters and is computationally fast enough to track objects in real time.	Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst Grp, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	Nguyen, HT (corresponding author), Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst Grp, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	tat@science.uva.nl; smeulders@science.uva.nl						Baker S., 2003, CMURITR0335; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; DELLAERT F, 1998, P 4 WORKSH APPL COMP; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; Ghahramani Z., 1996, CRGTR962 U TOR; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson A.D., 2001, P COMP VIS PATT REC; LEGTERS GR, 1982, IEEE T PATTERN ANAL, V4, P583, DOI 10.1109/TPAMI.1982.4767311; Li BX, 2000, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2000.854755; Maybeck P. S., 1982, STOCHASTIC MODELS ES, V2; Nguyen HT, 2002, IEEE IMAGE PROC, P569; Nguyen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P678, DOI 10.1109/ICCV.2001.937587; PAPANIKOLOPOULOS NP, 1993, IEEE T ROBOTIC AUTOM, V9, P14, DOI 10.1109/70.210792; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; Sidenbladh H., 2000, LNCS, V2, P702; Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760; Vermaak J, 2002, LECT NOTES COMPUT SC, V2350, P645; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590	21	125	142	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1099	1104		10.1109/TPAMI.2004.45	http://dx.doi.org/10.1109/TPAMI.2004.45			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641740	Green Submitted			2022-12-18	WOS:000221872400014
J	Liu, Y; Srihari, SN				Liu, Y; Srihari, SN			Document image binarization based on texture features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; document images; thresholding; texture analysis	THRESHOLDING TECHNIQUES	Binarization has been difficult for document images with poor contrast, strong noise, complex patterns, and/or variable modalities in gray-scale histograms. We developed a texture feature based thresholding algorithm to address this problem. Our algorithm consists of three steps: 1) Candidate thresholds are produced through iterative use of Otsu's algorithm; 2) Texture features associated with each candidate threshold are extracted from the run-length histogram of the accordingly binarized image; 3) The optimal threshold is selected so that desirable document texture features are preserved. Experiments with 9,000 machine printed address blocks from an unconstrained U.S. mail stream demonstrated that over 99.6 percent of the images were successfully binarized by the new thresholding method, appreciably better than those obtained by typical existing thresholding techniques. Also, a system run with 500 troublesome mail address blocks showed that an 8.1 percent higher character recognition rate was achieved with our algorithm as compared with Otsu's algorithm.			Liu, Y (corresponding author), SUNY BUFFALO,CTR EXCELLENCE DOCUMENT ANAL & RECOGNIT,BUFFALO,NY 14228, USA.		Srihari, Sargur N/E-8100-2011					ALBREGTSEN F, 1993, 8TH P SCAND C IM AN, P273; GIULIANO E, 1836, Patent No. 404715; JOHANNSEN G, 1982, 6TH P INT C PATT REC, P140; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443; LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X; Liu Y., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P278, DOI 10.1109/ICDAR.1993.395732; LIU Y, 1995, THESIS DEP EL COMP E; Marr D., 1982, VISION; OTSU N, 1978, IEEE T SYST MAN CYB, V8, P62; Palumbo P. W., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V697, P278, DOI 10.1117/12.976229; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1; WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038; WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400	16	125	132	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					540	544		10.1109/34.589217	http://dx.doi.org/10.1109/34.589217			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300016
J	Jacobs, DW				Jacobs, DW			Robust and efficient detection of salient convex groups	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						grouping; perceptual organization; convexity; proximity; nonaccidental properties; robust; efficiency; recognition	PERCEPTUAL ORGANIZATION; OBJECT RECOGNITION; IMAGES; DISCRIMINATION; SEGMENTATION; INFERENCE; CURVE; VIEW	This paper describes an algorithm that robustly locates salient convex collections of line segments in an image. The algorithm is guaranteed to find all convex sets of line segments in which the length of the gaps between segments is smaller than some fixed proportion of the total length of the lines. This enables the algorithm to find convex groups whose contours are partially occluded or missing due to noise. We give an expected case analysis of the algorithm's performance. This demonstrates that salient convexity is unlikely to occur at random, and hence is a strong clue that grouped line segments reflect underlying structure in the scene. We also show that our algorithm's run time is O(n(2)log(n) + nm), when we wish to find the in most salient groups in an image with n line segments. We support this analysis with experiments on real data, and demonstrate the grouping system as part of a complete recognition system.			Jacobs, DW (corresponding author), NEC RES INST, 4 INDEPENDENCE WAY, PRINCETON, NJ 08540 USA.							ALTER TD, 1995, THESIS MIT; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BASRI R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P8, DOI 10.1109/ICCV.1995.466931; BERGEVIN R, 1993, IEEE T PATTERN ANAL, V15, P19, DOI 10.1109/34.184772; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; Burns J. B., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P328, DOI 10.1109/CVPR.1992.223255; CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLEMENS D, 1991, AI TR1307 MIT TECHN; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; COX IJ, 1993, INT J COMPUT VISION, V11, P5, DOI 10.1007/BF01420590; DENASI S, 1992, PATTERN RECOGN LETT, V13, P529, DOI 10.1016/0167-8655(92)90071-7; Dolan J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P264, DOI 10.1109/CVPR.1992.223265; ELDER J, 1994, VISION RES, V34, P3361, DOI 10.1016/0042-6989(94)90070-1; FINKEL LH, 1992, NEURAL COMPUT, V4, P901, DOI 10.1162/neco.1992.4.6.901; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GUY G, 1993, DARPA IMAGE UNDERSTA, P881; HEITGER R, 1993, P IEEE INT C COMPUTE, P32; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HOFFMAN D, 1984, VISUAL COGNITION; Hu J., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P56, DOI 10.1109/ACV.1992.240327; HUANG TS, 1991, CVGIP-IMAG UNDERSTAN, V53, P125, DOI 10.1016/1049-9660(91)90012-E; HUTTENLOCHER DP, 1992, INT J COMPUT VISION, V8, P7, DOI 10.1007/BF00126398; JACOBS D, 1995, P DIMACS WORKSHOP PA; JACOBS D, 1992, IEEE C COMP VIS PATT, P439; JACOBS D, 1992, MIT AI TR1416; JACOBS D, 1989, MIT AI1177 MEM; Jacobs D. W., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P164; Jacobs D. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P770, DOI 10.1109/CVPR.1993.341167; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANISZA G, 1976, VISION ARTIFACT; KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D; Kohler W., 1959, GESTALT PSYCHOL; KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495; Kubovy M., 1981, PERCEPTUAL ORG; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MAHONEY J, 1987, MIT AI TR980; MARR D, 1977, ARTIF INTELL, V9, P37, DOI 10.1016/0004-3702(77)90013-3; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; NITZBERG M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P138; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; RICHARDS W, 1992, MIT AI1356 MEM; SARKAR S, 1993, IEEE T PATTERN ANAL, V15, P256, DOI 10.1109/34.204907; SAUND E, 1993, CVGIP-IMAG UNDERSTAN, V58, P327, DOI 10.1006/ciun.1993.1045; SAWHNEY HS, 1993, INT J COMPUT VISION, V11, P237, DOI 10.1007/BF01469344; SHAASHUA A, 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; SYEDAMAMHOOD T, 1992, 2ND P EUR C COMP VIS, P115; Wayner P. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P473, DOI 10.1109/CVPR.1991.139738; Williams L. R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P133, DOI 10.1109/ICCV.1990.139510; Witkin A. P., 1983, HUMAN MACHINE VISION; ZERROUG M, 1984, APPLICATIONS INVARIA; ZUCKER S, 1983, PHYSICAL BIOL PROCES; [No title captured]; [No title captured]	60	125	126	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					23	37		10.1109/34.476008	http://dx.doi.org/10.1109/34.476008			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500003
J	YOKOYA, N; LEVINE, MD				YOKOYA, N; LEVINE, MD			RANGE IMAGE SEGMENTATION BASED ON DIFFERENTIAL GEOMETRY - A HYBRID APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									MCGILL UNIV,MCGILL RES CTR INTELLIGENT MACHINES,COMP VIS & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA	McGill University	YOKOYA, N (corresponding author), ELECTROTECH LAB,TSUKUBA SCI CITY,IBARAKI 305,JAPAN.							BESL P, 1986, JUN P IEEE C COMP VI, P77; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; BESL PJ, 1988, MI GMR6090 REP; BEUADET PR, 1978, 4TH P INT JOINT C PA, P579; Bhanu B., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P236; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; FAUGERAS OD, 1983, JUN P IEEE C COMP VI, P8; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; LIPSCHUTZ MM, 1969, THEORY PROBLEMS DIFF; Muller Y., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1101; NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; TERZOPOULOS D, 1983, 8TH P INT JOINT C AR, P1073; Tomita F., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P186; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; YANG HS, 1986, COMPUT VISION GRAPH, V36, P229, DOI 10.1016/0734-189X(86)90077-0; YOKOYA N, 1987, MCRCIMTRCIM8716 REP; YOKOYA N, 1978, 4 INT JOINT C PATT R, P645	22	125	138	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					643	649		10.1109/34.24798	http://dx.doi.org/10.1109/34.24798			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749					2022-12-18	WOS:A1989U674900009
J	Li, S; Shao, M; Fu, Y				Li, Sheng; Shao, Ming; Fu, Yun			Person Re-Identification by Cross-View Multi-Level Dictionary Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dictionary learning; cross-view learning; multi-level representation; person re-identification	RANK	Person re-identification plays an important role in many safety-critical applications. Existing works mainly focus on extracting patch-level features or learning distance metrics. However, the representation power of extracted features might be limited, due to the various viewing conditions of pedestrian images in complex real-world scenarios. To improve the representation power of features, we learn discriminative and robust representations via dictionary learning in this paper. First, we propose a Cross-view Dictionary Learning (CDL) model, which is a general solution to the multi-view learning problem. Inspired by the dictionary learning based domain adaptation, CDL learns a pair of dictionaries from two views. In particular, CDL adopts a projective learning strategy, which is more efficient than the l(1) optimization in traditional dictionary learning. Second, we propose a Cross-view Multi-level Dictionary Learning (CMDL) approach based on CDL. CMDL contains dictionary learning models at different representation levels, including image-level, horizontal part-level, and patch-level. The proposed models take advantages of the view-consistency information, and adaptively learn pairs of dictionaries to generate robust and compact representations for pedestrian images. Third, we incorporate a discriminative regularization term to CMDL, and propose a CMDL-Dis approach which learns pairs of discriminative dictionaries in image-level and part-level. We devise efficient optimization algorithms to solve the proposed models. Finally, a fusion strategy is utilized to generate the similarity scores for test images. Experiments on the public VIPeR, CUHKCampus, iLIDS, GRID and PRID450S datasets show that our approach achieves the state-of-the-art performance.	[Li, Sheng] Adobe Res, San Jose, CA 95110 USA; [Shao, Ming] Univ Massachusetts, Dept Comp & Informat Sci, Dartmouth, MA 02747 USA; [Fu, Yun] Northeastern Univ, Coll Engn, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA	Adobe Systems Inc.; University of Massachusetts System; University Massachusetts Dartmouth; Northeastern University; Northeastern University	Li, S (corresponding author), Adobe Res, San Jose, CA 95110 USA.	shengli@ece.neu.edu; mshao@umassd.edu; yunfu@ece.neu.edu			NSF IIS award [1651902]; ONR Young Investigator Award [N00014-14-1-0484]; U.S. Army Research Office Award [W911NF-17-1-0367]	NSF IIS award(National Science Foundation (NSF)); ONR Young Investigator Award; U.S. Army Research Office Award	This research is supported in part by the NSF IIS award 1651902, ONR Young Investigator Award N00014-14-1-0484, and U.S. Army Research Office Award W911NF-17-1-0367.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Ahmed E., 2015, P IEEE C COMP VIS PA, P2197; [Anonymous], WORKSH DEM COMP VIS; Bhadra S, 2017, MACH LEARN, V106, P713, DOI 10.1007/s10994-016-5618-0; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764; Chen JX, 2015, IEEE T IMAGE PROCESS, V24, P4741, DOI 10.1109/TIP.2015.2466117; Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Garcia J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154; Gray D., 2007, IEEE INT WORKSH PERF, V3, P1; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guo H., 2013, ACCV 2012, V7724, P328, DOI DOI 10.1007/978-3-642-37331-2; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9; Javed O., 2008, IEEE TPAMI, V109, P146, DOI [10.1016/j.cviu.2007.01.003, DOI 10.1109/TPAMI.2014.2369055]; Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513; Kostinger Martin, 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247939; Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24; Li LY, 2014, IMAGE VISION COMPUT, V32, P814, DOI 10.1016/j.imavis.2014.02.007; Li S, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2155; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Y, 2015, IEEE WINT CONF APPL, P373, DOI 10.1109/WACV.2015.56; Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu CX, 2013, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2013.62; LIU X, 2014, PROC CVPR IEEE, P3550, DOI DOI 10.1109/CVPR.2014.454; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757; Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443; Ma Bingpeng, 2012, P BRIT MACH VIS C, P1; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Memisevic R., 2012, P INT C MACH LEARN, P1067; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Ni J, 2013, PROC CVPR IEEE, P692, DOI 10.1109/CVPR.2013.95; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Qiu Q, 2014, IEEE T PATTERN ANAL, V36, P2173, DOI 10.1109/TPAMI.2014.2316824; Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12; Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366; Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046; Shuhang G., 2014, ADV NEURAL INFORM PR, V27, P793; Sindhwani V., 2008, INT C MACH LEARN, V307, P976, DOI DOI 10.1145/1390156.1390279; Sridharan Karthik, 2008, COLT, P403; Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426; Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wu ZY, 2015, IEEE T PATTERN ANAL, V37, P1095, DOI 10.1109/TPAMI.2014.2360373; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Xu C., 2013, ARXIV13045634; Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578; Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539; Yang Y, 2017, AAAI CONF ARTIF INTE, P4306; Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35; Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]; Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315; Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng J., 2012, P BRIT MACH VIS C, P1; Zheng WS, 2012, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2012.6247985; Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23	69	124	131	3	74	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2963	2977		10.1109/TPAMI.2017.2764893	http://dx.doi.org/10.1109/TPAMI.2017.2764893			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29989963	hybrid			2022-12-18	WOS:000449355500013
J	Yuan, JY				Yuan, Jiangye			Learning Building Extraction in Aerial Scenes with Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional network; building extraction; GIS map; remote sensing		Extracting buildings from aerial scene images is an important task with many applications. However, this task is highly difficult to automate due to extremely large variations of building appearances, and still heavily relies on manual work. To attack this problem, we design a deep convolutional network with a simple structure that integrates activation from multiple layers for pixel-wise prediction, and introduce the signed distance function of building boundaries to represent output, which has an enhanced representation power. To train the network, we leverage abundant building footprint data from geographic information systems (GIS) to generate large amounts of labeled data. The trained model achieves a superior performance on datasets that are significantly larger and more complex than those used in prior work, demonstrating that the proposed method provides a promising and scalable solution for automating this labor-intensive task.	[Yuan, Jiangye] Oak Ridge Natl Lab, Computat Sci Engn Div, Oak Ridge, TN 37831 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory	Yuan, JY (corresponding author), Oak Ridge Natl Lab, Computat Sci Engn Div, Oak Ridge, TN 37831 USA.	yuanj@ornl.gov			US Department of Energy [DE-AC05-00OR22725]	US Department of Energy(United States Department of Energy (DOE))	This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the US Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for United States Government purposes.	Awrangjeb M, 2010, ISPRS J PHOTOGRAMM, V65, P457, DOI 10.1016/j.isprsjprs.2010.06.001; Benedek C, 2012, IEEE T PATTERN ANAL, V34, P33, DOI 10.1109/TPAMI.2011.94; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4; Inglada J, 2007, ISPRS J PHOTOGRAMM, V62, P236, DOI 10.1016/j.isprsjprs.2007.05.011; Kim TJ, 1999, IMAGE VISION COMPUT, V17, P3, DOI 10.1016/S0262-8856(98)00092-4; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mnih V., 2013, THESIS; Nielsen J., 2006, J NIELSENS ALERTBOX, V9, P1; Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Porway J, 2008, PROC CVPR IEEE, P141; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shu Y., 2015, THESIS; Silberman N, 2014, LECT NOTES COMPUT SC, V8689, P616, DOI 10.1007/978-3-319-10590-1_40; Theano Development Team, 2016, ARXIV160502688 THEAN; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yuan, 2014, P 22 ACM SIGSPATIAL, P271, DOI [10.1145/2666310.2666389, DOI 10.1145/2666310.2666389]; Zhou Q.Y., 2008, P 16 ACM SIGSPATIAL, P1, DOI DOI 10.1145/1463434.1463444	23	124	133	4	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2793	2798		10.1109/TPAMI.2017.2750680	http://dx.doi.org/10.1109/TPAMI.2017.2750680			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	28910757				2022-12-18	WOS:000446683700020
J	Choi, WG; Pantofaru, C; Savarese, S				Choi, Wongun; Pantofaru, Caroline; Savarese, Silvio			A General Framework for Tracking Multiple People from a Moving Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multitarget tracking; person detection; people tracking; RJ-MCMC particle filtering		In this paper, we present a general framework for tracking multiple, possibly interacting, people from a mobile vision platform. To determine all of the trajectories robustly and in a 3D coordinate system, we estimate both the camera's ego-motion and the people's paths within a single coherent framework. The tracking problem is framed as finding the MAP solution of a posterior probability, and is solved using the reversible jump Markov chain Monte Carlo (RJ-MCMC) particle filtering method. We evaluate our system on challenging datasets taken from moving cameras, including an outdoor street scene video dataset, as well as an indoor RGB-D dataset collected in an office. Experimental evidence shows that the proposed method can robustly estimate a camera's motion from dynamic scenes and stably track people who are moving independently or interacting.	[Choi, Wongun; Savarese, Silvio] Univ Michigan, Dept Elect & Comp Engn, Room 4435,1301 Beal Ave, Ann Arbor, MI 48109 USA; [Pantofaru, Caroline] Willow Garage Inc, Menlo Pk, CA 94025 USA	University of Michigan System; University of Michigan	Choi, WG (corresponding author), Univ Michigan, Dept Elect & Comp Engn, Room 4435,1301 Beal Ave, Ann Arbor, MI 48109 USA.	wgchoi@umich.edu; pantofaru@willowgarage.com; silvio@eecs.umich.edu						Andriluka M., 2008, P IEEE C COMP VIS PA; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bibby C., 2008, P 10 EUR C COMP VIS; Breitenstein M.D., 2009, P 12 IEEE INT C COMP; Choi W., 2010, P EUR C COMP VIS; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, HISTOGRAMS ORIENTED; Ess A., 2008, P IEEE C COMP VIS PA; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gower J. C., 2004, PROCRUSTES PROBLEMS; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Izadi S., 2011, P ACM S US INT SOFTW; Jones Michael J., 1999, P IEEE C COMP VIS PA; Kammerl J, 2011, OCTREE POINT CLOUD C; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Kwak S., 2011, P IEEE INT C COMP VI; Leibe B., 2004, P ECCV STAT LEARN CO; Lienhart R., 2002, P INT C IM PROC; Microsoft Corp, 2012, KIN XBOX; Minvielle P., 2005, P INT C INF FUS; OpenCV, 2012, OP SOURC COMP VIS LI; Pellegrini S., 2009, P 12 IEEE INT C COMP; Pirsiavash H., 2011, P IEEE C COMP VIS PA; PrimeSense, 2012, NITE NAT INT MIDDL; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Rusu R. B., 2011, P INT C ROB AUT MAY; Scovanner P., 2009, P IEEE INT C COMP VI; Shitrit H. B., 2011, P IEEE INT C COMP VI; Tomasi C., 1991, TECHNICAL REPORT; TUZEL O, 2007, P IEEE C COMP VIS PA; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P., 2003, P IEEE INT C COMP VI; Wojek C., 2009, P IEEE C COMP VIS PA; Wojek C, 2011, PROC CVPR IEEE; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Xing J., 2009, P IEEE C COMP VIS PA; Zhang L., 2008, P IEEE C COMP VIS PA	45	124	132	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1577	1591		10.1109/TPAMI.2012.248	http://dx.doi.org/10.1109/TPAMI.2012.248			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681988				2022-12-18	WOS:000319060600004
J	Sarkar, S; Soundararajan, P				Sarkar, S; Soundararajan, P			Supervised learning of large perceptual organization: Graph spectral partitioning and learning automata	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual organization; learning in vision; learning automata; Bayesian networks; feature grouping; object recognition; figure ground segmentation	OBJECT RECOGNITION; IMAGE SEGMENTATION; QUANTITATIVE MEASURES; EIGENVECTORS; SYSTEM; DISCRIMINATION; INFORMATION; EIGENVALUES; PARAMETERS; ALGORITHM	Perceptual organization offers an elegant framework to group low-level features that are likely to come from a single object. We offer a novel strategy to adapt this grouping process to objects in a domain. Given a set of training images of objects in context, the associated learning process decides on the relative importance of the basic salient relationships such as proximity, parallelness, continuity, junctions, and common region toward segregating the objects from the background. The parameters of the grouping process are cast as probabilistic specifications of Bayesian networks that need to be learned. This learning is accomplished using a team of stochastic automata in an N-player cooperative game framework. The grouping process, which is based on graph partitioning is, able to form large groups from relationships defined over a small set of primitives and is fast. We statistically demonstrate the robust performance of the grouping and the learning frameworks on a variety of real images. Among the interesting conclusions are the significant role of photometric attributes in grouping and the ability to form large salient groups from a set of local relations, each defined over a small number of primitives.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	State University System of Florida; University of South Florida	Sarkar, S (corresponding author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.	sarkar@csee.usf.edu; psoundar@csee.usf.edu	Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; BHANU B, 1995, IEEE T SYST MAN CYB, V25, P1543, DOI 10.1109/21.478442; Borra S, 1997, IEEE T PATTERN ANAL, V19, P1306, DOI 10.1109/34.632991; BOYER KL, 1991, IEEE T SYST MAN CYB, V21, P143, DOI 10.1109/21.101145; CASADEI S, 1998, INT J COMPUTER VISIO, V27; CHO K, 1994, IEEE T PATTERN ANAL, V16, P882, DOI 10.1109/34.310683; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; DRAPER B, 1996, P INT C PATT REC, VD, P95; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; ETEMADI A, 1991, P BRIT MACH VIS C, P119; FIEDLER M, 1973, CZECH MATH J, V23, P298; FIEDLER M, 1975, CZECH MATH J, V25, P619; GREENSPAN H, 1994, IEEE T PATTERN ANAL, V16, P894, DOI 10.1109/34.310685; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P920, DOI 10.1109/34.93810; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; Horn R.A., 2013, MATRIX ANAL, P321; HOUZELLE S, 1994, INT C PATT RECOG, P830, DOI 10.1109/ICPR.1994.576460; IHLER E, 1993, INFORM PROCESS LETT, V45, P171, DOI 10.1016/0020-0190(93)90115-P; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; Li SZ, 1997, INT J COMPUT VISION, V21, P207, DOI 10.1023/A:1007947800092; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; McCafferty James D., 1990, HUMAN MACHINE VISION; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Murino V, 1996, IEEE T SYST MAN CY B, V26, P1, DOI 10.1109/3477.484434; Murino V, 1997, INT J PATTERN RECOGN, V11, P359, DOI 10.1142/S0218001497000160; Narendra K. S., 1989, LEARNING AUTOMATA IN; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691; Peng J, 1998, IEEE T PATTERN ANAL, V20, P139, DOI 10.1109/34.659932; POPE A, 1996, EARLY VISUAL LEARNIN, P67; POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030; ROCK I, 1990, SCI AM, V263, P84, DOI 10.1038/scientificamerican1290-84; ROTH G, 1994, IEEE T PATTERN ANAL, V16, P901, DOI 10.1109/34.310686; SARKAR S, 1994, IEEE T SYST MAN CYB, V24, P246, DOI 10.1109/21.281424; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; SARKAR S, 1993, IEEE T PATTERN ANAL, V15, P256, DOI 10.1109/34.204907; Sarkar S, 1998, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.1998.698692; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; THATHACHAR MAL, 1987, IEEE T SYST MAN CYB, V17, P73, DOI 10.1109/TSMC.1987.289334; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Williams C A, 1996, J Clin Rheumatol, V2, P64, DOI 10.1097/00124743-199604000-00002; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673	47	124	140	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					504	525		10.1109/34.857006	http://dx.doi.org/10.1109/34.857006			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV		Green Submitted			2022-12-18	WOS:000088347500007
J	KANATANI, K				KANATANI, K			ANALYSIS OF 3-D ROTATION FITTING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						3-D ROTATION; SINGULAR VALUE DECOMPOSITION; POLAR DECOMPOSITION; QUATERNION REPRESENTATION; ESSENTIAL MATRIX; COVARIANCE MATRIX	MOTION; PARAMETERS; VIEWS	Computational techniques for fitting a 3-D rotation to 3-D data are recapitulated in a refined form as minimization over proper rotations, extending three existing methods-the method of singular value decomposition, the method of polar decomposition, and the method of quaternion representation. Then, we describe the problem of 3-D motion estimation in this new light. Finally, we define the covariance matrix of a rotation and analyze the statistical behavior of errors in 3-D rotation fitting.			KANATANI, K (corresponding author), GUNMA UNIV, DEPT COMP SCI, KIRYU, GUNMA 376, JAPAN.							ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; KANATANI K, 1991, CVGIP-IMAG UNDERSTAN, V54, P333, DOI 10.1016/1049-9660(91)90034-M; KANATANI K, 1993, IEEE T PATTERN ANAL, V15, P37, DOI 10.1109/34.184773; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KANATANI K, 1994, COMPUT VISION GRAPHI, V59; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1988, P ROY SOC LOND A MAT, V418, P1, DOI 10.1098/rspa.1988.0071; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779	14	124	131	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					543	549		10.1109/34.291441	http://dx.doi.org/10.1109/34.291441			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100012
J	NELSON, RC; ALOIMONOS, JY				NELSON, RC; ALOIMONOS, JY			OBSTACLE AVOIDANCE USING FLOW FIELD DIVERGENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	NELSON, RC (corresponding author), UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627, USA.							ANANDAN P, 1985, 3RD P WORKSH COMP VI, P186; [Anonymous], 1986, EVASION DIVISAS HIST; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BOLLES RC, 1987, P INT JOINT C INTELL, P7; BROOKS RA, 1986, MIT899 ART INT LAB A; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; LONGUETHIGGINS HC, 1981, NATURE, V293; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MOROVEC HP, 1979, P IJCAI, P598; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NELSON RC, 1988, BIOL CYBERN, V58, P261, DOI 10.1007/BF00364131; NELSON RC, TR1840 U MAR COMP SC; NELSON RC, 1988, APR IM UND WORKSH CA, P548; PRAZDNY K, 1981, COMPUT VISION GRAPH, V22, P238; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006; VERRI A, 1987, JUN INT C COMP VIS, P171; WAXMAN AM, 1987, ADV COMPUTER VISION; YASUMOTO Y, 1985 P IEEE COMP SOC, P560	19	124	126	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1102	1106		10.1109/34.42840	http://dx.doi.org/10.1109/34.42840			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900007
J	COWAN, CK; KOVESI, PD				COWAN, CK; KOVESI, PD			AUTOMATIC SENSOR PLACEMENT FROM VISION TASK REQUIREMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											COWAN, CK (corresponding author), SRI INT,ROBOT LAB,MENLO PK,CA 94025, USA.							[Anonymous], AFHRLTR6914 US AIR F; BENTON R, 1986, AFWALTR864122 HON IN; CASTORE G, 1984, P IEEE INT C ROBOTIC, P90; CHAKRAVARTY I, 1982, THESIS RENSSELAER PO; COWAN CK, 1986, AUTOMATIC SENSOR PLA; ELZINGA DJ, 1972, MANAGE SCI, V19, P96, DOI 10.1287/mnsc.19.1.96; Fuchs H., 1980, Computer Graphics, V14, P124, DOI 10.1145/965105.807481; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KROTKOV EP, 1986, MSCIS8622 U PENNS TE; LARROWE VL, 1986, ERIM6281091X TECH RE; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; PLANTINGA WH, 1985, 627 U WISC DEP COMP	12	124	130	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					407	416		10.1109/34.3905	http://dx.doi.org/10.1109/34.3905			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700012
J	Han, XF; Laga, H; Bennamoun, M				Han, Xian-Feng; Laga, Hamid; Bennamoun, Mohammed			Image-Based 3D Object Reconstruction: State-of-the-Art and Trends in the Deep Learning Era	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Image reconstruction; Shape; Training; Deep learning; Two dimensional displays; Australia; 3D reconstruction; depth estimation; SLAM; SfM; CNN; deep learning; LSTM; 3D face; 3D human body; 3D video	PARAMETERIZATION	3D reconstruction is a longstanding ill-posed problem, which has been explored for decades by the computer vision, computer graphics, and machine learning communities. Since 2015, image-based 3D reconstruction using convolutional neural networks (CNN) has attracted increasing interest and demonstrated an impressive performance. Given this new era of rapid evolution, this article provides a comprehensive survey of the recent developments in this field. We focus on the works which use deep learning techniques to estimate the 3D shape of generic objects either from a single or multiple RGB images. We organize the literature based on the shape representations, the network architectures, and the training mechanisms they use. While this survey is intended for methods which reconstruct generic objects, we also review some of the recent works which focus on specific object classes such as human body shapes and faces. We provide an analysis and comparison of the performance of some key papers, summarize some of the open problems in this field, and discuss promising directions for future research.	[Han, Xian-Feng] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China; [Han, Xian-Feng] Tianjin Univ, Tianjin 300072, Peoples R China; [Han, Xian-Feng; Bennamoun, Mohammed] Univ Western Australia, Perth, WA 6009, Australia; [Laga, Hamid] Murdoch Univ, Informat Technol Math & Stat Discipline, Perth, WA 6150, Australia; [Laga, Hamid] Univ South Australia, Phen & Bioinformat Res Ctr, Adelaide, SA 5001, Australia	Southwest University - China; Tianjin University; University of Western Australia; Murdoch University; University of South Australia	Laga, H (corresponding author), Murdoch Univ, Informat Technol Math & Stat Discipline, Perth, WA 6150, Australia.	hanxianf@163.com; H.Laga@murdoch.edu.au; mohammed.bennamoun@uwa.edu.au	Bennamoun, Mohammed/C-2789-2013	Bennamoun, Mohammed/0000-0002-6603-3257; Han, Xianfeng/0000-0002-4869-4537	China Scholarship Council (CSC) scholarship; ARC [DP150100294, DP150104251]	China Scholarship Council (CSC) scholarship(China Scholarship Council); ARC(Australian Research Council)	Xian-Feng Han is supported by a China Scholarship Council (CSC) scholarship. This work was supported in part by ARC DP150100294 and DP150104251. Xian-Feng Han and Hamid Laga are joint first authors.	Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238; Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Arjovsky M., 2017, ARXIV170107875; Armeni I, 2017, ARXIV; Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170; Besl Paul J, 1992, ROBOTICS DL TENTATIV, P586, DOI DOI 10.1109/34.121791; Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Calakli F, 2011, COMPUT GRAPH FORUM, V30, P1993, DOI 10.1111/j.1467-8659.2011.02058.x; Cao YP, 2018, LECT NOTES COMPUT SC, V11213, P626, DOI 10.1007/978-3-030-01240-3_38; Chang Angel X., 2015, ARXIV151203012CSGR P; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609; CHERABIER I, 2018, P EUR C COMP VIS, P325; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Delanoy J, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203197; DErrico J, 2005, MATLAB CENTRAL FILE, V643; Dibra E, 2017, PROC CVPR IEEE, P5504, DOI 10.1109/CVPR.2017.584; Dibra E, 2016, INT CONF 3D VISION, P108, DOI 10.1109/3DV.2016.19; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Feng MT, 2018, LECT NOTES COMPUT SC, V11214, P508, DOI 10.1007/978-3-030-01249-6_31; Gadelha M, 2018, LECT NOTES COMPUT SC, V11211, P105, DOI 10.1007/978-3-030-01234-2_7; Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874; Georgiou P., 2019, IEEE T SYST MAN CYBE, DOI [DOI 10.1109/TSMC.2019, DOI 10.1109/TSUSC.2019.2904680]; Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021; Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276; Grant E, 2016, LECT NOTES COMPUT SC, V9915, P266, DOI 10.1007/978-3-319-49409-8_22; Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030; Gulrajani I, 2017, P NIPS 2017; Gwak J., 2017, ARXIV170510904, P263; Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19; Hane C., 2019, P PAMI, V1, P1; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HENDERSON P, 2018, P BRIT MACH VIS C; Huang Z, 2018, LECT NOTES COMPUT SC, V11220, P351, DOI 10.1007/978-3-030-01270-0_21; Insafutdinov E, 2018, ADV NEUR IN, V31; Izadinia H, 2017, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2017.260; Jack Dominic, 2018, P AS C COMP VIS, P317; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; Jiang L, 2018, LECT NOTES COMPUT SC, V11212, P820, DOI 10.1007/978-3-030-01237-3_49; Johnston A, 2017, IEEE INT CONF COMP V, P930, DOI 10.1109/ICCVW.2017.114; Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23; Kato H, 2019, PROC CVPR IEEE, P9770, DOI 10.1109/CVPR.2019.01001; Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411; Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Kingma D.P, P 3 INT C LEARNING R; Knyaz VA, 2019, LECT NOTES COMPUT SC, V11129, P601, DOI 10.1007/978-3-030-11009-3_37; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375; Kurenkov A, 2018, IEEE WINT CONF APPL, P858, DOI 10.1109/WACV.2018.00099; Kurtek S, 2013, COMPUT GRAPH FORUM, V32, P429, DOI 10.1111/cgf.12063; Laga H., 2018, ACAD PRESS LIB SIGNA, VVolume 6, P261, DOI [10.1016/B978-0-12-811889-4.00007-5, DOI 10.1016/B978-0-12-811889-4.00007-5]; Laga H, 2019, 3D SHAPE ANAL FUNDAM; Laga H., 2019, ARXIV PREPRINT ARXIV; Laga H, 2017, IEEE T PATTERN ANAL, V39, P2451, DOI 10.1109/TPAMI.2016.2647596; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Li C. L., 2019, PROC DEEP GENERATIVE, P1; Li C, 2017, PROC CVPR IEEE, P388, DOI 10.1109/CVPR.2017.49; Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637; Li KJ, 2018, LECT NOTES COMPUT SC, V11216, P508, DOI 10.1007/978-3-030-01258-8_31; Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060; Liao YY, 2018, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR.2018.00308; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Lin CH, 2018, AAAI CONF ARTIF INTE, P7114; Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202; Liu SK, 2018, INT CONF 3D VISION, P542, DOI 10.1109/3DV.2018.00068; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018; Lunscher N, 2017, IEEE INT CONF COMP V, P2300, DOI 10.1109/ICCVW.2017.271; Mandikal P., 2018, BMVC, P662; Mandikal P., 2018, PROC EUR C COMPUT VI, P662; Mandikal P, 2019, IEEE WINT CONF APPL, P1052, DOI 10.1109/WACV.2019.00117; Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459; Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576; Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475; Novotny D., 2018, IEEE T PATTERN ANAL, P1; Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062; Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025; Petersen F., 2019, ARXIV190311149; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Pontes JK, 2019, LECT NOTES COMPUT SC, V11361, P365, DOI 10.1007/978-3-030-20887-5_23; Pontes JK, 2017, INT CONF 3D VISION, P88, DOI 10.1109/3DV.2017.00020; Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274; Pumarola A, 2018, PROC CVPR IEEE, P4681, DOI 10.1109/CVPR.2018.00492; Qi Charles R, 2017, ARXIV170602413; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezende DJ, 2016, ADV NEUR IN, V29; Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589; Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56; Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207; Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701; Riemenschneider H, 2014, LECT NOTES COMPUT SC, V8693, P516, DOI 10.1007/978-3-319-10602-1_34; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sarma, 2018, ARXIV181005591; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175; Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011; Silberman Nathan, 2012, EUR C COMP VIS, DOI 10.1007/978-3-642-33715-4_54; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91; Smith E, 2018, ADV NEUR IN, V31; Smith Edward J., 2017, ABS170709557 CORR; Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314; Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20; Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Tulsiani S, 2017, IEEE T PATTERN ANAL, V39, P719, DOI 10.1109/TPAMI.2016.2574713; Tulsiani S, 2018, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR.2018.00306; Tulsiani S, 2018, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2018.00039; Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30; Varley J, 2017, IEEE INT C INT ROBOT, P2442; Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; Wah C., 2011, TECH REP; Wang G, 2018, COMPUT GRAPH FORUM, V37, P185, DOI 10.1111/cgf.13501; Wang G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3144456; Wang JL, 2019, AAAI CONF ARTIF INTE, P8949; Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4; Wang PS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275050; Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608; Wang WY, 2017, IEEE I CONF COMP VIS, P2317, DOI 10.1109/ICCV.2017.252; Ward I.R., 2019, RGB D IMAGE ANAL PRO, P169, DOI [10.1007/978-3-030-28603-3_8, DOI 10.1007/978-3-030-28603-3_8]; Welinder P., 2010, CNSTR2010001 CALTECH; Wiles O., 2017, BRIT MACH VIS C; Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40; Wu JY, 2017, INT C COMP SUPP COOP, P540; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xiang Y, 2016, LECT NOTES COMPUT SC, V9912, P160, DOI 10.1007/978-3-319-46484-8_10; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278; Yang B, 2017, IEEE INT CONF COMP V, P679, DOI 10.1109/ICCVW.2017.86; Yang B, 2019, IEEE T PATTERN ANAL, V41, P2820, DOI 10.1109/TPAMI.2018.2868195; YANG G, 2018, P EUR C COMP VIS, P90; Zeng W., 2018, ARXIV181201402; Zhang XM, 2018, ADV NEUR IN, V31; Zhu R, 2017, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2017.16; Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103	164	123	128	112	399	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1578	1604		10.1109/TPAMI.2019.2954885	http://dx.doi.org/10.1109/TPAMI.2019.2954885			27	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31751229	Green Submitted			2022-12-18	WOS:000637533800008
J	Robins, V; Wood, PJ; Sheppard, AP				Robins, Vanessa; Wood, Peter John; Sheppard, Adrian P.			Theory and Algorithms for Constructing Discrete Morse Complexes from Grayscale Digital Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Discrete Morse theory; computational topology; persistent homology; digital topology	COMPUTATION; POINTS; SPACES	We present an algorithm for determining the Morse complex of a two or three-dimensional grayscale digital image. Each cell in the Morse complex corresponds to a topological change in the level sets (i.e., a critical point) of the grayscale image. Since more than one critical point may be associated with a single image voxel, we model digital images by cubical complexes. A new homotopic algorithm is used to construct a discrete Morse function on the cubical complex that agrees with the digital image and has exactly the number and type of critical cells necessary to characterize the topological changes in the level sets. We make use of discrete Morse theory and simple homotopy theory to prove correctness of this algorithm. The resulting Morse complex is considerably simpler than the cubical complex originally used to represent the image and may be used to compute persistent homology.	[Robins, Vanessa; Sheppard, Adrian P.] Australian Natl Univ, Res Sch Phys & Engn, Dept Appl Math, Canberra, ACT 0200, Australia; [Wood, Peter John] Australian Natl Univ, Resource Management Asia Pacific Program, Coll Asia & Pacific, Canberra, ACT 0200, Australia	Australian National University; Australian National University	Robins, V (corresponding author), Australian Natl Univ, Res Sch Phys & Engn, Dept Appl Math, GPO Box 4, Canberra, ACT 0200, Australia.	Vanessa.Robins@anu.edu.au; peter.j.wood@anu.edu.au; Adrian.Sheppard@anu.edu.au	Robins, Vanessa/A-7010-2012; Sheppard, Adrian/W-4050-2019; Sheppard, Adrian/A-7410-2008	Robins, Vanessa/0000-0001-7118-8491; Sheppard, Adrian/0000-0001-9792-4143; Sheppard, Adrian/0000-0001-9792-4143	Australian Research Council [DP0666442]	Australian Research Council(Australian Research Council)	This work was supported by the Australian Research Council Discovery project DP0666442. We would like to thank Ajay Limaye and Munish Kumar for their help rendering Fig. 5 using the visualization tool Drishti.	BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380; Biasotti S, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391731; BOTT R, 1988, MORSE THEORY INDOMIT, V68, P99; CAYLEY A, 1859, PHILOS MAG, V18, P264; Couprie M, 2001, J ELECTRON IMAGING, V10, P1003, DOI 10.1117/1.1408316; Couprie M, 2008, LECT NOTES COMPUT SC, V4992, P105, DOI 10.1007/978-3-540-79126-3_11; Couprie M, 2009, IEEE T PATTERN ANAL, V31, P637, DOI 10.1109/TPAMI.2008.117; DELFINADO CJA, 1995, COMPUT AIDED GEOM D, V12, P771, DOI 10.1016/0167-8396(95)00016-Y; Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2; Edelsbrunner H., 2001, P 17 ACM S COMP GEOM, P70; Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI DOI 10.1145/777792.777846; Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650; Forman R., 2002, SEMINAIRE LOTHARINGI, V48; Gyulassy A. G., 2008, THESIS U CALIFORNIA; Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110; Gyulassy A, 2007, IEEE T VIS COMPUT GR, V13, P1440, DOI 10.1109/TVCG.2007.70552; Hatcher A., 2005, ALGEBRAIC TOPOLOGY; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; King H, 2005, EXP MATH, V14, P435, DOI 10.1080/10586458.2005.10128941; KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5; Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186; Lewiner T, 2003, EXP MATH, V12, P271, DOI 10.1080/10586458.2003.10504498; Lewiner T, 2003, COMP GEOM-THEOR APPL, V26, P221, DOI 10.1016/S0925-7721(03)00014-2; LEWINER T, 2005, THESIS PONTIFICIA U; Maxwell J.C., 1870, PHILOS MAGAZ J SCI, V40, P421; MILNOR J, 1969, MORSE THEORY ANN MAT, V51; Munkres J.R., 1984, ELEMENTS ALGEBRAIC T; Robins V., 1999, TOPOLOGY P, V24, P503; SAKELLARIOU A, 2004, P SOC PHOTO-OPT INS, V5535, P166; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Whitehead JHC, 1939, P LOND MATH SOC, V45, P243; ZOMORODIAN A, 2009, ALGORITHMS THEORY CO; 2006, DRISHTI VOLUME EXPLO	33	123	123	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1646	1658		10.1109/TPAMI.2011.95	http://dx.doi.org/10.1109/TPAMI.2011.95			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21576736				2022-12-18	WOS:000291807200012
J	Fu, ZY; Robles-Kelly, A; Zhou, J				Fu, Zhouyu; Robles-Kelly, Antonio; Zhou, Jun			MILIS: Multiple Instance Learning with Instance Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple instance learning; support vector machine; feature selection; alternating optimization	CLASSIFICATION	Multiple instance learning (MIL) is a paradigm in supervised learning that deals with the classification of collections of instances called bags. Each bag contains a number of instances from which features are extracted. The complexity of MIL is largely dependent on the number of instances in the training data set. Since we are usually confronted with a large instance space even for moderately sized real-world data sets applications, it is important to design efficient instance selection techniques to speed up the training process without compromising the performance. In this paper, we address the issue of instance selection in MIL. We propose MILIS, a novel MIL algorithm based on adaptive instance selection. We do this in an alternating optimization framework by intertwining the steps of instance selection and classifier learning in an iterative manner which is guaranteed to converge. Initial instance selection is achieved by a simple yet effective kernel density estimator on the negative instances. Experimental results demonstrate the utility and efficiency of the proposed approach as compared to the state of the art.	[Fu, Zhouyu] Monash Univ, Gippsland Sch IT, Fac Informat Technol, Churchill, Vic 3842, Australia; [Robles-Kelly, Antonio; Zhou, Jun] Natl ICT Australia, Canberra Res Lab, Canberra, ACT 2601, Australia; [Robles-Kelly, Antonio; Zhou, Jun] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia	Federation University Australia; Monash University; NICTA; Australian National University	Fu, ZY (corresponding author), Monash Univ, Gippsland Sch IT, Fac Informat Technol, Bldg 4N,Northways Rd, Churchill, Vic 3842, Australia.	zhouyu.fu@monash.edu; antonio.robles-kelly@nicta.com.au; jun.zhou@nicta.com.au	Robles-Kelly, Antonio/A-2459-2009; Zhou, Jun/W-2233-2019	Robles-Kelly, Antonio/0000-0002-2465-5971; Zhou, Jun/0000-0001-5822-8233	Australian Government, Department of Broadband, Communications and the Digital Economy; Australian Research Council through the ICT Centre of Excellence	Australian Government, Department of Broadband, Communications and the Digital Economy(Australian Government); Australian Research Council through the ICT Centre of Excellence(Australian Research Council)	The work presented here was done when Zhouyu Fu was with the National ICT Australia (NICTA). NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy, and the Australian Research Council through the ICT Centre of Excellence Program.	Andrews S., 2002, SUPPORT VECTOR MACHI, P561; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BOSCH A, 2008, INT J COMPUTER VISIO; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Bousquet O., 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Chen YX, 2004, J MACH LEARN RES, V5, P913; CHEUNG PM, 2006, P 23 INT C MACH LEAR, P193; Cholleti SR, 2006, PROC INT C TOOLS ART, P336; CRAMMER K, 2001, J MACHINE LEARNING R, V2, P265, DOI DOI 10.1162/15324430260185628; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Duda R.O., 2000, PATTERN CLASSIFICATI; FEIFEI L, 2004, P IEEE CVPR WORKSH G; FU Z, 2008, P INT C PATT REC; Gartner T., 2002, ICML, P179; Grauman K, 2007, J MACH LEARN RES, V8, P725; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HASTIE T, 1998, P C ADV NEUR INF PRO, V10; Joachims T., 2006, P KDD 2006; Lazebnik S., 2006, P IEEE C COMP VIS PA; Mangasarian OL, 2008, J OPTIMIZ THEORY APP, V137, P555, DOI 10.1007/s10957-007-9343-5; Maron O, 1998, ADV NEUR IN, V10, P570; Minka T, 1998, EXPECTATION MAXIMIZA; Platt JC, 2000, ADV NEUR IN, P61; Rahmani R, 2008, IEEE T PATTERN ANAL, V30, P1902, DOI 10.1109/TPAMI.2008.112; Ray S, 2005, P 22 INT C MACHINE L, P697, DOI DOI 10.1145/1102351.1102439; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Varma Manik, 2007, P INT C COMP VIS; VIOLA P, 2005, P C NEUR INF PROC SY; Wang Jun, 2000, ICML, P1119; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhou Z.-H., 2007, P 24 INT C MACHINE L, P1167; ZHU J, 2003, P C NEUR INF PROC SY	37	123	138	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					958	977		10.1109/TPAMI.2010.155	http://dx.doi.org/10.1109/TPAMI.2010.155			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20733226	Green Published, Green Submitted			2022-12-18	WOS:000288677800008
J	Wang, JD; Wang, F; Zhang, CS; Shen, HC; Quan, L				Wang, Jingdong; Wang, Fei; Zhang, Changshui; Shen, Helen C.; Quan, Long			Linear Neighborhood Propagation and Its Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian Markov random fields; linear neighborhood propagation; transductive classification; image segmentation	IMAGE	In this paper, a novel graph-based transductive classification approach, called Linear Neighborhood Propagation, is proposed. The basic idea is to predict the label of a data point according to its neighbors in a linear way. This method can be cast into a second-order intrinsic Gaussian Markov random field framework. Its result corresponds to a solution to an approximate inhomogeneous biharmonic equation with Dirichlet boundary conditions. Different from existing approaches, our approach provides a novel graph structure construction method by introducing multiple-wise edges instead of pairwise edges, and presents an effective scheme to estimate the weights for such multiple-wise edges. To the best of our knowledge, these two contributions are novel for semi-supervised classification. The experimental results on image segmentation and transductive classification demonstrate the effectiveness and efficiency of the proposed approach.	[Wang, Jingdong] Microsoft Res Asia, Internet Media Grp, Beijing Sigma Ctr, Beijing 100190, Peoples R China; [Wang, Fei; Zhang, Changshui] Tsinghua Univ, Dept Automat, Natl Lab Informat Sci & Technol TNList, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Shen, Helen C.; Quan, Long] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China; [Wang, Fei] Florida Int Univ, Data Min Grp, Miami, FL 33199 USA; [Shen, Helen C.] Univ Waterloo, Waterloo, ON N2L 3G1, Canada	Microsoft; Microsoft Research Asia; Tsinghua University; Hong Kong University of Science & Technology; State University System of Florida; Florida International University; University of Waterloo	Wang, JD (corresponding author), Microsoft Res Asia, Internet Media Grp, Beijing Sigma Ctr, 5-F,49,Zhichun Rd, Beijing 100190, Peoples R China.	welleast@gmail.com; feiwang03@gmail.com; zcs@mail.tsinghua.edu.cn; helens@cse.ust.hk; quan@cse.ust.hk	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445; Wang, Fei/0000-0001-9459-9461	NSFC [60721003]; RGC/NSFC [N_HKUST602/05]; Hong Kong RGC [619107]	NSFC(National Natural Science Foundation of China (NSFC)); RGC/NSFC(Hong Kong Research Grants CouncilNational Natural Science Foundation of China (NSFC)); Hong Kong RGC(Hong Kong Research Grants Council)	The authors would like to thank the anonymous reviewers for their constructive and helpful comments. Fei Wang and Changshui Zhang were supported by NSFC Grant No. 60721003. This work was also supported by RGC/NSFC project N_HKUST602/05 and Hong Kong RGC project 619107.	Agarwal S., 2006, ICML, P17, DOI DOI 10.1145/1143844.1143847; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2002, ADV NEUR IN, V14, P585; BELKIN M, 2004, P 17 ANN C LEARN THE, P624; Belkin Misha, 2005, P 10 INT WORKSH ART, P17; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; BLUM A, 2004, P 21 INT C MACH LEAR; Blumenthal M, 2001, Adv Nurse Pract, V9, P26; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; CHAPELLE O, 2002, ADV NEURAL INFORM PR, V15, P585; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Delalleau Olivier, 2005, P 10 INT WORKSH ART; Fujino A., 2005, PROC AAAI, P764; Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423; Grady L, 2005, PROC CVPR IEEE, P763; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; HE J., 2004, P 12 ANN ACM INT C M, P9, DOI DOI 10.1145/1027527.1027531; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Joachims T., 2003, P 20 INT C MACH LEAR, P290, DOI DOI 10.1145/2612669.2612699; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; KOLMOGOROV V, 2002, P EUR C COMP VIS, P82; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Lee JG, 2005, PATTERN RECOGN, V38, P997, DOI 10.1016/j.patcog.2005.01.007; LEVIN A, 2006, P IEEE CVPR 2006, P61; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Nene S. A., 1996, COLUMBIA OBJECT IMAG; NIGAM K, 2001, THSIS CARNEGIE MELLO; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rue H, 2005, G MARKOV RANDOM FIEL; Samaria F., 1994, P IEEE WORKSH APPL C; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang F, 2005, IEEE IJCNN, P1971; Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672; WU Q, 2005, P 11 WORLD C INT FUZ; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; Zhou D., 2006, ADV NEURAL INF PROCE, V19, P1601; Zhou Dengyong, 2003, ADV NEURAL INFORM PR, V16; Zhou DY, 2004, LECT NOTES COMPUT SC, V3175, P237; ZHU X, 2006, 1530 U WISC MAD DEP; Zhu X., 2003, INT C MACH LEARN	44	123	136	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1600	1615		10.1109/TPAMI.2008.216	http://dx.doi.org/10.1109/TPAMI.2008.216			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574621				2022-12-18	WOS:000267369800005
J	Lichtenauer, JF; Hendriks, EA; Reinders, MJT				Lichtenauer, Jeroen F.; Hendriks, Emile A.; Reinders, Marcel J. T.			Sign language recognition by combining statistical DTW and independent classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						time series analysis; face and gesture recognition; 3D/stereo scene analysis; statistical dynamic programming; Markov processes; classifier design and evaluation; real-time systems		To recognize speech, handwriting, or sign language, many hybrid approaches have been proposed that combine Dynamic Time Warping (DTW) or Hidden Markov Models (HMMs) with discriminative classifiers. However, all methods rely directly on the likelihood models of DTW/HMM. We hypothesize that time warping and classification should be separated because of conflicting likelihood modeling demands. To overcome these restrictions, we propose using Statistical DTW (SDTW) only for time warping, while classifying the warped features with a different method. Two novel statistical classifiers are proposed-Combined Discriminative Feature Detectors (CDFDs) and Quadratic Classification on DF Fisher Mapping (Q-DFFM)-both using a selection of discriminative features (DFs), and are shown to outperform HMM and SDTW. However, we have found that combining likelihoods of multiple models in a second classification stage degrades performance of the proposed classifiers, while improving performance with HMM and SDTW. A proof-of-concept experiment, combining DFFM mappings of multiple SDTW models with SDTW likelihoods, shows that, also for model-combining, hybrid classification can provide significant improvement over SDTW. Although recognition is mainly based on 3D hand motion features, these results can be expected to generalize to recognition with more detailed measurements such as hand/body pose and facial expression.	[Lichtenauer, Jeroen F.; Hendriks, Emile A.; Reinders, Marcel J. T.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Informat & Commun Theory Grp, NL-2628 CD Delft, Netherlands	Delft University of Technology	Lichtenauer, JF (corresponding author), Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Informat & Commun Theory Grp, Mekelweg 4, NL-2628 CD Delft, Netherlands.	j.lichtenauer@imperial.ac.uk; E.A.Hendriks@TUDelft.nl; M.J.T.Reinders@TUDelft.nl			VSB	VSB	This work was done in collaboration with the NSDSK and supported by the VSB fund.	ALON J, 2005, SIMULTANEOUS LOCALIZ, V2, P254; Aran O, 2006, LECT NOTES COMPUT SC, V4105, P159; Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883; Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308; Corradini A, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P82, DOI 10.1109/RATFG.2001.938914; CORRADINI A, 2000, P IEEE INT C NEUR NE, V4, P133; Di Martino J., 1985, NEW SYSTEMS ARCHITEC, P405; DING L, 2007, P IEEE C ADV VID SIG, P447; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GAVRILA DM, 1995, P INT WORKSH AUT FAC, P272; Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717; LICHTENAUER J, 2008, IEEE T PATTERN ANA S, V30; MATSUURA Y, 1994, P IEEE INT WORKSH NE, P329; MORGAN N, 1990, P ICASSP, P413; MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x; Sakoe H., 1971, P 7 INT C AC, V3, P65; Starner T., 1995, THESIS MIT; Stokoe, 1960, SIGN LANGUAGE STRUCT, V8; Stokoe WC, 2005, J DEAF STUD DEAF EDU, V10, P3, DOI 10.1093/deafed/eni001; TENHOLT G, 2006, THEORETICAL ISSUES S, V9; VONAGRIS U, 2006, P IEEE C COMP VIS PA; WHITE G, 1976, P INT C AC SPEECH SI, P183; Yang G, 2007, J INORG MATER, V22, P1; YANG S, 2006, P IEEE C COMP VIS PA, P766; YE JJ, 2004, P 3 INT C IM GRAPH I, P377; [No title captured]	26	123	129	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					2040	2046		10.1109/TPAMI.2008.123	http://dx.doi.org/10.1109/TPAMI.2008.123			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787250	Green Submitted			2022-12-18	WOS:000259110000015
J	Lv, FJ; Zhao, T; Nevatia, R				Lv, Fengjun; Zhao, Tao; Nevatia, Ramakant			Camera calibration from video of a walking human	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; self-calibration; vanishing point; vanishing line; human tracking		A self-calibration method to estimate a camera's intrinsic and extrinsic parameters from vertical line segments of the same height is presented. An algorithm to obtain the needed line segments by detecting the head and feet positions of a walking human in his leg-crossing phases is described. Experimental results show that the method is accurate and robust with respect to various viewing angles and subjects.	Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA; Sarnoff Corp, Princeton, NJ 08543 USA	University of Southern California; Sarnoff Corporation	Lv, FJ (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.	flv@usc.edu; tzhao@sarnoff.com; nevatia@usc.edu						Bose B, 2003, P JOINT IEEE INT WOR, P94; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; CIPOLLA R, 1999, P BRIT MACH VIS C, V2, P382; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; Deutscher J, 2002, LECT NOTES COMPUT SC, V2353, P175; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Liebowitz D., 1999, P EUROGRAPHICS, V18, P39; NAKATSUJI A, 2004, P AS C COMP VIS, V1, P1; STAUFFER C, 2003, P JOINT IEEE INT WOR, P1; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; ZHANG Z, 2002, P EUR C COMP VIS, V4, P161; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhao T, 2004, PROC CVPR IEEE, P406; Zhao T, 2001, PROC CVPR IEEE, P194	16	123	138	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1513	1518		10.1109/TPAMI.2006.178	http://dx.doi.org/10.1109/TPAMI.2006.178			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929736				2022-12-18	WOS:000238950800013
J	Song, Y; Goncalves, L; Perona, P				Song, Y; Goncalves, L; Perona, P			Unsupervised learning of human motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						unsupervised learning; human motion; decomposable triangulated graph; probabilistic models; greedy search; EM algorithm; mixture models	BIOLOGICAL MOTION; PERCEPTION; MODEL	An unsupervised learning algorithm that can obtain a probabilistic model of an object composed of a collection of parts (a moving human body in our examples) automatically from unlabeled training data is presented. The training data include both useful "foreground" features as well as features that arise from irrelevant background clutter-the correspondence between parts and detected features is unknown. The joint probability density function of the parts is represented by a mixture of decomposable triangulated graphs which allow for fast detection. To learn the model structure as well as model parameters, an EM-like algorithm is developed where the labeling of the data (part assignments) is treated as hidden variables. The unsupervised learning technique is not limited to decomposable triangulated graphs. The efficiency and effectiveness of our algorithm is demonstrated by applying it to generate models of human motion automatically from unlabeled image sequences, and testing the learned models on a variety of sequences.	Fujifilm Software Inc, San Jose, CA 95110 USA; Idealab, Pasadena, CA 91103 USA; CALTECH, Dept Elect Engn, Pasadena, CA 91125 USA	Fujifilm Corporation; California Institute of Technology	Song, Y (corresponding author), Fujifilm Software Inc, 1740 Technol Dr,Suite 490, San Jose, CA 95110 USA.	ysong@fujifilmsoft.com; luis.goncalves@idealab.com; perona@caltech.edu						Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; Bishop, 1995, NEURAL NETWORKS PATT; BLAKE A, 1994, P ACM SIGGRAPH, P185; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Chickering D. M., 1994, MSRTR9417; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Friedman N., 2000, P 16 C UNC ART INT; Friedman N., 1998, LEARNING BAYESIAN NE; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861; Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952; Ioffe S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P690, DOI 10.1109/ICCV.2001.937589; Jensen F.V., 1996, INTRO BAYESIAN NETWO; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Jordan M. I., 1999, LEARNING GRAPHICAL M; Meila M, 2001, J MACH LEARN RES, V1, P1, DOI 10.1162/153244301753344605; REHG JM, 1994, P EUR C COMP VIS, V2, P35; Rohr K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P8, DOI 10.1109/CVPR.1993.341008; Song Y, 2001, COMPUT VIS IMAGE UND, V81, P303, DOI 10.1006/cviu.2000.0890; Srebro N., 2001, P 17 C UNC ART INT U, P504; Tomasi C, 1991, CMUCS91132; Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758; Weber M, 2000, THESIS CALTECH; WEBER M, 2000, P ECCV, V1, P18; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	35	123	128	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					814	827		10.1109/TPAMI.2003.1206511	http://dx.doi.org/10.1109/TPAMI.2003.1206511			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN		Green Accepted			2022-12-18	WOS:000183667300004
J	Udupa, JK; Saha, PK; Lotufo, RA				Udupa, JK; Saha, PK; Lotufo, RA			Relative fuzzy connectedness and object definition: Theory, algorithms, and applications in image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fuzzy connectedness; image segmentation; object definition; digital topology	ARTERY-VEIN SEPARATION; MULTIPLE-SCLEROSIS; QUANTIFICATION; EXTRACTION; EDGE; MRA	The notion of fuzzy connectedness captures the idea of "hanging-togetherness" of image elements in an object by assigning a strength of connectedness to every possible path between every possible pair of image elements. This concept leads to powerful image segmentation algorithms based on dynamic programming whose effectiveness has been demonstrated on 1,000s of images in a variety of applications. In the previous framework, a fuzzy connected object is defined with a threshold on the strength of connectedness. In this paper, we introduce the notion of relative connectedness that overcomes the need for a threshold and that leads to more effective segmentations. The central idea is that an object gets defined in an image because of the presence of other co-objects. Each object is initialized by a seed element. An image element c is considered to belong to that object with respect to whose reference image element c has the highest strength of connectedness. In this fashion, objects compete among each other utilizing fuzzy connectedness to grab membership of image elements. We present a theoretical and algorithmic framework for defining objects via relative connectedness and demonstrate utilizing the theory that the objects defined are independent of reference elements chosen as long as they are not in the fuzzy boundary between objects. An iterative strategy is also introduced wherein the strongest relative connected core parts are first defined and iteratively relaxed to conservatively capture the more fuzzy parts subsequently. Examples from medical imaging are presented to illustrate visually the effectiveness of relative fuzzy connectedness. A quantitative mathematical phantom study involving 160 images is conducted to demonstrate objectively the effectiveness of relative fuzzy connectedness.	Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA; Univ Estadual Campinas, Dept Engn Compuacao & Automacao Ind, UNICAMP, Fac Engn Eletr, BR-13081970 Campinas, SP, Brazil	University of Pennsylvania; Universidade Estadual de Campinas	Udupa, JK (corresponding author), Univ Penn, Dept Radiol, Med Image Proc Grp, 4th Floor,Blockley Hall,418 Serv Dr, Philadelphia, PA 19104 USA.	jay@mipg.upenn.edu; saha@mipg.upenn.edu; lotufo@dca.fee.unimp.br	Lotufo, Roberto/C-1496-2009; Saha, Punam K/F-8833-2011	Lotufo, Roberto/0000-0002-5652-0852; Saha, Punam/0000-0003-1576-118X				BLOCH I, 1993, PATTERN RECOGN LETT, V14, P483, DOI 10.1016/0167-8655(93)90028-C; Bluemke D., 1999, ISMRM P, V2, P1237; CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778; CAPPELLETTI JD, 1989, COMPUT VISION GRAPH, V48, P80, DOI 10.1016/0734-189X(89)90105-9; CHRISTENSEN GE, 1994, PHYS MED BIOL, V39, P609, DOI 10.1088/0031-9155/39/3/022; DELLEPIANE S, 1995, PATTERN RECOGN LETT, V16, P313, DOI 10.1016/0167-8655(94)00088-K; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; GEE JC, 1993, J COMPUT ASSIST TOMO, V17, P225, DOI 10.1097/00004728-199303000-00011; GONG LG, 1995, IEEE T PATTERN ANAL, V17, P997, DOI 10.1109/34.464563; HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057; Herman GT, 2001, IEEE T PATTERN ANAL, V23, P460, DOI 10.1109/34.922705; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P222, DOI 10.1109/TPAMI.1984.4767505; KAMBER M, 1995, IEEE T MED IMAGING, V14, P442, DOI 10.1109/42.414608; Kaufmann A., 1975, INTRO THEORY FUZZY S; Lei TH, 2002, ACAD RADIOL, V9, pS127, DOI 10.1016/S1076-6332(03)80417-8; Lei TH, 2001, IEEE T MED IMAGING, V20, P689, DOI 10.1109/42.938238; Liang P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P193, DOI 10.1109/ICCV.1998.710718; Miki Y, 1999, RADIOLOGY, V210, P769, DOI 10.1148/radiology.210.3.r99mr44769; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563; RAYA SP, 1990, IEEE T MED IMAGING, V9, P327, DOI 10.1109/42.57771; Rice BL, 2000, INT J IMAG SYST TECH, V11, P62, DOI 10.1002/(SICI)1098-1098(2000)11:1<62::AID-IMA7>3.0.CO;2-6; ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Saha PK, 2001, IEEE T MED IMAGING, V20, P792, DOI 10.1109/42.938247; Saha PK, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P28, DOI 10.1109/MMBIA.2000.852357; Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813; SAHA PK, 2000, TRMIPG269 U PENN MED; Samarasekera S, 1997, J COMPUT ASSIST TOMO, V21, P145, DOI 10.1097/00004728-199701000-00028; Singh M, 1993, FDN MED IMAGING; SOLTANIANZADEH H, 1992, IEEE T MED IMAGING, V11, P302, DOI 10.1109/42.158934; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; Udupa JK, 1997, J CRANIOFAC SURG, V8, P333, DOI 10.1097/00001665-199708050-00002; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; UDUPA JK, 1993, IEEE COMPUT GRAPH, V13, P58, DOI 10.1109/38.252558; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; UDUPA JK, 1994, P SOC PHOTO-OPT INS, V2164, P58, DOI 10.1117/12.174042; Udupa JK, 1999, P SOC PHOTO-OPT INS, V3661, P236, DOI 10.1117/12.348578; ZHUGE Y, 2002, P INT SOC OPT ENG SP	42	123	144	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1485	1500		10.1109/TPAMI.2002.1046162	http://dx.doi.org/10.1109/TPAMI.2002.1046162			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY					2022-12-18	WOS:000178846400006
J	Noronha, S; Nevatia, R				Noronha, S; Nevatia, R			Detection and modeling of buildings from multiple aerial images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						aerial image analysis; building detection; building modeling; perceptual grouping; multiple image analysis	RECONSTRUCTION; 3D	Automatic detection and description of cultural features, such as buildings, from aerial images is becoming increasingly important for a number of applications. This task also offers an excellent domain for studying the general problems of scene segmentation, 3D inference, and shape description under highly challenging conditions. We describe a system that detects and constructs 3D models for rectilinear buildings with either fiat or symmetric gable roofs from multiple aerial images; the multiple images, however, need not be stereo pairs (i.e., they may be acquired at different times). Hypotheses for rectangular roof components are generated by grouping lines in the images hierarchically; the hypotheses are verified by searching for presence of predicted walls and shadows. The hypothesis generation process combines the tasks of hierarchical grouping with matching at successive stages. Overlap and containment relations between 3D structures are analyzed to resolve conflicts. This system has been tested on a large number of real examples with good results. some of which are included in the paper along with their evaluations.	eLance Inc, Sunnyvale, CA 94086 USA; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	University of Southern California	Noronha, S (corresponding author), eLance Inc, 820A Kifer Rd, Sunnyvale, CA 94086 USA.	nevatia@rodrigo.usc.edu						Baltsavias E., 1995, P AUT EXTR MAN MAD O, P199; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Collins RT, 1998, COMPUT VIS IMAGE UND, V72, P143, DOI 10.1006/cviu.1998.0729; FAUGERAS O, 1995, P AUTOMATIC EXTRACTI, P145; Fischer A, 1998, COMPUT VIS IMAGE UND, V72, P185, DOI 10.1006/cviu.1998.0721; FUA P, 1996, P 18 C INT SOC PHOT, P222; GRUN A, 1998, SPECIAL ISSUE AUTOMA, V72; HAALA N, 1995, P ASC WORKSH 95 AUT, P211; Henricsson O, 1998, COMPUT VIS IMAGE UND, V72, P163, DOI 10.1006/cviu.1998.0718; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; Huertas A., 1999, Proceedings of the Second International Conference on Information Fusion. FUSION '99, P680; Huertas A, 2000, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2000.854784; HUERTAS A, 1988, COMPUT VISION GRAPH, V41, P131, DOI 10.1016/0734-189X(88)90016-3; IRVIN RB, 1989, IEEE T SYST MAN CYB, V19, P1564, DOI [10.1109/21.44071, 10.1117/12.952691]; Kim ZW, 1999, COMPUT VIS IMAGE UND, V76, P278, DOI 10.1006/cviu.1999.0803; Lin C, 1998, COMPUT VIS IMAGE UND, V72, P101, DOI 10.1006/cviu.1998.0724; MCGLONE JC, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P54, DOI 10.1109/CVPR.1994.323810; McKeown D.M., 1998, P DARPA IMAGE UNDERS, P517; NEVATIA R, 1999, BULLETIN, V153, P15; Paparoditis N, 1998, COMPUT VIS IMAGE UND, V72, P122, DOI 10.1006/cviu.1998.0722; Roux M., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P46, DOI 10.1109/CVPR.1994.323809; SHUFELT JA, 1993, CVGIP-IMAG UNDERSTAN, V57, P307, DOI 10.1006/ciun.1993.1021; WEIDNER U, 1996, P 18 ISPRS C VIENN A, P924; [No title captured]; [No title captured]	25	123	166	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					501	518		10.1109/34.922708	http://dx.doi.org/10.1109/34.922708			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA					2022-12-18	WOS:000168641000006
J	Shufelt, JA				Shufelt, JA			Performance evaluation and analysis of monocular building extraction from aerial imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						monocular building extraction; performance evaluation; object detection; feature delineation; photogrammetry; computer vision; metrics	GEOMETRIC CONSTRAINTS; RECONSTRUCTION; SHADOWS; SYSTEM	Research in monocular building extraction from aerial imagery has neglected performance evaluation in three areas: unbiased metrics for quantifying detection and delineation performance, an evaluation methodology for applying these metrics to a representative body of test imagery, and an approach for understanding the impact of image and scene content on building extraction algorithms. This paper addresses these areas with an end-to-end performance evaluation of four existing monocular building extraction systems, using image space and object space-based metrics on 83 test images of 18 sites. This analysis is supplemented by an examination of the effects of image obliquity and object complexity on system performance, as well as a case study on the effects of edge fragmentation. This widely applicable performance evaluation approach highlights the consequences of various traditional assumptions about camera geometry, image content, and scene structure, and demonstrates the utility of rigorous photogrammetric object space modeling and primitive-based representations for building extraction.	Carnegie Mellon Univ, Dept Comp Sci, Digital Mapping Lab, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Shufelt, JA (corresponding author), Carnegie Mellon Univ, Dept Comp Sci, Digital Mapping Lab, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	js@maps.cs.cmu.edu						BRAUN C, 1994, P SOC PHOTO-OPT INS, V2357, P85; BRONIELSEN M, 1992, THESIS TU DENMARK; COLLINS RT, 1996, P ARPA IM UND WORKSH, V1, P305; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; Fischer A, 1997, P WORKSH SEM MOD ACQ; Fua P., 1991, Machine Vision and Applications, V4, P59, DOI 10.1007/BF01257823; FUA P, 1996, P ARPA IM UND WORKSH, V1, P409; Haala N, 1997, P SOC PHOTO-OPT INS, V3072, P212, DOI 10.1117/12.281041; HAALA N, 1997, P AUT EXTR MAN MAD O, V2, P213; HANSON AJ, 1987, P IM UND WORKSH FEB, P475; HARWOOD D, 1987, P DARPA IM UND WORKS, P507; HENRICSSON O, 1996, ANAL IMAGE STRUCTURE; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; HEUEL S, 1996, P ARPA IM UND WORKSH, V1, P429; Hsieh Y, 1996, PROC CVPR IEEE, P499, DOI 10.1109/CVPR.1996.517118; HSIEH Y, 1996, P ARPA IM UND WORKSH, V1, P435; HUERTAS A, 1988, COMPUT VISION GRAPH, V41, P131, DOI 10.1016/0734-189X(88)90016-3; IRVIN RB, 1989, IEEE T SYST MAN CYB, V19, P1564, DOI [10.1109/21.44071, 10.1117/12.952691]; Jaynes CO, 1997, PROC CVPR IEEE, P380, DOI 10.1109/CVPR.1997.609353; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LIN C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P62, DOI 10.1109/CVPR.1994.323811; LIN C, 1996, P ARPA IM UND WORKSH, P461; LIOW YT, 1990, COMPUT VISION GRAPH, V49, P242, DOI 10.1016/0734-189X(90)90139-M; MCGLONE C, 1995, P SOC PHOTO-OPT INS, V2486, P25; MCGLONE JC, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P54, DOI 10.1109/CVPR.1994.323810; McKeeown D. M.  Jr., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P205; McKeown D. M., 1990, NATO ASI SERIES F, V65, P149; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Nagao M., 1980, STRUCTURAL ANAL COMP; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NICOLIN B, 1987, IEEE T GEOSCI REMOTE, V25, P317, DOI 10.1109/TGRS.1987.289803; Roux M., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P46, DOI 10.1109/CVPR.1994.323809; Shufelt J. A., 1996, INT ARCH PHOTOGRA B6, V31, P74; SHUFELT JA, 1993, CVGIP-IMAG UNDERSTAN, V57, P307, DOI 10.1006/ciun.1993.1021; Shufelt JA, 1997, P SOC PHOTO-OPT INS, V3072, P231, DOI 10.1117/12.281044; SHUFELT JA, 1996, CMUCS96164; SHUFELT JA, 1996, P ARPA IM UND WORKSH, P1113; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; TAVAKOLI M, 1982, IEEE T SYST MAN CYB, V12, P84; Venkateswar V., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P204, DOI 10.1109/ICPR.1990.118092; ZLOTNICK A, 1988, CMUCS88199; [No title captured]; [No title captured]	43	123	141	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					311	326		10.1109/34.761262	http://dx.doi.org/10.1109/34.761262			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL					2022-12-18	WOS:000079781200003
J	Gunn, SR; Nixon, MS				Gunn, SR; Nixon, MS			Robust snake implementation; A dual active contour	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						snakes; active contours; regularization; feature extraction; local shape	DEFORMABLE CONTOURS; MODELS; BALLOONS; TRACKING	A conventional active contour formulation suffers difficulty in appropriate choice of an initial contour and values of parameters. Recent approaches have aimed to resolve these problems but can compromise other performance aspects. To relieve the problem in initialization, we use a dual active contour, which is combined with a local shape model to improve the parameterization. One contour expands from inside the target feature, the other contracts from the outside. The two contours are interlinked to provide a balanced technique with an ability to reject ''weak'' local energy minima.			Gunn, SR (corresponding author), UNIV SOUTHAMPTON, DEPT ELECT & COMP SCI, ISIS RES GRP, SOUTHAMPTON SO17 1BJ, HANTS, ENGLAND.		Nixon, Mark S/F-7406-2014	Nixon, Mark/0000-0002-9174-5934				BERGER MO, 1991, P 6 INT C IM AN PROC, V2, P47; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Fua P., 1990, Machine Vision and Applications, V3, P45, DOI 10.1007/BF01211451; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; GUNN SR, 1994, P BRIT MACH VIS C YO, P305; GUNN SR, 1995, LECT NOTES COMPUTER, V670, P600; HORN BK, 1972, T PATTERN ANAL MACHI, V21, P269; IVINS J, 1995, IMAGE VISION COMPUT, V13, P431, DOI 10.1016/0262-8856(95)99730-O; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LAI KF, 1995, IEEE T PATTERN ANAL, V17, P1084, DOI 10.1109/34.473235; MENET S, 1990, IEEE INT C SYST MAN, V212, P194; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; ROUGON N, 1991, SPIE CURVES SURFACES, V1610, P336; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; WANG Y, 1994, IEEE T IMAGE PROCESS, V3, P610, DOI 10.1109/83.334982; XU G, 1994, PATTERN RECOGN, V27, P879, DOI 10.1016/0031-3203(94)90153-8; Zucker S. W., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P568, DOI 10.1109/CCV.1988.590037	21	123	135	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					63	68		10.1109/34.566812	http://dx.doi.org/10.1109/34.566812			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800007
J	Jain, AK; Karu, K				Jain, AK; Karu, K			Learning texture discrimination masks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture; segmentation; learning; neural networks; feature extraction	SEGMENTATION; FILTERS	A neural network texture classification method is proposed in this paper. The approach is introduced as a generalization of the multichannel filtering method. Instead of using a general filter bank, a neural network is trained to find a minimal set of specific fitters, so that both the feature extraction and classification tasks are performed by the same unified network. We compute the error rates for different network parameters, and show the convergence speed of training and node pruning algorithms. The proposed method is demonstrated in several texture classification experiments. It is successfully applied in the tasks of locating barcodes in the images and segmenting a printed page into text, graphics, and background. Compared with the traditional multichannel filtering method, the neural network approach allows one to perform the same texture classification or segmentation task more efficiently. Extensions of the method, as well as its limitations, are discussed in the paper.			Jain, AK (corresponding author), MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA.							BENKE KK, 1987, AUST COMPUT J, V19, P134; BOVIK AC, 1991, IEEE T SIGNAL PROCES, V39, P2025, DOI 10.1109/78.134435; CHANG T, 1992, USC SIPI 198; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DUNN DF, 1992, P SOC PHOTO-OPT INS, V1826, P51, DOI 10.1117/12.131586; FARROKHNIA F, 1990, THESIS MICHIGAN STAT; Faugeras O. D., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P549; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Jain A. K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P41, DOI 10.1109/ICDAR.1993.395786; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Jain A.K., 1988, ALGORITHMS CLUSTERIN; JAIN AK, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P4374, DOI 10.1109/ICNN.1994.374972; JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI 10.1016/0031-3203(91)90143-S; JAIN AK, 1992, P IEEE INT JOINT C N, V3, P335; JAIN AK, UNPUB PAGE LAYOUT SE; JAIN AK, 1994, P 12 INT C PATT REC, V1, P454; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; Laws KI., 1980, THESIS U SO CALIFORN; LECUN Y, 1989, IEEE COMM MAGAZI NOV; MAO J, 1993, P JOINT C NEUR NETW; MAO J, 1994, P 12 INT C PATT REC, V2, P622; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; NIBLACK W, 1993, QBIC PROJECT QUERYIN; Oja E., 1989, International Journal of Neural Systems, V1, P61, DOI 10.1142/S0129065789000475; OJA E, 1994, COMPUTATIONAL INTELL, P13; POMERLEAU DA, 1993, NEURAL NETWORK PERCE; RANDEN T, IN PRESS OPTICAL ENG; Rumelhart DE, 1985, TECHNICAL REPORT, DOI 10.1016/b978-1-4832-1446-7.50035-2; Tuceryan M., 1993, HDB PATTERN RECOGNIT, P235, DOI DOI 10.1142/9789814343138_0010; VANGOOL L, 1985, COMPUT VISION GRAPH, V29, P336, DOI 10.1016/0734-189X(85)90130-6	33	123	133	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					195	205		10.1109/34.481543	http://dx.doi.org/10.1109/34.481543			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900009
J	CHEN, MY; KUNDU, A; ZHOU, J				CHEN, MY; KUNDU, A; ZHOU, J			OFF-LINE HANDWRITTEN WORLD RECOGNITION USING A HIDDEN MARKOV MODEL TYPE STOCHASTIC NETWORK	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						UNCONSTRAINED HANDWRITTEN WORD RECOGNITION; MATHEMATICAL MORPHOLOGY; WORD SEGMENTATION STATISTICS; FEATURE SELECTION; VECTOR QUANTIZATION; K-NEAREST-NEIGHBOR CLASSIFICATION; SINGLE CONTEXTUAL HIDDEN MARKOV MODEL; MODIFIED VITERBI ALGORITHM; HYPOTHESIS GENERATION	CONTINUOUS SPEECH RECOGNITION; CHARACTER-RECOGNITION; IMAGE-ANALYSIS	Because of large variations involved in handwritten words, the recognition problem is very difficult. Hidden Markov Models (HMM) have been widely and successfully used in speech processing and recognition. Recently, HMM has also been used with some success in recognizing handwritten words with presegmented letters. In this paper, a complete scheme for totally unconstrained handwritten word recognition based on a single contextual hidden Markov model type stochastic network is presented. Our scheme includes a morphology and heuristics based segmentation algorithm, a training algorithm that can adapt itself with the changing dictionary, and a modified Viterbi algorithm which searches for the (l + 1)th globally best path based on the previous l best paths. Detailed experiments are carried out and successful recognition results are reported.			CHEN, MY (corresponding author), SUNY BUFFALO, CTR EXCELLENCE DOCUMENT ANAL & RECOGNIT, BUFFALO, NY 14260 USA.							[Anonymous], AUTOMATIC GENERATION; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAHL LR, 1986, P IEEE INT C AC SPEE, P49; BENGIO Y, 1992, IEEE T NEURAL NETWOR, V3, P252, DOI 10.1109/72.125866; BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; Chen M.-Y., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P669, DOI 10.1109/CVPR.1992.223205; CHEN YS, 1985, P NATIONAL COMPUT S; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; DUTTA AK, 1974, IEEE T COMPUT, VC 23, P536, DOI 10.1109/T-C.1974.223978; EPHRAIM Y, 1989, IEEE T INFORM THEORY, V35, P1001, DOI 10.1109/18.42209; FARAG RFH, 1979, IEEE T COMPUT, V28, P172, DOI 10.1109/TC.1979.1675310; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; He Y., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P153, DOI 10.1109/ICASSP.1992.226253; KUNDU A, 1989, PATTERN RECOGN, V22, P283, DOI 10.1016/0031-3203(89)90076-9; Kundu A., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P457, DOI 10.1109/CVPR.1988.196275; LJOLJE A, 1991, IEEE T SIGNAL PROCES, V39, P29, DOI 10.1109/78.80762; MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3; Nag R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P2071; Pavlidis T., 1989, From Pixels to Features. Proceedings of a Workshop, P219; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; SCHWARTZ R, 1990, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1990.115542; Serra J, 1982, IMAGE ANAL MATH MORP; SESHADRI N, 1989, P IEEE GLOBAL TELECO, P1534; Silverman H., 1990, IEEE ASSP MAGAZINE, V7, P6; Simon J.-C., 1989, From Pixels to Features. Proceedings of a Workshop, P229; SRIHARI S, 1984, COMPUTER TEXT RECOGN; Tappert C. C., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1004; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; ULLMANN JR, 1986, APLICATIONS PATTERN, pCH9; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	39	123	133	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					481	496						16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100004
J	CHEN, JL; KUNDU, A				CHEN, JL; KUNDU, A			ROTATION AND GRAY-SCALE TRANSFORM INVARIANT TEXTURE IDENTIFICATION USING WAVELET DECOMPOSITION AND HIDDEN MARKOV MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BRODATZS TEXTURE; WAVELET DECOMPOSITION; QUADRATURE MIRROR FILTER BANK; HIDDEN MARKOV MODEL; SEGMENTAL K-MEANS ALGORITHM; ROTATED TEXTURE; GRAY SCALE TRANSFORM	RANDOM-FIELDS; CLASSIFICATION; SEGMENTATION; IMAGES; RECOGNITION; FILTERS	In this correspondence, we have presented a rotation and gray scale transform invariant texture recognition scheme using the combination of quadrature mirror filter (QMF) bank and hidden Markov model (HMM). In the first stage, the QMF bank is used as the wavelet transform to decompose the texture image into subbands. The gray scale transform invariant features derived from the statistics based on first-order distribution of gray levels are then extracted from each subband image. In the second stage, the sequence of subbands is modeled as a hidden Markov model (HMM), and one HMM is designed for each class of textures. The HMM is used to exploit the dependence among these subbands, and is able to capture the trend or changes caused by rotation. During recognition, the unknown texture is matched against all the models. The best matched model identifies the texture class. Up to 93.33% classification accuracy is reported.	NCCOSC,RDT&E,SAN DIEGO,CA 92152	Naval Information Warfare Center Pacific	CHEN, JL (corresponding author), CHUNG HUA POLYTECH INST,FAC COMP SCI,HSINCHU,TAIWAN.							BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1965, TEXTURES PHOTOGRAPHI; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Farrokhnia F., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P364, DOI 10.1109/CVPR.1991.139717; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HE Y, 1991, IEEE T PATTERN ANAL, V13, P1172, DOI 10.1109/34.103276; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; JAIN AK, 1989, FUNDAMENTALS DIGITAL, P344; JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; KUNDU A, 1989, PATTERN RECOGN, V22, P283, DOI 10.1016/0031-3203(89)90076-9; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376; LJOLJE A, 1991, IEEE T SIGNAL PROCES, V39, P29, DOI 10.1109/78.80762; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; NACHMIAS J, 1975, VISION RES, V15, P217, DOI 10.1016/0042-6989(75)90210-2; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466; Vaidyanathan P. P., 1987, IEEE ASSP Magazine, V4, P4, DOI 10.1109/MASSP.1987.1165589; VETTERLI M, 1984, SIGNAL PROCESS, V6, P97, DOI 10.1016/0165-1684(84)90012-4; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; WOODS JW, 1986, IEEE T ACOUST SPEECH, V34, P1278, DOI 10.1109/TASSP.1986.1164962	29	123	128	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					208	214		10.1109/34.273730	http://dx.doi.org/10.1109/34.273730			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100008
J	OHYA, J; SHIO, A; AKAMATSU, S				OHYA, J; SHIO, A; AKAMATSU, S			RECOGNIZING CHARACTERS IN SCENE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ADAPTIVE THRESHOLDING; CHARACTER PATTERN EXTRACTION; CHARACTER RECOGNITION; IMAGE PROCESSING; IMAGE SEGMENTATION; PATTERN RECOGNITION; RELAXATION; SCENE IMAGES	SEGMENTATION	An effective algorithm for character recognition in scene images is studied. Scene images are segmented into regions by an image segmentation method based on adaptive thresholding. Character candidate regions are detected by observing gray-level differences between adjacent regions. To ensure extraction of multisegment characters as well as single-segment characters, character pattern candidates are obtained by associating the detected regions according to their positions and gray levels. A character recognition process selects patterns with high similarities by calculating the similarities between character pattern candidates and the standard patterns in a dictionary and then comparing the similarities to the thresholds. A relaxational approach to determine character patterns updates the similarities by evaluating the interactions between categories of patterns, and finally character patterns and their recognition results are obtained. Highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting.	NTT HUMAN INTERFACE LABS,YOKOSUKA 23803,JAPAN; ATR HUMAN INFORMAT PROC LABS,KYOTO 61902,JAPAN	Nippon Telegraph & Telephone Corporation	OHYA, J (corresponding author), ATR COMMUN SYST RES LABS,SEIKA CHO,KYOTO 61902,JAPAN.							CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5; FUNAKOSHI K, 1987, IEICE JAPAN, V1503; HOSHINO H, 1983, NAT CONVENTION REC, V1152; HOWINGTON LC, 1989, ADV IMAGING, V4, P46; Kawatani T., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P538; MARDIA KV, 1988, IEEE T PATTERN ANAL, V10, P919, DOI 10.1109/34.9113; Masuda I., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P550; Nakamura Y., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), P364; Ohya J., 1988, Transactions of the Institute of Electronics, Information and Communication Engineers D, VJ71D, P1037; Ohya J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P424, DOI 10.1109/CVPR.1988.196270; OHYA J, 1986, NAT CONVENTION REC, V13; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PEREZ A, 1987, IEEE T PATTERN ANAL, V9, P742, DOI 10.1109/TPAMI.1987.4767981; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Takatoo M., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), P76; TAXT T, 1989, IEEE T PATTERN ANAL, V11, P1322, DOI 10.1109/34.41371; UMEDA M, 1982, 6TH P INT C PATT REC, P793; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7	18	123	142	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					214	220		10.1109/34.273729	http://dx.doi.org/10.1109/34.273729			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100009
J	GOSHTASBY, A; GAGE, SH; BARTHOLIC, JF				GOSHTASBY, A; GAGE, SH; BARTHOLIC, JF			A 2-STAGE CROSS-CORRELATION APPROACH TO TEMPLATE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48823; MICHIGAN STATE UNIV,DEPT ENTOMOL,E LANSING,MI 48823; MICHIGAN STATE UNIV,DEPT RESOURCE DEV,E LANSING,MI 48823	Michigan State University; Michigan State University; Michigan State University								Anuta PE., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI [10.1109/tge.1970.271435, DOI 10.1109/TGE.1970.271435]; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; BECHHOFER RE, 1954, ANN MATH STAT, V25, P16, DOI 10.1214/aoms/1177728845; FISHER RA, 1948, STATISTICAL METHODS, P175; GUPTA SS, 1965, TECHNOMETRICS, V7, P225, DOI 10.2307/1266672; ROSENFELD A, 1977, IEEE T SYSTEMS M FEB, P104; SVEDLOW M, 1976, S MACHINE PROCESSING; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; Yagi, 1973, COMPUT VISION GRAPH, V2, P131	9	123	134	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					374	378		10.1109/TPAMI.1984.4767532	http://dx.doi.org/10.1109/TPAMI.1984.4767532			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869206				2022-12-18	WOS:A1984SR54200015
J	Wang, P; Wu, Q; Shen, CH; Dick, A; van den Hengel, A				Wang, Peng; Wu, Qi; Shen, Chunhua; Dick, Anthony; van den Hengel, Anton			FVQA: Fact-Based Visual Question Answering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual question answering; knowledge base; recurrent neural networks	DYNAMIC MEMORY NETWORKS; WEB; ASK	Visual Question Answering (VQA) has attracted much attention in both computer vision and natural language processing communities, not least because it offers insight into the relationships between two important sources of information. Current datasets, and the models built upon them, have focused on questions which are answerable by direct analysis of the question and image alone. The set of such questions that require no external information to answer is interesting, but very limited. It excludes questions which require common sense, or basic factual knowledge to answer, for example. Here we introduce FVQA (Fact-based VQA), a VQA dataset which requires, and supports, much deeper reasoning. FVQA primarily contains questions that require external information to answer. We thus extend a conventional visual question answering dataset, which contains image-question-answer triplets, through additional image-question-answer-supporting fact tuples. Each supporting-fact is represented as a structural triplet, such as <Cat, CapableOf, ClimbingTrees>. We evaluate several baseline models on the FVQA dataset, and describe a novel model which is capable of reasoning about an image on the basis of supporting-facts.	[Wang, Peng] Northwestern Polytech Univ, Xian 710072, Shaanxi, Peoples R China; [Wu, Qi; Shen, Chunhua; Dick, Anthony; van den Hengel, Anton] Univ Adelaide, Adelaide, SA 5005, Australia	Northwestern Polytechnical University; University of Adelaide	Shen, CH (corresponding author), Univ Adelaide, Adelaide, SA 5005, Australia.	peng.wang@nwpu.edu.cn; qi.wu01@adelaide.edu.au; chunhua.shen@adelaide.edu.au; anthony.dick@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au	Wu, Qi/ABD-6304-2021	Wu, Qi/0000-0003-3631-256X; Dick, Anthony/0000-0001-9049-7345; Shen, Chunhua/0000-0002-8648-8718; van den Hengel, Anton/0000-0003-3027-8364	ARC Future Fellowship [FT120100969]	ARC Future Fellowship(Australian Research Council)	This work was in part supported by ARC Future Fellowship FT120100969. The authors Peng Wang and Qi Wu contributed to this work equally. Part of the work was done when Peng Wang was with The University of Adelaide.	Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Banko M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2670; Berant Jonathan, 2013, P 2013 C EMP METH NA, P1533; Bordes A., 2014, P EMNLP, P615, DOI DOI 10.3115/V1/D14-1067; Bordes A., 2014, JOINT EUR C MACH LEA, P165, DOI DOI 10.1007/978-3-662-44848-9; Bordes A., 2015, P INT C LEARN REPR; Carlson A, 2010, AAAI CONF ARTIF INTE, P1306; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen Kan, 2015, ARXIV151105960; Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260; Erling O., 2012, IEEE DATA ENG B, V35, P3; Etzioni O, 2011, IJCAI, V2011, P3, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-012; Evans C., 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616]; Fader A., 2011, P C EMP METH NAT LAN, P1535, DOI DOI 10.1234/12345678; Fader A, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1156, DOI 10.1145/2623330.2623677; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001; JasonWeston Sumit, 2015, P INT C LEARN REPR I; Jiang A., 2015, ARXIV PREPRINT ARXIV; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krishnamurthy J, 2013, T ASSOC COMPUT LING, V1, P193, DOI DOI 10.1162/TACL_A_00220; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar A, 2016, PR MACH LEARN RES, V48; Kwiatkowski T., 2013, P 2013 C EMP METH NA, P1545; Liang P, 2013, COMPUT LINGUIST, V39, P389, DOI 10.1162/COLI_a_00127; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Lu JS, 2016, ADV NEUR IN, V29; Mahdisoltani F., 2015, P 7 BIENN C INN DAT; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Malinowski M., 2014, ABS14108027 CORR; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Mikolov T., 2015, ARXIV150205698, V1502, P05698; Mikolov T., 2013, ARXIV; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Narasimhan Karthik, 2016, ARXIV160307954; Prud'Hommeaux E., 2008, W3C RECOMMEND, V15; R.W. Group, 2014, RESOURCE DESCRIPTION; Reddy S., 2016, T ASSOC COMPUT LING, V4, P127; Ren M., 2015, ADV NEURAL INFORM PR, V28, P2953; Sukhbaatar S, 2015, ADV NEUR IN, V28; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Tandon N, 2014, AAAI CONF ARTIF INTE, P166; Unger C., 2012, P 21 INT C WORLD WID, P639, DOI DOI 10.1145/2187836.2187923; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang P., 2015, ABS151102570 CORR; Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29; Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500; WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133; Xiao C, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1341; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yao XC, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P956; Yih WT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1321; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zettlemoyer L. S., 2005, P INT JOINT C NAT LA, P976; Zettlemoyer Luke S., 2005, P 21 C UNC ART INT, P658, DOI DOI 10.3115/1690219.1690283; Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhu L., 2015, ARXIV151104670; Zhu Y., 2015, ABS150705670 CORR; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	77	122	126	1	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2413	2427		10.1109/TPAMI.2017.2754246	http://dx.doi.org/10.1109/TPAMI.2017.2754246			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28945588	Green Submitted			2022-12-18	WOS:000443875500010
J	Rahmani, H; Mian, A; Shah, M				Rahmani, Hossein; Mian, Ajmal; Shah, Mubarak			Learning a Deep Model for Human Action Recognition from Novel Viewpoints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cross-view; dense trajectories; view knowledge transfer	VIEW ACTION RECOGNITION; DENSE	Recognizing human actions from unknown and unseen (novel) views is a challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model (R-NKTM) for human action recognition from novel views. The proposed R-NKTM is a deep fully-connected neural network that transfers knowledge of human actions from any unknown view to a shared high-level virtual view by finding a set of non-linear transformations that connects the views. The R-NKTM is learned from 2D projections of dense trajectories of synthetic 3D human models fitted to real motion capture data and generalizes to real videos of human actions. The strength of our technique is that we learn a single R-NKTM for all actions and all viewpoints for knowledge transfer of any real human action video without the need for retraining or fine-tuning the model. Thus, R-NKTM can efficiently scale to incorporate new action classes. R-NKTM is learned with dummy labels and does not require knowledge of the camera viewpoint at any stage. Experiments on three benchmark cross-view human action datasets show that our method outperforms existing state-of-the-art.	[Rahmani, Hossein; Mian, Ajmal] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia; [Shah, Mubarak] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA	University of Western Australia; State University System of Florida; University of Central Florida	Rahmani, H (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	hossein.rahmani@uwa.edu.au; ajmal.mian@uwa.edu.au; shah@eecs.ucf.edu	Rahmani, Hossein/S-5134-2019	Rahmani, Hossein/0000-0003-1920-0371; Mian, Ajmal/0000-0002-5206-3842; Shah, Mubarak/0000-0001-6172-5572	ARC [DP160101458]	ARC(Australian Research Council)	This research was supported by the ARC Discovery grant DP160101458. We thank NVIDIA for the GPU donation.	Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Bengio Y., 2012, NEURAL NETWORK TRICK; Bengio Y., 2007, P 24 INT C MACH LEAR, P473, DOI DOI 10.1145/1273496.1273556; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491; Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13; Farhadi A, 2009, IEEE I CONF COMP VIS, P948, DOI 10.1109/ICCV.2009.5459350; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676; Glorot X., 2011, P 14 INT C ART INT S, P315; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gupta A., 2014, P BRIT MACH VIS C; Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hinton G., 2012, NEURAL NETWORK TRICK; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22; Katz S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276407; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lawrence S., 1996, CSTR3617 U MAR; Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822; Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Liu JG, 2008, PROC CVPR IEEE, P2971; Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273; Lv F., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383131; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Qadir O, 2011, IEEE C EVOL COMPUTAT, P208; Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167; Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389; Rahmani H, 2016, PATTERN RECOGN LETT, V72, P62, DOI 10.1016/j.patrec.2015.07.015; Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860; Rahmani H, 2014, INT C PATT RECOG, P3511, DOI 10.1109/ICPR.2014.604; Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312; Shahroudy A., 2017, TPAMI; Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295; Shahroudy A, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P73, DOI 10.1109/ISCCSP.2014.6877819; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Weinland D, 2007, IEEE I CONF COMP VIS, P170; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397; Xiang SM, 2008, PATTERN RECOGN, V41, P3653, DOI 10.1016/j.patcog.2008.05.016; Yilmaz A, 2005, PROC CVPR IEEE, P984; Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347; Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394	66	122	125	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					667	681		10.1109/TPAMI.2017.2691768	http://dx.doi.org/10.1109/TPAMI.2017.2691768			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28410098	Green Accepted, Green Submitted			2022-12-18	WOS:000424465900012
J	Liang, XD; Liu, S; Shen, XH; Yang, JC; Liu, LQ; Dong, J; Lin, L; Yan, SC				Liang, Xiaodan; Liu, Si; Shen, Xiaohui; Yang, Jianchao; Liu, Luoqi; Dong, Jian; Lin, Liang; Yan, Shuicheng			Deep Human Parsing with Active Template Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active template regression; CNN; human parsing; active template network; active shape network	PARTS	In this work, the human parsing task, namely decomposing a human image into semantic fashion/body regions, is formulated as an active template regression (ATR) problem, where the normalized mask of each fashion/body item is expressed as the linear combination of the learned mask templates, and then morphed to a more precise mask with the active shape parameters, including position, scale and visibility of each semantic region. The mask template coefficients and the active shape parameters together can generate the human parsing results, and are thus called the structure outputs for human parsing. The deep Convolutional Neural Network (CNN) is utilized to build the end-to-end relation between the input human image and the structure outputs for human parsing. More specifically, the structure outputs are predicted by two separate networks. The first CNN network is with max-pooling, and designed to predict the template coefficients for each label mask, while the second CNN network is without max-pooling to preserve sensitivity to label mask position and accurately predict the active shape parameters. For a new image, the structure outputs of the two networks are fused to generate the probability of each label for each pixel, and super-pixel smoothing is finally used to refine the human parsing result. Comprehensive evaluations on a large dataset well demonstrate the significant superiority of the ATR framework over other state-of-the-arts for human parsing. In particular, the F1-score reaches 64: 38 percent by our ATR framework, significantly higher than 44: 76 percent based on the state-of-the-art algorithm [28].	[Liang, Xiaodan] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou, Guangdong, Peoples R China; [Liang, Xiaodan; Liu, Si; Liu, Luoqi; Dong, Jian; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore; [Shen, Xiaohui; Yang, Jianchao] Adobe Res, San Jose, CA USA; [Lin, Liang] Sun Yat Sen Univ, Sch Adv Comp, Guangzhou, Guangdong, Peoples R China; [Lin, Liang] SYSU CMU Shunde Int Joint Res Inst, Shunde, Peoples R China; [Liu, Si] Chinese Acad Sci, Inst Informat Engn, Beijing 100864, Peoples R China	Sun Yat Sen University; National University of Singapore; Adobe Systems Inc.; Sun Yat Sen University; Chinese Academy of Sciences; Institute of Information Engineering, CAS	Liang, XD (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou, Guangdong, Peoples R China.	xdliang328@gmail.com; fifthzombiesi@gmail.com; xshen@adobe.com; jiayang@adobe.com; llq667@gmail.com; timeflydj@gmail.com; linliang@ieee.org; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022; Dong, Jian/AAR-8670-2021		National Natural Science Foundation of China [61328205]; Guangdong Natural Science Foundation [S2013050014548]; Program of Guangzhou Zhujiang Star of Science and Technology [2013J2200067]; Special Project on Integration of Industry, Education and Research of Guangdong [2012B091000101]; Microsoft Research Asia	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); Program of Guangzhou Zhujiang Star of Science and Technology; Special Project on Integration of Industry, Education and Research of Guangdong; Microsoft Research Asia(Microsoft)	This work is supported by National Natural Science Foundation of China (No. 61328205), the Microsoft Research Asia collaboration projects, Guangdong Natural Science Foundation (no. S2013050014548), Program of Guangzhou Zhujiang Star of Science and Technology (no. 2013J2200067), Special Project on Integration of Industry, Education and Research of Guangdong (no. 2012B091000101). This work was done when Xiaodan Liang is an intern in the National University of Singapore. S. Liu is the corresponding author.	Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chen H., 2006, PROC IEEE COMPUT SCI, V1, P943; Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391; Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Girshick R., 2014, P COMP VIS PATT REC; Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073; Jolliffe I T, 2002, PRINCIPAL COMPONENT; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lin L., 2015, CORR; Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526; Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071; Liu Si, 2012, P 20 ACM MULT C MM 1, P619, DOI DOI 10.1145/2393347.2393433; Mairal J, 2010, J MACH LEARN RES, V11, P19; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Szegedy Christian, 2013, ADV NEURAL INFORM PR, P3, DOI DOI 10.5555/2999792.2999897; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53	30	122	135	4	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2402	2414		10.1109/TPAMI.2015.2408360	http://dx.doi.org/10.1109/TPAMI.2015.2408360			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539846	Green Accepted			2022-12-18	WOS:000364831700004
J	Chen, YL; Hsu, CT; Liao, HYM				Chen, Yi-Lei; Hsu, Chiou-Ting; Liao, Hong-Yuan Mark			Simultaneous Tensor Decomposition and Completion Using Factor Priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor completion; Tucker decomposition; factor priors; multilinear model analysis		The success of research on matrix completion is evident in a variety of real-world applications. Tensor completion, which is a high-order extension of matrix completion, has also generated a great deal of research interest in recent years. Given a tensor with incomplete entries, existing methods use either factorization or completion schemes to recover the missing parts. However, as the number of missing entries increases, factorization schemes may overfit the model because of incorrectly predefined ranks, while completion schemes may fail to interpret the model factors. In this paper, we introduce a novel concept: complete the missing entries and simultaneously capture the underlying model structure. To this end, we propose a method called simultaneous tensor decomposition and completion (STDC) that combines a rank minimization technique with Tucker model decomposition. Moreover, as the model structure is implicitly included in the Tucker model, we use factor priors, which are usually known a priori in real-world tensor objects, to characterize the underlying joint-manifold drawn from the model factors. By exploiting this auxiliary information, our method leverages two classic schemes and accurately estimates the model factors and missing entries. We conducted experiments to empirically verify the convergence of our algorithm on synthetic data and evaluate its effectiveness on various kinds of real-world data. The results demonstrate the efficacy of the proposed method and its potential usage in tensor-based applications. It also outperforms state-of-the-art methods on multilinear model analysis and visual data completion tasks.	[Chen, Yi-Lei; Hsu, Chiou-Ting] Natl Tsing Hua Univ, Multimedia Proc Lab, Dept Comp Sci, Hsinchu 300, Taiwan; [Liao, Hong-Yuan Mark] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan; [Liao, Hong-Yuan Mark] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan	National Tsing Hua University; Academia Sinica - Taiwan; National Yang Ming Chiao Tung University	Chen, YL (corresponding author), Natl Tsing Hua Univ, Multimedia Proc Lab, Dept Comp Sci, 101 Sec 2,Kuang Fu Rd, Hsinchu 300, Taiwan.	fallcolor@gmail.com; cthsu@cs.nthu.edu.tw; liao@iis.sinica.edu.tw	Liao, Hong-Yuan Mark/AAQ-5514-2021		National Science Council of R.O.C. [NSC101-2628-E-007-019-MY3]	National Science Council of R.O.C.(Ministry of Science and Technology, Taiwan)	This work was supported by the National Science Council of R.O.C. under Contract NSC101-2628-E-007-019-MY3.	Acar E, 2011, CHEMOMETR INTELL LAB, V106, P41, DOI 10.1016/j.chemolab.2010.08.004; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bertsekas D.P., 2019, REINFORCEMENT LEARNI; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229; Chen J., 2009, SIAM J MATRIX ANAL A, V30, P1709; Chen Y.L., IEEE T IMAG IN PRESS; Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238; Ding T, 2007, IEEE I CONF COMP VIS, P817; Duda R.O., 2000, PATTERN CLASSIFICATI; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Geng X, 2011, IEEE T SYST MAN CY B, V41, P881, DOI 10.1109/TSMCB.2010.2097588; Gillis N, 2011, SIAM J MATRIX ANAL A, V32, P1149, DOI 10.1137/110820361; He BS, 2012, SIAM J OPTIMIZ, V22, P313, DOI 10.1137/110822347; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274; Lathauwer L.D., 2000, SIAM J MATRIX ANAL A, V21, P1254; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Li K, 2012, IEEE T SYST MAN CY B, V42, P539, DOI 10.1109/TSMCB.2011.2168953; Li Y., 2010, P 11 EUR C COMP VIS; Liansheng Zhuang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P511, DOI 10.1109/ICIG.2011.86; Lin Z., 2009, UILUENG092215 U ILL; Liu G., 2012, NEURAL COMPUTING, V24; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu J., 2009, P 12 IEEE INT C COMP; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lu XQ, 2012, IEEE T SYST MAN CY B, V42, P939, DOI 10.1109/TSMCB.2012.2185490; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; Narita A, 2011, LECT NOTES ARTIF INT, V6912, P501, DOI 10.1007/978-3-642-23783-6_32; Oreifej O, 2013, IEEE T PATTERN ANAL, V35, P450, DOI 10.1109/TPAMI.2012.97; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Shen Y., 2011, TECHNICAL REPORT; Signoretto M., 2013, MACHINE LEARNING; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Tomioka R., 2011, ARXIV10100789; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Wang YX, 2011, IEEE IMAGE PROC, P3409, DOI 10.1109/ICIP.2011.6116443; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yang JF, 2013, MATH COMPUT, V82, P301; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132	47	122	125	2	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					577	591		10.1109/TPAMI.2013.164	http://dx.doi.org/10.1109/TPAMI.2013.164			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457512				2022-12-18	WOS:000331450100014
J	Li, ZF; Lin, DH; Tang, XO				Li, Zhifeng; Lin, Dahua; Tang, Xiaoou			Nonparametric Discriminant Analysis for Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; classifier design and evaluation; nonparametric discriminant analysis (NDA); multiclassifier fusion		In this paper, we develop a new framework for face recognition based on nonparametric discriminant analysis (NDA) and multiclassifier integration. Traditional LDA-based methods suffer a fundamental limitation originating from the parametric nature of scatter matrices, which are based on the Gaussian distribution assumption. The performance of these methods notably degrades when the actual distribution is non-Gaussian. To address this problem, we propose a new formulation of scatter matrices to extend the two-class NDA to multiclass cases. Then, in order to exploit the discriminant information in both the principal space and the null space of the intraclass scatter matrix, we develop two improved multiclass NDA-based algorithms (NSA and NFA) with each one having two complementary methods that are based on the principal space and the null space of the intraclass scatter matrix, respectively. Comparing to the NSA, the NFA is more effective in the utilization of the classification boundary information. In order to exploit the complementary nature of the two kinds of NFA (PNFA and NNFA), we finally develop a dual NFA-based multiclassifier fusion framework by employing the overcomplete Gabor representation for face images to boost the recognition performance. We show the improvements of the developed new algorithms over the traditional subspace methods through comparative experiments on two challenging face databases, the Purdue AR database and the XM2VTS database.	[Li, Zhifeng] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Human Comp Commun Lab, Hong Kong, Hong Kong, Peoples R China; [Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Lin, Dahua] MIT, Dept Elect Engn & Comp Sci, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Chinese University of Hong Kong; Chinese University of Hong Kong; Massachusetts Institute of Technology (MIT)	Li, ZF (corresponding author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Human Comp Commun Lab, Hong Kong, Hong Kong, Peoples R China.	zfli@se.cuhk.edu.hk; dhlin@mit.edu; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012; Lin, Dahua/W-6576-2019	Lin, Dahua/0000-0002-8865-7896	Research Grants Council of the Hong Kong Special Administrative Region [CUHK 4190/01E, CUHK 4224/03E, CUHK1/02C]	Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	The authors would like to thank Professor Helen Meng for her help and support. The work described in this paper was supported by grants from the Research Grants Council of the Hong Kong Special Administrative Region (Project CUHK 4190/01E, Project CUHK 4224/03E, and Project CUHK1/02C).	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chen H., 2005, P IEEE C COMP VIS PA; CHEN LF, 2000, PATTERN RECOGNITION, V33; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; ETEMAD K, 1996, P IEEE INT C AC SPEE, V4, P2148; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fukunaga K, 1990, STAT PATTERN RECOGNI; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Li Z, 2005, P IEEE C COMP VIS PA; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; MAITRE G., 1999, P 2 INT C AUD VID BA; Martinez A.M., 1998, 24 CVC PURD U; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TANG X, 2004, P IEEE C COMP VIS PA; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Wang DS, 2006, CHEM-ASIAN J, V1, P91, DOI 10.1002/asia.200600078; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; WANG XG, 2004, P IEEE C COMP VIS PA; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; YANG MH, 2002, P 5 INT C AUT FAC GE; Zeng WM, 2004, INT C PATT RECOG, P403, DOI 10.1109/ICPR.2004.1334234; Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971; Zhao W, 1998, PROC CVPR IEEE, P164, DOI 10.1109/CVPR.1998.698604; Zhao WY, 2000, INT C PATT RECOG, P818, DOI 10.1109/ICPR.2000.906201	27	122	139	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					755	761		10.1109/TPAMI.2008.174	http://dx.doi.org/10.1109/TPAMI.2008.174			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229090	Green Published			2022-12-18	WOS:000263396100015
J	Zanibbi, R; Blostein, D; Cordy, JR				Zanibbi, R; Blostein, D; Cordy, JR			Recognizing mathematical expressions using tree transformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; recognition of mathematical notation; diagram recognition; tree transformation; graphics recognition	PERFORMANCE EVALUATION; RECOGNITION; SYSTEMS	We describe a robust and efficient system for recognizing typeset and handwritten mathematical notation. From a list of symbols with bounding boxes the system analyzes an expression in three successive passes. The Layout Pass constructs a Baseline Structure Tree (BST) describing the two-dimensional arrangement of input symbols. Reading order and operator dominance are used to allow efficient recognition of symbol layout even when symbols deviate greatly from their ideal positions. Next, the Lexical Pass produces a Lexed BST from the initial BST by grouping tokens comprised of multiple input symbols; these include decimal numbers, function names, and symbols comprised of nonoverlapping primitives such as "=". The Lexical Pass also labels vertical structures such as fractions and accents. The Lexed BST is translated into LATEX. Additional processing, necessary for producing output for symbolic algebra systems, is carried out in the Expression Analysis Pass. The Lexed BST is translated into an Operator Tree, which describes the order and scope of operations in the input expression. The tree manipulations used in each pass are represented compactly using tree transformations. The compiler-like architecture of the system allows robust handling of unexpected input, increases the scalability of the system, and provides the groundwork for handling dialects of mathematical notation.	Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada	Queens University - Canada	Zanibbi, R (corresponding author), Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada.	zanibbi@cs.queensu.ca; blostein@cs.queensu.ca; cordy@cs.queensu.ca	Cordy, James R/G-9736-2011	Zanibbi, Richard/0000-0001-5921-9750				Aho Alfred V., 1977, PRINCIPLES COMPILER; ANDERSON R, 1968, THESIS HARVARD U; Anderson R.H., 1977, SYNTACTIC PATTERN RE, P147; BELAID A, 1984, IEEE T PATTERN ANAL, V6, P105, DOI 10.1109/TPAMI.1984.4767483; BERMAN BP, 1994, P INT S SYMB ALG COM, P348; Blostein D., 1996, HDB OPTICAL CHARACTE, P557; BRILL E, 1996, RECENT ADV PARSING T, P1; Chan KF, 2001, PATTERN RECOGN, V34, P1671, DOI 10.1016/S0031-3203(00)00102-3; CHAN KF, 2000, INT J DOC ANAL RECOG, V3, P3; CHANG SK, 1970, INFORM SCIENCES, V2, P253, DOI 10.1016/S0020-0255(70)80052-4; Charniak Eugene, 1993, STAT LANGUAGE LEARNI; CHAUNDY T, 1957, PRINTING MATH; CHOU PA, 1989, P SOC PHOTO-OPT INS, V1199, P852; CORDY JR, 1991, COMPUT LANG, V16, P97, DOI 10.1016/0096-0551(91)90019-6; CORDY JR, 2000, TXL PROGRAMMING LANG; Costagliola G, 1997, IEEE T SOFTWARE ENG, V23, P777, DOI 10.1109/32.637392; Eto Y, 2001, PROC INT CONF DOC, P762, DOI 10.1109/ICDAR.2001.953891; FATEMAN RJ, 1999, P SOC PHOTO-OPT INS, V3967, P98; FAURE C, 1990, COMPUTER PROCESSING OF HANDWRITING, P337; Fukuda R., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P131, DOI 10.1109/ICDAR.1999.791742; GARAIN U, 2001, P 4 INT IAPR WORKSH, P429; GARVAN F, 2001, MAPLE BOOK; Grbavec A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P417, DOI 10.1109/ICDAR.1995.599026; Higham NJ, 1993, HDB WRITING MATH SCI; Inoue K., 1998, P 3 ASIAN TECHNOLOGY, P280; Kacem A., 2001, International Journal on Document Analysis and Recognition, V4, P97, DOI 10.1007/s100320100064; KANAHORI T, 2001, P 4 INT IAPR WORKSH, P455; KNUTH D. E., 1979, TEX METAFONT NEW DIR; LEE HJ, 1994, PATTERN RECOGN, V27, P447, DOI 10.1016/0031-3203(94)90121-X; Miller EG, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P784; Okamoto M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P121, DOI 10.1109/ICDAR.2001.953767; OKAMOTO M, 1991, P 1 INT C DOC AN REC, V1, P242; Phillips IT, 1998, P SOC PHOTO-OPT INS, V3305, P112, DOI 10.1117/12.304624; Phillips IT, 1999, IEEE T PATTERN ANAL, V21, P849, DOI 10.1109/34.790427; Smithies S, 2001, BEHAV INFORM TECHNOL, V20, P53, DOI 10.1080/01449290010020657; Srihari S. N., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P416, DOI 10.1109/ICDAR.1993.395704; Toyozumi K, 2001, PROC INT CONF DOC, P1059, DOI 10.1109/ICDAR.2001.953948; WANG Z, 1988, P 9 INT C PATT REC R, P32; WINKLER H, 1995, P INT C AC SPEECH SI, P2459; Wolfram S., 1999, MATH BOOK VERSION 4; Zanibbi R, 2001, PROC INT CONF DOC, P768, DOI 10.1109/ICDAR.2001.953892; ZANIBBI R, 2001, P 4 INT IAPR WORKSH, P493; Zanibbi R., 2000, RECOGNITION MATH NOT; Zanibbi Richard, 2001, P GRAPH INT 2001 OTT, P127	44	122	128	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1455	1467		10.1109/TPAMI.2002.1046157	http://dx.doi.org/10.1109/TPAMI.2002.1046157			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY		Green Submitted			2022-12-18	WOS:000178846400004
J	Fiore, PD				Fiore, PD			Efficient linear solution of exterior orientation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						exterior orientation; pose estimation; absolute orientation; efficient linear method	CLOSED-FORM SOLUTION	This paper concerns an efficient algorithm for the solution of the exterior orientation problem. Orthogonal decompositions are used to first isolate the unknown depths of feature points in the camera reference frame, allowing the problem to be reduced to an absolute orientation with scale problem, which is solved using the SVD. The key feature of this approach is the low computational cost compared to existing approaches.	BAE Syst, Merrimack, NH 03054 USA	Bae Systems	Fiore, PD (corresponding author), BAE Syst, Merrimack, NH 03054 USA.	pfiore@sanders.com						ABDELAZIZ YI, 1971, P ASP UI S CLOS RANG, P1; [Anonymous], 1996, CRC STANDARD MATH TA; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Ghosh S.K., 1988, ANAL PHOTOGRAMMETRY; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759; Haralick R.M., 1993, COMPUTER ROBOT VISIO; Hartley RI, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P469, DOI 10.1109/ICCV.1998.710760; Hartley Richard I, 1997, IEEE T PATTERN ANAL, V19; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; STRANG G, 1980, LINEAR ALGEBRA; Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231; Trucco E., 1998, INTRO TECHNIQUES 3D; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; WANG ZY, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P129	20	122	136	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					140	148		10.1109/34.908965	http://dx.doi.org/10.1109/34.908965			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500004
J	HADDON, JF; BOYCE, JF				HADDON, JF; BOYCE, JF			IMAGE SEGMENTATION BY UNIFYING REGION AND BOUNDARY INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV LONDON KINGS COLL,WHEATSTONE LAB,DEPT PHYS,LONDON WC2R 2LS,ENGLAND	University of London; King's College London	HADDON, JF (corresponding author), ROYAL AEROSP ESTAB,FARNBOROUGH GU14 6TD,HANTS,ENGLAND.							AHUJA N, 1978, IEEE T SYST MAN CYB, V8, P895; ANDO S, 1978, 4TH P INT JOINT C PA; Ballard D.H., 1982, COMPUTER VISION; BESAG J, 1986, J R STAT SOC B, V48, P259; BOYCE JF, 1987, PATTERN RECOGN LETT, V6, P225, DOI 10.1016/0167-8655(87)90081-X; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CARLTON SG, 1977, JUN P IEEE C PATT RE; CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; Duda R.O., 1973, J ROYAL STAT SOC SER; DYER CR, 1987, PARALLEL COMPUTER VI; FEKETE G, 1981, IEEE T PAMI, V3, P460; FLECK MM, 1987, 10TH P INT JOINT C A; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; HADDON JF, 1988, PATTERN RECOGN, V21, P195, DOI 10.1016/0031-3203(88)90054-4; HANCOCK ER, 1987, 5TH P SCAND C IM AN; Haralick R. M., 1982, HDB STAT, V2, P399; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARLOW CA, 1985, P SOC PHOTO-OPT INST, V548, P10, DOI 10.1117/12.948401; HOROWITZ SL, 1974, 2ND P INT JOINT C PA; KINDERMANN R, 1980, CONT MATH; KITTLER J, 1986, COMPUT VISION GRAPH, V34, P257, DOI 10.1016/S0734-189X(86)80041-X; KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443; KITTLER J, 1983, 3RD P SCAND C IMAG A, P90; KOHLER R, 1981, COMPUT VISION GRAPH, V15, P319, DOI 10.1016/S0146-664X(81)80015-9; LEVINE MD, 1984, PATTERN RECOGN LETT, V1, P417; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; PAVLIDIS T, 1976, J ACM, V23, P368; PIERRE DA, 1975, MATH PROGRAMMING VIA; Preston C.J., 1974, CAMBRIDGE TRACTS MAT; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld A., 1982, DIGITAL PICTURE PROC; ROSENFELD A, 1969, PICTURE PROCESSING C; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7; WECHSLER H, 1980, SIGNAL PROCESS, V2, P271, DOI 10.1016/0165-1684(80)90024-9; WIGHTMAN AS, 1971, STATISTICAL MECHANIC; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1975, IEEE T COMPUT, V24	42	122	125	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1990	12	10					929	948		10.1109/34.58867	http://dx.doi.org/10.1109/34.58867			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EA042					2022-12-18	WOS:A1990EA04200001
J	CONNERS, RW; MCMILLIN, CW; LIN, K; VASQUEZESPINOSA, RE				CONNERS, RW; MCMILLIN, CW; LIN, K; VASQUEZESPINOSA, RE			IDENTIFYING AND LOCATING SURFACE-DEFECTS IN WOOD - PART OF AN AUTOMATED LUMBER PROCESSING SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									US FOREST SERV,SO FOREST EXPT STN,PINEVILLE,LA 71360	United States Department of Agriculture (USDA); United States Forest Service	CONNERS, RW (corresponding author), LOUISIANA STATE UNIV,DEPT ELECT & COMP ENGN,BATON ROUGE,LA 70803, USA.							ALGAZI VR, 1966, IEEE T COMMUN TECHN, VCO14, P297, DOI 10.1109/TCOM.1966.1089333; AUSHERMAN DA, 1972, THESIS U MISSOURI CO; CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2; CHIEN YP, 1974, IEEE T SYST MAN CYB, VMC 4, P145, DOI 10.1109/TSMC.1974.5409108; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; CONNERS RW, 1978, COMPUT VISION GRAPH, V8, P447; CONNERS RW, 1976, THESIS U MISSOURI CO; DARLING EM, 1968, IEEE T SYST SCI CYB, VSSC4, P38, DOI 10.1109/TSSC.1968.300186; ELIAS P, 1970, IEEE T INFORM THEORY, V16, P172, DOI 10.1109/TIT.1970.1054415; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; HALL EL, 1974, OPT ENG, V13, P250, DOI 10.1117/12.7971702; HARALICK RM, 1973, IEEE T GEOSCI REMOTE, VGE11, P171, DOI 10.1109/TGE.1973.294312; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HEMENWAY J, IAPX 432 GDP ARCHITE; HEMENWAY J, IAPX 432 OBJECT PRIM; HEMENWAY J, 1981, MINIMICRO SYST   MAY, P73; HEMENWAY J, INTRO IAPX ARCHITECT; HUBER HA, 1982, FOREST PROD J, V32, P16; Hummel R. A., 1975, COMPUT GRAPH IMAGE P, V4, P209; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KING EA, 1978, 4TH NDT WOOD S VANC, P15; KING EA, 1979, MAR N AM SAWM PLYW C; KRUGER RP, 1974, IEEE T SYST MAN CYB, VSMC4, P40, DOI 10.1109/TSMC.1974.5408519; Matthews PC, 1976, US Patent, Patent No. [3976384, 3,976,384]; MATTHEWS PC, 1977, Patent No. 1488841; MAX J, 1960, IRE T INFORM THEOR, V6, P7, DOI 10.1109/TIT.1960.1057548; MCMILLIN CW, 1980, USDA SO29 FOR SERV S; MORRISON DF, 1967, MULTIVARIATE STATIST; PANTER PF, 1951, P IRE, V39, P44, DOI 10.1109/JRPROC.1951.230419; PETERS CC, 1977, FOREST PROD J, V27, P41; RATHNER J, 1980, COMPUT ARCHITECT OCT; ROE GM, 1964, IEEE T INFORM THEORY, V10, P384, DOI 10.1109/TIT.1964.1053693; SZYMANI R, 1981, FOREST PROD J, V31, P34; TULLY RJ, 1978, INVEST RADIOL, V13, P298, DOI 10.1097/00004424-197807000-00005; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777	36	122	134	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					573	583		10.1109/TPAMI.1983.4767446	http://dx.doi.org/10.1109/TPAMI.1983.4767446			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869143				2022-12-18	WOS:A1983RV48800003
J	MICHALSKI, RS; STEPP, RE				MICHALSKI, RS; STEPP, RE			AUTOMATED CONSTRUCTION OF CLASSIFICATIONS - CONCEPTUAL CLUSTERING VERSUS NUMERICAL TAXONOMY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MICHALSKI, RS (corresponding author), UNIV ILLINOIS,DEPT COMP SCI,URBANA,IL 61801, USA.							ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; [Anonymous], 1980, PRINCIPLES ARTIFICIA; Diday E., 1980, COMMUNICATION CYBERN, V10, P47; DIDAY E, 1980, 5TH P INT C PATT REC, P424; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4, P219; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4, P125; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349, DOI 10.1109/TPAMI.1980.4767034; MICHALSKI RS, 1974, 1974 P INT S MULT VA, P323; MICHALSKI RS, 1981, PROGR PATTERN RECOGN, V1, P33; Michalski RS, 1983, MACHINE LEARNING ART, DOI 10.1007/978-3-662-12405-5; MICHALSKI RS, 1981, 7TH P INT JOINT C AR, P460; MICHALSKI RS, 1981, MACHINE INTELLIGENCE, V10; MICHALSKI RS, 1978, 867 U ILL DEP COMP S; MICHALSKI RS, 1975, MULTIPLE VALUED LOGI, P506; Sokal R, 1963, PRINCIPLES NUMERICAL; STEPP R, 1979, 982 U ILL DEP COMP S; STEPP R, 1982, UIUCDCSR821084 U ILL; WATANABE S., 1969, KNOWING GUESSING QUA; Winston P. H., 1977, ARTIFICIAL INTELLIGE; ZAGORUIKO NG, 1978, 4TH P INT C PATT REC, P1100	20	122	131	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					396	410		10.1109/TPAMI.1983.4767409	http://dx.doi.org/10.1109/TPAMI.1983.4767409			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869124	Green Submitted			2022-12-18	WOS:A1983RA57800005
J	Wang, TC; Efros, AA; Ramamoorthi, R				Wang, Ting-Chun; Efros, Alexei A.; Ramamoorthi, Ravi			Depth Estimation with Occlusion Modeling Using Light-Field Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light-fields; 3D reconstruction; occlusion detection	ENERGY MINIMIZATION; STEREO	Light-field cameras have become widely available in both consumer and industrial applications. However, most previous approaches do not model occlusions explicitly, and therefore fail to capture sharp object boundaries. A common assumption is that for a Lambertian scene, a pixel will exhibit photo-consistency, which means all viewpoints converge to a single point when focused to its depth. However, in the presence of occlusions this assumption fails to hold, making most current approaches unreliable precisely where accurate depth information is most important - at depth discontinuities. In this paper, an occlusion-aware depth estimation algorithm is developed; the method also enables identification of occlusion edges, which may be useful in other applications. It can be shown that although photo-consistency is not preserved for pixels at occlusions, it still holds in approximately half the viewpoints. Moreover, the line separating the two view regions (occluded object versus occluder) has the same orientation as that of the occlusion edge in the spatial domain. By ensuring photo-consistency in only the occluded view region, depth estimation can be improved. Occlusion predictions can also be computed and used for regularization. Experimental results show that our method outperforms current state-of-the-art light-field depth estimation algorithms, especially near occlusion boundaries.	[Wang, Ting-Chun; Efros, Alexei A.] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Ramamoorthi, Ravi] Univ Calif San Diego, CSE Dept, La Jolla, CA 92093 USA	University of California System; University of California Berkeley; University of California System; University of California San Diego	Wang, TC (corresponding author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.	tcwang0509@eecs.berkeley.edu; efros@eecs.berkeley.edu; ravir@cs.ucsd.edu	Wang, Ting-Chun/AAZ-2408-2020; Wang, Ting-Chun/AAD-4410-2021	Wang, Ting-Chun/0000-0002-1522-2381; Efros, Alexei A./0000-0001-5720-8070	ONR [N00014-15-1-2013]; Berkeley Fellowship; Intel; Draper; Nokia; Sony	ONR(Office of Naval Research); Berkeley Fellowship; Intel(Intel Corporation); Draper; Nokia(Nokia Corporation); Sony	The authors acknowledge support from ONR grant N00014-15-1-2013, a Berkeley Fellowship, Intel, and funding from Draper, Nokia and Sony to the UC San Diego Center for Visual Computing.	ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783; [Anonymous], 2015, 3D MOD AN REND SOFTW; [Anonymous], 2015, FREE 3DS MODE; Bleyer M, 2010, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2010.5539783; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Krishnamurthy V., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P313, DOI 10.1145/237170.237270; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Liang CK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665075; McCloskey S, 2014, INT C PATT RECOG, P2053, DOI 10.1109/ICPR.2014.358; Ng, 2005, LIGHT FIELD PHOTOGRA; Rother C, 2007, PROC CVPR IEEE, P1784; Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Wei YC, 2005, PROC CVPR IEEE, P902; Wietzke L., 2012, P IS SPIE EL IM; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347	29	121	135	0	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2170	2181		10.1109/TPAMI.2016.2515615	http://dx.doi.org/10.1109/TPAMI.2016.2515615			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26761194				2022-12-18	WOS:000385945000003
J	Zhang, ST; Yang, M; Cour, T; Yu, K; Metaxas, DN				Zhang, Shaoting; Yang, Ming; Cour, Timothee; Yu, Kai; Metaxas, Dimitris N.			Query Specific Rank Fusion for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large-scale image retrieval; vocabulary tree; hashing; graph-based fusion; query specific fusion	APPROXIMATE NEAREST-NEIGHBOR; PRODUCT QUANTIZATION; SCALE; IDENTIFICATION; FEATURES	Recently two lines of image retrieval algorithms demonstrate excellent scalability: 1) local features indexed by a vocabulary tree, and 2) holistic features indexed by compact hashing codes. Although both of them are able to search visually similar images effectively, their retrieval precision may vary dramatically among queries. Therefore, combining these two types of methods is expected to further enhance the retrieval precision. However, the feature characteristics and the algorithmic procedures of these methods are dramatically different, which is very challenging for the feature-level fusion. This motivates us to investigate how to fuse the ordered retrieval sets, i.e., the ranks of images, given by multiple retrieval methods, to boost the retrieval precision without sacrificing their scalability. In this paper, we model retrieval ranks as graphs of candidate images and propose a graph-based query specific fusion approach, where multiple graphs are merged and reranked by conducting a link analysis on a fused graph. The retrieval quality of an individual method is measured on-the-fly by assessing the consistency of the top candidates' nearest neighborhoods. Hence, it is capable of adaptively integrating the strengths of the retrieval methods using local or holistic features for different query images. This proposed method does not need any supervision, has few parameters, and is easy to implement. Extensive and thorough experiments have been conducted on four public datasets, i.e., the UKbench, Corel-5K, Holidays and the large-scale San Francisco Landmarks datasets. Our proposed method has achieved very competitive performance, including state-of-the-art results on several data sets, e. g., the N-S score 3.83 for UKbench.	[Zhang, Shaoting] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28027 USA; [Yang, Ming] Facebook Inc, AI Res, Menlo Pk, CA 94025 USA; [Cour, Timothee] Google Inc, Mountain View, CA USA; [Yu, Kai] Baidu Inc, Inst Deep Learning, Beijing, Peoples R China; [Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, Div Comp & Informat Sci, Piscataway, NJ 08854 USA	University of North Carolina; University of North Carolina Charlotte; Facebook Inc; Google Incorporated; Baidu; Rutgers State University New Brunswick	Zhang, ST (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28027 USA.	shaoting@cs.rutgers.edu; m-yang4@u.northwestern.edu; timothee.cour@gmail.com; kai.yu.cool@gmail.com; dnm@cs.rutgers.edu	Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Yang, Ming/0000-0003-1691-6817	NEC Laboratories America - University of North Carolina at Charlotte, Charlotte Research Institute (CRI); Oak Ridge Associated Universities for the Ralph E. Powe Junior Faculty Enhancement Award	NEC Laboratories America - University of North Carolina at Charlotte, Charlotte Research Institute (CRI); Oak Ridge Associated Universities for the Ralph E. Powe Junior Faculty Enhancement Award	This work was supported in part by NEC Laboratories America, funds provided by the University of North Carolina at Charlotte, Charlotte Research Institute (CRI), and the Oak Ridge Associated Universities for the Ralph E. Powe Junior Faculty Enhancement Award.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Cai D., 2007, P 15 ACM INT MULT C, P403; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Fagin R., 2003, P 2003 ACM SIGMOD IN, P301, DOI [10.1145/872757.872795, DOI 10.1145/872757.872795]; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI [DOI 10.1111/J.1469-8137.1912.TB05611.X, 10.1111/j.1469-8137.1912.tb05611.x]; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285; Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809; Liu Wei, 2011, Reports in Parasitology, V1, P1; Liu XL, 2014, PATTERN RECOGN, V47, P748, DOI 10.1016/j.patcog.2013.08.022; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Page L., 1999, PAGERANK CITATION RA; Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373; Richardson M, 2002, ADV NEUR IN, V14, P1441; Salakhutdinov Ruslan, 2007, J MACHINE LEARNING R, P412, DOI DOI 10.1109/ICCV.2017.74; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Song J., 2011, P 19 ACM INT C MULTI, P423, DOI [10.1145/2072298.2072354, DOI 10.1145/2072298.2072354]; Torralba A, 2008, PROC CVPR IEEE, P2269; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244; Weiss Y., 2008, ADV NEURAL INFORM PR, V21, P1753; Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566; Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225; Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47; Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533; Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528; Zhou W., 2010, P ACM INT C MULT, P511	46	121	126	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					803	815		10.1109/TPAMI.2014.2346201	http://dx.doi.org/10.1109/TPAMI.2014.2346201			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353295				2022-12-18	WOS:000351213400008
J	Seo, HJ; Milanfar, P				Seo, Hae Jong; Milanfar, Peyman			Action Recognition from One Example	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; space-time descriptor; correlation; regression analysis	IMAGE; KERNEL; OBJECT	We present a novel action recognition method based on space-time locally adaptive regression kernels and the matrix cosine similarity measure. The proposed method uses a single example of an action as a query to find similar matches. It does not require prior knowledge about actions, foreground/background segmentation, or any motion estimation or tracking. Our method is based on the computation of novel space-time descriptors from the query video which measure the likeness of a voxel to its surroundings. Salient features are extracted from said descriptors and compared against analogous features from the target video. This comparison is done using a matrix generalization of the cosine similarity measure. The algorithm yields a scalar resemblance volume, with each voxel indicating the likelihood of similarity between the query video and all cubes in the target video. Using nonparametric significance tests by controlling the false discovery rate, we detect the presence and location of actions similar to the query video. High performance is demonstrated on challenging sets of action data containing fast motions, varied contexts, and complicated background. Further experiments on the Weizmann and KTH data sets demonstrate state-of-the-art performance in action categorization.	[Seo, Hae Jong; Milanfar, Peyman] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Seo, HJ (corresponding author), Univ Calif Santa Cruz, 1156 High St,Mailcode SOE2, Santa Cruz, CA 95064 USA.	rokaf@soe.ucsc.edu; milanfar@ee.ucsc.edu	Milanfar, Peyman/B-2551-2009		US Air Force Office of Scientific Research [FA 9550-07-01-0365]	US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	This work was supported in part by US Air Force Office of Scientific Research Grant FA 9550-07-01-0365.	Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242; Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; [Anonymous], 2009, BMVC 2009 BRIT MACH; BANDOPADHAY A, 1988, P IEEE C COMP VIS PA; BATRA D, 2008, P IEEE WORKSH MOT VI; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boulanger J, 2007, IEEE T PATTERN ANAL, V29, P1096, DOI 10.1109/TPAMI.2007.1064; Bregonzio  M., 2009, P IEEE C COMP VIS PA; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Calinski T, 2006, COMMUN STAT-SIMUL C, V35, P727, DOI 10.1080/03610910600716290; CARLSSON C, 2001, P WORKSH MOD VERS EX; CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; CHEUNG KM, 2003, P IEEE C COMP VIS PA; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DARRELL T, 1993, P ADV NEURAL INFORM, V6, P945; Devernay F., 1995, RR2724 INRIA; DIVVALA SK, 2008, P IEEE C COMP VIS PA; DOLLAR P, 2005, P WORKSH PERF EV TRA; Duda R.O., 2000, PATTERN CLASSIFICATI; Fathi Alireza, 2008, CVPR; Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154; Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Grauman K, 2007, J MACH LEARN RES, V8, P725; HAYS J, 2007, P ACM SIGGRAPH; Jhuang H., 2007, P INT C CV; Jiang H., 2006, P IEEE C COMP VIS PA; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; KE, 2004, P ACM MUL; Ke Y., 2007, P IEEE INT C COMP VI; Ke Y., 2005, P IEEE C COMP VIS PA; KENDALL M, 1973, GRIFFIN, V2; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Kimmel R., 2003, NUMERICAL GEOMETRY I; Klaser A, 2008, BMVC 2008, P271; Kulis B., 2009, P IEEE INT C COMP VI; Kumar N., 2008, P EUR C COMP VIS; Lampert C., 2008, CVPR; Laptev I., 2007, P IEEE INT C COMP VI; Laptev I., 2008, P INT C CVPR; LAPTEV Z, 2003, P IEEE INT C COMP VI; Lee H., 2006, P ADV NEUR INF PROC; Lin D, 2005, P IEEE INT C IM PROC; Little J., 1998, VIDERE, V1, P1; Liu CJ, 2007, IEEE T PATTERN ANAL, V29, P1086, DOI 10.1109/TPAMI.2007.1063; LIU J, 2008, P INT C CVPR; Liu J., 2008, P IEEE C COMP VIS PA; Mahmood T, 2001, P IEEE WORKSH DET RE; Marszalek M., 2009, P IEEE C COMP VIS PA; Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990; Niebles J.C., 2007, P IEEE C COMP VIS PA; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Ning HZ, 2009, IEEE T CIRC SYST VID, V19, P808, DOI 10.1109/TCSVT.2009.2017399; OIKONOMOPOULOUS.A, 2005, P IEEE INT C MULT EX; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Petkov N, 2007, BIOL CYBERN, V97, P423, DOI 10.1007/s00422-007-0182-0; Rapantzikos K., 2009, P IEEE C COMP VIS PA; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Schindler K., 2008, P INT C CVPR; Schneider JW, 2007, J AM SOC INF SCI TEC, V58, P1586, DOI 10.1002/asi.20643; SCHULDT C, 2004, P INT C PR; Scovanner P., 2007, P ACM MULT C; Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Seo HJ, 2009, P IEEE INT C COMP VI; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Shechtman Eli, 2007, P CVPR 2007; STARNER T, 1995, P INT WORKSH AUT FAC; SUN X, 2009, P IEEE C COMP VIS PA; Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; TATSUOKA MM, 1988, MULTIVARIATE ANAL; TOMASI C, 1998, IEEE C COMP VIS; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; VEIT T, 2004, P IEEE C COMP VIS PA; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WEINLAND D, 2007, P IEEE INT C COMP VI; Wolf L., 2008, P FACES REAL LIFE IM; Wolf L, 2009, P IEEE INT C COMP VI; Wong A., 2008, P IEEE INT C IM PROC; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; YAMATO J, 1992, P IEEE C COMP VIS PA; Yang J., 2009, CVPR; Yang W., 2009, 2 MLVMA ICCV JAP SEP; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Yilmaz A., 2005, P IEEE C COMP VIS PA; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; Zhang H., 2006, 2006 IEEE COMP SOC C; ZHANG Z, 2008, P EUR COMP VIS; Zhao HL, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.245	96	121	130	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					867	882		10.1109/TPAMI.2010.156	http://dx.doi.org/10.1109/TPAMI.2010.156			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20733220				2022-12-18	WOS:000288677800002
J	Geyer, C; Daniilidis, K				Geyer, C; Daniilidis, K			Paracatadioptric camera calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						omnidirectional vision; panoramic vision; catadioptric camera; vanishing points; calibration		Catadioptric sensors refer to the combination of lens-based devices and reflective surfaces, These systems are useful because they may have a field of view which is greater than hemispherical, providing the ability to simultaneously view in any direction. Configurations which have a unique effective viewpoint are of primary interest, among these is the case where the reflective surface is a parabolic mirror and the camera is such that it induces an orthographic projection and which we call paracatadiotpric. We present an algorithm for the calibration of such a device using only the images of lines in space. In fact, we show that we may obtain all of the intrinsic parameters from the images of only three lines and that this is possible without any metric information. We propose a closed-form solution for focal length, image center, and aspect ratio for skewless cameras and a polynomial root solution in the presence of skew. We also give a method for determining the orientation of a plane containing two sets of parallel lines from one uncalibrated view. Such an orientation recovery enables a rectification which is impossible to achieve in the case of a single uncalibrated view taken by a conventional camera. We study the performance of the algorithm in simulated setups and compare results on real images with an approach based on the image of the mirror's bounding circle.	Univ Penn, Grasp Lab, Philadelphia, PA 19104 USA	University of Pennsylvania	Geyer, C (corresponding author), Univ Penn, Grasp Lab, 3401 Walnut St,336C, Philadelphia, PA 19104 USA.	geyer@grasp.cis.upenn.edu; kostas@grasp.cis.upenn.edu		Daniilidis, Kostas/0000-0003-0498-0758				Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Benosman R, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P112, DOI 10.1109/OMNVIS.2000.853816; Benosman R., 2000, PANORAMIC VISION; Boult TE, 1998, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.1998.698724; Bruckstein AM, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P79; COOPE ID, 1993, J OPTIMIZ THEORY APP, V76, P381, DOI 10.1007/BF00939613; DANIILIDIS K, 2000, P IEEE WORKSH OMN VI; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Geyer Christopher, 2000, LNCS, P445, DOI DOI 10.1007/3-540-45053-X_29; Hecht E, 1997, OPTICS; Jogan M, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P37, DOI 10.1109/OMNVIS.2000.853802; KANG S, 2000, IEEE C COMPUTER VISI; MOURA L, 1991, COMPUT PHYS COMMUN, V64, P57, DOI 10.1016/0010-4655(91)90049-Q; NALWA V, 1996, TRUE OMNIDIRECTIONAL; Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369; Nene SA, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1087, DOI 10.1109/ICCV.1998.710852; ONOE Y, 1998, COMPUTER VISION IMAG, V71, P588; Sturm P, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P119, DOI 10.1109/OMNVIS.2000.853818; SVOBODA T, 1998, P 5 EUR C COMP VIS, P218; Taylor CJ, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P3, DOI 10.1109/OMNVIS.2000.853795; TOOMER G, 1976, SOURCES HIST MATH PH; Winters N, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P21, DOI 10.1109/OMNVIS.2000.853799; YAGI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P11, DOI 10.1109/70.285581; Yagi Y, 1999, IEICE T INF SYST, VE82D, P568; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	25	121	138	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					687	695		10.1109/34.1000241	http://dx.doi.org/10.1109/34.1000241			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU		Green Published			2022-12-18	WOS:000175187800009
J	Milan, A; Schindler, K; Roth, S				Milan, Anton; Schindler, Konrad; Roth, Stefan			Multi-Target Tracking by Discrete-Continuous Energy Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-object tracking; tracking-by-detection; visual surveillance; discrete-continuous optimization	GRAPHS	The task of tracking multiple targets is often addressed with the so-called tracking-by-detection paradigm, where the first step is to obtain a set of target hypotheses for each frame independently. Tracking can then be regarded as solving two separate, but tightly coupled problems. The first is to carry out data association, i.e., to determine the origin of each of the available observations. The second problem is to reconstruct the actual trajectories that describe the spatio-temporal motion pattern of each individual target. The former is inherently a discrete problem, while the latter should intuitively be modeled in continuous space. Having to deal with an unknown number of targets, complex dependencies, and physical constraints, both are challenging tasks on their own and thus most previous work focuses on one of these subproblems. Here, we present a multi-target tracking approach that explicitly models both tasks as minimization of a unified discrete-continuous energy function. Trajectory properties are captured through global label costs, a recent concept from multi-model fitting, which we introduce to tracking. Specifically, label costs describe physical properties of individual tracks, e.g., linear and angular dynamics, or entry and exit points. We further introduce pairwise label costs to describe mutual interactions between targets in order to avoid collisions. By choosing appropriate forms for the individual energy components, powerful discrete optimization techniques can be leveraged to address data association, while the shapes of individual trajectories are updated by gradient-based continuous energy minimization. The proposed method achieves state-of-the-art results on diverse benchmark sequences.	[Milan, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Schindler, Konrad] Swiss Fed Inst Technol, Photogrammetry & Remote Sensing Grp, Wolfgang Pauli Str 15, CH-8093 Zurich, Switzerland; [Roth, Stefan] Tech Univ Darmstadt, Dept Comp Sci, Hsch Str 10, D-64289 Darmstadt, Germany	University of Adelaide; Swiss Federal Institutes of Technology Domain; ETH Zurich; Technical University of Darmstadt	Milan, A (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	anton.milan@adelaide.edu.au; konrad.schindler@geod.baug.ethz.ch; sroth@cs.tu-darmstadt.de		Roth, Stefan/0000-0001-9002-9832				Andres Bjoern, 2012, ARXIV12060111; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; Andriyenko A, 2010, LECT NOTES COMPUT SC, V6311, P466, DOI 10.1007/978-3-642-15549-9_34; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Berclaz J., 2009, 2009 12 IEEE INT WOR, P1, DOI [10.1109/PETSWINTER.2009.5399488, DOI 10.1109/PETSWINTER.2009.5399488, DOI 10.1109/PETS-WINTER.2009.5399488]; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278; CHARBONNIER P, 1994, IEEE IMAGE PROC, P168; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z; Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI DOI 10.1109/CVPR.2008.4587581; Fortmann T. E., 1980, Proceedings of the 19th IEEE Conference on Decision & Control Including the Symposium on Adaptive Processes, P807; Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Ladicky L, 2010, LECT NOTES COMPUT SC, V6315, P239, DOI 10.1007/978-3-642-15555-0_18; Leal-Taixe L, 2014, PROC CVPR IEEE, P3542, DOI 10.1109/CVPR.2014.453; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Lenz P., 2014, ARXIV14076251CS; Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239; Milan A., 2015, ARXIV150401942CS; Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Oh S, 2004, IEEE DECIS CONTR P, P735, DOI 10.1109/CDC.2004.1428740; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Rother C., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383203; Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110; Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102; Wu B., 2006, 2006 IEEE COMP SOC C, V1, P951, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]; Wu Z, 2011, PROC CVPR IEEE, P1185, DOI 10.1109/CVPR.2011.5995515; Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742	53	120	127	2	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					2054	2068		10.1109/TPAMI.2015.2505309	http://dx.doi.org/10.1109/TPAMI.2015.2505309			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26660703				2022-12-18	WOS:000384240600010
J	Oh, TH; Lee, JY; Tai, YW; Kweon, IS				Oh, Tae-Hyun; Lee, Joon-Young; Tai, Yu-Wing; Kweon, In So			Robust High Dynamic Range Imaging by Rank Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						High dynamic range image; rank minimization; RPCA; matrix completion; multi-exposure fusion; alignment	ALGORITHM; IMAGES	This paper introduces a new high dynamic range (HDR) imaging algorithm which utilizes rank minimization. Assuming a camera responses linearly to scene radiance, the input low dynamic range (LDR) images captured with different exposure time exhibit a linear dependency and form a rank-1 matrix when stacking intensity of each corresponding pixel together. In practice, misalignments caused by camera motion, presences of moving objects, saturations and image noise break the rank-1 structure of the LDR images. To address these problems, we present a rank minimization algorithm which simultaneously aligns LDR images and detects outliers for robust HDR generation. We evaluate the performances of our algorithm systematically using synthetic examples and qualitatively compare our results with results from the state-of-the-art HDR algorithms using challenging real world examples.	[Oh, Tae-Hyun; Lee, Joon-Young; Tai, Yu-Wing; Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Oh, TH (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea.	thoo@rcv.kaist.ac.kr; jylee@rcv.kaist.ac.kr; yuwing@kaist.ac.kr; iskweon77@kaist.ac.kr	Kweon, In So/C-2023-2011; Tai, Yu Wing/C-2047-2011; Oh, Tae-Hyun/D-7854-2016	Tai, Yu Wing/0000-0002-3148-0380; Oh, Tae-Hyun/0000-0003-0468-1571	National Research Foundation of Korea (NRF) - Korea government (MSIP) [2010-0028680]	National Research Foundation of Korea (NRF) - Korea government (MSIP)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680). In So Kweon is the corresponding author of this work.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Bertsekas D. P, 2014, CONSTRAINED OPTIMIZA; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884; Gallo O., 2009, COMP PHOT ICCP 2009, P1; GANESH A, 2009, 2009 3 IEEE INT, P213; Granados M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508410; Granados M, 2010, PROC CVPR IEEE, P215, DOI 10.1109/CVPR.2010.5540208; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920; Hasinoff SW, 2010, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2010.5540167; Heo Y. S., 2010, P AS C COMP VIS, P486, DOI DOI 10.1007/978-3-642-19282-139; Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154; Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23; Kalantari NK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508402; Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270; Khan EA, 2006, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2006.312892; Krymski A., 2008, U.S. Patent, Patent No. [7,397,509, 73975092008]; Lantern Magic, 2013, CANON DSLR CAMERA FI; Lee C, 2014, IEEE SIGNAL PROC LET, V21, P1045, DOI 10.1109/LSP.2014.2323404; Lee JY, 2013, IEEE T PATTERN ANAL, V35, P144, DOI 10.1109/TPAMI.2012.66; Lin Z, 2009, MATH PROGRAM; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x; MITSUNAGA T, 1999, P IEEE C COMP VIS PA; Nayar SK, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1168; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; Oh TH, 2013, IEEE I CONF COMP VIS, P145, DOI 10.1109/ICCV.2013.25; Oh TH, 2013, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2013.6738163; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Photomatrix, 2013, COMM AV HDR PROC SOF; Powell M.J., 1967, METHOD NONLINEAR CON; Raman S, 2011, VISUAL COMPUT, V27, P1099, DOI 10.1007/s00371-011-0653-0; Reinhard E., 2010, HIGH DYNAMIC RANGE I; Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222; Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001; Tocci MD, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964936; Toh KC, 2010, PAC J OPTIM, V6, P615; Tomaszewska A, 2007, WSCG 2007, FULL PAPERS PROCEEDINGS I AND II, P49; Unger J., 2007, P SOC PHOTO-OPT INS, V6501; Wang HM, 2005, FIBER POLYM, V6, P6, DOI 10.1007/BF02875567; Ward G., 2003, Journal of Graphics Tools, V8, P17, DOI 10.1080/10867651.2003.10487583; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Wu SQ, 2010, IEEE IMAGE PROC, P397, DOI 10.1109/ICIP.2010.5654196; Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079; Zimmer H, 2011, COMPUT GRAPH FORUM, V30, P405, DOI 10.1111/j.1467-8659.2011.01870.x; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	53	120	129	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1219	1232		10.1109/TPAMI.2014.2361338	http://dx.doi.org/10.1109/TPAMI.2014.2361338			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357344				2022-12-18	WOS:000354377100008
J	Wang, Y; Mori, G				Wang, Yang; Mori, Greg			Hidden Part Models for Human Action Recognition: Probabilistic versus Max Margin	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human action recognition; part-based model; discriminative learning; max margin; hidden conditional random field	REPRESENTATION	We present a discriminative part-based approach for human action recognition from video sequences using motion features. Our model is based on the recently proposed hidden conditional random field (HCRF) for object recognition. Similarly to HCRF for object recognition, we model a human action by a flexible constellation of parts conditioned on image observations. Differently from object recognition, our model combines both large-scale global features and local patch features to distinguish various actions. Our experimental results show that our model is comparable to other state-of-the-art approaches in action recognition. In particular, our experimental results demonstrate that combining large-scale global features and local patch features performs significantly better than directly applying HCRF on local patches alone. We also propose an alternative for learning the parameters of an HCRF model in a max-margin framework. We call this method the max-margin hidden conditional random field (MMHCRF). We demonstrate that MMHCRF outperforms HCRF in human action recognition. In addition, MMHCRF can handle a much broader range of complex hidden structures arising in various problems in computer vision.	[Wang, Yang] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	University of Illinois System; University of Illinois Urbana-Champaign; Simon Fraser University	Wang, Y (corresponding author), Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.	kywang@gmail.com; mori@cs.sfu.ca	Cataldi, Antonio/AAM-7411-2021					Altun Y., 2006, MACHINE LEARNING STR; [Anonymous], 2006, IEEE T AUTOM SCI ENG; BELONGIE S, 2005, ANAL STAT SHAPES; BERG AC, 2005, P IEEE CS C COMP VIS; Blank M., 2005, P IEEE INT C COMP VI; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boyd S, 2004, CONVEX OPTIMIZATION; Cherry C., 2008, P ASS MACH TRANSL AM; Collins M, 2008, J MACH LEARN RES, V9, P1775; CRAMMER K, 2001, J MACHINE LEARNING R, V2, P265, DOI DOI 10.1162/15324430260185628; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Dalal N., 2005, P IEEE CS C COMP VIS; Desai Chaitanya, 2009, P IEEE INT C COMP VI; Dollar P., 2005, P IEEE INT WORKSH VI; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Felzenszwalb P., 2008, P IEEE INT C COMP VI; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R., 2003, P IEEE CS C COMP VIS; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; JHUANG H, 2007, P IEEE INT C COMP VI; Ke Y., 2005, P IEEE INT C COMP VI; Ke Y., 2007, P IEEE INT C COMP VI; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Lafferty J., 2001, CONDITIONAL RANDOM F; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Little J., 1998, VIDERE, V1, P1; Liu J., 2008, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUCAS BD, 1981, P DARPA IM UND WORKS; MORI G., 2009, P IEEE C COMP VIS PA; Ng A. Y., 2002, P NEUR INF PROC SYST; Niebles J. C., 2007, P IEEE INT C COMP VI; Niebles J. C., 2006, P BRIT MACH VIS C; NOWOZIN S, 2007, P IEEE INT C COMP VI; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; PLATT JC, 1999, P NEUR INF PROC SYST; Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; SCHRIJVER A., 2003, COMBINATORIAL OPTIMI, V24; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Szummer M., 2008, P EUR C COMP VIS; Taskar B., 2004, P NEUR INF PROC SYST; Taskar B, 2006, J MACH LEARN RES, V7, P1627; TRAN D, 2008, P NEUR INF PROC SYST; Viola P., 2006, P NEUR INF PROC SYST; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; WANG Y, 2009, P NEUR INF PROC SYST; YU CN, 2009, P ANN INT C MACH LEA	51	120	127	3	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1310	1323		10.1109/TPAMI.2010.214	http://dx.doi.org/10.1109/TPAMI.2010.214			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21135448				2022-12-18	WOS:000290574000003
J	Wu, MR; Ye, JP				Wu, Mingrui; Ye, Jieping			A Small Sphere and Large Margin Approach for Novelty Detection Using Training Data with Outliers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Novelty detection; one-class classification; support vector machine; kernel methods	SUPPORT; CLASSIFICATION	We present a small sphere and large margin approach for novelty detection problems, where the majority of training data are normal examples. In addition, the training data also contain a small number of abnormal examples or outliers. The basic idea is to construct a hypersphere that contains most of the normal examples, such that the volume of this sphere is as small as possible, while at the same time the margin between the surface of this sphere and the outlier training data is as large as possible. This can result in a closed and tight boundary around the normal data. To build such a sphere, we only need to solve a convex optimization problem that can be efficiently solved with the existing software packages for training nu-Support Vector Machines. Experimental results are provided to validate the effectiveness of the proposed algorithm.	[Wu, Mingrui] Yahoo Inc, Sunnyvale, CA 94089 USA; [Ye, Jieping] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe	Wu, MR (corresponding author), Yahoo Inc, 701 1st Ave, Sunnyvale, CA 94089 USA.	mingrui@yahoo-inc.com; jieping.ye@asu.edu						CAMPBELL C, 2000, ADV NEURAL INFORM PR, V12; Cao LJ, 2003, PATTERN RECOGN LETT, V24, P2479, DOI 10.1016/S0167-8655(03)00093-X; Chang CC, 2002, NEURAL COMPUT, V14, P1959, DOI 10.1162/089976602760128081; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Karush W., 1939, THESIS U CHICAGO CHI; Kubat M., 1997, INT CAR MOT LTD, P179, DOI DOI 10.1007/S13398-014-0173-7.2; Kuhn H., 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; NAIR PB, 2002, NEURAL COMPUT, V15, P1115; PEKALSKA E, 2003, ADV NEURAL INFORM PR, V12; ROBERTS S, 1994, NEURAL COMPUT, V6, P270, DOI 10.1162/neco.1994.6.2.270; Scholkopf B., 2002, LEARNING KERNELS; Scott CD, 2006, J MACH LEARN RES, V7, P665; Steinwart I, 2005, J MACH LEARN RES, V6, P211; Suykens JAK, 2002, LEAST SQUARES SUPPOR; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; TOWEL GG, 2000, P 17 INT C MACH LEAR; VAPNIK V, 2000, NEURAL COMPUTATION, V12; VEROPOULOS K, 1999, P 16 INT C ART INT S; Vert R, 2006, J MACH LEARN RES, V7, P817; WU G, 2003, P INT C MACH LEARN W	24	120	166	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2088	2092		10.1109/TPAMI.2009.24	http://dx.doi.org/10.1109/TPAMI.2009.24			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762934				2022-12-18	WOS:000269767600013
J	Berretti, S; Del Bimbo, A; Vicario, E				Berretti, S; Del Bimbo, A; Vicario, E			Efficient matching and indexing of graph models in content-based retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image databases; content-based image retrieval; spatial arrangement; Attributed Relational Graphs; indexing; metric indexing; error correcting subgraph isomorphism; pairwise weighted assignment	ALGORITHM; QUERIES	In retrieval from image databases, evaluation of similarity, based both on the appearance of spatial entities and on their mutual relationships, depends on content representation based on Attributed Relational Graphs. This kind of modeling entails complex matching and indexing, which presently prevents its usage within comprehensive applications. In this paper, we provide a graph-theoretical formulation for the problem of retrieval based on the joint similarity of individual entitles and of their mutual relationships and we expound its implications on indexing and matching. In particular, we propose the usage of metric indexing to organize large archives of graph models, and we propose an original look-ahead method which represents an efficient solution for the (sub)graph error correcting isomorphism problem needed to compute object distances. Analytic comparison and experimental results show that the proposed lookahead improves the state-of-the-art in state-space search methods and that the combined use of the proposed matching and indexing scheme permits for the management of the complexity of a typical application of retrieval by spatial arrangement.	Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy	University of Florence	Berretti, S (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.		Berretti, Stefano/U-9004-2019; vicario, enrico/ABG-4344-2020	Berretti, Stefano/0000-0003-1219-4386; vicario, enrico/0000-0002-4983-4386; DEL BIMBO, ALBERTO/0000-0002-1052-8322				ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Berretti S, 2001, PATTERN ANAL APPL, V4, P83, DOI 10.1007/s100440170009; BERRETTI S, 2000, P IEEE INT WORKSH CO; BERRETTI S, IN PRESS PATTERN REC; BERRETTI S, IN PRESS IEEE T MULT; BERRETTI S, 1999, P IEEE INT C MULT CO; Bozkaya T, 1999, ACM T DATABASE SYST, V24, P361, DOI 10.1145/328939.328959; BRIN S, 1995, P 21 INT C VER LARG, P574; CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923; CHANG SK, 1991, J VISUAL LANG COMPUT, V2, P195; Cheng YT, 2000, J MICROELECTROMECH S, V9, P3, DOI 10.1109/84.825770; Ciaccia P., 1997, P INT C VER LARG DAT; CIACCIA P, 1998, P 6 INT C EXT DAT TE; CIOCCA G, 1999, P VIS 99 INF INF SYS, P107; cker Chiueh T., 1994, P 20 INT C VER LARG, P582; Del Bimbo A, 1998, PATTERN RECOGN, V31, P1241, DOI 10.1016/S0031-3203(97)00164-7; DELBIMBO A, 1999, VISUAL INFORMATION R; DELBIMBO A, 1998, IEEE WORKSH CONT BAS; DeMarsicoi M, 1997, IMAGE VISION COMPUT, V15, P119, DOI 10.1016/S0262-8856(96)01114-6; EGENHOFER MJ, 1991, INT J GEOGR INF SYST, V5, P161, DOI 10.1080/02693799108927841; EGENHOFER MJ, 1995, INT J GEOGR INF SYST, V9, P133, DOI 10.1080/02693799508902030; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; FALOUISOS C, 1996, SEARCHING MULTIMEDIA; Frank A. U., 1992, Journal of Visual Languages and Computing, V3, P343, DOI 10.1016/1045-926X(92)90007-9; FRESKA C, 1992, P INT C METH SPAT TE; Garey M., 1979, GUIDE NP COMPLETENES; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; GUDIVADA V, 1995, ACM T INFORMATION SY, V13; GUDIVADA VN, 1995, COMPUTER, V28; Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; JUNGERT E, 1993, IEEE INT WORKSH VIS, P83; LEE SY, 1992, PATTERN RECOGN, V25, P305, DOI 10.1016/0031-3203(92)90112-V; MEHROTRA R, 1995, IEEE COMPUTER    SEP, P57; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MESSMER BT, 1995, THESIS U BERN I INF; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Pardalos P.M., 1999, HDB COMBINATORIAL OP; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Petrakis EGM, 1997, IEEE T KNOWL DATA EN, V9, P435, DOI 10.1109/69.599932; PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617, DOI 10.1109/TPAMI.1985.4767709; RUI Y, 1998, IEEE T CIRCUITS VIDE; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHOKOUFANDEH A, 1999, P IEEE INT C COMP VI; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17; SMITH JR, 1996, ACM MULT 96 NOV; SMITH JR, 1995, 4149520 COL U; SOFFER A, 1996, P INT WORKSH IM DAT; TAO Y, 1999, P IEEE INT C MULT CO; TSAI WH, 1979, IEEE T SYST MAN CYB, V12, P657; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; ULLMAN JR, 1976, J ACM, V23; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; VICARIO E, 1997, P INT C IM AN PROC S; VICARIO E, 1998, IMAGE DESCRIPTION RE; WONG AKC, 1990, IEEE T SYST MAN CYB, V20, P628, DOI 10.1109/21.57275; [No title captured]	58	120	125	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1089	1105		10.1109/34.954600	http://dx.doi.org/10.1109/34.954600			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600004
J	Lee, TW; Lewicki, MS; Sejnowski, TJ				Lee, TW; Lewicki, MS; Sejnowski, TJ			ICA mixture models for unsupervised classification of non-Gaussian classes and automatic context switching in blind signal separation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						unsupervised classification; Gaussian mixture model; independent component analysis; blind source separation; image coding; automatic context switching; maximum likelihood	INDEPENDENT COMPONENT ANALYSIS; MAXIMUM-LIKELIHOOD; ALGORITHM; SPARSE	An unsupervised classification algorithm is derived by modeling observed data as a mixture of several mutually exclusive classes that are each described by linear combinations of independent, non-Gaussian densities. The algorithm estimates the density of each class and is able to model class distributions with non-Gaussian structure. The new algorithm can improve classification accuracy compared with standard Gaussian mixture models. When applied to blind source separation in nonstationary environments, the method can switch automatically between classes, which correspond to contexts with different mixing properties. The algorithm can learn efficient codes for images containing both natural scenes and text. This method shows promise for modeling non-Gaussian structure in high-dimensional data and has many potential applications.	Salk Inst Biol Studies, Computat Neurobiol Lab, Howard Hughes Med Inst, La Jolla, CA 92037 USA; Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA; Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA; Univ Calif San Diego, Dept Biol, La Jolla, CA 92093 USA	Howard Hughes Medical Institute; Salk Institute; University of California System; University of California San Diego; Carnegie Mellon University; Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of California System; University of California San Diego	Lee, TW (corresponding author), Salk Inst Biol Studies, Computat Neurobiol Lab, Howard Hughes Med Inst, La Jolla, CA 92037 USA.	tewon@salk.edu; lewicki@cnbc.cmu.edu; terry@salk.edu	Sejnowski, Terrence/AAV-5558-2021					Amari S, 1996, ADV NEUR IN, V8, P757; Amari S, 1997, IEEE T SIGNAL PROCES, V45, P2692, DOI 10.1109/78.650095; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Attias H, 1999, NEURAL COMPUT, V11, P803, DOI 10.1162/089976699300016458; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; BISHOP C, 1994, 4288 NCRG; Cardoso JF, 1997, IEEE SIGNAL PROC LET, V4, P112, DOI 10.1109/97.566704; Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Duda R.O., 1973, J ROYAL STAT SOC SER; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GAETA M, 1990, SIGNAL PROCESSING V : THEORIES AND APPLICATIONS, VOLS 1-3, P621; Ghahramani Z., 1997, EM ALGORITHM MIXTURE; Girolami M, 1998, NEURAL COMPUT, V10, P2103, DOI 10.1162/089976698300016981; GIROLAMI M, 1997, THESIS PAISLEY U SCO; GIROLAMI M, 1997, P IEEE INT C NEUR NE, P1788; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Lee T.W., 2000, P INT WORKSH IND COM, P239; Lee TW, 1999, ADV NEUR IN, V11, P508; Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719; Lee TW, 2000, COMPUT MATH APPL, V39, P1, DOI 10.1016/S0898-1221(00)00101-2; LEE TW, 1999, P INT WORKSH IND COM, P209; Lewicki MS, 1998, ADV NEUR IN, V10, P556; Lewicki MS, 1998, ADV NEUR IN, V10, P815; Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; MACKAY DJC, 1996, MAXIMUM LIKELIHOOD C; MERZ CJ, 1998, UCI REPOSITORY MACH; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PAPOULIS A, 1990, PROBABILITY STAT, V1; Pearlmutter B. A., 1996, Progress in Neural Information Processing. Proceedings of the International Conference on Neural Information Processing, P151; PEARSON K, 1894, PHIL T ROYAL SOC A, V185; Pham DT, 1997, IEEE T SIGNAL PROCES, V45, P1712, DOI 10.1109/78.599941; STUTZ J, 1994, MAXIMUM ENTROPY BAYE	37	120	126	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1078	1089		10.1109/34.879789	http://dx.doi.org/10.1109/34.879789			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ		Green Submitted			2022-12-18	WOS:000165067100002
J	Jain, AK; Zongker, D				Jain, AK; Zongker, D			Representation and recognition of handwritten digits using deformable templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digit recognition; deformable template; feature extraction; multidimensional scaling; clustering; nearest neighbor classification	CHARACTER-RECOGNITION; MODEL	We investigate the application of deformable templates to recognition of handprinted digits. Two characters are matched by deforming the contour of one to fit the edge strengths of the other, and a dissimilarity measure is derived from the amount of deformation needed, the goodness of fit of the edges, and the interior overlap between the deformed shapes. Classification using the minimum dissimilarity results in recognition rates up to 99.25 percent on a 2,000 character subset of NIST Special Database 1. Additional experiments on an independent test data were done to demonstrate the robustness of this method. Multidimensional scaling is also applied to the 2,000 x 2,000 proximity matrix, using the dissimilarity measure as a distance, to embed the patterns as points in low-dimensional spaces. A nearest neighbor classifier is applied to the resulting pattern matrices. The classification accuracies obtained in the derived feature space demonstrate that there does exist a good low-dimensional representation space. Methods to reduce the computational requirements, the primary limiting factor of this method, are discussed.	UNIV WASHINGTON, DEPT COMP SCI & ENGN, SEATTLE, WA 98195 USA	University of Washington; University of Washington Seattle	Jain, AK (corresponding author), MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA.							CASEY RG, 1970, IBM J RES DEV, V14, P548, DOI 10.1147/rd.145.0548; CHEUNG KW, 1995, P 2 AS C COMP VIS, V1, P344; GADER P, 1991, PATTERN RECOGN, V24, P421, DOI 10.1016/0031-3203(91)90055-A; GEIST J, 1988, 2 CENSUS OPTICAL CHA; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Kruskal JB, 1997, STAT METHODS DIGITAL, P296; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; NISHIDA H, 1995, PATTERN RECOGN, V28, P1611, DOI 10.1016/0031-3203(94)00025-H; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; SIMARD PY, 1994, INT C PATT RECOG, P262, DOI 10.1109/ICPR.1994.576916; *STAT SCI INC, 1993, S PLUS 3 2; SUEN CY, 1993, PATTERN RECOGN LETT, V14, P303, DOI 10.1016/0167-8655(93)90096-V; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906	16	120	122	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1386	1391		10.1109/34.643899	http://dx.doi.org/10.1109/34.643899			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781		Green Published			2022-12-18	WOS:A1997YK78100009
J	Nayar, SK; Watanabe, M; Noguchi, M				Nayar, SK; Watanabe, M; Noguchi, M			Real-time focus range sensor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						depth from defocus; constant magnification defocusing; active illumination pattern; optical transfer function; image sensing; tuned focus operator; depth estimation; real-time range sensor		Structures of dynamic scenes can only be recovered using a real-time range sensor. Depth from defocus offers an effective solution to fast and dense range estimation. However, accurate depth estimation requires theoretical and practical solutions to a variety of problems including recovery of textureless surfaces, precise blur estimation, and magnification variations caused by defocusing. Both textured and textureless surfaces are recovered using an illumination pattern that is projected via the same optical path used to acquire images. The illumination pattern is optimized to maximize accuracy and spatial resolution in computed depth. The relative blurring in two images is computed using a narrow-band linear operator that is designed by considering all the optical, sensing, and computational elements of the depth from defocus system. Defocus invariant magnification is achieved by the use of an additional aperture in the imaging optics. A prototype focus range sensor has been developed that has a workspace of 1 cubic foot and produces up to 512 x 480 depth estimates at 30 Hz with an average RMS error of 0.2%. Several experimental results are included to demonstrate the performance of the sensor.	HITACHI LTD, PROD ENGN RES LAB, TOTSUKA, JAPAN	Hitachi Limited	Nayar, SK (corresponding author), COLUMBIA UNIV, DEPT COMP SCI, NEW YORK, NY 10027 USA.							ASADA N, 1993, P AS C COMP VIS, P83; BESL RJ, 1988, GMR6090; Born M., 1968, PRINCIPLES OPTICS; BOVE VM, 1989, P OSA TROP M IM UND; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; Bracewell R, 1986, PENTAGRAM NOTATION C, V2nd, P192; Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282; Ens J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P600, DOI 10.1109/CVPR.1991.139760; GIROD B, 1989, P SPIE OPTICS ILLUM, V1194; GOKSTORP M, 1994, P INT C PATT REC OCT; GOKSTROP M, 1994, P INT C PATT REC OCT; GROSSMANN P, 1987, PATTERN RECOGN LETT, V5, P63, DOI 10.1016/0167-8655(87)90026-2; GRUSS A, 1993, P ARPA IM UND WORKSH, P977; Horn B., 1986, ROBOT VISION, P1; Horn Berthold K.P., 1968, FOCUSING; Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KANADE T, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1322, DOI 10.1109/ROBOT.1991.131796; Kingslake R., 1983, OPTICAL SYSTEM DESIG; KRISHNAN A, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P830; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; NAIR HN, 1988, P IEEE C COMP VIS PA, P309; NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479; NAYAR SK, 1995, P INT C COMP VIS, P995; PENTLAND A, 1994, J OPT SOC AM A, V11, P2925, DOI 10.1364/JOSAA.11.002925; Pentland A., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P256, DOI 10.1109/CVPR.1989.37858; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Subbarao M., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P149, DOI 10.1109/CCV.1988.589986; SUBBARAO M, 1992, P OE BOSTON 92 SPIE, V1822; WATANABE M, 1995, P SPE C PHIL PENN OC; WATANABE M, 1996, P EUR C COMP VIS CAM; WATANABE M, 1996, P IEEE C COMP VIS PA; WILLSON RG, 1994, CMURITR9403; XIONG Y, 1994, CMURITR9428 CARN MEL; XIONG Y, 1994, P IEEE C COMP VIS PA, P668; [No title captured]	36	120	153	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1186	1198		10.1109/34.546256	http://dx.doi.org/10.1109/34.546256			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000005
J	CLARK, JJ				CLARK, JJ			AUTHENTICATING EDGES PRODUCED BY ZERO-CROSSING ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CLARK, JJ (corresponding author), HARVARD UNIV,DIV APPL SCI,CAMBRIDGE,MA 02138, USA.			Clark, James/0000-0002-4512-6171				BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; Canny J. F., 1983, THESIS MIT CAMBRIDGE; CLARK JJ, 1987, 1ST P INT C COMP VIS, P491; CLARK JJ, IN PRESS IEEE T PATT; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUMMEL RA, 1984, 111 NEW YORK U COUR; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; RICE SO, 1945, AT&T TECH J, V24, P46, DOI 10.1002/j.1538-7305.1945.tb00453.x; RICHTER J, 1986, BIOL CYBERN, V53, P195, DOI 10.1007/BF00342887; Stoker JJ, 1969, DIFFERENTIAL GEOMETR; TORRE V, 1986, IEEE T PATTERN ANAL, V8; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; YUILLE AL, 1983, MIT AI722 MEM	15	120	127	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					43	57		10.1109/34.23112	http://dx.doi.org/10.1109/34.23112			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474					2022-12-18	WOS:A1989R447400004
J	MORI, S; YAMAMOTO, K; YASUDA, M				MORI, S; YAMAMOTO, K; YASUDA, M			RESEARCH ON MACHINE RECOGNITION OF HANDPRINTED CHARACTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									ELECTROTECH LAB,PATTERN PROC SECT,SAKURA,IBARAKI 305,JAPAN; HITACHI MICROCOMP LTD,SYST DESIGN SECT,KODAIRA,TOKYO 187,JAPAN	National Institute of Advanced Industrial Science & Technology (AIST)								AKAMATUS S, 1981, T IECE JAPAN PRL, V80, P93; AMBLER AP, 1973, 3RD P INT JOINT C AR, V6, P298; BABAGUCHI N, 1982, J IECE JAPAN D, V65, P874; BARROW HG, 1972, FRONTIERS PATTERN RE, P1; BJORKLUND CM, 1981, IEEE T PATTERN ANAL, V3, P144, DOI 10.1109/TPAMI.1981.4767072; Blesser B., 1973, 1st International Joint Conference on Pattern Recognition, P33; BURR DJ, 1981, COMPUT VISION GRAPH, V15, P102, DOI 10.1016/0146-664X(81)90072-1; CASEY R, 1966, IEEE TRANS ELECTRON, VEC15, P91, DOI 10.1109/PGEC.1966.264379; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DAVIS LS, 1977, IEEE T COMPUT, V26; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FUJII N, 1981, T IECE JAPAN, V81, P32; GLUCKSMAN HA, 1967, 1ST ANN IEEE COMP C, P137; GU YX, 1981, APPLICATION MULTILAY; HAGITA N, 1980, T IECE JAPAN PRL, V80, P23; HAGITA N, 1981, T IECE JAPAN PRL, V81, P13; HAGITA N, 1980, J IECE JAPAN D, V63, P1096; Iijima T., 1972, 1st USA-Japan Computer Conference Proceedings, P42; IIJIMA T, 1971, J IECE JAPAN C, V54, P641; Kasvand T., 1979, Proceedings of the International Conference on Cybernetics and Society, P674; KIMURA F, 1980, J IECE JAPAN D, V63, P414; KIMURA F, 1978, J IECE JAPAN D, V61, P496; Kobayashi K., 1981, T IECE JAPAN, P81; KUROSAWA Y, 1981, OCT P IECE JAP ANN C, pI79; MAEDA K, 1982, 6TH P INT JOINT C PA, P789; MORI K, 1980, 5TH P INT JOINT C PA, P652; Mori S., 1979, Bulletin of the Electrotechnical Laboratory, V43, P752; MORI S, 1982, SEP P INT CHIN LANG, P373; MORI S, 1983, T IECE JAPAN PRL, V83, P12; MORI S, 1974, 2ND P INT JOINT C PA, P233; MURASE H, 1981, J IECE JAPAN D, V64, P276; NAITO S, 1981, J IECE JAPAN J, V64, P757; Nakata K., 1972, Proceedings of the Conference on Machine Perception of Patterns and Pictures, P45; OGAWA H, 1980, T IECE JAPAN PRL, V80, P40; OGAWA H, 1975, P INT COMP S TAIP, V1, P411; OGAWA H, 1981, T IECE JAPAN PRL, V80, P5; OGI H, 1979, J INFORM PROCESSING, V20, P501; OKA R, 1982, J IECE JAPAN D, V65, P1219; OKA R, 1982, 1982 P INT C CHIN LA, P399; OKA R, 1982, 6TH P INT JOINT C PA, P783; OKABE N, 1976, J IECE JAPAN D, V59, P858; PAVLIDIS T, 1979, P IEEE, V67, P737, DOI 10.1109/PROC.1979.11323; PAVLIDIS T, 1968, PATTERN RECOGN, V1, P165, DOI 10.1016/0031-3203(68)90006-X; PAVLIDIS T, 1982, COMPUT VISION GRAPH, V20, P133, DOI 10.1016/0146-664X(82)90041-7; PAVLIDIS T, 1975, IEEE T SYST MAN CYBE, V5; PAVLIDIS T, 1977, STRUCTURAL PATTERN R, pCH7; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SAITO T, 1982, J IECE JAPAN D, V65, P550; Saito T., 1980, B ETL, V44, P219; Sakai K., 1976, 3rd International Joint Conference on Pattern Recognition, P122; SAKAI K, 1973, T IECE JAPAN PRL, V73, P14; SAKOE H, 1974, T IECE JAPAN PRL, V74, P20; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHI QY, 1982, TREE821 PURD U; SHIO A, 1980, T IECE JAPAN IE, V80, P83; STALLINGS WW, 1972, COMPUT GRAPH IMAGE P, V1, P44; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; TAKAHASHI H, 1982, T IECE JAPAN PRL, V82, P57; TAKAHASHI H, 1982, T IECE JAPAN PRL, V82, P8; TAKAHASHI T, 1980, T IECE JAPAN PRL, V80, P24; WAKAYAMA T, 1982, IEEE T PATTERN ANAL, V4, P68, DOI 10.1109/TPAMI.1982.4767198; YAMADA H, 1981, J IECE JAPAN D, V64, P970; YAMADA H, 1983, P ANNU C IECE, P1377; YAMAMOTO K, 1980, PATTERN RECOGN, V12, P229, DOI 10.1016/0031-3203(80)90062-X; YAMAMOTO K, 1982, 6TH P INT C PATT REC, P395; YAMAMOTO K, 1983, RES ELECTROTECH  FEB; YAMAMOTO K, 1982, J IECE JAPAN D, V65, P774; YAMAMOTO K, 1982, J IECE JAPAN D, V65, P1167; YAMASHITA Y, 1982, T IECE JAPAN PRL, V81, P93; YAMASHITA Y, 1982, T IECE JAPAN PRL, V82, P12; YASUDA M, 1983, J AVIRG, V18, P2; YASUDA M, 1979, J IECE JAPAN J D, V62, P217; Yasuda M., COMMUNICATION; YASUDA M, 1984, J JIECE D, V67, P224; Yoshida M., 1973, 1st International Joint Conference on Pattern Recognition, P197; 1981, NIKKEI ELECTRON, V12, P148	77	120	125	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					386	405		10.1109/TPAMI.1984.4767545	http://dx.doi.org/10.1109/TPAMI.1984.4767545			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869208				2022-12-18	WOS:A1984SY28900001
J	SUEN, CY				SUEN, CY			N-GRAM STATISTICS FOR NATURAL-LANGUAGE UNDERSTANDING AND TEXT PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review									MIT, ELECTR RES LAB, CAMBRIDGE, MA 02139 USA	Massachusetts Institute of Technology (MIT)	SUEN, CY (corresponding author), CONCORDIA UNIV, DEPT COMP SCI, MONTREAL H3G 1M8, QUEBEC, CANADA.							ABORN M, 1959, J EXP PSYCHOL, V57, P171, DOI 10.1037/h0040521; ALBERGA CN, 1967, COMMUN ACM, V10, P302, DOI 10.1145/363282.363326; ALTER R, 1968, IEEE T ACOUST SPEECH, VAU16, P6, DOI 10.1109/TAU.1968.1161943; [Anonymous], 1959, P E JOINT COMP C, DOI DOI 10.1145/1460299.1460326; ASCHER RN, 1971, IEEE T COMPUT, VC 20, P1527, DOI 10.1109/T-C.1971.223166; ATTAR R, 1978, J ACM, V25, P52, DOI 10.1145/322047.322052; BADDELEY AD, 1960, NATURE, V186, P414, DOI 10.1038/186414a0; BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; BAKER L, 1977, MEM COGNITION, V5, P308, DOI 10.3758/BF03197575; Blair CR., 1960, INF CONTROL, V3, P60; BOURNE CP, 1961, INFORM CONTROL, V4, P48, DOI 10.1016/S0019-9958(61)80036-3; CARLSON G, 1966, SPR P JOINT COMP C, P189; CARROLL JB, 1968, LANGUAGE LANGUAGE BE, P213; CARROLL JB, 1971, WORD FREQUENCY BOOK; Carroll JohnB., 1967, COMPUTATIONAL ANAL P; CARTERETTE EC, 1963, SCIENCE, V140, P1309, DOI 10.1126/science.140.3573.1309; CASEY RG, 1968, IEEE T COMPUT, VC 17, P492, DOI 10.1109/TC.1968.226928; CHRISTENSEN CS, 1968, AFOSR682470 CORN U C; CONRAD C, 1974, MEM COGNITION, V2, P130, DOI 10.3758/BF03197504; CORNEW RW, 1968, INFORM CONTROL, V12, P79, DOI 10.1016/S0019-9958(68)90201-5; DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994; DAVIDSON L, 1962, COMMUN ACM, V5, P169, DOI 10.1145/366862.366913; Dewey G., 1923, RELATIVE FREQUENCY E; DONALDSON RW, 1970, IEEE T COMPUT, VC 19, P1096, DOI 10.1109/T-C.1970.222839; DOSTER W, 1977, IEEE T COMPUT, V26, P1090, DOI 10.1109/TC.1977.1674755; DUDA RO, 1968, FAL P JOINT COMP C, P1139; EDWARDS AW, 1964, J ACM, V11, P465, DOI 10.1145/321239.321247; Ehrich R. W., 1973, 1st International Joint Conference on Pattern Recognition, P169; EHRICH RW, 1975, IEEE T COMPUT, VC 24, P182, DOI 10.1109/T-C.1975.224184; FISHER EG, 1976, THESIS U MASSACHUSET; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GAINES HF, 1956, CRYPTANALYSIS, P218; GIANGARDELLA JJ, 1967, IEEE T PROF COMMUN, VEW10, P57, DOI 10.1109/TEWS.1967.4322306; HAHN PM, 1972, OCT P INT C CYB SOC, P512; HANSON AR, 1976, PATTERN RECOGN, V8, P35, DOI 10.1016/0031-3203(76)90027-3; HARMON LD, 1965, Patent No. 3188609; Herdan G., 1966, ADV THEORY LANGUAGE; HOSHINO Y, 1977, Patent No. 4010445; HUSSAIN ABS, 1974, IEEE T COMPUT, VC 23, P582, DOI 10.1109/T-C.1974.223998; JAMES EB, 1973, COMMUN ACM, V16, P27, DOI 10.1145/361932.361940; KOLERS PA, 1966, LANG SPEECH, V9, P84, DOI 10.1177/002383096600900202; KOROLEV E, 1971, P INT C COMPUT LING; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; MAYZNER MS, 1965, PSYCHONOMIC MONOGR S, V1, P13; MAYZNER MS, 1965, PSYCHONOMIC MONOGR S, V1, P33; MCCALLA GI, 1972, COMMUN ACM, V15, P29, DOI 10.1145/361237.361247; MCELWAIN CK, 1962, INFORM CONTROL, V5, P368, DOI 10.1016/S0019-9958(62)90657-5; MEUNIER JG, 1976, COMPUT HUMANITIES, V10, P281, DOI 10.1007/BF02420062; MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491; MILLER GA, 1957, INFORM CONTR, V1, P38; MORGAN HL, 1970, COMMUN ACM, V13, P90, DOI 10.1145/362007.362033; MORRIS R, 1975, IEEE T PROF COMMUN, VPC18, P54, DOI 10.1109/TPC.1975.6593963; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; Newman E.B.., 1960, INFORM CONTROL, V3, P141, DOI [https://doi.org/10.1016/S0019-9958(60)90731-2, DOI 10.1016/S0019-9958(60)90731-2]; NEWMAN EB, 1952, J EXP PSYCHOL, V44, P114, DOI 10.1037/h0055693; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; PRATT F, 1939, SECRET URGENT STORY, P252; RAVIV J, 1967, IEEE T INFORM THEORY, V13, P536, DOI 10.1109/TIT.1967.1054060; RIEGER C, 1976, ARTIF INTELL, V7, P89, DOI 10.1016/0004-3702(76)90001-1; RISEMAN EM, 1971, IEEE T COMPUT, VC 20, P397, DOI 10.1109/T-C.1971.223255; RISEMAN EM, 1974, IEEE T COMPUT, VC 23, P480, DOI 10.1109/T-C.1974.223971; ROSENBAUM WS, 1975, IBM J RES DEV, V19, P398, DOI 10.1147/rd.194.0398; RUSTIN R, 1973, NATURAL LANGUAGE PRO; SALTON G, 1976, COMPUT HUMANITIES, V10, P69, DOI 10.1007/BF02426255; Schurmann J., 1976, 3rd International Joint Conference on Pattern Recognition, P658; SETH V, 1977, JUN P AFIPS, P779; SHIMURA M, 1973, PATTERN RECOGN, V5, P149, DOI 10.1016/0031-3203(73)90019-8; SHINGHAL R, 1978, IEEE T SYST MAN CYB, V8, P412; SHINGHAL R, 1977, THESIS MCGILL U; SHINGHAL R, 1977, 5TH P INT JOINT C AR, V1, P179; SILVA G, 1969, INFORM STORAGE RET, V5, P89, DOI 10.1016/0020-0271(69)90014-X; SMITH F, 1969, J VERB LEARN VERB BE, V8, P215, DOI 10.1016/S0022-5371(69)80064-2; SOLSO RL, 1976, BEHAV RES METH INSTR, V8, P283, DOI 10.3758/BF03201714; SUEN CY, 1977, IEEE T SYST MAN CYB, V7, P491; SUEN CY, 1973, IEEE T BIO-MED ENG, VBM20, P452, DOI 10.1109/TBME.1973.324219; SUEN CY, 1976, JUN P JOINT WORKSH P, P98; SUEN CY, 1976, JUN P AFIPS, P217; SUEN CY, 1978, 4TH P INT JOINT C PA; SYMONDS M, 1970, ERB843 NAT RES COUNC; SZANSER AJ, 1970, INFORM STORAGE RET, V5, P169, DOI 10.1016/0020-0271(70)90045-8; SZANSER AJ, 1970, REV APPL LINGUIST, V7, P49; SZANSER AJ, 1973, 63 NAT PHYS LAB TECH; SZANSER AJ, 1970, STATISTICAL METHODS, V6, P52; SZANSER AJ, 1971, 53 NAT PHYS LAB TECH; SZANSER AJ, 1969, P IFIP, V2, P1412; TANAKA E, 1972, ELECTRON COMMUN JPN, V55, P127; THOMAS RB, 1967, INFORM CONTROL, V10, P43, DOI 10.1016/S0019-9958(67)90042-3; THOMPSON RA, 1976, IEEE T COMPUT, V25, P275, DOI 10.1109/TC.1976.5009254; THORELLI LE, 1962, BIT NUMERICAL MATH, V0002, P00045, DOI [DOI 10.1007/BF02024781, 10.1007/BF02024781]; Thorndike E. L., 1944, TEACHERS WORD BOOK 3; TOPPER GE, 1973, BEHAV RES METH INSTR, V5, P51, DOI 10.3758/BF03200121; TOUSSAINT GT, 1972, P CANADIAN COMPUT C; TOUSSAINT GT, 1977, JUN P IEEE COMP SOC, P1; TOUSSAINT GT, 1974, 2ND INT J C PATT REC, P479; TULVING E, 1963, J EXP PSYCHOL, V66, P319, DOI 10.1037/h0048802; ULLMANN JR, 1977, COMPUT J, V20, P141, DOI 10.1093/comjnl/20.2.141; Underwood B.J., 1960, MEANINGFULNESS VERBA; VOSSLER CM, 1964, AUG P NAT ASS COMP M; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WEIZENBAUM J, 1967, COMMUN ACM, V10, P474, DOI 10.1145/363534.363545; WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8; Winograd Terry, 1972, UNDERSTANDING NATURA; ZIPF GK, 1949, HUMAN BEHAVIOR PRINC	104	120	124	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					164	172		10.1109/TPAMI.1979.4766902	http://dx.doi.org/10.1109/TPAMI.1979.4766902			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868845				2022-12-18	WOS:A1979HA30400006
J	Ranftl, R; Lasinger, K; Hafner, D; Schindler, K; Koltun, V				Ranftl, Rene; Lasinger, Katrin; Hafner, David; Schindler, Konrad; Koltun, Vladlen			Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Estimation; Three-dimensional displays; Cameras; Videos; Measurement; Motion pictures; Monocular depth estimation; single-image depth prediction; zero-shot cross-dataset transfer; multi-dataset training		The success of monocular depth estimation relies on large and diverse training sets. Due to the challenges associated with acquiring dense ground-truth depth across different environments at scale, a number of datasets with distinct characteristics and biases have emerged. We develop tools that enable mixing multiple datasets during training, even if their annotations are incompatible. In particular, we propose a robust training objective that is invariant to changes in depth range and scale, advocate the use of principled multi-objective learning to combine data from different sources, and highlight the importance of pretraining encoders on auxiliary tasks. Armed with these tools, we experiment with five diverse training datasets, including a new, massive data source: 3D films. To demonstrate the generalization power of our approach we use zero-shot cross-dataset transfer, i.e. we evaluate on datasets that were not seen during training. The experiments confirm that mixing data from complementary sources greatly improves monocular depth estimation. Our approach clearly outperforms competing methods across diverse datasets, setting a new state of the art for monocular depth estimation.	[Ranftl, Rene; Hafner, David] Intel Labs, Intelligent Syst Lab, D-85579 Munich, Germany; [Koltun, Vladlen] Intel Labs, Intelligent Syst Lab, Santa Clara, CA 95054 USA; [Lasinger, Katrin; Schindler, Konrad] ETH, Inst Geodesy & Photogrammetry, CH-8093 Zurich, Switzerland	Intel Corporation; Intel Corporation; Swiss Federal Institutes of Technology Domain; ETH Zurich	Ranftl, R (corresponding author), Intel Labs, Intelligent Syst Lab, D-85579 Munich, Germany.	rene.ranftl@intel.com; katrin.lasinger@geod.baug.ethz.ch; david.hafner@intel.com; konrad.schindler@geod.baug.ethz.ch; vladlen.koltun@intel.com		Lasinger, Katrin/0000-0002-9329-2916				Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Casser V, 2019, AAAI CONF ARTIF INTE, P8001; Chen Weifeng, 2016, NEURIPS, P2, DOI DOI 10.5555/3157096.3157178; Cho J., 2019, ARXIV190410230; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devernay F, 2010, GEOM COMPUT, V5, P11, DOI 10.1007/978-3-642-12392-4_2; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Facil JM, 2019, PROC CVPR IEEE, P11818, DOI 10.1109/CVPR.2019.01210; Fankhauser P, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P388, DOI 10.1109/ICAR.2015.7251485; FFmpeg developers, 2018, FFMPEG; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907; Guo XY, 2018, LECT NOTES COMPUT SC, V11215, P506, DOI 10.1007/978-3-030-01252-6_30; Hadfield S, 2017, INT J COMPUT VISION, V121, P95, DOI 10.1007/s11263-016-0917-2; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hertzmann A, 2020, PERCEPTION, V49, P439, DOI 10.1177/0301006620908207; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835; Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437; Kim Y, 2018, IEEE T IMAGE PROCESS, V27, P4131, DOI 10.1109/TIP.2018.2836318; Kingma D. P., 2015, P P INT C LEARN REPR; Knapitsch Arno, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3072959.3073599; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Li RB, 2019, LECT NOTES COMPUT SC, V11364, P663, DOI 10.1007/978-3-030-20870-7_41; Li ZQ, 2019, PROC CVPR IEEE, P4516, DOI 10.1109/CVPR.2019.00465; Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024; Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12; Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Neuman R, 2009, STEREOSCOPIC DISPLAY, V7237; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Sener O, 2018, ADV NEUR IN, V31; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012; Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596; Vasiljevic Igor, 2019, ARXIV190800463; Wang CY, 2019, INT CONF 3D VISION, P348, DOI 10.1109/3DV.2019.00046; Weifeng Chen, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5597, DOI 10.1109/CVPR.2019.00575; Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040; Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhou B, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aaw6661; Zhou Qian-Yi, 2018, ARXIV180109847; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700	65	119	119	25	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1623	1637		10.1109/TPAMI.2020.3019967	http://dx.doi.org/10.1109/TPAMI.2020.3019967			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32853149	hybrid, Green Published, Green Submitted			2022-12-18	WOS:000752018000039
J	Lindner, C; Bromiley, PA; Ionita, MC; Cootes, TF				Lindner, Claudia; Bromiley, Paul A.; Ionita, Mircea C.; Cootes, Tim F.			Robust and Accurate Shape Model Matching Using Random Forest Regression-Voting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; Random Forests; Constrained Local Models; statistical shape model; feature point detection	HOUGH FORESTS; LOCALIZATION	A widely used approach for locating points on deformable objects in images is to generate feature response images for each point, and then to fit a shape model to these response images. We demonstrate that Random Forest regression-voting can be used to generate high quality response images quickly. Rather than using a generative or a discriminative model to evaluate each pixel, a regressor is used to cast votes for the optimal position of each point. We show that this leads to fast and accurate shape model matching when applied in the Constrained Local Model framework. We evaluate the technique in detail, and compare it with a range of commonly used alternatives across application areas: the annotation of the joints of the hands in radiographs and the detection of feature points in facial images. We show that our approach outperforms alternative techniques, achieving what we believe to be the most accurate results yet published for hand joint annotation and state-of-the-art performance for facial feature point detection.	[Lindner, Claudia; Bromiley, Paul A.; Ionita, Mircea C.; Cootes, Tim F.] Univ Manchester, Ctr Imaging Sci, Manchester, Lancs, England	University of Manchester	Lindner, C (corresponding author), Univ Manchester, Ctr Imaging Sci, Manchester, Lancs, England.	claudia.lindner@manchester.ac.uk	Lindner, Claudia/F-8971-2014	Lindner, Claudia/0000-0001-9396-3436; Bromiley, Paul/0000-0003-4901-107X; Cootes, Timothy/0000-0002-2695-9063	Medical Research Council, UK [G1000399-1/1]; Medical Research Council [973611] Funding Source: researchfish	Medical Research Council, UK(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)); Medical Research Council(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)European Commission)	The work of C. Lindner was supported by the Medical Research Council, UK (G1000399-1/1). The authors would like to thank K. Ward, R. Ashby, Z. Mughal and Prof. J. Adams for providing the hand radiographs, S. Adeshina for the hand annotations, and H. Yang for providing the data from [43] (Fig. 13). C. Lindner is the corresponding author of the article.	BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21; Covell M, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P122, DOI 10.1109/AFGR.1996.557253; Criminisi A, 2013, MED IMAGE ANAL, V17, P1293, DOI 10.1016/j.media.2013.01.001; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Donner Rene, 2013, Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging. Second International MICCAI Workshop, MCV 2012. Revised Selected Papers, P133, DOI 10.1007/978-3-642-36620-8_14; Donner R, 2013, MED IMAGE ANAL, V17, P1304, DOI 10.1016/j.media.2013.02.004; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740; Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Konukoglu E, 2013, MED IMAGE ANAL, V17, P790, DOI 10.1016/j.media.2013.04.013; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Lindner C, 2013, IEEE T MED IMAGING, V32, P1462, DOI 10.1109/TMI.2013.2258030; Lindner C, 2013, LECT NOTES COMPUT SC, V8150, P181, DOI 10.1007/978-3-642-40763-5_23; Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205; Milborrow S, 2014, VISAPP, V1, P5, DOI DOI 10.1109/ICCVW.2013.57; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37; Nicolle J., 2013, P INT C IM PROC, P501; Saragih J, 2007, IEEE I CONF COMP VIS, P2173; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Sauer P, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.30; Schroff F., P BRIT MACH VIS C 20, DOI DOI 10.5244/C.22.54; Schulter S, 2013, IEEE I CONF COMP VIS, P417, DOI 10.1109/ICCV.2013.59; Schulter S, 2013, PROC CVPR IEEE, P508, DOI 10.1109/CVPR.2013.72; Sheerman-Chase T., 2013, P FG, P1; SHOTTON J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI DOI 10.1109/TPAMI.2012.241; Tresadern P., 2010, P BRIT MACH VIS C; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang H, 2013, IEEE I CONF COMP VIS, P1936, DOI 10.1109/ICCV.2013.243; Zhou F, 2013, IEEE I CONF COMP VIS, P1025, DOI 10.1109/ICCV.2013.131; Zhou SK, 2007, LECT NOTES COMPUT SC, V4584, P13	42	119	131	2	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1862	1874		10.1109/TPAMI.2014.2382106	http://dx.doi.org/10.1109/TPAMI.2014.2382106			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353132				2022-12-18	WOS:000359216600010
J	Kohli, P; Torr, PHS				Kohli, Pushmeet; Torr, Philip H. S.			Dynamic graph cuts for efficient inference in Markov random fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						energy minimization; Markov random fields; dynamic graph cuts; maximum flow; st-mincut; video segmentation	ENERGY MINIMIZATION; EXTRACTION	In this paper, we present a fast new fully dynamic algorithm for the st-mincut/ max- flow problem. We show how this algorithm can be used to efficiently compute MAP solutions for certain dynamically changing MRF models in computer vision such as image segmentation. Specifically, given the solution of the max- flow problem on a graph, the dynamic algorithm efficiently computes the maximum flow in a modified version of the graph. The time taken by it is roughly proportional to the total amount of change in the edge weights of the graph. Our experiments show that, when the number of changes in the graph is small, the dynamic algorithm is significantly faster than the best known static graph cut algorithm. We test the performance of our algorithm on one particular problem: the object- background segmentation problem for video. It should be noted that the application of our algorithm is not limited to the above problem, the algorithm is generic and can be used to yield similar improvements in many other cases that involve dynamic change.	Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England	Oxford Brookes University	Kohli, P (corresponding author), Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England.	pushmeet.kohli@brookes.ac.uk; philiptorr@brookes.ac.uk			Engineering and Physical Sciences Research Council [GR/T21790/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Ahuja R. K., 1993, NETWORK FLOWS THEORY; BLAKE A, 2004, P ECCV, V1, P428; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; BOYKOV Y, 2001, P INT C COMP VIS, P1; Bray M, 2006, LECT NOTES COMPUT SC, V3952, P642; CHIANG YJ, 1992, P IEEE, V80, P1412, DOI 10.1109/5.163409; COHEN RF, 1991, PROCEEDINGS OF THE SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P52; Dinitz Y, 1970, DOKL AKAD NAUK SSSR, V11, P1277; Ford L. R. J., 1962, FLOWS NETWORKS; Freedman D, 2005, PROC CVPR IEEE, P939; GALLO G, 1989, SIAM J COMPUT, V18, P30, DOI 10.1137/0218003; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; HENGEL A, 2006, P EUROGRAPHICS; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Ishikawa H, 1998, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.1998.698598; ISHIKAWA H, 1998, P EUR C COMP VIS, P232; Juan O., 2006, P IEEE COMP SOC C CO, V1, P1023, DOI [DOI 10.1109/CVPR.2006.47, 10.1109/CVPR.2006.47]; Kohli P, 2005, IEEE I CONF COMP VIS, P922; Kohli P, 2006, LECT NOTES COMPUT SC, V3952, P30; Kolmogorov V, 2005, IEEE I CONF COMP VIS, P564; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; KOLMOGOROV V, 2002, P EUR C COMP VIS; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kumar M., 2004, P IND C COMP VIS GRA, P158; Kumar MP, 2005, PROC CVPR IEEE, P18; LI S, 2001, M RANDOM FIELD MODEL; RAJ A, 2005, P INT C COMP VIS; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; SCHLESINGER MI, 2000, P CZECH PATT REC WOR; SNOW P, 2000, EXACT VOXEL OCCUPANC, P345; Thorup M., 2001, P 33 STOC, P224; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233; Xiao JJ, 2004, PROC CVPR IEEE, P972; Zabih R, 2004, PROC CVPR IEEE, P437	38	119	132	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2079	2088		10.1109/TPAMI.2007.1128	http://dx.doi.org/10.1109/TPAMI.2007.1128			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934219	Green Submitted			2022-12-18	WOS:000250087900002
J	Keysers, D; Deselaers, T; Gollan, C; Ney, H				Keysers, Daniel; Deselaers, Thomas; Gollan, Christian; Ney, Hermann			Deformation models for image recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image matching; image alignment; character recognition; medical image categorization		We present the application of different nonlinear image deformation models to the task of image recognition. The deformation models are especially suited for local changes as they often occur in the presence of image object variability. We show that, among the discussed models, there is one approach that combines simplicity of implementation, low-computational complexity, and highly competitive performance across various real-world image recognition tasks. We show experimentally that the model performs very well for four different handwritten digit recognition tasks and for the classification of medical images, thus showing high generalization capacity. In particular, an error rate of 0.54 percent on the MNIST benchmark is achieved, as well as the lowest reported error rate, specifically 12.6 percent, in the 2005 international ImageCLEF evaluation of medical image categorization.	DFKI GmbH, German Res Ctr Artificial Intelligence, Image Understanding & Pattern Recognit Grp, D-67663 Kaiserslautern, Germany; Rhein Westfal TH Aachen, Lehrstuhl Informat 6, Dept Comp Sci, D-52056 Aachen, Germany	German Research Center for Artificial Intelligence (DFKI); RWTH Aachen University	Keysers, D (corresponding author), DFKI GmbH, German Res Ctr Artificial Intelligence, Image Understanding & Pattern Recognit Grp, D-67663 Kaiserslautern, Germany.	daniel.keysers@dfki.de; deselaers@informatik.rwth-aachen.de; gollan@informatik.rwth-aachen.de; ney@informatik.rwth-aachen.de						Alpaydin E, 1998, KYBERNETIKA, V34, P369; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bishop CM, 2000, LECT NOTES COMPUT SC, V1842, P3; Botto H, 1994, Prog Urol, V4, P77; BURR DJ, 1981, COMPUT VISION GRAPH, V15, P102, DOI 10.1016/0146-664X(81)90072-1; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; Cai JH, 1999, IEEE T PATTERN ANAL, V21, P263, DOI 10.1109/34.754622; Clough P., 2005, P CLEF 2005 WORKSH W; Dahmen J, 2001, J MATH IMAGING VIS, V14, P285, DOI 10.1023/A:1011242314266; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DONG J, 2003, THESIS CONCORDIA U M; DONG JX, 2002, P INT C PATT REC AUG, V3; DONG JX, 2001, STAT RESULTS HUMAN; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P705, DOI 10.1142/S0218001493000352; Glasbey CA, 1998, J APPL STAT, V25, P155, DOI 10.1080/02664769823151; Haasdonk B, 2004, INT C PATT RECOG, P769, DOI 10.1109/ICPR.2004.1334372; Haasdonk B, 2002, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2002.1048439; Hastie T, 1998, STAT SCI, V13, P54; HINTON GE, 1992, ADV NEUR IN, V4, P512; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Keysers D, 2004, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2004.1333823; Keysers D, 2004, LECT NOTES COMPUT SC, V3175, P154; Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198; Keysers D, 2003, PATTERN RECOGN LETT, V24, P445, DOI 10.1016/S0167-8655(02)00268-4; Keysers D, 2000, INT C PATT RECOG, P38, DOI 10.1109/ICPR.2000.906014; KEYSERS D, 2004, P BVM 2004 BILDV MED, P366; KEYSERS D, 2002, P INT WORKSH STAT PA, P538; Kim HC, 2002, PATTERN RECOGN LETT, V23, P103, DOI 10.1016/S0167-8655(01)00093-9; Knuth DE., 1994, STANFORD GRAPHBASE P; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI DOI 10.1111/DSU.12130; Lehmann TM, 2004, METHOD INFORM MED, V43, P354; LEVIN E, 1992, P ICASSP, V3, P149; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3203(03)00085-2; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Maree R., 2004, P 6 ASIAN C COMPUTER, P860; Mayraz G, 2002, IEEE T PATTERN ANAL, V24, P189, DOI 10.1109/34.982899; Merz C.J., 1997, UCI REPOSITORY MACHI; MILGRAM J, 2005, ELECT LETT COMPUTER, V5, P1; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; Perronnin F, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P329; Ronee MA, 2001, PROC INT CONF DOC, P39, DOI 10.1109/ICDAR.2001.953751; Scholkopf Bernhard, 1997, SUPPORT VECTOR LEARN; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Simard PY, 2003, PROC INT CONF DOC, P958; SMITH SJ, 1994, IEEE T PATTERN ANAL, V16, P915, DOI 10.1109/34.310689; Teow LN, 2002, PATTERN RECOGN, V35, P2355, DOI 10.1016/S0031-3203(01)00228-X; TEOW LN, 2000, P IEEE C COMP VIS PA, V2, P76; Tipping M. E., 2000, ADV NEURAL INFORM PR, V12, P332; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Uchida S, 2005, IEICE T INF SYST, VE88D, P1781, DOI 10.1093/ietisy/e88-d.8.1781; Uchida S, 2003, PATTERN RECOGN, V36, P2031, DOI 10.1016/S0031-3203(03)00039-6; Uchida S, 1998, INT C PATT RECOG, P521, DOI 10.1109/ICPR.1998.711195; Umeda M, 1996, IEICE T INF SYST, VE79D, P401; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Zahedi M, 2005, LECT NOTES COMPUT SC, V3663, P401	58	119	136	11	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1422	1435		10.1109/TPAMI.2007.1153	http://dx.doi.org/10.1109/TPAMI.2007.1153			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568145				2022-12-18	WOS:000247186500010
J	Zimmer, C; Olivo-Marin, JC				Zimmer, C; Olivo-Marin, JC			Coupled parametric active contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; tracking; active contours; topology; 2D video	LEVEL SET METHOD; IMAGE SEGMENTATION; TRACKING; SHAPE; ALGORITHMS; CELLS	We propose an extension of parametric active contours designed to track nonoccluding objects transiently touching each other, a task where both parametric and single level set-based methods usually fail. Our technique minimizes a cost functional that depends on all contours simultaneously and includes a penalty for contour overlaps. This scheme allows us to take advantage of known constraints on object topology, namely, that objects cannot merge. The coupled contours preserve the identity of previously isolated objects during and after a contact event, thus allowing segmentation and tracking to proceed as desired.	Inst Pasteur, Quantitat Image Anal Grp, F-75015 Paris, France	Le Reseau International des Instituts Pasteur (RIIP); Institut Pasteur Paris	Zimmer, C (corresponding author), Inst Pasteur, Quantitat Image Anal Grp, 25 Rue Dr Roux, F-75015 Paris, France.	czimmer@pasteur.fr; jcolivo@pasteur.fr	Olivo-Marin, Jean-Christophe/K-4428-2015	Olivo-Marin, Jean-Christophe/0000-0001-6796-0696				ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; Delingette H, 2001, COMPUT VIS IMAGE UND, V83, P140, DOI 10.1006/cviu.2001.0920; Dufour A, 2005, IEEE T IMAGE PROCESS, V14, P1396, DOI 10.1109/TIP.2005.852790; Han X, 2003, IEEE T PATTERN ANAL, V25, P755, DOI 10.1109/TPAMI.2003.1201824; Jacob M, 2004, IEEE T IMAGE PROCESS, V13, P1231, DOI 10.1109/TIP.2004.832919; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; Malladi R, 1996, IEEE T IMAGE PROCESS, V5, P1554, DOI 10.1109/83.541425; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OROURKE J, 1993, COMPUTATIONAL GEOMET; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; PARAGIOS N, 2001, EUR C COMP VIS, P22; Ray N, 2002, IEEE T MED IMAGING, V21, P1222, DOI 10.1109/TMI.2002.806291; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Sebastian TB, 2003, MED IMAGE ANAL, V7, P21, DOI 10.1016/S1361-8415(02)00065-8; Sethian J. A., 1999, LEVEL SET METHODS FA; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; Zhang B, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P476; Zimmer C, 2002, IEEE T MED IMAGING, V21, P1212, DOI 10.1109/TMI.2002.806292	26	119	125	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1838	1842		10.1109/TPAMI.2005.214	http://dx.doi.org/10.1109/TPAMI.2005.214			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285382				2022-12-18	WOS:000231826300014
J	Umeyama, S; Godin, G				Umeyama, S; Godin, G			Separation of diffuse and specular components of surface reflection by use of polarization and statistical analysis of images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						probabilistic independence; mutual information; independent component analysis; diffuse reflection; specular reflection; polarization-based methods	COLOR	The image of an opaque object is created by observing the reflection of the light incident on its surface. The clichromatic reflection model describes the surface reflection as the sum of two components, diffuse and specular terms. The specular reflection component is usually strong in its intensity and polarized significantly compared to the diffuse components. On the other hand, the intensity of the diffuse component is weak and it tends to be unpolarized except near occluding contours. Thus, the observation of an object through a rotating polarizer approximately yields images containing constant diffuse component and specular component of different intensity. In this paper, we show that diffuse and specular components of surface reflection can be separated as two independent components when we apply Independent Component Analysis to the images observed through a polarizer of different orientations. We give a separation simulation of artificial data and also give some separation results of real scenes.	Natl Inst Adv Ind Sci & Technol, Inst Neurosci, Tsukuba, Ibaraki 3058568, Japan; Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada	National Institute of Advanced Industrial Science & Technology (AIST); National Research Council Canada	Umeyama, S (corresponding author), Natl Inst Adv Ind Sci & Technol, Inst Neurosci, Tsukuba Cent 2, Tsukuba, Ibaraki 3058568, Japan.	s.umeyama@aist.go.jp; guy.godin@nrc-cnrc.gc.ca						Bartlett M. S., 2001, FACE IMAGE ANAL UNSU; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bronstein A.M., 2003, P S IND COMP AN BLIN, P227; Farid H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P262, DOI 10.1109/CVPR.1999.786949; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Jenkins F.A., 1957, FUNDAMENTALS OPTICS, V4th; Klinker G. J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P145; KODAMA S, 1979, MATRIX THEORY SYSTEM; MAKEIG S, 1996, ADV NEURAL INFORMATI, V8; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; SATO Y, 1997, P SIGGRAPH 97, P379; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Umeyama S., 2003, P 4 INT S IND COMP A, P319; Wolff L. B., 1989, P IEEE C COMP VIS PA, V1, P363, DOI DOI 10.1109/CVPR.1989.37873; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; YAMAGUCHI I, 1998, APPL OPTICS	22	119	129	4	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					639	647		10.1109/TPAMI.2004.1273960	http://dx.doi.org/10.1109/TPAMI.2004.1273960			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460284				2022-12-18	WOS:000220756400008
J	Jurie, F; Dhome, M				Jurie, F; Dhome, M			Hyperplane approximation for template matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual tracking; motion estimation	TRACKING; ILLUMINATION; MODELS	Hager and Belhumeur [6] recently proposed a general framework for object tracking in video images. It consists of low-order parametric models for the image motion of a target region. These models are used to predict movement and to track the target. The difference in intensity between the pixels belonging to the current region and the pixels of the selected target (learned during an offline stage) allows a straightforward prediction of the region position in the current image. The main aim of this article is to propose an important improvement within this framework, making the convergence faster with the same amount of online computation.	Univ Clermont Ferrand, CNRS, UMR 6602, LASMEA, F-63177 Aubiere, France	Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite Clermont Auvergne (UCA)	Jurie, F (corresponding author), Univ Clermont Ferrand, CNRS, UMR 6602, LASMEA, F-63177 Aubiere, France.							Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BRUNELLI R, 1995, 1549 AI MIT; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259; Gleicher M, 1997, PROC CVPR IEEE, P331, DOI 10.1109/CVPR.1997.609345; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375	7	119	151	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					996	1000		10.1109/TPAMI.2002.1017625	http://dx.doi.org/10.1109/TPAMI.2002.1017625			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF		Green Submitted			2022-12-18	WOS:000176446100011
J	Mansouri, AR				Mansouri, AR			Region tracking via level set PDEs without motion computation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						region tracking; Bayesian estimation; level set equations; image sequence analysis		Tracking regions in an image sequence is a challenging and difficult problem in image processing and computer vision and at the same time, one that has many important applications: automated video surveillance, video database search and retrieval, automated video editing, etc. So far, numerous approaches to region tracking have been proposed. Many of them suffer from excessive constraints imposed on the motion of the region being tracked and need an explicit motion model (e.g., affine, Euclidean). Some, which do not need a parametrized motion model, rely instead on a dense motion field. By and large, most rely on some kind or other of motion information. Those which do not use any motion information instead use a model of the region being tracked, typically by assuming strong intensity boundaries, or constraining the shape of the region to belong to a parametrized family of shapes. In this paper, we propose a novel approach to region tracking that is derived from a Bayesian formulation. The novelty of the approach is twofold: First, no motion field or motion parameters need to be computed. This removes a major burden since accurate motion computation has been and remains a challenging problem and the quality of region tracking algorithms based on motion critically depends on the computed motion fields and parameters. The second novelty of this approach, is that very little a priori information about the region being tracked is used in the algorithm. In particular, unlike numerous tracking algorithms, no assumption is made on the strength of the intensity edges of the boundary of the region being tracked, nor is its shape assumed to be of a certain parametric form. The problem of region tracking is formulated as a Bayesian estimation problem and the resulting tracking algorithm is expressed as a level set partial differential equation. We present further extensions to this partial differential equation, allowing the possibility of including additional information in the tracking process, such as priors on the region's intensity boundaries and we present the details of the numerical implementation. Very promising experimental results are provided using numerous real image sequences with natural object and camera motion.	INRS Telecommun, Montreal, PQ H5A 1C6, Canada	University of Quebec; Institut national de la recherche scientifique (INRS)	Mansouri, AR (corresponding author), INRS Telecommun, Pl Bonaventure,POB 644, Montreal, PQ H5A 1C6, Canada.	mansouri@inrs-telecom.uquebec.ca						Bertalmio M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P318, DOI 10.1109/ICIP.1998.999021; BLAKE A, 1993, P 4 INT C COMP VIS; Comaniciu D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P70, DOI 10.1109/ICIP.2000.899297; CROWLEY JL, 1988, P 2 INT C COMP VIS, P658; Curwen R, 1992, ACTIVE VISION, P39; DERICHE R, 1993, P COMP VIS PATT REC; DERICHE R, 1990, P 1 EUR C COMP VIS, P259; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; Mansouri AR, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P636, DOI 10.1109/ICIP.2001.958199; Mansouri AR, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P66, DOI 10.1109/ICIP.2000.899294; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SETHIAN JA, 1998, LEVEL SET METHODS; Terzopoulos D., 1992, ACTIVE VISION, P3; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	18	119	129	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					947	961		10.1109/TPAMI.2002.1017621	http://dx.doi.org/10.1109/TPAMI.2002.1017621			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF		Green Submitted			2022-12-18	WOS:000176446100007
J	Ruzon, MA; Tomasi, C				Ruzon, MA; Tomasi, C			Edge, junction, and corner detection using color distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; junction detection; corner detection; earth mover's distance; color distributions; perceptual color distance	INFORMATION; DISTANCE; FUSION	For over 30 years researchers in computer vision have been proposing new methods for performing low-level vision tasks such as detecting edges and corners. One key element shared by most methods is that they represent local image neighborhoods as constant in color or intensity with deviations modeled as noise. Due to computational considerations that encourage the use of small neighborhoods where this assumption holds, these methods remain popular. This research models a neighborhood as a distribution of colors. Our goal is to show that the increase inaccuracy of this representation translates into higher-quality results for low-level vision tasks on difficult, natural images, especially as neighborhood size increases. We emphasize large neighborhoods because small ones often do not contain enough information. We emphasize color because it subsumes gray scale as an image range and because it is the dominant form of human perception. We discuss distributions in the context of detecting edges, corners, and junctions, and we show results for each.	Quindi Corp, Palo Alto, CA 94306 USA; Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Stanford University	Ruzon, MA (corresponding author), Quindi Corp, 480 S Calif Ave,Suite 304, Palo Alto, CA 94306 USA.	ruzon@quindi.com; tomasi@cs.stanford.edu						BINFORD TO, 1997, P IM UND WORKSH MAY, V2, P1237; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CARRON T, 1994, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.1994.413699; CARRON T, 1995, IEEE INT C IM PROC O, V2, P181; CHAPRON M, 1997, IEEE INT C IM PROC O, V3, P18; COHEN S, 1999, THESIS STANFORD U ST; CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F; DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; Djuric PM, 1997, IEEE T IMAGE PROCESS, V6, P1595, DOI 10.1109/83.641421; DOBRUSHIN RL, 1970, THEOR PROBAB APPL+, V15, P458, DOI 10.1137/1115049; DREWNIOK C, 1994, INT J REMOTE SENS, V15, P3743, DOI 10.1080/01431169408954356; DUDLEY RM, 1968, ANN MATH STAT, V39, P1563, DOI 10.1214/aoms/1177698137; GRAY RM, 1975, ANN PROBAB, V3, P315, DOI 10.1214/aop/1176996402; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUNTSBERGER TL, 1985, PATTERN RECOGN LETT, V3, P205, DOI 10.1016/0167-8655(85)90054-6; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; LECLERC YG, 1987, IEEE T PATTERN ANAL, V9, P341, DOI 10.1109/TPAMI.1987.4767918; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; MACAIRE L, 1996, IEEE INT C IM PROC S, V3, P1045; MACHUCA R, 1983, IEEE T PATTERN ANAL, V5, P316, DOI 10.1109/TPAMI.1983.4767393; MALOWANY ME, 1989, P INT SOC OPTICAL EN, V119, P1116; Moghaddamzadeh A, 1998, INT J PATTERN RECOGN, V12, P801, DOI 10.1142/S0218001498000440; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417; Pietikainen M., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P594; ROBINSON GS, 1977, OPT ENG, V16, P479, DOI 10.1117/12.7972120; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Rubner Y., 1999, THESIS STANFORD U ST; RUZON M, 2000, THESIS STANFORD U ST; RUZON M, 1999, IEEE INT C COMP VIS, V2, P1039; Ruzon M. A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P160, DOI 10.1109/CVPR.1999.784624; Saber E, 1997, IMAGE VISION COMPUT, V15, P769, DOI 10.1016/S0262-8856(97)00019-X; Salinas RA, 1996, IEEE T IND ELECTRON, V43, P355, DOI 10.1109/41.499807; Scharcanski J, 1997, IEEE T CIRC SYST VID, V7, P397, DOI 10.1109/76.564116; SHEN HC, 1983, COMPUT VISION GRAPH, V23, P187, DOI 10.1016/0734-189X(83)90112-3; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; SHIOZAKI A, 1986, COMPUT VISION GRAPH, V36, P1, DOI 10.1016/S0734-189X(86)80025-1; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Song KY, 1996, IMAGE VISION COMPUT, V14, P667, DOI 10.1016/0262-8856(96)84491-X; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TAO H, 1997, IEEE INT C IM PROC, V1, P834; Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445; Tsang WH, 1997, PATTERN RECOGN LETT, V18, P165, DOI 10.1016/S0167-8655(96)00125-0; WANG SJ, 1994, P IM UND WORKSH NOV, V2, P113; WEEKS AR, 1995, P SOC PHOTO-OPT INS, V2424, P291, DOI 10.1117/12.205231; WERMAN M, 1985, COMPUT VISION GRAPH, V32, P328, DOI 10.1016/0734-189X(85)90055-6; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; Yang CK, 1996, PATTERN RECOGN LETT, V17, P481, DOI 10.1016/0167-8655(95)00112-3; Zhang X., 1996, SID S, V27, P731	55	119	131	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1281	1295		10.1109/34.969118	http://dx.doi.org/10.1109/34.969118			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300006
J	Jain, AK; Yu, B				Jain, AK; Yu, B			Document representation and its application to page decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document model; document storage and retrieval; page segmentation; region identification; document image analysis	TEXTURE ANALYSIS; SEGMENTATION; SYSTEM; CLASSIFICATION	Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. in this paper, we use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2,550 x 3,300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise.	Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA; Electroglas Inc, Santa Clara, CA 95054 USA	Michigan State University	Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA.	jain@cps.msu.edu; byu@electroglas.com						Akindele O. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P341, DOI 10.1109/ICDAR.1993.395719; AKIYAMA T, 1990, PATTERN RECOGN, V23, P1141, DOI 10.1016/0031-3203(90)90112-X; Amamoto N., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P739, DOI 10.1109/ICDAR.1993.395631; Antonacopoulos A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1132, DOI 10.1109/ICDAR.1995.602119; ANTONACOPOULOS A, 1994, INT C PATT RECOG, P339, DOI 10.1109/ICPR.1994.576932; BAIRD HS, 1992, P IEEE, V80, P1059, DOI 10.1109/5.156469; *CAER CORP, 1996, OMN PRO WIND 95 VERS; CHENEVOY Y, 1991, P 1 INT C DOC AN REC, P121; Chetverikov D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P676, DOI 10.1109/ICPR.1996.547031; Couasnon B., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1092, DOI 10.1109/ICDAR.1995.602099; Dengel A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P86, DOI 10.1109/ICDAR.1993.395776; DERIENPEDEN D, 1991, P 1 INT C DOC AN REC, P311; DOERMANN D, 1995, P S DOC IM UND TECHN, P39; DRIVAS LD, 1995, P 3 INT C DOC AN REC, P610; Esposito F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P650, DOI 10.1109/ICDAR.1993.395653; Esposito F., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P466, DOI 10.1109/ICDAR.1995.599037; Esposito F., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P557, DOI 10.1109/ICPR.1990.118164; FAN KC, 1995, PATTERN RECOGN LETT, V16, P955, DOI 10.1016/0167-8655(95)00039-J; Fisher J. L., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P567, DOI 10.1109/ICPR.1990.118166; Fisher J. L., 1991, P INT C DOC AN REC S, P302; Fujisawa H., 1990, P WORKSH SYNT STRUCT, P113; HA J, 1995, P 3 INT C DOC AN REC, P952; HA J, 1995, P 3 INT C DOC AN REC, P1119; HARALICK RM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P385, DOI 10.1109/CVPR.1994.323855; Ingold R., 1991, P 1 INT C DOC AN REC, P41; Ittner D. J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P336, DOI 10.1109/ICDAR.1993.395720; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; KANAI J, 1995, IEEE T PATTERN ANAL, V17, P86, DOI 10.1109/34.368146; Kise K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P788, DOI 10.1109/ICPR.1996.547276; KREICH J, 1991, P INT C DOC AN REC S, P50; KRISHNAMOORTHY M, 1993, IEEE T PATTERN ANAL, V15, P737, DOI 10.1109/34.221173; LEGOURGIOIS F, 1992, P 11 INT C PATT REC, P272; LIU J, 1996, P 13 INT C PATT REC, P763; Mohiuddin M., 1997, P 4 INT C DOC AN REC; NAGY G, 1992, P IEEE, V80, P1093, DOI 10.1109/5.156472; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; NAGY G, 1992, STRUCTURED DOCUMENT; NAGY G, 1984, P 7 INT C PATT REC M, P347; Niyogi D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P472, DOI 10.1109/ICDAR.1995.599038; O'Gorman L., 1995, DOCUMENT IMAGE ANAL; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9; PAYNE JS, 1994, INT C PATT RECOG, P380, DOI 10.1109/ICPR.1994.576947; Phillips I. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P478, DOI 10.1109/ICDAR.1993.395691; RANDRIAMASY S, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/CVPR.1994.323859; Sivaramakrishnan R., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P541, DOI 10.1109/ICDAR.1995.601954; Sylwester D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P615, DOI 10.1109/ICDAR.1995.601971; Tang Y. Y., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P567, DOI 10.1109/ICDAR.1995.601960; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; Tsujimoto S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P551, DOI 10.1109/ICPR.1990.118163; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; WANG D, 1989, COMPUT VISION GRAPH, V47, P327, DOI 10.1016/0734-189X(89)90116-3; Yamashita A, 1996, IBM J RES DEV, V40, P341, DOI 10.1147/rd.403.0341; YAMASHITA A, 1991, P INT C DOC AN REC S, P130; YU B, 1992, CVGIP-IMAG UNDERSTAN, V56, P264, DOI 10.1016/1049-9660(92)90042-2; Yu B, 1996, IEEE T PATTERN ANAL, V18, P1127, DOI 10.1109/34.544084; Yu B, 1996, PATTERN RECOGN, V29, P1599, DOI 10.1016/0031-3203(96)00020-9; Yu B, 1995, P 3 INT C DOC AN REC, P803; ZENZO SD, 1996, IEEE T PAMI, V18, P83; Zhou J., 1991, 1 INT C DOC AN REC I, P945; ZLATOPOLSKY AA, 1994, PATTERN RECOGN LETT, V15, P699, DOI 10.1016/0167-8655(94)90074-4	62	119	133	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					294	308		10.1109/34.667886	http://dx.doi.org/10.1109/34.667886			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400006
J	Maintz, JBA; vandenElsen, PA; Viergever, MA				Maintz, JBA; vandenElsen, PA; Viergever, MA			Evaluation of ridge seeking operators for multimodality medical image matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						medical image matching; registration; differential operators; ridges	PET; MR; CT	Ridge-like structures in digital images may be extracted by convolving the images with derivatives of Gaussians. The choice of the convolution operator and of the parameters involved defines a specific ridge image. In this paper, various ridge measures related to isophote curvature are constructed, reviewed, and evaluated with respect to their usability in CT/MRI matching of human brain scans. construction is initially done using heuristics in two-dimensional images, and then established firmly in a mathematical framework. Attention is paid to the necessity of operator invariance, scale of the operator, extension to three-dimensional images, and relations to isophote and principal curvature. It will be shown that one of the ridge measures appears well suited for the purpose of matching, despite the fact that the measure fails to detect ridges in a number of stylized scenes.	STANFORD UNIV, SCH MED, DEPT RADIOL, RADIOL SCI LAB, STANFORD, CA 94305 USA	Stanford University	Maintz, JBA (corresponding author), UNIV UTRECHT HOSP, IMAGING CTR UTRECHT, HEIDELBERGLAAN 100, E01 334, 3584 CX UTRECHT, NETHERLANDS.		Viergever, Max A/J-1215-2014					BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; EBERLY D, 1993, RIDGES IMAGE ANAL; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; FLORACK LMJ, 1994, J MATH IMAGING VISIO, V4; GUEZIEC A, 1992, P SOC PHOTO-OPT INS, V1808, P259, DOI 10.1117/12.131083; KOENDERINK JJ, 1993, PATTERN RECOGNITION; LEVIN DN, 1988, RADIOLOGY, V169, P817, DOI 10.1148/radiology.169.3.3263666; MAINTZ JBA, 1992, 9230 3DCV UTRECHT U; MAXWELL JC, 1859, LONDON EDINBURGH DUB, V40, P421; MONGA O, 1992, P SOC PHOTO-OPT INS, V1, P118; MORSE BS, 1993, MULTISCALE MEDIAL AN; PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004; PIZER SM, 1992, NATO ASI SERIES; Spivak M., 1970, COMPREHENSIVE INTRO, V1; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VANDENELSEN PA, 1993, THESIS UTRECHT U; VANDENELSEN PA, 1995, IEEE T MED IMAGING; VANDENELSEN PA, 1994, EUR RADIOL, V4, P45; VANDENELSEN PA, 1993, BRAIN TOPOGRAPHY, V5, P153; WITKIN A, 1983, P 7 INT JOINT C ART, P1109	21	119	122	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					353	365		10.1109/34.491617	http://dx.doi.org/10.1109/34.491617			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500001
J	REED, TR; WECHSLER, H				REED, TR; WECHSLER, H			SEGMENTATION OF TEXTURED IMAGES AND GESTALT ORGANIZATION USING SPATIAL SPATIAL-FREQUENCY REPRESENTATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									GEORGE MASON UNIV,DEPT COMP SCI,FAIRFAX,VA 22030	George Mason University	REED, TR (corresponding author), ECOLE POLYTECH FED LAUSANNE,TRAITEMENT SIGNAUX LAB,ECUBLENS DE,CH-1015 LAUSANNE,SWITZERLAND.							ALLEN JB, 1977, P IEEE, V65, P1558, DOI 10.1109/PROC.1977.10770; ANDERSON CH, 1985, SEP P SPIE CAMBR INT, P72; Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; BARTELT HO, 1980, OPT COMMUN, V32, P32, DOI 10.1016/0030-4018(80)90308-9; BASTIAANS MJ, 1979, J OPT SOC AM, V69, P1710, DOI 10.1364/JOSA.69.001710; BASTIAANS MJ, 1978, OPT COMMUN, V25, P26, DOI 10.1016/0030-4018(78)90080-9; BECK J, 1983, BIOL CYBERN, V48, P125, DOI 10.1007/BF00344396; BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3; BOUDREAUXBARTEL.GF, 1983, APR P INT C AC SPEEC, P1438; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CAELLI T, 1985, Spatial Vision, V1, P19, DOI 10.1163/156856885X00044; CLAASEN TACM, 1980, PHILIPS J RES, V35, P372; CLAASEN TACM, 1980, PHILIPS J RES, V35, P217; CLAASEN TACM, 1980, PHILIPS J RES, V35, P276; CLARK M, 1987, APR P INT C AC SPEEC; COHEN L, 1966, J MATH PHYS, V7, P781, DOI 10.1063/1.1931206; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; CRICK FHC, INFORMATION PROCESSI; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GAGALOWICZ A, 1981, IEEE T PATTERN ANAL, V3, P520, DOI 10.1109/TPAMI.1981.4767145; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GINSBURG AP, 1980, P SID, V21, P219; GURARI EM, 1982, IEEE T PATTERN ANAL, V4, P304, DOI 10.1109/TPAMI.1982.4767247; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837; JACOBSON L, 1984, IEEE T PATTERN ANAL, V6, P325, DOI 10.1109/TPAMI.1984.4767525; JACOBSON L, 1987, COMPUT VISION GRAPH, V38, P29, DOI 10.1016/S0734-189X(87)80152-4; JACOBSON LD, 1988, SIGNAL PROCESS, V14, P37, DOI 10.1016/0165-1684(88)90043-6; Jacobson L, 1982, PATTERN RECOGN LETT, V1, P61, DOI 10.1016/0167-8655(82)90053-8; JANEZ L, 1984, VISION RES, V24, P271, DOI 10.1016/0042-6989(84)90130-5; JULESZ B, 1983, AT&T TECH J, V62, P1619; Kaiser J. F., 1974, Proceedings of the 1974 IEEE International Symposium on Circuits and Systems, P20; KULIKOWSKI JJ, 1982, BIOL CYBERN, V43, P187, DOI 10.1007/BF00319978; MARR D, 1982, VISION, P64; MARTIN W, 1985, IEEE T ACOUST SPEECH, V33, P1461, DOI 10.1109/TASSP.1985.1164760; MARTIN W, 1985, SIGNAL PROCESS, V8, P215, DOI 10.1016/0165-1684(85)90075-1; MARTIN W, 1984, MAR P INT C AC SPEEC; MARTIN W, 1983, EUSIPCO83, P455; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; PAVLIDIS T, 1977, STRUCTRAL PATTERN RE, P68; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; POLLEN DA, 1981, SCIENCE, V212, P1409, DOI 10.1126/science.7233231; PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910; PREPARATA FP, 1985, COMPUTATIONAL GEOMET, P181; REED T, 1988, SIGNAL PROCESS, V14, P95, DOI 10.1016/0165-1684(88)90047-3; ROSENFELD A, 1978, PATTERN RECOGN, V10, P181, DOI 10.1016/0031-3203(78)90026-2; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9; Ville J., 1948, CABLES TRANSM, V2, P61; WATSON AB, 1987, COMPUT VISION GRAPH, V39, P311, DOI 10.1016/S0734-189X(87)80184-6; Wertheimer M., 1958, READINGS PERCEPTION, P115; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749; WILSON HR, 1977, VISION RES, V17, P1177, DOI 10.1016/0042-6989(77)90152-3; WILSON R, 1984, IEEE T PATTERN ANAL, V6, P758, DOI 10.1109/TPAMI.1984.4767599; WILSON R, 1987, IEEE T PATTERN ANAL, V9, P787, DOI 10.1109/TPAMI.1987.4767985; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; ZUCKER SW, 1985, TR852R MCG U COMP VI	65	119	123	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					1	12		10.1109/34.41379	http://dx.doi.org/10.1109/34.41379			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700001
J	Wang, WG; Lai, QX; Fu, HZ; Shen, JB; Ling, HB; Yang, RG				Wang, Wenguan; Lai, Qiuxia; Fu, Huazhu; Shen, Jianbing; Ling, Haibin; Yang, Ruigang			Salient Object Detection in the Deep Learning Era: An In-Depth Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Visualization; Predictive models; Analytical models; Deep learning; Computational modeling; Benchmark testing; Salient object detection; deep learning; benchmark; image saliency	CONVOLUTIONAL NEURAL-NETWORK; VISUAL-ATTENTION; IMAGE; MODEL; SEGMENTATION	As an essential problem in computer vision, salient object detection (SOD) has attracted an increasing amount of research attention over the years. Recent advances in SOD are predominantly led by deep learning-based solutions (named deep SOD). To enable in-depth understanding of deep SOD, in this paper, we provide a comprehensive survey covering various aspects, ranging from algorithm taxonomy to unsolved issues. In particular, we first review deep SOD algorithms from different perspectives, including network architecture, level of supervision, learning paradigm, and object-/instance-level detection. Following that, we summarize and analyze existing SOD datasets and evaluation metrics. Then, we benchmark a large group of representative SOD models, and provide detailed analyses of the comparison results. Moreover, we study the performance of SOD algorithms under different attribute settings, which has not been thoroughly explored previously, by constructing a novel SOD dataset with rich attribute annotations covering various salient object types, challenging factors, and scene categories. We further analyze, for the first time in the field, the robustness of SOD models to random input perturbations and adversarial attacks. We also look into the generalization and difficulty of existing SOD datasets. Finally, we discuss several open issues of SOD and outline future research directions. All the saliency prediction maps, our constructed dataset with annotations, and codes for evaluation are publicly available at https://github.com/wenguanwang/SODsurvey.	[Wang, Wenguan] Swiss Fed Inst Technol, Zurich, Switzerland; [Lai, Qiuxia] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China; [Fu, Huazhu; Shen, Jianbing] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci, Beijing, Peoples R China; [Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Yang, Ruigang] Univ Kentucky, Lexington, KY 40506 USA	Swiss Federal Institutes of Technology Domain; ETH Zurich; Chinese University of Hong Kong; Beijing Institute of Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of Kentucky	Shen, JB (corresponding author), Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.; Shen, JB (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing, Peoples R China.	wenguanwang.ai@gmail.com; qxlai@cse.cuhk.edu.hk; hzfu@ieee.org; shenjianbingcg@gmail.com; hbling@temple.edu; ryang@cs.uky.edu	Fu, Huazhu/A-1411-2014	Fu, Huazhu/0000-0002-9702-5524; LAI, Qiuxia/0000-0001-6872-5540; Yang, Ruigang/0000-0001-5296-6307	Zhejiang Lab's Open Fund [2019KD0AB04]; CCF-Baidu Open Fund	Zhejiang Lab's Open Fund; CCF-Baidu Open Fund	This work was supported in part by the CCF-Baidu Open Fund and Zhejiang Lab's Open Fund (No. 2019KD0AB04).	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alpert S, 2007, PROC CVPR IEEE, P359; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Bengio E.l, 2016, P INT C LEARN REPR W; Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464; Bi S., 2014, J IMAGE GRAPHICS, V2, P151; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320; Borji A, 2014, J VISION, V14, DOI 10.1167/14.3.29; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Bucilua Cristian, 2006, P 12 ACM SIGKDD INT, P535, DOI [10.1145/1150402.1150464, DOI 10.1145/1150402.1150464]; Cao CS, 2018, AAAI CONF ARTIF INTE, P6690; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen GB, 2017, ADV NEUR IN, V30; Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15; Chen XW, 2017, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2017.119; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832; Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487; Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698; Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12; Fan RC, 2018, LECT NOTES COMPUT SC, V11213, P371, DOI 10.1007/978-3-030-01240-3_23; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Fawzi A., 2016, ADV NEURAL INFORM PR, P1632; Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172; Frintrop S, 2014, INT C PATT RECOG, P2329, DOI 10.1109/ICPR.2014.404; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Guo F, 2018, IEEE T CYBERNETICS, V48, P3159, DOI 10.1109/TCYB.2017.2761361; Guolei Sun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P347, DOI 10.1007/978-3-030-58536-5_21; Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015; He SF, 2017, IEEE I CONF COMP VIS, P1059, DOI 10.1109/ICCV.2017.120; He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0; Hinton G., 2015, NIPS WORKSH, P1; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563; Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65; Hu XW, 2018, AAAI CONF ARTIF INTE, P6943; Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710; Jiang M, 2014, LECT NOTES COMPUT SC, V8695, P17, DOI 10.1007/978-3-319-10584-0_2; Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393; Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002; Karpathy A, 2013, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2013.6630857; KAUFMAN EL, 1949, AM J PSYCHOL, V62, P498, DOI 10.2307/1418556; Ke TW, 2018, LECT NOTES COMPUT SC, V11205, P605, DOI 10.1007/978-3-030-01246-5_36; Kim J, 2016, LECT NOTES COMPUT SC, V9908, P455, DOI 10.1007/978-3-319-46493-0_28; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623; Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399; Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96; Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78; Li B, 2019, AAAI CONF ARTIF INTE, P8569; Li CY, 2019, IEEE T GEOSCI REMOTE, V57, P9156, DOI 10.1109/TGRS.2019.2925070; Li GB, 2018, AAAI CONF ARTIF INTE, P7024; Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34; Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li X, 2018, LECT NOTES COMPUT SC, V11206, P287, DOI [10.1007/978-3-030-01216-8_18, 10.1007/978-3-030-01267-0_22]; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu H, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1, DOI 10.1109/INTMAG.2017.8007847; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Long J. L., 2014, ADV NEURAL INFORM PR, V27, P1601; Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698; Ma Y.F., 2002, P 10 ACM INT C MULTI, P533; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Masciocchi CM, 2009, J VISION, V9, DOI 10.1167/9.11.25; Mehmood I, 2015, INFORM FUSION, V24, P16, DOI 10.1016/j.inffus.2014.07.002; Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171; Movahedi Vida, 2010, P IEEE C COMP VIS PA, P49, DOI DOI 10.1109/CVPRW.2010.5543739; Palazzi A, 2017, IEEE INT VEH SYM, P920, DOI 10.1109/IVS.2017.7995833; Papernot N, 2016, ARXIV160507277, DOI 10.48550/arXiv.1605.07277; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Qi Q, 2019, IEEE INT CON MULTI, P1762, DOI 10.1109/ICME.2019.00303; Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766; Romero Adriana, 2014, ARXIV14126550; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rosin PL, 2013, GRAPH MODELS, V75, P208, DOI 10.1016/j.gmod.2013.03.004; Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960; Simonyan K., 2015, INT C LEARN REPR ICL; Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44; Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390; Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984; Szegedy C, 2014, INTRIGUING PROPERTIE, P6; Tang YB, 2016, LECT NOTES COMPUT SC, V9912, P809, DOI 10.1007/978-3-319-46484-8_49; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Veit A, 2018, LECT NOTES COMPUT SC, V11205, P3, DOI 10.1007/978-3-030-01246-5_1; Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3; Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404; Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938; Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50; Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330; Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433; Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154; Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612; Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724; Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594; Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784; Wang X, 2018, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2018.00147; Wang ZS, 2008, INT CONF ACOUST SPEE, P965; Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687; Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736; Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403; Xia CQ, 2017, PROC CVPR IEEE, P4399, DOI 10.1109/CVPR.2017.468; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28; Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733; Zeng Y, 2019, IEEE I CONF COMP VIS, P7222, DOI 10.1109/ICCV.2019.00732; Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623; Zhang D., 2016, PROC INT JOINT C ART, P3538; Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674; Zhang DW, 2017, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2017.436; Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078; Zhang JM, 2016, PROC CVPR IEEE, P5733, DOI 10.1109/CVPR.2016.618; Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844; Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165; Zhang JM, 2015, PROC CVPR IEEE, P4045, DOI 10.1109/CVPR.2015.7299031; Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941; Zhang L, 2019, PROC CVPR IEEE, P6017, DOI 10.1109/CVPR.2019.00618; Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081; Zhang ZY, 2016, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2016.79; Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887; Zhao J, 2020, INT J COMPUT VISION, V128, P2185, DOI 10.1007/s11263-019-01181-5; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng QL, 2018, LECT NOTES COMPUT SC, V11218, P300, DOI 10.1007/978-3-030-01264-9_18; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu JY, 2015, IEEE T PATTERN ANAL, V37, P862, DOI 10.1109/TPAMI.2014.2353617; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360; Zhuge YZ, 2019, AAAI CONF ARTIF INTE, P9340; Zlateski A, 2018, PROC CVPR IEEE, P1479, DOI 10.1109/CVPR.2018.00160; Zoph B., 2017, P1	169	118	120	67	70	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3239	3259		10.1109/TPAMI.2021.3051099	http://dx.doi.org/10.1109/TPAMI.2021.3051099			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33434124	Green Submitted			2022-12-18	WOS:000803117500033
J	Duan, YQ; Lu, JW; Feng, JJ; Zhou, J				Duan, Yueqi; Lu, Jiwen; Feng, Jianjiang; Zhou, Jie			Context-Aware Local Binary Feature Learning for Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; binary feature learning; context-aware; multi-feature learning; heterogeneous face matching	PATTERNS; REPRESENTATION; VERIFICATION; ALGORITHM; HISTOGRAM; SCALE; CLASSIFICATION; MAGNITUDES; EIGENFACES; DESCRIPTOR	In this paper, we propose a context-aware local binary feature learning (CA-LBFL) method for face recognition. Unlike existing learning-based local face descriptors such as discriminant face descriptor (DFD) and compact binary face descriptor (CBFD) which learn each feature code individually, our CA-LBFL exploits the contextual information of adjacent bits by constraining the number of shifts from different binary bits, so that more robust information can be exploited for face representation. Given a face image, we first extract pixel difference vectors (PDV) in local patches, and learn a discriminative mapping in an unsupervised manner to project each pixel difference vector into a context-aware binary vector. Then, we perform clustering on the learned binary codes to construct a codebook, and extract a histogram feature for each face image with the learned codebook as the final representation. In order to exploit local information from different scales, we propose a context-aware local binary multi-scale feature learning (CA-LBMFL) method to jointly learn multiple projection matrices for face representation. To make the proposed methods applicable for heterogeneous face recognition, we present a coupled CA-LBFL (C-CA-LBFL) method and a coupled CA-LBMFL (C-CA-LBMFL) method to reduce the modality gap of corresponding heterogeneous faces in the feature level, respectively. Extensive experimental results on four widely used face datasets clearly show that our methods outperform most state-of-the-art face descriptors.	[Duan, Yueqi; Lu, Jiwen; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Duan, Yueqi; Lu, Jiwen; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	duanyq14@mails.tsinghua.edu.cn; lujiwen@tsinghua.edu.cn; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn	Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2016YFB 1001001]; National Natural Science Foundation of China [61672306, 61572271, 61527808, 61373074, 61373090]; National 1000 Young Talents Plan Program; National Basic Research Program of China [2014CB349304]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National 1000 Young Talents Plan Program; National Basic Research Program of China(National Basic Research Program of China); Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program	This work is supported by the National Key Research and Development Program of China under Grant 2016YFB 1001001, the National Natural Science Foundation of China under Grants 61672306, 61572271, 61527808, 61373074 and 61373090, the National 1000 Young Talents Plan Program, the National Basic Research Program of China under Grant 2014CB349304, the Ministry of Education of China under Grant 20120002110033, and the Tsinghua University Initiative Scientific Research Program.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alahi A., P IEEE C COMP VIS PA, P510; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arashloo S. R., 2013, P IEEE 6 INT C BIOM, P1, DOI DOI 10.1109/BTAS.2013.6712721; Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850; Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Brodatz P., 1966, TEXTURES PHOTOGRAPHI, V66; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398; CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Cui Z., 2013, P ASME 2013 INT MECH, P1; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981; Feng JS, 2012, IEEE T IMAGE PROCESS, V21, P778, DOI 10.1109/TIP.2011.2163521; Galoogahi H. K., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P224, DOI 10.1109/ICME.2012.128; Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu JL, 2015, LECT NOTES COMPUT SC, V9005, P252, DOI 10.1007/978-3-319-16811-1_17; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang G.B., 2007, 0749 UMASS AMH; HUANG GB, 2012, PROC CVPR IEEE, P2518, DOI DOI 10.1109/CVPR; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P151; Kan M, 2012, COMPUT VIS ECCV, V2012, P808; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Le Q.V., 2011, NEURIPS, P1017; Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Li HR, 2015, APPL THERM ENG, V88, P363, DOI 10.1016/j.applthermaleng.2014.10.071; Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu GY, 2016, NEUROCOMPUTING, V173, P83, DOI 10.1016/j.neucom.2015.07.106; Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424; Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359; Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70; Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Mignon A., 2012, P AS C COMP VIS, P14; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Parkhi Omkar M., 2015, BRIT MACH VIS C; Peng CL, 2017, IEEE T PATTERN ANAL, V39, P301, DOI 10.1109/TPAMI.2016.2542816; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rifai S., 2011, PROC INT C MACH LEAR; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Sharma A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247923; Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Sun Y., 2015, ARXIV PREPRINT ARXIV; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99; Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866; Wolf L., 2008, P REAL LIF IM WORKSH, P1; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Wolf L, 2013, PROC CVPR IEEE, P3523, DOI 10.1109/CVPR.2013.452; Wolf L, 2010, LECT NOTES COMPUT SC, V5995, P88; Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang SL, 2014, IEEE T IMAGE PROCESS, V23, P3671, DOI 10.1109/TIP.2014.2330794; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679; Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21	84	118	122	1	80	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1139	1153		10.1109/TPAMI.2017.2710183	http://dx.doi.org/10.1109/TPAMI.2017.2710183			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	29610106				2022-12-18	WOS:000428901200010
J	Zheng, WS; Gong, SG; Xiang, T				Zheng, Wei-Shi; Gong, Shaogang; Xiang, Tao			Towards Open-World Person Re-Identification by One-Shot Group-Based Verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Group-based verification; open-world re-identification; transfer relative distance comparison	FRAMEWORK	Solving the problem of matching people across non-overlapping multi-camera views, known as person re-identification (re-id), has received increasing interests in computer vision. In a real-world application scenario, a watch-list (gallery set) of a handful of known target people are provided with very few (in many cases only a single) image(s) (shots) per target. Existing re-id methods are largely unsuitable to address this open-world re-id challenge because they are designed for (1) a closed-world scenario where the gallery and probe sets are assumed to contain exactly the same people, (2) person-wise identification whereby the model attempts to verify exhaustively against each individual in the gallery set, and (3) learning a matching model using multi-shots. In this paper, a novel transfer local relative distance comparison (t-LRDC) model is formulated to address the open-world person re-identification problem by one-shot group-based verification. The model is designed to mine and transfer useful information from a labelled open-world non-target dataset. Extensive experiments demonstrate that the proposed approach outperforms both non-transfer learning and existing transfer learning based re-id methods.	[Zheng, Wei-Shi] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China; [Zheng, Wei-Shi] Guangdong Prov Key Lab Computat Sci, Guangzhou, Guangdong, Peoples R China; [Gong, Shaogang; Xiang, Tao] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England	Sun Yat Sen University; University of London; Queen Mary University London	Zheng, WS (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.; Zheng, WS (corresponding author), Guangdong Prov Key Lab Computat Sci, Guangzhou, Guangdong, Peoples R China.; Gong, SG; Xiang, T (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.	wszheng@ieee.org; s.gong@qmul.ac.uk; t.xiang.@qmul.ac.uk	Zheng, Wei-Shi/J-7661-2016	Zheng, Wei-Shi/0000-0001-8327-0003	Guangdong Provincial Government of China through Computational Science Innovative Research Team Program; National Natural Science of Foundation of China [61472456, U1135001]; NSFC [61522115]; Guangzhou Pearl River Science and Technology Rising Star Project [2013J2200068]; Guangdong Natural Science Funds for Distinguished Young Scholar Grant [S2013050014265]; United Kingdom Home Office CONTEST Programme; Vision Semantics Limited; Engineering and Physical Sciences Research Council [EP/E028594/1] Funding Source: researchfish; EPSRC [EP/E028594/1] Funding Source: UKRI	Guangdong Provincial Government of China through Computational Science Innovative Research Team Program; National Natural Science of Foundation of China(National Natural Science Foundation of China (NSFC)); NSFC(National Natural Science Foundation of China (NSFC)); Guangzhou Pearl River Science and Technology Rising Star Project; Guangdong Natural Science Funds for Distinguished Young Scholar Grant; United Kingdom Home Office CONTEST Programme; Vision Semantics Limited; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported partially by Guangdong Provincial Government of China through the Computational Science Innovative Research Team Program, the National Natural Science of Foundation of China (Nos. 61472456, U1135001), NSFC for Excellent Young Scientist Programme (No. 61522115), Guangzhou Pearl River Science and Technology Rising Star Project under Grant 2013J2200068, and in part by the Guangdong Natural Science Funds for Distinguished Young Scholar under Grant S2013050014265. S. Gong and T. Xiang are supported by the United Kingdom Home Office CONTEST Programme and Vision Semantics Limited.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2008, HOME OFFICE I LIDS M; Bart E, 2005, PROC CVPR IEEE, P672; Bousquet O., 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Dollar P., 2007, IEEE C COMP VIS PATT, V1-8; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Ess A, 2007, IEEE I CONF COMP VIS, P2065; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Goldberger J., 2005, ADV NEURAL INF PROCE, V17; Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Layne R., 2013, P 4 ACM IEEE INT WOR, P25; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736; Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Pan S.J., 2008, AAAI; Parameswaran S., 2010, P ADV NEUR INF PROC; Park U, 2006, INT C PATT RECOG, P1204; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Prosser B., 2008, P BRIT MACH VIS C, P641; Prosser B., 2010, P BRIT MACH VIS C, p[211, 6]; Salakhutdinov R., 2012, P WORKSH UNS TRANSF; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413; Tao H, 2007, PETS WORKSH; Tommasi T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.87; Torralba A, 2004, PROC CVPR IEEE, P762; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Wu Y, 2013, IEEE IMAGE PROC, P2812, DOI 10.1109/ICIP.2013.6738579; Yang L., 2006, P AAAI C ARTIFICIAL, P543; Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng WS, 2012, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2012.6247985; Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23	50	118	124	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					591	606		10.1109/TPAMI.2015.2453984	http://dx.doi.org/10.1109/TPAMI.2015.2453984			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046499				2022-12-18	WOS:000370738900013
J	De la Torre, F				De la Torre, Fernando			A Least-Squares Framework for Component Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Principal component analysis; linear discriminant analysis; canonical correlation analysis; k-means; spectral clustering; reduced rank regression; kernel methods; dimensionality reduction	DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; MATRIX FACTORIZATION; SPECTRAL METHODS; RECOGNITION; KERNEL; MODEL; VARIABLES; OBJECTS; CUTS	Over the last century, Component Analysis (CA) methods such as Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Canonical Correlation Analysis (CCA), Locality Preserving Projections (LPP), and Spectral Clustering (SC) have been extensively used as a feature extraction step for modeling, classification, visualization, and clustering. CA techniques are appealing because many can be formulated as eigen-problems, offering great potential for learning linear and nonlinear representations of data in closed-form. However, the eigen-formulation often conceals important analytic and computational drawbacks of CA techniques, such as solving generalized eigen-problems with rank deficient matrices (e.g., small sample size problem), lacking intuitive interpretation of normalization factors, and understanding commonalities and differences between CA methods. This paper proposes a unified least-squares framework to formulate many CA methods. We show how PCA, LDA, CCA, LPP, SC, and its kernel and regularized extensions correspond to a particular instance of least-squares weighted kernel reduced rank regression (LS-WKRRR). The LS-WKRRR formulation of CA methods has several benefits: 1) provides a clean connection between many CA techniques and an intuitive framework to understand normalization factors; 2) yields efficient numerical schemes to solve CA techniques; 3) overcomes the small sample size problem; 4) provides a framework to easily extend CA methods. We derive weighted generalizations of PCA, LDA, SC, and CCA, and several new CA techniques.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	De la Torre, F (corresponding author), Carnegie Mellon Univ, Inst Robot, 211 Smith Hall,5000 Forbes Ave, Pittsburgh, PA 15213 USA.	ftorre@cs.cmu.edu			US Naval Research Laboratory [N00173-07-C-2040]; US National Science Foundation [CPS-0931999]	US Naval Research Laboratory; US National Science Foundation(National Science Foundation (NSF))	This material is based upon work partially supported by the US Naval Research Laboratory under Contract No. N00173-07-C-2040 and by the US National Science Foundation under Grant CPS-0931999. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the US Naval Research Laboratory or the US National Science Foundation. Thanks to Louis-Philippe Morency, Chris Ding, Andrew Fitzgibbon, Feng Zhou, Tomas Simon, Minyoung Kim, Karim Abou-Moustafa, Zaid Harchaoui, Jordi Soler for valuable comments. Thanks to the anonymous reviewers who provided helpful feedback on an earlier draft of this paper.	Aguiar P., 2008, P IEEE C COMP VIS PA; Anderson T. W, 1984, INTRO MULTIVARIATE S; ANDERSON TW, 1951, ANN MATH STAT, V22, P327, DOI 10.1214/aoms/1177729580; [Anonymous], P NEUR INF PROC SYST; Bach F., 2007, P NEUR INF PROC SYST; Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Bathe K.J., 2011, NUMERICAL METHODS FI; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396; Bischof H, 2004, COMPUT VIS IMAGE UND, V95, P86, DOI 10.1016/j.cviu.2004.01.002; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BORGA M, 1998, THESIS LINKOPING U S; Buchanan A., 2005, P IEEE C COMP VIS PA; Chung F.R.K., 1997, AM MATH SOC, DOI DOI 10.1090/CBMS/092; Collins M., 2002, P NEUR INF PROC SYST; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 2001, STAT MODELS APPEARAN; Cox M., 2008, P IEEE C COMP VIS PA; De la Torre F, 2003, COMPUT VIS IMAGE UND, V91, P53, DOI 10.1016/S1077-3142(03)00076-6; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; De la Torre F., 2008, P IEEE C COMP VIS PA; De la Torre F., 2005, P INT C MACH LEARN; De la Torre F., 2001, P IEEE C COMP VIS PA; De la Torre F., 2008, CMURITR0829; De la Torre F., 2007, P IEEE C COMP VIS PA; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Diamantaras K.I., 1996, PRINCIPAL COMPONENT; Ding C., 2007, P INT C MACH LEARN; Ding C., 2004, P INT C MACH LEARN; Ding C., 2005, P SIAM INT C DAT MIN; Duda R.O., 2001, PATTERN CLASSIFICATI; Everitt B., 1984, INTRO LATENT VARIABL; Filippone M, 2008, PATTERN RECOGN, V41, P176, DOI 10.1016/j.patcog.2007.05.018; Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fletcher Roger, 1987, PRACTICAL METHODS OP, DOI 10.1002/9781118723203; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GABRIEL KR, 1979, TECHNOMETRICS, V21, P489, DOI 10.2307/1268288; GALLINARI P, 1991, NEURAL NETWORKS, V4, P349, DOI 10.1016/0893-6080(91)90071-C; Gordon G., 2002, P NEUR INF PROC SYST; Greenacre M.J., 1984, THEORY APPL CORRES A; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Ham J., 2004, P INT C MACH LEARN; HARTLEY R, 2003, P AUSTR JAP ADV WORK; Hastie T, 2009, ELEMENTS STAT LEARNI; Haykin S., 1996, ADAPTIVE FILTER THEO; He X., 2005, P IEEE INT C COMP VI; He X., 2003, P NEUR INF PROC SYST; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Irani M., 2000, P EUR C COMP VIS; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kanade T, 2006, P INT C MACH LEARN; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kookinos I., 2007, P INT C COMP VIS; LAWTON WH, 1971, TECHNOMETRICS, V13, P617, DOI 10.2307/1267173; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; LeCun Y., 1998, CONVOLUTIONAL NETWOR, V3361, P255, DOI DOI 10.1109/IJCNN.2004.1381049; Lee DD, 2000, P NEUR INF PROC SYST; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Magnus J. R, 1999, MATRIX DIFFERENTIAL; Mardia K.V., 1979, MULTIVARIATE ANAL; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Mika S., 2002, THESIS U TECHNOLOGY; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Moghaddam B., 2008, P INF THEOR APPL WOR; Mohar B, 1997, NATO ADV SCI I C-MAT, V497, P225; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Ng A. Y., 2002, P NEUR INF PROC SYST; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Rahimi A., 2004, P WORKSH STAT LEARN; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Roig G., 2009, P 2 IEEE INT WORKSH; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Roweis S., 1997, EM ALGORITHMS PCA SE; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scharf L., 2002, SIGNAL PROCESS, V25, P113; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, MIT PRESS SERIES; SHEN J, 1989, ATMOS ENVIRON, V23, P2289, DOI 10.1016/0004-6981(89)90190-X; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shimodaira H., 2001, P NEUR INF PROC SYST; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; Skocaj D., 2003, P INT C COMP VIS; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tolliver D., 2006, CMURITR0644; Tsang I., 2003, P INT C ART NEUR NET; TSO MKS, 1981, J ROY STAT SOC B MET, V43, P183; Verma D., 2003, P NEUR INF PROC SYST; Weiss Y., 1999, P IEEE INT C COMP VI; Ye J., 2007, P 24 INT C MACH LEAR, P1087, DOI DOI 10.1145/1273496.1273633; Ye J., 2007, P NEUR INF PROC SYST; Ye JP, 2005, J MACH LEARN RES, V6, P483; YOHAI VJ, 1980, ANN STAT, V8, P865, DOI 10.1214/aos/1176345079; Yu S., 2003, P IEEE INT C COMP VI; Zass R., 2005, P IEEE INT C COMP VI; Zass R., 2006, P NEUR INF PROC SYST; ZHA H, 2001, P NEUR INF PROC SYST; Zhang S, 2007, IEEE T PATTERN ANAL, V29, P1732, DOI 10.1109/TPAMI.2007.1089; Zhou F., 2009, P NEUR INF PROC SYST, P2286; Zhou F., 2008, P 8 IEEE INT C AUT F	115	118	120	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1041	1055		10.1109/TPAMI.2011.184	http://dx.doi.org/10.1109/TPAMI.2011.184			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	21911913	Green Submitted			2022-12-18	WOS:000302916600001
J	Felzenszwalb, PF; Zabih, R				Felzenszwalb, Pedro F.; Zabih, Ramin			Dynamic Programming and Graph Algorithms in Computer Vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Combinatorial algorithms; vision and scene understanding; artificial intelligence; computing methodologies	MARKOV RANDOM-FIELDS; ENERGY MINIMIZATION; IMAGE; CUTS; STEREO; CLASSIFICATION; REPRESENTATION; OPTIMIZATION; BOUNDARIES; TRACKING	Optimization is a powerful paradigm for expressing and solving problems in a wide range of areas, and has been successfully applied to many vision problems. Discrete optimization techniques are especially interesting since, by carefully exploiting problem structure, they often provide nontrivial guarantees concerning solution quality. In this paper, we review dynamic programming and graph algorithms, and discuss representative examples of how these discrete optimization techniques have been applied to some classical vision problems. We focus on the low-level vision problem of stereo, the mid-level problem of interactive object segmentation, and the high-level problem of model-based recognition.	[Felzenszwalb, Pedro F.] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; [Zabih, Ramin] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	University of Chicago; Cornell University	Felzenszwalb, PF (corresponding author), Univ Chicago, Dept Comp Sci, 1100 E 58th St, Chicago, IL 60637 USA.	pff@cs.uchicago.edu; rdz@cs.cornell.edu		Zabih, Ramin/0000-0001-8769-5666	US National Science Foundation (NSF) [IIS-0746569, IIS-0803705]; US National Institutes of Health (NIH) [R21EB008138, P41RR023953]; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR023953] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R21EB008138] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	The authors received help from many people with the content and presentation of this material, and especially wish to thank Jon Kleinberg, David Kriegman, Eva Tardos, and Phil Torr, as well as the anonymous reviewers. This research has been supported by the US National Science Foundation (NSF) under grants IIS-0746569 and IIS-0803705 and by the US National Institutes of Health (NIH) under grants R21EB008138 and P41RR023953.	Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Ahuja RK, 2002, DISCRETE APPL MATH, V123, P75, DOI 10.1016/S0166-218X(01)00338-9; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; BAKER HH, 1981, P 7 INT JOINT C ART, P631; BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Bellman RE, 1957, DYNAMIC PROGRAMMING; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Boros E, 2002, DISCRETE APPL MATH, V123, P1; Boyd S, 2004, CONVEX OPTIMIZATION; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245; BOYKOV Y, 2005, MMCV05, P79; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Burkard RE, 1996, DISCRETE APPL MATH, V70, P95, DOI 10.1016/0166-218X(95)00103-X; Cook WJ, 1998, COMBINATORIAL OPTIMI; Cormen T.H., 1989, INTRO ALGORITHMS; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; COUGHLAN J, 2006, NEURAL COMPUT, V14, P1929; CUNNINGHAM WH, 1985, NETWORKS, V15, P205, DOI 10.1002/net.3230150206; DAHLHAUS E, 1994, SIAM J COMPUT, V23, P864, DOI 10.1137/S0097539792225297; Darrell T., 2001, P IEEE INT C COMP VI; Dellaert F, 2001, THESIS CARNEGIE MELL; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Felzenszwalb P.F., 2004, TR20041963 CORN U FA; Felzenszwalb PF, 2007, J ARTIF INTELL RES, V29, P153, DOI 10.1613/jair.2187; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Ford L. R. J., 1962, FLOWS NETWORKS; Garey M.R., 1979, COMPUTERS INTRACTABI; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; GUPTA A, 2000, P ACM S THEOR COMP S; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Hampel FR., 2011, WILEY SERIES PROBABI; HANNA M, 1974, THESIS STANFORD U; Holland J.H., 1975, ADAPTATION NATURAL A, DOI DOI 10.7551/MITPRESS/1090.001.0001; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Ishikawa H, 1998, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.1998.698598; Ishikawa H., 2009, P IEEE C COMP VIS PA; ISHIKAWA H, 1998, EUR C COMP VIS, P232; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313; KARP RM, 1983, ARTIF INTELL, V21, P99, DOI 10.1016/S0004-3702(83)80006-X; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kim J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1033, DOI 10.1109/ICCV.2003.1238463; Kim J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P502; Kleinberg J, 2002, J ACM, V49, P616, DOI 10.1145/585265.585268; Kleinberg Jon, 2005, ALGORITHM DESIGN; KNUTH DE, 1977, INFORM PROCESS LETT, V6, P1, DOI 10.1016/0020-0190(77)90002-3; KOHLI P, 2005, P IEEE INT C COMP VI; Kohli P, 2009, IEEE T PATTERN ANAL, V31, P1645, DOI 10.1109/TPAMI.2008.217; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193; KOMODAKIS N, 2005, P IEEE INT C COMP VI; KORTE B, 2005, COMBINATORIAL OPTIMI; Krause A, 2008, J MACH LEARN RES, V9, P235; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143; Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54; Ling HB, 2005, PROC CVPR IEEE, P719; MAES M, 1990, INFORM PROCESS LETT, V35, P73, DOI 10.1016/0020-0190(90)90109-B; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; MORTENSEN EN, 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; PRESS WH, 1992, NUMERICAL RECIPES C, pCH15; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raphael C, 2001, IEEE T PATTERN ANAL, V23, P1379, DOI 10.1109/34.977562; RAPHAEL C, 1997, P C SPIE, P316; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; ROTHER C, 2005, P IEEE C COMP VIS PA; ROY S, 1998, P IEEE INT C COMP VI; SATORU I, 2001, J ACM, V48, P761; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schoenemann T, 2008, P IEEE C COMP VIS PA, P1; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tikhonov A.N., 1977, SOLUTION ILL POSED P; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Veksler O, 2005, PROC CVPR IEEE, P384; VEKSLER O, 1999, THESIS CORNELL U; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; WEISS Y, 2007, P C UNC ART INT; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; [No title captured]	103	118	133	3	68	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					721	740		10.1109/TPAMI.2010.135	http://dx.doi.org/10.1109/TPAMI.2010.135			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20660950	Green Accepted, Green Submitted			2022-12-18	WOS:000287370400006
J	Favaro, P; Soatto, S; Burger, M; Osher, SJ				Favaro, Paolo; Soatto, Stefano; Burger, Martin; Osher, Stanley J.			Shape from defocus via diffusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; reconstruction; depth cues; gradient methods; iterative methods; partial differential equations; inverse problems; sharpening; and deblurring	DEPTH; EDGE	Defocus can be modeled as a diffusion process and represented mathematically using the heat equation, where image blur corresponds to the diffusion of heat. This analogy can be extended to nonplanar scenes by allowing a space-varying diffusion coefficient. The inverse problem of reconstructing 3D structure from blurred images corresponds to an "inverse diffusion" that is notoriously ill posed. We show how to bypass this problem by using the notion of relative blur. Given two images, within each neighborhood, the amount of diffusion necessary to transform the sharper image into the blurrier one depends on the depth of the scene. This can be used to devise a global algorithm to estimate the depth profile of the scene without recovering the deblurred image using only forward diffusion.	[Favaro, Paolo] Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh EH14 4AS, Midlothian, Scotland; [Soatto, Stefano] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; [Burger, Martin] Univ Munster, Inst Computat & App Math, D-48149 Munster, Germany; [Osher, Stanley J.] Univ Calif Los Angeles, Dept Appl Math, Los Angeles, CA 90095 USA	Heriot Watt University; University of California System; University of California Los Angeles; University of Munster; University of California System; University of California Los Angeles	Favaro, P (corresponding author), Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh EH14 4AS, Midlothian, Scotland.	p.favaro@hw.ac.uk; soatto@ucla.edu; martin.burger@uni-muenster.de; sjo@math.ucla.edu	Burger, Martin/D-9928-2012	Burger, Martin/0000-0003-2619-2912				AMANN H, 1995, LINEAR QUASILINEAR, V1; Ambrosio L, 2005, LEC MATH; Asada N, 1998, INT J COMPUT VISION, V26, P153, DOI 10.1023/A:1007996810301; Aubert G., 2001, APPL MATH SCI; Bertero Mario, 2020, INTRO INVERSE PROBLE, P2; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Chaudhuri S., 1999, DEPTH DEFOCUS REAL A; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; Favaro P, 2003, PROC CVPR IEEE, P179; Favaro P, 2003, INT J COMPUT VISION, V52, P25, DOI 10.1023/A:1022366408068; Favaro P, 2000, LECT NOTES COMPUT SC, V1842, P755; FAVARO P, 2006, 3 D SHAPE RECONSTRUC; FAVARO P, 2002, P EUR C COMP VIS, V2, P735; Fischl B, 1997, IEEE T PATTERN ANAL, V19, P342, DOI 10.1109/34.588012; Forsyth DA, 2002, PRENT HALL PROF TECH; GILARDI G, 1992, ANAL DUE; GIROD B, 1989, P SOC PHOTOOPT INSTR, V1194, P209; GOKSTORP M, 1994, INT C PATT RECOG, P153, DOI 10.1109/ICPR.1994.576248; HOPKINS HH, 1955, PROC R SOC LON SER-A, V231, P91, DOI 10.1098/rspa.1955.0158; Lagnado R., 1997, J COMPUT FINANC, V1, P13, DOI [10.21314/JCF.1997.002, DOI 10.21314/JCF.1997.002]; LEUNBERGER D, 1968, OPTIMIZATION VECTOR; Marshall JA, 1996, J OPT SOC AM A, V13, P681, DOI 10.1364/JOSAA.13.000681; NAIR N, 1992, P IEEE COMP VIS PATT, P309; Nayar S. K., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P218, DOI 10.1109/ROBOT.1990.125976; Nayar SK, 1996, IEEE T PATTERN ANAL, V18, P1186, DOI 10.1109/34.546256; NOGUCHI M, 1994, INT C PATT RECOG, P147, DOI 10.1109/ICPR.1994.576247; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PENTLAND A, 1994, J OPT SOC AM A, V11, P2925, DOI 10.1364/JOSAA.11.002925; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Protter M.H., 1984, MAXIMUM PRINCIPLE DI, DOI 10.1007/978-1-4612-5282-5; Rajagopalan AN, 2004, IEEE T PATTERN ANAL, V26, P1521, DOI 10.1109/TPAMI.2004.102; Rajagopalan AN, 1997, PROC CVPR IEEE, P219, DOI 10.1109/CVPR.1997.609323; Rajagopalan AN, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1047, DOI 10.1109/ICCV.1998.710846; SCHECHNER Y, 1993, P INT C COMP VIS, P843; SCHNEIDER G, 1994, IEEE IMAGE PROC, P116, DOI 10.1109/ICIP.1994.413542; Soatto S, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.854725; Subbarao M., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P498, DOI 10.1109/CVPR.1988.196281; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; SUBBARAO M, 1988, P INT C COMP VIS, P149; Tschumperle D, 2003, PROC CVPR IEEE, P651; Watanabe M, 1996, PROC CVPR IEEE, P431, DOI 10.1109/CVPR.1996.517108; WATANABE M, 1998, P I J COMP VIS, V27; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977; XIONG Y, 1995, P INT C INT ROB SYST, P108; ZEIDLER E, 1998, NONLINEAR FUNCTION 1; Ziou D, 2001, COMPUT VIS IMAGE UND, V81, P143, DOI 10.1006/cviu.2000.0899	49	118	135	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					518	531		10.1109/TPAMI.2007.1175	http://dx.doi.org/10.1109/TPAMI.2007.1175			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195444				2022-12-18	WOS:000252286100012
J	Marroquin, JL; Santana, EA; Botello, S				Marroquin, JL; Santana, EA; Botello, S			Hidden Markov measure field models for image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	3rd International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	SEP 03-05, 2001	SOPHIA ANTIPOLIS, FRANCE	INRIA, Int Assoc Pattern Recognit, Conseil Gen Alpes Maritimes		Markov random fields; segmentation; motion	BRAIN MR-IMAGES; STATISTICAL-ANALYSIS; MOTION SEGMENTATION; MAXIMUM-LIKELIHOOD; RESTORATION; ALGORITHM; VISION	Parametric image segmentation consists of finding a label field that defines a partition of an image into a set of nonoverlapping regions and the parameters of the models that describe the variation of some property within each region. A new Bayesian formulation for the solution of this problem is presented, based on the key idea of using a doubly stochastic prior model for the label field, which allows one to find exact optimal estimators for both this field and the model parameters by the minimization of a differentiable function. An efficient minimization algorithm and comparisons with existing methods on synthetic images are presented, as well as examples of realistic applications to the segmentation of Magnetic Resonance volumes and to motion segmentation.	CIMAT, Guanajuato 36000, Gto, Mexico	CIMAT - Centro de Investigacion en Matematicas	Marroquin, JL (corresponding author), CIMAT, Apartado Postal 402, Guanajuato 36000, Gto, Mexico.	jlm@cimat.mx; roman@cimat.mx; botello@cimat.mx	Arce-Santana, Edgar/A-9740-2016					[Anonymous], 1999, NUMERICAL OPTIMIZATI; [Anonymous], [No title captured]; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; Chellappa R, 1993, MARKOV RANDOM FIELDS; Cocosco C.A., 1997, NEUROIMAGE, V5, P425, DOI DOI 10.1016/S1053-8119(97)80018-3; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883; Jalobeanu A, 2002, PATTERN RECOGN, V35, P341, DOI 10.1016/S0031-3203(00)00178-3; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; LUENBERGER D.G., 1989, INTRO LINEAR NONLINE; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN JL, 1993, CVGIP-GRAPH MODEL IM, V55, P408, DOI 10.1006/cgip.1993.1031; Marroquin JL, 2002, IEEE T MED IMAGING, V21, P934, DOI 10.1109/TMI.2002.803119; Marroquin JL, 2001, IEEE T PATTERN ANAL, V23, P337, DOI 10.1109/34.917570; MARROQUIN JL, 2002, 10205 CTR INV MAT; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Rajapakse JC, 1998, IMAGE VISION COMPUT, V16, P165, DOI 10.1016/S0262-8856(97)00067-X; Schoenberg I.J., 1973, CARDINAL SPLINE INTE, DOI [10.1137/1.9781611970555, DOI 10.1137/1.9781611970555]; SHI J, 1998, P INT C COMP VIS; Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174; Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270; Vasconcelos N, 2001, IEEE T PATTERN ANAL, V23, P217, DOI 10.1109/34.908972; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; ZHANG J, 1995, IEEE T IMAGE PROCESS, V4, P19, DOI 10.1109/83.350816; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424	31	118	123	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1380	1387		10.1109/TPAMI.2003.1240112	http://dx.doi.org/10.1109/TPAMI.2003.1240112			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800003
J	Maciel, J; Costeira, JP				Maciel, J; Costeira, JP			A global solution to sparse correspondence problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						correspondence problem; linear and concave programming; sparse stereo	STEREO; MINIMIZATION	We propose a new methodology for reliably solving the correspondence problem between sparse sets of points of two or more images. This is a key step in most problems of computer vision and, so far, no general method exists to solve it. Our methodology is able to handle most of the commonly used assumptions in a unique formulation, independent of the domain of application and type of features. It performs correspondence and outlier rejection in a single step and achieves global optimality with feasible computation. Feature selection and correspondence are first formulated as an integer optimization problem. This is a blunt formulation, which considers the whole combinatorial space of possible point selections and correspondences. To find its global optimal solution, we build a concave objective function and relax the search domain into its convex-hull. The special structure of this extended problem assures its equivalence to the original one, but it can be optimally solved by efficient algorithms that avoid combinatorial search. This methodology can use any criterion provided it can be translated into cost functions with continuous second derivatives.	Univ Tecn Lisboa, Inst Sistemas & Robot, Inst Super Tecn, P-1049001 Lisbon, Portugal	Universidade de Lisboa; Instituto Superior Tecnico	Maciel, J (corresponding author), Univ Tecn Lisboa, Inst Sistemas & Robot, Inst Super Tecn, Av Rovisco Pais, P-1049001 Lisbon, Portugal.	maciel@isr.ist.utl.pt; jpc@isr.ist.utl.pt	Costeira, Joao P/D-8157-2013	Costeira, Joao P/0000-0001-6769-2935				BERTHILSSON R, 1997, P SCAND C IM AN; Bhatia R., 1997, MATRIX ANAL; BURKHARD R, 1993, P DIMACS WORKSH QUAD, P117; CABOT AV, 1970, OPER RES, V18, P82, DOI 10.1287/opre.18.1.82; Cheng Y, 1996, P SPIE C VIS COMM IM; Fielding G, 2000, PATTERN RECOGN, V33, P1511, DOI 10.1016/S0031-3203(99)00132-6; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; GOLDBERG AV, 1988, P 29 IEEE S F COMP S, P174; Horn R. A., 1986, MATRIX ANAL; HORST R., 1995, HDB GLOBAL OPTIMIZAT; Judice J, 1992, RECENT ADV GLOBAL OP, P76; Lucas Bruce, 1981, IJCAI; MACIEL J, 1999, 1199 VISLABTR; MACIEL J, 2000, P 11 BMVC BRIST UK, P626; MACIEL J, 2001, THESIS I SUPERIOR TE; MEYER C, 2000, 193 KARL FRANZ U GRA; NEMHAUSER GL, 1988, INTEGR COMBINATORIAL; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PARADOLAS P, 1986, CS8633 PENNS STAT U; PARDALOS PM, 1986, SIAM REV, V28, P367, DOI 10.1137/1028106; ROY S, 1997, P INT C COMP VIS; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; SILVA C, 2001, THESIS I SUPERIOR TE; STARINK JPP, 1995, PATTERN RECOGN, V28, P231, DOI 10.1016/0031-3203(94)00087-3; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr P.H.S., 1995, THESIS U OXFORD; WU MS, 1995, PATTERN RECOGN LETT, V16, P23, DOI 10.1016/0167-8655(94)00077-G; Zhang Z., 1992, RR1658 INRIA; [No title captured]	30	118	129	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2003	25	2					187	199		10.1109/TPAMI.2003.1177151	http://dx.doi.org/10.1109/TPAMI.2003.1177151			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	637NX		Green Submitted			2022-12-18	WOS:000180519800004
J	Morita, T; Kanade, T				Morita, T; Kanade, T			A sequential factorization method for recovering shape and motion from image streams	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape from motion; singular value decomposition; feature tracking; 3D object reconstruction; image understanding; real-time vision		We present a sequential factorization method for recovering the three-dimensional shape of an object and the motion of the camera from a sequence of images, using tracked features. The factorization method originally proposed by Tomasi and Kanade produces robust and accurate results incorporating the singular value decomposition. However, it is still difficult to apply the method to real-time applications, since it is based on a batch-type operation and the cost of the singular value decomposition is large. We develop the factorization method into a sequential method by regarding the feature positions as a vector time series. The new method produces estimates of shape and motion at each frame. The singular value decomposition is replaced with an updating computation of only three dominant eigenvectors, which can be performed in O(P-2) time, while the complete singular value decomposition requires O(FP2) operations for an F x P matrix. Also, the method is able to handle infinite sequences, since it does not store any increasingly large matrices. Experiments using synthetic and real images illustrate that the method has nearly the same accuracy and robustness as the original method.	CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University	Morita, T (corresponding author), FUJITSU LABS LTD,AUTONOMOUS SYST LAB,NAKAHARA KU,4-1-1 KAMIKODANAKA,KAWASAKI,KANAGAWA 21188,JAPAN.							COMON P, 1990, P IEEE, V78, P1327, DOI 10.1109/5.58320; *FINL HOL FILM COR, SAT RESC SPAC HIGHL; Golub G. H., 1996, MATRIX COMPUTATIONS; POELMAN CJ, 1994, P 3 EUR C COMP VIS S, V1, P97; Press WH, 1988, NUMERICAL RECIPES C; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684	6	118	127	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					858	867		10.1109/34.608289	http://dx.doi.org/10.1109/34.608289			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987		Green Published			2022-12-18	WOS:A1997XT98700005
J	Ha, TM; Bunke, H				Ha, TM; Bunke, H			Off-line, handwritten numeral recognition by perturbation method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						writing habits and styles; writing instruments; reversing process; perturbation method; decision combination; k-nearest neighbor rule; neural networks		This paper presents a new approach to off-line, handwritten numeral recognition. From the concept of perturbation due to writing habits and instruments, we propose a recognition method which is able to account for a variety of distortions due to eccentric handwriting. We tested our method on two worldwide standard databases of isolated numerals, namely, CEDAR and NIST, and obtained 99.09 percent and 99.54 percent correct recognition rates al no-rejection level, respectively. The latter result was obtained by testing on more than 170,000 numerals.			Ha, TM (corresponding author), UNIV BERN,INST COMP SCI & APPL MATH,NEUBRUECKSTR 10,CH-3012 BERN,SWITZERLAND.							Baird HS., 1992, STRUCTURED DOCUMENT, P546, DOI [10.1007/978-3-642-77281-8_26, DOI 10.1007/978-3-642-77281-8_26]; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P705, DOI 10.1142/S0218001493000352; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784; GUO J, 1993, IEICE D, V176, P835; HA TM, 1994, P 4 INT WORKSH FRONT, P97; HA TM, 1996, IAM96014 U BERN; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; KNERR S, 1993, P 1993 INT S NONL TH, V3; Lee D.-S., 1993, P 3 INT WORKSH FRONT, P153; Pratt W, 1991, DIGITAL IMAGE PROCES; REVOW M, 1993, PREPR 3 INT WORKSH F, P142; SCHURMANN J, 1992, P IEEE, V80, P1101, DOI 10.1109/5.156473; SMITH SJ, 1994, IEEE T PATTERN ANAL, V16, P915, DOI 10.1109/34.310689; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; Ullmann J.R., 1973, PATTERN RECOGNITION; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906; WILKINSON RA, 1992, 4912 NISTIR US BUR C	18	118	121	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					535	539		10.1109/34.589216	http://dx.doi.org/10.1109/34.589216			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300015
J	TISTARELLI, M; SANDINI, G				TISTARELLI, M; SANDINI, G			ON THE ADVANTAGES OF POLAR AND LOG-POLAR MAPPING FOR DIRECT ESTIMATION OF TIME-TO-IMPACT FROM OPTICAL-FLOW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACTIVE VISION; OPTICAL FLOW; SPACE-VARIANT SENSING; TIME TO IMPACT; VISUAL MOTION; VISUAL NAVIGATION	STRATEGY; FIELD; DEPTH	The estimation of time to impact is of vital importance for animals as well as for autonomous robots. The optical flow, which is the 2-D projection on the retinal plane of the relative, 3-D motion between the observer and the objects in the scene, can be used to estimate the time to impact. In this correspondence, the application of an anthropomorphic, retina-like visual sensor and the advantages of polar and log-polar mapping for visual navigation are investigated. From a static viewpoint, the main advantage of a log-polar sensor, apart from the shape invariance property to scaling and rotations [1], [2], stems from the considerable data reduction obtained with the nonuniform sampling, in conjunction with a high resolution in the central part of the field of view (which may correspond to the focus of attention). Considering a dynamic image sequence, there are further advantages to performing the log-polar transformation. In this correspondence, we demonstrate that the motion equations that relate the egomotion and/or the motion of the objects in the scene to the optical flow are considerably simplified if the velocity is represented in a polar or log-polar coordinate system, as opposed to a Cartesian representation. The analysis is conducted for tracking egomotion but is then generalized to arbitrary sensor and object motion. The main result stems from the abundance of equations that can be written directly that relate the polar or log-polar optical flow with the time to impact. Experiments performed on images acquired from real scenes are presented.			TISTARELLI, M (corresponding author), UNIV GENOA,DEPT COMMUN COMP & SYST SCI,INTEGRATED ADV ROBOT LAB,I-16126 GENOA,ITALY.		Tistarelli, Massimo/AAH-9437-2021	Tistarelli, Massimo/0000-0002-3406-3048				Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; ALOIMONOS Y, 1990, MAY P INT WORKSH ACT; [Anonymous], 1986, EVASION DIVISAS HIST; BAJCSY RK, 1985, 3RD P IEEE WORKSH CO, P13; Ballard D.H., 1982, COMPUTER VISION; BALLARD DH, 1989, OPT NEWS, V15, P17; BARTLETT SL, 1990, P SPIE INT C INTELL, V9, P4; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BRACCINI C, 1982, BIOL CYBERN, V44, P47, DOI 10.1007/BF00353955; BURT PJ, 1988, SMART SENSING MACHIN; CHIANG AM, 1988, P WORKSHOP HARDWARE, P171; DEMICHELI E, 1988, P IEEE INT WORKSHOP; DICKMANNS ED, 1988, 5TH P INT S ROB RES; GROSSO E, 1989, IEEE T SYST MAN CYBE, V19; HILDRETH E, 1983, MEASUREMENT VISUAL M; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Inoue H., 1985, Proceedings of '85 International Conference on Advanced Robotics, P199; JAIN R, 1987, IEEE T PATTERN ANAL, V9, P356, DOI 10.1109/TPAMI.1987.4767919; Marr D., 1982, VISION; MASSONE L, 1985, COMPUT VISION GRAPH, V30, P169, DOI 10.1016/0734-189X(85)90095-7; MORASSO P, 1986, P NATO ARW SENSORS S; NAGEL HH, 1990, 1ST P EUR C COMP VIS, P139; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; RIEGER JH, 1984, PROCESSING DIFFERENT; SANDINI G, 1990, IEEE T PATTERN ANAL, V12, P13, DOI 10.1109/34.41380; SANDINI G, 1980, COMPUT VISION GRAPH, V14, P365, DOI 10.1016/0146-664X(80)90026-X; SANDINI G, 1987, 4TH P INT S ROB RES; SANDINI G, 1989, 5TH P INT S ROB RES; SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636; TISTARELLI M, 1990, IMAGE VISION COMPUT, V8, P271, DOI 10.1016/0262-8856(90)80003-C; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; URAS S, 1988, BIOL CYBERN, V60, P69; VANDERSPIEGEL J, 1989, ANALOG VLSI NEURAL N; Weiman C. F. R., 1990, SPIE INT C INTELL RO, V1192, P843; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; WEIMAN CFR, 1990, COMMUNICATION	37	118	128	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1993	15	4					401	410		10.1109/34.206959	http://dx.doi.org/10.1109/34.206959			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU543					2022-12-18	WOS:A1993KU54300007
J	MOHAN, R; NEVATIA, R				MOHAN, R; NEVATIA, R			USING PERCEPTUAL ORGANIZATION TO EXTRACT 3-D STRUCTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,DEPT COMP SCI,LOS ANGELES,CA 90089; UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,DEPT ELECT ENGN,LOS ANGELES,CA 90089	University of Southern California; University of Southern California								Amari S., 1982, COMPETITION COOPERAT; [Anonymous], 1985, PERCEPTUAL ORG VISUA; ARBIB MA, 1985, HUM NEUROBIOL, V4, P201; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Ballard D.H., 1982, COMPUTER VISION; BALLARD DH, 1983, NATURE, V306, P21, DOI 10.1038/306021a0; BALLARD DH, 1986, TR148 U ROCH DEP COM; BINFORD T, 1982, INT J ROBOTICS RES, V1; CARPENTER GA, 1987, SCIENCE, V235; COCHRAN SD, 1987, FEB P DARPA IM UND W, P777; FAHLMAN SE, 1983, P NAT C ARTIFICIAL I; FAHLMAN SE, 1987, COMPUTER, P100; FELDMAN JA, 1982, COGNITIVE SCI, V6, P205, DOI 10.1207/s15516709cog0603_1; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FUA P, 1987, FEB P DARPA IM UND W; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HANSON A, 1978, VISIONS COMPUTER SYS; HERMAN M, 1984, P DARPA IMAGE UNDERS, P137; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HUERTAS A, 1988, COMPUT VISION GRAPH, V41, P131, DOI 10.1016/0734-189X(88)90016-3; HUERTAS A, 1986, IRIS203 U SO CAL I R; HUERTAS A, 1983, AUG P IJCAI KARLSR, P1099; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; JULESZ B, 1981, PERCEPTUAL ORG, P27; Katz D., 1950, GESTALT PSYCHOL ITS; KELLY RE, 1977, J PHOTOGRAM ENG REMO; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LIM HS, 1987, FEB P DARPA IM UND W, P234; LOWE DG, 1983, AUG P AAAI 83 WASH; MATSUYAMA T, 1985, AUG P IJCAI LOS ANG; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708; MOHAN R, USCIRIS225 TECH REP; MOHAN R, 1987, DEC P IEEE COMP SOC; MOHAN R, 1989, JUN P IEEE C COMP VI; MOHAN R, 1988, APR P DARPA IM UND W; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; OHTA Y, 1983, MAR IEEE T PATT AN M; PALMER SE, 1983, HUMAN MACHINE VISION, P269; REYNOLDS G, 1987, FEB P DARPA IM UND W; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TRIESMAN A, 1982, J EXP PSYCHOL HUMAN, V8, P194; ZUCKER SW, 1983, HUMAN MACHINE VISION, P545	49	118	132	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1121	1139		10.1109/34.42852	http://dx.doi.org/10.1109/34.42852			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600001
J	BOVIK, AC; HUANG, TS; MUNSON, DC				BOVIK, AC; HUANG, TS; MUNSON, DC			THE EFFECT OF MEDIAN FILTERING ON EDGE ESTIMATION AND DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801; UNIV ILLINOIS,DEPT ELECT & COMP ENGN,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign			Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X				BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247; BOVIK AC, 1985, COMPUT VISION RES CT; BOVIK AC, 1985, JOINT DISTRIBUTION O; BOVIK AC, IN PRESS IEEE T ACOU; CANNY JF, 1983, MIT720 AI LAB TECH R; DIETZ TE, 1982, CRYOBIOLOGY, V19, P539, DOI 10.1016/0011-2240(82)90183-3; GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUANG TS, 1981, 2 DIMENSIONAL DIGITA, V2; KUHLMANN F, 1981, IEEE T COMMUN, V29, P1374, DOI 10.1109/TCOM.1981.1095142; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NODES TA, 1983, IEEE T ACOUST SPEECH, V31, P1350, DOI 10.1109/TASSP.1983.1164220; Pratt W. K., 1978, DIGITAL IMAGE PROCES; Roberts L, 1965, MACHINE PERCEPTION 3; TUKEY JW, 1974 EASCON, P673; YANG CJ, 1981, COMPUT GRAPHICS IMAG, V15, P224	16	118	122	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					181	194		10.1109/TPAMI.1987.4767894	http://dx.doi.org/10.1109/TPAMI.1987.4767894			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869390				2022-12-18	WOS:A1987G163300001
J	TURNEY, JL; MUDGE, TN; VOLZ, RA				TURNEY, JL; MUDGE, TN; VOLZ, RA			RECOGNIZING PARTIALLY OCCLUDED PARTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											TURNEY, JL (corresponding author), UNIV MICHIGAN,CTR ROBOT & INTEGRATED MFG,DEPT ELECT ENGN & COMP,DIV ROBOT SYST,ANN ARBOR,MI 48109, USA.							ARBUSCHI A, 1983, IMAGE ANAL; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barrow H. G., 1971, Machine Intelligence Volume 6, P377; BAUMANN EE, 1981, OCT P INT C CYB SOC, P433; BAUMANN EW, 1982, NOV P AUTOFACT, V4; BLINCHIKOFF HJ, 1976, FILTERING TIME FREQU, pCH7; EICHEL PH, 1985, THESIS U MICHIGAN; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Lawson C. L., 1974, SOLVING LEAST SQUARE; MERLIN PM, 1975, IEEE T COMPUT, VC 24, P96, DOI 10.1109/T-C.1975.224087; MUDGE TN, 1983, 2ND P ANN IEEE COMP, P56; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PERKINS WA, 1980, 5TH P INT C PATT REC; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; TURNEY JL, 1983, APR P C ART INT ROCH; TURNEY JL, 1983, NOV P SOC PHOT INS 2, V449, P719; VOLZ RA, 1984, IEEE T SYST MAN CYB, V14, P863, DOI 10.1109/TSMC.1984.6313313; WOLTER J, 1982, 1982 P M IND APPL SO, P1309	19	118	124	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					410	421		10.1109/TPAMI.1985.4767680	http://dx.doi.org/10.1109/TPAMI.1985.4767680			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869279	Green Submitted			2022-12-18	WOS:A1985ALB6900005
J	He, R; Wu, X; Sun, ZN; Tan, TN				He, Ran; Wu, Xiang; Sun, Zhenan; Tan, Tieniu			Wasserstein CNN: Learning Invariant Features for NIR-VIS Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heterogeneous face recognition; VIS-NIR face matching; feature representation	SPECTRAL REGRESSION; COUPLED DICTIONARY	Heterogeneous face recognition (HFR) aims at matching facial images acquired from different sensing modalities with mission-critical applications in forensics, security and commercial sectors. However, HFR presents more challenging issues than traditional face recognition because of the large intra-class variation among heterogeneous face images and the limited availability of training samples of cross-modality face image pairs. This paper proposes the novel Wasserstein convolutional neural network (WCNN) approach for learning invariant features between near-infrared (NIR) and visual (VIS) face images (i.e., NIR-VIS face recognition). The low-level layers of the WCNN are trained with widely available face images in the VIS spectrum, and the high-level layer is divided into three parts: the NIR layer, the VIS layer and the NIR-VIS shared layer. The first two layers aim at learning modality-specific features, and the NIR-VIS shared layer is designed to learn a modality-invariant feature subspace. The Wasserstein distance is introduced into the NIR-VIS shared layer to measure the dissimilarity between heterogeneous feature distributions. W-CNN leaming is performed to minimize the Wasserstein distance between the NIR distribution and the VIS distribution for invariant deep feature representations of heterogeneous face images. To avoid the over-fitting problem on small-scale heterogeneous face data, a correlation prior is introduced on the fully-connected WCNN layers to reduce the size of the parameter space. This prior is implemented by a low-rank constraint in an end-to-end network. The joint formulation leads to an alternating minimization for deep feature representation at the training stage and an efficient computation for heterogeneous data at the testing stage. Extensive experiments using three challenging NIR-VIS face recognition databases demonstrate the superiority of the WCNN method over state-of-the-art methods.	[He, Ran; Wu, Xiang; Sun, Zhenan; Tan, Tieniu] Univ Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Ctr Res Intelligent Percept & Comp, CAS,CASIA,Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; University of Chinese Academy of Sciences, CAS	Sun, ZN (corresponding author), Univ Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Ctr Res Intelligent Percept & Comp, CAS,CASIA,Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	rhe@nlpr.ia.ac.cn; xiang.wu@cripac.ia.ac.cn; znsun@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn	Wu, Xiang/AAU-4792-2021	Wu, Xiang/0000-0001-5317-1338	State Key Development Program [2016YFB1001001]; National Natural Science Foundation of China [61622310, 61427811]	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	We would like to thank the associate editor and the reviewers for their valuable comments and advice. This work is funded by State Key Development Program (Grant No. 2016YFB1001001) and the National Natural Science Foundation of China (Grants No. 61622310 and 61427811).	Arjovsky M, 2017, PR MACH LEARN RES, V70; Berthelot D., 2017, BEGAN BOUNDARY EQUIL, DOI DOI 10.48550/ARXIV.1703.10717; Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832; Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314; Dong Yi, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163093; Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482; Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770; Gong DH, 2017, IEEE T IMAGE PROCESS, V26, P2079, DOI 10.1109/TIP.2017.2651380; Goodfellow I. J., 2013, P 30 INT C MACH LEAR; Goswami D, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; He R, 2017, AAAI CONF ARTIF INTE, P2000; He R, 2017, PATTERN RECOGN, V66, P1, DOI 10.1016/j.patcog.2017.02.002; Huang D., 2012, IRIPTR12FR001 BEIJ U; Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310; Huang LK, 2012, INT C PATT RECOG, P1683; Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267; Huang XS, 2013, IEEE T IMAGE PROCESS, V22, P353, DOI 10.1109/TIP.2012.2215617; Jin Y, 2015, IEEE T INF FOREN SEC, V10, P640, DOI 10.1109/TIFS.2015.2390414; Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kawulok M., 2016, ADV FACE DETECTION F, P189, DOI DOI 10.1007/978-3-319-25958-1_8; Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374; Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229; Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180; Lei Z., 2007, P IAPR IEEE INT C BI, P1700; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; Lei Z, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4563043; Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Li ZF, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2807705; Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Liu XX, 2016, LECT NOTES COMPUT SC, V9967, P147, DOI 10.1007/978-3-319-46654-5_17; Liu XX, 2016, INT CONF BIOMETR; Liu X, 2017, FRONT COMPUT SCI-CHI, V11, P208, DOI 10.1007/s11704-016-6076-3; Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001; Parkhi Omkar M., 2015, BRIT MACH VIS C; Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47; Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shao M, 2017, IEEE T NEUR NET LEAR, V28, P451, DOI 10.1109/TNNLS.2016.2517014; Su B, 2017, PROC CVPR IEEE, P2906, DOI 10.1109/CVPR.2017.310; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang X, 2002, IEEE IMAGE PROC, P257; Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414; Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261; Wang R, 2009, LECT NOTES COMPUT SC, V5558, P319, DOI 10.1007/978-3-642-01793-3_33; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xavier G, 2010, P INT C ART INT STAT, P499; Xiao LP, 2013, ELECTRON J QUAL THEO, P1; Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977	59	117	127	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1761	1773		10.1109/TPAMI.2018.2842770	http://dx.doi.org/10.1109/TPAMI.2018.2842770			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29993534	Green Submitted			2022-12-18	WOS:000470972300018
J	Shahroudy, A; Ng, TT; Gong, YH; Wang, G				Shahroudy, Amir; Ng, Tian-Tsong; Gong, Yihong; Wang, Gang			Deep Multimodal Feature Analysis for Action Recognition in RGB plus D Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal analysis; RGB plus D; action recognition; structured sparsity	ENSEMBLE	Single modality action recognition on RGB or depth sequences has been extensively explored recently. It is generally accepted that each of these two modalities has different strengths and limitations for the task of action recognition. Therefore, analysis of the RGB+D videos can help us to better study the complementary properties of these two types of modalities and achieve higher levels of performance. In this paper, we propose a new deep autoencoder based shared-specific feature factorization network to separate input multimodal signals into a hierarchy of components. Further, based on the structure of the features, a structured sparsity learning machine is proposed which utilizes mixed norms to apply regularization within components and group selection between them for better classification performance. Our experimental results show the effectiveness of our cross-modality feature analysis framework by achieving state-of-the-art accuracy for action classification on five challenging benchmark datasets.	[Shahroudy, Amir; Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Shahroudy, Amir; Ng, Tian-Tsong] Inst Infocomm Res, 1 Fusionopolis Way, Singapore 138632, Singapore; [Gong, Yihong] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710048, Shaanxi, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Xi'an Jiaotong University	Shahroudy, A (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.; Shahroudy, A (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way, Singapore 138632, Singapore.	amir3@ntu.edu.sg; ttng@i2r.a-star.edu.sg; ygong@mail.xjtu.edu.cn; wanggang@ntu.edu.sg	ARSLAN, Okan/AAA-3232-2020		National Research Foundation, Singapore	National Research Foundation, Singapore(National Research Foundation, Singapore)	This research was carried out at the Rapid-Rich Object Search (ROSE) Lab at the Nanyang Technological University, Singapore. The ROSE Lab is supported by the National Research Foundation, Singapore, under its Interactive Digital Media (IDM) Strategic Research Programme. Gang Wang is the corresponding author.	Andrew Galen, 2013, ICML; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bach F. R., 2005, 688 U CAL DEP STAT; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Borga M., 2001, ONLINE TUTORIAL; Bosch A., 2007, P 6 ACM INT C IM VID, V5, P401, DOI [10.1145/1282280.1282340, DOI 10.1145/1282280]; Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83; Chatzis S., 2013, P 30 INT C MACH LEAR, P729; Ding WW, 2016, J VIS COMMUN IMAGE R, V35, P103, DOI 10.1016/j.jvcir.2015.12.006; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Eigen David, 2014, NEURIPS; Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772; Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872; Gu J., 2015, CORR; Han F., 2016, CORR; Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; HU JF, 2015, PROC CVPR IEEE, P5344; Jia Y., 2010, NIPS, V10, P982; Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708; Kosmopoulos Dimitrios I., 2013, Distributed, Ambient, and Pervasive Interactions. First International Conference, DAPI 2013. Held as Part of HCI International 2013. Proceedings: LNCS 8028, P42, DOI 10.1007/978-3-642-39351-8_5; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lai PL, 2000, IEEE IJCNN, P614; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Le Q.V., 2011, NEURIPS, P1017; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Lee Honglak, 2008, ADV NEURAL INFORM PR, V20; Liu HP, 2015, NEUROCOMPUTING, V149, P79, DOI 10.1016/j.neucom.2013.12.061; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104; Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227; Meng M, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/MWSYM.2015.7166850; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Peng X, 2014, CORR; Perronnin F, 2007, PROC CVPR IEEE, P2272; Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768; Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167; Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389; Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860; Rahmani H, 2014, INT C PATT RECOG, P3511, DOI 10.1109/ICPR.2014.604; Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Ranzato M., 2007, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/mitpress/7503.003.0147; Rui PL, 2014, INFORMATION TECHNOLOGY AND COMPUTER APPLICATION ENGINEERING, P1; Salzmann Mathieu, 2010, P 13 INT C ART INT S, P701; Schmidt M., 2005, MINFUNC; Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312; Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295; Shahroudy A, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P73, DOI 10.1109/ISCCSP.2014.6877819; Shao, 2013, P 23 INT JOINT C ART; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Song Y, 2015, IEEE SIGNAL PROC LET, V22, P426, DOI 10.1109/LSP.2014.2361901; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Trindade L, 2013, INT CONF MACH LEARN, P277, DOI 10.1109/ICMLC.2013.6890481; Tsai JS, 2013, IEEE INT C INT ROBOT, P2234, DOI 10.1109/IROS.2013.6696669; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Wang H., 2014, P 30 INT C MACH LEAR, P352; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang H, 2013, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2013.398; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550; Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365; Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123; Yang X., 2012, P 20 ACM INT C MULTI, P1057, DOI [10.1145/2393347.2396382, DOI 10.1145/2393347.2396382]; Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108; Yu G., 2014, ACCV, DOI DOI 10.1007/978-3-319-16814-24; Zhang J., 2016, RGB D BASED ACTION R; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24; Zhao Runlin Z.Y, 2014, MATH COMPUT MODEL, V18, P419; Zhao Y, 2012, J NANOTECHNOL, V2012, DOI 10.1155/2012/601582; Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885; Zhu Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629483	89	117	120	3	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1045	1058		10.1109/TPAMI.2017.2691321	http://dx.doi.org/10.1109/TPAMI.2017.2691321			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28391189	Green Submitted			2022-12-18	WOS:000428901200003
J	Dosovitskiy, A; Springenberg, JT; Tatarchenko, M; Brox, T				Dosovitskiy, Alexey; Springenberg, Jost Tobias; Tatarchenko, Maxim; Brox, Thomas			Learning to Generate Chairs, Tables and Cars with Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional networks; generative models; image generation; up-convolutional networks		We train generative "up-convolutional' neural networks which are able to generate images of objects given object style, viewpoint, and color. We train the networks on rendered 3D models of chairs, tables, and cars. Our experiments show that the networks do not merely learn all images by heart, but rather find a meaningful representation of 3D models allowing them to assess the similarity of different models, interpolate between given views to generate the missing ones, extrapolate views, and invent new objects not present in the training set by recombining training instances, or even two different object classes. Moreover, we show that such generative networks can be used to find correspondences between different objects from the dataset, outperforming existing approaches on this task.	[Dosovitskiy, Alexey; Springenberg, Jost Tobias; Tatarchenko, Maxim; Brox, Thomas] Univ Freiburg, Dept Comp Sci, Freiburg, Germany	University of Freiburg	Dosovitskiy, A (corresponding author), Univ Freiburg, Dept Comp Sci, Freiburg, Germany.	dosovits@cs.uni-freiburg.de; springj@cs.uni-freiburg.de; tatarchm@cs.uni-freiburg.de; brox@cs.uni-freiburg.de			ERC Starting Grant VideoLearn [279401]; Brain-Links-BrainTools Cluster of Excellence - German Research Foundation [EXC 1086]	ERC Starting Grant VideoLearn; Brain-Links-BrainTools Cluster of Excellence - German Research Foundation	The authors acknowledge funding by the ERC Starting Grant VideoLearn (279401). JTS is supported by the Brain-Links-BrainTools Cluster of Excellence funded by the German Research Foundation (EXC 1086).	[Anonymous], 2014, ARXIV14126558; [Anonymous], 2014, ICLR; Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Bengio Y, 2014, PR MACH LEARN RES, V32, P226; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Chang A. X., 2015, ARXIV PREPRINT ARXIV; Denton E, 2015, DEEP GENERATIVE IMAG, DOI DOI 10.5555/; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Eigen David, 2014, NEURIPS; Francos R. P., 2003, P INT C AC SPEECH SI, P569; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jia Y., P ACM MULT, P675; Kavukcuoglu K, 2015, ADV NEURAL INF PROCE, P2017; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kingma D.P., 2015, INT C LEARN REPR, P1; Kingma DP, 2014, ADV NEUR IN, P3581, DOI DOI 10.5555/2969033.2969226; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kulkarni TD, 2015, ADV NEUR IN, V28; Larochelle H., 2011, INT C ART INT STAT; Lee H., 2009, P ANN INT C MACH LEA, P609; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Memisevic R., 2007, P IEEE C COMP VIS PA; Radford A., 2016, ICLR; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2857, DOI 10.1109/CVPR.2011.5995710; Reed S, 2015, ADV NEURAL INFORM PR, P1252; Reed S, 2014, PR MACH LEARN RES, V32, P1431; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Salakhutdinov R., 2009, P 12 INT C ART INT S, P448; Tang Y., 2012, P 15 INT C ART INT S, P1203; Tang Yichuan, 2013, ADV NEURAL INFORM PR, P530; Theis L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039857; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zhu Z., 2014, NIPS, P217	41	117	124	4	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					692	705		10.1109/TPAMI.2016.2567384	http://dx.doi.org/10.1109/TPAMI.2016.2567384			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27187944	Green Submitted			2022-12-18	WOS:000397717600007
J	Hayat, M; Bennamoun, M; An, SJ				Hayat, Munawar; Bennamoun, Mohammed; An, Senjian			Deep Reconstruction Models for Image Set Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image set classification; deep learning; auto-encoders; video based face recognition; object recognition	FACE RECOGNITION; APPEARANCE	Image set classification finds its applications in a number of real-life scenarios such as classification from surveillance videos, multi-view camera networks and personal albums. Compared with single image based classification, it offers more promises and has therefore attracted significant research attention in recent years. Unlike many existing methods which assume images of a set to lie on a certain geometric surface, this paper introduces a deep learning framework which makes no such prior assumptions and can automatically discover the underlying geometric structure. Specifically, a Template Deep Reconstruction Model (TDRM) is defined whose parameters are initialized by performing unsupervised pre-training in a layer-wise fashion using Gaussian Restricted Boltzmann Machines (GRBMs). The initialized TDRM is then separately trained for images of each class and class-specific DRMs are learnt. Based on the minimum reconstruction errors from the learnt class-specific models, three different voting strategies are devised for classification. Extensive experiments are performed to demonstrate the efficacy of the proposed framework for the tasks of face and object recognition from image sets. Experimental results show that the proposed method consistently outperforms the existing state of the art methods.	[Hayat, Munawar; Bennamoun, Mohammed; An, Senjian] Univ Western Australia, Sch Comp Sci & Software Engn, Perth, WA 6009, Australia	University of Western Australia	Hayat, M (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, Perth, WA 6009, Australia.	munawar.hayat@research.uwa.edu.au; mohammed.bennamoun@uwa.edu.au; senjian.an@uwa.edu.au	Hayat, Munawar/AAU-8658-2020; Bennamoun, Mohammed/C-2789-2013	Hayat, Munawar/0000-0002-2706-5985; Bennamoun, Mohammed/0000-0002-6603-3257; An, Senjian/0000-0002-1758-6824	SIRF scholarship from the University of Western Australia (UWA); ARC [DPI10102166]	SIRF scholarship from the University of Western Australia (UWA); ARC(Australian Research Council)	This work is supported by SIRF scholarship from the University of Western Australia (UWA) and ARC grant DPI10102166.	Arandjelovic O, 2005, PROC CVPR IEEE, P581; Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Carreira-Perpinan M. A., 2005, ARTIF INTELL STAT, V10, P17; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Gross R, 2001, CMURITR0118; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005; Harandi M. T., 2010, P IEEE C COMP VIS PA, P2705; Hayat M, 2014, PROC CVPR IEEE, P1915, DOI 10.1109/CVPR.2014.246; Hinton G., 2010, MOMENTUM, V9, P926; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lee H., 2009, P ANN INT C MACH LEA, P609; Lee KC, 2003, PROC CVPR IEEE, P313; Leibe B, 2003, PROC CVPR IEEE, P409; Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nishiyama M., 2007, P IEEE C COMP VIS PA, P1; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ortiz EG, 2013, PROC CVPR IEEE, P3531, DOI 10.1109/CVPR.2013.453; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Smolensky P, 1986, PARALLEL DISTRIBUTED, V1; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang R., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587719; Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965; Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968; Yang D, 2013, IEEE INT WORKSH COMP, P13, DOI 10.1109/CAMAD.2013.6708080; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhiwu Huang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P589, DOI 10.1007/978-3-642-37444-9_46; Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331	45	117	125	1	74	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					713	727		10.1109/TPAMI.2014.2353635	http://dx.doi.org/10.1109/TPAMI.2014.2353635			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353289				2022-12-18	WOS:000351213400002
J	Vasconcelos, F; Barreto, JP; Nunes, U				Vasconcelos, Francisco; Barreto, Joao P.; Nunes, Urbano			A Minimal Solution for the Extrinsic Calibration of a Camera and a Laser-Rangefinder	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Extrinsic calibration; laser-rangefinder; euclidean registration; minimal problems; sensor fusion		This paper presents a new algorithm for the extrinsic calibration of a perspective camera and an invisible 2D laser-rangefinder (LRF). The calibration is achieved by freely moving a checkerboard pattern in order to obtain plane poses in camera coordinates and depth readings in the LRF reference frame. The problem of estimating the rigid displacement between the two sensors is formulated as one of registering a set of planes and lines in the 3D space. It is proven for the first time that the alignment of three plane-line correspondences has at most eight solutions that can be determined by solving a standard p3p problem and a linear system of equations. This leads to a minimal closed-form solution for the extrinsic calibration that can be used as hypothesis generator in a RANSAC paradigm. Our calibration approach is validated through simulation and real experiments that show the superiority with respect to the current state-of-the-art method requiring a minimum of five input planes.	[Vasconcelos, Francisco; Barreto, Joao P.; Nunes, Urbano] Univ Coimbra, Dept Elect & Comp Engn, Inst Syst & Robot, P-3030290 Coimbra, Portugal	Universidade de Coimbra	Vasconcelos, F (corresponding author), Univ Coimbra, Dept Elect & Comp Engn, Inst Syst & Robot, P-3030290 Coimbra, Portugal.	fpv@isr.uc.pt; jpbar@isr.uc.pt; urbano@isr.uc.pt	Nunes, Urbano J/G-1187-2011; Barreto, Joao P/I-2845-2012	Nunes, Urbano J/0000-0002-7750-5221; Barreto, Joao P/0000-0001-5220-9170	Portuguese Foundation for Science and Technology (FCT) [SFRH/BD/72323/2010]; FCT [PTDC/EEA-AUT/113818/2009]	Portuguese Foundation for Science and Technology (FCT)(Portuguese Foundation for Science and Technology); FCT(Portuguese Foundation for Science and TechnologyEuropean Commission)	Francisco Vasconcelos is funded by the Portuguese Foundation for Science and Technology (FCT) through the PhD grant SFRH/BD/72323/2010. The authors also want to acknowledge the generous support of FCT through the project grant PTDC/EEA-AUT/113818/2009.	Aliakbarpour H., 2009, INT C ADV ROB, P1; Barreto J., 2008, P 8 WORKSH OMN VIS C; Barreto J. P., 2009, PROCEDINGS BRIT MACH; Caglioti V, 2008, VISAPP-ROBOTIC PERCEPTION, P33; Douillard B., 2008, P ROB SCI SYST C; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fruh C, 2004, INT J COMPUT VISION, V60, P5, DOI 10.1023/B:VISI.0000027787.82851.b6; Ganhua Li, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3854, DOI 10.1109/IROS.2007.4399041; Gao C, 2010, IEEE INT CONF ROBOT, P279, DOI 10.1109/ROBOT.2010.5509880; Grunert J.A., 1841, GRUNERTS ARCHIV MATH, V1, P238; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Ma Y., 2004, INVITATION 3 D VISIO; Moriya T, 2000, PROC CVPR IEEE, P766, DOI 10.1109/CVPR.2000.855898; Naroditsky O, 2011, IEEE INT CONF ROBOT; Nez P., 2009, P EUR C MOB ROB, P3136; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Premebida C, 2009, J FIELD ROBOT, V26, P696, DOI 10.1002/rob.20312; Ramalingam S, 2010, LECT NOTES COMPUT SC, V6315, P436, DOI 10.1007/978-3-642-15555-0_32; Ramos FT, 2007, IEEE INT CONF ROBOT, P2036, DOI 10.1109/ROBOT.2007.363621; SCARAMUZZA D, 2007, P IEEE INT C INT ROB; SICK AG, LMS200 211 221 291 L; Stolfi J., 1991, ORIENTED PROJECTIVE; Sturm P, 2008, LECT NOTES COMPUT SC, V5305, P609, DOI 10.1007/978-3-540-88693-8_45; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Triggs B., 1883, P INT WORKSH VIS ALG, P153; Unnikrishnan R., 2005, ORAL HLTH STATUS ORA; Zhang Q., 2004, PROC IEEERSJ INT C I, P2301, DOI 10.1109/IROS.2004.1389752; Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289	30	117	129	5	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2097	2107		10.1109/TPAMI.2012.18	http://dx.doi.org/10.1109/TPAMI.2012.18			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22231591				2022-12-18	WOS:000308755000003
J	Swaminathan, R; Nayar, SK				Swaminathan, R; Nayar, SK			Nonmetric calibration of wide-angle lenses and polycameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; wide-angle lens; radial distortion; decentering distortion; camera clusters; polycamera; nonsingle viewpoint; minimum working distance; real-time panoramic sensor	TRUE MULTIIMAGE ALIGNMENT; CAMERA CALIBRATION; DISTORTION CORRECTION	Images taken with wide-angle cameras tend to have severe distortions which pull points towards the optical center. This paper proposes a simple method for recovering the distortion parameters without the use of any calibration objects. Since distortions cause straight lines in the scene to appear as curves in the image, our algorithm seeks to find the distortion parameters that map the image curves to straight lines. The user selects a small set of points along the image curves. Recovery of the distortion parameters is formulated as the minimization of an objective function which is designed to explicitly account for noise in the selected image points. Experimental results are presented for synthetic data as well as real images. We also present the idea of a polycamera which is defined as a tightly packed camera cluster. Possible configurations are proposed to capture very large fields of view. Such camera clusters tend to have a nonsingle viewpoint. We therefore provide analysis of what we call the minimum working distance for such clusters. Finally, we present results for a polycamera consisting of four wide-angle sensors having a minimum working distance of about 4m. On undistorting the acquired images using our proposed technique, we create real-time high resolution panoramas.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Swaminathan, R (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	srahul@cs.columbia.edu; nayar@cs.columbia.edu		Swaminathan, Rahul/0000-0003-1647-6313				BECKER S, 1995, P SOC PHOTO-OPT INS, V2410, P447, DOI 10.1117/12.205979; Born M., 1968, PRINCIPLES OPTICS; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; Brown Duane C, 1966, PHOTOGRAMMETRIC ENG, P2, DOI DOI 10.1234/12345678; Conrady A. E., 1919, MON NOT R ASTRON SOC, V79, P384; GOSHTASBY A, 1989, COMPUT VISION GRAPH, V47, P385, DOI 10.1016/0734-189X(89)90120-5; KANG SB, 1997, TECHNICAL REPORT SER; MCCUTCHEN D, 1991, Patent No. 5023725; NALWA V, 1996, TRUE OMNIDIRECTIONAL; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589; Sawhney HS, 1997, PROC CVPR IEEE, P450, DOI 10.1109/CVPR.1997.609364; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; STEIN GP, 1997, P 1997 C COMP VIS PA, P143; STEIN GP, 1993, THESIS MIT AI LAB; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; *VNI, 1998, IMSL FORTRAN NUMERIC; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901	19	117	142	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1172	1178		10.1109/34.879797	http://dx.doi.org/10.1109/34.879797			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ		Green Submitted			2022-12-18	WOS:000165067100010
J	Nastar, C; Ayache, N				Nastar, C; Ayache, N			Frequency-based nonrigid motion analysis: Application to four dimensional medical images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						medical image analysis; nonrigid motion; deformable models; modal analysis; Fourier analysis; compression; dynamic data; four-dimensional images; cardiac imagery; automatic diagnosis	MODELS; SHAPE	We present a method for nonrigid motion analysis in time sequences of volume images (4D data). In this method, nonrigid motion of the deforming object contour is dynamically approximated by a physically-based deformable surface. In order to reduce the number of parameters describing the deformation, we make use of a modal analysis which provides a spatial smoothing of the surface. The deformation spectrum, which outlines the main excited modes, can be efficiently used for deformation comparison. Fourier analysis on time signals of the main deformation spectrum components provides a temporal smoothing of the data. Thus a complex nonrigid deformation is described by only a few parameters: the main excited modes and the main Fourier harmonics. Therefore, 4D data can be analyzed in a very concise manner. The power and robustness of the approach is illustrated by various results on medical data. We believe that our method has important applications in automatic diagnosis of heart diseases and in motion compression.			Nastar, C (corresponding author), INST NATL RECH INFORMAT & AUTOMAT, BP 105, F-78153 LE CHESNAY, FRANCE.							AMINI AA, 1992, IMAGE VISION COMPUT, V10, P418, DOI 10.1016/0262-8856(92)90027-Z; AMINI AA, 1994, AAAI 1994 SPRING S S; Ashcroft N., 1976, SOLID STATE PHYS; AYACHE N, 1995, IMAGE VISION COMPUT, V13, P295, DOI 10.1016/0262-8856(95)99717-F; AYACHE N, 1992, ACTIVE VISION, pCH17; Ayache N, 1991, ARTIFICIAL VISION MO; BARDINET E, 1995, 1 C COMP VIS VIRT RE, V905; Bathe Klaus Jurgen., 1982, J PRESS VESSEL TECHN; BENAYOUN S, 1995, 1 C COMP VIS VIRT RE, V905; BENAYOUN S, 1994, INT C PATT REC JER I; BLAKE A, 1993, P 4 INT C COMP VIS B, P66; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; CHEN CW, 1994, IEEE T PATTERN ANAL, V16, P342, DOI 10.1109/34.277589; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; COOTES TF, 1995, IMAGE VISION COMPUTI, V13; COOTES TF, 1993, P 13 INT C INF PROC; CRESWELL LL, 1992, IEEE T MED IMAGING, V11, P581, DOI 10.1109/42.192695; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DELINGETTE H, 1991, IEEE C COMPUTER VISI, P467; Duda R.O., 1973, J ROYAL STAT SOC SER; GUEZIEC A, 1993, P 4 INT C COMP VIS B; Huang W.-C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P833, DOI 10.1109/CVPR.1992.223246; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEITNER F, 1990, P INT C CURV SURF CH, V1; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; MONGA O, 1989, P COMPUTER VISION PA; MONGA O, 1990, P 1 EUR C COMP VIS E; NASTAR C, 1995, LECTURE NOTES COMPUT, V994; NASTAR C, 1993, P 4 INT C COMP VIS I; NASTAR C, 1994, P 3 EUR C COMP VIS E; NASTAR C, 1993, P 3 EUR C COMP VIS E; NASTAR C, 1993, P 13 INT C INF PROC; PARK J, 1995, P 5 INT C COMP VIS I; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; PENTLAND A, 1989, COMPUTER GRAPHICS; SHI P, 1994, P IEEE WORKSH BIOM I; SHI P, 1995, P 1 C COMP VIS VIRT, V608; SZELISKI R, 1994, P AAI 1994 SPRING S; Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877; VASILESCU M, 1992, P IEEE COMP SOC C JU, P529; Ye Q.-Z., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P495, DOI 10.1109/ICPR.1988.28276; YUILLE AL, 1989, P COMPUTER VISION PA	48	117	140	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1067	1079		10.1109/34.544076	http://dx.doi.org/10.1109/34.544076			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159		Green Submitted			2022-12-18	WOS:A1996VU15900002
J	WANG, L; PAVLIDIS, T				WANG, L; PAVLIDIS, T			DIRECT GRAY-SCALE EXTRACTION OF FEATURES FOR CHARACTER-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CHARACTER RECOGNITION; FEATURE EXTRACTION; GRAY-SCALE IMAGE; OCR SYSTEMS; SHAPE ANALYSIS; SURFACE DESCRIPTION		Most current OCR systems perform a binarization of the input before attempting recognition. Though this might appear to be a rather innocuous operation since the input is supposed to be binary to start with, a significant amount of information is lost during the process. To avoid this problem, other systems perform recognition without binarization by using techniques related to matched filters. However, this approach is limited to applications where there is only a limited variation on the form of the characters (such as in the case of a single font). In this paper, a new approach is explored; this appraoch eliminates binarization by extracting features directly from gray-scale images. In this method, a digitized gray-scale image is treated as a noisy sampling of the underlying continuous surface, and desired features are obtained by extracting and assembling topographic characteristics of this surface. The advantages and effectiveness of the new approach are both shown theoretically and demonstrated through preliminary experiments of the proposed method.	SUNY STONY BROOK,IMAGE ANAL LAB,STONY BROOK,NY 11794	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	WANG, L (corresponding author), SUNY STONY BROOK,DEPT COMP SCI,STONY BROOK,NY 11794, USA.							CHEN MH, 1991, IEEE T PATTERN ANAL, V13, P30, DOI 10.1109/34.67628; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; JOSEPH E, 1992, P ICPR 11, V2, P238; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Lee D., 1987, Journal of Complexity, V3, P359, DOI 10.1016/0885-064X(87)90006-9; LEUNG CM, 1985, JUN P IEEE COMP VIS, P532; Meer P., 1989, SMOOTHED DIFFERENTIA; NACKMAN LR, 1984, IEEE T PATTERN ANAL, V6, P442, DOI 10.1109/TPAMI.1984.4767549; PAVLIDIS T, 1986, JUN P IEEE COMP VIS, P570; PEUKER TK, 1975, COMPUT GRAPHICS IMAG, V4, P375; POGORELOV AV, 1983, DIFFERENTIAL GEOMETR; Rangarajan K., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P90, DOI 10.1109/CCV.1988.589975; ROCHA J, 1992, NOV P IEEE WORKSH AP; SAKODA WJ, 1992, 1 REP US POST SERV P; Snyder A.W., 1983, OPTICAL WAVEGUIDE TH; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; WANG L, 1992, TR920601 DEP COMP SC; WATSON LT, 1985, COMPUT VISION GRAPH, V29, P143, DOI 10.1016/0734-189X(85)90116-1; ZUNIGA OA, 1983, JUN P IEEE COMP VIS	20	117	130	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					1053	1067		10.1109/34.254062	http://dx.doi.org/10.1109/34.254062			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775					2022-12-18	WOS:A1993MD77500007
J	TRAHANIAS, P; SKORDALAKIS, E				TRAHANIAS, P; SKORDALAKIS, E			SYNTACTIC PATTERN-RECOGNITION OF THE ECG	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NATL TECH UNIV ATHENS,DIV COMP SCI,GR-15773 ATHENS,GREECE	National Technical University of Athens	TRAHANIAS, P (corresponding author), DEMOCRITOS NATL RES CTR PHYS SCI,INST INFORMAT & TELECOMMUN,GR-15310 ATHENS,GREECE.							BELFORTE G, 1979, IEEE T BIO-MED ENG, V26, P125, DOI 10.1109/TBME.1979.326470; BIRMAN KP, 1983, COMPUT BIOMED RES, V16, P311, DOI 10.1016/0010-4809(83)90055-1; BIRMAN KP, 1982, IEEE T PATTERN ANAL, V4, P369, DOI 10.1109/TPAMI.1982.4767268; COAST DA, 1984 P ENG F C COMP; FLOYD RW, 1964, IEEE T COMPUT, VEC13, P346, DOI 10.1109/PGEC.1964.263813; FU KS, 1983, IEEE T PATTERN ANAL, V5, P200; FU KS, 1982, SYNTACTIC PATTERN RE; HOROWITZ SL, 1977, SYNTACTIC PATTERN RE, P31; MYLOPOULOS J, 1983, COMPUTER, P83; PAHLM O, 1984, MED BIOL ENG COMPUT, V22, P289, DOI 10.1007/BF02442095; PAPAKONSTANTINOU G, 1981, COMPUT BIOMED RES, V14, P158, DOI 10.1016/0010-4809(81)90033-1; PAPAKONSTANTINOU G, 1986, PATTERN RECOGN, V19, P297, DOI 10.1016/0031-3203(86)90055-5; PAPAKONSTANTINOU G, 1986, PATTERN RECOGN, V4, P369; SHIBAHARA T, 1982, 4TH P CSCSI SCEIO C, P71; Skordalakis E., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P380; SKORDALAKIS E, 1984, COMPUT BIOMED RES, V17, P208, DOI 10.1016/S0010-4809(84)80012-9; SKORDALAKIS E, 1986, PATTERN RECOGN, V19, P305, DOI 10.1016/0031-3203(86)90056-7; STALLMANN F, 1961, CIRC RES, V9, P1138, DOI 10.1161/01.RES.9.6.1138; TRAHANIAS P, 1989, PATTERN RECOGN LETT, V9, P13, DOI 10.1016/0167-8655(89)90023-8; TSAI WH, 1980, IEEE T SYST MAN CYB, V10, P873, DOI 10.1109/TSMC.1980.4308414; UDUPA JK, 1980, IEEE T BIO-MED ENG, V27, P370, DOI 10.1109/TBME.1980.326650; WILLEMS JL, 1985, CIRCULATION, V71, P523, DOI 10.1161/01.CIR.71.3.523; WILLEMS JL, 1985, COMPUT BIOMED RES, V18, P439, DOI 10.1016/0010-4809(85)90021-7; WILLEMS JL, 1987, CRC CRIT REV MED INF, V1, P165; 1985, EUROPEAN HEART J, V6, P815	25	117	126	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					648	657		10.1109/34.56207	http://dx.doi.org/10.1109/34.56207			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400004
J	SCHWARTZ, EL; SHAW, A; WOLFSON, E				SCHWARTZ, EL; SHAW, A; WOLFSON, E			A NUMERICAL-SOLUTION TO THE GENERALIZED MAPMAKERS PROBLEM - FLATTENING NONCONVEX POLYHEDRAL SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									NYU,COURANT INST MATH SCI,DEPT COMP SCI,NEW YORK,NY 10003	New York University	SCHWARTZ, EL (corresponding author), NYU,SCH MED,DEPT PSYCHIAT,COMPUTAT NEUROSCI LABS,550 1ST AVE,NEW YORK,NY 10016, USA.							CARMAN GJ, 1985, NEUR ABSTR, V11, P1243; DOCARMO M, 1975, DIFFERENTIAL GEOMETR; KAPLOW WK, 1986, NYU CNSTR186 MED CTR; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; MERKER B, 1985, INVESTIG OPHTHALM S, V26, P164; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; OROURKE J, 1984, 2ND P SYMP THEOR ASP; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Schiffman SS, 1981, INTRO MULTIDIMENSION; SCHWARTZ EL, 1985, SOC NEUR ABSTR, V15; SHARIR M, 1986, SIAM J COMPUT, V15, P193, DOI 10.1137/0215014; SHARIR M, 1987, SIAM J COMPUT, V16, P561, DOI 10.1137/0216038; WOLFSON E, 1989, IEEE T PATTERN ANAL, V11, P1001, DOI 10.1109/34.35505	13	117	120	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					1005	1008		10.1109/34.35506	http://dx.doi.org/10.1109/34.35506			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800013
J	PETTIS, KW; BAILEY, TA; JAIN, AK; DUBES, RC				PETTIS, KW; BAILEY, TA; JAIN, AK; DUBES, RC			INTRINSIC DIMENSIONALITY ESTIMATOR FROM NEAR-NEIGHBOR INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PETTIS, KW (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							BALL GH, 1965, FAL P JOINT COMP C, P533; BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; BREIMAN L, 1968, PROBABILITY, P237; CALVERT TW, 1970, IEEE T COMPUT, VC 19, P447, DOI 10.1109/T-C.1970.222943; CHANG CL, 1973, IEEE T SYST MAN CYB, VSMC3, P197, DOI 10.1109/TSMC.1973.5408505; CHEN CK, 1974, IEEE T COMPUT, VC 23, P178, DOI 10.1109/T-C.1974.223882; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis P. J., 1965, HDB MATH FUNCTIONS, P253; DUDA RO, 1973, PATTERN CLASSIFICATI, P87; FRIEDMAN JH, 1975, IEEE T COMPUT, V25, P1000; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Kruskal J.B., 1972, MULTIDIMENSIONAL SCA, V1; KRUSKAL JB, 1966, AT&T TECH J, V45, P1299, DOI 10.1002/j.1538-7305.1966.tb01699.x; KRUSKAL JB, 1971, IEEE T COMPUT, VC 20, P1614, DOI 10.1109/T-C.1971.223184; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; KRUSKAL JB, 1969, MULTIVARIATE ANAL, P639; LEE RCT, 1977, IEEE T COMPUT, V26, P288, DOI 10.1109/TC.1977.1674822; MULLER ME, 1959, COMMUN ACM, V2, P19, DOI 10.1145/377939.377946; ROMNEY AK, 1972, MULTIDIMENSIONAL SCA, V2; ROMNEY AK, 1972, MULTIDIMENSIONAL SCA, V1; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCHWARTZMANN DH, 1975, IEEE T COMPUT, V24, P1175, DOI 10.1109/T-C.1975.224161; Shepard R., 1966, MULTIVARIATE ANAL, P561; SHEPARD RN, 1974, PSYCHOMETRIKA, V39, P373, DOI 10.1007/BF02291665; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; TRUNK GV, 1976, IEEE T COMPUT, V25, P165, DOI 10.1109/TC.1976.5009231; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	29	117	121	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					25	37		10.1109/TPAMI.1979.4766873	http://dx.doi.org/10.1109/TPAMI.1979.4766873			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HA303	21868828				2022-12-18	WOS:A1979HA30300004
J	Huang, XY; Wang, P; Cheng, XJ; Zhou, DF; Geng, QC; Yang, RG				Huang, Xinyu; Wang, Peng; Cheng, Xinjing; Zhou, Dingfu; Geng, Qichuan; Yang, Ruigang			The ApolloScape Open Dataset for Autonomous Driving and Its Application	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Semantics; Task analysis; Videos; Labeling; Two dimensional displays; Image segmentation; Autonomous driving; large-scale datasets; scene; lane parsing; self localization; 3D understanding	POSE	Autonomous driving has attracted tremendous attention especially in the past few years. The key techniques for a self-driving car include solving tasks like 3D map construction, self-localization, parsing the driving road and understanding objects, which enable vehicles to reason and act. However, large scale data set for training and system evaluation is still a bottleneck for developing robust perception models. In this paper, we present the ApolloScape dataset [1] and its applications for autonomous driving. Compared with existing public datasets from real scenes, e.g., KITTI [2] or Cityscapes [3] , ApolloScape contains much large and richer labelling including holistic semantic dense point cloud for each site, stereo, per-pixel semantic labelling, lanemark labelling, instance segmentation, 3D car instance, high accurate location for every frame in various driving videos from multiple sites, cities and daytimes. For each task, it contains at lease 15x larger amount of images than SOTA datasets. To label such a complete dataset, we develop various tools and algorithms specified for each task to accelerate the labelling process, such as joint 3D-2D segment labeling, active labelling in videos etc. Depend on ApolloScape, we are able to develop algorithms jointly consider the learning and inference of multiple tasks. In this paper, we provide a sensor fusion scheme integrating camera videos, consumer-grade motion sensors (GPS/IMU), and a 3D semantic map in order to achieve robust self-localization and semantic segmentation for autonomous driving. We show that practically, sensor fusion and joint learning of multiple tasks are beneficial to achieve a more robust and accurate system. We expect our dataset and proposed relevant algorithms can support and motivate researchers for further development of multi-sensor fusion and multi-task learning in the field of computer vision.	[Huang, Xinyu; Wang, Peng; Cheng, Xinjing; Zhou, Dingfu; Geng, Qichuan; Yang, Ruigang] Baidu Res, Beijing 100085, Peoples R China	Baidu	Wang, P (corresponding author), Baidu Res, Beijing 100085, Peoples R China.	huangximp01@baidu.com; wangpeng54@baidu.com; chengxinjing@baidu.com; zhoudingfu@baidu.com; gengqichuan@baidu.com; ryang@cs.uky.edu	Zhou, Dingfu/AAM-9192-2021	Huang, Xinyu/0000-0002-5786-3101; Yuille, Alan L./0000-0001-5207-9249; Yang, Ruigang/0000-0001-5296-6307	Baidu Inc.	Baidu Inc.	This work is supported by Baidu Inc. We also thank the work of Xibin Song, Binbin Cao, Jin Fang, He Jiang, Yu Zhang, Xiang Gu, and Xiaofei Liu for their laborious efforts in organizing data, helping writing label tools, checking labelled results and manage the content of benchmark websites. We thank Alan L. Yuille, Hongdong Li and Andreas Geiger for benchmark suggestions. Xinyu Huang and Peng Wang contributed equally to this work.	Arnab A, 2016, LECT NOTES COMPUT SC, V9906, P524, DOI 10.1007/978-3-319-46475-6_33; Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005; Byeon W, 2015, PROC CVPR IEEE, P3547, DOI 10.1109/CVPR.2015.7298977; Campbell D, 2017, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2017.10; Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen YH, 2018, PROC CVPR IEEE, P7892, DOI 10.1109/CVPR.2018.00823; Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3; Cheng XJ, 2018, LECT NOTES COMPUT SC, V11220, P108, DOI 10.1007/978-3-030-01270-0_7; Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Coskun H, 2017, IEEE I CONF COMP VIS, P5525, DOI 10.1109/ICCV.2017.589; David P, 2004, INT J COMPUT VISION, V59, P259, DOI 10.1023/B:VISI.0000025800.10423.1f; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Dozat T., 2016, INCORPORATING NESTER; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gadde R, 2017, IEEE I CONF COMP VIS, P4463, DOI 10.1109/ICCV.2017.477; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Guney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044; Hane C, 2013, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2013.20; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffman J, 2016, FCNS WILD PIXELLEVEL; Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kar A., 2017, ADV NEURAL INFORM PR; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9; Kovashka A, 2014, FOUND TRENDS COMPUT, V10, pI, DOI 10.1561/0600000071; Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375; Kundu A, 2016, PROC CVPR IEEE, P3168, DOI 10.1109/CVPR.2016.345; Kundu A, 2014, LECT NOTES COMPUT SC, V8694, P703, DOI 10.1007/978-3-319-10599-4_45; Laskar Z, 2017, IEEE INT CONF COMP V, P920, DOI 10.1109/ICCVW.2017.113; Lee BH, 2015, SENSORS-BASEL, V15, P20779, DOI 10.3390/s150820779; Li GL, 2016, IEEE T KNOWL DATA EN, V28, P2296, DOI 10.1109/TKDE.2016.2535242; Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0_15; Lidar Velodyne, 2018, HDL 64E; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu L., 2018, ARXIV180808779; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Long J., 2018, P IEEE C COMP VIS PA, P6896; Luo Chenxu, 2018, ARXIV181006125; Ma YX, 2019, AAAI CONF ARTIF INTE, P6120; Moreno-Noguer F, 2008, LECT NOTES COMPUT SC, V5303, P405, DOI 10.1007/978-3-540-88688-4_30; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Paszke A., 2016, ARXIV PREPRINT ARXIV; Peng W., 2018, APOLLOSCAPE API; Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353; Qi CR, 2017, ADV NEUR IN, V30; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3; Richter SR, 2017, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2017.243; RIEGL, 2000, VMX 1HA; Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song XB, 2019, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2019.00560; Stein SC, 2014, PROC CVPR IEEE, P304, DOI 10.1109/CVPR.2014.46; Su H., 2012, P WORKSH 26 AAAI C A, V1; Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695; Ummenhofer B., 2017, IEEE C COMP VIS PATT, V5, P6; Vishal Kumar, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI 10.1109/CVPRW.2015.7301390; Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75; Wang P, 2018, PROC CVPR IEEE, P5860, DOI 10.1109/CVPR.2018.00614; Wang P, 2015, IEEE I CONF COMP VIS, P1573, DOI 10.1109/ICCV.2015.184; Wang SL, 2017, IEEE I CONF COMP VIS, P3028, DOI 10.1109/ICCV.2017.327; Wu Y., 2016, GOOGLES NEURAL MACHI; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xie J, 2016, PROC CVPR IEEE, P3688, DOI 10.1109/CVPR.2016.401; Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47; Yu Fisher, 2018, BDD100K DIVERSE DRIV, P6; Yueqing Z., 2018, FIND TINY INSTANCE S; Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441	86	116	123	18	69	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2702	2719		10.1109/TPAMI.2019.2926463	http://dx.doi.org/10.1109/TPAMI.2019.2926463			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31283496	Green Submitted			2022-12-18	WOS:000567471300027
J	Liu, XW; Zhu, XZ; Li, MM; Wang, L; Tang, C; Yin, JP; Shen, DG; Wang, HM; Gao, W				Liu, Xinwang; Zhu, Xinzhong; Li, Miaomiao; Wang, Lei; Tang, Chang; Yin, Jianping; Shen, Dinggang; Wang, Huaimin; Gao, Wen			Late Fusion Incomplete Multi-View Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple kernel clustering; multiple view learning; incomplete kernel learning		Incomplete multi-view clustering optimally integrates a group of pre-specified incomplete views to improve clustering performance. Among various excellent solutions, multiple kernel k-means with incomplete kernels forms a benchmark, which redefines the incomplete multi-view clustering as a joint optimization problem where the imputation and clustering are alternatively performed until convergence. However, the comparatively intensive computational and storage complexities preclude it from practical applications. To address these issues, we propose Late Fusion Incomplete Multi-view Clustering (LF-IMVC) which effectively and efficiently integrates the incomplete clustering matrices generated by incomplete views. Specifically, our algorithm jointly learns a consensus clustering matrix, imputes each incomplete base matrix, and optimizes the corresponding permutation matrices. We develop a three-step iterative algorithm to solve the resultant optimization problem with linear computational complexity and theoretically prove its convergence. Further, we conduct comprehensive experiments to study the proposed LF-IMVC in terms of clustering accuracy, running time, advantages of late fusion multi-view clustering, evolution of the learned consensus clustering matrix, parameter sensitivity and convergence. As indicated, our algorithm significantly and consistently outperforms some state-of-the-art algorithms with much less running time and memory.	[Liu, Xinwang; Wang, Huaimin] Natl Univ Def Technol, Sch Comp, Changsha 410073, Hunan, Peoples R China; [Zhu, Xinzhong] Zhejiang Normal Univ, Coll Math Phys & Informat Engn, Jinhua 321004, Zhejiang, Peoples R China; [Zhu, Xinzhong] Res Inst Ningbo Cixing Co Ltd, Ningbo 315336, Zhejiang, Peoples R China; [Li, Miaomiao] Changsha Coll, Dept Comp, Changsha 410073, Hunan, Peoples R China; [Wang, Lei] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia; [Tang, Chang] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China; [Yin, Jianping] Dongguan Univ Technol, Dongguan 511700, Guangdong, Peoples R China; [Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA; [Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA; [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea; [Gao, Wen] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China	National University of Defense Technology - China; Zhejiang Normal University; University of Wollongong; China University of Geosciences; Dongguan University of Technology; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; Korea University; Peking University	Zhu, XZ (corresponding author), Zhejiang Normal Univ, Coll Math Phys & Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.	xinwangliu@nudt.edu.cn; zxz@zjnu.edu.cn; miaomiaolinudt@gmail.com; leiw@uow.edu.au; tangchang@cug.edu.cn; jpyin@dgut.edu.cn; dgshen@med.unc.edu; whm2@163.com; wgao@pku.edu.cn	Shen, Dinggang/ABF-6812-2020; Wang, Lei/D-9079-2013; Tang, Chang/AAU-8995-2020; LIU, Xinwang/L-8089-2019	Shen, Dinggang/0000-0002-7934-5698; Wang, Lei/0000-0002-0961-0441; Tang, Chang/0000-0002-6515-7696; LIU, Xinwang/0000-0001-9066-1475; Yin, Jianping/0000-0002-5474-4764	National Key R&D Program of China [2018YFB1003203]; Natural Science Foundation of China [61773392, 61672528, 61701451]; NATIONAL INSTITUTE ON AGING [R01AG041721] Funding Source: NIH RePORTER	National Key R&D Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This work was supported by National Key R&D Program of China 2018YFB1003203, the Natural Science Foundation of China (project no. 61773392, 61672528 and 61701451). The authors wish to gratefully acknowledge Prof. Huiying Xu from Zhejiang Normal University for her help in the proofreading of this paper. Xinwang Liu and Xinzhong Zhu equally contribute to the paper.	[Anonymous], 2013, P AAAI; Bhadra S, 2017, MACH LEARN, V106, P713, DOI 10.1007/s10994-016-5618-0; Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095; Bruno E, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P736, DOI 10.1145/1571941.1572103; Djelouah A, 2015, IEEE T PATTERN ANAL, V37, P1890, DOI 10.1109/TPAMI.2014.2385704; Djelouah A, 2013, IEEE I CONF COMP VIS, P2640, DOI 10.1109/ICCV.2013.328; Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476; Ghahramani Z., 1993, ADV NEURAL INFORM PR, P120; Gonen M., 2014, NIPS, P1305; Gretton A., 2006, NIPS, P513; Jegelka S, 2009, LECT NOTES ARTIF INT, V5803, P144, DOI 10.1007/978-3-642-04617-9_19; Kumar R, 2013, I S BIOMED IMAGING, P764; Li C, 2018, LECT NOTES COMPUT SC, V11220, P263, DOI 10.1007/978-3-030-01270-0_16; Li J, 2017, IEEE T IMAGE PROCESS, V26, P3113, DOI 10.1109/TIP.2017.2651379; Li M., 2016, IJCAI, P1704; Li SY, 2014, AAAI CONF ARTIF INTE, P1968; Li YQ, 2015, AAAI CONF ARTIF INTE, P2750; Liu HF, 2017, IEEE T KNOWL DATA EN, V29, P1129, DOI 10.1109/TKDE.2017.2650229; Liu J., 2013, IJCAI; Liu XW, 2017, AAAI CONF ARTIF INTE, P2266; Liu XW, 2017, AAAI CONF ARTIF INTE, P2259; Liu XW, 2016, AAAI CONF ARTIF INTE, P1888; Lovasz L., 1986, MATCHING THEORY; Rai P., 2010, P NEURAL INFORM PROC, P1; Rivero R, 2017, IEICE T INF SYST, VE100D, P1844, DOI 10.1587/transinf.2017EDP7059; Shao WX, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1012, DOI 10.1109/BigData.2016.7840701; Shao WX, 2015, LECT NOTES ARTIF INT, V9284, P318, DOI 10.1007/978-3-319-23528-8_20; Tao Z., 2017, P 26 INT JOINT C ART, P2843; Tao ZQ, 2017, AAAI CONF ARTIF INTE, P1546; Tremblay N, 2016, PR MACH LEARN RES, V48; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Xiang S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P185; Xie XJ, 2013, INT CONF MACH LEARN, P51, DOI 10.1109/ICMLC.2013.6890443; Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539; Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222; Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255; Zhang RZ, 2015, IEEE I CONF COMP VIS, P2084, DOI 10.1109/ICCV.2015.241; Zhao B, 2009, IEEE DATA MINING, P637, DOI 10.1109/ICDM.2009.37	38	116	120	15	73	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2410	2423		10.1109/TPAMI.2018.2879108	http://dx.doi.org/10.1109/TPAMI.2018.2879108			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30387725	Green Accepted			2022-12-18	WOS:000489763000010
J	Achille, A; Soatto, S				Achille, Alessandro; Soatto, Stefano			Information Dropout: Learning Optimal Representations Through Noisy Computation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Representation learning; deep learning; information bottleneck; nuisances; invariants; minimality		The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of optimal disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that Information Dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.	[Achille, Alessandro; Soatto, Stefano] Univ Calif Los Angeles, Dept Comp Sci, 405 Hilgard Ave, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Achille, A (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, 405 Hilgard Ave, Los Angeles, CA 90095 USA.	achille@cs.ucla.edu; soatto@cs.ucla.edu			ARO; ONR; AFOSR	ARO; ONR(Office of Naval Research); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	Work supported by ARO, ONR, AFOSR. We are very grateful to the reviewers for their through analysis of the paper. In particular, we would like to thank one of the anonymous reviewers for for providing an elegant alternative proof to Proposition 1, as well as thoughtful critiques to the theorems. Dedicated to Naftali Tishby in the occasion of the conference Information, Control and Learning held in his honor in Jerusalem, September 26-28, 2016. Registered as Tech Report UCLA-CSD160009 and arXiv: 1611.01353 on November 6, 2016.	Abadi M, 2015, P 12 USENIX S OPERAT; Adragni KP, 2009, PHILOS T R SOC A, V367, P4385, DOI 10.1098/rsta.2009.0110; Alemi Alex, 2017, ICLR; Anselmi F, 2016, INF INFERENCE, V5, P134, DOI 10.1093/imaiai/iaw009; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bruna J, 2011, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2011.5995635; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Gal Y., 2016, ICLR WORK, V1506, P02158; Higgins I., 2013, P 2 INT C LEARN REPR; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, P5, DOI 10.1145/168304.168306; Kingma D. P., 2013, AUTO ENCODING VARIAT; Kingma DP., 2016, ADV NEURAL INFORM PR, V29, P4743; Kingma Durk P, 2015, ADV NEURAL INFORM PR, P2575; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Liu X., 2003, P IEEE COMP SOC C CO, V1, pI; Mnih V, 2014, ADV NEUR IN, V27; Soatto S., 2016, P INT C LEARN REPR M; Springenberg J. T, 2015, ARXIV PREPRINT ARXIV; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Steeg G. V., P 26 INT JOINT C ART, P5151, DOI [10.24963/ijcai.2017/740, DOI 10.24963/IJCAI.2017/740]; Studeny M, 1998, NATO ADV SCI I D-BEH, V89, P261; Sundaramoorthi G, 2009, PROC CVPR IEEE, P832, DOI 10.1109/CVPRW.2009.5206704; Tishby Naftali, 1999, P ANN ALL C COMM CON; Tishby Naftali, 2015, P IEEE INF THEOR WOR, P1, DOI DOI 10.1109/ITW.2015.7133169; WATANABE S, 1960, IBM J RES DEV, V4, P66, DOI 10.1147/rd.41.0066	27	116	118	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2897	2905		10.1109/TPAMI.2017.2784440	http://dx.doi.org/10.1109/TPAMI.2017.2784440			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29994167	Bronze, Green Submitted			2022-12-18	WOS:000449355500008
J	Liu, BY; Huang, JZ; Kulikowski, C; Yang, L				Liu, Baiyang; Huang, Junzhou; Kulikowski, Casimir; Yang, Lin			Robust Visual Tracking Using Local Sparse Appearance Model and K-Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse representation; tracking; K-selection; appearance model; dictionary learning	RECOGNITION	Online learned tracking is widely used for its adaptive ability to handle appearance changes. However, it introduces potential drifting problems due to the accumulation of errors during the self-updating, especially for occluded scenarios. The recent literature demonstrates that appropriate combinations of trackers can help balance the stability and flexibility requirements. We have developed a robust tracking algorithm using a local sparse appearance model (SPT) and K-Selection. A static sparse dictionary and a dynamically updated online dictionary basis distribution are used to model the target appearance. A novel sparse representation-based voting map and a sparse constraint regularized mean shift are proposed to track the object robustly. Besides these contributions, we also introduce a new selection-based dictionary learning algorithm with a locally constrained sparse representation, called K-Selection. Based on a set of comprehensive experiments, our algorithm has demonstrated better performance than alternatives reported in the recent literature.	[Liu, Baiyang] Rutgers State Univ, Dept Comp Sci, Bellevue, WA 98007 USA; [Liu, Baiyang] Amazon Com, Bellevue, WA 98007 USA; [Huang, Junzhou] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Kulikowski, Casimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; [Yang, Lin] Univ Kentucky, Dept Biostat, Div Biomed Informat, Lexington, KY 40536 USA	Amazon.com; University of Texas System; University of Texas Arlington; Rutgers State University New Brunswick; University of Kentucky	Liu, BY (corresponding author), Rutgers State Univ, Dept Comp Sci, 514 142nd Ave SE Apt 94, Bellevue, WA 98007 USA.	jproboy@gmail.com; jzhuang75@gmail.com; kulikows@cs.rutgers.edu; linyang711@gmail.com						Adam A., 2006, IEEE C COMP VIS PATT; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2010, P IEEE C COMP VIS PA; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B., 2009, P IEEE C COMP VIS PA; Black M.J., 1998, INT J COMPUT VISION, V26, P329; Breitenstein M. D., 2009, P IEEE INT C COMP VI; Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dai W., 2008, CORR, Vabs/0803.0811, P1; Grabner H, 2006, IEEE C COMP VIS PATT, P260; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Gu JW, 2008, LECT NOTES COMPUT SC, V5305, P845; Hess R., 2009, P IEEE C COMP VIS PA; Huang JZ, 2009, IEEE I CONF COMP VIS, P64, DOI 10.1109/ICCV.2009.5459202; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kim S. J., 2008, P IEEE C COMP VIS PA; Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951; Leichter I, 2004, PROC CVPR IEEE, P445; Liu B., 2011, P IEEE C COMP VIS PA; Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624; Mairal J, 2009, P 26 INT C MACH LEAR, P1, DOI DOI 10.1145/1553374.1553463; Mairal J., 2008, P IEEE C COMP VIS PA; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Mei X, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1818; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J., 2010, P IEEE C COMP VIS PA; Stenger Bjorn, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2647, DOI 10.1109/CVPRW.2009.5206634; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang L., 2008, P IEEE C COMP VIS PA; Yang L, 2011, IEEE T MED IMAGING, V30, P1921, DOI 10.1109/TMI.2011.2158440; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	39	116	127	0	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2968	2981		10.1109/TPAMI.2012.215	http://dx.doi.org/10.1109/TPAMI.2012.215			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136434				2022-12-18	WOS:000326502200013
J	Bekios-Calfa, J; Buenaposada, JM; Baumela, L				Bekios-Calfa, Juan; Buenaposada, Jose M.; Baumela, Luis			Revisiting Linear Discriminant Techniques in Gender Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; gender classification; Fisher linear discriminant analysis		Emerging applications of computer vision and pattern recognition in mobile devices and networked computing require the development of resource-limited algorithms. Linear classification techniques have an important role to play in this context, given their simplicity and low computational requirements. The paper reviews the state-of-the-art in gender classification, giving special attention to linear techniques and their relations. It discusses why linear techniques are not achieving competitive results and shows how to obtain state-of-the-art performances. Our work confirms previous results reporting very close classification accuracies for Support Vector Machines (SVMs) and boosting algorithms on single-database experiments. We have proven that Linear Discriminant Analysis on a linearly selected set of features also achieves similar accuracies. We perform cross-database experiments and prove that single database experiments were optimistically biased. If enough training data and computational resources are available, SVM's gender classifiers are superior to the rest. When computational resources are scarce but there is enough data, boosting or linear approaches are adequate. Finally, if training data and computational resources are very scarce, then the linear approach is the best choice.	[Bekios-Calfa, Juan] Univ Catolica Norte, Dept Ingn Sistemas & Computac, Antofagasta, Chile; [Buenaposada, Jose M.] Univ Rey Juan Carlos, Dept Ciencias Computac, Mostoles 28933, Spain; [Baumela, Luis] Univ Politecn Madrid, Dept Inteligencia Artificial, Boadilla Del Monte 28660, Spain	Universidad Catolica del Norte; Universidad Rey Juan Carlos; Universidad Politecnica de Madrid	Bekios-Calfa, J (corresponding author), Univ Catolica Norte, Dept Ingn Sistemas & Computac, Ave Angamos 0610,Gran Via, Antofagasta, Chile.	juan.bekios@ucn.cl; josemiguel.buenaposada@urjc.es; lbaumela@fi.upm.es	Buenaposada, Jose Miguel/L-6458-2014; Baumela, Luis/F-8867-2013	Buenaposada, Jose Miguel/0000-0002-4308-9653; Bekios-Calfa, Juan/0000-0003-0085-2425	Spanish Ministerio de Ciencia e Innovacion [TIN2008-06815-C02-02, TIN2010-19654]; Consolider Ingenio program [CSD2007-00018]; US Department of Defense (DOD) Counterdrug Technology Development Program Office	Spanish Ministerio de Ciencia e Innovacion(Ministry of Science and Innovation, Spain (MICINN)Instituto de Salud Carlos IIISpanish Government); Consolider Ingenio program(Spanish Government); US Department of Defense (DOD) Counterdrug Technology Development Program Office(United States Department of Defense)	The authors gratefully acknowledge funding from the Spanish Ministerio de Ciencia e Innovacion under contracts TIN2008-06815-C02-02 and TIN2010-19654 and the Consolider Ingenio program contract CSD2007-00018. Portions of the research in this paper use the FERET database of facial images collected under the FERET program, sponsored by the US Department of Defense (DOD) Counterdrug Technology Development Program Office.	AI H, 2009, P C ADV BIOM; Vicente MA, 2007, IEEE T PATTERN ANAL, V29, P896, DOI [10.1109/TPAMI.2007.1025, 10.1109/TPAMI.2007.1074]; Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golomb B. A., 1990, NIPS, V1, P572; Guodong Guo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2032, DOI 10.1109/ICCVW.2009.5457531; Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524; Johnson RA, 1998, APPL MULTIVARIATE ST; Lapedriza A, 2006, INT C PATT RECOG, P834; Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016; Makinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37; ZHANG P, 2005, P IEEE C COMP VIS PA; Zheng WM, 2004, PATTERN RECOGN, V37, P1077, DOI 10.1016/j.patcog.2003.02.001; ZHU M, 2006, P IEEE COMPUT VIS PA, V1, P132	23	116	122	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					858	864		10.1109/TPAMI.2010.208	http://dx.doi.org/10.1109/TPAMI.2010.208			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	21135443	Green Submitted			2022-12-18	WOS:000287370400017
J	Schechner, YY; Averbuch, Y				Schechner, Yoav Y.; Averbuch, Yuval			Regularized image recovery in scattering media	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color; polarization; vision in bad weather; inverse problems; dehazing	POLARIZATION; VISION; VISIBILITY	When imaging in scattering media, visibility degrades as objects become more distant. Visibility can be significantly restored by computer vision methods that account for physical processes occurring during image formation. Nevertheless, such recovery is prone to noise amplification in pixels corresponding to distant objects, where the medium transmittance is low. We present an adaptive filtering approach that counters the above problems: While significantly improving visibility relative to raw images, it inhibits noise amplification. Essentially, the recovery formulation is regularized, where the regularization adapts to the spatially varying medium transmittance. Thus, this regularization does not blur close objects. We demonstrate the approach in atmospheric and underwater experiments, based on an automatic method for determining the medium transmittance.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Schechner, YY (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	yoav@ee.technion.ac.il; averbuch@tx.technion.ac.il						Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; Hecht E., 2002, OPTICS, P562; JAGGER WS, 1993, VISION RES, V33, P1755, DOI 10.1016/0042-6989(93)90166-T; JAIN AK, 1989, FUNDAMENTALS DIGITAL, P67; Kocak DM, 2005, MAR TECHNOL SOC J, V39, P5, DOI 10.4031/002533205787442576; KOPEIKA NS, 1998, SYSTEM ENG APPROACH, P446; Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806; Miyazaki D, 2004, IEEE T PATTERN ANAL, V26, P73, DOI 10.1109/TPAMI.2004.1261080; Narasimhan S., 2003, INTERACTIVE DEWEATHE; Narasimhan SG, 2002, LECT NOTES COMPUT SC, V2352, P148; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; Negahdaripour S, 2003, IEEE J OCEANIC ENG, V28, P625, DOI 10.1109/JOE.2003.819313; Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994; Polzehl J, 2000, J R STAT SOC B, V62, P335, DOI 10.1111/1467-9868.00235; Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871; Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; Shwartz S., 1991, IEEE COMPUTER SOC C, P1984, DOI DOI 10.1109/CVPR.2006.71; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Treibitz T, 2006, P IEEE COMP SOC C CO; WOLFF LB, 1999, IEEE T PATTERN ANAL, V21, P1059	22	116	135	3	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1655	1660		10.1109/TPAMI.2007.1141	http://dx.doi.org/10.1109/TPAMI.2007.1141			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627052	Green Submitted			2022-12-18	WOS:000247965600014
J	Justice, D; Hero, A				Justice, Derek; Hero, Alfred			A binary linear programming formulation of the graph edit distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph algorithms; similarity measures; structural pattern recognition; graphs and networks; linear programming; continuation (homotopy) methods	MAXIMUM COMMON SUBGRAPH; ALGORITHM; RECOGNITION	A binary linear programming formulation of the graph edit distance for unweighted, undirected graphs with vertex attributes is derived and applied to a graph recognition problem. A general formulation for editing graphs is used to derive a graph edit distance that is proven to be a metric, provided the cost function for individual edit operations is a metric. Then, a binary linear program is developed for computing this graph edit distance, and polynomial time methods for determining upper and lower bounds on the solution of the binary program are derived by applying solution methods for standard linear programming and the assignment problem. A recognition problem of comparing a sample input graph to a database of known prototype graphs in the context of a chemical information system is presented as an application of the new method. The costs associated with various edit operations are chosen by using a minimum normalized variance criterion applied to pairwise distances between nearest neighbors in the database of prototypes. The new metric is shown to perform quite well in comparison to existing metrics when applied to a database of chemical graphs.	Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Justice, D (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, 1301 Beal Ave, Ann Arbor, MI 48109 USA.	justiced@umich.edu; hero@umich.edu		Hero, Alfred/0000-0002-2531-9670				ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Artin M., 1988, SPHERE PACKINGS LATT; BERGAMINI P, 2000, P JOINT IAPR INT WOR, P246; Berkelaar M., 2004, LP SOLVE OPEN SOURCE; Boyd S, 2004, CONVEX OPTIMIZATION; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 2000, INT C PATT RECOG, P117, DOI 10.1109/ICPR.2000.906030; Bunke H, 1999, IEEE T PATTERN ANAL, V21, P917, DOI 10.1109/34.790431; CONE MM, 1977, J AM CHEM SOC, V99, P7668, DOI 10.1021/ja00465a041; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; DOWNS GM, 1996, REV COMP CH, V7, P1; DUNFORDSHORE B, 2002, KLOTHO BIOCH COMPOUN; Fernandez ML, 2001, PATTERN RECOGN LETT, V22, P753, DOI 10.1016/S0167-8655(01)00017-4; Garey M.R., 1979, COMPUTERS INTRACTABI; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138; HAGADONE TR, 1992, J CHEM INF COMP SCI, V32, P515, DOI 10.1021/ci00009a019; Harper G, 2004, J CHEM INF COMP SCI, V44, P2145, DOI 10.1021/ci049860f; Hlaoui A, 2002, INT C PATT RECOG, P180, DOI 10.1109/ICPR.2002.1047427; JIANZHUANG L, 2000, IEEE T PATTERN ANAL, V23, P1106; JOHNSON M, 1987, GRAPH THEORY TOPOLOG, P219; Johnson M. A., 1990, CONCEPTS APPL MOL SI; Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696; Levi G., 1973, CALCOLO, V9, P341, DOI 10.1007/BF02575586; Llados J, 2001, IEEE T PATTERN ANAL, V23, P1137, DOI 10.1109/34.954603; Luenberger D. G., 1969, OPTIMIZATION VECTOR; McKay B. D., 1981, C NUMERANTIUM, V30, P45, DOI DOI 10.1016/J.JSC.2013.09.003; Messmer BT, 1998, INT J PATTERN RECOGN, V12, P721, DOI 10.1142/S0218001498000415; Myers R, 2000, IEEE T PATTERN ANAL, V22, P628, DOI 10.1109/34.862201; Neuhaus M, 2004, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2004.1334548; Ostergard PRJ, 2002, DISCRETE APPL MATH, V120, P197, DOI 10.1016/S0166-218X(01)00290-6; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; PAVEL M, 1989, FUNDAMENTALS PATTERN; Pavlidis T., 1977, STRUCTURAL PATTERN R; Raymond JW, 2002, J COMPUT AID MOL DES, V16, P521, DOI 10.1023/A:1021271615909; Raymond JW, 2002, J COMPUT AID MOL DES, V16, P59, DOI 10.1023/A:1016387816342; Raymond JW, 2002, COMPUT J, V45, P631, DOI 10.1093/comjnl/45.6.631; Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56; Saigal R., 1995, LINEAR PROGRAMMING M, DOI [10.1007/978-1-4615-2311-6, DOI 10.1007/978-1-4615-2311-6]; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; SHASHA D, 2005, P 21 ACM SIGMODSIGAC; Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Wyk BJ, 2004, IEEE T PATTERN ANAL, V26, P1526, DOI 10.1109/TPAMI.2004.95; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wallis WD, 2001, PATTERN RECOGN LETT, V22, P701, DOI 10.1016/S0167-8655(01)00022-8; WANG Z, 2001, P 26 S MATH FDN COMP, P690; Willett P, 1999, IMA V MATH, V108, P11; WILLETT P, 1986, QUANTITATIVE STRUCTU, V5; WILLETT P, 1987, CLUSTERING CHEM INFO; Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866	52	116	120	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1200	1214		10.1109/TPAMI.2006.152	http://dx.doi.org/10.1109/TPAMI.2006.152			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886857				2022-12-18	WOS:000238162400003
J	Garcia, C; Delakis, M				Garcia, C; Delakis, M			Convolutional face finder: A neural architecture for fast and robust face detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face detection; neural networks; machine learning; convolutional networks	RECOGNITION; FEATURES	In this paper, we present a novel face detection approach based on a convolutional neural architecture, designed to robustly detect highly variable face patterns, rotated up to +/-20 degrees in image plane and turned up to 9+/-60 degrees, in complex real world images. The proposed system automatically synthesizes simple problem-specific feature extractors from a training set of face and nonface patterns, without making any assumptions or using any hand-made design concerning the features to extract or the areas of the face pattern to analyze. The face detection procedure acts like a pipeline of simple convolution and subsampling modules that treat the raw input image as a whole. We therefore show that an efficient face detection system does not require any costly local preprocessing before classification of image areas. The proposed scheme provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases. We present extensive experimental results illustrating the efficiency of the proposed approach on difficult test sets and including an indepth sensitivity analysis with respect to the degrees of variability of the face patterns.	France Telecom R&D, F-35512 Cesson Sevigne, France; IRISA INRIA Rennes, F-35042 Rennes, France	Orange SA	Garcia, C (corresponding author), France Telecom R&D, 4 Rue Clos Courtel, F-35512 Cesson Sevigne, France.	cgarcia@csd.uoc.gr; delakis@csd.uoc.gr		Garcia, christophe/0000-0001-7997-9837				Colmenarez AJ, 1997, PROC CVPR IEEE, P782, DOI 10.1109/CVPR.1997.609415; Feraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945; FLEURET F, 2003, INT J COMPUT VISION, V20, P1157; FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633; Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6; Garcia C, 2002, INT C PATT RECOG, P44, DOI 10.1109/ICPR.2002.1048232; Garcia C., 2001, P INT WORKSH VER LOW; Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465; Govindaraju V, 1996, INT J COMPUT VISION, V19, P129, DOI 10.1007/BF00055801; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Jeng SH, 1998, PATTERN RECOGN, V31, P273, DOI 10.1016/S0031-3203(97)00048-4; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; LECUN Y, 1989, CONNECTIONISM IN PERSPECTIVE, P143; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1989, ADV NEURAL INFORM PR, P396; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; Lin CC, 1996, PATTERN RECOGN, V29, P2079, DOI 10.1016/S0031-3203(96)00034-9; Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822; LOW BK, 1997, P INT C IM PROC; Maio D, 2000, PATTERN RECOGN, V33, P1525, DOI 10.1016/S0031-3203(99)00130-2; MARTIN GL, 1993, NEURAL COMPUT, V5, P419, DOI 10.1162/neco.1993.5.3.419; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MOZER M, 1991, CONNECTIONISM PERSPE; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; VAILLANT R, 1994, IEE P-VIS IMAGE SIGN, V141, P245, DOI 10.1049/ip-vis:19941301; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; VIOLA P, 2001, 3 ICCV 2 INT WORKSH; WANG J, 1993, P INT C NEUR NETW, V3, P1588; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; YANG GZ, 1994, PATTERN RECOGN, V27, P53, DOI 10.1016/0031-3203(94)90017-5; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Yang MH, 2001, COMPUT VIS IMAGE UND, V84, P264, DOI 10.1006/cviu.2001.0937; Yang MH, 2000, ADV NEUR IN, V12, P862; Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6	39	116	134	1	89	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1408	1423		10.1109/TPAMI.2004.97	http://dx.doi.org/10.1109/TPAMI.2004.97			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521490				2022-12-18	WOS:000223737000002
J	Soille, P; Talbot, H				Soille, P; Talbot, H			Directional morphological filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image analysis; mathematical morphology; rank filters; directional filters; periodic line; discrete geometry; granulometry; orientation field; radial decomposition	MATHEMATICAL MORPHOLOGY; ALGORITHM; MIN; IMPLEMENTATION; DECOMPOSITION; LINES	We show that a translation invariant implementation of min/max filters along a line segment of slope in the form of an irreducible fraction dy/dx can be achieved at the cost of 2 + k min/max comparisons per image pixel, where k = max(\ dx \, \ dy \). Therefore, for a given slope, the computation time is constant and independent of the length of the line segment. We then present the notion of periodic moving histogram algorithm. This allows for a similar performance to be achieved in the more general case of rank filters and rank-based morphological filters. Applications. to the filtering of thin nets and computation of both granulometries and orientation fields are detailed. Finally, two extensions are developed. The first deals with the decomposition of discrete disks and arbitrarily oriented discrete rectangles, while the second concerns min/max filters along gray tone periodic line segments.	Commiss European Communities, Joint Res Ctr, Space Applicat Inst, I-21020 Ispra, Italy; CSIRO, Math & Informat Sci, Image Anal Grp, N Ryde, NSW 2113, Australia	European Commission Joint Research Centre; EC JRC ISPRA Site; Commonwealth Scientific & Industrial Research Organisation (CSIRO)	Soille, P (corresponding author), Commiss European Communities, Joint Res Ctr, Space Applicat Inst, TP 262, I-21020 Ispra, Italy.	Pierre.Soille@jrc.it; Hugues.Talbot@cmis.csiro.au		Soille, Pierre/0000-0002-8479-9205				ADAMS R, 1993, CVGIP-GRAPH MODEL IM, V55, P325, DOI 10.1006/cgip.1993.1024; BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960; BEUCHER S, 1996, C NATL ECRIT DOCUMEN, P133; BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; CHAUDHURI BB, 1990, PATTERN RECOGN LETT, V11, P77, DOI 10.1016/0167-8655(90)90116-J; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAVIES ER, 1997, ELECTRON LETT, V33, P1774; DONAHUE MJ, 1993, CVGIP-IMAG UNDERSTAN, V57, P185, DOI 10.1006/ciun.1993.1012; Drimbarean A., 1999, P IR MACH VIS IM PRO, P267; Dufour A, 1995, SPATIAL VISION, V9, P307, DOI 10.1163/156856895X00025; FAREY J, 1816, PHILOS MAGAZINE; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GARIBOTTO G, 1979, ELECTRON LETT, V15, P24, DOI 10.1049/el:19790018; Gevorkian DZ, 1997, IEEE T PATTERN ANAL, V19, P526, DOI 10.1109/34.589214; GIL J, 1993, IEEE T PATTERN ANAL, V15, P504, DOI 10.1109/34.211471; Hague T, 1997, IEEE INT CONF ROBOT, P1880, DOI 10.1109/ROBOT.1997.619062; HEIIJMANS H, 1994, ADV ELECT ELECT PHYS; HEYGSTER G, 1982, COMPUT VISION GRAPH, V19, P148, DOI 10.1016/0146-664X(82)90105-8; HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188; ISAAC EJ, 1956, J ACM, V3, P169, DOI 10.1145/320831.320834; JEULIN D, 1992, ACTA STEREOL, V11, P545; Jones R, 1996, COMP IMAG VIS, P263; Jones R, 1996, PATTERN RECOGN LETT, V17, P1057, DOI 10.1016/0167-8655(96)00066-9; Kurylo DD, 1996, SPATIAL VISION, V10, P149, DOI 10.1163/156856896X00105; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Marchant JA, 1998, REAL-TIME IMAGING, V4, P243, DOI 10.1006/rtim.1997.0086; Matheron G., 1975, RANDOM SETS INTEGRAL; Matheron G, 1967, ELEMENTS THEORIE MIL; Minkowski H, 1903, MATH ANN, V57, P447, DOI 10.1007/BF01445180; Rivest J.-F., 1992, Journal of Visual Communication and Image Representation, V3, P137, DOI 10.1016/1047-3203(92)90011-H; RONSE C, 1991, CVGIP-IMAG UNDERSTAN, V54, P74, DOI 10.1016/1049-9660(91)90076-2; RONSE C, 1986, P 2 INT C IM PROC IT, P77; Sanchiz JM, 1996, IMAGE VISION COMPUT, V14, P353, DOI 10.1016/0262-8856(96)89800-3; SAUPE D, 1988, SCI FRACTAL IMAGES, pCH2; SERRA J, 1992, CIRC SYST SIGNAL PR, V11, P47, DOI 10.1007/BF01189221; SERRA J, 1988, IMAGE ANAL MATH MORP, V2, P101; Serra J, 1982, IMAGE ANAL MATH MORP; Sivakumar K, 2000, REAL-TIME IMAGING, V6, P223, DOI 10.1006/rtim.1999.0172; Soille P, 2000, IMAGE VISION COMPUT, V18, P1025, DOI 10.1016/S0262-8856(00)00043-3; Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646; Soille P, 2000, LECT NOTES COMPUT SC, V1953, P78; Soille P, 1998, COMP IMAG VIS, V12, P83; Soille P., 2000, Fundamenta Informaticae, V41, P131; Soille P, 1998, INT C PATT RECOG, P1467, DOI 10.1109/ICPR.1998.711982; SOILLE P, 1995, P 1995 IEEE WORKSH N, P987; SOILLE P, UNPUB PATTERN RECOGN; SOILLE P, 1995, PERIODIC LINES FAST; Soille P., 1999, MORPHOLOGICAL IMAGE, DOI 10.1007/978-3-662-03939-7; SOILLE P, 1993, IMAGE ALGEBRA MORPHO, V4, P43; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; VANDENBOOMGAARD R, 1992, CVGIP-GRAPH MODEL IM, V54, P252, DOI 10.1016/1049-9652(92)90055-3; VanDroogenbroeck M, 1996, PATTERN RECOGN LETT, V17, P1451, DOI 10.1016/S0167-8655(96)00113-4; VANHERK M, 1992, PATTERN RECOGN LETT, V13, P517, DOI 10.1016/0167-8655(92)90069-C; WERMAN M, 1985, IEEE T PATTERN ANAL, V7, P730, DOI 10.1109/TPAMI.1985.4767732; WHELAN P, 1998, P OPT ENG SOC IR IR, P287; Whelan PF, 2001, REAL-TIME IMAGING, V7, P367, DOI 10.1006/rtim.2000.0239; WILSON SS, 1989, IEEE T SYST MAN CYB, V19, P1636, DOI 10.1109/21.44079; YAMADA H, 1993, IEEE T PATTERN ANAL, V15, P380, DOI 10.1109/34.206957; Zwiggelaar R, 1998, LECT NOTES COMPUT SC, V1496, P570, DOI 10.1007/BFb0056242	60	116	124	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1313	1329		10.1109/34.969120	http://dx.doi.org/10.1109/34.969120			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300008
J	Black, MJ; Jepson, AD				Black, MJ; Jepson, AD			Estimating optical flow in segmented images using variable-order parametric models with local deformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; segmentation; robust regression; parameterized flow models; local deformation	MOVING-OBJECTS; MOTION; TRACKING; OPTIMIZATION; ALGORITHM; SEQUENCES; VELOCITY; LAYERS	This paper presents a new model for estimating optical flow based on the motion of planar regions plus local deformations. The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene. Parametric flow models are estimated in these regions in a two step process which first computes a coarse fit and estimates the appropriate parameterization of the motion of the region (two, six, or eight parameters). The initial fit is refined using a generalization of the standard area-based regression approaches. Since the assumption of planarity is likely to be violated, we allow local deformations from the planar assumption in the same spirit as physically-based approaches which model shape using coarse parametric models plus local deformations. This parametric+deformation model exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches. Experimental results on a variety of images indicate that the parametric+deformation model produces accurate flow estimates while the incorporation of brightness segmentation provides precise localization of motion boundaries.	UNIV TORONTO, DEPT COMP SCI, TORONTO, ON M5S 1A4, CANADA	University of Toronto	Black, MJ (corresponding author), XEROX CORP, PALO ALTO RES CTR, 3333 COYOTE HILL RD, PALO ALTO, CA 94304 USA.		Estrela, Vania Vieira/I-7599-2012	Estrela, Vania Vieira/0000-0002-4465-7691				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; AYER S, 1994, LNCS SERIES, V801, P317; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214; BLACK MJ, 1992, LECT NOTES COMPUT SC, V588, P485; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; BLACK MJ, 1994, LECT NOTES COMPUTER, V800, P138; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; Dubuisson M.-P., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P471, DOI 10.1109/CVPR.1993.341088; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; Hampel FR., 2011, WILEY SERIES PROBABI; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; Hoaglin D. C., 1985, EXPLORING DATA TABLE; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; JEPSON A, 1993, PARTITIONING DATA SE, P271; Kakadiaris I.A., 1994, C COMP VIS PATT REC, P980; KOCH R, 1993, EUROGRPHICS 93, V12, P339; KUMAR R, 1990, P INT WORKSH ROB COM, P167; KUMAR R, 1994, P ARPA IM UND WORKSH; LEONARDIS A, 1990, MSCIS9030; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Luo W., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P60, DOI 10.1109/ICPR.1990.118065; MACLEAN WJ, 1994, P BRIT MACH VIS C YO; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; Otte M., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P51; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; SINGH A, 1992, OPTIC FLOW COMPUTATI; SULL S, 1991, OCT P IEEE WORKSH VI, P274; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Waxman A. M., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P49; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; Weber J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P12, DOI 10.1109/ICCV.1993.378240	50	116	123	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					972	986		10.1109/34.541407	http://dx.doi.org/10.1109/34.541407			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100002
J	Dong, Q; Gong, SG; Zhu, XT				Dong, Qi; Gong, Shaogang; Zhu, Xiatian			Imbalanced Deep Learning by Minority Class Incremental Rectification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Class imbalanced deep learning; multi-label learning; inter-class boundary rectification; hard sample mining; facial attribute recognition; clothing attribute recognition; person attribute recognition	SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; CLASSIFICATION; SMOTE	Model learning from class imbalanced training data is a long-standing and significant challenge for machine learning. In particular, existing deep learning methods consider mostly either class balanced data or moderately imbalanced data in model training, and ignore the challenge of learning from significantly imbalanced training data. To address this problem, we formulate a class imbalanced deep learning model based on batch-wise incremental minority (sparsely sampled) class rectification by hard sample mining in majority (frequently sampled) classes during model training. This model is designed to minimise the dominant effect of majority classes by discovering sparsely sampled boundaries of minority classes in an iterative batch-wise learning process. To that end, we introduce a Class Rectification Loss (CRL) function that can be deployed readily in deep network architectures. Extensive experimental evaluations are conducted on three imbalanced person attribute benchmark datasets (CelebA, X-Domain, DeepFashion) and one balanced object category benchmark dataset (CIFAR-100). These experimental results demonstrate the performance advantages and model scalability of the proposed batch-wise incremental minority class rectification model over the existing state-of-the-art models for addressing the problem of imbalanced data learning.	[Dong, Qi; Gong, Shaogang] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England; [Zhu, Xiatian] Vis Semant Ltd, London E1 4NS, England	University of London; Queen Mary University London	Dong, Q (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.	q.dong@qmul.ac.uk; s.gong@qmul.ac.uk; eddy@visionsemantics.com	Zhu, Xiatian/Y-1601-2019	Zhu, Xiatian/0000-0002-9284-2955; Gong, Shaogang/0000-0001-8156-2299	China Scholarship Council; Vision Semantics Ltd.; Royal Society Newton Advanced Fellowship Programme [NA150459]; Innovate UK Industrial Challenge Project on Developing and Commercialising Intelligent Video Analytics Solutions for Public Safety [98111-571149]	China Scholarship Council(China Scholarship Council); Vision Semantics Ltd.; Royal Society Newton Advanced Fellowship Programme; Innovate UK Industrial Challenge Project on Developing and Commercialising Intelligent Video Analytics Solutions for Public Safety(UK Research & Innovation (UKRI)Innovate UK)	We shall thank Victor Lempitsky for providing the histogram loss code, Chen Huang and Chen Change Loy for sharing the pre-trained DeepID2 face recognition model. This work was partly supported by the China Scholarship Council, Vision Semantics Ltd., the Royal Society Newton Advanced Fellowship Programme (NA150459), and Innovate UK Industrial Challenge Project on Developing and Commercialising Intelligent Video Analytics Solutions for Public Safety (98111-571149).	Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7; Alejo R, 2006, LECT NOTES COMPUT SC, V4224, P464; Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], P 30 INT C NEUR INF; Arthur D., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P144, DOI 10.1145/1137856.1137880; Bai Y, 2014, PROC INT CONF RECON; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Brown S, 2012, INT CONF ACOUST SPEE, P5, DOI 10.1109/ICASSP.2012.6287803; Castro CL, 2013, IEEE T NEUR NET LEAR, V24, P888, DOI 10.1109/TNNLS.2013.2246188; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chen C., 2004, TECH REP, V666; Chen JJ, 2006, SAR QSAR ENVIRON RES, V17, P337, DOI 10.1080/10659360600787700; Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319; Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dong Q, 2017, IEEE WINT CONF APPL, P520, DOI 10.1109/WACV.2017.64; Drummond Chris, 2003, WORKSH LEARN IMB DAT; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Feris R., 2014, P INT C MULTIMEDIA R, P153; Fernandez-Navarro F, 2011, PATTERN RECOGN, V44, P1821, DOI 10.1016/j.patcog.2011.02.019; GaryWeiss M., 2004, SIGKDD EXPLOR NEWSL, V6, P7, DOI DOI 10.1145/1007730.1007734; Gong S., 2014, PERSON REIDENTIFICAT, V1; Griffin G., 2007, 120 CAL I TECHN; Guan S, 2015, 2015 IEEE CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P288, DOI 10.1109/CIC.2015.40; Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hospedales TM, 2013, IEEE T KNOWL DATA EN, V25, P374, DOI 10.1109/TKDE.2011.231; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127; Huang YM, 2006, NONLINEAR ANAL-REAL, V7, P720, DOI 10.1016/j.nonrwa.2005.04.006; Ioffe Sergey, 2015, COMPUTING RES REPOSI; Japkowicz N., 2000, Learning from Imbalanced Data Sets. Papers from the AAAI Workshop (Technical Report WS-00-05), P10; Japkowicz N., 2002, Intelligent Data Analysis, V6, P429; Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19; Khandy SA, 2018, INT J ENERG RES, V42, P4221, DOI 10.1002/er.4182; Khoshgoftaar TM, 2010, IEEE T NEURAL NETWOR, V21, P813, DOI 10.1109/TNN.2010.2042730; Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0; Krawczyk B, 2015, LECT NOTES COMPUT SC, V9375, P45, DOI 10.1007/978-3-319-24834-9_6; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lan J, 2010, DECIS SUPPORT SYST, V48, P582, DOI 10.1016/j.dss.2009.11.008; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Liu B, 2000, LECT NOTES COMPUT<D>, V1910, P504; Liu T-Y., 2009, FOUND TRENDS INF RET, V3, P225, DOI DOI 10.1561/1500000016; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Maciejewski T., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P104, DOI 10.1109/CIDM.2011.5949434; Mazurowski MA, 2008, NEURAL NETWORKS, V21, P427, DOI 10.1016/j.neunet.2007.12.031; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Provost F., 2000, P AAAI 2000 WORKSHOP, V68, P1; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1023/A:1022646118217; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Simonyan K, 2015, 3 INT C LEARN REPR I; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909; Ting Kai Ming, 2000, P 17 INT C MACH LEAR, P983; Triguero I, 2015, KNOWL-BASED SYST, V87, P69, DOI 10.1016/j.knosys.2015.05.027; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wozniak M., 2013, HYBRID CLASSIFIERS M, V519; Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006; Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95; Yan YL, 2015, IEEE INT SYM MULTIM, P483, DOI 10.1109/ISM.2015.126; Yu HL, 2016, KNOWL-BASED SYST, V92, P55, DOI 10.1016/j.knosys.2015.10.012; Zadrozny B, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P435, DOI 10.1109/icdm.2003.1250950; Zadrozny B., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P204, DOI 10.1145/502512.502540; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17; 2016, P IEEE C COMP VIS PA, P4004, DOI DOI 10.1109/CVPR.2016.434	83	115	118	10	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1367	1381		10.1109/TPAMI.2018.2832629	http://dx.doi.org/10.1109/TPAMI.2018.2832629			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993438	Green Submitted			2022-12-18	WOS:000467037000007
J	Rozantsev, A; Lepetit, V; Fua, P				Rozantsev, Artem; Lepetit, Vincent; Fua, Pascal			Detecting Flying Objects Using a Single Moving Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion compensation; object detection	BACKGROUND SUBTRACTION; VISION; SYSTEM	We propose an approach for detecting flying objects such as Unmanned Aerial Vehicles (UAVs) and aircrafts when they occupy a small portion of the field of view, possibly moving against complex backgrounds, and are filmed by a camera that itself moves. We argue that solving such a difficult problem requires combining both appearance and motion cues. To this end we propose a regression-based approach for object-centric motion stabilization of image patches that allows us to achieve effective classification on spatio-temporal image cubes and outperform state-of-the-art techniques. As this problem has not yet been extensively studied, no test datasets are publicly available. We therefore built our own, both for UAVs and aircrafts, and will make them publicly available so they can be used to benchmark future flying object detection and collision avoidance algorithms.	[Rozantsev, Artem; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, Lausanne, Switzerland; [Lepetit, Vincent] Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Graz University of Technology	Rozantsev, A (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, Lausanne, Switzerland.	artem.rozantsev@epfl.ch; lepetit@icg.tugraz.at; pascal.fua@epfl.ch		Rozantsev, Artem/0000-0003-2867-5459	Honeywell International, Inc.	Honeywell International, Inc.	This work was conducted in the context of the "Visual detection and tracking of flying objects in Unmanned Aerial Vehicles" project, funded by Honeywell International, Inc.	[Anonymous], 2006 C COMP VIS PATT; [Anonymous], 2014, MERCEDES BENZ INTELL; Bastien F., 2012, THEANO NEW FEATURES; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Conte G, 2008, AEROSP CONF PROC, P3142; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Dollar P., 2013, PIOTRS COMPUTER VISI; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Elqursh A, 2012, LECT NOTES COMPUT SC, V7577, P228, DOI 10.1007/978-3-642-33783-3_17; Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Glorot X., 2011, P 14 INT C ART INT S, P315; Hane C, 2011, IEEE INT C INT ROBOT, P1618, DOI 10.1109/IROS.2011.6048261; Hastie T, 2009, ELEMENTS STAT LEARNI; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281; Kim SW, 2013, MACH VISION APPL, V24, P1015, DOI 10.1007/s00138-012-0448-y; Kwak S, 2011, IEEE I CONF COMP VIS, P2174, DOI 10.1109/ICCV.2011.6126494; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917; Martinez C, 2011, J INTELL ROBOT SYST, V61, P301, DOI 10.1007/s10846-010-9505-9; Meier L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P2992, DOI 10.1109/ICRA.2011.5980229; Narayana M, 2013, IEEE I CONF COMP VIS, P1577, DOI 10.1109/ICCV.2013.199; Oberweger M., 2015, CVWW; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371; Rozantsev A, 2015, PROC CVPR IEEE, P4128, DOI 10.1109/CVPR.2015.7299040; SeungJong Noh, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P493, DOI 10.1007/978-3-642-37431-9_38; Sobral A., 2013, P 9 WORKSH VIS COMP; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sznitman R, 2013, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2013.420; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; WALK S, 2010, PROC CVPR IEEE, P1030, DOI DOI 10.1109/CVPR.2010.5540102; Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635; Weiss S, 2013, J FIELD ROBOT, V30, P803, DOI 10.1002/rob.21466; Zamalieva D, 2014, COMPUT VIS IMAGE UND, V127, P73, DOI 10.1016/j.cviu.2014.06.007; Zeiler Matthew D, 2012, ARXIV12125701; Zsedrovits T., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P472, DOI 10.1109/ECCTD.2011.6043389	47	115	126	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					879	892		10.1109/TPAMI.2016.2564408	http://dx.doi.org/10.1109/TPAMI.2016.2564408			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113698	Green Submitted			2022-12-18	WOS:000399250000004
J	Gijsenij, A; Gevers, T; van de Weijer, J				Gijsenij, Arjan; Gevers, Theo; van de Weijer, Joost			Improving Color Constancy by Photometric Edge Weighting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; illuminant estimation; Gray Edge; edge classification	ALGORITHM; SHADOWS	Edge-based color constancy methods make use of image derivatives to estimate the illuminant. However, different edge types exist in real-world images, such as material, shadow, and highlight edges. These different edge types may have a distinctive influence on the performance of the illuminant estimation. Therefore, in this paper, an extensive analysis is provided of different edge types on the performance of edge-based color constancy methods. First, an edge-based taxonomy is presented classifying edge types based on their photometric properties (e.g., material, shadow-geometry, and highlights). Then, a performance evaluation of edge-based color constancy is provided using these different edge types. From this performance evaluation, it is derived that specular and shadow edge types are more valuable than material edges for the estimation of the illuminant. To this end, the (iterative) weighted Gray-Edge algorithm is proposed in which these edge types are more emphasized for the estimation of the illuminant. Images that are recorded under controlled circumstances demonstrate that the proposed iterative weighted Gray-Edge algorithm based on highlights reduces the median angular error with approximately 25 percent. In an uncontrolled environment, improvements in angular error up to 11 percent are obtained with respect to regular edge-based color constancy.	[Gijsenij, Arjan] Alten PTS, NL-2909 LE Capelle aan den IJssel, Netherlands; [Gevers, Theo] Univ Amsterdam, ISLA, NL-1098 XH Amsterdam, Netherlands; [Gevers, Theo; van de Weijer, Joost] Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Cerdanyola, Spain	University of Amsterdam; Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Gijsenij, A (corresponding author), Alten PTS, Rivium 1E Str, NL-2909 LE Capelle aan den IJssel, Netherlands.	arjan.gijsenij@gmail.com; th.gevers@uva.nl; joost@cvc.uab.es	van de Weijer, Joost/A-1643-2009	van de Weijer, Joost/0000-0002-9656-9706; Gijsenij, Arjan/0000-0003-4926-3672	EU [ERGTS-VICI-224737]; Spanish Research Program Consolider-Ingenio 2010: MIPRCV [CSD200700018]; Ramon y Cajal fellowship;  [TIN2009-14173]	EU(European Commission); Spanish Research Program Consolider-Ingenio 2010: MIPRCV; Ramon y Cajal fellowship(Spanish Government); 	This work has been supported by the EU projects ERGTS-VICI-224737, by the Spanish Research Program Consolider-Ingenio 2010: MIPRCV (CSD200700018), and by the Spanish projects TIN2009-14173. Joost van de Weijer acknowledges the support of a Ramon y Cajal fellowship.	Barnard K, 1997, COMPUT VIS IMAGE UND, V65, P311, DOI 10.1006/cviu.1996.0567; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Barnard K, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P114; Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; Bianco S, 2008, IEEE T IMAGE PROCESS, V17, P2381, DOI 10.1109/TIP.2008.2006661; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Chakrabarti A., 2008, P IEEE C COMP VIS PA; Chen H., 2007, VISUAL COMM IMAGE PR; Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160; Ebner M, 2007, COLOR CONSTANCY, V7; Fairchild M.D., 2005, COLOR APPEARANCE MOD; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson GD, 2006, INT J COMPUT VISION, V67, P93, DOI 10.1007/s11263-006-4100-z; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; FINLAYSON GD, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P720, DOI 10.1109/ICCV.1995.466867; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gehler Peter Vincent, 2008, 2008 IEEE C COMP VIS, P1, DOI [10.1109/CVPR.2008.4587765, DOI 10.1109/CVPR.2008.4587765]; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Gevers T, 2003, IEEE T MULTIMEDIA, V5, P237, DOI 10.1109/TMM.2003.811620; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; Gijsenij A., 2009, P IEEE INT C IM PROC, P1; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; van de Weijer J, 2005, IEEE T PATTERN ANAL, V27, P625, DOI 10.1109/TPAMI.2005.75; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; Von Kries J., 1905, HDB PHYSIOLOGIE MENS, V3, P109; Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209	33	115	122	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					918	929		10.1109/TPAMI.2011.197	http://dx.doi.org/10.1109/TPAMI.2011.197			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22442121				2022-12-18	WOS:000301747400007
J	Passalis, G; Perakis, P; Theoharis, T; Kakadiaris, IA				Passalis, Georgios; Perakis, Panagiotis; Theoharis, Theoharis; Kakadiaris, Ioannis A.			Using Facial Symmetry to Handle Pose Variations in Real-World 3D Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; face and gesture recognition; physically-based modeling	OBJECTS	The uncontrolled conditions of real-world biometric applications pose a great challenge to any face recognition approach. The unconstrained acquisition of data from uncooperative subjects may result in facial scans with significant pose variations along the yaw axis. Such pose variations can cause extensive occlusions, resulting in missing data. In this paper, a novel 3D face recognition method is proposed that uses facial symmetry to handle pose variations. It employs an automatic landmark detector that estimates pose and detects occluded areas for each facial scan. Subsequently, an Annotated Face Model is registered and fitted to the scan. During fitting, facial symmetry is used to overcome the challenges of missing data. The result is a pose invariant geometry image. Unlike existing methods that require frontal scans, the proposed method performs comparisons among interpose scans using a wavelet-based biometric signature. It is suitable for real-world applications as it only requires half of the face to be visible to the sensor. The proposed method was evaluated using databases from the University of Notre Dame and the University of Houston that, to the best of our knowledge, include the most challenging pose variations publicly available. The average rank-one recognition rate of the proposed method in these databases was 83.7 percent.	[Passalis, Georgios; Perakis, Panagiotis; Theoharis, Theoharis] Univ Athens, Comp Graph Lab, Dept Informat & Telecommun, Athens 15784, Greece; [Passalis, Georgios; Perakis, Panagiotis; Theoharis, Theoharis; Kakadiaris, Ioannis A.] Univ Houston, Dept Comp Sci, Computat Biomed Lab, Houston, TX 77204 USA	National & Kapodistrian University of Athens; University of Houston System; University of Houston	Passalis, G (corresponding author), Univ Athens, Comp Graph Lab, Dept Informat & Telecommun, Athens 15784, Greece.	passalis@di.uoa.gr; perakis@di.uoa.gr; theotheo@di.uoa.gr; ioannisk@uh.edu	Theoharis, Theoharis/AAN-2555-2020; Perakis, Panagiotis/AAS-4573-2021	Kakadiaris, Ioannis/0000-0002-0591-1079	European Social Fund; Greek National Resources; University of Houston	European Social Fund(European Social Fund (ESF)); Greek National Resources(Greek Ministry of Development-GSRT); University of Houston	This research was supported in part by the European Social Fund and Greek National Resources within the context of Basic Research Program Heraclitus II and by the University of Houston Eckhard Pfeiffer Endowment Fund. All statements of fact, opinion, or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of the sponsors.	Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V, 2007, IEEE I CONF COMP VIS, P1562; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2006, LECT NOTES COMPUT SC, V3953, P396, DOI 10.1007/11744078_31; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Colbry D., 2006, THESIS MICHIGAN STAT; COLBRY D, 2005, P IEEE COMP SOC C CO, P118; Cootes T, 2005, HANDBOOK OF FACE RECOGNITION, P39, DOI 10.1007/0-387-27257-7_3; Cootes TF, 2001, STAT MODELS APPEARAN; DIBEKLIOGLU H, 2008, P 2 IEEE INT C BIOM, P1; DIBEKLIOGLU H, 2008, THESIS BOGAZICI U; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Faltemier TC, 2008, P 8 IEEE INT C AUT F, P1, DOI DOI 10.1109/AFGR.2008.4813413; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933; GAO Y, 2003, P IEEE C VIS IM SIGN, P346; Gu XF, 2002, ACM T GRAPHIC, V21, P355; Gutta S, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P33, DOI 10.1109/AFGR.2002.1004126; Johnson A., 1997, THESIS CARNEGIE MELL; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Klinger A., 1971, PATTERN SEARCH STAT, P303, DOI [10.1016/b978-0-12-604550-5.50019-5, DOI 10.1016/B978-0-12-604550-5.50019-5]; KOMPANETS L, 2004, P 1 INT C BIOM AUTH, P67; Lin T.H., 2006, P 44 ANN SE REG C, P423; Liu Y., 2001, CMURITR0123; Liu YX, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P222; Loop C., 1987, SMOOTH SUBDIVISION S; Lu X., 2005, MSUCSE0522; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585; MANDAL C, 1998, THESIS U FLORIDA; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mitra S, 2006, IEEE T INF FOREN SEC, V1, P350, DOI 10.1109/TIFS.2006.879301; NAIR P, 2008, P BRIT MACH VIS C SE; Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629; Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888; Passalis G, 2007, IEEE T PATTERN ANAL, V29, P218, DOI 10.1109/TPAMI.2007.37; Perakis P, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P439; Perakis P, 2011, 3D FACIAL LANDMARK D; Perakis P., 2009, P EUR WORKSH 3D OBJ, P37, DOI DOI 10.2312/3DOR/3DOR09/037-044; Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59; Phillips PJ, 2005, PROC CVPR IEEE, P947; Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274; Segundo MP, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P431, DOI 10.1109/ICIAP.2007.4362816; Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043; Stegmann M, 2002, INFORM MATH MODELLIN; Stollnitz E.J., 1996, WAVELETS COMPUTER GR; *U NOTR DAM, 2008, U NOTR DAM BIOM DAT; *UH, 2011, UH BIOM DAT; Wei XZ, 2007, LECT NOTES COMPUT SC, V4642, P144; Xu C., 2006, PATTERN RECOGN, V27, P62	52	115	122	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1938	1951		10.1109/TPAMI.2011.49	http://dx.doi.org/10.1109/TPAMI.2011.49			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21383396				2022-12-18	WOS:000293969000003
J	Provenzi, E; Gatta, C; Fierro, M; Rizzi, A				Provenzi, Edoardo; Gatta, Carlo; Fierro, Massimo; Rizzi, Alessandro			A spatially variant white-patch and gray-world method for color image enhancement driven by local contrast	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		color image enhancement; image stabilization; contrast-based regulation mechanism; Retinex; ACE	RETINEX THEORY; COMPUTATION; DIFFUSION; INDUCTION; LIGHTNESS	Starting from the revolutionary Retinex by Land and McCann, several further perceptually inspired color correction models have been developed with different aims, e. g., reproduction of color sensation, robust features recognition, and enhancement of color images. Such models have a differential, spatially variant, and nonlinear nature, and they can coarsely be distinguished between white-patch (WP) and gray-world (GW) algorithms. In this paper, we show that the combination of a pure WP algorithm (Random Spray Retinex (RSR)) and an essentially GW one (Automatic Color Equalization (ACE)) leads to a more robust and better performing model (RACE). The choice of RSR and ACE follows from the recent identification of a unified spatially variant approach for both algorithms. Mathematically, the originally distinct nonlinear and differential mechanisms of RSR and ACE have been fused using the spray technique and local average operations. The investigation of RACE allowed us to put in evidence a common drawback of differential models: corruption of uniform image areas. To overcome this intrinsic defect, we devised a local and global contrast-based and image-driven regulation mechanism that has a general applicability to perceptually inspired color correction algorithms. Tests, comparisons, and discussions are presented.	[Provenzi, Edoardo; Gatta, Carlo; Fierro, Massimo; Rizzi, Alessandro] Univ Milan, Dipartimento Tecnol Informaz, I-26013 Crema, CR, Italy	University of Milan	Provenzi, E (corresponding author), Univ Milan, Dipartimento Tecnol Informaz, Via Bramante 65, I-26013 Crema, CR, Italy.	provenzi@dti.unimi.it; gatta@dti.unimi.it; massimo.fierro@dti.unimi.it; rizzi@dti.unimi.it	Rizzi, Alessandro/I-2138-2012	Rizzi, Alessandro/0000-0001-6240-4383; PROVENZI, Edoardo/0000-0002-1476-1236				ADAMS A, 1970, BASIC PHOTO; ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807; BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P269, DOI 10.1109/TIP.1998.661176; Ciocca G, 2003, J ELECTRON IMAGING, V12, P161, DOI 10.1117/1.1526844; Cooper TJ, 2004, J ELECTRON IMAGING, V13, P85, DOI 10.1117/1.1636182; COOPER TJ, 1999, P SPIE COLOR IMAGING, V3963, P167; CREUTZFELDT O, 1990, J OPT SOC AM A, V7, P1644, DOI 10.1364/JOSAA.7.001644; CREUTZFELDT O, 1987, EXP BRAIN RES, V67, P270; DALY S, 1993, DIGITAL IMAGES HUMAN, P179; Ebner M, 2003, LECT NOTES COMPUT SC, V2781, P60; Frankle J., 1983, United States Patent, Patent No. [US 4,348,336, 4348336]; Funt B, 2004, J ELECTRON IMAGING, V13, P48, DOI 10.1117/1.1636761; FUNT B, 1998, P 5 EUR C COMP VIS, P445; Gasparini F, 2004, PATTERN RECOGN, V37, P1201, DOI 10.1016/j.patcog.2003.12.007; Gonzales R., 2002, DIGITAL IMAGE PROCES; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; JAMESON D, 1964, VISION RES, V4, P135, DOI 10.1016/0042-6989(64)90037-9; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356; Jobson DJ, 2002, P SOC PHOTO-OPT INS, V4736, P25, DOI 10.1117/12.477589; Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998; Lam EY, 2005, I SYMP CONSUM ELECTR, P134, DOI 10.1109/ISCE.2005.1502356; LAND E, 1977, SCI AM, V237, P2; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163; LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078; Lucchese L, 2004, IEEE T IMAGE PROCESS, V13, P534, DOI 10.1109/TIP.2003.822609; Marini D, 2000, IMAGE VISION COMPUT, V18, P1005, DOI 10.1016/S0262-8856(00)00037-8; MCCANN JJ, 1989, P SOC PHOTO-OPT INS, V1077, P355; MCCANN JJ, 1990, P 1990 AS C CIRC SYS, V1, P408; MCCANN JJ, 2004, J ELECTRON IMAGING, V13, P1; MOORE A, 1991, IEEE T NEURAL NETWOR, V2, P237, DOI 10.1109/72.80334; OSHER S, 2003, VISION GRAPHICS; Panchanathan S, 2000, IEEE IMAGE PROC, P517, DOI 10.1109/ICIP.2000.901009; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; PLATANIOTIS KN, 1999, COLOR IMAGE PROCESSI; Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787; Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613; Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946; Ramponi G, 2003, PROC SPIE, V5014, P169, DOI 10.1117/12.477714; Rizzi A., 2002, Machine Graphics & Vision, V11, P153; Rizzi A, 2004, J ELECTRON IMAGING, V13, P75, DOI 10.1117/1.1635366; Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9; RIZZI A, 2003, P IS T SPIES INT S C, P24; SANGWINE SJ, 1999, COLOR IMAGE PROCESSI; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Von Kries J., 1905, HDB PHYSIOLOGIE MENS, V3, P109; WEST G, 1979, J MATH BIOL, V8, P47, DOI 10.1007/BF00280585; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Wyszecky G, 2000, COLOR SCI CONCEPTS M; ZAIDI Q, 1999, COLOR VISION GENES P; Zhang X., 1996, P SID S	56	115	127	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1757	1770		10.1109/TPAMI.2007.70827	http://dx.doi.org/10.1109/TPAMI.2007.70827			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703829				2022-12-18	WOS:000258344900007
J	O'Toole, AJ; Harms, J; Snow, SL; Hurst, DR; Pappas, MR; Ayyad, JH; Abdi, H				O'Toole, AJ; Harms, J; Snow, SL; Hurst, DR; Pappas, MR; Ayyad, JH; Abdi, H			A video database of moving faces and people	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face database; face recognition; face tracking; digital video	RECOGNITION; EXPRESSIONS	We describe a database of static images and video clips of human faces and people that is useful for testing algorithms for face and person recognition, head/ eye tracking, and computer graphics modeling of natural human motions. For each person there are nine static "facial mug shots" and a series of video streams. The videos include a "moving facial mug shot," a facial speech clip, one or more dynamic facial expression clips, two gait videos, and a conversation video taken at a moderate distance from the camera. Complete data sets are available for 284 subjects and duplicate data sets, taken subsequent to the original set, are available for 229 subjects.	Univ Texas, Sch Behav & Brain Sci, Richardson, TX 75083 USA	University of Texas System; University of Texas Dallas	O'Toole, AJ (corresponding author), Univ Texas, Sch Behav & Brain Sci, GR4-1, Richardson, TX 75083 USA.	otoole@utdallas.edu; herve@utdallas.edu	Abdi, Hervé/G-6620-2011	O'Toole, Alice/0000-0001-7981-1508; Abdi, Herve/0000-0002-9522-1978				Blanz Volker, 1999, P SIGGRAPH 99; Chen Q, 2001, J VLSI SIG PROC SYST, V27, P127, DOI 10.1023/A:1008131816432; Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dubuisson S, 2002, SIGNAL PROCESS-IMAGE, V17, P657, DOI 10.1016/S0923-5965(02)00076-0; Ekman P., 2002, FACIAL ACTION CODING; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Hong PY, 2002, IEEE T NEURAL NETWOR, V13, P916, DOI 10.1109/TNN.2002.1021892; Kanade T, 2000, P 4 IEEE INT C AUT F; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Lien JJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P390, DOI 10.1109/AFGR.1998.670980; Lien JJJ, 1998, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.1998.698704; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; PHILLIPS PJ, 2003, 6965 NISTIR; Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; SNOW S, 2002, J VISION, V2, pA600; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0; Zhang CZ, 2002, IEEE T IMAGE PROCESS, V11, P1249, DOI 10.1109/TIP.2002.804277; ZHAO W, 2000, CASTR948 U MAR	24	115	121	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					812	816		10.1109/TPAMI.2005.90	http://dx.doi.org/10.1109/TPAMI.2005.90			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875802				2022-12-18	WOS:000227569300014
J	Ying, XH; Hu, ZY				Ying, XH; Hu, ZY			Catadioptric camera calibration using geometric invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; catadioptric camera; geometric invariant; omnidirectional vision; panoramic vision		Central catadioptric cameras are imaging devices that use mirrors to enhance the field of view while preserving a single effective viewpoint. In this paper, we propose a novel method for the calibration of central catadioptric cameras using geometric invariants. Lines and spheres in space are all projected into conics in the catadioptric image plane. We prove that the projection of a line can provide three invariants whereas the projection of a sphere can only provide two. From these invariants, constraint equations for the intrinsic parameters of catadioptric camera are derived. Therefore, there are two kinds of variants of this novel method. The first one uses projections of lines and the second one uses projections of spheres. In general, the projections of two lines or three spheres are sufficient to achieve catadioptric camera calibration. One important conclusion in this paper is that the method based on projections of spheres is more robust and has higher accuracy than that based on projections of lines. The performances of our method are demonstrated by both the results of simulations and experiments with real images.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Ying, XH (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100080, Peoples R China.	xhying@nlpr.ia.ac.cn; huzy@nlpr.ia.ac.cn						Aliaga DG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P127, DOI 10.1109/ICCV.2001.937508; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Barreto J. P., 2003, P IEEE C COMP VIS PA, V7, P78; BARRETO JP, 2002, P EUR C COMP VIS, P237; BOGNER S, 1995, P IEEE SMC C, P3100; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; Daucher N., 1994, P 3 EUR C COMP VIS, P449; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Fitzgibbon A. W., 1995, BMVC '95 Proceedings of the 6th British Machine Vision Conference, P513; Geyer C, 2001, PROC CVPR IEEE, P279; Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241; Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135; Geyer Christopher, 1999, P 7 IEEE INT C COMP, V1, P398; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; HONG JW, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P620, DOI 10.1109/ROBOT.1991.131651; Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820; NALWA V, 1996, TRUE OMNIDIRECTIONAL; Nene SA, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1087, DOI 10.1109/ICCV.1998.710852; Pajdla T, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P85, DOI 10.1109/SMBV.2001.988766; PENNA MA, 1991, IEEE T PATTERN ANAL, V13, P1240, DOI 10.1109/34.107007; Quan L, 1996, IEEE T PATTERN ANAL, V18, P151, DOI 10.1109/34.481540; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Stein G.P., 1993, THESIS MIT; Svoboda T, 2002, INT J COMPUT VISION, V49, P23, DOI 10.1023/A:1019869530073; Swaminathan R, 2000, IEEE T PATTERN ANAL, V22, P1172, DOI 10.1109/34.879797; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; Yagi Y., 1990, Proceedings. IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90. Towards a New Frontier of Applications (Cat. No.90TH0332-7), P181, DOI 10.1109/IROS.1990.262385; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	28	115	137	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1260	1271		10.1109/TPAMI.2004.79	http://dx.doi.org/10.1109/TPAMI.2004.79			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641714				2022-12-18	WOS:000223140200002
J	Bao, CL; Ji, H; Quan, YH; Shen, ZW				Bao, Chenglong; Ji, Hui; Quan, Yuhui; Shen, Zuowei			Dictionary Learning for Sparse Coding: Algorithms and Convergence Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Dictionary learning; sparse coding; non-convex optimization; convergence analysis	INCOHERENT DICTIONARIES; VARIABLE SELECTION; NONCONVEX; FACTORIZATION; OPTIMIZATION; MINIMIZATION; SVD	In recent years, sparse coding has been widely used in many applications ranging from image processing to pattern recognition. Most existing sparse coding based applications require solving a class of challenging non-smooth and non-convex optimization problems. Despite the fact that many numerical methods have been developed for solving these problems, it remains an open problem to find a numerical method which is not only empirically fast, but also has mathematically guaranteed strong convergence. In this paper, we propose an alternating iteration scheme for solving such problems. A rigorous convergence analysis shows that the proposed method satisfies the global convergence property: the whole sequence of iterates is convergent and converges to a critical point. Besides the theoretical soundness, the practical benefit of the proposed method is validated in applications including image restoration and recognition. Experiments show that the proposed method achieves similar results with less computation when compared to widely used methods such as K-SVD.	[Bao, Chenglong; Ji, Hui; Quan, Yuhui; Shen, Zuowei] Natl Univ Singapore, Dept Math, Singapore 119076, Singapore	National University of Singapore	Bao, CL (corresponding author), Natl Univ Singapore, Dept Math, Singapore 119076, Singapore.	matbc@nus.edu.sg; matjh@nus.edu.sg; matquan@nus.edu.sg; matzuows@nus.edu.sg	JI, Hui/C-5107-2016; Shen, Zuowei/A-9455-2012	JI, Hui/0000-0002-1674-6056; Shen, Zuowei/0000-0002-1861-1884				Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Attouch H, 2013, MATH PROGRAM, V137, P91, DOI 10.1007/s10107-011-0484-9; Attouch H, 2010, MATH OPER RES, V35, P438, DOI 10.1287/moor.1100.0449; Bao CL, 2014, PROC CVPR IEEE, P3858, DOI 10.1109/CVPR.2014.493; Barchiesi D, 2013, IEEE T SIGNAL PROCES, V61, P2055, DOI 10.1109/TSP.2013.2245663; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; CHISTOV AL, 1984, LECT NOTES COMPUT SC, V176, P17; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Fei-Fei L., 2004, C COMP VIS PATT REC, P178, DOI [10.1109/CVPR.2004.109, DOI 10.1109/CVPR.2004.109]; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gong Pinghua, 2013, JMLR Workshop Conf Proc, V28, P37; Grippo L, 2000, OPER RES LETT, V26, P127, DOI 10.1016/S0167-6377(99)00074-7; Jenatton R., 2010, P 27 INT C MACH LEAR, P487; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Mailhe B, 2012, INT CONF ACOUST SPEE, P3573, DOI 10.1109/ICASSP.2012.6288688; Mairal J., 2009, ADV NEURAL INFORM PR, P1033; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Mairal J, 2010, J MACH LEARN RES, V11, P19; Martinez A. M., 1998, AR FACE DATABASE, V24; Powell MJ., 1973, MATH PROGRAM, V4, P193, DOI [DOI 10.1007/BF01584660, 10.1007/BF01584660]; Rakotomamonjy A, 2013, IEEE T SIGNAL PROCES, V61, P5495, DOI 10.1109/TSP.2013.2278158; Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964; Rheinboldt, 2000, ITERATIVE SOLUTION N, V30; Rockafellar R.T., 1998, VARIATIONAL ANAL GRU, V317; Rubinstein R., 2008, EFFICIENT IMPLEMENTA; Shi JP, 2011, PROC CVPR IEEE, P1809, DOI 10.1109/CVPR.2011.5995592; Sra S, 2012, ADV NEURAL INFORM PR, P539; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795; Yin W., 2013, FAST PATCH DICT METH; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023; Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989	40	114	121	4	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1356	10.1109/TPAMI.2015.2487966	http://dx.doi.org/10.1109/TPAMI.2015.2487966			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26452248				2022-12-18	WOS:000377897100007
J	Treibitz, T; Schechner, YY; Kunz, C; Singh, H				Treibitz, Tali; Schechner, Yoav Y.; Kunz, Clayton; Singh, Hanumant			Flat Refractive Geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; vision and scene understanding; 3D/stereo scene analysis; camera calibration; imaging geometry	UNDERWATER; MOTION; MODEL	While the study of geometry has mainly concentrated on single viewpoint (SVP) cameras, there is growing attention to more general non-SVP systems. Here, we study an important class of systems that inherently have a non-SVP: a perspective camera imaging through an interface into a medium. Such systems are ubiquitous: They are common when looking into water-based environments. The paper analyzes the common flat-interface class of systems. It characterizes the locus of the viewpoints (caustic) of this class and proves that the SVP model is invalid in it. This may explain geometrical errors encountered in prior studies. Our physics-based model is parameterized by the distance of the lens from the medium interface, besides the focal length. The physical parameters are calibrated by a simple approach that can be based on a single frame. This directly determines the system geometry. The calibration is then used to compensate for modeled system distortion. Based on this model, geometrical measurements of objects are significantly more accurate than if based on an SVP model. This is demonstrated in real-world experiments. In addition, we examine by simulation the errors expected by using the SVP model. We show that when working at a constant range, the SVP model can be a good approximation.	[Treibitz, Tali] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA; [Schechner, Yoav Y.] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; [Kunz, Clayton; Singh, Hanumant] Woods Hole Oceanog Inst, Dept Appl Ocean Phys & Engn, Woods Hole, MA 02543 USA	University of California System; University of California San Diego; Technion Israel Institute of Technology; Woods Hole Oceanographic Institution	Treibitz, T (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, 9500 Gilman Dr,Mail Code 0404, La Jolla, CA 92093 USA.	tali@cs.ucsd.edu; yoav@ee.technion.ac.il; ckunz@whoi.edu; hsingh@whoi.edu		Treibitz, Tali/0000-0002-3078-282X	Taub Foundation; US-Israel Binational Science Foundation (BSF) [2006384]; Israeli Ministry of Science, Culture and Sport [3-3426]; Ollendorff Minerva Center for Vision and Image Science; BMBF; US Department of the Navy [N62909-10-1-4056]; CenSSIS ERC of the US National Science Foundation (NSF) [EEC-9986821]; NSF [ATM-0941760]; ONR [N00014-08-1-0638]; Weizmann Institute of Science	Taub Foundation; US-Israel Binational Science Foundation (BSF)(US-Israel Binational Science Foundation); Israeli Ministry of Science, Culture and Sport; Ollendorff Minerva Center for Vision and Image Science; BMBF(Federal Ministry of Education & Research (BMBF)); US Department of the Navy; CenSSIS ERC of the US National Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); Weizmann Institute of Science	The authors thank the reviewers for their insightful comments and Hank Chezar of the USGS and Boaz Zion of Volcani Center for letting them use their images in Fig. 1. They thank Ben Herzberg and Gal Gur-Arye for help in the experimental dives. Yoav Y. Schechner is a Landau Fellow-supported by the Taub Foundation. This work was supported by the US-Israel Binational Science Foundation (BSF grant 2006384) and the Israeli Ministry of Science, Culture and Sport (Grant 3-3426). This reasearch was supported by the Ollendorff Minerva Center for Vision and Image Science. Minerva is funded through the BMBF. Yoav Y. Schechner was partially supported by US Department of the Navy Grant N62909-10-1-4056 issued by the US Office of Naval Research (ONR) Global and the United States has a royalty-free license throughout the world in all copyrightable materials contained herein. Funding was also provided in part by the CenSSIS ERC of the US National Science Foundation (NSF) under Grant EEC-9986821. Tali Treibitz was partailly supported under grants from NSF ATM-0941760 and ONR N00014-08-1-0638. Tali Treibitz is an Awardee of the Weizmann Institute of Science-National Postdoctoral Award Program for Advancing Women in Science.	Aggarwal M, 2002, INT J COMPUT VISION, V48, P195, DOI 10.1023/A:1016324132583; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Barta AS, 2003, J OPT SOC AM A, V20, P2370, DOI 10.1364/JOSAA.20.002370; Born M., 1999, PRINCIPLES OPTICS; Bouguet J.-Y., 2011, CAMERA CALIBRATION T; BURKHARD DG, 1973, J OPT SOC AM, V63, P299, DOI 10.1364/JOSA.63.000299; Chari V., 2009, P BRIT MACH VIS C; FRYER JG, 1986, PHOTOGRAMM REC, V12, P73; Glaeser G., 2000, J GEOM GRAPH, V4, P1; Gracias N, 2000, COMPUT VIS IMAGE UND, V79, P66, DOI 10.1006/cviu.2000.0848; Grossberg MD, 2005, INT J COMPUT VISION, V61, P119, DOI 10.1023/B:VISI.0000043754.56350.10; GUPTA M, 2008, P IEEE C COMP VIS PA; Hartley R., 2003, MULTIPLE VIEW GEOMET; Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468; Hogue A., 2008, THESIS YORK U; IVANOFF A, 1960, J SMPTE, V69, P264; Kerkez I., 2006, P IEEE COMP VIS PATT; Kunz C., 2008, P MTS IEEE OC; Kwon YH, 2006, SPORT BIOMECH, V5, P313, DOI 10.1080/14763140608522881; Lavest J.-M., 2000, EUR C COMPUT VISION, P654, DOI DOI 10.1007/3-540-45053-X_42; Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806; Li RX, 1997, IEEE J OCEANIC ENG, V22, P364, DOI 10.1109/48.585955; LURIA SM, 1970, SCIENCE, V167, P1454, DOI 10.1126/science.167.3924.1454; Maas H. G., 1995, OPTICAL 3D MEASUREME; Micusik B, 2006, IEEE T PATTERN ANAL, V28, P1135, DOI 10.1109/TPAMI.2006.151; Mobley C. D., 1994, LIGHT WATER RAD TRAN; Morris NJW, 2005, IEEE I CONF COMP VIS, P1573; NEGAHDARIPOUR S, 2007, P IEEE MULT GEOM; Negahdaripour S, 2006, IEEE J OCEANIC ENG, V31, P533, DOI 10.1109/JOE.2005.850914; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Pessel N., 2003, P INT C CENTR EUR CO; Pizarro O., 2003, RELATIVE POSE ESTIMA, P601; Queiroz-Neto JP, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P170, DOI 10.1109/SIBGRA.2004.1352958; Ramalingam S, 2005, PROC CVPR IEEE, P1093; RAY S, 2002, APPL PHOTOGRAPHIC OP, P349; Rubin DM, 2007, SEDIMENT GEOL, V202, P402, DOI 10.1016/j.sedgeo.2007.03.020; Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871; Schuster S, 2004, CURR BIOL, V14, P1565, DOI 10.1016/j.cub.2004.08.050; Shortis M.R., 1998, INT ARCH PHOTOGRAMM, V32, P792, DOI DOI 10.1017/CB09781107415324.004; Strelow D., 2005, P IEEE CS C COMP VIS; Strum P, 2006, COMPUT IMAGING VIS, V33, P87; Swaminathan R, 2006, INT J COMPUT VISION, V66, P211, DOI 10.1007/s11263-005-3220-1; Swirski Y., 2009, P IEEE INT C COMP VI; Telem G, 2010, ISPRS J PHOTOGRAMM, V65, P433, DOI 10.1016/j.isprsjprs.2010.05.004; Treibitz T., 2011, MOVIE; Treibitz T, 2006, P IEEE COMP SOC C CO; Treibitz T., 2008, P IEEE C COMP VIS PA; Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85; Wolff K., 2000, INT ARCH PHOTOGRAMME, VXXXIII, P900; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zion B, 2007, COMPUT ELECTRON AGR, V56, P34, DOI 10.1016/j.compag.2006.12.007	51	114	121	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					51	65		10.1109/TPAMI.2011.105	http://dx.doi.org/10.1109/TPAMI.2011.105			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576744	Green Submitted			2022-12-18	WOS:000297069900004
J	Li, Y; Zheng, YF; Doermann, D; Jaeger, S				Li, Yi; Zheng, Yefeng; Doermann, David; Jaeger, Stefan			Script-independent text line segmentation in freestyle handwritten documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten text line segmentation; document image analysis; density estimation; level set methods	DETECTION ALGORITHM; RECOGNITION; EXTRACTION	Text line segmentation in freestyle handwritten documents remains an open document analysis problem. Curvilinear text lines and small gaps between neighboring text lines present a challenge to algorithms developed for machine-printed or hand-printed documents. In this paper, we propose a novel approach based on density estimation and a state-of-the-art image segmentation technique, the level set method. From an input document image, we estimate a probability map where each element represents the probability of the underlying pixel belonging to a text line. The level set method is then exploited to determine the boundary of neighboring text lines by evolving an initial estimate. Unlike connected component-based methods ([1] and [2], for example), the proposed algorithm does not use any script-specific knowledge. Extensive quantitative experiments on freestyle handwritten documents with diverse scripts such as Arabic, Chinese, Korean, and Hindi demonstrate that our algorithm consistently outperforms previous methods [1], [2], [3]. Further experiments show that the proposed algorithm is robust to scale change, rotation, and noise.	[Li, Yi; Jaeger, Stefan] Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA; [Zheng, Yefeng] Siemens Corp Res, Princeton, NJ 08540 USA; [Jaeger, Stefan] Partner Inst Computat Biol, Grp Syst Bioinformat, CAS MPG, Shanghai 200031, Peoples R China	University System of Maryland; University of Maryland College Park; Siemens AG; Chinese Academy of Sciences; Shanghai Institutes for Biological Sciences, CAS; Max Planck Society	Li, Y (corresponding author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	liyi@cfar.umd.edu; yefeng.zheng@siemens.com; doermann@cfar.umd.edu; jaeger@picb.ac.cn	Zheng, Yefeng/ABG-7053-2020	Zheng, Yefeng/0000-0003-2195-2847				[Anonymous], [No title captured]; Baird H. S., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P1; Cannon M., 1999, INT J DOC ANAL RECOG, P80, DOI [10.1007/s100320050039, DOI 10.1007/S100320050039]; Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888; DUDA RO, 2000, PATTERN CLASSIFICATI, P84; JAEGER S, 2006, P SOC PHOTO-OPT INS, V13, P63; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; Li Y, 2006, IEEE COMMUN LETT, V10, P40, DOI [10.1109/LCOMM.2006.1576563, 10.1109/LCOMM.2006.01007]; Li Y, 2006, INT C PATT RECOG, P1030; Liang JS, 2001, COMPUT VIS IMAGE UND, V84, P144, DOI 10.1006/cviu.2001.0933; Liu G, 2002, PATTERN RECOGN, V35, P2125, DOI 10.1016/S0031-3203(01)00204-7; Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150; MAO S, 2003, P SOC PHOTO-OPT INS, V10, P197; Mao S., 2002, INT J DOC ANAL RECOG, V4, P205; Marti UV, 2001, PROC INT CONF DOC, P159, DOI 10.1109/ICDAR.2001.953775; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Osher S, 2003, LEVEL SET METHODS DY; Pal U, 2004, IEEE T SYST MAN CY B, V34, P1676, DOI 10.1109/TSMCB.2004.827613; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; ROSENFEL.A, 1966, J ACM, V13, P471; SAUVOLA J, 1997, P SOC PHOTO-OPT INS, V4, P96; Sethian J. A., 1999, LEVEL SET METHODS FA; SIMONS A, 1997, NATIONS NATL, V3, P273; Tripathy N, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P306, DOI 10.1109/IWFHR.2004.50; Yu B, 1996, PATTERN RECOGN, V29, P1599, DOI 10.1016/0031-3203(96)00020-9; Zahour A, 2001, PROC INT CONF DOC, P281; Zheng YF, 2005, IEEE T PATTERN ANAL, V27, P777, DOI 10.1109/TPAMI.2005.89	31	114	118	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1313	1329		10.1109/TPAMI.2007.70792	http://dx.doi.org/10.1109/TPAMI.2007.70792			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566488				2022-12-18	WOS:000256679700001
J	TUCERYAN, M; JAIN, AK				TUCERYAN, M; JAIN, AK			TEXTURE SEGMENTATION USING VORONOI POLYGONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											TUCERYAN, M (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.		Tuceryan, Mihran/O-8134-2019	Tuceryan, Mihran/0000-0003-3828-6123				BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3; Beck J., 1983, HUMAN MACHINE VISION; BLOSTEIN D, 1987, 1ST P IEEE INT C COM, P444; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9; COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DAVIS LS, 1981, IEEE T PATTERN ANAL, V3, P214, DOI 10.1109/TPAMI.1981.4767084; Gagalowicz A., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P46, DOI 10.1109/ICPR.1988.28169; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KASHYAP RL, 1981, COMPUT VISION GRAPH, V15, P301, DOI 10.1016/S0146-664X(81)80014-7; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Marr D., 1982, VISION; Press WH, 1988, NUMERICAL RECIPES C; Rearick T. C., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P312; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SHAMOS MI, 1975, 16TH P ANN S F COMP, P131; TUCERYAN M, 1989, COMPUT VISION GR DEC; TURNER MR, 1986, BIOL CYBERN, V55, P71; VOORHEES H, 1987, 1ST P INT C COMP VIS, P250; Voronoi G, 1908, J REINE ANGEW MATH, V134, P198, DOI 10.1515/crll.1908.134.198; Wilson H. B.  Jr., 1976, Computer Aided Design, V8, P257, DOI 10.1016/0010-4485(76)90161-5; ZUCKER SW, 1983, IEEE T PATTERN ANAL, V5, P267	28	114	124	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					211	216		10.1109/34.44407	http://dx.doi.org/10.1109/34.44407			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282		Green Submitted			2022-12-18	WOS:A1990CL28200009
J	Aldrian, O; Smith, WAP				Aldrian, Oswald; Smith, William A. P.			Inverse Rendering of Faces with a 3D Morphable Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Inverse rendering; face shape; texture and illumination analysis	SIGNAL-PROCESSING FRAMEWORK; SHAPE; RECOGNITION; RECONSTRUCTION; ILLUMINATION; REFLECTANCE; SUBSPACES; IMAGE; POSE	In this paper, we present a complete framework to inverse render faces with a 3D Morphable Model (3DMM). By decomposing the image formation process into geometric and photometric parts, we are able to state the problem as a multilinear system which can be solved accurately and efficiently. As we treat each contribution as independent, the objective function is convex in the parameters and a global solution is guaranteed. We start by recovering 3D shape using a novel algorithm which incorporates generalization error of the model obtained from empirical measurements. We then describe two methods to recover facial texture, diffuse lighting, specular reflectance, and camera properties from a single image. The methods make increasingly weak assumptions and can be solved in a linear fashion. We evaluate our findings on a publicly available database, where we are able to outperform an existing state-of-the-art algorithm. We demonstrate the usability of the recovered parameters in a recognition experiment conducted on the CMU-PIE database.	[Aldrian, Oswald; Smith, William A. P.] Univ York, Dept Comp Sci, York YO10 5GH, N Yorkshire, England	University of York - UK	Aldrian, O (corresponding author), Univ York, Dept Comp Sci, Deramore Lane, York YO10 5GH, N Yorkshire, England.	oa525@york.ac.uk; william.smith@york.ac.uk	Smith, William/AAK-9101-2020	Smith, William/0000-0002-6047-0413	Engineering and Physical Sciences Research Council [EP/F036949/1] Funding Source: researchfish; EPSRC [EP/F036949/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Amberg B, 2011, IEEE I CONF COMP VIS, P455, DOI 10.1109/ICCV.2011.6126275; [Anonymous], 2005, P IEEE INT C COMP VI; Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P293, DOI 10.1109/TDPVT.2004.1335212; COOTES TF, 1998, LNCS, V1407, P484, DOI DOI 10.1007/BFB0054760; Costen NP, 2002, IMAGE VISION COMPUT, V20, P319, DOI 10.1016/S0262-8856(02)00004-5; Craw I., 1991, P BRIT MACH VIS C, V91, P367, DOI [https://doi.org/10.5244/c.5.52, DOI 10.1007/978-1-4471-1921-0_52, 10.1007/978-1-4471-1921-0_52]; Creusot C., 2012, P IEEE CVPR WORKSH P; Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Fuchs M, 2005, IEEE T VIS COMPUT GR, V11, P296, DOI 10.1109/TVCG.2005.47; Georghiades A. S., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P230; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Heseltine T., 2004, P BRIT MACH VIS C, V2004; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; Paysan P, 2009, P IEEE INT C ADV VID; Ramamoorthi R, 2004, ACM T GRAPHIC, V23, P1004, DOI 10.1145/1027411.1027416; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Romdhani S, 2005, PROC CVPR IEEE, P986; Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3; Romdhani S, 2006, P IEEE, V94, P1977, DOI 10.1109/JPROC.2006.886019; Sidorov K. A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2401, DOI 10.1109/CVPR.2011.5995632; Sidorov KA, 2009, PROC CVPR IEEE, P2208, DOI 10.1109/CVPRW.2009.5206516; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Turk M. A., 1991, P IEEE C COMP VIS PA, V591, P586, DOI DOI 10.1109/CVPR.1991.139758; University of Southern California, 2011, HIGH RES LIGHT PROB; Yagi Y, 2007, LECT NOTES COMPUT SC, V4844, P869; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhou SH, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P11; Zickler T, 2008, INT J COMPUT VISION, V79, P13, DOI 10.1007/s11I263-007-0087-3; [No title captured]; [No title captured]	40	113	116	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1080	1093		10.1109/TPAMI.2012.206	http://dx.doi.org/10.1109/TPAMI.2012.206			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520253	Green Submitted			2022-12-18	WOS:000316126800005
J	Zhang, ZY; Wang, J; Zha, HY				Zhang, Zhenyue; Wang, Jing; Zha, Hongyuan			Adaptive Manifold Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifold learning; dimensionality reduction; neighborhood selection; bias reduction; classification	NONLINEAR DIMENSIONALITY REDUCTION; FACE RECOGNITION; VISION	Manifold learning algorithms seek to find a low-dimensional parameterization of high-dimensional data. They heavily rely on the notion of what can be considered as local, how accurately the manifold can be approximated locally, and, last but not least, how the local structures can be patched together to produce the global parameterization. In this paper, we develop algorithms that address two key issues in manifold learning: 1) the adaptive selection of the local neighborhood sizes when imposing a connectivity structure on the given set of high-dimensional data points and 2) the adaptive bias reduction in the local low-dimensional embedding by accounting for the variations in the curvature of the manifold as well as its interplay with the sampling density of the data set. We demonstrate the effectiveness of our methods for improving the performance of manifold learning algorithms using both synthetic and real-world data sets.	[Zhang, Zhenyue] Zhejiang Univ, Dept Math, Hangzhou 310027, Zhejiang, Peoples R China; [Zhang, Zhenyue] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China; [Wang, Jing] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361021, Peoples R China; [Zha, Hongyuan] Georgia Inst Technol, Coll Comp, Atlanta, GA 30322 USA	Zhejiang University; Zhejiang University; Huaqiao University; University System of Georgia; Georgia Institute of Technology	Zhang, ZY (corresponding author), Zhejiang Univ, Dept Math, Hangzhou 310027, Zhejiang, Peoples R China.	zyzhang@zju.edu.cn; wroaring@yahoo.com.cn; zha@cc.gatech.edu			NSFC [10771194, 11071218]; National Basic Research Program of China (973 Program) [2009CB320804]; NSFC for Youth [10901062]; NSF of Fujian Province [2010J01336]; US National Science Foundation (NSF) [DMS-0311800, CCF-0305879, DMS-0736328]	NSFC(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); NSFC for Youth; NSF of Fujian Province(Natural Science Foundation of Fujian Province); US National Science Foundation (NSF)(National Science Foundation (NSF))	The work of Zhenye Zhang was supported in part by NSFC projects 10771194 and 11071218, and National Basic Research Program of China (973 Program) 2009CB320804, the work of Jing Wang was supported by NSFC for Youth 10901062 and NSF of Fujian Province 2010J01336, and the work of Hongyuan Zha was supported by US National Science Foundation (NSF) grants DMS-0311800, CCF-0305879, and DMS-0736328. A preliminary version of a subset of the results reported in this paper was published without proof in [28].	Abramoff M.D., 2004, BIOPHOT INT, V11, P36; Brand  M., 2003, ADV NEURAL INFORM PR, P961, DOI DOI 10.1109/34.682189; Bunke H, 2008, LECT NOTES COMPUT SC, V5342, P996, DOI 10.1007/978-3-540-89689-0_103; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Elgammal A., 2004, P IEEE CS C COMP VIS; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Izenman AJ, 2008, SPRINGER TEXTS STAT, P1, DOI 10.1007/978-0-387-78189-1_1; Jansen A., 2006, P IEEE INT C AC SPEE; Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li LX, 2004, BIOINFORMATICS, V20, P3406, DOI 10.1093/bioinformatics/bth415; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Rabiner L., 1993, FUNDAMENTALS SPEECH; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Venna J, 2010, J MACH LEARN RES, V11, P451; Wang J., 2005, P ADV NEUR INF PROC, P1473; Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z; Zha HY, 2007, COMPUT STAT DATA AN, V52, P184, DOI 10.1016/j.csda.2006.11.027; Zha HY, 2009, SIAM REV, V51, P545, DOI 10.1137/060676829; Zhang J., 2004, P 6 INT C AUT FAC GE; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhang ZY, 2001, SIAM J MATRIX ANAL A, V22, P1245, DOI 10.1137/S0895479899357875	32	113	136	3	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					253	265		10.1109/TPAMI.2011.115	http://dx.doi.org/10.1109/TPAMI.2011.115			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21670485	Green Submitted			2022-12-18	WOS:000298105500005
J	Cheng, QA; Zhou, HB; Cheng, J				Cheng, Qiang; Zhou, Hongbo; Cheng, Jie			The Fisher-Markov Selector: Fast Selecting Maximally Separable Feature Subset for Multiclass Classification with Applications to High-Dimensional Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification; feature subset selection; Fisher's linear discriminant analysis; high-dimensional data; kernel; Markov random field	RANDOM-FIELDS; CANCER; REGRESSION; ALGORITHM	Selecting features for multiclass classification is a critically important task for pattern recognition and machine learning applications. Especially challenging is selecting an optimal subset of features from high-dimensional data, which typically have many more variables than observations and contain significant noise, missing components, or outliers. Existing methods either cannot handle high-dimensional data efficiently or scalably, or can only obtain local optimum instead of global optimum. Toward the selection of the globally optimal subset of features efficiently, we introduce a new selector-which we call the Fisher-Markov selector-to identify those features that are the most useful in describing essential differences among the possible groups. In particular, in this paper we present a way to represent essential discriminating characteristics together with the sparsity as an optimization objective. With properly identified measures for the sparseness and discriminativeness in possibly high-dimensional settings, we take a systematic approach for optimizing the measures to choose the best feature subset. We use Markov random field optimization techniques to solve the formulated objective functions for simultaneous feature selection. Our results are noncombinatorial, and they can achieve the exact global optimum of the objective function for some special kernels. The method is fast; in particular, it can be linear in the number of features and quadratic in the number of observations. We apply our procedure to a variety of real-world data, including mid-dimensional optical handwritten digit data set and high-dimensional microarray gene expression data sets. The effectiveness of our method is confirmed by experimental results. In pattern recognition and from a model selection viewpoint, our procedure says that it is possible to select the most discriminating subset of variables by solving a very simple unconstrained objective function which in fact can be obtained with an explicit expression.	[Cheng, Qiang; Zhou, Hongbo] So Illinois Univ, Dept Comp Sci, Carbondale, IL 62901 USA; [Cheng, Jie] Univ Hawaii, Dept Comp Sci & Engn, Hilo, HI 96720 USA	Southern Illinois University System; Southern Illinois University; University of Hawaii System; University Hawaii Hilo	Cheng, QA (corresponding author), So Illinois Univ, Dept Comp Sci, Faner Hall,Mailcode 4511,1000 Faner Dr, Carbondale, IL 62901 USA.	qcheng@cs.siu.edu; hongboz@cs.siu.edu; chengjie@hawaii.edu			US National Science Foundation (NSF) [0855221]; Southern Illinois University	US National Science Foundation (NSF)(National Science Foundation (NSF)); Southern Illinois University	The authors thank the editor and anonymous referees' insightful comments and helpful suggestions, which helped improve the paper's quality and composition. This work was partially supported by the US National Science Foundation (NSF) 0855221 and Southern Illinois University Doctoral Fellowship. Q. C. and J.C. produced the formulation, algorithms, and analyses of this work. H.Z. performed the experiments and wrote the Experiments portion of this paper. Q.C. wrote the overall paper.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Bosq D, 1998, NONPARAMETRIC STAT S; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; CHEN CH, 1975, PATTERN RECOGN, V7, P87, DOI 10.1016/0031-3203(75)90018-7; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P956, DOI 10.1109/TIP.2009.2012906; Demsar J, 2006, J MACH LEARN RES, V7, P1; Devijver PA, 1982, PATTERN RECOGNITION; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; FOWLKES EB, 1987, DESIGN DATA ANAL, P13; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; FU KS, 1970, IEEE T SYST SCI CYB, VSSC6, P33, DOI 10.1109/TSSC.1970.300326; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GARRIS MD, 1994, 5469 NISTIR; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GREENWOOD P, 1985, CONTIGUITY STAT INVA; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hochbaum DS, 2001, J ACM, V48, P686, DOI 10.1145/502090.502093; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Kendall M.G., 1957, COURSE MULTIVARIATE; KIRA K, 1992, MACHINE LEARNING /, P249; Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P284; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Lam C, 2008, ANN STAT, V36, P2232, DOI 10.1214/07-AOS544; Latshaw VV., 1957, AM MATH MON, V64, P685, DOI [10.2307/2309989, DOI 10.2307/2309989]; LIU H, 1999, FEATURE SELECTION KN; McLachlan Geoffrey J., 2004, DISCRIMINANT ANAL ST, V544; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; Mika S, 2001, ADV NEUR IN, V13, P591; NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Picard J. C., 1975, Networks, V5, P357, DOI 10.1002/net.3230050405; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Rosenblatt M., 2000, GAUSSIAN NONGAUSSIAN; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Scholkopf B., 2002, LEARNING KERNELS; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wang L, 2008, IEEE T PATTERN ANAL, V30, P1534, DOI 10.1109/TPAMI.2007.70799; Webb A.R., 2003, STAT PATTERN RECOGNI; Welsh JB, 2001, CANCER RES, V61, P5974; Weston J, 2001, ADV NEUR IN, V13, P668; Weston J., 2003, Journal of Machine Learning Research, V3, P1439, DOI 10.1162/153244303322753751; Winkler G., 2006, IMAGE ANAL RANDOM FI; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085	64	113	116	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1217	1233		10.1109/TPAMI.2010.195	http://dx.doi.org/10.1109/TPAMI.2010.195			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	21493968				2022-12-18	WOS:000289524000011
J	Wang, X				Wang, Xin			Laplacian operator-based edge detectors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Laplacian operator; LoG operator; multistage median filter; edge detection		Laplacian operator is a second derivative operator often used in edge detection. Compared with the first derivative-based edge detectors such as Sobel operator, the Laplacian operator may yield better results in edge localization. Unfortunately, the Laplacian operator is very sensitive to noise. In this paper, based on the Laplacian operator, a model is introduced for making some edge detectors. Also, the optimal threshold is introduced for obtaining a Maximum a Posteriori ( MAP) estimate of edges.	Shandong Univ, Sch Informat Sci & Engn, Jinan 250061, Peoples R China	Shandong University	Wang, X (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan 250061, Peoples R China.	xwang@sdu.edu.cn						ARCE GR, 1989, IEEE T ACOUST SPEECH, V37, P83, DOI 10.1109/29.17503; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633; Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Faghih F, 2002, IEEE T IMAGE PROCESS, V11, P1062, DOI 10.1109/TIP.2002.802526; Jain R., 1995, MACHINE VISION; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332; PINGLE KK, 1969, AUTOMATIC INTERPREDA; RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490; Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091; Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151	15	113	124	6	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					886	U1		10.1109/TPAMI.2007.1027	http://dx.doi.org/10.1109/TPAMI.2007.1027			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356206				2022-12-18	WOS:000244855700010
J	Zheng, YF; Li, HP; Doermann, D				Zheng, YF; Li, HP; Doermann, D			Machine printed text and handwriting identification in noisy document images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						text identification; handwriting identification; Markov random field; postprocessing; noisy document image enhancement; document analysis	PAGE SEGMENTATION; RECOGNITION	In this paper, we address the problem of the identification of text in noisy document images. We are especially focused on segmenting and identifying between handwriting and machine printed text because: 1) Handwriting in a document often indicates corrections, additions, or other supplemental information that should be treated differently from the main content and 2) the segmentation and recognition techniques requested for machine printed and handwritten text are significantly different. A novel aspect of our approach is that we treat noise as a separate class and model noise based on selected features. Trained Fisher classifiers are used to identify machine printed text and handwriting from noise and we further exploit context to refine the classification. A Markov Random Field-based (MRF) approach is used to model the geometrical structure of the printed text, handwriting, and noise to rectify misclassifications. Experimental results show that our approach is robust and can significantly improve page segmentation in noisy document collections.	Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Zheng, YF (corresponding author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	zhengyf@cfar.umd.edu; huiping@cfar.umd.edu; doermann@cfar.umd.edu	Zheng, Yefeng/ABG-7053-2020	Zheng, Yefeng/0000-0003-2195-2847				AKIYAMA T, 1990, PATTERN RECOGN, V23, P1141, DOI 10.1016/0031-3203(90)90112-X; [Anonymous], P 1 IARP WORKSH GRAP; Baird H. S., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P1; Baird H. S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P459, DOI 10.1109/ICDAR.1999.791824; Baird H. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P820, DOI 10.1109/ICPR.1990.118223; Cannon M., 1999, INT J DOC ANAL RECOG, P80, DOI [10.1007/s100320050039, DOI 10.1007/S100320050039]; CHANG C.C., 2003, LIBSVM LIB SUPPORT V; Chinnasarn K, 1998, APCCAS '98 - IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P459, DOI 10.1109/APCCAS.1998.743809; CHOU PB, 1993, MARKOV RANDOM FIELDS; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; Fan KC, 1998, PATTERN RECOGN, V31, P1275, DOI 10.1016/S0031-3203(97)00143-X; FANKE J, 1993, P INT C DOC AN REC, P581; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Grimmett G. R., 2001, PROBABILITY RANDOM P; Guo JHK, 2001, PROC INT CONF DOC, P439, DOI 10.1109/ICDAR.2001.953828; HARALICK RM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P385, DOI 10.1109/CVPR.1994.323855; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hull JJ, 1996, IEEE T PATTERN ANAL, V18, P1251, DOI 10.1109/34.546261; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; KANAI J, 1995, IEEE T PATTERN ANAL, V17, P86, DOI 10.1109/34.368146; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; Kanungo T., 1994, Proceedings of IAPR Workshop on Machine Vision Applications, P552; Kanungo T, 2001, INT CONF ACOUST SPEE, P1961, DOI 10.1109/ICASSP.2001.941331; Kuhnke K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P811, DOI 10.1109/ICDAR.1995.602025; KUKOLICK L, 2003, LNKNET USERS GUIDE; Lee SW, 2001, IEEE T PATTERN ANAL, V23, P1240, DOI 10.1109/34.969115; LI H, 2002, P SPIE C DOC REC RET, P232; Li S. Z., 2001, COMP SCI W; LIANG J, 1996, P SPIE C DOC REC, P274; Liang JS, 1997, P SOC PHOTO-OPT INS, V3027, P149, DOI 10.1117/12.270067; Lin XF, 1998, PATTERN RECOGN LETT, V19, P975, DOI 10.1016/S0167-8655(98)00072-5; LOCE RP, 1997, ENHANCEMENT RESTORAT; Mao S, 2001, IEEE T PATTERN ANAL, V23, P242, DOI 10.1109/34.910877; NAGY G, 1984, PATTERN RECOGN, V2, P149; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; OGORMAN L, 1992, P INT C PATT REC, P820; Pal U, 2001, PATTERN RECOGN LETT, V22, P431, DOI 10.1016/S0167-8655(00)00126-4; PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9; RANDRIAMASY S, 1994, P SPIE C DOC REC, P217; *SCANS CORP, 2003, SCANS DEV KIT 2000; SINHA RMK, 1993, IEEE T PATTERN ANAL, V15, P915, DOI 10.1109/34.232077; Soffer A, 1997, PROC INT CONF DOC, P233, DOI 10.1109/ICDAR.1997.619847; SRIHARI SN, 1994, CEDARTR942 SUNY; Sural S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P463, DOI 10.1109/ICDAR.1999.791825; Sylwester D, 2001, PROC INT CONF DOC, P827, DOI 10.1109/ICDAR.2001.953903; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wang YL, 2001, PROC INT CONF DOC, P540, DOI 10.1109/ICDAR.2001.953847; WOLF C, 2002, P INT C PATT REC; ZHENG Y, 2002, P SPIE C DOC REC RET, P49; Zheng YF, 2002, LECT NOTES COMPUT SC, V2423, P95	54	113	125	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					337	353		10.1109/TPAMI.2004.1262324	http://dx.doi.org/10.1109/TPAMI.2004.1262324			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376881	Green Submitted			2022-12-18	WOS:000188949400005
J	Gdalyahu, Y; Weinshall, D; Werman, M				Gdalyahu, Y; Weinshall, D; Werman, M			Self-organization in vision: Stochastic clustering for image segmentation, perceptual grouping, and image database organization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; segmentetion; perceptual grouping; image retrieval	FEATURES	We present a stochastic clustering algorithm which uses pairwise similarity of elements and show how it can be used to address various problems in computer vision, including the low-level image segmentation, mid-level perceptual grouping, and high-level image database organization. The clustering problem is viewed as a graph partitioning problem, where nodes represent data elements and the weights of the edges represent pairwise similarities. We generate samples of cuts in this graph, by using Karger's contraction algorithm, and compute an "average" cut which provides the basis for our solution to the clustering problem. The stochastic nature of our method makes it robust against noise, including accidental edges and small spurious clusters. The complexity of our algorithm is very low: O(\E \ log(2) N) for N objects, \E \ similarity relations, and a fixed accuracy level. In addition, and without additional computational cost, our algorithm provides a hierarchy of nested partitions. We demonstrate the superiority of our method for image segmentation on a few synthetic and real images, both B&W and color. Our other examples include the concatenation of edges in a cluttered scene (perceptual grouping) and the organization of an image database for the purpose of multiview 3D object recognition.	Hebrew Univ Jerusalem, Inst Comp Sci, IL-91901 Jerusalem, Israel; MobilEye Vis Technol Ltd, IL-97278 Jerusalem, Israel	Hebrew University of Jerusalem	Gdalyahu, Y (corresponding author), MobilEye Vis Technol Ltd, 24 Mishol Hadkalim St, IL-97278 Jerusalem, Israel.	yoram@mobileye.com; daphna@cs.huji.ac.il; werman@cs.huji.ac.il						[Anonymous], 1998, PROC SODA; [Anonymous], 1994, INTRO COMPUTATIONAL; Blatt M, 1997, NEURAL COMPUT, V9, P1805, DOI 10.1162/neco.1997.9.8.1805; Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245; Cho KJ, 1997, COMPUT VIS IMAGE UND, V68, P72, DOI 10.1006/cviu.1997.0546; CHUNG F. R. K., 1977, SPECTRAL GRAPH THEOR; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; ENNIS DM, 1992, MULTIDIMENSIONAL MOD, P279; Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; Gdalyahu Y, 2000, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.2000.855842; GDALYAHU Y, 2000, THESIS HEBREW U JERU; GDALYAHU Y, 1998, ADV NEURAL INFORMATI, V11, P424; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Guedalia ID, 1999, NEURAL COMPUT, V11, P521, DOI 10.1162/089976699300016755; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; Hart P. E, 1973, PATTERN CLASSIFICATI; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; Hu T. C., 1982, COMBINATORIAL ALGORI; Ishikawa H, 1998, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.1998.698598; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Karger DR, 1996, J ACM, V43, P601, DOI 10.1145/234533.234534; LANCE G, 1969, COMPUT J, V10, P271; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PERONA P, 1998, P EUR C COMP VIS, P655; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; ROSE K, 1993, IEEE T PATTERN ANAL, V15, P785, DOI 10.1109/34.236251; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; Scott G.L., 1990, BMVC, P1; Sharon E, 2000, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2000.855801; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; TISHBY N, 2000, ADV NEURAL INFORMATI; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; WILLIAMS L, 1997, NEURAL COMPUT, V9, P849; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; [No title captured]	42	113	132	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1053	1074		10.1109/34.954598	http://dx.doi.org/10.1109/34.954598			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600002
J	Chojnacki, W; Brooks, MJ; van den Hengel, A; Gawley, D				Chojnacki, W; Brooks, MJ; van den Hengel, A; Gawley, D			On the fitting of surfaces to data with covariances	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical methods; surface fitting; parameter estimation; covariance matrix; maximum-likelihood; renormalization; conic fitting; fundamental matrix	ALGORITHMS; CURVES; MOTION	We consider the problem of estimating parameters of a model described by an equation of special form. Specific models arise in the analysis of a wide class of computer vision problems, including conic fitting and estimation of the fundamental matrix. We assume that noisy data are accompanied by (known) covariance matrices characterizing the uncertainty of the measurements. A cost function is first obtained by considering a maximum-likelihood formulation and applying certain necessary approximations that render the problem tractable. A novel, Newton-like iterative scheme is then generated for determining a minimizer of the cost function. Unlike alternative approaches such as Sampson's method or the renormalization technique, the new scheme has as its theoretical limit the minimizer of the cost function. Furthermore, the scheme is simply expressed, efficient, and unsurpassed as a general technique in our testing. An important feature of the method is that it can serve as a basis for conducting theoretical comparison of various estimation approaches.	Univ Adelaide, Dept Comp Sci, Adelaide, SA 5005, Australia	University of Adelaide	Chojnacki, W (corresponding author), Univ Adelaide, Dept Comp Sci, Adelaide, SA 5005, Australia.	wojtek@cs.adelaide.edu.au; mjb@cs.adelaide.edu.au; hengel@cs.adelaide.edu.au; dg@cs.adelaide.edu.au	Brooks, Michael/G-5614-2012; Chojnacki, Wojciech/AAE-9875-2020	Brooks, Michael/0000-0001-9612-5884; Chojnacki, Wojciech/0000-0001-7782-1956				Boggs PT, 1990, CONT MATH, V112, P183, DOI [10.1090/conm/112/1087109, DOI 10.1090/CONM/112/1087109]; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; Brooks MJ, 1997, J OPT SOC AM A, V14, P2670, DOI 10.1364/JOSAA.14.002670; CHOJNACKI W, 2001, IN PRESS J MATH IMAG; ELLIS T, 1992, IMAGE VISION COMPUT, V10, P271, DOI 10.1016/0262-8856(92)90041-Z; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Fitzgibbon A. W., 1995, BMVC '95 Proceedings of the 6th British Machine Vision Conference, P513; FORSTNER W, 2000, P 6 EUR C COMP VIS, V2, P669; Fuller W. A., 2009, MEASUREMENT ERROR MO; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; KANAMORI T, 1993, J LOGIC PROGRAM, V15, P1, DOI 10.1016/0743-1066(93)90011-5; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Kanatani K., 1996, STAT OPTIMIZATION GE; Kanazawa Y, 1996, IEICE T INF SYST, VE79D, P1323; Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375; Leedan Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P733, DOI 10.1109/ICCV.1998.710799; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727; MATEI B, 2000, P 15 INT C PATT REC, V3, P802; MUHLICH M, 1998, P 5 EUR C COMP VIS, V2, P305; MUHLICH M, 1999, XPTRC21 J WOLFG GOET; PORRILL J, 1990, IMAGE VISION COMPUT, V8, P37, DOI 10.1016/0262-8856(90)90054-9; PRESS WH, 1995, NUMERCIAL RECIPES C; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; Sampson CB, 1997, NUCL MED COMMUN, V18, P1, DOI 10.1097/00006231-199701000-00001; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Tismenetsky M., 1985, THEORY MATRICES APPL; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; TRIGGS B, 1998, ECCV 98 WORKSH 3D ST; TRIGGS B, NEW APPROACH GEOMETR; Van Huffel S., 1991, TOTAL LEAST SQUARES; VIEVILLE T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P750, DOI 10.1109/ICCV.1995.466863; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; ZHANG B, 1997, PROBE MICROS, V1, P57; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; Zhang ZY, 1998, IEEE T PATTERN ANAL, V20, P717, DOI 10.1109/34.689302; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	43	113	114	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1294	1303						10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE		Green Submitted			2022-12-18	WOS:000165355200007
J	Zhong, Y; Jain, AK; Dubuisson-Jolly, MP				Zhong, Y; Jain, AK; Dubuisson-Jolly, MP			Object tracking using deformable templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; image sequence deformable template; shape; texture; motion	MODELS; SHAPE; MOTION; FLOW	We propose a novel method for object tracking using prototype-based deformable template models. To track an object in an image sequence, we use a criterion which combines two terms: the frame-to-frame deviations of the object shape and the fidelity of the modeled shape to the Input image. The deformable template model utilizes the prior shape information which is extracted from the previous frames along with a systematic shape deformation scheme to model the object shape in a new frame. The following image information Is used in the tracking process: 1) edge and gradient information: the object boundary consists of pixels with large image gradient, 2) region consistency: the same object region possesses consistent color and texture throughout the sequence, and 3) interframe motion: the boundary of a moving object is characterized by large interframe motion. The tracking proceeds by optimizing an objective function which combines both the shape deformation and the fidelity of the modeled shape to the current image (in terms of gradient, texture, and interframe motion). The inherent structure in the deformable template. together with region, motion, and image gradient cues. makes the proposed algorithm relatively insensitive to the adverse effects of weak image features and moderate amounts of occlusion.	Carnegie Mellon Univ, Natl Robot Consortium, Pittsburgh, PA 15201 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; Siemens Corp Res, Princeton, NJ 08540 USA	Carnegie Mellon University; Michigan State University; Siemens AG	Zhong, Y (corresponding author), Carnegie Mellon Univ, Natl Robot Consortium, Pittsburgh, PA 15201 USA.	zhongyu@cs.cmu.edu; jain@cse.msu.edu; jolly@scr.siemens.com						AYACHE N, 1992, ACTIVE VISION, P25; BASCLE B, 1994, INT C PATT RECOG, P426, DOI 10.1109/ICPR.1994.576315; BASCLE B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P302, DOI 10.1109/ICCV.1995.466925; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; DeCarlo D, 1996, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.1996.517079; Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; Heisele B, 1997, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.1997.609329; ISARD M, 1996, P EUR C COMP VIS CAM, V1, P343; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Kakadiaris IA, 1996, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.1996.517057; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KERVRANN C, 1994, IEEE IMAGE PROC, P88, DOI 10.1109/ICIP.1994.413882; LANITIS A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P368, DOI 10.1109/ICCV.1995.466919; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; TERZOPOULOUS D, 1992, ACTIVE VISION, P1; YUILLE A, 1992, ACTIVE VISION; Zhong Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P440, DOI 10.1109/ICCV.1998.710756; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909	24	113	148	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					544	549		10.1109/34.857008	http://dx.doi.org/10.1109/34.857008			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500009
J	GRIMSON, WEL; HUTTENLOCHER, DP				GRIMSON, WEL; HUTTENLOCHER, DP			ON THE SENSITIVITY OF THE HOUGH TRANSFORM FOR OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CORNELL UNIV,DEPT COMP SCI,ITHACA,NY 14853	Cornell University	GRIMSON, WEL (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,545 TECHNOL SQ,CAMBRIDGE,MA 02139, USA.							ALAGAR VS, 1981, IEEE T PATTERN ANAL, V3, P245, DOI 10.1109/TPAMI.1981.4767097; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; CHIN RT, 1986, ACM COMPUT SURV, V18, P67; CLEMENS DT, 1986, THESIS MIT; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; DAVIS LS, 1982, PATTERN RECOGN, V15, P277, DOI 10.1016/0031-3203(82)90030-9; Feller W., 1968, INTRO PROBABILITY TH, V3; LINAINMAA S, 1985, CARTR143 U MAR CTR A; MAITRE H, 1986, IEEE T PATTERN ANAL, V8, P669, DOI 10.1109/TPAMI.1986.4767840; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHAPIRO SD, 1979, IEEE T PATTERN ANAL, V1, P310, DOI 10.1109/TPAMI.1979.4766929; SILBERBERG TM, 1986, COMPUT VISION GRAPH, V35, P47, DOI 10.1016/0734-189X(86)90125-8; SILBERBERG TM, 1984, PATTERN RECOGN, V17, P612; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; THOMPSON DW, 1987, IEEE J ROBOTIC AUTOM, P208; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; [No title captured]; [No title captured]	20	113	151	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1990	12	3					255	274		10.1109/34.49052	http://dx.doi.org/10.1109/34.49052			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CP943		Green Submitted			2022-12-18	WOS:A1990CP94300003
J	Zhang, XC; Sugano, Y; Fritz, M; Bulling, A				Zhang, Xucong; Sugano, Yusuke; Fritz, Mario; Bulling, Andreas			MPIIGaze: Real World Dataset and Deep Appearance-Based Gaze Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unconstrained gaze estimation; cross-dataset evaluation; convolutional neural network; deep learning	TRACKING	Learning-based methods are believed to work well for unconstrained gaze estimation, i.e. gaze estimation from a monocular RGB camera without assumptions regarding user, environment, or camera. However, current gaze datasets were collected under laboratory conditions and methods were not evaluated across multiple datasets. Our work makes three contributions towards addressing these limitations. First, we present the MPIIGaze dataset, which contains 213,659 full face images and corresponding ground-truth gaze positions collected from 15 users during everyday laptop use over several months. An experience sampling approach ensured continuous gaze and head poses and realistic variation in eye appearance and illumination. To facilitate cross-dataset evaluations, 37,667 images were manually annotated with eye corners, mouth corners, and pupil centres. Second, we present an extensive evaluation of state-of-the-art gaze estimation methods on three current datasets, including MPIIGaze. We study key challenges including target gaze range, illumination conditions, and facial appearance variation. We show that image resolution and the use of both eyes affect gaze estimation performance, while head pose and pupil centre information are less informative. Finally, we propose GazeNet, the first deep appearance-based gaze estimation method. GazeNet improves on the state of the art by 22 percent (from a mean error of 13.9 degrees to 10.8 degrees) for the most challenging cross-dataset evaluation.	[Zhang, Xucong; Fritz, Mario; Bulling, Andreas] Max Planck Inst Informat, Saarland Informat Campus, D-66123 Saarbrucken, Germany; [Sugano, Yusuke] Osaka Univ, Grad Sch Informat Sci & Technol, Osaka 5650871, Japan	Max Planck Society; Osaka University	Zhang, XC (corresponding author), Max Planck Inst Informat, Saarland Informat Campus, D-66123 Saarbrucken, Germany.	xczhang@mpi-inf.mpg.de; sugano@ist.osaka-u.ac.jp; mfritz@mpi-inf.mpg.de; bulling@mpi-inf.mpg.de	Sugano, Yusuke/X-3689-2019	Sugano, Yusuke/0000-0003-4206-710X	Cluster of Excellence on Multimodal Computing and Interaction (MMCI) at Saarland University, Germany; Alexander von Humboldt Postdoctoral Fellowship, Germany; JST CREST Research Grant, Japan [JPMJCR14E1]	Cluster of Excellence on Multimodal Computing and Interaction (MMCI) at Saarland University, Germany; Alexander von Humboldt Postdoctoral Fellowship, Germany; JST CREST Research Grant, Japan	We would like to thank Laura Sesma for her help with the dataset handling and normalisation. This work was funded, in part, by the Cluster of Excellence on Multimodal Computing and Interaction (MMCI) at Saarland University, Germany, an Alexander von Humboldt Postdoctoral Fellowship, Germany, and a JST CREST Research Grant (JPMJCR14E1), Japan. Yusuke Sugano's work was conducted while at the Max Planck Institute for Informatics.	Alnajar F, 2013, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2013.24; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Baltrusaitis T, 2014, LECT NOTES COMPUT SC, V8692, P593, DOI 10.1007/978-3-319-10593-2_39; Baluja S., 1994, ADV NEURAL INFORM PR, V6, P753; Bradski G, 2000, DR DOBBS J, V25, P120; Chen D., 2014, LECT NOTES COMPUT SC, P109, DOI DOI 10.1007/978-3-319-10599-4; Chen J, 2008, LECT NOTES COMPUT SC, V5018, P1, DOI 10.1007/978-3-540-79723-4_1; Chen JX, 2011, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.2011.5995675; Choi J, 2013, INT CONF UBIQ ROBOT, P260, DOI 10.1109/URAI.2013.6677362; Cohn J. F, 2016, P IEEE C COMP VIS PA, P87; Cristina S, 2016, COMPUT VIS IMAGE UND, V149, P157, DOI 10.1016/j.cviu.2016.02.012; Funes Mora K.A., 2014, P S EYE TRACK RES AP, P255; Funes-Mora KA, 2016, INT J COMPUT VISION, V118, P194, DOI 10.1007/s11263-015-0863-4; Gao T., 2014, TECH REP; Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30; Hennessey Craig, 2006, P 2006 S EYE TRACK R, DOI DOI 10.1145/1117309.1117349; Huang MX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1017, DOI 10.1145/2647868.2655031; Huang Q, 2017, MACH VISION APPL, V28, P445, DOI 10.1007/s00138-017-0852-4; Ishikawa T., IEEE T INTELLIGENT T; Jia Y., 2014, P 22 ACM INT C MULT, P675; Kassner M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1151, DOI 10.1145/2638728.2641695; King DE, 2009, J MACH LEARN RES, V10, P1755; Kingma D.P, P 3 INT C LEARNING R; Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239; Larson R., 2014, NEW DIRECTIONS METHO, P21; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li JF, 2014, IEEE COMPUT SOC CONF, P606, DOI 10.1109/CVPRW.2014.93; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liang K., 2013, P C EYE TRACK S AFR, P17; Lu F, 2012, INT C PATT RECOG, P1008; Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123; Lu F, 2014, IMAGE VISION COMPUT, V32, P169, DOI 10.1016/j.imavis.2014.01.005; Majaranta Paivi, 2014, ADV PHYSL COMPUTING, P39, DOI DOI 10.1007/978-1-4471-6392-3_3; McMurrough C. D., 2012, P S EYE TRACK RES AP, P305, DOI DOI 10.1145/2168556.2168622; Mora K. A. F., 2012, P IEEE COMP SOC C CO, P25, DOI DOI 10.1109/CVPRW.2012.6239182; Mora KAF, 2014, PROC CVPR IEEE, P1773, DOI 10.1109/CVPR.2014.229; Mora KAF, 2013, IEEE IMAGE PROC, P2787, DOI 10.1109/ICIP.2013.6738574; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Ponz V, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P681; Qiuhai He, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P418, DOI 10.1007/978-3-319-19665-7_35; Rodrigues R, 2010, LECT NOTES COMPUT SC, V6314, P382, DOI 10.1007/978-3-642-15561-1_28; SATTAR H, 2015, PROC CVPR IEEE, P981, DOI DOI 10.1109/CVPR.2015.7298700; Schneider T, 2014, INT C PATT RECOG, P1167, DOI 10.1109/ICPR.2014.210; Sewell W., 2010, REAL TIME EYE GAZE T, P3739; Shih SW, 2004, IEEE T SYST MAN CY B, V34, P234, DOI 10.1109/TSMCB.2003.811128; Smith Brian A, 2013, P 26 ANN ACM S US IN, P271, DOI DOI 10.1145/2501988.2501994; Sugano Y, 2008, LECT NOTES COMPUT SC, V5304, P656, DOI 10.1007/978-3-540-88690-7_49; Sugano Y, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P821, DOI 10.1145/2984511.2984536; Sugano Y, 2015, IEEE T HUM-MACH SYST, V45, P750, DOI 10.1109/THMS.2015.2400434; Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235; Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101; Sun L, 2014, IEEE MULTIMEDIA, V21, P28, DOI 10.1109/MMUL.2014.54; Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180; Tonsen M, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P139, DOI 10.1145/2857491.2857520; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740; Villanueva A, 2013, ACM T MULTIM COMPUT, V9, P4; Weidenbacher Ulrich, 2007, P 3 IET INT C INT EN, P455; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285; Wood E., 2016, P EUR C COMPUT VIS, P3756; Wood E, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P131, DOI 10.1145/2857491.2857492; Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428; Wood Erroll, 2014, P S EYE TRACK RES AP, P207, DOI [10.1145/2578153.2578185, DOI 10.1145/2578153.2578185]; Xu P., 2015, TECH REP; Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527; Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011; Yu P, 2016, PROC CVPR IEEE, P3447, DOI 10.1109/CVPR.2016.375; ZHANG XC, 2015, PROC CVPR IEEE, P4511, DOI DOI 10.1109/CVPR.2015.7299081; Zhang XC, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P193, DOI 10.1145/3126594.3126614; Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284; Zhang Y., 2013, P CHI 13, P851, DOI DOI 10.1145/2470654.2470775; Zhu ZW, 2006, INT C PATT RECOG, P1132; Zhu ZW, 2005, PROC CVPR IEEE, P918	77	112	115	10	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					162	175		10.1109/TPAMI.2017.2778103	http://dx.doi.org/10.1109/TPAMI.2017.2778103			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990057	Green Submitted			2022-12-18	WOS:000452434800013
J	Zhang, SS; Benenson, R; Omran, M; Hosang, J; Schiele, B				Zhang, Shanshan; Benenson, Rodrigo; Omran, Mohamed; Hosang, Jan; Schiele, Bernt			Towards Reaching Human Performance in Pedestrian Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pedestrian detection; human baseline; failure analysis; annotations; convnets; integral channel features	TRACKING; SINGLE	Encouraged by the recent progress in pedestrian detection, we investigate the gap between current state-of-the-art methods and the "perfect single frame detector". We enable our analysis by creating a human baseline for pedestrian detection (over the Caltech pedestrian dataset). After manually clustering the frequent errors of a top detector, we characterise both localisation and background-versus-foreground errors. To address localisation errors we study the impact of training annotation noise on the detector performance, and show that we can improve results even with a small portion of sanitised training data. To address background/foreground discrimination, we study convnets for pedestrian detection, and discuss which factors affect their performance. Other than our in-depth analysis, we report top performance on the Caltech pedestrian dataset, and provide a new sanitised set of training and test annotations.	[Zhang, Shanshan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Zhang, Shanshan; Benenson, Rodrigo; Omran, Mohamed; Hosang, Jan; Schiele, Bernt] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Nanjing University of Science & Technology; Max Planck Society	Zhang, SS (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.; Zhang, SS (corresponding author), Max Planck Inst Informat, D-66123 Saarbrucken, Germany.	shanshan.zhang@njust.edu.cn; benenson@mpi-inf.mpg.de; mohomran@mpi-inf.mpg.de; jhosang@mpi-inf.mpg.de; schiele@mpi-inf.mpg.de						Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Angelova A., 2015, PROC BRIT MACH VIS C, P1, DOI DOI 10.5244/C.29.32; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384; Costea AD, 2016, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2016.259; Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, LECT NOTES COMPUT SC, V7573, P645, DOI 10.1007/978-3-642-33709-3_46; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Dollar Piotr, 2010, BMVC, DOI DOI 10.5244/C.24.68; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; Geiger A., 2012, P IEEE COMP SOC C CO; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25; Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li J., 2016, ARXIV151008160; Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120; Nam W, 2014, ADV NEUR IN, V27; Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257; Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411; Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062; Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36; Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221; Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; WALK S, 2010, PROC CVPR IEEE, P1030, DOI DOI 10.1109/CVPR.2010.5540102; Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769; Xu D, 2012, IEEE T IMAGE PROCESS, V21, P316, DOI 10.1109/TIP.2011.2160956; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Zeng XY, 2013, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2013.22; Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28; Zhang S., 2014, CVPR; Zhang S., 2015, P IEEE C COMP VIS PA, P681; Zhang SS, 2015, IEEE T CIRC SYST VID, V25, P1709, DOI 10.1109/TCSVT.2015.2397199; ZHANG SS, 2016, PROC CVPR IEEE, P1259, DOI DOI 10.1109/CVPR.2016.141	52	112	121	3	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					973	986		10.1109/TPAMI.2017.2700460	http://dx.doi.org/10.1109/TPAMI.2017.2700460			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28475049				2022-12-18	WOS:000426687100015
J	Jayasumana, S; Hartley, R; Salzmann, M; Li, HD; Harandi, M				Jayasumana, Sadeep; Hartley, Richard; Salzmann, Mathieu; Li, Hongdong; Harandi, Mehrtash			Kernel Methods on Riemannian Manifolds with Gaussian RBF Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Riemannian manifolds; Gaussian RBF kernels; kernel methods; positive definite kernels; symmetric positive definite matrices; Grassmann manifolds	TEXTURE CLASSIFICATION; FRAMEWORK	In this paper, we develop an approach to exploiting kernel methods with manifold-valued data. In many computer vision problems, the data can be naturally represented as points on a Riemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds, usual Euclidean computer vision and machine learning algorithms yield inferior results on such data. In this paper, we define Gaussian radial basis function (RBF)-based positive definite kernels on manifolds that permit us to embed a given manifold with a corresponding metric in a high dimensional reproducing kernel Hilbert space. These kernels make it possible to utilize algorithms developed for linear spaces on nonlinear manifold-valued data. Since the Gaussian RBF defined with any given metric is not always positive definite, we present a unified framework for analyzing the positive definiteness of the Gaussian RBF on a generic metric space. We then use the proposed framework to identify positive definite kernels on two specific manifolds commonly encountered in computer vision: the Riemannian manifold of symmetric positive definite matrices and the Grassmann manifold, i.e., the Riemannian manifold of linear subspaces of a Euclidean space. We show that many popular algorithms designed for Euclidean spaces, such as support vector machines, discriminant analysis and principal component analysis can be generalized to Riemannian manifolds with the help of such positive definite Gaussian kernels.	[Jayasumana, Sadeep] Australian Natl Univ, Canberra, ACT, Australia; NICTA, Canberra, ACT, Australia	Australian National University; Australian National University	Jayasumana, S (corresponding author), Australian Natl Univ, Canberra, ACT, Australia.	sadeep.jayasumana@anu.edu.au; richard.hartley@anu.edu.au; mathieu.salzmann@nicta.com.au; Hongdong.Li@anu.edu.au; mehrtash.harandi@nicta.com.au	Jayasumana, Sadeep/W-1590-2019; Harandi, Mehrtash/D-6586-2018	Harandi, Mehrtash/0000-0002-6937-6300; Hartley, Richard/0000-0002-5005-0191; Salzmann, Mathieu/0000-0002-8347-8637	ARC; Australian Government; Australian Research Council (ARC) through the ICT Centre of Excellence program	ARC(Australian Research Council); Australian Government(Australian GovernmentCGIAR); Australian Research Council (ARC) through the ICT Centre of Excellence program(Australian Research Council)	This work was supported in part by an ARC grant. The authors would like thank Bob Williamson for useful discussions. NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council (ARC) through the ICT Centre of Excellence program. S. Jayasumana is the corresponding author.	ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; Arsigny V, 2005, FAST SIMPLE COMPUTAT; Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; Berg C., 1984, HARMONIC ANAL SEMIGR; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Caseiro R, 2013, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2013.13; Caseiro R, 2012, LECT NOTES COMPUT SC, V7572, P342, DOI 10.1007/978-3-642-33718-5_25; Caseiro R, 2011, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2011.6126218; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dryden IL, 2009, ANN APPL STAT, V3, P1102, DOI 10.1214/09-AOAS249; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Goh A, 2008, 2008 IEEE C COMP VIS, P1; Ham J., 2008, P NEUR INF PROC SYST, P601; Hamm J., 2008, P 25 INT C MACH LEAR; Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005; Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564; Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Leibe B, 2003, PROC CVPR IEEE, P409; Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202; Li PH, 2012, LECT NOTES COMPUT SC, V7574, P469, DOI 10.1007/978-3-642-33712-3_34; Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002; Malcolm J., 2007, P IEEE C COMP VIS PA, P1; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ong C. S., 2004, P 21 INT C MACH LEAR, P639; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Platt J, 1999, ADV KERNEL METHODS S; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2001, LEARNING KERNELS SUP; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Sra S., 2012, ARXIV11101773; Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Varma M., 2007, P IEEE INT C COMP VI, V1, P1, DOI DOI 10.1109/ICCV.2007.4408875; Varma Manik, 2009, P 26 ANN INT C MACH, P1065; Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Wu G., 2005, ANAL TRANSFORMATION	50	112	118	2	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2464	2477		10.1109/TPAMI.2015.2414422	http://dx.doi.org/10.1109/TPAMI.2015.2414422			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539851	Green Submitted			2022-12-18	WOS:000364831700009
J	Lu, WL; Ting, JA; Little, JJ; Murphy, KP				Lu, Wei-Lwun; Ting, Jo-Anne; Little, James J.; Murphy, Kevin P.			Learning to Track and Identify Players from Broadcast Sports Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sports video analysis; identification; tracking; weakly supervised learning	OBJECT TRACKING; MULTIPLE	Tracking and identifying players in sports videos filmed with a single pan-tilt-zoom camera has many applications, but it is also a challenging problem. This paper introduces a system that tackles this difficult task. The system possesses the ability to detect and track multiple players, estimates the homography between video frames and the court, and identifies the players. The identification system combines three weak visual cues, and exploits both temporal and mutual exclusion constraints in a Conditional Random Field (CRF). In addition, we propose a novel Linear Programming (LP) Relaxation algorithm for predicting the best player identification in a video clip. In order to reduce the number of labeled training data required to learn the identification system, we make use of weakly supervised learning with the assistance of play-by-play texts. Experiments show promising results in tracking, homography estimation, and identification. Moreover, weakly supervised learning with play-by-play texts greatly reduces the number of labeled training examples required. The identification system can achieve similar accuracies by using merely 200 labels in weakly supervised learning, while a strongly supervised approach needs a least 20,000 labels.	[Lu, Wei-Lwun; Murphy, Kevin P.] Google, Mountain View, CA 94043 USA; [Ting, Jo-Anne] Robert Bosch Res & Technol Ctr, Palo Alto, CA 94304 USA; [Little, James J.] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada	Google Incorporated; Bosch; University of British Columbia	Lu, WL (corresponding author), Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	vailen@cs.ubc.ca; Jo-Anne.Ting@us.bosch.com; little@cs.ubc.ca; murphyk@gmail.com			National Science and Engineering Research Council of Canada; GEOIDE Network of Centres of Excellence; Canadian Institute for Advanced Research	National Science and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); GEOIDE Network of Centres of Excellence; Canadian Institute for Advanced Research(Canadian Institute for Advanced Research (CIFAR))	This work has been supported by grants from the National Science and Engineering Research Council of Canada, the GEOIDE Network of Centres of Excellence, and the Canadian Institute for Advanced Research. The authors would also like to thank the National Basketball Association Entertainment for kindly providing the image dataset.	[Anonymous], 2012, TESSERACT OCR; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], P IEEE; Ballan L., 2007, P 6 ACM INT C IM VID; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BenShitrit H., 2011, P IEEE INT COMP VIS; Bertini M., 2005, P 7 ACM SIGMM INT WO; Bishop C.M, 2006, PATTERN RECOGN; Cai Y., 2006, P 9 EUR C COMP VIS; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Cour T., 2009, P IEEE C COMP VIS PA; Cour T., 2010, P IEEE C COMP VIS PA; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duchenne O., 2009, P IEEE INT COMP VIS; Everingham M, 2006, P BRIT MACHINE VISIO, V4, P6; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Forssen P.-E., 2007, P IEEE INT COMP VIS; Frey B., 1998, ADV NEUR INF PROC SY; Gupta A., 2009, P IEEE C COMP VIS PA; Gupta A., 2011, P C COMP ROB VIS; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hess R., 2007, P IEEE C COMP VIS PA; Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373; Jiang H, 2008, IEEE T MULTIMEDIA, V10, P997, DOI 10.1109/TMM.2008.2001379; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu WL, 2011, PROC CVPR IEEE; Marszalek M., 2009, P IEEE C COMP VIS PA; Ng A. Y., 2004, P ADV NEUR INF PROC; Nocedal J., 1999, SPRINGER SERIES OPER; Okuma K., 2004, P AS C COMP VIS; Okuma K., 2012, THESIS U BRIT COLUMB; Okuma K., 2004, P EUR C COMP VIS; Saric M., 2008, P 10 WSEAS INT C AUT; Schmidt M., 2009, P C ART INT STAT; Sivic J., 2009, P IEEE C COMP VIS PA; Song B., 2010, P 11 EUR C COMP VIS; Tari S. M., 2012, THESIS U BRIT COLUMB; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Vondrick C., 2010, P 11 EUR C COMP VIS; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Yang B., 2011, P IEEE C COMP VIS PA; Ye Q., 2005, P SPIE; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhu GY, 2009, IEEE T MULTIMEDIA, V11, P49, DOI 10.1109/TMM.2008.2008918; Zhu X, 2009, MORGAN CLAYPOOL, DOI DOI 10.1007/978-3-031-01548-9	51	112	129	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1704	1716		10.1109/TPAMI.2012.242	http://dx.doi.org/10.1109/TPAMI.2012.242			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681997				2022-12-18	WOS:000319060600013
J	Chan, CH; Tahir, MA; Kittler, J; Pietikainen, M				Chan, Chi Ho; Tahir, Muhammad Atif; Kittler, Josef; Pietikainen, Matti			Multiscale Local Phase Quantization for Robust Component-Based Face Recognition Using Kernel Fusion of Multiple Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; face image representation; local binary pattern; local phase quantization; kernel discriminant analysis; kernel fusion	TEXTURE; CLASSIFICATION; ILLUMINATION; HISTOGRAM; PATTERNS; MODELS	Face recognition subject to uncontrolled illumination and blur is challenging. Interestingly, image degradation caused by blurring, often present in real-world imagery, has mostly been overlooked by the face recognition community. Such degradation corrupts face information and affects image alignment, which together negatively impact recognition accuracy. We propose a number of countermeasures designed to achieve system robustness to blurring. First, we propose a novel blur-robust face image descriptor based on Local Phase Quantization (LPQ) and extend it to a multiscale framework (MLPQ) to increase its effectiveness. To maximize the insensitivity to misalignment, the MLPQ descriptor is computed regionally by adopting a component-based framework. Second, the regional features are combined using kernel fusion. Third, the proposed MLPQ representation is combined with the Multiscale Local Binary Pattern (MLBP) descriptor using kernel fusion to increase insensitivity to illumination. Kernel Discriminant Analysis (KDA) of the combined features extracts discriminative information for face recognition. Last, two geometric normalizations are used to generate and combine multiple scores from different face image scales to further enhance the accuracy. The proposed approach has been comprehensively evaluated using the combined Yale and Extended Yale database B (degraded by artificially induced linear motion blur) as well as the FERET, FRGC 2.0, and LFW databases. The combined system is comparable to state-of-the-art approaches using similar system configurations. The reported work provides a new insight into the merits of various face representation and fusion methods, as well as their role in dealing with variable lighting and blur degradation.	[Chan, Chi Ho; Tahir, Muhammad Atif; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; [Pietikainen, Matti] Univ Oulu, Machine Vis Grp, Infotech Oulu, Dept Elect & Informat Engn, FI-90014 Oulu, Finland	University of Surrey; University of Oulu	Chan, CH (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, AB Bldg, Guildford GU2 7XH, Surrey, England.	chiho.chan@surrey.ac.uk; m.tahir@surrey.ac.uk; j.kittler@surrey.ac.uk; mkp@ee.oulu.fi			EPSRC [EP/F069421/1]; Wellcome Trust [045804]; Engineering and Physical Sciences Research Council [EP/F069421/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Wellcome Trust(Wellcome TrustEuropean Commission); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was carried out as part of EPSRC project Adaptive cognition for automated sports video annotation (ACASVA) under grant EP/F069421/1 and Wellcome Trust Grant 045804. Their support is gratefully acknowledged.	Ahonen T., 2008 19 INT C PATT R, P1; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge R., 2003, TECHNICAL REPORT; Cai D., 2007, P INT C DAT MIN; CHAN C. H., 2009, VOEC, P633; Chan CH, 2010, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2010.5651933; Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809; Chan CH, 2010, LECT NOTES COMPUT SC, V6218, P718, DOI 10.1007/978-3-642-14980-1_71; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Guillaumin M., 2009, P IEEE INT C COMP VI; Heikkila J, 2009, LNLA: 2009 INTERNATIONAL WORKSHOP ON LOCAL AND NON-LOCAL APPROXIMATION IN IMAGE PROCESSING, P104, DOI 10.1109/LNLA.2009.5278397; Huang C., 2011, TR115 NEC LAB AM; Huang G.B., 2008, WORKSHOP FACESREAL L; Huang G. B., 2007, P IEEE INT C COMP VI; Hwang W., 2006, IEEE C COMPUT VIS PA, V2, P1574; Jain A. K., 2004, HDB FACE RECOGNITION; Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104; Liu ZM, 2009, LECT NOTES COMPUT SC, V5558, P122; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311; Pinto Nicolas, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2591, DOI 10.1109/CVPRW.2009.5206605; Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001; Shan S., 2006, P INT C PATT REC; Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314; Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737; Taigman Y., 2009, P BRIT MACH VIS C SE; Taigman Y., 2011, CORR; Tan X., 2007, P INT C AN MOD FAC G; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Turk M. A., 1991, P IEEE C COMP VIS PA, V591, P586, DOI DOI 10.1109/CVPR.1991.139758; Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654; Wang H., 2008, P IEEE C COMP VIS PA; Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhao J., 2005, P IEEE COMP SOC C CO, P167; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	45	112	123	0	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1164	1177		10.1109/TPAMI.2012.199	http://dx.doi.org/10.1109/TPAMI.2012.199			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520257				2022-12-18	WOS:000316126800011
J	Tzimiropoulos, G; Zafeiriou, S; Pantic, M				Tzimiropoulos, Georgios; Zafeiriou, Stefanos; Pantic, Maja			Subspace Learning from Image Gradient Orientations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image gradient orientations; robust principal component analysis; discriminant analysis; nonlinear dimensionality reduction; face recognition	FACE-RECOGNITION; DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; FEATURE-EXTRACTION; ILLUMINATION; REGISTRATION; EIGENFACES; FRAMEWORK	We introduce the notion of subspace learning from image gradient orientations for appearance-based object recognition. As image data are typically noisy and noise is substantially different from Gaussian, traditional subspace learning from pixel intensities very often fails to estimate reliably the low-dimensional subspace of a given data population. We show that replacing pixel intensities with gradient orientations and the l(2) norm with a cosine-based distance measure offers, to some extend, a remedy to this problem. Within this framework, which we coin Image Gradient Orientations (IGO) subspace learning, we first formulate and study the properties of Principal Component Analysis of image gradient orientations (IGO-PCA). We then show its connection to previously proposed robust PCA techniques both theoretically and experimentally. Finally, we derive a number of other popular subspace learning techniques, namely, Linear Discriminant Analysis (LDA), Locally Linear Embedding (LLE), and Laplacian Eigenmaps (LE). Experimental results show that our algorithms significantly outperform popular methods such as Gabor features and Local Binary Patterns and achieve state-of-the-art performance for difficult problems such as illumination and occlusion-robust face recognition. In addition to this, the proposed IGO-methods require the eigendecomposition of simple covariance matrices and are as computationally efficient as their corresponding l(2) norm intensity-based counterparts. Matlab code for the methods presented in this paper can be found at http://ibug.doc.ic.ac.uk/resources.	[Tzimiropoulos, Georgios] Lincoln Univ, Sch Comp Sci, Lincoln LN67 7TS, England; [Tzimiropoulos, Georgios; Zafeiriou, Stefanos; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Pantic, Maja] Univ Twente, Dept Comp Sci, NL-7522 NB Enschede, Netherlands	University of Lincoln; Imperial College London; University of Twente	Tzimiropoulos, G (corresponding author), Lincoln Univ, Sch Comp Sci, Lincoln LN67 7TS, England.	gtzimiropoulos@lincoln.ac.uk; s.zafeiriou@imperial.ac.uk; m.pantic@imperial.ac.uk		Tzimiropoulos, Georgios/0000-0002-1803-5338	European Research Council under the ERC [ERC-2007-StG-203143]; European Community [288235]; Imperial College London	European Research Council under the ERC(European Research Council (ERC)); European Community(European Commission); Imperial College London(General Electric)	The research presented in this paper has been funded by the European Research Council under the ERC Starting Grant agreement no. ERC-2007-StG-203143 (MAHNOB). The work by G. Tzimiropoulos is currently supported in part by the European Community's Seventh Framework Programme [FP7/2007-2013] under grant agreement no. 288235 (FROG). The work of S. Zafeiriou was funded in part by the Junior Research Fellowship of Imperial College London.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Balasubramanian M, 2002, SCIENCE, V295; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Campbell N. A., 1980, Applied Statistics, V29, P231, DOI 10.2307/2346896; Candes E.J., 2009, ARXIV09123599; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Cevikalp H, 2006, IEEE T NEURAL NETWOR, V17, P1550, DOI 10.1109/TNN.2006.881485; Chandrasekaran V., 2009, RAPID POST; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Croux C, 2000, BIOMETRIKA, V87, P603, DOI 10.1093/biomet/87.3.603; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8; Fitch A. J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P133; Frey HP, 2007, PERCEPT PSYCHOPHYS, V69, P153, DOI 10.3758/BF03193738; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goudelis G, 2007, IEEE T INF FOREN SEC, V2, P570, DOI 10.1109/TIFS.2007.902915; He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949; He XF, 2005, IEEE I CONF COMP VIS, P1208; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jia H., 2008, P C AUT FAC GEST REC; Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708; Ke Q., 2005, P IEEE C COMP VIS PA, V1; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90; Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927; Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Martinez A., 1998, AR FACE DATABASE CVC; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Papoulis A, 2004, PROBABILITY RANDOM V; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Ros A, 1995, INDIANA U MATH J, V44, P841; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Tzimiropoulos, 2011, P IEEE INT C AUT FAC, P553, DOI [10.1109/FG.2011.5771457, DOI 10.1109/FG.2011.5771457]; Tzimiropoulos G, 2010, IEEE T PATTERN ANAL, V32, P1899, DOI 10.1109/TPAMI.2010.107; Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan SC, 2010, IEEE T IMAGE PROCESS, V19, P1087, DOI 10.1109/TIP.2009.2038765; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	56	112	124	0	49	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2454	2466		10.1109/TPAMI.2012.40	http://dx.doi.org/10.1109/TPAMI.2012.40			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22271825	Green Accepted, Green Published			2022-12-18	WOS:000309913700013
J	Cao, X; Du, H; Tong, X; Dai, QH; Lin, S				Cao, Xun; Du, Hao; Tong, Xin; Dai, Qionghai; Lin, Stephen			A Prism-Mask System for Multispectral Video Acquisition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multispectral imaging; multispectral video; prism; occlusion mask	TOMOGRAPHY IMAGING SPECTROMETER; SPECTROSCOPY	This paper presents a prism-mask system for capturing multispectral videos. The system is composed of a triangular prism, a monochrome camera, and an occlusion mask. Incoming light beams from the scene are sampled by the occlusion mask, dispersed into their constituent spectra by the triangular prism, and then captured by the monochrome camera. Our system is capable of capturing frames with high spectral resolution at video rates. It also allows for different trade-offs between spectral and spatial resolution by adjusting the focal length of the camera. We demonstrate multispectral video acquisition with various spectral resolutions and spatial resolutions, as well as different frame rates. The effectiveness of our system is further evaluated with several applications, including human skin detection, physical material recognition, video segmentation, RGB video generation, and illumination identification.	[Cao, Xun; Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Du, Hao] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Tong, Xin; Lin, Stephen] Microsoft Res Asia, Internet Graph Grp, Beijing Sigma Ctr, Beijing 100190, Peoples R China	Tsinghua University; University of Washington; University of Washington Seattle; Microsoft; Microsoft Research Asia	Cao, X (corresponding author), Tsinghua Univ, Dept Automat, Cent Main Bldg, Beijing 100084, Peoples R China.	xuncao@gmail.com; duhao@cs.washington.edu; xtong@microsoft.com; qhdai@tsinghua.edu.cn; stevelin@microsoft.com	Dai, Qionghai/ABD-5298-2021	Dai, Qionghai/0000-0001-7043-3061	National Basic Research Project [2010CB731800]; NSFC [61120106003]	National Basic Research Project(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC))	The authors thank Moshe Ben-Ezra for helpful discussionsi on implementation issues, Yue Xu and Tao Yue for assistance in experimentation, and the reviewers for their constructive comments. The authors also would like to thank the National Basic Research Project (No. 2010CB731800) and the NSFC project (No. 61120106003). This work was done while X. Cao and H. Du were visiting students at Microsoft Research Asia, Beijing, P.R. China.	Allington-Smith J., 1998, P C SPIE, V3355; Angelopoulou E, 2001, PROC SPIE, V4299, P243, DOI 10.1117/12.429495; Brady D.J., 2006, P C SPIE, V6246; Content R., 1998, P C SPIE, V3356; DESCOUR M, 1995, APPL OPTICS, V34, P4817, DOI 10.1364/AO.34.004817; Descour MR, 1997, APPL OPTICS, V36, P3694, DOI 10.1364/AO.36.003694; Du H, 2009, IEEE I CONF COMP VIS, P175, DOI 10.1109/ICCV.2009.5459162; Finlayson G.D., 2004, P 2 COMP GRAPH IM VI; Fletcher-Holmes DW, 2005, J OPT A-PURE APPL OP, V7, pS298, DOI 10.1088/1464-4258/7/6/007; Gat N., 2000, P SPIE C WAVELET APP, V4056; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Gehm ME, 2006, APPL OPTICS, V45, P2965, DOI 10.1364/AO.45.002965; GOLAY MJE, 1949, J OPT SOC AM, V39, P437, DOI 10.1364/JOSA.39.000437; Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9; Hagen N.A., 2006, P C SPIE, V6302; Hagen N, 2008, APPL OPTICS, V47, pF85, DOI 10.1364/AO.47.000F85; Hanley QS, 2000, J MICROSC-OXFORD, V197, P5, DOI 10.1046/j.1365-2818.2000.00665.x; Harvey AR, 2005, P SOC PHOTO-OPT INS, V5694, P110, DOI 10.1117/12.604609; HERRALA E, 1994, PROC SPIE, P33, DOI 10.1117/12.194344; James J.F., 2007, SPECTROGRAPH DESIGN; Johnson WR, 2006, APPL OPTICS, V45, P1898, DOI 10.1364/AO.45.001898; Kidono K., 2007, P IEEE INT VEH S; Li ZY, 2005, P SOC PHOTO-OPT INS, V5694, P33, DOI 10.1117/12.611350; Liu WH, 2004, APPL OPTICS, V43, P3581, DOI 10.1364/AO.43.003581; MENDE SB, 1993, APPL OPTICS, V32, P7095, DOI 10.1364/AO.32.007095; Mohan A, 2008, COMPUT GRAPH FORUM, V27, P709, DOI 10.1111/j.1467-8659.2008.01169.x; Mooney JM, 1997, J OPT SOC AM A, V14, P2951, DOI 10.1364/JOSAA.14.002951; MORRIS HR, 1994, APPL SPECTROSC, V48, P857, DOI 10.1366/0003702944029820; Morris N.J.W., 2007, P 2007 IEEE C COMPUT, DOI [10.1109/CVPR.2007.383003, DOI 10.1109/CVPR.2007.383003]; OKAMOTO T, 1993, APPL SPECTROSC, V47, P1198, DOI 10.1366/0003702934067810; Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872; Photo Research, 1999, P C PHOT RES; ROSEN M, 1999, P INT S MULT IM COL, P117; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Schroeder D. J., 1987, ASTRONOMICAL OPTICS; Vandervlugt C., 2007, P C SPIE, V6565; Volin C., 2000, MWIR SPECTROMETER OP; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wagadarikar AA, 2009, OPT EXPRESS, V17, P6368, DOI 10.1364/OE.17.006368; Yamaguchi M., 2006, P C SPIE IS T ELECT, V6062	40	112	124	2	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2423	2435		10.1109/TPAMI.2011.80	http://dx.doi.org/10.1109/TPAMI.2011.80			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21519097				2022-12-18	WOS:000295980000009
J	Cousty, J; Bertrand, G; Najman, L; Couprie, M				Cousty, Jean; Bertrand, Gilles; Najman, Laurent; Couprie, Michel			Watershed Cuts: Thinnings, Shortest Path Forests, and Topological Watersheds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Watershed; thinning; minimum spanning forest; shortest path forest; connection value; image segmentation	RELATIVE FUZZY CONNECTEDNESS; MERGING PROPERTIES; OBJECT DEFINITION; FUSION GRAPHS; ALGORITHMS; CONNECTIVITY	We recently introduced watershed cuts, a notion of watershed in edge-weighted graphs. In this paper, our main contribution is a thinning paradigm from which we derive three algorithmic watershed cut strategies: The first one is well suited to parallel implementations, the second one leads to a flexible linear-time sequential implementation, whereas the third one links the watershed cuts and the popular flooding algorithms. We state that watershed cuts preserve a notion of contrast, called connection value, on which several morphological region merging methods are (implicitly) based. We also establish the links and differences between watershed cuts, minimum spanning forests, shortest path forests, and topological watersheds. Finally, we present illustrations of the proposed framework to the segmentation of artwork surfaces and diffusion tensor images.	[Cousty, Jean; Bertrand, Gilles; Najman, Laurent; Couprie, Michel] Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE Paris, F-93162 Noisy Le Grand, France; [Cousty, Jean] ESIEE, INRIA Sophia Antipolis ASCLEPIOS Team, F-93162 Noisy Le Grand, France; [Najman, Laurent] Ecole Super Ingenieurs Electrotech & Elect, Dept Informat, Paris, France	Universite Gustave-Eiffel; ESIEE Paris; Universite Gustave-Eiffel; ESIEE Paris	Cousty, J (corresponding author), Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE Paris, F-93162 Noisy Le Grand, France.	j.cousty@esiee.fr; g.bertrand@esiee.fr; l.najman@esiee.fr; m.couprie@esiee.fr	Najman, Laurent/AAB-4212-2020	Najman, Laurent/0000-0002-6190-0235				ALCOVERRO M, 2008, P 2 3DTV CON C, P393; Allene, 2007, MATH MORPHOLOGY ITS, V1, P253; [Anonymous], 1997, GRAPH THEORY; Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; AUDIGIER R, 2007, P 8 INT S MATH MORPH, P277; Audigier R, 2007, J MATH IMAGING VIS, V27, P157, DOI 10.1007/s10851-007-0780-4; Audigier R, 2006, SIBGRAPI, P53; BASSER PJ, 1994, BIOPHYS J, V66, P259, DOI 10.1016/S0006-3495(94)80775-1; Berge C., 1973, GRAPHS HYPERGRAPHS; Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5; Bertrand G, 2007, IMAGE VISION COMPUT, V25, P447, DOI 10.1016/j.imavis.2006.04.017; Beucher S, 1994, COMP IMAG VIS, V2, P69; Beucher S., 1979, INT WORK IMAGE PROCE; BEUCHER S, 1993, MATH MORPHOLOGY IMAG, P443; Bieniek A, 1998, COMP IMAG VIS, V12, P215; Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CIESIELSKI KC, 2007, P SPIE MED IM; Cormen Thomas H, 2001, INTRO ALGORITHMS; Couprie M, 2005, J MATH IMAGING VIS, V22, P231, DOI 10.1007/s10851-005-4892-4; Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778; Cousty J, 2008, J MATH IMAGING VIS, V30, P87, DOI 10.1007/s10851-007-0047-0; COUSTY J, WATERSHEDS STA UNPUB; COUSTY J, 2009, J MATH IMAG IN PRESS; Cousty J, 2008, DISCRETE APPL MATH, V156, P3011, DOI 10.1016/j.dam.2008.01.005; Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173; Englert R, 2000, LECT NOTES COMPUT SC, V1779, P297; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; MEIJSTER A, 1998, P EUR SIGN PROC C, P1669; MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4; Meyer F, 1996, COMPUT IMAGING VIS, P329; Meyer F, 1994, COMP IMAG VIS, V2, P77; MEYER F, 1991, P 8 C AFCET LYON VIL, P847; MOGA AN, 1995, P IEEE WORKSH NONL S; Najman L, 2005, DISCRETE APPL MATH, V147, P301, DOI 10.1016/j.dam.2004.09.017; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; NAJMAN L, 1993, SIGNAL PROCESS, V38, P68; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; ROSENFELD A, 1983, PATTERN RECOGN, V16, P47, DOI 10.1016/0031-3203(83)90007-9; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Serra J, 2006, J MATH IMAGING VIS, V24, P83, DOI 10.1007/s10851-005-3616-0; SERRA J, 1992, CIRC SYST SIGNAL PR, V11, P47, DOI 10.1007/BF01189221; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sinop AK, 2007, IEEE I CONF COMP VIS, P778; Soille P., 1999, MORPHOLOGICAL IMAGE; Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; Thorup M, 1996, PROCEEDINGS OF THE SEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P59; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	54	112	116	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					925	939		10.1109/TPAMI.2009.71	http://dx.doi.org/10.1109/TPAMI.2009.71			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299715	Green Submitted			2022-12-18	WOS:000275569300012
J	Park, M; Brocklehurst, K; Collins, RT; Liu, YX				Park, Minwoo; Brocklehurst, Kyle; Collins, Robert T.; Liu, Yanxi			Deformed Lattice Detection in Real-World Images Using Mean-Shift Belief Propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Belief propagation; MRF; mean shift; lattice detection; wallpaper patterns	MODEL	We propose a novel and robust computational framework for automatic detection of deformed 2D wallpaper patterns in real-world images. The theory of 2D crystallographic groups provides a sound and natural correspondence between the underlying lattice of a deformed wallpaper pattern and a degree-4 graphical model. We start the discovery process with unsupervised clustering of interest points and voting for consistent lattice unit proposals. The proposed lattice basis vectors and pattern element contribute to the pairwise compatibility and joint compatibility (observation model) functions in a Markov Random Field (MRF). Thus, we formulate the 2D lattice detection as a spatial, multitarget tracking problem, solved within an MRF framework using a novel and efficient Mean-Shift Belief Propagation (MSBP) method. Iterative detection and growth of the deformed lattice are interleaved with regularized thin-plate spline (TPS) warping, which rectifies the current deformed lattice into a regular one to ensure stability of the MRF model in the next round of lattice recovery. We provide quantitative comparisons of our proposed method with existing algorithms on a diverse set of 261 real-world photos to demonstrate significant advances in accuracy and speed over the state of the art in automatic discovery of regularity in real images.	[Park, Minwoo; Brocklehurst, Kyle; Collins, Robert T.; Liu, Yanxi] Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Park, M (corresponding author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.	mipark@cse.psu.edu; kpb136@psu.edu; rcollins@cse.psu.edu; yanxi@cse.psu.edu		Park, Minwoo/0000-0002-9117-2128	US National Science Foundation (NSF) [IIS-0535324]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This work was partially funded under US National Science Foundation (NSF) grant IIS-0535324 and a gift grant to Dr. Liu from Northrop Grumman Corporation. The authors thank F. Dellaert for the urban image set and J. Hays for his lattice detection code (ECCV '06).	CANADA KCJ, 2008, P IEEE INT C IM PROC; Chastain E, 2007, NEUROCOMPUTING, V70, P1723, DOI 10.1016/j.neucom.2006.10.050; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COUGHLAN J, 2004, P IEEE COMP SOC C CO, P180; Coxeter H.S.M., 1980, INTRO GEOMETRY, VSecond; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; FORSYTH D, 2002, P 7 EUR C COMP VIS, P43; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FROST R, 2009, SIMULATED ANNEALING; Ghanem B, 2007, IEEE I CONF COMP VIS, P2081; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; Gr?nbaum B., 1987, TILINGS PATTERNS; HAN T, 2006, P IEEE C COMP VIS PA, V1, P214; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; Isard M, 2003, PROC CVPR IEEE, P613; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; LIN WC, 2006, P IEEE C COMP VIS PA, P427; Lin WC, 2007, IEEE T PATTERN ANAL, V29, P777, DOI 10.1109/TPAMI.2007.1053; Lin Y, 2006, ANN SURG ONCOL, V13, P44; Liu SX, 2005, ORAL ONCOL, V1, P145, DOI 10.1016/S1744-7895(05)80367-0; Liu Y, 2008, EL PACKAG TECH CONF, P1, DOI [10.1109/PLASMA.2008.4590846, 10.1109/EPTC.2008.4763404]; Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346; Park M., 2008, P 10 EUR C COMP VIS; Parkinson JF, 2008, J CLIN NEUROSCI, V15, P1, DOI 10.1016/j.jocn.2007.06.005; RAMANAN D, 2003, CVPR, V2, P467; Salamon P., 2002, FACTS CONJECTURES IM; Schindler G, 2008, PROC CVPR IEEE, P77; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SIGAL L, 2005, PAMPAS NONPARAMETRIC; Sudderth EB, 2003, PROC CVPR IEEE, P605; Tsin YH, 2001, PROC CVPR IEEE, P539; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Weiss Y, 2001, NEURAL COMPUT, V13, P2173, DOI 10.1162/089976601750541769	35	112	117	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1804	1816		10.1109/TPAMI.2009.73	http://dx.doi.org/10.1109/TPAMI.2009.73			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696451	Green Submitted			2022-12-18	WOS:000268996500007
J	Han, B; Comaniciu, D; Zhu, Y; Davis, LS				Han, Bohyung; Comaniciu, Dorin; Zhu, Ying; Davis, Larry S.			Sequential kernel density approximation and its application to real-time visual tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel density approximation; mean shift; mode propagation; online target appearance modeling; object tracking; real-time computer vision		Visual features are commonly modeled with probability density functions in computer vision problems, but current methods such as a mixture of Gaussians and kernel density estimation suffer from either the lack of flexibility by fixing or limiting the number of Gaussian components in the mixture or large memory requirement by maintaining a nonparametric representation of the density. These problems are aggravated in real-time computer vision applications since density functions are required to be updated as new data becomes available. We present a novel kernel density approximation technique based on the mean-shift mode finding algorithm and describe an efficient method to sequentially propagate the density modes over time. Although the proposed density representation is memory efficient, which is typical for mixture densities, it inherits the flexibility of nonparametric methods by allowing the number of components to be variable. The accuracy and compactness of the sequential kernel density approximation technique is illustrated by both simulations and experiments. Sequential kernel density approximation is applied to online target appearance modeling for visual tracking, and its performance is demonstrated on a variety of videos.	[Han, Bohyung] Mobileye Vis Technol, Adv Project Ctr, Princeton, NJ 08542 USA; [Comaniciu, Dorin] Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA; [Zhu, Ying] Siemens Corp Res, Real Time Vis & Modeling Dept, Princeton, NJ 08540 USA; [Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Siemens AG; Siemens AG; University System of Maryland; University of Maryland College Park	Han, B (corresponding author), Mobileye Vis Technol, Adv Project Ctr, Princeton, NJ 08542 USA.	bhhan@cs.umd.edu; Dorin.Comaniciu@siemens.com; yingzhu@scr.siemens.com; lsd@cs.umd.edu	Elhamod, Mohannad/A-1904-2012	Comaniciu, Dorin/0000-0002-5238-8647				ABRAMSON IS, 1982, ANN STAT, V10, P1217, DOI 10.1214/aos/1176345986; CHAM TJ, 1999, P COMP VIS PATT REC, V2, P239; Cleveland W.S., 1996, P STAT THEORY COMPUT, P10; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Elgammal A., 2003, P IEEE C COMP VIS PA; Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292; FREY B, 2000, P IEEE C COMP VIS PA, V1, P185; Han B., 2004, P AS C COMP VIS; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8; Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; PRIEBE CE, 1993, PATTERN RECOGN, V26, P771, DOI 10.1016/0031-3203(93)90130-O; ROSS D, 2004, P 8 EUR C COMP VIS, V2, P470; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	33	112	131	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1186	1197		10.1109/TPAMI.2007.70771	http://dx.doi.org/10.1109/TPAMI.2007.70771			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550902				2022-12-18	WOS:000256294100006
J	Sato, I; Sato, Y; Ikeuchi, K				Sato, I; Sato, Y; Ikeuchi, K			Illumination from shadows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; physics-based vision; illumination distribution estimation	REFLECTION; SHAPE; PARAMETERS	In this paper, we introduce a method for recovering an illumination distribution of a scene from image brightness inside shadows cast by an object of known shape in the scene. In a natural illumination condition, a scene includes both direct and indirect illumination distributed in a complex way, and it is often difficult to recover an illumination distribution from image brightness observed on an object surface. The main reason for this difficulty is that there is usually not adequate variation in the image brightness observed on the object surface to reflect the subtle characteristics of the entire illumination. In this study, we demonstrate the effectiveness of using occluding information of incoming light in estimating an illumination distribution of a scene. Shadows in a real scene are caused by the occlusion of incoming light and, thus, analyzing the relationships between the image brightness and the occlusions of incoming light enables us to reliably estimate an illumination distribution of a scene even in a complex illumination environment. This study further concerns the following two issues that need to be addressed. First, the method combines the illumination analysis with an estimation of the reflectance properties of a shadow surface. This makes the method applicable to the case where reflectance properties of a surface are not known a priori and enlarges the variety of images applicable to the method. Second, we introduce an adaptive sampling framework for efficient estimation of illumination distribution. Using this framework, we are able to avoid a unnecessarily dense sampling of the illumination and can estimate the entire illumination distribution more efficiently with a smaller number of sampling directions of the illumination distribution. To demonstrate the effectiveness of the proposed method, we have successfully tested the proposed method by using sets of real images taken in natural illumination conditions with different surface materials of shadow regions.	Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Bunkyo Ku, Tokyo 1130033, Japan; Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan	University of Tokyo; University of Tokyo	Sato, I (corresponding author), Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.	imarik@iis.u-tokyo.ac.jp; ysato@iis.u-tokyo.ac.jp; ki@iis.u-tokyo.ac.jp						BARIBEAU R, 1992, IEEE T PATTERN ANAL, V14, P263, DOI 10.1109/34.121793; Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651; BOURGUET J, 1998, P IEEE INT C COMP VI, P43; COHEN MF, 1986, IEEE COMPUT GRAPH, V6, P26, DOI 10.1109/MCG.1986.276629; FORSYTH DA, 2002, COMPUTER VISION MODE, P70; Fournier A., 1993, Proceedings Graphics Interface '93, P254; HEALEY GE, 1992, PHYSICS BASED VISION; Horn B., 1986, ROBOT VISION, P1; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Ikeuchi K., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P12, DOI 10.1109/ICCV.1990.139483; Kawai J. K., 1993, Computer Graphics Proceedings, P147, DOI 10.1145/166117.166136; Kay G, 1995, GRAPH MODEL IM PROC, V57, P365, DOI 10.1006/gmip.1995.1032; Kender J. R., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P539; Kim T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P329, DOI 10.1109/ICCV.2001.937644; LU JP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P80; MACKWORTH AK, 1974, THESIS U SUSSEX; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; MOON P, 1981, PHOTIC FIELD; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; Nishino K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P599, DOI 10.1109/ICCV.2001.937573; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; Press WH, 1988, NUMERICAL RECIPES C; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Sato I, 1999, IEEE T VIS COMPUT GR, V5, P1, DOI 10.1109/2945.764865; Sato I., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P306, DOI 10.1109/CVPR.1999.786956; Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314; SATO Y, 1997, P SIGGRAPH 97, P379; Schoeneman C., 1993, Computer Graphics Proceedings, P143, DOI 10.1145/166117.166135; SHAFER SA, 1983, COMPUT VISION GRAPH, V22, P145, DOI 10.1016/0734-189X(83)90099-3; Tominaga S, 2000, IEEE COMPUT GRAPH, V20, P58, DOI 10.1109/38.865881; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Yu YZ, 1999, COMP GRAPH, P215; ZANG Y, 2000, P IEEE C COMP VIS PA, P269	36	112	121	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					290	300		10.1109/TPAMI.2003.1182093	http://dx.doi.org/10.1109/TPAMI.2003.1182093			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL		Green Submitted			2022-12-18	WOS:000181071300002
J	Bloch, I				Bloch, I			Fuzzy relative position between objects in image processing: A morphological approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fuzzy sets; spatial relative position; directional relations; fuzzy mathematical morphology; structural shape recognition	RECOGNITION	In order to cope with the ambiguity of spatial relative position concepts, we propose a new definition of the relative position between two objects in a fuzzy set framework. This definition is based on a morphological and fuzzy pattern-matching approach, and consists of comparing an object to a fuzzy landscape representing the degree of satisfaction of a directional relationship to a reference object. It has good formal properties, it is flexible, it fits the intuition, and it can be used for structural pattern recognition under imprecision. Moreover, it also applies in 3D and for fuzzy objects issued from images.	CNRS, URA 822, Ecole Natl Super Telecommun, Dept TSI, F-75634 Paris 13, France	Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; UDICE-French Research Universities; Universite Paris Cite	Bloch, I (corresponding author), CNRS, URA 822, Ecole Natl Super Telecommun, Dept TSI, 46 Rue Barrault, F-75634 Paris 13, France.							BLOCH I, 1995, PATTERN RECOGN, V28, P1341, DOI 10.1016/0031-3203(94)00312-A; Bloch I, 1996, P SOC PHOTO-OPT INS, V2955, P141, DOI 10.1117/12.262882; BLOCH I, 1997, 97D0032 ENST; BLOCH I, 1996, P WORLD AUT C SOFT C, P79; BLOCH I, 1996, P IEEE INT C IMAGE P, V2, P987; DUBOIS D, 1988, FUZZY SET SYST, V28, P313, DOI 10.1016/0165-0114(88)90038-3; DUBOIS D, 1985, INFORM SCIENCES, V36, P85, DOI 10.1016/0020-0255(85)90027-1; Dutta S., 1991, International Journal of Approximate Reasoning, V5, P307, DOI 10.1016/0888-613X(91)90015-E; Keller J. M., 1995, Proceedings of ISUMA - NAFIPS '95 The Third International Symposium on Uncertainty Modeling and Analysis and Annual Conference of the North American Fuzzy Information Processing Society (Cat. No.95TB8082), P679, DOI 10.1109/ISUMA.1995.527776; KOCZY LT, 1988, PATTERN RECOGN LETT, V8, P21, DOI 10.1016/0167-8655(88)90019-0; Krishnapuram R., 1992, IEEE International Conference on Fuzzy Systems (Cat. No.92CH3073-4), P135, DOI 10.1109/FUZZY.1992.258608; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P222, DOI 10.1109/91.236554; Ma^itre H., 1996, PROGR PICTURE PROCES, P46; MATSAKIS P, IN PRESS IEEE T PATT; MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3	15	112	114	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					657	664		10.1109/34.777378	http://dx.doi.org/10.1109/34.777378			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT					2022-12-18	WOS:000081472600010
J	Tieng, QM; Boles, WW				Tieng, QM; Boles, WW			Recognition of 2D object contours using the wavelet transform zero-crossing representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						zero-crossings; wavelet transform; object recognition; object contours; linear transformation invariance	SHAPES	A new algorithm to recognize a two-dimensional object of arbitrary shape is presented. The object boundary is first represented by a one-dimensional signal. This signal is then used to build the wavelet transform zero-crossing representation of the object. The algorithm is invariant to translation, rotation and scaling. Experimental results show that, compared with the use of Fourier descriptors, our algorithm gives more stable and accurate results.			Tieng, QM (corresponding author), QUEENSLAND UNIV TECHNOL,SCH ELECT ELECT & SYST ENGN,SIGNAL PROC RES CTR,BRISBANE,QLD 4001,AUSTRALIA.		Boles, Wageeh W/I-9633-2012; Tieng, Quang/A-8479-2011; Rohlf, F J/A-8710-2008	Boles, Wageeh W/0000-0002-5093-2952; 				CHEN BD, 1987, IEEE T PATTERN ANAL, V9, P438, DOI 10.1109/TPAMI.1987.4767925; CHETVERIKOV D, 1992, PATTERN RECOGN LETT, V13, P669, DOI 10.1016/0167-8655(92)90123-H; DOBKIN DP, 1990, ACM T GRAPHIC, V9, P389, DOI 10.1145/88560.88575; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; FLECK MM, 1992, IEEE T PATTERN ANAL, V14, P337, DOI 10.1109/34.120328; HAIG TD, 1992, IEE PROC-I, V139, P206, DOI 10.1049/ip-i-2.1992.0029; JAWERTH B, OVERVIEW WAVELET BAS; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; MALLAT S, 1991, IEEE T INFORM THEORY, V37, P1019, DOI 10.1109/18.86995; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	12	112	120	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					910	916						7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700010
J	HARTLEY, RI				HARTLEY, RI			PROJECTIVE RECONSTRUCTION AND INVARIANTS FROM MULTIPLE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						FUNDAMENTAL MATRIX; PROJECTIVE RECONSTRUCTION; INVARIANTS; STRUCTURE FROM MOTION		This correspondence investigates projective reconstruction of geometric configurations seen in two or more perspective views, and the computation of projective invariants of these configurations from their images. A basic tool in this investigation is the fundamental matrix that describes the epipolar correspondence between image pairs. It is proven that once the epipolar geometry is known, the configurations of many geometric structures (for instance sets of points or lines) are determined up to a collineation of projective 3-space rho3 by their projection in two independent images. This theorem is the key to a method for the computation of invariants of the geometry. Invariants of six points in rho3 and of four lines in rho3 are defined and discussed. An example with real images shows that they are effective in distinguishing different geometrical configurations. Since the fundamental matrix is a basic tool in the computation of these invariants, new methods of computing the fundamental matrix from seven-point correspondences in two images or six-point correspondences in three images are given.			HARTLEY, RI (corresponding author), GE CO, CORP RES & DEV, SCHENECTADY, NY 12301 USA.			Hartley, Richard/0000-0002-5005-0191				ATKINSON K. E, 1989, INTRO NUMERICAL ANAL; BURNS JB, 1992, ARTIF INT, P120; COELHO C, 1992, ARTIF INT, P87; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; HARTLEY R, 1993, P DARPA IM UND WORKS, P737; HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MAYBANK SJ, 1990, PHILOS T ROY SOC A, V332, P1, DOI 10.1098/rsta.1990.0099; Mundy J., 1992, GEOMETRIC INVARIANCE; PONCE J, 1993, UIUCBIAIRCV9307 U IL; Press WH, 1988, NUMERICAL RECIPES C; QUAN L, 1994, COMPUTER VISION ECCV, V2, P459; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Sturm R., 1869, MATH ANN, V1, P533; ZISSERMAN A, 1992, ARTIF INT, P228	16	112	132	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					1036	1041		10.1109/34.329005	http://dx.doi.org/10.1109/34.329005			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700008
J	ROTH, G; LEVINE, MD				ROTH, G; LEVINE, MD			GEOMETRIC PRIMITIVE EXTRACTION USING A GENETIC ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						GENETIC ALGORITHMS; GEOMETRIC PRIMITIVE EXTRACTION; HOUGH TRANSFORM; TEMPLATE MATCHING; MINIMAL SUBSET	HOUGH TRANSFORM	Extracting geometric primitives from geometric sensor data is an important problem in model-based vision. A minimal subset is the smallest number of points necessary to define a unique instance of a geometric primitive. A genetic algorithm based on a minimal subset representation is used to perform primitive extraction. It is shown that the genetic approach is an improvement over random search and is capable of extracting more complex primitives than the Hough transform.	MCGILL UNIV,CTR INTELLIGENT MACHINES,MONTREAL H3A 2A7,QUEBEC,CANADA	McGill University	ROTH, G (corresponding author), NATL RES COUNCIL CANADA,INST INFORMAT TECHNOL,OTTAWA K1A 0R6,ONTARIO,CANADA.							BHANU B, 1991, 4TH P INT C GEN ALG, P362; BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; CALIFANO A, 1992, IEEE T PATTERN ANAL, V14, P1157, DOI 10.1109/34.177381; Fogel D., 1991, SYSTEM IDENTIFICATIO; Goldberg D., 1988, GENETIC ALGORITHMS S; HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5; HOLLAND J, 1975, ADAPTATION NATURAL A; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KENDER JR, 1991, 12TH INT JOINT C ART, P1271; KIM DY, 1989, DARPA IMAGE UNDERSTA, P1117; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; KULTANEN P, 1990, 10TH P ICPR, P631; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; ROSENFELD A, 1988, COMPUT VISION GRAPH, V41, P293, DOI 10.1016/0734-189X(88)90104-1; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; ROTH G, 1991, 4TH P INT C GEN ALG, P487; ROTH G, 1990, 10TH INT C PATT REC, P826; ROTH G, 1992, MCRICMTRCIM9214 MCG; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; SPEARS WM, 1991, 3RD P INT C GEN ALG, P230; Syswerda G., 1991, FDN GENETIC ALGORITH, V1, P94	22	112	122	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					901	905		10.1109/34.310686	http://dx.doi.org/10.1109/34.310686			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200006
J	GELFAND, SB; RAVISHANKAR, CS; DELP, EJ				GELFAND, SB; RAVISHANKAR, CS; DELP, EJ			AN ITERATIVE GROWING AND PRUNING ALGORITHM FOR CLASSIFICATION TREE DESIGN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CLASSIFICATION TREE; ERROR RATE ESTIMATION; GRAPH THEORY (TREES); PATTERN RECOGNITION; TREE GROWING; TREE PRUNING	PATTERN-RECOGNITION PROBLEMS; DECISION TREE; BINARY-TREE; BLOOD-CELLS; CLASSIFIERS	A critical issue in classification tree design is obtaining right-sized trees, i.e., trees which neither underfit nor overfit the data. Instead of using stopping rules to halt partitioning, we follow the approach of growing a large tree with pure terminal nodes and selectively pruning it back. A new efficient iterative method is proposed to grow and prune classification trees. This method divides the data sample into two subsets and iteratively grows a tree with one subset and prunes it with the other subset, successively interchanging the roles of the two subsets. The convergence and other properties of the algorithm are established. Theoretical and practical considerations suggest that the iterative tree growing and pruning algorithm should perform better and require less computation than other widely used tree growing and pruning algorithms. Numerical results on a waveform recognition problem are presented to support this view.			GELFAND, SB (corresponding author), PURDUE UNIV, SCH ELECT ENGN, COMP VIS & IMAGE PROC LAB, W LAFAYETTE, IN 47907 USA.		Delp, Edward J/C-3616-2013; Sankaranarayanan, Ravishankar/O-6960-2016	Delp, Edward J/0000-0002-2909-7323; Sankaranarayanan, Ravishankar/0000-0003-0634-4835				ANDERSON AC, 1979, TREE7931 PURD U TECH; ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51, DOI 10.1109/TPAMI.1982.4767195; ATLAS L, 1989, P IEEE C SYSTEMS MAN, P915; BARTOLUCCI LA, 1976, IEEE T GEOSCI REMOTE, V14, P101, DOI 10.1109/TGE.1976.294417; CASEY RG, 1984, IEEE T INFORM THEORY, V30, P93, DOI 10.1109/TIT.1984.1056834; CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124; DATTATREYA GR, 1980, 5TH P INT C PATT REC, P1212; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404, DOI 10.1109/TC.1977.1674849; GOODMAN RM, 1988, IEEE T INFORM THEORY, V34, P979, DOI 10.1109/18.21221; GU YX, 1983, IEEE T PATTERN ANAL, V5, P83, DOI 10.1109/TPAMI.1983.4767349; GUSTAFSON DE, 1980, 5TH P INT C PATT REC, P654; HENRICHON EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; KULKARNI AV, 1978, IEEE T COMPUT, V27, P771, DOI 10.1109/TC.1978.1675190; KULKARNI AV, 1978, 4TH P INT JOINT C PA, P238; Kurzynski MW, 1983, PATTERN RECOGN LETT, V1, P305, DOI 10.1016/0167-8655(83)90068-5; KURZYNSKI MW, 1983, PATTERN RECOGN, V16, P81, DOI 10.1016/0031-3203(83)90011-0; LANDEWEERD GH, 1983, PATTERN RECOGN, V16, P571, DOI 10.1016/0031-3203(83)90073-0; LIN YK, 1983, PATTERN RECOGN, V16, P69, DOI 10.1016/0031-3203(83)90010-9; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429, DOI 10.1109/TPAMI.1980.6592364; Olshen R., 1984, CLASSIFICATION REGRE; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905, DOI 10.1109/TC.1977.1674938; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; SETHI IK, 1977, PATTERN RECOGN, V9, P197, DOI 10.1016/0031-3203(77)90004-8; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441, DOI 10.1109/TPAMI.1982.4767278; SHI QY, 1983, PATTERN RECOGN, V16, P593, DOI 10.1016/0031-3203(83)90076-6; SHI QY, 1981, AUG P IEEE C IM PROC, P21; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101, DOI 10.1109/TPAMI.1980.4766988; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972; TAYLOR J, 1978, ACTA CYTOL, V22, P29; WANG QR, 1987, IEEE T PATTERN ANAL, V9, P91, DOI 10.1109/TPAMI.1987.4767874; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546; [No title captured]	33	112	115	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					163	174		10.1109/34.67645	http://dx.doi.org/10.1109/34.67645			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900005
J	SCHAEFFER, J				SCHAEFFER, J			THE HISTORY HEURISTIC AND ALPHA-BETA SEARCH ENHANCEMENTS IN PRACTICE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SCHAEFFER, J (corresponding author), UNIV ALBERTA,DEPT COMP SCI,EDMONTON T6G 2H1,ALBERTA,CANADA.							ADELSONVELSKIY GM, 1975, ARTIF INTELL, V6, P361, DOI 10.1016/0004-3702(75)90021-1; AKL SG, 1977, ACM ANN C, P466; ANANTHARAMAN T, IN PRESS P AAAI SPRI; BAUDET GM, 1978, THESIS CARNEGIE MELL; Beal D.F., 1989, ADV COMPUTER CHESS, V5, P65; CAMPBELL MS, 1983, ARTIF INTELL, V20, P347, DOI 10.1016/0004-3702(83)90001-2; EBELING C, 1989, J PARALLEL DISTRIBUT, P90; FINKEL RA, 1980, P INT C PARALLEL PRO, P235; GILLOGLY JJ, 1978, THESIS CARNEGIE MELL; GOETSCH G, 1988, P AAAI SPRINT S, P14; GREENBLATT RD, 1967, FAL P AFIPS JOINT CO, V31, P801; HYATT RM, 1983, THESIS U SO MISSISSI; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; KOPEC D, 1982, ADV COMPUTER CHESS, V3, P57; MARSLAND TA, 1987, ARTIF INTELL, V31, P185, DOI 10.1016/0004-3702(87)90019-1; MARSLAND TA, 1986, ICCA J, V9, P3; MARSLAND TA, 1983, P 8 INT JOINT C ART, P763; MARSLAND TA, 1985, ADV COMPUTER CHESS, V4, P37; MCALLESTER DA, 1988, ARTIF INTELL, V35, P287, DOI 10.1016/0004-3702(88)90019-7; MUSZYCKA A, 1985, IEEE T SYST MAN CYB, V15, P389, DOI 10.1109/TSMC.1985.6313374; NAU DS, 1979, THESIS DUKE U; NEWBORN M., 1985, ACM ANN C, P272; Newell A, 1972, HUMAN PROBLEM SOLVIN; PEARL J, 1980, 1ST P ANN NAT C ART; REINEFELD A, 1983, J INT COMPUT CHESS A, V6, P4; SCHAEFFER J, 1983, J INT COMPUT CHESS A, V6, P16; SCHAEFFER J, 1989, ADV COMPUTER CHESS, P199; SCHAEFFER J, IN PRESS ARTIFICIAL; SCHAEFFER J, 1986, THESIS U WATERLOO; SLAGLE J, 1969, J ACM, V2, P189; Slate D. J., 1977, Chess skill in man and machine, P82	31	112	118	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1203	1212		10.1109/34.42858	http://dx.doi.org/10.1109/34.42858			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600007
J	ADIV, G				ADIV, G			INHERENT AMBIGUITIES IN RECOVERING 3-D MOTION AND STRUCTURE FROM A NOISY FLOW FIELD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003	University of Massachusetts System; University of Massachusetts Amherst								ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ADIV G, 1985, THESIS U MASSACHUSET; Fang J.-Q., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P253; FANG JQ, 1983, P INT JOINT C ART IN, P1035; Hanson A., 1978, COMPUTER VISION SYST, P303; LAWTON DT, 1984, THESIS U MASSACHUSET; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; RALSTON A, 1965, 1ST COURSE NUMERICAL; RIEGER JH, 1983, P ACM INTERDISCIPLIN, P33; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30, P525, DOI 10.1109/TASSP.1982.1163931; ULLMAN S, 1981, COMPUTER, V14, P57, DOI 10.1109/C-M.1981.220564; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WAXMAN A, 1983, SURFACE STRUCTURE 3D	15	112	116	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					477	489		10.1109/34.24780	http://dx.doi.org/10.1109/34.24780			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400003
J	DORST, L; SMEULDERS, AWM				DORST, L; SMEULDERS, AWM			DISCRETE REPRESENTATION OF STRAIGHT-LINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									DELFT UNIV TECHNOL,DEPT APPL PHYS,DELFT,NETHERLANDS	Delft University of Technology	DORST, L (corresponding author), TECH HOGSCH DELFT,TECH NAT KUNDE LAB,DELFT,NETHERLANDS.							DORST L, 1982, 6TH P ICPR MUNCH; GONZALEZ RC, 1982, COMPUTER, V15, P17, DOI 10.1109/MC.1982.1653913; GROEN FCA, 1978, COMPUT VISION GRAPH, V7, P391, DOI 10.1016/S0146-664X(78)80005-7; HARDY GH, 1979, INTRO THEORY NUMBERS, pCH5; Kulpa Z., 1977, COMPUTER GRAPHICS IM, V6, P434, DOI [10.1016/S0146-664X(77)80021-X, DOI 10.1016/S0146-664X(77)80021-X]; Lipkin BS, 1970, PICTURE PROCESSING P, P241; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2, P121; SMEULDERS AWM, 1983, TH DELFT INTERNAL RE; VOSSEPOEL AM, 1982, COMPUT VISION GRAPH, V20, P347, DOI 10.1016/0146-664X(82)90057-0	10	112	113	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					450	463		10.1109/TPAMI.1984.4767550	http://dx.doi.org/10.1109/TPAMI.1984.4767550			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869213	Green Submitted			2022-12-18	WOS:A1984SY28900006
J	AHUJA, N				AHUJA, N			DOT PATTERN PROCESSING USING VORONOI NEIGHBORHOODS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV ILLINOIS,DEPT ELECT ENGN,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	AHUJA, N (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							BALL GH, 1965, 1965 P FALL JOINT CO, P533; BERNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, STATISTICIAN, V24, P179; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; Fairfield J., 1979, Proceedings of the International Conference on Cybernetics and Society, P60; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P917, DOI 10.1109/T-C.1970.222799; GITMAN I, 1972, PATTERN RECOGN, V4, P307, DOI 10.1016/0031-3203(72)90008-8; GOWER JC, 1969, APPL STATIST, V18, P54, DOI DOI 10.2307/2346439; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HUBERT LJ, 1974, PSYCHOMETRIKA, V39, P283, DOI 10.1007/BF02291704; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KAHL DJ, 1978, THESIS U MARYLAND CO; KAHL DJ, 1978, TR690 U MAR COMP SCI; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171, DOI 10.1109/TC.1972.5008922; LAVINE D, 1981, AUG P IEEE C PATT RE, P49; LEE DT, 1978, ACT12 U ILL COORD SC; OCALLAGH.JF, 1974, PERCEPTION, V3, P33, DOI 10.1068/p030033; OCALLAGHAN JF, 1975, IEEE T COMPUT, V24, P1121, DOI 10.1109/T-C.1975.224144; OCALLAGHAN JF, 1974, COMPUT GRAPHICS IMAG, V3, P141; PATRICK EA, 1971, IEEE T COMPUT, VC 20, P216, DOI 10.1109/T-C.1971.223217; Pielou EC., 1977, MATH ECOLOGY; RANADE S, 1978, TR702 U MAR COMP SCI; Rankin R.A., 1964, PACKING COVERING, V5414, P247; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SHAMOS MI, 1975, 16TH P ANN S F COMP, P131; SIBSON R, 1980, SCAND J STAT, V7, P14; SIMON JC, 1972, PATTERN RECOGN, V4, P73, DOI 10.1016/0031-3203(72)90020-9; SNEATH PHA, 1966, COMPUT J, V9, P383; Thiessen A.H., 1911, MONTHLY WEATHER REV, V39, P1082; TOBLER WR, 1975, DISPLAY ANAL SPATIAL; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; TOUSSAINT GT, 1979, NOV COMPSAC CHIC; VELASCO FRD, 1979, TR718 U MAR COMP SCI; VELASCO FRD, 1979, TR740 U MAR COMP SCI; Voronoi G, 1908, J REINE ANGEW MATH, V134, P198, DOI 10.1515/crll.1908.134.198; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; ZAHN CT, 1974, P IFIP, P727; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7; ZUCKER SW, 1979, COMPUT VISION GRAPH, V9, P213, DOI 10.1016/0146-664X(79)90038-8	43	112	117	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					336	343		10.1109/TPAMI.1982.4767255	http://dx.doi.org/10.1109/TPAMI.1982.4767255			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869045				2022-12-18	WOS:A1982NN06900016
J	Luo, JH; Zhang, H; Zhou, HY; Xie, CW; Wu, JX; Lin, WY				Luo, Jian-Hao; Zhang, Hao; Zhou, Hong-Yu; Xie, Chen-Wei; Wu, Jianxin; Lin, Weiyao			ThiNet: Pruning CNN Filters for a Thinner Net	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural networks; filter pruning; deep learning; model compression		This paper aims at accelerating and compressing deep neural networks to deploy CNN models into small devices like mobile phones or embedded gadgets. We focus on filter level pruning, i.e., the whole filter will be discarded if it is less important. An effective and unified framework, ThiNet (stands for "Thin Net"), is proposed in this paper. We formally establish filter pruning as an optimization problem, and reveal that we need to prune filters based on statistics computed from its next layer, not the current layer, which differentiates ThiNet from existing methods. We also propose "gcos" (Group COnvolution with Shuffling), a more accurate group convolution scheme, to further reduce the pruned model size. Experimental results demonstrate the effectiveness of our method, which has advanced the state-of-the-art. Moreover, we show that the original VGG-16 model can be compressed into a very small model (ThiNet-Tiny) with only 2.66 MB model size, but still preserve AlexNet level accuracy. This small model is evaluated on several benchmarks with different vision tasks (e.g., classification, detection, segmentation), and shows excellent generalization ability.	[Luo, Jian-Hao; Zhang, Hao; Zhou, Hong-Yu; Xie, Chen-Wei; Wu, Jianxin] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200000, Peoples R China	Nanjing University; Shanghai Jiao Tong University	Wu, JX (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	luojh@lamda.nju.edu.cn; zhangh@lamda.nju.edu.cn; zhouhy@lamda.nju.edu.cn; xiecw@lamda.nju.edu.cn; wujx@lamda.nju.edu.cn; wylin@sjtu.edu.cn		Zhang, Hao/0000-0001-5447-180X; Lin, Weiyao/0000-0001-8307-7107; Zhou, Hong-Yu/0000-0002-1256-7050	National Natural Science Foundation of China [61772256, 61422203]; Shanghai 'The Belt and Road' Young Scholar Exchange Grant [17510740100]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai 'The Belt and Road' Young Scholar Exchange Grant	This work was supported in part by the National Natural Science Foundation of China under Grant No. 61772256 and No. 61422203, in part by Shanghai 'The Belt and Road' Young Scholar Exchange Grant No. (17510740100).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Chechik G, 1998, NEURAL COMPUT, V10, P1759, DOI 10.1162/089976698300017124; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen WL, 2015, PR MACH LEARN RES, V37, P2285; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; Denil M., 2013, ADV NEURAL INFORM PR, P2148, DOI DOI 10.5555/2999792.2999852; Dentinel Zarembaw, 2014, NEURIPS, P1269; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong Yunchao, 2014, ARXIV14126115; Han S., 2016, P 4 INT C LEARN REPR, P1; Han SQ, 2017, IOP C SER EARTH ENV, V69, DOI 10.1088/1755-1315/69/1/012096; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155; Hinton G, 1986, P 8 ANN C COGN SCI S, V1, DOI DOI 10.1016/J.NEUCOM.2013.03.009; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Howard A.G., 2017, MOBILENETS EFFICIENT; Hu H., 2016, ARXIV160703250, P1; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Iandola F.N., 2016, ARXIV; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li HF, 2017, ADV SOC SCI EDUC HUM, V179, P1; Li L., 2011, PROC OPT FIBER COMMU, P1, DOI DOI 10.1145/2093698.2093824; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241; Molchanov P., 2017, P INT C LEARN REPR I, P1; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [DOI 10.1007/978-3-030-28954-6_10, 10.1109/CVPR.2012.6248092, DOI 10.1109/CVPR.2012.6248092]; Polyak A, 2015, IEEE ACCESS, V3, P2163, DOI 10.1109/ACCESS.2015.2494536; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Sindhwani V., 2015, ADV NEURAL INFORM PR, P3088; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Wah C., 2011, TECH REP; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133; Wen W, 2016, ADV NEUR IN, V29; Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319	54	111	114	9	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2525	2538		10.1109/TPAMI.2018.2858232	http://dx.doi.org/10.1109/TPAMI.2018.2858232			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30040622				2022-12-18	WOS:000489763000018
J	Vazquez, D; Lopez, AM; Marin, J; Ponsa, D; Geronimo, D				Vazquez, David; Lopez, Antonio M.; Marin, Javier; Ponsa, Daniel; Geronimo, David			Virtual and Real World Adaptation for Pedestrian Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pedestrian detection; photo-realistic computer animation; data set shift; domain adaptation		Pedestrian detection is of paramount interest for many applications. Most promising detectors rely on discriminatively learnt classifiers, i.e., trained with annotated samples. However, the annotation step is a human intensive and subjective task worth to be minimized. By using virtual worlds we can automatically obtain precise and rich annotations. Thus, we face the question: can a pedestrian appearance model learnt in realistic virtual worlds work successfully for pedestrian detection in real-world images? Conducted experiments show that virtual-world based training can provide excellent testing accuracy in real world, but it can also suffer the data set shift problem as real-world based training does. Accordingly, we have designed a domain adaptation framework, V-AYLA, in which we have tested different techniques to collect a few pedestrian samples from the target domain (real world) and combine them with the many examples of the source domain (virtual world) in order to train a domain adapted pedestrian classifier that will operate in the target domain. V-AYLA reports the same detection accuracy than when training with many human-provided pedestrian annotations and testing with real-world images of the same domain. To the best of our knowledge, this is the first work demonstrating adaptation of virtual and real worlds for developing an object detector.	[Vazquez, David; Lopez, Antonio M.; Marin, Javier; Ponsa, Daniel; Geronimo, David] Univ Autonoma Barcelona, Ctr Vis Comp, E-08193 Barcelona, Spain	Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Vazquez, D (corresponding author), Univ Autonoma Barcelona, Ctr Vis Comp, Edificio O, E-08193 Barcelona, Spain.	david.vazquez@cvc.uab.es	Vázquez, David/P-3306-2019; Hajra, Suvadeep/L-8460-2015; Vázquez, David/M-1315-2014; López, Antonio M/L-5303-2014; Ponsa, Daniel/A-5496-2010	Vázquez, David/0000-0002-2845-8158; Vázquez, David/0000-0002-2845-8158; López, Antonio M/0000-0002-6979-5783; Ponsa, Daniel/0000-0002-7330-6524	Spanish MICINN [TRA2011-29454-C03-01, TIN2011-29494-C03-02]	Spanish MICINN(Ministry of Science and Innovation, Spain (MICINN)Spanish Government)	This work was supported by Spanish MICINN projects TRA2011-29454-C03-01 and TIN2011-29494-C03-02.	Abramson Y., 2005, P IEEE C COMP VIS PA; Agarwal A., 2006, P AS C COMP VIS; [Anonymous], 2007, P ANN M ASS COMP LIN; Ben-David S., 2010, ML, V79, P151, DOI DOI 10.1007/S10994-009-5152-4]; Berg TL, 2010, P IEEE, V98, P1434, DOI 10.1109/JPROC.2009.2032355; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Bishop CM, 2006, PATTERN RECOGNITION; BROGGI A, 2005, P IEEE C COMP VIS PA; Chen YT, 2008, IEEE T IMAGE PROCESS, V17, P1452, DOI 10.1109/TIP.2008.926152; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1007/BF00993277; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dalal N., 2006, THESIS I NATL POLYTE; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Endres I., 2010, P IEEE C COMP VIS PA; Enzweiler M., 2008, P IEEE C COMP VIS PA; Enzweiler M, 2011, IEEE T IMAGE PROCESS, V20, P2967, DOI 10.1109/TIP.2011.2142006; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Garcia S, 2008, J MACH LEARN RES, V9, P2677; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Geronimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122; Jain A., 2010, P ACM SIGGRAPH; Laptev I, 2009, IMAGE VISION COMPUT, V27, P535, DOI 10.1016/j.imavis.2008.08.010; Li MK, 2006, IEEE T PATTERN ANAL, V28, P1251, DOI 10.1109/TPAMI.2006.156; Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Marin J., 2010, P IEEE C COMP VIS PA; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pouli T., 2010, P EUR COMP GRAPH C E; Quinonero-Candela J., 2008, NEURAL INFORM PROCES; Ross J., 2010, P ACM INT C HUM FACT; Saenko Kate, 2010, P EUR C COMP VIS; SHAO W, 2006, THESIS NEW YORK U; Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177; Vazquez D., 2011, P ADV NEUR INF PROC; Vazquez D., 2011, P ACM INT C MULT INT; Walk S., 2010, CVPR; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Zhang J., 2010, P IEEE C COMP VIS PA	43	111	118	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					797	809		10.1109/TPAMI.2013.163	http://dx.doi.org/10.1109/TPAMI.2013.163			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353201				2022-12-18	WOS:000334109000013
J	Park, C; Huang, JHZ; Ji, JX; Ding, Y				Park, Chiwoo; Huang, Jianhua Z.; Ji, Jim X.; Ding, Yu			Segmentation, Inference, and Classification of Partially Overlapping Nanoparticles	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; morphology analysis; shape inference; shape classification; nanoparticle analysis	MAXIMUM-LIKELIHOOD; IMAGE SEGMENTATION; ACTIVE CONTOURS; CELL-NUCLEI; BAND; REGISTRATION; ALGORITHM; TIME	This paper presents a method that enables automated morphology analysis of partially overlapping nanoparticles in electron micrographs. In the undertaking of morphology analysis, three tasks appear necessary: separate individual particles from an agglomerate of overlapping nanoobjects, infer the particle's missing contours, and, ultimately, classify the particles by shape based on their complete contours. Our specific method adopts a two-stage approach: The first stage executes the task of particle separation, and the second stage simultaneously conducts the tasks of contour inference and shape classification. For the first stage, a-modified ultimate erosion process is developed for decomposing a mixture of particles into markers, and then an edge-to-marker association method is proposed to identify the set of evidences that eventually delineate individual objects. We also provide theoretical justification regarding the separation capability of the first stage. In the second stage, the set of evidences becomes inputs to a Gaussian mixture model on B-splines, the solution of which leads to the joint learning of the missing contour and the particle shape. Using 12 real electron micrographs of overlapping nanoparticles, we compare the proposed method with seven state-of-the-art methods. The results show the superiority of the proposed method in terms of particle recognition rate.	[Park, Chiwoo] Florida A&M, Dept Ind & Mfg Engn, Tallahassee, FL 32310 USA; [Huang, Jianhua Z.] Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA; [Ji, Jim X.] Texas A&M Univ, Dept Elect & Comp Engn, Off Zachry 237L, College Stn, TX 77843 USA; [Ding, Yu] Texas A&M Univ, Dept Ind & Syst Engn, Off ETB 4016, College Stn, TX 77843 USA	State University System of Florida; Florida A&M University; Texas A&M University System; Texas A&M University College Station; Texas A&M University System; Texas A&M University College Station; Texas A&M University System; Texas A&M University College Station	Park, C (corresponding author), Florida A&M, Dept Ind & Mfg Engn, Tallahassee, FL 32310 USA.	cpark5@fsu.edu; jianhua@stat.tamu.edu; jimji@ece.tamu.edu; yuding@iemail.tamu.edu	Park, Chiwoo/ABA-4876-2021	Park, Chiwoo/0000-0002-2463-8901	US National Science Foundation (NSF) [CMMI-0348150, CMMI-1000088]; Texas Norman Hackerman Advanced Research Program [010366-0024-2007]; NSF [DMS-0907170, DMS-1007618, 0748180]; King Abdullah University of Science and Technology [KUS-CI-016-04]	US National Science Foundation (NSF)(National Science Foundation (NSF)); Texas Norman Hackerman Advanced Research Program; NSF(National Science Foundation (NSF)); King Abdullah University of Science and Technology(King Abdullah University of Science & Technology)	The authors would like to acknowledge the generous support from their sponsors. Ding and Park are partially supported by US National Science Foundation (NSF) grants CMMI-0348150, CMMI-1000088, and Texas Norman Hackerman Advanced Research Program grant 010366-0024-2007; Huang is partially supported by NSF grants DMS-0907170, DMS-1007618, and King Abdullah University of Science and Technology award KUS-CI-016-04; Ji is partially supported by NSF grant 0748180. The authors would also like to thank Dr. Hong Liang and Dr. Subrata Kundu in the Department of Mechanical Engineering at Texas A&M University for providing the electron micrographs of gold nanoparticles.	Adiga PSU, 2001, PATTERN RECOGN, V34, P1449, DOI 10.1016/S0031-3203(00)00076-5; Al-Thyabat S, 2006, POWDER TECHNOL, V166, P152, DOI 10.1016/j.powtec.2006.05.008; Bamford P, 1998, SIGNAL PROCESS, V71, P203, DOI 10.1016/S0165-1684(98)00145-5; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bengtsson E., 2004, Pattern Recognition and Image Analysis, V14, P157; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen LC, 2008, REV ADV MATER SCI, V18, P679; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Cheng JR, 2009, IEEE T BIO-MED ENG, V56, P741, DOI 10.1109/TBME.2008.2008635; DANEK O, 2009, P 16 SCAND C AN, V5575, P410; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dougherty ER, 1994, DIGITAL IMAGE PROCES; El-Sayed MA, 2001, ACCOUNTS CHEM RES, V34, P257, DOI 10.1021/ar960016n; EPSTEIN MP, 1976, SIAM J NUMER ANAL, V13, P261, DOI 10.1137/0713025; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fisker R, 2000, J NANOPART RES, V2, P267, DOI 10.1023/A:1010023316775; Foulonneau A, 2009, INT J COMPUT VISION, V81, P68, DOI 10.1007/s11263-008-0163-3; Glotov OG, 2008, RUSS J PHYS CHEM A+, V82, P2213, DOI 10.1134/S0036024408130098; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Goshtasby AA, 2000, ACM T GRAPHIC, V19, P185, DOI 10.1145/353981.353992; Hodneland E, 2009, INT J COMPUT VISION, V82, P264, DOI 10.1007/s11263-008-0199-4; Hoschek J., 1988, Computer-Aided Geometric Design, V5, P27, DOI 10.1016/0167-8396(88)90017-9; Jean S., 2001, GALOIS THEORY ALGEBR; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kim YJ, 2008, JPN J APPL PHYS, V47, P1325, DOI 10.1143/JJAP.47.1325; Lecumberry F, 2010, IEEE T IMAGE PROCESS, V19, P625, DOI 10.1109/TIP.2009.2038759; LEE ETY, 1989, COMPUT AIDED DESIGN, V21, P363, DOI 10.1016/0010-4485(89)90003-1; Lin G, 2005, CYTOM PART A, V63A, P20, DOI 10.1002/cyto.a.20099; Malpica N, 1997, CYTOMETRY, V28, P289, DOI 10.1002/(SICI)1097-0320(19970801)28:4<289::AID-CYTO3>3.0.CO;2-7; Marcuzzo M, 2009, LECT NOTES COMPUT SC, V5627, P824, DOI 10.1007/978-3-642-02611-9_81; Matheron G., 1975, RANDOM SETS INTEGRAL; McFarland AD, 2003, NANO LETT, V3, P1057, DOI 10.1021/nl034372s; Nath SK, 2006, LECT NOTES COMPUT SC, V4190, P101; Nehl CL, 2006, NANO LETT, V6, P683, DOI 10.1021/nl052409y; Ng L, 2003, LECT NOTES COMPUT SC, V2717, P271; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pan Y, 2007, SMALL, V3, P1941, DOI 10.1002/smll.200700378; Park C., 2011, THESIS TEXAS A M U; Parvin B, 2007, IEEE T IMAGE PROCESS, V16, P615, DOI 10.1109/TIP.2007.891154; Pinidiyaarachchi A, 2005, LECT NOTES COMPUT SC, V3617, P336, DOI 10.1007/11553595_41; Qiu P, 2007, J AM STAT ASSOC, V102, P1129, DOI 10.1198/016214506000001158; Qiu PH, 2009, J COMPUT GRAPH STAT, V18, P147, DOI 10.1198/jcgs.2009.0009; Quelhas P, 2010, IEEE T MED IMAGING, V29, P1463, DOI 10.1109/TMI.2010.2048253; RONSE C, 1989, IEEE T PATTERN ANAL, V11, P181, DOI 10.1109/34.16713; ROSENFELD A, 1985, PATTERN RECOGN LETT, V3, P71, DOI 10.1016/0167-8655(85)90045-5; Saux E, 2003, COMPUT AIDED GEOM D, V20, P513, DOI 10.1016/j.cagd.2003.06.004; Schmitt O, 2009, COMPUT VIS IMAGE UND, V113, P188, DOI 10.1016/j.cviu.2008.08.011; Schneider R., 1993, CONVEX BODIES BRUNN; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tek FB, 2005, COMPUT IMAGING VIS, V30, P441; Tu ZW, 2008, COMPUT VIS IMAGE UND, V109, P290, DOI 10.1016/j.cviu.2007.04.004; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Wang WX, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P41, DOI 10.1109/FSKD.2007.353; Wang ZL, 1998, J PHYS CHEM B, V102, P6145, DOI 10.1021/jp981594j; Wortis M., 1988, CHEM PHYS SOLID PHYS; Wu R., 2004, REXS TRIBE IMAGE PRO; Zhang Y, 2009, IEEE IMAGE PROC, P2993, DOI 10.1109/ICIP.2009.5414505	59	111	118	0	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					669	681		10.1109/TPAMI.2012.163	http://dx.doi.org/10.1109/TPAMI.2012.163			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22848127				2022-12-18	WOS:000314792900012
J	Zhu, X; Milanfar, P				Zhu, Xiang; Milanfar, Peyman			Removing Atmospheric Turbulence via Space-Invariant Deconvolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image restoration; atmospheric turbulence; nonrigid image registration; point spread function; sharpness metric	IMAGE REGISTRATION; INFORMATION FUSION; IDENTIFICATION; RESTORATION	To correct geometric distortion and reduce space and time-varying blur, a new approach is proposed in this paper capable of restoring a single high-quality image from a given image sequence distorted by atmospheric turbulence. This approach reduces the space and time-varying deblurring problem to a shift invariant one. It first registers each frame to suppress geometric deformation through B-spline-based nonrigid registration. Next, a temporal regression process is carried out to produce an image from the registered frames, which can be viewed as being convolved with a space invariant near-diffraction-limited blur. Finally, a blind deconvolution algorithm is implemented to deblur the fused image, generating a final output. Experiments using real data illustrate that this approach can effectively alleviate blur and distortions, recover details of the scene, and significantly improve visual quality.	[Zhu, Xiang; Milanfar, Peyman] Univ Calif Santa Cruz, Dept Elect Engn, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Zhu, X (corresponding author), Univ Calif Santa Cruz, Dept Elect Engn, 1156 High St, Santa Cruz, CA 95064 USA.	xzhu@ee.ucsc.edu; milanfar@ee.ucsc.edu	Milanfar, Peyman/B-2551-2009		US Air Force Office of Scientific Research [FA9550-07-1-0365]; US National Science Foundation [CCF-1016018]	US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); US National Science Foundation(National Science Foundation (NSF))	The authors would like to thank Prof. Mikhail A. Vorontsov from the Intelligent Optics Lab of the University of Maryland for allowing them to use the video data Water Tower, and thank Mr. Faisal A. Salem from the University of Michigan and Dr. Joseph M. Zawodny from NASA Langley Research Center for providing them with the video Moon Surface. The authors also thank Mr. M. Hirsch and Dr. S. Harmeling from Max Plank Institute for Biological Cybernetics for sharing with them the sequences Chimney and Building. This work was supported by US Air Force Office of Scientific Research Grant FA9550-07-1-0365 and US National Science Foundation Grant CCF-1016018.	Aubailly M., 2009, P SPIE, V7463; Aubailly M., 2008, P SPIE, V7090; Beg MF, 2007, IEEE T MED IMAGING, V26, P1179, DOI 10.1109/TMI.2007.898813; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Christou JC, 2006, PROC SPIE, V6272, pU660, DOI 10.1117/12.670430; Dantowitz RF, 2000, ASTRON J, V119, P2455, DOI 10.1086/301328; DAVIES L, 1993, J AM STAT ASSOC, V88, P782, DOI 10.2307/2290763; Farsiu S, 2005, 2005 IEEE/SP 13TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING (SSP), VOLS 1 AND 2, P1313, DOI 10.1109/SSP.2005.1628814; Fergus R., 2006, P ACM SIGGRAPH; Fried D. L., 1978, OPTICAL SOC AM J, V68, P1651, DOI DOI 10.1364/JOSA.68.001651; Giannakis GB, 2000, IEEE T IMAGE PROCESS, V9, P1877, DOI 10.1109/83.877210; HAMPEL FR, 1974, J AM STAT ASSOC, V69, P383, DOI 10.2307/2285666; Harmeling S., 2009, P IEEE INT C COMP PH; Hirsch M, 2010, PROC CVPR IEEE, P607, DOI 10.1109/CVPR.2010.5540158; John S, 2005, IEEE T IMAGE PROCESS, V14, P577, DOI 10.1109/TIP.2005.846022; Joshi N., 2010, P IEEE INT C COMP PH; Law N. M, 2003, THESIS CAMBRIDGE U; LEVIN A, 2009, P IEEE C COMP VIS PA; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Li DL, 2007, IEEE GEOSCI REMOTE S, V4, P340, DOI 10.1109/LGRS.2007.895691; Oreifej Omar, 2011, P IEEE C COMP VIS PA; ROGGEMANN MC, 1994, OPT ENG, V33, P3254, DOI 10.1117/12.181250; Roggemann Michael C, 1996, IMAGING TURBULENCE; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Souidene W, 2009, IEEE T IMAGE PROCESS, V18, P1487, DOI 10.1109/TIP.2009.2018566; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; Tian Y., 2009, P 12 IEEE INT C COMP; TUBBS RN, 2003, THESIS CAMBRIDGE U; Tyson R. K., 1998, PRINCIPLES ADAPTIVE; Vorontsov MA, 1999, J OPT SOC AM A, V16, P1623, DOI 10.1364/JOSAA.16.001623; Vorontsov MA, 2001, J OPT SOC AM A, V18, P1312, DOI 10.1364/JOSAA.18.001312; Wand M.P., 1995, MONOGRAPHS STAT APPL; Zhu X., 2010, P SPIE EL IM C VIS I; [No title captured]; [No title captured]; [No title captured]	37	111	130	0	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					157	170		10.1109/TPAMI.2012.82	http://dx.doi.org/10.1109/TPAMI.2012.82			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	23154324	Green Submitted			2022-12-18	WOS:000311127700015
J	Masnadi-Shirazi, H; Vasconcelos, N				Masnadi-Shirazi, Hamed; Vasconcelos, Nuno			Cost-Sensitive Boosting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Boosting; AdaBoost; cost-sensitive learning; asymmetric boosting	CLASSIFICATION; RECOGNITION; SPARSE; VIEW	A novel framework is proposed for the design of cost-sensitive boosting algorithms. The framework is based on the identification of two necessary conditions for optimal cost-sensitive learning that 1) expected losses must be minimized by optimal cost-sensitive decision rules and 2) empirical loss minimization must emphasize the neighborhood of the target cost-sensitive boundary. It is shown that these conditions enable the derivation of cost-sensitive losses that can be minimized by gradient descent, in the functional space of convex combinations of weak learners, to produce novel boosting algorithms. The proposed framework is applied to the derivation of cost-sensitive extensions of AdaBoost, RealBoost, and LogitBoost. Experimental evidence, with a synthetic problem, standard data sets, and the computer vision problems of face and car detection, is presented in support of the cost-sensitive optimality of the new algorithms. Their performance is also compared to those of various previous cost-sensitive boosting proposals, as well as the popular combination of large-margin classifiers and probability calibration. Cost-sensitive boosting is shown to consistently outperform all other methods.	[Masnadi-Shirazi, Hamed; Vasconcelos, Nuno] Univ Calif San Diego, Stat Visual Comp Lab, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Masnadi-Shirazi, H (corresponding author), Univ Calif San Diego, Stat Visual Comp Lab, 9500 Gilman Dr,Mail Code 0407,EBU 1,Room 5512, La Jolla, CA 92093 USA.	hmasnadi@ucsd.edu; nuno@ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302				Agarwal S, 2005, J MACH LEARN RES, V6, P393; Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Bar-Hillel A, 2008, INT J COMPUT VISION, V77, P175, DOI [10.1007/s11263-007-0091-7, 10.1007/s11263-007-0091]; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 2017, CLASSIFICATION REGRE; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P.M., 1999, P 5 ACM SIGKDD INT C, P155, DOI DOI 10.1145/312129.312220; Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36; Duda R.O., 2001, PATTERN CLASSIFICATI; Elkan C., 2001, INT JOINT C ART INT, V17, P973, DOI DOI 10.5555/1642194.1642224; Fan W, 1999, MACHINE LEARNING, PROCEEDINGS, P97; Fergus R, 2003, PROC CVPR IEEE, P264; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; GRABNER H, 2005, P COMP VIS WINT WORK, P23; Green D. M., 1966, SIGNAL DETECTION THE, DOI DOI 10.1086/405615; Hastie T, 2009, ELEMENTS STAT LEARNI; Jiang WX, 2004, ANN STAT, V32, P13; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6; Mason L, 2000, ADV NEUR IN, V12, P512; Mease D, 2008, J MACH LEARN RES, V9, P131; Mease D, 2007, J MACH LEARN RES, V8, P409; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009; Niculescu-Mizil A., 2005, P 21 C UNC ART INT, P413, DOI DOI 10.5555/3020336.3020388; OREN M, 1997, P IEEE C PATT REC CO; Platt JC, 2000, ADV NEUR IN, P61; Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Schneiderman H., 2004, P IEEE C COMP VIS PA; Seemann E., 2006, P IEEE INT C COMP VI, V2, P1582, DOI DOI 10.1109/CVPR.2006.193; Shotton J, 2005, IEEE I CONF COMP VIS, P503; Sun YM, 2005, LECT NOTES ARTIF INT, V3587, P21; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Ting Kai Ming, 2000, P 17 INT C MACH LEAR, P983; TREE HLV, 1968, DETECTION ESTIMATION; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Viaene S, 2004, INT J INTELL SYST, V19, P1197, DOI 10.1002/int.20049; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P, 2002, ADV NEUR IN, V14, P1311; Vlahou A, 2003, J BIOMED BIOTECHNOL, P308, DOI 10.1155/S1110724303210032; Wald A, 1939, ANN MATH STAT, V10, P299, DOI 10.1214/aoms/1177732144; Winn J., 2006, CVPR; ZADROZNY B, 2001, P 7 INT C KNOWL DISC, P203; Zadrozny Bianca, 2001, ICML; ZEMEL RS, 2000, ADV NEURAL INFORM PR, P696	56	111	119	5	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					294	309		10.1109/TPAMI.2010.71	http://dx.doi.org/10.1109/TPAMI.2010.71			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	21193808	Green Submitted			2022-12-18	WOS:000285313200007
J	Wang, XJ; Zhang, L; Li, XR; Ma, WY				Wang, Xin-Jing; Zhang, Lei; Li, Xirong; Ma, Wei-Ying			Annotating images by mining image search results	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; information filtering; object recognition; real-time systems	RETRIEVAL	Although it has been studied for years by the computer vision and machine learning communities, image annotation is still far from practical. In this paper, we propose a novel attempt at model-free image annotation, which is a data-driven approach that annotates images by mining their search results. Some 2.4 million images with their surrounding text are collected from a few photo forums to support this approach. The entire process is formulated in a divide-and-conquer framework where a query keyword is provided along with the uncaptioned image to improve both the effectiveness and efficiency. This is helpful when the collected data set is not dense everywhere. In this sense, our approach contains three steps: 1) the search process to discover visually and semantically similar search results, 2) the mining process to identify salient terms from textual descriptions of the search results, and 3) the annotation rejection process to filter out noisy terms yielded by Step 2. To ensure real-time annotation, two key techniques are leveraged-one is to map the high-dimensional image visual features into hash codes, the other is to implement it as a distributed system, of which the search and mining processes are provided as Web services. As a typical result, the entire process finishes in less than 1 second. Since no training data set is required, our approach enables annotating with unlimited vocabulary and is highly scalable and robust to outliers. Experimental results on both real Web images and a benchmark image data set show the effectiveness and efficiency of the proposed algorithm. It is also worth noting that, although the entire approach is illustrated within the divide-and-conquer framework, a query keyword is not crucial to our current implementation. We provide experimental results to prove this.	[Wang, Xin-Jing; Zhang, Lei; Ma, Wei-Ying] Microsoft Res Asia, 4F Sigma Ctr, Beijing 100190, Peoples R China; [Li, Xirong] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 SJ Amsterdam, Netherlands	Microsoft; Microsoft Research Asia; University of Amsterdam	Wang, XJ (corresponding author), Microsoft Res Asia, 4F Sigma Ctr, 49 Zhichun Rd,Haidan Dist, Beijing 100190, Peoples R China.	xjwang@microsoft.com; leizhang@microsoft.com; xirong@science.uva.nl; wyma@microsoft.com	Li, Xirong/AAD-3347-2019	Li, Xirong/0000-0002-0220-8310				Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barnard K, 2001, PROC CVPR IEEE, P434; BARNARD K, 2003, INTERNET IMAGING, V9; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; CAI D, 2004, P 12 ANN ACM INT C M, P952, DOI DOI 10.1145/1027527.1027747; Carneiro G., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P559, DOI 10.1145/1076034.1076129; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079; CHEN Z, 2001, P 24 ANN INT ACM SIG, P450; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Datta Ritendra, 2005, P MIR, P253; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; FAN J, 2004, P 27 ANN INT ACM SIG, P361; Fan J., 2004, P 12 ANN ACM INT C M, P540, DOI [10.1145/1027527.1027660, DOI 10.1145/1027527.1027660]; FAN X, 2005, P 7 ACM SIGMM INT WO, P143, DOI DOI 10.1145/1101826.1101851; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; GHOSHAL A, 2005, P 28 ANN INT ACM SIG, P544; HAYS J, 2007, P ACM SIGGRAPH; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; JEON J, 2004, P ACM INT C MULT; Jeon J., 2003, P ACM SIGIR C RES DE, P119; Joliffe I. T., 1986, PRINCIPAL COMPONENT; Lavrenko V., 2003, ADV NEURAL INFORM PR; LI B, 2003, P 11 ACM INT C MULT, P195; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984; Li J., 2006, P 14 ANN ACM INT C M, P911, DOI DOI 10.1145/1180639.1180841; LI X, 2007, P ACM INT C MULT, P467; LI X, 2006, P 14 ANN ACM INT C M, P607; Liu WY, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P326; Monay F, 2003, P 11 ACM INT C MULT, P275, DOI DOI 10.1145/957013.957070; Monayand F., 2004, ACM MULTIMEDIA, P348; Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63; Oka R., 1999, P 1 INT WORKSH MULT; PAN JY, 2004, P COMP VIS PATT REC, V9, P146; PAN JY, 2004, P 10 ACM SIGKDD INT, P653, DOI DOI 10.1145/1014052.1014135; ROBERTSON SE, 1995, P 3 TEXT RETR C TREC, P109; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; SHEVADE B, 2004, AMET200402 AR STAT U; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; *SRC, 2006, SEARCH RES CLUST TOO; Toda H., 2005, P 7 ANN ACM INT WORK, P81, DOI [10.1145/1097047.1097063, DOI 10.1145/1097047.1097063]; Torralba A, 2007, MITCSAILTR2007024; Wang B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P353, DOI 10.1109/ICME.2006.262509; Wang XJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2231, DOI 10.1109/ICME.2004.1394714; WANG XJ, 2004, P 12 ACM INT C MULT, P944; WANG XJ, 2006, P CVPR, P1483; WEIJER J, 2007, P IEEE INT C COMP VI; Yang C., 2004, P ACM INT C MULT, P435; YEH T, 2004, CVPR, V2, P76; ZENG HJ, 2004, P 27 ANN INT ACM SIG, P210, DOI DOI 10.1145/1008992.1009030; ZHU L, 2000, P ACM MULT 2000 LOS, P157; 2008, YAHOO NEWS SEARCH	53	111	131	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1919	1932		10.1109/TPAMI.2008.127	http://dx.doi.org/10.1109/TPAMI.2008.127			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787241				2022-12-18	WOS:000259110000006
J	Alajlan, N; Kamel, MS; Freeman, GH				Alajlan, Naif; Kamel, Mohamed S.; Freeman, George H.			Geometry-based image retrieval in binary image databases	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometry-based image retrieval; shape matching; attributed tree matching; medical image retrieval	NONRIGID SHAPES; RECOGNITION; REPRESENTATION; ALGORITHMS; DESIGN	In this paper, a geometry-based image retrieval system is developed for multiobject images. We model both shape and topology of image objects using a structured representation called curvature tree (CT). The hierarchy of the CT reflects the inclusion relationships between the image objects. To facilitate shape-based matching, triangle-area representation (TAR) of each object is stored at the corresponding node in the CT. The similarity between two multiobject images is measured based on the maximum similarity subtree isomorphism (MSSI) between their CTs. For this purpose, we adopt a recursive algorithm to solve the MSSI problem and a very effective dynamic programming algorithm to measure the similarity between the attributed nodes. Our matching scheme agrees with many recent findings in psychology about the human perception of multiobject images. Experiments on a database of 13,500 real and synthesized medical images and the MPEG-7 CE-1 database of 1,400 shape images have shown the effectiveness of the proposed method.	[Alajlan, Naif] King Saud Univ, Coll Engn, Dept Elect Engn, Riyadh 11421, Saudi Arabia; [Kamel, Mohamed S.; Freeman, George H.] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada	King Saud University; University of Waterloo	Alajlan, N (corresponding author), King Saud Univ, Coll Engn, Dept Elect Engn, POB 800, Riyadh 11421, Saudi Arabia.	najlan@ksu.edu.sa; mkamel@uwaterloo.ca; G.Freeman@ece.uwaterloo.ca	Alajlan, Naif/A-3904-2008; Kamel, Mohamed S/D-9323-2011	Alajlan, Naif/0000-0003-1846-1131; Kamel, Mohamed/0000-0001-6173-8082				Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776; [Anonymous], 1985, PERCEPTUAL ORG VISUA; Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; CHANG CC, 1991, PATTERN RECOGN, V24, P675, DOI 10.1016/0031-3203(91)90034-3; CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923; Eakins JP, 1996, P SOC PHOTO-OPT INS, V2670, P17, DOI 10.1117/12.234792; Eakins JP, 2003, LECT NOTES COMPUT SC, V2728, P28; Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3; El Badawy O, 2002, INT C PATT RECOG, P461, DOI 10.1109/ICPR.2002.1047976; El-Kwae EA, 1999, ACM T INFORM SYST, V17, P174, DOI 10.1145/306686.306689; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; Freeman G., 2006, SHAPE RETRIEVAL USIN; GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041; Harary F., 1994, GRAPH THEORY; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; KIM WY, 1999, MPEG99M5472 ISOIEC; Kim YS, 1998, IMAGE VISION COMPUT, V16, P931, DOI 10.1016/S0262-8856(98)00060-2; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Ling HB, 2005, PROC CVPR IEEE, P719; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; Markman AB, 2000, AM J PSYCHOL, V113, P501, DOI 10.2307/1423470; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; MOKHTARIAN F, 1986, CURVATURE SCALE SPAC; Monasse P, 2000, J VIS COMMUN IMAGE R, V11, P224, DOI 10.1006/jvci.1999.0441; Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Peng HL, 1997, PATTERN RECOGN LETT, V18, P791, DOI 10.1016/S0167-8655(97)00050-0; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; Petrakis EGM, 2002, IMAGE VISION COMPUT, V20, P59, DOI 10.1016/S0262-8856(01)00077-4; Petrakis EGM, 2002, IEEE T KNOWL DATA EN, V14, P979, DOI 10.1109/TKDE.2002.1033768; Petrakis EGM, 1997, IEEE T KNOWL DATA EN, V9, P435, DOI 10.1109/69.599932; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Soffer A, 1998, INT C PATT RECOG, P571, DOI 10.1109/ICPR.1998.711207; THORISSON KR, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P876; Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146; Veltkamp RC, 2001, ADV PTRN RECOGNIT, P87; VELTKAMP RC, 2000, UUCS200034; Voorhees E. M., 1998, NIST SPECIAL PUBLICA; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008	46	111	129	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1003	1013		10.1109/TPAMI.2008.37	http://dx.doi.org/10.1109/TPAMI.2008.37			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421106				2022-12-18	WOS:000254872500006
J	Zhou, SK; Chellappa, R				Zhou, SK; Chellappa, R			From sample similarity to ensemble similarity: Probabilistic distance measures in reproducing kernel Hilbert space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ensemble similarity; kernel methods; Chernoff distance; Bhattacharyya distance; Kullback-Leibler (KL) divergence/relative entropy; Patrick-Fisher distance; Mahalonobis distance; reproducing kernel Hilbert space	COMPONENT ANALYSIS; SELECTION	This paper addresses the problem of characterizing ensemble similarity from sample similarity in a principled manner. Using reproducing kernel as a characterization of sample similarity, we suggest a probabilistic distance measure in the reproducing kernel Hilbert space ( RKHS) as the ensemble similarity. Assuming normality in the RKHS, we derive analytic expressions for probabilistic distance measures that are commonly used in many applications, such as Chernoff distance ( or the Bhattacharyya distance as its special case), Kullback- Leibler divergence, etc. Since the reproducing kernel implicitly embeds a nonlinear mapping, our approach presents a new way to study these distances whose feasibility and efficiency is demonstrated using experiments with synthetic and real examples. Further, we extend the ensemble similarity to the reproducing kernel for ensemble and study the ensemble similarity for more general data representations.	Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA; Univ Maryland, Dept Elect & Comp Engn, UMIACS, College Pk, MD 20742 USA; Univ Maryland, Ctr Automat Res, UMIACS, College Pk, MD 20742 USA	Siemens AG; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Zhou, SK (corresponding author), Siemens Corp Res, Integrated Data Syst Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.	kzhou@scr.siemens.com; rama@cfar.umd.edu	Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012					Adhikari B.P., 1956, PUBLICATIONS I STATI, V5, P57; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; BACH F, 2002, NEURAL INFORMATION P; BACH FR, 2002, J MACHINE LEARNING R, V3, P1; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Collins M, 2002, ADV NEUR IN, V14, P625; CORTES C, 2003, P INT C AC SPEECH SI; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; JAAKKOLA T, 1999, P C NEUR INF PROC SY, V11; JEBARA T, 2003, P C LEARN THEOR COLT; JEBARA T, 2003, P IEEE INT C COMP VI; KONDON R, 2003, P INT C MACH LEARN I; Lee K.C., 2003, P IEEE CS C COMP VIS; LISSACK TSVI, 1976, IEEE T INFORM THEORY, V22, P34, DOI 10.1109/TIT.1976.1055512; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Mahalanobis, 1936, P NATL I SCI INDIA, V2, P49; Mardia KV, 1979, MULTIVARIATE ANAL; MATUSITA K, 1955, ANN MATH STAT, V26, P631, DOI 10.1214/aoms/1177728422; MORENO P, 2003, NEURAL INFORMATION P; PATRICK EA, 1969, IEEE T INFORM THEORY, V15, P577, DOI 10.1109/TIT.1969.1054354; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Seeger M, 2002, ADV NEUR IN, V14, P905; Shakhnarovich G., 2002, P EUR C COMP VIS; TIPPING M, 2001, NEURAL INFORMATION P; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TSUDA K, 2002, P C NEUR INF PROC SY, V14; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P72; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VASCONCELOS N, 2004, P EUR C COMP VIS; WOLF L, 2003, P IEEE CS C COMP VIS; WOLF L, 2003, J MACHINE LEARNING R, V4, P895; ZHANG Z, 2004, KHUSTCS40101; [No title captured]	41	111	120	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					917	929		10.1109/TPAMI.2006.120	http://dx.doi.org/10.1109/TPAMI.2006.120			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724586				2022-12-18	WOS:000236734400006
J	Fidler, S; Skocaj, D; Leonardis, A				Fidler, S; Skocaj, D; Leonardis, A			Combining reconstructive and discriminative subspace methods for robust classification and regression by subsampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						subspace methods; reconstructive methods; discriminative methods; robust classification; robust regression; subsampling; PCA; LDA; CCA; high-breakdown point classification; outlier detection; occlusion		Linear subspace methods that provide sufficient reconstruction of the data, such as PCA, offer an efficient way of dealing with missing pixels, outliers, and occlusions that often appear in the visual data. Discriminative methods, such as LDA, which, on the other hand, are better suited for classification tasks, are highly sensitive to corrupted data. We present a theoretical framework for achieving the best of both types of methods: An approach that combines the discrimination power of discriminative methods with the reconstruction property of reconstructive methods which enables one to work on subsets of pixels in images to efficiently detect and reject the outliers. The proposed approach is therefore capable of robust classification with a high-breakdown point. We also show that subspace methods, such as CCA, which are used for solving regression tasks, can be treated in a similar manner. The theoretical results are demonstrated on several computer vision tasks showing that the proposed approach significantly outperforms the standard discriminative methods in the case of missing pixels and images containing occlusions and outliers.	Univ Ljubljana, Fac Comp & Informat Sci, SL-1001 Ljubljana, Slovenia	University of Ljubljana	Fidler, S (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SL-1001 Ljubljana, Slovenia.	sanja.fidler@fri.uni-lj.si; danijel.skocaj@fri.uni-lj.si; ales.leonardis@fri.uni-lj.si						Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BORGA M, 1998, THESIS LINKOPING U S; BORGA M, 2001, P 9 EUR S ART NEUR N, P309; CHORK CY, 1992, J GEOCHEM EXPLOR, V43, P191, DOI 10.1016/0375-6742(92)90105-H; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Croux C, 2001, CAN J STAT, V29, P473, DOI 10.2307/3316042; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Dehon C, 2000, STUD CLASS DATA ANAL, P321; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gross R., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P481; Hawkins DM, 1997, J AM STAT ASSOC, V92, P136, DOI 10.2307/2291457; He XM, 2000, J MULTIVARIATE ANAL, V72, P151, DOI 10.1006/jmva.1999.1857; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hubert M, 2004, COMPUT STAT DATA AN, V45, P301, DOI 10.1016/S0167-9473(02)00299-2; Lee DD, 2001, ADV NEUR IN, V13, P556; Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830; Lu XG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P13; Mangasarian OL, 2000, IEEE T PATTERN ANAL, V22, P950, DOI 10.1109/34.877518; Marcialis GL, 2002, LNCS, P30; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Meer P, 2000, COMPUT VIS IMAGE UND, V78, P1, DOI 10.1006/cviu.1999.0833; Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X; NAYAR SK, 1996, EARLY VISUAL LEARNIN, P131; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Pires A.M., 2001, P INT C ROB STAT; Rousseeuw PJ., 1985, MATH STAT APPL, VB, P283; Samaria F., 1994, P 2 IEEE WORKSH APPL; STAINVAS I, UNPUB IMPROVING RECO; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1; Zhao W., 1998, FACE RECOGNITION THE, P73	34	111	117	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					337	350		10.1109/TPAMI.2006.46	http://dx.doi.org/10.1109/TPAMI.2006.46			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526421				2022-12-18	WOS:000234517900001
J	Barreto, JP; Araujo, H				Barreto, JP; Araujo, H			Geometric properties of central catadioptric line images and their application in calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						catadioptric; omnidirectional vision; projective geometry; lines; calibration		In central catadioptric systems, lines in a scene are projected to conic curves in the image. This work studies the geometry of the central catadioptric projection of lines and its use in calibration. It is shown that the conic curves where the lines are mapped possess several projective invariant properties. From these properties, it follows that any central catadioptric system can be fully calibrated from an image of three or more lines. The image of the absolute conic, the relative pose between the camera and the mirror, and the shape of the reflective surface can be recovered using a geometric construction based on the conic loci where the lines are projected. This result is valid for any central catadioptric system and generalizes previous results for paracatadioptric sensors. Moreover, it is proven that systems with a hyperbolic/elliptical mirror can be calibrated from the image of two lines. If both the shape and the pose of the mirror are known, then two line images are enough to determine the image of the absolute conic encoding the camera's intrinsic parameters. The sensitivity to errors is evaluated and the approach is used to calibrate a real camera.	Univ Coimbra, Inst Syst & Robot, Dept Elect & Comp Engn, P-3030 Coimbra, Portugal	Universidade de Coimbra	Barreto, JP (corresponding author), Univ Coimbra, Inst Syst & Robot, Dept Elect & Comp Engn, Polo 2, P-3030 Coimbra, Portugal.	jpbar@isr.uc.pt; helder@isr.uc.pt	Barreto, Joao P/I-2845-2012; Araujo, Helder/B-3554-2008	Barreto, Joao P/0000-0001-5220-9170; Araujo, Helder/0000-0002-9544-424X				Baker S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P35, DOI 10.1109/ICCV.1998.710698; BARRETO JP, 2003, P WORKSH OMN VIS CAM; BARRETO JP, 2002, P 8 INT S EXP ROB JU; BARRETO JP, 2003, THESIS U COIMBRA; BARRETO JP, 2003, P IEEE INT C COMP VI; Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241; Geyer Christopher, 2000, LNCS, P445, DOI DOI 10.1007/3-540-45053-X_29; LIEBOWITZ D, 2001, THESIS U OXFORD; Semple J. G., 1998, ALGEBRAIC PROJECTIVE; Sturm P, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P119, DOI 10.1109/OMNVIS.2000.853818; Svoboda T, 2002, INT J COMPUT VISION, V49, P23, DOI 10.1023/A:1019869530073; Zhang Zhengyou, 1995, 2676 INRIA	12	111	127	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1327	1333		10.1109/TPAMI.2005.163	http://dx.doi.org/10.1109/TPAMI.2005.163			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119270	Green Submitted			2022-12-18	WOS:000229700900012
J	Wang, JZ; Li, J; Gray, RM; Wiederhold, G				Wang, JZ; Li, J; Gray, RM; Wiederhold, G			Unsupervised multiresolution segmentation for images with low depth of field	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						content-based image retrieval; image region segmentation; low depth-of-field; wavelet; multiresolution image analysis	FOCUS; SHAPE	Unsupervised segmentation of images with law depth of field (DOF) is highly useful in various applications including image enhancement for digital cameras, target recognition, image indexing for content-based retrieval, and 3D microscopic image analysis. This paper describes a novel multiresolution image segmentation algorithm for low DOF images. The algorithm is designed to separate a sharply focused object-of-interest from other foreground or background objects. The algorithm is fully automatic in that all parameters are image independent. A multiscale approach based on high frequency wavelet coefficients and their statistics is used to perform context-dependent classification of individual blocks of the image. Unlike other edge-based approaches, our algorithm does not rely on the process of connecting object boundaries. The algorithm has achieved high accuracy when tested on more than 100 low DOF images. many with inhomogeneous foreground or background distractions. Compared with the state of the art algorithms, this new algorithm provides better accuracy at higher speed.	Penn State Univ, Sch Informat Sci & Technol, University Pk, PA 16801 USA; Penn State Univ, Dept Stat, University Pk, PA 16802 USA; Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Stanford University; Stanford University	Wang, JZ (corresponding author), Penn State Univ, Sch Informat Sci & Technol, 120 S Burrowes St, University Pk, PA 16801 USA.			Wang, James/0000-0003-4379-4173				Adams A., 1980, CAMERA; BOYKOV Y, 1998, P DARPA IU WORKSH; CARSON C, UNPUB SEGMENTATION U; DARELL T, 1990, PATTERN RECOGN LETT, V11, P787, DOI 10.1016/0167-8655(90)90032-W; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; GUPTA A, 1997, COMMUN ACM, V40, P69; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Krotkov EP, 1989, ACTIVE COMPUTER VISI; LI J, 2000, P 2000 ACM MULT C OC; LI J, 1998, P IEEE INT C IM  OCT; Ma WY, 1997, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.1997.609409; NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479; Noguchi M, 1996, MATH COMPUT MODEL, V24, P31, DOI 10.1016/0895-7177(96)00114-8; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; *STROEBEL L, 1990, BASIC PHOTOGRAPHIC M; SUBBARAO M, 1997, 3 DIMENSIONAL IMAGIN, V3, P14; Tsai DM, 1998, PATTERN RECOGN LETT, V19, P929, DOI 10.1016/S0167-8655(98)00078-6; Wang J., 1999, D LIB MAGAZINE, V5; Yim CH, 1998, IEEE T IMAGE PROCESS, V7, P1283, DOI 10.1109/83.709661; Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026	22	111	125	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					85	90		10.1109/34.899949	http://dx.doi.org/10.1109/34.899949			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA		Green Submitted			2022-12-18	WOS:000166316700008
J	Mangasarian, OL; Musicant, DR				Mangasarian, OL; Musicant, DR			Robust linear and support vector regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						support vector machines; regression; Huber M-estimator; kernel methods	HUBER M-ESTIMATOR; FINITE ALGORITHMS; PROGRAMS	The robust Huber M-estimator, a differentiable cost function that is quadratic for small errors and linear otherwise, is modeled exactly, in the original primal space of the problem, by an easily solvable simple convex quadratic program for both linear and nonlinear support vector estimators. Previous models were significantly more complex or formulated in the dual space and most involved specialized numerical algorithms for solving the robust Huber linear estimator [3], [6], [12], [13], [14], [23], [28]. Numerical test comparisons with these algorithms indicate the computational effectiveness of the new quadratic programming model for both linear and nonlinear support vector problems. Results are shown on problems with as many as 20,000 data points, with considerably faster running times on larger problems.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	University of Wisconsin System; University of Wisconsin Madison	Mangasarian, OL (corresponding author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.							Bartlett P., 1999, SHRINKING TUBE NEW S; Cherkassky V. S., 1998, LEARNING DATA CONCEP, V1st; CLARK DI, 1986, SIAM J SCI STAT COMP, V7, P72, DOI 10.1137/0907005; Cristianini N., 2000, INTRO SUPPORT VECTOR; EKBLOM H, 1988, BIT, V28, P123, DOI 10.1007/BF01934700; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Huber P., 1981, ROBUST STAT; Huber P. J., 1974, Proceedings on computational statistics, P165; *ILOG CPLEX DIV, 1999, ILOG CPLEX 6 5 REF M; Li W, 1998, SIAM J OPTIMIZ, V8, P457, DOI 10.1137/S1052623495293160; LI W, 1995, APPROXIMATION THEORY, V8, P325; MADSEN K, 1990, BIT, V30, P682, DOI 10.1007/BF01933216; Mangasarian O.L., 1994, NONLINEAR PROGRAMMIN; MANGASARIAN OL, 1979, SIAM J CONTROL OPTIM, V17, P745, DOI 10.1137/0317052; MANGASARIAN OL, 1987, SIAM J CONTROL OPTIM, V25, P583, DOI 10.1137/0325033; Mangasarian OL, 2000, ADV NEUR IN, P135; MANGASARIAN OL, 1999, 9902 U WISC DAT MIN; MANGASARIAN OL, 2000, IN PRESS APPL ALGORI; *MATHW INC, 1997, MATLAB APPL PROGR IN; *MATHW INC, 1992, MATLAB US GUID; MICHELOT C, 1994, APPL MATH OPT, V30, P203, DOI 10.1007/BF01189455; Murphy P.M., 1992, UCI REPOSITORY MACHI; Polyak B. T., 1987, INTRO OPTIMIZATION; SCHOLKOPF B, 1998, P 8 INT C ART NEUR N, P111; SHANNO DF, 1986, SIAM J SCI STAT COMP, V7, P86, DOI 10.1137/0907006; Smola A, 1999, LINEAR PROGRAMS AUTO; Smola A., 1996, THESIS TU MUNCHEN MU; Smola A. J, 1998, THESIS TU BERLIN GER; Street WN, 1998, J OPTIMIZ THEORY APP, V96, P259, DOI 10.1023/A:1022664513146; *US CENS BUR, AD DAT; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; WRIGHT SJ, 1999, P INT C COMPL PROBL; WRIGHT SJ, 2000, ANLMCSP8080400; DELVE DATA EVALUATIN	35	111	116	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					950	955		10.1109/34.877518	http://dx.doi.org/10.1109/34.877518			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY		Green Submitted			2022-12-18	WOS:000089741300003
J	Zramdini, A; Ingold, R				Zramdini, A; Ingold, R			Optical font recognition using typographical features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical font recognition; typographical features; font models; multivariate Bayesian classifier; document analysis; OCR		A new statistical approach based on global typographical features is proposed to the widely neglected problem of font recognition. It aims at the identification of the typeface, weight, slope and size of the text from an image block without any knowledge of the content of that text. The recognition is based on a multivariate Bayesian classifier and operates on a given set of known fonts. The effectiveness of the adopted approach has been experimented on a set of 280 fonts. Font recognition accuracies of about 97 percent were reached on high-quality images. In addition, rates higher than 99.9 percent were obtained for weight and slope detection. Experiments have also shown the system robustness to document language and text content and its sensitivity to text length.	Univ Fribourg, Inst Informat, CH-1700 Fribourg, Switzerland; A2i SA, Oron La Ville, Switzerland	University of Fribourg	Zramdini, A (corresponding author), Univ Fribourg, Inst Informat, CH-1700 Fribourg, Switzerland.			Ingold, Rolf/0000-0001-7738-133X				ANIGBOGU J, 1992, THESIS U NANCY 1; BAPST F, 1998, RIDT 98 4 INT C RAST; BAUERMEISTER B, 1991, MANUAL COMP TYPOGRAP; CHENEVOY Y, 1993, THESIS CRIN U NANCY; Chenzbraun A, 1995, J Am Soc Echocardiogr, V8, P1, DOI 10.1016/S0894-7317(05)80351-7; COOPERMAN B, 1997, SPIE, V3027, P50; DELUCA PG, 1991, PATTERN RECOGN, V24, P609, DOI 10.1016/0031-3203(91)90028-4; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Khoubyari S, 1996, COMPUT VIS IMAGE UND, V63, P66, DOI 10.1006/cviu.1996.0005; Kopec GE, 1993, IEEE T IMAGE PROCESS, V2, P510, DOI 10.1109/83.242359; MORRIS RA, 1992, PATTERN RECOGN, V25, P869, DOI 10.1016/0031-3203(92)90039-L; Nagy G, 1996, FROEHLICH KENT ENCY, V11, P473; Rubinstein R., 1988, DIGITAL TYPOGRAPHY I; SHI H, 1997, ICDAR 97, P39; ZRAMDINI A, 1995, THESIS U FRIBOURG	15	111	123	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					877	882		10.1109/34.709616	http://dx.doi.org/10.1109/34.709616			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700012
J	Hartley, RI				Hartley, RI			Kruppa's equations derived from the fundamental matrix	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						singular value decomposition; fundamental matrix; Kruppa's equations; camera calibration	SELF-CALIBRATION; CAMERA	The purpose of this note is to give a specific form for Kruppa's equations in terms of the Fundamental matrix. Kruppa's equations can be written explicitly in terms of the singular value decomposition (SVD) of the fundamental matrix.			Hartley, RI (corresponding author), GE CO,CORP RES & DEV,POB 8,SCHENECTADY,NY 12301, USA.			Hartley, Richard/0000-0002-5005-0191				FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; Golub G. H., 1996, MATRIX COMPUTATIONS; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; HARTLEY RI, 1994, LNCS SERIES, V825, P237; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; Kruppa E., 1913, SITZ BER AKAD WIS MN, V122, P1939; Luong Q. T., 1992, THESIS U PARIS SUD; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; MOONS T, 1994, LNCS, V825, P297; Press WH, 1988, NUMERICAL RECIPES C; Semple J.G, 1952, ALGEBRAIC PROJECTIVE	11	111	126	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					133	135		10.1109/34.574792	http://dx.doi.org/10.1109/34.574792			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800004
J	MURASE, H; NAYAR, SK				MURASE, H; NAYAR, SK			ILLUMINATION PLANNING FOR OBJECT RECOGNITION USING PARAMETRIC EIGENSPACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ILLUMINATION PLANNING; OBJECT RECOGNITION; CORRELATION; IMAGE COMPRESSION; PRINCIPAL COMPONENT ANALYSIS; APPEARANCE MATCHING; PARAMETRIC APPEARANCE REPRESENTATION; POSE INVARIANCE		This correspondence presents a novel approach to the problem of illumination planning for robust object recognition in structured environments. Given a set of objects, the goal is to determine the illumination For which the objects are most distinguishable in appearance from each other. Correlation is used as a measure of similarity between objects. For each object, a large number of images is automatically obtained by varying pose and illumination direction. Images of all objects, together, constitute the planning image set. The planning set is compressed using the Karhunen-Loeve transform to obtain a row-dimensional subspace, called the eigenspace. For each illumination direction, objects are represented as parametrized manifolds in eigenspace. The minimum distance between the manifolds of two objects represents similarity between tbe objects in the correlation sense. The optimal source direction is therefore one that maximizes the shortest distance between object manifolds. Several experiments have been conducted using real objects. Results produced by the illumination planner have been used to enhance the performance of an object recognition system.	COLUMBIA UNIV, DEPT COMP SCI, NEW YORK, NY 10027 USA	Columbia University	MURASE, H (corresponding author), NIPPON TELEGRAPH & TEL PUBL CORP, BASIC RES LABS, ATSUGI, KANAGAWA 24301, JAPAN.							BATCHELOR BG, 1993, SPIE P INTELLIGENT R, V1193; COWAN C, 1992, 18TH P ANN NSF C DES; COWAN CK, 1989, IEEE T ROBOTIC AUTOM, P509; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; MURASE H, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P31, DOI 10.1109/CVPR.1994.323807; MURASE H, IN PRESS IEEE T IMAG; MURASE H, 1992, NTT6527 TECH REP; MURASE H, 1981, T IECE J, V64; OJA E, 1983, SUBSPACE METHODS PAT; Press WH, 1988, NUMERICAL RECIPES C; Sakane S., 1990, Proceedings. IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90. Towards a New Frontier of Applications (Cat. No.90TH0332-7), P559, DOI 10.1109/IROS.1990.262440; TURK MA, 1991, JUN P IEEE C COMP VI, P586; YI S, 1990, THESIS U WASHINGTON; YI S, 1990, P INT C PATTERN RECO	14	111	114	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1219	1227		10.1109/34.387485	http://dx.doi.org/10.1109/34.387485			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500007
J	CHEN, SS; KELLER, JM; CROWNOVER, RM				CHEN, SS; KELLER, JM; CROWNOVER, RM			ON THE CALCULATION OF FRACTAL FEATURES FROM IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BOX DIMENSION; FRACTIONAL BROWNIAN MOTION; FRACTAL GEOMETRY; IMAGE FEATURES; MASS DENSITY FUNCTION; SCALE-INSENSITIVE MEASUREMENTS	NATURAL SCENES; TEXTURE; GEOMETRY	Fractal Geometry is becoming increasingly more important in the study of image characteristics. There are numerous methods available to estimate parameters from images of fractal surfaces. A very general technique to calculate numerous fractal features involves the estimation of the mass density function by box counting. In this correspondence, we analyze the box-counting method, establish a lower bound for the box size, and indicate how algorithms can be improved to give better estimates of fractal features of images. This provides a theoretical basis for a heuristic approach employed by Pickover and Khorasani.	UNIV MISSOURI, DEPT ELECT & COMP ENGN, COLUMBIA, MO 65211 USA; UNIV MISSOURI, DEPT MATH, COLUMBIA, MO 65211 USA	University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia	CHEN, SS (corresponding author), ALLIED BENDIX KING RADIO CORP, OLATHE, KS 66062 USA.							CHEN SS, 1990, ARTIF INTELL, V43, P199, DOI 10.1016/0004-3702(90)90085-E; Falconer K.J., 2014, FRACTAL GEOMETRY MAT, V3rd ed.; KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8; KELLER JM, 1987, IEEE T PATTERN ANAL, V9, P621, DOI 10.1109/TPAMI.1987.4767956; KELLER JM, 1988, P INTELLIGENT ROBOTS, P369; KUBE P, 1988, IEEE T PATTERN ANAL, V10, P704, DOI 10.1109/34.6779; LUNDAHL T, 1986, IEEE T MED IMAGING, V5, P152, DOI 10.1109/TMI.1986.4307764; Mandelbrot, 1982, FRACTAL GEOMETRY NAT, P394; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; Medioni G. G., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P25; Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557; PENTLAND A, 1983, P INT JOINT C ART IN, P973; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; PICKOVER CA, 1986, COMPUT GRAPH, V10, P51, DOI 10.1016/0097-8493(86)90068-3; Voss RF, 1985, SCALING PHENOMENA DI, P1, DOI DOI 10.1007/978-1-4757-1402-9_1	15	111	131	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					1087	1090		10.1109/34.254066	http://dx.doi.org/10.1109/34.254066			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775					2022-12-18	WOS:A1993MD77500011
J	PETROU, M; KITTLER, J				PETROU, M; KITTLER, J			OPTIMAL EDGE DETECTORS FOR RAMP EDGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CANNY EDGE DETECTOR; EDGE DETECTION; OPTIMAL FILTERS; RAMP EDGES; STEP EDGES		We argue that the best way to model an edge is by assuming an ideal mathematical function passed through a low pass filter and emersed in noise. Using techniques similar to those developed by Canny and Spacek, we derive optimal filters for ramp edges of various slopes. We also derive the optimal nonrecursive filter for ideal step edges as a limiting case of the filters for ramp edges. Because there are no step edges in images, we show that edge detection is improved when the ramp filter is used instead of the filters developed for step edges. For practical purposes we give in Table IV some convolution masks which can be used directly for edge detection without the need to go into the details of the subject.			PETROU, M (corresponding author), UNIV SURREY,DEPT ELECTR & ELECT ENGN,GUILDFORD GU2 5XH,SURREY,ENGLAND.							Boie R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P100; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CANNY J, 1983, MIT AI720 LAB TEC RE; COURANT R, 1953, METHODS MATH PHYSICS, V1; DERICHE R, 1987, INT J COMPUT VISION, V1; FIASCONARO JG, 1979, TOP APPL PHYS, V6, P69; LEE D, 1989, JUN P IEEE COMP SOC, P2; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7; SPACEK LA, 1986, THESIS U ESSEX; WILSON R, 1987, IMAGE SEGMENTATION U	11	111	123	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1991	13	5					483	491		10.1109/34.134047	http://dx.doi.org/10.1109/34.134047			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FQ207					2022-12-18	WOS:A1991FQ20700008
J	LINNAINMAA, S; HARWOOD, D; DAVIS, LS				LINNAINMAA, S; HARWOOD, D; DAVIS, LS			POSE DETERMINATION OF A 3-DIMENSIONAL OBJECT USING TRIANGLE PAIRS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									TECH RES CTR FINLAND,SF-00340 HELSINKI,FINLAND	VTT Technical Research Center Finland	LINNAINMAA, S (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742, USA.							BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; DAVIS LS, 1982, PATTERN RECOGN, V15, P277, DOI 10.1016/0031-3203(82)90030-9; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GANAPATHY S, 1984, 1ST P IEEE C ROB, P130; HARWOOD D, 1984, CARTR59 U MAR CEN AU; HUNG Y, 1985, COMPUT VISION GRAPHI; HUNG Y, 1984, CARTR65 U MAR CEN AU; Roberts L, 1965, MACHINE PERCEPTION 3; SILBERBERG TM, 1986, COMPUT VISION GRAPH, V35, P47, DOI 10.1016/0734-189X(86)90125-8; Stockman G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P742; [No title captured]	13	111	116	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					634	647		10.1109/34.6772	http://dx.doi.org/10.1109/34.6772			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500003
J	BACKER, E; JAIN, AK				BACKER, E; JAIN, AK			A CLUSTERING PERFORMANCE-MEASURE BASED ON FUZZY SET DECOMPOSITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48823	Michigan State University	BACKER, E (corresponding author), DELFT UNIV TECHNOL,INFORMAT THEORY GRP,DELFT,NETHERLANDS.							ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; [Anonymous], 1974, CLUSTER ANAL; BACKER E, 1978, CLUSTER ANAL OPTIMAL; Bezdek James C., 1974, J CYBERNETICS, V3, P58, DOI [DOI 10.1080/01969727308546047, 10.1080/01969727308546047]; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; DUBES RC, 1970, PATTERN RECOGNITION, V8, P247	6	111	121	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					66	75		10.1109/TPAMI.1981.4767051	http://dx.doi.org/10.1109/TPAMI.1981.4767051			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868919				2022-12-18	WOS:A1981LK11600007
J	Zhao, Q; Tan, P; Dai, Q; Shen, L; Wu, EH; Lin, SP				Zhao, Qi; Tan, Ping; Dai, Qiang; Shen, Li; Wu, Enhua; Lin, Stephen			A Closed-Form Solution to Retinex with Nonlocal Texture Constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Intrinsic images; retinex; nonlocal constraint; texture		We propose a method for intrinsic image decomposition based on retinex theory and texture analysis. While most previous methods approach this problem by analyzing local gradient properties, our technique additionally identifies distant pixels with the same reflectance through texture analysis, and uses these nonlocal reflectance constraints to significantly reduce ambiguity in decomposition. We formulate the decomposition problem as the minimization of a quadratic function which incorporates both the retinex constraint and our nonlocal texture constraint. This optimization can be solved in closed form with the standard conjugate gradient algorithm. Extensive experimentation with comparisons to previous techniques validate our method in terms of both decomposition accuracy and runtime efficiency.	[Zhao, Qi; Tan, Ping] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Dai, Qiang] Jilin Univ, Dept Comp Sci & Technol, Changchun 130021, Jilin, Peoples R China; [Shen, Li] Inst Infocomm Res, Dept Comp Graph & Interface, Singapore 138632, Singapore; [Wu, Enhua] Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Taipa, Peoples R China; [Wu, Enhua] Chinese Acad Sci, SKLCS IOS, Taipa, Peoples R China; [Lin, Stephen] Microsoft Res, Beijing 100080, Peoples R China	National University of Singapore; Jilin University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); University of Macau; Chinese Academy of Sciences; Microsoft	Zhao, Q (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.	eletp@nus.edu.sg; qiangd@jlu.edu.cn; lshen@i2r.a-star.edu.sg; ehwu@umac.mo; stevelin@microsoft.com			Singapore MOE [R-263-000-555-112, R-263-000-620-112]; China National Fundamental Research Grant 973 Program [2009CB320802]	Singapore MOE(Ministry of Education, Singapore); China National Fundamental Research Grant 973 Program(National Basic Research Program of China)	The authors thank all the reviewers for their helpful comments. This work is supported by the Singapore MOE Project R-263-000-555-112 and R-263-000-620-112, and China National Fundamental Research Grant 973 Program (2009CB320802).	AGRAWAL A, 2006, CVPR, V2, P2301; Bell M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P670, DOI 10.1109/ICCV.2001.937585; Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124; Grosse R., 2009, P IEEE INT C COMP VI; Jiang X., 2010, P EUR C COMP VIS; Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998; Land E., 1971, J OPT SOC AM A, V3, P1684; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Matsushita Y, 2004, LECT NOTES COMPUT SC, V3022, P274; Matsushita Y, 2003, PROC CVPR IEEE, P3; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Shen L., 2008, P IEEE C COMP VIS PA; Sinha P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P156, DOI 10.1109/ICCV.1993.378224; Tappen M.F., 2006, 2006 IEEE COMPUTER S, V2, P1992; Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	22	110	119	2	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1437	1444		10.1109/TPAMI.2012.77	http://dx.doi.org/10.1109/TPAMI.2012.77			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22450820				2022-12-18	WOS:000304138300014
J	Chavez, E; Figueroa, K; Navarro, G				Chavez, Edgar; Figueroa, Karina; Navarro, Gonzalo			Effective proximity retrieval by ordering permutations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	4th Mexican International Conference on Artificial Intelligence (MICAI 2005)	NOV 14-18, 2005	Monterrey, MEXICO			similarity searching; metric spaces; indexing methods; information search and retrieval; pattern recognition	METRIC-SPACES; SEARCH; QUERIES	We introduce a new probabilistic proximity search algorithm for range and K-nearest neighbor (K-NN) searching in both coordinate and metric spaces. Although there exist solutions for these problems, they boil down to a linear scan when the space is intrinsically high dimensional, as is the case in many pattern recognition tasks. This, for example, renders the K-NN approach to classification rather slow in large databases. Our novel idea is to predict closeness between elements according to how they order their distances toward a distinguished set of anchor objects. Each element in the space sorts the anchor objects from closest to farthest to it and the similarity between orders turns out to be an excellent predictor of the closeness between the corresponding elements. We present extensive experiments comparing our method against state-of-the-art exact and approximate techniques, both in synthetic and real, metric and nonmetric databases, measuring both CPU time and distance computations. The experiments demonstrate that our technique almost always improves upon the performance of alternative techniques, in some cases by a wide margin.	[Chavez, Edgar; Figueroa, Karina] Univ Michoacana, Fac Ciencias Fis & Matemat, Morelia 58000, Michoacan, Mexico; [Navarro, Gonzalo] Univ Chile, Dept Comp Sci, Santiago, Chile	Universidad Michoacana de San Nicolas de Hidalgo; Universidad de Chile	Chavez, E (corresponding author), Univ Michoacana, Fac Ciencias Fis & Matemat, Edificio B,Ciudad Univ, Morelia 58000, Michoacan, Mexico.	elchavez@fismat.umich.mx; karina@fismat.umich.mx; gnavarro@dcc.uchile.cl	Chavez, Edgar/M-4162-2019; Navarro, Gonzalo/J-3731-2016	Chavez, Edgar/0000-0002-0148-695X; 				AGGARWAL CC, 2001, P SIGMOD PODS, V1, P13; AGGARWAL CC, 2001, P 8 INT C DAT THEOR, P420; Arslan AN, 2000, J DISCRETE ALGORITHM, V1, P3; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Baeza-Yates R., 1994, Combinatorial Pattern Matching. 5th Annual Symposium, CPM 94. Proceedings, P198; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BRIN S, 1995, P 21 INT C VER LARG, P574; BURKHARD WA, 1973, COMMUN ACM, V16, P230, DOI 10.1145/362003.362025; BUSTOS B, 2003, J DISCRETE ALGORITHM, V2, P115; Chavez E, 2005, PATTERN RECOGN LETT, V26, P1363, DOI 10.1016/j.patrec.2004.11.014; Chavez E, 2003, INFORM PROCESS LETT, V85, P39, DOI 10.1016/S0020-0190(02)00344-7; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Chavez E, 2001, MULTIMED TOOLS APPL, V14, P113, DOI 10.1023/A:1011343115154; CHAVEZ E, 2004, P MEX INT C ART INT, P222; CHAVEZ E, 1999, P 6 STRING PROC INF; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Ciaccia P, 2002, ACM T DATABASE SYST, V27, P398, DOI 10.1145/582410.582412; Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P244, DOI 10.1109/ICDE.2000.839417; Clarkson KL, 1999, DISCRETE COMPUT GEOM, V22, P63, DOI 10.1007/PL00009449; DOHERYU K, 2004, P 12 EUR S ART NEUR; Duda R.O., 1973, J ROYAL STAT SOC SER; EGECIOGLU O, 2001, P C PRINC PRACT KNOW, P79; Fagin R, 2003, SIAM J DISCRETE MATH, V17, P134, DOI 10.1137/S0895480102412856; FIGUEROA K, 2006, P 5 WORKSH EFF EXP A, P279; HARMAN D, 1995, NIST SPECIAL PUBLICA, V500, P1; Hjaltason GR, 2003, ACM T DATABASE SYST, V28, P517, DOI 10.1145/958942.958948; HOWARTH P, 2005, P 27 EUR C INF RETR, P447; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Navarro G, 2002, VLDB J, V11, P28, DOI 10.1007/s007780200060; Paredes R, 2006, SIAM PROC S, P171; Paredes R, 2005, LECT NOTES COMPUT SC, V3772, P127; Paredes R, 2006, LECT NOTES COMPUT SC, V4007, P85; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Samet Hanan, 2005, FDN MULTIDIMENSIONAL; SKOPAL T, 2006, P INT C EXT DAT TECH, P718; TOUSSAINT GT, 1981, NATO ASI SERIES; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, P145, DOI 10.1016/0167-8655(86)90013-9; WHITE D, 1996, VCL96101 U CAL SAN D; YIANILOS P, 1999, P INT WORKSH ALG ENG; Yianilos P.N., 1999, LOCALLY LIFTING CURS; Zezula P., 2006, ADV DATABASE SYSTEMS, V32	44	110	114	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1647	1658		10.1109/TPAMI.2007.70815	http://dx.doi.org/10.1109/TPAMI.2007.70815			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	324FZ	18617721				2022-12-18	WOS:000257504400011
J	Bouguila, N; Ziou, D				Bouguila, Nizar; Ziou, Djemel			High-dimensional unsupervised selection and estimation of a finite generalized Dirichlet mixture model based on minimum message length	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						finite mixture models; generalized Dirichlet mixture; EM; information theory; MML; AIC; MDL; MMDL; LEC; data clustering; image database summarization; web mining	CLASSIFICATION; INFERENCE; NUMBER	We consider the problem of determining the structure of high-dimensional data without prior knowledge of the number of clusters. Data are represented by a finite mixture model based on the generalized Dirichlet distribution. The generalized Dirichlet distribution has a more general covariance structure than the Dirichlet distribution and offers high flexibility and ease of use for the approximation of both symmetric and asymmetric distributions. This makes the generalized Dirichlet distribution more practical and useful. An important problem in mixture modeling is the determination of the number of clusters. Indeed, a mixture with too many or too few components may not be appropriate to approximate the true model. Here, we consider the application of the minimum message length (MML) principle to determine the number of clusters. The MML is derived so as to choose the number of clusters in the mixture model that best describes the data. A comparison with other selection criteria is performed. The validation involves synthetic data, real data clustering, and two interesting real applications: classification of Web pages, and texture database summarization for efficient retrieval.	Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 1T7, Canada; Univ Sherbrooke, Fac Sci, Dept Informat, Sherbrooke, PQ J1K 2RI, Canada	Concordia University - Canada; University of Sherbrooke	Bouguila, N (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, 1455 Maisonneuve Blvd W,EV-007-632, Montreal, PQ H3G 1T7, Canada.	bouguila@ciise.concordia.ca; djemel.ziou@usherbrooke.ca	Bouguila, Nizar/AGN-5929-2022; Bouguila, Nizar/AAJ-2518-2020					Agusta Y., 2003, P 3 IASTED INT MULTI, P457; AGUSTA Y, 2003, P 16 AUSTR JOINT C A, P477; AGUSTA Y, 2002, P AUSTR JOINT C ART, P143; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Anderson E., 1935, B AM IRIS SOC, V59, P2; [Anonymous], 1990, P INT C COMP INF; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Baxter RA, 2000, STAT COMPUT, V10, P5, DOI 10.1023/A:1008928315401; Beckman R. J., 1978, Journal of Statistical Computation and Simulation, V7, P253, DOI 10.1080/00949657808810232; Bensmail H, 1997, STAT COMPUT, V7, P1, DOI 10.1023/A:1018510926151; Blake C., 1998, REPOSITORY MACHINE L; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bouguila N, 2004, INT C PATT RECOG, P280, DOI 10.1109/ICPR.2004.1334107; Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664; BOUGUILA N, 2005, P IEEE CS C COMP VI, P53; BOZDOGAN H, 1983, A831 U ILL QUANT MET; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Celeux G., 1992, STOCHASTICS STOCHAST, V41, P119, DOI DOI 10.1080/17442509208833797; Celeux G., 1986, COMPUT STAT Q, V2, P73; Comley JW, 2005, NEURAL INF PROCESS S, P265; CONNOR RJ, 1969, J AM STAT ASSOC, V64, P194, DOI 10.2307/2283728; Conway J. H., 1993, SPHERE PACKINGS LATT; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; EDWARDS RT, 1998, P 2 PAC AS C KNOWL D, P96; Everitt B., 1981, FINITE MIXTURE DISTR, P143; Figueiredo M. A. T., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P54; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fraley C., 1998, COMPUTER J, V41; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kaufman L., 2009, FINDING GROUPS DATA; Kherfi ML, 2003, J VIS COMMUN IMAGE R, V14, P428, DOI 10.1016/S1047-3203(03)00043-9; Kothari R, 1999, PATTERN RECOGN LETT, V20, P405, DOI 10.1016/S0167-8655(99)00008-2; McCallum AK, 1996, BOW TOOLKIT STAT LAN; McLachlan, 1997, EM ALGORITHM EXTENSI; Mclachlan G., 2000, WILEY SER PROB STAT; MCLACHLAN GJ, 1987, J R STAT SOC C-APPL, V36, P318; NEWSMAN S, 2001, P 7 IEEE INT C IMAG; NIBLACK W, 1993, 9203 IBM; OLIVER J, 1994, 205 MON U DEP COMP S; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Rao C.R., 1952, ADV STAT METHODS BIO; REAVEN GM, 1979, DIABETOLOGIA, V16, P17, DOI 10.1007/BF00423145; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553; Salton G., 1989, AUTOMATIC TEXT PROCE; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Scott D. W., 1983, Computer Science and Statistics: Proceedings of the Fifteenth Symposium on the Interface, P173; Sjolander K, 1996, COMPUT APPL BIOSCI, V12, P327; Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151; Smyth P, 2000, STAT COMPUT, V10, P63, DOI 10.1023/A:1008940618127; UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Wallace C. S., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future, P37; Wallace CS, 1999, COMPUT J, V42, P270, DOI 10.1093/comjnl/42.4.270; Wallace CS, 2000, STAT COMPUT, V10, P73, DOI 10.1023/A:1008992619036; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; Wallace CS, 1998, COMPUT J, V41, P602, DOI 10.1093/comjnl/41.8.602; Wallace CS, 2005, STAT INDUCTIVE INFER; WALLACE CS, 1997, P 28 S INT COMP SCI, P608; WALLACE CS, 1986, P 9 AUSTR COMP SCI C, P357; WALLACE CS, 1997, P 6 INT WORKSH ART I, P529; Wong TT, 1998, APPL MATH COMPUT, V97, P165, DOI 10.1016/S0096-3003(97)10140-0; Ziou D, 2004, INT C PATT RECOG, P68, DOI 10.1109/ICPR.2004.1334042	69	110	110	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1716	1731		10.1109/TPAMI.2007.1095	http://dx.doi.org/10.1109/TPAMI.2007.1095			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699918				2022-12-18	WOS:000248696100003
J	Manmatha, R; Rothfeder, JL				Manmatha, R; Rothfeder, JL			A scale space approach for automatically segmenting words from historical handwritten documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; document and text processing; document analysis; handwriting analysis; document indexing; smoothing; optical character recognition	RECOGNITION	Many libraries, museums, and other organizations contain large collections of handwritten historical documents, for example, the papers of early presidents like George Washington at the Library of Congress. The first step in providing recognition/retrieval tools is to automatically segment handwritten pages into words. State of the art segmentation techniques like the gap metrics algorithm have been mostly developed and tested on highly constrained documents like bank checks and postal addresses. There has been little work on full handwritten pages and this work has usually involved testing on clean artificial documents created for the purpose of research. Historical manuscript images, on the other hand, contain a great deal of noise and are much more challenging. Here, a novel scale space algorithm for automatically segmenting handwritten ( historical) documents into words is described. First, the page is cleaned to remove margins. This is followed by a gray-level projection profile algorithm for finding lines in images. Each line image is then filtered with an anisotropic Laplacian at several scales. This procedure produces blobs which correspond to portions of characters at small scales and to words at larger scales. Crucial to the algorithm is scale selection, that is, finding the optimum scale at which blobs correspond to words. This is done by finding the maximum over scale of the extent or area of the blobs. This scale maximum is estimated using three different approaches. The blobs recovered at the optimum scale are then bounded with a rectangular box to recover the words. A postprocessing filtering step is performed to eliminate boxes of unusual size which are unlikely to correspond to words. The approach is tested on a number of different data sets and it is shown that, on 100 sampled documents from the George Washington corpus of handwritten document images, a total error rate of 17 percent is observed. The technique outperforms a state-of-the-art gap metrics word-segmentation algorithm on this collection.	Univ Massachusetts, Ctr Intelligent Informat Retrieval, Dept Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Manmatha, R (corresponding author), Univ Massachusetts, Ctr Intelligent Informat Retrieval, Dept Comp Sci, 140 Governors Dr, Amherst, MA 01003 USA.	manmatha@cs.umass.edu; jrothfed@cs.umass.edu						BAIRD HS, 1990, IEEE T PATTERN ANAL, V12, P552, DOI 10.1109/34.56191; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; DUDA RO, 1968, AFIPS C P, P1139; Feldbach M., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P403; FLORACK LMJ, 1997, SYNTACTIC STRUCTURES; Govindaraju V, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P314, DOI 10.1109/DIAL.2004.1263260; HA J, 1995, P 3 INT C DOC AN REC, P1119; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Kim PA, 1999, J VASC INTERV RADIOL, V10, P37, DOI 10.1016/S1051-0443(99)70007-2; Koenderink Jan J, 1992, IMAGE VISION COMPUTI, V10; Lavrenko V, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P278, DOI 10.1109/DIAL.2004.1263256; Lindeberg T., 1994, SCALE SPACE THEORY C; Luttin J., 2000, P 7 INT WORKSH FRONT, P493; Mahadevan U., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P124, DOI 10.1109/ICDAR.1995.598958; Manmatha R, 1999, LECT NOTES COMPUT SC, V1682, P22; MANMATHA R, 1998, INTELLIGENT MULTIMED; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885; Marti UV, 2001, PROC INT CONF DOC, P101, DOI 10.1109/ICDAR.2001.953763; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056; SENI G, 1994, PATTERN RECOGN, V27, P41, DOI 10.1016/0031-3203(94)90016-7; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; Tomai CI, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P413, DOI 10.1109/IWFHR.2002.1030945; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; Weickert J, 1997, COMP IMAG VIS, V8, P45	30	110	119	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1212	1225		10.1109/TPAMI.2005.150	http://dx.doi.org/10.1109/TPAMI.2005.150			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119261	Green Submitted			2022-12-18	WOS:000229700900003
J	Guy, G; Medioni, G				Guy, G; Medioni, G			Inference of surfaces, 3D curves, and junctions from sparse, noisy, 3D data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation and feature extraction; human visual perception issues; isosurface extraction	REGULARIZATION	We address the problem of obtaining dense surface information from a sparse set of 3D data in the presence of spurious noise samples. The input can be in the form of points, or points with an associated tangent or normal, allowing both position and direction to be corrupted by noise. Most approaches treat the problem as an interpolation problem, which is solved by fitting a surface such as a membrane or thin plate to minimize some function. We argue that these physical constraints are not sufficient, and propose to impose additional perceptual constraints such as good continuity and ''cosurfacity.'' These constraints allow us to not only infer surfaces, but also to detect surface orientation discontinuities, as well as junctions, all at the same time. The approach Imposes no restriction on genus, number of discontinuities, number of objects, and is noniterative. The result is in the form of three dense saliency maps for surfaces, intersections between surfaces (i.e., 3D curves), and 3D junctions, respectively. These saliency maps are then used to guide a ''marching'' process to generate a description (e.g., a triangulated mesh) making information about surfaces, space curves, and 3D junctions explicit. The traditional marching process needs to be refined as the polarity of the surface orientation is not necessarily locally consistent. These three maps are currently not integrated, and this is the topic of our ongoing research. We present results on a variety of computer-generated and real data, having varying curvature, of different genus, and multiple objects.	UNIV SO CALIF, INST ROBOT & INTELLIGENT SYST, LOS ANGELES, CA 90089 USA	University of Southern California								AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; Boissonnat J. D., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P830; BOULT TE, 1986, JUN P IEEE C COMP VI, P68; DOLAN J, 1989, P IMAGE UNDERSTANDIN, P1135; FUA P, 1992, P EUR C COMP VIS SAN, P676; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; GUY G, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P99, DOI 10.1109/ICPR.1992.201517; GUY G, THESIS U SO CALIFORN; HAN S, 1996, P IEEE VISUALIZATION, P295; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LIAO C, 1994, CAD94 WORKSH PITTSB; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; MOHAN R, 1989, JUN P IEEE C COMP VI, P333; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Sinha S. S., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P44, DOI 10.1109/CVPR.1991.139659; Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P82, DOI 10.1109/CVPR.1993.340975; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; Vaidya N. M., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P115, DOI 10.1109/ISCV.1995.476987	24	110	119	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1265	1277		10.1109/34.632985	http://dx.doi.org/10.1109/34.632985			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585		Green Submitted			2022-12-18	WOS:A1997YG58500007
J	AZARBAYEJANI, A; STARNER, T; HOROWITZ, B; PENTLAND, A				AZARBAYEJANI, A; STARNER, T; HOROWITZ, B; PENTLAND, A			VISUALLY CONTROLLED GRAPHICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EGOMOTION; HEAD TRACKING; KALMAN FILTER; STRUCTURE FROM MOTION; TELECONFERENCING; VIRTUAL HOLOGRAPHY	OBJECT; IMAGES	This correspondence discusses interactive graphics systems driven by visual input. It describes the underlying computer vision techniques and presents a theoretical formulation that addresses issues of accuracy, computational efficiency, and compensation for display latency. Experimental results quantitatively compare the accuracy of the visual technique with traditional sensing. An extension to the basic technique to include structure recovery is discussed.			AZARBAYEJANI, A (corresponding author), MIT,MEDIA LAB,CAMBRIDGE,MA 02139, USA.							AZARBAYEJANI AJ, 1991, TEHSIS MIT; AZARBAYEJANI AJ, 1993, 1993 P IEEE C COMP V; BROIDA TJ, 1991, IEEE T PATTERN ANAL, V13, P497, DOI 10.1109/34.87338; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; Brown R. G., 1983, INTRO RANDOM SIGNAL; DICKMANNS ED, 1988, MACH VISION APPL, V1, P223; FAUGERAS O, 1989, INT J ROBOTICS RES; FRIEDMANN M, 1993, VIRTUAL REALITY SYST, pCH9; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; LUCAS BD, 1981, 7TH P INT JOINT C AR; Pentland A., 1989, Computer Graphics, V23, P215, DOI 10.1145/74334.74355	11	110	190	0	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					602	605		10.1109/34.216730	http://dx.doi.org/10.1109/34.216730			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700009
J	UNSER, M; ALDROUBI, A; EDEN, M				UNSER, M; ALDROUBI, A; EDEN, M			THE L(2) POLYNOMIAL SPLINE PYRAMID	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BINOMIAL FILTERS; B-SPLINES; DECIMATION; INTERPOLATION; MULTIGRID METHODS; MULTIRESOLUTION; POLYNOMIAL SPLINES; PYRAMID; RECURSIVE FILTERS; SCALE SPACE; SIGNAL APPROXIMATION; SPLINE FILTERS; WAVELET TRANSFORM	SCALE-SPACE; INTERPOLATION; ALGORITHMS; REPRESENTATION; SIGNALS; IMAGES	The first part of this paper is concerned with the derivation of general methods for the L2 approximation of signals by polynomial splines. Such approximations can be represented in a variety of ways using different sets of shift-invariant basis functions (e.g., cardinal, dual, orthogonal or standard B-splines). The main result is that the expansion coefficients of the approximation are obtained by linear filtering and sampling. The second part applies those results to construct a L2 polynomial spline pyramid that is a parametric multiresolution representation of a signal. This hierarchical data structure is generated by repeated application of a REDUCE function (prefilter and down-sampler). A complementary EXPAND function (up-sampler and post-filter) allows a finer resolution mapping of any coarser level of the pyramid. Four equivalent representations of this pyramid are considered, and the corresponding REDUCE and EXPAND filters are determined explicitly for polynomial splines of any order n (odd). Some image processing examples are presented. The present formulation provides a number of interesting links with several other multiresolution techniques including the wavelet transform, scale-space filtering, and Burt's Gaussian and Laplacian pyramids. In particular, we demonstrate that the performance of the Laplacian pyramid can be improved significantly by using a modified EXPAND function associated with the dual representation of a cubic spline pyramid.			UNSER, M (corresponding author), NIH, NATL CTR RES RESOURCES, BIOMED ENGN & INSTRUMENTAT PROGRAM, BETHESDA, MD 20892 USA.		Aldroubi, Akram/J-7186-2012; Unser, Michael/A-1550-2008					ALDROUBI A, 1992, SIGNAL PROCESS, V28, P127, DOI 10.1016/0165-1684(92)90030-Z; ALDROUBI A, 1990, NOV P INT S INF THEO, P271; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; CHUI CK, 1992, T AM MATH SOC, V330, P903, DOI 10.2307/2153941; CROCHIERE RE, 1981, P IEEE, V69, P300, DOI 10.1109/PROC.1981.11969; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P212, DOI 10.1109/TPAMI.1984.4767504; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; HACKBUSCH W., 1985, SPRINGER SER COMPUT, V4; HARLOW CA, 1973, IEEE T COMPUT, VC 22, P678, DOI 10.1109/TC.1973.5009135; Horn B., 1986, ROBOT VISION, P1; JERRI AJ, 1977, P IEEE, V65, P1565, DOI 10.1109/PROC.1977.10771; LEMARIE PG, 1988, J MATH PURE APPL, V67, P227; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Pratt W. K., 1978, DIGITAL IMAGE PROCES; Prenter PM., 1975, SPLINES VARIATIONAL; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Schoenberg I., 1969, J APPROXIMATION THEO, V2, P167; Schoenberg I.J., 1973, CARDINAL SPLINE INTE, DOI [10.1137/1.9781611970555, DOI 10.1137/1.9781611970555]; SCHOENBERG IJ, 1946, Q APPL MATH, V4, P112, DOI 10.1090/qam/16705; SCHOENBERG IJ, 1946, Q APPL MATH, V4, P45, DOI 10.1090/qam/15914; SCHOENBERG IJ, 1973, ISR J MATH, V16, P87, DOI 10.1007/BF02761973; Schumaker L. L., 1981, SPLINE FUNCTIONS BAS; Stuart A., 1987, KENDALLS ADV THEORY, V1; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515; UNSER M, 1992, IEEE T INFORM THEORY, V38, P95, DOI 10.1109/18.108253; UNSER M, 1992, IEEE T INFORM THEORY, V38, P864, DOI 10.1109/18.119742; UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466; UNSER M, 1990, NCRR15390 NIH REP; UNSER M, 1984, THESIS SWISS FED I T; VETTERLI M, 1984, SIGNAL PROCESS, V6, P97, DOI 10.1016/0165-1684(84)90012-4; WITKIN AP, 1983, 4TH P INT JOINT C AR, P1019; WOODS JW, 1986, IEEE T ACOUST SPEECH, V34, P1278, DOI 10.1109/TASSP.1986.1164962; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	44	110	121	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1993	15	4					364	379		10.1109/34.206956	http://dx.doi.org/10.1109/34.206956			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU543					2022-12-18	WOS:A1993KU54300004
J	MONTANVERT, A; MEER, P; ROSENFELD, A				MONTANVERT, A; MEER, P; ROSENFELD, A			HIERARCHICAL IMAGE-ANALYSIS USING IRREGULAR TESSELLATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONNECTED COMPONENTS; IMAGE PYRAMIDS; IMAGE SEGMENTATION; IRREGULAR TESSELLATIONS; MULTIRESOLUTION TECHNIQUES		We present a novel multiresolution image analysis technique based on hierarchies of irregular tessellations generated in parallel by independent stochastic processes. Like the "traditional" image pyramids these hierarchies are constructed in on the order of log(image-size) steps. However, the structure of a hierarchy is adapted to the image content and artifacts of rigid resolution reduction are avoided. We give two applications of our technique: connected component analysis of labeled images, and segmentation of gray level images. In labeled images, every connected component is reduced to a separate root, with the adjacency relations among the components also extracted. In gray level images the output is a segmentation of the image into a small number of classes as well as the adjaceny graph of the classes.	RUTGERS STATE UNIV,DEPT ELECT & COMP ENGN,NEW BRUNSWICK,NJ 08903; UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	Rutgers State University New Brunswick; University System of Maryland; University of Maryland College Park	MONTANVERT, A (corresponding author), UNIV JOSEPH FOURIER GRENOBLE 2,TIM3 LAB,EQUIPE RFMQ,IMAG GRP,POB 53X,F-38041 GRENOBLE,FRANCE.							Adelson E. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P50, DOI 10.1117/12.976485; AHUJA N, 1983, COMPUT VISION GRAPH, V24, P200, DOI 10.1016/0734-189X(83)90043-9; BALLARD DH, 1986, BEHAV BRAIN SCI, V9, P67, DOI 10.1017/S0140525X00021555; BARONTI S, 1990, COMPUT VISION GRAPH, V49, P346, DOI 10.1016/0734-189X(90)90108-8; BISTER M, 1989, IRISTR0006 VRIJ U IN; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; BURT PJ, 1980, COMPUT GRAPHICS IMAG, V14, P171; CANTONI V, 1986, PYRAMIDAL SYSTEMS CO; CHASSERY JM, 1989, 6TH P SCAND C IM AN, P408; CIBULSKIS J, 1984, MULTIRESOLUTION IMAG, P109; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P212, DOI 10.1109/TPAMI.1984.4767504; DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; GROSS AD, 1987, COMPUT VISION GRAPH, V39, P102, DOI 10.1016/S0734-189X(87)80204-9; HARTMAN NP, 1984, IEEE T SYST MAN CYB, V14, P247, DOI 10.1109/TSMC.1984.6313207; HARWOOD D, 1987, PATTERN RECOGN, V6, P115; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P222, DOI 10.1109/TPAMI.1984.4767505; JOLION JM, 1989, 7TH P RFIA C PAR, P197; KROPATSCH WG, 1985, PATTERN RECOGN LETT, V3, P315, DOI 10.1016/0167-8655(85)90062-5; KROPATSCH WG, 1987, PATTERN RECOGN LETT, V6, P179, DOI 10.1016/0167-8655(87)90005-5; LI M, 1982, COMPUT VISION GRAPH, V20, P72, DOI 10.1016/0146-664X(82)90074-0; LUBY M, 1985, 17TH P ANN ACM S THE, P1; MEER P, 1989, PATTERN RECOGN, V22, P189, DOI 10.1016/0031-3203(89)90065-4; MEER P, 1989, COMPUT VISION GRAPH, V45, P269, DOI 10.1016/0734-189X(89)90084-4; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; MILLER R, 1987, SIAM J COMPUT, V16, P38, DOI 10.1137/0216004; Miller R., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P912, DOI 10.1109/CVPR.1988.196341; Minsky M., 1988, PERCEPTRONS; PELEG S, 1987, PARALLEL COMPUTER VI, P125; ROM H, 1988, JUN P IEEE COMP SOC, P282; Ronse C, 1984, CONNECTED COMPONENTS; Rosenfeld A., 1987, INT J PATTERN RECOGN, V1, P71; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; SHAFFER CA, 1988, PATTERN RECOGN LETT, V7, P45, DOI 10.1016/0167-8655(88)90043-8; Tanimoto S. L., 1976, Computer Graphics and Image Processing, V5, P333, DOI 10.1016/S0146-664X(76)80012-3; UHR L, 1987, PARALLEL COMPUTER VI; [No title captured], DOI DOI 10.1145/356924.356930	36	110	116	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					307	316		10.1109/34.88566	http://dx.doi.org/10.1109/34.88566			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600001
J	TAGARE, HD; DEFIGUEIREDO, RJP				TAGARE, HD; DEFIGUEIREDO, RJP			A THEORY OF PHOTOMETRIC STEREO FOR A CLASS OF DIFFUSE NON-LAMBERTIAN SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MACHINE VISION; NON-LAMBERTIAN REFLECTION; PHOTOMETRIC STEREO; REFLECTANCE MAPS; SHAPE FROM SHADING	DEPENDENT SCATTERING; RADIATIVE-TRANSFER; SPECULAR SURFACES; PARTICLES	Photometric stereo is a method of reconstructing a surface from the amount of light reflected by it. This is done by using prior knowledge of the surface reflectance to estimate the surface normal at all visible points. The theory of photometric stereo has been extensively developed for surfaces and illumination geometries that give rise to a Lambertian reflectance map. For non-Lambertian reflectance maps, the theory has been developed for specific cases, but a general theory has not been presented in the literature. In this paper, we propose a theory of photometric stereo for a large class of non-Lambertian reflectance maps. First, we review the different reflectance maps proposed in the literature for modeling reflection from real-world surfaces. From this, we obtain a mathematical class of reflectance maps to which the maps belong. Next, we show that three lights can be sufficient for a unique inversion of the photometric stereo equation for the entire class of reflectance maps. We also obtain a constraint on the positions of light sources for obtaining this solution. Next, we investigate the sufficiency of three light sources to estimate the surface normal and the illuminant strength. Finally, we address the issue of completeness of reconstruction. We show that if k lights are sufficient for a unique inversion, 2k lights are necessary for a complete inversion.	YALE UNIV, DEPT ELECT ENGN, NEW HAVEN, CT 06510 USA; UNIV CALIF IRVINE, DEPT MATH, IRVINE, CA 92717 USA; UNIV CALIF IRVINE, INTELLIGENT SENSORS & SYST LAB, IRVINE, CA 92717 USA	Yale University; University of California System; University of California Irvine; University of California System; University of California Irvine	TAGARE, HD (corresponding author), YALE UNIV, DEPT DIAGNOST RADIOL, NEW HAVEN, CT 06510 USA.							Baltes H., 1980, INVERSE SCATTERING P, V20; BECKMANN P, 1965, IEEE T ANTENN PROPAG, VAP13, P384, DOI 10.1109/TAP.1965.1138443; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; BIRKEBAK RC, 1965, J HEAT TRANSFER  FEB, P85; BRANDENB.WM, 1966, J OPT SOC AM, V56, P97, DOI 10.1364/JOSA.56.000097; BROCKELMAN RA, 1966, IEEE T ANTENN PROPAG, VAP14, P621, DOI 10.1109/TAP.1966.1138758; CARTIGNY JD, 1986, J HEAT TRANS-T ASME, V108, P608, DOI 10.1115/1.3246979; CHANDRASEDKAR S, 1960, RAD HEAT TRANSFER; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; NAYAR SK, 1989, CMURITR897 CARN U RO; NAYAR SK, 1988, CMURITR8814 CARN U R; Nicodemus F. E., 1978, Geometrical considerations and nomenclature for reflectance; ONeill B., 1966, ELEMENTARY DIFFERENT; ONN R, COMMUNICATION; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; PHONG BT, 1975, COMMUN ASS COMPUT MA, V18; RAY R, 1983, IEEE T PATTERN ANAL, V5, P631, DOI 10.1109/TPAMI.1983.4767454; REICHMAN J, 1973, APPL OPTICS, V12, P1811, DOI 10.1364/AO.12.001811; Siegel R., 2001, THERMAL RAD HEAT TRA, V4th; Silver W.M., 1980, THESIS MIT; SMITH BG, 1967, IEEE T ANTENN PROPAG, VAP15, P668, DOI 10.1109/TAP.1967.1138991; Stone J. M., 1963, RAD OPTICS; TAGARE HD, 1990, P INT C COMPUTER VIS; TAGARE HD, UNPUB COMPUT VISION; TAGARE HD, 1988, EE8816 RIC U TECH RE; TAGARE HD, 1989, THESIS RICE U HOUSTO; TAGARE HD, IN PRESS PHOTOMETRIC; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531; VAN DE HULST H C, 1981, LIGHT SCATTERING SMA, P496; WOLFF LB, 1987, P IMAGE UNDERSTANDIN, V2, P810; WOODHAM RJ, 1978, MIT457 AI LAB TECH R; YAMADA Y, 1986, J HEAT TRANS-T ASME, V108, P614, DOI 10.1115/1.3246980; ZHENG Q, 1990, ROBUST ALGORITHM INF	37	110	114	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					133	152		10.1109/34.67643	http://dx.doi.org/10.1109/34.67643			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900003
J	JANG, BK; CHIN, RT				JANG, BK; CHIN, RT			ANALYSIS OF THINNING ALGORITHMS USING MATHEMATICAL MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											JANG, BK (corresponding author), UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706, USA.		Chin, Roland Tai Hong/E-9856-2010					ARCELLI C, 1975, ELECTRON LETT, V11, P148, DOI 10.1049/el:19750113; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1964, P S MODELS PERCEPTIO; CHIN RT, 1987, COMPUT VISION GRAPH, V40, P30, DOI 10.1016/0734-189X(87)90054-5; CRIMMINS TR, 1985, IEEE T AERO ELEC SYS, V21, P60, DOI 10.1109/TAES.1985.310539; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Hilditch C J, 1983, IMAGE VISION COMPUT, V1, P115, DOI DOI 10.1016/0262-8856(83)90063-X; Hilditch C.J., 1969, MACH INTELL, P403; Lantuejoul C., 1980, ISSUES DIGITAL IMAGE; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; MATHERON G., 1975, RANDOM SETS INTEGRAL; MEYER F, 1988, IMAGE ANAL MATH MORP; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; Pavlidis T., 1977, STRUCTURAL PATTERN R; ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Serra J, 1982, IMAGE ANAL MATH MORP; STERNBERG SR, 1983, 3RD P IEEE INT COMP, P22; Sternberg SR, 1983, IEEE T COMPUT, V32, P22; TAMURA H, 1978, 4TH P INT JOINT C PA, P715	23	110	126	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					541	551		10.1109/34.56190	http://dx.doi.org/10.1109/34.56190			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300003
J	KELLER, JM; CROWNOVER, RM; CHEN, RY				KELLER, JM; CROWNOVER, RM; CHEN, RY			CHARACTERISTICS OF NATURAL SCENES RELATED TO THE FRACTAL DIMENSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MISSOURI, DEPT MATH, COLUMBIA, MO 65211 USA	University of Missouri System; University of Missouri Columbia	KELLER, JM (corresponding author), UNIV MISSOURI, DEPT ELECT & COMP ENGN, COLUMBIA, MO 65211 USA.							Adler R. J., 1981, GEOMETRY RANDOM FIEL; BURROUGH PA, 1981, NATURE, V294, P240, DOI 10.1038/294240a0; BURROUGH PA, 1984, B I MATH ITS APPLICA, V20, P36; CROWNOVER RM, 1984, FRACTAL FEATURES IMA; Mandelbrot, 1983, FRACTAL GEOMETRY NAT; Mandelbrot B.B., 1977, FRACTALS FORM CHANCE; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; PALEY R, 1934, AM MATH SOC C PUBL, V19; Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557; PENTLAND A, 1983, AUG P IJCAI 83 KARLS; PENTLAND A, 1984, AUG P NAT C AI AUST, P269; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; Smith A. R., 1984, Computers & Graphics, V18, P1; Wiener N, 1930, ACTA MATH-DJURSHOLM, V55, P117, DOI 10.1007/BF02546511	14	110	118	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					621	627		10.1109/TPAMI.1987.4767956	http://dx.doi.org/10.1109/TPAMI.1987.4767956			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869420				2022-12-18	WOS:A1987J739300003
J	MURAKAMI, H; KUMAR, BVKV				MURAKAMI, H; KUMAR, BVKV			EFFICIENT CALCULATION OF PRIMARY IMAGES FROM A SET OF IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CARNEGIE MELLON UNIV, DEPT ELECT ENGN, PITTSBURGH, PA 15213 USA	Carnegie Mellon University	MURAKAMI, H (corresponding author), TOSHIBA CORP, RES & DEV SECT, YANAGICHO WORKS, KAWASAKI 210, JAPAN.			Bhagavatula, Vijayakumar/0000-0001-7126-6381				CHIEN YT, 1967, IEEE T INFORM THEORY, V13, P518, DOI 10.1109/TIT.1967.1054021; FUKUNAGA K, 1970, INFORM CONTROL, V16, P85, DOI 10.1016/S0019-9958(70)80043-2; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HABIBI A, 1971, IEEE T COMMUN TECHN, VCO19, P948, DOI 10.1109/TCOM.1971.1090776; MCLAUGHLIN JA, 1968, INFORM CONTROL, V12, P121, DOI 10.1016/S0019-9958(68)90241-6; READY PJ, 1973, IEEE T COMMUN, VCO12, P1123, DOI 10.1109/TCOM.1973.1091550; WINTZ PA, 1972, PR INST ELECTR ELECT, V60, P809, DOI 10.1109/PROC.1972.8780; WONG RY, 1977, IEEE T SYST MAN CYB, V7, P836, DOI 10.1109/TSMC.1977.4309639	8	110	112	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					511	515		10.1109/TPAMI.1982.4767295	http://dx.doi.org/10.1109/TPAMI.1982.4767295			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PG894	21869070				2022-12-18	WOS:A1982PG89400007
J	Maninis, KK; Caelles, S; Chen, YH; Pont-Tuset, J; Leal-Taixe, L; Cremers, D; Van Gool, L				Maninis, Kevis-Kokitsi; Caelles, Sergi; Chen, Yuhua; Pont-Tuset, Jordi; Leal-Taixe, Laura; Cremers, Daniel; Van Gool, Luc			Video Object Segmentation without Temporal Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video object segmentation; convolutional neural networks; semantic segmentation; instance segmentation		Video Object Segmentation, and video processing in general, has been historically dominated by methods that rely on the temporal consistency and redundancy in consecutive video frames. When the temporal smoothness is suddenly broken, such as when an object is occluded, or some frames are missing in a sequence, the result of these methods can deteriorate significantly. This paper explores the orthogonal approach of processing each frame independently, i.e., disregarding the temporal information. In particular, it tackles the task of semi-supervised video object segmentation: the separation of an object from the background in a video, given its mask in the first frame. We present Semantic One-Shot Video Object Segmentation (OSVOSS), based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence (hence one shot). We show that instance-level semantic information, when combined effectively, can dramatically improve the results of our previous method, OSVOS. We perform experiments on two recent single-object video segmentation databases, which show that OSVOSS is both the fastest and most accurate method in the state of the art. Experiments on multi-object video segmentation show that OSVOSS obtains competitive results.	[Maninis, Kevis-Kokitsi; Caelles, Sergi; Chen, Yuhua; Pont-Tuset, Jordi; Van Gool, Luc] ETHZ, CH-8092 Zurich, Switzerland; [Leal-Taixe, Laura; Cremers, Daniel] TUM, D-80333 Munich, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; Technical University of Munich	Maninis, KK (corresponding author), ETHZ, CH-8092 Zurich, Switzerland.	kmaninis@vision.ee.ethz.ch; scaelles@vision.ee.ethz.ch; yuhua.chen@vision.ee.ethz.ch; jponttuset@vision.ee.ethz.ch; leal.taixe@tum.de; cremers@tum.de; vangool@vision.ee.ethz.ch	Leal-Taixe, Laura/HFZ-8079-2022	Leal-Taixe, Laura/0000-0001-8709-1133; Chen, Yuhua/0000-0002-1278-4960	EU Framework Programme for Research and Innovation Horizon 2020 [645331]; Swiss Commission for Technology and Innovation (CTI, NeGeVA) [19015.1 PFES-ES]; armasuisse	EU Framework Programme for Research and Innovation Horizon 2020; Swiss Commission for Technology and Innovation (CTI, NeGeVA); armasuisse	Research funded by the EU Framework Programme for Research and Innovation Horizon 2020 (Grant No. 645331, EurEyeCase), and by the Swiss Commission for Technology and Innovation (CTI, Grant No. 19015.1 PFES-ES, NeGeVA). The authors gratefully acknowledge support by armasuisse and thank NVidia Corporation for donating the GPUs used in this project. K.-K. Maninis and S. Caelles contributed equally.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392; Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Chang J, 2013, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2013.267; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Faktor A., 2014, P BMVC, V2, P8; Fan QN, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818105; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Hane C, 2013, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2013.20; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hopwood Henry V., 1899, LIVING PICTURES THEI; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336; JANG WD, 2017, PROC CVPR IEEE, P7474, DOI DOI 10.1109/CVPR.2017.790; Khoreva A., 2017, P DAVIS CHALL VID OB; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Kokkinos I.., 2016, P 4 INT C LEARN REPR, P1; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le T.-N., 2017, P DAVIS CHALL VID OB; Li X., 2017, 2017 DAVIS CHALL VID; Li Yi, 2017, P IEEE C COMP VIS PA; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17; Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35; Nair V, 2010, P 27 INT C MACHINE L, P807; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Pont-Tuset J., 2017, ARXIV170400675; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Romera-Paredes B, 2016, LECT NOTES COMPUT SC, V9910, P312, DOI 10.1007/978-3-319-46466-4_19; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shaban A., 2017, P DAVIS CHALL VID OB; Stampfer S., 1833, STROBOSCOPISCHEN SCH; Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079; Tekalp A. M., 2015, DIGITAL VIDEO PROCES, V2nd; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Uijlings JRR, 2015, PROC CVPR IEEE, P4712, DOI 10.1109/CVPR.2015.7299103; Voigtlaender P., 2017, P DAVIS CHALL VID OB; Voigtlaender Paul, 2017, ARXIV170609364; WANG Y, 2001, VIDEO PROCESSING COM; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xie S., 2017, CORR, P1; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yang Jianwei, 2016, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2016.28; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; 2016, P IEEE C COMP VIS PA, P743, DOI DOI 10.1109/CVPR.2016.87	74	109	121	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1515	1530		10.1109/TPAMI.2018.2838670	http://dx.doi.org/10.1109/TPAMI.2018.2838670			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29994298	Green Submitted, Green Accepted			2022-12-18	WOS:000467037000017
J	Zhang, TZ; Xu, CS; Yang, MH				Zhang, Tianzhu; Xu, Changsheng; Yang, Ming-Hsuan			Learning Multi-Task Correlation Particle Filters for Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; correlation filter; structural modeling; particle filter	OBJECT TRACKING	In this paper, we propose a multi-task correlation particle filter (MCPF) for robust visual tracking. We first present the multi-task correlation filter (MCF) that takes the interdependencies among different object parts and features into account to learn the correlation filters jointly. Next, the proposed MCPF is introduced to exploit and complement the strength of a MCF and a particle filter. Compared with existing tracking methods based on correlation filters and particle filters, the proposed MCPF enjoys several merits. First, it exploits the interdependencies among different features to derive the correlation filters jointly, and makes the learned filters complement and enhance each other to obtain consistent responses. Second, it handles partial occlusion via a part-based representation, and exploits the intrinsic relationship among local parts via spatial constraints to preserve object structure and learn the correlation filters jointly. Third, it effectively handles large scale variation via a sampling scheme by drawing particles at different scales for target object state estimation. Fourth, it shepherds the sampled particles toward the modes of the target state distribution via the MCF, and effectively covers object states well using fewer particles than conventional particle filters, thereby resulting in robust tracking performance and low computational cost. Extensive experimental results on four challenging benchmark datasets demonstrate that the proposed MCPF tracking algorithm performs favorably against the state-of-the-art methods.	[Zhang, Tianzhu; Xu, Changsheng] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Zhang, Tianzhu; Xu, Changsheng] Univ Chinese Acad Sci, Beijing 100190, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of California System; University of California Merced	Zhang, TZ (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.; Zhang, TZ (corresponding author), Univ Chinese Acad Sci, Beijing 100190, Peoples R China.	tzzhang10@gmail.com; csxu@nlpr.ia.ac.cn; mhyang@ucmerced.edu	Xu, Chang/GQP-7280-2022; Zhang, Tianzhu/AGY-9389-2022; Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Zhang, Tianzhu/0000-0003-0764-6106; Yang, Ming-Hsuan/0000-0003-4848-2304; zhang, tian zhu/0000-0003-1856-9564	National Natural Science Foundation of China [61432019, 61532009, 61721004, 61572498]; Key Research Program of Frontier Sciences, CAS [QYZDJ-SSW-JSC039]; Beijing Natural Science Foundation [4172062]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research Program of Frontier Sciences, CAS; Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work was supported in part by the National Natural Science Foundation of China under Grant 61432019, 61532009, 61721004, 61572498, Key Research Program of Frontier Sciences, CAS, Grant NO. QYZDJ-SSW-JSC039, and Beijing Natural Science Foundation (4172062).	Adam A., 2006, IEEE C COMP VIS PATT; [Anonymous], P EUR C COMP VIS WOR; [Anonymous], INT C LEARN REPR; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Avidan S, 2005, PROC CVPR IEEE, P494; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Chen X, 2009, IEEE DATA MINING, P746, DOI 10.1109/ICDM.2009.128; Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Cristina G. C., 2012, P BRIT MACH VIS C; Danelljan M, 2014, BRIT MACHINE VISIO, P1; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Doucet A., 2001, SEQUENTIAL MONTE CAR; Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275; Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13; Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Hong S, 2015, PR MACH LEARN RES, V37, P597; Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Khan Z, 2004, PROC CVPR IEEE, P980; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632; Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18; Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905; Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467; Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; Rifkin R, 2003, NATO SCI SERIES 3, V190, P131, DOI DOI 10.1016/S0072-9752(06)80038-2; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yang CJ, 2005, IEEE I CONF COMP VIS, P212; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhang MD, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P595, DOI 10.1109/ICCVW.2015.81; Zhang T, 2017, CVPR, P1, DOI DOI 10.7448/IAS.20.01/21372; Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421; Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307; Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164; Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0; Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34; Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; ZHANG TZ, 2015, PROC CVPR IEEE, P150, DOI DOI 10.1109/CVPR.2015.7298610; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108	71	109	118	2	118	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					365	378		10.1109/TPAMI.2018.2797062	http://dx.doi.org/10.1109/TPAMI.2018.2797062			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994598				2022-12-18	WOS:000456150600008
J	Han, H; Jain, AK; Wang, F; Shan, SG; Chen, XL				Han, Hu; Jain, Anil K.; Wang, Fang; Shan, Shiguang; Chen, Xilin			Heterogeneous Face Attribute Estimation: A Deep Multi-Task Learning Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; heterogeneous attribute estimation; attribute correlation; attribute heterogeneity; multi-task learning	AGE ESTIMATION; GENDER; CLASSIFICATION	Face attribute estimation has many potential applications in video surveillance, face retrieval, and social media. While a number of methods have been proposed for face attribute estimation, most of them did not explicitly consider the attribute correlation and heterogeneity (e.g., ordinal versus nominal and holistic versus local) during feature representation learning. In this paper, we present a Deep Multi-Task Learning (DMTL) approach to jointly estimate multiple heterogeneous attributes from a single face image. In DMTL, we tackle attribute correlation and heterogeneity with convolutional neural networks (CNNs) consisting of shared feature learning for all the attributes, and category-specific feature learning for heterogeneous attributes. We also introduce an unconstrained face database (LFW+), an extension of public-domain LFW, with heterogeneous demographic attributes (age, gender, and race) obtained via crowdsourcing. Experimental results on benchmarks with multiple face attributes (MORPH II, LFW+, CelebA, LFWA, and FotW) show that the proposed approach has superior performance compared to state of the art. Finally, evaluations on a public-domain face database (LAP) with a single attribute show that the proposed approach has excellent generalization ability.	[Han, Hu; Wang, Fang; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Han, Hu; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Shan, Shiguang] CAS Ctr Excellence Brain Sci & Intelligence Tech, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Michigan State University	Shan, SG (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.; Shan, SG (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.; Shan, SG (corresponding author), CAS Ctr Excellence Brain Sci & Intelligence Tech, Beijing 100190, Peoples R China.	hanhu@ict.ac.cn; jain@cse.msu.edu; fang.wang14@vipl.ict.ac.cn; sgshan@ict.ac.cn; xlchen@ict.ac.cn	Boothapati, Anil Kumar/HHS-1813-2022; wang, fang/GYD-4295-2022	Shan, Shiguang/0000-0002-8348-392X; Han, Hu/0000-0001-6010-1792	National Basic Research Program of China (973 Program) [2015CB351802]; Natural Science Foundation of China [61390511, 61732004, 61672496, 61650202]; CAS-INRIA JRPs [GJHZ1843]	National Basic Research Program of China (973 Program)(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CAS-INRIA JRPs	This research was partially supported by the National Basic Research Program of China (973 Program) (grant 2015CB351802), Natural Science Foundation of China (grant 61390511, 61732004, 61672496, and 61650202), and CAS-INRIA JRPs (grant GJHZ1843 (FER4HM)). Early versions of this work appeared in the MSU technical report (MSU-CSE-14-5), 2014 [1], and the Proceedings of the 12th IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2017 [2].	Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Cottrell GW, 1990, P ADV NEUR INF PROC, P564; De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z; Ehrlich M, 2016, IEEE COMPUT SOC CONF, P752, DOI 10.1109/CVPRW.2016.99; Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646; Escalera S, 2017, IEEE IJCNN, P1594, DOI 10.1109/IJCNN.2017.7966041; Escalera S, 2016, IEEE COMPUT SOC CONF, P706, DOI 10.1109/CVPRW.2016.93; Escalera S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P243, DOI 10.1109/ICCVW.2015.40; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011; Han H., 2014, TECH REP; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Hand E. M., 2016, ARXIV160407360, P1; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Huang GB, 2007, 07 UMASS TR; Jain A. K., 2011, HDB FACE RECOGNITION, V1; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kanade Takeo, 2000, P 4 IEEE INT C AUT F, P1, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]; Kim J, 2012, INT C PATT RECOG, P1611; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krogh Anders, 1991, P NIPS, P950; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Levi G., 2015, ARXIV PREPRINT ARXIV, P1; Li CH, 2016, IEEE COMPUT SOC CONF, P744, DOI 10.1109/CVPRW.2016.98; Li CT, 2014, PR MACH LEARN RES, V32, P415; Li SJ, 2015, INT J COMPUT VISION, V113, P19, DOI 10.1007/s11263-014-0767-8; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Luo P, 2013, IEEE I CONF COMP VIS, P2864, DOI 10.1109/ICCV.2013.356; Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016; Ni BB, 2011, IEEE T MULTIMEDIA, V13, P1217, DOI 10.1109/TMM.2011.2167317; Otto C, 2012, LECT NOTES COMPUT SC, V7584, P189, DOI 10.1007/978-3-642-33868-7_19; Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053; Qi G.-J., 2009, P 17 ACM INT C MULT, P243; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Samangooei S., 2008, 2 IEEE INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2008.4699354; Sun YL, 2018, IEEE T PATTERN ANAL, V40, P332, DOI 10.1109/TPAMI.2017.2669035; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Uricar M, 2016, IEEE COMPUT SOC CONF, P730, DOI 10.1109/CVPRW.2016.96; Vaquero D. A., 2009, PROC WORKSHOP APPL C, P1; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang F, 2017, IEEE INT CONF AUTOMA, P173, DOI 10.1109/FG.2017.30; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111; Xia SY, 2012, INT C PATT RECOG, P549; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang KP, 2016, IEEE COMPUT SOC CONF, P739, DOI 10.1109/CVPRW.2016.97; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhong Y, 2016, INT C PATT RECOG, P2264, DOI 10.1109/ICPR.2016.7899973	60	109	120	4	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2597	2609		10.1109/TPAMI.2017.2738004	http://dx.doi.org/10.1109/TPAMI.2017.2738004			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	28809673	Green Submitted			2022-12-18	WOS:000446683700006
J	Lu, F; Sugano, Y; Okabe, T; Sato, Y				Lu, Feng; Sugano, Yusuke; Okabe, Takahiro; Sato, Yoichi			Adaptive Linear Regression for Appearance-Based Gaze Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Eye; gaze estimation; face and gesture recognition; sub-pixel alignment; blink detection	TRACKING TECHNIQUES; BLINK DETECTION; SYSTEM	We investigate the appearance-based gaze estimation problem, with respect to its essential difficulty in reducing the number of required training samples, and other practical issues such as slight head motion, image resolution variation, and eye blinking. We cast the problem as mapping high-dimensional eye image features to low-dimensional gaze positions, and propose an adaptive linear regression (ALR) method as the key to our solution. The ALR method adaptively selects an optimal set of sparsest training samples for the gaze estimation via l(1)-optimization. In this sense, the number of required training samples is significantly reduced for high accuracy estimation. In addition, by adopting the basic ALR objective function, we integrate the gaze estimation, sub-pixel alignment and blink detection into a unified optimization framework. By solving these problems simultaneously, we successfully handle slight head motion, image resolution variation and eye blinking in appearance-based gaze estimation. We evaluated the proposed method by conducting experiments with multiple users and variant conditions to verify its effectiveness.	[Lu, Feng; Sugano, Yusuke; Okabe, Takahiro; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan	University of Tokyo	Lu, F (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan.	lufeng@iis.u-tokyo.ac.jp; sugano@iis.u-tokyo.ac.jp; takahiro@iis.u-tokyo.ac.jp; ysato@iis.u-tokyo.ac.jp	Sugano, Yusuke/X-3689-2019	Sugano, Yusuke/0000-0003-4206-710X				Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; [Anonymous], 2005, L1 MAGIC; Bacivarov I, 2008, IEEE T CONSUM ELECTR, V54, P1312, DOI 10.1109/TCE.2008.4637622; Baluja S., 1994, ADV NEURAL INFORM PR, V6, P753; Beymer D, 2003, PROC CVPR IEEE, P451; Brolly X.L.C, 2004, P 2004 C COMP VIS PA, P134, DOI DOI 10.1109/CVPR.2004.92; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Chen JX, 2011, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.2011.5995675; Coutinho FL, 2013, INT J COMPUT VISION, V101, P459, DOI 10.1007/s11263-012-0541-8; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952; Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30; Heishman R, 2007, P 8 IEEE WORKSH APPL, P52; Krolak Aleksandra, 2008, 2008 Conference on Human System Interactions, P994, DOI 10.1109/HSI.2008.4581580; Lalonde M, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P481, DOI 10.1109/CRV.2007.54; Li-Qun Xu, 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P428; Liang K., 2013, P C EYE TRACK S AFR, P17; Lu F., 2011, P INT COMP VIS, P153; Lu F, 2012, INT C PATT RECOG, P1008; Lu F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.126; Machines S., 2013, FACEAPI; Martinez F, 2012, IEEE IMAGE PROC, P1961, DOI 10.1109/ICIP.2012.6467271; Mora K. A. F., 2012, P IEEE COMP SOC C CO, P25, DOI DOI 10.1109/CVPRW.2012.6239182; Mora KAF, 2013, IEEE IMAGE PROC, P2787, DOI 10.1109/ICIP.2013.6738574; Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010; Morris T, 2002, J NETW COMPUT APPL, V25, P129, DOI 10.1006/jnca.2002.0130; Nitschke C, 2009, IEEE I CONF COMP VIS, P1226, DOI 10.1109/ICCV.2009.5459330; Noris B, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P611; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Sugano Y, 2008, LECT NOTES COMPUT SC, V5304, P656, DOI 10.1007/978-3-540-88690-7_49; Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101; Tan HC, 2006, PATTERN RECOGN LETT, V27, P667, DOI 10.1016/j.patrec.2005.10.005; Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180; Tan X., 2010, ICCV WORKSH, P139; TIAN Y, 1999, CMURITR9918; Torricelli D, 2009, PATTERN RECOGN LETT, V30, P1144, DOI 10.1016/j.patrec.2009.05.014; Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740; Villanueva A, 2008, IEEE T SYST MAN CY B, V38, P1123, DOI 10.1109/TSMCB.2008.926606; Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654; Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136; Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011; Zhu ZW, 2007, IEEE T BIO-MED ENG, V54, P2246, DOI 10.1109/TBME.2007.895750	44	109	115	2	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2033	2046		10.1109/TPAMI.2014.2313123	http://dx.doi.org/10.1109/TPAMI.2014.2313123			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352633				2022-12-18	WOS:000341981300010
J	Lee, J; Lee, D				Lee, Jaewook; Lee, Daewon			Dynamic characterization of cluster structures for robust and inductive support vector clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; kernel methods; support vector machines; inductive learning; dynamical systems		A topological and dynamical characterization of the cluster structures described by the support vector clustering is developed. It is shown that each cluster can be decomposed into its constituent basin level cells and can be naturally extended to an enlarged clustered domain, which serves as a basis for inductive clustering. A simplified weighted graph preserving the topological structure of the clusters is also constructed and is employed to develop a robust and inductive clustering algorithm. Simulation results are given to illustrate the robustness and effectiveness of the proposed method.	Pohang Univ Sci & Technol, Dept Ind Engn & Management, Pohang 790784, Kyungbuk, South Korea	Pohang University of Science & Technology (POSTECH)	Lee, J (corresponding author), Pohang Univ Sci & Technol, Dept Ind Engn & Management, Pohang 790784, Kyungbuk, South Korea.	jaewookl@postech.ac.kr; woosuhan@postech.ac.kr	Lee, Jaewook/A-8862-2012; Lee, Jaewook/A-7355-2013; LEE, Daewon/GWZ-8418-2022	Lee, Jaewook/0000-0001-5720-8337; 				Ben-Hur A., 2002, Journal of Machine Learning Research, V2, P125, DOI 10.1162/15324430260185565; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; Jenssen R., 2005, ADV NEURAL INFORM PR, P625; Khalil H. K., 1992, NONLINEAR SYSTEMS; Lee J, 2005, IEEE T PATTERN ANAL, V27, P461, DOI 10.1109/TPAMI.2005.47; Lee J, 2004, IEEE T AUTOMAT CONTR, V49, P888, DOI 10.1109/TAC.2004.829603; Ng AY, 2002, ADV NEURAL INFORM PR, V14; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang JH, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P898	13	109	111	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1869	1874		10.1109/TPAMI.2006.225	http://dx.doi.org/10.1109/TPAMI.2006.225			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063691				2022-12-18	WOS:000240443400014
J	Veenman, CJ; Reinders, MJT				Veenman, CJ; Reinders, MJT			The nearest subclass classifier: A compromise between the nearest mean and nearest neighbor classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; regularization; cross-validation; prototype selection	LEARNING ALGORITHMS; NEURAL NETWORKS; RULE; SELECTION; DESIGN; PROTOTYPES; SUBSET; BIAS; ABSTRACTION; SEPARATION	We present the Nearest Subclass Classifier (NSC), which is a classification algorithm that unifies the flexibility of the nearest neighbor classifier with the robustness of the nearest mean classifier. The algorithm is based on the Maximum Variance Cluster algorithm and, as such, it belongs to the class of prototype- based classifiers. The variance constraint parameter of the cluster algorithm serves to regularize the classifier, that is, to prevent overfitting. With a low variance constraint value, the classifier turns into the nearest neighbor classifier and, with a high variance parameter, it becomes the nearest mean classifier with the respective properties. In other words, the number of prototypes ranges from the whole training set to only one per class. In the experiments, we compared the NSC with regard to its performance and data set compression ratio to several other prototype- based methods. On several data sets, the NSC performed similarly to the k-nearest neighbor classifier, which is a well-established classifier in many domains. Also concerning storage requirements and classification speed, the NSC has favorable properties, so it gives a good compromise between classification performance and efficiency.	Delft Univ Technol, Dept Mediamat, NL-2600 GA Delft, Netherlands	Delft University of Technology	Veenman, CJ (corresponding author), Delft Univ Technol, Dept Mediamat, POB 5031, NL-2600 GA Delft, Netherlands.	C.J.Veenman@ewi.tudelft.nl; M.J.T.Reinders@ewi.tudelft.nl						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179, DOI 10.1109/T-C.1974.223827; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Dunn J. C., 1974, J CYBERNETICS, V4, P95, DOI 10.1080/01969727408546059; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fix E., 1951, 4 USAF SCH AV MED, P261; Ganti V, 1999, COMPUTER, V32, P38, DOI 10.1109/2.781633; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Glover F., 2013, TABU SEARCH; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HENERY RJ, 1994, MACHINE LEARNING NEU, P107; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1999, IEEE T NEURAL NETWOR, V10, P1142, DOI 10.1109/72.788653; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075, DOI 10.1109/TPAMI.2002.1023804; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Newman C. B. D., 1998, UCI REPOSITORY MACHI; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1023/A:1022653209073; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Skalak D. B, 1994, P 11 INT C MACH LEAR, P293, DOI DOI 10.1016/B978-1-55860-335-6.50043-X; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Veenman CJ, 2003, IEEE T IMAGE PROCESS, V12, P304, DOI 10.1109/TIP.2002.806256; Veenman CJ, 2002, IEEE T PATTERN ANAL, V24, P1273, DOI 10.1109/TPAMI.2002.1033218; Wilfong G., 1991, P SCG 1991, P224, DOI 10.1145/109648.109673; Wilson D.R., 1997, P MACH LEARN 14 INT, P404; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; [No title captured]	54	109	111	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1417	1429		10.1109/TPAMI.2005.187	http://dx.doi.org/10.1109/TPAMI.2005.187			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173185	Green Submitted			2022-12-18	WOS:000230463300005
J	Roth, V; Laub, J; Kawanabe, M; Buhmann, JM				Roth, V; Laub, J; Kawanabe, M; Buhmann, JM			Optimal cluster preserving embedding of nonmetric proximity data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; pairwise proximity data; cost function; embedding; MDS		For several major applications of data analysis, objects are often not represented as feature vectors in a vector space, but rather by a matrix gathering pairwise proximites. Such pairwise data often violates metricity and, therefore, cannot be naturally embedded in a vector space. Concerning the problem of unsupervised structure detection or clustering, in this paper, a new embedding method for pairwise data into Euclidean vector spaces is introduced. We show that all clustering methods, which are invariant under additive shifts of the pairwise proximities, can be reformulated as grouping problems in Euclidian spaces. The most prominent property of this constant shift embedding framework is the complete preservation of the cluster structure in the embedding space. Restating pairwise clustering problems in vector spaces has several important consequences, such as the statistical description of the clusters by way of cluster prototypes, the generic extension of the grouping procedure to a discriminative prediction rule, and the applicability of standard preprocessing methods like denoising or dimensionality reduction.	Univ Bonn, Dept Comp Sci 3, D-53117 Bonn, Germany; Fraunhofer FIRST, D-12489 Berlin, Germany	University of Bonn; Fraunhofer Gesellschaft; Fraunhofer Institute Center Schloss Birlinghoven	Roth, V (corresponding author), Univ Bonn, Dept Comp Sci 3, Roemerstr 164, D-53117 Bonn, Germany.	roth@cs.uni-bonn.de; julian.laub@first.fhg.de; nabe@first.fhg.de; jb@cs.uni-bonn.de	Roth, Volker/Q-4025-2017	Roth, Volker/0000-0003-0991-0273				Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; BRUCKER P, 1978, LECTURE NOTES EC MAT, V157, P45; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; DRINES P, 1999, P S DISCR ALG; Duda R.O., 2001, PATTERN CLASSIFICATI; Dudoit S, 2002, GENOME BIOL, V3; Durbin R., 1998, BIOL SEQUENCE ANAL P; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kohonen T., 1995, SELF ORG MAPS; LANGE T, 2003, P C NEUR INF PROC SY; Mika S, 1999, ADV NEUR IN, V11, P536; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Puzicha J, 2000, PATTERN RECOGN, V33, P617, DOI 10.1016/S0031-3203(99)00076-X; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Soundararajan P, 2001, PROC CVPR IEEE, P239; TAKANE Y, 1977, PSYCHOMETRIKA, V42, P7, DOI 10.1007/BF02293745; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Torgerson W.S., 1958, THEORY METHODS SCALI; Young G, 1938, PSYCHOMETRIKA, V3, P19, DOI 10.1007/BF02287916	27	109	110	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1540	1551		10.1109/TPAMI.2003.1251147	http://dx.doi.org/10.1109/TPAMI.2003.1251147			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000004
J	Avidan, S; Shashua, A				Avidan, S; Shashua, A			Trajectory triangulation: 3D reconstruction of moving points from a monocular image sequence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; multiple-view geometry; dynamic scenes		We consider the problem of reconstructing the 3D coordinates of a moving point seen from a monocular moving camera, i.e., to reconstruct moving objects from line-of-sight measurements only. The task is feasible only when some constraints are placed on the shape of the trajectory of the moving point. We coin the family of such tasks as "trajectory triangulation." We investigate the solutions for points moving along a straight-line and along conic-section trajectories. We show that if the point is moving along a straight line, then the parameters of the line (and, hence, the 3D position of the point at each time instant) can be uniquely recovered, and by linear methods, from at least five views. For the case of conic-shaped trajectory, we show that generally nine views are sufficient for a unique reconstruction of the moving point and fewer views when the conic is of a known type (like a circle in 3D Euclidean space for which seven views are sufficient). The paradigm of trajectory triangulation, in general, pushes the envelope of processing dynamic scenes forward. Thus static scenes become a particular case of a more general task of reconstructing scenes rich with moving objects (where an object could be a single point).	Microsoft Corp, Microsoft Res, Vis Technol Grp, Redmond, WA 98052 USA; Hebrew Univ Jerusalem, Inst Comp Sci, IL-91905 Jerusalem, Israel	Microsoft; Hebrew University of Jerusalem	Avidan, S (corresponding author), Microsoft Corp, Microsoft Res, Vis Technol Grp, Redmond, WA 98052 USA.	avidan@microsoft.com; shashua@cs.huji.ac.il						[Anonymous], 1976, METHODS ORBIT DETERM; AVIDAN S, 1999, P IEEE C COMP VIS PA; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; FAUGERAS OD, 1995, P INT C COMP VIS JUN; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Leedan Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P733, DOI 10.1109/ICCV.1998.710799; SEGAL D, 2000, P EUR C COMP VIS ECC; Shashua A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P330, DOI 10.1109/ICCV.1999.791238; SHASHUA A, 2000, P EUR C COMP VIS JUN; TELLER SJ, 1992, COMP GRAPH, V26, P139, DOI 10.1145/142920.134029; TORR PHS, 1995, WORKSH GEOM MOD INV	11	109	167	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					348	357		10.1109/34.845377	http://dx.doi.org/10.1109/34.845377			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT		Green Submitted			2022-12-18	WOS:000087250500004
J	Hochberg, J; Kelly, P; Thomas, T; Kerns, L				Hochberg, J; Kelly, P; Thomas, T; Kerns, L			Automatic script identification from document images using cluster-based templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	3rd International Conference on Document Analysis and Recognition	AUG, 1995	MONTREAL, CANADA			script identification; document analysis; optical character recognition		We describe an automated script identification system for typeset document images. Templates for each script are created by clustering textual symbols from a training set. Symbols from new images are compared to the templates to find the best script. Our current system processes thirteen scripts with minimal preprocessing and high accuracy.			Hochberg, J (corresponding author), LOS ALAMOS NATL LAB,POB 1663,LOS ALAMOS,NM 87544, USA.							CHURCH KW, 1986, P INT C ACOUSTICS SP, P2423; DAMASHEK M, 1995, SCIENCE, V267, P843, DOI 10.1126/science.267.5199.843; Duda R.O., 1973, J ROYAL STAT SOC SER; Hochberg J., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P378, DOI 10.1109/ICDAR.1995.599017; HONG A, 1995, P 4 ANN S DOC AN INF, P177; Rasure J. R., 1991, Journal of Visual Languages and Computing, V2, P217, DOI 10.1016/S1045-926X(06)80007-8; SIBUN P, 1994, P 4 C APPL NAT LANG, P115; Spitz A. L., 1994, P 3 ANN S DOC AN INF, P229; SPITZ AL, 1994, P DOCUMENT RECOGNITI, P97	9	109	116	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					176	181		10.1109/34.574802	http://dx.doi.org/10.1109/34.574802			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800013
J	GIL, J; WERMAN, M				GIL, J; WERMAN, M			COMPUTING 2-D MIN, MEDIAN, AND MAX FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ALGORITHM; LOWER BOUND; MAX FILTER; MEDIAN FILTER; MIN FILTER; ORDER FILTER		Fast algorithms to compute min, median, max, or any other order statistic filter transforms are described. The algorithms take constant time per pixel to compute min or max filters and polylog time per pixel, in the size of the filter, to compute the median filter. A logarithmic time per pixel lower bound for the computation of the median filter is shown.			GIL, J (corresponding author), HEBREW UNIV JERUSALEM,DEPT COMP SCI,JERUSALEM,ISRAEL.							BROWNRIGG DR, 1984, COMMUN ASS COMPUT MA, V27, P204; GIL J, IN PRESS RUNNING MED; HUANG TS, 1981, 2 DIMENSIONAL DIGITA, V2; KATAJAINEN J, 1991, IEEE T SIGNAL PROCES, V39, P204; Serra J, 1982, IMAGE ANAL MATH MORP; WERMAN M, 1985, IEEE T PATTERN ANAL, V7, P730, DOI 10.1109/TPAMI.1985.4767732	6	109	122	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					504	507		10.1109/34.211471	http://dx.doi.org/10.1109/34.211471			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000009
J	MARAGOS, P				MARAGOS, P			A REPRESENTATION-THEORY FOR MORPHOLOGICAL IMAGE AND SIGNAL-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MARAGOS, P (corresponding author), HARVARD UNIV,DIV APPL SCI,CAMBRIDGE,MA 02138, USA.							ARCE GR, 1986, ADV COMPUTER VISION, V2; BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247; CRIMMINS TR, 1985, IEEE T AERO ELEC SYS, V21, P60, DOI 10.1109/TAES.1985.310539; Dougherty E. R., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P270, DOI 10.1117/12.976515; DOUGHERTY ER, 1986, JUN P IEEE C COMP VI, P534; DUFF MJB, 1973, PATTERN RECOGN, V5, P229, DOI 10.1016/0031-3203(73)90045-9; ESSELMAN T, 1987, MIT797 LINC LAB TECH; FITCH JP, 1984, IEEE T ACOUST SPEECH, V32, P1183, DOI 10.1109/TASSP.1984.1164468; GOETCHERIAN V, 1980, PATTERN RECOGN, V12, P7, DOI 10.1016/0031-3203(80)90049-7; HADWIGER H, 1957, VORLESUNGEN UBER INH; HARALICK RM, 1987, 1ST P ICCV; HARBER RG, 1985, MAR P IEEE INT C AC, P1396; HEIJMANS HJA, 1988, AMR8807 NETH REP; HEREFORD JM, 1988, OPT ENG          MAY; HSING TR, 1987, P SPIE, V845; Huang T.S., 1981, TOP APPL PHYS; Kaufmann A., 1975, INTRO THEORY FUZZY S, VVolume 2; KLEIN JC, 1972, J MICROSCOPY, V95, P349; Kohler W., 1970, GESTALT PSYCHOL; Kolmogorov A. N., 1975, INTRO REAL ANAL; LANTUEJOUL C, 1982, MAY P IEEE INT C AC, P2063; LOUGHEED RM, 1980, P WORKSHOP PICTURE D; MARAGOS P, 1985, MAR P IEEE INT C AC, P34; MARAGOS P, 1985, THESIS SCH ELEC ENG; MARAGOS P, 1987, AUG IEEE T AC SPEECH, V35; MARAGOS P P, 1986, P SPIE 707; MATHERON G., 1975, RANDOM SETS INTEGRAL; MILLER PE, 1983, DEV MATH STRUCTURE I; MILLER PE, 1978, THESIS OHIO STATE U; NAKAGAWA Y, 1978, IEEE T SYST MAN CYBE, V8; NODES TA, 1982, IEEE T ACOUST SPEECH, V30, P739, DOI 10.1109/TASSP.1982.1163951; O'Neill K. S., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V638, P41, DOI 10.1117/12.964262; OCHOA E, 1987, APPL OPTICS, V26, P252, DOI 10.1364/AO.26.000252; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; Ritter G. X., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P260, DOI 10.1117/12.976514; RITTER GX, 1987, J PARALLEL DISTR COM, V4, P7, DOI 10.1016/0743-7315(87)90007-4; RITTER GX, 1987, 1ST P INT C COMP VIS, P641; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; Serra J, 1982, IMAGE ANAL MATH MORP; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; STERNBERG SR, 1982, BIOMEDICAL IMAGES CO; STEVENSON RL, 1987, IEEE T CIRCUITS SYST, V34, P1292, DOI 10.1109/TCS.1987.1086067; WENDT PD, 1986, IEEE T ACOUST SPEECH, V34, P898, DOI 10.1109/TASSP.1986.1164871; 1985, NOV P IEEE WORKSH CA; [No title captured]	45	109	112	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					586	599		10.1109/34.24793	http://dx.doi.org/10.1109/34.24793			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749		Green Submitted			2022-12-18	WOS:A1989U674900004
J	WONG, AKC; CHIU, DKY				WONG, AKC; CHIU, DKY			SYNTHESIZING STATISTICAL KNOWLEDGE FROM INCOMPLETE MIXED-MODE DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV GUELPH,DEPT COMP & INFORMAT SCI,GUELPH N1G 2W1,ONTARIO,CANADA	University of Guelph	WONG, AKC (corresponding author), UNIV WATERLOO,DEPT SYST DESIGN ENGN,WATERLOO N2L 3G1,ONTARIO,CANADA.		Chiu, David/C-4922-2013					CHIU DKY, 1986, IEEE T SYST MAN CYB, V16, P251, DOI 10.1109/TSMC.1986.4308945; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHRISTENSEN R, 1973 P IEEE INT C CY, P321; Duda R.O., 1973, J ROYAL STAT SOC SER; FORTE B, IN PRESS IEEE T INFO; GALLAIRE H, 1984, COMPUT SURV, V16, P153, DOI 10.1145/356924.356929; Garfinkel R. S., 1972, INTEGER PROGRAMMING; GUIASU S, 1977, INFORMATION THEORY A; HAND DJ, 1982, PATTERN RECOGN, P19; NAVATHE S, 1984, ACM T DATABASE SYST, V9, P680, DOI 10.1145/1994.2209; NG CT, IN PRESS IEEE T INFO; REZA FM, 1961, INTRO INFORMATION TH; SHEN HC, 1983 P INT C SYST MA; Smallwood RD., 1962, DECISION STRUCTURE T; STOFFEL JC, 1974, IEEE T COMPUT, VC 23, P428, DOI 10.1109/T-C.1974.223958; Tapia R, 1978, NONPARAMETRIC PROBAB; THIERAUF RJ, 1982, DECISION SUPPORT SYS; WILKS SS, 1962, MATH STATISTICS; WONG AKC, 1987, PATTERN RECOGN, V20, P245, DOI 10.1016/0031-3203(87)90058-6; WONG AKC, 1975, IEEE T COMPUT, VC 24, P158, DOI 10.1109/T-C.1975.224183; WONG AKC, 1979 P INT C CYB SOC, P514; WONG AKC, 1982, PROBLEM DEFINITION P	22	109	112	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					796	805		10.1109/TPAMI.1987.4767986	http://dx.doi.org/10.1109/TPAMI.1987.4767986			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869441				2022-12-18	WOS:A1987K673500007
J	Pan, JS; Sun, DQ; Pfister, H; Yang, MH				Pan, Jinshan; Sun, Deqing; Pfister, Hanspeter; Yang, Ming-Hsuan			Deblurring Images via Dark Channel Prior	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image deblurring; dark channel prior; non-uniform deblurring; convolution; linear approximation	VARIATION BLIND DECONVOLUTION; SINGLE IMAGE; ALGORITHM	We present an effective blind image deblurring algorithm based on the dark channel prior. The motivation of this work is an interesting observation that the dark channel of blurred images is less sparse. While most patches in a clean image contain some dark pixels, this is not the case when they are averaged with neighboring ones by motion blur. This change in sparsity of the dark channel pixels is an inherent property of the motion blur process, which we prove mathematically and validate using image data. Enforcing sparsity of the dark channel thus helps blind deblurring in various scenarios such as natural, face, text, and low-illumination images. However, imposing sparsity of the dark channel introduces a non-convex non-linear optimization problem. In this work, we introduce a linear approximation to address this issue. Extensive experiments demonstrate that the proposed deblurring algorithm achieves the state-of-the-art results on natural images and performs favorably against methods designed for specific scenarios. In addition, we show that the proposed method can be applied to image dehazing.	[Pan, Jinshan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Sun, Deqing] NVIDIA, Westford, MA 01886 USA; [Pfister, Hanspeter] Harvard Univ, Cambridge, MA 02138 USA; [Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA 95344 USA	Nanjing University of Science & Technology; Harvard University; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif, Sch Engn, Merced, CA 95344 USA.	sdluran@gmail.com; deqings@nvidia.com; pfister@seas.harvard.edu; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Pan, Jinshan/S-3658-2019; Pan, Jinshan/AAO-2258-2021; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Pfister, Hanspeter/0000-0002-3620-2582	US National Science Foundation CAREER Grant [1149783]; US National Science Foundation [IIS-1447344, IIS-1607800]; IARPA via DoI/IBC [D16PC00002]; 973 Program of China [2014CB347600]; NSF of China [61732007]; NSF of Jiangsu Province [BK20140058]; National Key R&D Program of China [2016YFB1001001]	US National Science Foundation CAREER Grant(National Science Foundation (NSF)); US National Science Foundation(National Science Foundation (NSF)); IARPA via DoI/IBC; 973 Program of China(National Basic Research Program of China); NSF of China(National Natural Science Foundation of China (NSFC)); NSF of Jiangsu Province; National Key R&D Program of China	This work is supported in part by the US National Science Foundation CAREER Grant 1149783, US National Science Foundation grants IIS-1447344, IIS-1607800, IARPA via DoI/IBC contract D16PC00002, 973 Program of China (No. 2014CB347600), NSF of China (No. 61732007), NSF of Jiangsu Province (No. BK20140058), the National Key R&D Program of China (No. 2016YFB1001001), and gifts from Adobe and Nvidia.	Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413; Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36; Chen XG, 2011, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2011.5995568; Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; HaCohen Y, 2013, IEEE I CONF COMP VIS, P2384, DOI 10.1109/ICCV.2013.296; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276; Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432; Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5; Jia J., 2014, MATH MODELS PRACTICA; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D., 2011, CVPR, P2657; Lemire D., 2006, Nordic Journal of Computing, V13, P328; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Lou YF, 2011, J MATH IMAGING VIS, V39, P1, DOI 10.1007/s10851-010-0220-8; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51; Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pan JS, 2016, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2016.306; Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Perrone D, 2016, INT J COMPUT VISION, V117, P159, DOI 10.1007/s11263-015-0857-2; Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372; Pya S., 2018, P IEEE C COMP VIS PA, P1; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shan Q., 2007, P IEEE 11 INT C COMP, P1, DOI DOI 10.1109/ICCV.2007.4408922; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028; Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wieschollek Patrick, 2016, P AS C COMP VIS, P35; Xiao L, 2016, LECT NOTES COMPUT SC, V9907, P734, DOI 10.1007/978-3-319-46487-9_45; Xu L, 2011, ACM T GRAPHIC, V30, P6; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; [张华 ZHANG Hua], 2011, [高分子通报, Polymer Bulletin], P1; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	50	108	122	11	78	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2315	2328		10.1109/TPAMI.2017.2753804	http://dx.doi.org/10.1109/TPAMI.2017.2753804			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28952935	hybrid			2022-12-18	WOS:000443875500003
J	Hu, JL; Lu, JW; Tan, YP				Hu, Junlin; Lu, Jiwen; Tan, Yap-Peng			Sharable and Individual Multi-View Metric Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Metric learning; deep learning; multi-view learning; face verification; kinship verification; person re-identification	RECOGNITION	This paper presents a sharable and individual multi-view metric learning (MvML) approach for visual recognition. Unlike conventional metric leaning methods which learn a distance metric on either a single type of feature representation or a concatenated representation of multiple types of features, the proposed MvML jointly learns an optimal combination of multiple distance metrics on multi-view representations, where not only it learns an individual distance metric for each view to retain its specific property but also a shared representation for different views in a unified latent subspace to preserve the common properties. The objective function of the MvML is formulated in the large margin learning framework via pairwise constraints, under which the distance of each similar pair is smaller than that of each dissimilar pair by a margin. Moreover, to exploit the nonlinear structure of data points, we extend MvML to a sharable and individual multi-view deep metric learning (MvDML) method by utilizing the neural network architecture to seek multiple nonlinear transformations. Experimental results on face verification, kinship verification, and person re-identification show the effectiveness of the proposed sharable and individual multi-view metric learning methods.	[Hu, Junlin; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Lu, Jiwen] Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Lu, Jiwen] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Tsinghua University; Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	jhu007@e.ntu.edu.sg; lujiwen@tsinghua.edu.cn; eyptan@ntu.edu.sg	Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529; Hu, Junlin/0000-0002-0117-3494	National Natural Science Foundation of China [61672306]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank the anonymous reviewers for their insightful suggestions for improving the paper. This work was supported in part by the National Natural Science Foundation of China under Grant 61672306.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246; Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590; Goldberger J., 2004, ADV NEURAL INF PROCE, P1; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hu J., 2015, COMPUTER VISION ACCV, P252; Hu JL, 2016, IEEE T IMAGE PROCESS, V25, P5576, DOI 10.1109/TIP.2016.2612827; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang G. B., 2007, 0749 U MASS US; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134; McFee B, 2011, J MACH LEARN RES, V12, P491; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Nguyen Hieu V., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P709, DOI 10.1007/978-3-642-19309-5_55; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wolf L., 2008, P REAL LIF IM WORKSH, P1; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Wu P., 2013, PROC 21 ACM INT C MU, P153, DOI [10.1145/2502081.2502112, DOI 10.1145/2502081.2502112]; Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204; Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436; Xie P., 2013, PROC INT JOINT C ART, P1806; Xu C., 2013, COMPUT RES REPOSITOR; Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528; Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757; Zhai DM, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168767; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	48	108	111	2	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2281	2288		10.1109/TPAMI.2017.2749576	http://dx.doi.org/10.1109/TPAMI.2017.2749576			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28885151				2022-12-18	WOS:000440868400019
J	Cherian, A; Sra, S; Banerjee, A; Papanikolopoulos, N				Cherian, Anoop; Sra, Suvrit; Banerjee, Arindam; Papanikolopoulos, Nikolaos			Jensen-Bregman LogDet Divergence with Application to Efficient Similarity Search for Covariance Matrices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Region covariance descriptors; Bregman divergence; image search; nearest neighbor search; LogDet divergence; video surveillance; activity recognition	RIEMANNIAN FRAMEWORK; TENSOR; TEXTURE	Covariance matrices have found success in several computer vision applications, including activity recognition, visual surveillance, and diffusion tensor imaging. This is because they provide an easy platform for fusing multiple features compactly. An important task in all of these applications is to compare two covariance matrices using a (dis)similarity function, for which the common choice is the Riemannian metric on the manifold inhabited by these matrices. As this Riemannian manifold is not flat, the dissimilarities should take into account the curvature of the manifold. As a result, such distance computations tend to slow down, especially when the matrix dimensions are large or gradients are required. Further, suitability of the metric to enable efficient nearest neighbor retrieval is an important requirement in the contemporary times of big data analytics. To alleviate these difficulties, this paper proposes a novel dissimilarity measure for covariances, the Jensen-Bregman LogDet Divergence (JBLD). This divergence enjoys several desirable theoretical properties and at the same time is computationally less demanding (compared to standard measures). Utilizing the fact that the square root of JBLD is a metric, we address the problem of efficient nearest neighbor retrieval on large covariance datasets via a metric tree data structure. To this end, we propose a K-Means clustering algorithm on JBLD. We demonstrate the superior performance of JBLD on covariance datasets from several computer vision applications.	[Cherian, Anoop; Banerjee, Arindam; Papanikolopoulos, Nikolaos] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Sra, Suvrit] Max Planck Inst Intelligent Syst, Dept Empir Inference, D-72076 Tubingen, Germany	University of Minnesota System; University of Minnesota Twin Cities; Max Planck Society	Cherian, A (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	cherian@cs.umn.edu; suvrit.sra@tuebingen.mpg.de; banerjee@cs.umn.edu; npapas@cs.umn.edu			US Army Research Laboratory; US Army Research Office [911NF-08-1-0463]; US National Science Foundation (NSF) [IIP-0443945, CNS-0821474, IIP-0934327, CNS-1039741, IIS-1017344, IIP-1032018, SMA-1028076]; NSF [IIS-0916750, IIS-0812183, IIS-1029711, NetSE-1017647, IIS-0953274]	US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office; US National Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF))	This material is based upon work supported in part by the US Army Research Laboratory and the US Army Research Office under Contract #911NF-08-1-0463 (Proposal 55111-CI), and the US National Science Foundation (NSF) through Grants #IIP-0443945, #CNS-0821474, #IIP-0934327, #CNS-1039741, #IIS-1017344, #IIP-1032018, and #SMA-1028076. Arindam Banerjee is supported by NSF grants #IIS-0916750, #IIS-0812183, #IIS-1029711, #NetSE-1017647, and NSF CAREER award #IIS-0953274.	Alexander DC, 2001, IEEE T MED IMAGING, V20, P1131, DOI 10.1109/42.963816; [Anonymous], 2010, UMCS2010009; Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Bhatia R, 2007, PRINC SER APPL MATH, P1; Bhatia Rajendra, 1997, MATRIX ANAL, DOI 10.1007/978-1-4612-0653-8; Bini DA, 2013, LINEAR ALGEBRA APPL, V438, P1700, DOI 10.1016/j.laa.2011.08.052; Brin S., 1995, P 21 INT C VER LARG; Brox T, 2003, LECT NOTES COMPUT SC, V2756, P353; Caseiro R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3570, DOI 10.1109/ICPR.2010.871; Cavallaro A., 2007, P IEEE INT C AC SPEE, V1; Cayton L., 2008, P 25 INT C MACHINE L, P112; Censor Y., 1997, PARALLEL OPTIMIZATIO; Chaudhry R, 2010, LECT NOTES COMPUT SC, V6312, P735, DOI 10.1007/978-3-642-15552-9_53; Chebbi Z, 2012, LINEAR ALGEBRA APPL, V436, P1872, DOI 10.1016/j.laa.2011.12.003; Chen C., 2010, UT TOWER DATA SET AE; Chiang MC, 2007, NEUROIMAGE, V34, P44, DOI 10.1016/j.neuroimage.2006.08.030; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Dryden IL, 2009, ANN APPL STAT, V3, P1102, DOI 10.1214/09-AOAS249; Fillard P, 2005, LECT NOTES COMPUT SC, V3753, P112, DOI 10.1007/11577812_10; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gu Q., 2009, ICPR, P1; Horn R.A., 2013, MATRIX ANAL, P321; Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71; Kulis B, 2009, J MACH LEARN RES, V10, P341; Lanckriet G. R., 2009, P 22 INT C NEURAL IN, P1759; Lawson JD, 2001, AM MATH MON, V108, P797, DOI 10.2307/2695553; Li XB, 2008, CAN J EDUC ADM POLIC, P1, DOI 10.1109/CVPR.2008.4587516; Malcolm J., 2007, P IEEE C COMP VIS PA, P1; Moakher M, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P285, DOI 10.1007/3-540-31272-2_17; Myrvoll T. A., 2003, EUROSPEECH 2003 8 EU, P1517; Nielsen F., 2007, ARXIV07113242; Nielsen F, 2011, IEEE T INFORM THEORY, V57, P5455, DOI 10.1109/TIT.2011.2159046; Nielsen F, 2009, IEEE INT CON MULTI, P878, DOI 10.1109/ICME.2009.5202635; Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Sra S., 2011, POSITIVE DEFINITE MA; Turaga P., 2010, P 7 IND C COMP VIS G, P282; Tuzel O., 2006, P EUR C COMP VIS; Tuzel O., 2007, PROC CVPR IEEE, P1, DOI [DOI 10.1109/CVPR.2007.383197, 10.1109/CVPR.2007.383197]; Tuzel O., 2006, P IEEE C COMP VIS PA; Vemuri B. C., 2012, MATRIX INFORM GEOMET, P111; Wang ZZ, 2004, IEEE T MED IMAGING, V23, P930, DOI 10.1109/TMI.2004.831218; Ye CX, 2008, LECT NOTES COMPUT SC, V5353, P61; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zheng WM, 2010, LECT NOTES COMPUT SC, V6316, P490, DOI 10.1007/978-3-642-15567-3_36; Zhu HT, 2007, J AM STAT ASSOC, V102, P1085, DOI 10.1198/016214507000000581	51	108	113	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2161	2174		10.1109/TPAMI.2012.259	http://dx.doi.org/10.1109/TPAMI.2012.259			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868777				2022-12-18	WOS:000322029000009
J	Rudovic, O; Pantic, M; Patras, I				Rudovic, Ognjen; Pantic, Maja; Patras, Ioannis (Yiannis)			Coupled Gaussian Processes for Pose-Invariant Facial Expression Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiview/pose-invariant facial expression/emotion recognition; head-pose estimation; Gaussian process regression	FACE	We propose a method for head-pose invariant facial expression recognition that is based on a set of characteristic facial points. To achieve head-pose invariance, we propose the Coupled Scaled Gaussian Process Regression (CSGPR) model for head-pose normalization. In this model, we first learn independently the mappings between the facial points in each pair of (discrete) nonfrontal poses and the frontal pose, and then perform their coupling in order to capture dependences between them. During inference, the outputs of the coupled functions from different poses are combined using a gating function, devised based on the head-pose estimation for the query points. The proposed model outperforms state-of-the-art regression-based approaches to head-pose normalization, 2D and 3D Point Distribution Models (PDMs), and Active Appearance Models (AAMs), especially in cases of unknown poses and imbalanced training data. To the best of our knowledge, the proposed method is the first one that is able to deal with expressive faces in the range from -45 degrees to +45 degrees pan rotation and -30 degrees to +30 degrees tilt rotation, and with continuous changes in head pose, despite the fact that training was conducted on a small set of discrete poses. We evaluate the proposed method on synthetic and real images depicting acted and spontaneously displayed facial expressions.	[Rudovic, Ognjen; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Patras, Ioannis (Yiannis)] Queen Mary Univ London, London E1 4NS, England	Imperial College London; University of London; Queen Mary University London	Rudovic, O (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	o.rudovic@imperial.ac.uk; m.pantic@imperial.ac.uk; patras@eecs.qmul.ac.uk		Patras, Ioannis/0000-0003-3913-4738	European Research Council [ERC-2007-StG-203143]; Engineering and Physical Sciences Research Council [EP/G033935/1]; EPSRC [EP/G033935/1] Funding Source: UKRI	European Research Council(European Research Council (ERC)European Commission); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work is funded in part by the European Research Council under the ERC Starting Grant agreement no. ERC-2007-StG-203143 (MAHNOB). The work of Ioannis Patras is supported in part by the Engineering and Physical Sciences Research Council Grant EP/G033935/1.	Alex M, 2002, LECT NOTES COMPUT SC, V2350, P447; Alvarez M., 2008, NIPS, P57; Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; Bishop Christopher M., 2007, PATTERN RECOGNITION, V4, DOI 10.1117/1.2819119; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bonilla EV., 2008, ADV NEURAL INF PROCE, V20, P153, DOI DOI 10.5555/2981562.2981582; Boyle P., 2005, ADV NEURAL INFORM PR, P217; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cootes Timothy F, 1992, BMVC, DOI DOI 10.1007/978-1-4471-3201-1_28; Dornaika F, 2007, J REAL-TIME IMAGE PR, V2, P35, DOI 10.1007/s11554-007-0032-2; Ekman P., 1978, UNMASKING FACE GUIDE, V3; ELKALIOUBY R, 2004, P INT C COMP VIS PAT, V3, P154, DOI DOI 10.1109/CVPR.2004.153; Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hu Y, 2008, PROC CVPR IEEE, P85; Hu YX, 2008, INT C PATT RECOG, P460; Jeni LA, 2012, IMAGE VISION COMPUT, V30, P785, DOI 10.1016/j.imavis.2012.02.003; Julier SJ, 1997, P AMER CONTR CONF, P2369, DOI 10.1109/ACC.1997.609105; Kumano S, 2009, INT J COMPUT VISION, V83, P178, DOI 10.1007/s11263-008-0185-x; Liao W.-K., 2006, P IEEE SOC C COMP VI, P158; Lucey S., 2007, INVESTIGATING SPONTA; McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006; Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26; Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5; Sung J, 2009, IMAGE VISION COMPUT, V27, P1313, DOI 10.1016/j.imavis.2008.11.010; Tang H, 2010, IEEE INT CON MULTI, P1202, DOI 10.1109/ICME.2010.5582576; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293; Tresp V, 2000, NEURAL COMPUT, V12, P2719, DOI 10.1162/089976600300014908; TRESP V, 1995, P NEUR INF PROC SYST, V7, P419; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007; Wang J., 2006, COMPUTER VISION PATT, V2, P1399, DOI [10.1109/CVPR.2006.14, DOI 10.1109/CVPR.2006.14]; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479; Yu SP, 2011, J MACH LEARN RES, V12, P2649; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zheng WM, 2009, IEEE I CONF COMP VIS, P1901, DOI 10.1109/ICCV.2009.5459421; Zheng WM, 2010, LECT NOTES COMPUT SC, V6316, P490, DOI 10.1007/978-3-642-15567-3_36; Zhu Z., 2006, 2006 IEEE COMP SOC C, V1, P681, DOI DOI 10.1109/CVPR.2006.259	49	108	118	1	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1357	1369		10.1109/TPAMI.2012.233	http://dx.doi.org/10.1109/TPAMI.2012.233			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599052	Green Submitted			2022-12-18	WOS:000317857900007
J	Barinova, O; Lempitsky, V; Kholi, P				Barinova, Olga; Lempitsky, Victor; Kholi, Pushmeet			On Detection of Multiple Object Instances Using Hough Transforms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough transforms; object detection in images; line detection; scene understanding		Hough transform-based methods for detecting multiple objects use nonmaxima suppression or mode seeking to locate and distinguish peaks in Hough images. Such postprocessing requires the tuning of many parameters and is often fragile, especially when objects are located spatially close to each other. In this paper, we develop a new probabilistic framework for object detection which is related to the Hough transform. It shares the simplicity and wide applicability of the Hough transform but, at the same time, bypasses the problem of multiple peak identification in Hough images and permits detection of multiple objects without invoking nonmaximum suppression heuristics. Our experiments demonstrate that this method results in a significant improvement in detection accuracy both for the classical task of straight line detection and for a more modern category-level (pedestrian) detection problem.	[Barinova, Olga] Moscow MV Lomonosov State Univ, Moscow 119296, Russia; [Lempitsky, Victor] Yandex, Moscow 117321, Russia; [Kholi, Pushmeet] Microsoft Res, Cambridge CB3 0FB, England	Lomonosov Moscow State University; Microsoft	Barinova, O (corresponding author), Moscow MV Lomonosov State Univ, Molodezhnaya Str 111, Moscow 119296, Russia.	obarinova@graphics.cs.msu.ru; victorlempitsky@gmail.com; pkohli@microsoft.com						Ageev AA, 1999, DISCRETE APPL MATH, V93, P149, DOI 10.1016/S0166-218X(99)00103-1; Allan M, 2009, COMPUT VIS IMAGE UND, V113, P824, DOI 10.1016/j.cviu.2009.02.002; Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Andriluka M., 2008, P IEEE C COMP VIS PA; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barinova O., 2010, P 11 EUR C COMP VIS; Bourdev L., 2009, P 12 IEEE INT C COMP; CONFORTI M, 1984, DISCRETE APPL MATH, V7, P251, DOI 10.1016/0166-218X(84)90003-9; Delong A., 2010, P IEEE C COMP VIS PA; Denis P., 2008, P 10 EUR C COMP VIS; Desai C., 2009, P 12 IEEE INT C COMP; Feige U, 2007, ANN IEEE SYMP FOUND, P461, DOI 10.1109/FOCS.2007.29; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Gall J., 2009, P IEEE C COMP VIS PA; Gu C., 2009, P IEEE C COMP VIS PA; HOCHBAUM DS, 1982, MATH PROGRAM, V22, P148, DOI 10.1007/BF01581035; HOIEM D., 2007, P IEEE C COMP VIS PA; Hough P., 1959, P INT C HIGH EN ACC, V5; Kolmogorov V, 2005, IEEE I CONF COMP VIS, P564; Ladicky L., 2010, P 11 EUR C COMP VIS; Lazic N., 2009, P 12 IEEE INT C COMP; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Lehmann A., 2010, P BRIT MACH VIS C; Lehmussola A, 2007, IEEE T MED IMAGING, V26, P1010, DOI 10.1109/TMI.2007.896925; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Lempitsky V., 2010, P NEUR INF PROC SYST; Maji S., 2009, P IEEE C COMP VIS PA; Minka T., 2003, SUMMATION HACK OUTLI; NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971; Okada R., 2009, P 12 IEEE INT C COMP; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Sheikh Y. A., 2007, P 11 IEEE INT C COMP; STEPHENS RS, 1991, IMAGE VISION COMPUT, V9, P66, DOI 10.1016/0262-8856(91)90051-P; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	34	108	122	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1773	1784		10.1109/TPAMI.2012.79	http://dx.doi.org/10.1109/TPAMI.2012.79			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22450818				2022-12-18	WOS:000306409100010
J	Pan, JJ; Pan, SJ; Yin, J; Ni, LM; Yang, Q				Pan, Jeffrey Junfeng; Pan, Sinno Jialin; Yin, Jie; Ni, Lionel M.; Yang, Qiang			Tracking Mobile Users in Wireless Networks via Semi-Supervised Colocalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Wireless sensor networks; semi-supervised learning; indoor localization; colocalization; AI applications	DIMENSIONALITY REDUCTION	Recent years have witnessed the growing popularity of sensor and sensor-network technologies, supporting important practical applications. One of the fundamental issues is how to accurately locate a user with few labeled data in a wireless sensor network, where a major difficulty arises from the need to label large quantities of user location data, which in turn requires knowledge about the locations of signal transmitters or access points. To solve this problem, we have developed a novel machine learning-based approach that combines collaborative filtering with graph-based semi-supervised learning to learn both mobile users' locations and the locations of access points. Our framework exploits both labeled and unlabeled data from mobile devices and access points. In our two-phase solution, we first build a manifold-based model from a batch of labeled and unlabeled data in an offline training phase and then use a weighted k-nearest-neighbor method to localize a mobile client in an online localization phase. We extend the two-phase colocalization to an online and incremental model that can deal with labeled and unlabeled data that come sequentially and adapt to environmental changes. Finally, we embed an action model to the framework such that additional kinds of sensor signals can be utilized to further boost the performance of mobile tracking. Compared to other state-of-the-art systems, our framework has been shown to be more accurate while requiring less calibration effort in our experiments performed on three different testbeds.	[Pan, Jeffrey Junfeng] Facebook Inc, Palo Alto, CA 94304 USA; [Pan, Sinno Jialin] Inst Infocomm Res, Singapore 138632, Singapore; [Ni, Lionel M.; Yang, Qiang] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Ni, Lionel M.] Hong Kong Univ Sci & Technol, Fok Ying Tung Grad Sch, Hong Kong, Hong Kong, Peoples R China; [Ni, Lionel M.] Hong Kong Univ Sci & Technol, China Minist Educ, Microsoft Res Asia IT Key Lab, Hong Kong, Hong Kong, Peoples R China	Facebook Inc; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Hong Kong University of Science & Technology; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology	Pan, JJ (corresponding author), Facebook Inc, 1601 S Calif Ave, Palo Alto, CA 94304 USA.	panjunfeng@gmail.com; sinnocat@gmail.com; Jie.Yin@csiro.au; ni@cse.ust.hk; qyang@cse.ust.hk	yang, qiang/GYJ-0971-2022; Zhang, JinYuan/C-1542-2010; Yin, Jessie Jie/B-3850-2011; PAN, Sinno Jialin/P-6696-2014	PAN, Sinno Jialin/0000-0001-6565-3836; Yang, Qiang/0000-0001-5059-8360	Hong Kong RGC/NSFC [N_HKUST624/09]; Hong Kong RGC [621010]; Microsoft Research Asia [MRA10EG01]	Hong Kong RGC/NSFC(Hong Kong Research Grants CouncilNational Natural Science Foundation of China (NSFC)); Hong Kong RGC(Hong Kong Research Grants Council); Microsoft Research Asia(Microsoft)	The authors thank Seth Teller, Rong Pan, and Vincent Wenchen Zheng for their helpful discussions and ideas during the long run of this work in the past years. They also thank the support of Hong Kong RGC/NSFC N_HKUST624/09 and Hong Kong RGC grant 621010, and Microsoft Research Asia Grant MRA10EG01.	Bahl P., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P775, DOI 10.1109/INFCOM.2000.832252; Batalin MA, 2004, IEEE INT CONF ROBOT, P636, DOI 10.1109/ROBOT.2004.1307220; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bowling M., 2005, P 22 INT C MACHINE L, P65, DOI [10.1145/1102351.1102360, DOI 10.1145/1102351.1102360]; BRIGHAM EO, 1967, IEEE SPECTRUM, V4, P63, DOI 10.1109/MSPEC.1967.5217220; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550; Farrahi K, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889684; Ferris B., 2006, P ROB SCI SYST AUG; Ferris B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2480; Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140; Ham J., 2005, P ANN C UNC ART INT, P120; Hendrickson B., 2006, P SIAM WORKSH TEXT M; Kotanen A, 2003, PIMRC 2003: 14TH IEEE 2003 INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS PROCEEDINGS, VOLS 1-3 2003, P2218, DOI 10.1109/PIMRC.2003.1259110; Kouropteva O, 2005, PATTERN RECOGN, V38, P1764, DOI 10.1016/j.patcog.2005.04.006; Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56; LETCHNER J., 2005, P NAT C ART INT, V1, P15; Liao L, 2007, ARTIF INTELL, V171, P311, DOI 10.1016/j.artint.2007.01.006; Madigan D, 2005, IEEE INFOCOM SER, P1217; Nguyen, 2005, ACM T SENSOR NETWORK, V1, P134, DOI DOI 10.1145/1077391.1077397; Ni LM, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P407, DOI 10.1109/PERCOM.2003.1192765; Pan JJ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2166; Pan Jeffrey Junfeng, 2007, P NATL C ARTIF INTEL, P1102; Pan JJ, 2006, AAAI, P988; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Ravi Nishkam, 2005, P 17 C INN APPL ART, V3, P1541, DOI DOI 10.1007/978-3-642-02481-8_120; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Thrun S., 2005, PROBABILISTIC ROBOTI; Ward JA, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889687; Yairi T., 2007, P 24 INT C MACH LEAR, P1071; Yang Q, 2008, IEEE INTELL SYST, V23, P8, DOI 10.1109/MIS.2008.4; Youssef MA, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P143, DOI 10.1109/PERCOM.2003.1192736; Zheng Y, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889683; Zhu Xiaojin., 2003, P ICLR, P912	37	108	117	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					587	600		10.1109/TPAMI.2011.165	http://dx.doi.org/10.1109/TPAMI.2011.165			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21844623	Green Submitted			2022-12-18	WOS:000299381600013
J	Gilbert, A; Illingworth, J; Bowden, R				Gilbert, Andrew; Illingworth, John; Bowden, Richard			Action Recognition Using Mined Hierarchical Compound Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; data mining; real-time; learning; spatiotemporal		The field of Action Recognition has seen a large increase in activity in recent years. Much of the progress has been through incorporating ideas from single-frame object recognition and adapting them for temporal-based action recognition. Inspired by the success of interest points in the 2D spatial domain, their 3D (space-time) counterparts typically form the basic components used to describe actions, and in action recognition the features used are often engineered to fire sparsely. This is to ensure that the problem is tractable; however, this can sacrifice recognition accuracy as it cannot be assumed that the optimum features in terms of class discrimination are obtained from this approach. In contrast, we propose to initially use an overcomplete set of simple 2D corners in both space and time. These are grouped spatially and temporally using a hierarchical process, with an increasing search area. At each stage of the hierarchy, the most distinctive and descriptive features are learned efficiently through data mining. This allows large amounts of data to be searched for frequently reoccurring patterns of features. At each level of the hierarchy, the mined compound features become more complex, discriminative, and sparse. This results in fast, accurate recognition with real-time performance on high-resolution video. As the compound features are constructed and selected based upon their ability to discriminate, their speed and accuracy increase at each level of the hierarchy. The approach is tested on four state-of-the-art data sets, the popular KTH data set to provide a comparison with other state-of-the-art approaches, the Multi-KTH data set to illustrate performance at simultaneous multiaction classification, despite no explicit localization information provided during training. Finally, the recent Hollywood and Hollywood2 data sets provide challenging complex actions taken from commercial movie sequences. For all four data sets, the proposed hierarchical approach outperforms all other methods reported thus far in the literature and can achieve real-time operation.	[Gilbert, Andrew; Illingworth, John; Bowden, Richard] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Gilbert, A (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	a.gilbert@surrey.ac.uk; j.illingworth@surrey.ac.uk; r.bowden@surrey.ac.uk	Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020	European Commission [045062, 215078]; EPSRC [EP/H023135/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/H023135/1] Funding Source: researchfish	European Commission(European CommissionEuropean Commission Joint Research Centre); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work is supported by Ubiquitous networking Robotics in Urban Settings (URUS), funded by the European Commission under FP6 with contract number 045062, and by Dynamic Interactive Perception-action LEarning in Cognitive Systems (DIPLECS), funded by the European Commission under FP7 with contract number 215078.	AGRAWAL, 1993, P 1993 ACM SIGMOD, P207; Agrawal R., 1994, P 20 INT C VER LARG; Bregonzio M., 2009, P IEEE INT C COMP VI; Chum O., 2007, ICCV; Chum O., 2008, P BMVA BRIT MACH VIS; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; DING Q, 2002, P PAC AS C ADV KNOWL, P66; DOLLAR P, 2005, P WORKSH PERF EV TRA; Freund Y., 1996, INT C MACH LEARN; Gilbert A., 2009, P INT C COMP VIS ICC, VI, P222; GILBERT A, 2008, P EUR C COMP VI, V1, P222; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427; Harris C., 1988, P ALVEY VIS C SEPT 1; Ke Y., 2005, P IEEE INT C COMP VI; Klaser A., 2008, P BMVA BRIT MACH VIS; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I., 2007, P IEEE INT C COMP VI; Laptev I., 2008, P INT C CVPR; Lazebnik S., 2004, P BRIT MACH VIS C, V2, P959, DOI DOI 10.5244/C.18.98; LIU J, 2008, P INT C CVPR; LOWE, 2003, INT J COMPUT VISION, V20, P91; Lucas B., 1998, P 7 INT JOINT C ART, P674; Maron O, 1998, ADV NEUR IN, V10, P570; Marszalek M., 2009, P IEEE INT C COMP VI; MATIKAIEN P, 2009, P WORKSH VID OR OBJ, V1, P514; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Niebles J. C., 2007, P IEEE INT C COMP VI; NIEBLES JC, 2006, P BRIT MACH VIS C, P1249; Nowozin S., 2007, P IEEE INT C COMP VI, P1919; Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872; QUACK T, 2007, P 11 IEEE INT C COMP; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Sivic J, 2004, PROC CVPR IEEE, P488; TESIC J, 2003, P SIAM INT C DAT MIN, P7177; Tuytelaars T, 2007, IEEE I CONF COMP VIS, P754; Uemura H., 2008, P BMVA BRIT MACH VIS; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang H., 2009, P BMVA BRIT MACH VIS, p[1, 7]; Willamowski J., 2004, P IWLAVS; WILLEMS G, 2009, P BMVA BRIT MACH VIS; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wong S., 2007, P IEEE INT C COMP VI; YANG M, 2009, P WORKSH VID OR OBJ, V1, P522; Yuan JS, 2008, PROC CVPR IEEE, P47; ZHANG T, 2009, P WORKSH VID OR OBJ, V1, P538	47	108	112	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					883	897		10.1109/TPAMI.2010.144	http://dx.doi.org/10.1109/TPAMI.2010.144			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20714014	Green Submitted			2022-12-18	WOS:000288677800003
J	Monay, F; Gatica-Perez, D				Monay, Florent; Gatica-Perez, Daniel			Modeling semantic aspects for cross-media image indexing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image annotation; textual indexing; image retrieval; quantized local descriptors; latent aspect modeling	RETRIEVAL	To go beyond the query-by-example paradigm in image retrieval, there is a need for semantic indexing of large image collections for intuitive text-based image search. Different models have been proposed to learn the dependencies between the visual content of an image set and the associated text captions, then allowing for the automatic creation of semantic indexes for unannotated images. The task, however, remains unsolved. In this paper, we present three alternatives to learn a Probabilistic Latent Semantic Analysis (PLSA) model for annotated images and evaluate their respective performance for automatic image indexing. Under the PLSA assumptions, an image is modeled as a mixture of latent aspects that generates both image features and text captions, and we investigate three ways to learn the mixture of aspects. We also propose a more discriminative image representation than the traditional Blob histogram, concatenating quantized local color information and quantized local texture descriptors. The first learning procedure of a PLSA model for annotated images is a standard Expectation-Maximization ( EM) algorithm, which implicitly assumes that the visual and the textual modalities can be treated equivalently. The other two models are based on an asymmetric PLSA learning, allowing to constrain the definition of the latent space on the visual or on the textual modality. We demonstrate that the textual modality is more appropriate to learn a semantically meaningful latent space, which translates into improved annotation performance. A comparison of our learning algorithms with respect to recent methods on a standard data set is presented, and a detailed evaluation of the performance shows the validity of our framework.	Ecole Polytech Fed Lausanne, Signal Proc Inst, CH-1015 Lausanne, Switzerland; IDIAP Res Inst, CH-1920 Martigny, Switzerland; Ecole Polytech Fed Lausanne, CH-1920 Martigny, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Monay, F (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Inst, CH-1015 Lausanne, Switzerland.	florent.monay@epfl.ch; gatica@idiap.ch						Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BLEI D, 2003, P INT C RES DEV INF; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brants T, 2005, INFORM RETRIEVAL, V8, P181, DOI 10.1007/s10791-005-5658-8; Buntine W., 2002, P EUR C MACH LEARN; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079; DUYGULU P, 2002, P EUR C COMP VIS MAY; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Feifei L., 2005, 2005 IEEE COMP SOC C, P524, DOI [10.1109/CVPR.2005.16, DOI 10.1109/CVPR.2005.16]; FENG S. L., 2004, P IEEE INT C COMP VI; GIRGENSOHN A, 2004, P ACM SIGMM INT WORK; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Jeon J., 2003, P 26 INT C RES DEV I; JEON J, 2004, P IEEE INT C IM VID; LAVRENKO V, 2003, P ANN C NEUR INF PRO; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MONAY F, 2005, P PASCAL WORKSH SUBS; MONAY F, 2003, P ACM INT C MULT NOV; MORI Y., 1999, P INT WORKSH MULT IN; MUELLER H, 2002, P INT C IM VID RETR; NIBLACK W, 1993, P SPIE C STOR RETR I; ORTEGA M, 1997, P ACM INT C MULT NOV; PAN JY, 2004, P IEEE INT C MULT EX; Quelhas P, 2005, IEEE I CONF COMP VIS, P883; SHI J, 1997, P IEEE INT C COMP VI; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith J. R., 2003, P IEEE INT C MULT EX; SMITH JR, 1996, P ACM INT C MULT NOV; Sophia T., 2005, THESIS J GUTENBERG U; Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P. A., 2001, P IEEE INT C COMP VI	35	108	131	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1802	1817		10.1109/TPAMI.2007.1097	http://dx.doi.org/10.1109/TPAMI.2007.1097			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699924	Green Submitted			2022-12-18	WOS:000248696100009
J	Sim, T; Zhang, S; Janakiraman, R; Kumar, S				Sim, Terence; Zhang, Sheng; Janakiraman, Rajkumar; Kumar, Sandeep			Continuous verification using multimodal biometrics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; biometrics; fusion; verification	FUSION	Conventional verification systems, such as those controlling access to a secure room, do not usually require the user to reauthenticate himself for continued access to the protected resource. This may not be sufficient for high-security environments in which the protected resource needs to be continuously monitored for unauthorized use. In such cases, continuous verification is needed. In this paper, we present the theory, architecture, implementation, and performance of a multimodal biometrics verification system that continuously verifies the presence of a logged-in user. Two modalities are currently used-face and fingerprint-but our theory can be readily extended to include more modalities. We show that continuous verification imposes additional requirements on multimodal fusion when compared to conventional verification systems. We also argue that the usual performance metrics of false accept and false reject rates are insufficient yardsticks for continuous verification and propose new metrics against which we benchmark our system.	Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore; Gen Motors India, Bangalore 560066, Karnataka, India	National University of Singapore; General Motors	Sim, T (corresponding author), Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.	tsim@comp.nus.edu.sg; zhangshe@comp.nus.edu.sg; rajkumar@comp.nus.edu.sg; sandeep.kumar1@gm.com		Sim, Terence/0000-0002-0198-094X				Altinok Alphan, 2003, P WORKSH MULT US AUT; CARRILLO C, 2003, THESIS NAVAL POSTGRA; CROOK N, 2005, KDM HDB; Duda R.O., 2000, PATTERN CLASSIFICATI; Duin RPW, 2000, LECT NOTES COMPUT SC, V1857, P16; Janakiraman R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P501; JONCHERAY L, 1995, PROCEEDINGS OF THE FIFTH USENIX UNIX SECURITY SYMPOSIUM, P7; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KLOSTERMAN A, 2000, CMUCS00134; KUMAR S, 2005, P 21 ANN COMP SEC AP, P441; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; MORGAN AG, 2006, LINUX PAM SYSTEM ADM; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Sim T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P214, DOI 10.1109/AFGR.2000.840637; Viola P., 2002, INT J COMPUTER VISIO; Zhang S., 2006, P 2 INT C BIOM, P562; 2003, LINUX KERNEL ARCH	18	108	125	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					687	700		10.1109/TPAMI.2007.1010	http://dx.doi.org/10.1109/TPAMI.2007.1010			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299225				2022-12-18	WOS:000244855600016
J	Micusik, B; Pajdla, T				Micusik, B; Pajdla, T			Structure from motion with wide circular field of view cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						omnidirectional vision; fish-eye lens; catadioptric camera; autocalibration	CALIBRATION; DISTORTION; GEOMETRY	This paper presents a method for fully automatic and robust estimation of two-view geometry, autocalibration, and 3D metric reconstruction from point correspondences in images taken by cameras with wide circular field of view. We focus on cameras which have more than 180 degrees field of view and for which the standard perspective camera model is not sufficient, e. g., the cameras equipped with circular fish-eye lenses Nikon FC-E8 (183 degrees), Sigma 8mm-f4-EX (180 degrees), or with curved conical mirrors. We assume a circular field of view and axially symmetric image projection to autocalibrate the cameras. Many wide field of view cameras can still be modeled by the central projection followed by a nonlinear image mapping. Examples are the above-mentioned fish-eye lenses and properly assembled catadioptric cameras with conical mirrors. We show that epipolar geometry of these cameras can be estimated from a small number of correspondences by solving a polynomial eigenvalue problem. This allows the use of efficient RANSAC robust estimation to find the image projection model, the epipolar geometry, and the selection of true point correspondences from tentative correspondences contaminated by mismatches. Real catadioptric cameras are often slightly noncentral. We show that the proposed autocalibration with approximate central models is usually good enough to get correct point correspondences which can be used with accurate noncentral models in a bundle adjustment to obtain accurate 3D scene reconstruction. Noncentral camera models are dealt with and results are shown for catadioptric cameras with parabolic and spherical mirrors.	Vienna Univ Technol, Inst Comp Aided Automat, Pattern Recognit & Image Proc Grp, A-1040 Vienna, Austria; Czech Tech Univ, Dept Cybernet, Ctr Machine Percept, Prague 12135, Czech Republic	Technische Universitat Wien; Czech Technical University Prague	Micusik, B (corresponding author), Vienna Univ Technol, Inst Comp Aided Automat, Pattern Recognit & Image Proc Grp, Favoritenstr 9-1832, A-1040 Vienna, Austria.	micusik@prip.tuwien.ac.at; pajdla@cmp.felt.cvut.cz	Pajdla, Tomas/K-7954-2013	Pajdla, Tomas/0000-0001-6325-0072				Aliaga DG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P127, DOI 10.1109/ICCV.2001.937508; Bai Zhaojun, 2000, TEMPLATES SOLUTION A; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Bakstein H, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P60, DOI 10.1109/OMNVIS.2002.1044492; Barreto JP, 2001, PROC CVPR IEEE, P422; Benosman R. B., 2001, PANORAMIC VISION SEN; Brauer-Burchardt C, 2001, IEEE IMAGE PROC, P225, DOI 10.1109/ICIP.2001.958994; BRODSKY T, 1996, P EUR C COMP VIS; Derrien S, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P85, DOI 10.1109/OMNVIS.2000.853811; Fermuller C, 1998, INT J COMPUT VISION, V28, P137, DOI 10.1023/A:1008063000586; Fitzgibbon AW, 2001, PROC CVPR IEEE, P125; Fleck Margaret M., 1995, 9501 TR U IOW DEP CO; GACHTER S, 2001, P IEEE WORKSH OMN VI, P99; Geyer C, 2003, VISUAL COMPUT, V19, P405, DOI 10.1007/s00371-003-0204-4; Geyer C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P766; Geyer C, 2001, PROC CVPR IEEE, P279; Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241; GEYER C, 2000, P EUR C COMP VIS; Gluckman J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P999, DOI 10.1109/ICCV.1998.710838; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hicks RA, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P97, DOI 10.1109/OMNVIS.2000.853813; Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820; Kumler J, 2000, P SOC PHOTO-OPT INS, V4093, P360, DOI 10.1117/12.405226; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Micusik B, 2003, PROC CVPR IEEE, P485; MICUSIK B, 2004, THESIS CZECH TU PRAG; MICUSIK B, 2003, P SCAND C IM AN; MICUSIK B, 2004, P AS C COMP VIS, V2, P48; Micusik B., 2004, P IEEE C COMP VIS PA; Nister D, 2004, PROC CVPR IEEE, P560; Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853; Ray S. F., 2002, APPL PHOTOGRAPHIC OP, DOI 10.4324/9780080499253; Shah S, 1996, PATTERN RECOGN, V29, P1775, DOI 10.1016/0031-3203(96)00038-6; SHAKERNIA O, 2003, P IEEE WORKSH OMN VI; Strelow D, 2001, PROC CVPR IEEE, P689; Sturm P, 2004, LECT NOTES COMPUT SC, V3022, P1; Sturm P, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P37, DOI 10.1109/OMNVIS.2002.1044489; Sturm P, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P119, DOI 10.1109/OMNVIS.2000.853818; Svoboda T, 2002, INT J COMPUT VISION, V49, P23, DOI 10.1023/A:1019869530073; SVOBODA T, 1998, P IEEE C INT VEH, P335; SVOBODA T, 1998, P 5 EUR C COMP VIS, P218; Swaminathan R, 2000, IEEE T PATTERN ANAL, V22, P1172, DOI 10.1109/34.879797; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; TAYLOR CJ, 2003, IEEE T VISUALIZATION, V8, P171; Thirthala S, 2005, PROC CVPR IEEE, P321; Tisseur F, 2001, SIAM REV, V43, P235, DOI 10.1137/S0036144500381988; Xiong YL, 1997, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.1997.609326; YING X, 2004, P EUR C COMP VIS	50	108	111	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1135	1149		10.1109/TPAMI.2006.151	http://dx.doi.org/10.1109/TPAMI.2006.151			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792102				2022-12-18	WOS:000237424400010
J	Busch, A; Boles, WW; Sridharan, S				Busch, A; Boles, WW; Sridharan, S			Texture for script identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						script identification; wavelets and fractals; texture; document analysis; clustering; classification and association rules	DOCUMENT IMAGE BINARIZATION; WAVELET TRANSFORM; FEATURES	The problem of determining the script and language of a document image has a number of important applications in the field of document analysis, such as indexing and sorting of large collections of such images, or as a precursor to optical character recognition (OCR). In this paper, we investigate the use of texture as a tool for determining the script of a document image, based on the observation that text has a distinct visual texture. An experimental evaluation of a number of commonly used texture features is conducted on a newly created script database, providing a qualitative measure of which features are most appropriate for this task. Strategies for improving classification results in situations with limited training data and multiple font types are also proposed.	Griffith Univ, Sch Microelect Engn, Nathan, Qld 4111, Australia; Queensland Univ Technol, Sch Engn Syst, Brisbane, Qld 4001, Australia	Griffith University; Queensland University of Technology (QUT)	Busch, A (corresponding author), Griffith Univ, Sch Microelect Engn, Nathan Campus, Nathan, Qld 4111, Australia.	a.busch@griffith.edu.au; w.boles@qut.edu.au; s.sridharan@qut.edu.au	Boles, Wageeh W/I-9633-2012	Boles, Wageeh W/0000-0002-5093-2952; Busch, Andrew/0000-0002-9461-9722; Sridharan, Sridha/0000-0003-4316-9001				Acharyya M, 2002, IEEE T CIRC SYST VID, V12, P1117, DOI 10.1109/TCSVT.2002.806812; Baird H. S., 1995, DOCUMENT IMAGE ANAL, P204; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; BUSCH A, 2004, IEEE INT C AC SPEECH; BUSCH A, 2002, P IEEE INT C AC SPEE, V4, P3484; CHANG T, 1992, P IEEE INT S TIM FRE, V2, P577; Chaudhuri BB, 1997, IEEE T PATTERN ANAL, V19, P182, DOI 10.1109/34.574803; Clark P, 2000, INT C PATT RECOG, P450, DOI 10.1109/ICPR.2000.905373; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GREENSPAN H, 1994, P 12 INT C PATT REC, V2, P162; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; JIN N, 2001, P 6 INT C DOC AN REC, P1126; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; LEE CH, 1991, IEEE T SIGNAL PROCES, V39, P806, DOI 10.1109/78.80902; Lee CH, 1996, ACIAR PROC, P83; Lee SG, 1996, J MICROBIOL BIOTECHN, V6, P98; Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607; Liu Y, 1997, IEEE T PATTERN ANAL, V19, P540, DOI 10.1109/34.589217; Liu Y., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P278, DOI 10.1109/ICDAR.1993.395732; LOWTHER S, 2002, DIGITAL IMAGE COMPUT, V1, P25; MALLAT S, 1991, IEEE T INFORM THEORY, V37, P1019, DOI 10.1109/18.86995; OLIVIER J, 1994, 206 MON U; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pal U, 2001, PROC INT CONF DOC, P790, DOI 10.1109/ICDAR.2001.953896; PEAKE G, 1997, P WORKSH DOC IM AN, V1, P10; Peake G.S., 1997, P 8 BRIT MACH VIS C, V2, P230, DOI DOI 10.1109/DIA.1997.627086; Post W., 1986, P 8 INT C PATT REC, P687; REYNOLDS DA, 1997, P EUR C SPEECH COMM, V2, P963; RHEE HS, 1996, P IEEE INT C FUZZ SY, V2, P1020; Ronse C, 1984, CONNECTED COMPONENTS; Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; SPITZ AL, 1995, P INT ASS PATT REC W, P16; SUEN CY, 1998, P INT C ADV PATT REC, P297; Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305; UNSER M, 1993, SIGNAL PROCESS, V30, P141, DOI 10.1016/0165-1684(93)90144-Y; VAILAYA A, 1999, P 6 IEEE INT C IM PR, V2, P600; Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747; Wu V, 1997, P 2 ACM INT C DIG LI; YANG JD, 1994, PATTERN RECOGN LETT, V15, P141, DOI 10.1016/0167-8655(94)90043-4; YOUNIS KS, 1997, P IEEE AER EL C, V1, P503	49	108	112	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1720	1732		10.1109/TPAMI.2005.227	http://dx.doi.org/10.1109/TPAMI.2005.227			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285372	Green Submitted			2022-12-18	WOS:000231826300004
J	Bahlmann, C; Burkhardt, H				Bahlmann, C; Burkhardt, H			The writer independent online handwriting recognition system frog on hand and cluster generative statistical dynamic time warping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; handwriting analysis; Markov processes; dynamic programming; clustering		In this paper, we give a comprehensive description of our writer-independent online handwriting recognition system frog on hand. The focus of this work concerns the presentation of the classification/training approach, which we call cluster generative statistical dynamic time warping (CSDTW). CSDTW is a general, scalable, HMM-based method for variable-sized, sequential data that holistically combines cluster analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential type of data, e.g., speech recognition, genome processing, robotics, etc. Contrary to previous attempts, clustering and statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show character recognition experiments of frog on hand using CSDTW on the UNIPEN online handwriting database. The recognition accuracy is significantly higher than reported results of other handwriting recognition systems. Finally, we describe the real-time implementation of frog on hand on a Linux Compaq iPAQ embedded device.	Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany	University of Freiburg	Bahlmann, C (corresponding author), Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany.	bahlmann@informatik.uni-freiburg.de; burkhardt@informatik.uni-freiburg.de	Burkhardt, Hans/M-5895-2019					[Anonymous], 1998, STAT METHODS SPEECH; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883; Bahlmann C, 2001, PROC INT CONF DOC, P406, DOI 10.1109/ICDAR.2001.953822; BAHLMANN C, 2004, THESIS A LUDWIGS U F; BAHLMANN C, 2003, DIRECTIONAL FEATURES; Bercu S., 1993, P 3 INT WORKSH FRONT, P385; CONNELL SD, 1994, P 12 INT C PATT REC, P182; Dengel A., 1997, HDB CHARACTER RECOGN, P227; Gauthier N, 2001, PROC INT CONF DOC, P412, DOI 10.1109/ICDAR.2001.953823; GUERFALI W, 1993, PATTERN RECOGNITION, V16; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Hu JY, 2000, PATTERN RECOGN, V33, P133, DOI 10.1016/S0031-3203(99)00043-6; JAAKKOLA T, 1999, P 8 INT C IM AN PROC; JAGER S, 2000, P 7 INT WORKSH FRONT, P249; JUANG BH, 1990, IEEE T ACOUST SPEECH, V38, P1639, DOI 10.1109/29.60082; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257, DOI 10.1109/89.568732; LEE JJ, 2000, P 7 INT WORKSH FRONT, P239; MANKE S, 1996, P 5 INT WORKSH FRONT; Oates T, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P846; OATES T, 1999, IJCAI 99 WORKSH NEUR, P17; Parizeau M, 2001, PROC INT CONF DOC, P481, DOI 10.1109/ICDAR.2001.953836; Perrone M. P., 2000, P 7 INT WORKSH FRONT, P229; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Plamondon R., 1999, ENCY ELECT ELECT ENG, V15, P123; PREVOST L, 1999, P 5 INT C DOC AN REC; Rabiner L., 1993, FUNDAMENTALS SPEECH; RIGOLL G, 1994, P 12 INT C PATT REC, P1512; SCHENKEL M, 1995, MACH VISION APPL, V8, P215, DOI 10.1007/BF01219589; SCHOMAKER L, 1993, PATTERN RECOGN, V26, P443, DOI 10.1016/0031-3203(93)90171-R; Schukat-Talamazzini E.G., 1995, AUTOMATISCHE SPRACHE; Seni G, 1996, IEEE T PATTERN ANAL, V18, P757, DOI 10.1109/34.506798; SIMON K, 2003, THESIS A LUDWIGS U F; Smyth P, 1997, ADV NEUR IN, V9, P648; Theodoridis S., 2008, PATTERN RECOGN; Vuori V., 2001, International Journal on Document Analysis and Recognition, V3, P150, DOI 10.1007/PL00013555; Vuurpijl L, 1997, PROC INT CONF DOC, P387, DOI 10.1109/ICDAR.1997.619876; Wilfong G, 1996, IEEE T PATTERN ANAL, V18, P935, DOI 10.1109/34.537348; ZHANG R, 2002, P 16 INT C PATT REC	40	108	111	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					299	310		10.1109/TPAMI.2004.1262308	http://dx.doi.org/10.1109/TPAMI.2004.1262308			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376878				2022-12-18	WOS:000188949400002
J	Zhu, Y; Tan, TN; Wang, YH				Zhu, Y; Tan, TN; Wang, YH			Font recognition based on global texture analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						font recognition; texture analysts; content-independent	IDENTIFICATION; FILTERS; SEGMENTATION; FEATURES	In this paper, we describe a novel texture-analysis-based approach toward font recognition. Existing methods are typically based on local typographical features that often, require connected components analysis. In our method, we take the document as an image containing some, specific textures, and regard font recognition as texture identification. The method is content-independent and involves no detailed local feature analysis. Experiments are, carried out by using 14,000 samples of 24 frequently used Chinese fonts (six typefaces combined with four styles), as welt as 32 frequently used English fonts (eight typefaces combine with four styles). An average recognition rate of 99.1 percent is achieved. Experimental results are also included on the robustness of the method against image degradation (e.g., Pepper and Salt noise) and on the comparison with existing methods.	Chinese Acad Sci, Inst Automat, NLPR, Beijing 100080, Peoples R China; Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Chinese Academy of Sciences; Institute of Automation, CAS; University System of Georgia; Georgia Institute of Technology	Zhu, Y (corresponding author), Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.	yongzhu@cc.gatech.edu; tieniu.tan@nlpr.ia.ac.cn; yunhong.wang@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X				BOVIK AC, 1992, IEEE T INFORM THEORY, V38, P691, DOI 10.1109/18.119731; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Cooperman B, 1997, P SOC PHOTO-OPT INS, V3027, P50, DOI 10.1117/12.270079; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x; Khoubyari S, 1996, COMPUT VIS IMAGE UND, V63, P66, DOI 10.1006/cviu.1996.0005; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; PEAKE GS, 1997, P BMVC 97, V2, P169; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; Said HES, 1998, INT C PATT RECOG, P1761, DOI 10.1109/ICPR.1998.712068; SCHREYER A, 1998, P 3 DOC AN SYST WORK; Shi HW, 1997, PROC INT CONF DOC, P39, DOI 10.1109/ICDAR.1997.619810; Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305; TAN TN, 1992, P 11 IAPR INT C PATT, V3, P607, DOI DOI 10.1109/ICPR.1992.202060; TURNER MR, 1986, BIOL CYBERN, V55, P71; Zramdini A, 1998, IEEE T PATTERN ANAL, V20, P877, DOI 10.1109/34.709616	17	108	116	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1192	1200		10.1109/34.954608	http://dx.doi.org/10.1109/34.954608			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK					2022-12-18	WOS:000171586600012
J	Carreira-Perpinan, MA				Carreira-Perpinan, MA			Mode-finding for mixtures of Gaussian distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian mixtures; maximization algorithms; mode finding; bump finding; error bars; sparseness		Gradient-quadratic and fixed-point Iteration algorithms and appropriate Values for their control parameters are derived for finding all modes of a Gaussian mixture, a problem with applications in clustering and regression. The significance of the modes found is quantified locally by Hessian-based error bars and globally by the entropy as sparseness measure.	Georgetown Univ, Med Ctr, Dept Neurosci, Washington, DC 20007 USA; Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England	Georgetown University; University of Sheffield	Carreira-Perpinan, MA (corresponding author), Georgetown Univ, Med Ctr, Dept Neurosci, Washington, DC 20007 USA.	miguel@giccs.georgetown.edu						Bishop, 1995, NEURAL NETWORKS PATT; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Carreira-Perpinan MA, 2000, ADV NEUR IN, V12, P414; CARREIRAPERPINA.MA, 1999, CS9903 U SHEFF DEP C; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; Gelman A, 2013, BAYESIAN DATA ANAL, P16; GENEST C, 1986, STAT SCI, V1, P135; Genest C., 1986, STAT SCI, P114, DOI [10.1214/ss/1177013825, DOI 10.1214/SS/1177013825]; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; Isaacson E., 1966, ANAL NUMERICAL METHO; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; PISANI A, 1993, MON NOT R ASTRON SOC, V265, P706, DOI 10.1093/mnras/265.3.706; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Rabiner L., 1993, FUNDAMENTALS SPEECH; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Titterington DM, 1985, STAT ANAL FINITE MIX; Vapnik VN, 2000, ADV NEUR IN, V12, P659; WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2; ZHANG RD, 1994, PATTERN RECOGN, V27, P135, DOI 10.1016/0031-3203(94)90023-X	28	108	110	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1318	1323		10.1109/34.888716	http://dx.doi.org/10.1109/34.888716			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200009
J	Suarez, A; Lutsko, JF				Suarez, A; Lutsko, JF			Globally optimal fuzzy decision trees for classification and regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic learning; decision trees; fuzzy set theory; global optimization; backpropagation; nonparametric regression; classification	CLASSIFIERS; ALGORITHM; DESIGN	A fuzzy decision tree is constructed by allowing the possibility of partial membership of a point in the nodes that make up the tree structure. This extension of its expressive capabilities transforms the decision tree into a powerful functional approximant that incorporates features of connectionist methods, while remaining easily interpretable. Fuzzification is achieved by superimposing a fuzzy structure over the skeleton of a CART decision tree. A training rule for fuzzy trees, similar to backpropagation in neural networks, is designed. This rule corresponds to a global optimization algorithm that fixes the parameters of the fuzzy splits. The method developed for the automatic generation of fuzzy decision trees is applied to both classification and regression problems. In regression problems, it is seen that the continuity constraint imposed by tt-re function representation of the fuzzy tree leads to substantial improvements in the quality of the regression and limits the tendency to overfitting. In classification, fuzzification provides a means of uncovering the structure of the probability distribution for the classification errors in attribute space. This allows the identification of regions for which the error rate of the tree is significantly tower than the average error rate, sometimes even below the Bayes misclassification rate.	Univ Autonoma Madrid, Escuela Tecn Super Informat, E-28049 Madrid, Spain; I2 Technol, B-1932 Sint Stevens Woluwe, Belgium	Autonomous University of Madrid	Suarez, A (corresponding author), Univ Autonoma Madrid, Escuela Tecn Super Informat, Ctra Colmenar Viejo,Km 15, E-28049 Madrid, Spain.		Suárez, Alberto/D-6293-2011	Suárez, Alberto/0000-0003-4534-0909				CHANG RLP, 1977, IEEE T SYST MAN CYB, V7, P28, DOI 10.1109/TSMC.1977.4309586; Cherkassky V, 1996, IEEE T NEURAL NETWOR, V7, P969, DOI 10.1109/72.508939; CHERKASSKY V, 1994, SELECTING MODELS DAT, P383; CHERKASSKY V, COMMUNICATION; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; FRIEDMAN S, 1991, ENDOD DENT TRAUMATOL, V7, P19; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; Hellendoorn H., 1997, FUZZY MODEL IDENTIFI; Hertz J., 1991, INTRO THEORY NEURAL, DOI DOI 10.1201/9780429499661; JANG JSR, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P480, DOI 10.1109/FUZZY.1994.343738; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KANDEL A, 1982, FUZZY TECHNIQUES PAT; Kasabov N.K., 1996, FDN NEURAL NETWORKS; MAHER PE, 1993, P 2 IEEE INT C FUZZ, P7; Olshen R., 1984, CLASSIFICATION REGRE; PARK YT, 1994, PATTERN RECOGN, V27, P1493, DOI 10.1016/0031-3203(94)90127-9; Press WH., 1993, NUMERICAL RECIPES C; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Quinlan J. R., 1987, Proceedings of the Fourth International Workshop on Machine Learning, P31; SCHUERMANN J, 1984, PATTERN RECOGN, V17, P359, DOI 10.1016/0031-3203(84)90087-6; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; Sethi IK, 1997, PATTERN RECOGN, V30, P1893, DOI 10.1016/S0031-3203(97)00005-8; SETHI IK, 1995, IEEE T SYST MAN CYB, V25, P1243, DOI 10.1109/21.398685; SHAVLIK J, 1995, HDB BRAIN THEORY NEU, P533; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399; WANG MX, 1987, J NANJING FOR U, V9, P1; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1977, CLASSIFICATION CLUST	31	108	108	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1297	1311		10.1109/34.817409	http://dx.doi.org/10.1109/34.817409			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG					2022-12-18	WOS:000084828100004
J	Phillips, IT; Chhabra, AK				Phillips, IT; Chhabra, AK			Empirical performance evaluation of graphics recognition systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						empirical evaluation; benchmark; graphics recognition; engineering-drawing	DRAWING UNDERSTANDING SYSTEM	This paper presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks. it enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems. The methodology includes a set of matching criteria for pairs of graphical entities, a set of performance evaluation metrics, and a benchmark for the evaluation of graphics recognition systems. The benchmark was tested on three systems. The results are reported and analyzed in this paper.	Seattle Univ, Dept Comp Sci Software Engn, Seattle, WA 98122 USA; Bell Atlantic Network Syst, Adv Technol, White Plains, NY 10604 USA	Seattle University	Phillips, IT (corresponding author), Seattle Univ, Dept Comp Sci Software Engn, Seattle, WA 98122 USA.	yun@seattleu.edu; atul@basit.com						*AUT INC, 1995, AUT CAD REL 13 CUST; Baird H., 1990, P IAPR WORKSH SYNT S, P38; CHHABRA A, WEB PAGE 2 INT GRAPH; CHHABRA A, 1998, EMPIRICAL EVALUATION, P28; Chhabra AK, 1998, LECT NOTES COMPUT SC, V1389, P390; Dori D., 1998, International Journal on Document Analysis and Recognition, V1, P62; DORI D, 1995, PATTERN RECOGN LETT, V16, P377, DOI 10.1016/0167-8655(94)00105-C; DORI D, 1995, IEEE T PATTERN ANAL, V17, P1057, DOI 10.1109/34.473231; Dori D., 1995, Journal of Logic and Computation, V5, P227, DOI 10.1093/logcom/5.2.227; Egan J.P., 1975, SIGNAL DETECTION THE; HARALICK RM, 1992, PATTERN RECOGN LETT, V13, P5, DOI 10.1016/0167-8655(92)90108-C; Hori O., 1996, LECT NOTES COMPUTER, V1072, P57; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; KASTURI R, 1996, LECT NOTES COMPUTER, V1072; KNAUNGO T, 1996, THESIS U WASHINGTON; Knuth D E, 1997, ART COMPUTER PROGRAM, V2; KONG B, 1996, LECT NOTES COMPUTER, V1072, P270; Liu WY, 1997, MACH VISION APPL, V9, P240, DOI 10.1007/s001380050045; Liu WY, 1998, LECT NOTES COMPUT SC, V1389, P359; ORourke J., 1994, COMPUTATIONAL GEOMET; PHILLIPS I, USERS REFERENCE MANU; Phillips IT, 1998, LECT NOTES COMPUT SC, V1389, P372; WENYIN L, 1996, P IAPR WORKSH DOC AN, P241	23	108	110	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					849	870		10.1109/34.790427	http://dx.doi.org/10.1109/34.790427			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600003
J	Ohba, K; Ikeuchi, K				Ohba, K; Ikeuchi, K			Detectability, uniqueness, and reliability of eigen windows for stable verification of partially occluded objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; multiple objects; eigenspace; detectability; uniqueness; reliability	RECOGNITION	This paper describes a method for recognizing partially occluded objects for bin-picking tasks using eigenspace analysis, referred to as the ''eigen window'' method, that stares multiple partial appearances of an object in an eigenspace. Such partial appearances require a large amount of memory space. Three measurements, detectability, uniqueness, and reliability, on windows are developed to eliminate redundant windows and thereby reduce memory requirements. Using a pose clustering technique, the method determines the pose of an object and the object type itself. We have implemented the method and verified its Validity.	UNIV TOKYO, INST IND SCI, TOKYO, JAPAN	University of Tokyo	Ohba, K (corresponding author), MINIST INT TRADE & IND, MECH ENGN LAB, TSUKUBA, IBARAKI, JAPAN.		Ohba, Kohtaro/C-3519-2017	Ohba, Kohtaro/0000-0001-6909-3530				AGIN GJ, 1975, P 2 US JAP COMP C, P113; BIRK JR, 1981, IEEE T SYST MAN CYB, V11, P151, DOI 10.1109/TSMC.1981.4308640; BOLLES RC, P INT JOINT C ART IN, P1116; Fukada Y., 1984, Robotica, V2, P147, DOI 10.1017/S0263574700000849; HORN BKP, 1984, SCI AM, V251, P100, DOI 10.1038/scientificamerican0884-100; HUTCHINSON SA, 1990, AI MAG, V11, P30; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KRUMM J, 1996, P IEEE CS C COMP VIS; MOGHADDAM B, 1995, P 5 INT C COMP VIS; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; MURASE H, 1995, P 9 SCAND C IM AN, P325; NAYAR SK, 1994, P IEEE INT C ROB AUT; OHBA K, 1996, P INT C PATTERN RECO; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; PENTLAND A, 1994, IEEE C COMPUTER VISI; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SCLAROFF S, 1993, P 4 INT C COMP VIS, P308; TOMASI C, 1991, CMUCS91105; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; UENOHARA M, 1995, P 1 INT C COMP VIS R	21	108	108	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					1043	1048		10.1109/34.615453	http://dx.doi.org/10.1109/34.615453			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985		Green Published			2022-12-18	WOS:A1997XX98500010
