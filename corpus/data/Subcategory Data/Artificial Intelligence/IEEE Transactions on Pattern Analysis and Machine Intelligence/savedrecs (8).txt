PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Tau, M; Hassner, T				Tau, Moria; Hassner, Tal			Dense Correspondences across Scenes and Scales	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image representation; feature representation	FLOW	We seek a practical method for establishing dense correspondences between two images with similar content, but possibly different 3D scenes. One of the challenges in designing such a system is the local scale differences of objects appearing in the two images. Previous methods often considered only few image pixels; matching only pixels for which stable scales may be reliably estimated. Recently, others have considered dense correspondences, but with substantial costs associated with generating, storing and matching scale invariant descriptors. Our work is motivated by the observation that pixels in the image have contexts-the pixels around them-which may be exploited in order to reliably estimate local scales. We make the following contributions. (i) We show that scales estimated in sparse interest points may be propagated to neighboring pixels where this information cannot be reliably determined. Doing so allows scale invariant descriptors to be extracted anywhere in the image. (ii) We explore three means for propagating this information: using the scales at detected interest points, using the underlying image information to guide scale propagation in each image separately, and using both images together. Finally, (iii), we provide extensive qualitative and quantitative results, demonstrating that scale propagation allows for accurate dense correspondences to be obtained even between very different images, with little computational costs beyond those required by existing methods.	[Tau, Moria; Hassner, Tal] Open Univ Israel, Dept Math & Comp Sci, Raanana, Israel; [Hassner, Tal] Univ So Calif, Inst Informat Sci, Los Angeles, CA 90089 USA	Open University Israel; University of Southern California	Tau, M; Hassner, T (corresponding author), Open Univ Israel, Dept Math & Comp Sci, Raanana, Israel.; Hassner, T (corresponding author), Univ So Calif, Inst Informat Sci, Los Angeles, CA 90089 USA.	moria.tau@gmail.com; hassner@openu.ac.il						Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Baker S., 2001, INT J COMPUT VISION, V92, P1; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Basri Ronen, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P109, DOI 10.1109/ICCVW.2009.5457710; Basri R., 2007, COMPUTER VISION PATT, P1; Basri R, 2011, IEEE T PATTERN ANAL, V33, P266, DOI 10.1109/TPAMI.2010.110; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; Hartley R., 2004, ROBOTICA; Hassner T., DENSE IMAGE CORRESPO; Hassner T., 2013, ARXIV13043915; Hassner T., 2006, 2006 C COMP VIS PATT, P15, DOI DOI 10.1109/CVPRW.2006.76; Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448; Hassner T, 2013, PROC INT CONF DOC, P1310, DOI 10.1109/ICDAR.2013.265; Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842; Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kokkinos I., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587798; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Leordeanu M, 2013, IEEE I CONF COMP VIS, P1721, DOI 10.1109/ICCV.2013.216; Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780; Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lindeberg T., 1999, HDB COMPUTER VISION, P239; LIU C, 2008, P 10 EUR C COMP VIS; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; MIKOLAJCZYK K, 2002, THESIS I NAT POLYTEC; Qiu WC, 2014, IEEE WINT CONF APPL, P1112, DOI 10.1109/WACV.2014.6835734; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7; Sadeh G., 2015, P INT C DOC AN REC; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Torralba A, 2003, PROC CVPR IEEE, P383; Trulls E, 2013, PROC CVPR IEEE, P2890, DOI 10.1109/CVPR.2013.372; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435; Zomet A, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P27, DOI 10.1109/ACV.2002.1182150	48	25	25	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					875	888		10.1109/TPAMI.2015.2474356	http://dx.doi.org/10.1109/TPAMI.2015.2474356			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26336115	Green Submitted			2022-12-18	WOS:000374164700004
J	Jalba, AC; Sobiecki, A; Telea, AC				Jalba, Andrei C.; Sobiecki, Andre; Telea, Alexandru C.			An Unified Multiscale Framework for Planar, Surface, and Curve Skeletonization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Medial axes; skeleton regularization; physically-based shape processing	SHAPE; TRANSFORM; ALGORITHM; MODELS; IMAGE	Computing skeletons of 2D shapes, and medial surface and curve skeletons of 3D shapes, is a challenging task. In particular, there is no unified framework that detects all types of skeletons using a single model, and also produces a multiscale representation which allows to progressively simplify, or regularize, all skeleton types. In this paper, we present such a framework. We model skeleton detection and regularization by a conservative mass transport process from a shape's boundary to its surface skeleton, next to its curve skeleton, and finally to the shape center. The resulting density field can be thresholded to obtain a multiscale representation of progressively simplified surface, or curve, skeletons. We detail a numerical implementation of our framework which is demonstrably stable and has high computational efficiency. We demonstrate our framework on several complex 2D and 3D shapes.	[Jalba, Andrei C.] Eindhoven Univ Technol, Inst Math & Comp Sci, NL-5600 MB Eindhoven, Netherlands; [Sobiecki, Andre; Telea, Alexandru C.] Univ Groningen, Johann Bernoulli Inst Math & Comp Sci, Groningen, Netherlands	Eindhoven University of Technology; University of Groningen	Jalba, AC (corresponding author), Eindhoven Univ Technol, Inst Math & Comp Sci, POB 513, NL-5600 MB Eindhoven, Netherlands.	a.c.jalba@tue.nl; a.sobiecki@rug.nl; a.c.telea@rug.nl			CNPq, Brazil [202535/2011-8]	CNPq, Brazil(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ))	The authors acknowledge the financial support of CNPq, Brazil, through the grant 202535/2011-8, and the help of the authors of [3] in providing us their DDS method implementation. Andrei C. Jalba is the corresponding author.	Ahuja N, 1997, IEEE T PATTERN ANAL, V19, P169, DOI 10.1109/34.574801; AMENTA N, 2001, P SMA, P65; Arcelli C, 2011, IEEE T PATTERN ANAL, V33, P709, DOI 10.1109/TPAMI.2010.140; Aslan C, 2008, IEEE T PATTERN ANAL, V30, P2188, DOI 10.1109/TPAMI.2007.70842; Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769; Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P169, DOI 10.1016/0167-8655(94)90046-9; Biben T, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.041921; Bouix S, 2005, MED IMAGE ANAL, V9, P209, DOI 10.1016/j.media.2004.06.026; C AU O. K., 2008, P ACM SIGGRAPH, P441; Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI DOI 10.1109/SMI.2010.25; CAO T., 2010, P ACM SIGGRAPH S INT, P134; Chang MC, 2009, COMPUT VIS IMAGE UND, V113, P1130, DOI 10.1016/j.cviu.2009.04.001; Chuang M, 2011, COMPUT GRAPH FORUM, V30, P1750, DOI 10.1111/j.1467-8659.2011.01899.x; Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0; Damon J, 2006, GEOM TOPOL, V10, P2385, DOI 10.2140/gt.2006.10.2385; Dey K., 2006, P S GEOMETRY PROCESS, V6, P143; Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y; Ebert D., 2002, P S DATA VISUALISATI, P251; Falcao AX, 2002, PATTERN RECOGN, V35, P1571, DOI 10.1016/S0031-3203(01)00148-0; FOSKEY M., 2003, P SMA, p[135, 6, 8, 11]; Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075; Giblin P, 2004, IEEE T PATTERN ANAL, V26, P238, DOI 10.1109/TPAMI.2004.1262192; Giesen J, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P106, DOI 10.1145/1542362.1542388; Han X, 2003, IEEE T PATTERN ANAL, V25, P755, DOI 10.1109/TPAMI.2003.1201824; Hassouna MS, 2009, IEEE T PATTERN ANAL, V31, P2257, DOI 10.1109/TPAMI.2008.271; Hesselink WH, 2008, IEEE T PATTERN ANAL, V30, P2204, DOI 10.1109/TPAMI.2008.21; Iwanowski M, 2007, LECT NOTES COMPUT SC, V4432, P606; Jalba AC, 2013, IEEE T PATTERN ANAL, V35, P1495, DOI 10.1109/TPAMI.2012.212; Ju T, 2007, COMPUT AIDED DESIGN, V39, P352, DOI 10.1016/j.cad.2007.02.006; Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Kustra J, 2013, P 8 INT JOINT C COMP, V2, P237; Lentine M, 2011, J COMPUT PHYS, V230, P2857, DOI 10.1016/j.jcp.2010.12.036; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; Leymarie FF, 2007, IEEE T PATTERN ANAL, V29, P313, DOI 10.1109/TPAMI.2007.44; Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343; Liu L, 2010, COMPUT GRAPH FORUM, V29, P2253, DOI 10.1111/j.1467-8659.2010.01814.x; Livesu M, 2012, IEEE T VIS COMPUT GR, V18, P1891, DOI 10.1109/TVCG.2012.71; Ma J, 2012, VISUAL COMPUT, V28, P7, DOI 10.1007/s00371-011-0594-7; Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7; Maragos P., 2000, Fundamenta Informaticae, V41, P91; MIKLOS B, 2010, P ACM SIGGRAPH, P394; Ming W, 2001, IEEE VISUAL, P239, DOI 10.1109/VISUAL.2001.964517; Mortara M., 2004, P 9 ACM S SOL MOD AP, P339; Neumann L, 2000, COMPUT GRAPH FORUM, V19, pC351, DOI 10.1111/1467-8659.00427; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; Palagyi K, 1999, LECT NOTES COMPUT SC, V1568, P325; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Pizer SM, 2003, INT J COMPUT VISION, V55, P155, DOI 10.1023/A:1026135101267; Prohaska S, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P29, DOI 10.1109/VISUAL.2002.1183753; Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680; Reniers D, 2008, IEEE T VIS COMPUT GR, V14, P355, DOI [10.1109/TVCG.2008.23, 10.1109/TC.2007.70786]; Rossi L, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P371, DOI 10.1109/3DIMPVT.2012.30; Rumpf M., 2002, P S DAT VIS, p[151, 151]; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Sethian J. A., 2002, LEVEL SET METHODS FA; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; SIDDIQI K., 2009, MEDIAL REPRESENTATIO; Sobiecki Andre, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P425, DOI 10.1007/978-3-642-38294-9_36; Sobiecki A, 2014, PATTERN RECOGN LETT, V47, P147, DOI 10.1016/j.patrec.2014.01.012; Stolpner S., 2009, P IEEE 3DIM, P87; Stolpner S, 2011, COMPUT VIS IMAGE UND, V115, P695, DOI 10.1016/j.cviu.2010.10.014; Strzodka R, 2004, P EG IEEE TCVG S VIS, P221, DOI DOI 10.2312/VISSYM/VISSYM04/221-230; SUD A., 2005, P SPM, P103; TAGLIASACCHI A., 2009, P SIGGRAPH, P541; Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x; Telea A., 2012, P THEOR PRACT COMP G, P99; Thomas H., 2007, STUD LOGIC GRAMMAR R, V10, P567; Torsello A, 2006, IEEE T IMAGE PROCESS, V15, P877, DOI 10.1109/TIP.2005.863951; van Dortmont MAMM, 2006, LECT NOTES COMPUT SC, V4245, P617	72	25	26	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					30	45		10.1109/TPAMI.2015.2414420	http://dx.doi.org/10.1109/TPAMI.2015.2414420			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656576	Green Published			2022-12-18	WOS:000366669200003
J	Attanasi, A; Cavagna, A; Del Castello, L; Giardina, I; Jelic, A; Melillo, S; Parisi, L; Pellacini, F; Shen, E; Silvestri, E; Viale, M				Attanasi, Alessandro; Cavagna, Andrea; Del Castello, Lorenzo; Giardina, Irene; Jelic, Asja; Melillo, Stefania; Parisi, Leonardo; Pellacini, Fabio; Shen, Edward; Silvestri, Edmondo; Viale, Massimiliano			GReTA-A Novel Global and Recursive Tracking Algorithm in Three Dimensions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tracking; 3D; multi-object; multi-path; branching; global optimization; recursion; divide and conquer		Tracking multiple moving targets allows quantitative measure of the dynamic behavior in systems as diverse as animal groups in biology, turbulence in fluid dynamics and crowd and traffic control. In three dimensions, tracking several targets becomes increasingly hard since optical occlusions are very likely, i.e., two featureless targets frequently overlap for several frames. Occlusions are particularly frequent in biological groups such as bird flocks, fish schools, and insect swarms, a fact that has severely limited collective animal behavior field studies in the past. This paper presents a 3D tracking method that is robust in the case of severe occlusions. To ensure robustness, we adopt a global optimization approach that works on all objects and frames at once. To achieve practicality and scalability, we employ a divide and conquer formulation, thanks to which the computational complexity of the problem is reduced by orders of magnitude. We tested our algorithm with synthetic data, with experimental data of bird flocks and insect swarms and with public benchmark datasets, and show that our system yields high quality trajectories for hundreds of moving targets with severe overlap. The results obtained on very heterogeneous data show the potential applicability of our method to the most diverse experimental situations.	[Cavagna, Andrea; Del Castello, Lorenzo; Giardina, Irene; Melillo, Stefania; Parisi, Leonardo; Viale, Massimiliano] Univ Roma La Sapienza, Dipartimento Fis, I-00185 Rome, Italy; [Cavagna, Andrea; Del Castello, Lorenzo; Giardina, Irene; Melillo, Stefania; Parisi, Leonardo; Viale, Massimiliano] CNR, Ist Sistemi Complessi, Uos Sapienza, I-00185 Rome, Italy; [Pellacini, Fabio] Univ Roma La Sapienza, Dipartimento Informat, I-00198 Rome, Italy; [Jelic, Asja] Abdus Salam Int Ctr Theoret Phys, I-34014 Trieste, Italy; [Shen, Edward] Bublcam Technol Inc, Toronto, ON, Canada; [Attanasi, Alessandro; Silvestri, Edmondo] SISTeMA ITS Srl, I-00153 Rome, Italy	Sapienza University Rome; Consiglio Nazionale delle Ricerche (CNR); Istituto dei Sistemi Complessi (ISC-CNR); Sapienza University Rome; Abdus Salam International Centre for Theoretical Physics (ICTP)	Attanasi, A (corresponding author), Co SISTeMA ITS, Cleveland, OH 44103 USA.	alexapta@gmail.com; andrea.cavagna@roma1.infn.it; lorenzodelcastello@gmail.com; irene.giardina@roma1.infn.it; asja.jelic@gmail.com; stefania.melillo79@gmail.com; leonardo.parisi@gmail.com; pellacini@di.uniroma1.it; ed.shen99@gmail.com; edmondo.silvestri@gmail.com; massimiliano.viale@gmail.com	Giardina, Irene/O-4211-2015; cavagna, andrea/B-6400-2008; Parisi, Leonardo/G-9408-2018; Viale, Massimiliano/AAK-6302-2021	Giardina, Irene/0000-0001-6900-1739; cavagna, andrea/0000-0003-2057-5971; Parisi, Leonardo/0000-0001-6425-5887; Viale, Massimiliano/0000-0003-4808-4103	IIT-Seed Artswarm; ERC-StG [257126]; University of Maryland [AFOSR-FA95501010250]; Intel	IIT-Seed Artswarm; ERC-StG; University of Maryland; Intel(Intel Corporation)	This work was supported by grants IIT-Seed Artswarm, ERC-StG n. 257126, and AFOSR-FA95501010250 (through the University of Maryland). F. Pellacini was partially supported by Intel. We acknowledge the advice of Carlo Lucibello on multi-objective optimization. L. Del Castello is the corresponding author.	ADRIAN RJ, 1991, ANNU REV FLUID MECH, V23, P261, DOI 10.1146/annurev.fl.23.010191.001401; Ardekani R., 2012, J R SOC INTERFACE, V10, P78; Attanasi A, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238102; Attanasi A, 2014, NAT PHYS, V10, P692, DOI [10.1038/nphys3035, 10.1038/NPHYS3035]; Attanasi A, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003697; Bialek W, 2014, P NATL ACAD SCI USA, V111, P7212, DOI 10.1073/pnas.1324045111; Biferale L, 2008, PHYS FLUIDS, V20, DOI 10.1063/1.2930672; Butail S, 2012, J R SOC INTERFACE, V9, P2624, DOI 10.1098/rsif.2012.0150; Butail S, 2011, IEEE ENG MED BIO, P720, DOI 10.1109/IEMBS.2011.6090163; Butail S, 2010, IEEE INT CONF ROBOT, P2438, DOI 10.1109/ROBOT.2010.5509566; Cavagna A, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2012.2484; *CPLEX OPT INC, 1994, US CPLEX CALL LIB; CULLEN JM, 1965, ANIM BEHAV, V13, P534, DOI 10.1016/0003-3472(65)90117-X; DAHMEN HJ, 1984, PROC R SOC SER B-BIO, V222, P107, DOI 10.1098/rspb.1984.0051; Doh DH, 2000, EXP FLUIDS, V29, pS85, DOI 10.1007/s003480070011; Fisher M. L., 2004, Management Science, V50, P1861, DOI 10.1287/mnsc.1040.0263; Hai Shan Wu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P593, DOI 10.1109/ICCVW.2009.5457649; Hartley R., 2003, MULTIPLE VIEW GEOMET; Keni B., 2008, EURASIP J IMAGE VIDE, V2008; Liu Y, 2012, LECT NOTES COMPUT SC, V7575, P730, DOI 10.1007/978-3-642-33765-9_52; Luthi B, 2005, J FLUID MECH, V528, P87, DOI 10.1017/S0022112004003283; MALIK NA, 1993, EXP FLUIDS, V15, P279; Messac A, 2003, STRUCT MULTIDISCIP O, V25, P86, DOI 10.1007/s00158-002-0276-1; Ouellette NT, 2006, EXP FLUIDS, V40, P301, DOI 10.1007/s00348-005-0068-7; PARETO V, 1964, COUR EC POLITIQUE; POMEROY H, 1992, AUK, V109, P256; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Straw AD, 2011, J R SOC INTERFACE, V8, P395, DOI 10.1098/rsif.2010.0230; Veeraraghavan A., 2006, P IEEE INT C AC SPEE, V2, pII; Willneff J, 2002, INT ARCH PHOTOGR REM, V34, P601; Wu H. S., 2011, OPT EXPRESS, V19, P8; Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047; Wu Z, 2014, IEEE COMPUT SOC CONF, P201, DOI 10.1109/CVPRW.2014.39; Wu Z, 2011, PROC CVPR IEEE, P1185, DOI 10.1109/CVPR.2011.5995515; Wu Z, 2009, IEEE I CONF COMP VIS, P1546; Zou D, 2009, IEEE I CONF COMP VIS, P1578, DOI 10.1109/ICCV.2009.5459358	36	25	26	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2451	2463		10.1109/TPAMI.2015.2414427	http://dx.doi.org/10.1109/TPAMI.2015.2414427			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539850	Green Submitted			2022-12-18	WOS:000364831700008
J	Leordeanu, M; Sukthankar, R; Sminchisescu, C				Leordeanu, Marius; Sukthankar, Rahul; Sminchisescu, Cristian			Generalized Boundaries from Multiple Image Interpretations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Edge; boundary and contour detection; occlusion boundaries; soft image segmentation; computer vision	EDGE-DETECTION; COLOR	Boundary detection is a fundamental computer vision problem that is essential for a variety of tasks, such as contour and region segmentation, symmetry detection and object recognition and categorization. We propose a generalized formulation for boundary detection, with closed-form solution, applicable to the localization of different types of boundaries, such as object edges in natural images and occlusion boundaries from video. Our generalized boundary detection method (Gb) simultaneously combines low-level and mid-level image representations in a single eigenvalue problem and solves for the optimal continuous boundary orientation and strength. The closed-form solution to boundary detection enables our algorithm to achieve state-of-the-art results at a significantly lower computational cost than current methods. We also propose two complementary novel components that can seamlessly be combined with Gb: first, we introduce a soft-segmentation procedure that provides region input layers to our boundary detection algorithm for a significant improvement in accuracy, at negligible computational cost; second, we present an efficient method for contour grouping and reasoning, which when applied as a final post-processing stage, further increases the boundary detection performance.	[Leordeanu, Marius] Romanian Acad IMAR, Inst Math, Bucharest 010702, Romania; [Sukthankar, Rahul] Google Res, Mountain View, CA 94043 USA; [Sminchisescu, Cristian] Lund Univ, Dept Math, S-22100 Lund, Skane, Sweden	Institute of Mathematics of the Romanian Academy; Romanian Academy of Sciences; University of Bucharest; Google Incorporated; Lund University	Leordeanu, M (corresponding author), Romanian Acad IMAR, Inst Math, Bucharest 010702, Romania.	marius.leordeanu@imar.ro; rahuls@cs.cmu.edu; cristian.sminchisescu@math.lth.se			CNCS-UEFICSDI [PNII RU-RC-2/2009, PCE-2011-3-0438, PCE-2012-4-0581, CT-ERC-2012-1]	CNCS-UEFICSDI	The authors would like to thank A. Zanfir for helping with parts of the code. This work was supported in part by CNCS-UEFICSDI, under PNII RU-RC-2/2009, PCE-2011-3-0438, PCE-2012-4-0581, and CT-ERC-2012-1.	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Baker S., 1997, P 1997 DARPA IUW; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Catanzaro B., 2009, P IEEE 12 ICCV KYOT; CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; Dollar P., 2006, P IEEE COMP SOC C CV; Elder J., 1995, P 4 ECCV CAMBR UK; Felzenszwalb P., 2006, P C CVPRW WASH DC US; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Hariharan B., 2011, P IEEE ICCV BARC SPA; He X., 2010, P 11 ECCV HER GREEC; Ion A., 2011, P IEEE ICCV BARC SPA; Kanade T., 1987, P DARPA IUW; Kokkinos I., 2010, P IEEE C CVPR SAN FR; Kokkinos I., 2010, P 11 ECCV HER GREEC; Konishi S., 1999, P IEEE COMP SOC C CV; Koschan A, 2005, IEEE SIGNAL PROC MAG, V22, P64, DOI 10.1109/MSP.2005.1407716; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Leordeanu M., 2007, P CVPR; Leordeanu M., 2012, P 12 ECCV FLOR IT; Levin A., 2006, P CVPR; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; Mairal J., 2008, P 10 ECCV MARS FRANC; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560; Morron M., 1987, PATTERN RECOGNIT LET; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; Palmer S.E., 1999, VISION SCI PHOTONS P; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Perez P., 2001, P 8 IEEE ICCV VANC B; Perona P., 1990, P 3 ICCV OS JAP; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Prewitt J., 1970, PICTURE PROCESSING P, VVolume 10; Ren X., 2005, P 10 IEEE ICCV; Ren X., 2012, P NIPS; Ren X., 2008, P 10 ECCV MARS FRANC; Roberts L., 1965, MACHINE PERCEPTION 3; Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118; Sargin M., 2009, P IEEE 12 ICCV KYOT; Shashua A., 1988, P 2 ICCV TAMP FL US; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Snoek C., 2005, P 13 ACM ICM NEW YOR; Stein A., 2008, P IEEE C CVPR ANCH A; Stein AN, 2009, INT J COMPUT VISION, V82, P325, DOI 10.1007/s11263-008-0203-z; Sun D., 2010, P IEEE C CVPR SAN FR; Sundberg P., 2011, P IEEE C CVPR; Trulls E., P 2013 IEEE C CVPR W; Widynski N., 2012, P 12 ECCV FLOR IT; Williams L., 1995, P ICCV; Ye G., 2012, P IEEE C CVPR PROV R; Zhu Q., 1988, P 2 ICCV TAMP FL US	54	25	27	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1312	1324		10.1109/TPAMI.2014.17	http://dx.doi.org/10.1109/TPAMI.2014.17			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353305	Green Submitted, Green Published, hybrid			2022-12-18	WOS:000338209900003
J	Evangelidis, GD; Bauckhage, C				Evangelidis, Georgios D.; Bauckhage, Christian			Efficient Subframe Video Alignment Using Short Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video synchronization; spatiotemporal alignment; image/video retrieval; short image descriptors		This paper addresses the problem of video alignment. We present efficient approaches that allow for spatiotemporal alignment of two sequences. Unlike most related works, we consider independently moving cameras that capture a 3D scene at different times. The novelty of the proposed method lies in the adaptation and extension of an efficient information retrieval framework that casts the sequences as an image database and a set of query frames, respectively. The efficient retrieval builds on the recently proposed quad descriptor. In this context, we define the 3D Vote Space (VS) by aggregating votes through a multiquerying (multiscale) scheme and we present two solutions based on VS entries; a causal solution that permits online synchronization and a global solution through multiscale dynamic programming. In addition, we extend the recently introduced ECC image-alignment algorithm to the temporal dimension that allows for spatial registration and synchronization refinement with subframe accuracy. We investigate full search and quantization methods for short descriptors and we compare the proposed schemes with the state of the art. Experiments with real videos by moving or static cameras demonstrate the efficiency of the proposed method and verify its effectiveness with respect to spatiotemporal alignment accuracy.	[Evangelidis, Georgios D.] INRIA Rhone Alpes, Percept Team, F-38330 Grenoble, Rhone Alpes, France; [Bauckhage, Christian] Fraunhofer IAIS, D-53754 St Augustin, Germany		Evangelidis, GD (corresponding author), INRIA Rhone Alpes, Percept Team, 655 Ave Europe, F-38330 Grenoble, Rhone Alpes, France.	georgios.evangelidis@inria.fr; christian.bauckhage@iais.fraunhofer.de	Bauckhage, Christian/M-7872-2014	Bauckhage, Christian/0000-0001-6615-2128				Andriluka M., 2010, P IEEE RSJ INT C INT; Baker S., 2003, CMURITR0301 ROB I; Bronstein A.M., 2010, COMPUTING RES REPOSI; BROWN M., 2005, P IEEE C COMP VIS PA; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Caspi Y, 2002, INT J COMPUT VISION, V48, P39, DOI 10.1023/A:1014803327923; Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148; Csurka G., 2004, P EUR C COMP VIS WOR; Dasgupta S., 2006, ALGORITHMS; Diego F, 2011, IEEE T IMAGE PROCESS, V20, P1858, DOI 10.1109/TIP.2010.2095873; Evangelidis G. D., 2011, P 33 GERM C PATT REC; Evangelidis GD, 2008, IEEE T PATTERN ANAL, V30, P1858, DOI 10.1109/TPAMI.2008.113; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fraundorfer F., 2007, P IEEE RSJ INT C INT; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley R., 2004, ROBOTICA; Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1; Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2201, DOI 10.1109/TIP.2010.2045714; Lang D, 2010, ASTRON J, V139, P1782, DOI 10.1088/0004-6256/139/5/1782; Lei C, 2006, IEEE T IMAGE PROCESS, V15, P2473, DOI 10.1109/TIP.2006.877438; Lindeberg T., 1994, SCALE SPACE THEORY C; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mainali P., 2010, P IEEE INT C AC SPEE; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; NISTER D, 2006, P IEEE CS C COMP VIS; Padua FLC, 2010, IEEE T PATTERN ANAL, V32, P304, DOI 10.1109/TPAMI.2008.301; Pundik D., 2010, P 11 EUR C COMP VIS; Rao C., 2003, P 9 IEEE INT C COMP; Ravichandran A, 2011, IEEE T PATTERN ANAL, V33, P158, DOI 10.1109/TPAMI.2010.61; Sand P, 2004, ACM T GRAPHIC, V23, P592, DOI 10.1145/1015706.1015765; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111; TUYTELAARS T, 2004, P IEEE C COMP VIS PA; Ukrainitz Y., 2006, P EUR C COMP VIS; Wolf L, 2006, INT J COMPUT VISION, V68, P43, DOI 10.1007/s11263-005-4841-0	37	25	27	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2371	2386		10.1109/TPAMI.2013.56	http://dx.doi.org/10.1109/TPAMI.2013.56			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969383	Green Submitted			2022-12-18	WOS:000323175200005
J	Bai, L; Liang, JY; Dang, CY; Cao, FY				Bai, Liang; Liang, Jiye; Dang, Chuangyin; Cao, Fuyuan			The Impact of Cluster Representatives on the Convergence of the K-Modes Type Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; K-modes type clustering algorithms; categorical data; weighted cluster prototype; convergence	MEANS ALGORITHM	As a leading partitional clustering technique, k-modes is one of the most computationally efficient clustering methods for categorical data. In the k-modes, a cluster is represented by a "mode," which is composed of the attribute value that occurs most frequently in each attribute domain of the cluster, whereas, in real applications, using only one attribute value in each attribute to represent a cluster may not be adequate as it could in turn affect the accuracy of data analysis. To get rid of this deficiency, several modified clustering algorithms were developed by assigning appropriate weights to several attribute values in each attribute. Although these modified algorithms are quite effective, their convergence proofs are lacking. In this paper, we analyze their convergence property and prove that they cannot guarantee to converge under their optimization frameworks unless they degrade to the original k-modes type algorithms. Furthermore, we propose two different modified algorithms with weighted cluster prototypes to overcome the shortcomings of these existing algorithms. We rigorously derive updating formulas for the proposed algorithms and prove the convergence of the proposed algorithms. The experimental studies show that the proposed algorithms are effective and efficient for large categorical datasets.	[Bai, Liang; Liang, Jiye; Cao, Fuyuan] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China; [Bai, Liang; Dang, Chuangyin] City Univ Hong Kong, Dept Syst Engn & Engn Management, Kowloon, Hong Kong, Peoples R China	Shanxi University; City University of Hong Kong	Bai, L (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.	sxbailiang@126.com; ljy@sxu.edu.cn; mecdang@cityu.edu.hk; cfy@sxu.edu.cn	Dang, Chuangyin/F-5964-2012	Dang, Chuangyin/0000-0003-4731-4616; Bai, Liang/0000-0002-0380-2995	National Natural Science Foundation of China [71031006, 70971080]; Hong Kong SAR Government [GRF: CityU 112809]; National Key Basic Research and Development Program of China (973) [2013CB329404]; Special Prophase Project on National Key Basic Research and Development Program of China (973) [2011CB311805]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hong Kong SAR Government; National Key Basic Research and Development Program of China (973)(National Basic Research Program of China); Special Prophase Project on National Key Basic Research and Development Program of China (973)	The authors are very grateful to the editors and reviewers for their valuable comments and suggestions. This work was supported by the National Natural Science Foundation of China (Nos. 71031006, 70971080), GRF: CityU 112809 of the Hong Kong SAR Government, the National Key Basic Research and Development Program of China (973) (No. 2013CB329404), the Special Prophase Project on National Key Basic Research and Development Program of China (973) (No. 2011CB311805).	Aggarwal CC, 2002, IEEE T KNOWL DATA EN, V14, P51, DOI 10.1109/69.979972; Andritsos P, 2004, LECT NOTES COMPUT SC, V2992, P123; [Anonymous], 2010, UCI MACHINE LEARNING; Barbara D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P582, DOI 10.1145/584792.584888; BARBARA D, 2002, APPL DATA MINING COM; Baxevanis A.D., 2001, BIOINFORMATICS PRACT; BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964; Cao FY, 2010, IEEE T FUZZY SYST, V18, P872, DOI 10.1109/TFUZZ.2010.2050891; Cesario E, 2007, IEEE T KNOWL DATA EN, V19, P1607, DOI 10.1109/TKDE.2007.190649; Chen HL, 2008, IEEE T KNOWL DATA EN, V20, P1458, DOI 10.1109/TKDE.2008.81; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; Ganti V., 1999, P 5 ACM SIGKDD INT C, P73; Gluck M.A., 1985, P 7 ANN C COGN SCI S, P283; GOWDA KC, 1991, PATTERN RECOGN, V24, P567, DOI 10.1016/0031-3203(91)90022-W; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; He ZY, 2005, LECT NOTES ARTIF INT, V3801, P157; Huang Z., 1997, DMKD, V3, P34; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446, DOI 10.1109/91.784206; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048; Kim DW, 2005, PATTERN RECOGN, V38, P1131, DOI 10.1016/j.patcog.2004.11.017; Lee M, 2009, FUZZY SET SYST, V160, P3590, DOI 10.1016/j.fss.2009.06.015; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Miyamoto S., 1997, P 7 INT FUZZ SYST AS, VII, P86; Ng Michael K., 2009, International Journal of Granular Computing, Rough Sets and Intelligent Systems, V1, P105, DOI 10.1504/IJGCRSIS.2009.026727; Ng MK, 2007, IEEE T PATTERN ANAL, V29, P503, DOI 10.1109/TPAMI.2007.53; Ohn Mar San, 2004, International Journal of Applied Mathematics and Computer Science, V14, P241; Wrigley N, 1985, CATEGORICAL DATA ANA; Xiong TK, 2012, DATA MIN KNOWL DISC, V24, P103, DOI 10.1007/s10618-011-0221-2; Xiong TK, 2009, IEEE DATA MINING, P1058, DOI 10.1109/ICDM.2009.118; Zait M, 1997, FUTURE GENER COMP SY, V13, P149, DOI 10.1016/S0167-739X(97)00018-6; Zangwill W., 1969, NONLINEAR PROGRAMMIN	37	25	30	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1509	1522		10.1109/TPAMI.2012.228	http://dx.doi.org/10.1109/TPAMI.2012.228			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599062				2022-12-18	WOS:000317857900018
J	Bulow, H; Birk, A				Buelow, Heiko; Birk, Andreas			Spectral 6DOF Registration of Noisy 3D Range Data with Partial Overlap	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D scan matching; spectral registration; phase matching	FREQUENCY-DOMAIN TECHNIQUE; PHASE CORRELATION; FOURIER; IDENTIFICATION; TRANSFORMS; EXTENSION; IMAGES	We present Spectral Registration with Multilayer Resampling (SRMR) as a 6 Degrees Of Freedom (DOF) registration method for noisy 3D data with partial overlap. The algorithm is based on decoupling 3D rotation from 3D translation by a corresponding resampling process of the spectral magnitude of a 3D Fast Fourier Transform (FFT) calculation on discretized 3D range data. The registration of all 6DOF is then subsequently carried out with spectral registrations using Phase Only Matched Filtering (POMF). There are two main aspects for the fast and robust registration of Euler angles from spherical information in SRMR. First of all, there is the permanent use of phase matching. Second, based on the FFT on a discrete Cartesian grid, not only one spherical layer but also a complete stack of layers are processed in one step. Experiments are presented with challenging datasets with respect to interference and overlap. The results include the fast and robust registration of artificially transformed data for ground-truth comparison, scans from the Stanford Bunny dataset, high end 3D laser range finder (LRF) scans of a city center, and range data from a low-cost actuated LRF in a disaster response scenario.	[Buelow, Heiko; Birk, Andreas] Jacobs Univ Bremen, Sch Sci & Engn, D-28759 Bremen, Germany	Jacobs University	Bulow, H (corresponding author), Jacobs Univ Bremen, Sch Sci & Engn, D-28759 Bremen, Germany.	h.buelow@jacobs-university.de; a.birk@jacobs-university.de	Birk, Andreas/W-9259-2019	Birk, Andreas/0000-0003-4577-2525	European Community's Seventh Framework Programme [231378, 270350, 288704]	European Community's Seventh Framework Programme	The research leading to the presented results was supported in part by the European Community's Seventh Framework Programme under grant agreement no. 231378 "Cooperative Cognitive Control for Autonomous Underwater Vehicles (Co<SUP>3</SUP>-AUVs)," grant agreement no. 270350 " Cognitive Robot for Automation Logistics Processes (RobLog)," and grant agreement no. 288704 " Marine robotic system of self-organizing, logically linked physical nodes (MORPH)."	Averbuch A, 2003, APPL COMPUT HARMON A, V15, P33, DOI 10.1016/S1063-5203(03)00030-7; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Buelow H., 2009, P INT OCEANS C; Censi A, 2005, IEEE INT CONF ROBOT, P2739; Censi A., 2009, P IEEE INT C ROB AUT; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966; DRISCOLL JR, 1994, ADV APPL MATH, V15, P202, DOI 10.1006/aama.1994.1008; Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953; Healy DM, 2003, J FOURIER ANAL APPL, V9, P341, DOI 10.1007/s00041-003-0018-9; Hoge WS, 2005, IEEE T IMAGE PROCESS, V14, P884, DOI 10.1109/TIP.2005.849327; Hoge WS, 2003, IEEE T MED IMAGING, V22, P277, DOI 10.1109/TMI.2002.808359; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; HORNER JL, 1984, APPL OPTICS, V23, P812, DOI 10.1364/AO.23.000812; Kazhdan M, 2003, P EUR S GEOM PROC; Keller Y, 2005, IEEE T PATTERN ANAL, V27, P969, DOI 10.1109/TPAMI.2005.128; Keller Y., 2005, P IEEE C COMP VIS PA; Keller Y, 2006, IEEE T SIGNAL PROCES, V54, P4323, DOI 10.1109/TSP.2006.881217; Kostelec P., 2012, SOFT PACKAGE; Kostelec PJ, 2008, J FOURIER ANAL APPL, V14, P145, DOI 10.1007/s00041-008-9013-5; KOSTELEC PJ, 2003, WORKING PAPER SERIES; Lucchese L, 2000, IEEE T SIGNAL PROCES, V48, P1769, DOI 10.1109/78.845934; Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160; Magnusson M, 2007, J FIELD ROBOT, V24, P803, DOI 10.1002/rob.20204; Makadia A, 2003, PROC CVPR IEEE, P217; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; MAKADIA A, 2004, P INT C PATT REC; Nuchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209; Nuchter A, 2010, COMPUT VIS IMAGE UND, V114, P963, DOI 10.1016/j.cviu.2010.03.007; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; Pathak K, 2010, IEEE INT C INT ROBOT, P5725, DOI 10.1109/IROS.2010.5649648; Pathak K, 2010, IEEE INT C INT ROBOT, P4880, DOI 10.1109/IROS.2010.5650953; Pathak K, 2010, IEEE T ROBOT, V26, P424, DOI 10.1109/TRO.2010.2042989; Pathak K, 2010, J FIELD ROBOT, V27, P52, DOI 10.1002/rob.20322; Radon J., 1917, BESTIMMUNG FUNKTIONE; S.U.C.G. Laboratory, 2013, STANF 3D SCANN REP; Takeuchi E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3068, DOI 10.1109/IROS.2006.282246; WEINGARTEN J, 2006, THESIS EPFL LAUSANNE	38	25	26	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					954	969		10.1109/TPAMI.2012.173	http://dx.doi.org/10.1109/TPAMI.2012.173			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22868648				2022-12-18	WOS:000314931000014
J	Ricci, E; Zen, G; Sebe, N; Messelodi, S				Ricci, Elisa; Zen, Gloria; Sebe, Nicu; Messelodi, Stefano			A Prototype Learning Framework Using EMD: Application to Complex Scenes Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video surveillance; complex scene analysis; earth mover's distance; parametric linear programming	EARTH-MOVERS-DISTANCE	In the last decades, many efforts have been devoted to develop methods for automatic Scene understanding in the context of video surveillance applications. This paper presents a novel nonobject centric approach for complex scene analysis. Similarly to previous methods, we use low-level cues to individuate atomic activities and create clip histograms. Differently from recent works, the task of discovering high-level activity patterns is formulated as a convex prototype learning problem. This problem results in a simple linear program that can be solved efficiently with standard solvers. The main advantage of our approach is that, using as the objective function the Earth Mover's Distance (EMD), the similarity among elementary activities is taken into account in the learning phase. To improve scalability we also consider some variants of EMD adopting L-1 as ground distance for 1D and 2D, linear and circular histograms. In these cases, only the similarity between neighboring atomic activities, corresponding to adjacent histogram bins, is taken into account. Therefore, we also propose an automatic strategy for sorting atomic activities. Experimental results on publicly available datasets show that our method compares favorably with state-of-the-art approaches, often outperforming them.	[Ricci, Elisa] Univ Perugia, Fac Ingn, Dipartimento Ingn Elettron & Informaz, I-06125 Perugia, Italy; [Zen, Gloria; Sebe, Nicu] Univ Trent, Dipartimento Ingn & Sci Informaz DISI, I-38123 Trento, Italy; [Messelodi, Stefano] Fdn Bruno Kessler FBK Irst, I-38123 Trento, Italy	University of Perugia; University of Trento; Fondazione Bruno Kessler; FBK-ICT - Center for Information & Communication Technology	Ricci, E (corresponding author), Univ Perugia, Fac Ingn, Dipartimento Ingn Elettron & Informaz, Via Duranti 93, I-06125 Perugia, Italy.	elisa.ricci@diei.unipg.it; zen@disi.unitn.it; sebe@disi.unitn.it; messelod@fbk.eu		Ricci, Elisa/0000-0002-0228-1147; Sebe, Niculae/0000-0002-6597-7248				Applegate D., 2011, P ACM SIGKDD INT C K; Bertsimas D., 1997, INTRO LINEAR OPTIMIZ; Breitenstein M.D., 2009, P IEEE INT WORKSH VI; Breunig M.M., 2000, P ACM SIGMOD INT C M; Duong T., 2005, P IEEE C COMP VIS PA; Emonet R, 2011, PROC CVPR IEEE; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Hamid R., 2005, P IEEE C COMP VIS PA; Hospedales T., 2009, P IEEE INT C COMP VI; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; Kuettel D., 2010, P IEEE C COMP VIS PA; Lashkari D., 2008, P ADV NEUR INF PROC; Li J., 2008, P EUR C COMP VIS; Li J., 2008, P BRIT MACH VIS C; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; Marszalek M., 2009, P IEEE C COMP VIS PA; Murty K.G., 1983, LINEAR PROGRAMMING; Nater F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.21; Niebles J.C., 2010, P 12 EUR C COMP VIS; Nowozin S., 2009, P INT C MACH LEARN; Pele O., 2008, P EUR C COMP VIS; Pele O., 2009, P 12 IEEE INT C COMP; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sandler R., 2009, P IEEE C COMP VIS PA; Shirdhonkar S., 2008, P IEEE COMP VIS PATT; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; Takano Y, 2010, ASIA PAC J OPER RES, V27, P39, DOI 10.1142/S0217595910002545; Tang J., 2002, P 6 PAC AS C ADV KNO; Varadarajan J., 2010, P BRIT MACH VIS C; Wagner J., 2010, P AS C COMP VIS; Wang X., 2007, P IEEE C COMP VIS PA; Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Yang Y., 2009, P 12 IEEE INT C COMP; Yao Y., 2007, 800 OH STAT U DEP ST; Zelniker E.E., 2008, P WORKSH VIS SURV; Zen G., 2011, P INT C IM AN PROC; Zen G, 2011, PROC CVPR IEEE	43	25	26	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					513	526		10.1109/TPAMI.2012.131	http://dx.doi.org/10.1109/TPAMI.2012.131			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22689076				2022-12-18	WOS:000314792900001
J	Angiulli, F				Angiulli, Fabrizio			Prototype-Based Domain Description for One-Class Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						One-class classification; novelty detection; nearest neighbor classification; data set condensation		This work introduces the Prototype-based Domain Description rule (PDD) one-class classifier. PDD is a nearest neighbor-based classifier since it accepts objects on the basis of their nearest neighbor distances in a reference set of objects, also called prototypes. For a suitable choice of the prototype set, the PDD classifier is equivalent to another nearest neighbor-based one-class classifier, namely, the NNDD classifier. Moreover, it generalizes statistical tests for outlier detection. The concept of a PDD consistent subset is introduced, which exploits only a selected subset of the training set. It is shown that computing a minimum size PDD consistent subset is, in general, not approximable within any constant factor. A logarithmic approximation factor algorithm, called the CPDD algorithm, for computing a minimum size PDD consistent subset is then introduced. In order to efficiently manage very large data sets, a variant of the basic rule, called Fast CPDD, is also presented. Experimental results show that the CPDD rule sensibly improves over the CNNDD classifier, namely the condensed variant of NNDD, in terms of size of the subset while guaranteeing a comparable classification quality, that it is competitive over other one-class classification methods and is suitable to classify large data sets.	Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	University of Calabria	Angiulli, F (corresponding author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	f.angiulli@deis.unical.it		Angiulli, Fabrizio/0000-0002-9860-7569				Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Angiulli F, 2007, IEEE T PATTERN ANAL, V29, P1746, DOI 10.1109/TPAMI.2007.1086; Angiulli F, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497581; Angiulli F, 2008, FRONT ARTIF INTEL AP, V178, P107, DOI 10.3233/978-1-58603-891-5-107; Ausiello Giorgio, 1999, COMPLEXITY APPROXIMA; Bellare M., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, P294, DOI 10.1145/167088.167174; Breunig M., 2000, P ACM INT C MAN DAT; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Floyd S, 1995, MACH LEARN, V21, P269; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392; Lewis T., 1994, OUTLIERS STAT DATA; Littlestone N., 1986, RELATING DATA COMPRE; Martinus David, 2002, ONE CLASS CLASSIFICA; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 1995, P INT C KNOWL DISC D, P251; Tax D. M. J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P251; Tax DMJ, 2000, INT C PATT RECOG, P672, DOI 10.1109/ICPR.2000.906164; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Tsang IW, 2007, P 24 INT C MACH LEAR, P911; Ypma A., 1998, P INT C ART NEUR NET	22	25	27	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1131	1144		10.1109/TPAMI.2011.204	http://dx.doi.org/10.1109/TPAMI.2011.204			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22516649				2022-12-18	WOS:000302916600008
J	Wu, L; Hua, XS; Yu, NH; Ma, WY; Li, SP				Wu, Lei; Hua, Xian-Sheng; Yu, Nenghai; Ma, Wei-Ying; Li, Shipeng			Flickr Distance: A Relationship Measure for Visual Concepts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Artificial intelligence; distance learning; machine vision; image analysis		This paper proposes the Flickr Distance (FD) to measure the visual correlation between concepts. For each concept, a collection of related images are obtained from the Flickr website. We assume that each concept consists of several states, e. g., different views, different semantics, etc., which are considered as latent topics. Then a latent topic visual language model (LTVLM) is built to capture these states. The Flickr distance between two concepts is defined as the Jensen-Shannon (J-S) divergence between their LTVLM. Differently from traditional conceptual distance measurements, which are based on Web textual documents, FD is based on the visual information. Comparing with the WordNet distance, FD can easily scale up with the increasing size of the conceptual corpus. Comparing with the Google Distance (NGD) and Tag Concurrence Distance (TCD), FD uses the visual information and can properly measure the conceptual relations. We apply FD to multimedia-related tasks and find methods based on FD significantly outperform those based on NGD and TCD. With the FD measurement, we also construct a large-scale visual conceptual network (VCNet) to store the knowledge of conceptual relationship. Experiments show that FD is more coherent to human cognition and it also outperforms text-based distances in real-world applications.	[Wu, Lei] Univ Pittsburgh, Pittsburgh, PA 15217 USA; [Wu, Lei] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China; [Hua, Xian-Sheng] Microsoft Res Asia, Redmond, WA 98052 USA; [Yu, Nenghai] Univ Sci & Technol China, Informat Proc Ctr, Hefei 230026, Peoples R China; [Ma, Wei-Ying; Li, Shipeng] Microsoft Res Asia, Beijing 100080, Peoples R China	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Microsoft; Microsoft Research Asia	Wu, L (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China.	leiwu@live.com; xshua@microsoft.com; ynh@ustc.edu.cn; wyma@microsoft.com; spli@microsoft.com	Li, Shipeng/AAA-3374-2020	Li, Shipeng/0000-0001-5368-4256; PPCT, Leo/0000-0003-0897-4830	Fundamental Research Funds for the Central Universities [WK2100230002]; National Natural Science Foundation of China [60933013, 60903146]; National Science and Technology Major Project [2010ZX03004-003]; National High Tecenology Research and Development Program of China(863) [2008AA01Z117]	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Science and Technology Major Project; National High Tecenology Research and Development Program of China(863)	This paper is partially supported by the Fundamental Research Funds for the Central Universities (No. WK2100230002), the National Natural Science Foundation of China (No. 60933013), National Science and Technology Major Project (No. 2010ZX03004-003), National Natural Science Foundation of China (Grant No. 60903146), and the National High Tecenology Research and Development Program of China(863) (No. 2008AA01Z117). This paper is an extension to the conference paper "Flickr Distance"(download) [34] which was one of the best paper candidates at ACM Multimedia 2008.	Al-Khatib W, 1999, IEEE T KNOWL DATA EN, V11, P64, DOI 10.1109/69.755616; [Anonymous], 2007, P SIGCHI C HUM FACT; [Anonymous], 2009, GERONTOLOGY; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Blei D., 2006, NIPS, V18, P147, DOI [10.5555/2976248.2976267, DOI 10.5555/2976248.2976267, DOI 10.1145/1143844.1143859]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Budanitsky A., 2001, P WORDNET OTH LEX RE; Cao Liangliang, 2008, P 16 ACM INT C MULT, P121, DOI DOI 10.1145/1459359.1459376; Chang S., 2007, P INT WORKSH MULT IN; Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Fergus Y.W.A.T. Rob, 2010, P EUR C COMP VIS; Freund Yoav, 2003, J MACHINE LEARNING R, V4, P170; Huang TS, 2008, P IEEE, V96, P648, DOI 10.1109/JPROC.2008.916364; JEON J, 2003, P 26 ANN INT ACM SIG; Kennedy L.S., 2007, P 15 INT C MULT, P631, DOI DOI 10.1145/1291233.1291384; LAVRENKO V, 2003, P NEUR INF PROC SYST; LAZEBNIK, 2006, P IEEE C COMP VIS PA, V2, P2169; Lei Wu, 2011, Proceedings of the International Conference on Signal Processing and Multimedia Applications. SIGMAP 2011, P149; Li L.-J., 2010, P IEEE C COMP VIS PA; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu D, 2009, P 18 INT C WORLD WID; Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380; Natsev AP, 2007, P 15 INT C MULT; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Qi G., 2007, P 15 INT C MULT; Rodriguez-Serrano J.A., 2009, P IEEE C COMP VIS PA; Sen S, 2006, P 20 ANN C COMP SUPP; Sigurbjornsson B., 2008, P 17 INT C WORLD WID; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; WANG B, 2006, P IEEE INT C MULT EX; Wang C., 2007, P IEEE C COMP VIS PA; Wu L., 2008, P IEEE INT C MULT EX; Wu L., 2009, P 17 ACM INT C MULT, P135; Wu L., 2007, P 9 ACM SIGMM INT WO; Wu L., 2008, MM 08 P 16 ACM INT C, P31, DOI DOI 10.1145/1459359.1459364	38	25	26	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					863	875		10.1109/TPAMI.2011.195	http://dx.doi.org/10.1109/TPAMI.2011.195			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21987557				2022-12-18	WOS:000301747400003
J	De Laet, T; Bruyninckx, H; De Schutter, J				De Laet, Tinne; Bruyninckx, Herman; De Schutter, Joris			Shape-Based Online Multitarget Tracking and Detection for Targets Causing Multiple Measurements: Variational Bayesian Clustering and Lossless Data Association	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multitarget tracking; data association; detection; laser range scanner; video; Bayesian networks; Kalman filter; particle filter	ALGORITHM	This paper proposes a novel online two-level multitarget tracking and detection (MTTD) algorithm. The algorithm focuses on multitarget detection and tracking for the case of multiple measurements per target and for an unknown and varying number of targets. Information is continuously exchanged in both directions between the two levels. Using the high level target position and shape information, the low level clusters the measurements. Furthermore, the low level features automatic relevance detection (ARD), as it automatically determines the optimal number of clusters from the measurements taking into account the expected target shapes. The high level's data association allows for a varying number of targets. A joint probabilistic data association algorithm looks for associations between clusters of measurements and targets. These associations are used to update the target trackers and the target shapes with the individual measurements. No information is lost in the two-level approach since the measurement information is not summarized into features. The target trackers are based on an underlying motion model, while the high level is supplemented with a filter estimating the number of targets. The algorithm is verified using both simulations and experiments using two sensor modalities, video and laser scanner, for detection and tracking of people and ants.	[De Laet, Tinne; Bruyninckx, Herman; De Schutter, Joris] Katholieke Univ Leuven, Dept Mech Engn, B-3001 Heverlee, Belgium	KU Leuven	De Laet, T (corresponding author), Katholieke Univ Leuven, Dept Mech Engn, Celestijnenlaan 300-B,Box 2420, B-3001 Heverlee, Belgium.	Tinne.DeLaet@mech.kuleuven.be; Herman.Bruyninckx@mech.kuleuven.be; Joris.DeSchutter@mech.kuleuven.be	De Laet, Tinne/AAK-8612-2020	De Laet, Tinne/0000-0003-0624-3305; De Schutter, Joris/0000-0001-9619-5815	K.U. Leuven's Concerted Research Actions [GOA/2005/10, GOA/2010/011]; K.U. Leuven-BOF Center-of-Excellence Optimization in Engineering (OPTEC) [PFV/10/002]; European FP7 project [2008-IST-230902 Rosetta]; Fund for Scientific Research-Flanders in Belgium	K.U. Leuven's Concerted Research Actions; K.U. Leuven-BOF Center-of-Excellence Optimization in Engineering (OPTEC); European FP7 project; Fund for Scientific Research-Flanders in Belgium(FWO)	All of the authors gratefully acknowledge the support of Koen Buys for his help on processing the visual data from the experiments and Ruben Smits for his support during the software development. The authors furthermore gratefully acknowledge the financial support by K.U. Leuven's Concerted Research Actions GOA/2005/10 and GOA/2010/011, the K.U. Leuven-BOF PFV/10/002 Center-of-Excellence Optimization in Engineering (OPTEC), and the European FP7 project 2008-IST-230902 Rosetta. Tinne De Laet is a postdoctoral fellow of the Fund for Scientific Research-Flanders (F.W.O.) in Belgium.	ARRAS KO, 2008, P IEEE INT C ROB AUT, P1710; Bar-Shalom Y., 1990, MULTITARGET MULTISEN; Bar-Shalom Y, 2009, IEEE CONTR SYST MAG, V29, P82, DOI 10.1109/MCS.2009.934469; BARSHALOM Y, 1988, TRACKING DATA ASS SE; BARSHALOM Y, 1992, MULTITARGET MULTISEN, V2, P93; BARSHALOM Y, 1992, MULTITARGET MULTISEN, P25; Beal M.J., 2003, VARIATIONAL ALGORITH; BEAL MJ, 2003, P VAL INT M BAY STAT; Bishop C.M, 2006, PATTERN RECOGN; Blom HAP, 2000, IEEE T AUTOMAT CONTR, V45, P247, DOI 10.1109/9.839947; BLOM HAP, 1992, MULTITARGET MULTISEN, V2, P31; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; De Laet T, 2008, J ARTIF INTELL RES, V33, P179, DOI 10.1613/jair.2540; Du W, 2005, LECT NOTES COMPUT SC, V3687, P701; Fod A, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3024, DOI 10.1109/ROBOT.2002.1013691; Gennari G, 2004, PROC CVPR IEEE, P876; Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247; Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2602, DOI 10.1109/TSP.2003.816754; Lau B, 2009, IEEE INT CONF ROBOT, P3487; Lindtrom M, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1364, DOI 10.1109/IROS.2001.977171; MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374; Montemerlo M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P695, DOI 10.1109/ROBOT.2002.1013439; MURTY KG, 1968, OPER RES, V16, P682, DOI 10.1287/opre.16.3.682; Ng W, 2005, AEROSP CONF PROC, P2126; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Schulz D, 2003, INT J ROBOT RES, V22, P99, DOI 10.1177/0278364903022002002; Song TL, 2005, SIGNAL PROCESS, V85, P2044, DOI 10.1016/j.sigpro.2005.01.016; STREIT RL, 1995, 10428 NUWCNPT TR; Vermaak J, 2005, IEE P-RADAR SON NAV, V152, P353, DOI 10.1049/ip-rsn:20045044; Vermaak J, 2005, IEEE T AERO ELEC SYS, V41, P309, DOI 10.1109/TAES.2005.1413764; Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110	33	25	25	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2477	2491		10.1109/TPAMI.2011.83	http://dx.doi.org/10.1109/TPAMI.2011.83			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21576748				2022-12-18	WOS:000295980000013
J	Karpenko, A; Aarabi, P				Karpenko, Alexandre; Aarabi, Parham			Tiny Videos: A Large Data Set for Nonparametric Video Retrieval and Frame Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image classification; content-based retrieval; tiny videos; tiny images; data mining; nearest-neighbor methods		In this paper, we present a large database of over 50,000 user-labeled videos collected from YouTube. We develop a compact representation called "tiny videos" that achieves high video compression rates while retaining the overall visual appearance of the video as it varies over time. We show that frame sampling using affinity propagation-an exemplar-based clustering algorithm-achieves the best trade-off between compression and video recall. We use this large collection of user-labeled videos in conjunction with simple data mining techniques to perform related video retrieval, as well as classification of images and video frames. The classification results achieved by tiny videos are compared with the tiny images framework [24] for a variety of recognition tasks. The tiny images data set consists of 80 million images collected from the Internet. These are the largest labeled research data sets of videos and images available to date. We show that tiny videos are better suited for classifying scenery and sports activities, while tiny images perform better at recognizing objects. Furthermore, we demonstrate that combining the tiny images and tiny videos data sets improves classification precision in a wider range of categories.	[Karpenko, Alexandre; Aarabi, Parham] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 1A1, Canada	University of Toronto	Karpenko, A (corresponding author), Univ Toronto, Dept Elect & Comp Engn, 100 Coll St, Toronto, ON M5S 1A1, Canada.	alexander@comm.utoronto.ca; parham@ecf.utoronto.ca						Dimitrova N., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, P113, DOI 10.1145/266714.266876; DOUZE M, 2008, P TEXT RETR C VID RE; EICKELER S, 1999, P IEEE INT C AC SPEE, V6, P2997; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Hampapur A., 1995, Multimedia Tools and Applications, V1, P9, DOI 10.1007/BF01261224; Joly A, 2003, LECT NOTES COMPUT SC, V2728, P414; JUNEE R., 2009, ZOINKS 20 HOURS VIDE; Karpenko A, 2008, IEEE INT SYM MULTIM, P619, DOI 10.1109/ISM.2008.53; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Law-To J., 2007, C IMAGE VIDEO RETRIE, P371; Law-To J., 2007, MUSCLE VCD 2007 LIVE; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu S, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P60, DOI 10.1109/MMMC.2005.64; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Peker KA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P414, DOI 10.1109/ICIP.2001.958139; SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348; Smeaton A.F., 2006, MIR 2006 P 8 ACM INT, P321, DOI DOI 10.1145/1178677.1178722; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; TOKLU C, 2000, P 1 IEEE INT C MULT, V3, P1333; Torralba A, 2007, MITCSAILTR2007024; Torralba A., 2008, P IEEE C COMP VIS PA; Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115; Zabih R., 1995, P 3 ACM INT C MULTIM, P189, DOI DOI 10.1145/217279.215266; [No title captured]; 2010, YOUTUBES APIS DEV TO	26	25	27	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					618	630		10.1109/TPAMI.2010.118	http://dx.doi.org/10.1109/TPAMI.2010.118			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	21252400				2022-12-18	WOS:000286204700013
J	Adam, A; Kimmel, R; Rivlin, E				Adam, Amit; Kimmel, Ron; Rivlin, Ehud			On Scene Segmentation and Histograms-Based Curve Evolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; Earth Mover's Distance; curve evolution; scene analysis	ACTIVE CONTOURS; IMAGE; COMPETITION; DRIVEN; MOTION	We consider curve evolution based on comparing distributions of features, and its applications for scene segmentation. In the first part, we promote using cross-bin metrics such as the Earth Mover's Distance (EMD), instead of standard bin-wise metrics as the Bhattacharyya or Kullback-Leibler metrics. To derive flow equations for minimizing functionals involving the EMD, we employ a tractable expression for calculating EMD between one-dimensional distributions. We then apply the derived flows to various examples of single image segmentation, and to scene analysis using video data. In the latter, we consider the problem of segmenting a scene to spatial regions in which different activities occur. We use a nonparametric local representation of the regions by considering multiple one-dimensional histograms of normalized spatiotemporal derivatives. We then obtain semisupervised segmentation of regions using the flows derived in the first part of the paper. Our results are demonstrated on challenging surveillance scenes, and compare favorably with state-of-the-art results using parametric representations by dynamic systems or mixtures of them.	[Adam, Amit; Kimmel, Ron; Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Adam, A (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	amita@cs.technion.ac.il; ron@cs.technion.ac.il; ehudr@cs.technion.ac.il			Israel Ministry of Science	Israel Ministry of Science(Ministry of Science, Technology and Space (MOST), Israel)	The authors thank Gianfranco Doretto for motivating this work [14] and for providing the fire-over-water sequence. This research was partly supported by the Horowitz fund and by the Israel Ministry of Science research networks program under the Medical and Biological Imaging grant no. 3-3414.	Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; BREM E, 2007, COMMUNICATION; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chan HK, 2008, EXPERT OPIN DRUG DEL, V5, P909, DOI [10.1517/17425247.5.8.909, 10.1517/17425247.5.8.909 ]; CHAN T, 2007, P C SCAL SPAC METH V; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; COOPER L, 2005, WORKSH DYN VIS CONJ; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; DEMENTHON D, 2006, P IEEE C COMP VIS PA; Doretto G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1236; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; FOWLKES C, 2001, P IEEE C COMP VIS PA; Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445; Greenspan H, 2004, IEEE T PATTERN ANAL, V26, P384, DOI 10.1109/TPAMI.2004.1262334; Jehan-Besson S, 2003, INT J COMPUT VISION, V53, P45, DOI 10.1023/A:1023031708305; JEHANBESSON S, 2001, P IEEE INT C COMP VI; KAHN S, 2001, P IEEE C COMP VIS PA; Lu Zongqing, 2005, WACVMOTION, P241; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MEGRET R, 2002, 094 LAMP U MAR; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Osher S., 2002, APPL MATH SCI, V44, P685; Porikli F., 2005, P IEEE C COMP VIS PA; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; SETHIAN JA, 1999, LEVEL SETS METHODS F; Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194; ZHAI Y, 2005, P IEEE INT C COMP VI; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	33	25	26	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1708	1714		10.1109/TPAMI.2009.21	http://dx.doi.org/10.1109/TPAMI.2009.21			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574629	Green Submitted			2022-12-18	WOS:000267369800013
J	Kokkinos, I; Maragos, P				Kokkinos, Iasonas; Maragos, Petros			Synergy between Object Recognition and Image Segmentation Using the Expectation-Maximization Algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; object recognition; Expectation Maximization; Active Appearance Models; curve evolution; top-down segmentation; generative models	ACTIVE APPEARANCE MODELS; VISUAL RECOGNITION; FRAMEWORK	In this work, we formulate the interaction between image segmentation and object recognition in the framework of the Expectation-Maximization (EM) algorithm. We consider segmentation as the assignment of image observations to object hypotheses and phrase it as the E-step, while the M-step amounts to fitting the object models to the observations. These two tasks are performed iteratively, thereby simultaneously segmenting an image and reconstructing it in terms of objects. We model objects using Active Appearance Models (AAMs) as they capture both shape and appearance variation. During the E-step, the fidelity of the AAM predictions to the image is used to decide about assigning observations to the object. For this, we propose two top-down segmentation algorithms. The first starts with an oversegmentation of the image and then softly assigns image segments to objects, as in the common setting of EM. The second uses curve evolution to minimize a criterion derived from the variational interpretation of EM and introduces AAMs as shape priors. For the M-step, we derive AAM fitting equations that accommodate segmentation information, thereby allowing for the automated treatment of occlusions. Apart from top-down segmentation results, we provide systematic experiments on object detection that validate the merits of our joint segmentation and recognition approach.	[Kokkinos, Iasonas] Ecole Cent Paris, Dept Appl Math, F-92295 Chatenay Malabry, France; [Maragos, Petros] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15773, Greece; [Kokkinos, Iasonas] Univ Calif Los Angeles, Ctr Image & Vis Sci, Los Angeles, CA USA	UDICE-French Research Universities; Universite Paris Saclay; National Technical University of Athens; University of California System; University of California Los Angeles	Kokkinos, I (corresponding author), Ecole Cent Paris, Dept Appl Math, F-92295 Chatenay Malabry, France.	iasonas.kokkinos@ecp.fr; maragos@cs.ntua.gr			Greek Ministry of Education research program "HRAKLEITOS"; European Network of Excellence "MUSCLE."	Greek Ministry of Education research program "HRAKLEITOS"; European Network of Excellence "MUSCLE."	The authors thank G. Papandreou for the discussions on AAM fitting and for indicating related references. They wish to thank the reviewers for their constructive comments that helped improve the quality of the paper. This work was supported by the Greek Ministry of Education research program "HRAKLEITOS" and by the European Network of Excellence "MUSCLE." Iasonas Kokkinos was with the National Technical University of Athens when this paper was first written.	AGARWAL S, 2002, P 7 EUR C COMP VIS; BARBU A, 2003, P 9 INT C COMP VIS; BELONGIE S, 1998, P 6 INT C COMP VIS; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; BISHOP C, 1998, LEARNING GRAPHICAL M; BORENSTEIN E, 2002, P 7 EUR C COMP VIS; BORENSTEIN E., 2004, P IEEE C COMP VIS PA; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cremers D., 2003, P 4 INT C SCAL SPAC; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Dempster A., 1977, J ROYAL STAT SOC B; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; FERRARI V, 2004, P 8 EUR C COMP VIS; FREY BJ, 1999, P IEEE C COMP VIS PA; Grenander U., 1993, GEN PATTERN THEORY; Gross R, 2006, IMAGE VISION COMPUT, V24, P593, DOI 10.1016/j.imavis.2005.08.001; Jaakkola T., 2000, ADV MEAN FIELD METHO; JACOBS RA, 1995, NEURAL COMPUT, V7, P867, DOI 10.1162/neco.1995.7.5.867; Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832; KOKKINOS I, 2005, P 10 INT C COMP VIS; KOKKINOS I, 2007, P 11 INT C COMP VIS; Kokkinos I., 2006, P IEEE C COMP VIS PA; LEIBE B., 2004, P ECCV WORKSH STAT L; Leventon M. E., 2000, P IEEE C COMP VIS PA; LEVIN A, 2006, P 9 EUR C COMP VIS; Marr D., 1982, VISION; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; MILANESE R, 1994, P IEEE C COMP VIS PA; MORI G, 2004, P IEEE C COMP VIS PA; Mumford D., 1996, PERCEPTION BAYESIAN; Mumford D., 1994, LARGE SCALE THEORIES; Neal R. M., 1998, LEARNING GRAPHICAL M; OPELT A, 2004, P 8 EUR C COMP VIS; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Papavasiliou KA, 2007, J PEDIATR ORTHOP B, V16, P1, DOI 10.1097/BPB.0b013e328010b73d; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; ROUSSON M, 2005, P 8 INT C MED IM COM; ROUSSON M, 2002, P 7 EUR C COMP VIS; Sethian J., 1996, LEVEL SET METHODS; TON P. H. S., 2005, P IEEE C COMP VIS PA; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; TURK M, 1991, J COGNITIVE SCI, V3, P1; ULLMAN S, 1994, LARGE SCALE THEORIES; WEISS Y, 1995, P 5 INT C COMP VIS; WELLING M, 2000, P 6 EUR C COMP VIS; Winn J., 2005, P 10 INT C COMP VIS, P2; XU S, 2003, P IEEE C COMP VIS PA; Zhu S.-C., 2000, P IEEE C COMP VIS PA; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	54	25	31	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1486	1501		10.1109/TPAMI.2008.158	http://dx.doi.org/10.1109/TPAMI.2008.158			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542581				2022-12-18	WOS:000267050600011
J	Silva, J; Willett, R				Silva, Jorge; Willett, Rebecca			Hypergraph-Based Anomaly Detection of High-Dimensional Co-Occurrences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Anomaly detection; co-occurrence analysis; unsupervised learning; variational methods; social networks	SUPPORT	This paper addresses the problem of detecting anomalous multivariate co-occurrences using a limited number of unlabeled training observations. A novel method based on using a hypergraph representation of the data is proposed to deal with this very high-dimensional problem. Hypergraphs constitute an important extension of graphs that allow edges to connect more than two vertices simultaneously. A variational Expectation-Maximization algorithm for detecting anomalies directly on the hypergraph domain without any feature selection or dimensionality reduction is presented. The resulting estimate can be used to calculate a measure of anomalousness based on the false-discovery rate. The algorithm has O(np) computational complexity, where n is the number of training observations and p is the number of potential participants in each co-occurrence event. This efficiency makes the method ideally suited for very high-dimensional settings and requires no tuning, bandwidth, or regularization parameters. The proposed approach is validated on both high-dimensional synthetic data and the Enron e-mail database, where p > 75,000, and it is shown that it can outperform other state-of-the-art methods.	[Silva, Jorge; Willett, Rebecca] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Duke University	Silva, J (corresponding author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	jg.silva@duke.edu; willett@duke.edu	Willett, Rebecca/G-6930-2012		US National Science Foundation [CCF-06-04397]; US Defense Advanced Research Projects Agency [HT0011-07-1-003]	US National Science Foundation(National Science Foundation (NSF)); US Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	The authors wish to thank Professor Al Hero for providing the code for the L1O-kNNG algorithm. This work was supported by US National Science Foundation CAREER Award CCF-06-04397 and US Defense Advanced Research Projects Agency Grant HT0011-07-1-003.	ABELSON R, 2002, NY TIMES         JAN; Ahmed T., 2007, P 2 WORKSH TACKL COM; AITCHISON J, 1976, BIOMETRIKA, V63, P413, DOI 10.2307/2335719; Atienza N, 2007, J STAT PLAN INFER, V137, P496, DOI 10.1016/j.jspi.2005.12.014; Berge C., 1989, HYPERGRAPHS COMBINAT; BEYLKIN G, 2007, MULTIVARIATE R UNPUB; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; ELYANIV R, 2007, ADV NEURAL INFORM PR; Eskin Eleazar, 2002, APPL DATA MINING COM, P77, DOI DOI 10.1007/978-1-4615-0953-0_4; GARCIA E, 2008, TARGETING DOCUMENTS; Globerson A, 2007, J MACH LEARN RES, V8, P2265; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HERO AO, 2007, ADV NEURAL INFORM PR; Hoffmann JN, 2002, ANESTHESIOLOGY, V97, P460, DOI 10.1097/00000542-200208000-00025; Hofmann T., 1998, STAT MODELS COOCCURR; Humphreys K, 2000, NEURAL PROCESS LETT, V12, P183, DOI 10.1023/A:1009617914949; JHANWAR N, 2004, P 4 IND C COMP VIS G, V22, P1211; KLIMT B, 2004, P 15 EUR C MACH LEAR; Lazarevic A, 2003, SIAM PROC S, P25; LEE W, 1998, P 7 US SEC S; LI H, 2002, P 19 INT C COMP LING; Li M, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.36; McCallum A., 1998, AAAI 98 WORKSHOP LEA, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426; Mclachlan G., 2000, WILEY SER PROB STAT; McLachlan GJ., 1996, WILEY SERIES PROBABI; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; OZGUR A, 2007, COOCCURRENCE NETWORK; Rabbat MG, 2008, IEEE T INFORM THEORY, V54, P4053, DOI 10.1109/TIT.2008.926315; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; SCOTT C, 2007, NONPARAMETRIC ASSESS; SILVA J, 2008, ECE200801 DUK U; Storey JD, 2003, ANN STAT, V31, P2013, DOI 10.1214/aos/1074290335; TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768; Titterington DM, 1985, STAT ANAL FINITE MIX; Wainwright M. J., 2003, 649 UC BERK DEP STAT; WOLFE JH, 1970, MULTIVAR BEHAV RES, V5, P329, DOI 10.1207/s15327906mbr0503_6; Ye N, 2001, QUAL RELIAB ENG INT, V17, P105, DOI 10.1002/qre.392	39	25	26	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					563	569		10.1109/TPAMI.2008.232	http://dx.doi.org/10.1109/TPAMI.2008.232			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147882				2022-12-18	WOS:000262480200013
J	Chin, TJ; Suter, D				Chin, Tat-Jun; Suter, David			Out-of-sample extrapolation of learned manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						manifold learning; out-of-sample extrapolation; Maximum Variance Unfolding		We investigate the problem of extrapolating the embedding of a manifold learned from finite samples to novel out-of-sample data. We concentrate on the manifold learning method called Maximum Variance Unfolding (MVU), for which the extrapolation problem is still largely unsolved. Taking the perspective of MVU learning being equivalent to Kernel Principal Component Analysis (KPCA), our problem reduces to extending a kernel matrix generated from an unknown kernel function to novel points. Leveraging on previous developments, we propose a novel solution, which involves approximating the kernel eigenfunction by using Gaussian basis functions. We also show how the width of the Gaussian can be tuned to achieve extrapolation. Experimental results, which demonstrate the effectiveness of the proposed approach, are also included.	[Suter, David] Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3168, Australia	Monash University		tjchin@i2r.a-star.edu.sg; d.suter@eng.monash.edu.au		Suter, David/0000-0001-6306-3023				Baker C., 1977, NUMERICAL TREATMENT; Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396; Bengio Y., 2003, P ADV NEURAL INFORM; Burges CJC, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P59, DOI 10.1007/0-387-25465-X_4; Cramer J.S., 2003, ORIGINS LOGISTIC REG; DESILVA V, 2003, ADV NEURAL INFORM PR, V15, P705; Elgammal A, 2004, PROC CVPR IEEE, P681; GONG H, 2006, P 17 BRIT MACH VIS C; Nabney I.T., 2004, NETLAB ALGORITHMS PA; Peters G, 2004, MACH VISION APPL, V16, P59, DOI 10.1007/s00138-004-0143-8; Saul L.K., 2006, SEMISUPERVISED LEARN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHWAIGHOFER A, 2005, P ADV NEUR INF PROC; Vishwanathan SVN, 2006, NEUROCOMPUTING, V69, P721, DOI 10.1016/j.neucom.2005.12.113; Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z; WEINBERGER KQ, 2005, P 10 INT WORKSH ART; Williams CKI, 2001, ADV NEUR IN, V13, P682	17	25	32	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1547	1556		10.1109/TPAMI.2007.70813	http://dx.doi.org/10.1109/TPAMI.2007.70813			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617714				2022-12-18	WOS:000257504400004
J	Lee, JA; Geets, X; Gregoire, V; Bol, A				Lee, John A.; Geets, Xavier; Gregoire, Vincent; Bol, Anne			Edge-preserving filtering of images with low photon counts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge-preserving filter; local M-smoothers; bilateral filtering; anisotropic diffusion; photometry invariance; Poissonian noise	NONLINEAR DIFFUSION; RECONSTRUCTION	Edge-preserving filters such as local M-smoothers or bilateral filtering are usually designed for Gaussian noise. This paper investigates how these filters can be adapted in order to efficiently deal with Poissonian noise. In addition, the issue of photometry invariance is addressed by changing the way filter coefficients are normalized. The proposed normalization is additive, instead of being multiplicative, and leads to a strong connection with anisotropic diffusion. Experiments show that ensuring the photometry invariance leads to comparable denoising performances in terms of the root mean square error computed on the signal.	[Lee, John A.; Geets, Xavier; Gregoire, Vincent; Bol, Anne] Catholic Univ Louvain, IMRE, B-1200 Brussels, Belgium	Universite Catholique Louvain	Lee, JA (corresponding author), Catholic Univ Louvain, IMRE, Ave Hippocrate 54-69, B-1200 Brussels, Belgium.	John.Lee@uclouvain.be; Anne.Bol@uclouvain.be1; Vincent.Gregoire@uclouvain.be; Xavier.Geets@imre.ucl.ac.be	Lee, John/N-7434-2013	Lee, John/0000-0001-5218-759X				ANSCOMBE FJ, 1948, BIOMETRIKA, V35, P246, DOI 10.2307/2332343; Aurich V., 1995, MUSTERERKENNUNG, P538; Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005; Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; Beekman FJ, 1997, PHYS MED BIOL, V42, P1619, DOI 10.1088/0031-9155/42/8/011; Beekman FJ, 1998, PHYS MED BIOL, V43, P1713, DOI 10.1088/0031-9155/43/6/024; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Devroye L., 1986, NONUNIFORM RANDOM VA, P61; Donoho DL, 1993, P S APPL MATH, V47; Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126; Fisz M., 1955, C MATH, V3, P138, DOI DOI 10.4064/CM-3-2-138-146; FRYLEWICZ P, 2004, J COMPUTATIONAL GRAP, V13, P621; Hampel F. R., 1986, WILEY SERIES PROBABI; Huber P. J, 1981, ROBUST STAT; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JASZCZAK RJ, 1995, PRINCIPLES NUCL MED; MRAZEK P, 2004, 51 U BREM; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Ramos CD, 2001, EUR J NUCL MED, V28, P155, DOI 10.1007/s002590000421; Slijpen ETP, 1999, IEEE T NUCL SCI, V46, P2233, DOI 10.1109/23.819309; Soret M, 2007, J NUCL MED, V48, P932, DOI 10.2967/jnumed.106.035774; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Valk P.E., 2003, POSITRON EMISSION TO; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Winkler G., 1999, Pattern Recognition and Image Analysis, V9, P749; ZHANG B, 2006, P INT C AC SPEECH SI, V2, P81	27	25	25	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1014	1027		10.1109/TPAMI.2008.16	http://dx.doi.org/10.1109/TPAMI.2008.16			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421107				2022-12-18	WOS:000254872500007
J	Hoey, J; Little, JJ				Hoey, Jesse; Little, James J.			Value-directed human behavior analysis from video using partially observable Markov decision processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face and gesture recognition; video analysis; motion; statistical models; clustering algorithms; machine learning; parameter learning; control theory; dynamic programming	RECOGNITION; MODELS; PEOPLE	This paper presents a method for learning decision theoretic models of human behaviors from video data. Our system learns relationships between the movements of a person, the context in which they are acting, and a utility function. This learning makes explicit that the meaning of a behavior to an observer is contained in its relationship to actions and outcomes. An agent wishing to capitalize on these relationships must learn to distinguish the behaviors according to how they help the agent to maximize utility. The model we use is a partially observable Markov decision process, or POMDP. The video observations are integrated into the POMDP using a dynamic Bayesian network that creates spatial and temporal abstractions amenable to decision making at the high level. The parameters of the model are learned from training data using an a posteriori constrained optimization technique based on the expectation-maximization algorithm. The system automatically discovers classes of behaviors and determines which are important for choosing actions that optimize over the utility of possible outcomes. This type of learning obviates the need for labeled data from expert knowledge about which behaviors are significant and removes bias about what behaviors may be useful to recognize in a particular situation. We show results in three interactions: a single player imitation game, a gestural robotic control problem, and a card game played by two people.	Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland; Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada	University of Dundee; University of British Columbia	Hoey, J (corresponding author), Univ Dundee, Sch Comp, Queen Mother Bldg, Dundee DD1 4HN, Scotland.	jessehoey@computing.dundee.ac.uk; little@cs.ubc.ca						ASTROM KJ, 1965, J MATH ANAL APPL, V10, P174, DOI 10.1016/0022-247X(65)90154-X; BARTLETT MS, 2003, ADV NEURAL INFORM PR, V15, P382; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bellman RE, 1957, DYNAMIC PROGRAMMING; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boger J, 2006, IEEE T INF TECHNOL B, V10, P323, DOI 10.1109/TITB.2006.864480; Boutilier C, 1999, J ARTIF INTELL RES, V11, P1; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; BRAND M, 1997, TR9725 MITS EL RES L; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; CARBONETTO P, 2003, P 9 INT WORKSH ART I, P122; Cassell J., 2000, EMBODIED CONVERSATIO; CHRISMAN L, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P183; CLARKSON B, 1999, P INT C AC SPEECH SI; DARRELL T, 1996, P 13 IEEE INT C PATT; Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Fleet DJ, 2000, INT J COMPUT VISION, V36, P171, DOI 10.1023/A:1008156202475; Fridlund A.J., 1994, HUMAN FACIAL EXPRESS; Galantucci B, 2005, COGNITIVE SCI, V29, P737, DOI 10.1207/s15516709cog0000_34; Hoey J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1086; Hoey J, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P279; Hoey J, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.855896; HOEY J, 2004, THESIS U BRIT COLUMB; Hoey J., 2005, P AAAI FALL S CAR MA; Hoey J, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1332; HUNTER E, 1995, P INT WORKSH AUT FAC, P290; Jebara T., 1999, Computer Vision Systems. First International Conference, ICVS'99. Proceedings, P273; KRAUSS RM, 1977, SCI AM, V236, P100, DOI 10.1038/scientificamerican0277-100; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; LI C, 1999, ADV INTELLIGENT DATA; Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809; McNeill D., 1992, HAND MIND WHAT GESTU; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004; PAEK T, 2000, P C UNC ART INT JUN; Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823; Poupart P., 2003, ADV NEURAL INFORM PR, V15, P1547; PRATA A, 1989, APPL OPTICS, V28, P749, DOI 10.1364/AO.28.000749; Rabiner L., 1993, FUNDAMENTALS SPEECH; Russell J.A., 1997, PSYCHOL FACIAL EXPRE, P3, DOI DOI 10.1017/CBO9780511659911.003; SCHLENZIG J, 1994, P AS C SIGN SYST COM, P394; SIMONCELLI EP, 1991, IEEE C COMP VIS PATT, P310, DOI 10.1109/CVPR.1991.139707; SMYTH P, 1997, ADV NEURAL INFORM PR, V10; Spaan MTJ, 2005, J ARTIF INTELL RES, V24, P195, DOI 10.1613/jair.1659; STARNER T, 1995, P INT WORKSH AUT FAC, P189; Sutton Richard S, 1998, INTRO REINFORCEMENT, V2; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Thrun S, 2000, AI MAG, V21, P93; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WILLIAMS JD, 2005, P 4 WORKSH KNOWL REA, P76	57	25	25	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1118	1132		10.1109/TPAMI.2007.1145	http://dx.doi.org/10.1109/TPAMI.2007.1145			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496372				2022-12-18	WOS:000246395300002
J	Leymarie, FF; Kimia, BB				Leymarie, Frederic F.; Kimia, Benjamin B.			The medial scaffold of 3D unorganized point clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D shape understanding; object representation; geometric algorithms; 3D medial axis; shock graphs; flow singularities; 3D bucketing; visibility constraints	AXIS; SHAPE; ALGORITHM; RECONSTRUCTION; DEFORMATIONS; SKELETONS; CURVES; FORM	We introduce the notion of the medial scaffold, a hierarchical organization of the medial axis of a 3D shape in the form of a graph constructed from special medial curves connecting special medial points. A key advantage of the scaffold is that it captures the qualitative aspects of shape in a hierarchical and tightly condensed representation. We propose an efficient and exact method for computing the medial scaffold based on a notion of propagation along the scaffold itself, starting from initial sources of the flow and constructing the scaffold during the propagation. We examine this method specifically in the context of an unorganized cloud of points in 3D, e. g., as obtained from laser range finders, which typically involve hundreds of thousands of points, but the ideas are generalizable to data arising from geometrically described surface patches. The computational bottleneck in the propagation-based scheme is in finding the initial sources of the flow. We thus present several ideas to avoid the unnecessary consideration of pairs of points which cannot possibly form a medial point source, such as the "visibility" of a point from another given a third point and the interaction of clusters of points. An application of using the medial scaffold for the representation of point samplings of real-life objects is also illustrated.	Univ London Goldsmiths Coll, Dept Comp, London SE14 6NW, England; Brown Univ, Div Engn, Providence, RI 02912 USA	University of London; Goldsmiths University London; Brown University	Leymarie, FF (corresponding author), Univ London Goldsmiths Coll, Dept Comp, New Cross, London SE14 6NW, England.	ffl@gold.ac.uk; kimia@lems.brown.edu		Leymarie, Frederic/0000-0002-3221-8966				Amenta N, 2002, INT J COMPUT GEOM AP, V12, P125, DOI 10.1142/S0218195902000773; Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475; ATTALI D, 2002, P 7 ACM S SOL MOD AP, P139; BALLICCIONI A, 1964, COORDONNES BARYCENTR; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Barequet G, 1998, IEEE T VIS COMPUT GR, V4, P162, DOI 10.1109/2945.694983; Berge C., 1989, HYPERGRAPHS COMBINAT, V45; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BOEHM W, 1994, GEOMETRIC CONCEPTS G; Borgefors G, 1999, PATTERN RECOGN, V32, P1225, DOI 10.1016/S0031-3203(98)00082-X; Chang NC, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P987; Chazal F., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P319, DOI 10.1145/1137856.1137904; Culver T, 2004, COMPUT AIDED GEOM D, V21, P65, DOI 10.1016/j.cagd.2003.07.008; DEVROYE L, 1986, LECT NTOES BUCKET AL; Elber G, 1999, IEEE COMPUT GRAPH, V19, P76, DOI 10.1109/38.799747; Giblin P, 2004, IEEE T PATTERN ANAL, V26, P238, DOI 10.1109/TPAMI.2004.1262192; Giblin P, 2002, LECT NOTES COMPUT SC, V2351, P718; Giblin PJ, 2003, IEEE T PATTERN ANAL, V25, P895, DOI 10.1109/TPAMI.2003.1206518; Giblin PJ, 2003, INT J COMPUT VISION, V54, P143, DOI 10.1023/A:1023761518825; HALLIMAN P, 1999, 2 3 DIMENSIONAL PATT; HEWCHUK J, 1999, LECT NOTES GEOMETRIC; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HOFFMANN C, 1994, MATH SURFACES, V4, P421; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; LEYMARIE F, 2007, MEDIAL REPRESENTATIO, pCH11; LEYMARIE F, 2003, P IEEE COMP SOC C CO, V1, P821; LEYMARIE F, 2001, COMPUTING ARCHAEOLOG, P78; Leymarie FF, 2004, INT C PATT RECOG, P123, DOI 10.1109/ICPR.2004.1334484; LEYMARIE FF, 2003, THESIS BROWN U; Leyton M, 2001, LECT NOTES COMPUTER, V2145; Leyton M., 1992, SYMMETRY CAUSALITY M; Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7; MUMFORD D, 1991, P SOC PHOTO-OPT INS, V1570, P2, DOI 10.1117/12.49981; Okabe A., 2000, PROBABILITY STAT SER; Patrikalakis N. M., 2002, SHAPE INTERROGATION; Peternell M, 2000, GRAPH MODELS, V62, P202, DOI 10.1006/gmod.1999.0521; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Sherbrooke EC, 1996, GRAPH MODEL IM PROC, V58, P574, DOI 10.1006/gmip.1996.0047; Sherbrooke EC, 1996, IEEE T VIS COMPUT GR, V2, P44, DOI 10.1109/2945.489386; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; SIERSMA D, 1999, GEOMETRY PRESENT DAY; Smid M, 2000, HANDBOOK OF COMPUTATIONAL GEOMETRY, P877, DOI 10.1016/B978-044482537-7/50021-8; Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609; Tek H, 2003, INT J COMPUT VISION, V54, P35, DOI 10.1023/A:1023753317008; Tek H, 1998, COMP IMAG VIS, V12, P115; Tek H, 2001, J MATH IMAGING VIS, V14, P211, DOI 10.1023/A:1011229911541; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Verroust A, 2000, VISUAL COMPUT, V16, P15, DOI 10.1007/PL00007210; Wade L, 2002, VISUAL COMPUT, V18, P97, DOI 10.1007/s003710100139; Wolter FE, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P137, DOI 10.1109/CGI.2000.852329; WOLTER FE, 1992, 922 MIT DEP OC ENG D; Zerroug M, 1996, IEEE T PATTERN ANAL, V18, P237, DOI 10.1109/34.485553; [No title captured]	58	25	25	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					313	330		10.1109/TPAMI.2007.44	http://dx.doi.org/10.1109/TPAMI.2007.44			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170483				2022-12-18	WOS:000242826900011
J	Gupta, MR; Gray, RM; Olshen, RA				Gupta, MR; Gray, RM; Olshen, RA			Nonparametric supervised learning by linear interpolation with maximum entropy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonparametric statistics; probabilistic algorithms; pattern recognition; maximum entropy; linear interpolation		Nonparametric neighborhood methods for learning entail estimation of class conditional probabilities based on relative frequencies of samples that are "near-neighbors" of a test point. We propose and explore the behavior of a learning algorithm that uses linear interpolation and the principle of maximum entropy (LIME). We consider some theoretical properties of the LIME algorithm: LIME weights have exponential form; the estimates are consistent; and the estimates are robust to additive noise. In relation to bias reduction, we show that near-neighbors contain a test point in their convex hull asymptotically. The common linear interpolation solution used for regression on grids or look-up-tables is shown to solve a related maximum entropy problem. LIME simulation results support use of the method, and performance on a pipeline integrity classification problem demonstrates that the proposed algorithm has practical value.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; Stanford Univ, Informat Syst Lab, Dept Elect Engn, Stanford, CA 94305 USA; Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	University of Washington; University of Washington Seattle; Stanford University; Stanford University; Stanford University	Gupta, MR (corresponding author), Univ Washington, Dept Elect Engn, Box 352500, Seattle, WA 98195 USA.	gupta@ee.washington.edu; rmgray@stanford.edu; olshen@stanford.edu			NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB002784] Funding Source: NIH RePORTER; NIBIB NIH HHS [5R01 EB002784] Funding Source: Medline	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIBIB NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; BICKEL PJ, 1983, ANN PROBAB, V11, P185, DOI 10.1214/aop/1176993668; BICKEL PJ, 1968, ANN MATH STAT, V39, P442, DOI 10.1214/aoms/1177698408; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; De Guzman M., 1975, DIFFERENTIATION INTE; Fix E., 1951, 4 US AIR FORC SCH AV; Friedlander MP, 2006, IEEE T INFORM THEORY, V52, P238, DOI 10.1109/TIT.2005.860448; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Garsia A.M., 1970, TOPICS ALMOST EVERYW; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P147, DOI 10.1016/0047-259X(84)90022-8; Gray R. M., 1990, ENTROPY INFORM THEOR; Gray RM, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P172, DOI 10.1109/SEQUEN.1997.666914; HASTIE T, 1993, STAT SCI, V8, P120, DOI 10.1214/ss/1177011002; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HESTERBERG TC, 1997, P SECT STAT COMP AM, P34; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Kang H., 1997, COLOR TECHNOLOGY ELE; Kneale W. C., 1949, PROBABILITY INDUCTIO; KOHONEN T, 1988, IEEE INT C NEUR NETW, V1, P61; Kullback S, 1959, INFORM THEORY STAT; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Lugosi G, 1996, IEEE T INFORM THEORY, V42, P48, DOI 10.1109/18.481777; MACK YP, 1979, J MULTIVARIATE ANAL, V9, P1, DOI 10.1016/0047-259X(79)90065-4; NAJMI A, 1999, THESIS STANFORD U ST; OBRIEN DB, 2003, P IEEE INT C IM PROC; Olshen R., 1984, CLASSIFICATION REGRE; Peirce C. S., 1956, PHILOS PEIRCE SELECT; Pollard David, 1984, CONVERGENCE STOCHAST; Press W. H., 1999, NUMERICAL RECIPES C; RICE J, 1984, COMMUN STAT-THEOR M, V13, P893; RIPLEY B, 2001, PATTERN RECOGNITION; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; Wu N., 1997, MAXIMUM ENTROPY METH; 2002, MATLAB VERSION 6 1 M	39	25	27	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					766	781		10.1109/TPAMI.2006.101	http://dx.doi.org/10.1109/TPAMI.2006.101			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640262				2022-12-18	WOS:000235885700008
J	Fan, ZM; Zhou, J; Wu, Y				Fan, ZM; Zhou, J; Wu, Y			Multibody grouping by inference of multiple subspaces from high-dimensional data using oriented-frames	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; motion segmentation; subspace constraints	FACTORIZATION METHOD; MOTION SEGMENTATION; IMAGE	Recently, subspace constraints have been widely exploited in many computer vision problems such as multibody grouping. Under linear projection models, feature points associated with multiple bodies reside in multiple subspaces. Most existing factorization-based algorithms can segment objects undergoing independent motions. However, intersections among the correlated motion subspaces will lead most previous factorization-based algorithms to erroneous segmentation. To overcome this limitation, in this paper, we formulate the problem of multibody grouping as inference of multiple subspaces from a high-dimensional data space. A novel and robust algorithm is proposed to capture the configuration of the multiple subspace structure and to find the segmentation of objects by clustering the feature points into these inferred subspaces, no matter whether they are independent or correlated. In the proposed method, an Oriented-Frame (OF), which is a multidimensional coordinate frame, is associated with each data point indicating the point's preferred subspace configuration. Based on the similarity between the subspaces, novel mechanisms of subspace evolution and voting are developed. By filtering the outliers due to their structural incompatibility, the subspace configurations will emerge. Compared with most existing factorization-based algorithms that cannot correctly segment correlated motions, such as motions of articulated objects, the proposed method has a robust performance in both independent and correlated motion segmentation. A number of controlled and real experiments show the effectiveness of the proposed method. However, the current approach does not deal with transparent motions and motion subspaces of different dimensions.	Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA	Tsinghua University; Northwestern University	Fan, ZM (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	z-fan@northwestern.edu; jzhou@tsinghua.edu.cn; yingwu@ece.northwestern.edu	Wu, Ying/B-7283-2009					Bishop C. M., 1999, NEURAL COMPUTATION, V11; Bissacco A, 2001, PROC CVPR IEEE, P52; Boult T. E., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P179, DOI 10.1109/WVM.1991.212809; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 2003, P IEEE CS C COMP VIS; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Golub G. H., 1996, MATRIX COMPUTATIONS; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5; Ichimura N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P600, DOI 10.1109/ICCV.1999.791279; Irani M, 2002, INT J COMPUT VISION, V48, P173, DOI 10.1023/A:1016372015744; KANATANI K, 2003, P AUSTR JAP ADV WORK; Kanazawa Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCV.2001.937640; LII J, 2004, P INT C MACH LEARN; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SIMARD P, 1993, P NEUR INF PROC SYST; Soatto S, 1997, INT J COMPUT VISION, V22, P235, DOI 10.1023/A:1007930700152; Tang CK, 2001, IEEE T PATTERN ANAL, V23, P829, DOI 10.1109/34.946987; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Vidal R, 2004, PROC CVPR IEEE, P310; Vidal R, 2003, PROC CVPR IEEE, P621; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Wolf L, 2003, PROC CVPR IEEE, P635; Wu Y, 2001, PROC CVPR IEEE, P252; Zelnik-Manor L, 2003, PROC CVPR IEEE, P287	30	25	26	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					91	105		10.1109/TPAMI.2006.16	http://dx.doi.org/10.1109/TPAMI.2006.16			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402622	Green Submitted			2022-12-18	WOS:000233172000008
J	Cornelis, K; Verbiest, F; Van Gool, L				Cornelis, K; Verbiest, F; Van Gool, L			Drift detection and removal for sequential structure from motion algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric correction; registration		In sequential Structure from Motion algorithms for extended image or video sequences, error build up caused by drift poses a problem as feature tracks that normally represent a single scene point will have distinct 3D reconstructions. For the final bundle adjustment to remove this drift, it must be told about these 3D-3D correspondences through a change in the cost function. However, as a bundle adjustment is a nonlinear optimization technique, the drift needs to be removed from the supplied initial solution to allow for convergence of the bundle adjustment to the real global optimum. Before drift can be removed, it has to be detected. This is accomplished through understanding of the long term behavior of drift which leaves 3D reconstructions from short sequences intact. Drift detection boils down to identifying reconstructions of the same scene part that only differ up to a projective transformation. After detection, the drift can be removed from future processed images and an Adapted Bundle Adjustment using correspondences supplied by the drift detection can remove the drift from previous images. Several experiments on real video sequences demonstrate the merit of drift detection and removal.	Katholieke Univ Leuven, B-3001 Louvain, Belgium	KU Leuven	Cornelis, K (corresponding author), Katholieke Univ Leuven, Kasteelpk Arenberg 10, B-3001 Louvain, Belgium.	kurt.cornelis@esat.kuleuven.ac.be; frank.verbiest@esat.kuleuven.ac.be; luc.vangool@esat.kuleuven.ac.be						AHERNE F, 1997, KYBERNETIKA, V32, P1; BAJURA M, 1995, IEEE COMPUT GRAPH, V15, P52, DOI 10.1109/38.403828; BAJURA M, 1998, TR98036, P17; CORNELIS K, 2002, P EUR C COMP VIS, V2, P186; CORNELIS K, 2001, P ACM S VIRT REAL SO, P17, DOI DOI 10.1145/505008.505012]; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 1998, P EUR C COMP VIS, P311; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Hartley R. I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P510, DOI 10.1109/ICCV.1999.791264; Koch R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P585, DOI 10.1109/ICCV.1999.791277; Nister D, 2003, PROC CVPR IEEE, P195; Nister D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P116, DOI 10.1109/ICCV.2001.937612; POLLEFEYS M, 2000, P AS C COMP VIS, P893; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; SMITH RA, 1999, P BMVC, P295; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Triggs B., 1999, VISION ALGORITHMS TH, P298; TUYTELAARS T, 1999, P 3 INT C VIS INF SY, P493	21	25	29	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1249	1259		10.1109/TPAMI.2004.85	http://dx.doi.org/10.1109/TPAMI.2004.85			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641713				2022-12-18	WOS:000223140200001
J	Wechsler, H; Duric, Z; Li, FY; Cherkassky, V				Wechsler, H; Duric, Z; Li, FY; Cherkassky, V			Motion estimation using statistical learning theory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						aperture problem; complexity control; condition number; image flow; model selection; motion estimation; robust learning; statistical learning theory; tracking; visual motion	COMPUTER VISION; SELECTION	This paper describes a novel application of Statistical Learning Theory (SLT) to single motion estimation and tracking. The problem of motion estimation can be related to statistical model selection, where the goal is to select one (correct) motion model from several possible motion models, given finite noisy samples. SLT, also known as Vapnik-Chervonenkis (VC), theory provides analytic generalization bounds for model selection, which have been used successfully for practical model selection. This paper describes a successful application of an SLT-based model selection approach to the challenging problem of estimating optimal motion models from small data sets of image measurements (flow). We present results of experiments on both synthetic and real image sequences for motion interpolation and extrapolation; these results demonstrate the feasibility and strength of our approach. Our experimental results show that for motion estimation applications, SLT-based model selection compares favorably against alternative model selection methods, such as the Akaike's fpe, Schwartz' criterion (sc), Generalized Cross-Validation (gcv), and Shibata's Model Selector (sms). The paper also shows how to address the aperture problem using SLT-based model selection for penalized linear (ridge regression) formulation.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA; Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	George Mason University; University of Minnesota System; University of Minnesota Twin Cities	Wechsler, H (corresponding author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	wechsler@cs.gmu.edu; zduric@cs.gmu.edu; fli@cs.gmu.edu; cherkass@ece.umn.edu						AKAIKE H, 1970, ANN I STAT MATH, V22, P203, DOI 10.1007/BF02506337; ALOIMONOS Y, 1994, INT J COMPUT VISION, V13, P33, DOI 10.1007/BF01420794; Black M.J., 1997, MOTION BASED RECOGNI, P245; Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bubna K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P895, DOI 10.1109/ICCV.1998.710823; Bubna K, 2000, COMPUT VIS IMAGE UND, V80, P215, DOI 10.1006/cviu.2000.0871; Cherkassky V, 1999, IEEE T NEURAL NETWOR, V10, P1075, DOI 10.1109/72.788648; Cherkassky V. F. M., 2007, LEARNING DATA CONCEP; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; DURIC Z, 2002, P INT C PATT REC; Friedman J.H., 1994, NATO ASI SERIES F, V136; GIROSI F, 1994, NATO ASI SERIES F, V136; Golub G. H., 1996, MATRIX COMPUTATION; Hampel FR., 2011, WILEY SERIES PROBABI; Huber P., 1981, ROBUST STAT; Lee WS, 1996, IEEE T INFORM THEORY, V42, P2118, DOI 10.1109/18.556601; Meer P, 2000, COMPUT VIS IMAGE UND, V78, P1, DOI 10.1006/cviu.1999.0833; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; NAYAR SK, 1996, EARLY VISUAL LEARNIN; Poggio T, 1999, AI MAG, V20, P37; Ripley BD., 1996; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHIBATA R, 1981, BIOMETRIKA, V68, P45, DOI 10.1093/biomet/68.1.45; Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296; Trucco E., 1998, INTRO TECHNIQUES 3D; Vapnik V.N., 1999, NATURE STAT LEARNING; Vapnik V.N, 1998, STAT LEARNING THEORY	30	25	39	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					466	478		10.1109/TPAMI.2004.1265862	http://dx.doi.org/10.1109/TPAMI.2004.1265862			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382651				2022-12-18	WOS:000220102800003
J	Jiang, G; Tsui, HT; Quan, L; Zisserman, A				Jiang, G; Tsui, HT; Quan, L; Zisserman, A			Geometry of single axis motions using conic fitting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						turntable; structure from motion; single axis motion; geometry; conic; fundamental matrix	RECONSTRUCTION; SECTIONS; OBJECTS; IMAGES; ROBUST	Previous algorithms for recovering 3D geometry from an uncalibrated image sequence of a single axis motion of unknown rotation angles are mainly based on the computation of two-view fundamental matrices and three-view trifocal tensors. In this paper, we propose three new methods that are based on fitting a conic locus to corresponding image points over multiple views. The main advantage is that determining only five parameters of a conic from one corresponding point over at least five views is simpler and more robust than determining a fundamental matrix from two views or a trifocal tensor from three views. It is shown that the geometry of single axis motion can be recovered either by computing one conic locus and one fundamental matrix or by computing at least two conic loci. A maximum likelihood solution based on this parametrization of the single axis motion is also described for optimal estimation using three or more loci. The experiments on real image sequences demonstrate the simplicity, accuracy, and robustness Of the new methods.	Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Chinese University of Hong Kong; Hong Kong University of Science & Technology; University of Oxford	Jiang, G (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.	gjiang@ee.cuhk.edu.hk; httsui@ee.cuhk.edu.hk; quan@cs.ust.hk; az@robots.ox.ac.uk						ARMSTRONG M, 1996, P 4 EUR C COMP VIS C, P3; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P256, DOI 10.1016/0734-189X(86)90078-2; FAUGERAS O, 1998, P 5 EUR C COMP VIS F, P36; FITZGIBBON AW, 1998, P EUR WORKSH 3D STRU, P155; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Jiang G, 2002, LECT NOTES COMPUT SC, V2350, P537; Jiang G, 2001, PROC CVPR IEEE, P293; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; NIEM W, 1994, P SOC PHOTO-OPT INS, V2182, P388, DOI 10.1117/12.171088; Quan L, 1996, IEEE T PATTERN ANAL, V18, P151, DOI 10.1109/34.481540; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SAWHNEY HS, 1993, IEEE T PATTERN ANAL, V15, P885, DOI 10.1109/34.232075; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; Szeliski R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P625, DOI 10.1109/CVPR.1991.139764; Vieville T, 1999, INT J COMPUT VISION, V31, P5, DOI 10.1023/A:1008082308694; Wong KYK, 2002, IMAGE VISION COMPUT, V20, P441, DOI 10.1016/S0262-8856(02)00015-X; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zisserman A, 1998, PHILOS T R SOC A, V356, P1193, DOI 10.1098/rsta.1998.0217; [No title captured]	23	25	33	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1343	1348		10.1109/TPAMI.2003.1233910	http://dx.doi.org/10.1109/TPAMI.2003.1233910			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800016
J	Steinwart, I				Steinwart, I			On the optimal parameter choice for nu-support vector machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; PAC model; support vector machines; parameter selection		We determine the asymptotically optimal choice of the parameter v for classifiers of v-support vector machine (v-SVM) type which has been introduced by Scholkopf et al. [14]. It turns out that v should be a close upper estimate of twice the optimal Bayes risk provided that the classifier uses a so-called universal kernel such as the Gaussian RBF kernel. Moreover, several experiments show that this result can be used to implement some modified cross validation procedures which improve standard cross validation for v-SVMs.	Los Alamos Natl Lab, Modeling Algorithms & Informat Grp, Los Alamos, NM 87545 USA	United States Department of Energy (DOE); Los Alamos National Laboratory	Steinwart, I (corresponding author), Los Alamos Natl Lab, Modeling Algorithms & Informat Grp, CCS-3, Los Alamos, NM 87545 USA.	ingo@lanl.gov		Steinwart, Ingo/0000-0002-4436-7109				Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; CHANG CC, LIBSVM 2 33; Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]; Cucker F, 2002, B AM MATH SOC, V39, P1; Dahmen W., 1987, APPROX THEORY APPL, V3, P139; Devroye L., 1997, PROBABILISTIC THEORY; Dudley R.M., 1989, REAL ANAL PROBABILIT; DUDLEY RM, 1984, LECT NOTES MATH, V1097, P1, DOI [DOI 10.1007/BFB0099432, 10.1007/BFb0099432]; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Loeve M., 2017, PROBABILITY THEORY; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RATSCH G, COMMUNICATION; Scholkopf B., 2001, LEARNING KERNELS; Steinwart I, 2002, J MACH LEARN RES, V2, P67, DOI 10.1162/153244302760185252; Steinwart I, 2002, J COMPLEXITY, V18, P768, DOI 10.1006/jcom.2002.0642; STEINWART I, 2003, IN PRESS J MACHINE L; STEINWART I, IN PRESS IEEE T INFO	18	25	29	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1274	1284		10.1109/TPAMI.2003.1233901	http://dx.doi.org/10.1109/TPAMI.2003.1233901			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800007
J	Giusti, N; Masulli, F; Sperduti, A				Giusti, N; Masulli, F; Sperduti, A			Theoretical and experimental analysis of a two-stage system for classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multicategory classification; rejection; global and local classification; hierarchical classifier; Bayes classifier	FUZZY-LOGIC	We consider a popular approach to multicategory classification tasks: a two-stage system based on a first (global) classifier with rejection followed by a (local) nearest-neighbor classifier. Patterns which are not rejected by the first classifier are classified according to its output. Rejected patterns are passed to the nearest-neighbor classifier together with the top-it ranking classes returned by the first classifier. The nearest-neighbor classifier, looking at patterns in the top-h classes, classifies the rejected pattern. An editing strategy for the nearest-neighbor reference database, controlled by the first classifier, is also considered. We analyze this system, showing that even if the first level and nearest-neighbor classifiers are not optimal in a Bayes sense, the system as a whole may be optimal. Moreover, we formally relate the response time of the system to the rejection rate of the first classifier and to the other system parameters. The error-response time trade-off is also discussed. Finally, we experimentally study two instances of the system applied to the recognition of handwritten digits. In one system, the first classifier is a fuzzy basis functions network, while in the second system it is a feed-forward neural network. Classification results as well as response times for different settings of the system parameters are reported for both systems.	Micronix Comp, I-51016 Montecatini Terme, PT, Italy; Univ Pisa, Dipartimento Informat, I-56125 Pisa, Italy	University of Pisa	Giusti, N (corresponding author), Micronix Comp, Via Colombi,2, I-51016 Montecatini Terme, PT, Italy.	ngiusti@micronix.net; masulli@di.unipi.it; perso@di.unipi.it	Masulli, Francesco/V-9719-2017	Masulli, Francesco/0000-0002-6612-0932				ALFONSO D, 1996, P INT ICSC S IND INT, P2; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Casalino F, 1998, INTELL AUTOM SOFT CO, V4, P73; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Duda R.O., 1973, J ROYAL STAT SOC SER; Furlanello C., 1997, Connection Science, V9, P31, DOI 10.1080/095400997116720; GARRIS MD, 1992, NIST SPECIAL DATABAS, V3; GUTTA S, 1997, P INT C NEUR NETW, V3, P1353; Hashem S., 1996, Connection Science, V8, P315, DOI 10.1080/095400996116794; Jimenez D, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P753, DOI 10.1109/IJCNN.1998.682375; KIM HM, 1995, IEEE T FUZZY SYST, V3, P158, DOI 10.1109/91.388171; KNERR S, 1993, P INT S NONL THEOR I, P957; KURZYNSKI MW, 1988, PATTERN RECOGN, V21, P355, DOI 10.1016/0031-3203(88)90049-0; Larkey L. S., 1996, SIGIR Forum, P289; LEE CC, 1990, IEEE T SYST MAN CYB, V20, P404, DOI 10.1109/21.52551; Liu Y, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P2202, DOI 10.1109/IJCNN.1998.687202; Maclin R., 1997, PROC NATL CONF ARTIF, V1997, P546; MASULLI F, 1994, P EUR C ART NEUR NET, P189; MENDEL JM, 1995, P IEEE, V83, P345, DOI 10.1109/5.364485; OPITZ DW, 1996, CONNECTION SCI, V8; PARMANTO B, 1996, CONNECTION SCI, V8; PODDAR P, 1993, P INT C NEUR NETW, V1, P287; PUDIL P, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P92, DOI 10.1109/ICPR.1992.201729; Rodriguez C, 1998, INT C PATT RECOG, P1101, DOI 10.1109/ICPR.1998.711886; Rokui J, 1999, IEE CONF PUBL, P221, DOI 10.1049/cp:19991112; Rosen B. E., 1996, Connection Science, V8, P373, DOI 10.1080/095400996116820; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sharf BF, 1997, HEALTH COMMUN, V9, P1, DOI 10.1207/s15327027hc0901_1; SHARKEY AJC, 1996, CONNECT SCI, V8, P299, DOI DOI 10.1080/095400996116785; Simon S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P244, DOI 10.1109/CIRA.1999.810056; Tso SK, 1997, FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN POWER SYSTEM CONTROL, OPERATION & MANAGEMENT, VOLS 1 AND 2, P499; Tumer K., 1996, CONNECTION SCI, V8; Vapnik V.N, 1998, STAT LEARNING THEORY; WANG LX, 1992, IEEE T NEURAL NETWOR, V3, P807, DOI 10.1109/72.159070; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466	35	25	31	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					893	904		10.1109/TPAMI.2002.1017617	http://dx.doi.org/10.1109/TPAMI.2002.1017617			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF					2022-12-18	WOS:000176446100003
J	Bjorkman, M; Eklundh, JO				Bjorkman, M; Eklundh, JO			Real-time epipolar geometry estimation of binocular stereo heads	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						epipolar geometry; active vision; real-time stereo; dynamic vergence	MOTION ESTIMATION; ALGORITHM; FIXATION; VISION; SYSTEM	Stereo is an important cue for visually guided robots. While moving around in the world, such a robot can use dynamic fixation to overcome limitations in image resolution and field of view. In this paper, a binocular stereo system capable of dynamic fixation is presented. The external calibration is performed continuously taking temporal consistency into consideration, greatly simplifying the process. The essential matrix, which is estimated in real-time, is used to describe the epipolar geometry. It will be shown, how outliers can be identified and excluded from the calculations. An iterative approach based on a differential model of the optical flow, commonly used in structure from motion, is also presented and tested towards the essential matrix. The iterative method will be shown to be superior in terms of both computational speed and robustness, when the vergence angles are less than about 15degrees. For larger angles, the differential model is insufficient and the essential matrix is preferably used instead.	Royal Inst Technol, Computat Vis & Act Percept Lab, CVAP, Dept Numer Anal & Comp Sci,KTH, S-10044 Stockholm, Sweden	Royal Institute of Technology	Bjorkman, M (corresponding author), Royal Inst Technol, Computat Vis & Act Percept Lab, CVAP, Dept Numer Anal & Comp Sci,KTH, S-10044 Stockholm, Sweden.	celle@nada.kth.se; joe@nada.kth.se						BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Bjorkman M, 2000, PROC CVPR IEEE, P506, DOI 10.1109/CVPR.2000.854897; BROOKS MJ, 1996, P 4 EUR C COMP VIS, P415; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; Daniilidis K, 1997, COMPUT VIS IMAGE UND, V68, P158, DOI 10.1006/cviu.1997.0535; FERMULLER C, 1993, INT J COMPUT VISION, V11, P165, DOI 10.1007/BF01469227; Fischler M. A., 1980, P IM UND WORKSH, P71; Harris C, 1988, P 4 ALV VIS C, P147, DOI DOI 10.5244/C.2.23; HARTLEY R, 1992, P 2 EUR C COMP VIS, P579; HEEL J, 1989, P DARPA IM UND WORKS, P702; Kanade T., 1992, P DARPA IM UND WORKS, P409; KONOLIGE K, 1997, P 8 INT S ROB RES; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MA Y, 1999, M9933 UCBERL; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Tucakov V, 1997, P ANN HICSS, P188, DOI 10.1109/HICSS.1997.663174; Yau WY, 1999, REAL-TIME IMAGING, V5, P189, DOI 10.1006/rtim.1997.0114; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	20	25	26	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					425	432		10.1109/34.990147	http://dx.doi.org/10.1109/34.990147			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM					2022-12-18	WOS:000174035900012
J	Munich, ME; Perona, P				Munich, ME; Perona, P			Visual input for pen-based computers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						systems and applications; active and real-time vision; pen-based computing; pen-based interface		The design and implementation of a camera-based, human-computer interface for acquisition of handwriting is presented. The camera focuses on a standard sheet of paper and images a common pen; the trajectory of the tip of the pen is tracked and the contact with the paper is detected. The recovered trajectory is shown to have sufficient spatio-temporal resolution and accuracy to enable handwritten character recognition. More than 100 subjects have used the system and have provided a large and heterogeneous set of examples showing that the system is both convenient and accurate.	Vocalpoint Technol, San Francisco, CA 94103 USA; CALTECH, Dept Elect Engn 136 93, Pasadena, CA 91125 USA	California Institute of Technology	Munich, ME (corresponding author), Vocalpoint Technol, 847 Howard St, San Francisco, CA 94103 USA.	mariomu@vision.caltech.edu; perona@caltech.edu	Munich, Mario E./Q-4849-2019	Munich, Mario E./0000-0002-6665-7473				Anderson B. D. O., 1979, OPTIMAL FILTERING; Bunke H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P573, DOI 10.1109/ICDAR.1999.791852; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Crowley James L., 1995, P INT WORKSHOP FACE, P195; Crowley JL, 1997, ROBOT AUTON SYST, V19, P347, DOI 10.1016/S0921-8890(96)00061-9; Elrod S., 1992, P SIGCHI C HUMAN FAC, P599, DOI [10.1145/142750.143052, DOI 10.1145/142750.143052]; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Fukunaga K, 1990, STAT PATTERN RECOGNI; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Impedovo S., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P1, DOI 10.1142/S0218001491000041; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; LORETTE G, 1990, COMPUTER PROCESSING OF HANDWRITING, P21; Lucas Bruce, 1981, IJCAI; Munich M. E., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P782, DOI 10.1007/BFb0055704; Munich M. E., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P180, DOI 10.1109/CVPR.1999.784627; MUNICH ME, 1996, P 13 INT C PATT REC; MUNICH ME, 2000, THESIS CALTECH PASAD; Nabeshima S., 1995, P INT C HUM FACT COM, P256, DOI DOI 10.1145/223355.223662; NAKAGAWA M, 1996, P INT C VIRT SYST MU, P479; PLAMONDON R, 1989, IEEE T SYST MAN CYB, V19, P1060, DOI 10.1109/21.44021; PLAMONDON R, 1991, HUM MOVEMENT SCI, V10, P193, DOI 10.1016/0167-9457(91)90004-H; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rabiner L., 1993, FUNDAMENTALS SPEECH; SIMARD B, 1993, PATTERN RECOGN, V26, P993, DOI 10.1016/0031-3203(93)90001-D; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Van Trees H. L, 2004, DETECTION ESTIMATION; VIVIANI P, 1982, NEUROSCIENCE, V7, P431, DOI 10.1016/0306-4522(82)90277-9; VIVIANI P, 1983, NEUROSCIENCE, V10, P211, DOI 10.1016/0306-4522(83)90094-5; VREDENBREGT J, 1971, PHILIPS TECH REV, V32, P73; Wellner PD., 1993, EPC1993110, pp. 1; WELLNER PD, 1993, EPC1993109; Yamasaki T, 1996, INFORMATION INTELLIGENCE AND SYSTEMS, VOLS 1-4, P428, DOI 10.1109/ICSMC.1996.569811	32	25	28	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					313	328		10.1109/34.990134	http://dx.doi.org/10.1109/34.990134			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM		Green Accepted, Green Submitted			2022-12-18	WOS:000174035900003
J	Leavers, VF				Leavers, VF			Use of the two-dimensional Radon Transform to generate a taxonomy of shape for the characterization of abrasive powder particles	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Radon Transform; shape characterization; powder particle technology; wear particles	HOUGH; ANGULARITY; LOCATION	A novel image processing technique for the extraction of parameters characteristic of the shape and angularity of abrasive powder particles is proposed. The image data are not analyzed directly. Information concerning angularity and shape is extracted from the parametric transformation of the 2D binarized edge map. The transformation process used, the Radon Transform, is one to many, that is, each image point generates in transform space the parameters of all the possible curves on which it may lie and the resulting distribution is an accumulation of that evidence. Once the image data are segmented, the technique has the potential to deliver a comprehensive numerical description of the shape and angularity of the particles under investigation without the need for further interaction by the operator. The parameters obtained are arranged into a Taxonomy according to their usefulness in categorizing the shapes under inspection. The technique is novel in that it offers an analytical definition of a corner and its apex and it automatically selects only those protrusions coincident with the convex hull of the shape and, hence, those most likely to contribute to the process of abrasion. The advantages and potential pitfalls of using the technique are illustrated and discussed using real image data.	Univ Manchester, Manchester Sch Engn, Manchester M13 9PL, Lancs, England	University of Manchester	Leavers, VF (corresponding author), Univ Manchester, Manchester Sch Engn, Manchester M13 9PL, Lancs, England.	v.leavers@man.ac.uk						Allen T., 1997, PARTICLE SIZE MEASUR, V5th; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; CASASENT D, 1987, PATTERN RECOGN, V20, P181, DOI 10.1016/0031-3203(87)90052-5; Deans S.R., 1983, APPL RADON TRANSFORM; DEANS SR, 1981, IEEE T PATTERN ANAL, V3, P185, DOI 10.1109/TPAMI.1981.4767076; FLOOK AG, 1981, PARTICLE SIZE ANAL; FULL WE, 1982, J INT ASS MATH GEOL, V14, P43, DOI 10.1007/BF01037446; Hawkins A. E., 1993, SHAPE POWDER PARTICL; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KAYE BH, 1992, PART PART SYST CHAR, V9, P1, DOI 10.1002/ppsc.19920090102; KAYE BH, 1981, DIRECT CHARACTERIZAT; KIRK TB, 1995, WEAR, V181, P717; KIRYATI N, 1991, CVGIP-GRAPH MODEL IM, V53, P213, DOI 10.1016/1049-9652(91)90043-J; LATTO A, 1984, P IEEE WORKSH COMP V; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; LEAVERS VF, 1999, Patent No. 99081523; Radon J., 1917, SITZBER SACHS AKAD W, V69, P262, DOI DOI 10.1109/TMI.1986.4307775; Stachowiak GW, 1998, TRIBOL INT, V31, P139, DOI 10.1016/S0301-679X(98)00016-4; STOCKMAN GC, 1977, COMM ACM, V20; TURIN GL, 1960, IRE T INFORMATION TH, V6; Verspui MA, 1996, WEAR, V199, P122, DOI 10.1016/0043-1648(96)07224-9; Ya Vilenkin N., 1966, GEN FUNCTIONS, V5	23	25	27	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1411	1423		10.1109/34.895975	http://dx.doi.org/10.1109/34.895975			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR					2022-12-18	WOS:000165901900005
J	Filippidis, A; Jain, LC; Martin, N				Filippidis, A; Jain, LC; Martin, N			Fusion of intelligent agents for the detection of aircraft in SAR images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fusion; Automatic Target Recognition	MINE DETECTION	Receiver Operating Curves are used in the analysis of 20 images using a novel Automatic Target Recognition (ATR) Fusion System. Fuzzy reasoning is used to improve the accuracy of the automatic detection of aircraft in Synthetic Aperture Radar (SAR) images using a priori knowledge derived from color aerial photographs. The images taken by the two different sensors are taken at different times. In summarizing the results of our experiments using real and generated targets with noise for a probability of detection of 91.5 percent using the ATR fusion technique, we have improved our false alarm rates by approximately 17 percent over using texture classification.	Def Sci & Technol Org, Land Operat Div, Salisbury, SA 5108, Australia; Univ S Australia, Knowledge Based Intelligent Engn Syst Ctr, Mawson Lakes, SA 5095, Australia; Def Sci & Technol Org, Weap Syst Div, Salisbury, SA 5108, Australia	Defence Science & Technology; University of South Australia; Defence Science & Technology	Filippidis, A (corresponding author), Def Sci & Technol Org, Land Operat Div, POB 1500, Salisbury, SA 5108, Australia.							ABDULGHAFOUR MB, 1992, THESIS U TENNESSEE K, P41; BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772; Filippidis A, 1999, IEEE T SIGNAL PROCES, V47, P176, DOI 10.1109/78.738250; Goutsias J, 1996, P SOC PHOTO-OPT INS, V2765, P2, DOI 10.1117/12.241222; GYER M, 1988, ETTAR002 SCI APPL IN; HARLICK RM, 1973, IEEE T SYST MAN CYB, V3, P610; Kreithen D.E., 1993, LINCOLN LAB J, V6, P11; OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I; Roth M W, 1990, IEEE Trans Neural Netw, V1, P28, DOI 10.1109/72.80203; SHETTIGARA VK, 1997, P INT WORKSH IAIF 97, P495; STACY N, 1994, INGARA210 DSTO, P1; WHITBREAD P, 1992, THESIS U ADELAIDE S	12	25	28	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					378	384		10.1109/34.845380	http://dx.doi.org/10.1109/34.845380			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT		Green Submitted			2022-12-18	WOS:000087250500007
J	Sivakumar, K; Goutsias, J				Sivakumar, K; Goutsias, J			Morphologically constrained GRFs: Applications to texture synthesis and analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gibbs random fields; mathematical morphology; Metropolis algorithm; Monte Carlo simulation; morphological constraints; size density; statistical inference; texture synthesis and analysis	CARLO MAXIMUM-LIKELIHOOD; BINARY IMAGES; RANDOM-FIELDS; CLASSIFICATION; RESTORATION; REPRESENTATION	A new class of Gibbs random fields (GRFs) is proposed capable of modeling geometrical constraints in images by means of mathematical morphology. The proposed models, known as morphologically constrained GRFs, model images by means of their size density. Since the size density is a multiresolution statistical summary morphologically constrained GRFs explicitly incorporate multiresolution information into image modeling. Important properties are studied and their implication to texture synthesis and analysis is discussed. For morphologically constrained GRFs to be useful in practice, it is important that an efficient technique is available for fitting these models to real data. It is shown that, at low enough temperatures and under a natural condition, the maximum-likelihood estimator of the morphologically constrained GRF parameters can be approximated by means of an important tool of mathematical morphology known as the pattern spectrum. Therefore, statistical inference can he easily implemented by means of mathematical morphology. This allows the design of a, computationally simple morphological Bayes classifier which produces excellent results in classifying natural textures.	Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA; Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA	Washington State University; Johns Hopkins University; Johns Hopkins University	Sivakumar, K (corresponding author), Washington State Univ, Sch Elect Engn & Comp Sci, POB 642752, Pullman, WA 99164 USA.	siva@eecs.wsu.edu; goutsias@mycenae.ece.jhu.edu	Goutsias, John/A-3274-2010					Bickel P.J., 1977, MATH STAT; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; Chen F., 1992, P 26 C INF SCI SYST, P902; CHEN F, 1994, THESIS U MASSACHUSET; CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552; CHEN ZY, 1994, ACTA PHYS SIN-OV ED, V3, P1, DOI 10.1088/1004-423X/3/1/001; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DELFINER P, 1971, J MICROSCOPY, V95, P203; DOUGHERTY ER, 1992, PATTERN RECOGN, V25, P1181, DOI 10.1016/0031-3203(92)90020-J; ELFADEL IM, 1994, IEEE T PATTERN ANAL, V16, P24, DOI 10.1109/34.273719; Ellis R. S., 1985, ENTROPY LARGE DEVIAT; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEYER CJ, 1992, J R STAT SOC B, V54, P657; GEYER CJ, 1994, J ROY STAT SOC B MET, V56, P261; Geyer CJ, 1992, STAT SCI, V7, P473, DOI [10.1214/ss/1177011137, DOI 10.1214/SS/1177011137]; Gidas B., 1995, TOPICS CONT PROBABIL, P159; Gidas B, 1993, MARKOV RANDOM FIELDS, P471; GOUTSIAS J, 1991, IEEE T SIGNAL PROCES, V39, P1369, DOI 10.1109/78.136543; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Heijmans H., 1994, MORPHOLOGICAL IMAGE; Kashyap RL, 1982, PATTERN RECOGN LETT, V1, P43, DOI 10.1016/0167-8655(82)90050-2; KELLY PA, 1993, P IEEE INT C AC SPEE, V5, P49; LEVITAN E, 1995, GRAPH MODEL IM PROC, V57, P117, DOI 10.1006/gmip.1995.1013; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Matheron G., 1975, RANDOM SETS INTEGRAL; SCHONFELD D, 1991, IEEE T PATTERN ANAL, V13, P14, DOI 10.1109/34.67627; Serra J, 1982, IMAGE ANAL MATH MORP; Sivakumar K, 1997, J ELECTRON IMAGING, V6, P31, DOI 10.1117/12.261931; SIVAKUMAR K, 1997, THESIS J HOPKINS U; SIVAKUMAR K, 1997, ADV THEORY APPL RAND, P49; SIVAKUMAR K, 1998, P IEEE INT C IM PROC; Van Lieshout MNM, 1998, COMP IMAG VIS, V12, P291; VANLIESHOUT MNM, 1997, PNAR9715 CWI; ZHOU ZH, 1992, CIRC SYST SIGNAL PR, V11, P253, DOI 10.1007/BF01189229; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	38	25	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					99	113		10.1109/34.748817	http://dx.doi.org/10.1109/34.748817			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL					2022-12-18	WOS:000078639900001
J	Thai, B; Healey, G				Thai, B; Healey, G			Modeling and classifying symmetries using a multiscale opponent color representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symmetry; Gabor filter; opponent; multiscale; color; texture; recognition; opponent color; image retrieval	ILLUMINATION-INVARIANT RECOGNITION; COMPLEX MOMENTS; SEGMENTATION; TEXTURE; IMAGES	A new class of multiscale symmetry features provides a useful high-level representation for color texture. These symmetry features are defined within and between the bands of a color image using complex moments computed from the output of a bank of orientation and scale selective filters. We show that these features not only represent symmetry information but are also invariant to rotation, scale, and illumination conditions. The features computed between color bands are motivated by opponent process mechanisms in human vision. Experimental results are provided to show the performance of this set of features for texture classification and retrieval.	Univ Calif Irvine, Comp Vis Lab, Irvine, CA 92697 USA	University of California System; University of California Irvine	Thai, B (corresponding author), Univ Calif Irvine, Comp Vis Lab, Irvine, CA 92697 USA.	bthai@ece.uci.edu; healey@ece.uci.edu						ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714; BIGUN J, 1995, J VIS COMMUN IMAGE R, V6, P154, DOI 10.1006/jvci.1995.1014; FINLAYSON G, 1996, P 4 EUR C COMP VIS C, P16; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; FREEMAN MO, 1988, J OPT SOC AM A, V5, P1073, DOI 10.1364/JOSAA.5.001073; GAGALOWICZ A, 1986, P INT C PATT REC PAR, P412; Goldstein E.-B., 1996, SENSATION PERCEPTION; Healey G, 1997, IEEE T IMAGE PROCESS, V6, P1002, DOI 10.1109/83.597275; HEALEY G, 1995, J OPT SOC AM A, V12, P1877, DOI 10.1364/JOSAA.12.001877; HEALEY G, 1997, HDB PATTERN RECOGNIT; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; HEALEY GE, 1992, PHYSICS BASED VISION; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HURVICH LM, 1957, PSYCHOL REV, V64, P384, DOI 10.1037/h0041403; Jain A, 1998, IEEE T IMAGE PROCESS, V7, P124, DOI 10.1109/83.650858; KONDEPUDY R, 1994, J OPT SOC AM A, V11, P3037, DOI 10.1364/JOSAA.11.003037; Masland RH, 1996, SCIENCE, V271, P616, DOI 10.1126/science.271.5249.616; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; SCHARCANSKI J, 1992, VISUAL COMM IMAGE PR, P156; Slater D, 1996, IEEE T PATTERN ANAL, V18, P206, DOI 10.1109/34.481544; Slater D, 1998, J OPT SOC AM A, V15, P1068, DOI 10.1364/JOSAA.15.001068; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996; WIESEL TN, 1966, J NEUROPHYSIOL, V29, P1115, DOI 10.1152/jn.1966.29.6.1115	25	25	27	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1224	1235		10.1109/34.730556	http://dx.doi.org/10.1109/34.730556			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100008
J	Wong, PK; Chan, CK				Wong, PK; Chan, CK			Off-line handwritten Chinese character recognition as a compound Bayes decision problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						off-line handwritten Chinese character recognition; Chinese language modeling; compound Bayes decision; contextual vector quantization; Chinese word segmentation		A handwritten Chinese character off-line recognizer based on Contextual Vector Quantization (CVQ) of every pixel of an unknown character image has been constructed. Each template character is represented by a codebook. When an unknown image is matched against a template character, each pixel of the image is quantized according to the associated codebook by considering not just the feature vector observed at each pixel, but those observed at its neighbors and their quantizations as well. Structural information such as stroke counts observed at each pixel are captured to form a cellular feature vector. Supporting a vocabulary of 4,616 simplified Chinese characters and alphanumeric and punctuation symbols, the writer-independent recognizer has an average recognition rate of 77.2 percent. Three statistical language models for postprocessing have been studied for their effectiveness in upgrading the recognition rate of the system. Among them. the CVQ-based language model is the most effective one upgrading the recognition rate by 10.4 percent on the average.	Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam Rd, Hong Kong, Peoples R China	University of Hong Kong	Wong, PK (corresponding author), Univ Hong Kong, Dept Comp Sci & Informat Syst, Pokfulam Rd, Hong Kong, Peoples R China.	pkwong@csis.hku.hk; cchan@csis.hku.hk						AGAZZI OE, 1993, P ICASSP 93, pV113; ARUMUGAM A, 1994, THINNING METHODOLOGI, P23; *BEIJ I LING, 1986, XIAND HAN PINL CID, P1300; BESAG J, 1986, J R STAT SOC B, V48, P259; DEVORE JL, 1991, PROBABILITY STAT ENG, P272; Eckert W, 1996, INT CONF ACOUST SPEE, P423, DOI 10.1109/ICASSP.1996.541123; HASLETT J, 1985, PATTERN RECOGN, V18, P287, DOI 10.1016/0031-3203(85)90054-8; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; HUO QA, 1995, PATTERN RECOGN, V28, P513, DOI 10.1016/0031-3203(94)00117-5; *I INF SCI AC SIN, 1993, 9305 CHIN KNOWL INF; KITTLESEN GP, 1985, J MOL ELECTRON, V2, P23; KUO S, 1993, P ICASSP93, pV81; Liu Yuan, 1994, WORD SEGMENTATION RU, P36; Lu S.Y., 1980, P ICCS80, P935; Lua K. T., 1990, Computer Processing of Chinese & Oriental Languages, V4, P304; SUCHENWIRTH R, 1989, OPTICAL RECOGNITION, P61; SUZUKI S, 1986, P 8 INT C PATT REC, P289; TAI JW, 1984, P ICPR84, P374; Tsui H. T., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P786; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2; Zhang XH, 1983, PATTERN RECOGN LETT, V1, P259, DOI 10.1016/0167-8655(83)90035-1	22	25	27	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					1016	1023		10.1109/34.713366	http://dx.doi.org/10.1109/34.713366			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500009
J	Solka, JL; Marchette, DJ; Wallet, BC; Irwin, VL; Rogers, GW				Solka, JL; Marchette, DJ; Wallet, BC; Irwin, VL; Rogers, GW			Identification of man-made regions in unmanned aerial vehicle imagery and videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						region of interest identification; unmanned aerial vehicle; video processing	ADAPTIVE MIXTURES; COMPUTATION	This paper details recent work in our group on the use of low-level features for the identification of man-made regions in unmanned aerial vehicle (UAV) imagery. The feature sets that we have examined include classical statistical features such as the coefficient of variation in a window about a pixel, locally computed fractal dimension, and fractal dimension computed in the presence of wavelet boundaries. We will discuss these techniques of feature extraction along with our approach to the classification of the features. Our classification work has focused on the use of a new semiparametric probability density estimation technique. In addition, we will present classification results for region of interest identification based on a Set of test images from a recent UAV test flight.	USN, Ctr Surface Warfare, Adv Computat Technol Grp, Dahlgren Div, Dahlgren, VA 22448 USA	United States Department of Defense; United States Navy	Solka, JL (corresponding author), USN, Ctr Surface Warfare, Adv Computat Technol Grp, Dahlgren Div, Code B10,17320 Dahlgren Rd, Dahlgren, VA 22448 USA.	jsolka@nswc.navy.mil		Marchette, David/0000-0002-2732-0392				DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; MARCHETTE DJ, 1997, IN PRESS COMPUTATION; PELI T, 1990, J OPT SOC AM A, V7, P1101, DOI 10.1364/JOSAA.7.001101; PRIEBE CE, 1993, P SOC PHOTO-OPT INS, V1962, P196, DOI 10.1117/12.150588; PRIEBE CE, 1991, PATTERN RECOGN, V24, P1197, DOI 10.1016/0031-3203(91)90145-U; PRIEBE CE, 1997, 574 J HOPK U DEP MAT; PRIEBE CE, 1994, J AM STAT ASSOC, V89, P796; PRIEBE CE, 1993, PATTERN RECOGNITION, V26; ROGERS GW, 1992, OPT ENG, V31, P1886, DOI 10.1117/12.59981; ROGERS GW, 1994, P SUMM COMP, P223; ROGERS GW, 1995, SIMULATION, V65, P26, DOI 10.1177/003754979506500104; SOLKA JL, 1995, J COMPUTATIONAL GRAP, V4, P180; SOLKA JL, 1997, P 28 S INT; Titterington DM, 1985, STAT ANAL FINITE MIX; Wallet BC, 1996, P 28 S INT, P545	15	25	34	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					852	857		10.1109/34.709607	http://dx.doi.org/10.1109/34.709607			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700008
J	Fdez-Valdivia, J; Garcia, JA; Martinez-Baena, J; Fdez-Vidal, XR				Fdez-Valdivia, J; Garcia, JA; Martinez-Baena, J; Fdez-Vidal, XR			The selection of natural scales in 2D images using adaptive gabor filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						natural scale selection; data-driven multichannel scheme; activated sensors; complex 2D Gabor filters	SPATIAL-FREQUENCY; ORIENTATION; CORTEX; CELLS; MODEL	This paper analyzes how the natural scales of the shapes in 2D images can be extracted. Spatial information is analyzed by multiple units sensitive to both spatial and spatial-frequency variables. Scale estimates of the relevant shapes are constructed only from strongly responding detectors. The meaningful structures in the response of a detector (computed through 2D Gabor filtering) are, at their natural level of resolution, relatively sharp and have well-defined boundaries. A natural scale is so defined as a level sigma producing local minimum of a function that returns the relative sharpness of the detector response filtered over a range of scales. In a second stage, to improve a first crude estimate of the local scale, the criterion is also rewritten to directly select scales at locations of significant features of each activated detector.	Univ Granada, ETS Ingn Informat, Dept Ciencias Computac, E-18071 Granada, Spain; Univ Santiago de Compostela, Fac Fis, Dept Fis Aplicada, Santiago De Compostela 15706, Spain	University of Granada; University of Sevilla; Universidade de Santiago de Compostela	Fdez-Valdivia, J (corresponding author), Univ Granada, ETS Ingn Informat, Dept Ciencias Computac, E-18071 Granada, Spain.	J.Fdez-Valdivia@decsai.ugr.es; jags@decsai.ugr.es; jbaena@decsai.ugr.es; faxose@uscmail.usc.es	Fdez-Vidal, Xose R./L-5740-2014; Fdez-Valdivia, J/B-1844-2012; Martinez Baena, Javier/E-1002-2012; Garcia, Jose A./C-1703-2010	Fdez-Vidal, Xose R./0000-0001-9388-7461; Fdez-Valdivia, J/0000-0001-7181-1554; Garcia, Jose A./0000-0001-7742-7270				DASTOUS F, 1983, THESIS U WATERLOO ON; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1984, VISION RES, V24, P891, DOI 10.1016/0042-6989(84)90065-8; DEVALOIS RL, 1982, VISION RES, V22, P531, DOI 10.1016/0042-6989(82)90112-2; Fdez-Vidal XR, 1998, PATTERN RECOGN LETT, V19, P77, DOI 10.1016/S0167-8655(97)00150-5; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; GARCIA JA, 1995, PATTERN RECOGN LETT, V16, P637, DOI 10.1016/0167-8655(95)80009-I; Graham N. V. S., 1989, OXFORD PSYCHOL SERIE, V16; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JERNIGAN ME, 1984, IEEE T PATTERN ANAL, V6, P237, DOI 10.1109/TPAMI.1984.4767507; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; MARTINEZBAENA J, 1998, PATTERN RECOGNITION, V31; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; NAVARRO R, 1995, ADV IMAGING ELECT PH; Rao C. R, 1973, LINEAR STAT INFERENC; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478; WATSON AB, 1987, J OPT SOC AM A, V4, P2401, DOI 10.1364/JOSAA.4.002401	18	25	31	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					458	469		10.1109/34.682176	http://dx.doi.org/10.1109/34.682176			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600002
J	Zingaretti, P; Gasparroni, M; Vecci, L				Zingaretti, P; Gasparroni, M; Vecci, L			Fast chain coding of region boundaries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						boundary representations; chain coding; run-length coding; multivalued images; image coding; image processing; shape analysis		A fast single-pass algorithm to convert a multivalued image from a raster-based representation into chain codes is presented. Ail chain codes are obtained in linear time with respect to the number of chain segments that are generated at each raster according to a set of templates. A formal statement and the complexity and performance analysis of the algorithm are given.	Univ Ancona, Ist Informat, I-60131 Ancona, Italy	Marche Polytechnic University	Zingaretti, P (corresponding author), Univ Ancona, Ist Informat, I-60131 Ancona, Italy.	zinga@inform.unian.it	Zingaretti, Primo/B-1678-2012	Zingaretti, Primo/0000-0002-5709-2159				CEDERBERG LT, 1979, COMPUTER GRAPHICS IM, P224; CHAKRAVARTY I, 1981, COMPUTING GRAPHICS I, P182; CHEN JH, 1994, RES COMMUN SUBSTANCE, V15, P113; FISCHLER MA, 1993, IEEE T PATTERN ANAL, V16, P69; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; KIM SD, 1988, COMPUTER VISION GRAP, P114; KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184; MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387; Morrin T., 1976, COMPUT GRAPHICS IMAG, V5, P172; NICOL CJ, 1995, COMPUT VIS IMAGE UND, V61, P17, DOI 10.1006/cviu.1995.1002; PAVLIDIS T, 1978, IEEE T SYST MAN CYB, V8, P66; Rosenfeld A., 1982, DIGITAL IMAGE PROCES; ROSENFELD A, 1978, COMPUTER GRAPHICS, P135; Samet H., 1990, DESIGN ANAL SPATIAL, V85; SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3	15	25	29	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					407	415		10.1109/34.677272	http://dx.doi.org/10.1109/34.677272			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200007
J	KamgarParsi, B; KamgarParsi, B				KamgarParsi, B; KamgarParsi, B			Matching sets of 3D line segments with application to polygonal arc matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve matching; polygonal arcs; 3D registration; segment matching; 3D arcs	REGISTRATION; CURVES	In this paper, we consider two sets of corresponding 3D line segments of equal length. We derive a closed-form solution for the coordinate transform (rotation and translation) that gives the best match between the two sets; best in the sense of a least squares distance measure between the sets. We use these results as the basis to construct efficient algorithms for solving other problems in computer vision. Specifically, we address the problem of matching polygonal arcs, that is, the problem of finding a match between a short are and a piece of a long arc.	USN, RES LAB, NAVY CTR APPL RES ARTIFICIAL INTELLIGENCE, WASHINGTON, DC 20375 USA	United States Department of Defense; United States Navy; Naval Research Laboratory	KamgarParsi, B (corresponding author), USN, RES LAB, DIV INFORMAT TECHNOL, WASHINGTON, DC 20375 USA.							Abramowitz M., 1972, HDB MATH FUNCTIONS F, P17; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BALLARD DH, 1983, IEEE T PATTERN ANAL, V5, P653, DOI 10.1109/TPAMI.1983.4767456; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CHEN HH, 1990, IEEE T PATTERN ANAL, V12, P1002, DOI 10.1109/34.58872; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; GRIMSON WEL, 1990, OBJECT RECOGNITION C, pCH5; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; JOHNSON B, 1993, P IEEE OC 93 C VICT, V3, P444; KAMGARPARSI B, 1991, IEEE T PATTERN ANAL, V13, P857, DOI 10.1109/34.93805; KAMGARPARSI B, 1991, CVGIP-IMAG UNDERSTAN, V53, P227, DOI 10.1016/1049-9660(91)90030-S; KAMGARPARSI B, 1995, AIT956007 NAV RES LA; KOCH MW, 1989, PATTERN RECOGN LETT, V10, P297, DOI 10.1016/0167-8655(89)90032-9; Marr D, 1978, COMPUTER VISION SYST; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, P281; RAY BK, 1992, PATTERN RECOGN LETT, V13, P489, DOI 10.1016/0167-8655(92)90066-9; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Tanaka H. T., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P491; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	21	25	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1090	1099		10.1109/34.625109	http://dx.doi.org/10.1109/34.625109			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678		Green Submitted			2022-12-18	WOS:A1997YB67800005
J	vanEngelen, RA				vanEngelen, RA			Approximating Bayesian belief networks by arc removal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian belief networks; belief network approximation; model simplification; approximate probabilistic inference; information theory	PROBABILISTIC INFERENCE	I propose a general framework for approximating Bayesian belief networks through model simplification by are removal. Given an upper bound on the absolute error allowed on the prior and posterior probability distributions of the approximated network, a subset of arcs is removed, thereby speeding up probabilistic inference.			vanEngelen, RA (corresponding author), LEIDEN UNIV,DEPT COMP SCI,POB 9512,NL-2300 RA LEIDEN,NETHERLANDS.							ANDREASSEN S, 1987, 10TH P INT JOINT C A, P366; BRUZA PD, 1994, INT J EXPERT SYST, V7, P107; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cousins S B, 1993, Artif Intell Med, V5, P315, DOI 10.1016/0933-3657(93)90020-4; GEIGER D, 1989, R130 U CAL COMP SCI; JENSEN F, 1990, P 6 WORKSH UNC ART I; Jensen F. V., 1990, Computational Statistics Quarterly, V5, P269; JENSEN FV, 1990, R9039 U AALB; Kanal, 1988, UNCERTAINTY ARTIFICI, P149, DOI DOI 10.1016/B978-0-444-70396-5.50019-4; KIIVERI H, 1984, J AUST MATH SOC A, V36, P30, DOI 10.1017/S1446788700027312; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KJAERULFF U, 1994, P 10 C UNC ART INT, P374; KULLBACK S, 1967, IEEE T INFORM THEORY, V13, P126, DOI 10.1109/TIT.1967.1053968; KULLBACK S, 1959, INFORMATION THEORY S; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Michalewicz Z, 1994, GENETIC ALGORITHMS P; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Suermondt H. J., 1991, International Journal of Approximate Reasoning, V5, P521, DOI 10.1016/0888-613X(91)90028-K; Suermondt H. J., 1990, International Journal of Approximate Reasoning, V4, P283, DOI 10.1016/0888-613X(90)90003-K; VANENGELEN RA, 1996, TR9615 LEID U DEP CO; WERMUTH N, 1990, J ROY STAT SOC B MET, V52, P21; Whittaker J., 1990, GRAPHICAL MODELS APP	23	25	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					916	920		10.1109/34.608295	http://dx.doi.org/10.1109/34.608295			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700011
J	Reinhardt, JM; Higgins, WE				Reinhardt, JM; Higgins, WE			Comparison between the morphological skeleton and morphological shape decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; shape representation; morphological skeleton; morphological shape decomposition; image analysis; computer vision; shape analysis	BINARY IMAGES; REPRESENTATION	The morphological skeleton and morphological shape decomposition (MSD) are two popular approaches for morphological shape representation. Each method represents an object as an algebraic combination of a number of components, where each component is given by a locus of points dilated by a specified structuring-element homothetic. This correspondence develops a theoretical comparison between the two methods. Combining the theoretical results with several representation cost measures, we make a concrete comparison of the efficiency of the two methods. The results indicate that for complex objects-i.e., objects requiring a full range of homothetic sizes in the morphological skeleton representation-the MSD represents objects more efficiently than the morphological skeleton for three of four suggested cost measures.	PENN STATE UNIV,DEPT ELECT ENGN,UNIVERSITY PK,PA 16802	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Reinhardt, JM (corresponding author), UNIV IOWA,COLL MED,DEPT RADIOL,DIV PHYSIOL IMAGING,IOWA CITY,IA 52242, USA.			Reinhardt, Joseph/0000-0003-3526-3591				GOUTSIAS J, 1991, IEEE T SIGNAL PROCES, V39, P1369, DOI 10.1109/78.136543; KIMOTO T, 1992, P SOC PHOTO-OPT INS, V1818, P897, DOI 10.1117/12.131502; KISACANIN B, 1994, IEEE T IMAGE PROCESS, V3, P455, DOI 10.1109/83.298399; KRESCH R, 1994, SIGNAL PROCESS, V38, P143, DOI 10.1016/0165-1684(94)90062-0; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; PAI TW, 1994, IEEE T PATTERN ANAL, V16, P201, DOI 10.1109/34.273731; PITAS I, 1992, PATTERN RECOGN, V25, P555, DOI 10.1016/0031-3203(92)90073-R; PITAS I, 1990, IEEE T PATTERN ANAL, V12, P38, DOI 10.1109/34.41382; Reinhardt JM, 1996, IEEE T IMAGE PROCESS, V5, P89, DOI 10.1109/83.481673; REINHARDT JM, 1993, P SOC PHOTO-OPT INS, V2094, P1424, DOI 10.1117/12.157901; REINHARDT JM, 1995, ENGTR9631 PENNS STAT; REINHARDT WE, 1994, P IEEE INT C IM PROC, V1, P91; RICHARDSON CH, 1990, P IEEE INT C AC SPEE, P2173; SHOJI K, 1992, P SOC PHOTO-OPT INS, V1769, P404, DOI 10.1117/12.60660; VANDENBOOMGAARD R, 1992, CVGIP-GRAPH MODEL IM, V54, P252, DOI 10.1016/1049-9652(92)90055-3	16	25	25	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					951	957		10.1109/34.537351	http://dx.doi.org/10.1109/34.537351			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900011
J	Seni, G; Srihari, RK; Nasrabadi, N				Seni, G; Srihari, RK; Nasrabadi, N			Large vocabulary recognition of on-line handwritten cursive words	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten text recognition; on-line cursive handwriting recognition; neural network applications; pen-based systems; document processing	NETWORKS; ONLINE	This paper presents a writer independent system for large vocabulary recognition of on-line handwritten cursive words. The system first uses a filtering module, based on simple letter features, to quickly reduce a large reference dictionary (lexicon) to a more manageable size; the reduced lexicon is subsequently fed to a recognition module. The recognition module uses a temporal representation of the input, instead of a static two-dimensional image, thereby preserving the sequential nature of the data and enabling the use of a Time-Delay Neural Network (TDNN); such networks have been previously successful in the continuous speech recognition domain. Explicit segmentation of the input words into characters is avoided by sequentially presenting the input word representation to the neural network-based recognizer. The outputs of the recognition module are collected and converted into a string of characters that is matched against the reduced lexicon using an extended Damerau-Levenshtein function. Trained on 2,443 unconstrained word images (11 k characters) from 55 writers and using a 21 k lexicon we reached a 97.9% and 82.4% top-5 word recognition rate on a writer-dependent and writer-independent test, respectively.	CEDAR,AMHERST,NY 14228; SUNY BUFFALO,DEPT COMP & ELECT ENGN,BUFFALO,NY 14260	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Seni, G (corresponding author), MOTOROLA INC,LEXICUS DIV,490 CALIFORNIA AVE,SUITE 300,PALO ALTO,CA 94306, USA.							BABCOCK MK, 1988, AM J PSYCHOL, V101, P111, DOI 10.2307/1422797; BENGIO Y, 1993, INT J PATTERN RECOGN, V7, P3; BROCKLEHURST ER, 1988, 13288 NPL DITC; ELLITOO D, 1993, TR938 U MAR I SYST R; FAHLMAN S, 1988, CMUCSDD88162; FUJISAKI T, 1992, PIXELS FEATURES, V3; GUERFALI W, 1993, PATTERN RECOGN, V26, P419, DOI 10.1016/0031-3203(93)90169-W; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; HAKIM N, 1992, IJCNN IEEE; HUANG W, 1987, P 1 IEEE C NEUR NETW; LeCun Y., 1989, CONNECTIONISM PERSPE; MORASSO P, 1993, PATTERN RECOGN, V26, P451, DOI 10.1016/0031-3203(93)90172-S; OHMORI K, 1993, IWFHR 3; RUMELHART DE, 1986, LEARNING INTERNAL RE, V1, P318; SCHENKEL M, 1993, ADV NEURAL INFORMATI, V5; SCHOMAKER L, 1993, PATTERN RECOGN, V26, P443, DOI 10.1016/0031-3203(93)90171-R; SENI G, 1995, P SPIE IS T C DOC RE; SENI G, 1994, IWFHR, V4; SINGER Y, 1993, CS934 HEBR U JER I C; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701	20	25	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					757	762		10.1109/34.506798	http://dx.doi.org/10.1109/34.506798			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700008
J	Gross, AD; Boult, TE				Gross, AD; Boult, TE			Recovery of SHGCs from a single intensity view	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; shape recovery; generalized cylinders; shape from shading; shape from contour	SHAPE	Generalized Cylinders are a flexible, loosely-defined class of parametric shapes capable of modeling many real-world objects. Straight Homogeneous Generalized Cylinders are an important subclass of Generalized Cylinders, whose cross-sections are scaled versions of a reference curve. Although there has been considerable research into recovering the shape of SHGCs from their contour, this work has almost exclusively involved methods that couple contour and heuristic constraints. A rigorous approach to the problem of recovering solid parametric shape from a single intensity View should involve at least two stages: 1) deriving the contour constraints, and 2) determining if additional image constraints, e.g., intensity, can be used to uniquely determine the 3D object shape. In this paper, the authors follow the approach just described. This methodology is also important for the recovery of object classes like tubes, where contour and heuristic constraints are shown to be insufficient for shape recovery. First, we prove that SHGC contours generated under orthography have exactly two degrees of freedom. Next, we show that the remaining free parameters can be resolved using reflectance-based constraints, without knowledge of the number of light sources, their positions, intensities, the amount of ambient light, or the surface albedo. Finally, the reflectance-based recovery algorithm is demonstrated on both synthetic and real SHGC images.	LEHIGH UNIV,DEPT ELECT & COMP ENGN,ALLENTOWN,PA 18015	Lehigh University	Gross, AD (corresponding author), CUNY,UNIV GRAD CTR & QUEENS COLL,DEPT COMP SCI,65-30 KISSENA BLVD,FLUSHING,NY 11367, USA.		Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529				ASADA M, 1987, P 1 ICCV JUN, P412; ASADA M, 1993, P CVPR; ASADA M, P 1992 CVPR; Berthold KP Horn, 1970, SHAPE SHADING METHOD, P1; BINFORD TO, 1971, P IEEE C SYST CONTR; BRADY JM, 1985, P 2 INT S ROB RES; BRADY JM, 1983, MIT AIM 711 AI LAB; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BUITUONG P, 1975, COMMUN ACM, V18, P311; CHELBERG DM, 1989, THESIS STANFORD U; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; Gross A. D., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P790, DOI 10.1109/ROBOT.1990.126084; Gross A.D., 1994, P SPIE C INT ROB COM; GROSS AD, 1994, IEEE T PATTERN ANAL, V16, P794, DOI 10.1109/34.308474; GROSS AD, 1989 SPIE P VIS COMM, V4, P1661; HORAUD R, 1987, P 1 ICCV LOND JUN; HORN BKP, 1981, P IEEE, V69, P14, DOI 10.1109/PROC.1981.11918; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Koenderink J., 1990, SOLID SHAPE; Lavest J. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P690, DOI 10.1109/CVPR.1991.139784; LEE CH, 1989, SHAPE SHADING, P323; MARR D, 1977, PROC R SOC SER B-BIO, V197, P441, DOI 10.1098/rspb.1977.0080; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; OREN M, 1992, CUCS05792 COL U DEP; PENTLAND AP, 1994, IEEE T PATTERN ANAL, V16, P170; Ponce J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P327, DOI 10.1109/CVPR.1988.196256; PONCE J, 1987, P 1 ICCV LOND JUN; PONCE J, 1989, IEEE T PATTERN ANAL, V11; Ramachandran V. S., 1988, Scientific American, V259, P58, DOI 10.1038/scientificamerican0888-76; Rao K., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P256; RICHETIN M, 1989, P 1989 CVPR SAN DIEG; SHAFER S, 1983, CS083105 C MELL U; SINGH H, 1994, CARTR700; ULPUINAR F, 1995, IEEE T PATTERN ANAL, V17, P120; ULUPINAR F, 1988, P INT C COMPUTER VIS, P414; ZERROUG M, 1993, P DARPA IM UND WORKS, P725; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	38	25	25	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					161	180		10.1109/34.481541	http://dx.doi.org/10.1109/34.481541			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900007
J	KEREN, D				KEREN, D			USING SYMBOLIC COMPUTATION TO FIND ALGEBRAIC INVARIANTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter							IMAGE	Implicit polynomials have proved themselves as having excellent representation power for complicated objects, and there is growing use of them in computer vision, graphics, and CAD. A must for every system that tries to recognize objects based on their representation by implicit polynomials are invariants, which are quantities assigned to polynomials that do not change under coordinate transformations. In the recognition system developed at the Laboratory for Engineering Man-Machine Studies in Brown University (LEMS), it became necessary to use invariants which are explicit and simple functions of the polynomial coefficients. A method to find such invariants is described and the new invariants presented. This work addresses only the problem of finding the invariants; their stability is studied in another paper.			KEREN, D (corresponding author), BROWN UNIV,DIV ENGN,ENGN MAN MACHINE SYST LAB,PROVIDENCE,RI 02912, USA.							FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Grace John Hilton, 1903, ALGEBRA INVARIANTS; JERIAN C, 1990, IEEE T PATTERN ANAL, V12, P1150, DOI 10.1109/34.62604; KEREN D, 1991, IN PRESS IEEE T PATT; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; MUNDY J, 1993, C APPLICATIONS INVAR, V2; Mundy J., 1992, GEOMETRIC INVARIANCE; SUBRAHMONIA J, 1992, UNPUB IEEE T PATTERN; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; WEISS L, 1993, IJCV, V10, P201; Wolfram S., 1988, MATH SYSTEM DOING MA	11	25	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1143	1149		10.1109/34.334397	http://dx.doi.org/10.1109/34.334397			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100011
J	LAI, CP; KASTURI, R				LAI, CP; KASTURI, R			DETECTION OF DIMENSION SETS IN ENGINEERING DRAWINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						DOCUMENT IMAGE ANALYSIS; ENGINEERING DRAWINGS; GRAPHICS RECOGNITION; IMAGE PROCESSING; PATTERN RECOGNITION; TEXT SEGMENTATION		This correspondence presents a system for detecting dimension sets in engineering drawings that are drawn to ANSI drafting standards. A new rule-based text/graphics separation algorithm and a model-based procedure for detecting arrowheads in any orientation have been developed. Arrowhead tracking and search methods are used to extract leaders, tails, and witness lines from segmented images containing only graphics. Text blocks and feature control frames extracted from the segmented images are then associated with their corresponding leaders to obtain complete dimension sets. Experimental results are presented.	PENN STATE UNIV,DEPT ELECT & COMP ENGN,COMP ENGN PROGRAM,UNIVERSITY PK,PA 16802	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park								[Anonymous], STRUCTURED DOCUMENT; Dori D., 1993, Machine Vision and Applications, V6, P69, DOI 10.1007/BF01211932; DORI D, 1989, COMPUT VISION GRAPH, V47, P271, DOI 10.1016/0734-189X(89)90114-X; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870; KASTURI R, 1992, COMPUTER, V25; KASTURI R, 1992, MACHINE VISION APPLI, V5; LYSAK DB, 1991, 1ST P INT C DOC AN R, P79; O'Gorman L., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P235, DOI 10.1109/CVPR.1988.196242; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; WESLEY MA, 1981, IBM J RES DEV, V25, P934, DOI 10.1147/rd.256.0934; [No title captured]; 1982, ANSI Y142M ASME; 1982, ANSI Y145 ASME	15	25	41	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					848	855						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500013
J	RAVICHANDRAN, G; CASASENT, D				RAVICHANDRAN, G; CASASENT, D			ADVANCED INPLANE ROTATION-INVARIANT CORRELATION FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CIRCULAR HARMONIC FUNCTION; DISCRIMINATION; NOISE PERFORMANCE; PATTERN RECOGNITION; ROTATION-INVARIANT FILTERS	CORRELATION-ENERGY FILTERS; RECOGNITION	Advanced correlation filter synthesis algorithms to achieve rotation invariance are described. We use a specified form for the filter as the rotation invariance constraint and derive a general closed-form solution for a multiclass rotation-invariant filter that can recognize a number of different objects. By requiring the filter to minimize the average correlation plane energy, we produce a multiclass rotation invariant (RI) RI-MACE filter, which controls correlation plane sidelobes and improves discrimination against false targets. To improve noise performance, we require the filter to minimize a weighted sum of correlation plane signal and noise energy. Initial test results of all filters are provided.			RAVICHANDRAN, G (corresponding author), CARNEGIE MELLON UNIV,DEPT ELECT & COMP ENGN,CTR EXCELLENCE OPT DATA PROC,PITTSBURGH,PA 15213, USA.							BENYOSEF N, 1985, APPL OPTICS, V24, P2109, DOI 10.1364/AO.24.002109; BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; CAMPOS J, 1988, P SOC PHOTO-OPT INST, V963, P298; CASASENT D, 1984, APPL OPTICS, V23, P1620, DOI 10.1364/AO.23.001620; CASASENT D, 1991, APPL OPTICS, V30, P5169, DOI 10.1364/AO.30.005169; DANIELSSON PE, 1985, COMPUT VISION PA JUN, P155; FLANNERY DL, 1989, P IEEE, V77, P1511, DOI 10.1109/5.40666; HSU YN, 1982, APPL OPTICS, V21, P4016, DOI 10.1364/AO.21.004016; MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633; MCWILLIAMS JK, 1984, IEEE T AERO ELEC SYS, V20, P38, DOI 10.1109/TAES.1984.310491; MINOR LG, 1981, IEEE T SYST MAN CYB, V11, P216; OCHOA E, 1988, OPT ENG, V27, P266, DOI 10.1117/12.7976669; RAVICHANDRAN G, 1992, APPL OPTICS, V31, P1823, DOI 10.1364/AO.31.001823; RAVICHANDRAN G, 1991, OPT ENG, V30, P1601, DOI 10.1117/12.55953	15	25	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					415	420		10.1109/34.277595	http://dx.doi.org/10.1109/34.277595			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700008
J	GARDING, J				GARDING, J			DIRECT ESTIMATION OF SHAPE FROM TEXTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						SHAPE FROM TEXTURE; SURFACE ORIENTATION; FORESHORTENING; ISOTROPY; DISTRIBUTIONS ON THE CIRCLE; MAXIMUM LIKELIHOOD; METHOD OF MOMENTS	ORIENTATION	Witkin has proposed a maximum likelihood (ML) estimator of surface orientation based on the observed directional bias of projected texture elements. However, a drawback of this procedure is that the estimate is only defined indirectly in terms of a set of nonlinear equations. An alternative method is proposed, which allows an estimate of the surface orientation to be computed directly in a single step from certain simple statistics of the image data. We also show that this direct estimate allows Witkin's ML estimate to be computed to within 0.05-degrees in only two or three iterative steps. The performance of the new estimator is demonstrated experimentally and compared to that of the ML estimator, using both synthetic data and real gray-level images.			GARDING, J (corresponding author), ROYAL INST TECHNOL,DEPT NUMER ANAL & COMP SCI,COMP VIS & ACT PERCEPT LAB,S-10044 STOCKHOLM 70,SWEDEN.							BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; Dahlquist G., 1974, NUMERICAL METHODS; DAVIS L, 1982, TR1133 U MAR COMP VI; DAVIS LS, 1983, IEEE T PATTERN ANAL, V5, P485, DOI 10.1109/TPAMI.1983.4767427; Garding J., 1992, Journal of Mathematical Imaging and Vision, V2, P327, DOI 10.1007/BF00121877; GARDING J, 1991, THESIS ROYAL I TECHN; GARDING J, 1993, J ARTIFICIAL INTELL, V64, P243; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; KANATANI K, 1984, ARTIF INTELL, V23, P213, DOI 10.1016/0004-3702(84)90010-9; MARDIA KV, 1972, STATISTICS DIRECTION; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	12	25	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1993	15	11					1202	1208		10.1109/34.244682	http://dx.doi.org/10.1109/34.244682			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MH083					2022-12-18	WOS:A1993MH08300010
J	BLAKE, A; MCCOWEN, D; LO, HR; LINDSEY, PJ				BLAKE, A; MCCOWEN, D; LO, HR; LINDSEY, PJ			TRINOCULAR ACTIVE RANGE-SENSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACTIVE SENSOR; CORRESPONDENCE PROBLEM; RANGE SENSOR; TRINOCULAR STEREO	VISION; METROLOGY	The principle of trinocular stereo is well known in the domain of passive devices and has application in active metrology as well. Trinocular active devices have the advantage of freedom from mechanical scanning and rapid image capture compared with more conventional active designs based on scanning laser stripes. Their efficient operation relies, however, on a good solution to the correspondence problem. This requires careful geometric design to take account of epipolar geometry and thorough modeling of image-measurement error. We present a novel design that, curiously, involves setting up the projector-camera geometry to be degenerate-so that depth computation is ill-conditioned-and then backing off a little. We call this near-degenerate epipolar alignment. The result is that unambiguous stereo matching can, in principle, be guaranteed within a given working volume. This is in marked contrast with passive stereo in which ambiguity cannot be guaranteed, merely minimized statistically. The principles have proved to work well in laboratory tests, achieving unambiguous operation over a working volume of a 50-mm cube with a depth resolution of around 0.2 mm.			BLAKE, A (corresponding author), UNIV OXFORD,DEPT ENGN SCI,OXFORD,ENGLAND.							ALTSCHULER MD, 1981, OPT ENG, V20, P953, DOI 10.1117/12.7972842; ALTSCHULER MD, 1987, 3 DIMENSIONAL MACHIN, P97; BASTUSCHECK CM, 1984, 28 NEW YORK U ROB RE; BASTUSCHECK CM, 1989, IEEE P CVPR, P262; Besl P. J., 1988, Machine Vision and Applications, V1, P127, DOI 10.1007/BF01212277; BLAKE A, 1990, P BRIT MACHINE VISIO, P19; BLAKE A, 1991, 3 DIMENSIONAL VISION; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASE SK, 1987, 3 DIMENSIONAL MACHIN, P63; HU GZ, 1989, IEEE T PATTERN ANAL, V11, P390, DOI 10.1109/34.19035; Ito M., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P9; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P505, DOI 10.1109/TPAMI.1983.4767429; KREMERS JH, 1981, Patent No. 2104652; MUNDY JL, 1987, 3 DIMENSIONAL MACHIN, P3, DOI DOI 10.1007/978-1-4613-1981-8_1; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; REID GT, 1984, OPT LASER ENG, V5, P63, DOI 10.1016/0143-8166(84)90012-5; SHIRAI Y, 1972, PATTERN RECOGN, V4, P243, DOI 10.1016/0031-3203(72)90003-9; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109	20	25	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					477	483		10.1109/34.211467	http://dx.doi.org/10.1109/34.211467			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000005
J	DAGUM, P; CHAVEZ, RM				DAGUM, P; CHAVEZ, RM			APPROXIMATING PROBABILISTIC INFERENCE IN BAYESIAN BELIEF NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								A belief network comprises a graphical representation of dependencies between variables of a domain and a set of conditional probabilities associated with each dependency. Unless P=NP, an efficient, exact algorithm does not exist to compute probabilistic inference in belief networks. Stochastic simulation methods, which often improve run times, provide an alternative to exact inference algorithms. We present such a stochastic simulation algorithm D-BNRAS that is a randomized approximation scheme. To analyze the run time, we parameterize belief networks by the dependence value D(xi), which is a measure of the cumulative strengths of the belief network dependencies given background evidence xi. This parameterization defines the class of f-dependence networks. The run time of D-BNRAS is polynomial when f is a polynomial function. Thus, the results of this paper prove the existence of a class of belief networks for which inference approximation is polynomial and, hence, provably faster than any exact algorithm.	ROCKWELL INT CORP,PALO ALTO LAB,PALO ALTO,CA	Rockwell Collins	DAGUM, P (corresponding author), STANFORD UNIV,MED CTR,SCH MED,MED INFORMAT SECT,STANFORD,CA 94305, USA.							BERZUINI C, 1989, 1989 P WORKSH UNC AR, P14; BRODER AZ, 1986, 18TH P ACM S THEOR C, P50; CHAVEZ R, 1990, 6TH P C UNC ART INT, P130; CHAVEZ RM, 1990, NETWORKS, V20, P661, DOI 10.1002/net.3230200510; CHAVEZ RM, 1990, THESIS STANFORD U ST; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; DAGUM P, 1991, KSL9151 STANF U KNOW; DAGUM P, 1992, 8TH P C UNC ART INT, P49; DAGUM P, 1991, KSL9167 STANF U KNOW; FUNG R, 1990, UNCERTAINTY ARTIFICI, V5, P209; JERRUM M, 1989, SIAM J COMPUT, V18, P1149, DOI 10.1137/0218077; Kanal, 1988, UNCERTAINTY ARTIFICI, P149, DOI DOI 10.1016/B978-0-444-70396-5.50019-4; KARP RM, 1989, J ALGORITHM, V10, P429, DOI 10.1016/0196-6774(89)90038-2; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; PEARL J, 1987, ARTIF INTELL, V633, P131; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; SHACHTER R, IN PRESS ARTIFICIAL; SHACHTER RD, 1990, UNCERTAINTY ARTIFICI, V5, P221; SINCLAIR A, 1989, INFORM COMPUT, V82, P93, DOI 10.1016/0890-5401(89)90067-9; Valiant L. G., 1979, Theoretical Computer Science, V8, P189, DOI 10.1016/0304-3975(79)90044-6	21	25	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					246	255		10.1109/34.204906	http://dx.doi.org/10.1109/34.204906			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800006
J	HORN, BKP; SZELISKI, RS; YUILLE, AL				HORN, BKP; SZELISKI, RS; YUILLE, AL			IMPOSSIBLE SHADED IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EXISTENCE; IMPOSSIBLE IMAGES; SHAPE FROM SHADING; UNIQUENESS	COMPUTER VISION; SHAPE	In this correspondence, we show that images that could not have arisen from shading on a smooth surface with uniform reflecting properties and lighting exist. Much work has been done on recovering surface shape from images, and there has been some attention paid to the question of uniqueness. It has been shown, for example, that singular points curtail ambiguity. However, little has been said about the existence of solutions, perhaps because in practice, the given image is assumed to have arisen from a uniform, smoothly curved surface, and therefore, one knows that there must be at least one solution. What if, however, the reflecting properties of the surface vary from place to place? What if the actual surface does not reflect light the way one has assumed or that the light source is not where it was thought to be? Will the solution only be warped by these departures from the ideal model, or may there in fact be situations where there is no smooth surface that could have given rise to the given shading pattern? Can the fact that a shaded image of some surface with spatially varying surface reflectance is impossible in this sense be used to detect surface albedo variations?	DIGITAL EQUIPMENT CORP,CAMBRIDGE,MA; HARVARD UNIV,DIV APPL SCI,CAMBRIDGE,MA 02138	Harvard University	HORN, BKP (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.			/0000-0003-3434-391X; Yuille, Alan L./0000-0001-5207-9249				Berthold KP Horn, 1970, SHAPE SHADING METHOD, P1; BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X; BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4; BLAKE A, 1989, SHAPE SHADING; Brooks M., 1983, AUG P NAT C ART INT, P36; BRUSS A, 1989, SHAPE SHADING; BRUSS AR, 1982, J MATH PHYS, V23, P890, DOI 10.1063/1.525441; DEIFT P, 1981, J MATH ANAL APPL, V84, P235, DOI 10.1016/0022-247X(81)90161-X; Hilbert D., 1952, GEOMETRY IMAGINATION; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; HORN BKP, 1986, ROBOT VISION, P202; HORN BKP, 1978, NOV P DARPA IM UND W, P115; HORN BKP, 1991, 9115 HARV ROB LAB TE; HORN BKP, 1987, READINGS COMPUTER VI, P45; HORN BKP, MIT1105 ART INT LAB; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; KOENDERINK JJ, 1989, SHAPE SHADING; OLIENSIS J, 1989, UNPUB EXISTENCE UNIQ; Rindfleisch T., 1966, PHOTOGRAMM ENG, V32, P262; SAXBERG BVH, 1988, THESIS MIT; YUILLE AL, 1989, COMPUT VISION GRAPH, V45, P68, DOI 10.1016/0734-189X(89)90071-6; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	27	25	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					166	170		10.1109/34.192489	http://dx.doi.org/10.1109/34.192489			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000008
J	LINDENBAUM, M; KOPLOWITZ, J				LINDENBAUM, M; KOPLOWITZ, J			A NEW PARAMETERIZATION OF DIGITAL STRAIGHT-LINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CHAIN CODES; DIGITAL STRAIGHT LINES; DISCRETE GEOMETRY; FAREY SERIES; LINE DRAWINGS	ALGORITHM; NUMBER	A 1-1 correspondence is established between digital straight lines which start at a fixed point and a simple set of quadruples of integer parameters. Such a representation by parameters is useful for enumeration. An O(N) algorithm is given for determining the parameters from the digital line, as well as O(log N) algorithms for transforming between these parameters and the parameters suggested by Dorst and Smeulders.	CLARKSON UNIV,DEPT ELECT & COMP ENGN,POTSDAM,NY 13676	Clarkson University	LINDENBAUM, M (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,HAIFA,ISRAEL.							BERENSTEIN CA, 1988, IEEE T PATTERN ANAL, V10, P880, DOI 10.1109/34.9109; BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; HUNG SHY, 1985, IEEE T PATTERN ANAL, V7, P203, DOI 10.1109/TPAMI.1985.4767644; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; Knuth D. E., 1969, ART COMPUTER PROGRAM, V2; KOPLOWITZ J, 1987, IEEE T PATTERN ANAL, V9, P451, DOI 10.1109/TPAMI.1987.4767927; KOPLOWITZ J, 1990, IEEE T INFORM THEORY, V36, P192, DOI 10.1109/18.50392; LINDENBAUM M, 1988, PATTERN RECOGN LETT, V7, P167, DOI 10.1016/0167-8655(88)90061-X; MCILROY MD, 1984, AT&T TECH J, V64, P481; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; ROHNERT H, 1986, INFORM PROCESS LETT, V23, P71, DOI 10.1016/0020-0190(86)90045-1; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; TOUSSAINT GT, 1982, PATTERN RECOGN, V15, P23, DOI 10.1016/0031-3203(82)90057-7; TOUSSAINT GT, 1983, P MELECON83; Wright E., 1979, INTRO THEORY NUMBERS; WU LD, 1982, IEEE T PATTERN ANAL, V4, P347, DOI 10.1109/TPAMI.1982.4767258	18	25	25	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					847	852		10.1109/34.85678	http://dx.doi.org/10.1109/34.85678			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200013
J	UNSER, M; ALDROUBI, A; EDEN, M				UNSER, M; ALDROUBI, A; EDEN, M			RECURSIVE REGULARIZATION FILTERS - DESIGN, PROPERTIES, AND APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						APPROXIMATION METHODS; EDGE DETECTION; GAUSSIAN FILTERING; RECURSIVE FILTERS; REGULARIZATION; SMOOTHING	EDGE-DETECTION; EXTRACTION; VISION	Least squares approximation problems that are regularized with specified highpass stabilizing kernels are considered. For each problem, there is a family of discrete regularization filters (R-filters) allowing an efficient determination of the solutions. These operators are stable symmetric lowpass filters with an adjustable scale factor. Two decomposition theorems for the z-transform of such systems are presented. One facilitates the determination of their impulse response, while the other allows an efficient implementation through successive causal and anticausal recursive filtering. A case of special interest is the design of R-filters for the first and second order difference operators. These results are extended for two-dimensional signals and, for illustration purposes, are applied to the problem of edge detection. This leads to a very efficient implementation (8 multiplies + 10 adds per pixel) of the optimal Canny edge detector based on the use of a separable second order R-filter.	HOP HENRI MONDOR,INSERM,UNITE 2,F-94010 CRETEIL,FRANCE	Assistance Publique Hopitaux Paris (APHP); Universite Paris-Est-Creteil-Val-de-Marne (UPEC); Hopital Universitaire Henri-Mondor - APHP; Institut National de la Sante et de la Recherche Medicale (Inserm)	UNSER, M (corresponding author), NIH,BIOMED & INSTRUMENTAT PROGRAM,BETHESDA,MD 20892, USA.		Unser, Michael/A-1550-2008; Aldroubi, Akram/J-7186-2012					BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; Poggio T., 1988, Journal of Complexity, V4, P106, DOI 10.1016/0885-064X(88)90024-6; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1984, MIT776 ART INT LAB M; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RABINER LR, 1975, THEORY APPLICATION D; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; Tikhonov A., 1977, SOLUTIONS ILL POSED; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; UNSER M, 1990, SIGNAL PROCESS, V20, P3, DOI 10.1016/0165-1684(90)90073-8; UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466; UNSER M, 1989, IEEE T MED IMAGING, V8, P96, DOI 10.1109/42.20367; WELLS WM, 1986, IEEE T PATTERN ANAL, V8, P234, DOI 10.1109/TPAMI.1986.4767776; WITKIN AP, 1983, 4TH P INT JOINT C AR, P1019	23	25	27	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1991	13	3					272	277		10.1109/34.75514	http://dx.doi.org/10.1109/34.75514			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FG360					2022-12-18	WOS:A1991FG36000006
J	GOLDGOF, DB; HUANG, TS; HUA, L				GOLDGOF, DB; HUANG, TS; HUA, L			A CURVATURE-BASED APPROACH TO TERRAIN RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	GOLDGOF, DB (corresponding author), UNIV ILLINOIS,DEPT ELECT ENGN,URBANA,IL 61801, USA.		Goldgof, Dmitry/ABF-1366-2020					ASADA M, 1988, APR P IEEE INT C ROB, P918; BESL PJ, 1984, RSDTR2084 U MICH REP; BESL PJ, 1986, MAY P CVPR; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; CHEN HH, 1986, OCT P ICPR; DAILY M, 1988, APR P IEEE INT C ROB, P718; DAILY M, 1988, MAY P IEEE COMP SOC, P794; FAN TJ, 1986, MAY P CVPR; GOLDGOF DB, 1989, ISP910 U ILL COORD S; GOLDGOF DB, 1988, MAY P IEEE COMP SOC; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HEBERT M, 1985, P DARPA IUW; ONeill B., 1966, ELEMENTARY DIFFERENT; [No title captured]	14	25	29	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1213	1217		10.1109/34.42859	http://dx.doi.org/10.1109/34.42859			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600008
J	CERNUSCHIFRIAS, B; COOPER, DB; HUNG, YP; BELHUMEUR, PN				CERNUSCHIFRIAS, B; COOPER, DB; HUNG, YP; BELHUMEUR, PN			TOWARD A MODEL-BASED BAYESIAN THEORY FOR ESTIMATING AND RECOGNIZING PARAMETERIZED 3-D OBJECTS USING 2 OR MORE IMAGES TAKEN FROM DIFFERENT POSITIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									BROWN UNIV, DIV ENGN, PROVIDENCE, RI 02912 USA	Brown University	CERNUSCHIFRIAS, B (corresponding author), UNIV BUENOS AIRES, FAC INGN, BUENOS AIRES, ARGENTINA.		Cernuschi-Frias, Bruno/G-9177-2012	Cernuschi-Frias, Bruno/0000-0001-5335-9402				ALBERT AE, 1967, STOCHASTC APPROXIMAT; AMBLARD FG, 1986, 5TH P SPIE CAMBRC IN, V726, P36; Ballard D.H., 1982, COMPUTER VISION; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BOLLE RM, 1986, SEP IEEE T PATT AN M, P619; BOLLERM, 1986, DEC P INT AT SYST, P142; BOLLES RC, 1985, DEC P IM UND, P137; Castan S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P444; CERNUSCHIFRIAS B, 1986, LEMS32 BROWN U DIV E; CERNUSCHIFRIAS B, 1985, JUN P IEEE COMP SOC, P167; CERNUSCHIFRIAS B, 1984, THESIS BROWN U; COHEN FS, 1988, JUN P IEEE COMP SOC, P964; COOPER DB, 1985, DIGITAL IMAGE PROCES, V2, P68; COOPER DB, 1981, MAGE MODELING, P63; COOPER DB, 1988, 1988 P INT C COMP VI, P74; DRUMHELLER M, 1986, 1986 P IEEE C ROB AU, P1439; DUDA D, 1973, PATTERN CLASSIFICATI, P381; DUNNINGHAM DR, 1976, IEEE T INFORM THEORY, V22, P603; EASTMAN RD, 1985, CSTR1547 U MAR TECH; FAUGERASOD, 1986, 1986 P IEEE C ROB AU, P1433; HAKALA DG, 1981, SGGRAPH 81 SEMINAL S; Horn B., 1986, ROBOT VISION, P1; HUNG YP, 1988, 1988 IEEE NT C ROB A, P906; HUNG YP, 1986, JAN P JPL CALT WORKS, P71; MILLER WT, 1986, APR P IEEE INTC ROB, P112; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; SILVERMAN JF, 1988, JUL IEEE T PATT AN M, P482; VanTrees H. L, 1968, DETECTION ESTIMATI 1, P74; WAXMAN AM, 1988, ADV COMPUTER VISION, V1, P165; WILKS SS, 1963, MATH STATISTICS, P419	30	25	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1028	1052		10.1109/34.42835	http://dx.doi.org/10.1109/34.42835			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900002
J	CHEN, DS				CHEN, DS			A DATA-DRIVEN INTERMEDIATE LEVEL FEATURE-EXTRACTION ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CHEN, DS (corresponding author), GM CORP,CTR TECH,DEPT ARTIFICIAL INTELLIGENCE,WARREN,MI 48090, USA.							BESL PJ, 1988, IEEE T PATTERN ANAL, V10; CHAMBERS JM, 1971, J AM STAT ASSOC, V68, P66; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; DONGARRA JJ, 1979, LIN PACK USERS GUIDE; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HAAR RL, 1986, SEP ULTR C P SOC MAN; Iannino A., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P32; KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677; NAGATA T, 1985, J ROBOTIC SYST, V2, P163, DOI 10.1002/rob.4620020202; PERKINS WA, 1976, GMR2125 GEN MOT RES; SEBER GAF, 1977, LINEAR REGRESSION AN, P302; Shapiro S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P205; THORPE CE, 1987, 1986 ANN RES REV CMU, P7; TSUJI S, 1978, IEEE T COMPUT, V27, P777, DOI 10.1109/TC.1978.1675191; Wallace A., 1983, IMAGE VISION COMPUT, V1, P178; WALLACE AM, 1985, IEE PROC-E, V132, P309, DOI 10.1049/ip-e.1985.0042; WALLACE AM, 1978, IEEE T COMPUT, V27, P126; Young R., COMMUNICATION	18	25	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1989	11	7					749	758		10.1109/34.192470	http://dx.doi.org/10.1109/34.192470			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AB815					2022-12-18	WOS:A1989AB81500009
J	SANKAR, PV; FERRARI, LA				SANKAR, PV; FERRARI, LA			SIMPLE ALGORITHMS AND ARCHITECTURES FOR B-SPLINE INTERPOLATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SANKAR, PV (corresponding author), UNIV CALIF IRVINE,DEPT ELECT ENGN,IRVINE,CA 92717, USA.							[Anonymous], [No title captured]; CHEN TC, 1985, IEEE T ACOUST SPEECH, V33; HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508; PARK SK, 1983, COMPUT VISION GRAPH, V23, P258, DOI 10.1016/0734-189X(83)90026-9	5	25	25	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					271	276		10.1109/34.3889	http://dx.doi.org/10.1109/34.3889			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400011
J	DORST, L; SMEULDERS, AWM				DORST, L; SMEULDERS, AWM			BEST LINEAR UNBIASED ESTIMATORS FOR PROPERTIES OF DIGITIZED STRAIGHT-LINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									FREE UNIV AMSTERDAM,DEPT PATHOL & MED INFORMAT,1007 MC AMSTERDAM,NETHERLANDS	Vrije Universiteit Amsterdam	DORST, L (corresponding author), DELFT UNIV TECHNOL,DEPT APPL PHYS,2628 CJ DELFT,NETHERLANDS.							DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1984, IEEE T PATTERN ANAL, V6, P632, DOI 10.1109/TPAMI.1984.4767577; DORST L, 1985, 4TH P SCAND C IM AN, V2, P743; DORST L, 1985, LENGTH ESTIMATORS CO, V2, P73; GROEN FCA, 1978, COMPUT VISION GRAPH, V7, P391, DOI 10.1016/S0146-664X(78)80005-7; Lipkin BS, 1970, PICTURE PROCESSING P, P241; MCILROY MD, 1985, ATT TECH J, V64; PROFFITT D, 1979, COMPUT VISION GRAPH, V10, P318, DOI 10.1016/S0146-664X(79)80041-6; VOSSEPOEL AM, 1982, COMPUT VISION GRAPH, V20, P347, DOI 10.1016/0146-664X(82)90057-0	9	25	25	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					276	282		10.1109/TPAMI.1986.4767781	http://dx.doi.org/10.1109/TPAMI.1986.4767781			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869346	Green Submitted			2022-12-18	WOS:A1986A107300015
J	SCHREIBER, WF; TROXEL, DE				SCHREIBER, WF; TROXEL, DE			TRANSFORMATION BETWEEN CONTINUOUS AND DISCRETE REPRESENTATIONS OF IMAGES - A PERCEPTUAL APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ELECTR RES LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	SCHREIBER, WF (corresponding author), MIT,DEPT ELECT ENGN & COMP SCI,CAMBRIDGE,MA 02139, USA.							CURLANDER PJ, 1977, THESIS MIT CAMBRIDGE; DAVIDSON M, 1968, J OPT SOC AM, V58, P1300, DOI 10.1364/JOSA.58.001300; GRASS RW, 1978, THESIS MIT CAMBRIDGE; HASHIZUME B, 1973, THESIS MIT CAMBRIDGE; HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508; KANG G, 1977, QUEST, V1, P3; KERMISCH D, 1975, J OPT SOC AM, V65, P716, DOI 10.1364/JOSA.65.000716; MALONE U, 1977, THESIS MIT CAMBRIDGE; MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250; RATZEL JN, 1970, THESIS MIT CAMBRIDGE; SCHREIBER WF, 1978, P IEEE, V66, P1640, DOI 10.1109/PROC.1978.11172; SCHREIBER WF, 1981, Patent No. 4268861; SCHREIBER WF, 1983, P TECH ASS GRAPHIC A, P701; SCHREIBER WJ, 1974, J TECH ASS PULP PAPE, V57, P91; SHARPE RB, 1979, THESIS MIT CAMBRIDGE; TROXEL DE, 1979, P IEEE, V67, P972, DOI 10.1109/PROC.1979.11371; TROXEL DE, 1981, IEEE T PATTERN ANAL, V3, P95, DOI 10.1109/TPAMI.1981.4767055; TROXEL DE, 1980, JUN ICCC 80, V2	19	25	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	2					178	186		10.1109/TPAMI.1985.4767642	http://dx.doi.org/10.1109/TPAMI.1985.4767642			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ACP84	21869256				2022-12-18	WOS:A1985ACP8400005
J	HENDERSON, TC				HENDERSON, TC			EFFICIENT 3-D OBJECT REPRESENTATIONS FOR INDUSTRIAL VISION SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											HENDERSON, TC (corresponding author), UNIV UTAH,DEPT COMP SCI,SALT LAKE CITY,UT 84112, USA.							AGIN GJ, 1972, AIM173 STANF U MEM; AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; AHUJA N, 1980, 1ST P NAT C ART INT, P44; BAJCSY R, 1980, 5TH P INT C PATT REC, P1064; BAKER H, 1977, 5TH P INT JOINT C AR, P649; BALLARD D, 1977, TR55 U ROCH DEP COMP; BENTLEY JL, 1980, COMMUN ACM, V23, P214, DOI 10.1145/358841.358850; BENTLEY JL, 1976, MAY P ACM S THEOR CO, P220; BHANU B, 1981, USC IPI1030 TECH REP; BINFORD TO, 1982, ROBOTICS RES, V1, P18; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; BOISSONNAT JD, 1981, 7TH P INT JOINT C AR, P658; BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; BOYSE JW, 1979, COMMUN ACM, V22, P3, DOI 10.1145/359046.359048; BROOKS RA, 1978, NOV ARPA IM UND WORK, P45; BROWN CM, 1979, WORKSHOP REPRESENTAT, pF1; COMBA PG, J ASS COMPUT MACH, V15, P354; DIDAY E, 1981, DIGITAL IMAGE PROCES, P331; DRESCHLER L, 1981, MODELLE STRUKTUREN, P76; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1979, IEEE T PATTERN ANAL, V1, P259, DOI 10.1109/TPAMI.1979.4766922; FAUGERAS OD, 1982, 12TH P INT S IND ROB, P67; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; GRIMSON E, 1981, IMAGES SURFACES; HALL EL, 1982, IEEE COMPUT, V15, P42; HENDERSON TC, 1981, 3RD P C PATT REC ART, P277; HENDERSON TC, 1982, MAY P WORKSH IND APP, P181; HENDERSON TC, 1982, MAY SPIE C P ARL, P46; HENDERSON TC, 1981, MODELLE STRUKTUREN; HORN BKP, 1970, PSYCHOL COMPUTER VIS, P115; INOKUCHI W, 1980, 5TH P ICPR MIAM BEAC, P1301; ISHII M, 1976, PATTERN RECOGN, V8, P229, DOI 10.1016/0031-3203(76)90043-1; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; LOZANOPEREZ T, 1979, COMMUN ACM, V22, P560, DOI 10.1145/359156.359164; MARR D, 1977, MIT AI415 LAB MEM; MILGRAM DL, 1980, 5TH P INT C PATT REC, P912; NEVATIA R, 1973, 3RD P IJCAI STANF; OROURKE J, 1981, 7TH P INT JOINT C AR, P664; OSHIMA M, 1981, 7TH P INT JOINT C AR, P601; Pavilidis T., 1977, STRUCTURAL PATTERN R; POPPLESTONE RJ, 1975, 4TH P INT JOINT C AR, P664; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; Requicha A. A. G., 1980, Computing Surveys, V12, P437, DOI 10.1145/356827.356833; ROSEN CA, 1978, SRI174 TECH NOT, P12; Shamos M.I., 1978, THESIS YALE U; SHAPIRA R, 1978, IEEE T COMPUT, V27, P841, DOI 10.1109/TC.1978.1675204; SHAPIRA R, 1974, COMP GRAPH IMAGE PRO, V3, P318; SHIRAI Y, 1971, 2ND P INT JOINT C AR, P80; SRIHARI SN, 1981, ACM COMPUT SURV, V13, P399; TENNENBAUM J, 1978, SRI173 TECH REP; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; UDUPA SM, 1977, 5TH P INT JOINT C AR, P737; UNDERWOOD SA, 1975, IEEE T COMPUT, VC 24, P651, DOI 10.1109/T-C.1975.224277; WATSON LT, 1982, IEEE T PATTERN ANAL, V4, P469, DOI 10.1109/TPAMI.1982.4767290; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; ZUCHER S, 1980, AUG P IEEE C PATT RE, P162	56	25	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					609	618		10.1109/TPAMI.1983.4767450	http://dx.doi.org/10.1109/TPAMI.1983.4767450			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869147				2022-12-18	WOS:A1983RV48800007
J	POSTAIRE, JG; VASSEUR, C				POSTAIRE, JG; VASSEUR, C			A FAST ALGORITHM FOR NONPARAMETRIC PROBABILITY DENSITY-ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV LILLE 1,CTR AUTOMAT,F-59655 VILLENEUVE DASCQ,FRANCE	Universite de Lille - ISITE; Universite de Lille								CACOULLOS T, 1965, ANN I STAT MATH, V18, P179; Duda R.O., 1973, J ROYAL STAT SOC SER; GREBLICKI W, 1978, IEEE T SYST MAN CYB, V8, P809; KITTLER J, 1976, PATTERN RECOGN, V8, P23, DOI 10.1016/0031-3203(76)90026-1; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P967, DOI 10.1109/TC.1972.5009073; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SILVERMAN L, 1980, ASYMPTOTIC THEORY ST; WEGMAN EJ, 1972, TECHNOMETRICS, V14, P533, DOI 10.2307/1267282	9	25	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					663	666		10.1109/TPAMI.1982.4767322	http://dx.doi.org/10.1109/TPAMI.1982.4767322			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	PS237	22499643				2022-12-18	WOS:A1982PS23700014
J	MODESTINO, JW; FRIES, RW; VICKERS, AL				MODESTINO, JW; FRIES, RW; VICKERS, AL			TEXTURE-DISCRIMINATION BASED UPON AN ASSUMED STOCHASTIC TEXTURE MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MODESTINO, JW (corresponding author), RENSSELAER POLYTECH INST,DEPT ELECT & SYST ENGN,TROY,NY 12181, USA.							BOCHNER S, 1959, ANN MATH STUDIES, V42, P235; BRODATZ P, 1956, TEXTURE PHOTOGRAPH A; CHELLAPPA R, 1980, TR928 U MAR COMP SCI; Cinlar E., 2013, INTRO STOCHASTIC PRO; Feller W, 1971, INTRO PROBABILITY TH, VII; FRIES RW, 1979, THESIS RENSSELAER PO; FUKUNAGA K, 1972, INTRO STATISTICAL PA; Haralick R. M., 1976, Digital picture analysis, P5; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hawkins JK, 1970, PICTURE PROCESSING P, P347; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; LU SY, 1978, COMPUT VISION GRAPH, V7, P303, DOI 10.1016/S0146-664X(78)80001-X; McCormick B. H., 1974, International Journal of Computer & Information Sciences, V3, P329, DOI 10.1007/BF00978978; MCCORMICK BH, 1978, INT J COMPUT INFORM, V4, P1; Modestino J. W., 1978, Pattern Recognition and Signal Processing, P225; MODESTINO JW, 1979, J OPT SOC AM, V69, P897, DOI 10.1364/JOSA.69.000897; MODESTINO JW, 1980, IEEE T INFORM THEORY, V26, P44, DOI 10.1109/TIT.1980.1056138; MODESTINO JW, 1980, COMPUT VISION GRAPH, V12, P74, DOI 10.1016/0146-664X(80)90005-2; MODESTINO JW, UNPUBLISHED; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; PAPOULIS A, 1967, J OPT SOC AM, V57, P207, DOI 10.1364/JOSA.57.000207; PAPOULIS A, 1965, PROBABILITY RANDOM V, pCH11; PAPOULIS A, 1968, SYSTEMS TRANSFORMS A; Parzen E., 1962, STOCHASTIC PROCESSES; PICKETT RM, 1970, PICTURE PROCESSING P, P289; PRATT WK, 1978, IEEE T SYST MAN CYB, V8, P796, DOI 10.1109/TSMC.1978.4309867; PRATT WK, 1978, DIGITAL IMAGE PROCES, P503; SCHACHTER BJ, 1978, IEEE T SYST MAN CYB, V8, P694; Snyder D, 1975, RANDOM POINT PROCESS; TOU JT, 1976, 1976 P IEEE C DEC CO, P398; Van Trees H., 2013, DETECTION ESTIMATION; VICKERS AL, 1980, TR802 RENSS POL I DE; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; WONG E, 1968, SIAM J APPL MATH, V16, P756, DOI 10.1137/0116062; Zucker SW., 1976, COMPUTER GRAPHICS IM, V5, P190, DOI [10.1016/0146-664X(76)90027-7, DOI 10.1016/0146-664X(76)90027-7]	37	25	25	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					557	580		10.1109/TPAMI.1981.4767148	http://dx.doi.org/10.1109/TPAMI.1981.4767148			24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868975				2022-12-18	WOS:A1981MQ35800006
J	SHAPIRO, SD; IANNINO, A				SHAPIRO, SD; IANNINO, A			GEOMETRIC CONSTRUCTIONS FOR PREDICTING HOUGH TRANSFORM PERFORMANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SHAPIRO, SD (corresponding author), STEVENS INST TECHNOL,DEPT ELECT ENGN,HOBOKEN,NJ 07030, USA.							BASTIEN PL, 1971, IEEE T COMPUT, VC 20, P995, DOI 10.1109/T-C.1971.223394; BAZIN MJ, 1965, IEEE T NUCL SCI, VNS12, P291, DOI 10.1109/TNS.1965.4323870; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Duda RO, 1973, PATTERN RECOGNITION; DUDANI SA, 1977, JUN P IEEE CONF PATT, P367; GRIFFITH AK, 1973, IEEE T COMPUT, VC 22, P371, DOI 10.1109/T-C.1973.223724; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677; NEVATIA R, 1976, IEEE T COMPUT, V25, P1170, DOI 10.1109/TC.1976.1674576; NITZAN D, 1976, SRI128 ART INT CTR T; OGORMAN F, 1973, 3RD P IJC AI KYOT, P543; PERKINS WA, 1973, J COMPUT GRAPHICS IM, V2, P355; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHAPIRO SD, 1978, COMPUT VISION GRAPH, V8, P219, DOI 10.1016/0146-664X(78)90050-3; SHAPIRO SD, 1978, IEEE T COMPUT, V27, P254, DOI 10.1109/TC.1978.1675080; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; WECHSLER H, 1977, PATTERN RECOGN, V9, P21, DOI 10.1016/0031-3203(77)90027-9	17	25	25	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					310	317		10.1109/TPAMI.1979.4766929	http://dx.doi.org/10.1109/TPAMI.1979.4766929			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868864				2022-12-18	WOS:A1979HC30100011
J	Wang, X; Chen, YD; Zhu, WW				Wang, Xin; Chen, Yudong; Zhu, Wenwu			A Survey on Curriculum Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Curriculum learning; machine learning; training strategy; example reweighting; self-paced learning	SELECTION	Curriculum learning (CL) is a training strategy that trains a machine learning model from easier data to harder data, which imitates the meaningful learning order in human curricula. As an easy-to-use plug-in, the CL strategy has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision and natural language processing etc. In this survey article, we comprehensively review CL from various aspects including motivations, definitions, theories, and applications. We discuss works on curriculum learning within a general CL framework, elaborating on how to design a manually predefined curriculum or an automatic curriculum. In particular, we summarize existing CL designs based on the general framework of Difficulty Measurer + Training Scheduler and further categorize the methodologies for automatic CL into four groups, i.e., Self-paced Learning, Transfer Teacher, RLTeacher, and Other Automatic CL. We also analyze principles to select different CL designs that may benefit practical applications. Finally, we present our insights on the relationships connecting CL and other machine learning concepts including transfer learning, meta-learning, continual learning and active learning, etc., then point out challenges in CL as well as potential future research directions deserving further investigations.	[Wang, Xin; Chen, Yudong; Zhu, Wenwu] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Tsinghua University	Zhu, WW (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	xin_wang@tsinghua.edu.cn; cyd18@mails.tsinghua.edu.cn; wwzhu@tsinghua.edu.cn			National Key Research and Development Program of China [2020AAA0106301]; National Natural Science Foundation of China [62050110]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key Research and Development Program of China under Grant 2020AAA0106301 and National Natural Science Foundation of China under Grant 62050110.	Aaron Courville, 2016, Arxiv, DOI arXiv:1511.06481; Allgower E.L., 2012, NUMERICAL CONTINUATI, V13; Amos Storkey, 2020, Arxiv, DOI arXiv:2004.05439; Olvera-Lopez JA, 2010, ARTIF INTELL REV, V34, P133, DOI 10.1007/s10462-010-9165-y; Avramova V., 2015, THESIS KTH ROY I TEC; Bei Peng, 2020, Arxiv, DOI arXiv:2003.04960; Bengio S, 2015, ADV NEUR IN, V28; Bengio Y., 2014, GROWING ADAPTIVE MAC, P109; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Chang H. -S., 2017, ADV NEURAL INFORM PR, V30, P1002; Changick Kim, 2019, Arxiv, DOI arXiv:1908.00262; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168; Cirik V, 2016, ARXIV; De Lange M, 2022, IEEE T PATTERN ANAL, V44, P3366, DOI 10.1109/TPAMI.2021.3057446; Derek F. Wong, 2020, Arxiv, DOI arXiv:2006.02014; Dizaji KG, 2019, PROC CVPR IEEE, P4386, DOI 10.1109/CVPR.2019.00452; El-Bouri R., 2020, ARXIV; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Fan Y., 2018, ARXIV PREPRINT ARXIV; Florensa C., 2017, PROC 1 C ROBOT LEARN, P482; Florensa C, 2018, PR MACH LEARN RES, V80; Frank Hutter, 2016, Arxiv, DOI arXiv:1511.06343; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148; Gaurav Kumar, 2019, Arxiv, DOI arXiv:1905.05816; Gaurav Kumar, 2018, Arxiv, DOI arXiv:1811.00739; Goldberger J., 2016, PROC INT C LEARN REP, P1; Gong C, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3322122; Gong MG, 2019, IEEE T EVOLUT COMPUT, V23, P288, DOI 10.1109/TEVC.2018.2850769; Gopal S, 2016, PR MACH LEARN RES, V48; Graves A, 2017, PR MACH LEARN RES, V70; Guo S, 2018, LECT NOTES COMPUT SC, V11214, P139, DOI 10.1007/978-3-030-01249-6_9; Guo Y., 2020, INTERNA TIONAL C MAC, P3822; Hacohen G, 2019, PR MACH LEARN RES, V97; Han JW, 2021, IEEE T PATTERN ANAL, V43, P1423, DOI 10.1109/TPAMI.2019.2949562; Han LF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1816; Hung Wei-Chih, 2018, ARXIV180207934; Ilya Sutskever, 2015, Arxiv, DOI arXiv:1410.4615; Ionescu RT, 2016, PROC CVPR IEEE, P2157, DOI 10.1109/CVPR.2016.237; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Jiang L, 2015, AAAI CONF ARTIF INTE, P2694; Jiang L, 2014, ADV NEUR IN, V27; Jimenez-Sanchez A, 2019, LECT NOTES COMPUT SC, V11769, P694, DOI 10.1007/978-3-030-32226-7_77; Jin S, 2018, LECT NOTES COMPUT SC, V11217, P316, DOI 10.1007/978-3-030-01261-8_19; Karras T, 2017, ARXIV171010196; Khan Salman H, 2018, IEEE Trans Neural Netw Learn Syst, V29, P3573, DOI 10.1109/TNNLS.2017.2732482; Kim T., 2018, ARXIV; Klink P., 2020, P CORL, P513; Kocmi Tom, 2017, RANLP; Krueger KA, 2009, COGNITION, V110, P380, DOI 10.1016/j.cognition.2008.11.014; Kumar Gaurav, 2019, NAACL HLT; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523; Li CS, 2017, AAAI CONF ARTIF INTE, P2175; Li YC, 2017, IEEE I CONF COMP VIS, P1928, DOI 10.1109/ICCV.2017.211; Lin L, 2018, IEEE T PATTERN ANAL, V40, P7, DOI 10.1109/TPAMI.2017.2652459; Liu C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4223; Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24; Liuyu Xiang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P247, DOI 10.1007/978-3-030-58558-7_15; Lu J, 2018, PR MACH LEARN RES, V80; Ma F, 2017, PR MACH LEARN RES, V70; Matiisen T, 2020, IEEE T NEUR NET LEAR, V31, P3732, DOI 10.1109/TNNLS.2019.2934906; Meng DY, 2017, INFORM SCIENCES, V414, P319, DOI 10.1016/j.ins.2017.05.043; Moore Robert C., 2010, P ACL 2010 C SHORT P, P220; Morerio P, 2017, IEEE I CONF COMP VIS, P3564, DOI 10.1109/ICCV.2017.383; Narvekar S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2536; Natarajan Nagarajan, 2013, ADV NEURAL INFORM PR; NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1207/s15516709cog1401_2; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Penha G., ARXIV; Pentina A, 2015, PROC CVPR IEEE, P5492, DOI 10.1109/CVPR.2015.7299188; Peterson GB, 2004, J EXP ANAL BEHAV, V82, P317, DOI 10.1901/jeab.2004.82-317; Pi Te, 2016, P 25 INT JOINT C ART, P1932; Platanios Emmanouil Antonios, 2019, P 2019 C N AM CHAPT, P1162, DOI DOI 10.18653/V1/N19-1119; Portelas R., 2020, ARXIV; Qu M, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P468, DOI 10.1145/3159652.3159711; Reedman SE, 2016, PHYS OCCUP THER PEDI, V36, P292, DOI 10.3109/01942638.2015.1040576; Ren MY, 2018, PR MACH LEARN RES, V80; Ren YZ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2641; Ren ZP, 2018, IEEE T NEUR NET LEAR, V29, P2216, DOI 10.1109/TNNLS.2018.2790981; Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1; SANGER TD, 1994, IEEE T ROBOTIC AUTOM, V10, P323, DOI 10.1109/70.294207; Saxena Shreyas, 2019, ADV NEURAL INFORM PR, P11095; SCHMIDHUBER J, 1991, IEEE IJCNN, P1458, DOI 10.1109/IJCNN.1991.170605; Selfridge O. G., 1985, IJCAI, P670; Settles B., 2009, ACT LEARN LIT SURV; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Shu Y, 2019, AAAI CONF ARTIF INTE, P4951; Sinha S, 2020, ROUT RES POSTCOL LIT, P1; Soviany P, 2020, IEEE WINT CONF APPL, P3452, DOI 10.1109/WACV45572.2020.9093408; Spitkovsky V. I., 2010, HUM LANG TECHN 2010, P751; Tang K., 2012, ADV NEURAL INFORM PR; Tang Y., 2012, ACM INT C MULT, P833, DOI DOI 10.1145/2393347.2396324; Tang YP, 2019, AAAI CONF ARTIF INTE, P5117; Tang YX, 2018, LECT NOTES COMPUT SC, V11046, P249, DOI 10.1007/978-3-030-00919-9_29; Tay Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4922; Tsvetkov Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P130; Tullis JG, 2011, J MEM LANG, V64, P109, DOI 10.1016/j.jml.2010.11.002; Wang W, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1282; Wang Xinyi, 2020, P MACHINE LEARNING R, V119, P9983; Wang YR, 2019, IEEE I CONF COMP VIS, P5016, DOI 10.1109/ICCV.2019.00512; Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150; Weinshall D, 2018, PR MACH LEARN RES, V80; Wu LJ, 2018, ADV NEUR IN, V31; Xu C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3974; Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649; Zhang DW, 2019, IEEE T CIRC SYST VID, V29, P3622, DOI 10.1109/TCSVT.2018.2884173; Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4; Zhang DW, 2017, PROC CVPR IEEE, P5340, DOI 10.1109/CVPR.2017.567; Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75; Zhang Dingyi, 2020, ADV NEUR IN; Zhao M., 2020, ARXIV; Zhao Q, 2015, AAAI CONF ARTIF INTE, P3196; Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029; Zhou T., 2020, ADV NEURAL INFORM PR, V33, P8602; Zhou T, 2018, PLANT SOIL, V429, P321, DOI 10.1007/s11104-018-3698-2; Zhou Yikai, 2020, ACL, P6934; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106	147	24	24	12	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4555	4576		10.1109/TPAMI.2021.3069908	http://dx.doi.org/10.1109/TPAMI.2021.3069908			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33788677	Green Submitted			2022-12-18	WOS:000836666600010
J	Chen, TS; Lin, L; Chen, RQ; Hui, XL; Wu, HF				Chen, Tianshui; Lin, Liang; Chen, Riquan; Hui, Xiaolu; Wu, Hefeng			Knowledge-Guided Multi-Label Few-Shot Learning for General Image Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Task analysis; Training; Image recognition; Correlation; Neural networks; Proposals; Image recognition; multi-label learning; few-shot learning; knowledge graph; graph reasoning		Recognizing multiple labels of an image is a practical yet challenging task, and remarkable progress has been achieved by searching for semantic regions and exploiting label dependencies. However, current works utilize RNN/LSTM to implicitly capture sequential region/label dependencies, which cannot fully explore mutual interactions among the semantic regions/labels and do not explicitly integrate label co-occurrences. In addition, these works require large amounts of training samples for each category, and they are unable to generalize to novel categories with limited samples. To address these issues, we propose a knowledge-guided graph routing (KGGR) framework, which unifies prior knowledge of statistical label correlations with deep neural networks. The framework exploits prior knowledge to guide adaptive information propagation among different categories to facilitate multi-label analysis and reduce the dependency of training samples. Specifically, it first builds a structured knowledge graph to correlate different labels based on statistical label co-occurrence. Then, it introduces the label semantics to guide learning semantic-specific features to initialize the graph, and it exploits a graph propagation network to explore graph node interactions, enabling learning contextualized image feature representations. Moreover, we initialize each graph node with the classifier weights for the corresponding label and apply another propagation network to transfer node messages through the graph. In this way, it can facilitate exploiting the information of correlated labels to help train better classifiers, especially for labels with limited training samples. We conduct extensive experiments on the traditional multi-label image recognition (MLR) and multi-label few-shot learning (ML-FSL) tasks and show that our KGGR framework outperforms the current state-of-the-art methods by sizable margins on the public benchmarks.	[Chen, Tianshui; Lin, Liang; Chen, Riquan; Hui, Xiaolu; Wu, Hefeng] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China; [Chen, Tianshui; Lin, Liang] DarkMatter AI Res, Guangzhou 511458, Peoples R China	Sun Yat Sen University	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China.	tianshuichen@gmail.com; linliang@ieee.org; chenrq6@mail2.sysu.edu.cn; huixlu@mail2.sysu.edu.cn; wuhefeng@gmail.com		Wu, Hefeng/0000-0002-2132-6515; Chen, Tianshui/0000-0002-5848-5624; Liang, Lin/0000-0003-2248-3755	National Key Research and Development Program of China [2018YFC0830103]; National Natural Science Foundation of China (NSFC) [61876045, 61836012]; Zhujiang Science and Technology New Star Project of Guangzhou [201906010057]	National Key Research and Development Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Zhujiang Science and Technology New Star Project of Guangzhou	This work was supported in part by theNational Key Research and Development Program of China under Grant No. 2018YFC0830103, in part by the National Natural Science Foundation of China (NSFC) under Grants 61876045 and 61836012, and in part by Zhujiang Science and Technology New Star Project ofGuangzhou underGrants 201906010057.	Alfassy A, 2019, PROC CVPR IEEE, P6541, DOI 10.1109/CVPR.2019.00671; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234; Chen RQ, 2020, AAAI CONF ARTIF INTE, V34, P10575; Chen T., 2020, P 28 ACM INT C MULT; Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061; Chen TS, 2019, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2019.00632; Chen TS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2023, DOI 10.1145/3240508.3240523; Chen TS, 2019, IEEE T MULTIMEDIA, V21, P1022, DOI 10.1109/TMM.2018.2870062; Chen TS, 2018, AAAI CONF ARTIF INTE, P6730; Chen TS, 2018, IEEE T IMAGE PROCESS, V27, P5827, DOI 10.1109/TIP.2018.2859025; Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664; Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong J, 2013, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2013.112; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Finn C, 2017, PR MACH LEARN RES, V70; Ghamrawi N., 2005, ACM INT C INFORM KNO, P195, DOI DOI 10.1145/1099554.1099591; Guo Y., 2011, PROC 22 INT JOINT C, P1300, DOI DOI 10.5591/978-1-57735-516-8/IJCA111-220; Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He SY, 2018, AAAI CONF ARTIF INTE, P3183; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Ioffe S., 2014, ICLR, P1; Jiang CH, 2018, ADV NEUR IN, V31; Kim Jin-Hwa, 2016, ICLR; Kim J, 2019, PROC CVPR IEEE, P9454, DOI 10.1109/CVPR.2019.00969; Kingma D.P, P 3 INT C LEARNING R; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Lapin M, 2018, IEEE T PATTERN ANAL, V40, P1533, DOI 10.1109/TPAMI.2017.2751607; Li AX, 2019, PROC CVPR IEEE, P7205, DOI 10.1109/CVPR.2019.00738; Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu YC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P700, DOI 10.1145/3240508.3240567; Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Qi H, 2018, PROC CVPR IEEE, P5822, DOI 10.1109/CVPR.2018.00610; Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755; Ravi S., 2017, P INT C LEARN REPR, P1; Ravichandran A, 2019, IEEE I CONF COMP VIS, P331, DOI 10.1109/ICCV.2019.00042; Reed Scott, 2015, 2015 IEEE C COMPUTE, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Schwartz E, 2018, ADV NEUR IN, V31; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Song HO, 2015, IEEE T PATTERN ANAL, V37, P1001, DOI 10.1109/TPAMI.2014.2353631; Sui YL, 2013, INT SYM CODE GENER, P1; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tang YX, 2018, IEEE T PATTERN ANAL, V40, P3045, DOI 10.1109/TPAMI.2017.2771779; Tat-Seng Chua, 1994, Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. Vol.III: Information Systems: Decision Support and Knowledge-Based Systems (Cat. No.94TH0607-2), P590, DOI 10.1109/HICSS.1994.323321; Tokmakov P, 2019, IEEE I CONF COMP VIS, P6381, DOI 10.1109/ICCV.2019.00647; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829; Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717; Wang Z., 2018, P INT JOINT C ART IN, P2021; Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Xue XY, 2011, IEEE I CONF COMP VIS, P651, DOI 10.1109/ICCV.2011.6126300; Yang H, 2016, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2016.37; Yang W., 2019, P INT C LEARN REPR; Yang XJ, 2020, PATTERN RECOGN LETT, V130, P345, DOI 10.1016/j.patrec.2018.06.024; Yang XT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P963, DOI 10.1145/2733373.2806375; Zhang H., 2018, 6 INT C LEARNING REP, DOI 10.48550/arXiv.1710.09412; Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288; Zhang JJ, 2018, IEEE T MULTIMEDIA, V20, P2801, DOI 10.1109/TMM.2018.2812605; Zhang SW, 2020, AAAI CONF ARTIF INTE, V34, P12862; Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	72	24	25	38	81	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1371	1384		10.1109/TPAMI.2020.3025814	http://dx.doi.org/10.1109/TPAMI.2020.3025814			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32986543	Green Submitted			2022-12-18	WOS:000752018000022
J	Zhang, SF; Chi, C; Lei, Z; Li, SZ				Zhang, Shifeng; Chi, Cheng; Lei, Zhen; Li, Stan Z.			RefineFace: Refinement Neural Network for High Performance Face Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Detectors; Face detection; Feature extraction; Task analysis; Proposals; Neural networks; Face detection; refinement network; high performance	REAL-TIME	Face detection has achieved significant progress in recent years. However, high performance face detection still remains a very challenging problem, especially when there exists many tiny faces. In this paper, we present a single-shot refinement face detector namely RefineFace to achieve high performance. Specifically, it consists of five modules: selective two-step regression (STR), selective two-step classification (STC), scale-aware margin loss (SML), feature supervision module (FSM) and receptive field enhancement (RFE). To enhance the regression ability for high location accuracy, STR coarsely adjusts locations and sizes of anchors from high level detection layers to provide better initialization for subsequent regressor. To improve the classification ability for high recall efficiency, STC first filters out most simple negatives from low level detection layers to reduce search space for subsequent classifier, then SML is applied to better distinguish faces from background at various scales and FSM is introduced to let the backbone learn more discriminative features for classification. Besides, RFE is presented to provide more diverse receptive field to better capture faces in some extreme poses. Extensive experiments conducted on WIDER FACE, AFW, PASCAL Face, FDDB, MAFA demonstrate that our method achieves state-of-the-art results and runs at 37.3 FPS with ResNet-18 for VGA-resolution images.	[Zhang, Shifeng; Lei, Zhen] Chinese Acad Sci CASIA, Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence SAI,Inst Automat, Ctr Biometr & Secur Res CBSR,Natl Lab Pattern Rec, Beijing 100049, Peoples R China; [Chi, Cheng] Chinese Acad Sci, Univ Chinese Acad Sci UCAS, Aerosp Informat Res Inst AIR, Beijing 100049, Peoples R China; [Li, Stan Z.] Westlake Univ, Hangzhou 310013, Peoples R China	Chinese Academy of Sciences; Westlake University	Lei, Z (corresponding author), Chinese Acad Sci CASIA, Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence SAI,Inst Automat, Ctr Biometr & Secur Res CBSR,Natl Lab Pattern Rec, Beijing 100049, Peoples R China.	shifeng.zhang@nlpr.ia.ac.cn; chicheng15@mails.ucas.ac.cn; zlei@nlpr.ia.ac.cn; Stan.Z.Q.Li@westlake.edu.cn		Zhang, Shifeng/0000-0003-3109-5770	National Key Research and Development Plan [2019YFC2003901]; Chinese National Natural Science Foundation [61872367, 61876178, 61806196, 61976229]	National Key Research and Development Plan; Chinese National Natural Science Foundation(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Plan under Grant 2019YFC2003901, and Chinese National Natural Science Foundation Projects #61872367, #61876178, #61806196, #61976229. Shifeng Zhang and Cheng Chi contributed equally to this work.	[Anonymous], ARXIV160605413; [Anonymous], 2017, NEUROCOMPUTING; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; [Anonymous], 2019, IMPROVED SELECTIVE R; Bai YC, 2018, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2018.00010; Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1; Chen Y., 2017, ARXIV170905188; Chi C, 2019, AAAI CONF ARTIF INTE, P8231; Dai JF, 2016, ADV NEUR IN, V29; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Deng Jiankang, 2019, ARXIV190500641; Dong Chen, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9909, P122, DOI 10.1007/978-3-319-46454-1_8; Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194; Ge SM, 2017, PROC CVPR IEEE, P426, DOI 10.1109/CVPR.2017.53; Ghiasi Golnaz, 2015, ARXIV150608347; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Hao ZK, 2017, PROC CVPR IEEE, P1913, DOI 10.1109/CVPR.2017.207; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166; Jain V., UMCS2010009; Kalal Z., 2008, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.22.42; Kumar V, 2015, IEEE I CONF COMP VIS, P1994, DOI 10.1109/ICCV.2015.231; Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170; Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238; Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520; Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26; Li Z., ABS19040086 CORR; Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533; Liu WY, 2016, PR MACH LEARN RES, V48; Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47; Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522; Ohn-Bar E, 2016, INT C PATT RECOG, P3350, DOI 10.1109/ICPR.2016.7900151; Paszke Adam, 2017, PYTORCH TENSORS DYNA, P6; Pham MT, 2007, IEEE I CONF COMP VIS, P1634; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Shen XH, 2013, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2013.444; Shi XP, 2018, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2018.00244; Song GL, 2018, PROC CVPR IEEE, P7756, DOI 10.1109/CVPR.2018.00809; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49; Tian Wanxin, 2018, ARXIV181108557; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang H., 2017, ARXIV170601061; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang J., 2017, ARXIV171107246; Wang Yitong, 2017, ARXIV170905256; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320; Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004; Yang B, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014); Yang S., 2017, ARXIV170602863; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419; Yoo Y., 2019, EXTD EXTREMELY TINY; Yu Jiahui., 2016, ACM MM, DOI DOI 10.1145/2964284.2967274; Zhang Changzheng, 2018, ARXIV180202142; Zhang F., 2019, ACCURATE FACE DETECT; Zhang JL, 2020, NEUROCOMPUTING, V380, P180, DOI 10.1016/j.neucom.2019.10.087; Zhang KP, 2017, IEEE I CONF COMP VIS, P3190, DOI 10.1109/ICCV.2017.344; Zhang SF, 2019, NEUROCOMPUTING, V364, P297, DOI 10.1016/j.neucom.2019.07.064; Zhang SF, 2019, INT J COMPUT VISION, V127, P537, DOI 10.1007/s11263-019-01159-3; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhang SF, 2018, NEUROCOMPUTING, V284, P119, DOI 10.1016/j.neucom.2018.01.012; Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675; Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30; Zhang Y, 2019, ARXIV190102350; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	83	24	25	5	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4008	4020		10.1109/TPAMI.2020.2997456	http://dx.doi.org/10.1109/TPAMI.2020.2997456			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32750774	Green Submitted			2022-12-18	WOS:000702649700023
J	Schops, T; Sattler, T; Pollefeys, M				Schops, Thomas; Sattler, Torsten; Pollefeys, Marc			SurfelMeshing: Online Surfel-Based Mesh Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Real-time systems; Simultaneous localization and mapping; Three-dimensional displays; Surface reconstruction; Cameras; Noise reduction; Image reconstruction; Applications of RGB-D vision; depth fusion; loop closure; 3-D modeling and scene reconstruction; RGB-D SLAM; real-time dense mapping; surfels	INTEGRATION	We address the problem of mesh reconstruction from live RGB-D video, assuming a calibrated camera and poses provided externally (e.g., by a SLAM system). In contrast to most existing approaches, we do not fuse depth measurements in a volume but in a dense surfel cloud. We asynchronously (re)triangulate the smoothed surfels to reconstruct a surface mesh. This novel approach enables to maintain a dense surface representation of the scene during SLAM which can quickly adapt to loop closures. This is possible by deforming the surfel cloud and asynchronously remeshing the surface where necessary. The surfel-based representation also naturally supports strongly varying scan resolution. In particular, it reconstructs colors at the input camera's resolution. Moreover, in contrast to many volumetric approaches, ours can reconstruct thin objects since objects do not need to enclose a volume. We demonstrate our approach in a number of experiments, showing that it produces reconstructions that are competitive with the state-of-the-art, and we discuss its advantages and limitations. The algorithm (excluding loop closure functionality) is available as open source at https://github.com/puzzlepaint/surfelmeshing.	[Schops, Thomas; Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sci, CH-8001 Zurich, Switzerland; [Pollefeys, Marc] Microsoft, CH-8001 Zurich, Switzerland; [Sattler, Torsten] Chalmers Univ Technol, S-1296 Gothenburg, Sweden	Swiss Federal Institutes of Technology Domain; ETH Zurich; Chalmers University of Technology	Schops, T (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, CH-8001 Zurich, Switzerland.	thomas.schoeps@inf.ethz.ch; torsat@chalmers.se; marc.pollefeys@inf.ethz.ch	Pollefeys, Marc/I-7607-2013; Sattler, Torsten/AAM-3155-2021	Sattler, Torsten/0000-0001-9760-4553	Google PhD Fellowship	Google PhD Fellowship(Google Incorporated)	Thomas Schops was supported by a Google PhD Fellowship.	Arth C., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P37, DOI 10.1109/ISMAR.2011.6092368; Bircher A, 2015, IEEE INT CONF ROBOT, P6423, DOI 10.1109/ICRA.2015.7140101; Bodenmuller T., 2009, THESIS; Breitenmoser A., 2012, 2012 2nd International Conference on Applied Robotics for the Power Industry (CARPI 2012), P22, DOI 10.1109/CARPI.2012.6473354; Chen JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461940; Clarkson K. L., 1983, 24th Annual Symposium on Foundations of Computer Science, P226, DOI 10.1109/SFCS.1983.16; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739; Gao W., 2018, P ROB SCI SYST PITTS, DOI [10.15607/RSS.2018.XIV.029, DOI 10.15607/RSS.2018.XIV.029]; Garrido S, 2013, ROBOT AUTON SYST, V61, P106, DOI 10.1016/j.robot.2012.10.012; Gopi M, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRA.2002.1167141; Han L., 2018, P ROB SCI SYST JUN, DOI [10.15607/RSS.2018.XIV.006, DOI 10.15607/RSS.2018.XIV.006]; Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054; Hane C, 2017, IMAGE VISION COMPUT, V68, P14, DOI 10.1016/j.imavis.2017.07.003; Kahler O, 2016, LECT NOTES COMPUT SC, V9912, P500, DOI 10.1007/978-3-319-46484-8_30; Kahler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891; Kahler O, 2016, IEEE ROBOT AUTOM LET, V1, P192, DOI 10.1109/LRA.2015.2512958; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Keller M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P1, DOI 10.1109/3DV.2013.9; Klingensmith M., 2015, P ROB SCI SYST ROM I, DOI [10.15607/RSS.2015.XI.040, DOI 10.15607/RSS.2015.XI.040]; Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599; Ladicky L, 2017, IEEE I CONF COMP VIS, P3913, DOI 10.1109/ICCV.2017.420; Lefloch D, 2017, IEEE T PATTERN ANAL, V39, P2349, DOI 10.1109/TPAMI.2017.2648803; Lefloch D, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2121; Litvinov V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.61; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Maier R., 2017, P BRIT MACH VIS C; Marton ZC, 2009, IEEE INT CONF ROBOT, P2829; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374; Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936; Romanoni A, 2015, LECT NOTES COMPUT SC, V9279, P489, DOI 10.1007/978-3-319-23231-7_44; Schertler N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073635; Schops T, 2017, COMPUT VIS IMAGE UND, V157, P151, DOI 10.1016/j.cviu.2016.09.007; Schops T, 2014, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2014.6948420; Schops T, 2019, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2019.00022; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Schops T, 2017, IEEE T VIS COMPUT GR, V23, P2455, DOI 10.1109/TVCG.2017.2734578; Steinbrucker F, 2014, IEEE INT CONF ROBOT, P2021, DOI 10.1109/ICRA.2014.6907127; Stuckler J, 2014, J VIS COMMUN IMAGE R, V25, P137, DOI 10.1016/j.jvcir.2013.02.008; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Wasenmuller O, 2016, IEEE WINT CONF APPL; Weise T, 2011, COMPUT VIS IMAGE UND, V115, P635, DOI 10.1016/j.cviu.2010.11.023; Whelan T., 2015, ELASTICFUSION DENSE, DOI [10.15607/RSS.2015.XI.001, DOI 10.15607/RSS.2015.XI.001]; Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008; WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1; Yan ZX, 2017, IEEE T VIS COMPUT GR, V23, P2389, DOI 10.1109/TVCG.2017.2734458; Zienkiewicz J, 2016, INT CONF 3D VISION, P37, DOI 10.1109/3DV.2016.82	49	24	24	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2494	2507		10.1109/TPAMI.2019.2947048	http://dx.doi.org/10.1109/TPAMI.2019.2947048			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31613751	Green Accepted			2022-12-18	WOS:000567471300013
J	Barz, B; Rodner, E; Garcia, YG; Denzler, J				Barz, Bjorn; Rodner, Erik; Garcia, Yanira Guanche; Denzler, Joachim			Detecting Regions of Maximal Divergence for Spatio-Temporal Anomaly Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Anomaly detection; time series analysis; spatio-temporal data; data mining; unsupervised machine learning		Automatic detection of anomalies in space- and time-varying measurements is an important tool in several fields, e.g., fraud detection, climate analysis, or healthcare monitoring. We present an algorithm for detecting anomalous regions in multivariate spatio-temporal time-series, which allows for spotting the interesting parts in large amounts of data, including video and text data. In opposition to existing techniques for detecting isolated anomalous data points, we propose the "Maximally Divergent Intervals" (MDI) framework for unsupervised detection of coherent spatial regions and time intervals characterized by a high Kullback-Leibler divergence compared with all other data given. In this regard, we define an unbiased Kullback-Leibler divergence that allows for ranking regions of different size and show how to enable the algorithm to run on large-scale data sets in reasonable time using an interval proposal technique. Experiments on both synthetic and real data from various domains, such as climate analysis, video surveillance, and text forensics, demonstrate that our method is widely applicable and a valuable tool for finding interesting events in different types of data.	[Barz, Bjorn; Garcia, Yanira Guanche; Denzler, Joachim] Friedrich Schiller Univ Jena, Dept Math & Comp Sci, Comp Vis Grp, D-07737 Jena, Germany; [Rodner, Erik] Carl Zeiss, Corp Res & Technol, Oberkochen, Germany	Friedrich Schiller University of Jena; Carl Zeiss AG	Barz, B (corresponding author), Friedrich Schiller Univ Jena, Dept Math & Comp Sci, Comp Vis Grp, D-07737 Jena, Germany.	bjoern.barz@uni-jena.de; Erik.Rodner@uni-jena.de; yanira.guanche.garcia@uni-jena.de; joachim.denzler@uni-jena.de	Barz, Björn/AAX-8736-2020	Barz, Björn/0000-0003-1019-9538; Denzler, Joachim/0000-0002-3193-3300	EU H2020-EO-2014 project BACI [640176]	EU H2020-EO-2014 project BACI	The support of the project EU H2020-EO-2014 project BACI "Detecting changes in essential ecosystem and biodiversity properties-towards a Biosphere Atmosphere Change Index", contract 640176, is gratefully acknowledged.	AHMED NA, 1989, IEEE T INFORM THEORY, V35, P688, DOI 10.1109/18.30996; Anderson T. W., 2003, INTRO MULTIVARIATE S, V3rd; [Anonymous], 2012, HELMH ZENTR GEESTH Z, DOI [10.1594/WDCC/coastDat-1_Waves, DOI 10.1594/WDCC/COASTDAT-1_WAVES]; Birant D., 2006, Journal of Computing and Information Technology - CIT, V14, P291, DOI 10.2498/cit.2006.04.04; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Cheng T., 2006, T GIS, V10, P253, DOI DOI 10.1111/J.1467-9671.2006.00256.X; Duchi J., 2007, DERIVATIONS LINEAR A; Hawkins D. M, 1980, IDENTIFICATION OUTLI, V11; Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang M, 2015, IEEE DATA MINING, P781, DOI 10.1109/ICDM.2015.61; Kalnay E, 1996, B AM METEOROL SOC, V77, P437, DOI 10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2; Kanungo T., 1995, ISLTR9505; Keogh E., 2005, 5 IEEE INT C DAT MIN, P8; Kim J, 2012, J MACH LEARN RES, V13, P2529; Koehn P., 2005, P MT SUMM PHUK THAIL, VVolume 5, P79; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Liu S, 2013, NEURAL NETWORKS, V43, P72, DOI 10.1016/j.neunet.2013.01.012; MACGREGOR JF, 1995, CONTROL ENG PRACT, V3, P403, DOI 10.1016/0967-0661(95)00014-L; Mikolov T., 2013, EFFICIENT ESTIMATION; Paciorek CJ, 2004, ADV NEUR IN, V16, P273; PACKARD NH, 1980, PHYS REV LETT, V45, P712, DOI 10.1103/PhysRevLett.45.712; Ren HR, 2018, IEEJ T ELECTR ELECTR, V13, P757, DOI 10.1002/tee.22626; Rodner E., 2016, P ICML WORKSH AN DET, P1; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Senin P, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3051126; Takens F., 1981, DYNAMICAL SYSTEMS TU, P366, DOI [DOI 10.1007/BFB0091924, 10.1007/bfb0091924, 10.1007/BFb0091924]; Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walker G., 1928, Q J ROY METEOR SOC, V54, P79, DOI DOI 10.1002/QJ.49705422601; Wu E, 2010, LECT NOTES COMPUT SC, V5840, P115, DOI 10.1007/978-3-642-12519-5_7	31	24	27	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1088	1101		10.1109/TPAMI.2018.2823766	http://dx.doi.org/10.1109/TPAMI.2018.2823766			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993434	Green Submitted, Bronze			2022-12-18	WOS:000463607400005
J	Li, W; Chen, L; Xu, D; Van Gool, L				Li, Wen; Chen, Lin; Xu, Dong; Van Gool, Luc			Visual Recognition in RGB Images and Videos by Learning from RGB-D Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain adaptation; object recognition; human action recognition	DOMAIN ADAPTATION; KERNEL; FEATURES	In this work, we propose a framework for recognizing RGB images or videos by learning from RGB-D training data that contains additional depth information. We formulate this task as a new unsupervised domain adaptation (UDA) problem, in which we aim to take advantage of the additional depth features in the source domain and also cope with the data distribution mismatch between the source and target domains. To handle the domain distribution mismatch, we propose to learn an optimal projection matrix to map the samples from both domains into a common subspace such that the domain distribution mismatch can be reduced. Such projection matrix can be effectively optimized by exploiting different strategies. Moreover, we also use different ways to utilize the additional depth features. To simultaneously cope with the above two issues, we formulate a unified learning framework called domain adaptation from multi-view to single-view (DAM2S). By defining various forms of regularizers in our DAM2S framework, different strategies can be readily incorporated to learn robust SVM classifiers for classifying the target samples, and three methods are developed under our DAM2S framework. We conduct comprehensive experiments for object recognition, cross-dataset and cross-view action recognition, which demonstrate the effectiveness of our proposed methods for recognizing RGB images and videos by learning from RGB-D data.	[Li, Wen; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland; [Chen, Lin] Amazon, 410 Terry Ave N, Seattle, WA 98109 USA; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia	Swiss Federal Institutes of Technology Domain; ETH Zurich; Amazon.com; University of Sydney	Xu, D (corresponding author), Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.	liwen@vision.ee.ethz.ch; gggchenlin@gmail.com; dongxudongxu@gmail.com; vangool@vision.ee.ethz.ch	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730; Li, Wen/0000-0002-5559-8594	CHIST-ERA project MUSTER	CHIST-ERA project MUSTER	This work was partially supported by CHIST-ERA project MUSTER.	Angeli Gabor, 2010, P 2010 C EMP METH NA, P502; [Anonymous], 2011, P 17 ACM SIGKDD INT; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717; Chen L, 2014, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2014.184; Chen L, 2013, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2013.344; Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6; Cortes C, 2011, LECT NOTES ARTIF INT, V6925, P308, DOI 10.1007/978-3-642-24412-4_25; Crammer K, 2008, J MACH LEARN RES, V9, P1757; Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding Z, 2014, AAAI CONF ARTIF INTE, P1192; Donahue J, 2014, PR MACH LEARN RES, V32; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Farquhar J., 2017, NEURAL INF PROCESS S, P355; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Yaroslav, 2015, ICML; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A, 2012, J MACH LEARN RES, V13, P723; Griffin G., 2007, ANN PHYS, P1; Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309; Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hoffman J, 2016, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2016.96; Jia CC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P87, DOI 10.1145/2647868.2654928; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Lai K, 2011, IEEE INT CONF ROBOT, P1817; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Li W, 2012, IEEE DATA MINING, P419, DOI 10.1109/ICDM.2012.78; Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Motiian S, 2016, PROC CVPR IEEE, P1496, DOI 10.1109/CVPR.2016.166; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ., 2008, PROC NATL CONF ARTIF, V8, P677; Sha, 2013, P INT C MACH LEARN; Sharmanska V, 2013, IEEE I CONF COMP VIS, P825, DOI 10.1109/ICCV.2013.107; Sindhwani V., 2005, P 22 INT C MACH LEAR, P824, DOI DOI 10.1145/1102351.1102455; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang ZH, 2015, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2015.7299131; Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574; Zhang QL, 2015, LECT NOTES COMPUT SC, V9003, P65, DOI 10.1007/978-3-319-16865-4_5	48	24	24	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					2030	2036		10.1109/TPAMI.2017.2734890	http://dx.doi.org/10.1109/TPAMI.2017.2734890			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28783624	Green Published			2022-12-18	WOS:000437271100018
J	Zhang, ZM; Liu, Y; Chen, X; Zhu, YJ; Cheng, MM; Saligrama, V; Torr, PHS				Zhang, Ziming; Liu, Yun; Chen, Xi; Zhu, Yanjun; Cheng, Ming-Ming; Saligrama, Venkatesh; Torr, Philip H. S.			Sequential Optimization for Efficient High-Quality Object Proposal Generation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Efficient high-quality object proposal; object detection; sequential minimization		We are motivated by the need for a generic object proposal generation algorithm which achieves good balance between object detection recall, proposal localization quality and computational efficiency. We propose a novel object proposal algorithm, BING ++, which inherits the virtue of good computational efficiency of BING [1] but significantly improves its proposal localization quality. At high level we formulate the problem of object proposal generation from a novel probabilistic perspective, based on which our BING++ manages to improve the localization quality by employing edges and segments to estimate object boundaries and update the proposals sequentially. We propose learning the parameters efficiently by searching for approximate solutions in a quantized parameter space for complexity reduction. We demonstrate the generalization of BING++ with the same fixed parameters across different object classes and datasets. Empirically our BING++ can run at half speed of BING on CPU, but significantly improve the localization quality by 18.5 and 16.7 percent on both VOC2007 and Microhsoft COCO datasets, respectively. Compared with other state-of-the-art approaches, BING++ can achieve comparable performance, but run significantly faster.	[Zhang, Ziming] Mitsubishi Elect Res Labs MERL, Cambridge, MA 02139 USA; [Liu, Yun; Cheng, Ming-Ming] Nankai Univ, CCCE & CS, Tianjin 300071, Peoples R China; [Chen, Xi; Zhu, Yanjun] Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Hubei, Peoples R China; [Saligrama, Venkatesh] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA; [Torr, Philip H. S.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Nankai University; Huazhong University of Science & Technology; Boston University; University of Oxford	Zhang, ZM (corresponding author), Mitsubishi Elect Res Labs MERL, Cambridge, MA 02139 USA.	zzhang@merl.com; nk12csly@mail.nankai.edu.cn; chenxihust@hust.edu.cn; yjzhu@hust.edu.cn; cmm@nankai.edu.cn; srv@bu.edu; philip.torr@eng.ox.ac.uk	Cheng, Ming-Ming/A-2527-2009; Zhang, ziming/HGA-8604-2022	Cheng, Ming-Ming/0000-0001-5550-8758; Saligrama, Venkatesh/0000-0002-0675-2268	EPSRC [EP/N019474/1, EP/I001107/2] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/I001107/2, EP/N019474/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Ahmed F, 2015, IEEE I CONF COMP VIS, P1850, DOI 10.1109/ICCV.2015.215; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Blaschko MB, 2013, LECT NOTES COMPUT SC, V7944, P408; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; CASTANON G, 2015, P 23 ACM INT C MULT, P391, DOI DOI 10.1145/2733373.2806229; Chen XZ, 2015, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2015.7298874; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cook W., 1998, WILEY INTERSCIENCE S, V605, P1; Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Forsyth David A., 1996, FINDING PICTURES OBJ; Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889; He SF, 2015, IEEE I CONF COMP VIS, P280, DOI 10.1109/ICCV.2015.40; Hosang J., 2014, BMVC; Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Humayun A, 2015, IEEE I CONF COMP VIS, P1600, DOI 10.1109/ICCV.2015.187; Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50; Jie Z., 2016, ARXIV160104798; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Lee T., 2015, ICCV; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lu CW, 2015, IEEE I CONF COMP VIS, P2021, DOI 10.1109/ICCV.2015.234; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Nowozin S, 2014, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2014.77; Qi YG, 2015, PROC CVPR IEEE, P1856, DOI 10.1109/CVPR.2015.7298795; Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Ren C. Y., 2015, ARXIV E PRINTS; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Teuber HL, 1955, ANNU REV PSYCHOL, V6, P267, DOI 10.1146/annurev.ps.06.020155.001411; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang C., 2015, CVPR; Wei Y., 2014, ARXIV PREPRINT ARXIV; Xiao Y, 2015, PROC CVPR IEEE, P778, DOI 10.1109/CVPR.2015.7298678; Yanulevskaya V, 2014, PROC CVPR IEEE, P3134, DOI 10.1109/CVPR.2014.401; Zhang Z., 2013, EFFICIENT OBJECT DET; Zhang  Z., 2014, P EUR C COMP VIS WOR, P122; Zhang ZM, 2015, IEEE I CONF COMP VIS, P3916, DOI 10.1109/ICCV.2015.446; Zhang ZM, 2016, IEEE T PATTERN ANAL, V38, P102, DOI 10.1109/TPAMI.2015.2430348; Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411; Zhao Q., 2014, BMVC; ZHENG SH, 2013, P 10 IEEE INT C WORK, V84, P1; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	59	24	25	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1209	1223		10.1109/TPAMI.2017.2707492	http://dx.doi.org/10.1109/TPAMI.2017.2707492			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28541893	Green Submitted			2022-12-18	WOS:000428901200015
J	Xing, JL; Niu, ZH; Huang, JS; Hu, WM; Zhou, X; Yan, SC				Xing, Junliang; Niu, Zhiheng; Huang, Junshi; Hu, Weiming; Zhou, Xi; Yan, Shuicheng			Towards Robust and Accurate Multi-View and Partially-Occluded Face Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face alignment; dictionary learning; sparse representation; appearance-shape modeling	RECOGNITION; MODELS	Face alignment acts as an important task in computer vision. Regression-based methods currently dominate the approach to solving this problem, which generally employ a series of mapping functions from the face appearance to iteratively update the face shape hypothesis. One keypoint here is thus how to perform the regression procedure. In this work, we formulate this regression procedure as a sparse coding problem. We learn two relational dictionaries, one for the face appearance and the other one for the face shape, with coupled reconstruction coefficient to capture their underlying relationships. To deploy this model for face alignment, we derive the relational dictionaries in a stage-wised manner to perform close-loop refinement of themselves,i.e., the face appearance dictionary is first learned from the face shape dictionary and then used to update the face shape hypothesis, and the updated face shape dictionary from the shape hypothesis is in return used to refine the face appearance dictionary. To improve the model accuracy, we extend this model hierarchically from the whole face shape to face part shapes, thus both the global and local view variations of a face are captured. To locate facial landmarks under occlusions, we further introduce an occlusion dictionary into the face appearance dictionary to recover face shape from partially occluded face appearance. The occlusion dictionary is learned in a data driven manner from background images to represent a set of elemental occlusion patterns, a sparse combination of which models various practical partial face occlusions. By integrating all these technical innovations, we obtain a robust and accurate approach to locate facial landmarks under different face views and possibly severe occlusions for face images in the wild. Extensive experimental analyses and evaluations on different benchmark datasets, as well as two new datasets built by ourselves, have demonstrated the robustness and accuracy of our proposed model, especially for face images with large view variations and/or severe occlusions.	[Xing, Junliang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Niu, Zhiheng] Delphi Deutschland GMBH, Adv Engn Elect & Safety, Delphipl 1, D-42119 Wuppertal, North Rhine Wes, Germany; [Huang, Junshi; Yan, Shuicheng] AI Inst Qihoo 360 Co, Jiuxianqiao Rd, Beijing 100015, Peoples R China; [Hu, Weiming] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Automat,Natl Lab Pattern Recognit, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China; [Zhou, Xi] Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Intelligent Media Tech Res Ctr, Chongqing 400714, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Chinese Academy of Sciences; Institute of Automation, CAS; Delphi; Chinese Academy of Sciences; Institute of Automation, CAS; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Chongqing Institute of Green & Intelligent Technology, CAS; National University of Singapore	Xing, JL (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	jlxing@nlpr.ia.ac.cn; niuzhiheng@gmail.com; huangjunshi@360.cn; wmhu@nlpr.ia.ac.cn; zhouxi@cigit.ac.cn; eleyans@nus.edu.sg	Xing, Junliang/HGE-9630-2022; Yan, Shuicheng/HCI-1431-2022	Xing, Junliang/0000-0001-6801-0510; 	973 basic research program of China [2014CB349303]; Natural Science Foundation of China [61672519, 61303178, 61472421, U1636218]; Strategic Priority Research Program of the CAS [XDB02070003]	973 basic research program of China(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of the CAS	The authors would like to thank the associate editor and the reviewers for their constructive comments and suggestions. This work is partly supported by the Natural Science Foundation of China (Grant No. 61672519, 61303178, 61472421, and U1636218), the 973 basic research program of China (Grant No. 2014CB349303), and the Strategic Priority Research Program of the CAS (Grant No. XDB02070003).	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2013, 300 FACE IN THE WILD; [Anonymous], 2011, BIOID DATASET; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Chen D., 2014, LECT NOTES COMPUT SC, P109, DOI DOI 10.1007/978-3-319-10599-4; Cootes T. F., 2012, LECT NOTES COMPUT SC, P278, DOI DOI 10.1007/978-3-642-33786-4; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2007, P BMVC, P880; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618; Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J, 2010, J MACH LEARN RES, V11, P19; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Saragih J, 2007, IEEE I CONF COMP VIS, P2173; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Smith BM, 2012, LECT NOTES COMPUT SC, V7574, P43, DOI 10.1007/978-3-642-33712-3_4; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xing JL, 2014, PROC CVPR IEEE, P1829, DOI 10.1109/CVPR.2014.236; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yan SC, 2003, INT J IMAG SYST TECH, V13, P106, DOI 10.1002/ima.10039; Zhang J., 2014, INT J DISTRIB SENS N, V2014, P1, DOI DOI 10.1371/J0URNAL.P0NE.0110734; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhao XW, 2012, LECT NOTES COMPUT SC, V7573, P616, DOI 10.1007/978-3-642-33709-3_44; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	48	24	27	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					987	1001		10.1109/TPAMI.2017.2697958	http://dx.doi.org/10.1109/TPAMI.2017.2697958			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28459684				2022-12-18	WOS:000426687100016
J	Hua, G; Long, CJ; Yang, M; Gao, Y				Hua, Gang; Long, Chengjiang; Yang, Ming; Gao, Yan			Collaborative Active Visual Recognition from Crowds: A Distributed Ensemble Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active learning; multiple oracles; collaborative learning; ensemble kernel machine; label quality; detect irresponsible labelers	MACHINE	Active learning is an effective way of engaging users to interactively train models for visual recognition more efficiently. The vast majority of previous works focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. We present a collaborative computational model for active learning with multiple human oracles, the input from whom may possess different levels of noises. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our experiments with both simulated and real crowd-sourced noisy labels demonstrate the efficacy of our model.	[Hua, Gang] Microsoft Res Asia, Beijing 100080, Peoples R China; [Long, Chengjiang] Kitware Inc, Clifton Pk, NY 12065 USA; [Yang, Ming] Horizon Robot Inc, Beijing 100080, Peoples R China; [Yang, Ming] Horizon Robot Inc, Shenzhen 100080, Peoples R China; [Gao, Yan] Amazon, Seattle, WA 98109 USA	Microsoft; Microsoft Research Asia; Amazon.com	Hua, G (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.	ganghua@gmail.com; chengjiang.long@kitware.com; ming.yang@horizon-robotics.com; beargaoyan@gmail.com	Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Yang, Ming/0000-0003-1691-6817	Google Research Faculty Award; GH's start-up funds from Stevens Institute of Technology; China National Natural Science Foundation [61228303, 61629301]; US National Science Foundation [IIS 1350763]	Google Research Faculty Award(Google Incorporated); GH's start-up funds from Stevens Institute of Technology; China National Natural Science Foundation(National Natural Science Foundation of China (NSFC)); US National Science Foundation(National Science Foundation (NSF))	This work is partly supported by US National Science Foundation Grant IIS 1350763, China National Natural Science Foundation Grant 61228303 and 61629301, GH's start-up funds from Stevens Institute of Technology, a Google Research Faculty Award, a gift grant from Microsoft Research, and a gift grant from NEC Labs America.	Ambati V, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2169; Balean Maria-Florina, 2006, P 23 INT C MACH LEAR, P65, DOI DOI 10.1145/1143844.1143853]; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Branson S, 2010, LECT NOTES COMPUT SC, V6314, P438, DOI 10.1007/978-3-642-15561-1_32; Chen S, 2010, AAAI CONF ARTIF INTE, P419; Dekel O, 2009, P 26 ANN INT C MACH, P233; Dekel O., 2009, COLT; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donmez P, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P259; Donmez Pinar, 2010, P SIAM INT C DAT MIN, P826; Ebert S, 2012, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2012.6248108; Guyon I, 1993, ADV NEURAL INFORM PR, P147; Hoi S.C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587351; Hua G, 2013, IEEE I CONF COMP VIS, P1209, DOI 10.1109/ICCV.2013.153; Ipeirotis PG, 2014, DATA MIN KNOWL DISC, V28, P402, DOI 10.1007/s10618-013-0306-1; Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81; Kapoor A, 2007, IEEE I CONF COMP VIS, P134; Karger David R., 2013, Performance Evaluation Review, V41, P81; Kovashka A, 2011, IEEE I CONF COMP VIS, P1403, DOI 10.1109/ICCV.2011.6126395; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laws F., 2011, P C EMPIRICAL METHOD, P1546; Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477; Liyue Zhao, 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P728, DOI 10.1109/PASSAT/SocialCom.2011.193; Loy CC, 2012, PROC CVPR IEEE, P1560, DOI 10.1109/CVPR.2012.6247847; Parikh D, 2012, IEEE T PATTERN ANAL, V34, P1978, DOI 10.1109/TPAMI.2011.276; Parikh D, 2011, IEEE I CONF COMP VIS, P519, DOI 10.1109/ICCV.2011.6126283; Parikh D, 2011, PROC CVPR IEEE, P1425, DOI 10.1109/CVPR.2011.5995450; Parikh D, 2010, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2010.5539920; Patterson G., 2013, P NIPSW; Raykar V. C., 2009, P 26 ANN INT C MACH, P889, DOI DOI 10.1145/1553374.1553488; Raykar VC, 2012, J MACH LEARN RES, V13, P491; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Sheng Victor S, 2008, P 14 ACM SIGKDD INT, P614, DOI DOI 10.1145/1401890.1401965; Vempaty A, 2014, IEEE J-STSP, V8, P667, DOI 10.1109/JSTSP.2014.2316116; Vezhnevets A, 2012, PROC CVPR IEEE, P3162, DOI 10.1109/CVPR.2012.6248050; Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2011.5995430; von Ahn L., 2006, P SIGCHI C HUMAN FAC, P55, DOI DOI 10.1145/1124772.1124782; Von Ahn Luis, 2004, P SIGCHI C HUM FACT, P319, DOI DOI 10.1145/985692.985733; Wah C, 2011, IEEE I CONF COMP VIS, P2524, DOI 10.1109/ICCV.2011.6126539; Welinder P., 2010, 2010 IEEE COMPUTER S, P25, DOI [10.1109/CVPRW.2010.5543189, DOI 10.1109/CVPRW.2010.5543189]; Yan Y., 2012, P ART INT STAT, P1350; Yan Y., 2010, PMLR P MACHINE LEARN, V9, P932; Yan Y., 2011, ICML, V11, P1161; Yan Y, 2014, ANN ALLERTON CONF, P385, DOI 10.1109/ALLERTON.2014.7028481; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236; Zitnick CL, 2012, PROC CVPR IEEE, P622, DOI 10.1109/CVPR.2012.6247729	47	24	24	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					582	594		10.1109/TPAMI.2017.2682082	http://dx.doi.org/10.1109/TPAMI.2017.2682082			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28320651	hybrid			2022-12-18	WOS:000424465900006
J	Painsky, A; Rosset, S				Painsky, Amichai; Rosset, Saharon			Cross-Validated Variable Selection in Tree-Based Methods Improves Predictive Performance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification and regression trees; random forests; gradient boosting	CLASSIFICATION	Recursive partitioning methods producing tree-like models are a long standing staple of predictive modeling. However, a fundamental flaw in the partitioning (or splitting) rule of commonly used tree building methods precludes them from treating different types of variables equally. This most clearly manifests in these methods' inability to properly utilize categorical variables with a large number of categories, which are ubiquitous in the new age of big data. We propose a framework to splitting using leave-one-out (LOO) cross validation (CV) for selecting the splitting variable, then performing a regular split (in our case, following CART's approach) for the selected variable. The most important consequence of our approach is that categorical variables with many categories can be safely used in tree building and are only chosen if they contribute to predictive power. We demonstrate in extensive simulation and real data analysis that our splitting approach significantly improves the performance of both single tree models and ensemble methods that utilize trees. Importantly, we design an algorithm for LOO splitting variable selection which under reasonable assumptions does not substantially increase the overall computational complexity compared to CART for two-class classification.	[Painsky, Amichai; Rosset, Saharon] Tel Aviv Univ, Sch Math Sci, IL-6997801 Ramat Aviv, Israel	Tel Aviv University	Painsky, A (corresponding author), Tel Aviv Univ, Sch Math Sci, IL-6997801 Ramat Aviv, Israel.	amichaip@eng.tau.ac.il; saharon@post.tau.ac.il			Israel Science Foundation [1487/12]; Israeli Ministry of Immigration	Israel Science Foundation(Israel Science Foundation); Israeli Ministry of Immigration	This research was partially supported by Israel Science Foundation grant 1487/12 and by a returning scientist fellowship from the Israeli Ministry of Immigration to Amichai Painsky. The authors thank the associate editor, the anonymous reviewers, Jerry Friedman and Liran Katzir for useful comments and suggestions.	[Anonymous], 2014, INT STAT REV, DOI DOI 10.1111/insr.12016; Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054; Bengio Y, 2004, J MACH LEARN RES, V5, P1089; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2017, CLASSIFICATION REGRE; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; Caruana R, 2006, P 23 INT C MACH LEAR, P161, DOI [DOI 10.1145/1143844.1143865, 10.1145/1143844.1143865]; Cawley GC, 2010, J MACH LEARN RES, V11, P2079; Demsar J, 2006, J MACH LEARN RES, V7, P1; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; Elisseeff A., 2003, NATO SCI SER SUBSER, V190, P111; Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P152; Frank E., 1996, 9631 U WAIK; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T, 2009, ELEMENTS STAT LEARNI; Hothorn T, 2006, J COMPUT GRAPH STAT, V15, P651, DOI 10.1198/106186006X133933; Kass, 1980, APPL STAT, V29, P119, DOI [10.2307/2986296, DOI 10.2307/2986296]; Kim H, 2003, J COMPUT GRAPH STAT, V12, P512, DOI 10.1198/1061860032049; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; King R., 2000, APPL ARTIF INTELL, V9, DOI 10.1080/08839519508945477; Kohavi R., 1995, INT JOINT C ART INT, V14, P1137, DOI DOI 10.1067/MOD.2000.109031; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Loh WY, 2002, STAT SINICA, V12, P361; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Quinlan J. R., 2004, DATA MINING TOOLS SE; Sabato S, 2008, J MACH LEARN RES, V9, P1083; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25	29	24	24	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2142	2153		10.1109/TPAMI.2016.2636831	http://dx.doi.org/10.1109/TPAMI.2016.2636831			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114007	Green Submitted			2022-12-18	WOS:000412028600003
J	Pinheiro, MA; Kybic, J; Fua, P				Pinheiro, Miguel Amavel; Kybic, Jan; Fua, Pascal			Geometric Graph Matching Using Monte Carlo Tree Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geometric graph matching; Monte Carlo tree search; image registration; curve descriptor	IMAGE REGISTRATION; ALGORITHM; ROBUST; ASSIGNMENT; FEATURES; 2D	We present an efficient matching method for generalized geometric graphs. Such graphs consist of vertices in space connected by curves and can represent many real world structures such as road networks in remote sensing, or vessel networks in medical imaging. Graph matching can be used for very fast and possibly multimodal registration of images of these structures. We formulate the matching problem as a single player game solved using Monte Carlo Tree Search, which automatically balances exploring new possible matches and extending existing matches. Our method can handle partial matches, topological differences, geometrical distortion, does not use appearance information and does not require an initial alignment. Moreover, our method is very efficient-it can match graphs with thousands of nodes, which is an order of magnitude better than the best competing method, and the matching only takes a few seconds.	[Pinheiro, Miguel Amavel; Kybic, Jan] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, Prague 16636 6, Czech Republic; [Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland	Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Pinheiro, MA (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, Prague 16636 6, Czech Republic.	amavemig@cmp.felk.cvut.cz; kybic@fel.cvut.cz; pascal.fua@epfl.ch	Jan, Kybic/K-8071-2017		Czech Science Foundation [14-21421S]; Fundacao para a Ciencia e Tecnologia [SFRH/BD/77134/2011]	Czech Science Foundation(Grant Agency of the Czech Republic); Fundacao para a Ciencia e Tecnologia(Portuguese Foundation for Science and TechnologyEuropean Commission)	This work has been supported by the Czech Science Foundation project 14-21421S and by the Ph.D. grant SFRH/BD/77134/2011 of the Fundacao para a Ciencia e Tecnologia.	Al-Khaiyat M., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P174; Ascher H, 1983, NATO ASI SERIES SERI; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BORUVKA O, 1926, PRACE MORAVSKE PRIRO, V3, P37; Browne CB, 2012, IEEE T COMP INTEL AI, V4, P1, DOI 10.1109/TCIAIG.2012.2186810; Brubaker MA, 2013, PROC CVPR IEEE, P3057, DOI 10.1109/CVPR.2013.393; Buchin K, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P645; Can A, 2002, IEEE T PATTERN ANAL, V24, P347, DOI 10.1109/34.990136; Charnoz A, 2005, LECT NOTES COMPUT SC, V3434, P183; Chaslot GMJB, 2008, LECT NOTES COMPUT SC, V5131, P60, DOI 10.1007/978-3-540-87608-3_6; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Choi S., 1997, P BRIT MACH VIS C, V24, P271; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; COUR T, 2006, ADV NEURAL INFORM PR, V19, P313; Cui M, 2009, PATTERN RECOGN LETT, V30, P1, DOI 10.1016/j.patrec.2008.08.013; Deng K, 2010, J BIOMED IMAGING, V13, P14, DOI DOI 10.1155/2010/906067; Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022; Enqvist O, 2009, IEEE I CONF COMP VIS, P1295, DOI 10.1109/ICCV.2009.5459319; Erickson J, 2005, COMP GEOM-THEOR APPL, V31, P101, DOI 10.1016/j.comgeo.2004.08.004; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frenkel M, 2003, LECT NOTES COMPUT SC, V2683, P35; Fu HJ, 2013, IET COMPUT VIS, V7, P279, DOI 10.1049/iet-cvi.2012.0123; Glowacki P, 2014, PROC CVPR IEEE, P3035, DOI 10.1109/CVPR.2014.388; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Graham MW, 2006, I S BIOMED IMAGING, P109; Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80; Holtmaat A, 2013, EUR J PHARMACOL, V719, P128, DOI 10.1016/j.ejphar.2013.07.020; Kolar R, 2013, IMAGING SCI J, V61, P369, DOI 10.1179/1743131X11Y.0000000065; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Li S. Z., 1993, P 1 AS C COMP VIS OS, P454; Longair MH, 2011, BIOINFORMATICS, V27, P2453, DOI 10.1093/bioinformatics/btr390; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913; Pinheiro MA, 2015, IEEE IMAGE PROC, P3145, DOI 10.1109/ICIP.2015.7351383; Pinheiro MA, 2014, LECT NOTES COMPUT SC, V8814, P3, DOI 10.1007/978-3-319-11758-4_1; Pinheiro Miguel Amavel, 2013, Inf Process Med Imaging, V23, P572, DOI 10.1007/978-3-642-38868-2_48; PISUPATI C, 1996, P 12 ANN S COMP GEOM, P419, DOI DOI 10.1145/237218.237421.; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; Sebastian TB, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P70, DOI 10.1109/MMBIA.2000.852362; Serradell E, 2015, IEEE T PATTERN ANAL, V37, P625, DOI 10.1109/TPAMI.2014.2343235; Serradell E, 2012, PROC SPIE, V8314, DOI 10.1117/12.910573; Smeets D., 2010, WORKSH PULM IM AN, P61; Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603; Suh Y, 2012, LECT NOTES COMPUT SC, V7574, P624, DOI 10.1007/978-3-642-33712-3_45; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; Tordoff B, 2002, LECT NOTES COMPUT SC, V2350, P82; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Turetken E, 2012, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2012.6247722; Unser M, 2002, PROC SPIE, V4684, P225, DOI 10.1117/12.467162; Wang ZH, 2010, LECT NOTES COMPUT SC, V5996, P448; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	62	24	25	3	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2171	2185		10.1109/TPAMI.2016.2636200	http://dx.doi.org/10.1109/TPAMI.2016.2636200			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114003				2022-12-18	WOS:000412028600005
J	Peharz, R; Gens, R; Pernkopf, F; Domingos, P				Peharz, Robert; Gens, Robert; Pernkopf, Franz; Domingos, Pedro			On the Latent Variable Interpretation in Sum-Product Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sum-product networks; latent variables; mixture models; expectation-maximization; MPE inference		One of the central themes in Sum-Product networks (SPNs) is the interpretation of sum nodes as marginalized latent variables (LVs). This interpretation yields an increased syntactic or semantic structure, allows the application of the EM algorithm and to efficiently perform MPE inference. In literature, the LV interpretation was justified by explicitly introducing the indicator variables corresponding to the LVs' states. However, as pointed out in this paper, this approach is in conflict with the completeness condition in SPNs and does not fully specify the probabilistic model. We propose a remedy for this problem by modifying the original approach for introducing the LVs, which we call SPN augmentation. We discuss conditional independencies in augmented SPNs, formally establish the probabilistic interpretation of the sum-weights and give an interpretation of augmented SPNs as Bayesian networks. Based on these results, we find a sound derivation of the EM algorithm for SPNs. Furthermore, the Viterbi-style algorithm for MPE proposed in literature was never proven to be correct. We show that this is indeed a correct algorithm, when applied to selective SPNs, and in particular when applied to augmented SPNs. Our theoretical results are confirmed in experiments on synthetic data and 103 real-world datasets.	[Peharz, Robert] Med Univ Graz, Inst Physiol IDN, A-8036 Graz, Austria; [Peharz, Robert] BioTechMed Graz, A-8036 Graz, Austria; [Gens, Robert; Domingos, Pedro] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98105 USA; [Pernkopf, Franz] Graz Univ Technol, Signal Proc & Speech Commun Lab, A-8010 Graz, Austria	Medical University of Graz; University of Washington; University of Washington Seattle; Graz University of Technology	Peharz, R (corresponding author), Med Univ Graz, Inst Physiol IDN, A-8036 Graz, Austria.; Peharz, R (corresponding author), BioTechMed Graz, A-8036 Graz, Austria.	robert.peharz@gmail.com; rcg@cs.washington.edu; pernkopf@tugraz.at; pedrod@cs.washington.edu		Peharz, Robert/0000-0002-8644-9655	Austrian Science Fund (FWF) [P25244-N15, P27803-N15]; ONR [N00014-16-1-2697]; AFRL [FA8750-13-2-0019]; Austrian Science Fund (FWF) [P 25244] Funding Source: researchfish	Austrian Science Fund (FWF)(Austrian Science Fund (FWF)); ONR(Office of Naval Research); AFRL(United States Department of DefenseUS Air Force Research Laboratory); Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	We would like to thank the anonymous reviewers for their constructive comments. This work was supported by the Austrian Science Fund (FWF): P25244-N15 and Austrian Science Fund (FWF): P27803-N15. This research was partly funded by ONR grant N00014-16-1-2697 and AFRL contract FA8750-13-2-0019.	Adel T, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P32; Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816; [Anonymous], 2015, THESIS GRAZ U TECHNO; [Anonymous], 2002, P EIGHTS INT C PRINC; Bengio, 2011, ADV NEURAL INFORM PR, P666, DOI DOI 10.5555/2986459.2986534; Bodlaender HL, 2002, FR ART INT, V77, P675; Boutilier C, 1996, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P115; Cheng W., 2014, 15 ANN C INT SPEECH, P2098; Darwiche A, 2001, J ACM, V48, P608, DOI 10.1145/502090.502091; Darwiche A, 2002, J ARTIF INTELL RES, V17, P229, DOI 10.1613/jair.989; Darwiche A, 2003, J ACM, V50, P280, DOI 10.1145/765568.765570; Darwiche A, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P284; Darwiche A., 2014, MODELING REASONING B; de Campos Cassio P, 2011, P 22 INT JOINT C ART, V11, P2100; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dennis A., 2012, ADV NEURAL INFORM PR, P2042; Domingos P, 2008, P 24 C UNC ART INT, P383; Friesen AL, 2016, PR MACH LEARN RES, V48; Gens R., 2012, 26 ADV NEURAL INFORM, P3239; Gens R., 2013, 30 INT C MACHINE LEA, P873; Ghahramani Z., 1994, P ADV NEUR INF PROC, P120; Johnson N., 1994, WILEY SERIES PROBABI, V1; Koller D., 2009, PROBABILISTIC GRAPHI; Kwisthout J, 2011, INT J APPROX REASON, V52, P1452, DOI 10.1016/j.ijar.2011.08.003; Lee S.-W., 2014, P WORKSH LEARN TRACT; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Lowd D., 2013, P 16 INT C ART INT S, P406; Park JD, 2004, J ARTIF INTELL RES, V21, P101; Pearl Judea, 2014, PROBABILISTIC REASON; Peharz Robert, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3699, DOI 10.1109/ICASSP.2014.6854292; Peharz Robert, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P612, DOI 10.1007/978-3-642-40991-2_39; Peharz R., 2014, P ICML WORKSH LEARN; Peharz R, 2015, JMLR WORKSH CONF PRO, V38, P744; Poon H., 2011, P 27 C UNC ART INT, P337, DOI DOI 10.1109/ICCVW.2011; Rooshenas A, 2014, PR MACH LEARN RES, V32; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Trapp M., 2016, P NIPS WORKSH PRACT; Vergari A, 2015, LECT NOTES ARTIF INT, V9285, P343, DOI 10.1007/978-3-319-23525-7_21; Zhao H., 2016, UNIFIED APPROACH LEA; Zhao H, 2015, PR MACH LEARN RES, V37, P116; Zohrer M, 2015, IEEE-ACM T AUDIO SPE, V23, P2398, DOI 10.1109/TASLP.2015.2470560	41	24	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					2030	2044		10.1109/TPAMI.2016.2618381	http://dx.doi.org/10.1109/TPAMI.2016.2618381			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27875213	Bronze, Green Submitted			2022-12-18	WOS:000408807600010
J	Wang, L; Hua, G; Sukthankar, R; Xue, JR; Niu, ZX; Zheng, NN				Wang, Le; Hua, Gang; Sukthankar, Rahul; Xue, Jianru; Niu, Zhenxing; Zheng, Nanning			Video Object Discovery and Co-Segmentation with Extremely Weak Supervision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video object discovery; video object co-segmentation; spatio-temporal auto-context model; Spatial-MILBoost	CATEGORIZED OBJECTS; IMAGE; EXTRACTION; COSEGMENTATION; RECOGNITION	We present a spatio-temporal energy minimization formulation for simultaneous video object discovery and co-segmentation across multiple videos containing irrelevant frames. Our approach overcomes a limitation that most existing video co-segmentation methods possess, i.e., they perform poorly when dealing with practical videos in which the target objects are not present in many frames. Our formulation incorporates a spatio-temporal auto-context model, which is combined with appearance modeling for superpixel labeling. The superpixel-level labels are propagated to the frame level through a multiple instance boosting algorithm with spatial reasoning, based on which frames containing the target object are identified. Our method only needs to be bootstrapped with the frame-level labels for a few video frames (e.g., usually 1 to 3) to indicate if they contain the target objects or not. Extensive experiments on four datasets validate the efficacy of our proposed method: 1) object segmentation from a single video on the SegTrack dataset, 2) object co-segmentation from multiple videos on a video co-segmentation dataset, and 3) joint object discovery and co-segmentation from multiple videos containing irrelevant frames on the MOViCS dataset and XJTU-Stevens, a new dataset that we introduce in this paper. The proposed method compares favorably with the state-of-the-art in all of these experiments.	[Wang, Le; Xue, Jianru; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China; [Hua, Gang] Microsoft Res, Beijing 100080, Peoples R China; [Sukthankar, Rahul] Google Res, New York, NY 10011 USA; [Niu, Zhenxing] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China	Xi'an Jiaotong University; Microsoft; Google Incorporated; Xidian University	Wang, L (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.	lewang@mail.xjtu.edu.cn; ganghua@gmail.com; rahulsukthankar@gmail.com; jrxue@mail.xjtu.edu.cn; zxniu@xidian.edu.cn; nnzheng@mail.xjtu.edu.cn			NSFC [61231018, 61629301, 61273252, 61503296, 61672402]; National Key Research and Development Plan [2016YFB1001004]; China Postdoctoral Science Foundation [2015M572563]; Fundamental Research Funds for the Central Universities [XJJ2015066]; China Scholarship Council	NSFC(National Natural Science Foundation of China (NSFC)); National Key Research and Development Plan; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); China Scholarship Council(China Scholarship Council)	This work was supported partly by NSFC Grants 61231018, 61629301, and 61273252, and National Key Research and Development Plan 2016YFB1001004. Le Wang was supported by NSFC Grant 61503296, China Postdoctoral Science Foundation Grant 2015M572563, the Fundamental Research Funds for the Central Universities Grant XJJ2015066, and China Scholarship Council. Zhenxing Niu was supported by NSFC Grant 61672402.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Avidan S, 2006, LECT NOTES COMPUT SC, V3954, P386; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Chen D.-J., 2012, P ACM MULT, P805, DOI DOI 10.1145/2393347.2396317; Chiu WC, 2013, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2013.48; Cour T, 2005, PROC CVPR IEEE, P1124; Dai JF, 2013, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2013.165; Faktor A, 2014, IEEE T PATTERN ANAL, V36, P1092, DOI 10.1109/TPAMI.2013.251; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fu HZ, 2014, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2014.405; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Guo JM, 2013, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2013.278; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756; Kwak S, 2015, IEEE I CONF COMP VIS, P3173, DOI 10.1109/ICCV.2015.363; Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Liu D., 2007, COMP VIS PATT REC 20, P1; Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31; Lou ZY, 2014, IEEE T MULTIMEDIA, V16, P2110, DOI 10.1109/TMM.2014.2363936; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7; Rubio J. C., 2012, P AS C COMP VIS, P13, DOI DOI 10.1007/978-3-642-37444-9; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Tao WB, 2015, IEEE T IMAGE PROCESS, V24, P943, DOI 10.1109/TIP.2014.2387384; Tiburzi F, 2008, IEEE IMAGE PROC, P17, DOI 10.1109/ICIP.2008.4711680; Tsai D., 2010, P BRIT MACH VIS C, P56; Tu Z., 2008, IEEE C COMP VIS PATT, P1; Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8; Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34; Viola P., 2005, ADV NEURAL INFORM PR, P1417; Wang C, 2014, IEEE T MULTIMEDIA, V16, P903, DOI 10.1109/TMM.2014.2306393; Wang F, 2014, PROC CVPR IEEE, P3142, DOI 10.1109/CVPR.2014.402; Wang HX, 2014, WIRES DATA MIN KNOWL, V4, P24, DOI 10.1002/widm.1110; Wang L, 2014, IEEE T IMAGE PROCESS, V23, P4070, DOI 10.1109/TIP.2014.2339196; Wang L, 2014, LECT NOTES COMPUT SC, V8692, P640, DOI 10.1007/978-3-319-10593-2_42; Wang L, 2012, INT C PATT RECOG, P3309; Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231; Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550; Xia Y, 2015, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2015.177; Xue JR, 2013, PATTERN RECOGN, V46, P2874, DOI 10.1016/j.patcog.2013.03.028; Yang J, 2016, IEEE T CIRC SYST VID, V26, P1070, DOI 10.1109/TCSVT.2015.2433171; Zhang D, 2014, LECT NOTES COMPUT SC, V8695, P551, DOI 10.1007/978-3-319-10584-0_36; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhao GQ, 2013, PROC CVPR IEEE, P1602, DOI 10.1109/CVPR.2013.210	63	24	26	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					2074	2088		10.1109/TPAMI.2016.2612187	http://dx.doi.org/10.1109/TPAMI.2016.2612187			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	28113741				2022-12-18	WOS:000408807600013
J	Wang, P; Shen, CH; van den Hengel, A; Torr, PHS				Wang, Peng; Shen, Chunhua; van den Hengel, Anton; Torr, Philip H. S.			Large-Scale Binary Quadratic Optimization Using SemidefiniteRelaxation and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary quadratic optimization; semidefinite programming; Markov random fields	SUPERLINEAR CONVERGENCE; MAP ESTIMATION; ALGORITHM; RANK; CUT; RELAXATIONS; DERIVATIVES; INEQUALITY; PROGRAMS; CONE	In computer vision, many problems can be formulated as binary quadratic programs (BQPs), which are in general NP hard. Finding a solution when the problem is of large size to be of practical interest typically requires relaxation. Semidefinite relaxation usually yields tight bounds, but its computational complexity is high. In this work, we present a semidefinite programming (SDP) formulation for BQPs, with two desirable properties. First, it produces similar bounds to the standard SDP formulation. Second, compared with the conventional SDP formulation, the proposed SDP formulation leads to a considerably more efficient and scalable dual optimization approach. We then propose two solvers, namely, quasi-Newton and smoothing Newton methods, for the simplified dual problem. Both of them are significantly more efficient than standard interior-point methods. Empirically the smoothing Newton solver is faster than the quasi-Newton solver for dense or medium-sized problems, while the quasi-Newton solver is preferable for large sparse/structured problems.	[Wang, Peng] Univ Adelaide, Adelaide, SA, Australia; [Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia; [van den Hengel, Anton] Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA, Australia; [Torr, Philip H. S.] Univ Oxford, Robot Res Grp, Oxford, England	University of Adelaide; University of Adelaide; University of Adelaide; University of Oxford	Wang, P (corresponding author), Univ Adelaide, Adelaide, SA, Australia.	p.wang@adelaide.edu.au; chunhua.shen@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au; philip.torr@eng.ox.ac.uk		Shen, Chunhua/0000-0002-8648-8718; van den Hengel, Anton/0000-0003-3027-8364	ARC Future Fellowship [FT120100969]; Data to Decisions Cooperative Research Centre, Australia; Engineering and Physical Sciences Research Council [EP/N019474/1, EP/I001107/2] Funding Source: researchfish; EPSRC [EP/I001107/2, EP/N019474/1] Funding Source: UKRI	ARC Future Fellowship(Australian Research Council); Data to Decisions Cooperative Research Centre, Australia(Australian GovernmentDepartment of Industry, Innovation and ScienceCooperative Research Centres (CRC) Programme); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We thank the anonymous reviewers for the constructive comments on Propositions 1 and 4. This work was in part supported by ARC Future Fellowship FT120100969, and the Data to Decisions Cooperative Research Centre, Australia. C. Shen is the corresponding author.	Anderson E., 1999, LAPACK USERS GUIDE, V9; Andres B., 2012, OPENGM C LIB DISCRET; [Anonymous], 2015, MAGMA 1 6 3; [Anonymous], [No title captured]; [Anonymous], 2015, PLASMA 2 7 1; BARVINOK AI, 1995, DISCRETE COMPUT GEOM, V13, P189, DOI 10.1007/BF02574037; Boyd S, 2004, CONVEX OPTIMIZATION; Broyden C. G., 1973, Journal of the Institute of Mathematics and Its Applications, V12, P223; Burer S, 2003, MATH PROGRAM, V95, P359, DOI 10.1007/S10107-002-0353-7; Chunhua Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2601, DOI 10.1109/CVPR.2011.5995447; Cour T, 2007, ARTIF INTELL, P75; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; d'Aspremont A., 2003, EE392O CLASS NOTES, VEE392o; DENNIS JE, 1974, MATH COMPUT, V28, P549, DOI 10.1090/S0025-5718-1974-0343581-1; Frostig Roy, 2014, P ADV NEUR INF PROC, P3077; Gao Y, 2009, SIAM J MATRIX ANAL A, V31, P1432, DOI 10.1137/080727075; Ghaddar B, 2011, SIAM J OPTIMIZ, V21, P391, DOI 10.1137/100802190; Givry S. D., 2014, C ROADEF 2014 BORD F; Globerson A., 2007, ADV NEUR INF PROC SY; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Gorelick L, 2012, LECT NOTES COMPUT SC, V7572, P583, DOI 10.1007/978-3-642-33718-5_42; Guattery S, 1998, SIAM J MATRIX ANAL A, V19, P701, DOI 10.1137/S0895479896312262; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; HARKER PT, 1990, MATH PROGRAM, V48, P161, DOI 10.1007/BF01582255; Heiler M, 2005, LECT NOTES COMPUT SC, V3663, P309; Helmberg C, 2000, SIAM J OPTIMIZ, V10, P673, DOI 10.1137/S1052623497328987; Helmberg C., 1998, TOPICS SEMIDEFINITE, V18, P197; Henrion D, 2012, INT SER OPER RES MAN, V166, P565, DOI 10.1007/978-1-4614-0769-0_20; Hernandez V, 2005, ACM T MATH SOFTWARE, V31, P351, DOI 10.1145/1089014.1089019; HIGHAM NJ, 1988, LINEAR ALGEBRA APPL, V103, P103, DOI 10.1016/0024-3795(88)90223-6; Huang Q., 2014, INT C MACH LEARN ICM; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Journee M, 2010, SIAM J OPTIMIZ, V20, P2327, DOI 10.1137/080731359; Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313; Keuchel J, 2003, IEEE T PATTERN ANAL, V25, P1364, DOI 10.1109/TPAMI.2003.1240111; Kim SY, 2003, COMPUT OPTIM APPL, V26, P143, DOI 10.1023/A:1025794313696; Kochenberger G, 2014, J COMB OPTIM, V28, P58, DOI 10.1007/s10878-014-9734-0; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Krislock N., 2013, MATH PROGRAM A; Kumar M. P., 2006, P IEEE C COMP VIS PA, P1045; Kumar MP, 2009, J MACH LEARN RES, V10, P71; Lang K., 2005, ADV NEURAL INFORM PR, P715; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; Lehoucq R. B., 2000, MATH COMPUT, V69, P1309; Lewis AS, 2001, SIAM J MATRIX ANAL A, V23, P368, DOI 10.1137/S089547980036838X; Lewis AS, 1996, MATH OPER RES, V21, P576, DOI 10.1287/moor.21.3.576; Li DA, 2010, OPTIMIZATION AND OPTIMAL CONTROL: THEORY AND APPLICATIONS, P199, DOI 10.1007/978-0-387-89496-6_11; Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368; Luo ZQ, 2010, IEEE SIGNAL PROC MAG, V27, P20, DOI 10.1109/MSP.2010.936019; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2057, DOI 10.1109/CVPR.2011.5995630; Malick J, 2007, J GLOBAL OPTIM, V39, P609, DOI 10.1007/s10898-007-9161-1; Malick J, 2009, SIAM J OPTIMIZ, V20, P336, DOI 10.1137/070704575; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MOSEK, 2013, MOSEK OPT TOOLB MATL; Nesterov Y., 1994, INTERIOR POINT POLYN, V13; Thoai NV, 2013, STUD COMPUT INTELL, V479, P3, DOI 10.1007/978-3-319-00293-4_1; Nowozin S, 2011, IEEE I CONF COMP VIS, P1668, DOI 10.1109/ICCV.2011.6126429; Olsson C., 2007, P IEEE C COMP VIS PA, p1{8, DOI DOI 10.1109/CVPR.2007.383202; Pataki G, 1998, MATH OPER RES, V23, P339, DOI 10.1287/moor.23.2.339; Qi LQ, 1997, OPER RES LETT, V20, P223, DOI 10.1016/S0167-6377(97)00012-6; Raj A, 2005, IEEE I CONF COMP VIS, P1048; Ravikumar Pradeep, 2006, P 23 INT C MACH LEAR, P737, DOI DOI 10.1145/1143844.1143937; Rockafellar RT., 1973, MATH PROGRAM, V5, P354, DOI [10.1007/BF01580138, DOI 10.1007/BF01580138]; Rother C., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383203; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; Sendov HS, 2007, LINEAR ALGEBRA APPL, V424, P240, DOI 10.1016/j.laa.2006.12.013; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sontag D., 2012, UAI, P795; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; Torr P.H.S., 2003, AISTATS; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; VANDERVORST HA, 1992, SIAM J SCI STAT COMP, V13, P631, DOI 10.1137/0913035; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wainwright MJ, 2004, ADV NEUR IN, V16, P369; Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004; Wang P., 2016, LARGE SCALE BINARY Q; Wang P, 2013, PROC CVPR IEEE, P1312, DOI 10.1109/CVPR.2013.173; Wang X., 2010, P 16 ACM SIGKDD INT, P563, DOI DOI 10.1145/1835804.1835877; Weiss Y., 2008, P UAI, P503; Wen ZW, 2010, MATH PROGRAM COMPUT, V2, P203, DOI 10.1007/s12532-010-0017-1; Wolkowicz H., 2000, HDB SEMIDEFINITE PRO; Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179; Zhao XY, 2010, SIAM J OPTIMIZ, V20, P1737, DOI 10.1137/080718206; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	90	24	24	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					470	485		10.1109/TPAMI.2016.2541146	http://dx.doi.org/10.1109/TPAMI.2016.2541146			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	26978557	Green Submitted			2022-12-18	WOS:000395555100005
J	Chakrabarti, A; Xiong, Y; Sun, B; Darrell, T; Scharstein, D; Zickler, T; Saenko, K				Chakrabarti, Ayan; Xiong, Ying; Sun, Baochen; Darrell, Trevor; Scharstein, Daniel; Zickler, Todd; Saenko, Kate			Modeling Radiometric Uncertainty for Vision with Tone-Mapped Color Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Radiometric calibration; camera response functions; tone-mapping; statistical models; signal-dependent noise; HDR imaging; image fusion; depth estimation; photometric stereo; image restoration; deblurring	CAMERA RESPONSE; SPACE	To produce images that are suitable for display, tone-mapping is widely used in digital cameras to map linear color measurements into narrow gamuts with limited dynamic range. This introduces non-linear distortion that must be undone, through a radiometric calibration process, before computer vision systems can analyze such photographs radiometrically. This paper considers the inherent uncertainty of undoing the effects of tone-mapping. We observe that this uncertainty varies substantially across color space, making some pixels more reliable than others. We introduce a model for this uncertainty and a method for fitting it to a given camera or imaging pipeline. Once fit, the model provides for each pixel in a tone-mapped digital photograph a probability distribution over linear scene colors that could have induced it. We demonstrate how these distributions can be useful for visual inference by incorporating them into estimation algorithms for a representative set of vision tasks.	[Chakrabarti, Ayan; Xiong, Ying; Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Sun, Baochen; Saenko, Kate] Univ Massachusetts Lowell, Lowell, MA 01854 USA; [Darrell, Trevor] Univ Calif Berkeley, CS Div, Berkeley, CA USA; [Scharstein, Daniel] Middlebury Coll, Middlebury, VT 05753 USA	Harvard University; University of Massachusetts System; University of Massachusetts Lowell; University of California System; University of California Berkeley	Chakrabarti, A (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.	ayanc@eecs.harvard.edu; yxiong@seas.harvard.edu; bsun@cs.uml.edu; trevor@eecs.berkeley.edu; schar@middlebury.edu; zickler@seas.harvard.edu; saenko@cs.uml.edu			National Science Foundation [IIS-0905243, IIS-0905647, IIS-1134072, IIS-1212798, IIS-1212928, IIS-0413169, IIS-1320715]; DARPA under the Mind's Eye program; DARPA under the MSEE program; Toyota	National Science Foundation(National Science Foundation (NSF)); DARPA under the Mind's Eye program; DARPA under the MSEE program; Toyota	The authors would like to thank the associate editor and reviewers for their comments. This material is based on work supported by the National Science Foundation under Grants no. IIS-0905243, IIS-0905647, IIS-1134072, IIS-1212798, IIS-1212928, IIS-0413169, and IIS-1320715; by DARPA under the Mind's Eye and MSEE programs; and by Toyota.	Ackermann J, 2012, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2012.6247684; Barsky S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P600, DOI 10.1109/ICCV.2001.937681; Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743; Chakrabarti A., 2009, P BRIT MACH VIS C; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen XG, 2012, LECT NOTES COMPUT SC, V7578, P333, DOI 10.1007/978-3-642-33786-4_25; Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Gehler PV, 2008, PROC CVPR IEEE, P3291; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; Grundmann M, 2013, IEEE INT CONF COMPUT; Hastie T, 2009, ELEMENTS STAT LEARNI; Holm J., 2006, P 14 IS T SID COL IM, P108; Jiang J, 2013, IEEE WORK APP COMP, P168, DOI 10.1109/WACV.2013.6475015; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; Kim S, 2012, PROC CVPR IEEE, P25, DOI [10.1109/MMBIA.2012.6164736, 10.1109/CVPR.2012.6247654]; Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402; Kuthirummal S, 2008, LECT NOTES COMPUT SC, V5305, P74, DOI 10.1007/978-3-540-88693-8_6; Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4; Lee JY, 2013, IEEE T PATTERN ANAL, V35, P144, DOI 10.1109/TPAMI.2012.66; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Lin S, 2004, PROC CVPR IEEE, P938; Malik J., 2008, P 24 ANN C COMPUTER, P31, DOI DOI 10.1145/1401132.1401174; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Pal C, 2004, PROC CVPR IEEE, P173; Reinhard E., 2006, HIGH DYNAMIC RANGE I; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Shen L, 2009, PROC CVPR IEEE, P1850, DOI 10.1109/CVPRW.2009.5206732; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; SHI L, 2010, REPROCESSED VERSION; Tai YW, 2013, IEEE T PATTERN ANAL, V35, P2498, DOI 10.1109/TPAMI.2013.40; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Xiong Y, 2012, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.2012.6247696	37	24	25	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2185	2198		10.1109/TPAMI.2014.2318713	http://dx.doi.org/10.1109/TPAMI.2014.2318713			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353060	Green Submitted			2022-12-18	WOS:000343702400006
J	Hsiao, E; Hebert, M				Hsiao, Edward; Hebert, Martial			Occlusion Reasoning for Object Detection under Arbitrary Viewpoint	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Occlusion reasoning; object detection; arbitrary viewpoint		We present a unified occlusion model for object instance detection under arbitrary viewpoint. Whereas previous approaches primarily modeled local coherency of occlusions or attempted to learn the structure of occlusions from data, we propose to explicitly model occlusions by reasoning about 3D interactions of objects. Our approach accurately represents occlusions under arbitrary viewpoint without requiring additional training data, which can often be difficult to obtain. We validate our model by incorporating occlusion reasoning with the state-of-the-art LINE2D and Gradient Network methods for object instance detection and demonstrate significant improvement in recognizing texture-less objects under severe occlusions.	[Hsiao, Edward; Hebert, Martial] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Hsiao, E (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	ehsiao@cs.cmu.edu; hebert@cs.cmu.edu			NSF [IIS-0713406, EEC-0540865];  [W-91-CRB-10C0132]	NSF(National Science Foundation (NSF)); 	This work was supported in part by NSF Grants IIS-0713406 and EEC-0540865, and Grant W-91-CRB-10C0132.	Bao S., 2010, P IEEE C COMP VIS PA; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Ess A., 2009, P IEEE INT C ROB AUT; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Ferrari V., 2006, P EUR C COMP VIS; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Fransens R., 2006, P IEEE C COMP VIS PA; Gao T., 2011, P IEEE C COMP VIS PA; Girshick R. B., 2011, P NEUR INF PROC SYST; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Hinterstoisser S., 2010, P IEEE C COMP VIS PA; Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206; Hogg R.V., 2009, PROBABILITY STAT INF; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Hsiao E., 2010, P IEEE C COMP VIS PA; Hsiao E., 2012, P IEEE C COMP VIS PA; Hsiao E., 2013, P AAAI C ART INT; Kowdle A., 2013, P IEEE C COMP VIS PA; Kwak S., 2011, P IEEE INT C COMP VI; Lai K, 2011, IEEE INT CONF ROBOT, P1817; Lalonde J.F., 2007, P ACM SIGGRAPH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Meger D, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.113; Pepik B., 2013, P IEEE C COMP VIS PA; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; Santal LA., 1953, INTRO INTEGRAL GEOME, V1198; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Shu G., 2012, P IEEE C COMP VIS PA; Sigal L., 2006, P IEEE C COMP VIS PA; Stevens M., 2000, INTEHRATING GRAPHICS; Su H., 2009, ICCV; Sun M., 2010, P EUR C COMP VIS; Tang SY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.9; Thomas A., 2006, P IEEE C COMP VIS PA; Toshev A., 2010, P IEEE C COMP VIS PA; Vedaldi A., 2009, P NEUR INF PROC SYST; Wang T., 2013, P IEEE C COMP VIS PA; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wojek C, 2011, PROC CVPR IEEE; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; Xing J., 2009, P IEEE C COMP VIS PA; Zia M.Z, 2013, P IEEE C COMP VIS PA	42	24	26	4	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1803	1815		10.1109/TPAMI.2014.2303085	http://dx.doi.org/10.1109/TPAMI.2014.2303085			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352233	Green Submitted			2022-12-18	WOS:000340210100008
J	Kittler, J; Christmas, W; de Campos, T; Windridge, D; Yan, F; Illingworth, J; Osman, M				Kittler, Josef; Christmas, William; de Campos, Teofilo; Windridge, David; Yan, Fei; Illingworth, John; Osman, Magda			Domain Anomaly Detection in Machine Perception: A System Architecture and Taxonomy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain anomaly; anomaly detection framework; machine perception; anomaly detection mechanisms	NOVELTY DETECTION; OUTLIER DETECTION; ALGORITHMS; CLASSIFICATION; FRAMEWORK; NETWORKS; EVENTS	We address the problem of anomaly detection in machine perception. The concept of domain anomaly is introduced as distinct from the conventional notion of anomaly used in the literature. We propose a unified framework for anomaly detection which exposes the multifaceted nature of anomalies and suggest effective mechanisms for identifying and distinguishing each facet as instruments for domain anomaly detection. The framework draws on the Bayesian probabilistic reasoning apparatus which clearly defines concepts such as outlier, noise, distribution drift, novelty detection (object, object primitive), rare events, and unexpected events. Based on these concepts we provide a taxonomy of domain anomaly events. One of the mechanisms helping to pinpoint the nature of anomaly is based on detecting incongruence between contextual and noncontextual sensor(y) data interpretation. The proposed methodology has wide applicability. It underpins in a unified way the anomaly detection applications found in the literature. To illustrate some of its distinguishing features, in here the domain anomaly detection methodology is applied to the problem of anomaly detection for a video annotation system.	[Kittler, Josef; Christmas, William; de Campos, Teofilo; Windridge, David; Yan, Fei; Illingworth, John] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; [Osman, Magda] Queen Mary Univ London, Dept Psychol, London E1 4NS, England	University of Surrey; University of London; Queen Mary University London	Kittler, J (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	j.kittler@surrey.ac.uk; w.christmas@surrey.ac.uk; t.deCampos@surrey.ac.uk; d.windridge@surrey.ac.uk; f.yan@surrey.ac.uk; j.illingworth@surrey.ac.uk; m.osman@qmul.ac.uk	de Campos, Teofilo/ABF-8003-2020	de Campos, Teofilo/0000-0001-6172-0229; Windridge, David/0000-0001-5507-8516; osman, magda/0000-0003-1480-6657	EPSRC project Adaptive Cognition for Automated Sports Video Annotation (ACASVA) [EP/F069421/1]; EPSRC project Signal processing in a networked battlespace [EP/K014307/1]; EPSRC; EPSRC [EP/F069421/1, EP/K014307/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/K014307/1, EP/F069421/1] Funding Source: researchfish	EPSRC project Adaptive Cognition for Automated Sports Video Annotation (ACASVA)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC project Signal processing in a networked battlespace(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was carried out as part of EPSRC projects Adaptive Cognition for Automated Sports Video Annotation (ACASVA) under contract EP/F069421/1 and Signal processing in a networked battlespace under contract EP/K014307/1. The EPSRC financial support is gratefully acknowledged. J. Kittler would like to thank the DIRAC Project consortium for the discussions that inspired this work.	Agarwal D, 2007, KNOWL INF SYST, V11, P29, DOI 10.1007/s10115-006-0036-4; Agyemang M, 2006, INTELL DATA ANAL, V10, P521, DOI 10.3233/IDA-2006-10604; Almajai I, 2010, IEEE IMAGE PROC, P1509, DOI 10.1109/ICIP.2010.5652415; Ando S, 2007, IEEE DATA MINING, P13, DOI 10.1109/ICDM.2007.53; Anemuller J., 2008, P ICMI CRET GREEC, P289; [Anonymous], 1960, TECHNOMETRICS, DOI DOI 10.1080/00401706.1960.10489888; [Anonymous], 2007, P 13 ACM SIGKDD INT; Basu S, 2007, KNOWL INF SYST, V11, P137, DOI 10.1007/s10115-006-0026-6; Burget L, 2008, INT CONF ACOUST SPEE, P4081, DOI 10.1109/ICASSP.2008.4518551; Chatzigiannakis V., 2006, P 11 IEEE S COMP COM, P761, DOI DOI 10.1109/ISCC.2006.1691116; Chawla S, 2006, KNOWL INF SYST, V9, P412, DOI 10.1007/s10115-005-0200-2; Crook PA, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3894, DOI 10.1109/ROBOT.2002.1014330; De Stefano C, 2000, IEEE T SYST MAN CY C, V30, P84, DOI 10.1109/5326.827457; Diehl CP, 2002, IEEE IJCNN, P2620, DOI 10.1109/IJCNN.2002.1007557; Edgeworth F.Y., 1887, PHILOS MAGAZINE J SC, V23, P364, DOI [10.1080/14786448708628471, DOI 10.1080/14786448708628471]; Eskin E., 2000, P INT C MACHINE LEAR, P255, DOI DOI 10.1109/ICCSA.2008.70; Esponda F, 2004, IEEE T SYST MAN CY B, V34, P357, DOI 10.1109/TSMCB.2003.817026; Fan W, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P123, DOI 10.1109/ICDM.2001.989509; He ZY, 2004, EXPERT SYST APPL, V27, P681, DOI 10.1016/j.eswa.2004.07.002; He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5; Helman P, 1997, IEEE T SYST MAN CY A, V27, P449, DOI 10.1109/3468.594912; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; Huber P, 1974, ROBUST STAT; Itti L, 2005, PROC CVPR IEEE, P631; Japkowicz N, 1995, INT JOINT CONF ARTIF, P518; Joshi M. V., 2002, PROC 8 ACM SIGKDD IN, P297; Keogh E, 2007, KNOWL INF SYST, V11, P1, DOI [10.1007/S10115-006-0034-6, 10.1007/s10115-006-0034-6]; Ketabdar H., 2007, P INTERSPEECH, P1757; Kittler J., 2005, P SCIA, P343; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Kombrink S, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P84; Lewis T., 1994, OUTLIERS STAT DATA; Li X, 2002, IEEE IMAGE PROC, P449; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; McNeil A. J., 1999, EXTREME VALUE THEORY, P93; NAIRAC A, 1997, P 5 IEE INT C ART NE, P227; Patcha A, 2007, COMPUT NETW, V51, P3448, DOI 10.1016/j.comnet.2007.02.001; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; ROBERTS S, 1994, NEURAL COMPUT, V6, P270, DOI 10.1162/neco.1994.6.2.270; Roberts SJ, 1999, IEE P-VIS IMAGE SIGN, V146, P124, DOI 10.1049/ip-vis:19990428; Roth V, 2006, NEURAL COMPUT, V18, P942, DOI 10.1162/089976606775774679; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Song XY, 2007, IEEE T KNOWL DATA EN, V19, P631, DOI 10.1109/TKDE.2007.1009; Soule A., 2005, Performance Evaluation Review, V33, P362, DOI 10.1145/1071690.1064259; Steinwart I, 2005, J MACH LEARN RES, V6, P211; Tax D. M. J., 2001, THESIS DELFT U NETHE; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; VASCONCELOS GC, 1995, PATTERN RECOGN LETT, V16, P207, DOI 10.1016/0167-8655(94)00092-H; Weinshall D., 2012, DETECTION IDENTIFICA; Weinshall D., 2009, P NIPS, P1; Weinshall D, 2012, IEEE T PATTERN ANAL, V34, P1886, DOI 10.1109/TPAMI.2011.279; Yan F, 2008, IEEE T PATTERN ANAL, V30, P1814, DOI 10.1109/TPAMI.2007.70834; Ye N., 2004, P 5 ANN IEEE INF ASS; Zhang J, 2006, KNOWL INF SYST, V10, P333, DOI 10.1007/s10115-006-0020-z; Zhang KJ, 2007, LECT NOTES ARTIF INT, V4632, P158; Zimmermann K., 2007, P IEEE 11 ICCV RIO J; Zweig A., 2007, P IEEE 11 ICCV RIO J; Zweig A., 2012, DETECTION IDENTIFICA	64	24	24	6	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					845	859		10.1109/TPAMI.2013.209	http://dx.doi.org/10.1109/TPAMI.2013.209			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353221	Green Published, Green Accepted			2022-12-18	WOS:000336054200002
J	Li, N; Tsang, IW; Zhou, ZH				Li, Nan; Tsang, Ivor W.; Zhou, Zhi-Hua			Efficient Optimization of Performance Measures by Classifier Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimize performance measures; classifier adaptation; ensemble learning; curriculum learning		In practical applications, machine learning algorithms are often needed to learn classifiers that optimize domain specific performance measures. Previously, the research has focused on learning the needed classifier in isolation, yet learning nonlinear classifier for nonlinear and nonsmooth performance measures is still hard. In this paper, rather than learning the needed classifier by optimizing specific performance measure directly, we circumvent this problem by proposing a novel two-step approach called CAPO, namely, to first train nonlinear auxiliary classifiers with existing learning methods and then to adapt auxiliary classifiers for specific performance measures. In the first step, auxiliary classifiers can be obtained efficiently by taking off-the-shelf learning algorithms. For the second step, we show that the classifier adaptation problem can be reduced to a quadratic program problem, which is similar to linear SVMperf and can be efficiently solved. By exploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear classifier which optimizes a large variety of performance measures, including all the performance measures based on the contingency table and AUC, while keeping high computational efficiency. Empirical studies show that CAPO is effective and of high computational efficiency, and it is even more efficient than linear SVMperf.	[Li, Nan; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Li, Nan] Soochow Univ, Sch Math Sci, Suzhou 215006, Peoples R China; [Tsang, Ivor W.] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Nanjing University; Soochow University - China; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Li, N (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	lin@lamda.nju.edu.cn; IvorTsang@ntu.edu.sg; zhouzh@lamda.nju.edu.cn	Tsang, Ivor/E-8653-2011	Tsang, Ivor/0000-0003-2211-8176; Tsang, Ivor/0000-0001-8095-4637	National Fundamental Research Program of China [2010CB327903]; National Science Foundation of China [61073097, 61021062]; Jiangsu Science Foundation [BK2011566]	National Fundamental Research Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Jiangsu Science Foundation	The authors want to thank the anonymous reviewers and the associate editor for their helpful comments and suggestions. This research was supported by the National Fundamental Research Program of China (2010CB327903), the National Science Foundation of China (61073097, 61021062), and the Jiangsu Science Foundation (BK2011566). Z.-H. Zhou is the corresponding author of this paper.	[Anonymous], 2006, P 19 INT C NEUR INF; [Anonymous], 2007, P 15 ACM INT C MULTI; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bishop, 1995, NEURAL NETWORKS PATT; Caruana Rich, 2004, ICML, DOI DOI 10.1145/1015330.1015432; Chang CC, 2001, IEEE IJCNN, P1031, DOI 10.1109/IJCNN.2001.939502; Cortes C, 2004, ADV NEUR IN, V16, P313; Duan L., 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Ferri C., 2002, P 19 INT C MACHINE L, V2, P139; Hall M., 2008, WEKA DATA MINING SOF, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]; Herschtal A., 2004, P 21 INT C MACH LEAR, P49; Joachims T, 2009, MACH LEARN, V76, P179, DOI 10.1007/s10994-009-5126-6; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Joachims Thorsten, 2005, ICML, DOI DOI 10.1145/1102351.1102399; Lafferty John, 2001, P 24 ANN INT ACM SIG, P111, DOI DOI 10.1145/383952.383970; LANGFORD J, 2005, P 10 INT WORKSH ART, P198; Li XC, 2007, Proceedings of the 2007 Chinese Control and Decision Conference, P275; Matheus C. J., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, P645; Morik K, 1999, MACHINE LEARNING, PROCEEDINGS, P268; Musicant D., 2003, P INT FLAIRS C, P356; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Valizadegan Hamed, 2009, ADV NEURAL INFORM PR, P1883; Xu J., 2008, P 31 ANN INT ACM SIG, P107, DOI DOI 10.1145/1390334.1390355; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Yu C.-N. J., 2008, KDD, P794; Yunbo Cao, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P186; Zhou Z.-H, 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207; Zhou ZH, 2004, IEEE T KNOWL DATA EN, V16, P770, DOI 10.1109/TKDE.2004.11; [No title captured]; [No title captured]; [No title captured]	34	24	26	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1370	1382		10.1109/TPAMI.2012.172	http://dx.doi.org/10.1109/TPAMI.2012.172			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	22868653	Green Submitted			2022-12-18	WOS:000317857900008
J	Mu, TT; Goulermas, JY; Tsujii, J; Ananiadou, S				Mu, Tingting; Goulermas, John Yannis; Tsujii, Jun'ichi; Ananiadou, Sophia			Proximity-Based Frameworks for Generating Embeddings from Multi-Output Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; supervised; semi-supervised; multilabel classification; embeddings	DIMENSIONALITY REDUCTION; FEATURE-EXTRACTION; INFORMATION; SELECTION	This paper is about supervised and semi-supervised dimensionality reduction (DR) by generating spectral embeddings from multi-output data based on the pairwise proximity information. Two flexible and generic frameworks are proposed to achieve supervised DR (SDR) for multilabel classification. One is able to extend any existing single-label SDR to multilabel via sample duplication, referred to as MESD. The other is a multilabel design framework that tackles the SDR problem by computing weight (proximity) matrices based on simultaneous feature and label information, referred to as MOPE, as a generalization of many current techniques. A diverse set of different schemes for label-based proximity calculation, as well as a mechanism for combining label-based and feature-based weight information by considering information importance and prioritization, are proposed for MOPE. Additionally, we summarize many current spectral methods for unsupervised DR (UDR), single/multilabel SDR, and semi-supervised DR (SSDR) and express them under a common template representation as a general guide to researchers in the field. We also propose a general framework for achieving SSDR by combining existing SDR and UDR models, and also a procedure of reducing the computational cost via learning with a target set of relation features. The effectiveness of our proposed methodologies is demonstrated with experiments with document collections for multilabel text categorization from the natural language processing domain.	[Mu, Tingting; Ananiadou, Sophia] Univ Manchester, Sch Comp Sci, Natl Ctr Text Min NaCTeM, Manchester M1 7DN, Lancs, England; [Goulermas, John Yannis] Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3GJ, Merseyside, England; [Tsujii, Jun'ichi] Microsoft Res Asia, Beijing, Peoples R China	University of Manchester; University of Liverpool; Microsoft; Microsoft Research Asia	Mu, TT (corresponding author), Univ Manchester, Sch Comp Sci, Natl Ctr Text Min NaCTeM, MIB Bldg,131 Princess St, Manchester M1 7DN, Lancs, England.	tingtingmu@me.com; j.y.goulermas@liverpool.ac.uk; jtsujii@microsoft.com; sophia.ananiadou@manchester.ac.uk	Mu, Tingting/AAV-4795-2020	Mu, Tingting/0000-0001-6315-3432	UK Biotechnology and Biological Sciences Research Council (BBSRC) [BB/G013160/1]; Biotechnology and Biological Sciences Research Council [BB/G013160/1] Funding Source: researchfish; BBSRC [BB/G013160/1] Funding Source: UKRI	UK Biotechnology and Biological Sciences Research Council (BBSRC)(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)); Biotechnology and Biological Sciences Research Council(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)); BBSRC(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC))	This work was funded by the UK Biotechnology and Biological Sciences Research Council (BBSRC project BB/G013160/1 Automated Biological Event Extraction from the Literature for Drug Discovery).	Arenas-Garcia J., 2006, P C NEUR INF PROC SY; BACH FR, 2002, J MACHINE LEARNING R, V3, P1; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Bekkerman R., 2003, Journal of Machine Learning Research, V3, P1183, DOI 10.1162/153244303322753625; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y., 2006, FEATURE EXTRACTION F; Bennett P.N., 2009, P 32 INT ACM SIGIR C; Bezdek JC, 2007, IEEE T FUZZY SYST, V15, P890, DOI 10.1109/TFUZZ.2006.889956; Bjorne J, 2009, P WORKSH CURR TRENDS, P10; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898; Chatpatanasiri R, 2010, NEUROCOMPUTING, V73, P1631, DOI 10.1016/j.neucom.2009.10.024; Chen CY, 2010, IEEE T SYST MAN CY B, V40, P208, DOI 10.1109/TSMCB.2009.2025028; Chen G., 2018, P 2008 SIAM INT C DA, P410; Chen WZ, 2007, IEEE DATA MINING, P451, DOI 10.1109/ICDM.2007.18; Chung F.R.K., 1997, AM MATH SOC, DOI DOI 10.1090/CBMS/092; Daniusis P, 2009, LECT NOTES COMPUT SC, V5788, P25, DOI 10.1007/978-3-642-04394-9_4; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, P1265, DOI 10.1162/153244303322753661; Dhillon I.S., 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Goulermas JY, 2008, IEEE T NEURAL NETWOR, V19, P1574, DOI 10.1109/TNN.2008.2000808; Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; He X., 2003, P NEUR INF PROC SYST; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hild KE, 2006, IEEE T PATTERN ANAL, V28, P1385, DOI 10.1109/TPAMI.2006.186; Hou YX, 2009, IEEE T NEURAL NETWOR, V20, P300, DOI 10.1109/TNN.2008.2005582; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kim H, 2005, J MACH LEARN RES, V6, P37; Kokiopoulou E, 2011, NUMER LINEAR ALGEBR, V18, P565, DOI 10.1002/nla.743; Kokiopoulou E, 2009, PATTERN RECOGN, V42, P2392, DOI 10.1016/j.patcog.2009.04.005; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; Lawrence N. D., 2011, P 14 INT C ART INT S; Lawrence N. D., 2004, P ADV NEUR INF PROC; LEWIS DD, 1992, SPEECH AND NATURAL LANGUAGE, P212; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Maaten L., 2011, P 14 INT C ART INT S; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Rai P., 2009, P C NEUR INF PROC SY; Roweis S., 1999, ORAL HLTH STATUS ORA; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Song L., 2007, P 24 INT C MACHINE L, P823, DOI [10.1145/1273496.1273600, DOI 10.1145/1273496.1273600]; Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001; STEWART GW, 2001, MATRIX ALGORITHMS EI, V2; Sugiyama M, 2007, J MACH LEARN RES, V8, P1027; Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7; Sun L., 2008, P INT C MACH LEARN; Sun L., 2008, HYPERGRAPH SPECTRAL, P668, DOI [10.1145/1401890.1401971, DOI 10.1145/1401890.1401971]; Sun L., 2008, P 3 INT JOINT C NAT, P769; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tsoumakas G., 2009, MINING MULTILA UNPUB; Urtasun R., 2007, P 24 INT C MACH LEAR, P927; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wold H., 1985, ENCY STAT SCI, DOI DOI 10.1002/0471667196; Yu K., 2005, P 28 ANN INT ACM SIG; Yu SP, 2006, IEEE T KNOWL DATA EN, V18, P1600, DOI 10.1109/TKDE.2006.194; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009; Zhang SQ, 2009, PATTERN RECOGN LETT, V30, P1208, DOI 10.1016/j.patrec.2009.05.011; Zhang TH, 2010, IEEE T SYST MAN CY B, V40, P253, DOI 10.1109/TSMCB.2009.2027473; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212; Zhang W., 2007, P 24 INT C MACH LEAR, V227, P1135; Zhang Y., 2007, P 23 NAT C ART INT, V3, P1503; Zhang Y., 2008, P 14 ACM SIGKDD INT; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhao DF, 2009, IEEE T PATTERN ANAL, V31, P86, DOI 10.1109/TPAMI.2008.34; Zhou D., 2007, P ADV NEUR INF PROC; Zhu X, 2005, 1530 U WISC DEP COMP	78	24	24	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2216	2232		10.1109/TPAMI.2012.20	http://dx.doi.org/10.1109/TPAMI.2012.20			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	23289130				2022-12-18	WOS:000308755000013
J	Tang, L; Garvin, MK; Lee, K; Alward, WLM; Kwon, YH; Abramoff, MD				Tang, Li; Garvin, Mona K.; Lee, Kyungmoo; Alward, Wallace L. M.; Kwon, Young H.; Abramoff, Michael D.			Robust Multiscale Stereo Matching from Fundus Images with Radiometric Differences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Depth from stereo; radiometric differences; pixel feature vector; fundus image; scale space	ENERGY MINIMIZATION; BELIEF PROPAGATION; SEGMENTATION; ALGORITHM; REGISTRATION; LAYER; SHAPE	A robust multiscale stereo matching algorithm is proposed to find reliable correspondences between low contrast and weakly textured retinal image pairs with radiometric differences. Existing algorithms designed to deal with piecewise planar surfaces with distinct features and Lambertian reflectance do not apply in applications such as 3D reconstruction of medical images including stereo retinal images. In this paper, robust pixel feature vectors are formulated to extract discriminative features in the presence of noise in scale space, through which the response of low-frequency mechanisms alter and interact with the response of high-frequency mechanisms. The deep structures of the scene are represented with the evolution of disparity estimates in scale space, which distributes the matching ambiguity along the scale dimension to obtain globally coherent reconstructions. The performance is verified both qualitatively by face validity and quantitatively on our collection of stereo fundus image sets with ground truth, which have been made publicly available as an extension of standard test images for performance evaluation.	[Tang, Li; Alward, Wallace L. M.; Kwon, Young H.; Abramoff, Michael D.] Univ Iowa, Dept Ophthalmol & Visual Sci, Iowa City, IA 52242 USA; [Garvin, Mona K.; Abramoff, Michael D.] Univ Iowa, Dept Elect & Comp Engn, Iowa City, IA 52242 USA; [Abramoff, Michael D.] Univ Iowa, Dept Biomed Engn, Iowa City, IA 52242 USA; [Abramoff, Michael D.] Vet Adm Med Ctr, Iowa City, IA 52240 USA	University of Iowa; University of Iowa; University of Iowa; US Department of Veterans Affairs; Veterans Health Administration (VHA)	Tang, L (corresponding author), Univ Iowa, Dept Ophthalmol & Visual Sci, Iowa City, IA 52242 USA.	li-tang-1@uiowa.edu; mona-garvin@uiowa.edu; kyungmle@engineering.uiowa.edu; wallace-alward@uiowa.edu; young-kwon@uiowa.edu; michael-abramoff@uiowa.edu	Alward, Wallace/AAY-4149-2020; Abramoff, Michael D/A-5836-2009; Garvin, Mona K/F-9275-2011	Abramoff, Michael D/0000-0002-3490-0037; Alward, Wallace/0000-0001-6368-9018; Kwon, Young/0000-0002-1116-8250	National Eye Institute [R01 EY017066, R01 EY018853, R01 EY019112]; Research to Prevent Blindness, New York; US Department for Veterans Affairs; Marlene S. and Leonard A. Hadley Glaucoma Research Fund; NATIONAL EYE INSTITUTE [R01EY018853, R01EY017066, R01EY019112] Funding Source: NIH RePORTER	National Eye Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); Research to Prevent Blindness, New York(Research to Prevent Blindness (RPB)); US Department for Veterans Affairs(US Department of Veterans Affairs); Marlene S. and Leonard A. Hadley Glaucoma Research Fund; NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))	This research was supported by the National Eye Institute (R01 EY017066, R01 EY018853, R01 EY019112), Research to Prevent Blindness, New York, the US Department for Veterans Affairs, and the Marlene S. and Leonard A. Hadley Glaucoma Research Fund. Li Tang and Michael D. Abramoff report that they are named as inventors on a patent application that is related to the subject matter of this manuscript. The authors would like to thank Dr. Qingxiong Yang for letting them run his algorithm on their data set and Dr. Min Zhu for permission to use her portrait in experiments. The authors would also like to thank the anonymous reviewers for their valuable comments to the earlier versions of this paper.	Abramoff MD, 2007, INVEST OPHTH VIS SCI, V48, P1665, DOI 10.1167/iovs.06-1081; Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Brox T., 2009, P IEEE C COMP VIS PA; Brox T., 2004, P EUR C COMP VIS; Choe TE, 2008, MED IMAGE ANAL, V12, P174, DOI 10.1016/j.media.2007.10.002; Favaro P, 2008, IEEE T PATTERN ANAL, V30, P518, DOI 10.1109/TPAMI.2007.1175; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Garvin MK, 2008, IEEE T MED IMAGING, V27, P1495, DOI 10.1109/TMI.2008.923966; HAEKER M, 2007, P INT C MED IM COMP, V10, P244; Haeker M, 2006, LECT NOTES COMPUT SC, V4190, P800; HIRSCHMUELLER H, 2009, P IEEE C COMP VIS PA; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Hirschmuller Heiko, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383248; Kim J, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P556; Kim J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1033, DOI 10.1109/ICCV.2003.1238463; KLAUS A, 2006, P 18 INT C PATT REC; LALIBERTE F, 2005, P SOC PHOTO-OPT INS, V56, P412; Lee K. Y., 2009, P SPIE, DOI 10.1117/12.852155; Lim JS, 1990, 2 DIMENSIONAL SIGNAL; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MAIMONE MW, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 1, P519, DOI 10.1109/IROS.1995.525846; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MARR D, 2005, VISION; Menz MD, 2003, NAT NEUROSCI, V6, P59, DOI 10.1038/nn986; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Niemeijer M, 2008, IEEE ENG MED BIO, P3538, DOI 10.1109/IEMBS.2008.4649969; Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154; Penney GP, 1998, IEEE T MED IMAGING, V17, P586, DOI 10.1109/42.730403; Platel B, 2004, IEEE IMAGE PROC, P389; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Romeny B. t. H., 2003, FRONT END VISION MUL; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Schuman J S, 1995, Curr Opin Ophthalmol, V6, P89; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; TOLA E, 2008, P IEEE C COMP VIS PA; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Van Meerbergen G, 2002, INT J COMPUT VISION, V47, P275, DOI 10.1023/A:1014562312225; Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99; Zhang L, 2007, IEEE T PATTERN ANAL, V29, P331, DOI 10.1109/TPAMI.2007.36; Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	46	24	26	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2245	2258		10.1109/TPAMI.2011.69	http://dx.doi.org/10.1109/TPAMI.2011.69			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21464502	Green Accepted			2022-12-18	WOS:000294910000010
J	Loog, M; Lauze, F				Loog, Marco; Lauze, Francois			The Improbability of Harris Interest Points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interest points; saliency; Harris corners; visual attention; low probability; elementary characterization	VISUAL-ATTENTION; SALIENCY; SCALE; MODEL	An elementary characterization of the map underlying Harris corners, also known as Harris interest points or key points, is provided. Two principal and basic assumptions made are: 1) Local image structure is captured in an uncommitted way, simply using weighted raw image values around every image location to describe the local image information, and 2) the lower the probability of observing the image structure present in a particular point, the more salient, or interesting, this position is, i.e., saliency is related to how uncommon it is to see a certain image structure, how surprising it is. Through the latter assumption, the axiomatization proposed makes a sound link between image saliency in computer vision on the one hand and, on the other, computational models of preattentive human visual perception, where exactly the same definition of saliency has been proposed. Because of this link, the characterization provides a compelling case in favor of Harris interest points over other approaches.	[Loog, Marco] Delft Univ Technol, Pattern Recognit Lab, NL-2628 CD Delft, Netherlands; [Loog, Marco; Lauze, Francois] Univ Copenhagen, Dept Comp Sci, Image Grp, DK-2100 Copenhagen O, Denmark	Delft University of Technology; University of Copenhagen	Loog, M (corresponding author), Delft Univ Technol, Pattern Recognit Lab, HB 11-070,Mekelweg 4, NL-2628 CD Delft, Netherlands.	m.loog@tudelft.nl; francois@diku.dk	Lauze, Francois B/L-8757-2016	Lauze, Francois B/0000-0003-2503-6475	Faculty of Science, University of Copenhagen [10-05087]; Netherlands Research Organization (NWO) [639.021.611]; Villum Fonden [00008721] Funding Source: researchfish	Faculty of Science, University of Copenhagen; Netherlands Research Organization (NWO)(Netherlands Organization for Scientific Research (NWO)); Villum Fonden(Villum Fonden)	Pierre Kornprobst (INRIA, NeuroMathComp) is sincerely acknowledged for an appraisal of this work and for pointing out a few omissions in the math. Sincere thanks also go to the three reviewers for their critical appraisals, kind suggestions, and for the fact that they pointed out to the authors a disturbing unclarity in the original manuscript. Both authors were supported by the Research Grant Program of the Faculty of Science, University of Copenhagen (Research Grant 10-05087). Marco Loog received additional support from the Innovational Research Incentives Scheme of the Netherlands Research Organization (NWO, VENI-Grant 639.021.611).	Adams R. A., 2003, SOBOLEV SPACES, VSecond; [Anonymous], 1991, FUNCTIONAL ANAL, DOI DOI 10.1070/IM8580; Aubert G., 2006, MATH PROBLEMS IMAGE, DOI 10.1007/978-0-387-44588-5; Boothby WM., 1975, INTRO DIFFERENTIABLE; Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010; Bruce NDB, 2005, NEUROCOMPUTING, V65, P125, DOI 10.1016/j.neucom.2004.10.065; Fecteau JH, 2006, TRENDS COGN SCI, V10, P382, DOI 10.1016/j.tics.2006.06.011; Florack LMJ, 1997, IMAGE STRUCTURE; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; Gallot S., 1990, RIEMANNIAN GEOMETRY; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Griffin LD, 2007, IEEE T PATTERN ANAL, V29, P1355, DOI 10.1109/TPAMI.2007.1066; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lingyun Z, 2007, P 29 ANN COGN SCI C; LISIN D, 2003, P 3 INT C COMP VIS S; Loog M, 2008, PERCEPTION, V37, P4; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; Matthies L, 2007, INT J COMPUT VISION, V75, P67, DOI 10.1007/s11263-007-0046-z; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Montesinos P, 1998, INT C PATT RECOG, P838, DOI 10.1109/ICPR.1998.711280; Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042; NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8; Rohr K, 1997, IMAGE VISION COMPUT, V15, P219, DOI 10.1016/S0262-8856(96)01127-4; ROHR K, 1992, IMAGE VISION COMPUT, V10, P66, DOI 10.1016/0262-8856(92)90001-J; Romeny B. t. H., 2003, FRONT END VISION MUL; Rosenholtz R, 1999, VISION RES, V39, P3157, DOI 10.1016/S0042-6989(99)00077-2; ROSENTHALER L, 1992, LECT NOTES COMPUT SC, V588, P78; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Torralba A, 2003, J OPT SOC AM A, V20, P1407, DOI 10.1364/JOSAA.20.001407; TRIGGS B, 2004, P EUR C COMP VIS, P100; Walker K. N., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P557; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32	45	24	36	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1141	1147		10.1109/TPAMI.2010.53	http://dx.doi.org/10.1109/TPAMI.2010.53			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431138				2022-12-18	WOS:000276671900015
J	Chen, DT; Yang, J				Chen, Datong; Yang, Jie			Robust object tracking via online dynamic spatial bias appearance models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object tracking; online learning; dynamic spatial bias appearance model; region confidence; hierarchical Monte Carlo		This paper presents a robust object tracking method via a spatial bias appearance model learned dynamically in video. Motivated by the attention shifting among local regions of a human vision system during object tracking, we propose to partition an object into regions with different confidences and track the object using a dynamic spatial bias appearance model ( DSBAM) estimated from region confidences. The confidence of a region is estimated to reflect the discriminative power of the region in a feature space and the probability of occlusion. We propose a novel hierarchical Monte Carlo ( HAMC) algorithm to learn region confidences dynamically in every frame. The algorithm consists of two levels of Monte Carlo processes implemented using two particle filtering procedures at each level and can efficiently extract high- confidence regions through video frames by exploiting the temporal consistency of region confidences. A dynamic spatial bias map is then generated from the high- confidence regions and is employed to adapt the appearance model of the object and to guide a tracking algorithm in searching for correspondences in adjacent frames of video images. We demonstrate feasibility of the proposed method in video surveillance applications. The proposed method can be combined with many other existing tracking systems to enhance the robustness of these systems.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University	Chen, DT (corresponding author), Carnegie Mellon Univ, Dept Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	datong@cs.cmu.edu; jie.yang@cs.cmu.edu						CHEN D, 2005, P WORKSH VID SURV PE; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; Collins RT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P346; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; Davatzikos C, 1996, IEEE T MED IMAGING, V15, P112, DOI 10.1109/42.481446; DEUTSCH B, 2005, GERMAN PATTERN RECOG, P269; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GRIMSON WEL, 1999, P INT C COMP VIS PAT, P22; Haritaoglu I, 1998, PROC CVPR IEEE, P962, DOI 10.1109/CVPR.1998.698720; HEISELE B, 1997, P INT C COMP VIS PAT, P253; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; PARAGIOS N, 1997, INRIA 3173; PARK S, 2002, P IEEE WORKSH MOT VI; Shahrokni A, 2004, LECT NOTES COMPUT SC, V3022, P566; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SHIM WM, 2004, J VISION, V4, P575; Sminchisescu C, 2002, LECT NOTES COMPUT SC, V2350, P769; Stenger B., 2002, P INT C COMP VIS, P294; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; TOYAMA K, 1999, INT C COMP VIS, P255, DOI DOI 10.1109/ICCV.1999.791228; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; YANG J, 1996, P 3 IEEE WORKSH APPL, P142; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96	27	24	26	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2157	2169		10.1109/TPAMI.2007.1134	http://dx.doi.org/10.1109/TPAMI.2007.1134			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934225				2022-12-18	WOS:000250087900008
J	Negahdaripour, S				Negahdaripour, Shahriar			Epipolar geometry of opti-acoustic stereo imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereovision; epipolar geometry; triangulation; optical and sonar imaging		Optical and sonar cameras are suitable imaging systems for inspecting underwater structures, both in regular maintenance and security operations. Despite their high resolution, optical systems have limited visibility range when deployed in turbid waters. In contrast, the new generation of high-frequency (MHz) forward-scan sonar cameras can provide images with enhanced target details in highly turbid waters though their range is reduced by one or two orders of magnitude as compared to traditional low or midfrequency (10s-100s KHz) sonar systems. It is conceivable that an effective inspection strategy is the deployment of both optical and sonar cameras on a submersible platform to enable target imaging in a range of turbidity conditions. Under this scenario and where visibility allows, registration of the images from both cameras ( arranged in binocular stereo configuration) provides valuable scene information that cannot be readily recovered from each sensor alone. We explore and derive the constraint equations for the epipolar geometry and stereo triangulation in utilizing these two sensing modalities with different projection models. Theoretical results supported by computer simulations show that an opti-acoustic stereo imaging system outperforms a traditional binocular vision with optical cameras, particularly for increasing target distance and/or turbidity.	Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33146 USA	University of Miami	Negahdaripour, S (corresponding author), Univ Miami, Dept Elect & Comp Engn, 1251 Mem Dr Rm-406, Coral Gables, FL 33146 USA.	shahriar@miami.edu						BARAT C, 2005, P MTS IEEE OC C JUN, V1; BELCHER EO, 2001, P MTS IEEE OC C NOV; BELCHER EO, 2003, P MTS IEEE OC C SEP; BENSOMAN R, 2001, PANORAMIC VISION SEN; BROWN M, 2003, IEEE T PATTER ANAL M, V25; CASTELLANI U, 2005, SIGNAL PROCESSING IM, V20; CHEN Q, 1999, P IEEE C COMP VIS PA, V1; COLLIGNON A, 1998, THESIS CATHOLIC U LE; FAUGERAS O, 1996, 3 DIMENSIONAL COMPUT; FUSIELLO A, 2004, IEEE T VISUALIZATION, V10; GIFFORD JA, 1997, UNDERWATER ARCHAEOLO; GRACIAS N, 2001, P MTS IEEE OC C; GRACIAS N, 2005, P MTS IEEE OC C; GUERIOT D, 2000, P MTS IEEE OC C; Hajnal JV, 2001, MED IMAGE REGISTRATI; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; KAMGARPARSI B, 1998, IEEE T IMAGE PROCESS, V7; LHUILLIER M, 2002, IEEE T PATTERN ANAL, V24; NEGAHDARIPOUR S, 2005, P MTS IEEE OC C AUG; NEGAHDARIPOUR S, 2006, IEEE J OCEANIC ENG, V31; PAJDLA T, 2001, P COMP VIS WINT WORK; PATOULATOS N, 1999, IEEE T INFORM TECHNO, V3; PIRON CA, 2003, IEEE T MED IMAGING, V20; RADEMACHER P, 1998, P ACM SIGGRAPH 98 JU; RZHANOV Y, 2001, P INT C IM PROC; SCHECHNER YY, 2004, P IEEE INT C COMP VI, V1; SEITZ S. M., 2002, INT J COMPUTER VISIO, V48; SEKKATI H, 2006, P IEEE INT C 3D VIS; SEKKATI H, IN PRESS IEEE T IMAG; SERMESANT M, 2002, P 5 INT C MED IM COM; SLAMA CC, 1983, AM SOC PHOTOGRAMMETR; SVOBADA T, 1998, P 5 EUR C COMP VIS J; TSAI RY, 1987, IEEE T ROBOTICS AUTO, V3; VESETAS R, 2001, P MTS IEEE OC C NOV; VIOLA PA, 1995, THESIS MASSACHUSETTS; VONALT C, 2003, P MTS IEEE OC C SEPT; Wolf PR, 2000, ELEMENTS PHOTOGRAMME; YU J, 2004, P 8 EUR C COMP VIS; [No title captured]	39	24	30	5	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1776	1788		10.1109/TPAMI.2007.1092	http://dx.doi.org/10.1109/TPAMI.2007.1092			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699922				2022-12-18	WOS:000248696100007
J	Deng, Y; Yang, Q; Lin, XY; Tang, X				Deng, Yi; Yang, Qiong; Lin, Xueyin; Tang, Xiaoou			Stereo correspondence with occlusion handling in a symmetric patch-based graph-cuts model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo; correspondence; segmentation; graph-cuts; occlusion; energy minimization		A novel patch-based correspondence model is presented in this paper. Many segment-based correspondence approaches have been proposed in recent years. Untextured pixels and boundaries of discontinuities are imposed with hard constraints by the discontinuity assumption that large disparity variation only happens at the boundaries of segments in the above approaches. Significant improvements on performance of untextured and discontinuity area have been reported. But, the performance near occlusion is not satisfactory because a segmented region in one image may be only partially visible in the other one. To solve this problem, we utilize the observation that the shared edge of a visible area and an occluded area corresponds to the discontinuity in the other image. So, the proposed model conducts color segmentation on both images first and then a segment in one image is further cut into smaller patches corresponding to the boundaries of segments in the other when it is assigned with a disparity. Different visibility of patches in one segment is allowed. The uniqueness constraint in a segment level is used to compute the occlusions. An energy minimization framework using graph-cuts is proposed to find a global optimal configuration including both disparities and occlusions. Besides, some measurements are taken to make our segment-based algorithm suffer less from violation of the discontinuity assumption. Experimental results have shown superior performance of the proposed approach, especially on occlusions, untextured areas, and near discontinuities.	Tsinghua Univ, Beijing 100084, Peoples R China; Mirosoft Res Asia, Visual Comp Grp, Beijing Sigma Ctr 49, Beijing 100080, Peoples R China	Tsinghua University	Deng, Y (corresponding author), Tsinghua Univ, 3-524,FIT Bldg, Beijing 100084, Peoples R China.	dengyi00@mails.tsinghua.edu.cn; qyang@microsoft.com; lxy-dcs@mail.tsinghua.edu.cn; xitang@microsoft.com						Baillard C, 1999, COMPUT VIS IMAGE UND, V76, P244, DOI 10.1006/cviu.1999.0793; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; BLEYER M, 2005, P SPIE, V5656; BOYKOV Y, 2001, P IEEE INT C COMP VI, V1, P532; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421; Deng Y, 2005, IEEE I CONF COMP VIS, P1316; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; HONG L, 2004, P IEEE INT C COMP VI, V1; ISHIKAWA H, 1998, P EUR C COMP VIS, P232; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; KOLMOGOROV V, 2001, P IEEE INT C COMP VI; Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54; Ogale AS, 2004, PROC CVPR IEEE, P568; Roy S, 1999, INT J COMPUT VISION, V34, P147, DOI 10.1023/A:1008192004934; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Wei YC, 2004, PROC CVPR IEEE, P106; Zhang Y, 2002, LECT NOTES COMPUT SC, V2351, P556; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	23	24	33	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1068	1079		10.1109/TPAMI.2007.1043	http://dx.doi.org/10.1109/TPAMI.2007.1043			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431303	Green Submitted			2022-12-18	WOS:000245600800011
J	Nicolescu, M; Medioni, G				Nicolescu, M; Medioni, G			A voting-based computational framework for visual motion analysis and interpretation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion; image models; scene analysis	EPIPOLAR GEOMETRY; SEGMENTATION; ALGORITHM; SMOOTHNESS; INFERENCE; SURFACES; FIELDS	Most approaches for motion analysis and interpretation rely on restrictive parametric models and involve iterative methods which depend heavily on initial conditions and are subject to instability. Further difficulties are encountered in image regions where motion is not smooth - typically around motion boundaries. This work addresses the problem of visual motion analysis and interpretation by formulating it as an inference of motion layers from a noisy and possibly sparse point set in a 4D space. The core of the method is based on a layered 4D representation of data and a voting scheme for affinity propagation. The inherent problem caused by the ambiguity of 2D to 3D interpretation is usually handled by adding additional constraints, such as rigidity. However, enforcing such a global constraint has been problematic in the combined presence of noise and multiple independent motions. By decoupling the processes of matching, outlier rejection, segmentation, and interpretation, we extract accurate motion layers based on the smoothness of image motion, then locally enforce rigidity for each layer in order to infer its 3D structure and motion. The proposed framework is noniterative and consistently handles both smooth moving regions and motion discontinuities without using any prior knowledge of the motion model.	Univ Nevada, Dept Comp Sci, Reno, NV 89557 USA; Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	Nevada System of Higher Education (NSHE); University of Nevada Reno; University of Southern California; University of Southern California	Nicolescu, M (corresponding author), Univ Nevada, Dept Comp Sci, 1664 N Virginia St, Reno, NV 89557 USA.	mircea@cs.unr.edu; medioni@usc.edu						Adam A, 2001, IEEE T PATTERN ANAL, V23, P78, DOI 10.1109/34.899948; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P173, DOI 10.1109/WVM.1991.212810; DERICHE R, 1995, P 2 AS C COMP VIS AC, V2, P290; Fleet DJ, 1998, PROC CVPR IEEE, P274, DOI 10.1109/CVPR.1998.698620; Gelgon M, 1997, PROC CVPR IEEE, P514, DOI 10.1109/CVPR.1997.609374; Ghosal S, 1996, IEEE T PATTERN ANAL, V18, P181, DOI 10.1109/34.481542; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HILDRETH E, 1983, MEASUREMENT VISUAL M; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HSU S, 1994, P INT C PATT REC; Irani M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P216, DOI 10.1109/CVPR.1992.223272; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; KERVRANN C, 1995, IEEE T IMAGE PROCESS, V4, P856, DOI 10.1109/83.388090; Lee MS, 2002, IEEE T PATTERN ANAL, V24, P824, DOI 10.1109/TPAMI.2002.1008388; Little J., 1988, P ICCV 88, P454; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; McReynolds DP, 1996, IEEE T PATTERN ANAL, V18, P1174, DOI 10.1109/34.546255; Medioni G., 2000, COMPUTATIONAL FRAMEW; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Nicolescu M, 2003, IEEE T PATTERN ANAL, V25, P492, DOI 10.1109/TPAMI.2003.1190574; Nicolescu M, 2003, PROC CVPR IEEE, P382; Scharstein D, 2003, PROC CVPR IEEE, P195; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; SIMONCELLI EP, 1991, IEEE C COMP VIS PATT, P310, DOI 10.1109/CVPR.1991.139707; SINGH A, 1992, OPTICAL FLOW COMPUTA; Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863; SMITH PA, 2001, THESIS U CAMBRIDGE; Tong WS, 2004, IEEE T PATTERN ANAL, V26, P1167, DOI 10.1109/TPAMI.2004.72; TORR PHS, 1997, P INT J COMP VIS; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Wu YT, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P992, DOI 10.1109/ICCV.1998.710837; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	46	24	27	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					739	752		10.1109/TPAMI.2005.91	http://dx.doi.org/10.1109/TPAMI.2005.91			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875795				2022-12-18	WOS:000227569300007
J	Chojnacki, W; Brooks, MJ; van den Hengel, A; Gawley, D				Chojnacki, W; Brooks, MJ; van den Hengel, A; Gawley, D			From FNS to HEIV: A link between two vision parameter estimation methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical methods; maximum likelihood; (un)constrained minimization; fundamental matrix; epipolar equation		Problems requiring accurate determination of parameters from image-based quantities arise often in computer vision. Two recent, independently developed frameworks for estimating such parameters are the FNS and HEW schemes. Here, it is shown that FNS and a core version of HEIV are essentially equivalent, solving a common underlying equation via different means. The analysis is driven by the search for a nondegenerate form of a certain generalized eigenvalue problem and effectively leads to a new derivation of the relevant case of the HEW algorithm. This work may be seen as an extension of previous efforts to rationalize and interrelate a spectrum of estimators, including the renormalization method of Kanatani and the normalized eight-point method of Hartley.	Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; CRC, Sensor Signal & Informat Proc, Mawson Lakes, SA 5095, Australia	University of Adelaide	Chojnacki, W (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	wojtek@cs.adelaide.edu.au; mjb@cs.adelaide.edu.au; hengel@cs.adelaide.edu.au; dg@cs.adelaide.edu.au	Brooks, Michael/G-5614-2012; Chojnacki, Wojciech/AAE-9875-2020	Brooks, Michael/0000-0001-9612-5884; Chojnacki, Wojciech/0000-0001-7782-1956; van den Hengel, Anton/0000-0003-3027-8364				Brooks MJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P302, DOI 10.1109/ICCV.2001.937533; Brooks MJ, 1997, J OPT SOC AM A, V14, P2670, DOI 10.1364/JOSAA.14.002670; Chojnacki W., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P43; Chojnacki W, 2003, IEEE T PATTERN ANAL, V25, P1172, DOI 10.1109/TPAMI.2003.1227992; Chojnacki W, 2001, J MATH IMAGING VIS, V14, P21, DOI 10.1023/A:1008355213497; Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Halir R, 1998, WSCG '98, VOL 1, P125; Kanatani K., 1996, STAT OPTIMIZATION GE; Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375; Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727; Matei B., 2001, THESIS RUTGERS U NEW; Parlett B. N., 1998, SYMMETRIC EIGENVALUE, V20, DOI DOI 10.1137/1.9781611971163; VANDENHENGEL A, 2002, P 13 BRIT MACH VIS C, V2, P468	15	24	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					264	268		10.1109/TPAMI.2004.1262197	http://dx.doi.org/10.1109/TPAMI.2004.1262197			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376901	Green Submitted			2022-12-18	WOS:000187954300012
J	Baker, S; Sim, T; Kanade, T				Baker, S; Sim, T; Kanade, T			When is the shape of a scene unique given its light-field: A fundamental theorem of 3D vision?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D shape reconstruction; stereo; shape-from-silhouette; the plenoptic function; light-fields; uniqueness		The complete set of measurements that could ever be used by a passive 3D vision algorithm is the plenoptic function or light-field. We give a concise characterization of when the light-field of a Lambertian scene uniquely determines its shape and, conversely, when the shape is inherently ambiguous. In particular, we show that stereo computed from the light-field is ambiguous if and only if the scene is radiating light of a constant intensity (and color, etc.) over an extended region.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore	Carnegie Mellon University; National University of Singapore	Baker, S (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	simonb@cs.cmu.edu; tsim@comp.nus.edu.sg; tk@cs.cmu.edu		Sim, Terence/0000-0002-0198-094X				Adelson E., 1991, PLENOPTIC FUNCTION E; BAKER S, 2001, P 8 INT C COMP VIS; BAKER S, 1998, P IEEE C COMP VIS PA; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; BHAT DN, 1995, P 5 INT C COMP VIS; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Brocker T., 1982, INTRO DIFFERENTIAL T; CHEUNG KM, 2002, CMURITR0205; DEVERNAY F, 1994, P IEEE C COMP VIS PA; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; GIBLIN P, 1987, P 1 INT C COMP VIS; GORTLER S, 1996, COMPUTER GRAPHICS P; Horn B., 1986, ROBOT VISION, P1; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LEVOY M, 1996, COMPUTER GRAPHICS P; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; Nayar S.K., 1999, P 7 IEEE INT C COMP; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955	19	24	25	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					100	109		10.1109/TPAMI.2003.1159949	http://dx.doi.org/10.1109/TPAMI.2003.1159949			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300008
J	Fernandez-Madrigal, JA; Gonzalez, J				Fernandez-Madrigal, JA; Gonzalez, J			Multihierarchical graph search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph theory; search; hierarchical graphs; path planning	PATH	The use of hierarchical graph search for finding paths in graphs is well known in the literature, providing better results than plain graph search regarding computational costs in many cases. This paper offers a step forward by including multiple hierarchies in a graph-based model. Such a multihierarchical model has the following advantages: First, a multiple hierarchy permits us to choose the best hierarchy to solve each search problem; second, when several search problems have to be solved, a multiple hierarchy provides the possibility of solving part of them simultaneously; and third, solutions to the search problems can be expressed in any of the hierarchies of the multiple hierarchy, which allows us to represent the information in the most suitable way for each specific purpose. In general, multiple hierarchies have proven to be a more adaptable model than single-hierarchy or nonhierarchical models. This paper formalizes the multihierarchical model, describes the techniques that have been designed for taking advantage of multiple hierarchies in a hierarchical path search, and presents some experiments and results on the performance of these techniques.	Univ Malaga, Syst Engn & Automat Dept, E-29071 Malaga, Spain	Universidad de Malaga	Fernandez-Madrigal, JA (corresponding author), Univ Malaga, Syst Engn & Automat Dept, Campus Teatinos,Complejo Tecnol, E-29071 Malaga, Spain.	jafma@ctima.uma.es; jgonzalez@ctima.uma.es	Fernández-Madrigal, Juan-Antonio/D-5871-2011; Gonzalez-Jimenez, Javier/D-5774-2011	Fernández-Madrigal, Juan-Antonio/0000-0003-1376-7967; Gonzalez-Jimenez, Javier/0000-0003-3845-3497				BROOKS RA, 1990, AUTONOMOUS ROBOT VEH, P290; BUNDY A, 1990, P UK IT 90, P221; CAR A, 1994, LECT NOTES COMPUTER, V884, P15; DARIO M, 1996, IEEE T PATTERN ANAL, V18, P1080; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; FENNEMA C, 1990, IEEE T SYSTEMS MAN C, V20; Fernandez JA, 1999, ENG APPL ARTIF INTEL, V12, P543, DOI 10.1016/S0952-1976(99)00018-4; FERNANDEZ JA, 1997, P 7 C SPAN ASS ART I, P35; FERNANDEZ JA, 2000, THESIS U MALAGA SPAI; FERNANDEZ JA, 1998, P IEEE INT C ROB AUT; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; FUJIMURA K, 1995, IEEE T ROBOTIC AUTOM, V11, P343, DOI 10.1109/70.388776; GIUNCHIGLIA E, 1990, 901008 I RIC SCI TEC; HART PE, 1968, IEEE T SYSTEMS MAN C, V4; HOLMES PD, 1992, IEEE T PATTERN ANAL, V14, P549, DOI 10.1109/34.134059; HOLTE RC, 1995, TR9519 U OTT; HOLTE RC, 1994, P BIENN C CAN SOC CO, P00263; Hu HS, 1997, IEEE T ROBOTIC AUTOM, V13, P760, DOI 10.1109/70.631237; JING N, 1996, P 5 INT C INF KNOWL, P261; KORF RE, 1987, ARTIF INTELL, V33, P65, DOI 10.1016/0004-3702(87)90051-8; KUIPERS BJ, 1996, P WORK PAP 10 INT WO; OLLERO A, 1992, P INT FED AUT CONTR; PARK IP, 1995, ARTIFICIAL INTELLIGE, V78; Remolina E, 1999, LECT NOTES COMPUT SC, V1661, P109; RICH E, 1994, ARTIFICIAL INTELLIGE; SHEKHAR S, 1996, 96046 U MINN; STENTZ A, 1996, P AAAI S PLANN INC I; THORPE C, 1990, VISION NAVIGATION CM; TUPPER JA, 1996, THESIS U TORONTO CAN; YANG Q, 1994, CS9165 U WAT; YEN JY, 1971, MANAGE SCI, V17, P712, DOI 10.1287/mnsc.17.11.712; ZHU D, 1991, IEEE T ROBOTIC AUTOM, V7, P9, DOI 10.1109/70.68066	33	24	25	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					103	113		10.1109/34.982887	http://dx.doi.org/10.1109/34.982887			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ					2022-12-18	WOS:000172960300007
J	Leung, Y; Ma, JH; Zhang, WX				Leung, Y; Ma, JH; Zhang, WX			A new method for mining regression classes in large data sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data mining; genetic algorithm; maximum likelihood method; mixture modeling; RCMD method; regression class; robustness	ROBUST ESTIMATOR; PERSPECTIVE; LIKELIHOOD; MIXTURES	Extracting patterns and models of interest from targe databases is attracting much attention in a variety of disciplines. Knowledge discovery in databases (KDD) and data mining (DM) are areas of common interest to researchers in machine learning, pattern recognition, statistics, artificial intelligence, and high performance computing. An effective and robust method, coined regression-class mixture decomposition (RCMD) method, is proposed in this paper for the mining of regression classes in large data sets, especially those contaminated by noise. A new concept, called "regression class" which is defined as a subset of the data set that is subject to a regression model, is proposed as a basic building block on which the mining process is based. A large data set is treated as a mixture population in which there are many such regression classes and others not accounted for by the regression models. Iterative and genetic-based algorithms for the optimization of the objective function in the RCMD method are also constructed. It is demonstrated that the RCMD method can resist a very large proportion of noisy data. identify each regression class. assign an inlier set of data points supporting each identified regression class, and determine the a priori unknown number of statistically valid models in the data set. Although the models are extracted sequentially, the final result is almost independent of the extraction order due to a novel dynamic classification strategy employed in the handling of overlapping regression classes. The effectiveness and robustness of the RCMD method are substantiated by a set of simulation experiments and a real-life application showing the way it can be used to fit mixed data to linear regression classes and nonlinear structures in various situations.	Chinese Univ Hong Kong, Ctr Environm Policy & Resource Management, Dept Geog, Shatin, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Joint Lab Geoinformat Sci, Shatin, Hong Kong, Peoples R China; Xi An Jiao Tong Univ, Inst Informat & Syst Sci, Xian 710049, Peoples R China	Chinese University of Hong Kong; Chinese University of Hong Kong; Xi'an Jiaotong University	Leung, Y (corresponding author), Chinese Univ Hong Kong, Ctr Environm Policy & Resource Management, Dept Geog, Shatin, Hong Kong, Peoples R China.	yeeleung@cuhk.edu.hk; jhmath@china.com						Arabie P., 1996, CLUSTERING CLASSIFIC, DOI DOI 10.1142/1930; Berthold M., 1999, INTELLIGENT DATA ANA; Caudill SB, 1998, COMMUN STAT-SIMUL C, V27, P667, DOI 10.1080/03610919808813502; Cherkassky V. S., 1998, LEARNING DATA CONCEP, V1st; Danuser G, 1998, IEEE T PATTERN ANAL, V20, P263, DOI 10.1109/34.667884; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; DEVEAUX RD, 1989, COMPUT STAT DATA AN, V8, P227, DOI 10.1016/0167-9473(89)90043-1; Fayyad U, 1997, FUTURE GENER COMP SY, V13, P99, DOI 10.1016/S0167-739X(97)00015-0; Friedman J. H., 1994, STAT NEURAL NETWORKS, P1; Glymour C, 1997, DATA MIN KNOWL DISC, V1, P11, DOI 10.1023/A:1009773905005; Hand D., 1999, ADV INTELLIGENT DATA; Hand DJ, 1998, AM STAT, V52, P112, DOI 10.2307/2685468; Hathaway R. J., 1993, IEEE Transactions on Fuzzy Systems, V1, P195, DOI 10.1109/91.236552; Hines RJO, 1997, J STAT COMPUT SIM, V59, P63, DOI 10.1080/00949659708811847; HOLSHEIMER M, 1995, P 1 INT C KNOWL DISC, P150; Hosking JRM, 1997, FUTURE GENER COMP SY, V13, P117, DOI 10.1016/S0167-739X(97)00016-2; HSU CN, 1995, P 1 INT C KNOWL DISC, P156; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Ji Q, 1998, IEEE T PATTERN ANAL, V20, P845, DOI 10.1109/34.709604; John G, 1995, P 1 INT C KNOWL DISC, P174; KENDALL MG, 1987, KENDALL ADV THEORY S; Kim E, 1997, IEEE T FUZZY SYST, V5, P328, DOI 10.1109/91.618271; Lau KN, 1996, COMPUT OPER RES, V23, P1163, DOI 10.1016/S0305-0548(96)00027-5; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; QUAGLIARELLA D, 1998, GENETIC ALGORITHMS E; QUANDT RE, 1978, J AM STAT ASSOC, V73, P730, DOI 10.2307/2286266; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; ROYSTON JP, 1982, J R STAT SOC C-APPL, V31, P115; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Titterington D.M., 1987, STAT ANAL FINITE MIX; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; ZHUANG XH, 1992, IEEE T PATTERN ANAL, V14, P19, DOI 10.1109/34.107011; Zhuang XH, 1996, IEEE T IMAGE PROCESS, V5, P1293, DOI 10.1109/83.535841; Zupan B., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P299	35	24	30	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					5	21		10.1109/34.899943	http://dx.doi.org/10.1109/34.899943			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA					2022-12-18	WOS:000166316700002
J	Lee, KH; Choy, YC; Cho, SB				Lee, KH; Choy, YC; Cho, SB			Geometric structure analysis of document images: A knowledge-based approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; geometric structure analysis; region segmentation; region identification; knowledge-based approach	TECHNICAL JOURNALS; PAGE SEGMENTATION; SYSTEM; CLASSIFICATION; REPRESENTATION; DECOMPOSITION	Geometric structure analysis is a prerequisite to create electronic documents from logical components extracted from document images. This paper presents a knowledge-based method for sophisticated geometric structure analysis of technical journal pages. The proposed knowledge base encodes geometric characteristics that are not only common in technical journals but also publication-specific in the farm of rules. The method takes the hybrid of top-down and bottom-up techniques and consists of two phases: region segmentation and identification. Generally, the result of the segmentation process does not have a one-to-one matching with composite layout components. Therefore, the proposed method identifies nontext objects, such as images drawings, and tables, as well as text objects, such as text lines and equations, by splitting or grouping segmented regions into composite layout components. Experimental results with 372 images scanned from the IEEE Transactions on Pattern Analysis and Machine Intelligence show that the proposed method has performed geometric structure analysis successfully on more than 99 percent of the test images, resulting in impressive performance compared with previous works.	Yonsei Univ, Dept Comp Sci, Seodaemoon Ku, Seoul 120749, South Korea	Yonsei University	Lee, KH (corresponding author), Yonsei Univ, Dept Comp Sci, Seodaemoon Ku, 134 Shinchon Dong, Seoul 120749, South Korea.	lkh@rainbow.yonsei.ac.kr; ycchoy@rainbow.yonsei.ac.kr; sbcho@csai.yonsei.ac.kr		LEE, KYONG-HO/0000-0002-1581-917X				Antonacopoulos A, 1998, COMPUT VIS IMAGE UND, V70, P350, DOI 10.1006/cviu.1998.0691; ANTONACOPOULOS A, 1994, P 12 INT C PATT REC, V2, P339; Cesarini F., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P563, DOI 10.1109/ICDAR.1999.791850; Dengel A., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P641, DOI 10.1142/S0218001488000406; DENGEL A, 1992, COMPUTER, V25, P63, DOI 10.1109/2.144442; Esposito F., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P466, DOI 10.1109/ICDAR.1995.599037; ETEMAD K, 1994, P INT C PATT REC, V2, P345; FAN KC, 1994, PATTERN RECOGN LETT, V15, P1201, DOI 10.1016/0167-8655(94)90110-4; Fisher J. L., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P567, DOI 10.1109/ICPR.1990.118166; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; Guyon Isabelle, 1997, HDB CHARACTER RECOGN, P779; HA J, 1995, P 3 INT C DOC AN REC, V2, P1119; HARALICK RM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P385, DOI 10.1109/CVPR.1994.323855; HIGASHINO J, 1986, P ICPR 86, P745; Hitz O., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P374, DOI 10.1109/ICDAR.1999.791802; *INT ORG STAND, 1986, 8879 ISOIEC; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; KANAI J, 1991, P C INT TEXT IM HAND, P194; KRISHNAMOORTHY M, 1993, IEEE T PATTERN ANAL, V15, P737, DOI 10.1109/34.221173; Lee KH, 2000, ENG APPL ARTIF INTEL, V13, P165, DOI 10.1016/S0952-1976(99)00049-4; Lefevre P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P480, DOI 10.1109/ICDAR.1995.599040; Mao S, 2000, PROC SPIE, V3967, P303; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; Nagy G., 1988, P ACM C DOC PROC SYS, P169; NAGY G, 1984, P 7 INT C PATT REC M, P347; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570; Niyogi D, 1996, INT J IMAG SYST TECH, V7, P330, DOI 10.1002/(SICI)1098-1098(199624)7:4<330::AID-IMA8>3.0.CO;2-9; O'Gorman L., 1995, DOCUMENT IMAGE ANAL; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9; Phillips I. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P478, DOI 10.1109/ICDAR.1993.395691; SAITOH T, 1994, IEICE T INF SYST, VE77D, P778; Sauvola J, 1997, WORKSHOP ON DOCUMENT IMAGE ANALYSIS (DIA'97), PROCEEDINGS, P44, DOI 10.1109/DIA.1997.627091; Tang YY, 1996, PATTERN RECOGN, V29, P1931, DOI 10.1016/S0031-3203(96)00044-1; TSUJIMOTO S, 1992, P IEEE, V80, P1133, DOI 10.1109/5.156475; WANG D, 1989, COMPUT VISION GRAPH, V47, P327, DOI 10.1016/0734-189X(89)90116-3; *WORLD WID WEB CON, 1998, EXT MARK LANG XML 1; Worring M., 1999, International Journal on Document Analysis and Recognition, V1, P209, DOI 10.1007/s100320050020; Yamashita A, 1996, IBM J RES DEV, V40, P341, DOI 10.1147/rd.403.0341; Yu B, 1996, PATTERN RECOGN, V29, P1599, DOI 10.1016/0031-3203(96)00020-9; ZLATOPOLSKY AA, 1994, PATTERN RECOGN LETT, V15, P699, DOI 10.1016/0167-8655(94)90074-4	43	24	26	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1224	1240						17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200002
J	Atallah, M; Genin, Y; Szpankowski, W				Atallah, M; Genin, Y; Szpankowski, W			Pattern matching image compression: Algorithmic and empirical results	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						lossy Lempel-Ziv scheme; approximate pattern matching; image compression; generalized Shannon entropy; Hamming and square root distortion; algorithms on words; Fast Fourier Transform	LEMPEL-ZIV ALGORITHM; FIDELITY-CRITERION; SUFFIX TREE; UNIVERSAL	We propose a nontransform image compression scheme based on approximate one-dimensional pattern matching that we name Pattern Matching image Compression (PMIC). The main idea behind it is a lossy extension of the Lempel-Ziv data compression scheme in which one searches for the longest prefix of an uncompressed image that approximately occurs in the already processed image (e.g., in the sense of the Hamming distance or, alternatively, of the square error distortion). This main algorithm is enhanced with several new features such as searching for reverse approximate matching, recognizing substrings in images that are additively shifted versions of each other, introducing a variable and adaptive maximum distortion level D, and so forth. These enhancements are crucial to the overall quality of our scheme and their efficient implementation leads to algorithmic issues of interest in their own right. Both algorithmic and experimental results are presented. Our scheme turns out to be competitive with JPEG and wavelet compression for good quality graphical images. We also review related theoretical results.	Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA; Ecole Meteorol, F-30157 Toulouse, France	Purdue University System; Purdue University; Purdue University West Lafayette Campus; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite de Toulouse; Institut National Polytechnique de Toulouse	Atallah, M (corresponding author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.	mja@cs.purdue.edu; yann.genin@meteo.fr; spa@cs.purdue.edu						ABRAHAMSON K, 1987, SIAM J COMPUT, V16, P1039, DOI 10.1137/0216067; Alzina M, 1999, IEEE DATA COMPR CONF, P424, DOI 10.1109/DCC.1999.755692; APOSTOLICO A, 1992, J ALGORITHM, V13, P446, DOI 10.1016/0196-6774(92)90049-I; ARNAUD D, 1997, P DAT COMPR C SNOWB; ARNAUD D, 1996, CSDTR96069 PURD U; ARRATIA R, 1989, ANN PROBAB, V17, P1152, DOI 10.1214/aop/1176991262; ATALLAH M, 1996, P INT C IM PROC LAUS, V2, P349; ATALLAH M, 1992, LNCS, P27; Berger T., 1971, RATE DISTORTION THEO; CONSTANTINESCU C, 1994, P IEEE, V82, P933, DOI 10.1109/5.286197; Cornsweet T., 1970, VISUAL PERCEPTION; CROCHEMORE M, 1995, TEXT ALGORITHMS; DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733; FINAMORE W, 1993, 11 BRAS TEL C, P141; Fisher Y., 1992, Image and text compression, P35; Galil Z., 1988, Journal of Complexity, V4, P33, DOI 10.1016/0885-064X(88)90008-8; Gersho A., 1992, VECTOR QUANTIZATION; Gusfield D., 1997, ALGORITHMS STRINGS T; Jain A. K., 1989, FUNDAMENTALS DIGITAL; KIEFFER J, COMMUNICATION; KIEFFER JC, 1993, IEEE T INFORM THEORY, V39, P1473, DOI 10.1109/18.259634; Knuth D. E., 1981, ART COMPUTER PROGRAM, V2; KOGA H, 1994, P 1994 IEEE INT S IN, P24; KONTOYIANNIS I, 1998, UNPUB OPTIMALITY MEM; Luczak T, 1997, IEEE T INFORM THEORY, V43, P1439, DOI 10.1109/18.623143; LUCZAK T, 1994, P COMB PATT MATCH AS, P102; ORNSTEIN DS, 1990, ANN PROBAB, V18, P441, DOI 10.1214/aop/1176990840; Rabbani M., 1991, DIGITAL IMAGE COMPRE; SADEH I, 1993, P DAT COMPR C, P148; SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085; STEINBERG Y, 1993, IEEE T INFORM THEORY, V39, P877, DOI 10.1109/18.256495; SZPANKOWSKI W, 1993, SIAM J COMPUT, V22, P1176, DOI 10.1137/0222070; SZPANKOWSKI W, 1991, P DATA COMPRESSION C, P247; WYNER AD, 1989, IEEE T INFORM THEORY, V35, P1250, DOI 10.1109/18.45281; WYNER AD, 1994, P IEEE, V82, P872, DOI 10.1109/5.286191; Yang EH, 1996, IEEE T INFORM THEORY, V42, P239, DOI 10.1109/18.481794; Yang EH, 1998, IEEE T INFORM THEORY, V44, P47, DOI 10.1109/18.650987; ZAMIR R, 1999, UNPUB NATURAL TYPE S; Zhang Z, 1996, IEEE T INFORM THEORY, V42, P803; ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714; ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934; ZIV J, 1980, IEEE T INFORM THEORY, V26, P137, DOI 10.1109/TIT.1980.1056164	43	24	26	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					614	627		10.1109/34.777372	http://dx.doi.org/10.1109/34.777372			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT		Green Submitted			2022-12-18	WOS:000081472600004
J	Anelli, G; Broggi, A; Destri, G				Anelli, G; Broggi, A; Destri, G			Decomposition of arbitrarily shaped binary morphological structuring elements using genetic algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; arbitrarily shaped structuring element decomposition; genetic algorithms		A number of different algorithms have been described in the literature for the decomposition of both convex binary morphological structuring elements and a specific subset of nonconvex ones. Nevertheless, up to now no deterministic solutions have been found to the problem of decomposing arbitrarily shaped structuring elements. This work presents a new stochastic approach based on Genetic Algorithms in which no constraints are imposed on the shape of the initial structuring element, nor assumptions are made on the elementary factors, which are selected within a given set.	Univ Parma, Dipartimento Ingn Informaz, I-43100 Parma, Italy	University of Parma	Anelli, G (corresponding author), Univ Parma, Dipartimento Ingn Informaz, I-43100 Parma, Italy.			Broggi, Alberto/0000-0002-0893-1331				ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; BROGGI A, 1994, P 27 HAW INT C SYST, V1, P321; FALKENAUER E, 1994, EVOLUTIONARY COMPUTA, V2; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; Goldberg D. E., 1990, Complex Systems, V4, P415; Goldberg D. E., 1989, COMPLEX SYST, V3, P493, DOI DOI 10.1007/978-1-4757-3643-4; Goldberg DE, 1989, GENETIC ALGORITHMS S; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Holland JH., 1975, ADOPTION NATURAL ART; Mahfoud S. W., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P188, DOI 10.1109/ICEC.1994.350018; MATHERON G., 1975, RANDOM SETS INTEGRAL; MICHALEWICZ Z, 1992, GENETIC ALGORITHMS P; PARK H, 1994, IEEE T PATTERN ANAL, V16; PARK H, 1995, IEEE T PATTERN ANAL, V17; Serra J, 1982, IMAGE ANAL MATH MORP; SRINIVAS M, 1994, IEEE T SYSTEM MAN CY, V24; VANDENBOOMGAARD R, 1992, CVGIP-GRAPH MODEL IM, V54, P252, DOI 10.1016/1049-9652(92)90055-3; VANDENBOOMGAARD R, 1992, THESIS U AMSTERDAM; WILSON SS, 1992, IEEE T PATTERN ANAL, V14, P636, DOI 10.1109/34.141554; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	20	24	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					217	224		10.1109/34.659943	http://dx.doi.org/10.1109/34.659943			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800012
J	Matalas, I; Benjamin, R; Kitney, R				Matalas, I; Benjamin, R; Kitney, R			An edge detection technique using the facet model and parameterized relaxation labeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; relaxation labeling; facet model; curve enhancement; computer vision; image analysis		We present a method for detecting and labeling the edge structures in digital gray-scale images in two distinct stages: First, a variant of the cubic facet model is applied to detect the location, orientation and curvature of the putative edge points, Next, a relaxation labeling network is used to reinforce meaningful edge structures and suppress noisy edges. Each node label of this network isa 3D vector parameterizing the orientation and curvature information of the corresponding Edge point. A hysterisis step in the relaxation process maximizes connected contours. For certain types of images, prefiltering by adaptive smoothing improves robustness against noise and spatial blurring.			Matalas, I (corresponding author), UNIV LONDON IMPERIAL COLL SCI TECHNOL & MED,DEPT ELECT & ELECT ENGN,BIOMED SYST GRP,LONDON SW7 2BT,ENGLAND.							BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9; Canny J., 1986, IEEE T PATTERN ANAL, VPAMI-8; Canny J.F., 1983, AITR720 MIT ART INT, P6; DUNCAN JS, 1992, IEEE T PATTERN ANAL, V14; HANCOCK ER, 1992, P 11 INT C PATT REC, V2, P140; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12; Haralick R., 1984, IEEE T PATTERN ANAL, V6; Haralick R.M., 1992, COMPUTER ROBOT VISIO, V1; HILDRETH EC, 1980, 579 MIT AI; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5; IVERSON L, 1987, P IEEE WORKSH COMP V; JEONG H, 1992, IEEE T PATTERN ANAL, V14; LU Y, 1991, IEEE T PATTERN ANAL, V13; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NALWA VS, 1984, IEEE T PATTERN ANAL, V6; PARENT P, 1989, IEEE T PATTERN ANAL, V11; Perona P., 1990, IEEE T PATTERN ANAL, V12; PETROU M, 1991, IEEE T PATTERN ANAL, V13; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13; TORRE V, 1986, IEEE T PATTERN ANAL, V8; ZIOU D, 1993, PATTERN RECOGN, V26, P1305, DOI 10.1016/0031-3203(93)90137-L; ZUCKER SW, 1988, P 2 ICCV TARP SPRING; ZUNIGA OA, 1987, IEEE T SYST MAN CYBE, V17	27	24	48	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					328	341		10.1109/34.588006	http://dx.doi.org/10.1109/34.588006			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200004
J	GAZULA, S; KABUKA, MR				GAZULA, S; KABUKA, MR			DESIGN OF SUPERVISED CLASSIFIERS USING BOOLEAN NEURAL NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BOOLEAN NEURAL NETWORKS; PATTERN CLASSIFICATION; HIGH PERFORMANCE RECOGNITION NEURAL NETWORKS; PATTERN ANALYSIS; PATTERN RECOGNITION		In this paper we present two supervised pattern classifiers designed using Boolean neural networks (BNN). They are 1) nearest-to-an-exemplar (NTE) and 2) Boolean k-nearest neighbor (BKNN) classifier. The emphasis during the design of these classifiers was on simplicity, robustness, and the ease of hardware implementation. The classifiers use the idea of radius of attraction (ROA) to achieve their goal. Mathematical analysis of the algorithms presented in the paper is done to prove their feasibility. Both classifiers are tested with well-known binary and continuous feature valued data sets yielding results comparable with those obtained by similar existing classifiers.			GAZULA, S (corresponding author), UNIV MIAMI,DEPT ELECT & COMP ENGN,CORAL GABLES,FL 33124, USA.							Aleksander I., 1989, NEURAL COMPUTING ARC, P133; ANDERSON J, 1990, SEP P IEEE VID C NEU; BHIDE S, 1993, JUL P WORLD C NEUR N, P239; DASARATHY BV, 1977, SEP P INT C CYB SOC, P630; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GALLINARI P, NEURAL NETWORKS, V4, P349; GORSE D, 1989, PHYSICA D, V34, P90, DOI 10.1016/0167-2789(89)90229-7; Hecht-Nielsen R., 1989, NEUROCOMPUTING; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Huang W. Y., 1988, NEURAL INFORMATION P, P387; HUSSAIN B, 1992, 2ND P INT C AUT ROB; HUSSAIN B, 1992 P SPIE INT S OP; HUSSAIN B, 1994, JAN IEEE T PATT AN M, V16; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAIN AK, 1991, P INT JOINT C NEUR N, V2, P515; JI C, P IJCNN 91, V2, P127; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; OLAFSSON S, 1988, IEEE T PATTERN ANAL, V10, P277, DOI 10.1109/34.3890; PAPADAKIS INM, 1991, P IJCNN, P17; PENNY WD, 1992, JUN P IJCNN BALT, P845; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; Tou JT, 1974, PATTERN RECOGN	22	24	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1239	1246		10.1109/34.476519	http://dx.doi.org/10.1109/34.476519			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500014
J	TAGARE, HD; VOS, FM; JAFFE, CC; DUNCAN, JS				TAGARE, HD; VOS, FM; JAFFE, CC; DUNCAN, JS			ARRANGEMENT - A SPATIAL RELATION BETWEEN PARTS FOR EVALUATING SIMILARITY OF TOMOGRAPHIC SECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ARRANGEMENT; IMAGE DATABASES; RECOGNITION FROM PARTS; MEDICAL IMAGE PROCESSING; TOMOGRAPHY; VORONOI DIAGRAM		Medical tomographic images are formed by the intersection of the image plane and an object. As the image plane changes, different parts of the object come In view or drop out of view. However, for small changes of the image plane, most parts continue to remain visible and their qualitative embedding in the image remains similar, Therefore, similarity of part embeddings can be used to infer similarity of image planes, Part embeddings are useful features for other vision applications as well. In view of this, a spatial relation called ''arrangement'' is proposed to describe part embeddings, The relation describes how each part is surrounded by its neighbors, Further, a metric for arrangements is formulated by expressing arrangements in terms of the Voronoi diagram of the parts. Arrangements and their metric are used to retrieve images by image plane similarity in a cardiac magnetic resonance image database, Experiments with the database are reported which 1) validate the observation that similarity of image planes can be inferred from similarity of part embeddings, and 2) compare the performance of arrangement based image retrieval with that of expert radiologists.	YALE UNIV,DEPT COMP SCI,NEW HAVEN,CT 06520; UNIV AMSTERDAM,DEPT MATH & COMP SCI,AMSTERDAM,NETHERLANDS; YALE UNIV,DEPT ELECT ENGN,NEW HAVEN,CT 06520	Yale University; University of Amsterdam; Yale University	TAGARE, HD (corresponding author), YALE UNIV,DEPT DIAGNOST RADIOL,NEW HAVEN,CT 06520, USA.							Aurenhammer F., 1991, ACM COMPUTING SURVEY, V23; Ballard D.H., 1982, COMPUTER VISION; Bruce JW, 1984, CURVES SINGULARITIES; ELLIS HD, 1981, PERCEIVING REMEMBERI; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FRANTZ ROBERT L., 1961, SCI AMER, V204, P66; HILDRETH EC, 1989, F COGNITIVE SCI; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; Newman M.H.A., 1964, ELEMENTS TOPOLOGY PL, V2nd ed.; PERRET DI, 1989, SEEING CONTOUR COLOR; RIVIER N, 1987, ADV PHYS, V36, P95, DOI 10.1080/00018738700101961; SENECHAL M, 1989, BRIEF INTRO MATH QUA; Serra J, 1982, IMAGE ANAL MATH MORP; TAGARE HD, 1992, 9602 YAL U CTR SYST; TAGARE HD, 1993, LECTURE NOTES COMPUT, P687; TRUVE S, 1988, NATURAL COMPUTATION; WEAIRE D, 1984, CONTEMP PHYS, V25, P59, DOI 10.1080/00107518408210979; Wilson R. J., 1985, INTRO GRAPH THEORY; YOUNG AW, 1985, NEUROPSYCHOLOGIA, V23, P195, DOI 10.1016/0028-3932(85)90103-4	19	24	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					880	893		10.1109/34.406653	http://dx.doi.org/10.1109/34.406653			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989		Green Submitted			2022-12-18	WOS:A1995RR98900005
J	CHO, K; DUNN, SM				CHO, K; DUNN, SM			LEARNING SHAPE CLASSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE CLASSIFICATION; SHAPE REPRESENTATION; LEARNING; LEARNING SHAPE CLASSES; SHAPE LEARNING SYSTEMS; CONJUNCTIONS OF LOCAL PROPERTIES; PROPERTY BASED LEARNING	PLANAR CURVES; RECOGNITION	This correspondence is a summary of a new approach to learning shape concepts. In this system, a shape is represented by conjunctions of local shape properties. Conjunctions of local properties are consistent and unique for distinct shapes and are robust enough to represent shape in the presence of occlusion. A new learning method, called property based learning, is developed and used to learn conjunctions of local properties. Unlike other classification methods based on distances or similarities, classification performance does not degrade linearly as the number of classes increases and classification can be done correctly with only partial information of instances. Property based learning is an incremental learning method that selects properties crucial for classification. Two experiments are reported. In the first experiment with tool shapes, This shape learning system is used to classify shapes in the presence of view point changes, local movements such as moving handles of pliers, and occlusion. In the second experiment with hand gestures, The system can classify different gestures regardless of the movement in joints, fingers, and palms.	RUTGERS UNIV STATE,DEPT BIOMED ENGN,PISCATAWAY,NJ 08855	Rutgers State University New Brunswick	CHO, K (corresponding author), RUTGERS UNIV STATE,DEPT ELECT & COMP ENGN,POB 909,PISCATAWAY,NJ 08855, USA.							AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BURNS JB, 1984, IMAGE UNDERSTANDING, P165; CHO K, 1992, THESIS RUTGERS U; CONNELL JH, 1987, ARTIF INTELL, V34, P159; CROMWELL RL, 1991, 9TH P NAT C ART INT, P710; Duda R.O., 1973, J ROYAL STAT SOC SER; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; Everitt B., 1980, CLUSTER ANAL; FUKUNAGA K, 1990, INTRO STATISTICAL PA; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; Marr D., 1982, VISION; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349, DOI 10.1109/TPAMI.1980.4767034; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MILNER PM, 1974, PSYCHOL REV, V81, P521, DOI 10.1037/h0037149; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1983, MACHINE LEARNING ART; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salzberg SL, 1990, LEARNING NESTED GENE; SEGEN J, 1988, 5TH P INT C MACH LEA, P29; Shepherd B., 1983, P IJCAI, P473; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; Winston P. H., 1975, PSYCHOL COMPUTER VIS	26	24	24	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					882	888		10.1109/34.310683	http://dx.doi.org/10.1109/34.310683			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200003
J	SCHMIDT, WAC; DAVIS, JP				SCHMIDT, WAC; DAVIS, JP			PATTERN-RECOGNITION PROPERTIES OF VARIOUS FEATURE SPACES FOR HIGHER-ORDER NEURAL NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FEATURE SPACE; GEOMETRIC INVARIANCE; HIGHER ORDER NEURAL NETWORKS; PATTERN RECOGNITION; TARGET DETECTION; TEMPLATE MATCHING; TEMPLATES		Higher order neural networks (HONN's) are a form of preprocessing for the standard backpropagation neural networks that use geometrically motivated nonlinear combinations of scene pixels to achieve invariant pattern recognition feature spaces. In standard backpropagation, scene pixel values are presented directly to the neural network input nodes. By proper choice of HONN pixel combinations, it is possible to directly incorporate geometric invariance properties into the HONN. The HONN can be considered to be a particular type of preprocessing that explicitly creates nonlinear decision surfaces. Originally, HONN's had fully interconnected input pixels that caused a severe storage requirement. We explore alternatives that reduce the number of network weights while maintaining geometric invariant properties for recognizing patterns in real-time processing applications. This study is limited to translation and rotation invariance. We are primarily interested in examining the properties of various feature spaces for HONN's, in correlated and uncorrelated noise, such as the effect of various types of input features, feature size and number of feature pixels, and effect of scene size. We also consider the HONN training robustness in terms of target detectability. The experimental setup consists of a 15 x 20 pixel scene possibly containing a 3 x 10 target. Each trial used 500 training scenes plus 500 testing scenes. Results indicate that HONN's yield similar geometric invariant target recognition properties to classical template matching. However, the HONN's require an order of magnitude less computer processing time compared with template matching. For our simple target, HONN's with zero hidden layers yield results equivalent to HONN's with multiple layers. This reduces network training time over the multiple layer networks. Finally HONN's exhibit robust training characteristics. The HONN's that were trained at one input noise level and tested at a different level maintained similar probability of detection and probability of false alarm characteristics than did the HONN's that were trained and tested at the same input noise levels. Results indicate that HONN's could be considered for real-time target recognition applications.			SCHMIDT, WAC (corresponding author), USN,CTR AIR DEV,DEPT MISS & AVION TECHNOL,WARMINSTER,PA 18974, USA.							DUDA RO, 1973, PATTERN CLASSIFICATI, P276; GILES CL, 1987, APPL OPTICS, V26, P2972; HU M, 1992, IRE T INFORM THEORY, V8, P179; REID MB, 1989, JUN P INT JOINT NEUR; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1-2; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264667; SPIRKOVSKA L, 1990, FEB P INT JOINT C NE; WIDROW B, 1987, 1ST P IEEE INT C NEU, V2, P411	8	24	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					795	801		10.1109/34.236250	http://dx.doi.org/10.1109/34.236250			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800004
J	RICHETIN, M; DHOME, M; LAPRESTE, JT; RIVES, G				RICHETIN, M; DHOME, M; LAPRESTE, JT; RIVES, G			INVERSE PERSPECTIVE TRANSFORM USING ZERO-CURVATURE CONTOUR POINTS - APPLICATION TO THE LOCALIZATION OF SOME GENERALIZED CYLINDERS FROM A SINGLE VIEW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						GENERALIZED CYLINDERS; INVERSE PERSPECTIVE TRANSFORM; SINGLE PERSPECTIVE VIEW; 3-D LOCALIZATION FROM CONTOURS; ZERO-CURVATURE CONTOUR POINTS		This correspondence deals with the localization of some kinds of modeled generalized cylinders from a single brightness perspective image. It is shown how the zero-curvature points of their contours can be used to solve the inverse perspective problem. First, we recall three key theorems about the perspective projection of space curves and of the limbs of a straight homogeneous generalized cylinder whose scaling function has at least one zero-curvature point. Secondly, in view of the localization of homogeneous generalized cylinders, an algorithm previously developed by the authors is adapted, which estimates the pose of a line-triplet. Finally, a new theoretical result about the inverse perspective projection of cones of revolution useful for the localization of objects of revolution is presented. Both corresponding algorithms have been implemented and results of experiments demonstrate the feasibility of the proposed localization methods.			RICHETIN, M (corresponding author), BLAISE PASCAL UNIV,ELECTR LAB,CNRS,URA 830,F-63177 CLERMONT FERRAND,FRANCE.							Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; DHOME M, 1990, 1ST P EUR C COMP VIS, P475; FAUGERAS OD, 1988, INRIA790 RES REP; Horn B., 1986, ROBOT VISION, P1; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; Levine M., 1985, VISION MAN MACHINE; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; MARIMONT DH, 1984, 4TH P NAT C ART INT, P237; MOKTARIAN F, 1986, IEEE PATTERN ANAL MA, V8, P34; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1987, INT J COMPUT VISION, V1, P195, DOI 10.1007/BF00127820; PONCE J, 1989, NOV P IEEE WORKSH IN, P61; REIS P, 1989, 7TH P AFCET INRIA RE, P1091; RICHETIN M, 1987, 6TH P AFCET INRIA RE, P671; VERRI A, 1986, MIT AIM832 AI LAB ME	16	24	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					185	192		10.1109/34.67647	http://dx.doi.org/10.1109/34.67647			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900007
J	KAMGARPARSI, B; KAMGARPARSI, B; NETANYAHU, NS				KAMGARPARSI, B; KAMGARPARSI, B; NETANYAHU, NS			A NONPARAMETRIC METHOD FOR FITTING A STRAIGHT-LINE TO A NOISY IMAGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									USN,RES LAB,CTR APPL RES ARTIFICIAL INTELLIGENCE,WASHINGTON,DC 20375	United States Department of Defense; United States Navy; Naval Research Laboratory	KAMGARPARSI, B (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742, USA.							ATKINS GL, 1980, ANAL BIOCHEM, V104, P1, DOI 10.1016/0003-2697(80)90268-7; BROWN GW, 1951, 2ND P BERK S MATH ST; BROWN ML, 1982, J AM STAT ASSOC, V77, P71, DOI 10.2307/2287771; CORNISHB.A, 1974, BIOCHEM J, V139, P721, DOI 10.1042/bj1390721; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; MILLER RG, 1986, ANOVA BASICS APPLIED, pCH5; NETANYAHU NS, UNPUB APPLICATION DI; PRESS WH, 1986, NUMERICAL RECEPIES P, P459; Puri ML., 1985, NONPARAMETRIC METHOD; RUPERT D, 1980, J AM STAT ASSOC, V75, P828; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; WEISS I, 1989, IEEE T PATTERN ANAL, V11, P325, DOI 10.1109/34.21801; [No title captured]	15	24	25	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					998	1001		10.1109/34.35504	http://dx.doi.org/10.1109/34.35504			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800011
J	AISBETT, J				AISBETT, J			OPTICAL-FLOW WITH AN INTENSITY-WEIGHTED SMOOTHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											AISBETT, J (corresponding author), AUSTRALIAN DEF SCI & TECHNOL ORG,SURVEILLANCE RES LAB,SALISBURY,SA 5108,AUSTRALIA.							ANANDAN P, 1984, SPIE INTELL ROBOTS C, V521, P184; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; DEMLING L, 1972, ENDOSCOPY BIOPSY ESO; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; Fitzpatrick J. M., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P78; Gill P. E., 1981, PRACTICAL OPTIMIZATI; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; Hildreth E., 1984, MEASUREMENT VISUAL M; HOFF W, 1986, P INT C PATTERN RECO, P516; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NAGEL HH, 1983, P INT JOINT C ART IN, P945; Nolan, 1980, DOUBLE CONTRAST BARI; PRAZDNY K, 1985, BIOL CYBERN, V52, P93, DOI 10.1007/BF00363999; PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617, DOI 10.1109/TPAMI.1985.4767709; SCHUNCK BG, 1986, COMPUT VISION GRAPH, V35, P20, DOI 10.1016/0734-189X(86)90124-6; SCHUNCK BG, 1986, P WORKSHOP MOTION; TSUKIYAMA T, 1986, P IEEE INT C PATTERN, P165; VERRI A, 1987, 1ST P INT C COMP VIS, P171; VERSTAPPEN HT, 1977, REMOTE SENSING GEOMO	26	24	24	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					512	522		10.1109/34.24783	http://dx.doi.org/10.1109/34.24783			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400006
J	WEISS, I				WEISS, I			LINE FITTING IN A NOISY IMAGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WEISS, I (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742, USA.							ROSENFELD A, 1986, CARTR189 U MARYL COL	1	24	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					325	329		10.1109/34.21801	http://dx.doi.org/10.1109/34.21801			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000012
J	RONSE, C				RONSE, C			A BIBLIOGRAPHY ON DIGITAL AND COMPUTATIONAL CONVEXITY (1961-1988)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Bibliography											RONSE, C (corresponding author), PHILIPS RES LAB BRUSSELS,AV E VAN BECELAERE 2,BOX 8,B-1170 BRUSSELS,BELGIUM.								0	24	24	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					181	183		10.1109/34.16713	http://dx.doi.org/10.1109/34.16713			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900006
J	DEROUAULT, AM; MERIALDO, B				DEROUAULT, AM; MERIALDO, B			NATURAL-LANGUAGE MODELING FOR PHONEME-TO-TEXT TRANSCRIPTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DEROUAULT, AM (corresponding author), IBM FRANCE,CTR SCI,36 AVE RAYMOND POINCARE,F-75116 PARIS,FRANCE.							BAHL L, 1984, MAR IEEE INT C AC SP; Baum LE, 1972, INEQUALITIES, V3, P1; DEROUAULT AM, 1984, MAR IEEE INT C AC SP; DEROUAULT AM, 1984, 7TH INT C PATT REC M; FUSIJAKI T, 1984, 10TH P INT C COMP LI, P16; JELINEK F, 1983, IEEE T PATTERN ANAL, V5; NEWITT JW, 1970, IBM SYST J, V9; ZUE VW, 1983, TRENDS APPLICATIONS	8	24	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1986	8	6					742	749		10.1109/TPAMI.1986.4767855	http://dx.doi.org/10.1109/TPAMI.1986.4767855			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	E4469	21869369				2022-12-18	WOS:A1986E446900005
J	HORN, BKP; WELDON, EJ				HORN, BKP; WELDON, EJ			FILTERING CLOSED CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV HAWAII,DEPT ELECT ENGN,HONOLULU,HI 96822	University of Hawaii System	HORN, BKP (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.		Rohlf, F J/A-8710-2008	/0000-0003-3434-391X				ASADA H, 1984, MIT758 A I LAB MEM; Benson RV, 1966, EUCLIDEAN GEOMETRY C; COSGRIFF RL, 1960, ASTIA AO254792 REP; HORN BK, 1984, P IEEE, V72; LAWRENCE JD, 1972, CATALOG SPECIAL CURV; LOZANOPEREZ T, 1983, IEEE T COMPUT, V32, P108, DOI 10.1109/TC.1983.1676196; LUYSTERNIK LA, 1963, CONVEX FIGURES POLYH; MOKHTARIAN F, 1984, 5TH P CAN SOC COMP S; NAJFELD I, 1980, LINEAR ALGEBRA APPL, V29, P259, DOI 10.1016/0024-3795(80)90246-3; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	10	24	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					665	668		10.1109/TPAMI.1986.4767839	http://dx.doi.org/10.1109/TPAMI.1986.4767839			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584	21869363				2022-12-18	WOS:A1986D758400007
J	FU, KS; BOOTH, TL				FU, KS; BOOTH, TL			GRAMMATICAL INFERENCE - INTRODUCTION AND SURVEY .1.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CONNECTICUT,DEPT ELECT ENGN & COMP SCI,STORRS,CT 06268; PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	University of Connecticut; Purdue University System; Purdue University; Purdue University West Lafayette Campus								Aho A. V., 1972, PARSING, V1; BHARGAVA BK, 1974, 1974 IEEE SYST MAN C; BIERMANN AW, 1971, 4TH HAW INT C SYST S; BIERMANN AW, 1970, AIM114 STANF U STANF; BIERMANN AW, 1971, JAN INT C FRONT PATT; BIERMANN AW, 1971, IEEE T COMPUT, V21, P592; Booth TL, 1967, SEQUENTIAL MACHINES; BOOTH TL, 1969, 10TH ANN S SWITCH AU; Chomsky N., 1964, ASPECTS THEORY SYNTA; CRESPIREGHIZZI S, 1973, COMMUN ACM, V16, P83, DOI 10.1145/361952.361958; CRESPIREGHIZZI S, 1971, 711 I EL LAB CALC RE; CRESPIREGHIZZI S, 1971, 2ND INT JOINT C ART; CRESPIREGHIZZI S, 1971, P IFIP C; CRESPIREGHIZZI S, 1970, UCLAENG7054 U CAL TE; EVANS TG, 1971, SOFTWARE ENG, V2; FELDMAN J, 1972, INFORM CONTROL, V20, P244, DOI 10.1016/S0019-9958(72)90424-X; FELDMAN J, 1968, COMMUN ACM, V11, P77, DOI 10.1145/362896.362902; FELDMAN JA, 1969, AI93 STANF U STANF A; FELDMAN JA, 1972, CS255 STANF U COMP S; FELDMAN JA, 1967, 55 STANF U STANF ART; FELDMAN JA, 1969, CS125 STANF U COMP S; FLOYD RW, 1964, IEEE T COMPUT, VEC13, P346, DOI 10.1109/PGEC.1964.263813; Fu K. S., 1972, International Journal of Computer & Information Sciences, V1, P135, DOI 10.1007/BF00995736; Fu K. S., 1971, J CYBERNETICS, V1, P31, DOI 10.1080/01969727108548630; FU KS, 1971, JAN INT C FRONT PATT; FU KS, 1972, FRONTIERS PATTERN RE; FU KS, 1971, SOFTWARE ENG, V2; FU KS, 1974, SYNTACTIC METHODS PA, pCH7; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Hartmanis J., 1966, ALGEBRAIC STRUCTURE; Hopcroft J.E., 1969, FORMAL LANGUAGES THE; HORNING J, 1969, CS139 STANF U COMP S; HORNING JJ, 1971, P IFIP C; HUANG T, 1972, TREE725 PURD U SCH E; IRONS ET, 1961, COMMUN ACM, V4, P51, DOI 10.1145/366062.366083; KANEFF S, 1970, PICTURE LANGUAGE MAC; Klein S., 1970, Computer Studies in the Humanities and Verbal Behavior, V3, P144; LEAVENWORTH BM, 1964, COMMUN ACM, V7, P72, DOI 10.1145/363921.363932; LEE HC, 1972, 4TH P INT S COMP INF; LEE HC, 1972, TREE7217 PURD U SCH; NAUR P, 1960, COMMUN ACM, V3, P299; NAUR P, 1960, COMMUN ASS COMPUT MA, V3, P314; PAO TW, 1969, 6919 U PENNS MOOR SC; PATEL AR, 1972, THESIS U CONN STORRS; PEIZER DB, 1969, LANGUAGE, V45, P60, DOI 10.2307/411753; REYNOLDS JC, 1968, ANL96 APPL MATH DIV; ROSENBAUM PS, 1967, COMMUN ACM, V10, P630, DOI 10.1145/363717.363759; ROSS DT, 1963, 1963 SPRING JOINT CO; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P224, DOI 10.1016/S0019-9958(64)90131-7; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2; SOLOMONOFF RJ, 1959, INFORMATION PROCESSI; SUPPES P, 1970, SYNTHESE, V22, P95; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575	53	24	25	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					343	359		10.1109/TPAMI.1986.4767796	http://dx.doi.org/10.1109/TPAMI.1986.4767796			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	C0841	21869352				2022-12-18	WOS:A1986C084100005
J	DORST, L; DUIN, RPW				DORST, L; DUIN, RPW			SPIROGRAPH THEORY - A FRAMEWORK FOR CALCULATIONS ON DIGITIZED STRAIGHT-LINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											DORST, L (corresponding author), DELFT UNIV TECHNOL,DEPT APPL PHYS,PATTERN RECOGNIT GRP,DELFT,NETHERLANDS.							ARCELLI C, 1978, COMPUT VISION GRAPH, V7, P67, DOI 10.1016/S0146-664X(78)80014-8; BRONS R, 1974, COMPUT GRAPHICS IMAG, V3, P48; DUDA RO, 1973, PATTERN CLASSIFICATI, P369; GROEN FCA, 1978, COMPUT VISION GRAPH, V7, P391, DOI 10.1016/S0146-664X(78)80005-7; HARDY GH, 1979, INTRO THEORY NUMBERS, pCH3; HURWITZ A, 1894, MATH ANN, V44, P417; KNUTH D, 1971, ART COMPUTER PROGRAM, V2, P316; Lipkin BS, 1970, PICTURE PROCESSING P, P241; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; WU LD, 1982, IEEE T PATTERN ANAL, V4, P347, DOI 10.1109/TPAMI.1982.4767258	10	24	24	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					632	639		10.1109/TPAMI.1984.4767577	http://dx.doi.org/10.1109/TPAMI.1984.4767577			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869232				2022-12-18	WOS:A1984TM81300009
J	HULL, JJ; SRIHARI, SN; CHOUDHARI, R				HULL, JJ; SRIHARI, SN; CHOUDHARI, R			AN INTEGRATED ALGORITHM FOR TEXT RECOGNITION - COMPARISON WITH A CASCADED ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											HULL, JJ (corresponding author), SUNY BUFFALO, DEPT COMP SCI, AMHERST, NY 14226 USA.		Srihari, Sargur N/E-8100-2011					AMSLER RA, 1982, P NAT COMPUT C HOUST, P657; BLEDSOE W. W., 1966, P301; BOBROW RJ, 1980, P AAAI 80 NAT C ARTI, P316; BOUCHARD DC, 1980, SOCS805 MCGILL U SCH; Carroll JohnB., 1967, COMPUTATIONAL ANAL P; DOSTER W, 1980, 5TH P INT C PATT REC, P855; FISHER EG, 1976, THESIS U MASSACHUSET; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; HULL JJ, 1982, IEEE T PATTERN ANAL, V4, P520, DOI 10.1109/TPAMI.1982.4767297; KASHYAP RL, 1981, INFORM SCIENCES, V23, P123, DOI 10.1016/0020-0255(81)90052-9; Knuth D., 1973, ART COMPUTER PROGRAM, V3; Knuth DE, 1968, ART COMPUTER PROGRAM, VI; MUTH FE, 1977, INFORM PROCESS MANAG, V13, P329, DOI 10.1016/0306-4573(77)90053-X; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; PETERSON JL, 1980, COMMUN ACM, V23, P676, DOI 10.1145/359038.359041; ROSENBAUM WS, 1975, IBM J RES DEV, V19, P398, DOI 10.1147/rd.194.0398; Schank RC., 1980, AM J COMPUT LING, V6, P13; SHINGHAL R, 1979, INT J MAN MACH STUD, V11, P201, DOI 10.1016/S0020-7373(79)80017-6; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184, DOI 10.1109/TPAMI.1979.4766904; SRIHARI SN, 1983, ACM T OFF INF SYST, V1, P68, DOI 10.1145/357423.357428; Toussaint G. T., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P164; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; TURBA TN, 1981, JUN P ACM SIGPLAN SI, P51; ULLMANN JR, 1977, COMPUT J, V20, P141, DOI 10.1093/comjnl/20.2.141; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WINSTON PH, 1977, ARTIF INTELL, pCH9	26	24	32	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					384	395		10.1109/TPAMI.1983.4767408	http://dx.doi.org/10.1109/TPAMI.1983.4767408			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869123				2022-12-18	WOS:A1983RA57800004
J	TSAI, RY				TSAI, RY			MULTIFRAME IMAGE POINT MATCHING AND 3-D SURFACE RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											TSAI, RY (corresponding author), IBM CORP, THOMAS J WATSON RES CTR, YORKTOWN HTS, NY 10598 USA.							BAKER HH, 1981, 7TH P INT JOINT C AR; Duda R.O., 1973, J ROYAL STAT SOC SER; GENNERY DB, 1980, AIM339 STANF ART INT; GRIMSON WEL, 1980, THESIS MASSACHUSETTS; HENDERSON RL, 1979, SOC PHOTO OPT INSTRU, V186; HOGG RV, 1970, INTRO MATH STATISTIC; KEATING TJ, 1975, PHOTOGRAMMETRIC ENG, P994; MARR D, 1977, MIT AI451 MEM; MORAVEC HP, 1981, 7TH P INT JOINT C AR; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; NITZAN D, 1980, APR WORKSH RES NEED; PANTON DJ, 1978, PHOTOGRAMM ENG REM S, V44, P1499; Papoulis A., 2002, PROBABILITY RANDOM V; SHIRAI Y, 1979, COMPUTER VISION SENS; WANG MC, 1945, REV MOD PHYS, V17, P323, DOI 10.1103/RevModPhys.17.323; WILL PM, 1972, PR INST ELECTR ELECT, V60, P669, DOI 10.1109/PROC.1972.8726; Yagi, 1973, COMPUT VISION GRAPH, V2, P131; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0; 1980, MANUAL PHOTOGRAMMETR; [No title captured]	20	24	28	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					159	174		10.1109/TPAMI.1983.4767368	http://dx.doi.org/10.1109/TPAMI.1983.4767368			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869097				2022-12-18	WOS:A1983QJ97400004
J	SHLIEN, S				SHLIEN, S			A METHOD FOR COMPUTING THE PARTIAL SINGULAR VALUE DECOMPOSITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SHLIEN, S (corresponding author), COMMUN RES CTR,DEPT COMMUN,BOX 11490,OTTAWA K2H 8S2,ONTARIO,CANADA.							Acton F.S., 1970, NUMERICAL METHODS WO; ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309; ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766; ANDREWS HC, 1976, IEEE T COMPUT, V25, P72; ANDREWS HC, 1974, AM MATH MONTHLY, V82, P1; CRAMER H, 1945, MATH METHODS STATIST; GARGUIR N, 1979, IEEE T COMMUN, V27, P1230, DOI 10.1109/TCOM.1979.1094538; GOLUB GH, 1981, ACM T MATH SOFTWARE, V7, P149, DOI 10.1145/355945.355946; GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027; GOOD IJ, 1969, TECHNOMETRICS, V11, P823, DOI 10.2307/1266902; HANSON RJ, 1971, SIAM J NUMER ANAL, V8, P616, DOI 10.1137/0708058; HUANG TS, 1975, APPL OPTICS, V14, P2213, DOI 10.1364/AO.14.002213; Isaacson E., 1966, ANAL NUMERICAL METHO; KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314; Lawson C. L., 1974, SOLVING LEAST SQUARE; LUK FT, 1980, ACM T MATH SOFTWARE, V6, P524, DOI 10.1145/355921.355925; Nash J. C., 1979, COMPACT NUMERICAL ME; NASH JC, 1975, COMPUT J, P74; Noble B, 1969, APPL LINEAR ALGEBRA; SAHASRABUDHE SC, 1979, COMPUT VISION GRAPH, V9, P203, DOI 10.1016/0146-664X(79)90037-6; SAHASRABUDHE SC, 1979, IEEE T ACOUST SPEECH, V27, P434, DOI 10.1109/TASSP.1979.1163257; SHIM YS, 1981, IEEE T ACOUST SPEECH, V29, P904, DOI 10.1109/TASSP.1981.1163632; Stewart G., 1973, INTRO MATRIX COMPUTA; WIGGINS RA, 1972, REV GEOPHYS SPACE GE, V10, P251, DOI 10.1029/RG010i001p00251	24	24	24	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					671	676		10.1109/TPAMI.1982.4767324	http://dx.doi.org/10.1109/TPAMI.1982.4767324			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499645				2022-12-18	WOS:A1982PS23700016
J	FEKETE, G; EKLUNDH, JO; ROSENFELD, A				FEKETE, G; EKLUNDH, JO; ROSENFELD, A			RELAXATION - EVALUATION AND APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FEKETE, G (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							EKLUNDH JO, 1980, IEEE T PATTERN ANAL, V2, P72, DOI 10.1109/TPAMI.1980.4766973; EKLUNDH JO, 1980, IEEE T SYST MAN CYB, V10, P150; FAUGERAS O, P PRIP 79, P318; FEKETE G, 1979, THESIS U MARYLAND CO; Hanson A. R., 1978, COMPUTER VISION SYST, P129; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, P PRIP 79, P337; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SMITH RC, 1979, TR839 U MAR COMP SCI; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, P IJCAI 79, P1014	11	24	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					459	469		10.1109/TPAMI.1981.4767131	http://dx.doi.org/10.1109/TPAMI.1981.4767131			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868966				2022-12-18	WOS:A1981MQ35700010
J	ZUCKER, SW; LECLERC, YG; MOHAMMED, JL				ZUCKER, SW; LECLERC, YG; MOHAMMED, JL			CONTINUOUS RELAXATION AND LOCAL MAXIMA SELECTION - CONDITIONS FOR EQUIVALENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ZUCKER, SW (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,COMP VISION & GRAPH LAB,MONTREAL H3C 3G1,QUEBEC,CANADA.							Abelson H., 1978, Theoretical Computer Science, V6, P41, DOI 10.1016/0304-3975(78)90004-X; AMARI S, 1977, SYSTEMS NEUROSCIENCE; [Anonymous], 1975, PSYCHOL COMPUTER VIS; BARROW HG, 1976, 121 STANF RES I TECH; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; EKLUNDH J, 1978, TR662 U MAR COMP SCI; Hanson A., 1978, COMPUTER VISION SYST; HARALICK RM, 1978, CONSISTENT LABELING; Hardy G.H., 1934, INEQUALITIES; HAYES KC, THESIS U MARYLAND CO; HAYESROTH F, 1977, 5TH P INT JOINT C AR; HINTON GE, 1977, THESIS U EDINBURGH E; LEVINE MD, 1978, P CANADIAN SOC COMPU; Marr D, 1978, COMPUTER VISION SYST; Pavlidis T., 1977, STRUCTURAL PATTERN R; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; RISEMAN E, 1977, COMP GRAPHICS IMAGE, V6, P492; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1977, P IEEE C IMAGE P PAT; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; ULLMAN J, 1978, P NATO ASI DIGITAL I; ULLMAN S, 1978, BEHAV BRAIN SCI, V1, P117, DOI 10.1017/S0140525X00060076; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1977, IEEE T COMPUT, V26, P922; ZUCKER SW, 1977, PATTERN RECOGNITION; ZUCKER SW, 1978, 7815R MCGILL U DEP E; ZUCKER SW, 1976, 3RD P INT JOINT C PA; ZUCKER SW, 1978, IEEE C IMAGE PROCESS	29	24	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					117	127		10.1109/TPAMI.1981.4767069	http://dx.doi.org/10.1109/TPAMI.1981.4767069			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868926				2022-12-18	WOS:A1981MN96800001
J	Lu, XK; Wang, WG; Shen, JB; Crandall, DJ; Van Gool, L				Lu, Xiankai; Wang, Wenguan; Shen, Jianbing; Crandall, David J.; Van Gool, Luc			Segmenting Objects From Relational Visual Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Visualization; Integrated circuits; Task analysis; Frequency selective surfaces; Semantics; Message passing; Graph neural network; automatic video segmentation; image co-segmentation; few-shot semantic segmentation	SEGMENTATION; NETWORK	In this article, we model a set of pixelwise object segmentation tasks - automatic video segmentation (AVS), image co-segmentation (ICS) and few-shot semantic segmentation (FSS) - in a unified view of segmenting objects from relational visual data. To this end, we propose an attentive graph neural network (AGNN) that addresses these tasks in a holistic fashion, by formulating them as a process of iterative information fusion over data graphs. It builds a fully-connected graph to efficiently represent visual data as nodes and relations between data instances as edges. The underlying relations are described by a differentiable attention mechanism, which thoroughly examines fine-grained semantic similarities between all the possible location pairs in two data instances. Through parametric message passing, AGNN is able to capture knowledge from the relational visual data, enabling more accurate object discovery and segmentation. Experiments show that AGNN can automatically highlight primary foreground objects from video sequences (i.e., automatic video segmentation), and extract common objects from noisy collections of semantically related images (i.e., image co-segmentation). AGNN can even generalize segment new categories with little annotated data (i.e., few-shot semantic segmentation). Taken together, our results demonstrate that AGNN provides a powerful tool that is applicable to a wide range of pixel-wise object pattern understanding tasks with relational visual data. Our algorithm implementations have been made publicly available at https://github.com/carrierlxk/AGNN.	[Lu, Xiankai] Shangdong Univ, Sch Software, Jinan 250100, Shandong, Peoples R China; [Wang, Wenguan; Van Gool, Luc] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland; [Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Macau, Peoples R China; [Crandall, David J.] Indiana Univ, Luddy Sch Informat Comp & Engn, Bloomington, IN 47405 USA	Shandong University; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Macau; Indiana University System; Indiana University Bloomington	Wang, WG (corresponding author), Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.	carrierlxk@gmail.com; wenguan.wang@gmail.com; shenjianbingcg@gmail.com; djcran@indiana.edu; vangool@vision.ee.ethz.ch			National Natural Science Foundation of China [62106128]; Natural Science Foundation of Shandong Province [ZR2021QF001]; Young Elite Scientists Sponsorship Program by CAST; CCF-Baidu Open Fund	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Shandong Province(Natural Science Foundation of Shandong Province); Young Elite Scientists Sponsorship Program by CAST; CCF-Baidu Open Fund	This work was supported in part by the National Natural Science Foundation of China under Grant 62106128, in part by the Natural Science Foundation of Shandong Province under Grant ZR2021QF001, in part by the Young Elite Scientists Sponsorship Program by CAST, and in part by the CCF-Baidu Open Fund. (Corresponding author: Wenguan Wang.)	Ballas N., 2016, PROC INT C LEARN REP; Banerjee S, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P673; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chen H, 2019, LECT NOTES COMPUT SC, V11364, P435, DOI 10.1007/978-3-030-20870-7_27; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cho K., 2014, P 2014 C EMP METH NA, P1724; Dave A, 2019, IEEE INT CONF COMP V, P1493, DOI 10.1109/ICCVW.2019.00187; Duvenaud David K, 2015, P NIPS; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Faisal M, 2020, IEEE WINT CONF APPL, P1873, DOI 10.1109/WACV45572.2020.9093589; Faktor A., 2014, BMVC; Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164; Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582; Florian Schroff, 2017, Arxiv, DOI arXiv:1706.05587; Garcia Victor, 2017, ARXIV171104043; Gilmer J, 2017, PR MACH LEARN RES, V70; Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261; Hsu KJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P748; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jayaraman D, 2016, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2016.418; Jerripothula KR, 2017, PROC CVPR IEEE, P3881, DOI 10.1109/CVPR.2017.413; Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Jun Koh Y., 2018, PROC EUR C COMPUT VI, P517; Jure Leskovec, 2018, Arxiv, DOI arXiv:1709.05584; Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374; Nguyen K, 2019, IEEE I CONF COMP VIS, P622, DOI 10.1109/ICCV.2019.00071; Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008; Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342; Li W., 2018, PROC ASI C COMPUT VI, P435; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu JS, 2016, ADV NEUR IN, V29; Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258; Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374; Lu Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P490, DOI 10.1007/978-3-030-58568-6_29; Luiten J, 2020, IEEE WINT CONF APPL, P1989, DOI 10.1109/WACV45572.2020.9093285; Mingmin Zhen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P445, DOI 10.1007/978-3-030-58583-9_27; Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652; Niepert M, 2016, PR MACH LEARN RES, V48; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81; Rakelly Kate, 2018, ICLR WORKSH; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Shaban Amirreza, 2017, P BRIT MACH VIS C BM; Siam M, 2019, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2019.00535; Siam M, 2019, IEEE INT CONF ROBOT, P50, DOI 10.1109/ICRA.2019.8794254; Simonyan Karen, 2015, INT C LEARN REPR; Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44; Tao ZQ, 2017, AAAI CONF ARTIF INTE, P4285; Zhou TF, 2022, Arxiv, DOI arXiv:2107.01153; Tokmakov P, 2019, INT J COMPUT VISION, V127, P282, DOI 10.1007/s11263-018-1122-2; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic P., 2018, P INT C LEARN REPR, DOI DOI 10.17863/CAM.48429; Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34; Wang H., 2021, PROC IEEECVF C COMPU, P8455; Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929; Wang W., 2019, P IEEE C COMP VIS PA, P3064, DOI DOI 10.1109/CVPR.2019.00318; Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3508, DOI 10.1109/TPAMI.2021.3055780; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173; Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Xiankai Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P661, DOI 10.1007/978-3-030-58580-8_39; Xiankai Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8957, DOI 10.1109/CVPR42600.2020.00898; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yuan ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3371; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhang H, 2019, PR MACH LEARN RES, V97; Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zheng ZL, 2019, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2019.00683; Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156	96	23	23	7	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7885	7897		10.1109/TPAMI.2021.3115815	http://dx.doi.org/10.1109/TPAMI.2021.3115815			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34582345	Green Accepted			2022-12-18	WOS:000864325900045
J	Haris, M; Shakhnarovich, G; Ukita, N				Haris, Muhammad; Shakhnarovich, Greg; Ukita, Norimichi			Deep Back-ProjectiNetworks for Single Image Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image super-resolution; deep cnn; back-projection; deep concatenation; large scale; recurrent; residual	PROJECTION	Previous feed-forward architectures of recently proposed deep super-resolution networks learn the features of low-resolution inputs and the non-linear mapping from those to a high-resolution output. However, this approach does not fully address the mutual dependencies of low- and high-resolution images. We propose Deep Back-Projection Networks (DBPN), the winner of two image super-resolution challenges (NTIRE2018 and PIRM2018), that exploit iterative up- and down-sampling layers. These layers are formed as a unit providing an error feedback mechanism for projection errors. We construct mutually-connected up- and down-sampling units each of which represents different types of low- and high-resolution components. We also show that extending this idea to demonstrate a new insight towards more efficient network design substantially, such as parameter sharing on the projection module and transition layer on projection step. The experimental results yield superior results and in particular establishing new state-of-the-art results across multiple data sets, especially for large scaling factors such as 8x.	[Haris, Muhammad; Ukita, Norimichi] Toyota Technol Inst TTI, Intelligent Informat Media Lab, Nagoya, Aichi 4688511, Japan; [Shakhnarovich, Greg] Toyota Technol Inst Chicago, Chicago, IL 60637 USA	Toyota Technological Institute - Chicago	Haris, M (corresponding author), Toyota Technol Inst TTI, Intelligent Informat Media Lab, Nagoya, Aichi 4688511, Japan.	muhammad.haris@bukalapak.com; greg@ttic.edu; ukita@toyota-ti.ac.jp		Ukita, Norimichi/0000-0002-0240-1065	JSPS KAKENHI [19K12129]; AFOSR Center of Excellence in Efficient and Robust Machine Learning [FA9550-181-0166]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); AFOSR Center of Excellence in Efficient and Robust Machine Learning	This work was partly supported by JSPS KAKENHI Grant Number 19K12129 and by AFOSR Center of Excellence in Efficient and Robust Machine Learning, Award FA9550-181-0166.	Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Cheon M, 2019, LECT NOTES COMPUT SC, V11133, P51, DOI 10.1007/978-3-030-11021-5_4; Choi JH, 2020, NEUROCOMPUTING, V398, P347, DOI 10.1016/j.neucom.2019.06.103; Dai SY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1039; Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132; Denton E, 2015, DEEP GENERATIVE IMAG, DOI DOI 10.5555/; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong WS, 2009, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2009.5414423; Dosovitskiy Alexey, 2016, NEURIPS; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; Haris M, 2017, APPL OPTICS, V56, P6043, DOI 10.1364/AO.56.006043; Haris M, 2017, IEEE T GEOSCI REMOTE, V55, P4047, DOI 10.1109/TGRS.2017.2687419; Haris M, 2017, SIGNAL IMAGE VIDEO P, V11, P1, DOI 10.1007/s11760-016-0880-y; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kravitz DJ, 2013, TRENDS COGN SCI, V17, P26, DOI 10.1016/j.tics.2012.10.011; Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Lamme VAF, 2000, TRENDS NEUROSCI, V23, P571, DOI 10.1016/S0166-2236(00)01657-X; Larsson G., 2017, INT C LEARN REPR ICL; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li J., 2018, PROC EUR C COMPUT VI, DOI DOI 10.1007/978-3-030-01237-3_32; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lotter W., 2017, ICLR, DOI [DOI 10.48550/ARXIV.1605.08104, 10.48550/arXiv.1605.08104]; Luo X., 2018, P EUR C COMP VIS; Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009; Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z; Michelini P.N., 2018, EUR C COMP VIS, P3; Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726; Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27; Purohit K., 2018, P EUR C COMP VIS, P132; Radford A., 2016, ICLR 2016 INT C LEAR, DOI DOI 10.1007/S11280-018-0565-2; Ross S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2737, DOI 10.1109/CVPR.2011.5995724; Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479; Timofte R, 2018, IEEE COMPUT SOC CONF, P965, DOI 10.1109/CVPRW.2018.00130; Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206; Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8; Vasu S., 2018, ANAL PERCEPTION DIST, P114; Vu T., 2018, P EUR C COMP VIS, P98; Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002; Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Zamir AR, 2017, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2017.196; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhao Y, 2017, NEUROCOMPUTING, V226, P200, DOI 10.1016/j.neucom.2016.11.049	72	23	23	5	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4323	4337		10.1109/TPAMI.2020.3002836	http://dx.doi.org/10.1109/TPAMI.2020.3002836			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750788	hybrid			2022-12-18	WOS:000714203900014
J	Zhong, Z; Yang, ZC; Deng, BY; Yan, JJ; Wu, W; Shao, J; Liu, CL				Zhong, Zhao; Yang, Zichen; Deng, Boyang; Yan, Junjie; Wu, Wei; Shao, Jing; Liu, Cheng-Lin			BlockQNN: Efficient Block-Wise Neural Network Architecture Generation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Task analysis; Neural networks; Network architecture; Graphics processing units; Acceleration; Indexes; Convolutional neural network; neural architecture search; AutoML; reinforcement learning; Q-learning		Convolutional neural networks have gained a remarkable success in computer vision. However, most popular network architectures are hand-crafted and usually require expertise and elaborate design. In this paper, we provide a block-wise network generation pipeline called BlockQNN which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy. The optimal network block is constructed by the learning agent which is trained to choose component layers sequentially. We stack the block to construct the whole auto-generated network. To accelerate the generation process, we also propose a distributed asynchronous framework and an early stop strategy. The block-wise generation brings unique advantages: (1) it yields state-of-the-art results in comparison to the hand-crafted networks on image classification, particularly, the best network generated by BlockQNN achieves 2.35 percent top-1 error rate on CIFAR-10. (2) it offers tremendous reduction of the search space in designing networks, spending only 3 days with 32 GPUs. A faster version can yield a comparable result with only 1 GPU in 20 hours. (3) it has strong generalizability in that the network built on CIFAR also performs well on the larger-scale dataset. The best network achieves very competitive accuracy of 82.0 percent top-1 and 96.0 percent top-5 on ImageNet.	[Zhong, Zhao] Univ Chinese Acad Sci, Inst Automat, Chinese Acad Sci, NLPR, Beijing 100190, Peoples R China; [Yang, Zichen; Deng, Boyang; Yan, Junjie; Wu, Wei; Shao, Jing] Sensetime Res Inst, SenseTime Grp Ltd, Beijing, Peoples R China; [Liu, Cheng-Lin] Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China; [Liu, Cheng-Lin] Univ Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Liu, CL (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China.	zhao.zhong@nlpr.ia.ac.cn; yangzichen@sensetime.com; dengboyang@sensetime.com; yanjunjie@sensetime.com; wuwei@sensetime.com; shaojing@sensetime.com; liucl@nlpr.ia.ac.cn		Liu, Cheng-Lin/0000-0002-6743-4175	Major Project for New Generation of AI [2018AAA0100400]; National Natural Science Foundation of China (NSFC) [61721004, 61633021]	Major Project for New Generation of AI; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by the Major Project for New Generation of AI under Grant No.2018AAA0100400 and the National Natural Science Foundation of China (NSFC) Grants 61721004 and 61633021.	Andrychowicz M, 2016, ADV NEUR IN, V29; [Anonymous], 2013, COMPUT SCI; Bender G, 2018, PR MACH LEARN RES, V80; Bergstra James S, 2011, ADV NEURAL INFORM PR, P2546, DOI [10.5555/2986459.2986743, DOI 10.5555/2986459.2986743]; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Brock A., 2017, ARXIV PREPRINT ARXIV; Cai H, 2018, PR MACH LEARN RES, V80; Cai H, 2018, AAAI CONF ARTIF INTE, P2787; Cai Han, 2019, INT C LEARN REPR; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Dean J., 2012, NIPS 12, V1, P1223; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Elsken Thomas., 2018, J MACH LEARN RES; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang GL, 2017, IEEE ICC; Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5; Pham HX, 2020, IEEE T SYST MAN CY-S, V50, P1537, DOI 10.1109/TSMC.2018.2815988; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kingma D.P, P 3 INT C LEARNING R; Klein Adam., 2017, FANATICISM RACISM RA, DOI 10.1007/978-3-319-51424-6; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li L, 2019, IEEE VTS VEH TECHNOL; Li Mike, 2013, Proceedings of the IEEE 2013 Custom Integrated Circuits Conference (CICC 2013), DOI 10.1109/CICC.2013.6658558; Lin Long-Ji, 1992, REINFORCEMENT LEARNI, P4; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu H., 2018, ISA T; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Loshchilov Ilya, 2016, INT C LEARN REPR; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465; Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278; Pham H, 2018, PR MACH LEARN RES, V80; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Schaffer J. D., 1992, COGANN-92. International Workshop on Combinations of Genetic Algorithms and Neural Networks (Cat. No.92TH0435-8), P1, DOI 10.1109/COGANN.1992.273950; Simonyan K., 2015, INT C LEARN REPR ICL; Stanley KO, 2009, ARTIF LIFE, V15, P185, DOI 10.1162/artl.2009.15.2.15202; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Suganuma M, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'17), P497, DOI 10.1145/3071178.3071229; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Watkins C. J. C. H., 1989, THESIS KINGS COLL; Xie S., 2019, ARXIV PREPRINT ARXIV; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Younger AS, 2001, IEEE IJCNN, P2001, DOI 10.1109/IJCNN.2001.938471; Zagoruyko S, 2016, P BRIT MACH VIS C BM, DOI [10.5244/C.30.87, DOI 10.5244/C.30.87]; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	73	23	23	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2314	2328		10.1109/TPAMI.2020.2969193	http://dx.doi.org/10.1109/TPAMI.2020.2969193			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	31985407	Green Submitted			2022-12-18	WOS:000692540900011
J	Fan, DP; Li, TP; Lin, Z; Ji, GP; Zhang, DW; Cheng, MM; Fu, HZ; Shen, JB				Fan, Deng-Ping; Li, Tengpeng; Lin, Zheng; Ji, Ge-Peng; Zhang, Dingwen; Cheng, Ming-Ming; Fu, Huazhu; Shen, Jianbing			Re-Thinking Co-Salient Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Benchmark testing; Object detection; Measurement; Semantics; Task analysis; Annotations; Optimization; Co-salient object detection; co-attention projection; CoSOD dataset; benchmark	DEEP; SEGMENTATION; DISCOVERY; FEATURES	In this article, we conduct a comprehensive study on the co-salient object detection (CoSOD) problem for images. CoSOD is an emerging and rapidly growing extension of salient object detection (SOD), which aims to detect the co-occurring salient objects in a group of images. However, existing CoSOD datasets often have a serious data bias, assuming that each group of images contains salient objects of similar visual appearances. This bias can lead to the ideal settings and effectiveness of models trained on existing datasets, being impaired in real-life situations, where similarities are usually semantic or conceptual. To tackle this issue, we first introduce a new benchmark, called CoSOD3k in the wild, which requires a large amount of semantic context, making it more challenging than existing CoSOD datasets. Our CoSOD3k consists of 3,316 high-quality, elaborately selected images divided into 160 groups with hierarchical annotations. The images span a wide range of categories, shapes, object sizes, and backgrounds. Second, we integrate the existing SOD techniques to build a unified, trainable CoSOD framework, which is long overdue in this field. Specifically, we propose a novel CoEG-Net that augments our prior model EGNet with a co-attention projection strategy to enable fast common information learning. CoEG-Net fully leverages previous large-scale SOD datasets and significantly improves the model scalability and stability. Third, we comprehensively summarize 40 cutting-edge algorithms, benchmarking 18 of them over three challenging CoSOD datasets (iCoSeg, CoSal2015, and our CoSOD3k), and reporting more detailed (i.e., group-level) performance analysis. Finally, we discuss the challenges and future works of CoSOD. We hope that our study will give a strong boost to growth in the CoSOD community. The benchmark toolbox and results are available on our project page at https://dpfan.net/CoSOD3K.	[Fan, Deng-Ping; Lin, Zheng; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China; [Li, Tengpeng] Nanjing Univ Informat Sci & Technol, B DAT, Tianjin 300071, Peoples R China; [Li, Tengpeng] Nanjing Univ Informat Sci & Technol, CICAEET, Tianjin 300071, Peoples R China; [Ji, Ge-Peng] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China; [Zhang, Dingwen] Northwestern Polytech Univ, Brain & Artificial Intelligence Lab, Sch Automat, Xian 710072, Peoples R China; [Fu, Huazhu] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Macau, Peoples R China	Nankai University; Wuhan University; Northwestern Polytechnical University; University of Macau	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China.	dengpfan@gmail.com; ltpfor1225@gmail.com; frazer.linzheng@gmail.com; gepengai.ji@gmail.com; zhangdingwen2006yyy@gmail.com; cmm@nankai.edu.cn; huazhu.fu@inceptioniai.org; shenjianbingcg@gmail.com	Fan, DengPing/AAT-6679-2020; Fan, Deng-Ping/ABD-4052-2020; Fu, Huazhu/A-1411-2014	Fan, DengPing/0000-0002-5245-7518; Fan, Deng-Ping/0000-0002-5245-7518; Fu, Huazhu/0000-0002-9702-5524	NSFC [61922046]; S&T innovation project from Chinese Ministry of Education; Tianjin Natural Science Foundation [18ZXZNGX00110]	NSFC(National Natural Science Foundation of China (NSFC)); S&T innovation project from Chinese Ministry of Education; Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin)	The authors would like to thank professor Kaihua Zhang from Nanjing University of Information Science & Technology for insightful feedback. This work was supported by NSFC (61922046), S&T innovation project from Chinese Ministry of Education, and Tianjin Natural Science Foundation (18ZXZNGX00110). A preliminary version of this work has appeared in CVPR 2020 [1].	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alpert S, 2007, PROC CVPR IEEE, P359; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bahat Y, 2020, PROC CVPR IEEE, P2713, DOI 10.1109/CVPR42600.2020.00279; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Cao XC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P997, DOI 10.1145/2647868.2655007; Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen HT, 2010, IEEE IMAGE PROC, P1117, DOI 10.1109/ICIP.2010.5650014; Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193; Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377; Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832; Dai JF, 2013, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2013.165; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Eigen D., 2014, 6 INT C LEARN REPR I; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487; Fan DP, 2020, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR42600.2020.00299; Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285; Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406; Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875; Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172; Fu HZ, 2015, IEEE T IMAGE PROCESS, V24, P3415, DOI 10.1109/TIP.2015.2442915; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Fu K., 2020, ARXIV 200812134; Gao G., 2020, IEEE T CIRCUIT SYST, P1; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Guanghai Liu, 2013, 2013 International Conference on Information Science and Cloud Computing Companion (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21; Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou X., 2009, ADV NEURAL INFORM PR, P681; Hou XD, 2007, PROC CVPR IEEE, P2280; Hsu KJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P748; Hsu KJ, 2019, PROC CVPR IEEE, P8838, DOI 10.1109/CVPR.2019.00905; Hsu KJ, 2018, LECT NOTES COMPUT SC, V11209, P502, DOI 10.1007/978-3-030-01228-1_30; Jacobs D.E., 2010, P 23ND ANN ACM S USE, P219; Jeong DJ, 2018, IEEE T IMAGE PROCESS, V27, P5866, DOI 10.1109/TIP.2018.2859752; Jerripothula KR, 2018, IEEE T MULTIMEDIA, V20, P2466, DOI 10.1109/TMM.2018.2798294; Jiang B, 2021, IEEE T MULTIMEDIA, V23, P3193, DOI 10.1109/TMM.2020.3021251; Jiang B, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1375, DOI 10.1145/3343031.3350860; Jiang B, 2019, IEEE INT CON MULTI, P332, DOI 10.1109/ICME.2019.00065; Jiang HZ, 2019, FRONT COMPUT SCI-CHI, V13, P778, DOI 10.1007/s11704-017-6613-8; Jiaxing Zhao, 2018, Computational Visual Media, V4, P333, DOI 10.1007/s41095-018-0123-y; KAUFMAN EL, 1949, AM J PSYCHOL, V62, P498, DOI 10.2307/1418556; Kingma DP, 2 INT C LEARN REPR I, P1; Kipf Thomas N, 2016, 5 INT C LEARN REPR I; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Li B, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P818; Li B, 2019, IEEE I CONF COMP VIS, P8518, DOI 10.1109/ICCV.2019.00861; Li B, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1392, DOI 10.1145/3343031.3351016; Li CY, 2019, IEEE T GEOSCI REMOTE, V57, P9156, DOI 10.1109/TGRS.2019.2925070; Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34; Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476; Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803; Li L, 2014, CHANDOS INF PROF SER, P1; Li M., 2018, P BRIT MACH VIS C; Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873; Lou J, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P718, DOI 10.1109/ACPR.2017.91; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lugmayr Andreas, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P715, DOI 10.1007/978-3-030-58558-7_42; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Qin X., 2021, ARXIV210104704; Ren JM, 2021, PACE, V44, P35, DOI 10.1111/pace.14113; Ren JR, 2020, NEUROCOMPUTING, V371, P137, DOI 10.1016/j.neucom.2019.09.010; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Song SY, 2019, NEUROCOMPUTING, V358, P166, DOI 10.1016/j.neucom.2019.05.009; Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tang ZJ, 2020, INT J ADV MANUF TECH, V108, P3437, DOI 10.1007/s00170-020-05569-3; Tasi CC, 2019, IEEE T IMAGE PROCESS, V28, P56, DOI 10.1109/TIP.2018.2861217; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Wang C, 2019, AAAI CONF ARTIF INTE, P8917; Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404; Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50; Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417; Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409; Wei LN, 2019, IEEE T IMAGE PROCESS, V28, P5052, DOI 10.1109/TIP.2019.2909649; Wei LN, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3041; Wei XS, 2019, PATTERN RECOGN, V88, P113, DOI 10.1016/j.patcog.2018.10.022; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Wu ZX, 2019, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2019.00137; Xia CQ, 2017, PROC CVPR IEEE, P4399, DOI 10.1109/CVPR.2017.468; Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222; Ye LW, 2015, IEEE SIGNAL PROC LET, V22, P2073, DOI 10.1109/LSP.2015.2458434; Yu HK, 2018, AAAI CONF ARTIF INTE, P7509; Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733; Zha ZJ, 2020, IEEE T NEUR NET LEAR, V31, P2398, DOI 10.1109/TNNLS.2020.2967471; Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674; Zhang DW, 2017, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2017.436; Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393; Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4; Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161; Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75; Zhang DW, 2015, PROC CVPR IEEE, P2994, DOI 10.1109/CVPR.2015.7298918; Zhang J., 2020, ARXIV 200903075; Zhang K, 2020, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR42600.2020.00328; Zhang KH, 2019, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2019.00321; Zhang L, 2019, PROC CVPR IEEE, P6017, DOI 10.1109/CVPR.2019.00618; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405; Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887; Zhao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P455, DOI 10.1007/978-3-030-58610-2_27; Zheng XJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P959, DOI 10.1145/3240508.3240648; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	129	23	23	6	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 18	2021	44	8					4339	4354		10.1109/TPAMI.2021.3060412	http://dx.doi.org/10.1109/TPAMI.2021.3060412			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6IA	33600309	Green Submitted			2022-12-18	WOS:000820523000001
J	Estella-Aguerri, I; Zaidi, A				Estella-Aguerri, Inaki; Zaidi, Abdellatif			Distributed Variational Representation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Representation learning; distributed learning; information theory; neural networks; information bottleneck	INFORMATION; STABILITY; ENTROPY	The problem of distributed representation learning is one in which multiple sources of information X-1, ..., X-K are processed separately so as to learn as much information as possible about some ground truth Y. We investigate this problem from informationtheoretic grounds, through a generalization of Tishby's centralized Information Bottleneck (IB) method to the distributed setting. Specifically, K encoders, K >= 2, compress their observations X-1, ..., X-K separately in a manner such that, collectively, the produced representations preserve as much information as possible about Y. We study both discrete memoryless (DM) and memoryless vector Gaussian data models. For the discrete model, we establish a single-letter characterization of the optimal tradeoff between complexity (or rate) and relevance (or information) for a class of memoryless sources (the observations X-1, ..., X-K being conditionally independent given Y). For the vector Gaussian model, we provide an explicit characterization of the optimal complexity-relevance tradeoff. Furthermore, we develop a variational bound on the complexity-relevance tradeoff which generalizes the evidence lower bound (ELBO) to the distributed setting. We also provide two algorithms that allow to compute this bound: i) a Blahut-Arimoto type iterative algorithm which enables to compute optimal complexity-relevance encoding mappings by iterating over a set of self-consistent equations, and ii) a variational inference type algorithm in which the encoding mappings are parametrized by neural networks and the bound approximated by Markov sampling and optimized with stochastic gradient descent. Numerical results on synthetic and real datasets are provided to support the efficiency of the approaches and algorithms developed in this paper.	[Estella-Aguerri, Inaki; Zaidi, Abdellatif] Huawei Technol France, Math & Algorithm Sci Lab, Paris Res Ctr, F-92100 Boulogne, France; [Zaidi, Abdellatif] Univ Paris Est, F-77454 Champs Sur Marne, France	Huawei Technologies; Universite Gustave-Eiffel	Estella-Aguerri, I (corresponding author), Huawei Technol France, Math & Algorithm Sci Lab, Paris Res Ctr, F-92100 Boulogne, France.	inaki.estella@huawei.com; abdellatif.zaidi@u-pem.fr		Estella-Aguerri, Inaki/0000-0001-5110-6858				Achille A, 2018, J MACH LEARN RES, V19; Achille A, 2018, IEEE T PATTERN ANAL, V40, P2897, DOI 10.1109/TPAMI.2017.2784440; Aguerri I. E., 2018, P IEEE INT ZUR SEM C, P154; Aguerri IE, 2019, IEEE T INFORM THEORY, V65, P4575, DOI 10.1109/TIT.2019.2897564; Alemi A. A., 2017, FIXING BROKEN ELBO; Alemi A. A., 2018, THERML THERMODYNAMIC; Alemi Alex, 2017, ICLR; [Anonymous], 2018, P INT C LEARN REPR; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; BLAHUT RE, 1972, IEEE T INFORM THEORY, V18, P460, DOI 10.1109/TIT.1972.1054855; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Cesa-Bianchi Nicolo, 2006, PREDICTION LEARNING; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Courtade TA, 2014, IEEE T INFORM THEORY, V60, P740, DOI 10.1109/TIT.2013.2288257; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI 10.1002/0471200611; Dai B., 2018, COMPRESSING NEURAL N; DEMBO A, 1991, IEEE T INFORM THEORY, V37, P1501, DOI 10.1109/18.104312; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dhillon Paramveer, 2011, ADV NEURAL INFORM PR, V24, P199; Ekrem E, 2014, IEEE T INFORM THEORY, V60, P6870, DOI 10.1109/TIT.2014.2358692; Erdogmus D, 2002, THESIS U FLORIDA GAI; Gamal A.E., 2011, NETWORK INFORM THEOR; Globerson A., 2004, TECH REP; Glorot X., 2010, PROC MACH LEARN RES, P249; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Harremoes P, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS, VOLS 1-7, P566, DOI 10.1109/ISIT.2007.4557285; Higgins I, 2016, BETA VAE LEARNING BA; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, P5, DOI 10.1145/168304.168306; Hu XG, 2010, SYNLETT, P982, DOI 10.1055/s-0029-1219540; Jang E., 2017, ICLR; Jiao JT, 2015, IEEE T INFORM THEORY, V61, P5357, DOI 10.1109/TIT.2015.2462848; Jiao JT, 2015, IEEE T INFORM THEORY, V61, P2835, DOI [10.1109/TIT.2015.2412945, 10.1109/tit.2015.2412945]; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P., 2016, IMPROVING VARIATIONA; Kingma D. P., 2013, AUTO ENCODING VARIAT; Kittichokechai K, 2016, IEEE INT SYMP INFO, P1078, DOI 10.1109/ISIT.2016.7541465; Kong Y., 2018, P 2018 ACM C EC COMP; Kumar A., 2011, P 28 INT C MACH LEAR, P393, DOI DOI 10.5555/3104482.3104532; Lehmann E.L., 2006, THEORY POINT ESTIMAT; LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36; Maddison Chris J, 2016, ARXIV161100712; McAllester D. A., 2013, PAC BAYESIAN TUTORIA; Olsen C, 2009, EURASIP J BIOINFORM, DOI 10.1155/2009/308959; Painsky A, 2018, IEEE INT SYMP INFO, P936; Paninski L, 2003, NEURAL COMPUT, V15, P1191, DOI 10.1162/089976603321780272; Papamakarios G., 2017, ADV NEURAL INF PROCE, V30; Peng Xue Bin, 2018, ARXIV PREPRINT ARXIV; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Principe J. C., 2000, NEURAL ADAPTIVE SYST, V672; Principe JC, 2010, INFORM SCI STAT, P1, DOI 10.1007/978-1-4419-1570-2; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Razaviyayn M, 2013, SIAM J OPTIMIZ, V23, P1126, DOI 10.1137/120891009; Rezende Danilo Jimenez, 2014, P 31 INT C INT C MAC; Russo D., 2016, MUCH DOES YOUR DATA; Shalev-Shwartz S, 2010, J MACH LEARN RES, V11, P2635; Shwartz-Ziv R., 2017, OPENING BLACK BOX DE; Slonim N, 2005, P NATL ACAD SCI USA, V102, P18297, DOI 10.1073/pnas.0507432102; Slonim N., 2000, SIGIR Forum, V34, P208; Sreekumar S, 2018, IEEE INT SYMP INFO, P181; Tian C, 2008, IEEE T INFORM THEORY, V54, P4666, DOI 10.1109/TIT.2008.928951; Tishby N., 1999, P 37 ANN ALL C COMM, P368; Ugur Y, 2017, INFO THEOR WORKSH, P349; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang W., 2016, DEEP MULTIVIEW REPRE; Winkelbauer A, 2014, IEEE INT SYMP INFO, P2849, DOI 10.1109/ISIT.2014.6875354; WITSENHAUSEN HS, 1975, IEEE T INFORM THEORY, V21, P493, DOI 10.1109/TIT.1975.1055437; Xu A., 2017, ADV NEURAL INFORM PR, P2521; Xu C., 2013, ARXIV13045634; Yu S., 2018, ARXIV180406537; Yu SJ, 2019, NEURAL NETWORKS, V117, P104, DOI 10.1016/j.neunet.2019.05.003; Zhou YH, 2016, IEEE T INFORM THEORY, V62, P7402, DOI 10.1109/TIT.2016.2617862	76	23	23	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					120	138		10.1109/TPAMI.2019.2928806	http://dx.doi.org/10.1109/TPAMI.2019.2928806			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31329108	Green Submitted			2022-12-18	WOS:000597206900009
J	Shi, YK; Li, GB; Cao, QX; Wang, KZ; Lin, L				Shi, Yukai; Li, Guanbin; Cao, Qingxing; Wang, Keze; Lin, Liang			Face Hallucination by Attentive Sequence Optimization with Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Image resolution; Image reconstruction; Optimization; Reinforcement learning; Visualization; Image restoration; Face hallucination; reinforcement learning; recurrent neural network	IMAGE SUPERRESOLUTION; REPRESENTATION; ALIGNMENT; NETWORKS	Face hallucination is a domain-specific super-resolution problem that aims to generate a high-resolution (HR) face image from a low-resolution (LR) input. In contrast to the existing patch-wise super-resolution models that divide a face image into regular patches and independently apply LR to HR mapping to each patch, we implement deep reinforcement learning and develop a novel attention-aware face hallucination (Attention-FH) framework, which recurrently learns to attend a sequence of patches and performs facial part enhancement by fully exploiting the global interdependency of the image. Specifically, our proposed framework incorporates two components: a recurrent policy network for dynamically specifying a new attended region at each time step based on the status of the super-resolved image and the past attended region sequence, and a local enhancement network for selected patch hallucination and global state updating. The Attention-FH model jointly learns the recurrent policy network and local enhancement network through maximizing a long-term reward that reflects the hallucination result with respect to the whole HR image. Extensive experiments demonstrate that our Attention-FH significantly outperforms the state-of-the-art methods on in-the-wild face images with large pose and illumination variations.	[Shi, Yukai; Li, Guanbin; Cao, Qingxing; Wang, Keze; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China	Sun Yat Sen University	Li, GB (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.	shiyk3@mail2.sysu.edu.cn; liguanbin@mail.sysu.edu.cn; caoqx@mail2.sysu.edu.cn; kezewang@gmail.com; linliang@ieee.org		Shi, Yukai/0000-0002-9413-6528	National Key Research and Development Program of China [2018YFC0830103, 2016YFB1001004]; NSFC-Shenzhen Robotics Projects [U1613211]; National Natural Science Foundation of China [61702565]; National High Level Talents Special Support Plan (Ten Thousand Talents Program); Fundamental Research Funds for the Central Universities [18lgpy63]	National Key Research and Development Program of China; NSFC-Shenzhen Robotics Projects; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National High Level Talents Special Support Plan (Ten Thousand Talents Program); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Key Research and Development Program of China under Grant No.2018YFC0830103 and No.2016YFB1001004, in part by the NSFC-Shenzhen Robotics Projects (U1613211), in part by the National Natural Science Foundation of China under Grant No.61702565, in part by National High Level Talents Special Support Plan (Ten Thousand Talents Program) and in part by the Fundamental Research Funds for the Central Universities under Grant No.18lgpy63.	Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180; Chen T., 2018, 32 AAAI C ART INT; Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264; Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goodrich B., 2012, 2012 IEEE COMP SOC C, P19; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Gross R., 2007, TR0708 CARN MELL U R; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082; Jaderberg M, 2015, ADV NEUR IN, V28; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Jie ZQ, 2016, ADV NEUR IN, V29; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma DP., 2015, INT C LEARN REPR ICL; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li GB, 2019, IEEE T IMAGE PROCESS, V28, P1591, DOI 10.1109/TIP.2018.2878956; Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu LB, 2019, IEEE T MULTIMEDIA, V21, P2248, DOI 10.1109/TMM.2019.2902096; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Parmar N, 2018, PR MACH LEARN RES, V80; Reed S, 2017, PR MACH LEARN RES, V70; Ronneberger O., 2015, P MEDICAL IMAGE COMP, P234; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Song YB, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4537; Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tappen MF, 2012, LECT NOTES COMPUT SC, V7578, P236, DOI 10.1007/978-3-642-33786-4_18; Tuzel O., 2016, ARXIV160307235; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171; Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yin Q., 2015, NAIVE DEEP FACE RECO; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871; Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134	56	23	23	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2809	2824		10.1109/TPAMI.2019.2915301	http://dx.doi.org/10.1109/TPAMI.2019.2915301			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NX0AD	31071019	Green Submitted			2022-12-18	WOS:000575381000006
J	Liong, VE; Lu, JW; Duan, LY; Tan, YP				Liong, Venice Erin; Lu, Jiwen; Duan, Ling-Yu; Tan, Yap-Peng			Deep Variational and Structural Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary codes; Training; Visualization; Semantics; Quantization (signal); Probabilistic logic; Convolution; Scalable image search; fast similarity search; hashing; deep learning; cross-modal retrieval	NEAREST-NEIGHBOR; QUANTIZATION; ALGORITHMS	In this paper, we propose a deep variational and structural hashing (DVStH) method to learn compact binary codes for multimedia retrieval. Unlike most existing deep hashing methods which use a series of convolution and fully-connected layers to learn binary features, we develop a probabilistic framework to infer latent feature representation inside the network. Then, we design a struct layer rather than a bottleneck hash layer, to obtain binary codes through a simple encoding procedure. By doing these, we are able to obtain binary codes discriminatively and generatively. To make it applicable to cross-modal scalable multimedia retrieval, we extend our method to a cross-modal deep variational and structural hashing (CM-DVStH). We design a deep fusion network with a struct layer to maximize the correlation between image-text input pairs during the training stage so that a unified binary vector can be obtained. We then design modality-specific hashing networks to handle the out-of-sample extension scenario. Specifically, we train a network for each modality which outputs a latent representation that is as close as possible to the binary codes which are inferred from the fusion network. Experimental results on five benchmark datasets are presented to show the efficacy of the proposed approach.	[Liong, Venice Erin] Nanyang Technol Univ, Interdisciplinary Grad Sch, Rapid Rich Object Search ROSE Lab, Singapore 639798, Singapore; [Lu, Jiwen] Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China; [Lu, Jiwen] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Duan, Ling-Yu] Peking Univ, Inst Digital Media, Beijing 100080, Peoples R China; [Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Tsinghua University; Tsinghua University; Peking University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Lu, JW (corresponding author), Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	veniceer001@e.ntu.edu.sg; lujiwen@tsinghua.edu.cn; lingyu@pku.edu.cn; eyptan@ntu.edu.sg	Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529	National Key R&D Program of China [2017YFA0700802]; National Natural Science Foundation of China [61822603, 61672306, 61661146005]; PKU-NTU Joint Research Institute (JRI); Ng Teng Fong Charitable Foundation	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); PKU-NTU Joint Research Institute (JRI); Ng Teng Fong Charitable Foundation	This work was supported in part by the National Key R&D Program of China under Grant 2017YFA0700802, in part by the National Natural Science Foundation of China under Grant 61822603, Grant 61672306, Grant 61661146005, and in part by the PKU-NTU Joint Research Institute (JRI) sponsored by a donation from the Ng Teng Fong Charitable Foundation. Partial of this research was carried out at the Rapid-Rich Object Search (ROSE) Lab at the Nanyang Technological University, Singapore. Part of this work was presented in [40].	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Andoni Alexandr, 2015, ADV NEURAL INFORM PR, P1225; [Anonymous], P BRIT MACH VIS C; [Anonymous], P AS C COMP VIS; [Anonymous], 2006, P ONT 2006 LANG RES; [Anonymous], LEARNING MULTIPLE LA; [Anonymous], 2017, P IEEE C COMP VIS PA; Cao Y, 2016, IEEE ICC, P80, DOI 10.1109/ICC.2016.7510612; Cao Y, 2017, AAAI CONF ARTIF INTE, P3974; Cao Y, 2017, PROC CVPR IEEE, P916, DOI 10.1109/CVPR.2017.104; Cao Y, 2016, AAAI CONF ARTIF INTE, P3457; Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598; Chaidaroon S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P75, DOI 10.1145/3077136.3080816; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chua T.-S., 2009, P ACM INT C IM VID R, P1, DOI 10.1145/1646396.1646452; Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267; Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Gu XQ, 2015, J COMPUT EDUC, V2, P25, DOI 10.1007/s40692-014-0023-9; Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jain H, 2017, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2017.96; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348; Jiang Q, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201703043; King DB, 2015, ACS SYM SER, V1214, P1; Kingma DP, 2014, ADV NEUR IN, V27; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar S, 2011, P TWENTYSECOND INT J, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Lei Z, 2015, LECT NOTES ENG COMP, P27; Li W., 2016, INT JOINT C ARTIFICI, P1711; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011; Liong VE, 2017, IEEE I CONF COMP VIS, P4097, DOI 10.1109/ICCV.2017.439; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538; Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4042, DOI 10.1109/TIP.2017.2713940; Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163; Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327; Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359; Martinez J, 2016, LECT NOTES COMPUT SC, V9906, P137, DOI 10.1007/978-3-319-46475-6_9; Miao YS, 2016, PR MACH LEARN RES, V48; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Rastegari M., 2013, ICML; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sablayrolles A, 2017, INT CONF ACOUST SPEE, P1732, DOI 10.1109/ICASSP.2017.7952453; Shakhnarovich G., 2008, IEEE T NEURAL NETWOR, V19, P377; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shen YM, 2017, IEEE I CONF COMP VIS, P4117, DOI 10.1109/ICCV.2017.441; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8; Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xu X, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P305, DOI 10.1145/2911996.2912056; Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177; Zhang QF, 2014, INT CONF MACH LEARN, P807, DOI 10.1109/ICMLC.2014.7009713; Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763; Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415; Zhu H, 2016, AAAI CONF ARTIF INTE, P2415; Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641	75	23	23	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					580	595		10.1109/TPAMI.2018.2882816	http://dx.doi.org/10.1109/TPAMI.2018.2882816			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30475712				2022-12-18	WOS:000525365300005
J	Wu, BY; Ghanem, B				Wu, Baoyuan; Ghanem, Bernard			l(p)-Box ADMM: A Versatile Framework for Integer Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Integer programming; nonconvex optimization; ADMM; computer vision; machine learning	ENERGY MINIMIZATION; SEGMENTATION; RELAXATIONS; ALGORITHMS; BINARY	This paper revisits the integer programming (IP) problem, which plays a fundamental role in many computer vision and machine learning applications. The literature abounds with many seminal works that address this problem, some focusing on continuous approaches (e.g., linear program relaxation), while others on discrete ones (e.g., min-cut). However, since many of these methods are designed to solve specific IP forms, they cannot adequately satisfy the simultaneous requirements of accuracy, feasibility, and scalability. To this end, we propose a novel and versatile framework called l(p)-box ADMM, which is based on two main ideas. (1) The discrete constraint is equivalently replaced by the intersection of a box and an i n -norm sphere. (2) We infuse this equivalence into the Alternating Direction Method of Multipliers (ADMM) framework to handle the continuous constraints separately and to harness its attractive properties. More importantly, the ADMM update steps can lead to manageable sub-problems in the continuous domain. To demonstrate its efficacy, we apply it to an optimization form that occurs often in computer vision and machine learning, namely binary quadratic programming (BOP). In this case, the ADMM steps are simple, computationally efficient. Moreover, we present the theoretic analysis about the global convergence of the l(p)-box ADMM through adding a perturbation with the sufficiently small factor epsilon to the original IP problem. Specifically, the globally converged solution generated by l(p)-box ADMM for the perturbed IP problem will be close to the stationary and feasible point of the original IP problem within O(epsilon). We demonstrate the applicability of l(p)-box ADMM on three important applications: MRF energy minimization, graph matching, and clustering. Results clearly show that it significantly outperforms existing generic IP solvers both in runtime and objective. It also achieves very competitive performance to state-of-the-art methods designed specifically for these applications.	[Wu, Baoyuan; Ghanem, Bernard] King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal 239556900, Saudi Arabia; [Wu, Baoyuan] Tencent AI Lab, Shenzhen 518057, Peoples R China	King Abdullah University of Science & Technology; Tencent	Wu, BY (corresponding author), King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal 239556900, Saudi Arabia.	wubaoyuan1987@gmail.com; bernard.ghanem@kaust.edu.sa	Ghanem, Bernard/J-7605-2017	Ghanem, Bernard/0000-0002-5534-587X; Wu, Baoyuan/0000-0003-2183-5990	King Abdullah University of Science and Technology (KAUST); Tencent AI Lab	King Abdullah University of Science and Technology (KAUST)(King Abdullah University of Science & Technology); Tencent AI Lab	This work is supported by competitive research funding from King Abdullah University of Science and Technology (KAUST), and Tencent AI Lab. The authors would like to thank Prof. Siwei Lyu, Prof. Wotao Yin, and Dr. Li Shen for their constructive comments and discussions for this work. Baoyuan Wu and Bernard Ghanem contributed equally to this work.	Bach F, 2013, FOUND TRENDS MACH LE, V6, P145, DOI 10.1561/2200000039; BEMPORAD A, 2004, HYBRID TOOLBOX USERS; Bertolazzi P, 2016, EUR J OPER RES, V250, P389, DOI 10.1016/j.ejor.2015.09.051; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Burer S, 2009, MATH PROGRAM, V120, P479, DOI 10.1007/s10107-008-0223-z; Chakraborty S, 2015, IEEE T PATTERN ANAL, V37, P1945, DOI 10.1109/TPAMI.2015.2389848; Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10; Coste M, 2002, RAAG NETW SCH, V145, P30; Currie J., 2012, FDN COMPUTER AIDED P, V24, P32; Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z; DeSantis M., 2012, THESIS; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Fu Q., 2013, P 29 C UNC ART INT U, P222; Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x; Hong L, 2004, PROC CVPR IEEE, P74; Jiang B, 2014, OPTIMIZATION, V63, P883, DOI 10.1080/02331934.2014.895901; JOULIN A, 2010, PROC CVPR IEEE, P1943, DOI DOI 10.1109/CVPR.2010.5539868; KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703, DOI 10.1137/0108053; Kim S, 2001, OPTIM METHOD SOFTW, V15, P201, DOI 10.1080/10556780108805819; Koller D., 2009, PROBABILISTIC GRAPHI; LAND AH, 1960, ECONOMETRICA, V28, P497, DOI 10.2307/1910129; Lasserre J. B., 2001, Integer Programming and Combinatorial Optimization. 8th International IPCO Conference. Proceedings (Lecture Notes in Computer Science Vol.2081), P293; Laurent M, 2003, MATH OPER RES, V28, P470, DOI 10.1287/moor.28.3.470.16391; Laurent M., 2002, SEMIDEFINITE PROGRAM; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Li GY, 2015, SIAM J OPTIMIZ, V25, P2434, DOI 10.1137/140998135; Li S, 2009, MARKOV RANDOM FIELD; Lichman M, 2013, UCI MACHINE LEARNING; Lucidi S, 2010, J OPTIMIZ THEORY APP, V145, P479, DOI 10.1007/s10957-010-9700-7; Mehrotra S, 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028; Mei X, 2015, IEEE I CONF COMP VIS, P459, DOI 10.1109/ICCV.2015.60; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Murray W, 2010, COMPUT OPTIM APPL, V47, P257, DOI 10.1007/s10589-008-9218-1; Parikh N, 2014, MATH PROGRAM COMPUT, V6, P77, DOI 10.1007/s12532-013-0061-8; Qian C., 2015, ADV NEURAL INFORM PR, P1774; Ramalingam S., 2008, P IEEE C COMP VIS PA, P1; Ravikumar Pradeep, 2006, P 23 INT C MACH LEAR, P737, DOI DOI 10.1145/1143844.1143937; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wang B, 2017, IEEE T PATTERN ANAL, V39, P589, DOI 10.1109/TPAMI.2016.2551245; Wang M., 2011, J MACHINE LEARNING R, P2011; Wang P, 2017, IEEE T PATTERN ANAL, V39, P470, DOI 10.1109/TPAMI.2016.2541146; Wang P, 2013, PROC CVPR IEEE, P1312, DOI 10.1109/CVPR.2013.173; Wang Weiran, 2013, ARXIV13091541; Wang Y., 2015, ARXIV151106324, DOI [10.1155/2015/893074, DOI 10.1155/2015/712349]; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Wolsey L.A., 2014, INTEGER COMBINATORIA; Wu B, 2016, AAAI CONF ARTIF INTE, P2229; Wu BY, 2015, IEEE I CONF COMP VIS, P4157, DOI 10.1109/ICCV.2015.473; Wu BY, 2014, INT C PATT RECOG, P1964, DOI 10.1109/ICPR.2014.343; Xu YY, 2012, FRONT MATH CHINA, V7, P365, DOI 10.1007/s11464-012-0194-5; Yang L, 2017, SIAM J IMAGING SCI, V10, P74, DOI 10.1137/15M1027528; Yu CJ, 2013, OPTIM LETT, V7, P23, DOI 10.1007/s11590-011-0391-2; Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	63	23	24	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1695	1708		10.1109/TPAMI.2018.2845842	http://dx.doi.org/10.1109/TPAMI.2018.2845842			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994196	Green Published			2022-12-18	WOS:000470972300013
J	Demisse, GG; Aouada, D; Ottersten, B				Demisse, Girum Getachew; Aouada, Djamila; Ottersten, Bjorn			Deformation Based Curved Shape Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape representation; similarity metric; shape matching; deformation	MANIFOLDS; METRICS; RECOGNITION; GENERATION; SPACES	In this paper, we introduce a deformation based representation space for curved shapes in R-n. Given an ordered set of points sampled from a curved shape, the proposed method represents the set as an element of a finite dimensional matrix Lie group. Variation due to scale and location are filtered in a preprocessing stage, while shapes that vary only in rotation are identified by an equivalence relationship. The use of a finite dimensional matrix Lie group leads to a similarity metric with an explicit geodesic solution. Subsequently, we discuss some of the properties of the metric and its relationship with a deformation by least action. Furthermore, invariance to reparametrization or estimation of point correspondence between shapes is formulated as an estimation of sampling function. Thereafter, two possible approaches are presented to solve the point correspondence estimation problem. Finally, we propose an adaptation of k-means clustering for shape analysis in the proposed representation space. Experimental results show that the proposed representation is robust to uninformative cues, e.g., local shape perturbation and displacement. In comparison to state of the art methods, it achieves a high precision on the Swedish and the Flavia leaf datasets and a comparable result on MPEG-7, Kimia99 and Kimia216 datasets.	[Demisse, Girum Getachew; Aouada, Djamila; Ottersten, Bjorn] Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust, L-2721 Luxembourg, Luxembourg	University of Luxembourg	Demisse, GG (corresponding author), Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust, L-2721 Luxembourg, Luxembourg.	girum.demisse@uni.lu; djamila.aouada@uni.lu; bjorn.ottersten@uni.lu	Ottersten, Bjorn/AAF-9147-2019; Ottersten, Bjorn/G-1005-2011	Ottersten, Bjorn/0000-0003-2298-6774; Aouada, Djamila/0000-0002-7576-2064				Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; AMIT Y, 1994, SIAM J SCI COMPUT, V15, P207, DOI 10.1137/0915014; [Anonymous], 2010, PATTERN THEORY STOCH; Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769; Bellman R. E., 2015, APPL DYNAMIC PROGRAM, V2050; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bhatia R., 2009, POSITIVE DEFINITE MA; Bini DA, 2010, MATH COMPUT, V79, P437, DOI 10.1090/S0025-5718-09-02261-3; Bookstein FL., 1986, STAT SCI, V1, P181, DOI [DOI 10.1214/SS/1177013696, 10.1214/ss/1177013696]; Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4; COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458; Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020; Demisse GG, 2016, PROC CVPR IEEE, P5042, DOI 10.1109/CVPR.2016.545; Demisse GG, 2015, IEEE IMAGE PROC, P4386, DOI 10.1109/ICIP.2015.7351635; doCarmoValero M.P, 1992, RIEMANNIAN GEOMETRY; Dryden I. L., 1998, STAT SHAPE ANAL, V4; Felzenszwalb P.F., 2007, P 2007 IEEE C COMP V, P1, DOI [DOI 10.1109/CVPR.2007.383018, 10.1109/CVPR.2007.383018]; FREIFELD O, 2012, P EUR C COMPUT VIS, V7572, P1; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Grenander U, 1997, P NATL ACAD SCI USA, V94, P783, DOI 10.1073/pnas.94.3.783; GRENANDER U, 1993, SIAM J APPL MATH, V53, P1072, DOI 10.1137/0153054; Grenander U., 2007, PATTERN THEORY REPRE; Hamerly G, 2004, ADV NEUR IN, V16, P281; Ho J., 2013, AISTATS, P325; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Khaneja N, 1998, IEEE T PATTERN ANAL, V20, P1260, DOI 10.1109/34.730559; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Laga H, 2014, J THEOR BIOL, V363, P41, DOI 10.1016/j.jtbi.2014.07.036; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu W., 2010, P 1 ACM INT C BIOINF, P62, DOI DOI 10.1145/1854776.1854790; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208; Mennucci ACG, 2013, LECT NOTES MATH, V2090, P205, DOI 10.1007/978-3-319-01712-9_4; Michor P. W., 2003, MATH0312384 ARXIV; Michor PW, 2007, APPL COMPUT HARMON A, V23, P74, DOI 10.1016/j.acha.2006.07.004; MILNOR J, 1976, ADV MATH, V21, P293, DOI 10.1016/S0001-8708(76)80002-3; Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877; Morgan F, 1993, RIEMANNIAN GEOMETRY; Mouine S., 2013, P 3 ACM C INT C MULT, P127; MUMFORD D, 1994, PROG MATH, V119, P187; Ng AY, 2002, ADV NEUR IN, V14, P849; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Pennec X, 2009, LECT NOTES COMPUT SC, V5416, P347; Scott C, 2006, IEEE T IMAGE PROCESS, V15, P1831, DOI 10.1109/TIP.2006.877038; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Sharon E, 2006, INT J COMPUT VISION, V70, P55, DOI 10.1007/s11263-006-6121-z; Small C. G., 1996, STAT THEORY SHAPE SP; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Tagare HD, 1999, IEEE T MED IMAGING, V18, P570, DOI 10.1109/42.790457; Thakoor N, 2007, IEEE T IMAGE PROCESS, V16, P2707, DOI 10.1109/TIP.2007.908076; Trouve A., 1995, INFINITE DIMENSIONAL; Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042; Wu M, 2006, ADV NEURAL INFORM PR, P1529; Yang M., 2008, PATTERN RECOGNIT, V15, P43, DOI DOI 10.5772/6237; Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; Younes L., 2010, PARAMETRIZED PLANE C; Younes L, 2012, IMAGE VISION COMPUT, V30, P389, DOI 10.1016/j.imavis.2011.09.009; Zefran M, 1998, IEEE T ROBOTIC AUTOM, V14, P576, DOI 10.1109/70.704225	65	23	26	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1338	1351		10.1109/TPAMI.2017.2711607	http://dx.doi.org/10.1109/TPAMI.2017.2711607			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28613161	Green Submitted			2022-12-18	WOS:000431524700005
J	Tsakiris, MC; Vidal, R				Tsakiris, Manolis C.; Vidal, Rene			Algebraic Clustering of Affine Subspaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Algebraic subspace clustering; affine subspaces; homogeneous coordinates; algebraic geometry	SERIES	Subspace clustering is an important problem in machine learning with many applications in computer vision and pattern recognition. Prior work has studied this problem using algebraic, iterative, statistical, low-rank and sparse representation techniques. While these methods have been applied to both linear and affine subspaces, theoretical results have only been established in the case of linear subspaces. For example, algebraic subspace clustering (ASC) is guaranteed to provide the correct clustering when the data points are in general position and the union of subspaces is transversal. In this paper we study in a rigorous fashion the properties of ASC in the case of affine subspaces. Using notions from algebraic geometry, we prove that the homogenization trick, which embeds points in a union of affine subspaces into points in a union of linear subspaces, preserves the general position of the points and the transversality of the union of subspaces in the embedded space, thus establishing the correctness of ASC for affine subspaces.	[Tsakiris, Manolis C.; Vidal, Rene] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA	Johns Hopkins University	Tsakiris, MC (corresponding author), Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA.	m.tsakiris@jhu.edu; rvidal@cis.jhu.edu			NSF [1447822, 1218709]; ONR [N000141310116]	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research)	This work was partially supported by grants NSF 1447822 and 1218709, and ONR N000141310116.	Atiyah Michael Francis, 1994, INTRO COMMUTATIVE AL; Bradley PS, 2000, J GLOBAL OPTIM, V16, P23, DOI 10.1023/A:1008324625522; Burgisser P., 2013, SPRINGER SCI BUS MED, V349; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Conca A., 2003, COLLECT MATH, V54, P137; Cox D. A., 2007, IDEALS VARIETIES ALG; Derksen H, 2002, ADV MATH, V172, P151, DOI 10.1016/S0001-8708(02)00019-1; Derksen H, 2007, J PURE APPL ALGEBRA, V209, P91, DOI 10.1016/j.jpaa.2006.05.032; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Hartshorne R., 1977, ALGEBRAIC GEOM; Heckel R, 2015, IEEE T INFORM THEORY, V61, P6320, DOI 10.1109/TIT.2015.2472520; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Livni R., 2013, INT C MACH LEARN, P597; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Ma Y, 2008, SIAM REV, V50, P413, DOI 10.1137/060655523; Sampath A, 2010, IEEE T GEOSCI REMOTE, V48, P1554, DOI 10.1109/TGRS.2009.2030180; Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Tsakiris M., 2015, ICCV WORKSH ROB SUBS, P28; Tsakiris MC, 2017, SIAM J IMAGING SCI, V10, P372, DOI 10.1137/16M1083451; Tsakiris MC, 2014, CONF REC ASILOMAR C, P1321, DOI 10.1109/ACSSC.2014.7094674; Tseng P, 2000, J OPTIMIZ THEORY APP, V105, P249, DOI 10.1023/A:1004678431677; Vidal R, 2003, PROC CVPR IEEE, P621; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; Vidal R., 2003, THESIS; Vidal R, 2008, AUTOMATICA, V44, P2274, DOI 10.1016/j.automatica.2008.01.025; Vidal R, 2006, INT J COMPUT VISION, V68, P7, DOI 10.1007/s11263-005-4839-7; Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Wang Y, 2016, ACSR ADV COMPUT, V37, P538; Yang Y., 2016, PROC EUR C COMPUT VI, P731; You C., 2016, P IEEE C COMP VIS PA, P2918; Zhang T, 2012, INT J COMPUT VISION, V100, P217, DOI 10.1007/s11263-012-0535-6	34	23	26	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					482	489		10.1109/TPAMI.2017.2678477	http://dx.doi.org/10.1109/TPAMI.2017.2678477			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28287957	Green Submitted, hybrid			2022-12-18	WOS:000422706000016
J	Noh, YK; Zhang, BT; Lee, DD				Noh, Yung-Kyun; Zhang, Byoung-Tak; Lee, Daniel D.			Generative Local Metric Learning for Nearest Neighbor Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Metric learning; nearest neighbor classification; f-divergence; generative-discriminative hybridization	INFORMATION DISCRIMINANT-ANALYSIS; FEATURE-EXTRACTION	We consider the problem of learning a local metric in order to enhance the performance of nearest neighbor classification. Conventional metric learning methods attempt to separate data distributions in a purely discriminative manner; here we show how to take advantage of information from parametric generative models. We focus on the bias in the information-theoretic error arising from finite sampling effects, and find an appropriate local metric that maximally reduces the bias based upon knowledge from generative models. As a byproduct, the asymptotic theoretical analysis in this work relates metric learning to dimensionality reduction from a novel perspective, which was not understood from previous discriminative approaches. Empirical experiments show that this learned local metric enhances the discriminative nearest neighbor performance on various datasets using simple class conditional generative models such as a Gaussian.	[Noh, Yung-Kyun] Seoul Natl Univ, Sch Mech & Aerosp Engn, Seoul 08826, South Korea; [Zhang, Byoung-Tak] Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 08826, South Korea; [Lee, Daniel D.] Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA	Seoul National University (SNU); Seoul National University (SNU); University of Pennsylvania	Noh, YK (corresponding author), Seoul Natl Univ, Sch Mech & Aerosp Engn, Seoul 08826, South Korea.	nohyung@snu.ac.kr; btzhang@snu.ac.kr; ddlee@seas.upenn.edu	Lee, Daniel D./B-5753-2013		U.S. Air Force Office of Scientific Research; National Security Research Institute in Korea; SNU-MAE BK21+program; Korea government [IITP-R0126-16-1072, KEIT-10044009, KEIT-10060086]; U.S. National Science Foundation; U.S. Department of Transportation; U.S. Army Research Laboratory; U.S. Office of Naval Research	U.S. Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); National Security Research Institute in Korea; SNU-MAE BK21+program; Korea government(Korean Government); U.S. National Science Foundation(National Science Foundation (NSF)); U.S. Department of Transportation; U.S. Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); U.S. Office of Naval Research(Office of Naval Research)	Y.-K. Noh is supported by grants from the U.S. Air Force Office of Scientific Research, the National Security Research Institute in Korea, and the SNU-MAE BK21+program. B.-T. Zhang is supported by grants from the U.S. Air Force Office of Scientific Research, and Korea government (IITP-R0126-16-1072, KEIT-10044009, KEIT-10060086). D. D. Lee is supported by grants from the U.S. National Science Foundation, the U.S. Department of Transportation, the U.S. Air Force Office of Scientific Research, the U.S. Army Research Laboratory, and the U.S. Office of Naval Research.	[Anonymous], 2006, P 18 INT C NEUR INF; [Anonymous], 2012, ADV NEURAL INF PROCE; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; BUNCH JR, 1978, NUMER MATH, V31, P31, DOI 10.1007/BF01396012; Chechik G, 2010, J MACH LEARN RES, V11, P1109; Das K, 2008, PATTERN RECOGN, V41, P1548, DOI 10.1016/j.patcog.2007.10.001; Duda R.O., 2000, PATTERN CLASSIFICATI; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314, DOI 10.1109/TPAMI.1984.4767523; Fukunaga K., 1981, IEEE T INFORM THEORY, V27, P622, DOI DOI 10.1109/TIT.1981.1056403; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Goldberger Jacob, 2005, ADV NEURAL INFORM PR, V17, P8, DOI DOI 10.1109/TCSVT.2013.2242640; Goria MN, 2005, J NONPARAMETR STAT, V17, P277, DOI 10.1080/104852504200026815; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Kapur J. N., 1994, MEASURES INFORM THEI; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lacoste-Julien S, 2009, ADV NEURAL INFORM PR, P897, DOI DOI 10.1007/S10618-010-0175-9; Lasserre J.A., 2006, IEEE COMP SOC C COMP, P87, DOI DOI 10.1109/CVPR.2006.227; LeCun Yann, MNIST DATABASE HANDW; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Nenadic Z, 2007, IEEE T PATTERN ANAL, V29, P1394, DOI 10.1109/TPAMI.2007.1156; Perez-Cruz F, 2009, ADV NEURAL INFORM PR, P1257; Raina R, 2004, ADV NEUR IN, V16, P545; Shen C., 2009, ADV NEURAL INFORM PR, P1651; Snapp RR, 1998, ANN STAT, V26, P850; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Trivedi S., 2014, ADV NEURAL INFORM PR, P3392; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang Jun, 2012, ADV NEURAL INF PROCE, V25, P1601; Wang Q, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P242, DOI 10.1109/ISIT.2006.261842; Wang Q, 2009, IEEE T INFORM THEORY, V55, P2392, DOI 10.1109/TIT.2009.2016060; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Ying YM, 2012, J MACH LEARN RES, V13, P1	35	23	25	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					106	118		10.1109/TPAMI.2017.2666151	http://dx.doi.org/10.1109/TPAMI.2017.2666151			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28186880	Green Submitted, hybrid			2022-12-18	WOS:000417806000009
J	Wang, XY; Ji, Q				Wang, Xiaoyang; Ji, Qiang			Hierarchical Context Modeling for Video Event Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchical context model; event recognition; image context; semantic context; priming context	DYNAMIC BAYESIAN NETWORKS; SPATIOTEMPORAL CONTEXT	Current video event recognition research remains largely target-centered. For real-world surveillance videos, target-centered event recognition faces great challenges due to large intra-class target variation, limited image resolution, and poor detection and tracking results. To mitigate these challenges, we introduced a context-augmented video event recognition approach. Specifically, we explicitly capture different types of contexts from three levels including image level, semantic level, and prior level. At the image level, we introduce two types of contextual features including the appearance context features and interaction context features to capture the appearance of context objects and their interactions with the target objects. At the semantic level, we propose a deep model based on deep Boltzmann machine to learn event object representations and their interactions. At the prior level, we utilize two types of prior-level contexts including scene priming and dynamic cueing. Finally, we introduce a hierarchical context model that systematically integrates the contextual information at different levels. Through the hierarchical context model, contexts at different levels jointly contribute to the event recognition. We evaluate the hierarchical context model for event recognition on benchmark surveillance video datasets. Results show that incorporating contexts in each level can improve event recognition performance, and jointly integrating three levels of contexts through our hierarchical model achieves the best performance.	[Wang, Xiaoyang] Nokia Bell Labs, Murray Hill, NJ 07974 USA; [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Nokia Corporation; Nokia Bell Labs; Rensselaer Polytechnic Institute	Wang, XY (corresponding author), Nokia Bell Labs, Murray Hill, NJ 07974 USA.	xiaoyang.wang@nokia-bell-labs.com; qji@ecse.rpi.edu		Wang, Xiaoyang/0000-0002-0746-1059	Defense Advanced Research Projects Agency [HR0011-08-C-0135-S8, HR0011-10-C-0112]; Army Research Office [W911NF-13-1-0395]	Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Army Research Office	This work is supported in part by Defense Advanced Research Projects Agency under grants HR0011-08-C-0135-S8 and HR0011-10-C-0112, and by the Army Research Office under grant W911NF-13-1-0395.	Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Cutler R, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P416, DOI 10.1109/AFGR.1998.670984; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Escorcia V, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P508, DOI 10.1109/ICCVW.2013.72; Gallagher Andrew C., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562984; Gupta A., 2007, IEEE C COMP VIS PATT, DOI 10.1109/CVPR.2007.383331; Hasan M, 2014, LECT NOTES COMPUT SC, V8691, P705, DOI 10.1007/978-3-319-10578-9_46; He XM, 2004, PROC CVPR IEEE, P695; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hospedales T, 2012, INT J COMPUT VISION, V98, P303, DOI 10.1007/s11263-011-0510-7; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li LJ, 2007, IEEE I CONF COMP VIS, P345; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Niebles J. C., 2007, P IEEE C COMP VIS PA, P1; Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Ramanathan V, 2013, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2013.320; Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342; Reddy KK, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P106, DOI 10.1109/AVSS.2012.40; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Ryoo M.S., 2010, ICPR; Salakhutdinov R., 2012, LEARNING DEEP BOLTZM; Salakhutdinov R., 2009, P 12 INT C ART INT S, P448; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Sangmin Oh, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3579, DOI 10.1109/ICPR.2010.873; Shariat S, 2013, IEEE I CONF COMP VIS, P3583, DOI 10.1109/ICCV.2013.445; Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI [DOI 10.1162/NEC0_A_00311, DOI 10.1109/CVPR.2013.49]; Srivastava N, 2014, J MACH LEARN RES, V15, P2949; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Vail D., 2007, P 6 INT JOINT C AUT, P1331; Varadarajan J, 2013, INT J COMPUT VISION, V103, P100, DOI 10.1007/s11263-012-0596-6; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Waltisberg D, 2010, LECT NOTES COMPUT SC, V6388, P306, DOI 10.1007/978-3-642-17711-8_31; Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493; Wang XY, 2015, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2015.7299071; Wang XY, 2014, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2014.328; Wang XY, 2012, INT C PATT RECOG, P3378; Wang XY, 2014, PATTERN RECOGN LETT, V43, P62, DOI 10.1016/j.patrec.2013.07.015; Yang GS, 2010, INFORM SCIENCES, V180, P1942, DOI 10.1016/j.ins.2010.01.011; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235; Yu G, 2012, LECT NOTES COMPUT SC, V7574, P693, DOI 10.1007/978-3-642-33712-3_50; Yuan F, 2012, PATTERN RECOGN, V45, P4182, DOI 10.1016/j.patcog.2012.05.001; Zeng XY, 2013, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2013.22; Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51; Zhu YY, 2013, PROC CVPR IEEE, P2491, DOI 10.1109/CVPR.2013.322	62	23	24	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1770	1782		10.1109/TPAMI.2016.2616308	http://dx.doi.org/10.1109/TPAMI.2016.2616308			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28113742				2022-12-18	WOS:000406840800006
J	Bergamasco, F; Albarelli, A; Cosmo, L; Rodola, E; Torsello, A				Bergamasco, Filippo; Albarelli, Andrea; Cosmo, Luca; Rodola, Emanuele; Torsello, Andrea			An Accurate and Robust Artificial Marker Based on Cyclic Codes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RUNE tag; fiducial markers; cyclic codes; camera calibration; pose estimation		Artificial markers are successfully adopted to solve several vision tasks, ranging from tracking to calibration. While most designs share the same working principles, many specialized approaches exist to address specific application domains. Some are specially crafted to boost pose recovery accuracy. Others are made robust to occlusion or easy to detect with minimal computational resources. The sheer amount of approaches available in recent literature is indeed a statement to the fact that no silver bullet exists. Furthermore, this is also a hint to the level of scholarly interest that still characterizes this research topic. With this paper we try to add a novel option to the offer, by introducing a general purpose fiducial marker which exhibits many useful properties while being easy to implement and fast to detect. The key ideas underlying our approach are three. The first one is to exploit the projective invariance of conics to jointly find the marker and set a reading frame for it. Moreover, the tag identity is assessed by a redundant cyclic coded sequence implemented using the same circular features used for detection. Finally, the specific design and feature organization of the marker are well suited for several practical tasks, ranging from camera calibration to information payload delivery.	[Bergamasco, Filippo; Albarelli, Andrea; Cosmo, Luca; Torsello, Andrea] Univ Ca Foscari Venezia, DAIS, Venice, Italy; [Rodola, Emanuele] Tech Univ Munich, Dept Informat, Munich, Bavaria, Germany	Universita Ca Foscari Venezia; Technical University of Munich	Bergamasco, F (corresponding author), Univ Ca Foscari Venezia, DAIS, Venice, Italy.	filippo.bergamasco@unive.it; albarelli@unive.it; luca.cosmo@unive.it; emanuele.rodola@in.tum.de; torsello@dsi.unive.it	Cosmo, Luca/AAT-4569-2020; Torsello, Andrea/K-6352-2016	Cosmo, Luca/0000-0001-7729-4666; Torsello, Andrea/0000-0001-9189-4924; Bergamasco, Filippo/0000-0001-6668-1556				Albarelli  A., 2010, P BRIT MACH VIS C, DOI [10.5244/C.24.16, DOI 10.5244/C.24.16]; Bergamasco F, 2014, INT C PATT RECOG, P2137, DOI 10.1109/ICPR.2014.372; Bergamasco F, 2011, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2011.5995544; Bradski G., 2008, LEARNING OPENCV COMP; Chen Q, 2004, LECT NOTES COMPUT SC, V3023, P521; Cho Y, 1998, P IEEE VIRT REAL ANN, P212, DOI 10.1109/VRAIS.1998.658494; Claus D, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P300; Daftry S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.19; Fiala M, 2005, PROC CVPR IEEE, P590; Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146; Fitzgibbon A. W., 1995, BMVC '95 Proceedings of the 6th British Machine Vision Conference, P513; FORNEY GD, 1965, IEEE T INFORM THEORY, V11, P549, DOI 10.1109/TIT.1965.1053825; Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005; Gatrell L., 1991, P SOC PHOTO-OPT INS, V1612, P235; Hagbi N, 2009, INT SYM MIX AUGMENT, P65, DOI 10.1109/ISMAR.2009.5336498; Herout A, 2013, PROC CVPR IEEE, P1384, DOI 10.1109/CVPR.2013.182; Huynh D. Q., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P262; Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809; Knyaz VA, 1998, 3D SURFACE MEASUREME; MACWILLIAMS FJ, 1978, THEORY ERROR CORRECT; Maidi M, 2010, MACH VISION APPL, V21, P365, DOI 10.1007/s00138-008-0170-y; Mallon J, 2007, PATTERN RECOGN LETT, V28, P921, DOI 10.1016/j.patrec.2006.12.008; Mooser J, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1301, DOI 10.1109/ICME.2006.262777; Naimark L, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P27, DOI 10.1109/ISMAR.2002.1115065; Orsini E, 2005, J PURE APPL ALGEBRA, V200, P191, DOI 10.1016/j.jpaa.2004.12.027; Ouellet JN, 2009, MACH VISION APPL, V21, P59, DOI 10.1007/s00138-008-0141-3; Rekimoto J., 2000, P DARE 2000 DES AUGM, P1, DOI DOI 10.1145/354666.354667; Stathakis A., 2011, 2011 IEEE International Symposium on Robotic and Sensors Environments (ROSE 2011), P19, DOI 10.1109/ROSE.2011.6058524; Szentandrasi I, 2012, INT SYM MIX AUGMENT, P319, DOI 10.1109/ISMAR.2012.6402593; Teixeira L, 2008, LECT NOTES COMPUT SC, V5358, P520, DOI 10.1007/978-3-540-89639-5_50; Thomas G., 2004, US Patent RE, Patent No. 38420; Tsonis VS, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P342, DOI 10.1109/IROS.1998.724642; van Liere R, 2003, P IEEE VIRT REAL ANN, P191, DOI 10.1109/VR.2003.1191138; van Rhijn A., 2004, P EUR S VIRT ENV 200, P35; Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99; Yu X., 2004, P 12 ANN ACM INT C M, P256; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	37	23	24	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2359	2373		10.1109/TPAMI.2016.2519024	http://dx.doi.org/10.1109/TPAMI.2016.2519024			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26800529	Green Submitted			2022-12-18	WOS:000387984700002
J	Ulen, J; Strandmark, P; Kahl, F				Ulen, Johannes; Strandmark, Petter; Kahl, Fredrik			Shortest Paths with Higher-Order Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Curve extraction; optimization; curvature; torsion; line graphs	SEGMENTATION; MINIMUM; CAR	This paper describes a new method of finding thin, elongated structures in images and volumes. We use shortest paths to minimize very general functionals of higher-order curve properties, such as curvature and torsion. Our method uses line graphs to find the optimal path on a given discretization, often in the order of seconds on a single computer. The curves are then refined using local optimization making it possible to recover very smooth curves. We are able to place constraints on our curves such as maximum integrated curvature, or a maximum curvature at any point of the curve. To our knowledge, we are the first to perform experiments in three dimensions with curvature and torsion regularization. The largest graphs we process have over a hundred billion arcs. Experiments on medical images and in multi-view reconstruction show the significance and practical usefulness of higher order regularization.	[Ulen, Johannes; Strandmark, Petter; Kahl, Fredrik] Lund Univ, S-22100 Lund, Sweden; [Kahl, Fredrik] Chalmers Univ Technol, Gothenburg, Sweden	Lund University; Chalmers University of Technology	Ulen, J (corresponding author), Lund Univ, S-22100 Lund, Sweden.	ulen@maths.lth.se; petter@maths.lth.se; fredrik@maths.lth.se			Swedish Foundation for Strategic Research (FFL); European Research Council [209480]; Swedish Research Council [2012-4215]	Swedish Foundation for Strategic Research (FFL); European Research Council(European Research Council (ERC)European Commission); Swedish Research Council(Swedish Research CouncilEuropean Commission)	The authors gratefully acknowledge funding from the Swedish Foundation for Strategic Research (FFL), the European Research Council (grant no. 209480) and the Swedish Research Council (grant no. 2012-4215). J. Ulen is the corresponding author.	AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Bazaraa M.S., 2013, NONLINEAR PROGRAMMIN, Vthird; BEASLEY JE, 1989, NETWORKS, V19, P379, DOI 10.1002/net.3230190402; Bendtsen Claus, 1996, IMMREP199617 TU DENM; CALDWELL T, 1961, COMMUN ACM, V4, P107, DOI 10.1145/366105.366184; CAMPEN M., 2014, ACM T GRAPHIC, V33, P183; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Desaulniers G., 2005, SHORTEST PATH PROBLE; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; El-Zehiry NY, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1288, DOI 10.1109/ISBI.2012.6235798; FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; Friman O., 2008, MIDAS J GRAND CHALLE; Kahl F, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1017; Kang HW, 2005, PATTERN RECOGN LETT, V26, P2042, DOI 10.1016/j.patrec.2005.02.011; Krueger M, 2013, PATTERN RECOGN LETT, V34, P833, DOI 10.1016/j.patrec.2012.12.017; Lesage D, 2009, MED IMAGE ANAL, V13, P819, DOI 10.1016/j.media.2009.07.011; MacCormick John, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P165, DOI 10.1007/978-3-642-40395-8_13; Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815; Mehlhorn K., 2000, Algorithms - ESA 2000. 8th Annual European Symposium. Proceedings (Lecture Notes in Computer Science Vol.1879), P326; Merlet N, 1996, P SOC PHOTO-OPT INS, V2785, P204, DOI 10.1117/12.248540; Metz C., 2008, MIDAS J GRAND CHALLE; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; Nocedal J, 2006, CONJUGATE GRADIENT M; Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI, VUnabridged edition; Pechaud M, 2009, PROC CVPR IEEE, P336, DOI 10.1109/CVPRW.2009.5206782; Pressley A., 2010, ELEMENTARY DIFFERENT, VSecond; REEDS JA, 1990, PAC J MATH, V145, P367, DOI 10.2140/pjm.1990.145.367; Schaap M, 2009, MED IMAGE ANAL, V13, P701, DOI 10.1016/j.media.2009.06.003; Schoenemann T, 2012, INT J COMPUT VISION, V99, P53, DOI 10.1007/s11263-012-0518-7; Schoenemann T, 2011, IEEE T IMAGE PROCESS, V20, P2565, DOI 10.1109/TIP.2011.2118225; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Strandmark Petter, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P205, DOI 10.1007/978-3-642-23094-3_15; Strandmark P., 2013, LIB UNCONSTRAINED MI; Strandmark P, 2013, IEEE I CONF COMP VIS, P2024, DOI 10.1109/ICCV.2013.253; Stuhmer J, 2013, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2013.290; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Vendittelli M, 1999, IEEE T ROBOTIC AUTOM, V15, P678, DOI 10.1109/70.781973; Winter S, 2002, GEOINFORMATICA, V6, P345, DOI 10.1023/A:1020853410145; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131	40	23	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2588	2600		10.1109/TPAMI.2015.2409869	http://dx.doi.org/10.1109/TPAMI.2015.2409869			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539860				2022-12-18	WOS:000364831700018
J	Dal Mutto, C; Zanuttigh, P; Cortelazzo, GM				Dal Mutto, Carlo; Zanuttigh, Pietro; Cortelazzo, Guido Maria			Probabilistic ToF and Stereo Data Fusion Based on Mixed Pixels Measurement Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ToF; stereo; data fusion; MAP-MRF; loopy belief propagation; mixed pixels	TIME-OF-FLIGHT; ENERGY MINIMIZATION; SPACETIME STEREO; DEPTH; SHAPE	This paper proposes a method for fusing data acquired by a ToF camera and a stereo pair based on a model for depth measurement by ToF cameras which accounts also for depth discontinuity artifacts due to the mixed pixel effect. Such model is exploited within both a ML and a MAP-MRF frameworks for ToF and stereo data fusion. The proposed MAP-MRF framework is characterized by site-dependent range values, a rather important feature since it can be used both to improve the accuracy and to decrease the computational complexity of standard MAP-MRF approaches. This paper, in order to optimize the site dependent global cost function characteristic of the proposed MAP-MRF approach, also introduces an extension to Loopy Belief Propagation which can be used in other contexts. Experimental data validate the proposed ToF measurements model and the effectiveness of the proposed fusion techniques.	[Dal Mutto, Carlo; Zanuttigh, Pietro; Cortelazzo, Guido Maria] Univ Padua, Dept Informat Engn, I-35100 Padua, Italy	University of Padua	Dal Mutto, C (corresponding author), Univ Padua, Dept Informat Engn, I-35100 Padua, Italy.	dalmutto@dei.unipd.it; zanuttigh@dei.unipd.it; corte@dei.unipd.it	Zanuttigh, Pietro/AAB-9555-2019	Zanuttigh, Pietro/0000-0002-9502-2389				BESAG J, 1986, J R STAT SOC B, V48, P259; Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Dal Mutto C, 2012, LECT NOTES COMPUT SC, V7583, P598, DOI 10.1007/978-3-642-33863-2_62; DalMutto C, 2012, SPRBRIEF ELECT, P1, DOI 10.1007/978-1-4614-3807-6; Davis J, 2003, PROC CVPR IEEE, P359; Diebel James, 2005, NEURAL INF PROCESS S, P291; Dolson J, 2010, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2010.5540086; FRICK A, 2009, 2009 3DTV C TRUE VIS, P1; Garro V, 2013, ANN TELECOMMUN, V68, P597, DOI 10.1007/s12243-013-0389-0; Garro V, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P52, DOI 10.1109/CVMP.2009.26; Godbaz J. P., 2008, P 23 INT C IM VIS CO, P1; Guomundsson Sigurjon Arni, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P425, DOI 10.1504/IJISTA.2008.021305; Hahne U, 2009, LECT NOTES COMPUT SC, V5742, P70, DOI 10.1007/978-3-642-03778-8_6; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Kahlmann T, 2008, J APPL GEOD, V2, P1, DOI 10.1515/JAG.2008.001; Kuhnert KD, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4780, DOI 10.1109/IROS.2006.282349; Lange R., 2000, THESIS U SIEGEN SIEG; Mattoccia Stefano, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P371; Mutto C. Dal, 2010, P 3DPVT, P1; Nair Rahul, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P105, DOI 10.1007/978-3-642-44964-2_6; Nair R, 2012, LECT NOTES COMPUT SC, V7584, P1, DOI 10.1007/978-3-642-33868-7_1; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Piatti D, 2012, REMOTE SENS-BASEL, V4, P1069, DOI 10.3390/rs4041069; Qingxiong Yang, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P69, DOI 10.1109/MMSP.2010.5661996; Remondino F., 2013, TOF RANGE IMAGING CA; Reynolds M, 2011, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2011.5995550; Sabov Alexander, 2008, P 24 SPRING C COMP G, P135; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schmidt M., 2011, THESIS U HEIDELBERG; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; Velten A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1747; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wang L, 2008, LECT NOTES COMPUT SC, V5302, P576, DOI 10.1007/978-3-540-88682-2_44; WOODS JW, 2006, MULTIDIMENSIONAL SIG; Wu D, 2014, INT J COMPUT VISION, V107, P123, DOI 10.1007/s11263-013-0668-2; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Yang QX, 2013, IEEE T IMAGE PROCESS, V22, P4841, DOI 10.1109/TIP.2013.2278917; Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430; Zhang L, 2003, PROC CVPR IEEE, P367; Zhu J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587761; Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172; Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68; [No title captured]	51	23	24	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2260	2272		10.1109/TPAMI.2015.2408361	http://dx.doi.org/10.1109/TPAMI.2015.2408361			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440266	Green Submitted			2022-12-18	WOS:000362411000009
J	Dubrovina-Karni, A; Rosman, G; Kimmel, R				Dubrovina-Karni, Anastasia; Rosman, Guy; Kimmel, Ron			Multi-Region Active Contours with a Single Level Set Function	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; multi-region; active contours; level sets	IMAGE SEGMENTATION; MINIMAL-SURFACES; FRAMEWORK; MUMFORD; SPACE; MODEL	Segmenting an image into an arbitrary number of coherent regions is at the core of image understanding. Many formulations of the segmentation problem have been suggested over the past years. These formulations include, among others, axiomatic functionals, which are hard to implement and analyze, and graph-based alternatives, which impose a non-geometric metric on the problem. We propose a novel method for segmenting an image into an arbitrary number of regions using an axiomatic variational approach. The proposed method allows to incorporate various generic region appearance models, while avoiding metrication errors. In the suggested framework, the segmentation is performed by level set evolution. Yet, contrarily to most existing methods, here, multiple regions are represented by a single non-negative level set function. The level set function evolution is efficiently executed through the Voronoi Implicit Interface Method for multi-phase interface evolution. The proposed approach is shown to obtain accurate segmentation results for various natural 2D and 3D images, comparable to state-of-the-art image segmentation algorithms.	[Dubrovina-Karni, Anastasia; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; [Rosman, Guy] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Technion Israel Institute of Technology; Massachusetts Institute of Technology (MIT)	Dubrovina-Karni, A (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	nastyad@cs.technion.ac.il; rosman@csail.mit.edu; ron@cs.technion.ac.il			European Community's FP7-ERC program [267414]	European Community's FP7-ERC program	The authors thank J.A. Sethian of UC Berkeley for intriguing discussions and introducing the VIIM to our group. The authors thank P. Arbelaez of the Berkeley Computer Vision Group, for the advice on using the BSDS500 benchmarks. This research was supported by the European Community's FP7-ERC program, grant agreement 267414. Anastasia Dubrovina is the corresponding author.	ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; Adalsteinsson D, 1999, J COMPUT PHYS, V148, P2, DOI 10.1006/jcph.1998.6090; Adam A, 2009, IEEE T PATTERN ANAL, V31, P1708, DOI 10.1109/TPAMI.2009.21; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y; Bae E, 2009, LECT NOTES COMPUT SC, V5567, P1, DOI 10.1007/978-3-642-02256-2_1; BAE EGIL, 2013, INNOVATIONS SHAPE AN, P421; Bertelli L, 2008, IEEE T PATTERN ANAL, V30, P1400, DOI 10.1109/TPAMI.2007.70785; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brox T, 2006, IEEE T IMAGE PROCESS, V15, P3213, DOI 10.1109/TIP.2006.877481; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Caselles V, 1997, NUMER MATH, V77, P423, DOI 10.1007/s002110050294; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chopp DL, 2001, SIAM J SCI COMPUT, V23, P230, DOI 10.1137/S106482750037617X; Cocosco C.A., 1997, NEUROIMAGE, V5, P425, DOI DOI 10.1016/S1053-8119(97)80018-3; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T, 2005, PROC CVPR IEEE, P1124; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z; Dubrovina A., 2013, LNCS, P416; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; Jung MY, 2012, SIAM J IMAGING SCI, V5, P1022, DOI [10.1137/11085863X, 10.1007/978-3-642-24785-9_22]; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237; Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4; Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417; Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Lie J, 2006, MATH COMPUT, V75, P1155, DOI 10.1090/S0025-5718-06-01835-7; Lucas BC, 2012, LECT NOTES COMPUT SC, V7510, P495, DOI 10.1007/978-3-642-33415-3_61; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mclachlan G., 2000, WILEY SER PROB STAT; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Morariu Vlad I, 2008, ADV NEURAL INFORM PR, P1113, DOI DOI 10.5555/2981780.2981919; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pock T, 2008, LECT NOTES COMPUT SC, V5304, P792, DOI 10.1007/978-3-540-88690-7_59; Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604; Riklin-Raviv T, 2005, IEEE I CONF COMP VIS, P204; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Sandberg B, 2010, IEEE T IMAGE PROCESS, V19, P119, DOI 10.1109/TIP.2009.2032310; Saye RI, 2012, J COMPUT PHYS, V231, P6051, DOI 10.1016/j.jcp.2012.04.004; Saye RI, 2011, P NATL ACAD SCI USA, V108, P19498, DOI 10.1073/pnas.1111557108; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Sumengen B, 2006, IEEE T PATTERN ANAL, V28, P509, DOI 10.1109/TPAMI.2006.76; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	63	23	25	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1585	1601		10.1109/TPAMI.2014.2385708	http://dx.doi.org/10.1109/TPAMI.2014.2385708			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26352997				2022-12-18	WOS:000357591900005
J	Ji, JQ; Yan, SC; Li, JM; Gao, GY; Tian, Q; Zhang, B				Ji, Jianqiu; Yan, Shuicheng; Li, Jianmin; Gao, Guangyu; Tian, Qi; Zhang, Bo			Batch-Orthogonal Locality-Sensitive Hashing for Angular Similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sign-random-projection; locality-sensitive hashing; angular similarity; approximate nearest neighbor search	NEAREST-NEIGHBOR; QUANTIZATION; ALGORITHMS; OBJECT	Sign-random-projection locality-sensitive hashing (SRP-LSH) is a widely used hashing method, which provides an unbiased estimate of pairwise angular similarity, yet may suffer from its large estimation variance. We propose in this work batch-orthogonal locality-sensitive hashing (BOLSH), as a significant improvement of SRP-LSH. Instead of independent random projections, BOLSH makes use of batch-orthogonalized random projections, i.e., we divide random projection vectors into several batches and orthogonalize the vectors in each batch respectively. These batch-orthogonalized random projections partition the data space into regular regions, and thus provide a more accurate estimator. We prove theoretically that BOLSH still provides an unbiased estimate of pairwise angular similarity, with a smaller variance for any angle in (0,pi), compared with SRP-LSH. Furthermore, we give a lower bound on the reduction of variance. The extensive experiments on real data well validate that with the same length of binary code, BOLSH may achieve significant mean squared error reduction in estimating pairwise angular similarity. Moreover, BOLSH shows the superiority in extensive approximate nearest neighbor (ANN) retrieval experiments.	[Ji, Jianqiu; Li, Jianmin; Zhang, Bo] Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Gao, Guangyu] Beijing Inst Technol, Sch Software, Beijing 100081, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA	Tsinghua University; Beijing Institute of Technology; National University of Singapore; University of Texas System; University of Texas at San Antonio (UTSA)	Ji, JQ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	jijq10@mails.tsinghua.edu.cn; eleyans@nus.edu.sg; lijianmin@mail.tsinghua.edu.cn; guangyugao@bit.edu.cn; qi.tian@utsa.edu; dcszb@mail.tsinghua.edu.cn	Yan, Shuicheng/HCI-1431-2022		National Basic Research Program (973 Program) of China [2013CB329403, 2012CB316301]; National Natural Science Foundation of China [61332007, 61273023, 91120011]; Beijing Natural Science Foundation [4132046]; Tsinghua University Initiative Scientific Research Program [20121088071]; Singapore National Research Foundation under its International Research Centre @Singapore Funding Initiative; ARO [W911NF-12-1-0057]; NEC Laboratories of America; UTSA START-R Research Award; National Science Foundation of China (NSFC) [61128007]	National Basic Research Program (973 Program) of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation); Tsinghua University Initiative Scientific Research Program; Singapore National Research Foundation under its International Research Centre @Singapore Funding Initiative(National Research Foundation, Singapore); ARO; NEC Laboratories of America; UTSA START-R Research Award; National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by the National Basic Research Program (973 Program) of China (Grant Nos. 2013CB329403 and 2012CB316301), the National Natural Science Foundation of China (Grant No. 61332007, 61273023 and 91120011), the Beijing Natural Science Foundation (Grant No. 4132046), and the Tsinghua University Initiative Scientific Research Program (Grant No. 20121088071). This research is partially supported by the Singapore National Research Foundation under its International Research Centre @Singapore Funding Initiative and administered by the IDM Programme Office. This work was supported in part to Dr. Qi Tian by ARO grant W911NF-12-1-0057, Faculty Research Awards by NEC Laboratories of America, and 2012 UTSA START-R Research Award respectively. This work was supported in part by National Science Foundation of China (NSFC) 61128007. Part of the work appeared in NIPS 2012.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900; Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7; Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965; Chum O, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPRW.2009.5206531; Chum Ondrej, 2008, BMVC, V810, P812, DOI DOI 10.5244/C.22.50; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dean T., 2013, P IEEE C COMP VIS PA; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jain P., 2010, P ADV NEUR INF PROC, P928; Jain P, 2008, PROC CVPR IEEE, P3879; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, INT CONF ACOUST SPEE, P2029, DOI 10.1109/ICASSP.2012.6288307; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Ji Jianqiu, 2012, ADV NEURAL INFORM PR, P108; Ke Y, 2004, ACM MULTIMEDIA, V4, P869, DOI DOI 10.1145/1027527.1027729; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Kuo Y., 2009, P 17 ACM INT C MULT, P65, DOI DOI 10.1145/1631272.1631284; Li P., 2006, P 12 ACM SIGKDD INT, P287, DOI [10.1145/1150402.1150436, DOI 10.1145/1150402.1150436]; Li Ping, 2010, P 19 INT C WORLD WID, P671, DOI DOI 10.1145/1772690.1772759; Li Ping, 2011, ADV NEURAL INFORM PR, P2672; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu Wei, 2011, Reports in Parasitology, V1, P1; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv Q, 2007, P 33 INT C VER LARG, P950, DOI DOI 10.1145/1143844.1143857; Manku G.S., 2007, P 16 INT C WORLD WID, P141; Matei B, 2006, IEEE T PATTERN ANAL, V28, P1111, DOI 10.1109/TPAMI.2006.148; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Norouzi M, 2012, PROC CVPR IEEE, P3108, DOI 10.1109/CVPR.2012.6248043; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Ravichandran Deepak, 2005, P 43 ANN M ASS COMP, P622, DOI DOI 10.3115/1219840.1219917; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Satuluri V, 2012, PROC VLDB ENDOW, V5, P430, DOI 10.14778/2140436.2140440; Schleimer S., 2003, P ACM SIGMOD INT C M, P76, DOI [DOI 10.1145/872757.872770, 10.1145/872757.872770]; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wang J., 2010, ICML, P1127; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Weiss Y., 2008, NIPS, V21, P1753; Winder SAJ, 2007, PROC CVPR IEEE, P17	50	23	24	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					1963	1974		10.1109/TPAMI.2014.2315806	http://dx.doi.org/10.1109/TPAMI.2014.2315806			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352628				2022-12-18	WOS:000341981300005
J	Park, SY; Park, SK; Hebert, M				Park, Soonyong; Park, Sung-Kee; Hebert, Martial			Fast and Scalable Approximate Spectral Matching for Higher Order Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Higher order graph matching; spectral relaxation; approximation algorithm	ALGORITHM	This paper presents a fast and efficient computational approach to higher order spectral graph matching. Exploiting the redundancy in a tensor representing the affinity between feature points, we approximate the affinity tensor with the linear combination of Kronecker products between bases and index tensors. The bases and index tensors are highly compressed representations of the approximated affinity tensor, requiring much smaller memory than in previous methods, which store the full affinity tensor. We compute the principal eigenvector of the approximated affinity tensor using the small bases and index tensors without explicitly storing the approximated tensor. To compensate for the loss of matching accuracy by the approximation, we also adopt and incorporate a marginalization scheme that maps a higher order tensor to matrix as well as a one-to-one mapping constraint into the eigenvector computation process. The experimental results show that the proposed method is faster and requires smaller memory than the existing methods with little or no loss of accuracy.	[Park, Soonyong] Samsung Adv Inst Technol, Future IT R& Ctr, Yongin, Kyounggi Do, South Korea; [Park, Sung-Kee] Korea Inst Sci & Technol, Seoul 136791, South Korea; [Hebert, Martial] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Samsung; Korea Institute of Science & Technology (KIST); Carnegie Mellon University	Park, SY (corresponding author), Samsung Adv Inst Technol, Future IT R& Ctr, San 14, Yongin, Kyounggi Do, South Korea.	soonyong.park@gmail.com; skee@kist.re.kr; hebert@ri.cmu.edu			Intelligent Robotics Development Program, one of the 21st Century Frontier RD Programs; Ministry of Knowledge Economy of Korea; National Agenda Project of the Korea Research Council of Fundamental Science and Technology; KIST Institutional Program [2E24123]	Intelligent Robotics Development Program, one of the 21st Century Frontier RD Programs; Ministry of Knowledge Economy of Korea(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); National Agenda Project of the Korea Research Council of Fundamental Science and Technology; KIST Institutional Program(Korea Institute of Science & Technology (KIST))	Soonyong Park and Martial Hebert were supported by the Intelligent Robotics Development Program, one of the 21st Century Frontier R&D Programs funded by the Ministry of Knowledge Economy of Korea. Sung-Kee Park was supported by the National Agenda Project of the Korea Research Council of Fundamental Science and Technology and the KIST Institutional Program (2E24123).	Albarelli A, 2009, IEEE I CONF COMP VIS, P1319, DOI 10.1109/ICCV.2009.5459312; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berg AC, 2005, PROC CVPR IEEE, P26; Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; Fielding G, 2000, PATTERN RECOGN, V33, P1511, DOI 10.1016/S0031-3203(99)00132-6; Garey M.R., 1979, COMPUTERS INTRACTABI; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hemayed EE, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P351, DOI 10.1109/AVSS.2003.1217942; Horn R. A., 1986, MATRIX ANAL; Kang U, 2013, INFORM SCIENCES, V220, P306, DOI 10.1016/j.ins.2012.07.008; Kofidis E, 2002, SIAM J MATRIX ANAL A, V23, P863, DOI 10.1137/S0895479801387413; Kolda TG, 2003, SIAM J MATRIX ANAL A, V24, P762, DOI 10.1137/S0895479801394465; Kruger J, 2003, ACM T GRAPHIC, V22, P908, DOI 10.1145/882262.882363; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lange K., 1999, NUMERICAL ANAL STAT; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M., 2007, P IEEE C COMP VIS PA; Leroy A.M., 2003, ROBUST REGRESSION OU; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Martin C.D., 2005, THESIS CORNELL U; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Veltkamp R.C., 2000, TECHNICAL REPORT; Zass R., 2008, P IEEE C COMP VIS PA; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	37	23	27	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					479	492		10.1109/TPAMI.2013.157	http://dx.doi.org/10.1109/TPAMI.2013.157			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457505	Green Submitted			2022-12-18	WOS:000331450100007
J	Goodfellow, IJ; Courville, A; Bengio, Y				Goodfellow, Ian J.; Courville, Aaron; Bengio, Yoshua			Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural nets; pattern recognition; computer vision		We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.	[Goodfellow, Ian J.; Courville, Aaron; Bengio, Yoshua] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Universite de Montreal	Goodfellow, IJ (corresponding author), Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.	goodfeli@iro.umontreal.ca		Goodfellow, Ian/0000-0002-9483-510X; Goodfellow, Ian/0000-0003-3937-2322	US Defense Advanced Research Projects Agency (DARPA); NSERC	US Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work was supported by the US Defense Advanced Research Projects Agency (DARPA) and NSERC. The authors would like to thank Pascal Vincent for helpful discussions. The computation done for this work was conducted in part on computers of RESMIQ, Clumeq, and SharcNet. The authors would like to thank the developers of Theano (Bergstra et al. [3]) and pylearn2 (Warde-Farley et al. [39]).	Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bergstra J., 2010, P PYTH SCI COMP C; Coates A., 2011, P INT C MACH LEARN; Coates A., 2011, P 13 INT C ART INT S; Courville A., 2011, P 13 INT C ART INT S; Courville A, 2011, P 28 INT C MACH LEAR; Deng L., 2010, P INTERSPEECH, V10; Desjardins G., 2012, ABS12034416 CORR; Douglas SC, 2000, IEEE T SIGNAL PROCES, V48, P1843, DOI 10.1109/78.845952; Garrigues P. J., 2008, ADV NEURAL INFORM PR, P505; Hinton G., 2010, MOMENTUM; Hinton G.E., 2000, 2000004 GCNU TR GATS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvaarinen A., 2009, NATURAL IMAGE STAT P; Jia Y., 2011, P NEUR INF PROC SYST; Karpenko A., 2011, ADV NEURAL INFORM PR; Kavukcuoglu K., 2010, P NEUR INF PROC SYST; Koller D., 2009, PROBABILISTIC GRAPHI; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Le Q.V., 2011, NEURIPS, P1017; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lucke J., 2011, ARXIV11052493; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; Mohamed S., 2012, P INT C MACH LEARN; Montavon G., 2012, CORR; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Salakhutdinov R., 2009, JMLR P, V5; Saul L.K., 1996, P ADV NEUR INF PROC; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Titsias M.K., 2011, P ADV NEUR INF PROC; Titterington DM, 1985, STAT ANAL FINITE MIX; Vincent P., 2008, P INT C MACH LEARN; Warde-Farley D., 2011, PYLEARN2; Younes L, 1998, STOCHASTICS STOCHAST, P177; Yu K., 2011, P IEEE C COMP VIS PA; Zeiler M., 2011, P INT C MACH LEARN; Zhou M, 2009, ADV NEURAL INFORM PR, P2295	43	23	24	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1902	1914		10.1109/TPAMI.2012.273	http://dx.doi.org/10.1109/TPAMI.2012.273			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787343				2022-12-18	WOS:000320381400007
J	Lim, MH; Teoh, ABJ				Lim, Meng-Hui; Teoh, Andrew Beng Jin			A Novel Encoding Scheme for Effective Biometric Discretization: Linearly Separable Subcode	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometric discretization; quantization; encoding; linearly separable subcode	CRYPTOGRAPHIC KEY GENERATION; GRAY	Separability in a code is crucial in guaranteeing a decent Hamming-distance separation among the codewords. In multibit biometric discretization where a code is used for quantization-intervals labeling, separability is necessary for preserving distance dissimilarity when feature components are mapped from a discrete space to a Hamming space. In this paper, we examine separability of Binary Reflected Gray Code (BRGC) encoding and reveal its inadequacy in tackling interclass variation during the discrete-to-binary mapping, leading to a tradeoff between classification performance and entropy of binary output. To overcome this drawback, we put forward two encoding schemes exhibiting full-ideal and near-ideal separability capabilities, known as Linearly Separable Subcode (LSSC) and Partially Linearly Separable Subcode (PLSSC), respectively. These encoding schemes convert the conventional entropy-performance tradeoff into an entropy-redundancy tradeoff in the increase of code length. Extensive experimental results vindicate the superiority of our schemes over the existing encoding schemes in discretization performance. This opens up possibilities of achieving much greater classification performance with high output entropy.	[Lim, Meng-Hui; Teoh, Andrew Beng Jin] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul 120749, South Korea	Yonsei University	Lim, MH (corresponding author), Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul 120749, South Korea.	menghui.lim@gmail.com; bjteoh@yonsei.ac.kr	Teoh, Andrew Beng Jin/F-4422-2010	Teoh, Andrew Beng Jin/0000-0001-5063-9484	Korea Science and Engineering Foundation (KOSEF); Korea government (MEST) [2011-8-1095]	Korea Science and Engineering Foundation (KOSEF)(Korea Science and Engineering Foundation); Korea government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaKorean Government)	This work was supported by the Korea Science and Engineering Foundation (KOSEF) grant funded by the Korea government (MEST) (No. 2011-8-1095).	CAVIOR SR, 1975, IEEE T INFORM THEORY, V21, P596, DOI 10.1109/TIT.1975.1055424; Chang Y., 2004, P IEEE INT C MULT EX; Chen C, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/784834; Chen C, 2011, SIGNAL PROCESS, V91, P906, DOI 10.1016/j.sigpro.2010.09.008; Chen C., 2004, P IEEE INT C MULT EX, V3, P2203; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523; Gray F., 1953, U.S. Patent no, Patent No. [2 632 058, 2632058, 2, 632, 058, 2,632,058]; Hao Feng, 2002, Information Management & Computer Security, V10, P159, DOI 10.1108/09685220210436949; Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714; Kelkboom EJC, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P230; Kevenaar TAM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P21, DOI 10.1109/AUTOID.2005.24; Killian CE, 2004, DISCRETE MATH, V281, P221, DOI 10.1016/j.disc.2003.07.012; Knuth D., 2005, FASCICLE 2 GENERATIN, V4; Lim M.-H., 2010, P IEEE 5 C IND EL AP; Linnartz J.-P., 2003, LNCS, P238; Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888; LUDMAN JE, 1981, IEEE T COMMUN, V29, P1519, DOI 10.1109/TCOM.1981.1094886; Martinez A., 1998, 24 CVC, P24; Monrose F, 2001, P IEEE S SECUR PRIV, P202, DOI 10.1109/SECPRI.2001.924299; Neylon T, 2010, PROC APPL MATH, V135, P1179; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Suparta I.N., 2006, THESIS DELFT U TECHN; Teoh ABJ, 2004, COMPUT SECUR, V23, P606, DOI 10.1016/j.cose.2004.06.002; Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250; Teoh ABJ, 2007, LECT NOTES COMPUT SC, V4642, P435; Teoh ABJ, 2010, PATTERN ANAL APPL, V13, P301, DOI 10.1007/s10044-009-0158-x; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Tuyls P, 2005, LECT NOTES COMPUT SC, V3546, P436; Verbitskiy E., 2003, 24 BEN S INF THEOR, P125; Yip WK, 2006, LECT NOTES COMPUT SC, V3832, P509; Yue F, 2009, PATTERN RECOGN, V42, P2841, DOI 10.1016/j.patcog.2009.03.015; YUEN CK, 1974, IEEE T INFORM THEORY, V20, P668, DOI 10.1109/TIT.1974.1055275	33	23	23	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					300	313		10.1109/TPAMI.2012.122	http://dx.doi.org/10.1109/TPAMI.2012.122			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22641702				2022-12-18	WOS:000312560600005
J	Eichner, M; Ferrari, V				Eichner, Marcin; Ferrari, Vittorio			Human Pose Co-Estimation and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human pose estimation; articulated objects; multiple image correspondence; object detection		Most existing techniques for articulated Human Pose Estimation (HPE) consider each person independently. Here we tackle the problem in a new setting, coined Human Pose Coestimation (PCE), where multiple people are in a common, but unknown pose. The task of PCE is to estimate their poses jointly and to produce prototypes characterizing the shared pose. Since the poses of the individual people should be similar to the prototype, PCE has less freedom compared to estimating each pose independently, which simplifies the problem. We demonstrate our PCE technique on two applications. The first is estimating the pose of people performing the same activity synchronously, such as during aerobics, cheerleading, and dancing in a group. We show that PCE improves pose estimation accuracy over estimating each person independently. The second application is learning prototype poses characterizing a pose class directly from an image search engine queried by the class name (e.g., "lotus pose"). We show that PCE leads to better pose estimation in such images, and it learns meaningful prototypes which can be used as priors for pose estimation in novel images.	[Eichner, Marcin] ETH, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland; [Ferrari, Vittorio] Univ Edinburgh, Sch Informat, IPAB Inst, Edinburgh EH8 9AB, Midlothian, Scotland	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Edinburgh	Eichner, M (corresponding author), ETH, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland.	eichner@vision.ee.ethz.ch; vferrari@staffmail.ed.ac.uk						Andriluka M., 2010, P IEEE C COMP VIS PA; ANDRILUKA M, 2009, P IEEE C COMP VIS PA; [Anonymous], 2004, CLUSTER ANAL RES; Berg Tamara L., 2004, WHOS PICTURE; Boyd S, 2004, CONVEX OPTIMIZATION; Buehler Patrick, 2008, P BRIT MACH VIS C; Eichner M., 2009, P BRIT MACH VIS C; Eichner M., 2010, P 11 EUR C COMP VIS; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FERGUS R, 2004, P 8 EUR C COMP VIS M; Ferrari V., 2009, P IEEE C COMP VIS PA; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Ioffe S., 2001, PROC EIGHTH IEEE INT; Johnson S., 2010, P 21 BRIT MACH VIS C; Kanaujia A., 2007, P IEEE C COMP VIS PA; Lan X., 2005, P 10 IEEE INT C COMP, V1; Lee M., 2004, P 8 EUR C COMP VIS M; MORI G, 2004, P IEEE C COMP VIS PA; Ramanan D., 2006, P ADV NEUR INF PROC; Ramanan D., 2006, P IEEE C COMP VIS PA; Sapp B., 2010, P 8 EUR C COMP VIS; Sapp B., 2010, P IEEE C COMP VIS PA; Schroff F., 2007, P 11 IEEE INT C COMP; Sigal L., 2006, PROC IEEE C COMPUT V, P2041; Sigal L., 2006, P 4 INT C ART MOT DE; Tran D., 2010, P 11 EUR C COMP VIS; Valmadre J., 2010, P 11 EUR C COMP VIS; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Yang Y., 2011, P IEEE C COMP VIS PA	30	23	25	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2282	2288		10.1109/TPAMI.2012.85	http://dx.doi.org/10.1109/TPAMI.2012.85			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22487983	Green Accepted			2022-12-18	WOS:000308755000018
J	Skibbe, H; Reisert, M; Schmidt, T; Brox, T; Ronneberger, O; Burkhardt, H				Skibbe, Henrik; Reisert, Marco; Schmidt, Thorsten; Brox, Thomas; Ronneberger, Olaf; Burkhardt, Hans			Fast Rotation Invariant 3D Feature Computation Utilizing Efficient Local Neighborhood Operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Voxel classification; local 3D descriptors; rotation invariants; spherical harmonics; Gauss-Laguerre functions	DESIGN	We present a method for densely computing local rotation invariant image descriptors in volumetric images. The descriptors are based on a transformation to the harmonic domain, which we compute very efficiently via differential operators. We show that this fast voxelwise computation is restricted to a family of basis functions that have certain differential relationships. Building upon this finding, we propose local descriptors based on the Gaussian Laguerre and spherical Gabor basis functions and show how the coefficients can be computed efficiently by recursive differentiation. We exemplarily demonstrate the effectiveness of such dense descriptors in a detection and classification task on biological 3D images. In a direct comparison to existing volumetric features, among them 3D SIFT, our descriptors reveal superior performance.	[Skibbe, Henrik; Reisert, Marco] Univ Med Ctr Freiburg, Dept Radiol, D-79106 Freiburg, Germany; [Skibbe, Henrik; Schmidt, Thorsten; Brox, Thomas; Ronneberger, Olaf; Burkhardt, Hans] Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany; [Skibbe, Henrik; Schmidt, Thorsten; Brox, Thomas; Ronneberger, Olaf; Burkhardt, Hans] Univ Freiburg, Ctr Biol Signalling Studies BIOSS, D-79106 Freiburg, Germany	University of Freiburg; University of Freiburg; University of Freiburg	Skibbe, H (corresponding author), Univ Med Ctr Freiburg, Dept Radiol, Breisacher Str 60A, D-79106 Freiburg, Germany.	henrik.skibbe@uniklinik-freiburg.de; marco.reisert@uniklinik-freiburg.de; tschmidt@informatik.uni-freiburg.de; brox@informatik.uni-freiburg.de; ronneber@informatik.uni-freiburg.de; hans.burkhardt@informatik.uni-freiburg.de	Burkhardt, Hans/M-5895-2019		Excellence Initiative of the German Federal and State Governments [EXC 294]; Baden-Wurttemberg Stiftung	Excellence Initiative of the German Federal and State Governments; Baden-Wurttemberg Stiftung	This study was supported by the Excellence Initiative of the German Federal and State Governments (EXC 294). Marco Reisert and Henrik Skibbe are indebted to the Baden-Wurttemberg Stiftung for the financial support of this research project by the Eliteprogramme for Postdocs.	Abramowitz M., 1964, HDB MATH FUNCTIONS F; Allaire Stephane, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563023; BIGUN J, 1994, INT C PATT RECOG, P184, DOI 10.1109/ICPR.1994.577153; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brink D. M., 1993, ANGULAR MOMENTUM; Chiu LYC, 2001, J MOL STRUC-THEOCHEM, V536, P263, DOI 10.1016/S0166-1280(00)00704-1; Chiu LYC, 1999, INT J QUANTUM CHEM, V73, P265, DOI 10.1002/(SICI)1097-461X(1999)73:3<265::AID-QUA1>3.0.CO;2-7; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Farid H, 2004, IEEE T IMAGE PROCESS, V13, P496, DOI 10.1109/TIP.2004.823819; Fehr J, 2006, LECT NOTES COMPUT SC, V4174, P263; Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI 10.1016/0031-3203(91)90143-S; Kazhdan M., 2003, Symposium on Geometry Processing, P156; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; Kondor R., 2008, THESIS COLUMBIA U; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Matsuoka O, 1998, J CHEM PHYS, V108, P1063, DOI 10.1063/1.475468; Qian Z., 2006, P INT C IEEE ENG MED, V1; Reisert M, 2008, IEEE T IMAGE PROCESS, V17, P2265, DOI 10.1109/TIP.2008.2006601; Reisert M, 2009, ADV PATTERN RECOGNIT, P153, DOI 10.1007/978-1-84882-299-3_7; Reisert M, 2009, LECT NOTES COMPUT SC, V5748, P131, DOI 10.1007/978-3-642-03798-6_14; Ronneberger O, 2005, LECT NOTES COMPUT SC, V3663, P85; Rose M. E, 1995, ELEMENTARY THEORY AN; Sandler R, 2009, INT J COMPUT VISION, V84, P308, DOI 10.1007/s11263-009-0237-x; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; Skibbe H., 2009, P IEEE INT C COMP VI; Skibbe H, 2010, LECT NOTES COMPUT SC, V6376, P412; Sorgi L., 2006, BMVC, V2, P539; Thomson JJ, 1904, PHILOS MAG, V7, P237, DOI 10.1080/14786440409463107; Wang Q, 2009, IEEE T PATTERN ANAL, V31, P1715, DOI 10.1109/TPAMI.2009.29	33	23	24	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1563	1575		10.1109/TPAMI.2011.263	http://dx.doi.org/10.1109/TPAMI.2011.263			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22201055				2022-12-18	WOS:000305188500009
J	Moser, BA				Moser, Bernhard A.			A Similarity Measure for Image and Volumetric Data Based on Hermann Weyl's Discrepancy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Similarity of images; normalized cross correlation; autocorrelation; mutual information; discrepancy norm; registration; tracking; image processing; similarity measure	REGISTRATION	The paper focuses on similarity measures for translationally misaligned image and volumetric patterns. For measures based on standard concepts such as cross-correlation, L-p-norm, and mutual information, monotonicity with respect to the extent of misalignment cannot be guaranteed. In this paper, we introduce a novel distance measure based on Hermann Weyl's discrepancy concept that relies on the evaluation of partial sums. In contrast to standard concepts, in this case, monotonicity, positive-definiteness, and a homogenously linear upper bound with respect to the extent of misalignment can be proven. We show that this monotonicity property is not influenced by the image's frequencies or other characteristics, which makes this new similarity measure useful for similarity-based registration, tracking, and segmentation.	Software Competence Ctr Hagenberg GmbH, A-4232 Hagenberg, Austria	Softwarepark Hagenberg	Moser, BA (corresponding author), Software Competence Ctr Hagenberg GmbH, Softwarepk 21, A-4232 Hagenberg, Austria.	bernhard.moser@scch.at			Austrian COMET; Austrian Science Fund (FWF) [P 21496] Funding Source: researchfish	Austrian COMET; Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	The author thanks Ulrich Bodenhofer for his original idea to apply Hermann Weyl's discrepancy norm to pixel classification. This inspired the author to the investigations outlined in this paper. This work was supported by the Austrian COMET Program.	Bauer P, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P2007, DOI 10.1109/FUZZY.1996.552744; Ben Hamza A, 2001, 2001 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING PROCEEDINGS, P130, DOI 10.1109/SSP.2001.955239; Bercher JF, 2008, INFORM SCIENCES, V178, P2489, DOI 10.1016/j.ins.2008.02.003; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Chazelle B., 2000, DISCREPANCY METHOD R; JAIN R, 1995, P IEEE INT C FUZZ SY, V3, P1247; Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105; Khalid MS, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P209, DOI 10.1109/ISPA.2005.195411; Kullback S, 1959, INFORM THEORY STAT; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; MOSER B, 2008, P 32 WORKSH AUSTR AS, P187; Neunzert H., 1987, 28 U KAIS DEP MATH; Niederreiter H., 1992, RANDOM NUMBER GENERA, V63; Peng NS, 2006, SOFT COMPUT, V10, P1127, DOI 10.1007/s00500-005-0035-5; Perez-Garcia A, 2006, LECT NOTES COMPUT SC, V4225, P686; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872; Renyi A., 1961, P 4 BERKELEY S MATH, V1; Vajda I, 1989, THEORY STAT INFERENC; VASCONCELOS N, 2001, P 15 INT C PATT REC, V1, P38; Weyl H, 1915, MATH ANN, V77, P313; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	22	23	25	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2321	U1501		10.1109/TPAMI.2009.50	http://dx.doi.org/10.1109/TPAMI.2009.50			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21921307				2022-12-18	WOS:000294910000016
J	Vazquez, E; Baldrich, R; van de Weijer, J; Vanrell, M				Vazquez, Eduard; Baldrich, Ramon; van de Weijer, Joost; Vanrell, Maria			Describing Reflectances for Color Segmentation Robust to Shadows, Highlights, and Textures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; color	IMAGE SEGMENTATION; ALGORITHM; SALIENCY; MODEL; INFORMATION; WATERSHEDS	The segmentation of a single material reflectance is a challenging problem due to the considerable variation in image measurements caused by the geometry of the object, shadows, and specularities. The combination of these effects has been modeled by the dichromatic reflection model. However, the application of the model to real-world images is limited due to unknown acquisition parameters and compression artifacts. In this paper, we present a robust model for the shape of a single material reflectance in histogram space. The method is based on a multilocal creaseness analysis of the histogram which results in a set of ridges representing the material reflectances. The segmentation method derived from these ridges is robust to both shadow, shading and specularities, and texture in real-world images. We further complete the method by incorporating prior knowledge from image statistics, and incorporate spatial coherence by using multiscale color contrast information. Results obtained show that our method clearly outperforms state-of-the-art segmentation methods on a widely used segmentation benchmark, having as a main characteristic its excellent performance in the presence of shadows and highlights at low computational cost.	[Vazquez, Eduard; Baldrich, Ramon; van de Weijer, Joost; Vanrell, Maria] Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona 08192, Spain	Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Vazquez, E (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Edifici O, Barcelona 08192, Spain.	eduard@cvc.uab.cat; ramon@cvc.uab.cat; joost@cvc.uab.cat; maria@cvc.uab.cat	van de Weijer, Joost/A-1643-2009; Vanrell, Maria/A-7694-2010	van de Weijer, Joost/0000-0002-9656-9706; Vanrell, Maria/0000-0002-1567-9293	Spanish MEC (Ministry of Science) [TIN2007-64577, TIN2009-14173, CSD2007-00018]; European Union [ERG 224737]; Ramon y Cajal Program; Generalitat de Catalunya [2009 SGR669]	Spanish MEC (Ministry of Science)(Spanish Government); European Union(European Commission); Ramon y Cajal Program(Spanish Government); Generalitat de Catalunya(Generalitat de Catalunya)	This work has been partially supported by projects TIN2007-64577, TIN2009-14173, and Consolider-Ingenio 2010 CSD2007-00018 of the Spanish MEC (Ministry of Science), the Marie Curie Reintegration grant (ERG 224737) of the European Union, Generalitat de Catalunya (2009 SGR669), and the Ramon y Cajal Program.	ABDALMAGEED W, 2006, P 9 EUR C COMP VIS; ABDELHAKIM EA, 2005, P 8 INT C INF FUS, V2, P1576; AGARWAL S, 2005, P INT C INF TECHN CO, V2, P147; Bajcsy R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P785, DOI 10.1109/ICPR.1990.118217; Berens J, 2000, INT C PATT RECOG, P206, DOI 10.1109/ICPR.2000.905304; BISHNU A, 2002, P 3 IND C COMP VIS G; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Cates JE, 2005, MED IMAGE ANAL, V9, P566, DOI 10.1016/j.media.2005.04.007; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1; Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7; Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421; Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985; DONOSER M, 2007, P IEEE CS C COMP VIS; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; FOWLKES C, 2003, P IEEE CS C COMP VIS, V2; Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P635, DOI 10.1109/34.216734; Ge F., 2006, IEEE COMP SOC C COMP, V1, P1146, DOI DOI 10.1109/CVRR.2006.147; Ge F, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762250; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Hanbury A, 2006, LECT NOTES COMPUT SC, V3851, P888; Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380; Heidemann G, 2008, IMAGE VISION COMPUT, V26, P211, DOI 10.1016/j.imavis.2007.05.001; Huang Q, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC53; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Kato Z, 2006, IMAGE VISION COMPUT, V24, P1103, DOI 10.1016/j.imavis.2006.03.005; Kim C, 2008, PATTERN RECOGN, V41, P22, DOI 10.1016/j.patcog.2007.04.011; Kim DW, 2004, PATTERN RECOGN LETT, V25, P227, DOI 10.1016/j.patrec.2003.10.004; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Liu T., 2007, P IEEE C COMP VIS PA, P1; Lopez AM, 1999, IEEE T PATTERN ANAL, V21, P327, DOI 10.1109/34.761263; Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Macaire L, 2006, COMPUT VIS IMAGE UND, V102, P105, DOI 10.1016/j.cviu.2005.12.001; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Maxwell BA, 1997, COMPUT VIS IMAGE UND, V65, P269, DOI 10.1006/cviu.1997.0573; MICUSIK B, 2006, P EUR C COMP VIS; Nikolaev DP, 2004, COMPUT VIS IMAGE UND, V94, P115, DOI 10.1016/j.cviu.2003.10.012; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; Omer I, 2004, PROC CVPR IEEE, P946; Ong CK, 1998, INT C PATT RECOG, P780, DOI 10.1109/ICPR.1998.711263; Pantofaru C., 2005, CMURITR0540; PAPPAS TN, 1992, IEEE T SIGNAL PROCES, V40, P901, DOI 10.1109/78.127962; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; Pichel JC, 2006, PATTERN RECOGN LETT, V27, P1105, DOI 10.1016/j.patrec.2005.12.012; Schmid P, 1999, IEEE T MED IMAGING, V18, P164, DOI 10.1109/42.759124; Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015; Skarbek W, 1994, COLOUR IMAGE SEGMENT; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; TAKAHASHI K, 1999, IEICE T, P751; van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3; VAZQUEZ E, 2008, P EUR C COMP VIS, P1; Vazquez E, 2007, LECT NOTES COMPUT SC, V4477, P55; Verma D., 2003, UWCSE030501; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; Wattuya P, 2008, INT C PATT RECOG, P1550; YANG Y, 2007, UNSUPERVISED SEGMENT	68	23	25	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					917	930		10.1109/TPAMI.2010.146	http://dx.doi.org/10.1109/TPAMI.2010.146			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20714021				2022-12-18	WOS:000288677800005
J	Schoenemann, T; Cremers, D				Schoenemann, Thomas; Cremers, Daniel			A Combinatorial Solution for Model-Based Image Segmentation and Real-Time Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; tracking; elastic shape priors; discrete optimization; dynamic programming; minimum ratio cycles; real-time applications	SHAPE PRIORS; REPRESENTATION; REGIONS	We propose a combinatorial solution to determine the optimal elastic matching of a deformable template to an image. The central idea is to cast the optimal matching of each template point to a corresponding image pixel as a problem of finding a minimum cost cyclic path in the three-dimensional product space spanned by the template and the input image. We introduce a cost functional associated with each cycle, which consists of three terms: a data fidelity term favoring strong intensity gradients, a shape consistency term favoring similarity of tangent angles of corresponding points, and an elastic penalty for stretching or shrinking. The functional is normalized with respect to the total length to avoid a bias toward shorter curves. Optimization is performed by Lawler's Minimum Ratio Cycle algorithm parallelized on state-of-the-art graphics cards. The algorithm provides the optimal segmentation and point correspondence between template and segmented curve in computation times that are essentially linear in the number of pixels. To the best of our knowledge, this is the only existing globally optimal algorithm for real-time tracking of deformable shapes.	[Schoenemann, Thomas; Cremers, Daniel] Univ Bonn, Dept Comp Sci, D-53117 Bonn, Germany	University of Bonn	Schoenemann, T (corresponding author), Univ Bonn, Dept Comp Sci, Roemerstr 164, D-53117 Bonn, Germany.	tosch@cs.uni-bonn.de; dcremers@cs.uni-bonn.de			German Research Foundation [CR-250/1-1, CR-250/2-1]	German Research Foundation(German Research Foundation (DFG))	The authors thank Bodo Rosenhahn and Daimler Research for providing image data. They thank also Thomas Pock for helpful comments on efficient GPU programming and Frank R. Schmidt for many fruitful discussions. This research was supported by the German Research Foundation under grants #CR-250/1-1 and #CR-250/2-1.	Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; COOTES TF, 1993, P BRIT MACH VIS C, P639; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; CREMERS D, 2008, P IEEE INT C COMP VI; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; DELLAERT F, 1997, P C INT TRANSP SYST; Denzler J, 1999, REAL-TIME IMAGING, V5, P203, DOI 10.1006/rtim.1997.0116; Doucet A., 2001, SEQUENTIAL MONTE CAR; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Ford L. R, 1956, P923 RAND CORP; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; Grenander U., 1991, HANDS PATTERN THEORE; GUI L, 2007, P IEEE INT C COMP VI; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Jalba AC, 2004, IEEE T PATTERN ANAL, V26, P1320, DOI 10.1109/TPAMI.2004.84; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; LAWLER E. L., 1966, P INT S THEORY GRAPH, P209; LEMPITSKY V, 2008, P EUR C COMP VIS OCT; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; MAES M, 1991, PATTERN RECOGN, V24, P433, DOI 10.1016/0031-3203(91)90056-B; MCCONNELL R, 1991, IEEE T GEOSCI REMOTE, V29, P1004, DOI 10.1109/36.101377; Moore E.F., 1959, P INT S SWITCH THEOR, V1959, P285; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Ramanan D., 2006, P 2006 IEEE COMP VIS, P206; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93; ROUSSON M, 2002, P EUR C COMP VIS, P78; Schoenemann T., 2007, P IEEE INT C COMP VI; Schoenemann T., 2008, P IEEE INT C COMP VI; SCHOENEMANN T, 2008, P BRIT MACH VIS C SE; Shi J., 1994, P IEEE INT C COMP VI; Tsai A, 2001, PROC CVPR IEEE, P463; Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737; Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6	44	23	24	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1153	1164		10.1109/TPAMI.2009.79	http://dx.doi.org/10.1109/TPAMI.2009.79			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489221				2022-12-18	WOS:000277649100001
J	Pflugfelder, R; Bischof, H				Pflugfelder, Roman; Bischof, Horst			Localization and Trajectory Reconstruction in Surveillance Cameras with Nonoverlapping Views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera localization; nonoverlapping camera views; direct reference plane method; simultaneous localization and tracking	SELF-CALIBRATION	This paper proposes a method that localizes two surveillance cameras and simultaneously reconstructs object trajectories in 3D space. The method is an extension of the Direct Reference Plane method, which formulates the localization and the reconstruction as a system of linear equations that is globally solvable by Singular Value Decomposition. The method's assumptions are static synchronized cameras, smooth trajectories, known camera internal parameters, and the rotation between the cameras in a world coordinate system. The paper describes the method in the context of self-calibrating cameras, where the internal parameters and the rotation can be jointly obtained assuming a man-made scene with orthogonal structures. Experiments with synthetic and real-image data show that the method can recover the camera centers with an error less than half a meter even in the presence of a 4 meter gap between the fields of view.	[Pflugfelder, Roman] AIT Austrian Inst Technol, Dept Safety & Secur, A-1220 Vienna, Austria; [Bischof, Horst] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria	Austrian Institute of Technology (AIT); Graz University of Technology	Pflugfelder, R (corresponding author), AIT Austrian Inst Technol, Dept Safety & Secur, Donau City Str 1, A-1220 Vienna, Austria.	roman.pflugfelder@arcs.ac.at; bischof@icg.tugraz.at		Bischof, Horst/0000-0002-9096-6671	Osterreichische Forschungsforderungsgesellschaft [813.377]; AIT Austrian Institute of Technology	Osterreichische Forschungsforderungsgesellschaft; AIT Austrian Institute of Technology	The authors would like to thank the reviewers for their valuable and constructive comments. This work was part of project 813.377 Nachwuchsforderung which was funded by Osterreichische Forschungsforderungsgesellschaft mbH and AIT Austrian Institute of Technology.	ANJUM N, 2007, P IEEE INT C AC SPEE; Brand M, 2006, LINEAR ALGEBRA APPL, V415, P20, DOI 10.1016/j.laa.2005.07.021; Caspi Y, 2002, INT J COMPUT VISION, V48, P39, DOI 10.1023/A:1014803327923; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; Devarajan D, 2008, P IEEE, V96, P1625, DOI 10.1109/JPROC.2008.928759; FISHER RB, 2002, P EUR C COMP VIS, V4, P146; Hartley R., 2004, ROBOTICA; HARTLEY R, 2007, P INT C COMP VIS OCT; Javed O., 2003, P IEEE INT C MULT EX; Kaucic R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P420, DOI 10.1109/ICCV.2001.937548; KOSECKA J, 2002, P 7 EUR C COMP VIS M, pF476; Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233; LIEBOWITZ D, 2001, THESIS U OXFORD; Makris D, 2004, PROC CVPR IEEE, P205; Marinakis D, 2009, IMAGE VISION COMPUT, V27, P116, DOI 10.1016/j.imavis.2006.06.009; PFLUGFELDER R, 2008, THESIS GRAZ U TECHNO; PFLUGFELDER R, 2008, P 19 INT C PATT REC; PFLUGFELDER R, 2007, P IEEE INT C ADV VID; Pflugfelder R., 2005, P DIG IM COMP TECHN; Rahimi A, 2004, PROC CVPR IEEE, P187; Rinner B, 2008, P IEEE, V96, P1565, DOI 10.1109/JPROC.2008.928742; ROTHER C, 2001, P INT C COMP VIS JUL; ROTHER C, 2003, THESIS ROYAL I TECHN; Rudoy M., 2006, P IEEE AS C SIGN SYS; Schindler G, 2004, PROC CVPR IEEE, P203; Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3; Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325; Taylor C, 2006, IPSN 2006: THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P27; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19	34	23	27	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					709	721		10.1109/TPAMI.2009.56	http://dx.doi.org/10.1109/TPAMI.2009.56			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224125				2022-12-18	WOS:000274548800011
J	Xu, D; Yan, SC; Lin, S; Huang, TS; Chang, SF				Xu, Dong; Yan, Shuicheng; Lin, Stephen; Huang, Thomas S.; Chang, Shih-Fu			Enhancing Bilinear Subspace Learning by Element Rearrangement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bilinear subspace learning; element rearrangement; earth mover's distance; dimensionality reduction	DISCRIMINANT-ANALYSIS	The success of bilinear subspace learning heavily depends on reducing correlations among features along rows and columns of the data matrices. In this work, we study the problem of rearranging elements within a matrix in order to maximize these correlations so that information redundancy in matrix data can be more extensively removed by existing bilinear subspace learning algorithms. An efficient iterative algorithm is proposed to tackle this essentially integer programming problem. In each step, the matrix structure is refined with a constrained Earth Mover's Distance procedure that incrementally rearranges matrices to become more similar to their low-rank approximations, which have high correlation among features along rows and columns. In addition, we present two extensions of the algorithm for conducting supervised bilinear subspace learning. Experiments in both unsupervised and supervised bilinear subspace learning demonstrate the effectiveness of our proposed algorithms in improving data compression performance and classification accuracy.	[Xu, Dong] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Lin, Stephen] Microsoft Res Asia, Sigma Ctr, Beijing 100080, Peoples R China; [Huang, Thomas S.] Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; [Chang, Shih-Fu] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; National University of Singapore; Microsoft; Microsoft Research Asia; University of Illinois System; University of Illinois Urbana-Champaign; Columbia University	Xu, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave,Blk N4, Singapore 639798, Singapore.	dongxu@ntu.edu.sg; eleyans@nus.edu.sg; stevelin@microsoft.com; huang@ifp.uiuc.edu; sfchang@ee.columbia.edu	Yan, Shuicheng/HCI-1431-2022; Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730	Singapore National Research Foundation [NRF2008IDM-IDM004-018, NRF-2008IDM-IDM004-029]; US Government	Singapore National Research Foundation(National Research Foundation, Singapore); US Government	This material is based upon work funded by the Singapore National Research Foundation Interactive Digital Media R& D Program under research grant NRF2008IDM-IDM004-018 and NRF-2008IDM-IDM004-029 as well as the US Government. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the US Government.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chen HT, 2005, PROC CVPR IEEE, P846; DAI G, 2006, P NAT C ART INT, P330; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jebara T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P265; JEBARA T, 2004, P C LEARN THEOR; JEBARA T, 2003, P INT C ART INT STAT; Jensen P.A., 2003, OPERATIONS RES MODEL; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Nemhauser G.L., 1988, INTEGER COMBINATORIA; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; SHIVASWAMY P, 2006, P INT C MACH LEARN; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P450; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Vasilescu MAO, 2003, PROC CVPR IEEE, P93; Xu D, 2005, PROC CVPR IEEE, P203; YAN S, 2007, P IEEE C COMP VIS PA; Yan SC, 2005, PROC CVPR IEEE, P526; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Ye J., 2004, P ADV NEUR INF PROC, P1569; Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6	26	23	23	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1913	1920		10.1109/TPAMI.2009.51	http://dx.doi.org/10.1109/TPAMI.2009.51			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696459				2022-12-18	WOS:000268996500015
J	Cuzol, A; Memin, E				Cuzol, Anne; Memin, Etienne			A Stochastic Filtering Technique for Fluid Flow Velocity Fields Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion estimation; tracking; nonlinear stochastic filtering; fluid flows	ORTHOGONAL DECOMPOSITION; VISUAL TRACKING; MOTION; MODELS	In this paper, we present a method for the temporal tracking of fluid flow velocity fields. The technique we propose is formalized within a sequential Bayesian filtering framework. The filtering model combines an Ito diffusion process coming from a stochastic formulation of the vorticity-velocity form of the Navier-Stokes equation and discrete measurements extracted from the image sequence. In order to handle a state space of reasonable dimension, the motion field is represented as a combination of adapted basis functions, derived from a discretization of the vorticity map of the fluid flow velocity field. The resulting nonlinear filtering problem is solved with the particle filter algorithm in continuous time. An adaptive dimensional reduction method is applied to the filtering technique, relying on dynamical systems theory. The efficiency of the tracking method is demonstrated on synthetic and real-world sequences.	[Cuzol, Anne] Univ Brittany UBS, CNRS, Lab STICC, UMR 3192, F-56000 Vannes, France; [Memin, Etienne] Ctr INRIA Rennes Bretagne Atlantique, F-35042 Rennes, France	Centre National de la Recherche Scientifique (CNRS); Universite de Bretagne Occidentale	Cuzol, A (corresponding author), Univ Brittany UBS, CNRS, Lab STICC, UMR 3192, Campus Tohannic,BP 573, F-56000 Vannes, France.	anne.cuzol@univ-ubs.fr; Etienne.Memin@inria.fr			European community	European community(European Commission)	The authors would like to thank ONERA for providing them with the experimental data of wingtip vortices. This work was supported by the European community through the IST Fet open FLUID project (http://fluid.irisa.fr).	ARNAUD E, 2006, P EUR C COMP VIS MAY; Arnaud E, 2007, INT J COMPUT VISION, V74, P75, DOI 10.1007/s11263-006-0003-2; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERKOOZ G, 1993, ANNU REV FLUID MECH, V25, P539, DOI 10.1146/annurev.fl.25.010193.002543; BOSSY M, 2005, P EUROPEAN SERIES AP, V15, P18; Canuto C., 1988, SPECTRAL METHODS FLU; Chorin A, 1993, MATHL INTRO FLUID ME; CHORIN AJ, 2004, P NATL ACAD SCI USA, V101, P42; Chorin AJ, 1973, J FLUID MECH, V57, P785, DOI 10.1017/S0022112073002016; Corpetti T, 2003, J MATH IMAGING VIS, V19, P175, DOI 10.1023/A:1026352203836; Corpetti T, 2002, IEEE T PATTERN ANAL, V24, P365, DOI 10.1109/34.990137; Cottet G.-H., 2000, VORTEX METHODS THEOR; CUZOL A, 2005, P INT C COMP VIS OCT; CUZOL A, 2005, P 5 INT C SCAL SPAC; Cuzol A, 2007, INT J COMPUT VISION, V75, P329, DOI 10.1007/s11263-007-0037-0; Del Moral P, 2001, PROBAB THEORY REL, V120, P346, DOI 10.1007/PL00008786; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Farge M, 1999, PHYS FLUIDS, V11, P2187, DOI 10.1063/1.870080; FARNEBACK G, 1999, P INT C COMP VIS, P5; HEAS P, 2007, IEEE T GEOSCIENCE RE; HEAS P, 2007, 6292 INRIA; Heas P, 2007, IEEE T GEOSCI REMOTE, V45, P4087, DOI 10.1109/TGRS.2007.906156; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kloeden P. E., 1991, NUMERICAL SOLUTION S; LEONARD A, 1980, J COMPUTATIONAL PHYS, V37; MARCHIORO C, 1982, COMMUN MATH PHYS, V84, P483, DOI 10.1007/BF01209630; Meleard S, 2001, PROBAB THEORY REL, V121, P367, DOI 10.1007/s004400100154; Miller RN, 2002, MON WEATHER REV, V130, P2313, DOI 10.1175/1520-0493(2002)130<2313:EGFMOM>2.0.CO;2; Papadakis N, 2008, J MATH IMAGING VIS, V31, P81, DOI 10.1007/s10851-008-0069-2; PAPADAKIS N, 2007, 6283 INRIA; Perez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147; Pham DT, 1998, J MARINE SYST, V16, P323; RUHNAU P, 2006, P 28 ANN S GERM ASS; Ruhnau P, 2007, EXP FLUIDS, V42, P61, DOI 10.1007/s00348-006-0220-z; Ruhnau P, 2007, MEAS SCI TECHNOL, V18, P755, DOI 10.1088/0957-0233/18/3/027; Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287; YUAN J, 2005, P 5 INT C SCAL SPAC; Yuan J, 2007, J MATH IMAGING VIS, V28, P67, DOI 10.1007/s10851-007-0014-9	38	23	23	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1278	1293		10.1109/TPAMI.2008.152	http://dx.doi.org/10.1109/TPAMI.2008.152			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443925				2022-12-18	WOS:000266188900011
J	Balasubramanian, M; Polimeni, JR; Schwartz, EL				Balasubramanian, Mukund; Polimeni, Jonathan R.; Schwartz, Eric L.			Exact Geodesics and Shortest Paths on Polyhedral Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Differential geometry; flat maps; triangular meshes; surface-based analysis; computational geometry	CONVEX POLYTOPE	We present two algorithms for computing distances along convex and nonconvex polyhedral surfaces. The first algorithm computes exact minimal-geodesic distances and the second algorithm combines these distances to compute exact shortest-path distances along the surface. Both algorithms have been extended to compute the exact minimal-geodesic paths and shortest paths. These algorithms have been implemented and validated on surfaces for which the correct solutions are known, in order to verify the accuracy and to measure the runtime performance, which is cubic or less for each algorithm. The exact-distance computations carried out by these algorithms are feasible for large-scale surfaces containing tens of thousands of vertices and are a necessary component of near-isometric surface flattening methods that accurately transform curved manifolds into flat representations.	[Balasubramanian, Mukund; Schwartz, Eric L.] Boston Univ, Dept Cognit & Neural Syst, Boston, MA 02215 USA; [Polimeni, Jonathan R.] Harvard Univ, Sch Med, Dept Radiol, Athinoula A Martinos Ctr Biomed Imaging,MGH, Charlestown, MA 02129 USA; [Schwartz, Eric L.] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA; [Schwartz, Eric L.] Boston Univ, Dept Anat & Neurobiol, Boston, MA 02215 USA	Boston University; Harvard University; Boston University; Boston University	Balasubramanian, M (corresponding author), Boston Univ, Dept Cognit & Neural Syst, 677 Beacon St, Boston, MA 02215 USA.	mukundb@cns.bu.edu; jonp@nmr.mgh.harvard.edu; eric@bu.edu	Polimeni, Jonathan R/P-1395-2014	Polimeni, Jonathan R/0000-0002-1348-1179	US National Institute for Biomedical Imaging and Bioengineering Grant [R01 EB001550]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB001550] Funding Source: NIH RePORTER	US National Institute for Biomedical Imaging and Bioengineering Grant(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	The authors would like to thank Dan Cruthirds and Oliver P. Hinds for their helpful insights and comments on this project, as well as Dr. Guillermo Sapiro and the anonymous reviewers, whose feedback led to a significant improvement of the manuscript. This work was supported in part by the US National Institute for Biomedical Imaging and Bioengineering Grant R01 EB001550.	Agarwal PK, 1997, J ACM, V44, P567, DOI 10.1145/263867.263869; BALASUBRAMANIAN M, 2005, SOC NEUR ABSTR; BALASUBRAMANIAN M, 2006, SOC NEUR ABSTR; BARTOSZYNSKIPRI.T, 2001, J MATH LOG, V1, P1, DOI DOI 10.1142/S0219061301000028; Chen JD, 1996, INT J COMPUT GEOM AP, V6, P127, DOI 10.1142/S0218195996000095; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; EDELSBRUNNER H, 2001, CAMBRIDGE MONOGRAPHS, V7; Fischl B, 2001, IEEE T MED IMAGING, V20, P70, DOI 10.1109/42.906426; Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846; GAREY MR, 1978, INFORM PROCESS LETT, V7, P175, DOI 10.1016/0020-0190(78)90062-5; Gelfand I.M., 1963, CALCULUS VARIATIONS; Har-Peled S, 1999, SIAM J COMPUT, V28, P1182, DOI 10.1137/S0097539797325223; Hershberger J, 1998, COMP GEOM-THEOR APPL, V10, P31, DOI 10.1016/S0925-7721(97)00004-7; HINDS OP, 2005, SOC NEUR ABSTR; HINDS OP, 2006, NEUROIMAGE, V31, pS445; Jolesz FA, 1997, AM J ROENTGENOL, V169, P1229, DOI 10.2214/ajr.169.5.9353433; Kageura M, 2004, J MECH DESIGN, V126, P1017, DOI 10.1115/1.1814386; Kanai T, 2001, COMPUT AIDED DESIGN, V33, P801, DOI 10.1016/S0010-4485(01)00097-5; Kaneva B., 2000, Proceedings of the 12th Annual Canadian Conference on Computational Geometry, P139; Kapoor S., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, P770, DOI 10.1145/301250.301449; Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369; Khaneja N, 1998, IEEE T PATTERN ANAL, V20, P1260, DOI 10.1109/34.730559; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; KRISHNAMURTHY V, 1996, P SIGGRAPH 96, P313, DOI DOI 10.1145/237170.237270; Lanthier M, 2001, ALGORITHMICA, V30, P527, DOI 10.1007/s00453-001-0027-5; McCleary John, 1994, GEOMETRY DIFFERENTIA; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; Mount D. M., 1984, 1495 U MAR DEP COMP; Novotni M, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P341; O'Rourke J, 1999, INT J COMPUT GEOM AP, V9, P513, DOI 10.1142/S0218195999000297; OROURKE J, 1985, LECT NOTES COMPUT SC, V182, P243; POLIMENI JR, 2005, SOC NEUR ABSTR; Polthier K., 1998, MATH VISUALIZATION A, P135; Press WH, 1988, NUMERICAL RECIPES C; SCHWARTZ E, 1985, SOC NEUR ABSTR; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; Schwartz Eric L., 1994, Cerebral Cortex, V10, P359; Sethian JA, 2000, P NATL ACAD SCI USA, V97, P5699, DOI 10.1073/pnas.090060097; SHARIR M, 1986, SIAM J COMPUT, V15, P193, DOI 10.1137/0215014; Smith D., 1974, VARIATIONAL METHODS; Struik Dirk Jan, 1961, LECT CLASSICAL DIFFE, P7; Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228; TARJAN RE, 1988, SIAM J COMPUT, V17, P143, DOI 10.1137/0217010; Varadarajan KR, 2000, SIAM J COMPUT, V30, P1321, DOI 10.1137/S0097539799352759; WOLFSON E, 1989, IEEE T PATTERN ANAL, V11, P1001, DOI 10.1109/34.35505; Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671; [No title captured]	50	23	24	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1006	1016		10.1109/TPAMI.2008.213	http://dx.doi.org/10.1109/TPAMI.2008.213			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372606				2022-12-18	WOS:000265100000004
J	Jia, HJ; Martinez, AM				Jia, Hongjun; Martinez, Aleix M.			Low-Rank Matrix Fitting Based on Subspace Perturbation Analysis with Applications to Structure from Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank matrix; noise; missing data; random matrix; matrix perturbation; subspace analysis; structure from motion; computer vision; pattern recognition	MISSING DATA; PRINCIPAL COMPONENTS; SHAPE; RECOGNITION; ALGORITHM	The task of finding a low-rank (r) matrix that best fits an original data matrix of higher rank is a recurring problem in science and engineering. The problem becomes especially difficult when the original data matrix has some missing entries and contains an unknown additive noise term in the remaining elements. The former problem can be solved by concatenating a set of r-column matrices that share a common single r-dimensional solution space. Unfortunately, the number of possible submatrices is generally very large and, hence, the results obtained with one set of r-column matrices will generally be different from that captured by a different set. Ideally, we would like to find that solution that is least affected by noise. This requires that we determine which of the r-column matrices (i.e., which of the original feature points) are less influenced by the unknown noise term. This paper presents a criterion to successfully carry out such a selection. Our key result is to formally prove that the more distinct the r vectors of the r-column matrices are, the less they are swayed by noise. This key result is then combined with the use of a noise model to derive an upper bound for the effect that noise and occlusions have on each of the r-column matrices. It is shown how this criterion can be effectively used to recover the noise-free matrix of rank r. Finally, we derive the affine and projective structure-from-motion (SFM) algorithms using the proposed criterion. Extensive validation on synthetic and real data sets shows the superiority of the proposed approach over the state of the art.	[Jia, Hongjun; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Jia, HJ (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, 205 Dreese Lab,2015 Neil Ave, Columbus, OH 43210 USA.	jia.22@osu.edu; aleix@ece.osu.edu	Martinez, Aleix M/A-2380-2008		US National Science Foundation [IIS 0713055]; US National Institutes of Health [R01 DC 005241]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC005241] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	The authors thank the reviewers for their constructive comments. Thanks also to Jeff Fortuna for the discussion and involvements in the early developments of the DP criterion. The authors thank David Jacobs for making his code available to them. This research was supported in part by US National Science Foundation Grant IIS 0713055 and US National Institutes of Health Grant R01 DC 005241.	[Anonymous], 2002, SUBSET SELECTION REG, DOI DOI 10.1201/9781420035933; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; Brandt S., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P109; Buchanan AM, 2005, PROC CVPR IEEE, P316; Chen P, 2004, IEEE T PATTERN ANAL, V26, P1051, DOI 10.1109/TPAMI.2004.52; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; Dodge Y., 1985, ANAL EXPT MISSING DA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 1998, LECT NOTES COMPUTER, V1506, P155; Friedland S., 2006, IEEE P ICASSP 2006 1, V2, P1092; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gruber A, 2004, PROC CVPR IEEE, P707; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hung YS, 2006, INT J COMPUT VISION, V66, P305, DOI 10.1007/s11263-005-3675-0; IRANI M, 1999, INT J COMPUT VISION, V48, P173; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; JIA H, 2006, P 3 INT S 3D DAT PRO, P1101; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; LI GY, 1985, J AM STAT ASSOC, V80, P759, DOI 10.2307/2288497; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Mahamud S, 2000, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2000.854872; Martinec D, 2002, LECT NOTES COMPUT SC, V2351, P355; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Oliensis J, 2007, IEEE T PATTERN ANAL, V29, P2217, DOI 10.1109/TPAMI.2007.1132; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; Roweis S, 1998, ADV NEUR IN, V10, P626; Sato Y, 1996, GRAPH MODEL IM PROC, V58, P437, DOI 10.1006/gmip.1996.0036; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Stewart G., 1990, MATRIX PERTURBATION; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Vidal R, 2004, PROC CVPR IEEE, P310; Voyles RM, 1997, J DYN SYST-T ASME, V119, P229, DOI 10.1115/1.2801238; Wedin P.-A., 1972, BIT (Nordisk Tidskrift for Informationsbehandling), V12, P99, DOI 10.1007/BF01932678; Wiberg T, 1976, P 2 S COMP STAT, P229; Wilkinson JH., 1965, ALGEBRAIC EIGENVALUE; Zhang YB, 2006, IMAGE VISION COMPUT, V24, P626, DOI 10.1016/j.imavis.2005.08.004	41	23	24	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					841	854		10.1109/TPAMI.2008.122	http://dx.doi.org/10.1109/TPAMI.2008.122			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299859				2022-12-18	WOS:000264144500006
J	Bruno, E; Moenne-Loccoz, N; Marchand-Maillet, S				Bruno, Eric; Moenne-Loccoz, Nicolas; Marchand-Maillet, Stephane			Design of multimodal dissimilarity spaces for retrieval of video documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multimedia databases; multimedia information systems; image/video retrieval; machine learning; concept learning		This paper proposes a novel representation space for multimodal information, enabling fast and efficient retrieval of video data. We suggest describing the documents not directly by selected multimodal features ( audio, visual, or text) but rather by considering cross-document similarities relative to their multimodal characteristics. This idea leads us to propose a particular form of dissimilarity space that is adapted to the asymmetric classification problem and, in turn, to the query-by-example and relevance feedback paradigm, widely used in information retrieval. Based on the proposed dissimilarity space, we then define various strategies to fuse modalities through a kernel-based learning approach. The problem of automatic kernel setting to adapt the learning process to the queries is also discussed. The properties of our strategies are studied and validated on artificial data. In a second phase, a large annotated video corpus (i.e., TRECVID '05) indexed by visual, audio, and text features is considered to evaluate the overall performance of the dissimilarity space and fusion strategies. The obtained results confirm the validity of the proposed approach for the representation and retrieval of multimodal information in a real-time framework.	[Bruno, Eric; Moenne-Loccoz, Nicolas; Marchand-Maillet, Stephane] Univ Geneva, Comp Vis & Multimedia Lab, CH-1211 Geneva 4, Switzerland	University of Geneva	Bruno, E (corresponding author), Univ Geneva, Comp Vis & Multimedia Lab, 24 Rue Gen Dufour, CH-1211 Geneva 4, Switzerland.	eric.bruno@cui.unige.ch; moennen@cui.unige.ch; marchand@cui.unige.ch						Athitsos V, 2004, PROC CVPR IEEE, P268; BOLDAREVA L, 2004, P INT C IM VID RETR, P308; Bruno E, 2005, PATTERN ANAL APPL, V7, P402, DOI 10.1007/s10044-005-0242-9; BRUNO E, 2005, P 3 INT WORKSH AD MU; Chan A., 2007, P IEEE C COMP VIS PA; CHANG EY, 2003, P IEEE INT C IM PROC; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; CHEN Y, 2001, P IEEE INT C IM PROC; Cox T., 1995, MULTIDIMENSIONAL SCA; Cristianini N., 2001, P ADV NEUR INF PROC; DUIN PW, 2004, P 16 INT C PATT REC, V2, P765; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163; Gu Jian-Wei, 2004, BMC Physiol, V4, P2, DOI 10.1186/1472-6793-4-2; Hastie TJ, 2001, ELEMENTS STAT LEARNI; HEESCH D, 2004, P 26 EUR C INF RETR; HSU WH, 2004, P INT C MULT EXP ICM; Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; MOENNELOCCOZ N, 2005, P IEEE INT C IM PROC; Naphade M., 2005, LIGHT SCALE CONCEPT; Nguyen G. P., 2006, P 8 ACM INT WORKSH M, P107, DOI DOI 10.1145/1178677.1178695.ISBN; ONG CS, 2003, P ADV NEUR INF PROC, V15; OVER P, 2005, P TREC VID RETR EV T; OZA N, 2005, LNCS, V3541; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; PEKALSKA E, 2005, P EOS C IND IM MACH, P50; Resnik P, 1995, INT JOINT CONF ARTIF, P448; Smith J. R., 2003, P IEEE INT C IM PROC; TIEU K, 2001, P INT C COMP VIS, P228; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang JTL, 2005, IEEE T SYST MAN CY B, V35, P973, DOI 10.1109/TSMCB.2005.848489; WU Y, 2004, P ACM INT C MULT; Xiong HL, 2005, IEEE T NEURAL NETWOR, V16, P460, DOI 10.1109/TNN.2004.841784; YAN R, 2003, P ACM MULT MM 03; YANG J, 2005, P EL IM C STOR RETR; Zezula P, 1998, VLDB J, V7, P275, DOI 10.1007/s007780050069; Zhou X., 2004, P IEEE C PATT REC CO, V1, P11; ZHOU XS, 2004, P 3 C IM VID RETR CI, P353	41	23	24	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1520	1533		10.1109/TPAMI.2007.70801	http://dx.doi.org/10.1109/TPAMI.2007.70801			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617712	Green Submitted			2022-12-18	WOS:000257504400002
J	Raykar, VC; Duraiswami, R; Krishnapuram, B				Raykar, Vikas C.; Duraiswami, Ramani; Krishnapuram, Balaji			A fast algorithm for learning a ranking function from large-scale data sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ranking; preference relations; fast erfc summation	COMPUTATION	We consider the problem of learning a ranking function that maximizes a generalization of the Wilcoxon-Mann-Whitney statistic on the training data. Relying on an epsilon-accurate approximation for the error function, we reduce the computational complexity of each iteration of a conjugate gradient algorithm for learning ranking functions from O(m(2)) to O(m), where m is the number of training samples. Experiments on public benchmarks for ordinal regression and collaborative filtering indicate that the proposed algorithm is as accurate as the best available methods in terms of ranking accuracy, when the algorithms are trained on the same data. However, since it is several orders of magnitude faster than the current state-of-the-art approaches, it is able to leverage much larger training data sets.	[Raykar, Vikas C.; Krishnapuram, Balaji] Siemens Med Solut Inc, CAD & Knowledge Solut IKM CKS, Malvern, PA 19355 USA; [Duraiswami, Ramani] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Siemens AG; University System of Maryland; University of Maryland College Park	Raykar, VC (corresponding author), Siemens Med Solut Inc, CAD & Knowledge Solut IKM CKS, 51 Valley Stream Pkwy, Malvern, PA 19355 USA.	vikas.rayka@siemens.com; ramani@umiacs.umd.edu; krishnapuram@siemens.com	Duraiswami, Ramani/J-6070-2012	Duraiswami, Ramani/0000-0002-5596-8460				BEAULIEU NC, 1989, IEEE T COMMUN, V37, P989, DOI 10.1109/26.35381; BREFELD U, 2005, P ICLM 2005 WORKSH R; Burges C. J., 2007, ADV NEURAL INFORM PR, V19, P193, DOI DOI 10.1007/S10994-010-5185-8; Caruana R, 1995, ADV NEURAL INFORM PR; Chris Burges T.S., 2005, P 22 INT MACH LEARN, DOI 10.1145/1102351.1102363; Chu WT, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P137; Crammer K, 2002, ADV NEUR IN, V14, P641; DEKEL O, 2004, ADV NEURAL INFORM PR, V16; Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI DOI 10.1162/JMLR.2003.4.6.933; FUNG G, 2006, ADV NEURAL INFORM PR, V18; GRAY A, 2003, P SIAM INT C DAT MIN; GREENGARD L, 1994, SCIENCE, V265, P909, DOI 10.1126/science.265.5174.909; HARRINGTON E, 2003, P 20 INT C MACH LEAR; Herbrich R, 2000, ADV NEUR IN, P115; Herbrich R., 1998, ICML 98 WORKSH TEXT, P80; Herschtal Alan, 2004, P 21 INT C MACH LEAR; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Mas-Colell A., 1995, MICROECONOMIC THEORY; Nocedal J., 2006, NUMERICAL OPTIMIZATI; Rakotomamonjy A., 2004, P 1 WORKSH ROC AN AI, P71; RAYKAR VC, 2007, LARGE SCALE KERNEL M, P175; Tellambura C, 2000, IEEE T COMMUN, V48, P529, DOI 10.1109/26.843116; WEI C, 2005, J MACH LEARN RES, V6, P1019; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Yan Lian, 2003, ICML, P848; YAN R, 2006, P INT C IM VID RETR; Yang C., 2005, ADV NEURAL INFORM PR, V17, P1561	29	23	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1158	1170		10.1109/TPAMI.2007.70776	http://dx.doi.org/10.1109/TPAMI.2007.70776			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550900				2022-12-18	WOS:000256294100004
J	Mohanty, P; Sarkar, S; Kasturi, R				Mohanty, Pranab; Sarkar, Sudeep; Kasturi, Rangachar			From scores to face templates: A model-based approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face template reconstruction; probability of break-in; multidimensional scaling; security and privacy issues in biometric systems; hill climbing attack		Regeneration of templates from match scores has security and privacy implications related to any biometric authentication system. We propose a novel paradigm to reconstruct face templates from match scores using a linear approach. It proceeds by first modeling the behavior of the given face recognition algorithm by an affine transformation. The goal of the modeling is to approximate the distances computed by a face recognition algorithm between two faces by distances between points, representing these faces, in an affine space. Given this space, templates from an independent image set ( break- in) are matched only once with the enrolled template of the targeted subject and match scores are recorded. These scores are then used to embed the targeted subject in the approximating affine ( nonorthogonal) space. Given the coordinates of the targeted subject in the affine space, the original template of the targeted subject is reconstructed using the inverse of the affine transformation. We demonstrate our ideas using three fundamentally different face recognition algorithms: Principal Component Analysis ( PCA) with Mahalanobis cosine distance measure, Bayesian intra-extrapersonal classifier ( BIC), and a feature- based commercial algorithm. To demonstrate the independence of the break- in set with the gallery set, we select face templates from two different databases: the Face Recognition Grand Challenge ( FRGC) database and the Facial Recognition Technology ( FERET) database. With an operational point set at 1 percent False Acceptance Rate ( FAR) and 99 percent True Acceptance Rate ( TAR) for 1,196 enrollments ( FERET gallery), we show that at most 600 attempts ( score computations) are required to achieve a 73 percent chance of breaking in as a randomly chosen target subject for the commercial face recognition system. With a similar operational setup, we achieve a 72 percent and 100 percent chance of breaking in for the Bayesian and PCA- based face recognition systems, respectively. With three different levels of score quantization, we achieve 69 percent, 68 percent, and 49 percent probability of break-in, indicating the robustness of our proposed scheme to score quantization. We also show that the proposed reconstruction scheme has 47 percent more probability of breaking in as a randomly chosen target subject for the commercial system as compared to a hill climbing approach with the same number of attempts. Given that the proposed template reconstruction method uses distinct face templates to reconstruct faces, this work exposes a more severe form of vulnerability than a hill climbing kind of attack where incrementally different versions of the same face are used. Also, the ability of the proposed approach to reconstruct the actual face templates of the users increases privacy concerns in biometric systems.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	State University System of Florida; University of South Florida	Mohanty, P (corresponding author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave,ENM 118, Tampa, FL 33620 USA.	pkmohant@cse.usf.edu; Sarkar@cse.usf.edu; chair@cse.usf.edu	Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Adler A, 2005, LECT NOTES COMPUT SC, V3546, P1100; ADLER A, 2004, P CAN C EL COMP ENG, P469; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7; *BIOAPI, 2005, BIOAPI 2 0 INT VERS; BOLME D, 2003, THESIS COLORADO STAT; Borg I., 2005, MODERN MULTIDIMENSIO, DOI 10.18637/jss.v014.b04; Boult T, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P560; Bucklew J., 2013, SPR PRO COM, DOI [10.1007/978-1-4757-4078-3, 10.1007/978-1-4757-4036-3]; Comon Pierre, 1994, SIGNAL PROCESSING, V36; Cox T.F., 1994, MULTIDIMENSIONAL SCA; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; Hachez G, 2000, INT FED INFO PROC, V52, P273; Li S.Z., 2005, BENCAO GANGMU; Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662, DOI 10.1109/TPAMI.2004.1273986; LOPRESTI DP, 2005, P INT C AUD VID BAS, P1090; Matsumoto T, 2002, P SOC PHOTO-OPT INS, V4677, P275, DOI 10.1117/12.462719; Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921; MOHANTY P, 2005, P IEEE WORKSH FAC RE; NANAVATI S, 2005, BIOMETRICS IDENTIFY; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209; RATHA N, 2001, P INT C AUD VID BAS; Ratha N., 2001, IBM SYSTEMS J, V40; Roth V, 2003, IEEE T PATTERN ANAL, V25, P1540, DOI 10.1109/TPAMI.2003.1251147; ROWEIS S, 2000, SCI MAGAZINE, V290; Schimke S, 2005, PROC SPIE, V5681, P474, DOI 10.1117/12.585485; Soutar C, 1998, P SOC PHOTO-OPT INS, V3314, P178, DOI 10.1117/12.304705; SOUTAR C, 2002, SECURE, V5, P46; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Uludag U, 2004, PROC SPIE, V5306, P622, DOI 10.1117/12.530907; Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372; WISKOTT L, 1997, IEEE T PATTERN ANAL, V19, P1160	36	23	24	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2065	2078		10.1109/TPAMI.2007.1129	http://dx.doi.org/10.1109/TPAMI.2007.1129			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934218				2022-12-18	WOS:000250087900001
J	Zheng, YF; Li, HP; Doermann, D				Zheng, YF; Li, HP; Doermann, D			A parallel-line detection algorithm based on HMM decoding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line detection; form processing; form registration; form identification; hidden Markov model; document image analysis	FORM DOCUMENTS; RECOGNITION; SYSTEM; VECTORIZATION; EXTRACTION; MODELS	The detection of groups of parallel lines is important in applications such as form processing and text ( handwriting) extraction from rule lined paper. These tasks can be very challenging in degraded documents where the lines are severely broken. In this paper, we propose a novel model-based method which incorporates high-level context to detect these lines. After preprocessing ( such as skew correction and text filtering), we use trained Hidden Markov Models (HMM) to locate the optimal positions of all lines simultaneously on the horizontal or vertical projection profiles, based on the Viterbi decoding. The algorithm is trainable so it can be easily adapted to different application scenarios. The experiments conducted on known form processing and rule line detection show our method is robust, and achieves better results than other widely used line detection methods.	Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Zheng, YF (corresponding author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	zhengyf@cfar.umd.edu; huiping@cfar.umd.edu; doermann@cfar.umd.edu	Zheng, Yefeng/ABG-7053-2020	Zheng, Yefeng/0000-0003-2195-2847				Arias JF, 1997, PROC INT CONF DOC, P788, DOI 10.1109/ICDAR.1997.620618; ARIAS JF, 1995, PATTERN RECOGN LETT, V16, P355, DOI 10.1016/0167-8655(94)00111-F; Cesarini F, 1998, IEEE T PATTERN ANAL, V20, P730, DOI 10.1109/34.689303; Chen JL, 1998, PATTERN RECOGN, V31, P1353, DOI 10.1016/S0031-3203(97)00156-8; CHHABRA AK, 1995, P IAPR INT WORKSH GR, P35; DANDECY VP, 1994, INT C PATT RECOG, P301, DOI 10.1109/ICPR.1994.576283; Dimmick D. L., 1991, NIST STRUCTURED FORM; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; Dori D., 1993, Machine Vision and Applications, V6, P69, DOI 10.1007/BF01211932; DORI D, 1997, P IAPR INT WORKSH GR, P286; Fan KC, 1998, PATTERN RECOGN, V31, P1205, DOI 10.1016/S0031-3203(97)00162-3; Grimmett G. R., 2001, PROBABILITY RANDOM P; Hori O., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P218, DOI 10.1109/ICDAR.1995.598980; Hori O., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P353, DOI 10.1109/ICDAR.1993.395716; Hough P., 1959, P INT C HIGH EN ACC, V5; Hull I.I., 1998, DOCUMENT ANAL SYSTEM, P40; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; JIMENEZ J, 1982, IBM J RES DEV, V26, P724, DOI 10.1147/rd.266.0724; Jurafsky Daniel, 2000, SPEECH LANGUAGE PROC; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; Kanungo T, 1999, IEEE T PATTERN ANAL, V21, P179, DOI 10.1109/34.748827; KONG B, 1995, P IAPR INT WORKSH GR, P270; Lam S. W., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P506, DOI 10.1109/ICDAR.1993.395685; LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L; Levinson S. E., 1986, Computer Speech and Language, V1, P29, DOI 10.1016/S0885-2308(86)80009-2; LIU J, 1995, P 3 INT C DOC AN REC, P579; Liu JH, 2000, PATTERN RECOGN, V33, P503, DOI 10.1016/S0031-3203(99)00066-7; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Prerau D, 1992, STRUCTURED DOCUMENT, P405; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROACH JW, 1988, PATTERN RECOGN, V21, P33, DOI 10.1016/0031-3203(88)90069-6; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Tamura H., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P715; TANG YY, 1995, IEEE T SYST MAN CYB, V25, P738, DOI 10.1109/21.376488; Ting A, 1999, PATTERN RECOGN, V32, P645, DOI 10.1016/S0031-3203(98)00106-X; Tseng LY, 1998, PATTERN RECOGN, V31, P1525, DOI 10.1016/S0031-3203(98)00007-7; WENYIN L, 1997, MACH VISION APPL, V9, P57; Yu B, 1996, IEEE T PATTERN ANAL, V18, P1127, DOI 10.1109/34.544084; ZHANG Y, 2003, LAMPTR109 U MAR; ZHENG Y, 2001, P 6 INT C DOC AN REC, P699	42	23	32	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					777	792		10.1109/TPAMI.2005.89	http://dx.doi.org/10.1109/TPAMI.2005.89			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875798	Green Submitted			2022-12-18	WOS:000227569300010
J	Carmichael, O; Hebert, M				Carmichael, O; Hebert, M			Shape-based recognition of wiry objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; edge and feature detection; classifier design and evaluation; shape	ALIGNMENT	We present an approach to the recognition of complex-shaped objects in cluttered environments based on edge information. We first use example images of a target object in typical environments to train a classifier cascade that determines whether edge pixels in an image belong to an instance of the desired object or the clutter. Presented with a novel image, we use the cascade to discard clutter edge pixels and group the object edge pixels into overall detections of the object. The features used for the edge pixel classification are localized, sparse edge density operations. Experiments validate the effectiveness of the technique for recognition of a set of complex objects in a variety of cluttered indoor scenes under arbitrary out-of-image-plane rotation. Furthermore, our experiments suggest that the technique is robust to variations between training and testing environments and is efficient at runtime.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Univ Pittsburgh, Sch Med, Dept Radiol, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Carmichael, O (corresponding author), Carnegie Mellon Univ, Inst Robot, 500 Forbes Ave, Pittsburgh, PA 15213 USA.	otc@andrew.cmu.edu; herbert@ri.cmu.edu		Carmichael, Owen/0000-0002-0576-0047				ALMUALLIM H, 1991, P NATL C ART INT AAA; AMIT Y, 1997, JOINT INDUCTION SHAP; [Anonymous], 1985, PERCEPTUAL ORG VISUA; Awais M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.60; Basri R, 2001, IEEE T PATTERN ANAL, V23, P519, DOI 10.1109/34.922709; Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BENARIE J, 1996, P IAPR IEEE INT C PA, V1, P672; Boykov Y., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P517, DOI 10.1109/CVPR.1999.784730; Bradford J., 1998, P 10 EUR C MACH LEAR, P131; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; BUJA A, 2001, P INT C KNOWL DISC D; CARMICHAEL O, 2003, P IEEE C COMP VIS PA; Carmichael O., 2002, P BRIT MACH VIS C; CARMICHAEL O, 2004, WORD WIRY OBJECT REC; DEVERDIERE VC, 1998, P EUR C COMP VIS, P640; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Egan J., 1975, SERIES COGNITION PER; FAYYAD UM, 1989, P IJCAI, P800; Fergus R, 2003, PROC CVPR IEEE, P264; Freeman WT, 1996, INT J COMPUT VISION, V20, P243, DOI 10.1007/BF00208721; Grimson W. E. L., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P334, DOI 10.1109/ICCV.1990.139544; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Kenji K, 1992, P 9 INT WORKSH MACH, P249, DOI DOI 10.1016/B978-1-55860-247-2.50037-1; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; KOHAVI R, 1996, TOOLS ARTIFICIAL INT; KONONEKO I, 1995, INDUCTION DECISION T; Krumm J, 1997, PROC CVPR IEEE, P179, DOI 10.1109/CVPR.1997.609317; LAMBDAN Y, 1988, P IEEE C COMP VIS, P238; LI SZ, 1998, P EUR C COMP VIS; LI SZ, 2002, P EUR C COMP VIS; LIENHART R, 2003, IEEE INT C MULT SYST; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MITCHELL T, 1997, MACHIEN LEARING; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Olshen R., 1984, CLASSIFICATION REGRE; POPE A, 1994, P IEEE C COMP VIS PA; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Schneiderman Henry, 2002, INT J COMPUTER VISIO; Selinger A, 1999, COMPUT VIS IMAGE UND, V76, P83, DOI 10.1006/cviu.1999.0788; THAYANANTHAN A, 2003, P IEEE C COMP VIS PA; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; VIOLA P, 2001, 200101 CRL COMP CAMB; WU J, 2003, ADV NEURAL INFORMATI; Zadrozny B., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P204, DOI 10.1145/502512.502540	48	23	23	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1537	1552		10.1109/TPAMI.2004.128	http://dx.doi.org/10.1109/TPAMI.2004.128			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573816	Green Submitted			2022-12-18	WOS:000224388700001
J	Soundararajan, P; Sarkar, S				Soundararajan, P; Sarkar, S			An in-depth study of graph partitioning measures for perceptual organization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual organization; grouping; graph partitioning; stochastic orders; empirical evaluation	PERFORMANCE; CUTS	In recent years, one of the effective engines for perceptual organization of low-level image features is based on the partitioning of a graph representation that captures Gestalt inspired local structures, such as similarity, proximity, continuity, parallelism, and perpendicularity, over the low-level image features. Mainly motivated by computational efficiency considerations, this graph partitioning process is usually implemented as a recursive bipartitioning process, where, at each step, the graph is broken into two parts based on a partitioning measure. We concentrate on three such measures, namely, the minimum [41], average [28], and normalized [32] cuts. The minimum cut partition seeks to minimize the total link weights cut. The average cut measure is proportional to the total link weight cut, normalized by the sizes of the partitions. The normalized cut measure is normalized by the product of the total connectivity (valencies) of the nodes in each partition. We provide theoretical and empirical insight into the nature of the three partitioning measures in terms of the underlying image statistics. In particular, we consider for what kinds of image statistics would optimizing a measure, irrespective of the particular algorithm used, result in correct partitioning. Are the quality of the groups significantly different for each cut measure? Are there classes of images for which grouping by partitioning does not work well? Another question of interest is if the recursive bipartitioning strategy can separate out groups corresponding to K objects from each other. In the analysis, we draw from probability theory and the rich body of work on stochastic ordering of random variables. Our major conclusion is that optimization of none of the three measures is guaranteed to, result in the correct partitioning of K objects, in the strict stochastic order sense, for all image statistics. Qualitatively speaking, under very restrictive conditions, when the average interobject feature affinity is very weak when compared to the average intraobject feature affinity, the minimum cut measure is optimal. The average cut measure is optimal for graphs whose partition width is less than the mode of distribution of all possible partition widths. The normalized cut measure is optimal for a more restrictive subclass of graphs whose partition width is less than the mode of the partition width distributions and the strength of interobject links is six times less than the intraobject links. Rigorous empirical evaluation on 50 real images indicates that, in practice, the quality of the groups generated using minimum or average or normalized cuts are statistically equivalent for object recognition, i.e., the best, the mean, and the variation of the qualities are statistically equivalent. We also find that, for certain image classes, such as aerial and scenes with man-made objects, in man-made surroundings, the performance of grouping by partitioning is the worst, irrespective of the cut measure.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	State University System of Florida; University of South Florida	Soundararajan, P (corresponding author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.	psoundar@csec.tisf.edu; sarkar@csec.tisf.edu	Sarkar, Sudeep/ABD-7629-2021; Sarkar, Sudeep/A-8213-2009	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; Berengolts A, 2001, INT J COMPUT VISION, V41, P195, DOI 10.1023/A:1011108121495; Boppana R, 1987, P 28 IEEE S FDN COMP, P280; Borra S, 1997, IEEE T PATTERN ANAL, V19, P1306, DOI 10.1109/34.632991; BUI T, 1984, P 25 IEEE S FDN COMP, P181; Casadei S, 1998, INT J COMPUT VISION, V27, P71, DOI 10.1023/A:1007905813513; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P557, DOI 10.1109/ICPR.1996.546886; Galambos J., 1987, ASYMPTOTIC THEORY EX, V2; GDAYLAHU Y, 2000, P IEEE CS C COMP VIS, V1, P367; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P920, DOI 10.1109/34.93810; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; Huttenlocher D. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P406, DOI 10.1109/CVPR.1991.139724; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; MATULA DW, 1977, CLASSIFICATION CLUST, P95; Narendra K. S., 1989, LEARNING AUTOMATA IN; PERONA P, 1998, P EUR C COMP VIS, P655; RAMAN SV, 1993, CVGIP-IMAG UNDERSTAN, V57, P81, DOI 10.1006/ciun.1993.1005; SAAB Y, 1992, IEEE T CIRCUITS-I, V39, P760, DOI 10.1109/81.250179; SANOCKI T, 2000, STUDENT FRIENDLY STA; SARAN H, 1995, SIAM J COMPUT, V24, P101, DOI 10.1137/S0097539792251730; SARKAR S, 1994, IEEE T SYST MAN CYB, V24, P246, DOI 10.1109/21.281424; Sarkar S, 2000, COMPUT VIS IMAGE UND, V79, P185, DOI 10.1006/cviu.2000.0854; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; Scott G.L., 1990, BMVC, P1; SHAASHUA J, 1988, P INT C COMP VIS, P321; Shaked M., 1994, STOCHASTIC ORDERS TH; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; Soundararajan P, 2001, PROC CVPR IEEE, P239; Stoer M., 1994, Algorithms - ESA '94. Second Annual European Symposium Proceedings, P141, DOI 10.1007/BFb0049404; TU CC, 1999, COMPUTERS OPERATIONS, V25, P519; WAGNER D, 1991, 3071991 TU BERL; Wang S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P517, DOI 10.1109/ICCV.2001.937560; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; WILLIAMS LR, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P408, DOI 10.1109/ICCV.1995.466910; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	42	23	27	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					642	660		10.1109/TPAMI.2003.1201817	http://dx.doi.org/10.1109/TPAMI.2003.1201817			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP		Green Submitted			2022-12-18	WOS:000182961300002
J	Gevers, T				Gevers, T			Adaptive image segmentation by combining photometric invariant region and edge information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; adaptive splitting; integrating region and edge information; photometric color invariance; noise robustness	COLOR	An adaptive image segmentation scheme is proposed employing the Delaunay triangulation for image splitting, The tessellation grid of the Delaunay triangulation is adapted to the semantics of the image data by combining region and edge information. To achieve robustness against imaging conditions (e.g., shading, shadows, illumination, and highlights), photometric invariant similarity measures, and edge computation is proposed. Experimental results on synthetic and real images show that the segmentation method is robust to edge orientation, partially weak object boundaries, and noisy, but homogeneous regions. Furthermore, the method is robust to a large degree to varying imaging conditions.	Univ Amsterdam, Dept Comp Sci, Fac Sci, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	Gevers, T (corresponding author), Univ Amsterdam, Dept Comp Sci, Fac Sci, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	gevers@science.uva.nl						Bajcsy R, 1996, INT J COMPUT VISION, V17, P241, DOI 10.1007/BF00128233; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730; Davoine F, 1996, IEEE T IMAGE PROCESS, V5, P338, DOI 10.1109/83.480769; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2001, PROC CVPR IEEE, P18; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; ROMENY BMT, 1991, P C INFORMATION PROC, P239; Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; TUCERYAN M, 1990, IEEE T PATTERN ANAL, V12, P211, DOI 10.1109/34.44407; WOLFF L, 1992, PHYSICS BASED VISION; WU A, 1993, IEEE T PATTERN ANAL, V15; ZHANG YJ, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P209, DOI 10.1109/ICPR.1992.201963	20	23	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					848	852		10.1109/TPAMI.2002.1008391	http://dx.doi.org/10.1109/TPAMI.2002.1008391			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU		Green Submitted			2022-12-18	WOS:000175846300013
J	Dell'Acqua, F; Fisher, R				Dell'Acqua, F; Fisher, R			Reconstruction of planar surfaces behind occlusions in range images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; occlusion; range data analysis; range image partition; range data reconstruction	SEGMENTATION; MODELS	Analysis and reconstruction of range images usually focuses on complex objects completely contained in the field of view; little attention has been devoted so far to the reconstruction of simply shaped wide areas like parts of a wall hidden behind furniture pieces in an indoor range image. The work presented in this paper is aimed at such reconstruction. First of all, the range image is partitioned based on depth discontinuities and fold edges. Next, the planes best fitting each of the regions constituting the partition of the image are determined, A third step locates potentially contiguous surfaces, while a final step reconstructs the hidden regions. This paper presents results for reconstruction of the shape of planar surfaces behind arbitrary occluding surfaces. The system proved to be effective and the reconstructed surfaces appear to be reasonable. Some examples of results are presented from the Bornholm church range images.	Univ Pavia, Lab Comunicaz Elettr, Dipartimento Elettr, I-27100 Pavia, Italy; Univ Edinburgh, Div Informat, Edinburgh EH1 2QL, Midlothian, Scotland	University of Pavia; University of Edinburgh	Dell'Acqua, F (corresponding author), Univ Pavia, Lab Comunicaz Elettr, Dipartimento Elettr, Via Ferrata 1, I-27100 Pavia, Italy.		Dell'Acqua, Fabio/L-5498-2013	Dell'Acqua, Fabio/0000-0002-0044-2998				BESL P, 1988, MACH VISION APPL, P127; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BHANU B, 1986, P 8 INT C PATT REC P, P732; BRESENHAM JE, 1982, COMPUT J, V25, P116, DOI 10.1093/comjnl/25.1.116; Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667; FISHER RB, 1989, SURFACES OBJECTS; FISHER RB, 1993, P CIAP93, P509; Ham YK, 1999, PATTERN RECOGN, V32, P729, DOI 10.1016/S0031-3203(98)00085-5; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; Hoffman RL, 1986, THESIS MICHIGAN STAT; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; HURT SL, 1984, PATTERN RECOGN, V17, P407, DOI 10.1016/0031-3203(84)90069-4; Jiang XY, 2000, IMAGE VISION COMPUT, V18, P817, DOI 10.1016/S0262-8856(99)00049-9; MULGAONKAR PG, 1992, IEEE T PATTERN ANAL, V14, P303, DOI 10.1109/34.121798; SANCHIZ JM, IN PRESS ROBOTICA; STULP F, 2001, P 3 INT C 3 D DIG IM; TRUCCO E, 1995, IEEE T PATTERN ANAL, V17, P177, DOI 10.1109/34.368172; WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131	18	23	24	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					569	575		10.1109/34.993564	http://dx.doi.org/10.1109/34.993564			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100013
J	El-Yacoubi, MA; Gilloux, M; Bertille, JM				El-Yacoubi, MA; Gilloux, M; Bertille, JM			A statistical approach for phrase location and recognition within a text line: An application to street name recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						phrase detection and recognition; handwriting recognition; statistical modeling; hidden Markov models	HIDDEN; SEGMENTATION	In this paper, we describe a new approach to conjointly locate and recognize a street name within a street line. The system developed is based on a probabilistic framework that naturally integrates various knowledge sources to emit a final decision. At the handwriting signal level, hidden Markov models are extensively used to provide the needed matching scores. Several optimization techniques are employed to speed up the processing time. Experiments carried out on large data sets of street line images, automatically extracted from real French mail envelope images, show very promising results.	LLC, Niwot, CO 80503 USA; SRTP, La Poste, F-44263 Nantes, France		El-Yacoubi, MA (corresponding author), LLC, 7105 La Vista Pl, Niwot, CO 80503 USA.	yacoubi@parascript.com; michel-gilloux@laposte.fr; jean-michel.bertille@laposte.fr	Yacoubi, Mounîm A. M.A. EL/C-1348-2017	Yacoubi, Mounîm A. M.A. EL/0000-0002-7383-0588				BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; Bercu S., 1993, P 3 INT WORKSH FRONT, P385; BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P; Cai JH, 1999, IEEE T PATTERN ANAL, V21, P263, DOI 10.1109/34.754622; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Chen F. R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P133, DOI 10.1109/ICDAR.1993.395765; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; Cho WY, 1995, PATTERN RECOGN, V28, P1941, DOI 10.1016/0031-3203(95)00041-0; El Yacoubi A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1024, DOI 10.1109/ICDAR.1995.602077; El-Yacoubi A, 1999, INT SER COMPUTAT INT, P191; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; ELYACOUBI A, 1997, P BRAZ S DOC IM AN, P60; ELYACOUBI A, 1996, THESIS U RENNES 1 FR; GADER P, 1995, MACH VISION APPL, V8, P31, DOI 10.1007/BF01213636; GILLOUX M, 1995, MACH VISION APPL, V8, P197, DOI 10.1007/BF01219587; Guillevic D, 1997, PROC INT CONF DOC, P544, DOI 10.1109/ICDAR.1997.620559; Hu JY, 1996, IEEE T PATTERN ANAL, V18, P1039, DOI 10.1109/34.541414; JELINEK F, 1998, STAT METHODS SPEECH, pCH7; Kim GG, 1998, PATTERN RECOGN, V31, P41, DOI 10.1016/S0031-3203(97)00023-X; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; Madhvanath S, 1999, IEEE T PATTERN ANAL, V21, P1344, DOI 10.1109/34.817412; Makhoul J, 1998, PATTERN RECOGN, V31, P1285, DOI 10.1016/S0031-3203(97)00152-0; Ney H, 1999, IEEE SIGNAL PROC MAG, V16, P64, DOI 10.1109/79.790984; ORIOT JC, 1991, P 1 INT C DOC AN REC, V2, P665; Parker T, 1998, COMPUTER, V31, P12; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SENI G, 1994, PATTERN RECOGN, V27, P41, DOI 10.1016/0031-3203(94)90016-7; SRIHARI SN, 1992, P 5 US POST SERV ADV, P321; Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Vlontzos JA, 1992, IEEE T IMAGE PROCESS, V1, P539, DOI 10.1109/83.199925	32	23	25	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					172	188		10.1109/34.982898	http://dx.doi.org/10.1109/34.982898			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC					2022-12-18	WOS:000173535700003
J	Horaud, R; Csurka, G; Demirdijian, D				Horaud, R; Csurka, G; Demirdijian, D			Stereo calibration from rigid motions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; projective reconstruction; metric reconstruction; rigid motion; stereo vision; epipolar geometry	RECONSTRUCTION	In this paper, we describe a method for calibrating a stereo pair of cameras using general or planar motions. The method consists of upgrading a 3D projective representation to affine and to Euclidean without any knowledge, neither about the motion parameters nor about the 3D layout. We investigate the algebraic properties relating projective representation to the plane at Infinity and to the intrinsic camera parameters when the camera pair is considered as a moving rigid body. We show that all the computations can be carried out using standard linear resolutions techniques. An error analysis reveals the relative importance of the various steps of the calibration process: projective-to-affine and affine-t-metric upgrades. Extensive experiments performed with calibrated and natural data confirm the error analysis as well as the sensitivity study performed with simulated data.	INRIA Rhone Alpes, F-38330 Montbonnot St Martin, France; CNRS, GRAVIR 655, F-38330 Montbonnot St Martin, France	Centre National de la Recherche Scientifique (CNRS)	Horaud, R (corresponding author), INRIA Rhone Alpes, Ave Europe, F-38330 Montbonnot St Martin, France.	Radu.Horaud@inrialpes.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				BEARDSLEY PA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P58, DOI 10.1109/ICCV.1995.466806; Csurka G, 1999, COMPUT VIS IMAGE UND, V75, P260, DOI 10.1006/cviu.1999.0782; DEMIRDJIAN D, 1998, P MACH VIS C SEPT, P751; Devernay F, 1996, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.1996.517084; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Horn RA., 1994, MATRIX ANAL; Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055; LUONG QT, 1992, THESIS U PARIS SUD O; Moons T, 1996, IEEE T PATTERN ANAL, V18, P77, DOI 10.1109/34.476015; Ruf A, 1998, PROC CVPR IEEE, P475, DOI 10.1109/CVPR.1998.698648; Ruf A, 1999, INT J ROBOT RES, V18, P1101, DOI 10.1177/02783649922067744; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Zisserman A., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P93, DOI 10.1109/WVRS.1995.476857	14	23	26	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1446	1452		10.1109/34.895977	http://dx.doi.org/10.1109/34.895977			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR		Green Submitted			2022-12-18	WOS:000165901900007
J	Ho, PK; Chung, R				Ho, PK; Chung, R			Stereo-motion with stereo and motion in complement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo-motion; 3D reconstruction; affine cameras	FACTORIZATION METHOD; IMAGE STREAMS; SHAPE	This paper presents a new approach of combining stereo vision and dynamic vision with the objective of retaining their advantages and removing their disadvantages. It is shown that, by assuming affine cameras, the stereo correspondences and motion correspondences, if organized in a particular way in a matrix, can be decomposed into the 3D structure or the scene, the camera parameters, the motion parameters, and the stereo geometry. With this, the approach can infer stereo correspondences from motion correspondences, requiring only a time linear with respect to the size of the available image data. The approach offers the advantages of simpler correspondence, as in dynamic vision, and accurate reconstruction, as in stereo vision, even with short image sequences.	Chinese Univ Hong Kong, Dept Mech & Automat Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Ho, PK (corresponding author), Chinese Univ Hong Kong, Dept Mech & Automat Engn, Shatin, Hong Kong, Peoples R China.		Chung, Chi-Kit Ronald/C-7702-2011					Balasubramanyam P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P115, DOI 10.1109/CVPR.1991.139671; CHUNG R, 1995, IEE P-VIS IMAGE SIGN, V142, P289, DOI 10.1049/ip-vis:19952196; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Dhond U.R., 1989, IEEE T SYSTEMS MAN C, V19; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; HO A, 1996, PATTERN RECOGNIT JAN; Jones GA, 1997, COMPUT VIS IMAGE UND, V65, P57, DOI 10.1006/cviu.1996.0482; MAYBANK S, 1993, THEORY RECONSTRUCTIO; Mitiche A., 1988, MOTION UNDERSTANDING, P81; Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; POELMAN CJ, 1994, P 3 EUR C COMP VIS S, P97; SHI J, 1994, P IEEE C COMP VIS PA, P593, DOI DOI 10.1109/CVPR.1994.323794; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853; ZHANG Z, 1988, P IEEE INT C COMP VI; ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394	17	23	24	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					215	220		10.1109/34.825760	http://dx.doi.org/10.1109/34.825760			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400009
J	Zerroug, M; Nevatia, R				Zerroug, M; Nevatia, R			Part-based 3D descriptions of complex objects from a single image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D shape descriptions; part-based representations; object segmentation	GENERALIZED CYLINDERS; CURVED OBJECTS; RANGE IMAGES; 3-D OBJECTS; RECOVERY; RECOGNITION; SHAPE	Volumetric, 3D, part-based descriptions of complex objects in a scene can be highly beneficial for many tasks such as generic object recognition, navigation, and manipulation. However, it has been difficult to derive such descriptions from image data. There has been some progress in getting such descriptions from range data or from perfect contours, but analysis of a real intensity image presents many difficulties. The object and part boundaries do not completely correspond to image boundaries. The detected boundaries are often fragmented and many boundaries due to surface markings, shadows, and noise are present. In addition, inference of 3D from a 2D image is difficult. This paper describes a method to compute the desired descriptions from a single image by exploiting projective properties of a class of generalized cylinders and of possible joints between them. Experimental results on some examples are given.	Adept Technol Inc, City of Industry, CA 91748 USA; Univ So Calif, Dept Comp Sci, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	University of Southern California	Zerroug, M (corresponding author), Adept Technol Inc, 17800 Castelton St,Suite 175, City of Industry, CA 91748 USA.							BERGEVIN R, 1993, IEEE T PATTERN ANAL, V15, P19, DOI 10.1109/34.184772; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BINFORD TO, 1971, IEEE C SYSTEMS CONTR; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; Dickinson C, 1997, J COUNTRY MUSIC, V19, P3; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; Gross AD, 1996, IEEE T PATTERN ANAL, V18, P161, DOI 10.1109/34.481541; HUMMEL JE, 1992, PSYCHOL REV; Lejeune A, 1996, COMPUT VIS IMAGE UND, V64, P230, DOI 10.1006/cviu.1996.0056; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; MARR D, 1977, P ROYAL PHYSICAL SOC, P269; MOHAN R, 1992, IEEE T PATTERN ANAL; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; Nguyen QL, 1996, COMPUT VIS IMAGE UND, V63, P158, DOI 10.1006/cviu.1996.0011; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; RAO K, 1993, CVGIP-IMAG UNDERSTAN, V57, P1, DOI 10.1006/ciun.1993.1001; Roberts L.G., 1965, OPTICAL ELECTROOPTIC; SATO H, 1993, CVGIP-IMAG UNDERSTAN, V57, P346, DOI 10.1006/ciun.1993.1023; ULUPINAR F, 1995, IEEE T PATTERN ANAL, V17, P120, DOI 10.1109/34.368175; ULUPINAR F, 1994, ARTIF INTELL, V67, P1, DOI 10.1016/0004-3702(94)90010-8; ULUPINAR F, 1993, IEEE T PATTERN ANAL, P3; Zerroug M, 1996, IEEE T PATTERN ANAL, V18, P237, DOI 10.1109/34.485553; Zerroug M, 1996, INT J COMPUT VISION, V20, P11, DOI 10.1007/BF00144115	24	23	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					835	848		10.1109/34.790426	http://dx.doi.org/10.1109/34.790426			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600002
J	Astrom, K; Kahl, F				Astrom, K; Kahl, F			Motion estimation in image sequences using the deformation of apparent contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion; surface geometry; silhouette; epipolar constraint	SURFACE; CURVE	The problem of determining the camera motion from apparent contours or silhouettes of a priori unknown curved three-dimensional surfaces is considered. In a sequence of images, it is shown how to use the generalized epipolar constraint an apparent contours. One such constraint is obtained for each epipolar tangency point in each image pair. An accurate algorithm for computing the motion is presented based on a maximum likelihood estimate. It is shown how to generate initial estimates on the camera motion using only the tracked contours. It is also shown that in theory the motion can be calculated from the deformation of a single contour. The algorithm has been tested on several real image sequences, for both Euclidean and protective reconstruction. The resulting motion estimate is compared to motion estimates calculated independently using standard feature-based methods. The motion estimate is also used to classify the silhouettes as curves or apparent contours. This is a strong indication that the motion estimate is of good quality. The statistical evaluation shows that the technique gives accurate and stable results.	Lund Univ, Ctr Math Sci, S-22100 Lund, Sweden	Lund University	Astrom, K (corresponding author), Lund Univ, Ctr Math Sci, Box 118, S-22100 Lund, Sweden.	kalle@maths.lth.se; fredrik@maths.lth.se	Åström, Kalle/C-2836-2009; Astrom, Kalle/AAT-9538-2020	Åström, Kalle/0000-0002-8689-7810; Astrom, Kalle/0000-0002-8689-7810				ASTROM K, 1997, GAUSSIAN SCALE SPACE; ASTROM K, 1996, P INT C PATT REC VIE, P339; ASTROM K, 1996, P 4 EUR C COMP VIS C, V2, P97; ATKINSON KB, 1996, CLOSE RANGE PHOTOGRA; Berthilsson R, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P581; BERTHILSSON R, 1997, P C COMP VIS PATT RE; Blake A., 1992, ACTIVE VISION; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; CARLSSON S, 1994, P 3 EUR C COMP VIS S, V1, P83; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; CIPOLLA R, 1995, LNCS, V1016; Cram?r H., 1946, MATH METHODS STAT; Curwen R, 1992, ACTIVE VISION, P39; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136; GIBLIN PJ, 1994, J OPT SOC AM A, V11, P1976, DOI 10.1364/JOSAA.11.001976; JOSHI T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P290, DOI 10.1109/ICCV.1995.466927; Kahl F, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P939, DOI 10.1109/ICCV.1998.710829; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SPARR G, 1996, P INT C PATT REC VIE, VA, P328; SPARR G, 1991, P 7 SCAND C IM AN, P274; SZELISKI R, 1994, REAL TIME VISION; ULUPINAR F, 1993, IEEE T PATTERN ANAL, V15, P3, DOI 10.1109/34.184771; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; Vijayakumar B, 1996, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.1996.517093; VIJAYAKUMAR B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P508, DOI 10.1109/ICCV.1995.466897; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	33	23	24	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					114	127		10.1109/34.748821	http://dx.doi.org/10.1109/34.748821			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL					2022-12-18	WOS:000078639900002
J	Folsom, TC; Pinter, RB				Folsom, TC; Pinter, RB			Primitive features by steering, quadrature, and scale	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge finders; orientation; steerable filters; quadrature filters; Gabor functions; visual cortex; silicon retina	STRIATE CORTEX; RECEPTIVE-FIELDS; FUNCTIONAL ARCHITECTURE; SPATIAL-FREQUENCY; VISUAL-CORTEX; SIMPLE CELLS; TRANSFORMS; RESPONSES; FILTERS	The impulse response of neurons in the visual cortex of the mammalian brain has been known for some time. How to make use of these as filters has led to many hypotheses. The response of a single filter is ambiguous because the result depends on stimulus type, contrast, position, orientation, and scale. We show that a set of quadrature filters at sparse positions can be constructed so that it is possible to disambiguate the 2D responses of the individual filters. Detecting edges is not the goal of the present work; rather, we seek to detect relevant edges. Thus, we make the assumption that at the scale of interest, a local image patch consists predominantly of an edge or a bar. When this patch is processed by five or seven oriented filters, one can compute the exact orientation and centroid position of the feature. When the set of filters is applied at two different scales, it is possible to distinguish edges from ridges and to identify the polarity, intensity, and width. It is also possible to find corners and blobs. These computations are stable under image shifts in position and orientation and can be made to subpixel resolution.	QUEST Integrated Inc, Kent, WA 98032 USA; Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Folsom, TC (corresponding author), QUEST Integrated Inc, 21414 68th Ave S, Kent, WA 98032 USA.			Folsom, Tyler/0000-0003-3981-6886				DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DAUGMAN JG, 1990, UNPUB FORTRAN CODE G; DEVALOIS KK, 1979, J PHYSIOL-LONDON, V291, P483, DOI 10.1113/jphysiol.1979.sp012827; DOBBINS A, 1992, THESIS MCGILL U CANA; FOLSOM TC, 1994, IEEE INT C SYST MAN; FOLSOM TC, 1994, THESIS U WASHINGTON; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Ghez C., 1985, VOLUNTARY MOVEMENT, P493; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; KULIKOWSKI JJ, 1982, BIOL CYBERN, V43, P187, DOI 10.1007/BF00319978; Landy M.S., 1991, COMPUTATIONAL MODELS; Levine M. W., 1991, FUNDAMENTALS SENSATI; MACKAY DM, 1981, NATURE, V289, P117, DOI 10.1038/289117a0; MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; Marr D., 1982, VISION; Mead, 1989, ANALOG VLSI NEURAL S; MOVSHON JA, 1978, J PHYSIOL-LONDON, V283, P53, DOI 10.1113/jphysiol.1978.sp012488; Nabet B, 1991, SENSORY NEURAL NETWO; NABET B, 1989, ADV NEURAL INFORMATI, P695; NABET B, 1991, Patent No. 5130563; PENTLAND AP, 1991, SPIE, V1570, P43; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SEITZ P, 1991, SPIE P, V1606, P252; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Wilson H. R., 1990, VISUAL PERCEPTION NE, P231, DOI DOI 10.1016/B978-0-12-657675-7.50016-8; YOUNG RA, 1986, GEN MOTORS RES PUBLI; [No title captured]	31	23	26	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1161	1173		10.1109/34.730552	http://dx.doi.org/10.1109/34.730552			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100004
J	Amengual, JC; Vidal, E				Amengual, JC; Vidal, E			Efficient error-correcting viterbi parsing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						error-correcting parsing; sequence alignment; Viterbi algorithm; beam search; depth-first topological sort; bucketsort; priority queues; language processing; shape recognition	LINEAR BLOCK-CODES	The problem of Error-Correcting Parsing (ECP) using an insertion-deletion-substitution error model and a Finite State Machine is examined. The Viterbi algorithm can be straightforwardly extended to perform ECP though the resulting computational complexity can become prohibitive for many applications. We propose three approaches in order to achieve an efficient implementation of Viterbilike ECP which are compatible with Beam Search acceleration techniques. Language processing and shape recognition experiments which assess the performance of the proposed algorithms are presented.	Univ Jaume 1, Unidad Predepartamental Informat, Castellon de La Plana 12071, Spain; Univ Politecn Valencia, Dept Sistemas Informat & Computac, E-46071 Valencia, Spain; Univ Politecn Valencia, Inst Tecnol Informat, E-46071 Valencia, Spain	Universitat Jaume I; Universitat Politecnica de Valencia; Universitat Politecnica de Valencia	Amengual, JC (corresponding author), Univ Jaume 1, Unidad Predepartamental Informat, Campus Penyeta Roja, Castellon de La Plana 12071, Spain.	jcamen@inf.uji.es; evidal@iti.upv.es						AHO AV, 1990, ALGORITHMS COMPLEXIT, VA, P255; Aho AV, 1974, DESIGN ANAL COMPUTER; Amengual JC, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P841, DOI 10.1109/ICSLP.1996.607732; AMENGUAL JC, 1996, LNCS, V1121, P30; AMENGUAL JC, 1996, DSIC23296 U POL VAL; AMENGUAL JC, 1995, 6 SPAN S PATT REC IM, P218; BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; BOULOUTAS A, 1991, IEEE T INFORM THEORY, V37, P430, DOI 10.1109/18.75270; FELDMAN J, 1990, TR90009 INT COMP SCI; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; FU KS, 1982, SYNTACTIC PATTERN RE; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; HAN YSS, 1993, IEEE T INFORM THEORY, V39, P1514, DOI 10.1109/18.259636; HART GW, 1993, IEEE T INFORM THEORY, V39, P1249, DOI 10.1109/18.243442; HUNT MJ, 1988, P ICASSP88, P457; Kruskal J.B., 1983, TIME WARPS STRING ED; Lowerre Bruce T, 1976, HARPY SPEECH RECOGNI; McEliece RJ, 1996, IEEE T INFORM THEORY, V42, P1072, DOI 10.1109/18.508834; RULOT H, 1992, THESIS U VALENCIA; TORRO F, 1990, SIGNAL PROCESSING, V5; Vidal E., 1995, SPEECH RECOGNITION C, P174; WIBERG N, 1995, EUR T TELECOMMUN, V6, P513, DOI 10.1002/ett.4460060507; [No title captured]	24	23	23	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1109	1116		10.1109/34.722628	http://dx.doi.org/10.1109/34.722628			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400009
J	Angelopoulou, E; Wolff, LB				Angelopoulou, E; Wolff, LB			Sign of gaussian curvature from curve orientation in photometric space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian curvature; differential geometry; photometric invariant; photometric data; shape recovery; curve orientation	SURFACE CURVATURE; RANGE IMAGES; SEGMENTATION; INVARIANT; MODEL	We compute the sign of Gaussian curvature using a purely geometric definition. Consider a point: p on a smooth surface Sand a closed curve gamma on S which encloses p. The image of gamma on the unit normal Gaussian sphere is a new curve beta. The Gaussian curvature at p is defined as the ratio of the area enclosed by gamma over the area enclosed by pas gamma contracts to p. The sign of Gaussian curvature at p is determined by the relative orientations of the closed curves gamma and beta. We directly compute the relative orientation of two such curves from intensity data. We employ three unknown illumination conditions to create a photometric scatter plot. This plot is in one-to-one correspondence with the subset of the unit Gaussian sphere containing the mutually illuminated surface normals. This permits direct computation of the sign of Gaussian curvature without the recovery of surface normals. Our method is albedo invariant. We assume diffuse reflectance, but the nature of the diffuse reflectance can be general and unknown. Error analysis on simulated images shows the accuracy of our technique. We also demonstrate the performance of this methodology on empirical data.	Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA; Johns Hopkins Univ, Comp Vis Lab, Baltimore, MD 21218 USA	University of Pennsylvania; Johns Hopkins University	Angelopoulou, E (corresponding author), Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA.							BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; BLAKE A, 1990, P EUR C COMP VIS, P465; DANE C, 1981, P PATT REC IM PROC C, P54; Fan J, 1997, COMPUT VIS IMAGE UND, V65, P347, DOI 10.1006/cviu.1996.0581; Fan T. J., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P86; Flynn P. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P110, DOI 10.1109/CVPR.1989.37837; HILTON A, 1994, P INT C PATTERN RECO, V1, P37; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; HORNE AM, 1977, BEHAV THER, V8, P1, DOI 10.1016/S0005-7894(77)80114-7; Ikeuchi K, 1981, P 7 IJCAI, P595; Lee C.-K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P536, DOI 10.1109/CVPR.1993.341078; Millman R.S., 1977, ELEMENTS DIFFERENTIA; Nene A. S., 1996, CUCS00696; Nene S. A., 1996, COLUMBIA OBJECT IMAG; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; SANDER PT, 1986, P 8 INT C PATT REC P, P1165; SPIEGEL MR, 1991, SCHAUMS OUTLINE THEO, P108; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; WOLFF LB, 1994, J OPT SOC AM A, V11, P2956, DOI 10.1364/JOSAA.11.002956; WOLFF LB, 1994, J OPT SOC AM A, V11, P3090, DOI 10.1364/JOSAA.11.003090; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; WOODHAM RJ, 1978, AITR457 MIT ART INT; WOODHAM RJ, 1989, IEEE T ROBOTIC AUTOM, V1, P36	26	23	25	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1056	1066		10.1109/34.722615	http://dx.doi.org/10.1109/34.722615			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400003
J	Sawaki, M; Hagita, N				Sawaki, M; Hagita, N			Text-line extraction and character recognition of document headlines with graphical designs using complementary similarity measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; OCR; character segmentation; projection feature; displacement matching; adaptive thresholding	SYSTEM	A method for recognizing characters on graphical designs is proposed. A new projection feature that separates text-line regions from backgrounds, and adaptive thresholding in displacement matching are introduced. Experimental results for newspaper headlines with graphical designs show a recognition rate of 97.7 percent.	NTT, Basic Res Labs, Kanagawa 2430198, Japan; NTT, Commun Sci Labs, Kyoto 6190237, Japan	Nippon Telegraph & Telephone Corporation; Nippon Telegraph & Telephone Corporation	Sawaki, M (corresponding author), NTT, Basic Res Labs, 3-1 Morinosato Wakamiya, Kanagawa 2430198, Japan.							AKIYAMA T, 1990, PATTERN RECOGN, V23, P1141, DOI 10.1016/0031-3203(90)90112-X; Casey R. G., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1023; Fenrich R., 1991, P 2 INT WORKSH FRONT, P33; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Kovalevsky V A, 1980, IMAGE PATTERN RECOGN; LIANG S, 1994, CVGIP-GRAPH MODEL IM, V56, P402; OKAMOTO M, 1991, PRU90151 IEICE, P47; Ozawa H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P58, DOI 10.1109/ICDAR.1993.395782; SAKOU H, 1990, IEICE T D, V73, P562; Sawaki M, 1996, IEICE T INF SYST, VE79D, P491; Sawaki M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P73, DOI 10.1109/ICPR.1996.546797; TSUJIMOTO S, 1992, P IEEE, V80, P1133, DOI 10.1109/5.156475	12	23	24	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1103	1109		10.1109/34.722625	http://dx.doi.org/10.1109/34.722625			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB		Green Submitted			2022-12-18	WOS:000076416400008
J	Yokomori, T; Kobayashi, S				Yokomori, T; Kobayashi, S			Learning local languages and their application to DNA sequence analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						local languages; deterministic automata; hemoglobin alpha-chain; DNA sequence analysis; machine learning	INDUCTIVE INFERENCE; SPLICING SYSTEMS	This paper concerns an efficient algorithm for learning in the limit a special type of regular languages called strictly locally testable languages from positive data, and its application to identifying the protein alpha-chain region in amino acid sequences. First, we present a linear time algorithm that, given a strictly locally testable language, learns (identifies) its deterministic finite state automaton in the limit from only positive data. This provides us with a practical and efficient method for learning a specific concept domain of sequence analysis. We then describe several experimental results using the learning algorithm developed above. Following a theoretical observation which strongly suggests that a certain type of amino acid sequences can be expressed by a locally testable language, we apply the learning algorithm to identifying the protein alpha-chain region in amino acid sequences for hemoglobin. Experimental scores show an overall success rate of 95 percent correct identification for positive data, and 96 percent for negative data.	Waseda Univ, Sch Educ, Dept Math, Shinjuku Ku, Tokyo 1698050, Japan; Tokyo Denki Univ, Fac Sci & Engn, Dept Informat Sci, Hatoyama, Saitama 3500394, Japan	Waseda University; Tokyo Denki University	Yokomori, T (corresponding author), Waseda Univ, Sch Educ, Dept Math, Shinjuku Ku, 1-6-1 Nishiwaseda, Tokyo 1698050, Japan.	yokomori@mn.waseda.ac.jp; satoshi@j.dendai.ac.jp						ABE N, 1994, P GEN INF WORKSH 5, P12; ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5; ANGLUIN D, 1983, ACM COMPUT SURV, V15, P237; ARIKAWA S, 1993, NEW GENERAT COMPUT, V11, P361, DOI 10.1007/BF03037183; Asai K., 1993, Proceeding of the Twenty-Sixth Hawaii International Conference on System Sciences (Cat. No.93TH0501-7), P783, DOI 10.1109/HICSS.1993.270612; Brzozowski J. A., 1973, Discrete Mathematics, V4, P243, DOI 10.1016/S0012-365X(73)80005-6; CULIK K, 1989, P ICALP 89, P222; Dayhoff M., 1978, ATLAS PROTEIN SEQ ST, V5; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; Garcia P., 1990, Algorithmic Learning Theory, P325; GATTERDAM RW, 1989, INT J COMPUT MATH, V31, P63, DOI 10.1080/00207168908803788; GATTERDAM RW, 1992, SIAM J COMPUT, V21, P507, DOI 10.1137/0221033; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; GRIBSKOV M, 1987, P NATL ACAD SCI USA, V84, P4355, DOI 10.1073/pnas.84.13.4355; Harrison M. A., 1978, INTRO FORMAL LANGUAG; HEAD T, 1987, B MATH BIOL, V49, P737, DOI 10.1016/S0092-8240(87)90018-8; HEAD T, 1992, LINDENMAYER SYSTEMS, P371, DOI DOI 10.1007/978-3-642-58117-5_23; HELGESEN C, 1993, P 1 INT C INT SYST M, P172; IBARRA O, 1988, P WORKSH COMP LEARN, P337; John Hopcroft, 1971, THEORY MACHINES COMP, P189, DOI DOI 10.1016/B978-0-12-417750-5.50022-1; Kobayashi S, 1994, P 5 GEN INF WORKSH, VV, P29; McNaughton R., 1971, COUNTER FREE AUTOMAT; MIYANO S, 1992, P 3 GEN INF WORKSH, P69; *PROT RES FDN, PROT DAT; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; Searls D. B., 1993, ARTIF INTELL, P47; Shinohara T., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory, P97; SHINOHARA T, 1983, P RIMS S SOFTW SCI E, P115; SIROMONEY R, 1992, LECT NOTES COMPUT SC, V654, P260; STORMO GD, 1989, P NATL ACAD SCI USA, V86, P1183, DOI 10.1073/pnas.86.4.1183; TAKADA Y, 1992, P AII 92, P305; TANIDA N, 1992, IEICE T INF SYST, VE75D, P125; WATSON JD, 1983, RECOMBINANT DNA SHOR; Yokomori T, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P219, DOI 10.1109/ICEC.1997.592299; YOKOMORI T, 1995, MACHINE LEARNING, V19; YOKOMORI T, 1995, P 1 INT S INT NEUR B, P38	39	23	23	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1067	1079		10.1109/34.722617	http://dx.doi.org/10.1109/34.722617			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400004
J	Pynadath, DV; Wellman, MP				Pynadath, DV; Wellman, MP			Generalized queries on probabilistic context-free grammars	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						probabilistic context-free grammars; Bayesian networks		Probabilistic context-free grammars (PCFGs) provide a simple way to represent a particular class of distributions over sentences in a context-free language. Efficient parsing algorithms for answering particular queries about a PCFG (i.e., calculating the probability of a given sentence, or finding the most likely parse) have been developed and applied to a variety of pattern-recognition problems. We extend the class of queries that can be answered in several ways: (1) allowing missing tokens in a sentence or sentence fragment, (2) supporting queries about intermediate structure, such as the presence of particular nonterminals, and (3) flexible conditioning on a variety of types of evidence. Our method works by constructing a Bayesian network to represent the distribution of parse trees induced by a given PCFG. The network structure mirrors that of the chart in a standard parser, and is generated using a similar dynamic-programming approach. We present an algorithm for constructing Bayesian networks from PCFGs, and show how queries or patterns of queries on the network correspond to interesting queries on PCFGs. The network formalism also supports extensions to encode various context sensitivities within the probabilistic dependency structure.	Univ Michigan, Artificial Intelligence Lab, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Pynadath, DV (corresponding author), Univ Michigan, Artificial Intelligence Lab, 1101 Beal Ave, Ann Arbor, MI 48109 USA.		Wellman, Michael/AAQ-7063-2020	Wellman, Michael/0000-0002-1691-6844				Black Ezra, 1992, P 5 DARPA SPEECH NAT, P31; Briscoe T., 1993, Computational Linguistics, V19, P25; CHARNIAK E, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P728; CHARNIAK E, 1994, ARTIF INTELL, V66, P345, DOI 10.1016/0004-3702(94)90030-2; Charniak Eugene, 1993, STAT LANGUAGE LEARNI; CHOU P, 1989, P SPIE VISUAL COMMUN, V4, P852; Darwiche A, 1997, J ARTIF INTELL RES, V6, P147, DOI 10.1613/jair.330; DECHTER R, 1996, P 12 C UNC ART INT S, P280; Dechter R., 1996, P 12 C UNC ART INT U, P211; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; Jensen F.V., 1996, INTRO BAYESIAN NETWO; Koller D., 1997, NAT C ART INT INN AP, P740; MAGERMAN DM, 1991, P 2 INT WORKSH PARS, P193; Neapolitan R.E., 1990, PROBABILISTIC REASON; Ney H., 1992, Speech Recognition and Understanding. Recent Advances, Trends and Applications. Proceedings of the NATO Advanced Study Institute, P319; Pearl J., 1987, PROBABILISTIC REASON; PYNADATH DV, 1995, P 11 C UNC ART INT, P472; Sakakibara Y., 1995, P 27 HAW INT C SYST, P284; VILAIN M, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P190; WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829	22	23	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1998	20	1					65	77		10.1109/34.655650	http://dx.doi.org/10.1109/34.655650			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YV876					2022-12-18	WOS:000071872400006
J	Kanatani, K				Kanatani, K			Symmetry as a continuous feature - Comment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symmetry detection; shape classification; pattern recognition; geometric AIC; statistical analysis		We point out the existence of a theoretical difficulty that underlies the symmetry detection studied by Zabrodsky et al. [4] and present a possible solution to it.			Kanatani, K (corresponding author), GUNMA UNIV,DEPT COMP SCI,KIRYU,GUMMA 371,JAPAN.							AKAIKE H, 1974, IEEE T AUTOMAT CONTR, V19, P176, DOI DOI 10.1109/TAC.1974.1100705; KANATANI K, 1996, P 4 EUR C COMP VIS C, V1, P697; Kanatani K., 1996, STAT OPTIMIZATION GE; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	4	23	25	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					246	247		10.1109/34.584101	http://dx.doi.org/10.1109/34.584101			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200005
J	Weber, J; Malik, J				Weber, J; Malik, J			Rigid body segmentation and shape description from dense optical flow under weak perspective	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; epipolar constraint; fundamental matrix; shape from motion; motion segmentation; scene partitioning problem	3-DIMENSIONAL MOTION; OBJECTS; IMAGES	We present an algorithm for identifying and tracking independently moving rigid objects from optical flow. Some pervious attempts at segmentation via optical flow have focused on finding discontinuities in the flow field. While discontinuities do indicate a change in scene depth, they do not in general signal a boundary between two separate objects. The proposed method uses the fact that each independently moving object has a unique epipolar constraint associated with its motion. Thus motion discontinuities based on self-occlusion can be distinguished from those due to separate objects. The use of epipolar geometry allows for the determination of individual motion parameters for each object as well as the recovery of relative depth for each point on the object. The algorithm assumes an affine camera where perspective effects are limited to changes in overall scale. No camera calibration parameters are required. A Kalman filter based approach is used for tracking motion parameters with time.	UNIV CALIF BERKELEY,DIV COMP SCI,BERKELEY,CA 94720	University of California System; University of California Berkeley	Weber, J (corresponding author), CALTECH,DEPT ENGN,PASADENA,CA 91125, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BLACK MJ, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1060; CERNUSCHIFRIAS B, 1989, IEEE T PATTERN ANAL, V11, P1028, DOI 10.1109/34.42835; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HOROWITZ SL, 1974, 2ND P INT JOINT C PA, P424; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LECLERC YG, 1989, INT J COMPUT VISION, V3, P72; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luong Q.-T., 1993, RR1894 INRIA; LUONG QT, ISR C ART INT COMP V; SHAPIRO LS, 1994, P EUROPEAN C COMPUTE, V2, P73; SOATTO S, 1994, P EUR C COMP VIS STO, V2, P61; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WEBER J, 1995, INT J COMPUTER VISIO, V14; WEBER J, 1995, IS T SPIE S EL IM SC; WEBER J, 1995, P 5 ICCV BOST, P12; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; [No title captured]	22	23	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					139	143		10.1109/34.574794	http://dx.doi.org/10.1109/34.574794			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800006
J	Neri, F; Saitta, L				Neri, F; Saitta, L			Exploring the power of genetic search in learning symbolic classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						genetic algorithms; distributed genetic algorithms; classification rules; machine learning; disjunctive concept learning; universal suffrage selection; mushroom dataset; splice junctions dataset; empirical comparison	ALGORITHMS; SELECTION; FEATURES	In this paper we show, in a constructive way, that there are problems for which the use of genetic algorithm based learning systems can be at least as effective as traditional symbolic or connectionist approaches. To this aim, the system REGAL* is briefly described, and its application to two classical benchmarks for Machine Learning is discussed, by comparing the results with the best ones published in the literature.			Neri, F (corresponding author), UNIV TURIN, DIPARTIMENTO INFORMAT, CORSO SVIZZERA 185, I-10149 TURIN, ITALY.		Neri, Filippo/E-1182-2011; Neri, Filippo/ABG-9710-2020	Neri, Filippo/0000-0002-2529-2287; Neri, Filippo/0000-0002-2529-2287				ANKENBRANDT CA, 1990, PATTERN RECOGN LETT, V11, P285, DOI 10.1016/0167-8655(90)90067-C; Bala J., 1991, Proceedings of the First International Workshop on Multistrategy Learning (MSL-91), P316; BONELLI P, 1990, P 7 INT C MACH LEARN, P153; BOSWELL R, 1990, MANUAL NEW2D VERSION; BOTTA M, 1993, P 2 IEEE INT C FUZZ, P18; BOTTA M, 1993, P 13 INT JOINT C ART, P937; BREZELLEC P, 1993, P 10 MACH LEARN C AM, P9; BRILL FZ, 1992, IEEE T NEURAL NETWOR, V3, P324, DOI 10.1109/72.125874; Clark P., 1991, Machine Learning - EWSL-91. European Working Session on Learning Proceedings, P151, DOI 10.1007/BFb0017011; COHOON JP, 1987, P 2 INT C GEN ALG CA, P153; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; De Jong K. A., 1975, THESIS U MICHIGAN DE; DEB K, 1989, 3RD P INT C GEN ALG, P42; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1007/BF00993042; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; Giordana A., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93), P234; Giordana A., 1994, P 11 INT C MACH LEAR, P96; GIORDANA A, 1992, P 9 INT WORKSH MACH, P169; GIORDANA A, 1994, P WORKSHOP KNOWLEDGE, P56; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D. E., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, P41; Goldberg D.E., 2013, GENETIC ALGORITHMS; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1007/BF00993044; Hekanaho J., 1995, P 12 INT C MACH LEAR, P278; Holland J. H., 1986, MACHINE LEARNING ART, V2, P593; HOLLAND JH, THESIS U MICHIGAN AN; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37; Janikow C. Z., 1993, MACH LEARN, V13, P198, DOI DOI 10.1023/A:1022669929488; Koppel M., 1994, P 1 INT C MACH LEARN, P139; LEWIN B, 1994, GENE, V5; Mahfoud S.W., 1995, THESIS U ILLINOIS UR; McCallum R. A., 1990, P 7 INT C MACH LEARN, P149; Michalski R, 1983, MACH LEARN, P183; MICHALSKI RS, 1986, 5TH P NAT C ART INT, P1041; NERI F, 1995, P 6 INT C GEN ALG, P32; NERI F, 1995, P 6 INT C GEN ALG, P436; NOORDEWIER M, 1991, NIPS, V3; NORTON SW, 1993, P 10 INT C MACH LEAR, P220; Olshen R., 1984, CLASSIFICATION REGRE; OPITZ DW, P 11 INT C MACH LEAR, P208; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; RACHLIN J, 1994, P 11 INT C MACH LEAR, P242; Rosenblatt F., 1961, PRINCIPLES NEURODYNA, DOI 10.21236/AD0256582; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHLIMMER JS, 1987, 8719 TR U CAL DEP IN; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Smith, 1983, P 8 INT JOINT C ART, V83, P422; SPEARS WM, 1994, P 3 ANN C EV PROGR, P296; Sutton R. S., 1988, Machine Learning, V3, P9, DOI 10.1023/A:1022633531479; SYSWERDA G, 1989, 3RD P INT C GEN ALG, P2; Towell G. G., 1991, Proceedings of the First International Workshop on Multistrategy Learning (MSL-91), P257; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Vafaie H., 1991, Proceedings of the First International Workshop on Multistrategy Learning (MSL-91), P305; Venturini G., 1993, P EUR C MACH LEARN, P280; Weiss SM, 1994, MACHINE LEARNING P 1, P335; Wilson S. W., 1987, Machine Learning, V2, P199, DOI 10.1023/A:1022655214215; YEUNG DY, 1991, P 8 INT C MACH LEARN, P228	61	23	23	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1135	1141		10.1109/34.544085	http://dx.doi.org/10.1109/34.544085			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900011
J	SASTRY, R; RANGANATHAN, N; REMEDIOS, K				SASTRY, R; RANGANATHAN, N; REMEDIOS, K			CASM - A VLSI CHIP FOR APPROXIMATE STRING-MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDIT DISTANCE COMPUTATION; STRING-TO-STRING CORRECTION PROBLEM; VERY LARGE SCALE INTEGRATION (VLSI) IMPLEMENTATION; SYSTOLIC ALGORITHM; SPECIAL PURPOSE ARCHITECTURE; HARDWARE ALGORITHM	NUCLEIC-ACID	The edit distance between two strings a(1),...,a(m) and b(1),...,b(n) is the minimum cost s of a sequence of editing operations (insertions, deletions and substitutions) that convert one string into the other. This paper describes the design and implementation of a linear systolic array chip for computing the edit distance between two strings over a given alphabet. An encoding scheme is proposed which reduces the number of bits required to represent a state in the computation. The architecture is a parallel realization of the standard dynamic programming algorithm proposed by Wagner and Fischer, and can perform approximate string matching for variable edit costs. More importantly, the architecture does not place any constraint on the lengths of the strings that can be compared. It makes use of simple basic cells and requires regular nearest-neighbor communication, which makes it suitable for VLSI implementation. A prototype of this array has been built at the University of South Florida.	UNIV S FLORIDA,CTR MICROELECTR RES,DEPT COMP SCI & ENGN,TAMPA,FL 33620	State University System of Florida; University of South Florida	SASTRY, R (corresponding author), HAL COMP SYST INC,1315 DELL AVE,CAMPBELL,CA 95008, USA.							Abe K., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P172; BAEZAYATES R, 1992, COMMUN ACM, V35, P74, DOI 10.1145/135239.135243; Bunke H., 1990, SYNTACTIC STRUCTURAL; CHENG HD, 1987, PATTERN RECOGN, V20, P125, DOI 10.1016/0031-3203(87)90023-9; HOANG DT, 1993, P IEEE WORKSHOP FPGA; HUGHEY R, 1988, P INT C SYST ARR, P41; LIPRESTI D, 1991, ADV RES VLSI, P138; Lipton R. J., 1985, 1985 Chapel Hill Conference on Very Large Scale Integration, P363; Lipton R. J., 1986, Proceedings of the 1986 International Conference on Parallel Processing (Cat. No.86CH2355-6), P917; LIU HC, 1989, SPIE P INTELLIGENT R, V1002, P92; LOPRESTI DP, 1987, COMPUTER, V20, P98, DOI 10.1109/MC.1987.1663629; MAES M, 1991, PATTERN RECOGN, V24, P433, DOI 10.1016/0031-3203(91)90056-B; REMEDIOS K, 1993, THESIS U S FLORIDA; Sastry R., 1993, Proceedings 1993 IEEE International Conference on Computer Design: VLSI in Computers and Processors (Cat. No.93CH3335-7), P402, DOI 10.1109/ICCD.1993.393344; UKKONEN E, 1985, INFORM CONTROL, V64, P100, DOI 10.1016/S0019-9958(85)80046-2; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WILBUR WJ, 1983, P NATL ACAD SCI-BIOL, V80, P726, DOI 10.1073/pnas.80.3.726; WU S, 1992, COMMUN ACM, V35, P83, DOI 10.1145/135239.135244	18	23	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					824	830		10.1109/34.400575	http://dx.doi.org/10.1109/34.400575			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035					2022-12-18	WOS:A1995RL03500011
J	CHEN, TW; LIN, WC				CHEN, TW; LIN, WC			A NEURAL-NETWORK APPROACH TO CSG-BASED 3-D OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						OBJECT REPRESENTATION AND RECOGNITION; CONSTRUCTIVE SOLID GEOMETRY (CSG); RANGE IMAGE; PRECEDENCE GRAPH; NEURAL NETWORKS; AND MEAN FIELD ANNEALING	COMPUTER VISION	In this correspondence, we describe the recognition subsystem of a computer vision system based on Constructive Solid Geometry (CSG) representation scheme. Instead of using the conventional CSG trees to represent objects, the proposed system uses an equivalent representation scheme-precedence graphs-for object representation. Each node in the graph represents a primitive volume and each arc between two nodes represents the relation between them. Object recognition is achieved by matching the scene precedence graph to the model precedence graph. A constraint satisfaction network is proposed to implement the matching process. The energy function associated with the network is used to enforce the matching constraints including match validity, primitive similarity, precedence graph preservation, and geometric structure preservation. The energy level is at its minimum only when the optimal match is reached. Experimental results on several range images are presented to demonstrate the proposed approach.	NORTHWESTERN UNIV,DEPT ELECT ENGN & COMP SCI,EVANSTON,IL 60208	Northwestern University	CHEN, TW (corresponding author), IBM CORP,INTERNAL ZIP 1512,BLDG 012,1000 NW 51ST ST,BOCA RATON,FL 33431, USA.		Lin, Wei-Chung/B-7248-2009					BALLARD DH, 1982, COMPUTER VISION, pCH9; Besl P. J., 1988, Machine Vision and Applications, V1, P127, DOI 10.1007/BF01212277; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; Brady J. P., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P85, DOI 10.1109/ICPR.1988.28178; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; FRIEDBERG SH, 1979, LINEAR ALGEBRA, P420; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOLMAN B, 1984, DISCRETE MATH STRUCT, P133; LEE YC, 1987, IEEE COMPUT GRAPH, V7, P20, DOI 10.1109/MCG.1987.277024; LI W, 1989, JUN IEEE INT JOINT C, V2, P287; LIN WC, 1991, IEEE T NEURAL NETWOR, V2, P84, DOI 10.1109/72.80293; LIN WC, 1990, MAY P VIS INT 90 HAL, P173; LIN WC, 1991, PATTERN RECOGN, P355; LIN WC, 1988, 9TH P INT C PATT REC, P99; LO F, 1988, THESIS NW U; PARVIN B, 1989, JUN P INT C NEUR NET, V2, P281; Requicha A. G., 1980, ACM COMPUT SURV, P437; ROTH SD, 1982, COMPUT VISION GRAPH, V18, P109, DOI 10.1016/0146-664X(82)90169-1; SEIBERT M, 1992, IEEE T PATTERN ANAL, V14, P107, DOI 10.1109/34.121784; Van den Bout D E, 1990, IEEE Trans Neural Netw, V1, P192, DOI 10.1109/72.80231; VANDENBOUT DE, 1989, BIOL CYBERN, V62, P129, DOI 10.1007/BF00203001; [No title captured]	32	23	26	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					719	726		10.1109/34.297953	http://dx.doi.org/10.1109/34.297953			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134					2022-12-18	WOS:A1994NY13400005
J	WEISS, I				WEISS, I			HIGH-ORDER DIFFERENTIATION FILTERS THAT WORK	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						SMOOTHING; DIFFERENTIATION; FILTERS; FITTING; SHAPE DESCRIPTION	DERIVATIVES; EDGES	Reliable derivatives or digital images have always been hard to obtain, especially (but not only) at high orders. We analyze the sources of errors in traditional filters, such as derivatives or the Gaussian, that are used for differentiation. We then study a class of filters which is much more suitable for our purpose, namely filters that preserve polynomials up to a given order. We show that the errors in differentiation can be corrected using these filters. We derive a condition for the validity domain of these filters, involving some characteristics of the filter and of the shape. Our experiments show a very good performance for smooth functions.			WEISS, I (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, COLLEGE PK, MD 20742 USA.							BESL PJ, 1988, 2ND P INT C COMP VIS; DIERCKX P, 1977, J COMPUT APPL MATH, V3, P2; GRIMSON WEL, 1981, MIT663 AI MEM; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HASHIMOTO M, 1987, COMPUT VISION GRAPH, V39, P28, DOI 10.1016/S0734-189X(87)80201-3; HORN BKP, 1983, ACM T MATH SOFTWARE, V9, P441, DOI 10.1145/356056.356061; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Meer P., 1992, Journal of Visual Communication and Image Representation, V3, P58, DOI 10.1016/1047-3203(92)90030-W; Ortega J.M., 1981, INTRO NUMERICAL METH; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1987, P DARPA IMAGE UNDERS; POGGIO T, 1985, J COMPLEXITY, V4, P106; SURIA G, 1993, JUN P IEEE COMP VIS, P61; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1993, INT J COMPUT VISION, V10, P207; TERZOPOULOS D, 1993, IEEE PATTERN ANAL MA, V15, P943; WEISS I, 1991, CSTR2639 U MARYL; WEISS I, 1988, P DARPA IMAGE UNDERS	21	23	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					734	739		10.1109/34.297955	http://dx.doi.org/10.1109/34.297955			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134					2022-12-18	WOS:A1994NY13400007
J	THOMPSON, WB; LECHLEIDER, P; STUCK, ER				THOMPSON, WB; LECHLEIDER, P; STUCK, ER			DETECTING MOVING-OBJECTS USING THE RIGIDITY CONSTRAINT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MOTION; MOVING OBJECT DETECTION; OUTLIER DETECTION; ROBUST ESTIMATION; SEGMENTATION		We describe a method for visually detecting moving objects from a moving camera using point correspondences in two orthographic views. The method applies a simple structure-from-motion analysis and then identifies those points inconsistent with the interpretation of the scene as a single rigid object. It is effective even when the actual motion parameters cannot be recovered. Demonstrations are presented using point correspondences automatically determined from real image sequences.	UNIV MINNESOTA,DEPT COMP SCI,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities	THOMPSON, WB (corresponding author), UNIV UTAH,DEPT COMP SCI,SALT LAKE CITY,UT 84112, USA.							[Anonymous], 1986, EVASION DIVISAS HIST; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Heeger D. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P435, DOI 10.1109/CCV.1988.590020; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; JAIN R, 1977, 5TH P INT JOINT C AR, P425; JAIN RC, 1984, IEEE T PATTERN ANAL, V6, P624, DOI 10.1109/TPAMI.1984.4767575; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Nelson R. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P173, DOI 10.1109/CVPR.1991.139683; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; THOMPSON WB, 1990, INT J COMPUT VISION, V4, P39, DOI 10.1007/BF00137442; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ZHANG Z, 1988, 2ND P INT C COMP VIS, P177; 1990, P INT WORKSHOP ROBUS	14	23	25	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					162	166		10.1109/34.192488	http://dx.doi.org/10.1109/34.192488			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000007
J	HERMAN, GT; YEUNG, KTD				HERMAN, GT; YEUNG, KTD			ON PIECEWISE-LINEAR CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note								If two sets of vectors (in N-dimensional real Euclidean space R(N)) do not have an element in common, then they can always be separated from each other by using a series of N - 1 dimensional hyperplanes in R(N). In piecewise-linear classification, one finds such a series of hyperplanes using a training set containing elements from both classes. Efficient methods to find such a piecewise-linear separation for the training sets have been proposed in the literature. However, since complete separation of the training set fits the "noise" as well as the "signal" in the training set, the desirability of such a complete separation depends on the nature of the data. In this paper, we make use of a real data set (containing 9-D measurements of fine needle aspirates of a patient's breast for the purpose of classifying a tumor's malignancy) for which early stopping in the generation of the separating hyperplanes is not appropriate. We compare a piecewise-linear classification method (both with complete separation on the training set and with separation using only seven hyperplanes) with classification based on a single (but in a statistical sense optimal) linear separator. A precise methodology for comparing the relative efficacy of two classification methods for a particular task (including a way of providing the statistical significance of the results) is described and is applied to the comparison on the breast cancer data of the relative performances of the two versions of the piecewise-linear classifier and the classification based on an optimal linear separator. It is found that for this data set, the piecewise-linear classifier that uses all the hyperplanes needed to separate the training set outperforms the other two methods and that these differences in performance are significant at the 0.001 level. There is no statistically significant difference between the performance of the other two methods. We discuss the relevance of these results for this and other applications.			HERMAN, GT (corresponding author), UNIV PENN, DEPT RADIOL, MED IMAGE PROC GRP, PHILADELPHIA, PA 19104 USA.							BASARATHY BV, 1979, P IEEE, V67, P708; Duda R.O., 1973, J ROYAL STAT SOC SER; FOROUTAN I, 1985, IEEE P COMPUT VISION, P149; FUKUNAGA K, 1972, INTRO STATISTICAL PA; Harth E., 1988, Proceedings of a Special Symposium on Maturing Technologies and Emerging Horizons in Biomedical Engineering (IEEE Cat. No.88CH2670-8), P97, DOI 10.1109/MTEHBE.1988.26407; Herman G. T., 1989, International Journal of Imaging Systems and Technology, V1, P187, DOI 10.1002/ima.1850010208; MANGASARIAN OL, 1990, SIAM PROC S, P22; MOULD R, 1989, INTRO MED STATISTICS; SHAVLIK JW, IN PRESS MACHINE LEA; WEISS S, 1989, 11TH IJCAI 89 INT JO, P781	10	23	27	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1992	14	7					782	786		10.1109/34.142914	http://dx.doi.org/10.1109/34.142914			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JB675					2022-12-18	WOS:A1992JB67500007
J	KAMGARPARSI, B; JONES, JL; ROSENFELD, A				KAMGARPARSI, B; JONES, JL; ROSENFELD, A			REGISTRATION OF MULTIPLE OVERLAPPING RANGE IMAGES - SCENES WITHOUT DISTINCTIVE FEATURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONTOURS; DEPTH DATA; ELEVATION DATA; MATCHING; RANGE DATA; REGISTRATION	SCALE	The recent increase in the use of range images may suggest the revision of some of the techniques developed for intensity images so that they adapt to range images more effectively. An important topic is image registration. A scheme is developed to register range images in an environment where distinctive features are scarce. When each image overlaps with several other images, the registration must also be performed at the global level. This is particularly challenging because of the possibility of bending and compression in some forms of range images (i.e., the relative position of data points on the image reference surface may be inaccurate). The "primitives" used for local registration are contours of constant range, which are extracted from data and are represented by means of a modified chain code method. All "best" matches of pairs of contours are considered tentative until their "geometrical" implications are evaluated and a consistent majority has emerged. To do global registration, a cost function is constructed and minimized. Terms contributing to the cost include violation of local matches as well as compression and bending in range images. In cases where there is no appreciable compression and bending in the images, the proposed global scheme could improve the quality of local registration by enforcing consistency among them. In particular, we have implemented this scheme to map the floor of the ocean, where the range data is obtained by a multibeam echo-sounder system installed aboard a sailing ship producing multiple overlapping range images. The system that we have developed is the first automated system for correctly registered mapping of the ocean floor; it is efficient and robust.	UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								Ballard D.H., 1982, COMPUTER VISION; Besl P. J., 1988, Machine Vision and Applications, V1, P127, DOI 10.1007/BF01212277; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P145; BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; Broit C., 1981, OPTIMAL REGISTRATION; DEMOUSTIER C, 1986, J GEOPHYS RES-SOLID, V91, P3407, DOI 10.1029/JB091iB03p03407; Duda R.O., 1973, J ROYAL STAT SOC SER; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; GHOSH SK, 1972, THEORY STEREOPHOTOGR; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; Henderson T.C., 1982, P WORKSHOP IND APPLI, P181; Horn B., 1986, ROBOT VISION, P1; KAMGARPARSI B, 1990, COMPUT VISION GRAPH, V52, P341, DOI 10.1016/0734-189X(90)90080-F; KAMGARPARSI B, 1988, CARTR377 U MAR CTR A; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; NEVATIA R, 1973, 3RD P INT JOINT C AR, P641; PHILLIPS TY, 1988, PATTERN RECOGN LETT, V7, P291, DOI 10.1016/0167-8655(88)90069-4; POGGIO T, 1985, COMPUT VISION GRAPH, V31, P139, DOI 10.1016/S0734-189X(85)80003-7; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SAMPSON RJ, 1978, SURFACE 2 GRAPHICS S; SHIRAI Y, 1971, 2ND P INT JOINT C AR, P80; SINHA S, 1989, GMR6724 COMP SCI DEP; Thompson M., 1966, MANUAL PHOTOGRAMMETR, V3rd; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162	26	23	27	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					857	871		10.1109/34.93805	http://dx.doi.org/10.1109/34.93805			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180					2022-12-18	WOS:A1991GJ18000001
J	BAIRD, HS; THOMPSON, K				BAIRD, HS; THOMPSON, K			READING CHESS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BAIRD, HS (corresponding author), AT&T BELL LABS,600 MT AVE,MURRAY HILL,NJ 07974, USA.							BAIRD HS, 1987, 40TH P SPSE C S HYBR, P21; BAIRD HS, 1987, NOV P IEEE COMP SOC; BLEDSOE WW, 1959, 1959 P E JOINT COMP; Condon J. H., 1982, CHESS SKILL MAN MACH; HULL JJ, 1982, IEEE T PATTERN ANAL, V4, P520, DOI 10.1109/TPAMI.1982.4767297; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Kida H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P446; Meynieux E., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P442; ROSENBAUM WS, 1975, IBM J RES DEV, V19, P398, DOI 10.1147/rd.194.0398; Schantz H. F., 1982, HIST OCR; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184, DOI 10.1109/TPAMI.1979.4766904; Srihari S. N., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P434; SRIHARI SN, 1983, ACM T OFF INF SYST, V1, P68, DOI 10.1145/357423.357428; ULLMANN JR, 1977, COMPUT J, V20, P141, DOI 10.1093/comjnl/20.2.141; 1980, CHESS INFORMANT, V33; 1980, CHESS INFORMANT, V30; 1982, CHICAGO MANUAL STYLE, P254; 1980, CHESS INFORMANT, V29	18	23	24	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					552	559		10.1109/34.56191	http://dx.doi.org/10.1109/34.56191			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300004
J	SUBBARAO, M				SUBBARAO, M			INTERPRETATION OF IMAGE FLOW - A SPATIO-TEMPORAL APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									THINKING MACHINES CORP,CAMBRIDGE,MA		SUBBARAO, M (corresponding author), SUNY BUFFALO,BUFFALO,NY 14260, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; Aris R., 1962, VECTORS TENSORS BASI; Bandopadhay A., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P23; BANDOPADHYAY A, 1985, TR157 U ROCH DEP COM; CHEN SS, 1985, 3RD P IEEE COMP SOC, P105; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; HAY JC, 1966, PSYCHOL REV, V73, P550, DOI 10.1037/h0023863; HILDRETH E, 1983, THESIS MIT; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KANTANI K, 1985, 9TH P INT JOINT C AR, P886; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1986, J OPT SOC AM A, V3, P242, DOI 10.1364/JOSAA.3.000242; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MCCONNELL AJ, 1957, APPLICATIONS TENSOR; PISKUNOV N, 1974, DIFFERENTIAL INTEGRA, V1, P264; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; SUBBARAO M, 1986, MAY P WORKSH MOT REP, P157; SUBBARAO M, 1986, CARTR199 U MARYL TEC; SUBBARAO M, 1986, THESIS U MARYLAND; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TSAI RY, 1981, R922 U ILL COORD SCI; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WAXMAN AM, 1984, STUD APPL MATH, V70, P63; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1987, INT J COMPUT VISION, V1; WAXMAN AM, 1986, ADV COMPUTER VISION; WOHN K, 1986, 5TH P NAT C ART INT, P671; WOHN K, 1985, CARTR134 U MARYL TEC; WOHN K, 1984, THESIS U MARYLAND; 1985, DEC P DARPA IM UND W, P399; 1986, CARTR214 U MARYL TEC	36	23	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					266	278		10.1109/34.21796	http://dx.doi.org/10.1109/34.21796			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000007
J	BERENSTEIN, CA; LAVINE, D				BERENSTEIN, CA; LAVINE, D			ON THE NUMBER OF DIGITAL STRAIGHT-LINE SEGMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,SYST RES CTR,COLLEGE PK,MD 20742; LNK CORP INC,RIVERDALE,MD 20737	University System of Maryland; University of Maryland College Park	BERENSTEIN, CA (corresponding author), UNIV MARYLAND,DEPT MATH,COLLEGE PK,MD 20742, USA.							BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; BERENSTEIN CA, 1984, JUN NASA MATH PATT R; DICKSON LE, 1952, HIST THEORY NUMBERS, P142; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; Hardy GH., 1968, INTRO THEORY NUMBERS; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KOPLOWITZ J, 1987, IEEE T PATTERN ANAL, V9, P451, DOI 10.1109/TPAMI.1987.4767927; LAVINE D, 1983, JUN P NASA S MATH PA; LAVINE D, 1985, JUN NASA MATH PATT R; MCILROY MD, 1984, AT&T TECH J, V64, P481; OLTRAMARE G, 1856, MEM I NAT GENEVOIS, V4, P1; RAJ APS, 1986, PATTERN RECOGNITION, V4, P99; Santal LA., 1953, INTRO INTEGRAL GEOME, V1198; Weiman C.F.R., 1976, COMPUTER GRAPHICS IM, V5, P106	14	23	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					880	887		10.1109/34.9109	http://dx.doi.org/10.1109/34.9109			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971		Green Submitted			2022-12-18	WOS:A1988Q997100009
J	ISHIKAWA, S; KUWAMOTO, H; OZAWA, S				ISHIKAWA, S; KUWAMOTO, H; OZAWA, S			VISUAL NAVIGATION OF AN AUTONOMOUS VEHICLE USING WHITE LINE RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									KEIO UNIV,FAC SCI & TECHNOL,DEPT ELECT ENGN,KOHOKU KU,YOKOHAMA,KANAGAWA 223,JAPAN	Keio University	ISHIKAWA, S (corresponding author), IBM JAPAN,TOKYO RES LAB,5-19 SANBAN CHO,CHIYODA KU,TOKYO 102,JAPAN.							ANDO S, 1974, 4TH P ISPR, P385; COOKE RA, 1983, 13TH P INT S IND ROB, V2; Crowley J. L., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P207; DRAKE KC, 1985, IEEE T PATTERN ANAL, V7, P485, DOI 10.1109/TPAMI.1985.4767687; HERBERT M, 1986, APR P IEEE INT C ROB, P1426; ISHIKAWA S, 1986, JUN P IEEE C COMP VI, P47; Kant K., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P196; MCVEY ES, 1986, IEEE T PATTERN ANAL, V8, P105, DOI 10.1109/TPAMI.1986.4767757; MOIGNE JL, 1984, 7TH P INT C PATT REC; MORAVEC HP, 1983, P IEEE, V71, P872, DOI 10.1109/PROC.1983.12684; OKAWA Y, 1981, P IFAC, P2419; OSHIMA Y, 1965, P TOKYO IFAC S, P347; Ruff R., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P188; Takinami E., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P1789; TURK M, 1986, OCT P SPIE MOB ROB C; WALLACE RS, P AAAI 86; WAXMAN A, 1986, APR P IEEE INT C ROB, P1600; YATABE T, 1978, P IAM, P29	18	23	32	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					743	749		10.1109/34.6786	http://dx.doi.org/10.1109/34.6786			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500017
J	SCHMITT, LA; WILSON, SS				SCHMITT, LA; WILSON, SS			THE AIS-5000 PARALLEL PROCESSOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SCHMITT, LA (corresponding author), APPL INTELLIGENT SYST INC,RES & DEV,SOFTWARE DEV,ANN ARBOR,MI 48104, USA.							BAKER HP, COMMUNICATION; DANIELSSON PE, 1983, COMPUTING STRUCTURES; FISHER AL, 1985, NOV P IEEE WORKSH CO, P484; Fountain T. J., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P24; FOUNTAIN TJ, 1985, INTEGRATED TECHNOLOG; FOUNTAIN TJ, 1983, COMPUTING STRUCTURES; GERRITSEN FA, 1983, COMPUTING STRUCTURES; Hillis W., 1985, CONNECTION MACHINE; HILLYER BK, 1986, J PARALLEL DISTR COM, V3, P236, DOI 10.1016/0743-7315(86)90006-7; HOLLAND J, MACHINE LEARNING; HWANG K, 1984, COMPUTER ARCHITECTUR, P324; JAMIESON LH, 1986, J PARALLEL DISTR COM, V3, P48, DOI 10.1016/0743-7315(86)90027-4; KITTLER J, 1985, IMAGE PROCESSING SYS; KNUTH DE, 1973, ART COMPUTER PROGRAM, V3, P220; Potter Jerry L., 1985, MASSIVELY PARALLEL P; RICE TA, 1985, INTEGRATED TECHNOLOG; RIMEY R, 1986, OCT SPIE CAMBR S INT; WILSON SS, 1985, NOV P IEEE WORKSH CO, P477	18	23	27	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					320	330		10.1109/34.3897	http://dx.doi.org/10.1109/34.3897			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700004
J	HUMMEL, RA; LANDY, MS				HUMMEL, RA; LANDY, MS			A STATISTICAL VIEWPOINT ON THE THEORY OF EVIDENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NYU,DEPT PSYCHOL,NEW YORK,NY 10003	New York University	HUMMEL, RA (corresponding author), NYU,COURANT INST MATH SCI,DEPT COMP SCI,NEW YORK,NY 10012, USA.			Landy, Michael/0000-0002-2079-4552				ANDERSON JA, 1977, PSYCHOL REV, V84, P413, DOI 10.1037/0033-295X.84.5.413; BARNETT JA, 1981, 7TH P INT JOINT C AR, P868; CHARNIAK E, 1983, P NAT C ARTIFICIAL I, P70; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205; DEMPSTER AP, 1967, BIOMETRIKA, V54, P515, DOI 10.2307/2335042; FALMAGNE JC, 1983, SYNTHESE, V57, P35, DOI 10.1007/BF01064066; FAUGERAS OD, 1982, 6TH P INT C PATT REC, P405; Fishburn PC, 1964, DECISION VALUE THEOR; FRIEDMAN L, 1981, 7TH P INT JOINT C AR, P487; GARVEY TD, 1981, 7TH P INT JOINT C AR, P319; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Good Irving John, 1966, STUDIES LOGIC FDN MA, V44, P319; Gordon J., 1984, RULE BASED EXPERT SY; GORDON J, 1984, METHOD MANAGING EVID; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Koopman B., 1940, B AM MATH SOC, V46, P763; Koopman BO, 1940, ANN MATH, V41, P269, DOI 10.2307/1969003; KRANTZ DH, 1983, J AM STAT ASSOC, V78, P418, DOI 10.2307/2288650; KYBURG HE, 1985, 139 U ROCH DEP COMP; LANDY MS, 1986, OCT P INT C PATT REC, P248; LINDLEY DV, 1982, INT STAT REV, V50, P1, DOI 10.2307/1402448; PRADE H, 1985, IEEE T PATTERN ANAL, V7, P260, DOI 10.1109/TPAMI.1985.4767656; REYNOLDS G, 1985, UNPUB CONVERTING FEA; SHAFER G, 1982, J ROY STAT SOC B MET, V44, P322; SHAFER G, 1981, SYNTHESE, V48, P1, DOI 10.1007/BF01064627; SHAFER G, 1975, F PHILOS STATISTICAL, V2; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; SHAFER G, 1973, THESIS PRINCETON U P; Shafer G., 1986, UNCERTAINTY ARTIFICI, V4, P127; SMITH CAB, 1965, J R STAT SOC SER A-G, V128, P469, DOI 10.2307/2343466; SMITH CAB, J ROY STATIST SOC B, V23, P1; Strat T., 1984, P NAT C ARTIFICIAL I, P308; WILLIAMS PM, 1978, BRIT J PHILOS SCI, V29, P375, DOI 10.1093/bjps/29.4.375	35	23	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					235	247		10.1109/34.3885	http://dx.doi.org/10.1109/34.3885			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974		Green Submitted			2022-12-18	WOS:A1988M297400007
J	MILI, H; RADA, R				MILI, H; RADA, R			MERGING THESAURI - PRINCIPLES AND EVALUATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NATL LIB MED,MED SUBJECT HEADINGS SECT,BETHESDA,MD 20894	National Institutes of Health (NIH) - USA; NIH National Library of Medicine (NLM)	MILI, H (corresponding author), GEORGE WASHINGTON UNIV,DEPT ELECT ENGN & COMP SCI,WASHINGTON,DC 20052, USA.							[Anonymous], 1994, MAR ECOL PROG SER; BRACHMAN RJ, 1983, IEEE COMPUT, V16, P30; BUCHANAN B, 1985, 9TH P INT JOINT C AR, P659; CARBONELL J, 1985, FRAMEKIT PLUS KNOWLE; CARDIN JC, 1979, ANAL MEANING, P206; COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407; Cote RA, 1979, SYSTEMATIZED NOMENCL; DAHLBERG I, 1983, INT CLASSIF, V10, P5; DAVIS R, KNOWLEDGE BASED SYST, P229; DUNHAM GS, 1978, J AM SOC INFORM SCI, V29, P81, DOI 10.1002/asi.4630290207; EDWARDS AL, 1964, STATISTICAL METHODS; EPSTEIN S, ACM T OFFICE INFORM, V3, P107; FIDEL R, 1984, J AM SOC INFORM SCI, V35, P211, DOI 10.1002/asi.4630350404; FIKES R, 1985, COMMUN ACM, V28, P904, DOI 10.1145/4284.4285; FORSYTH R, 1986, MACHINE LEARNING EXP; FOX EA, 1983, THESIS CORNELL U ITH; FRY JP, 1976, ACM COMPUT SURV, V8, P7, DOI DOI 10.1145/356662.356664; HENDLER J, 1986, THESIS BROWN U PROVI; HENDLER J, 1986, TR1624 U MAR DEP COM; HUMPHREY SM, 1986, DATABASES PRIMER RET; KIRTLAND M, 1981, J AM SOC INFORM SCI, V32, P249, DOI 10.1002/asi.4630320403; KORFHAGE RR, 1985, P EXPERT SYST GOVT C, P474; LIU CL, 1977, ELEMENTS DISCRETE MA; MILI H, 1985, OCT P EXP SYST GOVT, P457; MIYAMOTO S, 1986, IEEE T SYST MAN CYBE, V12, P278; Mylopoulos J., 1984, CONCEPTUAL MODELLING, P3; NAKAMURA K, 1982, IEEE T SYST MAN CYBE, V8, P193; QUILLIAN MR, 1968, SEMANTIC INFORMATION; RADA R, 1979, COMPUT BIOMED RES, V12, P131, DOI 10.1016/0010-4809(79)90011-9; RADA R, 1986, P MEDINFO 86 WASHING, P1096; RADA R, 1987, ROLE LANGUAGE PROBLE, V2, P71; RADA R, 1986, OCT P MEDINFO 86, P1164; RADA R, 1985, OCT ANN P ASS COMP M, P360; RADA R, 1985, OCT P EXP SYST GOVT, P532; RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8; Rich Elaine, 1979, COGNITIVE SCI, V3, P329, DOI DOI 10.1207/S15516709COG0304_3; SALTON G, 1983, INTRO MODERN INFORMA; SAMMET JE, 1982, COMMUN ACM, V25, P13, DOI 10.1145/358315.358322; Schank R., 1982, DYNAMIC MEMORY THEOR; SCHANK RC, 1981, INFORMATION RETRIEVA, P94; SEWELL W, 1986, J AM SOC INFORM SCI, V37, P234, DOI 10.1002/asi.4630370411; Shneiderman B., 1987, DESIGNING USER INTER; Siegel S., 1956, NONPARAMETRIC STAT B; SMITH EE, 1974, PSYCHOL REV, V81, P214, DOI 10.1037/h0036351; SOERGEL D, 1974, INT CLASSIF, V1, P34; SOERGEL D, 1974, INDEXING LANGUAGES T; SRIDHARAM NS, 1985, AI MAG           FAL, P108; SVENONIUS E, 1986, J AM SOC INFORM SCI, V37, P331, DOI 10.1002/(SICI)1097-4571(198609)37:5<331::AID-ASI8>3.0.CO;2-E; TONG RM, 1987, 10TH P ANN INT ACM S, P247; VANRIJSBERGEN CJ, 1986, 9TH P ANN ACM SPEC I, P194; WALKER WH, 1985, COGNITIVE SCI, V9, P261, DOI 10.1016/S0364-0213(85)80016-1; [No title captured]; 1980, GUIDELINES THESAURUS; 1979, DHEW NIH791286; 1986, MED SUBJECT HEADINGS; 1985, NLM PB84104829 PUBL	56	23	23	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					204	220		10.1109/34.3883	http://dx.doi.org/10.1109/34.3883			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400005
J	BRINKLEY, JF				BRINKLEY, JF			KNOWLEDGE-DRIVEN ULTRASONIC 3-DIMENSIONAL ORGAN MODELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BRINKLEY, JF (corresponding author), STANFORD UNIV,DEPT COMP SCI,KNOWLEDGE SYST LAB,PALO ALTO,CA 94304, USA.							[Anonymous], 1975, PSYCHOL COMPUTER VIS; BALLARD DH, 1978, COMPUTER VISION SYST, P271; BATNITZKY S, 1981, J COMPUT ASSIST TOMO, V5, P60, DOI 10.1097/00004728-198102000-00012; BINFORD TO, 1971, IEEE C SYST SCI CYBE; BOLLES RC, 1976, THESIS STANFORD U ST; BRINKLEY J F, 1978, Ultrasound in Medicine and Biology, V4, P317, DOI 10.1016/0301-5629(78)90020-0; BRINKLEY JF, 1982, ULTRASONIC IMAGING, V4, P126, DOI 10.1016/0161-7346(82)90096-7; BROOKS RA, 1976, PHYS MED BIOL, V21, P689, DOI 10.1088/0031-9155/21/5/001; BROOKS RA, 1981, THESIS STANFORD U ST; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; EATON LW, 1979, CIRCULATION, V60, P320, DOI 10.1161/01.CIR.60.2.320; GEISER EA, 1980, COMPUT BIOMED RES, V13, P225, DOI 10.1016/0010-4809(80)90018-X; GRITTON CWK, 1983, IEEE T PATTERN ANAL, V5, P8, DOI 10.1109/TPAMI.1983.4767339; Hanson A., 1978, COMPUTER VISION SYST; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; KELLY MD, 1971, MACH INTELL, V6; Knuth D., 1973, ART COMPUTER PROGRAM, V2nd; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PYKETT IL, 1982, RADIOLOGY, V143, P157, DOI 10.1148/radiology.143.1.7038763; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SHANI U, 1981, 82 U ROCH DEP COMP S; SOROKA BI, 1981, COMPUT VISION GRAPH, V15, P154, DOI 10.1016/0146-664X(81)90076-9; UDUPA JK, 1982, IEEE T PATTERN ANAL, V4, P41, DOI 10.1109/TPAMI.1982.4767193; YACHIDA M, 1980, IEEE T PATTERN ANAL, V2, P537, DOI 10.1109/TPAMI.1980.6447700	25	23	27	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					431	441		10.1109/TPAMI.1985.4767682	http://dx.doi.org/10.1109/TPAMI.1985.4767682			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869281				2022-12-18	WOS:A1985ALB6900007
J	LOWE, DG; BINFORD, TO				LOWE, DG; BINFORD, TO			THE RECOVERY OF 3-DIMENSIONAL STRUCTURE FROM IMAGE CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									STANFORD UNIV,STANFORD ARTIFICIAL INTELLIGENCE LAB,STANFORD,CA 94305	Stanford University								[Anonymous], 1975, PSYCHOL COMPUTER VIS; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; DRAPER SW, 1981, ARTIF INTELL, V17, P461, DOI 10.1016/0004-3702(81)90032-1; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Lowe D. G., 1984, THESIS STANFORD U ST; LOWE DG, 1985, UNPUB; LOWE DG, 1983, AUG P AM ASS ART INT, P255; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; ROBERTS LG, 1966, OPTICAL ELECTRO OPTI, P159; SHAFER SA, 1982, CMUCS82100 CARN MELL; SUGIHARA K, 1978, 4TH P INT JOINT C PA, P771; [No title captured]	17	23	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					320	326		10.1109/TPAMI.1985.4767660	http://dx.doi.org/10.1109/TPAMI.1985.4767660			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869266				2022-12-18	WOS:A1985AFM4400006
J	NIEMANN, H; BUNKE, H; HOFMANN, I; SAGERER, G; WOLF, F; FEISTEL, H				NIEMANN, H; BUNKE, H; HOFMANN, I; SAGERER, G; WOLF, F; FEISTEL, H			A KNOWLEDGE BASED SYSTEM FOR ANALYSIS OF GATED BLOOD POOL STUDIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ERLANGEN NURNBERG,INST NUKL MED,D-8520 ERLANGEN,FED REP GER; UNIV ERLANGEN NURNBERG,NUKL MED POLIKLIN,D-8520 ERLANGEN,FED REP GER	University of Erlangen Nuremberg; University of Erlangen Nuremberg	NIEMANN, H (corresponding author), UNIV ERLANGEN NURNBERG,LEHRSTUHL INFORMAT MUSTERERKENNUNG 5,D-8520 ERLANGEN,FED REP GER.							Azancot I., 1978, Computers in Cardiology 1978, P281; Ballard D.H., 1982, COMPUTER VISION; BRACHMAN RJ, 1979, ASS NETWORKS; Brower R. W., 1978, Computers in Cardiology 1978, P69; BUNKE H, 1984, DIGITAL SIGNAL PROCE; BUNKE H, 1984, 7TH INT C PATT REC M; BUNKE H, 1983, IMAGE SEQUENCE PROCE, P724; BUNKE H, 1982, 1ST P IEEE COMP SOC, P146; CONNERS RW, 1982, 6TH P INT C PATT REC, P1152; FEISTEL H, 1982, THESIS U ERLANGEN NU; FINDLER N, 1979, ASS NETWORKS; GEFFERS H, 1978, 5TH P INT C VAND U N, P322; Gerbrands J. J., 1981, 2nd International Conference on Visual Psychophysics and Medical Imaging, P155; GORIS ML, 1981, CARDIOVASC INTER RAD, V4, P117, DOI 10.1007/BF02552390; Hanson A., 1978, COMPUTER VISION SYST; HAWMAN EG, 1981, OPT ENG, V20, P719, DOI 10.1117/12.7972797; NIEMANN H, 1984, PATTERN RECOGNITION, V17; NIEMANN H, 1982, 6TH P INT C PATT REC, P16; Niemann H., 1981, SPRINGER SERIES INFO, V4; NILSSON NJ, 1983, PRINCIPLES ARTIFICIA; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; Pratt W. K., 1978, DIGITAL IMAGE PROCES; SAUER E, 1980, MYOKARD VENTRIKELSZI; TSOTSOS JK, 1980, IEEE T PATTERN ANAL, V2, P563, DOI 10.1109/TPAMI.1980.6447704; WATERMAN D, 1978, PATTERN DIRECTED INF; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; 1983, COMPUTER, V16	27	23	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					246	259		10.1109/TPAMI.1985.4767655	http://dx.doi.org/10.1109/TPAMI.1985.4767655			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869261				2022-12-18	WOS:A1985AFM4400001
J	SAMET, H				SAMET, H			A TOP-DOWN QUADTREE TRAVERSAL ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SAMET, H (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							DYER CR, 1980, COMPUT VISION GRAPH, V13, P270, DOI 10.1016/0146-664X(80)90050-7; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; HUNTER GM, 1978, THESIS PRINCETON U P; JACKINS CL, 1983, IEEE T PATTERN ANAL, V5, P533, DOI 10.1109/TPAMI.1983.4767433; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; KLINGER A, 1971, OPTIMIZING METHODS S, P303; ROSENFELD A, 1982, TR1197 U MAR COMP SC; SAMET H, 1981, IEEE T PATTERN ANAL, V3, P683, DOI 10.1109/TPAMI.1981.4767171; SAMET H, 1982, COMPUT VISION GRAPH, V18, P37, DOI 10.1016/0146-664X(82)90098-3; SAMET H, 1982, IEEE T PATTERN ANAL, V4, P298, DOI 10.1109/TPAMI.1982.4767246; SAMET H, 1983, COMMUN ACM, V26, P680, DOI 10.1145/358172.358409; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, UNPUB COMPUT VISION; SAMET H, 1982, TR1162 U MAR COMP SC; SAMET H, 1984, ACM COMPUT SURVEYS, V16; SAMET H, TR1224 U MAR COMP SC; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884	18	23	23	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					94	98		10.1109/TPAMI.1985.4767622	http://dx.doi.org/10.1109/TPAMI.1985.4767622			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869244				2022-12-18	WOS:A1985ABF0900009
J	CHOCK, M; CARDENAS, AF; KLINGER, A				CHOCK, M; CARDENAS, AF; KLINGER, A			DATABASE STRUCTURE AND MANIPULATION CAPABILITIES OF A PICTURE DATABASE-MANAGEMENT SYSTEM (PICDMS)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF LOS ANGELES,DEPT COMP SCI,LOS ANGELES,CA 90024	University of California System; University of California Los Angeles	CHOCK, M (corresponding author), MIB CHOCK,SANTA MONICA,CA 90403, USA.							BERMAN R, 1977, COMPUTER GRAPHICS, V11, P186; CHANG NS, 1981, COMPUTER, V14, P22; CHANG NS, 1980, INTEGRATED IMAGE ANA; CHANG SK, 1981, COMPUTER, V14, P13, DOI [10.1109/C-M.1981.220243, 10.1109/C-M.1981.220241]; CHOCK M, 1981, COMPUTER, V14, P43, DOI 10.1109/C-M.1981.220248; CHOCK M, 1982, THESIS U CALIFORNIA; CHOCK M, 1982, 5TH INT S COMP ASS C; CHOCK M, 1982, FEB WORLD C MED INF; MANTEY PE, 1974, IBM RJ1459 RES REP; NAGY G, 1979, COMPUT SURV, V11, P139, DOI 10.1145/356770.356777	10	23	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					484	492		10.1109/TPAMI.1984.4767553	http://dx.doi.org/10.1109/TPAMI.1984.4767553			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869216				2022-12-18	WOS:A1984SY28900009
J	DAVIS, LS; JANOS, L; DUNN, SM				DAVIS, LS; JANOS, L; DUNN, SM			EFFICIENT RECOVERY OF SHAPE FROM TEXTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	DAVIS, LS (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							DAVIS LS, 1982, TR1133 U MAR COMP SC; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	3	23	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					485	492		10.1109/TPAMI.1983.4767427	http://dx.doi.org/10.1109/TPAMI.1983.4767427			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869133				2022-12-18	WOS:A1983RM11800004
J	LEGTERS, GR; YOUNG, TY				LEGTERS, GR; YOUNG, TY			A MATHEMATICAL-MODEL FOR COMPUTER IMAGE TRACKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MIAMI,DEPT ELECT ENGN,CORAL GABLES,FL 33124	University of Miami								AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; AGGARWAL JK, 1980, IEEE T PATTERN ANAL, V2; ARFKEN G, 1973, MATH METHODS PHYSICI; BADLER NI, 1979, APR WORKSH COMP AN T; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; CAFFORIO C, 1979, SIGNAL PROCESS, V1, P133, DOI 10.1016/0165-1684(79)90015-X; CHOW WK, 1977, IEEE T COMPUT, V26, P179, DOI 10.1109/TC.1977.5009299; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FUTRELLE RP, 1978, MAY P PRIP CHIC, P405; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GILBERT AL, 1980, IEEE T PATTERN ANAL, V2, P47, DOI 10.1109/TPAMI.1980.4766969; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; LEGTERS GR, 1980, THESIS U MIAMI; LIMB JO, 1975, IEEE T COMMUN, VCO23, P474, DOI 10.1109/TCOM.1975.1092828; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; NAGEL HH, 1978, 4TH P INT JOINT C PA, P186; NETRAVALI AN, 1980, AT&T TECH J, V59, P1735, DOI 10.1002/j.1538-7305.1980.tb03058.x; NETRAVALI AN, 1979, AT&T TECH J, V58, P631, DOI 10.1002/j.1538-7305.1979.tb02238.x; POTTER JL, 1977, COMPUT VISION GRAPH, V6, P558, DOI 10.1016/S0146-664X(77)80016-6; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2, DOI 10.1109/TPAMI.1982.4767188; SCHALKOFF RJ, 1979, NOV P COMP SOFTW APP, P504; SNYDER WE, 1980, 5TH P INT C PATT REC, V2, P1111; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; Tomonaga S, 1968, QUANTUM MECH, VII; WANG TC, 1980, DEC P INT COMP S, V2, P860; WARD M, 1980, 5TH P INT C PATT REC, V2, P1236	29	23	28	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					583	594		10.1109/TPAMI.1982.4767311	http://dx.doi.org/10.1109/TPAMI.1982.4767311			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499632				2022-12-18	WOS:A1982PS23700003
J	MACHUCA, R; GILBERT, AL				MACHUCA, R; GILBERT, AL			FINDING EDGES IN NOISY SCENES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MACHUCA, R (corresponding author), USA,WHITE SANDS MISSILE RANGE,NM 88002, USA.							Abdou I. E., 1978, QUANTITATIVE METHODS; ANGUS RC, 1974, AM J AGR ECON, V56, P573, DOI 10.2307/1238610; GILES MK, 1979, OPT ENG, V18, P33, DOI 10.1117/12.7972316; KRASNOSELSKY MA, 1961, PLANE VECTOR FIELDS; Lipkin BS, 1970, PICTURE PROCESSING P; Milnor J. W., 1965, TOPOLOGY DIFFERENTIA; Pratt W. K., 1978, DIGITAL IMAGE PROCES; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SCHUCTER B, 1978, COMMUN ASS COMPUT MA, V21, P172; Stroud A.H., 1971, APPROXIMATE CALCULAT	10	23	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					103	111		10.1109/TPAMI.1981.4767057	http://dx.doi.org/10.1109/TPAMI.1981.4767057			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	LK116	21868925	Green Submitted			2022-12-18	WOS:A1981LK11600013
J	Yang, HM; Zhang, XY; Yin, F; Yang, Q; Liu, CL				Yang, Hong-Ming; Zhang, Xu-Yao; Yin, Fei; Yang, Qing; Liu, Cheng-Lin			Convolutional Prototype Network for Open Set Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Open set recognition; CNN; prototype model; unknown detection; discriminative model; generative model	NOVELTY DETECTION; CLASSIFIER; ONLINE; ERROR	Despite the success of convolutional neural network (CNN) in conventional closed-set recognition (CSR), it still lacks robustness for dealing with unknowns (those out of known classes) in open environment. To improve the robustness of CNN in open-set recognition (OSR) and meanwhile maintain its high accuracy in CSR, we propose an alternative deep framework called convolutional prototype network (CPN), which keeps CNN for representation learning but replaces the closed-world assumed softmax with an open-world oriented and human-like prototype model. To equip CPN with discriminative ability for classifying known samples, we design several discriminative losses for training. Moreover, to increase the robustness of CPN for unknowns, we interpret CPN from the perspective of generative model and further propose a generative loss, which is essentially maximizing the log-likelihood of known samples and serves as a latent regularization for discriminative learning. The combination of discriminative and generative losses makes CPN a hybrid model with advantages for both CSR and OSR. Under the designed losses, the CPN is trained end-to-end for learning the convolutional network and prototypes jointly. For application of CPN in OSR, we propose two rejection rules for detecting different types of unknowns. Experiments on several datasets demonstrate the efficiency and effectiveness of CPN for both CSR and OSR tasks.	[Yang, Hong-Ming; Zhang, Xu-Yao; Yin, Fei; Yang, Qing; Liu, Cheng-Lin] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Yang, Hong-Ming; Zhang, Xu-Yao; Liu, Cheng-Lin] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Liu, Cheng-Lin] CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Zhang, XY; Liu, CL (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.; Zhang, XY; Liu, CL (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.	hongming.yang@nlpr.ia.ac.cn; xyz@nlpr.ia.ac.cn; fyin@nlpr.ia.ac.cn; qyang@nlpr.ia.ac.cn; liucl@nlpr.ia.ac.cn			Major Project for New Generation of AI [2018AAA0100400]; National Natural Science Foundation of China (NSFC) [61633021, 61836014, 61721004, 62076236, 71621002]; Key Research Program of Frontier Sciences of CAS [ZDBS-LY-7004]; Youth Innovation Promotion Association of CAS [2019141]	Major Project for New Generation of AI; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Key Research Program of Frontier Sciences of CAS; Youth Innovation Promotion Association of CAS	This work was supported by the Major Project for New Generation of AI under Grant No. 2018AAA0100400, the National Natural Science Foundation of China (NSFC) under Grants 61633021, 61836014, 61721004, 62076236, and 71621002, the Key Research Program of Frontier Sciences of CAS under Grant ZDBS-LY-7004, and the Youth Innovation Promotion Association of CAS under Grant 2019141.	Albertini MK, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P462, DOI 10.1145/1244002.1244110; Ando S, 2007, IEEE DATA MINING, P13, DOI 10.1109/ICDM.2007.53; Augusteijn MF, 2002, INT J REMOTE SENS, V23, P2891, DOI 10.1080/01431160110055804; Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173; Cheng-Lin Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3328, DOI 10.1109/ICPR.2010.813; Cheng-Lin Liu, 2002, International Journal on Document Analysis and Recognition, V4, P191, DOI 10.1007/s100320200076; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Clifton DA, 2007, KEY ENG MATER, V347, P305, DOI 10.4028/www.scientific.net/KEM.347.305; Clifton DA, 2011, J SIGNAL PROCESS SYS, V65, P371, DOI 10.1007/s11265-010-0513-6; Crook PA, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3894, DOI 10.1109/ROBOT.2002.1014330; Decaestecker C, 1997, PATTERN RECOGN, V30, P281, DOI 10.1016/S0031-3203(96)00072-6; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Filippone M, 2010, PATTERN RECOGN, V43, P805, DOI 10.1016/j.patcog.2009.07.002; Gardner AB, 2006, J MACH LEARN RES, V7, P1025; Ge ZongYuan, 2017, BMVC; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; Ghoting A, 2008, DATA MIN KNOWL DISC, V16, P349, DOI 10.1007/s10618-008-0093-2; Grossman D, 2004, P 21 INT C MACHINE L, P361; Hawkins S., 2002, Data Warehousing and Knowledge Discovery. 4th International Conference, DaWaK 2002. Proceedings (Lecture Notes in Computer Science Vol.2454), P170; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He ZY, 2006, LECT NOTES ARTIF INT, V3918, P567; Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009; Huang Y. S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P483, DOI 10.1109/ICPR.1996.547612; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Kassab R, 2009, MACH LEARN, V74, P191, DOI 10.1007/s10994-008-5092-4; Kohonen T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P545, DOI 10.1109/IJCNN.1990.137622; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEE SW, 1994, PATTERN RECOGN, V27, P1267, DOI 10.1016/0031-3203(94)90010-8; Li YH, 2002, PATTERN RECOGN LETT, V23, P569, DOI 10.1016/S0167-8655(01)00133-7; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu CL, 1997, PROC INT CONF DOC, P1033, DOI 10.1109/ICDAR.1997.620666; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P1395, DOI 10.1109/TPAMI.2004.104; Liu CL, 2004, IEEE T NEURAL NETWOR, V15, P430, DOI 10.1109/TNN.2004.824263; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Miller D, 1996, IEEE T SIGNAL PROCES, V44, P3108, DOI 10.1109/78.553484; Neal L, 2018, LECT NOTES COMPUT SC, V11210, P620, DOI 10.1007/978-3-030-01231-1_38; Netzer Y, 2011, NIPS WORKSH DEEP LEA, P2011, DOI DOI 10.2118/18761-MS; Ntalampiras S, 2011, IEEE T MULTIMEDIA, V13, P713, DOI 10.1109/TMM.2011.2122247; Oza P, 2019, PROC CVPR IEEE, P2302, DOI 10.1109/CVPR.2019.00241; Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026; Ramadas M, 2003, LECT NOTES COMPUT SC, V2820, P36; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sato A, 1996, ADV NEUR IN, V8, P423; Sato A, 1998, INT C PATT RECOG, P322, DOI 10.1109/ICPR.1998.711145; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Seo S, 2003, NEURAL COMPUT, V15, P1589, DOI 10.1162/089976603321891819; Shu L, 2018, ARXIV 180105609; Shu Lei, 2017, EMNLP; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Springenberg J. T, 2015, ARXIV PREPRINT ARXIV; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Williams G, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P709, DOI 10.1109/ICDM.2002.1184035; Wu MR, 2009, IEEE T PATTERN ANAL, V31, P2088, DOI 10.1109/TPAMI.2009.24; Yamanishi K, 2004, DATA MIN KNOWL DISC, V8, P275, DOI 10.1023/B:DAMI.0000023676.72185.7c; Yang HM, 2018, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2018.00366; Yong SP, 2012, PATTERN RECOGN, V45, P3439, DOI 10.1016/j.patcog.2012.02.036; Yoshihashi R, 2019, PROC CVPR IEEE, P4011, DOI 10.1109/CVPR.2019.00414; Zhang XY, 2020, P IEEE, V108, P894, DOI 10.1109/JPROC.2020.2989782	60	22	22	14	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2358	2370		10.1109/TPAMI.2020.3045079	http://dx.doi.org/10.1109/TPAMI.2020.3045079			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33326375				2022-12-18	WOS:000792921400012
J	Zhao, J; Yan, SC; Feng, JS				Zhao, Jian; Yan, Shuicheng; Feng, Jiashi			Towards Age-Invariant Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Age-invariant face recognition; age-invariant model; generative adversarial networks; benchmark dataset	REPRESENTATION; VERIFICATION; PATTERNS; SHAPE	Despite the remarkable progress in face recognition related technologies, reliably recognizing faces across ages remains a big challenge. The appearance of a human face changes substantially over time, resulting in significant intra-class variations. As opposed to current techniques for age-invariant face recognition, which either directly extract age-invariant features for recognition, or first synthesize a face that matches target age before feature extraction, we argue that it is more desirable to perform both tasks jointly so that they can leverage each other. To this end, we propose a deep Age-Invariant Model (AIM) for face recognition in the wild with three distinct novelties. First, AIM presents a novel unified deep architecture jointly performing cross-age face synthesis and recognition in a mutual boosting way. Second, AIM achieves continuous face rejuvenation/aging with remarkable photorealistic and identity-preserving properties, avoiding the requirement of paired data and the true age of testing samples. Third, effective and novel training strategies are developed for end-to-end learning of the whole deep architecture, which generates powerful age-invariant face representations explicitly disentangled from the age variation. Moreover, we construct a new large-scaleCross-Age Face Recognition (CAFR) benchmark dataset to facilitate existing efforts and push the frontiers of age-invariant face recognition research. Extensive experiments on both our CAFR dataset and several other cross-age datasets (MORPH, CACD, and FG-NET) demonstrate the superiority of the proposed AIM model over the state-of-the-arts. Benchmarking our model on the popular unconstrained face recognition datasets YTFand IJB-C additionally verifies its promising generalization ability in recognizing faces in the wild.	[Zhao, Jian] Inst North Elect Equipment, Beijing 100191, Peoples R China; [Yan, Shuicheng] Yitu Technol, Beijing 100000, Peoples R China; [Feng, Jiashi] Natl Univ Singapore, Singapore 119077, Singapore	National University of Singapore	Zhao, J (corresponding author), Inst North Elect Equipment, Beijing 100191, Peoples R China.	zhaojian90@u.nus.edu; shuicheng.yan@gmail.com; elefjia@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022; Feng, Jiashi/AGX-6209-2022	Zhao, Jian/0000-0002-3508-756X	NUS [IDS R-263-000-C67-646]; MOE [R-263-000-D17-112]; ECRA [R-263-000-C87-133]	NUS(National University of Singapore); MOE(Ministry of Higher Education & Scientific Research (MHESR)); ECRA	The work of Jiashi Feng was partially supported by NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133 and MOE Tier-II R-263-000-D17-112.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2007, FG NET AGING DATABAS; BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374; Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Chen J, 2017, IMAGE VISION COMPUT, V64, P34, DOI 10.1016/j.imavis.2017.05.006; Cheng Y, 2017, IEEE INT CONF COMP V, P1924, DOI 10.1109/ICCVW.2017.227; Duong CN, 2017, IEEE I CONF COMP VIS, P3755, DOI 10.1109/ICCV.2017.403; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251; Dong YP, 2019, PROC CVPR IEEE, P7706, DOI 10.1109/CVPR.2019.00790; Ganin Y, 2016, J MACH LEARN RES, V17; Gong D., 2013, P 21 ACM INT C MULT, p[617, 2], DOI DOI 10.1145/2502081.2502162; Gong DH, 2015, PROC CVPR IEEE, P5289, DOI 10.1109/CVPR.2015.7299166; Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357; Guo YL, 2016, PATTERN RECOGN LETT, V83, P403, DOI 10.1016/j.patrec.2016.04.003; Hasnat A, 2017, IEEE INT CONF COMP V, P1682, DOI 10.1109/ICCVW.2017.197; Jian Z.., 2018, THESIS NAT U SINGAPO; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Kemelmacher-Shlizerman I, 2014, PROC CVPR IEEE, P3334, DOI 10.1109/CVPR.2014.426; Li JS, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1531, DOI 10.1145/3123266.3123438; Li JS, 2019, IEEE T CIRC SYST VID, V29, P104, DOI 10.1109/TCSVT.2017.2778227; Li JH, 2016, P IEEE RAS-EMBS INT, P1068, DOI 10.1109/BIOROB.2016.7523773; Li ZF, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2807705; Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284; Li ZF, 2014, IEEE T IMAGE PROCESS, V23, P2436, DOI 10.1109/TIP.2014.2315920; Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787; Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386; Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751; Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021; Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431; Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Nech A, 2017, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2017.363; Ramanathan N., 2006, P IEEE C COMP VIS PA, V1, P387; Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993; Ramanathan N, 2008, IEEE INT CONF AUTOMA, P1006; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Sungatullina D., 2013, P 10 IEEE INT C WORK, P1, DOI DOI 10.1109/FG.2013.6553724; Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; TANG X, 2004, P IEEE C COMP VIS PA, V2, pR2; Tang XO, 2009, IEEE T CIRC SYST VID, V19, P955, DOI 10.1109/TCSVT.2009.2022694; Tang XO, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P345; Tu X, 2019, ADV MECH ENG, V11, DOI 10.1177/1687814019837399; Tu XG, 2021, IEEE T MULTIMEDIA, V23, P1160, DOI 10.1109/TMM.2020.2993962; Wang H, 2019, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2019.00364; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261; Wang YT, 2018, LECT NOTES COMPUT SC, V11219, P764, DOI 10.1007/978-3-030-01267-0_45; Wang YH, 2012, IEEE T SYST MAN CY B, V42, P1107, DOI 10.1109/TSMCB.2012.2187051; Wang ZX, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P370, DOI 10.1145/3078971.3078973; Wang ZC, 2020, IEEE WINT CONF APPL, P3432, DOI 10.1109/WACV45572.2020.9093476; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; WEN YD, 2016, PROC CVPR IEEE, P4893, DOI DOI 10.1109/CVPR.2016.529; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xie W., 2018, ARXIV180709192; Xu CF, 2017, NEUROCOMPUTING, V222, P62, DOI 10.1016/j.neucom.2016.10.010; Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011; Yang HY, 2016, IEEE T IMAGE PROCESS, V25, P2493, DOI 10.1109/TIP.2016.2547587; Yu Z, 2017, IEEE INT SYMP ELEC; Zhang KP, 2018, LECT NOTES COMPUT SC, V11215, P196, DOI 10.1007/978-3-030-01252-6_12; Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463; Zhao J, 2020, INT J COMPUT VISION, V128, P460, DOI 10.1007/s11263-019-01252-7; Zhao J, 2019, AAAI CONF ARTIF INTE, P9251; Zhao J, 2017, ADV NEUR IN, V30; Zhao J, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1184; Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235; Zheng TY, 2017, IEEE COMPUT SOC CONF, P503, DOI 10.1109/CVPRW.2017.77	81	22	22	34	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					474	487		10.1109/TPAMI.2020.3011426	http://dx.doi.org/10.1109/TPAMI.2020.3011426			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750831				2022-12-18	WOS:000728561300034
J	Jia, XD; Jing, XY; Zhu, XK; Chen, SC; Du, B; Cai, ZY; He, ZY; Yue, D				Jia, Xiaodong; Jing, Xiao-Yuan; Zhu, Xiaoke; Chen, Songcan; Du, Bo; Cai, Ziyun; He, Zhenyu; Yue, Dong			Semi-Supervised Multi-View Deep Discriminant Representation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Redundancy; Feature extraction; Measurement; Machine learning; Taxonomy; Semisupervised learning; Semi-supervised multi-view deep representation learning; consensus and complementarity; redundancy; adversarial training; Siamese network; density clustering	LAPLACIAN	Learning an expressive representation from multi-view data is a key step in various real-world applications. In this paper, we propose a semi-supervised multi-view deep discriminant representation learning (SMDDRL) approach. Unlike existing joint or alignment multi-view representation learning methods that cannot simultaneously utilize the consensus and complementary properties of multi-view data to learn inter-view shared and intra-view specific representations, SMDDRL comprehensively exploits the consensus and complementary properties as well as learns both shared and specific representations by employing the shared and specific representation learning network. Unlike existing shared and specific multi-view representation learning methods that ignore the redundancy problem in representation learning, SMDDRL incorporates the orthogonality and adversarial similarity constraints to reduce the redundancy of learned representations. Moreover, to exploit the information contained in unlabeled data, we design a semi-supervised learning framework by combining deep metric learning and density clustering. Experimental results on three typical multi-view learning tasks, i.e., webpage classification, image classification, and document classification demonstrate the effectiveness of the proposed approach.	[Jia, Xiaodong] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China; [Jing, Xiao-Yuan] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China; [Jing, Xiao-Yuan] Guangdong Univ Petrochem Technol, Sch Comp, Maoming 525000, Peoples R China; [Jing, Xiao-Yuan] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210042, Peoples R China; [Zhu, Xiaoke] Henan Univ, Sch Comp & Informat Engn, Henan Key Lab Big Data Anal & Proc, Kaifeng 475001, Peoples R China; [Chen, Songcan] Nanjing Univ Aeronaut & Astronaut, MIIT Key Lab Pattern Anal & Machine Intelligence, Coll Comp Sci & Technol, Nanjing 210016, Peoples R China; [Du, Bo] Wuhan Univ, Inst Artificial Intelligence, Sch Comp Sci, Wuhan 430072, Peoples R China; [Du, Bo] Wuhan Univ, Natl Engn Res Ctr Multimed Software, Wuhan 430072, Peoples R China; [Cai, Ziyun; Yue, Dong] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210042, Peoples R China; [He, Zhenyu] Shenzhen Grad Sch, Harbin Inst Technol, Sch Comp Sci, Shenzhen 518055, Peoples R China	Wuhan University; Wuhan University; Guangdong University of Petrochemical Technology; Nanjing University of Posts & Telecommunications; Henan University; Nanjing University of Aeronautics & Astronautics; Wuhan University; Wuhan University; Nanjing University of Posts & Telecommunications; Harbin Institute of Technology; University Town of Shenzhen	Jing, XY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.; Jing, XY (corresponding author), Guangdong Univ Petrochem Technol, Sch Comp, Maoming 525000, Peoples R China.; Jing, XY (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210042, Peoples R China.	jxdshimon@gmail.com; jingxy_2000@126.com; henuzxk@163.com; s.chen@nuaa.edu.cn; gunspace@163.com; caiziyun@163.com; zhenyuhe@hit.edu.cn; medongy@vip.163.com		Cai, Ziyun/0000-0001-6822-915X; Zhu, Xiaoke/0000-0002-0664-1832; Jia, Xiaodong/0000-0001-9082-4254	National Natural Science Foundation of China (NSFC) [61933013, 61732006]; NSFC-Key Project of General Technology Fundamental Research United Fund [U1736211]; Science and Technology Major Project of Hubei Province (Next-Generation AI Technologies) [2019AEA170]; National Key Research and Development Program of China [2018AAA0100102, 2017YFB0202001]; Key Project of Natural Science Foundation of Hubei Province [2018CFA024]; Natural Science Foundation of Guangdong Province [2019A1515011076]; Innovation Group of Guangdong Education Department [2018KCXTD019]; Higher Education Institution Key Research Projects of Henan Province [19A520001]; Key Scientific and Technological Project of Henan Province [192102210277]; NSFC [61822113, 61672208]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); NSFC-Key Project of General Technology Fundamental Research United Fund; Science and Technology Major Project of Hubei Province (Next-Generation AI Technologies); National Key Research and Development Program of China; Key Project of Natural Science Foundation of Hubei Province(Natural Science Foundation of Hubei Province); Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); Innovation Group of Guangdong Education Department; Higher Education Institution Key Research Projects of Henan Province; Key Scientific and Technological Project of Henan Province; NSFC(National Natural Science Foundation of China (NSFC))	The authors would like to thank the editors and reviewers for helpful comments and suggestions. This work was supported by the National Natural Science Foundation of China (NSFC) Key Project (61933013, 61732006), the NSFC-Key Project of General Technology Fundamental Research United Fund (U1736211), the Science and TechnologyMajor Project of Hubei Province (Next-Generation AI Technologies) under Grant 2019AEA170, the National Key Research and Development Program of China (2018AAA0100102, 2017YFB0202001), the NSFC Project (61822113, 61672208), the Key Project of Natural Science Foundation of Hubei Province (2018CFA024), the Natural Science Foundation of Guangdong Province (2019A1515011076), the Innovation Group of Guangdong Education Department (2018KCXTD019), the Higher Education Institution Key Research Projects of Henan Province (19A520001), and the Key Scientific and Technological Project of Henan Province (192102210277). Xiaodong Jia and XiaoYuan Jing contributed equally to this work. Xiaoke Zhu, Bo Du and ZhenyuHe are co-corresponding authors.	Andrew Galen, 2013, ICML; [Anonymous], 2016, IJCAI; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Caragea C., 2015, P 2015 C EMP METH NA, P2357, DOI DOI 10.18653/V1/D15-1283; Chao GQ, 2019, INFORM FUSION, V45, P296, DOI 10.1016/j.inffus.2018.03.002; Chapelle O, 2005, P INT WORKSH ART INT, V2005, P57; Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64; Chen S, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2021; Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Christoudias CM, 2008, PROC CVPR IEEE, P2126; Duan YQ, 2018, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2018.00294; Elmadany NED, 2016, INT CONF ACOUST SPEE, P2409, DOI 10.1109/ICASSP.2016.7472109; Frome Andrea, 2013, NEURIPS; Gao W, 2013, ARTIF INTELL, V203, P1, DOI 10.1016/j.artint.2013.07.002; Gong C, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3322122; Gong C, 2017, AAAI CONF ARTIF INTE, P1926; Gong C, 2017, IEEE T NEUR NET LEAR, V28, P1452, DOI 10.1109/TNNLS.2016.2514360; Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Minh HQ, 2016, J MACH LEARN RES, V17; Harwath D., 2016, ADV NEURAL INFORM PR, P1858; Harwath D, 2018, LECT NOTES COMPUT SC, V11210, P659, DOI 10.1007/978-3-030-01231-1_40; He J., 2011, PROC INT C MACH LEAR, P25; Hermann K. M., 2015, ADV NEURAL INFORM PR, V28, P1693; Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576; Jing XY, 2017, AAAI CONF ARTIF INTE, P1374; Jing XY, 2014, AAAI CONF ARTIF INTE, P1882; Jing XY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2255; Kan MN, 2016, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2016.524; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kang Y, 2011, LECT NOTES ARTIF INT, V6912, P130, DOI 10.1007/978-3-642-23783-6_9; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar A., 2011, P 28 INT C MACH LEAR, P393, DOI DOI 10.5555/3104482.3104532; Kushmerick N., 1999, Proceedings of the Third International Conference on Autonomous Agents, P175, DOI 10.1145/301136.301186; Laine Samuli, 2017, P INT C LEARN REPR I, P3; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee D., 2013, INT C MACH LEARN ICM; Li JH, 2016, P IEEE RAS-EMBS INT, P1068, DOI 10.1109/BIOROB.2016.7523773; Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063; Liang B, 2017, IEEE T IMAGE PROCESS, V26, P5560, DOI 10.1109/TIP.2017.2740122; Liu PJ, 2017, 2017 24TH SAINT PETERSBURG INTERNATIONAL CONFERENCE ON INTEGRATED NAVIGATION SYSTEMS (ICINS); Luo SR, 2018, AAAI CONF ARTIF INTE, P3730; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Nie F., 2016, IJCAI, P1881; Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939; Noroozi V, 2018, IEEE INT CONF BIG DA, P56, DOI 10.1109/BigData.2018.8622015; Raffel C.A., 2019, ADV NEURAL INFORM PR, P5049; Rasmus A., 2015, ADV NEURAL INFORM PR, P3546, DOI DOI 10.1186/1477-5956-9-S1-S5; Rifai S., 2011, ADV NEURAL INFORM PR, V24, P2294; Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072; Salzmann Mathieu, 2010, P 13 INT C ART INT S, P701; Shabtai A., 2017, ACM T INTEL SYST TEC, V9, P1; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Sindhwani V., 2005, P 22 INT C MACH LEAR, P824, DOI DOI 10.1145/1102351.1102455; Springenberg J. T, 2016, P INT C LEARN REPR, P3581; Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI [DOI 10.1162/NEC0_A_00311, DOI 10.1109/CVPR.2013.49]; Sun SL, 2016, IEEE T CYBERNETICS, V46, P3272, DOI 10.1109/TCYB.2015.2502248; Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28; Tarvainen Antti, 2017, CORR, Vabs/1703; Wang Q, 2019, IEEE I CONF COMP VIS, P1466, DOI 10.1109/ICCV.2019.00155; Wang W., 2013, P AS C MACH LEARN CA, P467; Wang W, 2010, P ADV NEUR INF PROC, P2388; Wang WR, 2015, PR MACH LEARN RES, V37, P1083; Wu F, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3349, DOI 10.1145/3308558.3313492; XIE X, IN PRESS, DOI DOI 10.1109/TKDE.2019.2933511; Xu C., 2013, ARXIV13045634; Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578; Xu XX, 2016, IEEE T PATTERN ANAL, V38, P1113, DOI 10.1109/TPAMI.2015.2476813; Xue XW, 2017, AAAI CONF ARTIF INTE, P2810; Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007; Zhao L, 2015, LECT NOTES COMPUT SC, V9492, P11, DOI 10.1007/978-3-319-26561-2_2; ZHOU T, IN PRESS, DOI DOI 10.1109/TCYB.2018.2883673; Zhou Z.-H, 2016, P AS C MACH LEARN, P407; Zhu X., 2003, INT C MACH LEARN; Zhu Xiaojin, 2002, TECHNICAL REPORT, P1; Zuo ZQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1137, DOI 10.1145/2647868.2655002	81	22	22	13	69	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2496	2509		10.1109/TPAMI.2020.2973634	http://dx.doi.org/10.1109/TPAMI.2020.2973634			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	32070943				2022-12-18	WOS:000692540900023
J	Liu, J; Zhuang, BH; Zhuang, ZW; Guo, Y; Huang, JZ; Zhu, JH; Tan, MK				Liu, Jing; Zhuang, Bohan; Zhuang, Zhuangwei; Guo, Yong; Huang, Junzhou; Zhu, Jinhui; Tan, Mingkui			Discrimination-Aware Network Pruning for Deep Model Compression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Computational modeling; Quantization (signal); Training; Adaptation models; Acceleration; Redundancy; Channel pruning; kernel pruning; network compression; deep neural networks	CLASSIFICATION; MARGIN	We study network pruning which aims to remove redundant channels/kernels and hence speed up the inference of deep networks. Existing pruning methods either train from scratch with sparsity constraints or minimize the reconstruction error between the feature maps of the pre-trained models and the compressed ones. Both strategies suffer from some limitations: the former kind is computationally expensive and difficult to converge, while the latter kind optimizes the reconstruction error but ignores the discriminative power of channels. In this paper, we propose a simple-yet-effective method called discrimination-aware channel pruning (DCP) to choose the channels that actually contribute to the discriminative power. To this end, we first introduce additional discrimination-aware losses into the network to increase the discriminative power of the intermediate layers. Next, we select the most discriminative channels for each layer by considering the discrimination-aware loss and the reconstruction error, simultaneously. We then formulate channel pruning as a sparsity-inducing optimization problem with a convex objective and propose a greedy algorithm to solve the resultant problem. Note that a channel (3D tensor) often consists of a set of kernels (each with a 2D matrix). Besides the redundancy in channels, some kernels in a channel may also be redundant and fail to contribute to the discriminative power of the network, resulting in kernel level redundancy. To solve this issue, we propose a discrimination-aware kernel pruning (DKP) method to further compress deep networks by removing redundant kernels. To avoid manually determining the pruning rate for each layer, we propose two adaptive stopping conditions to automatically determine the number of selected channels/kernels. The proposed adaptive stopping conditions tend to yield more efficient models with better performance in practice. Extensive experiments on both image classification and face recognition demonstrate the effectiveness of our methods. For example, on ILSVRC-12, the resultant ResNet-50 model with 30 percent reduction of channels even outperforms the baseline model by 0.36 percent in terms of Top-1 accuracy. We also deploy the pruned models on a smartphone (equipped with a Qualcomm Snapdragon 845 processor). The pruned MobileNetV1 and MobileNetV2 achieve 1.93x and 1.42x inference acceleration on the mobile device, respectively, with negligible performance degradation. The source code and the pre-trained models are available at https://github.com/SCUT-AILab/DCP.	[Liu, Jing; Zhuang, Zhuangwei; Guo, Yong; Zhu, Jinhui; Tan, Mingkui] South China Univ Technol, Sch Software Engn, Guangzhou 510641, Peoples R China; [Liu, Jing] South China Univ Technol, Minist Educ, Key Lab Big Data & Intelligent Robot, Guangzhou 510641, Peoples R China; [Zhuang, Bohan] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia; [Huang, Junzhou] Tencent AI Lab, Shenzhen 518064, Peoples R China; [Tan, Mingkui] Pazhou Lab, Guangzhou 510335, Peoples R China	South China University of Technology; South China University of Technology; Monash University; Tencent; Pazhou Lab	Tan, MK (corresponding author), South China Univ Technol, Sch Software Engn, Guangzhou 510641, Peoples R China.	seliujing@mail.scut.edu.cn; bohan.zhuang@monash.edu; z.zhuangwei@mail.scut.edu.cn; guo.yong@mail.scut.edu.cn; joehhuang@tencent.com; csjhzhu@scut.edu.cn; mingkuitan@scut.edu.cn		, Li/0000-0002-8927-5056	Key-Area Research and Development Program of Guangdong Province [2018B010107001]; National Natural Science Foundation of China (NSFC) [62072190]; Program for Guangdong Introducing Innovative and Enterpreneurial Teams [2017ZT07X183]	Key-Area Research and Development Program of Guangdong Province; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Program for Guangdong Introducing Innovative and Enterpreneurial Teams	This work was supported in part by the Key-Area Research and Development Program of Guangdong Province under Grant 2018B010107001, in part by the National Natural Science Foundation of China (NSFC) under Grant 61836003 (key project), in part by the National Natural Science Foundation of China (NSFC) under Grant 62072190, and in part by the Program for Guangdong Introducing Innovative and Enterpreneurial Teams under Grant 2017ZT07X183. Jing Liu, Bohan Zhuang, Zhuangwei Zhuang, and Mingkui Tan contributed equally to this work.	Alvarez Jose M, 2016, ADV NEURAL INFORM PR, P2270; Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348; Bahmani S, 2013, J MACH LEARN RES, V14, P807; Bulat A, 2020, IEEE T PATTERN ANAL, V42, P343, DOI 10.1109/TPAMI.2018.2866051; Cao JZ, 2018, PR MACH LEARN RES, V80; Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46; Choi J, 2018, ARXIV 180506085; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Denton E, 2014, ADV NEUR IN, V27; Gong Yunchao, 2014, ARXIV14126115; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; Guo YW, 2016, ADV NEUR IN, V29; Guo Y, 2020, NEURAL NETWORKS, V126, P250, DOI 10.1016/j.neunet.2020.03.001; Guo Y, 2019, IEEE T MULTIMEDIA, V21, P2726, DOI 10.1109/TMM.2019.2908352; Guo Y, 2018, AAAI CONF ARTIF INTE, P3134; Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104; Han S, 2015, ADV NEUR IN, V28; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234; He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447; He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48; He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155; Howard A.G., 2017, MOBILENETS EFFICIENT; Hu H., 2016, ARXIV PREPRINT ARXIV; Huang G. B., 2007, LABELED FACES WILD; Hubara I, 2016, ADV NEUR IN, V29; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Jiang CH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2298; Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lee Namhoon, 2019, INT C LEARN REPR; Li H., 2017, P INT C LEARN REPR I, P1; Lin SH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2425; Lin SH, 2020, IEEE T NEUR NET LEAR, V31, P574, DOI 10.1109/TNNLS.2019.2906563; Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290; Liu J, 2014, PR MACH LEARN RES, V32; Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212; Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]; Liu Z, 2019, PATTERN ANAL APPL, V22, P1527, DOI 10.1007/s10044-019-00792-5; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Loshchilov I., 2017, P INT C LEARNING REP; Luo JH, 2019, IEEE T PATTERN ANAL, V41, P2525, DOI 10.1109/TPAMI.2018.2858232; McIntosh L., 2016, PROC INT C LEARN REP, P1; Molchanov P., 2017, P INT C LEARNING REP, P1; Molchanov P, 2019, PROC CVPR IEEE, P11256, DOI 10.1109/CVPR.2019.01152; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Nair V., 2010, ICML, P807; NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543; Paszke A, 2019, ADV NEUR IN, V32; Rao YM, 2019, IEEE T PATTERN ANAL, V41, P2291, DOI 10.1109/TPAMI.2018.2878258; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sengupta S, 2016, IEEE WINT CONF APPL; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Simonyan K, 2014, ADV NEUR IN, V27; Sindhwani V., 2015, ADV NEURAL INFORM PR, P3088; Srinivas S, 2017, IEEE COMPUT SOC CONF, P455, DOI 10.1109/CVPRW.2017.61; Srivastava RK, 2015, ADV NEUR IN, V28; Sun Y., 2015, ARXIV PREPRINT ARXIV; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MK, 2015, IEEE T SIGNAL PROCES, V63, P727, DOI 10.1109/TSP.2014.2385036; Tan MK, 2014, J MACH LEARN RES, V15, P1371; Tan MX, 2019, PR MACH LEARN RES, V97; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang HS, 2018, PALAEONTOL ELECTRON, V21, DOI 10.26879/841; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wen W, 2016, ADV NEUR IN, V29; Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18; Ye J., 2018, RETHINKING SMALLERNO; You ZH, 2019, ADV NEUR IN, V32; Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958; Yuan XT, 2014, PR MACH LEARN RES, V32, P127; Zeng RH, 2019, IEEE T IMAGE PROCESS, V28, P5797, DOI 10.1109/TIP.2019.2922108; Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579; Zhou A, 2017, INCREMENTAL NETWORK; Zhou S., 2016, ARXIV160606160; Zhu XT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3264; Zhuang BH, 2019, PROC CVPR IEEE, P413, DOI 10.1109/CVPR.2019.00050; Zhuang BH, 2018, PROC CVPR IEEE, P7920, DOI 10.1109/CVPR.2018.00826; Zhuang ZW, 2018, ADV NEUR IN, V31	91	22	22	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 23	2021	44	8					4035	4051		10.1109/TPAMI.2021.3066410	http://dx.doi.org/10.1109/TPAMI.2021.3066410			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HS	33755553	Green Submitted			2022-12-18	WOS:000820522200001
J	Luo, P; Zhang, RM; Ren, JM; Peng, ZL; Li, JY				Luo, Ping; Zhang, Ruimao; Ren, Jiamin; Peng, Zhanglin; Li, Jingyu			Switchable Normalization for Learning-to-Normalize Deep Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Training; Graphics processing units; Switches; Object detection; Image segmentation; Head; Deep learning; normalization; image; video classification; object detection; semantic segmentation and face verification		We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network. SN employs three distinct scopes to compute statistics (means and variances) including a channel, a layer, and a minibatch. SN switches between them by learning their importance weights in an end-to-end manner. It has several good properties. First, it adapts to various network architectures and tasks (see Fig. 1 ). Second, it is robust to a wide range of batch sizes, maintaining high performance even when small minibatch is presented (e.g., 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike group normalization that searches the number of groups as a hyper-parameter. Without bells and whistles, SN outperforms its counterparts on various challenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, MegaFace and Kinetics. Analyses of SN are also presented to answer the following three questions: (a) Is it useful to allow each normalization layer to select its own normalizer? (b) What impacts the choices of normalizers? (c) Do different tasks and datasets prefer different normalizers? We hope SN will help ease the usage and understand the normalization techniques in deep learning. The code of SN has been released at https://github.com/switchablenorms.	[Luo, Ping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Zhang, Ruimao; Ren, Jiamin; Peng, Zhanglin] SenseTime Res, Shenzhen, Peoples R China; [Zhang, Ruimao] Chinese Univ Hong Kong, Hong Kong, Peoples R China; [Li, Jingyu] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China	University of Hong Kong; Chinese University of Hong Kong; Chinese University of Hong Kong	Zhang, RM (corresponding author), SenseTime Res, Shenzhen, Peoples R China.	pluo.lhi@gmail.com; ruimao.zhang@ieee.org; renjiamin@sensetime.com; pengzhanglin@sensetime.com; jingyuli@cuhk.edu.hk	Li, Jingyu/GSD-1924-2022; Luo, Ping/HGE-7623-2022; Li, Jing/GYU-5036-2022	Luo, Ping/0000-0002-6685-7950; Zhang, Ruimao/0000-0001-9511-7532	Seed Funding for Basic Research for New Staff	Seed Funding for Basic Research for New Staff	Ping Luo is partially supported by the Seed Funding for Basic Research for New Staff.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arora S., 2019, INT C LEARN REPR; Bjorck J, 2018, ADV NEUR IN, V31; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Colson B, 2007, ANN OPER RES, V153, P235, DOI 10.1007/s10479-007-0176-2; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng Jiankang, 2019, P IEEE C COMP VIS PA, P4690, DOI DOI 10.1109/CVPR.2019.00482; Desjardins G., 2015, ADV NEURAL INFORM PR, P2071; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goyal Priya, 2017, ARXIV170602677; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hinton, 2016, ARXIV PREPRINT ARXIV; Hinton G., 2009, TECH REPT, V1; Hoffer E, 2018, P INT C NEUR INF PRO, P2164; Huang L, 2018, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2018.00089; Huang L, 2017, IEEE I CONF COMP VIS, P2822, DOI 10.1109/ICCV.2017.305; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Ioffe Sergey, 2017, NEURIPS; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laurent C, 2016, INT CONF ACOUST SPEE, P2657, DOI 10.1109/ICASSP.2016.7472159; Liao Q., 2016, CORR; Lin L., 2018, P INT C NEUR INF PRO, P21; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212; Luo P., 2019, ICLR, P1; Luo P., 2019, IEEE INT C COMP VIS; Luo P, 2019, PR MACH LEARN RES, V97; Luo P, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2428; Luo P, 2017, PR MACH LEARN RES, V70; Maclaurin D, 2015, PR MACH LEARN RES, V37, P2113; Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29; Perez E., 2018, P 32 AAAI C ART INT; Pham H, 2018, PR MACH LEARN RES, V80; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Santurkar S, 2018, ADV NEUR IN, V31; Schoenholz S. S., 2019, ARXIV190208129; Shao WQ, 2020, INT J COMPUT VISION, V128, P2107, DOI 10.1007/s11263-019-01269-y; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Ulyanov D., 2016, ARXIV160708022; Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Yang J., 2017, FASTER PYTORCH IMPLE; Zemel R.S., 2017, P INT C LEARN REPR; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544	60	22	22	6	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					712	728		10.1109/TPAMI.2019.2932062	http://dx.doi.org/10.1109/TPAMI.2019.2932062			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31380746	Green Submitted			2022-12-18	WOS:000607383300022
J	Ji, RR; Li, K; Wang, Y; Sun, XS; Guo, F; Guo, XW; Wu, YJ; Huang, FY; Luo, JB				Ji, Rongrong; Li, Ke; Wang, Yan; Sun, Xiaoshuai; Guo, Feng; Guo, Xiaowei; Wu, Yongjian; Huang, Feiyue; Luo, Jiebo			Semi-Supervised Adversarial Monocular Depth Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Generators; Training; Image reconstruction; Sensors; Adaptation models; Data models; Monocular depth estimation; generative adversarial learning; semi-supervise learning	SHAPE	In this paper, we address the problem of monocular depth estimation when only a limited number of training image-depth pairs are available. To achieve a high regression accuracy, the state-of-the-art estimation methods rely on CNNs trained with a large number of image-depth pairs, which are prohibitively costly or even infeasible to acquire. Aiming to break the curse of such expensive data collections, we propose a semi-supervised adversarial learning framework that only utilizes a small number of image-depth pairs in conjunction with a large number of easily-available monocular images to achieve high performance. In particular, we use one generator to regress the depth and two discriminators to evaluate the predicted depth, i.e., one inspects the image-depth pair while the other inspects the depth channel alone. These two discriminators provide their feedbacks to the generator as the loss to generate more realistic and accurate depth predictions. Experiments show that the proposed approach can (1) improve most state-of-the-art models on the NYUD v2 dataset by effectively leveraging additional unlabeled data sources; (2) reach state-of-the-art accuracy when the training set is small, e.g., on the Make3D dataset; (3) adapt well to an unseen new dataset (Make3D in our case) after training on an annotated dataset (KITTI in our case).	[Ji, Rongrong; Sun, Xiaoshuai; Guo, Feng] Xiamen Univ, Dept Artificial Intelligence, Media Analyt & Comp Lab, Sch Informat, Xiamen 361005, Peoples R China; [Li, Ke; Guo, Xiaowei; Wu, Yongjian; Huang, Feiyue] Tencent Youtu Lab, Shanghai, Peoples R China; [Wang, Yan] Microsoft, Redmond, WA 98052 USA; [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Xiamen University; Tencent; Microsoft; University of Rochester	Li, K (corresponding author), Tencent Youtu Lab, Shanghai, Peoples R China.	rrji@xmu.edu.cn; tristanli@tencent.com; grapeot@gmail.com; xssun@xmu.edu.cn; betop@xmu.edu.cn; scorpioguo@tencent.com; littlekenwu@tencent.com; garyhuang@tencent.com; jiebo.luo@gmail.com		Wang, Yan/0000-0003-4309-3166; Luo, Jiebo/0000-0002-4516-9729; Li, Ke/0000-0001-7998-0731	National Key RD Program [2017YFC0113000, 2016YFB1001503]; Nature Science Foundation of China [U1705262, 61772443, 61572410]; Post Doctoral Innovative Talent Support Program [BX201600094]; China Post-Doctoral Science Foundation [2017M612134]; Scientific Research Project of National Language Committee of China [YB135-49]; Nature Science Foundation of Fujian Province, China [2017J01125, 2018J01106]	National Key RD Program; Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Post Doctoral Innovative Talent Support Program; China Post-Doctoral Science Foundation(China Postdoctoral Science Foundation); Scientific Research Project of National Language Committee of China; Nature Science Foundation of Fujian Province, China(Natural Science Foundation of Fujian Province)	This work is supported by the National Key R&D Program (No.2017YFC0113000, and No.2016YFB1001503), Nature Science Foundation of China (No.U1705262, No.61772443, and No.61572410), Post Doctoral Innovative Talent Support Program under Grant BX201600094, China Post-Doctoral Science Foundation under Grant 2017M612134, Scientific Research Project of National Language Committee of China (Grant No. YB135-49), and Nature Science Foundation of Fujian Province, China (No. 2017J01125 and No. 2018J01106).	ALOIMONOS J, 1988, BIOL CYBERN, V58, P345, DOI 10.1007/BF00363944; [Anonymous], 2018, MULTIMEDIA TOOLS APP, DOI DOI 10.1007/S11042-018-6694-X#CITEAS; Atapour-Abarghouei A, 2018, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2018.00296; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Han F, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P12; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hassner T., 2006, 2006 C COMP VIS PATT, P15, DOI DOI 10.1109/CVPRW.2006.76; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835; Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56; King DB, 2015, ACS SYM SER, V1214, P1; Klein George, 2007, P1; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97; Luc P., 2016, ARXIV161108408; Mathieu M., 2016, INT C LEARN REPR ICL; Mirza M., 2014, ARXIV PREPRINT ARXIV; Nagai T., 2002, P INT C IM PROC; Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23; Ranftl R, 2016, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2016.440; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saran R, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P300, DOI 10.1109/PDGC.2018.8745829; Saxena AK, 2005, ARKIVOC, P1, DOI 10.3998/ark.5550190.0006.201; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897; Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25; Nguyen XT, 2017, IEEE INT SYMP CIRC S, P2667; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhang Y, 2017, IEEE DECIS CONTR P	52	22	23	7	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2410	2422		10.1109/TPAMI.2019.2936024	http://dx.doi.org/10.1109/TPAMI.2019.2936024			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31442969	Green Submitted			2022-12-18	WOS:000567471300007
J	Xu, L; Su, Z; Han, L; Yu, T; Liu, YB; Fang, L				Xu, Lan; Su, Zhuo; Han, Lei; Yu, Tao; Liu, Yebin; Fang, Lu			UnstructuredFusion: Realtime 4D Geometry and Texture Reconstruction Using Commercial RGBD Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Geometry; Skeleton; Dynamics; Surface reconstruction; Image reconstruction; Videos; 4D reconstruction; performance capture; multi-camera; atlas texturing; skeleton warping; online calibration	MARKERLESS MOTION CAPTURE; TRACKING; CHARACTERS	A high-quality 4D geometry and texture reconstruction for human activities usually requires multiview perceptions via highly structured multi-camera setup, where both the specifically designed cameras and the tedious pre-calibration restrict the popularity of professional multi-camera systems for daily applications. In this paper, we propose UnstructuredFusion, a practicable realtime markerless human performance capture method using unstructured commercial RGBD cameras. Along with the flexible hardware setup using simply three unstructured RGBD cameras without any careful pre-calibration, the challenge 4D reconstruction through multiple asynchronous videos is solved by proposing three novel technique contributions, i.e., online multi-camera calibration, skeleton warping based non-rigid tracking, and temporal blending based atlas texturing. The overall insights behind lie in the solid global constraints of human body and human motion which are modeled by the skeleton and the skeleton warping, respectively. Extensive experiments such as allocating three cameras flexibly in a handheld way demonstrate that the proposed UnstructuredFusion achieves high-quality 4D geometry and texture reconstruction without tiresome pre-calibration, liberating the cumbersome hardware and software restrictions in conventional structured multi-camera system, while eliminating the inherent occlusion issues of the single camera setup.	[Xu, Lan; Su, Zhuo; Han, Lei; Fang, Lu] Tsinghua Univ, Tsinghua Berkeley Shenzhen Inst, Beijing 100091, Peoples R China; [Xu, Lan; Han, Lei] Hong Kong Univ Sci & Technol, Dept ECE, Hong Kong, Peoples R China; [Liu, Yebin] Tsinghua Univ, Dept Automat, Beijing 100091, Peoples R China; [Yu, Tao] Beihang Univ, Beijing 100091, Peoples R China	Tsinghua University; Hong Kong University of Science & Technology; Tsinghua University; Beihang University	Fang, L (corresponding author), Tsinghua Univ, Tsinghua Berkeley Shenzhen Inst, Beijing 100091, Peoples R China.	lxuan@connect.ust.hk; su-z18@mails.tsinghua.edu.cn; lhanaf@connect.ust.hka; ytrock@buaa.edu.cn; liuyebin@mail.tsinghua.edu.cn; fanglu@sz.tsinghua.edu.cn		Su, Zhuo/0000-0002-7728-0835; Xu, Lan/0000-0002-8807-7787	Natural Science Foundation of China (NSFC) [61722209, 6181001011, 61827805]	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work is supported in part by Natural Science Foundation of China (NSFC) under contract No. 61722209, 6181001011 and 61827805.	Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684; Bi S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073610; Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b; Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945; Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801; Du RF, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190843; Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141; Guo K., 2017, ACM T GRAPHIC, V36, p44a, DOI 10.1145/3072959.3083722; Guo KW, 2015, IEEE I CONF COMP VIS, P3083, DOI 10.1109/ICCV.2015.353; Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970; Han L, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Han L, 2019, IEEE T ROBOT, V35, P498, DOI 10.1109/TRO.2018.2882730; Hasler N, 2009, PROC CVPR IEEE, P224, DOI 10.1109/CVPRW.2009.5206859; Huang JW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130824; Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323; Innmann M, 2016, LECT NOTES COMPUT SC, V9912, P362, DOI 10.1007/978-3-319-46484-8_22; Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868; Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381; Kao HT, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON BEHAVIORAL, ECONOMIC, AND SOCIO-CULTURAL COMPUTING (BESC), P156, DOI [10.1109/BESC.2018.00040, 10.1109/BESC.2018.8697325]; Li H, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1618521, 10.1145/1618452.1618503]; Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350; Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995; Liu YB, 2013, IEEE T PATTERN ANAL, V35, P2720, DOI 10.1109/TPAMI.2013.47; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517; Prada F, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201317; Schwarz LA, 2010, LECT NOTES COMPUT SC, V6169, P192, DOI 10.1007/978-3-642-14061-7_19; Shiratori T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964926; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Slavcheva M, 2018, PROC CVPR IEEE, P2646, DOI 10.1109/CVPR.2018.00280; Slavcheva M, 2017, PROC CVPR IEEE, P5474, DOI 10.1109/CVPR.2017.581; Soucy M, 1996, VISUAL COMPUT, V12, P503, DOI 10.1007/s003710050082; Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338; Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531; Vicon, 2016, VIC SYST; Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54; Wang RZ, 2016, LECT NOTES COMPUT SC, V9911, P271, DOI 10.1007/978-3-319-46478-7_17; WOLTRING HJ, 1974, BIOTELEMETRY, V1, P132; Wu CL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508418; Xiang D., 2018, ARXIV181201598; Xu L, 2018, IEEE T VIS COMPUT GR, V24, P2284, DOI 10.1109/TVCG.2017.2728660; Xu W., 2018, CORR; Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59; Yu T., 2019, IEEE C COMP VIS PATT; Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761; Yu T, 2017, IEEE I CONF COMP VIS, P910, DOI 10.1109/ICCV.2017.104; Zhang PZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661286; Zheng ZR, 2018, LECT NOTES COMPUT SC, V11213, P389, DOI 10.1007/978-3-030-01240-3_24; Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783; Zhou K., 2004, S GEOMETRY PROCESSIN, P45; Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134	62	22	23	2	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2508	2522		10.1109/TPAMI.2019.2915229	http://dx.doi.org/10.1109/TPAMI.2019.2915229			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31071018				2022-12-18	WOS:000567471300014
J	Kim, C; Klabjan, D				Kim, Cheolmin; Klabjan, Diego			A Simple and Fast Algorithm for L1-Norm Kernel PCA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Principal component analysis; Kernel; Matrix decomposition; Convergence; Anomaly detection; Loading; Sparse matrices; Principal component analysis; L1-norm; kernel; outlier detection	ROBUST PCA	We present an algorithm for L1-norm kernel PCA and provide a convergence analysis for it. While an optimal solution of L2-norm kernel PCA can be obtained through matrix decomposition, finding that of L1-norm kernel PCA is not trivial due to its non-convexity and non-smoothness. We provide a novel reformulation through which an equivalent, geometrically interpretable problem is obtained. Based on the geometric interpretation of the reformulated problem, we present a "fixed-point" type algorithm that iteratively computes a binary weight for each observation. As the algorithm requires only inner products of data vectors, it is computationally efficient and the kernel trick is applicable. In the convergence analysis, we show that the algorithm converges to a local optimal solution in a finite number of steps. Moreover, we provide a rate of convergence analysis, which has been never done for any L1-norm PCA algorithm, proving that the sequence of objective values converges at a linear rate. In numerical experiments, we show that the algorithm is robust in the presence of entry-wise perturbations and computationally scalable, especially in a large-scale setting. Lastly, we introduce an application to outlier detection where the model based on the proposed algorithm outperforms the benchmark algorithms.	[Kim, Cheolmin; Klabjan, Diego] Northwestern Univ, Dept Ind Engn & Management Sci, Evanston, IL 60208 USA	Northwestern University	Kim, C (corresponding author), Northwestern Univ, Dept Ind Engn & Management Sci, Evanston, IL 60208 USA.	cheolmkim@u.northwestern.edu; d-klabjan@northwestern.edu	Klabjan, Diego/B-7469-2009					Boyd S, 2004, CONVEX OPTIMIZATION; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Brooks JP, 2013, COMPUT STAT DATA AN, V61, P83, DOI 10.1016/j.csda.2012.11.007; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Golub G. H., 2012, MATRIX COMPUTATIONS, V3; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Karystinos GN, 2010, IEEE T INFORM THEORY, V56, P3581, DOI 10.1109/TIT.2010.2048450; Ke QF, 2005, PROC CVPR IEEE, P739; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Kwak N, 2013, IEEE T NEUR NET LEAR, V24, P2113, DOI 10.1109/TNNLS.2013.2272292; Lichman M., 2013, UCI MACHINE LEARNING; Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17; Liu G., 2014, P ADV NEUR INF PROC, P1206; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2017, IEEE T PATTERN ANAL, V39, P47, DOI 10.1109/TPAMI.2016.2539946; Liu GC, 2016, IEEE T PATTERN ANAL, V38, P417, DOI 10.1109/TPAMI.2015.2453969; Markopoulos PP, 2014, IEEE T SIGNAL PROCES, V62, P5046, DOI 10.1109/TSP.2014.2338077; McCoy M, 2011, ELECTRON J STAT, V5, P1123, DOI 10.1214/11-EJS636; Nesterov Y, 1998, OPTIM METHOD SOFTW, V9, P141, DOI 10.1080/10556789808805690; Nie F., 2011, PROC INT JOINT C ART, P1433; Park Y-H, 2015, THESIS; Park YW, 2018, KNOWL INF SYST, V54, P541, DOI 10.1007/s10115-017-1069-6; Park YW, 2016, IEEE DATA MINING, P430, DOI [10.1109/ICDM.2016.14, 10.1109/ICDM.2016.0054]; Rayana S., 2016, ODDS LIB; Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217; Shyu M. L., 2003, P IEEE FDN NEW DIR D, P172; Xiao YC, 2013, PATTERN RECOGN, V46, P389, DOI 10.1016/j.patcog.2012.06.017; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156	31	22	24	3	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1842	1855		10.1109/TPAMI.2019.2903505	http://dx.doi.org/10.1109/TPAMI.2019.2903505			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30843821	Green Submitted			2022-12-18	WOS:000545415400003
J	Horiguchi, S; Ikami, D; Aizawa, K				Horiguchi, Shota; Ikami, Daiki; Aizawa, Kiyoharu			Significance of Softmax-Based Features in Comparison to Distance Metric Learning-Based Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Measurement; Principal component analysis; Dimensionality reduction; Network architecture; Automobiles; Task analysis; Deep learning; distance metric learning; classification; retrieval		End-to-end distance metric learning (DML) has been applied to obtain features useful in many computer vision tasks. However, these DML studies have not provided equitable comparisons between features extracted from DML-based networks and softmax-based networks. In this paper, we present objective comparisons between these two approaches under the same network architecture.	[Horiguchi, Shota; Ikami, Daiki; Aizawa, Kiyoharu] Univ Tokyo, Dept Informat & Commun Engn, Bunkyo Ku, Tokyo 1338656, Japan	University of Tokyo	Aizawa, K (corresponding author), Univ Tokyo, Dept Informat & Commun Engn, Bunkyo Ku, Tokyo 1338656, Japan.	horiguchi@halt.u-okyo.acjp; ikami@halt.u-okyo.acjp; aizawa@halt.u-okyo.acjp	Horiguchi, Shota/HDN-2832-2022	Horiguchi, Shota/0000-0002-3166-4956	JST CREST [JPMJCR19F4]; JSPS KAKENHI [18H03254]	JST CREST(Japan Science & Technology Agency (JST)Core Research for Evolutional Science and Technology (CREST)); JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work is partially supported by JST CREST JPMJCR19F4 and JSPS KAKENHI 18H03254.	Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Castrejon L, 2016, PROC CVPR IEEE, P2940, DOI 10.1109/CVPR.2016.321; Chechik G, 2010, J MACH LEARN RES, V11, P1109; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Donahue J, 2014, PR MACH LEARN RES, V32; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jia Y., 2014, P 22 ACM INT C MULT, P675; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin TY, 2015, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2015.7299135; Liu Y, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P43, DOI 10.1145/2671188.2749300; Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sohn K, 2016, ADV NEUR IN, V29; Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948; Wei LY, 2016, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2016.171; Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93	32	22	22	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1279	1285		10.1109/TPAMI.2019.2911075	http://dx.doi.org/10.1109/TPAMI.2019.2911075			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30990420	hybrid, Green Submitted			2022-12-18	WOS:000523685800020
J	Chang, JL; Meng, GF; Wang, LF; Xiang, SM; Pan, CH				Chang, Jianlong; Meng, Gaofeng; Wang, Lingfeng; Xiang, Shiming; Pan, Chunhong			Deep Self-Evolution Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Unsupervised learning; Training; Clustering methods; Pattern analysis; Clustering; deep self-evolution clustering; self-evolution clustering training; deep unsupervised learning	IMAGE RETRIEVAL; REPRESENTATIONS	Clustering is a crucial but challenging task in pattern analysis and machine learning. Existing methods often ignore the combination between representation learning and clustering. To tackle this problem, we reconsider the clustering task from its definition to develop Deep Self-Evolution Clustering (DSEC) to jointly learn representations and cluster data. For this purpose, the clustering task is recast as a binary pairwise-classification problem to estimate whether pairwise patterns are similar. Specifically, similarities between pairwise patterns are defined by the dot product between indicator features which are generated by a deep neural network (DNN). To learn informative representations for clustering, clustering constraints are imposed on the indicator features to represent specific concepts with specific representations. Since the ground-truth similarities are unavailable in clustering, an alternating iterative algorithm called Self-Evolution Clustering Training (SECT) is presented to select similar and dissimilar pairwise patterns and to train the DNN alternately. Consequently, the indicator features tend to be one-hot vectors and the patterns can be clustered by locating the largest response of the learned indicator features. Extensive experiments strongly evidence that DSEC outperforms current models on twelve popular image, text and audio datasets consistently.	[Chang, Jianlong; Meng, Gaofeng; Wang, Lingfeng; Xiang, Shiming; Pan, Chunhong] Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Chang, Jianlong; Xiang, Shiming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Wang, LF (corresponding author), Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	jianlong.chang@nlpr.ia.ac.cn; gfmeng@nlpr.ia.ac.cn; lingfeng.wang@ia.ac.cn; smxiang@nlpr.ia.ac.cn; chpan@nlpr.ia.ac.cn		wang, ling feng/0000-0003-3707-0267	National Natural Science Foundation of China [91646207, 61773377, 61573352]; Beijing Natural Science Foundation [L172053]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work was supported by the National Natural Science Foundation of China under Grants 91646207, 61773377, and 61573352, and the Beijing Natural Science Foundation under Grant L172053. Wewould like to thank Lele Yu, Jie Gu, Cheng Da, and Tingzhao Yu for their invaluable contributions in shaping the early stage of thiswork.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2015, CORR; [Anonymous], THEAN DEEP LEARN TUT; [Anonymous], 2013, INT J DATA ANAL TECH; [Anonymous], CORR; [Anonymous], 2012, NIPS; [Anonymous], 2015, CORR; Bahmani B, 2012, PROC VLDB ENDOW, V5, P622, DOI 10.14778/2180912.2180915; Bengio Y, 2006, P 19 INT C NEUR INF, P153; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Caterini AL, 2018, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-75304-1_2; Chang JL, 2018, PATTERN RECOGN, V77, P438, DOI 10.1016/j.patcog.2017.10.022; Chang JL, 2017, IEEE I CONF COMP VIS, P5880, DOI 10.1109/ICCV.2017.626; Chollet F., 2015, KERAS; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; De la Torre Fernando, 2006, P 23 INT C MACH LEAR, DOI DOI 10.1145/1143844.1143875; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dilokthanakul N., 2016, CORR; Fanti C, 2004, ADV NEUR IN, V16, P1603; Feng LN, 2016, IEEE T PATTERN ANAL, V38, P785, DOI 10.1109/TPAMI.2015.2469281; Franti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227; Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Gross CG, 2002, NEUROSCIENTIST, V8, P512, DOI 10.1177/107385802237175; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hong S, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487982; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Husain SS, 2017, IEEE T PATTERN ANAL, V39, P1783, DOI 10.1109/TPAMI.2016.2613873; Kingma D.P., 2013, P 2 INT C LEARN REPR; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Li T, 2006, IEEE DATA MINING, P362; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ng A, 2011, ELGAR LAW TECH SOC, P1; Thinh NT, 2017, INT CONF SYST SCI EN, P1, DOI 10.1109/ICSSE.2017.8030825; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642; Paulin M, 2017, INT J COMPUT VISION, V121, P149, DOI 10.1007/s11263-016-0924-3; Purkait P, 2017, IEEE T PATTERN ANAL, V39, P1697, DOI 10.1109/TPAMI.2016.2614980; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072; Ross AJ, 2015, MON NOT R ASTRON SOC, V449, P835, DOI 10.1093/mnras/stv154; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang JF, 2015, IEEE T KNOWL DATA EN, V27, P180, DOI 10.1109/TKDE.2014.2324592; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Wang WT, 2015, INT CONF MACH LEARN, P445, DOI 10.1109/ICMLC.2015.7340962; Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722; Xie JY, 2016, PR MACH LEARN RES, V48; Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556; Yang ZR, 2016, J MACH LEARN RES, V17; Ye J., 2007, PROC NIPS 07, V20, P1649; Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137	70	22	23	5	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					809	823		10.1109/TPAMI.2018.2889949	http://dx.doi.org/10.1109/TPAMI.2018.2889949			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30596571				2022-12-18	WOS:000526541100004
J	Wang, LZ; Xiong, ZW; Huang, H; Shi, GM; Wu, F; Zeng, WJ				Wang, Lizhi; Xiong, Zhiwei; Huang, Hua; Shi, Guangming; Wu, Feng; Zeng, Wenjun			High-Speed Hyperspectral Video Acquisition By Combining Nyquist and Compressive Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Compressive sampling; computational reconstruction; hybrid imaging; hyperspectral video; simultaneous sparsity	SIMULTANEOUS SPARSE APPROXIMATION; IMAGING SPECTROMETER; ALGORITHMS; RESOLUTION; SYSTEM; RESTORATION; DESIGN; FLOW	We propose a novel hybrid imaging system to acquire 4D high-speed hyperspectral (HSHS) videos with high spatial and spectral resolution. The proposed system consists of two branches: one branch performs Nyquist sampling in the temporal dimension while integrating the whole spectrum, resulting in a high-frame-rate panchromatic video; the other branch performs compressive sampling in the spectral dimension with longer exposures, resulting in a low-frame-rate hyperspectral video. Owing to the high light throughput and complementary sampling, these two branches jointly provide reliable measurements for recovering the underlying HSHS video. Moreover, the panchromatic video can be used to learn an over-complete 3D dictionary to represent each band-wise video sparsely, thanks to the inherent structural similarity in the spectral dimension. Based on the joint measurements and the self-adaptive dictionary, we further propose a simultaneous spectral sparse (3S) model to reinforce the structural similarity across different bands and develop an efficient computational reconstruction algorithm to recover the HSHS video. Both simulation and hardware experiments validate the effectiveness of the proposed approach. To the best of our knowledge, this is the first time that hyperspectral videos can be acquired at a frame rate up to 100fps with commodity optical elements and under ordinary indoor illumination.	[Wang, Lizhi; Huang, Hua] Beijing Inst Technol, Beijing 100081, Peoples R China; [Xiong, Zhiwei; Wu, Feng] Univ Sci & Technol China, Hefei 230026, Anhui, Peoples R China; [Shi, Guangming] Xidian Univ, Xian 710071, Shaanxi, Peoples R China; [Zeng, Wenjun] Microsoft Res, Beijing 100080, Peoples R China	Beijing Institute of Technology; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Xidian University; Microsoft	Xiong, ZW (corresponding author), Univ Sci & Technol China, Hefei 230026, Anhui, Peoples R China.	lzwang@bit.edu.cn; zwxiong@ustc.edu.cn; huahuang@bit.edu.cn; gmshi@xidian.edu.cn; fengwu@ustc.edu.cn; wezeng@microsoft.com		Wang, Lizhi/0000-0002-1953-3339	National Natural Science Foundation of China [61671419, 61425026, 61425013, 61701025, 61621005]; CAS Pioneer Hundred Talents Program	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CAS Pioneer Hundred Talents Program	This work was partially supported by the National Natural Science Foundation of China (Nos. 61671419, 61425026, 61425013, 61701025, 61621005) and the CAS Pioneer Hundred Talents Program. L. Wang and Z. Xiong are co-first authors.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Arce GR, 2014, IEEE SIGNAL PROC MAG, V31, P105, DOI 10.1109/MSP.2013.2278763; Bao J, 2015, NATURE, V523, P67, DOI 10.1038/nature14576; BASEDOW RW, 1995, P SOC PHOTO-OPT INS, V2480, P258, DOI 10.1117/12.210881; Basiji DA, 2007, CLIN LAB MED, V27, P653, DOI 10.1016/j.cll.2007.05.008; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Bodkin A., 2009, P SOC PHOTO-OPT INS, V7334, P17; Borengasser M., 2007, HYPERSPECTRAL REMOTE; Brady DJ, 2012, NATURE, V486, P386, DOI 10.1038/nature11150; Brady David J., 2009, OPTICAL IMAGING SPEC; Candes EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002; Cao X, 2016, IEEE SIGNAL PROC MAG, V33, P95, DOI 10.1109/MSP.2016.2582378; Cao X, 2011, PROC CVPR IEEE, P297, DOI 10.1109/CVPR.2011.5995418; Cao X, 2011, IEEE T PATTERN ANAL, V33, P2423, DOI 10.1109/TPAMI.2011.80; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; DESCOUR M, 1995, APPL OPTICS, V34, P4817, DOI 10.1364/AO.34.004817; Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y; Du H, 2009, IEEE I CONF COMP VIS, P175, DOI 10.1109/ICCV.2009.5459162; Eikenberry S, 2004, PROC SPIE, V5492, P1264, DOI 10.1117/12.549150; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Gao L, 2016, PHYS REP, V616, P1, DOI 10.1016/j.physrep.2015.12.004; Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Gleichman S, 2011, IEEE T INFORM THEORY, V57, P6958, DOI 10.1109/TIT.2011.2165821; Horstmeyer R., 2009, 2009 IEEE INT C COMP, P1, DOI DOI 10.1109/ICCPHOT.2009.5559016; Huang JZ, 2011, J MACH LEARN RES, V12, P3371; Huang JZ, 2010, ANN STAT, V38, P1978, DOI 10.1214/09-AOS778; James J.F., 2007, SPECTROGRAPH DESIGN; Kim MH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185534; Kittle D, 2010, APPL OPTICS, V49, P6824, DOI 10.1364/AO.49.006824; KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N; Lin RP, 2002, SOL PHYS, V210, P3, DOI 10.1023/A:1022428818870; Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262; Lin X, 2014, OPT LETT, V39, P2044, DOI 10.1364/OL.39.002044; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Llull P, 2013, OPT EXPRESS, V21, P10526, DOI 10.1364/OE.21.010526; Ma CG, 2014, INT J COMPUT VISION, V110, P141, DOI 10.1007/s11263-013-0690-4; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Matsuoka H, 2002, J BIOTECHNOL, V94, P299, DOI 10.1016/S0168-1656(01)00431-X; Mian A, 2012, OPT EXPRESS, V20, P10658, DOI 10.1364/OE.20.010658; OKAMOTO T, 1991, OPT LETT, V16, P1277, DOI 10.1364/OL.16.001277; Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148; Porter WM., 1987, P SOC PHOTO-OPT INS, P22, DOI DOI 10.1117/12.942280; Rajwade A, 2013, SIAM J IMAGING SCI, V6, P782, DOI 10.1137/120875302; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tsai TH, 2015, OPT LETT, V40, P4054, DOI 10.1364/OL.40.004054; Van Nguyen H., 2010, P IEEE COMP VIS PATT, P44; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wagadarikar AA, 2009, OPT EXPRESS, V17, P6368, DOI 10.1364/OE.17.006368; Wang LZ, 2015, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2015.7299128; Wang LZ, 2015, APPL OPTICS, V54, P848, DOI 10.1364/AO.54.000848; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Yuan X, 2015, IEEE J-STSP, V9, P964, DOI 10.1109/JSTSP.2015.2411575; Yuan Y, 2017, PROC INT CONF ANTI, P1; Zheng HT, 2017, IEEE INT CONF COMP V, P2481, DOI 10.1109/ICCVW.2017.292	59	22	23	1	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					857	870		10.1109/TPAMI.2018.2817496	http://dx.doi.org/10.1109/TPAMI.2018.2817496			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29994146				2022-12-18	WOS:000460583500006
J	Li, CS; Wei, F; Dong, WS; Wang, XF; Liu, QS; Zhang, X				Li, Changsheng; Wei, Fan; Dong, Weishan; Wang, Xiangfeng; Liu, Qingshan; Zhang, Xin			Dynamic Structure Embedded Online Multiple-Output Regression for Streaming Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Online multiple-output regression; dynamic relationship learning; forgetting factor; lossless compression	MULTIVARIATE REGRESSION; EXPONENTIATED GRADIENT	Online multiple-output regression is an important machine learning technique for modeling, predicting, and compressing multi-dimensional correlated data streams. In this paper, we propose a novel online multiple-output regression method, called MORES, for streaming data. MORES can dynamically learn the structure of the regression coefficients to facilitate the model's continuous refinement. Considering that limited expressive ability of regression models often leading to residual errors being dependent, MORES intends to dynamically learn and leverage the structure of the residual errors to improve the prediction accuracy. Moreover, we introduce three modified covariance matrices to extract necessary information from all the seen data for training, and set different weights on samples so as to track the data streams' evolving characteristics. Furthermore, an efficient algorithm is designed to optimize the proposed objective function, and an efficient online eigen value decomposition algorithm is developed for the modified covariance matrix. Finally, we analyze the convergence of MORES in certain ideal condition. Experiments on two synthetic datasets and three real-world datasets validate the effectiveness and efficiency of MORES. In addition, MORES can process at least 2,000 instances per second (including training and testing) on the three real-world datasets, more than 12 times faster than the state-of-the-art online learning algorithm.	[Li, Changsheng] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China; [Li, Changsheng] Univ Elect Sci & Technol China, Big Data Res Ctr, Chengdu, Sichuan, Peoples R China; [Wei, Fan] Standford Univ, Dept Math, Stanford, CA 94305 USA; [Dong, Weishan] Baidu Search, Beijing 100085, Peoples R China; [Wang, Xiangfeng] East China Normal Univ, Inst Software Engn, Shanghai 200241, Peoples R China; [Liu, Qingshan] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, B DAT Lab, Nanjing 210044, Jiangsu, Peoples R China; [Zhang, Xin] IBM Res, Beijing 100094, Peoples R China	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; East China Normal University; Nanjing University of Information Science & Technology	Li, CS (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.; Li, CS (corresponding author), Univ Elect Sci & Technol China, Big Data Res Ctr, Chengdu, Sichuan, Peoples R China.	lichangsheng@uestc.edu.cn; fanwei@math.stanford.edu; dongweishan@baidu.com; xfwang@sei.ecnu.edu.cn; qsliu@nuist.edu.cn; xzhang@cn.ibm.com	Liu, Qing/GWC-9222-2022; liu, qingqing/HHD-0360-2022		University of Electronic Science and Technology of China [ZYGX2017KYQD178]; National Natural Science Foundation of China [61532009, 11501210, 61672231]	University of Electronic Science and Technology of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the Starting Research Fund from University of Electronic Science and Technology of China under Grant ZYGX2017KYQD178, in part by the National Natural Science Foundation of China under Grant 61532009, 11501210 and 61672231. Part of the work was done when the Changsheng Li was in IBM Research-China.	Aggarwal CC, 2006, IEEE T KNOWL DATA EN, V18, P577, DOI 10.1109/TKDE.2006.69; Aggarwal CC, 2003, P 2003 VLDB C, V29, P81, DOI 10.1016/b978-012722442-8/50016-1; Ammar HB, 2014, PR MACH LEARN RES, V32, P1206; [Anonymous], [No title captured]; [Anonymous], 2012, ADV NEURAL INFORM PR; [Anonymous], 2013, INT JOINT C ARTIFICI; Cavallanti G, 2010, J MACH LEARN RES, V11, P2901; Chen YX, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P133; Chu W., 2011, P 17 ACM SIGKDD INT, P195; Crammer K, 2006, J MACH LEARN RES, V7, P551; Dekel O, 2007, J MACH LEARN RES, V8, P2233; Dekel O, 2006, LECT NOTES ARTIF INT, V4005, P453, DOI 10.1007/11776420_34; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107; Gonen M, 2014, IEEE T PATTERN ANAL, V36, P2047, DOI 10.1109/TPAMI.2014.2313125; Han J, 2012, MOR KAUF D, P1; Ho SS, 2010, IEEE T PATTERN ANAL, V32, P2113, DOI 10.1109/TPAMI.2010.48; Kim S, 2012, ANN APPL STAT, V6, P1095, DOI 10.1214/12-AOAS549; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; Kumar A., 2012, INT C MACH LEARN; Lee W, 2012, J MULTIVARIATE ANAL, V111, P241, DOI 10.1016/j.jmva.2012.03.013; Leng C, 2015, PROC CVPR IEEE, P2503, DOI 10.1109/CVPR.2015.7298865; Li CS, 2015, IEEE T CYBERNETICS, V45, P2522, DOI 10.1109/TCYB.2014.2376517; Liberty E, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P581, DOI 10.1145/2487575.2487623; Liu H., 2014, ADV NEURAL INFORM PR, P127; Lozano AC, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P293; Ma JS, 2003, NEURAL COMPUT, V15, P2683, DOI 10.1162/089976603322385117; McWilliams Brian, 2010, Statistical Analysis and Data Mining, V3, P170, DOI 10.1002/sam.10074; Montana G, 2008, LECT NOTES ARTIF INT, V5271, P591, DOI 10.1007/978-3-540-87656-4_73; Muhlbaier MD, 2009, IEEE T NEURAL NETWOR, V20, P152, DOI 10.1109/TNN.2008.2008326; Nguyen-Tuong D, 2009, ADV ROBOTICS, V23, P2015, DOI 10.1163/016918609X12529286896877; Rothman AJ, 2010, J COMPUT GRAPH STAT, V19, P947, DOI 10.1198/jcgs.2010.09188; Ruvolo P., 2013, P 30 INT C MACHINE L, P507; Ruvolo P, 2014, AAAI CONF ARTIF INTE, P2062; Saha A., 2011, PROC INT C ARTIF INT, P643; Sanchez-Fernadez M, 2004, IEEE T SIGNAL PROCES, V52, P2298, DOI 10.1109/TSP.2004.831028; Sohn K.-A., 2012, P 15 INT C ARTIFICIA, P1081; Sun BY, 2010, IEEE T KNOWL DATA EN, V22, P906, DOI 10.1109/TKDE.2009.170; Wang CD, 2013, IEEE T KNOWL DATA EN, V25, P1410, DOI 10.1109/TKDE.2011.263; Wang JL, 2014, IEEE T KNOWL DATA EN, V26, P698, DOI 10.1109/TKDE.2013.32; Weinberger K.Q., P ADV NEURAL INFORM, P1473; Wu XD, 2013, IEEE T PATTERN ANAL, V35, P1178, DOI 10.1109/TPAMI.2012.197; Zhu XQ, 2007, IEEE DATA MINING, P757, DOI 10.1109/ICDM.2007.101; Zliobaite I, 2014, IEEE T NEUR NET LEAR, V25, P27, DOI 10.1109/TNNLS.2012.2236570	45	22	23	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					323	336		10.1109/TPAMI.2018.2794446	http://dx.doi.org/10.1109/TPAMI.2018.2794446			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994559				2022-12-18	WOS:000456150600005
J	Kafai, M; Eshghi, K				Kafai, Mehran; Eshghi, Kave			CROification: Accurate Kernel Classification with the Efficiency of Sparse Linear SVM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel method; SVM; concomitant rank order; classification; feature map		Kernel methods have been shown to be effective for many machine learning tasks such as classification and regression. In particular, support vector machines with the Gaussian kernel have proved to be powerful classification tools. The standard way to apply kernel methods is to use the kernel trick, where the inner product of the vectors in the feature space is computed via the kernel function. Using the kernel trick for SVMs, however, leads to training that is quadratic in the number of input vectors and classification that is linear with the number of support vectors. We introduce a new kernel, the CRO (Concomitant Rank Order) kernel that approximates the Gaussian kernel on the unit sphere. We also introduce a randomized feature map, called the CRO feature map that produces sparse, high-dimensional feature vectors whose inner product asymptotically equals the CRO kernel. Using the Discrete Cosine Transform for computing the CRO feature map ensures that the cost of computing feature vectors is low, allowing us to compute the feature map explicitly. Combining the CRO feature map with linear SVM we introduce the CROification algorithm which gives us the efficiency of a sparse high-dimensional linear SVM with the accuracy of the Gaussian kernel SVM.	[Kafai, Mehran] Amazon A9 Visual Search, Palo Alto, CA 94301 USA; [Eshghi, Kave] Box Inc, Redwood City, CA 94063 USA		Kafai, M (corresponding author), Amazon A9 Visual Search, Palo Alto, CA 94301 USA.	mkafai@amazon.com; keshghi@box.com						Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chang Y.W., 2010, J MACH LEARN RES, V11, P1471, DOI DOI 10.5555/1756006.1859899; Collobert R., 2011, NIPS; Dembinska A, 2014, STOCH PROC APPL, V124, P348, DOI 10.1016/j.spa.2013.08.001; Eshghi K., 2008, P 14 ACM SIGKDD INT, P221, DOI DOI 10.1145/1401890.1401921; Eshghi K, 2016, PROC INT CONF DATA, P721, DOI 10.1109/ICDE.2016.7498284; Garofolo J. S., 1993, LINGUISTIC DATA CONS; Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Joachims T, 2009, MACH LEARN, V76, P179, DOI 10.1007/s10994-009-5126-6; Kafai M, 2014, IEEE T MULTIMEDIA, V16, P1090, DOI 10.1109/TMM.2014.2305633; Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928; Le Q., 2013, ICML; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li P, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P315, DOI 10.1145/3097983.3098081; Litayem S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.86; Lu Z., 2014, CORR; Nandan M, 2014, J MACH LEARN RES, V15, P59; Pham N, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P239, DOI 10.1145/2487575.2487591; Po-Sen Huang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P205, DOI 10.1109/ICASSP.2014.6853587; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; Ristin M, 2016, IEEE T PATTERN ANAL, V38, P490, DOI 10.1109/TPAMI.2015.2459678; Segata N, 2010, J MACH LEARN RES, V11, P1883; SIBUYA M, 1960, ANN I STAT MATH, V11, P195, DOI 10.1007/BF01682329; Siddiqui M. M., 1960, J RES NATL INST STAN, V64, P124; Sivertsen J. von Tangen, 2014, THESIS; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Su YC, 2014, IEEE T MULTIMEDIA, V16, P1645, DOI 10.1109/TMM.2014.2322337; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Vasicek O. A., 2000, J COMPUT FINANC, V1, P5; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Weinberger K., 2009, P 26 ANN INT C MACH, P1113, DOI DOI 10.1145/1553374.1553516; Wu LF, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1265, DOI 10.1145/2939672.2939794; Yen I.E.-H., 2014, ADV NEURAL INF PROCE, P2456	36	22	24	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					34	48		10.1109/TPAMI.2017.2785313	http://dx.doi.org/10.1109/TPAMI.2017.2785313			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990038				2022-12-18	WOS:000452434800004
J	Liu, HF; Tao, ZQ; Fu, Y				Liu, Hongfu; Tao, Zhiqiang; Fu, Yun			Partition Level Constrained Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Constrained clustering; utility function; partition level; cosegmentation	K-MEANS; SALIENCY DETECTION; ALGORITHMS; MODEL	Constrained clustering uses pre-given knowledge to improve the clustering performance. Here we use a new constraint called partition level side information and propose the Partition Level Constrained Clustering (PLCC) framework, where only a small proportion of the data is given labels to guide the procedure of clustering. Our goal is to find a partition which captures the intrinsic structure from the data itself, and also agrees with the partition level side information. Then we derive the algorithm of partition level side information based on K-means and give its corresponding solution. Further, we extend it to handle multiple side information and design the algorithm of partition level side information for spectral clustering. Extensive experiments demonstrate the effectiveness and efficiency of our method compared to pairwise constrained clustering and ensemble clustering methods, even in the inconsistent cluster number setting, which verifies the superiority of partition level side information to pairwise constraints. Besides, our method has high robustness to noisy side information, and we also validate the performance of our method with multiple side information. Finally, the image cosegmentation application based on saliency-guided side information demonstrates the effectiveness of PLCC as a flexible framework in different domains, even with the unsupervised side information.	[Liu, Hongfu; Tao, Zhiqiang] Northeastern Univ, Somerville, MA 02145 USA; [Fu, Yun] Northeastern Univ, Coll Engn, Somerville, MA 02145 USA; [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Somerville, MA 02145 USA	Northeastern University; Northeastern University; Northeastern University	Liu, HF (corresponding author), Northeastern Univ, Somerville, MA 02145 USA.	hongf@husky.neu.edu; zqtaomail@gmail.com; yunfu@ece.neu.edu		Liu, Hongfu/0000-0002-4261-8154	NSF IIS award [1651902]; ONR Young Investigator Award [N00014-14-1-0484]; U.S. Army Research Office Award [W911NF-17-1-0367]	NSF IIS award(National Science Foundation (NSF)); ONR Young Investigator Award; U.S. Army Research Office Award	This research is supported in part by the NSF IIS award 1651902, ONR Young Investigator Award N00014-14-1-0484, and U.S. Army Research Office Award W911NF-17-1-0367.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1; [Anonymous], 2015, P SIAM INT C DAT MIN; Ayad HG, 2008, IEEE T PATTERN ANAL, V30, P160, DOI 10.1109/TPAMI.2007.1138; Basu S, 2003, SEMISUPERVISED CLUST; Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x; Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P407, DOI 10.1145/347090.347176; Bilenko  M., 2004, P INT C MACH LEARN, P201; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399; Coleman T., 2008, P 25 INT C MACH LEAR, P152; Covoes TF, 2013, INTELL DATA ANAL, V17, P485, DOI 10.3233/IDA-130590; Davidson I, 2005, SIAM PROC S, P138; Domeniconi C., 2009, ACM T KNOWL DISCOV D, V2, P1; Duda R.O., 2000, PATTERN CLASSIFICATI; Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Ji X., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P405, DOI 10.1145/1148170.1148241; Jiang L., 2008, 11 IEEE WORKSH DES E, P1, DOI [10.1109/CVPR.2008.4587451, DOI 10.1109/DDECS.2008.4538763>]; Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756; Li ZG, 2009, PROC CVPR IEEE, P421, DOI 10.1109/CVPRW.2009.5206852; Liu HX, 2015, AER ADV ENG RES, V23, P715; Liu HF, 2010, AAAI CONF ARTIF INTE, P506; Liu HF, 2017, BIOINFORMATICS, V33, P2691, DOI 10.1093/bioinformatics/btx167; Liu HF, 2017, IEEE T KNOWL DATA EN, V29, P1129, DOI 10.1109/TKDE.2017.2650229; Liu HF, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P715, DOI 10.1145/2783258.2783287; Liu HF, 2015, IEEE DATA MINING, P877, DOI 10.1109/ICDM.2015.18; Liu HR, 2017, DESTECH TRANS ENVIR, P1; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Mirkin B, 2001, MACH LEARN, V45, P219, DOI 10.1023/A:1010924920739; Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652; Pelleg D, 2007, LECT NOTES ARTIF INT, V4701, P674; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745; Shental N, 2004, ADV NEUR IN, V16, P465; Shepitsen A, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P259; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tao ZQ, 2017, AAAI CONF ARTIF INTE, P4285; Tao ZQ, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P367, DOI 10.1145/2983323.2983745; Topchy A, 2004, SIAM PROC S, P379; Topchy A, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P331; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Wagstaff  K., 2000, P 26 AAAI C ART INT; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wan P, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE OF NATURAL PRODUCT AND TRADITIONAL MEDICINE, VOLS 1 AND 2, P387; Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9; Wu J., 2013, P INT JOINT C ART IN, P1799; Wu JJ, 2015, IEEE T KNOWL DATA EN, V27, P155, DOI 10.1109/TKDE.2014.2316512; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Xu  Q., 2005, P 18 INT C FLOR ART, P866; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yi J., 2012, P ADV NEURAL INF PRO, P1772; Yoon HS, 2006, LECT NOTES COMPUT SC, V3916, P82; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361	66	22	22	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2469	2483		10.1109/TPAMI.2017.2763945	http://dx.doi.org/10.1109/TPAMI.2017.2763945			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	29053445	hybrid			2022-12-18	WOS:000443875500014
J	Laga, H; Xie, Q; Jermyn, IH; Srivastava, A				Laga, Hamid; Xie, Qian; Jermyn, Ian H.; Srivastava, Anuj			Numerical Inversion of SRNF Maps for Elastic Shape Analysis of Genus-Zero Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Elastic shape analysis; square-root representations; Riemannian metrics; elastic registration; shape statistics; shape modeling	SPACE; PARAMETERIZATION	Recent developments in elastic shape analysis (ESA) aremotivated by the fact that it provides a comprehensive framework for simultaneous registration, deformation, and comparison of shapes. These methods achieve computational efficiency using certain square-root representations that transform invariant elastic metrics into euclidean metrics, allowing for the application of standard algorithms and statistical tools. For analyzing shapes of embeddings of S-2 in R-3, Jermyn et al. [1] introduced square-root normal fields (SRNFs), which transform an elastic metric, with desirable invariant properties, into the L-2 metric. These SRNFs are essentially surface normals scaled by square-roots of infinitesimal area elements. A critical need in shape analysis is a method for inverting solutions (deformations, averages, modes of variations, etc.) computed in SRNF space, back to the original surface space for visualizations and inferences. Due to the lack of theory for understanding SRNF maps and their inverses, we take a numerical approach, and derive an efficient multiresolution algorithm, based on solving an optimization problem in the surface space, that estimates surfaces corresponding to given SRNFs. This solution is found to be effective even for complex shapes that undergo significant deformations including bending and stretching, e.g., human bodies and animals. We use this inversion for computing elastic shape deformations, transferring deformations, summarizing shapes, and for finding modes of variability in a given collection, while simultaneously registering the surfaces. We demonstrate the proposed algorithms using a statistical analysis of human body shapes, classification of generic surfaces, and analysis of brain structures.	[Laga, Hamid] Murdoch Univ, Sch Engn & IT, Murdoch, WA 6150, Australia; [Laga, Hamid] Univ South Australia, Phen & Bioinformat Res Ctr, Adelaide, SA 5001, Australia; [Xie, Qian; Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Jermyn, Ian H.] Univ Durham, Dept Math Sci, Durham DH1, England	Murdoch University; University of South Australia; State University System of Florida; Florida State University; Durham University	Laga, H (corresponding author), Murdoch Univ, Sch Engn & IT, Murdoch, WA 6150, Australia.; Laga, H (corresponding author), Univ South Australia, Phen & Bioinformat Res Ctr, Adelaide, SA 5001, Australia.	H.Laga@murdoch.edu.au; qxie@stat.fsu.edu; i.h.jermyn@durham.ac.uk; anuj@stat.fsu.edu	Srivastava, Anuj/L-4705-2019	Srivastava, Anuj/0000-0001-7406-0338	Durham University IAS Senior Research Fellowship (EU) [FP7-609412]; DU Department of Mathematical Sciences; Direct For Mathematical & Physical Scien [1621787] Funding Source: National Science Foundation	Durham University IAS Senior Research Fellowship (EU); DU Department of Mathematical Sciences; Direct For Mathematical & Physical Scien(National Science Foundation (NSF)NSF - Directorate for Mathematical & Physical Sciences (MPS))	The authors would like to thank: Nils Hasler for providing us with the 3D human shape models; Sebastian Kurtek for sharing programs for registration of SRNFs under the L<SUP>2</SUP> metric; Raif Rustamov and Maks Ovsjkanikov for the discussion about functional maps and for sharing their data and results. AS gratefully acknowledges support from a Durham University IAS Senior Research Fellowship (EU grant FP7-609412) and the DU Department of Mathematical Sciences.	ABE K, 1975, MATH ANN, V215, P197, DOI 10.1007/BF01343889; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Arnold V.I, 2004, ARNOLDS PROBLEMS; Arnold V.I., 1990, ADV SOV MATH, V1, P1; Berkels Benjamin, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P108, DOI 10.1007/978-3-642-40395-8_9; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bouix S., 2001, LNCS, V2208, P33, DOI DOI 10.1007/3-540-45468-3_; BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013; Burden MJ, 2010, ALCOHOL CLIN EXP RES, V34, P617, DOI 10.1111/j.1530-0277.2009.01130.x; Davies RH, 2010, IEEE T MED IMAGING, V29, P961, DOI 10.1109/TMI.2009.2035048; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Eschenburg JH, 2010, DIFFER GEOM APPL, V28, P228, DOI 10.1016/j.difgeo.2009.10.004; Giorgi D., 2007, SHREC COMPETITION, V8, P1; Gorczowski K, 2010, IEEE T PATTERN ANAL, V32, P652, DOI 10.1109/TPAMI.2009.92; Hasler N., 2009, CGF P EUROGRAPHICS, V28; Heeren B, 2012, COMPUT GRAPH FORUM, V31, P1755, DOI 10.1111/j.1467-8659.2012.03180.x; HIRSHBERG DA, 2012, P EUR C COMPUT VIS, V7577, P242; HOFFMAN DA, 1985, P LOND MATH SOC, V50, P27; Jacobson SW, 2004, ALCOHOL CLIN EXP RES, V28, P1732, DOI 10.1097/01.ALC.0000145691.81233.FA; Jermyn I., 2012, IEEE EUR C COMP VIS, V5, P805; Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276457, 10.1145/1239451.1239515]; Klassen E., COMMUNICATION; Kurtek S, 2013, COMPUT GRAPH FORUM, V32, P429, DOI 10.1111/cgf.12063; Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233; Kurtek S, 2011, LECT NOTES COMPUT SC, V6801, P147, DOI 10.1007/978-3-642-22092-0_13; Kurtek S, 2011, IEEE T MED IMAGING, V30, P849, DOI 10.1109/TMI.2010.2099130; Lavoue G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x; Michor P., 2017, REPRESENTING IMMERSI; Osher S, 2002, APPL MATH SCI; Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Styner Martin, 2006, Insight J, P242; Tabia H, 2014, PROC CVPR IEEE, P4185, DOI 10.1109/CVPR.2014.533; Tabia H, 2011, IEEE T PATTERN ANAL, V33, P852, DOI 10.1109/TPAMI.2010.202; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Windheuser T, 2011, IEEE I CONF COMP VIS, P2134, DOI 10.1109/ICCV.2011.6126489; Xie Q, 2013, IEEE I CONF COMP VIS, P865, DOI 10.1109/ICCV.2013.112; Xie Q, 2014, LECT NOTES COMPUT SC, V8693, P485, DOI 10.1007/978-3-319-10602-1_32; Yeo BTT, 2008, IEEE T IMAGE PROCESS, V17, P283, DOI 10.1109/TIP.2007.915550; Zhang C, 2015, IEEE I CONF COMP VIS, P1671, DOI 10.1109/ICCV.2015.195; Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x	41	22	22	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2451	2464		10.1109/TPAMI.2016.2647596	http://dx.doi.org/10.1109/TPAMI.2016.2647596			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28103188	Green Submitted, Green Accepted			2022-12-18	WOS:000414395400010
J	Zhang, ZY; Zhai, Z; Li, LM				Zhang, Zhenyue; Zhai, Zheng; Li, Limin			Uniform Projection for Multi-View Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view learning; low-dimensional projection; clustering; unsupervised learning	FUSION	Multi-view learning aims to integrate multiple data information from different views to improve the learning performance. The key problem is to handle the unconformities or distortions among view-specific samples or measurements of similarity or dissimilarity. This paper models the view-specific samples as a nonlinear mapping of uniform but latent intact samples for all the views, and the view-specific dissimilarity matrices or similarity matrices are estimated in terms of the uniform latent one. Two methods are then developed for multi-view clustering. One makes use of uniform multidimensional scaling (UMDS) on multi-view dissimilarities or kernels. The other one uses a uniform class assignment (UCA) procedure that optimally extracts the cluster components contained in the view-specific similarity matrices. These two methods result in the same optimization model, subjected to some slightly different constraints. A first-order condition of solutions is given as a nonlinear eigenvalue problem, and a second order condition guarantees local optimality. The nonlinear eigenvalue problem is solved by an iterative algorithm via eigen-space updating, and its convergence is proven. Furthermore, a fast implementation of the algorithm is discussed, which adopts the strategy of restarting subspace extension. Numerical experiments on some real-world data sets provide good support to the proposed methods.	[Zhang, Zhenyue; Zhai, Zheng] Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Zhang, Zhenyue] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China; [Li, Limin] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China	Zhejiang University; Zhejiang University; Xi'an Jiaotong University	Zhang, ZY (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Zhejiang, Peoples R China.; Zhang, ZY (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.	zyzhang@zju.edu.cn; zhaizheng@zju.edu.cn; liminli@mail.xjtu.edu.cn		ZHAI, ZHENG/0000-0002-7983-8134	NSFC [91230112, 11071218, 11471256]; National Basic Research Program of China (973 Program) [2015CB352503]	NSFC(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China)	The work was supported in part by NSFC projects 91230112, 11071218, and 11471256, and National Basic Research Program of China (973 Program) 2015CB352503. We would like to thank Dr. Dean Bodenham from ETH Zurich for his kind help with proofreading the manuscript. Limin Li is a corresponding author.	Amini M.R., 2009, ADV NEURAL INFORM PR, P28, DOI DOI 10.5555/2984093.2984097; [Anonymous], 2011, P 28 INT C INT C MAC; Bach F.R., 2004, P 21 INT C MACH LEAR, P6, DOI DOI 10.1145/1015330.1015424; Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Brefeld U., 2006, P 23 INT C MACH LEAR, P137; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; De Sa V.R., 2005, ICML WORKSHOP LEARNI, P20; Farquhar JDR, 2005, ADV NEURAL INFORM PR, P355, DOI 10.5555/2976248.2976293; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gonen M., 2014, NIPS, P1305; Huang HC, 2012, PROC CVPR IEEE, P773, DOI 10.1109/CVPR.2012.6247748; Kumar A., 2011, ADV NEURAL INFORM PR, P1413; Lange T., 2006, ADV NEURAL INFORM PR, V18, P723; Lichman M, 2013, UCI MACHINE LEARNING; Mo QX, 2013, P NATL ACAD SCI USA, V110, P4245, DOI 10.1073/pnas.1208949110; Shen R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035236; Sindhwani V., 2005, P ICML WORKSH LEARN, P74; Sindhwani V., 2008, INT C MACH LEARN, V307, P976, DOI DOI 10.1145/1390156.1390279; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang B, 2014, NAT METHODS, V11, P333, DOI [10.1038/NMETH.2810, 10.1038/nmeth.2810]; Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255; Yu SP, 2011, J MACH LEARN RES, V12, P2649; ZHOU D, 2005, P 22 INT C MACH LEAR, P1036	26	22	22	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1675	1689		10.1109/TPAMI.2016.2601608	http://dx.doi.org/10.1109/TPAMI.2016.2601608			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	28113618				2022-12-18	WOS:000404606300014
J	Venkataraman, V; Turaga, P				Venkataraman, Vinay; Turaga, Pavan			Shape Distributions of Nonlinear Dynamical Systems for Video-Based Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action modeling; largest Lyapunov exponent; chaos theory; shape distribution; action and gesture recognition; movement quality assessment; dynamical scene analysis	HUMAN MOVEMENT; RECOGNITION; SCENE; FEATURES; CHAOS	This paper presents a shape-theoretic framework for dynamical analysis of nonlinear dynamical systems which appear frequently in several video-based inference tasks. Traditional approaches to dynamical modeling have included linear and nonlinear methods with their respective drawbacks. A novel approach we propose is the use of descriptors of the shape of the dynamical attractor as a feature representation of nature of dynamics. The proposed framework has two main advantages over traditional approaches: a) representation of the dynamical system is derived directly from the observational data, without any inherent assumptions, and b) the proposed features show stability under different time-series lengths where traditional dynamical invariants fail. We illustrate our idea using nonlinear dynamical models such as Lorenz and Rossler systems, where our feature representations (shape distribution) support our hypothesis that the local shape of the reconstructed phase space can be used as a discriminative feature. Our experimental analyses on these models also indicate that the proposed framework show stability for different time-series lengths, which is useful when the available number of samples are small/variable. The specific applications of interest in this paper are: 1) activity recognition using motion capture and RGBD sensors, 2) activity quality assessment for applications in stroke rehabilitation, and 3) dynamical scene classification. We provide experimental validation through action and gesture recognition experiments on motion capture and Kinect datasets. In all these scenarios, we show experimental evidence of the favorable properties of the proposed representation.	[Venkataraman, Vinay; Turaga, Pavan] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA; [Venkataraman, Vinay; Turaga, Pavan] Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ 85281 USA	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe	Venkataraman, V (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.; Venkataraman, V (corresponding author), Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ 85281 USA.	vvenka18@asu.edu; pturaga@asu.edu	Turaga, Pavan/W-6186-2019	Turaga, Pavan/0000-0002-5263-5943	National Science Foundation (NSF) CAREER grant [1452163]; Direct For Computer & Info Scie & Enginr [1452163] Funding Source: National Science Foundation	National Science Foundation (NSF) CAREER grant(National Science Foundation (NSF)NSF - Office of the Director (OD)); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported by the National Science Foundation (NSF) CAREER grant 1452163.	Abarbanel H. D. I., 1996, ANAL OBSERVED CHAOTI; Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Ali S., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/ICCV.2007.4409046; Baran M, 2011, IEEE ENG MED BIO, P7602, DOI 10.1109/IEMBS.2011.6091874; Basharat A, 2009, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2009.5459429; Bhattacharyya A., 1943, B CALCUTTA MATH SOC, V35, P4; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bissacco A, 2005, PROC CVPR IEEE, P421; Bissacco A, 2001, PROC CVPR IEEE, P52; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; Cao LY, 1998, PHYSICA D, V121, P75, DOI 10.1016/S0167-2789(98)00151-1; Casti J.L., 1986, LINEAR DYNAMICAL SYS; Chen YP, 2011, AIP CONF PROC, V1371, P317, DOI 10.1063/1.3596656; Cuntoon N., 2007, P IEEE C COMP VIS PA, P1; Derpanis KG, 2012, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2012.6247815; Dingwell JB, 2007, J BIOMECH ENG-T ASME, V129, P586, DOI 10.1115/1.2746383; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; ECKMANN JP, 1985, REV MOD PHYS, V57, P617, DOI 10.1103/RevModPhys.57.617; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FUGLMEYER AR, 1975, SCAND J REHABIL MED, V7, P13; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Harbourne RT, 2009, PHYS THER, V89, P284, DOI 10.2522/ptj.20080130.ar; Iasemidis LD, 2003, IEEE T BIO-MED ENG, V50, P616, DOI 10.1109/TBME.2003.810689; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122; Miller DJ, 2006, J BIOMECH, V39, P2873, DOI 10.1016/j.jbiomech.2005.10.019; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Perc M, 2005, EUR J PHYS, V26, P525, DOI 10.1088/0143-0807/26/3/017; PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ralaivola L., 2003, ADV NEURAL INF PROCE, V4, P129; ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; SANO M, 1985, PHYS REV LETT, V55, P1082, DOI 10.1103/PhysRevLett.55.1082; Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864; Small M., 2005, APPL NONLINEAR TIME, V52; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; Srivastava A., 2007, IEEE C COMP VIS PATT, P1; Stergiou N, 2011, HUM MOVEMENT SCI, V30, P869, DOI 10.1016/j.humov.2011.06.002; Takens F., 1981, DYNAMICAL SYSTEMS TU, P366, DOI [DOI 10.1007/BFB0091924, 10.1007/bfb0091924, 10.1007/BFb0091924]; TenBroek T., 2007, J BIOMECH, V40, P210, DOI DOI 10.1016/S0021-9290(07)70206-3; Tucker W, 1999, CR ACAD SCI I-MATH, V328, P1197, DOI 10.1016/S0764-4442(99)80439-X; Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197; Venkataraman V, 2016, IEEE J BIOMED HEALTH, V20, P143, DOI 10.1109/JBHI.2014.2375206; Venkataraman V, 2013, IEEE COMPUT SOC CONF, P514, DOI 10.1109/CVPRW.2013.82; Williams G.P., 1997, CHAOS THEORY TAMED, DOI 10.1201/9781482295412; Wilson A. D., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P229, DOI 10.1109/ISCV.1995.477006; WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9; Wolf SL, 2001, STROKE, V32, P1635, DOI 10.1161/01.STR.32.7.1635; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970	56	22	22	3	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2531	2543		10.1109/TPAMI.2016.2533388	http://dx.doi.org/10.1109/TPAMI.2016.2533388			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	27824585	Green Submitted, hybrid			2022-12-18	WOS:000387984700014
J	Wu, TF; Li, B; Zhu, SC				Wu, Tianfu; Li, Bo; Zhu, Song-Chun			Learning And-Or Model to Represent Context and Occlusion for Car Detection and Viewpoint Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Car detection; car viewpoint estimation; and-or graph; hierarchical model; context; occlusion modeling	AWARE OBJECT DETECTION; RECOGNITION; APPEARANCE; TEMPLATES	This paper presents a method for learning an And-Or model to represent context and occlusion for car detection and viewpoint estimation. The learned And-Or model represents car-to-car context and occlusion configurations at three levels: (i) spatially-aligned cars, (ii) single car under different occlusion configurations, and (iii) a small number of parts. The And-Or model embeds a grammar for representing large structural and appearance variations in a reconfigurable hierarchy. The learning process consists of two stages in a weakly supervised way (i.e., only bounding boxes of single cars are annotated). First, the structure of the And-Or model is learned with three components: (a) mining multi-car contextual patterns based on layouts of annotated single car bounding boxes, (b) mining occlusion configurations between single cars, and (c) learning different combinations of part visibility based on CAD simulations. The And-Or model is organized in a directed and acyclic graph which can be inferred by Dynamic Programming. Second, the model parameters (for appearance, deformation and bias) are jointly trained using Weak-Label Structural SVM. In experiments, we test our model on four car detection datasets-the KITTI dataset [1], the PASCAL VOC2007 car dataset [2], and two self-collected car datasets, namely the Street-Parking car dataset and the Parking-Lot car dataset, and three datasets for car viewpoint estimation-the PASCAL VOC2006 car dataset [2], the 3D car dataset [3], and the PASCAL3D+ car dataset [4]. Compared with state-of-the-art variants of deformable part-based models and other methods, our model achieves significant improvement consistently on the four detection datasets, and comparable performance on car viewpoint estimation.	[Wu, Tianfu] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Li, Bo] Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China; [Li, Bo] Univ Calif Los Angeles, Ctr Vis Cognit Learning & Auton VCLA, Los Angeles, CA USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat & Comp Sci, Los Angeles, CA USA	University of California System; University of California Los Angeles; Beijing Institute of Technology; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Wu, TF (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	tfwu@stat.ucla.edu; boli86@bit.edu.cn; sczhu@stat.ucla.edu		Wu, Tianfu/0000-0001-8911-5506	China 973 Program [2012CB316300]; DARPA MSEE project [FA 8650-11-1-7149]; MURI [ONR N00014-10-1-0933]; NSF [IIS1018751]; NVIDIA Corporation	China 973 Program(National Basic Research Program of China); DARPA MSEE project; MURI(MURI); NSF(National Science Foundation (NSF)); NVIDIA Corporation	B. Li is supported by China 973 Program under Grant no. 2012CB316300. T.F. Wu and S.C. Zhu are supported by DARPA MSEE project FA 8650-11-1-7149, MURI grant ONR N00014-10-1-0933, and NSF IIS1018751. The authors thank Dr. Wenze Hu for helpful discussions. They also gratefully acknowledge the support of NVIDIA Corporation with the donation of one GPU. T.F. Wu and B. Li contributed equally to this work.	Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60; Behley J, 2013, IEEE INT C INT ROBOT, P4195, DOI 10.1109/IROS.2013.6696957; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Chen G, 2013, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2013.235; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Duan GQ, 2010, LECT NOTES COMPUT SC, V6316, P238, DOI 10.1007/978-3-642-15567-3_18; Everingham M., 2006, PASCAL VISUAL OBJECT; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb P., 2010, TR201002 U CHIC; Gao TS, 2011, PROC CVPR IEEE, P1361, DOI 10.1109/CVPR.2011.5995623; Geiger A., 2011, ADV NEURAL INFORM PR, VVol. 24, P1467; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Ghiasi G., 2014, P IEEE C COMP VIS PA; Ghiasi G, 2014, PROC CVPR IEEE, P2401, DOI 10.1109/CVPR.2014.308; Ghodrati A., 2014, P BMVC 2014, P1; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Girshick RB, 2012, DISCRIMINATIVELY TRA; Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379; Gonzalez A, 2015, IEEE INT VEH SYM, P356, DOI 10.1109/IVS.2015.7225711; Grauman K., 2011, SYNTHESIS LECT ARTIF; Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408; Hejrati M., 2012, NIPS; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Hoiem Derek, 2012, ECCV, P340, DOI [10.1007/978-3-642-33712-3_25, DOI 10.1007/978-3-642-33712-3_25]; Hu WZ, 2015, IEEE T PATTERN ANAL, V37, P1190, DOI 10.1109/TPAMI.2014.2362141; Jun Zhu, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P449, DOI 10.1109/WACV.2012.6163023; Keshet J., 2011, P 24 INT C NEUR INF, P2205; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Leibe B, 2003, PROC CVPR IEEE, P409; Li B, 2013, IEEE I CONF COMP VIS, P2560, DOI 10.1109/ICCV.2013.318; Li B, 2014, LECT NOTES COMPUT SC, V8694, P652, DOI 10.1007/978-3-319-10599-4_42; Li B, 2014, PATTERN RECOGN, V47, P3254, DOI 10.1016/j.patcog.2014.04.016; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Liu XB, 2014, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.2014.93; Lopez-Sastre RJ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130367; Mathias M, 2013, IEEE I CONF COMP VIS, P1505, DOI 10.1109/ICCV.2013.190; Matzen K, 2013, IEEE I CONF COMP VIS, P761, DOI 10.1109/ICCV.2013.99; Ozuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633; Ohn-Bar E, 2015, IEEE T INTELL TRANSP, V16, P2511, DOI 10.1109/TITS.2015.2409889; Opelt A, 2005, LECT NOTES COMPUT SC, V3540, P862; Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411; Pepik B., 2013, P IEEE C COMP VIS PA; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35; Song X, 2013, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2013.421; Sun M, 2009, PROC CVPR IEEE, P1247, DOI 10.1109/CVPRW.2009.5206723; Tang S., 2012, P BRIT MACH VIS C, P58; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang X., 2013, P IEEE INT C COMP VI, P2071; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Yang Y, 2012, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2012.6248095; Yu X, 2014, LECT NOTES COMPUT SC, V8692, P105, DOI 10.1007/978-3-319-10593-2_8; Yuille A. L, 2001, P ADV NEUR INF PROC, V14, P915; Zhang X, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522978; Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43; Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018; Zhu XC, 2013, PLANT MOL BIOL REP, V31, P248, DOI 10.1007/s11105-012-0473-z; Zia MZ, 2013, PROC CVPR IEEE, P3326, DOI 10.1109/CVPR.2013.427	71	22	24	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1829	1843		10.1109/TPAMI.2015.2497699	http://dx.doi.org/10.1109/TPAMI.2015.2497699			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26552076	hybrid, Green Submitted			2022-12-18	WOS:000381432700009
J	Chang, JY				Chang, Ju Yong			Nonparametric Feature Matching Based Conditional Random Fields for Gesture Recognition from Multi-Modal Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gesture recognition; conditional random field; nonparametric estimation; structured learning	POSE	We present a new gesture recognition method that is based on the conditional random field (CRF) model using multiple feature matching. Our approach solves the labeling problem, determining gesture categories and their temporal ranges at the same time. A generative probabilistic model is formalized and probability densities are nonparametrically estimated by matching input features with a training dataset. In addition to the conventional skeletal joint-based features, the appearance information near the active hand in an RGB image is exploited to capture the detailed motion of fingers. The estimated likelihood function is then used as the unary term for our CRF model. The smoothness term is also incorporated to enforce the temporal coherence of our solution. Frame-wise recognition results can then be obtained by applying an efficient dynamic programming technique. To estimate the parameters of the proposed CRF model, we incorporate the structured support vector machine (SSVM) framework that can perform efficient structured learning by using large-scale datasets. Experimental results demonstrate that our method provides effective gesture recognition results for challenging real gesture datasets. By scoring 0.8563 in the mean Jaccard index, our method has obtained the state-of-the-art results for the gesture recognition track of the 2014 ChaLearn Looking at People (LAP) Challenge.	[Chang, Ju Yong] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 305700, South Korea	Electronics & Telecommunications Research Institute - Korea (ETRI)	Chang, JY (corresponding author), Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 305700, South Korea.	juyong.chang@etri.re.kr		Chang, Ju Yong/0000-0003-3710-7314				Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Battison R, 1978, LEXICAL BORROWING AM; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Camgoz N. C., 2014, EUR C COMP VIS, P579; Chang JY, 2014, WORKSH EUR C COMP VI, P503; Chen G., 2014, P EUR C COMP VIS WOR, P608; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32; Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Jalal A, 2012, INDOOR BUILT ENVIRON, V21, P184, DOI 10.1177/1420326X11423163; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76; KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703, DOI 10.1137/0108053; Krupka E, 2014, PROC CVPR IEEE, P3670, DOI 10.1109/CVPR.2014.469; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; Monnier C, 2015, LECT NOTES COMPUT SC, V8925, P491, DOI 10.1007/978-3-319-16178-5_34; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Muller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247; Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; PENG X, 2014, WORKSH EUR C COMP VI, P518; Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52; Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simon F., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303; Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang S. B., 2006, PROC IEEE COMPUT SOC, P1521, DOI DOI 10.1109/CVPR.2006.132; Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389; Wu D., 2014, COMP VIS ECCV 2014 W, P552; Xia L., 2012, IEEE COMP SOC C COMP, V2012, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Yang X., 2012, COMP VIS PATT REC WO, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]; Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	55	22	23	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1612	1625		10.1109/TPAMI.2016.2519021	http://dx.doi.org/10.1109/TPAMI.2016.2519021			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26800528				2022-12-18	WOS:000379926200010
J	Crispim, CF; Buso, V; Avgerinakis, K; Meditskos, G; Briassouli, A; Benois-Pineau, J; Kompatsiaris, I; Bremond, F				Crispim-Junior, Carlos F.; Buso, Vincent; Avgerinakis, Konstantinos; Meditskos, Georgios; Briassouli, Alexia; Benois-Pineau, Jenny; Kompatsiaris, Ioannis (Yiannis); Bremond, Francois			Semantic Event Fusion of Different Visual Modality Concepts for Activity Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Knowledge representation formalism and methods; uncertainty and probabilistic reasoning; concept synchronization; activity recognition; vision and scene understanding; multimedia perceptual system	TIME	Combining multimodal concept streams from heterogeneous sensors is a problem superficially explored for activity recognition. Most studies explore simple sensors in nearly perfect conditions, where temporal synchronization is guaranteed. Sophisticated fusion schemes adopt problem-specific graphical representations of events that are generally deeply linked with their training data and focused on a single sensor. This paper proposes a hybrid framework between knowledge-driven and probabilistic-driven methods for event representation and recognition. It separates semantic modeling from raw sensor data by using an intermediate semantic representation, namely concepts. It introduces an algorithm for sensor alignment that uses concept similarity as a surrogate for the inaccurate temporal information of real life scenarios. Finally, it proposes the combined use of an ontology language, to overcome the rigidity of previous approaches at model definition, and a probabilistic interpretation for ontological models, which equips the framework with a mechanism to handle noisy and ambiguous concept observations, an ability that most knowledge-driven methods lack. We evaluate our contributions in multimodal recordings of elderly people carrying out IADLs. Results demonstrated that the proposed framework outperforms baseline methods both in event recognition performance and in delimiting the temporal boundaries of event instances.	[Crispim-Junior, Carlos F.; Bremond, Francois] INRIA Sophia Antipolis Mediterranee, STARS Team, Valbonne, France; [Buso, Vincent; Benois-Pineau, Jenny] Univ Bordeaux, LABRI, Talence, France; [Avgerinakis, Konstantinos; Meditskos, Georgios; Briassouli, Alexia; Kompatsiaris, Ioannis (Yiannis)] CERTH ITI, Thessaloniki, Greece	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite de Bordeaux	Crispim, CF (corresponding author), INRIA Sophia Antipolis Mediterranee, STARS Team, Valbonne, France.	carlos-fernando.crispim_junior@inria.fr; vbuso@labri.fr; koafgeri@iti.gr; gmeditsk@iti.gr; abria@iti.gr; jenny.benois@labri.fr; ikom@iti.gr; francois.bremond@inria.fr	Benois-Pineau, Jenny/ABG-6325-2020; Kompatsiaris, Ioannis/P-8594-2015; Meditskos, Georgios/AGO-3230-2022	Benois-Pineau, Jenny/0000-0003-0659-8894; Kompatsiaris, Ioannis/0000-0001-6447-9020; Meditskos, Georgios/0000-0003-4242-5245; Briassouli, Alexia/0000-0002-0545-3215				ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Nghiem AT, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P241, DOI 10.1109/AVSS.2014.6918675; Artikis A, 2015, IEEE T KNOWL DATA EN, V27, P895, DOI 10.1109/TKDE.2014.2356476; Avgerinakis K., 2015, COMPUT VIS IMAGE UND; Banerjee T, 2015, COMPUT VIS IMAGE UND, V140, P68, DOI 10.1016/j.cviu.2015.04.005; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Boujut H, 2012, LECT NOTES COMPUT SC, V7585, P436, DOI 10.1007/978-3-642-33885-4_44; Brendel W., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3329, DOI 10.1109/CVPR.2011.5995491; Chau D. P., 2011, INT C IM CRIM DET PR; Chen LM, 2014, IEEE T HUM-MACH SYST, V44, P92, DOI 10.1109/THMS.2013.2293714; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crispim CF, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P165, DOI 10.1109/AVSS.2013.6636634; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Fleury A., 2010, 2010 12th IEEE International Conference on e-Health Networking, Applications and Services (Healthcom 2010), P322, DOI 10.1109/HEALTH.2010.5556549; FOLSTEIN MF, 1983, ARCH GEN PSYCHIAT, V40, P812; Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Jhuo IH, 2014, MACH VISION APPL, V25, P33, DOI 10.1007/s00138-013-0567-0; Klaser A., 2012, LNCS, V6553, P219, DOI DOI 10.1007/978-3-642-35749-7_17; Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Luo G, 2014, IEEE T PATTERN ANAL, V36, P2466, DOI 10.1109/TPAMI.2014.2329301; Lyons B. E., 2015, FRONTIERS AGING NEUR, V7; Meditskos G, 2014, LECT NOTES COMPUT SC, V8797, P260, DOI 10.1007/978-3-319-11915-1_17; Medjahed H, 2011, IEEE INT CONF FUZZY, P1466; Muller M., 2007, INFORM RETRIEVAL MUS, V6, P9; Myers GK, 2014, MACH VISION APPL, V25, P17, DOI 10.1007/s00138-013-0527-8; Oh S, 2014, MACH VISION APPL, V25, P49, DOI 10.1007/s00138-013-0525-x; Platt JC, 2000, ADV NEUR IN, P61; Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508; SanMiguel JC, 2012, COMPUT VIS IMAGE UND, V116, P937, DOI 10.1016/j.cviu.2012.04.005; Vempati S., 2010, P BRIT MACH VIS C 20, P1; Vu VT, 2003, IJCAI, P1295; Wang XY, 2014, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2014.328; Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540; Yuanyuan Cao, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P120, DOI 10.1109/UIC-ATC.2009.47; Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P1360, DOI 10.1109/TPAMI.2014.2369044	38	22	22	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1598	1611		10.1109/TPAMI.2016.2537323	http://dx.doi.org/10.1109/TPAMI.2016.2537323			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26955015	Green Submitted			2022-12-18	WOS:000379926200009
J	Shi, YH; Gao, YZ; Liao, S; Zhang, DQ; Gao, Y; Shen, DG				Shi, Yinghuan; Gao, Yaozong; Liao, Shu; Zhang, Daoqiang; Gao, Yang; Shen, Dinggang			Semi-Automatic Segmentation of Prostate in CT Images via Coupled Feature Representation and Spatial-Constrained Transductive Lasso	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Prostate segmentation; feature representation; feature selection; label fusion	REGISTRATION; FRAMEWORK; CONTEXT; SHRINKAGE; BIOPSY; ROBUST; ATLAS; SCALE	Conventional learning-based methods for segmenting prostate in CT images ignore the relations among the low-level features by assuming all these features are independent. Also, their feature selection steps usually neglect the image appearance changes in different local regions of CT images. To this end, we present a novel semi-automatic learning-based prostate segmentation method in this article. For segmenting the prostate in a certain treatment image, the radiation oncologist will be first asked to take a few seconds to manually specify the first and last slices of the prostate. Then, prostate is segmented with the following two steps: (i) Estimation of 3D prostate-likelihood map to predict the likelihood of each voxel being prostate by employing the coupled feature representation, and the proposed Spatial-COnstrained Transductive LassO (SCOTO); (ii) Multi-atlases based label fusion to generate the final segmentation result by using the prostate shape information obtained from both planning and previous treatment images. The major contribution of the proposed method mainly includes: (i) incorporating radiation oncologist's manual specification to aid segmentation, (ii) adopting coupled features to relax previous assumption of feature independency for voxel representation, and (iii) developing SCOTO for joint feature selection across different local regions. The experimental result shows that the proposed method outperforms the state-of-the-art methods in a real-world prostate CT dataset, consisting of 24 patients with totally 330 images, all of which were manually delineated by the radiation oncologist for performance evaluation. Moreover, our method is also clinically feasible, since the segmentation performance can be improved by just requiring the radiation oncologist to spend only a few seconds for manual specification of ending slices in the current treatment CT image.	[Shi, Yinghuan; Gao, Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China; [Gao, Yaozong; Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC USA; [Gao, Yaozong; Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC USA; [Liao, Shu] Siemens Med Solut, Berkeley, CA USA; [Zhang, Daoqiang] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China; [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Nanjing University; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; Siemens AG; Nanjing University of Aeronautics & Astronautics; Korea University	Shi, YH (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.	yinghuan.shi@gmail.com; yzgao@cs.unc.edu; liaoshu.cse@gmail.com; daoqiangz@gmail.com; gaoy@nju.edu.cn; dgshen@med.unc.edu	Shen, Dinggang/ABF-6812-2020	Shen, Dinggang/0000-0002-7934-5698	NIH [CA140413]; NSFC [61432008, 61305068, 61321491, 61473190, 61422204, 61473149]; Jiangsu Nature Science Foundation (NSF) [BK20130581]; Jiangsu NSF for Distinguished Young Scholar [BK20130034]; NATIONAL CANCER INSTITUTE [R01CA140413] Funding Source: NIH RePORTER	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NSFC(National Natural Science Foundation of China (NSFC)); Jiangsu Nature Science Foundation (NSF); Jiangsu NSF for Distinguished Young Scholar; NATIONAL CANCER INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI))	The work was supported by NIH (CA140413), NSFC (61432008, 61305068, 61321491, 61473190, 61422204, 61473149), Jiangsu Nature Science Foundation (NSF) (BK20130581), and Jiangsu NSF for Distinguished Young Scholar (BK20130034). Preliminary version of this work has been published in our CVPR 2013 paper [37]. Yang Gao and Dinggang Shen are the corresponding authors.	Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen C, 2014, INT C PATT RECOG, P1645, DOI 10.1109/ICPR.2014.291; Chen C, 2014, PROC CVPR IEEE, P2713, DOI 10.1109/CVPR.2014.353; Chen SQ, 2011, MED IMAGE ANAL, V15, P1, DOI 10.1016/j.media.2010.06.004; Chen T, 2009, LECT NOTES COMPUT SC, V5761, P43, DOI 10.1007/978-3-642-04268-3_6; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Davis BC, 2005, LECT NOTES COMPUT SC, V3749, P442; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Feng QJ, 2010, MED PHYS, V37, P4121, DOI 10.1118/1.3464799; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gao Y., 2012, P MED IM COMP COMP A, P452; Gao Y, 2010, IEEE T MED IMAGING, V29, P1781, DOI 10.1109/TMI.2010.2052065; He X., 2005, P INT C NEUR INF PRO, P507, DOI DOI 10.3233/IDT-120147; Huang JZ, 2011, MED IMAGE ANAL, V15, P670, DOI 10.1016/j.media.2011.06.001; Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132; Langerak TR, 2010, IEEE T MED IMAGING, V29, P2000, DOI 10.1109/TMI.2010.2057442; Li DC, 2012, IEEE T KNOWL DATA EN, V24, P452, DOI 10.1109/TKDE.2010.254; Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341; Li W, 2011, LECT NOTES COMPUT SC, V6893, P570, DOI 10.1007/978-3-642-23626-6_70; Li W, 2012, PHYS MED BIOL, V57, P1283, DOI 10.1088/0031-9155/57/5/1283; Liao S, 2013, IEEE T MED IMAGING, V32, P419, DOI 10.1109/TMI.2012.2230018; Liao S, 2012, IEEE T IMAGE PROCESS, V21, P3546, DOI 10.1109/TIP.2012.2194296; Liu J., 2010, PROC 16 ACM SIGKDD I, P323; Lu C, 2012, LECT NOTES COMPUT SC, V7511, P462, DOI 10.1007/978-3-642-33418-4_57; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Shen DG, 2004, MED IMAGE ANAL, V8, P139, DOI 10.1016/j.media.2003.11.002; Shi YH, 2014, PROC CVPR IEEE, P2721, DOI 10.1109/CVPR.2014.354; Shi YH, 2013, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2013.289; Tibshirani R, 2005, J R STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Wang C., 2013, PROC INT JOINT C ART, P1736; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu Y, 2014, IEEE T MED IMAGING, V33, P1290, DOI 10.1109/TMI.2014.2308901; Xin B, 2014, AAAI CONF ARTIF INTE, P2163; Yinghuan Shi, 2012, Machine Learning in Medical Imaging. Third International Workshop (MLMI 2012). Held in Conjunction with MICCAI 2012. Revised Selected Papers, P1, DOI 10.1007/978-3-642-35428-1_1; Yuan L, 2013, IEEE T PATTERN ANAL, V35, P2104, DOI 10.1109/TPAMI.2013.17; Zhan YQ, 2007, IEEE T MED IMAGING, V26, P779, DOI [10.1109/TMI.2006.891497, 10.1109/TMI.2006.89I497]; Zhan YQ, 2006, IEEE T MED IMAGING, V25, P256, DOI 10.1109/TMI.2005.862744	48	22	24	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2286	2303		10.1109/TPAMI.2015.2424869	http://dx.doi.org/10.1109/TPAMI.2015.2424869			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440268				2022-12-18	WOS:000362411000011
J	Romero, A; Radeva, P; Gatta, C				Romero, Adriana; Radeva, Petia; Gatta, Carlo			Meta-Parameter Free Unsupervised Sparse Feature Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Representation learning; unsupervised feature learning; pre-training of deep networks; sparse visual features		We propose a meta-parameter free, off-the-shelf, simple and fast unsupervised feature learning algorithm, which exploits a new way of optimizing for sparsity. Experiments on CIFAR-10, STL-10 and UCMerced show that the method achieves the state-of-the-art performance, providing discriminative features that generalize well.	[Romero, Adriana; Radeva, Petia] Univ Barcelona, Dept MAIA, E-08007 Barcelona, Spain; [Radeva, Petia; Gatta, Carlo] Comp Vis Ctr, Barcelona 08193, Spain	University of Barcelona; Centre de Visio per Computador (CVC)	Romero, A (corresponding author), Univ Barcelona, Dept MAIA, E-08007 Barcelona, Spain.	adriana.romero@ub.edu; petia.ivanova@ub.edu; cgatta@cvc.uab.es	Radeva, Petia/I-3385-2015	Radeva, Petia/0000-0003-0047-5172	APIF-UB grant; MICINN under a Ramon y Cajal Fellowship;  [TIN2013-41751];  [2014-SGR-221]	APIF-UB grant; MICINN under a Ramon y Cajal Fellowship; ; 	The authors would like to thank the anonymous reviewers for their valuable comments. The work of A. Romero is supported by an APIF-UB grant. The work of C. Gatta was supported by MICINN under a Ramon y Cajal Fellowship. This work has been supported in part by projects TIN2013-41751 and 2014-SGR-221.	[Anonymous], 2010003 UTML TR U TO; Bengio Y, 2006, P 19 INT C NEUR INF, P153; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Blumensath T., 2007, DIFFERENCE ORTHOGONA; Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444; Coates A., 2011, P 14 INT C ART INT S, P214; Coates Adam, 2011, P 28 INT C MACH LEAR, P921; Erhan D., 2010, P AISTATS 2010 MAY, P201; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; Goh H, 2012, LECT NOTES COMPUT SC, V7576, P298, DOI 10.1007/978-3-642-33715-4_22; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Hyvarinen Aapo, 2000, INDEPENDENT COMPONEN; Kavukcuoglu Koray, 2010, ADV NEURAL INFORM PR, V23, P1090; Krizhevsky A., 2009, THESIS U TORONTO TOR; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Le Q.V., 2011, NEURIPS, P1017; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; Lee H, 2016, ADV NEURAL INFORM PR, V19; Lee Honglak, 2008, ADV NEURAL INFORM PR, V20; Newsam, 2010, P 18 SIGSPATIAL INT, P2, DOI DOI 10.1145/1869790.1869829; Ngiam J., 2011, ADV NEURAL INFORM PR, pp 24; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Ranzato M.A., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147; Schaul T., 2013, INT C MACHINE LEARNI, P343; Snoek J., 2012, P NIPS, V12, P2960; Sohn Kihyuk, 2012, ICML; Willmore B, 2001, NETWORK-COMP NEURAL, V12, P255, DOI 10.1088/0954-898X/12/3/302; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757	33	22	23	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1716	1722		10.1109/TPAMI.2014.2366129	http://dx.doi.org/10.1109/TPAMI.2014.2366129			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353006				2022-12-18	WOS:000357591900014
J	Gilboa, E; Saatci, Y; Cunningham, JP				Gilboa, Elad; Saatci, Yunus; Cunningham, John P.			Scaling Multidimensional Inference for Structured Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian processes; backfitting; projection-pursuit regression; Kronecker matrices	LIKELIHOOD; ALGORITHMS	Exact Gaussian process (GP) regression has O(N-3) runtime for data size N, making it intractable for large N. Many algorithms for improving GP scaling approximate the covariance with lower rank matrices. Other work has exploited structure inherent in particular covariance functions, including GPs with implied Markov structure, and inputs on a lattice (both enable O(N) or O(N log N) runtime). However, these GP advances have not been well extended to the multidimensional input setting, despite the preponderance of multidimensional applications. This paper introduces and tests three novel extensions of structured GPs to multidimensional inputs, for models with additive and multiplicative kernels. First we present a new method for inference in additive GPs, showing a novel connection between the classic backfitting method and the Bayesian framework. We extend this model using two advances: a variant of projection pursuit regression, and a Laplace approximation for non-Gaussian observations. Lastly, for multiplicative kernel structure, we present a novel method for GPs with inputs on a multidimensional grid. We illustrate the power of these three advances on several data sets, achieving performance equal to or very close to the naive GP at orders of magnitude less cost.	[Gilboa, Elad] Washington Univ St Louis, Preston M Green Dept Elect & Syst Engn, Chesterfield, MO 63017 USA; [Saatci, Yunus] Univ Cambridge, Dept Engn, Cambridge CB2 9AE, England; [Cunningham, John P.] Columbia Univ, Dept Stat, New York, NY 10027 USA	Washington University (WUSTL); University of Cambridge; Columbia University	Gilboa, E (corresponding author), Washington Univ St Louis, Preston M Green Dept Elect & Syst Engn, 14049 Agusta Dr, Chesterfield, MO 63017 USA.	gilboae@ese.wustl.edu; saatchi@cantab.net; jpc2181@columbia.edu			EPSRC [EP/H019472/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/H019472/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Alcala-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255; ARNOLD L, 1992, STOCHASTIC DIFFERENT; Bishop Christopher M., 2007, PATTERN RECOGNITION, V4, DOI 10.1117/1.2819119; Breiman L., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface, P121; Chang CC, 2001, IEEE IJCNN, P1031, DOI 10.1109/IJCNN.2001.939502; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chipman HA, 2010, ANN APPL STAT, V4, P266, DOI 10.1214/09-AOAS285; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cressie N, 2008, J R STAT SOC B, V70, P209, DOI 10.1111/j.1467-9868.2007.00633.x; Cunningham J. P., 2008, P 25 INT C MACH LEAR, P192, DOI DOI 10.1145/1390156.1390181; Duvenaud D.K., 2011, ADV NEURAL INFORM PR, P226; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Fritz J, 2009, MATH GEOSCI, V41, P509, DOI 10.1007/s11004-009-9220-x; Fuentes M, 2007, J AM STAT ASSOC, V102, P321, DOI 10.1198/016214506000000852; Furrer R, 2006, J COMPUT GRAPH STAT, V15, P502, DOI 10.1198/106186006X132178; Gilboa E., 2013, JMLR W CP, V28; Goldberg P.W., 1998, P ADV NEUR INF PROC, V10; Gramacy RB, 2012, TECHNOMETRICS, V54, P30, DOI 10.1080/00401706.2012.650527; Hahn P.R., 2012, TECHNICAL REPORT; Hartikainen Jouni, 2010, Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), P379, DOI 10.1109/MLSP.2010.5589113; Hastie T, 2000, STAT SCI, V15, P196; Hastie T, 1986, STAT SCI, V1, P297, DOI DOI 10.1214/SS/1177013604; Hastie T, 2009, ELEMENTS STAT LEARNI; Hastie T.J., 1990, GEN ADDITIVE MODELS; Herbrich R., 2003, ADV NEURAL INFORM PR, P625; Higdon D, 2002, QUANTITATIVE METHODS, P37, DOI DOI 10.1007/978-1-4471-0657-9_2; Kaufman CG, 2008, J AM STAT ASSOC, V103, P1545, DOI 10.1198/016214508000000959; Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537; Luttinen J., 2012, P 15 INT C ART INT S, P741; McCullagh P, 2002, ANN STAT, V30, P1225; Minka TP., 2001, THESIS MIT CAMBRIDGE; Naish-Guzman A., 2007, P ADV NEUR INF PROC, V21, P534; Nickisch H, 2008, J MACH LEARN RES, V9, P2035; PACIOREK CJ, 2007, J STAT SOFTWARE, V19; Perkins R, 2010, OPT EXPRESS, V18, P25815, DOI 10.1364/OE.18.025815; Platt JC, 2000, ADV NEUR IN, P61; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Rasmussen CE, 2010, J MACH LEARN RES, V11, P3011; Rue H, 2002, SCAND J STAT, V29, P31, DOI 10.1111/1467-9469.00058; Saatu║i Y., 2011, THESIS U CAMBRIDGE; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Snelson E., 2006, P UNC ART INT UAI 22; Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1259; Storkey AJ, 1999, IEE CONF PUBL, P55, DOI 10.1049/cp:19991084; Vanhatalo J, 2007, J MACHINE LEARNING R, V1, P73; Vanhatalo J., 2012, BAYESIAN MODELING GA; Vivarelli F., 1998, P ADV NEUR INF PROC, V11; Wikle CK, 1999, BIOMETRIKA, V86, P815, DOI 10.1093/biomet/86.4.815; Williams C., 2007, NOTE NOISE FREE GAUS; Wilson A.G., 2012, P INT C MACH LEARN I; Xia G., 2006, TECHNICAL REPORT	51	22	23	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					424	436		10.1109/TPAMI.2013.192	http://dx.doi.org/10.1109/TPAMI.2013.192			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353252	Green Submitted, Green Published			2022-12-18	WOS:000349625500017
J	Arora, SS; Liu, EY; Cao, K; Jain, AK				Arora, Sunpreet S.; Liu, Eryun; Cao, Kai; Jain, Anil K.			Latent Fingerprint Matching: Performance Gain via Feedback from Exemplar Prints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint; latent fingerprint matching; exemplar feedback; feature refinement; candidate list	OUTLIERS	Latent fingerprints serve as an important source of forensic evidence in a court of law. Automatic matching of latent fingerprints to rolled/plain (exemplar) fingerprints with high accuracy is quite vital for such applications. However, latent impressions are typically of poor quality with complex background noise which makes feature extraction and matching of latents a significantly challenging problem. We propose incorporating top-down information or feedback from an exemplar to refine the features extracted from a latent for improving latent matching accuracy. The refined latent features (e. g. ridge orientation and frequency), after feedback, are used to re-match the latent to the top K candidate exemplars returned by the baseline matcher and resort the candidate list. The contributions of this research include: (i) devising systemic ways to use information in exemplars for latent feature refinement, (ii) developing a feedback paradigm which can be wrapped around any latent matcher for improving its matching performance, and (iii) determining when feedback is actually necessary to improve latent matching accuracy. Experimental results show that integrating the proposed feedback paradigm with a state-of-the-art latent matcher improves its identification accuracy by 0.5-3.5 percent for NIST SD27 and WVU latent databases against a background database of 100k exemplars.	[Arora, Sunpreet S.; Cao, Kai; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Liu, Eryun] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China; [Cao, Kai] Xidian Univ, Sch Life Sci & Technol, Xian 710126, Shaanxi, Peoples R China	Michigan State University; Zhejiang University; Xidian University	Arora, SS (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	arorasun@cse.msu.edu; eryunliu@zju.edu.cn; kaicao@cse.msu.edu; jain@cse.msu.edu			National Science Foundation [1066197]; National Natural Science Foundation of China [61100234]	National Science Foundation(National Science Foundation (NSF)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This material was based upon work supported by the National Science Foundation under Grant No. 1066197. Eryun Liu's research was partially supported by the National Natural Science Foundation of China under Grant No. 61100234. The authors would like to thank Prof. Jianjiang Feng of Tsinghua University, China, and Soweon Yoon of Michigan State University for providing useful feedback during the course of this research. An earlier version of this paper appeared in the proceedings of the 6th IAPR International Conference on Biometrics (ICB), 2013 [35].	Ashbaugh D.R, 1999, CRC SER PR CRIM; Boden M, 2001, RNN DAN BPNN, P1; Borenstein E, 2008, IEEE T PATTERN ANAL, V30, P2109, DOI 10.1109/TPAMI.2007.70840; Casella G., 1990, STAT INFERENCE, V70; Champod C., 2017, FINGERPRINTS OTHER R, P136; Choi H., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P303, DOI 10.1109/BTAS.2012.6374593; Coppin B., 2004, ARTIF INTELL; Dror IE, 2005, APPL COGNITIVE PSYCH, V19, P799, DOI 10.1002/acp.1130; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; FBI, 2012, NEXT GEN ID; Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155; Fronthaler H, 2008, IEEE T IMAGE PROCESS, V17, P354, DOI 10.1109/TIP.2007.916155; Galton Francis, 1892, FINGER PRINTS; Hollands JG., 1999, ENG PSYCHOL HUMAN PE; Indovina M., 2012, ELFT EFS EVALUATION; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Lalitha S, 2012, J APPL STAT, V39, P1323, DOI 10.1080/02664763.2011.645158; Lancaster H. O., 1969, CHI SQUARE DISTRIBUT; Lee HC, 2001, ADV FINGERPRINT TECH; LEWIS T, 1979, TECHNOMETRICS, V21, P371, DOI 10.2307/1267762; Liu E., 2013, P 6 INT C BIOM ICB 1; *NIST, 2007, SUMM RES ELFT07 PHAS; Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Paulino AA, 2013, IEEE T INF FOREN SEC, V8, P31, DOI 10.1109/TIFS.2012.2223678; Wilson C., 2004, FINGERPRINT VENDOR T; Yoon S., 2010, P SPIE C SERIES, V7667; Yoon S., 2012, INT WORKSH COMP FOR; 2007, EVALUATION LATENT FI	31	22	25	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2452	2465		10.1109/TPAMI.2014.2330609	http://dx.doi.org/10.1109/TPAMI.2014.2330609			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353151	hybrid, Green Submitted			2022-12-18	WOS:000344988000010
J	Cheng, Q; Zhou, HB; Cheng, J; Li, HQ				Cheng, Qiang; Zhou, Hongbo; Cheng, Jie; Li, Huiqing			A Minimax Framework for Classification with Applications to Images and High Dimensional Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiclass classification; generalized multiplicative distortion; high dimensional data; minimax optimization; Bayesian optimal decision; kernel	FACE RECOGNITION; SELECTION; REGRESSION	This paper introduces a minimax framework for multiclass classification, which is applicable to general data including, in particular, imagery and other types of high-dimensional data. The framework consists of estimating a representation model that minimizes the fitting errors under a class of distortions of interest to an application, and deriving subsequently categorical information based on the estimated model. A variety of commonly used regression models, including lasso, elastic net and ridge regression, can be regarded as special cases that correspond to specific classes of distortions. Optimal decision rules are derived for this classification framework. By using kernel techniques the framework can account for nonlinearity in the input space. To demonstrate the power of the framework we consider a class of signal-dependent distortions and build a new family of classifiers as new special cases. This family of new methods-minimax classification with generalized multiplicative distortions-often outperforms the state-of-the-art classification methods such as the support vector machine in accuracy. Extensive experimental results on images, gene expressions and other types of data verify the effectiveness of the proposed framework.	[Cheng, Qiang; Zhou, Hongbo] So Illinois Univ, Dept Comp Sci, Carbondale, IL 62901 USA; [Cheng, Jie] Univ Hawaii, Dept Comp Sci, Hilo, HI 96720 USA; [Li, Huiqing] So Illinois Univ, Dept Econ, Carbondale, IL 62901 USA	Southern Illinois University System; Southern Illinois University; University of Hawaii System; University Hawaii Hilo; Southern Illinois University System; Southern Illinois University	Cheng, Q (corresponding author), So Illinois Univ, Dept Comp Sci, Faner Hall,Room 2140,MC 4511,1000 Faner Dr, Carbondale, IL 62901 USA.	qcheng@cs.siu.edu; hbzhou@cs.siu.edu; jcheng@bemidjistate.edu; huiqing.li@siu.edu		Li, Huiqing/0000-0003-2559-0804	 [NSF IIS-1218712]; Direct For Computer & Info Scie & Enginr [1218712] Funding Source: National Science Foundation	; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported in part by grant NSF IIS-1218712. The authors thank the editor for coordinating the review and the referees for comments that help improve the composition.	Asif MS, 2010, IEEE J-STSP, V4, P421, DOI 10.1109/JSTSP.2009.2039174; Bach FR, 2008, J MACH LEARN RES, V9, P1179; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Cheng Q, 2004, SIGNAL PROCESS, V84, P1429, DOI 10.1016/j.sigpro.2004.05.017; Cheng QA, 2011, IEEE T PATTERN ANAL, V33, P1217, DOI 10.1109/TPAMI.2010.195; Cheng Q, 2009, IEEE T CIRC SYST VID, V19, P978, DOI 10.1109/TCSVT.2009.2020255; Demsar J, 2006, J MACH LEARN RES, V7, P1; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Duda R.O., 2001, PATTERN CLASSIFICATI; ElGhaoui L, 1997, SIAM J MATRIX ANAL A, V18, P1035, DOI 10.1137/S0895479896298130; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Forsyth David A, 2012, COMPUTER VISION MODE; Frank A., 2010, UCI MACHINE LEARNING; Fujikoshi Y., 2010, MULTIVARIATE STAT HI; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gilchrist A, 1999, PSYCHOL REV, V106, P795, DOI 10.1037/0033-295X.106.4.795; Golub G. H., 2012, MATRIX COMPUTATIONS; Grant M., CVX MATLAB SOFTWARE; Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717; Hastie T, 2009, ELEMENTS STAT LEARNI; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332; Jacob L., 2009, P 26 INT C MACH LEAR, P433, DOI DOI 10.1145/1553374.1553431; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lee H., 2007, ADV NEURAL INF PROCE, P801; Leibe B, 2003, PROC CVPR IEEE, P409; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Martinez, 1998, 24 CVC; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Poynton C., 2003, DIGITAL VIDEO HDTV A; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; Scholkopf B., 2002, LEARNING KERNELS; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Sonka M., 2014, IMAGE PROCESSING ANA; STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Webb A.R., 2003, STAT PATTERN RECOGNI; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yu Kai, 2009, ADV NEURAL INFORM PR, P2223; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhou H., 2010, P ADV NEUR INF PROC, P2577; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	54	22	23	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2117	2130		10.1109/TPAMI.2014.2327978	http://dx.doi.org/10.1109/TPAMI.2014.2327978			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353055				2022-12-18	WOS:000343702400001
J	Alterman, M; Schechner, YY; Perona, P; Shamir, J				Alterman, Marina; Schechner, Yoav Y.; Perona, Pietro; Shamir, Joseph			Detecting Motion through Dynamic Refraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion detection; refraction; random media; classification; distortion	IMAGES; WATER; RECONSTRUCTION; OBJECTS; SYSTEM	Refraction causes random dynamic distortions in atmospheric turbulence and in views across a water interface. The latter scenario is experienced by submerged animals seeking to detect prey or avoid predators, which may be airborne or on land. Man encounters this when surveying a scene by a submarine or divers while wishing to avoid the use of an attention-drawing periscope. The problem of inverting random refracted dynamic distortions is difficult, particularly when some of the objects in the field of view (FOV) are moving. On the other hand, in many cases, just those moving objects are of interest, as they reveal animal, human, or machine activity. Furthermore, detecting and tracking these objects does not necessitate handling the difficult task of complete recovery of the scene. We show that moving objects can be detected very simply, with low false-positive rates, even when the distortions are very strong and dominate the object motion. Moreover, the moving object can be detected even if it has zero mean motion. While the object and distortion motions are random and unknown, they are mutually independent. This is expressed by a simple motion feature which enables discrimination of moving object points versus the background.	[Alterman, Marina; Schechner, Yoav Y.; Shamir, Joseph] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; [Perona, Pietro] CALTECH, Dept Elect Engn, Pasadena, CA 91125 USA	Technion Israel Institute of Technology; California Institute of Technology	Alterman, M (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	amarina@tx.technion.ac.il			Taub Foundation; R.L. Kohns Eye Research Fund; Office of Naval Research Global [N62909-10-1-4056]	Taub Foundation; R.L. Kohns Eye Research Fund; Office of Naval Research Global(Office of Naval Research)	The authors would like to thank the anonymous reviewers for their useful comments. They thank Tomer Schechner, Yotam Michael, Amit Aides, and Amit Oved for their participation and help in the experiments. Experiments were conducted in the swimming pool facilities of Caltech, and the authors are grateful for this. They appreciate the occasional visitors in the Caltech pool and spa for useful discussions. They also thank Ohad Ben-Shahar for useful discussions about fish orientation. They thank Yuandong Tian and Srinivasa G. Narasimhan for sharing their code for distortion estimation. Yoav Schechner is a Landau Fellow-supported by the Taub Foundation. Marina Alterman's research is supported by the R.L. Kohns Eye Research Fund. This work relates to US Department of the Navy Grant N62909-10-1-4056 issued by the Office of Naval Research Global. The United States Government has a royalty-free license throughout the world in all copyrightable material contained herein.	Adato Y, 2010, IEEE T PATTERN ANAL, V32, P2054, DOI 10.1109/TPAMI.2010.126; Agarwal S., 2004, P EUR C COMP VIS; Baglio S, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P449, DOI 10.1109/OCEANS.1998.725787; Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9; Brox T., 2012, LARGE DISPLACEMENT O; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Bugeau A., 2007, P IEEE C COMP VIS PA; Chang Y.J., 2011, P IEEE INT C COMP VI; Cochran WG, 1934, P CAMB PHILOS SOC, V30, P178, DOI 10.1017/S0305004100016595; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COX C, 1954, J MAR RES, V13, P198; Dabiri D., 2000, P INT S FLOW VIS; Ding Y., 2011, P IEEE INT C COMP VI; Dolin LS, 2007, PROC SPIE, V6615, DOI 10.1117/12.740457; Donate A, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P228; Efros A., 2004, ADV NEURAL INFORM PR, V17, P393; Fishbain B, 2007, J REAL-TIME IMAGE PR, V2, P11, DOI 10.1007/s11554-007-0037-x; HORVATH G, 1991, B MATH BIOL, V53, P425, DOI 10.1016/S0092-8240(05)80396-9; Ihrke I., 2008, P EUR; JAHNE B, 1994, J OPT SOC AM A, V11, P2197, DOI 10.1364/JOSAA.11.002197; Kalal Z., 2009, P ON LIN LEARN COMP; KATZIR G, 1987, J COMP PHYSIOL A, V160, P517, DOI 10.1007/BF00615085; Kleerekoper H., 1968, ORIENTATION SOUND FI; Ko T., 2010, P IEEE C COMP VIS PA; Levin IM, 2008, APPL OPTICS, V47, P6650, DOI 10.1364/AO.47.006650; Liu RT, 2008, PROC CVPR IEEE, P954; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Milder DM, 2006, WAVE RANDOM COMPLEX, V16, P521, DOI 10.1080/17455030600557202; Miyazaki D, 2007, IEEE T PATTERN ANAL, V29, P2018, DOI 10.1109/TPAMI.2007.1117; Monnet A., 2003, P IEEE INT C COMP VI; Morris N.J.W., 2005, P IEEE INT C COMP VI; MURASE H, 1992, IEEE T PATTERN ANAL, V14, P1045, DOI 10.1109/34.159906; Oreifej Omar, 2011, P IEEE C COMP VIS PA; Saito H., 2002, P IEEE 21 INT C IND, P1231; SCHMALZ MS, 1993, P SOC PHOTO-OPT INS, V1943, P115, DOI 10.1117/12.157138; Schultz H., 2007, US Patent, Patent No. [7,630,077, 7630077]; Schultz H., 1994, SURFACE PHOTOGRAMMET, V62, P93; Schuster S, 2004, CURR BIOL, V14, P1565, DOI 10.1016/j.cub.2004.08.050; Shan Q., 2010, P EUR C COMP VIS; Steen J.B., 1970, FISH PHYSL NERVOUS S, V4; Suiter H., 2008, P C OCEANS; Tian Y., 2010, P IEEE C COMP VIS PA; Tian Y., 2012, GLOBALLY OPTIMAL DAT; Tian Yuandong, 2009, P IEEE INT C COMP VI; Treibitz T., 2008, P IEEE C COMP VIS PA; Wen ZY, 2010, APPL OPTICS, V49, P6376, DOI 10.1364/AO.49.006376; Westaway RM, 2001, PHOTOGRAMM ENG REM S, V67, P1271; Wixson L, 2000, IEEE T PATTERN ANAL, V22, P774, DOI 10.1109/34.868680; Zhu Q., 2005, P IEEE INT C COMP VI; ZWEIG MH, 1993, CLIN CHEM, V39, P561	51	22	23	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					245	251		10.1109/TPAMI.2012.192	http://dx.doi.org/10.1109/TPAMI.2012.192			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	23154325	Green Submitted			2022-12-18	WOS:000311127700021
J	Parikh, D; Zitnick, CL; Chen, TH				Parikh, Devi; Zitnick, C. Lawrence; Chen, Tsuhan			Exploring Tiny Images: The Roles of Appearance and Contextual Information for Machine and Human Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; context; tiny images; blind recognition; image labeling; human studies		Typically, object recognition is performed based solely on the appearance of the object. However, relevant information also exists in the scene surrounding the object. In this paper, we explore the roles that appearance and contextual information play in object recognition. Through machine experiments and human studies, we show that the importance of contextual information varies with the quality of the appearance information, such as an image's resolution. Our machine experiments explicitly model context between object categories through the use of relative location and relative scale, in addition to co-occurrence. With the use of our context model, our algorithm achieves state-of-the-art performance on the MSRC and Corel data sets. We perform recognition tests for machines and human subjects on low and high resolution images, which vary significantly in the amount of appearance information present, using just the object appearance information, the combination of appearance and context, as well as just context without object appearance information (blind recognition). We also explore the impact of the different sources of context (co-occurrence, relative-location, and relative-scale). We find that the importance of different types of contextual information varies significantly across data sets such as MSRC and PASCAL.	[Parikh, Devi] TTIC, Chicago, IL 60637 USA; [Zitnick, C. Lawrence] Microsoft Res, Redmond, WA 98052 USA; [Chen, Tsuhan] Cornell Univ, Dept Elect & Comp Engn, Ithaca, NY 14853 USA	Microsoft; Cornell University	Parikh, D (corresponding author), TTIC, 6045 S Kenwood Ave, Chicago, IL 60637 USA.	dparikh@ttic.edu; larryz@microsoft.com; tsuhan@ece.cornell.edu		Chen, Tsuhan/0000-0003-3951-7931	US National Science Foundation [1115719]	US National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported in part by the US National Science Foundation under Grant No. 1115719.	[Anonymous], 2012, MSRC 21 CLASS DATASE; [Anonymous], 2012, COREL SUBSET; [Anonymous], 2012, PASCAL VISUAL OBJECT; BACHMANN T, 1991, EUROPEAN J COGNITIVE, V3, P85; Bose B., 2004, P IEEE CS C COMP VIS; CARBONETTO P, 2004, P EUR C COMP VIS; CARBONETTO P, 2004, P 8 EUR C COMP VIS; Choi M. J., 2010, P IEEE C COMP VIS PA; Desai C., 2009, P 12 IEEE INT C COMP; Divvala S.K., 2009, P IEEE C COMP VIS PA; EFROS AA, 2003, P 9 IEEE INT C COMP; Fei-Fei L., 2004, P WORKSH GEN MOD BAS; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R., 2003, P IEEE CS C COMP VIS; FINK M, 2003, P NEUR INF PROC SYST; Gallagher A., 2008, P IEEE C COMP VIS PA; Galleguillos C., 2008, P IEEE C COMP VIS PA; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004; Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x; Griffin G., 2007, 120 CAL I TECHN; HARMON LD, 1973, SCIENCE, V180, P1194, DOI 10.1126/science.180.4091.1194; He X., 2004, P IEEE CS C COMP VIS; He X., 2006, P 9 EUR C COMP VIS; HEITZ G, 2008, P EUR C COMP VIS; HOIEM D, 2006, P IEEE CS C COMP VIS; KUMAR S, 2005, P 10 IEEE INT C COMP; Ladicky L., 2009, P 12 IEEE INT C COMP; LEE Y. J., 2010, P IEEE C COMP VIS PA; Li C., 2011, P IEEE INT C COMP VI; Lin D., 2010, P 11 EUR C COMP VIS; Malisiewicz T., 2007, P BRIT MACH VIS C; MALISIEWICZ T, 2009, P NEUR INF PROC SYST; Meltzer T., 2012, INFERENCE PACKAGE UN; MURPHY K, 2003, P NEUR INF PROC SYST; Oliva A, 2000, COGNITIVE PSYCHOL, V41, P176, DOI 10.1006/cogp.1999.0728; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Oliva Aude, 2005, P251, DOI 10.1016/B978-012375731-9/50045-8; PARIKH D, 2008, P IEEE C COMP VIS PA; Parikh D., 2008, P 10 EUR C COMP VIS; Parikh D., 2011, P IEEE C COMP VIS PA; Parikh D., 2007, P 11 IEEE C COMP VIS; Rabinovich A., 2007, P IEEE INT C COMP VI; Rabinovich A., 2007, VELEST USERS GUIDE S; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shotton J., 2012, TEXTON BOOST CODE; Shotton J., 2006, P ECCV; Singhal A., 2003, P IEEE CS C COMP VIS; Torralba A., 2001, P 8 IEEE INT C COMP; Torralba A., 2005, P NEUR INF PROC SYST; Torralba A., 2003, P 9 IEEE INT C COMP; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; VERBEEK J., 2007, P IEEE C COMP VIS PA; Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0; YANG L, 2007, P IEEE C COMP VIS PA; Yao B., 2010, P IEEE C COMP VIS PA; ZITNICK C. L., 2010, P IEEE C COMP VIS PA	58	22	22	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1978	1991		10.1109/TPAMI.2011.276	http://dx.doi.org/10.1109/TPAMI.2011.276			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22201066				2022-12-18	WOS:000307522700009
J	Loy, CC; Xiang, T; Gong, SG				Loy, Chen Change; Xiang, Tao; Gong, Shaogang			Incremental Activity Modeling in Multiple Disjoint Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unusual event detection; multicamera activity modeling; time delay estimation; incremental structure learning	NETWORKS	Activity modeling and unusual event detection in a network of cameras is challenging, particularly when the camera views are not overlapped. We show that it is possible to detect unusual events in multiple disjoint cameras as context-incoherent patterns through incremental learning of time delayed dependencies between distributed local activities observed within and across camera views. Specifically, we model multicamera activities using a Time Delayed Probabilistic Graphical Model (TD-PGM) with different nodes representing activities in different decomposed regions from different views and the directed links between nodes encoding their time delayed dependencies. To deal with visual context changes, we formulate a novel incremental learning method for modeling time delayed dependencies that change over time. We validate the effectiveness of the proposed approach using a synthetic data set and videos captured from a camera network installed at a busy underground station.	[Loy, Chen Change; Xiang, Tao; Gong, Shaogang] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Loy, CC (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.	ccloy@eecs.qmul.ac.uk; txiang@eecs.qmul.ac.uk; sgg@eecs.qmul.ac.uk		Loy, Chen Change/0000-0001-5345-1591	Engineering and Physical Sciences Research Council [EP/E028594/1, EP/G063974/1] Funding Source: researchfish; EPSRC [EP/E028594/1, EP/G063974/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Auliac C, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-91; Chen XW, 2008, IEEE T KNOWL DATA EN, V20, P628, DOI 10.1109/TKDE.2007.190732; Chen XW, 2006, BIOINFORMATICS, V22, P1367, DOI 10.1093/bioinformatics/btl090; Chickering D., 1995, P 5 C ART INT STAT, P112; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cooper GF, 1997, DATA MIN KNOWL DISC, V1, P203, DOI 10.1023/A:1009787925236; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; de Campos C.P., 2009, P 26 ANN INT C MACHI, P113; Eaton D., 2007, PROC 23 C UNCERTAINT, P101; Fanti C, 2004, ADV NEUR IN, V16, P1603; FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134; Friedman N, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P196; Friedman N., 2000, P 16 C UNC ART INT; Friedman N., 1997, P 13 C UNC ART INT U, P165; Gilks W. R., 1995, MARKOV CHAIN MONTE C, DOI 10.1201/b14835; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342; Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569; Javed O, 2005, PROC CVPR IEEE, P26; Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771; Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869; Lam W., 1994, P 10 C UNC ART INT; Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5; Loy CC, 2009, IEEE I CONF COMP VIS, P120, DOI 10.1109/ICCV.2009.5459156; Makris D, 2004, PROC CVPR IEEE, P205; Murphy K., 2001, ACTIVE LEARNING CAUS; Nielsen SH, 2008, INT J APPROX REASON, V49, P379, DOI 10.1016/j.ijar.2008.02.007; Prabhakar K., 2010, P IEEE C COMP VIS PA; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Spirtes P., 2000, CAUSATION PREDICTION; Tieu K, 2005, IEEE I CONF COMP VIS, P1842; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Wang XG, 2010, IEEE T PATTERN ANAL, V32, P56, DOI 10.1109/TPAMI.2008.241; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Xiang T, 2008, COMPUT VIS IMAGE UND, V111, P59, DOI 10.1016/j.cviu.2007.06.004; Yang Y., 2009, P IEEE INT C COMP VI; Zelniker E. E., 2008, P IEEE INT WORKSH VI; Zhou HN, 2006, INT C PATT RECOG, P1161	41	22	23	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1799	1813		10.1109/TPAMI.2011.246	http://dx.doi.org/10.1109/TPAMI.2011.246			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22184260				2022-12-18	WOS:000306409100012
J	Sun, Y; Bhanu, B				Sun, Yu; Bhanu, Bir			Reflection Symmetry-Integrated Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local and global symmetry; region growing; symmetry affinity; segmentation and symmetry evaluation; comparison of segmentation algorithms	VIEW FACE DETECTION; COLOR; SHAPE; AXES	This paper presents a new symmetry-integrated region-based image segmentation method. The method is developed to obtain improved image segmentation by exploiting image symmetry. It is realized by constructing a symmetry token that can be flexibly embedded into segmentation cues. Interesting points are initially extracted from an image by the SIFT operator and they are further refined for detecting the global bilateral symmetry. A symmetry affinity matrix is then computed using the symmetry axis and it is used explicitly as a constraint in a region growing algorithm in order to refine the symmetry of the segmented regions. A multi-objective genetic search finds the segmentation result with the highest performance for both segmentation and symmetry, which is close to the global optimum. The method has been investigated experimentally in challenging natural images and images containing man-made objects. It is shown that the proposed method outperforms current segmentation methods both with and without exploiting symmetry. A thorough experimental analysis indicates that symmetry plays an important role as a segmentation cue, in conjunction with other attributes like color and texture.	[Sun, Yu] Univ Calif Riverside, Dept Elect Engn, Riverside, CA 92521 USA; [Bhanu, Bir] Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	University of California System; University of California Riverside; University of California System; University of California Riverside	Sun, Y (corresponding author), Univ Calif Riverside, Dept Elect Engn, Riverside, CA 92521 USA.	ysun005@ucr.edu; bhanu@vislab.ucr.edu		Bhanu, Bir/0000-0001-8971-6416	US National Science Foundation [0641076, 0727129]	US National Science Foundation(National Science Foundation (NSF))	This research was supported in part by US National Science Foundation grants 0641076 and 0727129.	ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Bergo F.P.G., 2008, P IEEE INT S BIOM IM; Beucher S., 1991, P C SIGN IM PROC MIC; Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X; Bruckstein AM, 1998, PATTERN RECOGN, V31, P181, DOI 10.1016/S0031-3203(97)00018-6; Cho M., 2009, P BRIT MACH VIS C; CICCONI P, 1993, P SOC PHOTO-OPT INS, V1977, P378, DOI 10.1117/12.160482; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Combes B., 2008, P IEEE C COMP VIS PA; Giblin PJ, 2003, IEEE T PATTERN ANAL, V25, P895, DOI 10.1109/TPAMI.2003.1206518; Guo Q, 2010, IEEE T PATTERN ANAL, V32, P1730, DOI 10.1109/TPAMI.2010.13; Gupta A., 2005, P INT C IM PROC; Hafiane A., 2007, P 9 INT C ADV CONC I; Hays J., 2006, P EUR C COMP VIS; Hooda A., 2011, P INT C SCAL SPAC VA; Jiao F., 2008, P 2 INT C BIOINF BIO; Kodali Shyam P., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P763, DOI 10.1109/ICETET.2008.139; Lee S.-M., 2007, P IEEE C COMP VIS PA; Lee S, 2012, IEEE T PATTERN ANAL, V34, P266, DOI 10.1109/TPAMI.2011.118; Lee S, 2010, IEEE T PATTERN ANAL, V32, P1659, DOI 10.1109/TPAMI.2009.173; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li W.H., 2006, P IEEE INT C INT ROB; Liu J., 2010, P AS C COMP VIS; Liu T., 1998, P INT C PATT REC; Liu YX, 2003, COMPUT VIS IMAGE UND, V91, P138, DOI 10.1016/S1077-3142(03)00078-X; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Loy G., 2006, P EUR C COMP VIS; Lu YX, 2009, FOUND TRENDS COMPUT, V5, P1, DOI 10.1561/0600000008; Marola G, 2005, IEEE T PATTERN ANAL, V27, P465, DOI 10.1109/TPAMI.2005.45; Mitra N.J., 2010, P 11 EUR C COMP VIS; Mitra N.J., 2007, P ACM SIGGR; Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x; Park M., 2008, P IEEE C VIS PATT RE; Park M, 2009, IEEE T PATTERN ANAL, V31, P1804, DOI 10.1109/TPAMI.2009.73; Pauly M., 2008, P ACM SIGGR; Prasad VSN, 2004, IEEE T IMAGE PROCESS, V13, P1559, DOI 10.1109/TIP.2004.837564; Ran Y, 2010, IEEE T SYST MAN CY B, V40, P1009, DOI 10.1109/TSMCB.2010.2044173; Raviv D., 2007, P 11 IEEE INT C COMP; Raviv D, 2010, INT J COMPUT VISION, V89, P18, DOI 10.1007/s11263-010-0320-3; Ray N, 2008, COMPUTER SOC INDIA C, V31, P7; Ren X., 2006, P EUR C COMP VIS; Riklin-Raviv T., 2006, P IEEE CS C COMP VIS; Saber E, 1998, PATTERN RECOGN LETT, V19, P669, DOI 10.1016/S0167-8655(98)00044-0; Saha S., 2007, P IEEE C EV COMP; Shen DG, 1999, IEEE T PATTERN ANAL, V21, P466, DOI 10.1109/34.765657; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shor R., 2000, P INT WORKSH THEOR F; Smith A. R., 1978, COMPUTER GRAPHICS, P12, DOI [DOI 10.1145/965139.807361, 10.1145/965139.807361]; Stahl J.S., 2006, P IEEE CS C COMP VIS; Stahl JS, 2008, IEEE T PATTERN ANAL, V30, P395, DOI 10.1109/TPAMI.2007.1186; Sun Q.B., 1998, P IEEE INT C AUT FAC; Sun Y., 2009, P IEEE CS C COMP VIS; Sun Y., 2009, P IEEE C COMP VIS PA; TEBOUL O, 2010, P IEEE C COMP VIS PA; Thrun S., 2005, P 10 IEEE INT C COMP; Tuzikov AV, 2003, PATTERN RECOGN LETT, V24, P2219, DOI 10.1016/S0167-8655(03)00049-7; Wang JG, 1999, PATTERN RECOGN LETT, V20, P1053, DOI 10.1016/S0167-8655(99)00072-0; WH Li, 2005, P AUSTR C ROB AUT; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	60	22	26	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1827	1841		10.1109/TPAMI.2011.259	http://dx.doi.org/10.1109/TPAMI.2011.259			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22201051				2022-12-18	WOS:000306409100014
J	Memisevic, R; Sigal, L; Fleet, DJ				Memisevic, Roland; Sigal, Leonid; Fleet, David J.			Shared Kernel Information Embedding for Discriminative Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Latent variable models; kernel information embedding; inference; nonparametric; mutual information	COMPONENT ANALYSIS	Latent variable models, such as the GPLVM and related methods, help mitigate overfitting when learning from small or moderately sized training sets. Nevertheless, existing methods suffer from several problems: 1) complexity, 2) the lack of explicit mappings to and from the latent space, 3) an inability to cope with multimodality, and 4) the lack of a well-defined density over the latent space. We propose an LVM called the Kernel Information Embedding (KIE) that defines a coherent joint density over the input and a learned latent space. Learning is quadratic, and it works well on small data sets. We also introduce a generalization, the shared KIE (sKIE), that allows us to model multiple input spaces (e. g., image features and poses) using a single, shared latent representation. KIE and sKIE permit missing data during inference and partially labeled data during learning. We show that with data sets too large to learn a coherent global model, one can use the sKIE to learn local online models. We use sKIE for human pose inference.	[Memisevic, Roland] Goethe Univ Frankfurt, Dept Comp Sci, D-60325 Frankfurt, Germany; [Sigal, Leonid] Disney Res, Pittsburgh, PA 15213 USA; [Fleet, David J.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3H5, Canada	Goethe University Frankfurt; University of Toronto	Memisevic, R (corresponding author), Goethe Univ Frankfurt, Dept Comp Sci, Robert Mayer Str 10, D-60325 Frankfurt, Germany.	ro@cs.uni-frankfurt.de; lsigal@disneyresearch.com; fleet@cs.toronto.edu		/0000-0003-0734-7114	NSERC, Canada; Canadian Institute for Advanced Research (CIFAR); German Federal Ministry of Education and Research (BMBF) [01GQ0841]	NSERC, Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institute for Advanced Research (CIFAR)(Canadian Institute for Advanced Research (CIFAR)); German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF))	This work was supported in part by NSERC, Canada, by the Canadian Institute for Advanced Research (CIFAR), and by the German Federal Ministry of Education and Research (BMBF) in the project 01GQ0841 (BFNT Frankfurt). The authors would also like to thank the reviewers for several useful suggestions.	Agarwal A, 2004, PROC CVPR IEEE, P882; Agarwal A., 2004, P INT C MACH LEARN, P9; [Anonymous], 2006, PROC IEEE COMPUT SOC; [Anonymous], 2007, MACHINE LEARNING MUL, DOI DOI 10.1007/978-3-540-78155-4; Bengio Y, 2004, ADV NEUR IN, V16, P177; Black M. J., 2006, CS0608 BROWN U; Bo L., 2010, INT J COMPUTER VISIO; Bo L., 2008, P IEEE C COMP VIS PA; Brox T., 2007, P 2 INT WORKSH HUM M; Carreira-Perpinan M. A., 1999, P NEUR INF PROC SYST, V12, P414; Carreira-Perpinan MA, 2010, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR.2010.5539862; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771; Jaeggli T, 2006, LECT NOTES COMPUT SC, V4069, P494; Kanaujia A., 2007, P IEEE C COMP VIS PA; KANAUJIA A, 2007, P IEEE INT C COMP VI; Kuss Malte, 2003, 108 M PLANCK I BIOL; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lu Z., 2008, ADV NEURAL INFORM PR, V20, P1705; Lu Zhengdong, 2007, J MACH LEARN RES, P59; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Meinicke P, 2005, IEEE T PATTERN ANAL, V27, P1379, DOI 10.1109/TPAMI.2005.183; Memisevic R., 2006, P INT C MACH LEARN, P633; Memisevic R., 2008, THESIS U TORONTO; Navaratnam R., 2007, P 11 IEEE INT C COMP; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Ranzato M., 2006, P ADV NEUR INF PROC; Raykar V., 2006, IMPROVED FAST GAUSS; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Salzmann M., 2010, P 13 INT C ART INT S; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scott D.W, 1992, WILEY SERIES PROBABI; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; SHON AP, 2006, P NIPS, P1233; Sigal Leonid, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2852, DOI 10.1109/CVPRW.2009.5206576; SIGAL L, 2007, P NEUR INF PROC SYST; Sminchisescu C, 2005, PROC CVPR IEEE, P390; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Thayananthan A, 2006, LECT NOTES COMPUT SC, V3953, P124, DOI 10.1007/11744078_10; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Urtasun R., 2008, P IEEE C COMP VIS PA	42	22	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					778	790		10.1109/TPAMI.2011.154	http://dx.doi.org/10.1109/TPAMI.2011.154			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	21808087				2022-12-18	WOS:000300581700011
J	Yu, SX				Yu, Stella X.			Angular Embedding: A Robust Quadratic Criterion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Least squares methods; spectral methods; graph algorithms; constrained optimization; linear programming; statistical computing; clustering; modeling and recovery of physical attributes	GEOMETRIC DIFFUSIONS; STRUCTURE DEFINITION; IMAGE SEGMENTATION; RANK PRESERVATION; HARMONIC-ANALYSIS; LEAST-SQUARES; DECOMPOSITION; ALGORITHMS; TOOL	Given the size and confidence of pairwise local orderings, angular embedding (AE) finds a global ordering with a near-global optimal eigensolution. As a quadratic criterion in the complex domain, AE is remarkably robust to outliers, unlike its real domain counterpart LS, the least squares embedding. Our comparative study of LS and AE reveals that AE's robustness is due not to the particular choice of the criterion, but to the choice of representation in the complex domain. When the embedding is encoded in the angular space, we not only have a nonconvex error function that delivers robustness, but also have a Hermitian graph Laplacian that completely determines the optimum and delivers efficiency. The high quality of embedding by AE in the presence of outliers can hardly be matched by LS, its corresponding L(1) norm formulation, or their bounded versions. These results suggest that the key to overcoming outliers lies not with additionally imposing constraints on the embedding solution, but with adaptively penalizing inconsistency between measurements themselves. AE thus significantly advances statistical ranking methods by removing the impact of outliers directly without explicit inconsistency characterization, and advances spectral clustering methods by covering the entire size-confidence measurement space and providing an ordered cluster organization.	Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA	Boston College	Yu, SX (corresponding author), Boston Coll, Dept Comp Sci, 140 Commonwealth Ave, Chestnut Hill, MA 02467 USA.	stella.yu@bc.edu			US National Science Foundation (NSF) [IIS-0644204]; Clare Boothe Luce Professorship	US National Science Foundation (NSF)(National Science Foundation (NSF)); Clare Boothe Luce Professorship	This research was funded by US National Science Foundation (NSF) CAREER IIS-0644204 and a Clare Boothe Luce Professorship. The author would like to thank Francis Bach and anonymous reviewers for thoughtful comments and excellent suggestions.	Agrawal A, 2005, ACM T GRAPHIC, V24, P828, DOI 10.1145/1073204.1073269; [Anonymous], [No title captured]; Bach F., 2004, P NEUR INF PROC SYST; Bagon S., 2010, P IEEE C COMP VIS PA; BELL RM, 2007, P INT C MACH LEARN; BERNARDIS E, 2010, P IEEE C COMP VIS PA; Bishop C.M, 2006, PATTERN RECOGN; Boyd S, 2004, CONVEX OPTIMIZATION; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243, DOI 10.1613/jair.587; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7432, DOI 10.1073/pnas.0500896102; CORTES C, 2007, P INT C MACH LEARN; DIACONIS P, 1989, ANN STAT, V17, P949, DOI 10.1214/aos/1176347251; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fattal R, 2002, ACM T GRAPHIC, V21, P249; FORSYTH D, 2001, P IEEE INT C COMP VI; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Guo QH, 2005, PATTERN RECOGN LETT, V26, P493, DOI 10.1016/j.patrec.2004.08.008; Herbrich R, 2000, ADV NEUR IN, P115; Horn B.K.P., 1989, SHAPE SHADING; Jiang XY, 2011, MATH PROGRAM, V127, P203, DOI 10.1007/s10107-010-0419-x; KOVESI P, 2005, P IEEE INT C COMP VI; KUCZYNSKI J, 1992, SIAM J MATRIX ANAL A, V13, P1094, DOI 10.1137/0613066; Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168; MA M, 2006, MATRIX APPROACH ASSE; MAIRE M, 2010, P EUR C COMP VIS; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Markovsky I, 2007, SIGNAL PROCESS, V87, P2283, DOI 10.1016/j.sigpro.2007.04.004; MEILA M, 2001, P NEUR INF PROC SYST; MOSTELLER F, 1951, PSYCHOMETRIKA, V16, P207; MOSTELLER F, 1951, PSYCHOMETRIKA, V16, P203; NADLER B, 2006, P NEUR INF PROC SYST; Ng A. Y., 2002, P NEUR INF PROC SYST; Petronetto F, 2010, IEEE T VIS COMPUT GR, V16, P338, DOI 10.1109/TVCG.2009.61; PETROVIC N, 2001, P IEEE C COMP VIS PA; POLTHIER K, 2000, P EUR WORKSH SCI VIS; Polthier K., 2003, VISUALIZATION MATH, VIII; ROUSSEEUW RJ, 1987, ROBUST REGRESSION OU; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saaty TL, 2009, MATH COMPUT MODEL, V49, P1230, DOI 10.1016/j.mcm.2008.08.001; SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5; SAATY TL, 1984, J MATH PSYCHOL, V28, P205, DOI 10.1016/0022-2496(84)90027-0; Sen A, 1999, AM ECON REV, V89, P349, DOI 10.1257/aer.89.3.349; SHASHUA A, 2003, P NEUR INF PROC SYST; Shi J., 1997, P IEEE C COMP VIS PA; SHI J, 1998, P IEEE INT C COMP VI; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; Singer A, 2009, SIAM J IMAGING SCI, V2, P118, DOI 10.1137/070712146; Spielman D. A., 2004, P ANN ACM S THEOR CO; STARK PB, 1995, COMPUTATION STAT, V10, P129; Stein A., 2008, P IEEE C COMP VIS PA; Tong YY, 2003, ACM T GRAPHIC, V22, P445, DOI 10.1145/882262.882290; TOSHEV A, 2007, P IEEE C COMP VIS PA; VITALADEVUNI S, 2010, P IEEE C COMP VIS PA; Weiss Y., 1999, P IEEE INT C COMP VI; Yu S., 2003, P IEEE INT C COMP VI; Yu S., 2008, P IEEE WORKSH PERC O; Yu S.X., 2003, P IEEE C COMP VIS PA; YU SX, 2001, P IEEE INT C COMP VI; YU SX, 2009, P IEEE C COMP VIS PA; Yuille A., 1997, P IEEE C COMP VIS PA; ZHU Q, 2007, P IEEE INT C COMP VI; [No title captured]	66	22	22	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					158	173		10.1109/TPAMI.2011.107	http://dx.doi.org/10.1109/TPAMI.2011.107			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576735				2022-12-18	WOS:000297069900011
J	Ong, EJ; Bowden, R				Ong, Eng-Jon; Bowden, Richard			Robust Facial Feature Tracking Using Shape-Constrained Multiresolution-Selected Linear Predictors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial feature tracking; learning; linear predictors; multiple resolution; probabilistic selection	ACTIVE APPEARANCE MODELS	This paper proposes a learned data-driven approach for accurate, real-time tracking of facial features using only intensity information. The task of automatic facial feature tracking is nontrivial since the face is a highly deformable object with large textural variations and motion in certain regions. Existing works attempt to address these problems by either limiting themselves to tracking feature points with strong and unique visual cues (e. g., mouth and eye corners) or by incorporating a priori information that needs to be manually designed (e. g., selecting points for a shape model). The framework proposed here largely avoids the need for such restrictions by automatically identifying the optimal visual support required for tracking a single facial feature point. This automatic identification of the visual context required for tracking allows the proposed method to potentially track any point on the face. Tracking is achieved via linear predictors which provide a fast and effective method for mapping pixel intensities into tracked feature position displacements. Building upon the simplicity and strengths of linear predictors, a more robust biased linear predictor is introduced. Multiple linear predictors are then grouped into a rigid flock to further increase robustness. To improve tracking accuracy, a novel probabilistic selection method is used to identify relevant visual areas for tracking a feature point. These selected flocks are then combined into a hierarchical multiresolution LP model. Finally, we also exploit a simple shape constraint for correcting the occasional tracking failure of a minority of feature points. Experimental results show that this method performs more robustly and accurately than AAMs, with minimal training examples on example sequences that range from SD quality to Youtube quality. Additionally, an analysis of the visual support consistency across different subjects is also provided.	[Ong, Eng-Jon; Bowden, Richard] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Ong, EJ (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	e.ong@surrey.ac.uk; r.bowden@surrey.ac.uk	Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020	EPSRC [EP/E027946/1]; European Community [231135 DictaSign]; Engineering and Physical Sciences Research Council [EP/E027946/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); European Community(European Commission); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work has been supported by the EPSRC project LILiR (EP/E027946/1) and the European Community Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 231135 DictaSign. The authors would like to acknowledge the authors of [28] and the following people: Yuxuan Lan, Barry Theobald, and Richard Harvey from the University of East Anglia for providing them with an implementation of the AAM method and expertise in using it to perform the experiments described in Section 6.	BARNARD M, 2002, P 5 AS C COMP VIS JA; BREGLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P494, DOI 10.1109/ICCV.1995.466899; BURL MC, 1995, P INT WORKSH AUT FAC, P154; Castelli I., 2008, P 8 IEEE INT C FAC G, P1; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; CRISTINACCE D, 2006, P 17 BRIT MACH VIS C, P929; Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28; Dornaika F, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P3, DOI 10.1109/ACV.2002.1182135; Dornaika F, 2006, IMAGE VISION COMPUT, V24, P1010, DOI 10.1016/j.imavis.2006.02.025; Hamouz M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P67, DOI 10.1109/AFGR.2004.1301510; HOEY J, 2006, P BRIT MACH VIS C, P367; Kanaujia A, 2006, LECT NOTES COMPUT SC, V4338, P492; Kolsch M., 2004, IEEE WORKSH REAL TIM, P158, DOI DOI 10.1109/CVPR.2004.345; Lievin M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P691, DOI 10.1109/MMCS.1999.779283; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; LOURAKIS M, 2006, HOMEST A C C LIB ROB; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37; NGUYEN MH, 2008, P IEEE C COMP VIS PA; ONG E, 2008, P 8 IEEE C AUT FAC G; Ong E., 2009, P 12 INT C COMP VIS; PATRAS I, 2007, P IEEE C COMP VIS PA, P1; Sukno FM, 2007, IEEE T PATTERN ANAL, V29, P1105, DOI 10.1109/TPAMI.2007.1041; Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1; Theobald BJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P149; Tomasi C, 1991, CMUCS91132; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; Wu H., 2008, P IEEE C COMP VIS PA; WU Z, 2002, P 4 IEEE C MULT INT; Xiao J, 2004, PROC CVPR IEEE, P535; Yow KC, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P16, DOI 10.1109/AFGR.1996.557238; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhang L., 2005, P INT C IM PROC, VII, P354; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119	38	22	24	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1844	1859		10.1109/TPAMI.2010.205	http://dx.doi.org/10.1109/TPAMI.2010.205			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21135441	Green Published			2022-12-18	WOS:000292740000011
J	Yuan, JS; Liu, ZC; Wu, Y				Yuan, Junsong; Liu, Zicheng; Wu, Ying			Discriminative Video Pattern Search for Efficient Action Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video pattern search; action detection; spatiotemporal branch-and-bound search	RECOGNITION	Actions are spatiotemporal patterns. Similar to the sliding window-based object detection, action detection finds the reoccurrences of such spatiotemporal patterns through pattern matching, by handling cluttered and dynamic backgrounds and other types of action variations. We address two critical issues in pattern matching-based action detection: 1) the intrapattern variations in actions, and 2) the computational efficiency in performing action pattern search in cluttered scenes. First, we propose a discriminative pattern matching criterion for action classification, called naive Bayes mutual information maximization (NBMIM). Each action is characterized by a collection of spatiotemporal invariant features and we match it with an action class by measuring the mutual information between them. Based on this matching criterion, action detection is to localize a subvolume in the volumetric video space that has the maximum mutual information toward a specific action class. A novel spatiotemporal branch-and-bound (STBB) search algorithm is designed to efficiently find the optimal solution. Our proposed action detection method does not rely on the results of human detection, tracking, or background subtraction. It can handle action variations such as performing speed and style variations as well as scale changes well. It is also insensitive to dynamic and cluttered backgrounds and even to partial occlusions. The cross-data set experiments on action detection, including KTH, CMU action data sets, and another new MSR action data set, demonstrate the effectiveness and efficiency of the proposed multiclass multiple-instance action detection method.	[Yuan, Junsong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore; [Liu, Zicheng] Microsoft Res, Redmond, WA 98052 USA; [Wu, Ying] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Microsoft; Northwestern University	Yuan, JS (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore, Singapore.	jsyuan@ntu.edu.sg; zliu@microsoft.com; yingwu@eecs.northwestern.edu	Yuan, Junsong/R-4352-2019; Wu, Ying/B-7283-2009; Yuan, Junsong/A-5171-2011	Koochak, Atousa/0000-0001-6547-2728	Nanyang Assistant Professorship; US National Science Foundation [IIS-0347877, IIS-0916607]; US Army Research Laboratory; US Army Research Office [ARO W911NF-08-1-0504]	Nanyang Assistant Professorship; US National Science Foundation(National Science Foundation (NSF)); US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office	This work was supported in part by the Nanyang Assistant Professorship to Dr. Junsong Yuan, US National Science Foundation grant IIS-0347877, IIS-0916607, and the US Army Research Laboratory and the US Army Research Office under grant ARO W911NF-08-1-0504. The authors thank Dr. Yan Ke, Dr. Cha Zhang, and Dr. Zhengyou Zhang for helpful discussions, and Liangliang Cao for the help on the experiments of the TRECVID data set.	Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Ali S, 2007, PROC CVPR IEEE, P65; [Anonymous], 2007, 2007 IEEE C COMP VIS; BENTLEY J, 1984, ACM COMMU, V27, P865; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Cao L., 2010, P IEEE C COMP VIS PA; Chatterjee A, 2009, PR IEEE COMP DESIGN, P319, DOI 10.1109/ICCD.2009.5413136; Datar M., 2004, P 20 ANN S COMP GEOM, P253; DHILLON PS, 2008, COMBINING APPEARANCE; DIKMEN M, 2008, P VID EV WORKSH; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; EFROS AA, 2003, P IEEE INT C COMP VI, V2; Fathi A, 2008, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2008.4587735; Hu YX, 2009, IEEE I CONF COMP VIS, P128, DOI 10.1109/ICCV.2009.5459153; Jia K., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587732; JIANG H, 2006, P IEEE C COMP VIS PA, P1646; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Ke Y, 2007, IEEE I CONF COMP VIS, P1424; Lampert CH, 2009, IEEE I CONF COMP VIS, P987, DOI 10.1109/ICCV.2009.5459359; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2007, P IEEE INT C COMP VI; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023; Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Liu JG, 2009, PROC CVPR IEEE, P1996; Liu Q, 2008, IEEE IC COMP COM NET, P1; Natarajan P, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P87; NGUYEN N, 2005, P IEEE C COMP VIS PA, V2; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Reddy KK, 2009, IEEE I CONF COMP VIS, P1010, DOI 10.1109/ICCV.2009.5459374; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, P ACM MULT; Shechtman E, 2005, PROC CVPR IEEE, P405; Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; VITALADEVUNI SN, 2008, P C COMP VIS PATT RE, P1; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Weinland D., 2008, CVPR 2008, P1, DOI DOI 10.1109/CVPR.2008.4587731; WEINLAND D, 2006, COMPUTER VISION IMAG, V104, P207; Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Yilmaz A., 2005, P IEEE C COMP VIS PA; YUAN J, 2009, P ACM MULT WORKSH EV; Yuan Jun-hui, 2010, Zhonghua Yixue Yichuanxue Zazhi, V27, P136, DOI 10.3760/cma.j.issn.1003-9406.2010.02.004; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60	56	22	26	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1728	1743		10.1109/TPAMI.2011.38	http://dx.doi.org/10.1109/TPAMI.2011.38			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21339530	Green Accepted			2022-12-18	WOS:000292740000003
J	Lee, W; Woo, W; Boyer, E				Lee, Wonwoo; Woo, Woontack; Boyer, Edmond			Silhouette Segmentation in Multiple Views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Background region; foreground region; multiview silhouette consistency; silhouette segmentation		In this paper, we present a method for extracting consistent foreground regions when multiple views of a scene are available. We propose a framework that automatically identifies such regions in images under the assumption that, in each image, background and foreground regions present different color properties. To achieve this task, monocular color information is not sufficient and we exploit the spatial consistency constraint that several image projections of the same space region must satisfy. Combining the monocular color consistency constraint with multiview spatial constraints allows us to automatically and simultaneously segment the foreground and background regions in multiview images. In contrast to standard background subtraction methods, the proposed approach does not require a priori knowledge of the background nor user interaction. Experimental results under realistic scenarios demonstrate the effectiveness of the method for multiple camera set ups.	[Lee, Wonwoo; Woo, Woontack] Gwangju Inst Sci & Technol, GIST U VR Lab, Kwangju 500712, South Korea; [Boyer, Edmond] INRIA Grenoble Rhone Alpes, F-38334 Saint Ismier, France	Gwangju Institute of Science & Technology (GIST)	Lee, W (corresponding author), Gwangju Inst Sci & Technol, GIST U VR Lab, 261 Chemdan Gwagiro Oryong Dong, Kwangju 500712, South Korea.	wlee@gist.ac.kr; wwoo@gist.ac.kr; edmond.boyer@inrialpes.fr	Woo, Woontack/C-3696-2012		Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content Agency (KOCCA)	Ministry of Culture, Sports and Tourism (MCST)(Ministry of Culture, Sports & Tourism (MCST), Republic of Korea); Korea Creative Content Agency (KOCCA)(Korea Creative Content Agency (KOCCA))	This research is supported by the Ministry of Culture, Sports and Tourism (MCST) and Korea Creative Content Agency (KOCCA), under the Culture Technology (CT) Research & Development Program 2009.	[Anonymous], 2007, SIFTGPU GPU IMPLEMEN; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Boyer E, 2006, LECT NOTES COMPUT SC, V3851, P1; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Bray M, 2006, LECT NOTES COMPUT SC, V3952, P642; CAMPBELL N, 2007, P BRIT MACH VIS C, V1, P530; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Franco JS, 2005, IEEE I CONF COMP VIS, P1747; Freedman D, 2005, PROC CVPR IEEE, P755; Friedman N., 1997, CVPR, P130; Furukawa Y, 2006, LECT NOTES COMPUT SC, V3951, P564; Gordon G, 1999, P IEEE C COMP VIS PA, P2459, DOI [10.1109/CVPR.1999.784721, DOI 10.1109/CVPR.1999.784721]; Harwood D., 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48; Khan SA, 2008, 2008 IEEE SWARM INTELLIGENCE SYMPOSIUM, P187; Kim N, 2006, IEEE T SYST MAN CY A, V36, P758, DOI 10.1109/TSMCA.2005.855752; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193; Kompatsiaris I, 1998, IEEE T CIRC SYST VID, V8, P547, DOI 10.1109/76.718502; Lai PT, 2008, PROCEEDINGS OF THE 2009 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P1; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Micusik B, 2006, LECT NOTES COMPUT SC, V3952, P468; MORTENSEN EN, 2006, P IEEE C COMP VIS PA, V1, P1007; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; ROTHER C, 2004, P ACM SIGGRAPH, V24, P309; Rowe S, 1996, IMAGE VISION COMPUT, V14, P549, DOI 10.1016/0262-8856(96)01103-1; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; SORMANN M, 2006, P INT S 3D DAT PROC; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628; TOYAMA K, 1999, INT C COMP VIS, P255, DOI DOI 10.1109/ICCV.1999.791228; Vu N., 2008, P IEEE COMP SOC C CO, P1, DOI DOI 10.1109/CVPR.2008.4587450; Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; XIN G, 2008, P 17 INT C COMP COMM, P1, DOI DOI 10.1109/ICCCN.2008.ECP.143; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166; ZENG G, 2004, P AS C COMP VIS, V2, P628; 2010, KUNG FU GIRL DATA SE; 2010, TEMPLE DATA SET MULT; 2009, DANCER DATA SET MULT; 2010, VIOLET DATA SET MULT; 2010, BUST DATA SET; 2009, CAMERA CALIBRATION T; 2009, GML C CAMERA CALIBRA	48	22	25	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1429	1441		10.1109/TPAMI.2010.196	http://dx.doi.org/10.1109/TPAMI.2010.196			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21079278	Green Published, Green Submitted			2022-12-18	WOS:000290574000011
J	Hernandez, C; Vogiatzis, G; Cipolla, R				Hernandez, Carlos; Vogiatzis, George; Cipolla, Roberto			Overcoming Shadows in 3-Source Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; shadows	MULTIPLE IMAGES; SHAPE; RECONSTRUCTION; INTEGRABILITY	Light occlusions are one of the most significant difficulties of photometric stereo methods. When three or more images are available without occlusion, the local surface orientation is overdetermined so that shape can be computed and the shadowed pixels can be discarded. In this paper, we look at the challenging case when only two images are available without occlusion, leading to a one degree of freedom ambiguity per pixel in the local orientation. We show that, in the presence of noise, integrability alone cannot resolve this ambiguity and reconstruct the geometry in the shadowed regions. As the problem is ill-posed in the presence of noise, we describe two regularization schemes that improve the numerical performance of the algorithm while preserving the data. Finally, the paper describes how this theory applies in the framework of color photometric stereo where one is restricted to only three images and light occlusions are common. Experiments on synthetic and real image sequences are presented.	[Hernandez, Carlos] Google Inc, Seattle, WA 98103 USA; [Vogiatzis, George] Aston Univ, Sch Engn & Appl Sci, Dept Comp Sci, Birmingham B4 7ET, W Midlands, England; [Cipolla, Roberto] Univ Cambridge, Dept Engn, Fallside Lab, Cambridge CB2 1PZ, England	Google Incorporated; Aston University; University of Cambridge	Hernandez, C (corresponding author), Google Inc, 651 N 34th St, Seattle, WA 98103 USA.	carloshernandez@google.com; g.vogiatzis@aston.co.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Vogiatzis, George/0000-0002-3226-0603; Cipolla, Roberto/0000-0002-8999-2151				AGRAWAL A, 2006, P EUR C COMP VIS, P578; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Chandraker M.K., 2007, P IEEE C COMP VIS PA; COLEMAN EN, 1992, SHAPE RECOVERY, P180; Daum M, 1998, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.1998.698646; Davis TA, 2004, ACM T MATH SOFTWARE, V30, P196, DOI 10.1145/992200.992206; Drew M. S., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P419, DOI 10.1109/ISCV.1995.477038; Fan J, 1997, COMPUT VIS IMAGE UND, V65, P347, DOI 10.1006/cviu.1996.0581; HERNANDEZ C, 2008, P 10 EUR C COMP VIS; HERNANDEZ C, 2007, P 11 INT C COMP VIS; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; LEE S, 1991, IMAGE VISION COMPUT, V9, P39, DOI 10.1016/0262-8856(91)90047-S; ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773; PETROV A, 1987, COGNITIVE PROCESS, P350; Tankus A, 2005, IEEE I CONF COMP VIS, P611; WOLFF LB, 1994, P 3 EUR C COMP VIS, V2, P247; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Yu YH, 2005, INT J COMPUT VISION, V62, P35, DOI 10.1007/s11263-005-4634-5; Yuille A, 1997, PROC CVPR IEEE, P158, DOI 10.1109/CVPR.1997.609314; [No title captured]	21	22	29	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					419	426		10.1109/TPAMI.2010.181	http://dx.doi.org/10.1109/TPAMI.2010.181			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20921582	Green Submitted, Green Accepted			2022-12-18	WOS:000285313200017
J	Lim, J; Barnes, N; Li, HD				Lim, John; Barnes, Nick; Li, Hongdong			Estimating Relative Camera Motion from the Antipodal-Epipolar Constraint	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiview geometry; antipodal points; epipolar constraint; structure and motion; Hough; robust estimation	RANSAC	This paper introduces a novel antipodal-epipolar constraint on relative camera motion. By using antipodal points, which are available in large Field-of-View cameras, the translational and rotational motions of a camera are geometrically decoupled, allowing them to be separately estimated as two problems in smaller dimensions. We present a new formulation based on discrete camera motions, which works over a larger range of motions compared to previous differential techniques using antipodal points. The use of our constraints is demonstrated with two robust and practical algorithms, one based on RANSAC and the other based on Hough-like voting. As an application of the motion decoupling property, we also present a new structure-from-motion algorithm that does not require explicitly estimating rotation (it uses only the translation found with our methods). Finally, experiments involving simulations and real image sequences will demonstrate that our algorithms perform accurately and robustly, with some advantages over the state-of-the-art.	[Lim, John; Barnes, Nick; Li, Hongdong] Australian Natl Univ, NICTA, Canberra, ACT 2601, Australia; [Lim, John; Barnes, Nick; Li, Hongdong] Australian Natl Univ, Dept Engn, Canberra, ACT 2601, Australia	Australian National University; Australian National University	Lim, J (corresponding author), Australian Natl Univ, NICTA, GPO Box 4, Canberra, ACT 2601, Australia.	john.lim@rsise.anu.edu.au; nick.barnes@nicta.com.au; hongdong.li@anu.edu.au	Barnes, Nick/Y-2744-2018	Barnes, Nick/0000-0002-9343-9535	Australian Government; Australian Research Council (ARC) through the ICT Centre of Excellence; ARC through its Special Research Initiative (SRI)	Australian Government(Australian GovernmentCGIAR); Australian Research Council (ARC) through the ICT Centre of Excellence(Australian Research Council); ARC through its Special Research Initiative (SRI)(Australian Research Council)	NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications, and the Digital Economy, and the Australian Research Council (ARC) through the ICT Centre of Excellence Program. This research was also supported in part by ARC through its Special Research Initiative (SRI) in Bionic Vision Science and Technology grant to Bionic Vision Australia (BVA).	ANTONE M, 2000, P IEEE CS C COMP VIS; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; Bazin JC, 2010, COMPUT VIS IMAGE UND, V114, P254, DOI 10.1016/j.cviu.2009.04.006; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; DENHOLLANDER RJM, 2007, P 18 BRIT MACH VIS C; FERMULLER C, 1995, INT J COMPUT VISION, V15, P7, DOI 10.1007/BF01450848; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GLUCKMAN J, 1998, P IEEE INT C COMP VI; Hart D, 2009, BRIT J RADIOL, V82, P1, DOI 10.1259/bjr/12568539; HARTLEY R, 2007, P IEEE INT C COMP VI; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; Hu CX, 2009, INT J COMPUT VISION, V84, P21, DOI 10.1007/s11263-009-0226-0; Kanatani K, 2000, J ELECTRON IMAGING, V9, P194, DOI 10.1117/1.482739; Kanatani K., 1996, STAT OPTIMIZATION GE; KOVESI PD, 2009, MATLAB OCTAVE FUNCTI; Kukelova Z., 2008, P BRIT MACH VIS C; Li H., 2009, P IEEE INT C COMP VI; Li HD, 2006, INT C PATT RECOG, P630; LIM J, 2007, P WORKSH OMN VIS CAM; LIM J, 2008, P IEEE CS C COMP VIS; Lim J, 2010, COMPUT VIS IMAGE UND, V114, P245, DOI 10.1016/j.cviu.2009.04.005; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LOWE D, 2009, SIFT CODE; Luong Q.-T., 1993, RR1894 INRIA; MAKADIA A, 2005, P IEEE CS C COMP VIS; Mariottini GL, 2008, INT J ROBOT RES, V27, P41, DOI 10.1177/0278364907084320; Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009; Nister D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P737, DOI 10.1109/ICCV.1999.790295; Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853; Oliensis J, 2000, COMPUT VIS IMAGE UND, V80, P172, DOI 10.1006/cviu.2000.0869; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; PRAZDNY K, 1983, COMPUT VISION GRAPH, V22, P239, DOI 10.1016/0734-189X(83)90067-1; RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354; Rother C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P42, DOI 10.1109/ICCV.2001.937497; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; STEWENIUS H, 2007, P IEEE CS C COMP VIS; THOMAS I, 1994, LINEAR STRUCTURE MOT; TOLA E, 2008, P IEEE CS C COMP VIS; Tomasi C., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P422, DOI 10.1109/CVPR.1993.341096; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; TRIGGS B, 2000, P EUR C COMP VIS, P522; ZHANG Z, 1996, RR2927 INRIA	49	22	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1907	U188		10.1109/TPAMI.2010.113	http://dx.doi.org/10.1109/TPAMI.2010.113			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20513926	Green Submitted			2022-12-18	WOS:000281000700015
J	Kushnir, D; Galun, M; Brandt, A				Kushnir, Dan; Galun, Meirav; Brandt, Achi			Efficient Multilevel Eigensolvers with Applications to Data Analysis Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Eigenvalues and eigenvectors; multigrid and multilevel methods; graph algorithms; segmentation; clustering	SMOOTHED AGGREGATION; EIGENVALUE PROBLEMS; ALGORITHM; SA	Multigrid solvers proved very efficient for solving massive systems of equations in various fields. These solvers are based on iterative relaxation schemes together with the approximation of the "smooth" error function on a coarser level (grid). We present two efficient multilevel eigensolvers for solving massive eigenvalue problems that emerge in data analysis tasks. The first solver, a version of classical algebraic multigrid (AMG), is applied to eigenproblems arising in clustering, image segmentation, and dimensionality reduction, demonstrating an order of magnitude speedup compared to the popular Lanczos algorithm. The second solver is based on a new, much more accurate interpolation scheme. It enables calculating a large number of eigenvectors very inexpensively.	[Kushnir, Dan] Yale Univ, Dept Math, New Haven, CT 06520 USA; [Galun, Meirav; Brandt, Achi] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Yale University; Weizmann Institute of Science	Kushnir, D (corresponding author), Yale Univ, Dept Math, 51 Prospect St, New Haven, CT 06520 USA.	dan.kushnir@yale.edu; meirav.galun@weizmann.ac.il; achi.brandt@weizmann.ac.il						Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Borzi A, 2006, INT J NUMER METH ENG, V65, P1186, DOI 10.1002/nme.1478; BRANDT A, 1983, SIAM J SCI STAT COMP, V4, P244, DOI 10.1137/0904019; Brandt A., 2002, MULTISCALE MULTIRESO; Brandt A., 1982, ALGEBRAIC MULTIGRID; Brandt A., 2003, MULTILEVEL OPTIMIZAT; BRANDT A, 2008, BRIDGING SCALES SCI; BRANNIGAN A, 1986, AUST NZ J CRIMINOL, V19, P23, DOI 10.1016/0096-3003(86)90095-0; Brezina M, 2008, NUMER LINEAR ALGEBR, V15, P249, DOI 10.1002/nla.575; Brezina M, 2004, SIAM J SCI COMPUT, V25, P1896, DOI 10.1137/S1064827502418598; Brezina M, 2006, SIAM J SCI COMPUT, V27, P1261, DOI 10.1137/040614402; Brezina M, 2005, SIAM REV, V47, P317, DOI 10.1137/050626272; Chung F., 1997, AM MATH SOC, V92; COSTINER S, 1995, PHYS REV E, V51, P3704, DOI 10.1103/PhysRevE.51.3704; Cour T., 2005, P IEEE INT C COMP VI; De Berg Mark, 1997, COMPUTATIONAL GEOMET; De Sterck H, 2008, SIAM J SCI COMPUT, V30, P2235, DOI 10.1137/070685142; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Elman HC, 2001, SIAM J SCI COMPUT, V23, P1290; Erlangga Y, 2006, SIAM J SCI COMPUT, V27, P1471, DOI 10.1137/040615195; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Golub G. H., 1996, MATRIX COMPUTATIONS; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; Hetmaniuk U, 2007, NUMER LINEAR ALGEBR, V14, P563, DOI 10.1002/nla.545; Horton G., 1994, Performance Evaluation Review, V22, P191, DOI 10.1145/183019.183040; ISENSEE C, 2004, SIMULATION VISUALISI; Kaczmarz S., 1937, B INT ACAD POL SCI L, V35, P355; Krieger UR, 1995, COMPUTATIONS WITH MARKOV CHAINS, P403; Kushnir D, 2006, PATTERN RECOGN, V39, P1876, DOI 10.1016/j.patcog.2006.04.007; LEHOUCQ RB, 1998, ARPACK USER GUIDE; Leutenegger ST, 1995, COMPUTATIONS WITH MARKOV CHAINS, P425; LIVNE O, 2001, MULTISCALE COMPUTATI; Livshits I, 2008, SIAM J SCI COMPUT, V30, P416, DOI 10.1137/070684197; Livshits I, 2004, NUMER LINEAR ALGEBR, V11, P229, DOI 10.1002/nla.379; MANDEL J, 1989, J COMPUT PHYS, V80, P442, DOI 10.1016/0021-9991(89)90109-5; MCCORMICK SF, 1981, MATH COMPUT, V36, P485, DOI 10.2307/2007654; Ng AY, 2002, ADV NEUR IN, V14, P849; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; TAKAHASHI Y, 1975, B18 TOK 23 I TECHN D; TROTTENBERG U., 2000, MULTIGRID; Vanek P, 1996, COMPUTING, V56, P179, DOI 10.1007/BF02238511; Yu S. X., 2003, P 9 IEEE INT C COMP; [No title captured]	44	22	23	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1377	1391		10.1109/TPAMI.2009.147	http://dx.doi.org/10.1109/TPAMI.2009.147			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558872				2022-12-18	WOS:000278858600003
J	Cao, H; Govindaraju, V				Cao, Huaigu; Govindaraju, Venu			Preprocessing of Low-Quality Handwritten Documents Using Markov Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random field; image segmentation; document analysis; handwriting recognition	RESTORATION	This paper presents a statistical approach to the preprocessing of degraded handwritten forms including the steps of binarization and form line removal. The degraded image is modeled by a Markov Random Field (MRF) where the hidden-layer prior probability is learned from a training set of high-quality binarized images and the observation probability density is learned on-the-fly from the gray-level histogram of the input image. We have modified the MRF model to drop the preprinted ruling lines from the image. We use the patch-based topology of the MRF and Belief Propagation (BP) for efficiency in processing. To further improve the processing speed, we prune unlikely solutions from the search space while solving the MRF. Experimental results show higher accuracy on two data sets of degraded handwritten images than previously used methods.	[Cao, Huaigu; Govindaraju, Venu] SUNY Buffalo, CUBS, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Cao, H (corresponding author), SUNY Buffalo, CUBS, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.	hcao@bbn.com; venu@cubs.buffalo.edu			US National Science Foundation [0429358]	US National Science Foundation(National Science Foundation (NSF))	This work was supported by US National Science Foundation Grant 0429358.	Bai ZL, 2004, INT C PATT RECOG, P578; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; CAO H, 2007, P IEEE CS C COMP VIS; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GUPTA MD, 2006, P COMP VIS PATT REC; GUPTA MD, 2005, P IEEE CS C COMP VIS; HOWE NR, 2005, P SIGIR, P377; Jojic N., 2003, P 9 IEEE INT C COMP; KAMEL M, 1993, CVGIP GRAPHIC MODELS, V55; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; MILEWSKI R, 2006, P 7 INT WORKSH DOC A, P106; Niblack W., 1986, ADV COMPUTER GRAPHIC; Otsu N., 1979, IEEE T SYSTEMS MAN C, VSMC-9; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Sauvola J, 1997, PROC INT CONF DOC, P147, DOI 10.1109/ICDAR.1997.619831; Seeger M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P54, DOI 10.1109/ICDAR.2001.953754; Wolf C., 2002, P 16 INT C PATT REC; YANG Y, 2000, PATTERN RECOGN, P787; YASUDA M, 2005, P INT C COMP INT MOD, V2, P747; Yoo JY, 1997, PROC INT CONF DOC, P128, DOI 10.1109/ICDAR.1997.619827	23	22	22	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1184	1194		10.1109/TPAMI.2008.126	http://dx.doi.org/10.1109/TPAMI.2008.126			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443918	Green Submitted			2022-12-18	WOS:000266188900004
J	Ferecatu, M; Geman, D				Ferecatu, Marin; Geman, Donald			A Statistical Framework for Image Category Search from a Mental Picture	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; relevance feedback; page zero problem; mental matching; Bayesian system; statistical learning	RELEVANCE FEEDBACK; RETRIEVAL; IMPLEMENTATION	Starting from a member of an image database designated the "query image," traditional image retrieval techniques, for example, search by visual similarity, allow one to locate additional instances of a target category residing in the database. However, in many cases, the query image or, more generally, the target category, resides only in the mind of the user as a set of subjective visual patterns, psychological impressions, or " mental pictures." Consequently, since image databases available today are often unstructured and lack reliable semantic annotations, it is often not obvious how to initiate a search session; this is the "page zero problem." We propose a new statistical framework based on relevance feedback to locate an instance of a semantic category in an unstructured image database with no semantic annotation. A search session is initiated from a random sample of images. At each retrieval round, the user is asked to select one image from among a set of displayed images-the one that is closest in his opinion to the target class. The matching is then "mental." Performance is measured by the number of iterations necessary to display an image which satisfies the user, at which point standard techniques can be employed to display other instances. Our core contribution is a Bayesian formulation which scales to large databases. The two key components are a response model which accounts for the user's subjective perception of similarity and a display algorithm which seeks to maximize the flow of information. Experiments with real users and two databases of 20,000 and 60,000 images demonstrate the efficiency of the search process.	[Ferecatu, Marin] Telecom Paristech, Inst Telecom, TSI Dept, F-75634 Paris, France; [Geman, Donald] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA	IMT - Institut Mines-Telecom; IMT Atlantique; Institut Polytechnique de Paris; Johns Hopkins University	Ferecatu, M (corresponding author), Telecom Paristech, Inst Telecom, TSI Dept, 46 Rue Barrault, F-75634 Paris, France.	marin.ferecatu@telecom-paristech.fr; geman@jhu.edu	Geman, Donald/A-3325-2010		US National Science Foundation [0427223]; US Office of Naval Research [N00014-07-1-1002]	US National Science Foundation(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research)	This work was performed while Marin Ferecatu was a member, and Donald Geman a visiting member, of the IMEDIA research team, INRIA Rocquencourt, Le Chesnay Cedex, France. The authors are deeply grateful to Nozha Boujemaa, the director of IMEDIA, for her advice and support throughout this work. Part of this work was also carried out in the TSI Department, TELECOM ParisTech, Paris, France, where Marin Ferecatu is now a postdoctoral fellow. Finally, the work of Donald Geman was also partially supported by the US National Science Foundation under grant NSF 0427223 and by the US Office of Naval Research under contract N00014-07-1-1002.	[Anonymous], 2002, LEARNING KERNELS; CAENEN G, 2001, P STOR RETR MED DAT, P49; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006; DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fang YC, 2005, LECT NOTES COMPUT SC, V3546, P637; Fauqueur J, 2006, MULTIMED TOOLS APPL, V31, P95, DOI 10.1007/s11042-006-0033-3; FERECATU M, 2005, THESIS INRIA U VERSA; Ferecatu M., 2007, P IEEE INT C COMP VI; Ferecatu M, 2008, MULTIMEDIA SYST, V13, P309, DOI 10.1007/s00530-007-0094-9; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; GEVERS T, 2004, EMERGING TOPICS COMP; GOH K, 2004, P 9 ACM INT C MULT; HE X, 2004, P 9 ACM INT C MULT; Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106; HOI C, 2004, P 9 ACM INT C MULT; Huang TS, 2008, P IEEE, V96, P648, DOI 10.1109/JPROC.2008.916364; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; KO B, 2002, P IEEE INT C PATT RE; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Li J., 2006, P 14 ANN ACM INT C M, P911, DOI DOI 10.1145/1180639.1180841; Manjunath B. S., 2002, INTRO MPEG 7 MULTIME; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; SAHBI H, 2008, P IEEE C COMP VIS PA; SAUX BL, 2004, P SPIE C STOR RETR M; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; Vapnik V., 1982, ESTIMATION DEPENDENC; VASCONCELOS N, 2000, P IEEE C COMP VIS PA; VASCONCELOS N, 2000, P C ADV NEURAL INFOR; VERTAN C, 2000, P INT C VIS INF SYST; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3; Zhou ZH, 2006, ACM T INFORM SYST, V24, P219, DOI 10.1145/1148020.1148023	38	22	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1087	1101		10.1109/TPAMI.2008.259	http://dx.doi.org/10.1109/TPAMI.2008.259			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372612	Green Submitted			2022-12-18	WOS:000265100000010
J	Ribnick, E; Atev, S; Papanikolopoulos, NP				Ribnick, Evan; Atev, Stefan; Papanikolopoulos, Nikolaos P.			Estimating 3D Positions and Velocities of Projectiles from Monocular Views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D localization; optimization; projectile motion	RECONSTRUCTION; POINTS	In this paper, we consider the problem of localizing a projectile in 3D based on its apparent motion in a stationary monocular view. A thorough theoretical analysis is developed, from which we establish the minimum conditions for the existence of a unique solution. The theoretical results obtained have important implications for applications involving projectile motion. A robust, nonlinear optimization-based formulation is proposed, and the use of a local optimization method is justified by detailed examination of the local convexity structure of the cost function. The potential of this approach is validated by experimental results.	[Ribnick, Evan; Atev, Stefan; Papanikolopoulos, Nikolaos P.] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Ribnick, E (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, EE CSci 4-192,200 Union St, Minneapolis, MN 55455 USA.	ribnick@cs.umn.edu; atev@cs.umn.edu; npapas@cs.umn.edu			US Department of Homeland Security; ITS Institute at the University of Minnesota; US National Science Foundation [IIS-0219863, CNS-0324864, CNS-0420836, IIP-0443945, IIP-0726109, CNS-0708344]	US Department of Homeland Security(United States Department of Homeland Security (DHS)); ITS Institute at the University of Minnesota(University of Minnesota System); US National Science Foundation(National Science Foundation (NSF))	This work has been supported by the US Department of Homeland Security, the ITS Institute at the University of Minnesota, and the US National Science Foundation (through grants IIS-0219863, CNS-0324864, CNS-0420836, IIP-0443945, IIP-0726109, and CNS-0708344).	[Anonymous], 1999, NUMERICAL OPTIMIZATI; Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004; Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; Boyd S, 2004, CONVEX OPTIMIZATION; GHOSH BK, 1994, P 33 C DEC CONTR, V13, P3229; Hartley R., 2003, MULTIPLE VIEW GEOMET; Kahl F, 2007, INT J COMPUT VISION, V74, P3, DOI 10.1007/s11263-006-0015-y; Kaminski JY, 2005, J EUR MATH SOC, V7, P145; Kaminski JY, 2004, J MATH IMAGING VIS, V21, P27, DOI 10.1023/B:JMIV.0000026555.79056.b8; Kim T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P721, DOI 10.1109/ICCV.1998.710797; Kiwiel KC, 1996, J OPTIMIZ THEORY APP, V89, P221, DOI 10.1007/BF02192649; Liu Y, 2006, IMAGE VISION COMPUT, V24, P1146, DOI 10.1016/j.imavis.2006.04.001; Nishiwaki K, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P94, DOI 10.1109/ROMAN.1997.646959; OHNO Y, 2000, P INT C PATT REC SEP, V1, P1145; Reid I., 1998, P BRIT MACH VIS C SE, P721; REN J, 1935, P IEEE INT C IM PROC, P2004; Ribnick E., 2007, P IEEE RSJ INT C INT; Riley M, 2002, AUTON ROBOT, V12, P119, DOI 10.1023/A:1013223328496; Schaible S, 2003, OPTIM METHOD SOFTW, V18, P219, DOI 10.1080/1055678031000105242	19	22	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					938	U180		10.1109/TPAMI.2008.247	http://dx.doi.org/10.1109/TPAMI.2008.247			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299865				2022-12-18	WOS:000264144500013
J	Dowson, N; Kadir, T; Bowden, R				Dowson, Nicholas; Kadir, Timor; Bowden, Richard			Estimating the joint statistics of images using Nonparametric Windows with application to registration using Mutual Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		mutual information; joint image statistics; registration; sampling		Recently, Nonparametric (NP) Windows has been proposed to estimate the statistics of real 1D and 2D signals. NP Windows is accurate because it is equivalent to sampling images at a high (infinite) resolution for an assumed interpolation model. This paper extends the proposed approach to consider joint distributions of image pairs. Second, Green's Theorem is used to simplify the previous NP Windows algorithm. Finally, a resolution-aware NP Windows algorithm is proposed to improve robustness to relative scaling between an image pair. Comparative testing of 2D image registration was performed using translation only and affine transformations. Although it is more expensive than other methods, NP Windows frequently demonstrated superior performance for bias (distance between ground truth and global maximum) and frequency of convergence. Unlike other methods, the number of samples and the number of bins have little effect on NP Windows and the prior selection of a kernel is not required.	[Dowson, Nicholas; Kadir, Timor] Siemens Mol Imaging, Oxford OX1 2EP, England; [Bowden, Richard] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Siemens AG; University of Surrey	Dowson, N (corresponding author), Siemens Mol Imaging, 28-36 Hythe Bridge Str, Oxford OX1 2EP, England.	nicholas.dowson@siemens.com; timor.kadir@siemens.com; r.bowden@surrey.ac.uk	Dowson, Nicholas/A-7537-2011; Dowson, Nicholas D H/B-7621-2017; Bowden, Richard/AAF-8283-2019	Dowson, Nicholas/0000-0003-4694-5459; Dowson, Nicholas D H/0000-0003-4694-5459; Bowden, Richard/0000-0003-3285-8020	Engineering and Physical Sciences Research Council [EP/E027946/1] Funding Source: researchfish; EPSRC [EP/E027946/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Baker S, 2002, CMURITR0216; Beyer WH, 1987, CRC STANDARD MATH TA, V28, P123; Chen HM, 2003, IEEE T MED IMAGING, V22, P1111, DOI 10.1109/TMI.2003.816949; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; D'Agostino E, 2006, MED IMAGE ANAL, V10, P413, DOI 10.1016/j.media.2005.03.004; HECKBERT P, 1990, GRAPHICS GEMS, P84; KADIR T, 2005, NONPARAMETRIC ESTIMA; KADIR T, 2005, P 16 BRIT MACH VIS C, V2, P589; Kanetsuna T, 2002, J SCH VIOLENCE, V1, P5, DOI DOI 10.1300/J202V01N03_; Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072; LOUTAS E, 2003, P 2003 INT S CIRC SY, V2, P672; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864; Maes F, 1999, Med Image Anal, V3, P373, DOI 10.1016/S1361-8415(99)80030-9; MATTHEWS I, 2003, P 14 BRIT MACH VIS C; MODDEMEIJER R, 1989, SIGNAL PROCESS, V16, P233, DOI 10.1016/0165-1684(89)90132-1; MORRISON JC, 1990, GRAPHICS GEMS, P63; Papoulis A., 1991, PROBABILITY RANDOM V, P124; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pluim JPW, 2000, COMPUT VIS IMAGE UND, V77, P211, DOI 10.1006/cviu.1999.0816; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RAJWADE A, 2006, P IEEE INT C COMP VI; SHAFFER CA, 1994, GRAPHICS GEMS, V3, P188; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Studholme C, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P27; Thevenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; WEISSTEIN EW, 2007, POLYGON AREA; [No title captured]	30	22	22	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1841	1857		10.1109/TPAMI.2007.70832	http://dx.doi.org/10.1109/TPAMI.2007.70832			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703835	Green Submitted			2022-12-18	WOS:000258344900013
J	Hernandez-Marin, S; Wallace, AM; Gibson, GJ				Hernandez-Marin, Sergio; Wallace, Andrew M.; Gibson, Gavin J.			Multilayered 3D LiDAR image construction using spatial models in a Bayesian framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; burst illumination laser; delayed rejection; LiDAR; Markov random fields; photon counting; reversible jump MCMC; spatial constraints	STATISTICAL-ANALYSIS; SEGMENTATION; MIXTURES; NUMBER	Standard 3D imaging systems process only a single return at each pixel from an assumed single opaque surface. However, there are situations when the laser return consists of multiple peaks due to the footprint of the beam impinging on a target with surfaces distributed in depth or with semitransparent surfaces. If all these returns are processed, a more informative multilayered 3D image is created. We propose a unified theory of pixel processing for Lidar data using a Bayesian approach that incorporates spatial constraints through a Markov Random Field with a Potts prior model. This allows us to model uncertainty about the underlying spatial process. To palliate some inherent deficiencies of this prior model, we also introduce two proposal distributions, one based on spatial mode jumping and the other on a spatial birth/death process. The different parameters of the several returns are estimated using reversible-jump Markov chain Monte Carlo (RJMCMC) techniques in combination with an adaptive strategy of delayed rejection to improve the estimates of the parameters.	[Hernandez-Marin, Sergio; Wallace, Andrew M.] Heriot Watt Univ, Sch Engn & Phys Sci, ERP Joint Res Inst Signal & Image Proc, Edinburgh EH14 4AS, Midlothian, Scotland; [Gibson, Gavin J.] Heriot Watt Univ, Sch Math & Comp Sci, Dept Actuarial Math & Stat, Maxwell Inst Math Sci, Edinburgh EH14 4AS, Midlothian, Scotland	Heriot Watt University; Heriot Watt University; University of Edinburgh	Hernandez-Marin, S (corresponding author), Heriot Watt Univ, Sch Engn & Phys Sci, ERP Joint Res Inst Signal & Image Proc, Edinburgh EH14 4AS, Midlothian, Scotland.	s.hernandezmarin@googlemail.com; a.m.wallace@hw.ac.uk; g.j.gibson@ma.hw.ac.uk		Wallace, Andrew/0000-0003-4425-8591				BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; Besag J. E., 1989, J APPL STAT, V16, P395, DOI [10.1080/02664768900000049, DOI 10.1080/02664768900000049]; Dias P, 2003, IEEE IMAGE PROC, P417; Diplaros A, 2004, IEEE SYS MAN CYBERN, P3071, DOI 10.1109/ICSMC.2004.1400810; Fernandez C, 2002, J R STAT SOC B, V64, P805, DOI 10.1111/1467-9868.00362; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; Green PJ, 2001, BIOMETRIKA, V88, P1035, DOI 10.1093/biomet/88.4.1035; GRENANDER U, 1983, TUTORIAL PATTERN THE; HALL P, 1986, J ROY STAT SOC B MET, V48, P330; Hazel GG, 2000, IEEE T GEOSCI REMOTE, V38, P1199, DOI 10.1109/36.843012; Hernandez-Marin S, 2007, IEEE T PATTERN ANAL, V29, P2170, DOI 10.1109/TPAMI.2007.1122; MARDIA KV, 1988, J MULTIVARIATE ANAL, V24, P265, DOI 10.1016/0047-259X(88)90040-1; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN JL, 1984, SURFACE RECONSTRUCTI; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Ren H, 2000, IEEE T GEOSCI REMOTE, V38, P2515, DOI 10.1109/36.885199; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Spiegelhalter DJ, 2002, J R STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; Tierney L, 1999, STAT MED, V18, P2507, DOI 10.1002/(SICI)1097-0258(19990915/30)18:17/18<2507::AID-SIM272>3.0.CO;2-J; Tso B., 2001, CLASSIFICATION METHO, V2nd; Wagner W, 2006, ISPRS J PHOTOGRAMM, V60, P100, DOI 10.1016/j.isprsjprs.2005.12.001; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; ZHANG GH, 1993, CVGIP-IMAG UNDERSTAN, V58, P191, DOI 10.1006/ciun.1993.1038	27	22	22	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1028	1040		10.1109/TPAMI.2008.47	http://dx.doi.org/10.1109/TPAMI.2008.47			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421108	Green Submitted			2022-12-18	WOS:000254872500008
J	Dedeoglu, G; Kanade, T; Baker, S				Dedeoglu, Goksel; Kanade, Takeo; Baker, Simon			The asymmetry of image registration and its application to face tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image registration; resolution; estimation bias; Active Appearance Models		Most image registration problems are formulated in an asymmetric fashion. Given a pair of images, one is implicitly or explicitly regarded as a template and warped onto the other to match as well as possible. In this paper, we focus on this seemingly arbitrary choice of the roles and reveal how it may lead to biased warp estimates in the presence of relative scaling. We present a principled way of selecting the template and explain why only the correct asymmetric form, with the potential inclusion of a blurring step, can yield an unbiased estimator. We validate our analysis in the domain of model-based face tracking. We show how the usual Active Appearance Model ( AAM) formulation overlooks the asymmetry issue, causing the fitting accuracy to degrade quickly when the observed objects are smaller than their model. We formulate a novel, "resolution-aware fitting" ( RAF) algorithm that respects the asymmetry and incorporates an explicit model of the blur caused by the camera's sensing elements into the fitting formulation. We compare the RAF algorithm against a state-of-the-art tracker across a variety of resolutions and AAM complexity levels. Experimental results show that RAF significantly improves the estimation accuracy of both shape and appearance parameters when fitting to low-resolution data. Recognizing and accounting for the asymmetry of image registration leads to tangible accuracy improvements in analyzing low-resolution imagery.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Dedeoglu, G (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	dedeoglu@cs.cmu.edu; tk@cs.cmu.edu; simonb@cs.cmu.edu						ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Ashburner J, 1999, NEUROIMAGE, V9, P619, DOI 10.1006/nimg.1999.0437; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Baker S., 2003, CMURITR0335; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363; BARBE DF, 1980, CHARGE COUPLED DEVIC; BERGEN JR, 1992, P EUR C COMP VIS, P237; BRANDT JW, 1994, P 28 AS C SIGN SYST, V1, P721; Bride J, 2001, PROC CVPR IEEE, P984; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Cachier P, 2000, LECT NOTES COMPUT SC, V1935, P472; CASELLA C, 1990, STAT INFERENCE; Christensen GE, 1999, LECT NOTES COMPUT SC, V1613, P224; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; DEDEOGLU G, 2005, CMURITR0517; Dedeoglu G, 2006, LECT NOTES COMPUT SC, V3952, P83; Dufournaud Y, 2000, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2000.855876; Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965; Fermuller C, 2001, COMPUT VIS IMAGE UND, V82, P1, DOI 10.1006/cviu.2000.0900; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; HANSES BB, 1999, P C COMP VIS PATT RE, V2, P202; Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Irani M., 2000, VISION ALGORITHMS TH, V1883, P267, DOI DOI 10.1007/3-540-44480-7; Kanatani K., 1996, STAT OPTIMIZATION GE; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Modersitzki J, 2004, NUMER MATH SCI COMP; Nagel HH, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1006, DOI 10.1109/ICCV.1998.710839; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; ROGELJ P, 2003, P SPIE FEB; Skrinjar O, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P920; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	36	22	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					807	823		10.1109/TPAMI.2007.1054	http://dx.doi.org/10.1109/TPAMI.2007.1054			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356201				2022-12-18	WOS:000244855700005
J	Kadyrov, A; Petrou, M				Kadyrov, Alexander; Petrou, Maria			Affine parameter estimation from the trace transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image registration; affine transform; trace transform; object matching; parameter estimation	IMAGE REGISTRATION; RECOGNITION; INVARIANT	In this paper, we assume that we are given the images of two segmented objects, one of which may be an affinely distorted version of the other, and wish to recover the values of the parameters of the affine transformation between the two images. The images may also differ by the overall level of illumination. The multiplicative constant of such difference may also be recovered. We present a generic theoretical framework to solve this problem. In terms of this framework, other proposed methods may be interpreted. We show how, in this framework, one can recover the affine parameters in a way that is robust to various effects, such as occlusion and illumination variation. The proposed method is generic enough to be applicable also to matching two images that do not depict the same scene or object.	Imperial Coll, Dept Elect & Elect Engn, London SW7 2AZ, England	Imperial College London	Kadyrov, A (corresponding author), Imperial Coll, Dept Elect & Elect Engn, London SW7 2AZ, England.	a.kadyrov@imperial.ac.uk; maria.petrou@imperial.ac.uk						ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807; Ben-Arie J, 1998, IEEE T PATTERN ANAL, V20, P604, DOI 10.1109/34.683774; BRACEWELL RN, 1993, ELECTRON LETT, V29, P304, DOI 10.1049/el:19930207; DELLAVENTURA A, 1990, IEEE T GEOSCI REMOTE, V28, P305, DOI 10.1109/36.54357; FLUSSER J, 1994, IEEE T GEOSCI REMOTE, V32, P382, DOI 10.1109/36.295052; GOSHTASBY A, 1988, IEEE T GEOSCI REMOTE, V26, P60, DOI 10.1109/36.3000; Kadyrov A, 2003, IMAGE VISION COMPUT, V21, P1135, DOI 10.1016/j.imavis.2003.08.013; Kadyrov A, 2001, IEEE T PATTERN ANAL, V23, P811, DOI 10.1109/34.946986; KRUGER S, 1998, P BRIT MACH VIS C, P316; Lucchese L, 2001, COMPUT VIS IMAGE UND, V81, P72, DOI 10.1006/cviu.2000.0885; Petrou M, 2004, ADV IMAG ELECT PHYS, V130, P243, DOI 10.1016/S1076-5670(04)30003-0; Petrou M, 2004, IEEE T PATTERN ANAL, V26, P30, DOI 10.1109/TPAMI.2004.1261077; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; TON JC, 1989, IEEE T GEOSCI REMOTE, V27, P642, DOI 10.1109/TGRS.1989.35948; Yang ZW, 1999, IEEE T PATTERN ANAL, V21, P804, DOI 10.1109/34.784312	15	22	24	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1631	1645		10.1109/TPAMI.2006.198	http://dx.doi.org/10.1109/TPAMI.2006.198			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986544				2022-12-18	WOS:000239605500007
J	Ilic, S; Fua, P				Ilic, S; Fua, P			Implicit meshes for surface reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; reconstruction; surface fitting; modeling optimization	MODELS	Deformable 3D models can be represented either as traditional explicit surfaces, such as triangulated meshes, or as implicit surfaces. Explicit surfaces are widely accepted because they are simple to deform and render, but fitting them involves minimizing a nondifferentiable distance function. By contrast, implicit surfaces allow fitting by minimizing a differentiable algebraic distance, but are harder to meaningfully deform and render. Here, we propose a method that combines the strength of both approaches. It relies on a technique that can turn a completely arbitrary triangulated mesh, such as one taken from the Web, into an implicit surface that closely approximates it and can deform in tandem with it. This allows both automated algorithms to take advantage of the attractive properties of implicit surfaces for fitting purposes and people to use standard deformation tools they feel comfortable for interaction and animation purposes. We demonstrate the applicability of our technique to modeling the human upper-body, including face, neck, shoulders, and ears, from noisy stereo and silhouette data.	Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Ilic, S (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland.	slobodan.ilic@epfl.ch; pascal.fua@epfl.ch	Fua, Pascal/H-3928-2011	Fua, Pascal/0000-0002-6702-9970; Ilic, Slobodan/0000-0002-3413-1936				Amenta N, 2004, ACM T GRAPHIC, V23, P264, DOI 10.1145/1015706.1015713; BAJAJ CL, 1992, COMP GRAPH, V26, P79, DOI 10.1145/142920.134014; Barr A. H., 1984, Computers & Graphics, V18, P21; BLANZ V, 1999, P SIGGRAPH COMPU AUG; Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290; CARR JC, 2001, P SIGGRAPH COMPUTER, V2; CARR JC, 2003, P 1 INT C COMP GRAPH, P119; Cohen I., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P738, DOI 10.1109/CVPR.1991.139807; COQUILLART S., 1990, COMPUT GRAPH, V24, P187, DOI [DOI 10.1145/97880.97900, DOI 10.1145/97879.97900]; DESBRUN M, 1995, P SIGGRAPH 95, P287; DIMITRIJEVIC M, 2004, P C COMP VIS PATT RE; Duan Y, 2004, LECT NOTES COMPUT SC, V3023, P238; Eck M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P325, DOI 10.1145/237170.237271; FERRIE FP, 1992, P EUR C COMP VIS APR; Fua P, 2000, INT J COMPUT VISION, V38, P153, DOI 10.1023/A:1008105802790; Hoppe H., 1994, P SIGGRAPH 94, P295, DOI DOI 10.1145/192161.192233; ILIC S, 2002, P EUR C COMP VIS MAY; ILIC S, 2004, IC200425 EPFL; ILIC S, 2003, P C COMP VIS PATT RE; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KRISHNAMURTHY V, 1996, P SIGGRAPH 96, P313, DOI DOI 10.1145/237170.237270; Levin D, 2004, MATH VISUAL, P37; Litke N, 2001, IEEE VISUAL, P319, DOI 10.1109/VISUAL.2001.964527; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Moccozet L, 1997, COMP ANIM CONF PROC, P93, DOI 10.1109/CA.1997.601047; Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PLANKERS R, 2003, IEEE T PATTERN ANAL; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; SEDERBERG TW, 1986, P SIGGRAPH COMPUTER, V20, P4; SHEN C, 2004, P ACM SIGGRAPH   AUG; SIBSON R, 1980, P MATH CAMBRIDGE PHI, P151; STOKELY EM, 1992, IEEE T PATTERN ANAL, V14, P833, DOI 10.1109/34.149594; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; SZELISKI R, 1992, COMP GRAPH, V26, P185, DOI 10.1145/142920.134037; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Terzopoulos D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P70, DOI 10.1109/CVPR.1991.139663; TURK G, 1999, P SIGGRAPH COMPUTER, V33, P335; Wyvill B, 1997, 1997 INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P205, DOI 10.1109/SMA.1997.634898	40	22	24	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					328	333		10.1109/TPAMI.2006.37	http://dx.doi.org/10.1109/TPAMI.2006.37			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468628	Green Submitted			2022-12-18	WOS:000233824500014
J	Vinciarelli, A				Vinciarelli, A			Noisy text categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						text categorization; noisy text; indexing; offline cursive handwriting recognition; optical character recognition	RECOGNITION; RETRIEVAL; IMAGES	This work presents categorization experiments performed over noisy texts. By noisy, we mean any text obtained through an extraction process (affected by errors) from media other than digital texts (e.g., transcriptions of speech recordings extracted with a recognition system). The performance of a categorization system over the clean and noisy (Word Error Rate between similar to 10 and similar to 50 percent) versions of the same documents is compared. The noisy texts are obtained through handwriting recognition and simulation of optical character recognition. The results show that the performance loss is acceptable for Recall values up to 60-70 percent depending on the noise sources. New measures of the extraction process performance, allowing a better explanation of the categorization results, are proposed.	IDIAP Res Inst, CH-1920 Martigny, Switzerland		Vinciarelli, A (corresponding author), IDIAP Res Inst, Rue Simplon 4, CH-1920 Martigny, Switzerland.	vincia@idiap.ch	Vinciarelli, Alessandro/C-1651-2012	Vinciarelli, Alessandro/0000-0002-9048-0524				ABBERLEY D, 1999, P 8 TEXT RETR C TREC, P699; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; BAEZAYATES RA, 1999, MODERN INF RETRIEVAL; Bayer T, 1998, COMPUT VIS IMAGE UND, V70, P299, DOI 10.1006/cviu.1998.0687; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001; Cristianini N., 2000, INTRO SUPPORT VECTOR; CROFT B, 1994, P S DOC AN INF RETR, P115; Doermann D, 1998, COMPUT VIS IMAGE UND, V70, P287, DOI 10.1006/cviu.1998.0692; DOERMANN DS, 1995, P 4 S DOC AN INF RET, P449; FOX C, 1992, INFORM RETRIEVAL DAT, P102; FRAKES WB, 1992, INFORMATION RETRIEVA, P131; FRANZ M, 1999, PROC 8 TEXT RETR C T, P391; GAROFOLO JS, 1999, P TREC 9, P107; GAUVAIN JL, 1999, P 8 TEXT RETR C TREC, P475; GRAFF D, 2000, P TOP DET TRACK WORK; HAN B, 1999, P 8 TEXT RETR C, P591; HOCH R, 1994, P 17 ANN INT ACM SIG, P31; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jelinek Frederick, 1997, STAT METHODS SPEECH; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; Joachims T., 1999, MAKING LARGE SCALE S, P41, DOI 10.17877/DE290R-5098; Joachims T., 2002, LEARNING CLASSIFY TE; Johnson LB, 1999, INFECT DIS CLIN PRAC, V8, P206, DOI 10.1097/00019048-199905000-00010; KOUMPIS K, 2003, P ISCA WORKSH MULT S, P19; KRAAIJ W, 1999, P 8 TEXT RETR C, P285; LEWIS DD, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P37; Lopresti D., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval, P255; Miller D, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P316; Ohta M, 1997, PROC INT CONF DOC, P950, DOI 10.1109/ICDAR.1997.620651; Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI 10.1108/eb046814; Rath TM, 2003, PROC INT CONF DOC, P218; Russell G, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P233, DOI 10.1109/IWFHR.2002.1030915; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SINGHAL A, 1999, P 8 TEXT RETR C, P317; TAGHVA K, 2001, P IS T SPIE 2001 INT, P68; TAGHVA K, 1994, P IS T SPIE 1994 INT, P270; Tan CL, 2002, IEEE T PATTERN ANAL, V24, P838, DOI 10.1109/TPAMI.2002.1008389; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; Vinciarelli A, 2001, PATTERN RECOGN LETT, V22, P1043, DOI 10.1016/S0167-8655(01)00042-3; Weston J, 2001, ADV NEUR IN, V13, P668; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Yang Yiming, 1997, P 14 INT C MACHINE L, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; ZHAI C, 1996, P 5 TEXT RETR C, P341; Zipf G. K., 1949, HUMAN BEHAVIOUR PRIN	46	22	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1882	1895		10.1109/TPAMI.2005.248	http://dx.doi.org/10.1109/TPAMI.2005.248			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355657	Green Submitted			2022-12-18	WOS:000232532600004
J	Jin, HD; Wong, ML; Leung, KS				Jin, HD; Wong, ML; Leung, KS			Scalable model-based clustering for large databases based on data summarization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scalable clustering; Gaussian mixture model; expectation-maximization; data summary; maximum penalized likelihood estimate	EM	The scalability problem in data mining involves the development of methods for handling large databases with limited computational resources such as memory and computation time. In this paper, two scalable clustering algorithms, bEMADS and gEMADS, are presented based on the Gaussian mixture model. Both summarize data into subclusters and then generate Gaussian mixtures from their data summaries. Their core algorithm, EMADS, is defined on data summaries and approximates the aggregate behavior of each subcluster of data under the Gaussian mixture model. EMADS is provably convergent. Experimental results substantiate that both algorithms can run several orders of magnitude faster than expectation-maximization with little loss of accuracy.	Commenwealth Sci & Ind Res Org, Div Math & Informat Sci, Canberra, ACT 2601, Australia; Lingnan Univ, Dept Comp & Decis Sci, Tuen Mun, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Lingnan University; Chinese University of Hong Kong	Jin, HD (corresponding author), Commenwealth Sci & Ind Res Org, Div Math & Informat Sci, GPO Box 664, Canberra, ACT 2601, Australia.	Warren.Jin@csiro.au; mlwong@ln.edu.hk; ksleung@cse.cuhk.edu.hk	jin, Huidong/B-3187-2009	jin, Huidong/0000-0002-3925-0256; WONG, Man Leung/0000-0002-4364-6747				Bradley PS, 2000, INT C PATT RECOG, P76, DOI 10.1109/ICPR.2000.906021; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV, ppp153; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fraley C, 1998, SIAM J SCI COMPUT, V20, P270, DOI 10.1137/S1064827596311451; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Ganti V, 1999, COMPUTER, V32, P38, DOI 10.1109/2.781633; Han J, 2001, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5; Jin HD, 2005, PATTERN RECOGN, V38, P637, DOI 10.1016/j.patcog.2004.07.012; Jin HD, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P91; JIN HD, 2002, THESIS CHINESE U HON; McLachlan, 1997, EM ALGORITHM EXTENSI; Meila M, 2001, MACH LEARN, V42, P9, DOI 10.1023/A:1007648401407; Moore AW, 1999, ADV NEUR IN, V11, P543; PALMER CR, 2000, P 2000 ACM SIGMOD IN, P82; PANTEL PA, 2003, THESIS U ALBERTA CAN; Shanmugasundaram J., 1999, KDD, V99, P223; Thiesson B, 2001, MACH LEARN, V45, P279, DOI 10.1023/A:1017986506241; WANG S., 2003, P 20 INT C MACH LEAR, P784; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328	20	22	23	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1710	1719		10.1109/TPAMI.2005.226	http://dx.doi.org/10.1109/TPAMI.2005.226			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285371				2022-12-18	WOS:000231826300003
J	Priebe, CE; Marchette, DJ; Healy, DM				Priebe, CE; Marchette, DJ; Healy, DM			Integrated sensing and processing decision trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; clustering; adaptive sensing; sequential sensing; local dimensionality reduction	DIMENSIONALITY; CLASSIFICATION; RECOGNITION; SYSTEM	We introduce a methodology for adaptive sequential sensing and processing in a classification setting. Our objective for sensor optimization is the back-end performance metric-in this case, misclassification rate. Our methodology, which we dub Integrated Sensing and Processing Decision Trees (ISPDT), optimizes adaptive sequential sensing for scenarios in which sensor and/or throughput constraints dictate that only a small subset of all measurable attributes can be measured at any one time. Our decision trees optimize misclassification rate by invoking a local dimensionality reduction-based partitioning metric in the early stages, focusing on classification only in the leaves of the tree. We present the ISPDT methodology and illustrative theoretical, simulation, and experimental results.	Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; USN, Ctr Surface Warfare, Dahlgren, VA 22448 USA; Univ Maryland, Dept Math, College Pk, MD 20742 USA	Johns Hopkins University; United States Department of Defense; United States Navy; University System of Maryland; University of Maryland College Park	Priebe, CE (corresponding author), Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA.	cep@jhu.edu; marchettedj@nswc.navy.mil; dhealy@math.umd.edu	Priebe, Carey E./A-3305-2010					ABE K, 1996, P IEEE C SYST MAN CY, V1, P696; Bellman R., 1961, ADAPTIVE CONTROL PRO; BREIMAN L, 567 U CAL DEP STAT; Breiman L., 1998, CLASSIFICATION REGRE; Dickinson TA, 1996, NATURE, V382, P697, DOI 10.1038/382697a0; Green P., 1994, NONPARAMETRIC REGRES; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HEALY DM, 1997, TIME FREQUENCY METHO; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Liang ZP, 2000, SPIE OPTICAL ENG; Marchette DJ, 1999, COMPUTATION STAT, V14, P469, DOI 10.1007/s001800050026; Pedrycz W, 2000, IEEE T SYST MAN CY A, V30, P151, DOI 10.1109/3468.833095; Priebe CE, 2001, IEEE T PATTERN ANAL, V23, P404, DOI 10.1109/34.917575; PRIEBE CE, 2004, MODERN SIGNAL PROCES; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306, DOI 10.1109/TPAMI.1979.4766926; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197	21	22	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					699	708		10.1109/TPAMI.2004.12	http://dx.doi.org/10.1109/TPAMI.2004.12			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579931				2022-12-18	WOS:000220756500004
J	Vanzella, W; Pellegrino, FA; Torre, V				Vanzella, W; Pellegrino, FA; Torre, V			Self-adaptive regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image regularization; Mumford-Shah; variational methods	EDGE-DETECTION; OPTICAL-FLOW; APPROXIMATION	Often an image g(x; y) is regularized and even restored by minimizing the Mumford-Shah functional. Properties of the regularized image u(x, y) depends critically on the numerical value of the two parameters alpha and gamma controlling smoothness and fidelity. When alpha and gamma are constant over the image, small details are lost when an extensive filtering is used in order to remove noise. In this paper, it is shown how the two parameters alpha and gamma can be made self-adaptive. In fact, alpha and gamma are not constant but automatically adapt to the local scale and contrast of features in the image. In this way, edges at all scales are detected and boundaries are well-localized and preserved. In order to preserve trihedral junctions alpha and gamma become locally small and the regularized image u(x, y) maintains sharp and well-defined trihedral junctions. Images regularized by the proposed procedure are well-suited for further processing, such as image segmentation and object recognition.	SISSA, ISAS, Neurobiol Sector, I-31014 Trieste, Italy; Univ Udine, Dept Math & Comp Sci, I-34100 Trieste, Italy	International School for Advanced Studies (SISSA); University of Udine	Vanzella, W (corresponding author), SISSA, ISAS, Neurobiol Sector, Via Beirut 7, I-31014 Trieste, Italy.	vanzella@sissa.it; fapellegrino@units.it; torre@sissa.it	Pellegrino, Felice Andrea/AAT-9036-2021	Pellegrino, Felice Andrea/0000-0002-4423-1666				Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170; Aubert G., 2002, MATH PROBLEMS IMAGE; BATTITI R, 1994, NEUROCOMPUTING, V6, P181, DOI 10.1016/0925-2312(94)90054-X; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chambolle A, 1999, RAIRO-MATH MODEL NUM, V33, P651; Chambolle A, 1999, RAIRO-MATH MODEL NUM, V33, P261; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Gobbino M, 1998, COMMUN PUR APPL MATH, V51, P197, DOI 10.1002/(SICI)1097-0312(199802)51:2<197::AID-CPA3>3.3.CO;2-K; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Lindeman J, 2002, NETW COMPUT, V13, P30; MAJER P, 2001, P 3 INT C SCAL SPAC; Morel J.-M., 1995, VARIATIONAL METHODS; MORINI M, IN PRESS MATH MODELS; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Negri M, 2001, CALCOLO, V38, P67, DOI 10.1007/s100920170004; PELLEGRINO FA, IN PRESS IEEE T SMC; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; Roberts L, 1965, MACHINE PERCEPTION 3; Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003; SCHNORR C, 1991, INT J COMPUT VISION, V6, P25, DOI 10.1007/BF00127124; STRONG DM, 2000, UNPUB SIAM J APPL MA; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914	28	22	22	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					804	809		10.1109/TPAMI.2004.15	http://dx.doi.org/10.1109/TPAMI.2004.15			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579940				2022-12-18	WOS:000220756500013
J	Isler, V; Kannan, S; Daniilidis, K; Valtr, P				Isler, V; Kannan, S; Daniilidis, K; Valtr, P			VC-dimension of exterior visibility	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						VC-dimension; sensor placement; sampling; visibility	COMPUTER VISION; GALLERIES; POLYGONS	In this paper, we study the Vapnilk-Chervonenkis (VC)-dimension of set systems arising in 2D polygonal and 3D polyhedral configurations where a subset consists of all points visible from one camera. In the past, it has been shown that the VC-dimension of planar visibility systems is bounded by 23 if the cameras are allowed to be anywhere inside a polygon without holes [11]. Here, we consider the case of exterior visibility, where the cameras lie on a constrained area outside the polygon and have to observe the entire boundary. We present results for the cases of cameras lying on a circle containing a polygon (VC-dimension= 2) or lying outside the convex hull of a polygon (VC-dimension= 5). The main result of this paper concerns the 3D case: We prove that the VC-dimension is unbounded if the cameras lie on a sphere containing the polyhedron, hence the term exterior visibility.	Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA; Charles Univ Prague, Dept Appl Math, CR-11800 Prague 1, Czech Republic; Charles Univ Prague, Inst Theoret Comp Sci, CR-11800 Prague 1, Czech Republic	University of Pennsylvania; Charles University Prague; Charles University Prague	Isler, V (corresponding author), Univ Penn, Dept Comp & Informat Sci, Levine Hall,3330 Walnut St, Philadelphia, PA 19104 USA.	isleri@cis.upenn.edu; kannan@cis.upenn.edu; kostas@cis.upenn.edu; valtr@kam.mff.cuni.cz	Valtr, Pavel/E-6788-2012	Valtr, Pavel/0000-0002-3102-4166; Daniilidis, Kostas/0000-0003-0498-0758				Acampora A, 2002, SCI AM, V287, P48, DOI 10.1038/scientificamerican0702-48; AGARWAL PK, 2003, HDB RANDOMIZATION; Broden Bjorn, 2001, P CAN C COMP GEOM CC, P45; BRONNIMANN H, 1995, DISCRETE COMPUT GEOM, V14, P463, DOI 10.1007/BF02570718; Bulusu N., 2001, P INT C DISTR COMP S; CHIN WP, 1991, DISCRETE COMPUT GEOM, V6, P9, DOI 10.1007/BF02574671; Deng XT, 1998, J ACM, V45, P215, DOI 10.1145/274787.274788; Eidenbenz S, 2001, ALGORITHMICA, V31, P79, DOI 10.1007/s00453-001-0040-8; GHOSH S, 1987, P CAN INF PROC SOC C; Gonzalez-Banos H., P 17 ANN S COMP GEOM, P232; Hernando C, 2002, THEOR COMPUT SCI, V289, P919, DOI 10.1016/S0304-3975(01)00409-1; HLAVAC V, 1996, P ECCV, P526; Hoffmann F, 2001, SIAM J COMPUT, V31, P577, DOI 10.1137/S0097539799348670; ISLER V, 2001, MSCIS0134 U PENNS; Kavraki LE, 1998, J COMPUT SYST SCI, V57, P50, DOI 10.1006/jcss.1998.1578; Kumar VSA, 2000, LECT NOTES COMPUT SC, V1853, P624; KUTULAKOS KN, 1994, INT J COMPUT VISION, V12, P113, DOI 10.1007/BF01421200; LaValle SM, 1997, INT J ROBOT RES, V16, P775, DOI 10.1177/027836499701600605; MATOUSEK J, 1998, IEEE S FDN COMP SCI; MITCHELL JSB, 1992, PROCEEDINGS OF THE THIRD ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P296; O'Rourke J., 1987, ART GALLERY THEOREMS; OROURKE J, 1997, HDB DISCRETE COMPUTA, P467; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; Sharma R, 1997, PRESENCE-VIRTUAL AUG, V6, P292, DOI 10.1162/pres.1997.6.3.292; SHERMER TC, 1992, P IEEE, V80, P1384, DOI 10.1109/5.163407; Slavik P, 1997, J ALGORITHM, V25, P237, DOI 10.1006/jagm.1997.0887; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940; Valtr P, 1999, DISCRETE COMPUT GEOM, V21, P193, DOI 10.1007/PL00009414; Valtr P, 1998, ISRAEL J MATH, V104, P1, DOI 10.1007/BF02897056; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025	30	22	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					667	671		10.1109/TPAMI.2004.1273987	http://dx.doi.org/10.1109/TPAMI.2004.1273987			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460289	Green Published			2022-12-18	WOS:000220756400013
J	Kanungo, T; Zheng, QG				Kanungo, T; Zheng, QG			Estimating degradation model parameters using neighborhood pattern distributions: An optimization approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						degradation models; parameter estimation; direct search algorithms; neighborhood pattern distributions	VALIDATION	Noise models are crucial for designing image restoration algorithms, generating synthetic training data, and predicting algorithm performance. There are two related but distinct estimation scenarios. The first is model calibration, where it is assumed that the input ideal bitmap and the output of the degradation process are both known. The second is the general estimation problem, where only the image from the output of the degradation process is given. While researchers have addressed the problem of calibration of models, issues with the general estimation problems have not been addressed in the literature. In this paper, we describe a parameter estimation algorithm for a morphological, binary, page-level image degradation model. The inputs to the estimation algorithm are 1) the degraded image and 2) information regarding the font type (italic, bold, serif, sans serif). We simulate degraded images using our model and search for the optimal parameter by looking for a parameter value for which the local neighborhood pattern distributions in the simulated image and the given degraded image are most similar. The parameter space is searched using a direct search optimization algorithm. We use the p-value of the Kolmogorov-Smirnov test as the measure of similarity between the two neighborhood pattern distributions. We show results of our algorithm on degraded document images.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; Univ Maryland, Dept Elect Engn, College Pk, MD 20742 USA	International Business Machines (IBM); University System of Maryland; University of Maryland College Park	Kanungo, T (corresponding author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.	kanungo@almaden.ibm.com; qzheng@cfar.umd.edu						AHRALICK RM, 1992, ROBOT COMPUTER VISIO, V1; AHRALICK RM, 1992, ROBOT COMPUTER VISIO, V2; Baird H., 1990, P IAPR WORKSH SYNT S, P38; Baird H. S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P459, DOI 10.1109/ICDAR.1999.791824; Booker AJ, 1999, STRUCT OPTIMIZATION, V17, P1, DOI 10.1007/BF01197708; BOOKER AJ, 1998, OPTIMAL DESIGN CONTR, P49; GILL PE, 1993, PRACTICAL OPTIMIZATI; KANUNGO T, 1995, P SOC PHOTO-OPT INS, V2424, P86, DOI 10.1117/12.205268; Kanungo T, 2000, IEEE T PATTERN ANAL, V22, P1209, DOI 10.1109/34.888707; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633; KANUNGO T, 1994, P INT WORKSH MACH VI; KANUNGO T, 2001, P IEEE INT C SPEECH; LEWIS RM, 1998, OPTIMA, V59, P1; Li YH, 1996, IEEE T PATTERN ANAL, V18, P99, DOI 10.1109/34.481536; MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Powell M. J. D., 1998, Acta Numerica, V7, P287, DOI 10.1017/S0962492900002841; Sural S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P463, DOI 10.1109/ICDAR.1999.791825; Wright M., 1996, NUMERICAL ANAL, P191; ZHENG Q, 2001, P IEEE INT C IM PROC	21	22	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					520	524		10.1109/TPAMI.2004.1265867	http://dx.doi.org/10.1109/TPAMI.2004.1265867			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382656	Green Submitted			2022-12-18	WOS:000220102800008
J	Hayman, E; Murray, DW				Hayman, E; Murray, DW			The effects of translational misalignment when self-calibrating rotating and zooming cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						self-calibration; zoom lenses; rotating cameras		Algorithms for self-calibrating cameras whose changes in calibration parameters are confined to rotation and zooming are useful since many real-world imaging situations do not permit translations-consider, for instance, cameras mounted on tripods and desk or wall-mounted active heads. In practice, however, the assumption of pure rotation is often violated because the optic center of the camera and the rotation center do not completely coincide. This work determines how such misalignments affect the estimation of the camera focal length. Expressions for the errors in focal length and recovered rotations are derived and results are confirmed with experiments on synthetic data. We show that the approximation of pure rotation is indeed sufficient in many cases, especially since other sources of error, such as noise and particularly radial distortion, tend to be more detrimental.	KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden; Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Royal Institute of Technology; University of Oxford	Hayman, E (corresponding author), KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden.	haman@nada.kth.se; dwm@robots.ox.ac.uk						BERGEN JR, 1992, P EUR C COMP VIS, P237; DAGAPITO L, 2001, INT J COMPUT VISION, V45, P107; de Agapito L., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P15, DOI 10.1109/CVPR.1999.786911; DEAGAPITO L, 1998, P BRIT MACH VIS C, P105; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HAYMAN E, 2000, P 6 EUR C COMP VIS D, P477; HAYMAN E, 2000, THESIS U OXFORD; HAYMAN E, 2002, 225002 U OXF; Kang SB, 1999, COMPUT VIS IMAGE UND, V73, P269, DOI 10.1006/cviu.1998.0727; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; SEO Y, 1999, P IEEE ICCV, P183; SEO Y, 1998, P IAPR WORKSH MACH V, P274; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; Tordoff B, 2000, INT C PATT RECOG, P423, DOI 10.1109/ICPR.2000.905367; TORR PHS, 1995, THESIS OXFORD U; Wang L, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P464, DOI 10.1109/ICCV.2001.937553	19	22	24	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					1015	1020		10.1109/TPAMI.2003.1217605	http://dx.doi.org/10.1109/TPAMI.2003.1217605			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ					2022-12-18	WOS:000184249800007
J	Storkey, AJ; Williams, CKI				Storkey, AJ; Williams, CKI			Image modeling with position-encoding dynamic trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic trees; variational inference; belief networks; Bayesian networks; image segmentation; structured image models; tree structured networks	BELIEF NETWORKS; SEGMENTATION	This paper describes the Position-Encoding Dynamic Tree (PEDT). The PEDT is a probabilistic model for images that improves on the dynamic tree by allowing the positions of objects to play a part in the model. This increases the flexibility of the model over the dynamic tree and allows the positions of objects to be located and manipulated. This paper motivates and defines this form of probabilistic model using the belief network formalism. A structured variational approach for inference and learning in the PEDT is developed, and the resulting variational updates are obtained, along with additional implementation considerations that ensure the computational cost scales linearly in the number of nodes of the belief network. The PEDT model is demonstrated and compared with the dynamic tree and fixed tree. The structured variational learning method is compared with mean field approaches.	Univ Edinburgh, Inst Adapt & Neural Computat, Div Informat, Edinburgh, Midlothian, Scotland	University of Edinburgh	Storkey, AJ (corresponding author), Univ Edinburgh, Inst Adapt & Neural Computat, Div Informat, 5 Forrest Hill, Edinburgh, Midlothian, Scotland.							ADAMS NJ, 2000, P 15 INT C PATT REC; ADAMS NJ, 2001, THESIS U EDINBURGH F; BASSEVILLE M, 1992, IEEE T INFORM THEORY, V38, P766, DOI 10.1109/18.119735; BESAG J, 1986, J R STAT SOC B, V48, P259; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Charniak Eugene, 1993, STAT LANGUAGE LEARNI; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; De Bonet JS, 1998, ADV NEUR IN, V10, P773; Feng XJ, 2002, IEEE T PATTERN ANAL, V24, P467, DOI 10.1109/34.993555; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GHAHRAMANI Z, 2000, P ADV NEUR INF PROC, V13; Gilkes W., 1996, MARKOV CHAIN MONTE C; Hinton GE, 2000, ADV NEUR IN, V12, P463; KITTLER J, 1994, ADV APPL STAT SER, V2, P61; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; LUCKE H, 1995, SPEECH COMMUN, V16, P89, DOI 10.1016/0167-6393(94)00046-D; LUETTGEN MR, 1995, IEEE T IMAGE PROCESS, V4, P194, DOI 10.1109/83.342185; LUETTGEN MR, 1994, IEEE T IMAGE PROCESS, V3, P41, DOI 10.1109/83.265979; MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Perez P, 2000, PATTERN RECOGN, V33, P573, DOI 10.1016/S0031-3203(99)00073-4; RONEN O, 1995, IEEE SIGNAL PROC LET, V2, P157, DOI 10.1109/97.404132; SAUL LK, 1996, P ADV NEUR INF PROC, V8; STORKEY AJ, 2000, UNCERTAINTY ARTIFICI, P566; von der Malsburg C., 1994, MODELS NEURAL NETWOR; von der Malsburg C., 1995, HDB BRAIN THEORY NEU, P329; WILLIAMS CKI, 1999, P ADV NEUR INF PROC, V11; WILLIAMS CKI, 1998, P NEUR NETW SIGN PRO, V8	30	22	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					859	871		10.1109/TPAMI.2003.1206515	http://dx.doi.org/10.1109/TPAMI.2003.1206515			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN		Green Accepted			2022-12-18	WOS:000183667300008
J	Kalitzin, SN; Staal, J; Romeny, BMT; Viergever, MA				Kalitzin, SN; Staal, J; Romeny, BMT; Viergever, MA			A computational method for segmenting topological point-sets and application to image analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						differential topology; critical point-sets; ridges; image analysis; scale space		We propose a new computational method for segmenting topological subdimensional point-sets in scalar images of arbitrary spatial dimensions. The technique is based on calculating the homotopy class defined by the gradient vector in a subdimensional neighborhood around every image point. This neighborhood is defined as the linear envelope spawned over a given subdimensional vector frame. In the simplest case where the rank of this frame is maximal, we obtain a technique for localizing the critical points, i.e., extrema and saddle points, We consider, in particular, the important case of frames formed by an arbitrary number of the first largest by absolute value principal directions of the Hessian. The method then segments positive and and negative ridges as well as other types of critical surfaces of different dimensionalities. The signs of the eigenvalues associated to the principal directions provide a natural labeling of the critical subsets. The result, in general, is a constructive definition of a hierarchy of point-sets of different dimensionalities linked by inclusion relations. Because of its explicit computational nature, the method gives a fast way to segment height ridges or edges in different applications. The defined topological point-sets are connected manifolds and, therefore, our method provides a tool for geometrical grouping using only local measurements. We have demonstrated the grouping properties of our construction by presenting two different cases where an extra image coordinate is introduced. In one of the examples, we considered the image analysis in the framework of the linear scale-space concept, where the topological properties are gradually simplified through the scale parameter. This scale parameter can be taken as an additional coordinate. In the second example, a local orientation parameter was used for grouping and segmenting elongated structures.	Dutch Epilepsy Clin Fdn, NL-2103 SW Hemmstede, Netherlands; Univ Utrecht, Med Ctr, Image Sci Inst, NL-3584 CX Utrecht, Netherlands	Utrecht University	Kalitzin, SN (corresponding author), Dutch Epilepsy Clin Fdn, Achterweg 5, NL-2103 SW Hemmstede, Netherlands.	skalitzin@scin.nl; joes@isi.uu.nl; bart@isi.uu.nl; max@isi.uu.nl	Romenij, Bart M. ter Haar/A-5323-2013; Viergever, Max A/J-1215-2014	Kalitzin, Stiliyan/0000-0002-7028-7778				BOOTHBY WM, 1975, INTRO DIFFERENTIAL G; Damon J, 1998, SIAM J APPL MATH, V59, P97, DOI 10.1137/S0036139997318032; EBERLY D, 1996, RIDGES IMAGES DATA A; Eberly D, 1994, J MATH IMAGING VIS, V4, P351; EGUCHI T, 1980, PHYS REP, V66, P213, DOI 10.1016/0370-1573(80)90130-1; Johansen P., 1994, Journal of Mathematical Imaging and Vision, V4, P57, DOI 10.1007/BF01250004; Kalitzin S, 1997, COMP IMAG VIS, V8, P181; Kalitzin SN, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P863, DOI 10.1109/ICIP.1997.638633; Kalitzin SN, 1998, J MATH IMAGING VIS, V9, P253, DOI 10.1023/A:1008376504545; KASS M, 1987, P IEEE 1 INT COMP VI; KELLER R, 1999, THESIS U N CAROLINA; Lindeberg T., 1992, Journal of Mathematical Imaging and Vision, V1, P65, DOI 10.1007/BF00135225; Lindeberg T., 1994, SCALE SPACE THEORY C; MILLER J., 1998, THESIS U N CAROLINA; Morse M., 1969, CRITICAL POINT THEOR; NAKAHARA M, 1989, GEOMETRY TOPOLOGY PH; OLSEN OF, 1997, GAUSSIAN SCALE SPACE	18	22	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					447	459		10.1109/34.922704	http://dx.doi.org/10.1109/34.922704			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA					2022-12-18	WOS:000168641000002
J	Hajjar, A; Chen, T				Hajjar, A; Chen, T			A VLSI architecture for real-time edge linking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						VLSI; edge linking; real-time image processing		A real-time algorithm and its VLSI implementation for edge linking is presented in this paper. The linking process is based on the break points' directions and the weak level points. The proposed VLSI architecture is capable of outputting one pixel of the linked edge map per clock cycle with a latency of 11n + 12 clock cycles, where n is the number of pixel columns in the image.	Colorado State Univ, Dept Elect Engn, Ft Collins, CO 80523 USA	Colorado State University	Hajjar, A (corresponding author), Colorado State Univ, Dept Elect Engn, Ft Collins, CO 80523 USA.		hajjar, amjad fuad/M-2191-2014					Alzahrani FM, 1997, REAL-TIME IMAGING, V3, P363, DOI 10.1006/rtim.1996.0071; BERNAND T, 1994, P ICIP, P13; BREEN E, 1994, COMPUTER ASSISTED, V6; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DIAMOND M, 1983, THESIS U MICHIGAN; FARA P, 1995, BRIT J HIST SCI, V28, P5, DOI 10.1017/S0007087400032672; Farag A., 1991, IEEE C SYSTEM MAN CY, V1, P563; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MILLER F, 1993, IEICE T INFORMATIO D, V76; Ungureanu D. O., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P793, DOI 10.1109/CVPR.1993.341179; William D., 1989, SPIE, V1095; XIE M, 1992, PATTERN RECOGNITION	12	22	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					89	94		10.1109/34.745740	http://dx.doi.org/10.1109/34.745740			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900013
J	Zhao, M; Quek, FKH; Wu, XD				Zhao, M; Quek, FKH; Wu, XD			RIEVL: Recursive induction learning in hand gesture recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hand gesture; hand pose recognition; rule-based induction; feature detection; feature selection; disjunctive norm form; machine learning; variable-valued logic	MINI	This paper presents a recursive inductive learning scheme that is able to acquire hand pose models in the form of disjunctive normal form expressions involving multivalued features. Based on an extended variable-valued logic, our rule-based induction system is able to abstract compact rule sets from any set of feature vectors describing a set of classifications. The rule bases which satisfy the completeness and consistency conditions are induced and refined through five heuristic strategies. A recursive induction learning scheme in the RIEVL algorithm is designed to escape local minima in the solution space. A performance comparison of RIEVL with other inductive algorithms, ID3, NewID, C4.5, CN2, and HCV, is given in the paper. In the experiments with hand gestures, the system produced the disjunctive normal form descriptions of each pose and identified the different hand poses based on the classification rules obtained by the RIEVL algorithm. RIEVL classified 94.4 percent of the gesture images in our testing set correctly, outperforming all other inductive algorithms.	Univ Illinois, Dept Neurosurg, Chicago, IL 60612 USA; Univ Illinois, Dept Elect Engn & Comp Sci, Vis Interfaces & Syst Lab, Chicago, IL 60607 USA; Colorado Sch Mines, Dept Math & Comp Sci, Golden, CO 80401 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; Colorado School of Mines	Zhao, M (corresponding author), Univ Illinois, Dept Neurosurg, Chicago, IL 60612 USA.							[Anonymous], P MACH LEARN; BOSWELL R, 1990, TIP2154RAB425; BRAYTON R, 1984, LOGIC MINIMIZATION A; CHO K, 1994, IEEE T PATTERN ANAL, V16, P882, DOI 10.1109/34.310683; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3, DOI 10.1677/jme.0.0020003; Cui Y, 1995, INT WORKSH AUT FAC G, P201; HONG JR, 1985, INT J COMPUT INF SCI, V14, P421, DOI 10.1007/BF00991183; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P709, DOI 10.1109/69.634750; HONG SJ, 1974, IBM J RES DEV, V18, P443, DOI 10.1147/rd.185.0443; HUANG TS, 1995, INT WORKSH AUT FAC G, P73; HUNTER E, 1995, INT WORKSH AUT FAC G, P290; Langley P., 1995, COMMUN ACM, V38, P54, DOI [10.1145/219717.219768, DOI 10.1145/219717.219768]; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P1041; MICHALSKI RS, 1973, P 1 INT JOINT C PATT, P3; MICHALSKI RS, 1983, MACHINE LEARNING ART, P83; Mitchell T.M., 1978, THESIS STANFORD U; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Quek F. K. H., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P17; QUEK FKH, 1995, IMAGE VISION COMPUT, V13, P511, DOI 10.1016/0262-8856(95)94384-C; QUEK FKH, 1995, INT WORKSH AUT FAC G, P372; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; SEGEN J, 1993, VIRTUAL REALITY SYST, P2; Starner T., 1995, INT WORKSHOP AUTOMAT, P189; THRUN SB, 1991, CMUCS91197 SCH COMP; Wu X., 1995, KNOWLEDGE ACQUISITIO; WU X, 1993, P 21 ACM COMP SCI C, P168; WU XD, 1993, ARTIF INTELL REV, V7, P93, DOI 10.1007/BF00849079; Wu XD, 1997, COMPUT J, V40, P50, DOI 10.1093/comjnl/40.1.50; ZHAO M, 1995, VISLAB95001 U ILL CH; Zhao Meide, 1994, Chinese Journal of Computers, V17, P703	31	22	24	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1174	1185		10.1109/34.730553	http://dx.doi.org/10.1109/34.730553			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100005
J	Soatto, S; Perona, P				Soatto, S; Perona, P			Reducing "structure from motion": A general framework for dynamic vision part 2: Implementation and experimental assessment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; structure from motion (SFM); shape estimation; recursive filter; nonlinear implicit extended Kalman filter	SEQUENCE; OBJECT; IMAGES	A number of methods have been proposed in the literature for estimating scene-structure and ego-motion from a sequence of images using dynamical models. Despite the fact that all methods may he derived from a "natural" dynamical model within a unified framework, from an engineering perspective there are a number of bade-offs that lead to different strategies depending upon the applications and the goals one is targeting. We want to characterize and compare the properties of each model such that the engineer may choose the one best suited to the specific application. We analyze the properties of filters derived from each dynamical model under a variety of experimental conditions, assess the accuracy of the estimates, their robustness to measurement noise, sensitivity to initial conditions and visual angle, effects of the bas-relief ambiguity and occlusions, dependence upon the number of image measurements and their sampling rate.	Washington Univ, Dept Elect Engn, St Louis, MO 63130 USA; CALTECH, Dept Elect Engn & Computat & Neural Syst, Pasadena, CA 91125 USA	Washington University (WUSTL); California Institute of Technology	Soatto, S (corresponding author), Washington Univ, Dept Elect Engn, Box 1127,1 Brookings Dr, St Louis, MO 63130 USA.	soatto@ee.wustl.edu; perona@vision.caltech.edu						ANANDAN P, 1994, P IM UND WORKSH; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN J, 1995, REPRESENTATION SCENE; BROIDA TJ, 1991, IEEE T PATTERN ANAL, V13, P497, DOI 10.1109/34.87338; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; CUI N, CVGIP IMAC, V59, P156; FERMULLER C, 1992, BIOL CYBERN, V67, P259, DOI 10.1007/BF00204399; Gennery D B, 1982, P AAAI 2 NAT C ART I, P13; HEEGER D, 1992, INT J COMPUTER VISIO, V7; HEEL J, 1990, 1190 AI MIT ART INT; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lucas Bruce, 1981, IJCAI; MATTHIES L, 1989, INT J COMPUTER VISIO; MCLAUGHLAN P, 1994, P 3 ECCV; Murray R. M., 1994, MATH INTRO ROBOTIC M; OLIENSIS J, 1992, P DARPA IM UND WORKS; RAVIV D, 1994, IEEE T SYSTEMS MAN C, V24; SAWHNEY HS, 1994, P INT C PATT REC; Soatto S, 1996, IEEE T AUTOMAT CONTR, V41, P393, DOI 10.1109/9.486640; Soatto S, 1997, AUTOMATICA, V33, P1287, DOI 10.1016/S0005-1098(97)00048-4; Soatto S, 1998, IEEE T PATTERN ANAL, V20, P933, DOI 10.1109/34.713360; SOATTO S, 1994, IEEE WORKSH MOT NONR, P228; SOATTO S, 1995, P IFAC S NONL CONTR; SOATTO S, 1996, INT J COMPUT VISION, V22, P252; SPETSAKIS M, 1991, INT J COMPUTER VISIO, V6; TAALEBINEZHAAD MA, 1992, IEEE T PATTERN ANAL	30	22	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					943	960		10.1109/34.713361	http://dx.doi.org/10.1109/34.713361			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX		Green Accepted			2022-12-18	WOS:000075758500004
J	Sarker, P; Nagy, G; Zhou, JY; Lopresti, D				Sarker, P; Nagy, G; Zhou, JY; Lopresti, D			Spatial sampling of printed patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						spatial sampling; random phase sampling; digitization; optical character recognition; document defect models; scanner models; modulo-grid diagram; locales		The bitmap obtained by scanning a printed pattern depends on the exact location of the scanning grid relative to the pattern. We consider ideal sampling with a regular lattice of delta functions. The displacement of the lattice relative to the pattern is random and obeys a uniform probability density function defined over a unit cell of the lattice. Random-phase sampling affects the edge-pixels of sampled patterns. The resulting number of distinct bitmaps and their relative frequencies can be predicted from a mapping of the original pattern boundary to the unit cell (called a module-grid diagram). The theory is supported by both simulated and experimental results. The module-grid diagram may be useful in helping to understand the effects of edge-pixel variation on Optical Character Recognition.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; Panason Technol Inc, Panason Informat & Networking Technol Lab, Princeton, NJ 08540 USA; Lucent Technol, Bell Labs Res, Murray Hill, NJ 07974 USA	Rensselaer Polytechnic Institute; Panasonic; Alcatel-Lucent; Lucent Technologies	Sarker, P (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	sarkap@rpi.edu; nagy@ecse.rpi.edu; jz@panasonic.research.com; dlopresti@bell-labs.com		Nagy, George/0000-0002-0521-1443				[Anonymous], P 1 IARP WORKSH GRAP; Armstrong M.A., 1983, BASIC TOPOLOGY; Baird HS., 1992, STRUCTURED DOCUMENT, P546, DOI [10.1007/978-3-642-77281-8_26, DOI 10.1007/978-3-642-77281-8_26]; Falconer K.J., 2014, FRACTAL GEOMETRY MAT, V3rd ed.; HAVELOCK DI, 1989, IEEE T PATTERN ANAL, V11, P1065, DOI 10.1109/34.42837; HAVELOCK DI, 1991, IEEE T PATTERN ANAL, V13, P380, DOI 10.1109/34.88574; INGOLD R, 1989, THESIS PRESSES POLYT; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; Li YH, 1996, IEEE T PATTERN ANAL, V18, P99, DOI 10.1109/34.481536; MANTYLA JM, 1988, INTRO SOLID MODELING; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; NADLER M, 1993, PATTERN RECOGNITION; NAGY G, 1968, IEEE REG 3 NEW ORL L; NAGY G, 1995, P 3 INT C DOC AN REC, P309; OGORMAN L, 1991, IEEE T PATTERN ANAL, V19, P746; OGORMAN L, 1990, P IAPR WORKSH MACH V, P253; RUBINSTEIN HJ, 1988, DIGITAL TYPOGRAPHY I; SARKAR P, 1994, THESIS RENSSELAER PO; ZHOU J, 1994, P IAPR WORKSH MACH V, P346	19	22	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					344	351		10.1109/34.667892	http://dx.doi.org/10.1109/34.667892			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400012
J	Zhong, JL; Huang, TS; Adrian, RJ				Zhong, JL; Huang, TS; Adrian, RJ			Extracting 3D vortices in turbulent fluid flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vector field segmentation; vortex structure analysis and extraction; critical points; pattern recognition	ORIENTED PATTERNS; FIELDS	This paper presents a computational framework to extract salient patterns, called vortex structures, from 3D turbulent fluid flows. These structures can be characterized as regions of dominating rotational motion in the velocity fields and intensity concentrations in the corresponding vorticity fields. A pointwise linear representation is employed to approximate the kinematics of the flow field, and the fluid motion is classified according to motion analysis or topological patterns. The regions of vortex structures are identified as those dominated by rotational motion or those of focus-type singularity. The 2D vortices, as a special case of 3D vortices, are detected by searching for regions of vorticity concentrations.	AT&T Bell Labs, Lucent Technol, Multimedia Commun Res Lab, Murray Hill, NJ 07974 USA; Univ Illinois, Beckman Inst, Dept Elect & Comp Engn, Urbana, IL 61801 USA; Univ Illinois, Dept Theoret & Appl Mech, Urbana, IL 61801 USA	Alcatel-Lucent; Lucent Technologies; AT&T; Nokia Corporation; Nokia Bell Labs; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Zhong, JL (corresponding author), AT&T Bell Labs, Lucent Technol, Multimedia Commun Res Lab, 600 Mt Ave, Murray Hill, NJ 07974 USA.	jlzhong@lucent.com; huang@ifp.uiuc.edu; r-adrian@uiuc.edu						ADRIAN RJ, 1991, ANNU REV FLUID MECH, V23, P261, DOI 10.1146/annurev.fl.23.010191.001401; Batchelor G., 2000, INTRO FLUID DYNAMICS; Batchelor G. K., 1960, THEORY HOMOGENEOUS T; CHONG MS, 1990, PHYS FLUIDS A-FLUID, V2, P765, DOI 10.1063/1.857730; Duda R.O., 1973, J ROYAL STAT SOC SER; FARGE M, 1992, ANNU REV FLUID MECH, V24, P395, DOI 10.1146/annurev.fl.24.010192.002143; FORD R, 1994, IEEE WORKSH VIS MACH; HUSSAIN AKMF, 1986, J FLUID MECH, V173, P303, DOI 10.1017/S0022112086001192; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; MAAS HG, 1989, OPTICAL 3D MEASUREME; MOIN P, 840174 AIAA PAP; MUMFORD JC, 1982, J FLUID MECH, V118, P241, DOI 10.1017/S0022112082001062; PERRY AE, 1987, ANNU REV FLUID MECH, V19, P125, DOI 10.1146/annurev.fluid.19.1.125; RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S; ROBINSON S, 1991, 103859 NASA TECHN ME; SAMTANEY R, 1994, IEEE COMPUT, V27, P20; SHU CF, 1994, IEEE T PATTERN ANAL, V16, P946, DOI 10.1109/34.310692; SHU CF, 1992, IEEE P COMP VIS PATT, P673; SIMARD PY, 1988, IEEE T PATTERN ANAL, V10, P248, DOI 10.1109/34.3886; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; ZHONG J, 1993, MULTIDIMENSIONAL SIG	21	22	26	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					193	199		10.1109/34.659938	http://dx.doi.org/10.1109/34.659938			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800008
J	Pedersini, F; Sarti, A; Tubaro, S				Pedersini, F; Sarti, A; Tubaro, S			Estimation and compensation of subpixel edge localization error	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction; edge localization; subpixel detection	VISION	We propose and analyze a method for improving the performance of subpixel Edge Localization (EL) techniques through compensation of the systematic portion of the localization error. The method is based on the estimation of the EL characteristic through statistical analysis of a test image and is independent of the EL technique in use.			Pedersini, F (corresponding author), POLITECN MILAN,DIPARTIMENTO ELETTRON & INFORMAZ,PIAZZA LEONARDO DA VINCI 32,I-20133 MILAN,ITALY.			PEDERSINI, FEDERICO/0000-0001-7367-6114				BARBE DF, 1975, P IEEE, V63; Born M.A.X., 1980, PRINCIPLES OPTICS, VSixth, P1, DOI 10.1016/B978-0-08-026482-0.50008-6; Canny J., 1986, IEEE T PATTERN ANAL, VPAMI-8; CHAMBERLAIN SG, 1978, IEEE T ELECT DEVICES, V25; DERICHE R, 1990, IEEE T PATTERN ANAL, V12; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; HYNECEK J, 1985, IEEE T ELECT DEVICES, V32; HYNECEK J, 1990, IEEE T ELECT DEVICES, V37; LENZ R, 1993, OPTICAL 3 D MEASUREM, V2; MAALENJOHANSEN I, 1993, P ISPRS 93; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Mehrotra R, 1996, GRAPH MODEL IM PROC, V58, P1, DOI 10.1006/gmip.1996.0001; PEDERSINI F, 1993, 4 INT WORKSH TIM VAR; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; WALKENBURG RJ, 1994, P SPIE VIDOEMETRIC 3, V2350, P229; WEST GAW, 1990, CLOSE RANGE PHOTOGRA, V1395, P456	16	22	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1278	1284		10.1109/34.632986	http://dx.doi.org/10.1109/34.632986			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500008
J	Bonmassar, G; Schwartz, EL				Bonmassar, G; Schwartz, EL			Space-variant Fourier analysis: The exponential chirp transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						logpolar mapping; rotation scale and shift invariance; attention; space-variant image processing; Fourier analysis; nonuniform sampling; real-time imaging; warped template matching	POLAR; INVARIANCE	Space-variant, or foveating, vision architectures are of importance in both machine and biological vision. In this paper, we focus on a particular space-variant map, the log-polar map, which approximates the primate visual map, and which has been applied in machine vision by a number of investigators during the past two decades. Associated with the log-polar map, we define a new linear integral transform, which we call the exponential chirp transform. This transform provides frequency domain image processing for space-variant image formats, while preserving the major aspects of the shift-invariant properties of the usual Fourier transform. We then show that a log-polar coordinate transform in frequency (similar to the Mellin-Transform) provides a fast exponential chirp transform. This provides size and rotation, in addition to shift, invariant properties in the transformed space. Finally, we demonstrate the use of the fast exponential chirp algorithm on a database of images in a template matching task, and also demonstrate its uses for spatial filtering. Given the general lack of algorithms in space-variant image processing, we expect that the fast exponential chirp transform will provide a fundamental tool for applications in this area.	BOSTON UNIV, DEPT COGNIT & NEURAL SYST, BOSTON, MA 02146 USA	Boston University	Bonmassar, G (corresponding author), BOSTON UNIV, DEPT BIOMED ENGN, BOSTON, MA 02215 USA.							ASSELIN D, 1994, OPT COMMUN, V104, P391, DOI 10.1016/0030-4018(94)90576-2; BEUTLER FJ, 1970, IEEE T INFORM THEORY, V16, P147, DOI 10.1109/TIT.1970.1054435; BONMASSAR G, 1997, THESIS BOSTON U; BONMASSAR G, 1994, P INT C PATT REC ICP; BONMASSAR G, 1996, P COMPUTER VISION PA, P229; BROUSIL JK, 1967, IEEE TRANS ELECTRON, VEC16, P818, DOI 10.1109/PGEC.1967.264727; BROWN JL, 1968, IEEE T AUTOMAT CONTR, VAC13, P754, DOI 10.1109/TAC.1968.1099054; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CAVANAGH P, 1978, PERCEPTION, V7, P167, DOI 10.1068/p070167; CLARK JJ, 1985, IEEE T ACOUST SPEECH, V33, P1151, DOI 10.1109/TASSP.1985.1164714; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DeValois RL, 1988, SPATIAL VISION; ELLIOT DF, 1982, FAST TRANSFORMS ALGO; ENGEL G, 1994, P INT C PATT REC ICP; FERRARI JA, 1995, J OPT SOC AM A, V12, P1812, DOI 10.1364/JOSAA.12.001812; Fischl B, 1997, NEURAL NETWORKS, V10, P815, DOI 10.1016/S0893-6080(96)00125-6; FRIEDEN BR, 1992, APPL OPTICS, V31, P1138, DOI 10.1364/AO.31.001138; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; JERRI AJ, 1977, P IEEE, V65, P1565, DOI 10.1109/PROC.1977.10771; JUDAY RD, 1995, OPT LETT, V20, P2234, DOI 10.1364/OL.20.002234; Kelley BT, 1993, IEEE T IMAGE PROCESS, V2, P382, DOI 10.1109/83.236530; KELLMAN P, 1977, APPL OPTICS, V16, P2609, DOI 10.1364/AO.16.002609; Kramer H.P., 1959, J MATH PHYS, V38, P68, DOI DOI 10.1002/SAPM195938168; LIU JC, 1995, SIGNAL PROCESS, V44, P211, DOI 10.1016/0165-1684(95)00025-9; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MCCLELLAN JH, 1979, NUMBER THEORY DIGITA; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; PAPOULIS A, 1966, PR INST ELECTR ELECT, V54, P947, DOI 10.1109/PROC.1966.4940; RADER CM, 1968, PR INST ELECTR ELECT, V56, P1107, DOI 10.1109/PROC.1968.6477; ROJER AS, 1990, P INT C PATT REC ICP, V10, P278; SANDINI G, 1989, P OSA TOP M IM UND M; SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636; SCHWARTZ EL, 1994, PRIMARY VISUAL CORTE, V10; SCHWARTZ EL, 1985, INVEST OPHTHALMOL, V26, P164; SHAPIRO HS, 1960, J SOC IND APPL MATH, V8, P225, DOI 10.1137/0108013; SHENG Y, 1986, J OPT SOC AM A, V3, P771, DOI 10.1364/JOSAA.3.000771; SPLETTSTOSSER AW, 1979, MATH METHOD APPL SCI, V1, P127; STARK H, 1979, J OPT SOC AM, V69, P1519, DOI 10.1364/JOSA.69.001519; STICKLER DC, 1967, PR INST ELECTR ELECT, V55, P418, DOI 10.1109/PROC.1967.5508; STRAIN J, 1992, MATH COMPUT, V58, P275, DOI 10.2307/2153033; TANIMOTO SL, 1981, COMPUT VISION GRAPH, V16, P356, DOI 10.1016/0146-664X(81)90046-0; van der Pol B, 1946, J IEE, V93, P153, DOI DOI 10.1049/JI-3-2.1946.0024; VANDERSPIEGEL J, 1989, ANALOG VLSI IMPLEMEN; WALLACE RS, 1994, INT J COMPUT VISION, V13, P71, DOI 10.1007/BF01420796; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; WEIMAN CFR, 1990, P SPIE S OE AERR SEN; YANG JF, 1993, IEEE T CONSUM ELECTR, V39, P934	50	22	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1080	1089		10.1109/34.625108	http://dx.doi.org/10.1109/34.625108			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800004
J	Sanchez, JA; Benedi, JM				Sanchez, JA; Benedi, JM			Consistency of stochastic context-free grammars from probabilistic estimation based on growth transformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stochastic context-free grammar; consistency; probabilistic estimation; inside-outside algorithm; growth transformations		An important problem related to the probabilistic estimation of Stochastic Context-Free Grammars (SCFGs) is guaranteeing the consistency of the estimated model. This problem was considered in [3], [14] and studied in [10], [4] for unambiguous SCFGs only, when the probabilistic distributions were estimated by the relative frequencies in a training sample. In this work, we extend this result by proving that the property of consistency is guaranteed for all SCFGs without restrictions, when the probability distributions are learned from the classical inside-Outside and Viterbi algorithms, both of which are based on Growth Transformations, Other important probabilistic properties which are related to these results are also proven.			Sanchez, JA (corresponding author), UNIV POLITECN VALENCIA,DEPT SISTEMAS INFORMAT & COMPUTAC,CAMINO DE VERA S-N,E-46071 VALENCIA,SPAIN.		Sánchez, Joan Andreu/M-1550-2014; Benedi, Juana/K-9740-2014; Benedi, Jose Miguel/E-4521-2018	Sánchez, Joan Andreu/0000-0003-0423-2020; Benedi, Juana/0000-0002-3796-639X; Benedi, Jose Miguel/0000-0001-6516-2746				BAKER JK, 1979, SPEECH COMM 97 M AC, P31; Baum LE, 1972, INEQUALITIES, V3, P1; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; CHAUDHURI R, 1983, IEEE T COMPUT, V32, P748, DOI 10.1109/TC.1983.1676313; CHAUDHURI R, 1983, INT J MATH MATH SCI, V6, P403; Chen S. F, 1996, BUILDING PROBABILIST; FU KS, 1982, SYNTACTIC PATTERN RE; GOPALAKRISHNAN PS, 1991, IEEE T INFORM THEORY, V37, P107, DOI 10.1109/18.61108; Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X; Ney H., 1992, Speech Recognition and Understanding. Recent Advances, Trends and Applications. Proceedings of the NATO Advanced Study Institute, P319; SANCHEZ JA, 1996, DSIC22096 U POL VAL; Stolcke A, 1994, THESIS U CALIFORNIA; WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829; [No title captured]	14	22	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					1052	1055		10.1109/34.615455	http://dx.doi.org/10.1109/34.615455			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500012
J	HOOVER, A; GOLDGOF, D; BOWYER, KW				HOOVER, A; GOLDGOF, D; BOWYER, KW			EXTRACTING A VALID BOUNDARY REPRESENTATION FROM A SEGMENTED RANGE IMAGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EXPERIMENTAL COMPUTER VISION; RANGE IMAGE PROCESSING 3D SHAPE; MODEL RECONSTRUCTION	MULTIPLE	A new approach is presented for extracting an explicit 3-D shape model from a single range image. One novel aspect is that the model represents both observed object surfaces, and surfaces which bound the volume of occluded space. Another novel aspect is that the approach does not require that the range image segmentation be perfect. The low-level segmentation may be such that the model-building process encounters topology versus geometry conflicts. The model-building process is designed to be ''fail soft'' in the face of such problems. The portion of the 3-D model where a problem presents itself is ''glued'' together in a manner meant to minimize the disturbance in the 3-D shape. The goal is to produce a valid boundary-representation which can be processed by higher-level routines. A third novel aspect of this work is that the implementation has been evaluated on over 200 real range images of polyhedral objects, with no operator intervention and all parameters held constant, and obtained a 97% success rate in creating valid b-reps.			HOOVER, A (corresponding author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.		Goldgof, Dmitry/ABF-1366-2020	Bowyer, Kevin/0000-0002-7562-4390				BHANDARKAR SM, 1992, PATTERN RECOGN, V25, P947, DOI 10.1016/0031-3203(92)90060-V; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; CHEN Z, 1993, PATTERN RECOGN, V26, P33, DOI 10.1016/0031-3203(93)90086-C; HOOVER A, 1994, 9401 U S FLOR DEP CO; JAIN RC, 1990, ANAL INTERPRETATION; PARVIN B, 1992, MAY P IEEE INT C R A, P1602; Requicha A. G., 1980, ACM COMPUT SURV, P437; STARK L, 1993, JUN IEEE WORKSH QUAL, P11; STENSTROM JR, 1992, INT J COMPUT VISION, V9, P185, DOI 10.1007/BF00133701	10	22	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					920	924		10.1109/34.406660	http://dx.doi.org/10.1109/34.406660			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900011
J	KATZ, AJ; THRIFT, PR				KATZ, AJ; THRIFT, PR			GENERATING IMAGE FILTERS FOR TARGET RECOGNITION BY GENETIC LEARNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							NEURAL NETWORK	We describe results obtained from applying genetic algorithms to the problem of detecting targets in image data. The method we describe is a two-layered approach, with the first layer providing a focus-of-attention function for the second layer. The first layer is called a Screener and selects subimages from the original image data to be processed by the second layer, called the Classifier. The Screener reduces the computational load of the system. Each layer consists of a set of linear operators (filters) applied directly to the image data. A genetic algorithm is applied to populations of filters based on fitness criteria. We note that the statistical classifier chosen for the Classifier stage drives the evolution of filters that are useful for that classifier to make good discriminations.			KATZ, AJ (corresponding author), TEXAS INSTRUMENTS INC,CENT RES LABS,POB 655936,MS 134,DALLAS,TX 75265, USA.							Davis L, 1991, HDB GENETIC ALGORITH, DOI DOI 10.1.1.87.3586; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GOLDBERG D, 1990, REAL CODED GENETIC A; Goldberg D., 1988, GENETIC ALGORITHMS S; INTRATOR N, 1992, NEURAL COMPUT, V4, P98, DOI 10.1162/neco.1992.4.1.98; Olshen R., 1984, CLASSIFICATION REGRE; Pao Y.H., 1989, ADAPTIVE PATTERN REC; RIZKI MM, ADAPTIVE SEARCH MORP; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0	10	22	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					906	910		10.1109/34.310687	http://dx.doi.org/10.1109/34.310687			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200007
J	PIKAZ, A; DINSTEIN, IH				PIKAZ, A; DINSTEIN, IH			USING SIMPLE DECOMPOSITION FOR SMOOTHING AND FEATURE POINT DETECTION OF NOISY DIGITAL CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						IMAGE PROCESSING; SHAPE ANALYSIS; DIGITAL CURVE DECOMPOSITION; FEATURE EXTRACTION	PLANAR CURVES; SHAPE; APPROXIMATION	This correspondence presents an algorithm for smoothed polygonal approximation of noisy digital planar curves, and feature point detection. The, resulting smoothed polygonal representation preserves the signs of the curvature function of the curve. The algorithm is based on a simple decomposition of noisy digital curves into a minimal number of convex and concave sections. The location of each separation point is optimized, yielding the minimal possible distance between the smoothed approximation and the original curve. Curve points within a convex (concave) section are discarded if their angle signs do not agree with the section sign, and if the resulted deviations from the curve are less than a threshold epsilon which is derived automatically. Inflection points are curve points between pairs of convex-concave sections, and cusps are curve points between pairs of convex-convex or concave-concave sections. Corners and points of local minimal curvature are detected by applying the algorithm to respective total curvature graphs. The detection of the feature points is based on properties of pairs of sections that are determined in an adaptive manner, rather than on properties of single points that are based on a fixed-size neighborhood. The detection is therefore reliable and robust. Complexity analysis and experimental results are presented.	BEN GURION UNIV NEGEV,DEPT COMP SCI,IL-84105 BEER SHEVA,ISRAEL; BEN GURION UNIV NEGEV,DEPT ELECT & COMP ENGN,IL-84105 BEER SHEVA,ISRAEL	Ben Gurion University; Ben Gurion University								ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BENGTSSON A, 1991, IEEE T PATTERN ANAL, V13, P85, DOI 10.1109/34.67634; BRUCKSTEIN AM, 1992, INT J COMPUT VISION, V7, P271, DOI 10.1007/BF00126396; DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; FISCHLER MA, 1986, IEEE T PATT ANAL MAC, V8; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; HAN HJ, 1990, 3RD P INT C COMP VIS, P71; KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; Pavlidis T., 1980, STRUCTURAL PATTERN R; PIKAZ A, 1992, THESIS BENGURION U B; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TOMEK I, 1974, IEEE T COMPUT, VC 23, P445, DOI 10.1109/T-C.1974.223961	22	22	24	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					808	813		10.1109/34.308476	http://dx.doi.org/10.1109/34.308476			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500006
J	BARNETT, JA				BARNETT, JA			CALCULATING DEMPSTER-SHAFER PLAUSIBILITY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DECISION MAKING; DEMPSTER-SHAFER BELIEF CALCULUS; PLAUSIBILITY CALCULATION; PLAUSIBLE REASONING	RULE	A sufficient condition is developed for the equality of the plausibility and commonality measures of the Dempster-Shafer belief calculus. When the condition is met, as it is in many applications, an efficient method to calculate relative plausibility is available. In particular, the method can be used to calculate the relative plausibility of atomic hypotheses and, therefore, it can be used to find the choice that maximizes this measure. The computation is efficient enough to make Dempster-Shafer practical in some domains where computational complexity would otherwise counterindicate its use.			BARNETT, JA (corresponding author), NORTHROP CORP,CTR & TECHNOL,1 RES PK,PALOS VERDES PENINSULA,CA 90274, USA.							Barnett J. A., 1981, P 7 INT JOINT C ART, P868; GORDON J, 1985, ARTIF INTELL, V26, P323, DOI 10.1016/0004-3702(85)90064-5; HUMMEL RA, 1988, IEEE T PATTERN ANAL, V10, P235, DOI 10.1109/34.3885; ORPONEN P, 1990, ARTIF INTELL, V44, P245, DOI 10.1016/0004-3702(90)90103-7; SCHOCKEN S, 1989, IEEE T SYST MAN CYB, V19, P1106, DOI 10.1109/21.44027; SHAFER G, 1987, ARTIF INTELL, V33, P271, DOI 10.1016/0004-3702(87)90040-3; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Tarski A., 1969, LOGIC SEMANTICS META	8	22	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					599	602		10.1109/34.87345	http://dx.doi.org/10.1109/34.87345			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372		Green Submitted			2022-12-18	WOS:A1991FU37200008
J	POWLEY, C; KORF, RE				POWLEY, C; KORF, RE			SINGLE-AGENT PARALLEL WINDOW SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DEPTH-FIRST SEARCH; HEURISTIC SEARCH; ITERATIVEDEEPENING A; NODE ORDERIING; PARALLEL SEARCH; PARALLEL WINDOW SEARCH	HEURISTIC-SEARCH	We apply parallel window search to single-agent problems by having different processes simultaneously perform iterations of Iterative-Deepening -A* (IDA*) on the same problem but with different cost thresholds. This approach is limited by the time to perform the goal iteration. To overcome this disadvantage, we then consider node ordering. We discuss how global node ordering by minimum h among nodes with equal f = g + h values can reduce the time complexity of serial IDA* by reducing the time of the goal iteration. This approach is limited by the time to perform the iterations prior to the goal iteration. Finally, we combine the two ideas of parallel window search and node ordering to eliminate the weaknesses of each approach while retaining the strengths. The resulting approach, which we call simply parallel window search, can be used to find a near-optimal solution quickly, improve the solution until it is optimal, and then finally guarantee optimality, depending on the amount of time available.			POWLEY, C (corresponding author), UNIV CALIF LOS ANGELES,DEPT COMP SCI,LOS ANGELES,CA 90024, USA.							BAUDET G, 1978, THESIS CARNEGIEMELLO; CHAKRABARTI PP, 1989, ARTIF INTELL, V41, P197, DOI 10.1016/0004-3702(89)90010-6; EBELING C, 1987, RIGHT MOVES; FELDERMAN RE, 1989, IEEE J SEL AREA COMM, V7, P303, DOI 10.1109/49.17702; Feldmann R., 1990, PARALLEL ALGORITHMS, P66, DOI [10.1007/978-1-4612-3390-9_3, DOI 10.1007/978-1-4612-3390-9_3]; FELTON E, 1988, 5TH P INT C GEN COMP; FERGUSON C, 1988, 7TH P NAT C ART INT, P128; HART PE, 1968, IEEE T SYS SCI CYBER, V4, P100, DOI DOI 10.1109/TSSC.1968.300136; HSU FH, 1990, THESIS CARNEGIEMELLO; KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0; KUMAR V, 1987, INT J PARALLEL PROG, V16, P501, DOI 10.1007/BF01389001; KUMAR V, 1984, IEEE T PATTERN ANAL, V6, P768, DOI 10.1109/TPAMI.1984.4767600; POHL I, 1970, ARTIF INTELL, V1, P193, DOI 10.1016/0004-3702(70)90007-X; POWLEY C, 1989, 11TH P INT JOINT C A, P36; POWLEY C, 1990, PARALLEL ALGORITHMS, P42; RAO VN, 1987, INT J PARALLEL PROG, V16, P479, DOI 10.1007/BF01389000; RAO VN, 1987, 6TH P NAT AI SEATTL, P178; SIMON HA, 1975, ARTIF INTELL, V6, P235, DOI 10.1016/0004-3702(75)90002-8; Slate D. J., 1977, Chess skill in man and machine, P82	19	22	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1991	13	5					466	477		10.1109/34.134045	http://dx.doi.org/10.1109/34.134045			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FQ207					2022-12-18	WOS:A1991FQ20700006
J	COX, IJ; KRUSKAL, JB; WALLACH, DA				COX, IJ; KRUSKAL, JB; WALLACH, DA			PREDICTING AND ESTIMATING THE ACCURACY OF A SUBPIXEL REGISTRATION ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									AT&T BELL LABS,MATH SCI RES CTR,MURRAY HILL,NJ 07974	AT&T; Nokia Corporation; Nokia Bell Labs								Barrow HG, 1977, P 5 INT JOINT C ART; BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; Boie R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P100; BOIE RA, 1987, 1ST P IEEE INT C CCO, P450; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; COX IJ, 1989, 28TH P IEEE C DEC CO; COX IJ, 1989, SEP P IEEE RSJ INT W; COX IJ, 1988, 2ND P INT C COMP VIS; Grimson W. E. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P218, DOI 10.1109/CCV.1988.589993; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; Williams EJ., 1978, INT ENCY STAT, P523	12	22	37	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1990	12	8					721	734		10.1109/34.57665	http://dx.doi.org/10.1109/34.57665			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DQ388					2022-12-18	WOS:A1990DQ38800001
J	KOENDERINK, JJ				KOENDERINK, JJ			A HITHERTO UNNOTICED SINGULARITY OF SCALE-SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KOENDERINK, JJ (corresponding author), STATE UNIV UTRECHT,DEPT MED & PHYSIOL PHYS,BUYS BALLOT LAB,PRINCETONPLEIN 5,3584 CC UTRECHT,NETHERLANDS.							KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; LIFSHITZ LM, 1987, 87012 U N CAR DEP CO; PAPOULIS A, 1968, SYSTEMS TRANSFORMS A, P59; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P1	6	22	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1222	1224		10.1109/34.42861	http://dx.doi.org/10.1109/34.42861			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600010
J	KEHTARNAVAZ, N; DEFIGUEIREDO, RJP				KEHTARNAVAZ, N; DEFIGUEIREDO, RJP			A 3-D CONTOUR SEGMENTATION SCHEME BASED ON CURVATURE AND TORSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									RICE UNIV,DEPT ELECT & COMP ENGN,HOUSTON,TX 77251; RICE UNIV,DEPT MATH SCI,HOUSTON,TX 77251	Rice University; Rice University	KEHTARNAVAZ, N (corresponding author), TEXAS A&M UNIV,DEPT ELECT ENGN,COLLEGE STN,TX 77843, USA.							ASADA H, 1984, MIT758 TECH REP A I; BAMIEH B, 1986, IEEE T ROBOTIC AUTOM, V2, P31, DOI 10.1109/JRA.1986.1087034; DAVIS LS, 1973, IEEE T COMPUT, V26, P236; DEFIGUEIREDO RJP, 1982, IEEE T PATTERN ANAL, V4, P105, DOI 10.1109/TPAMI.1982.4767214; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; KEHTARNAVAZ N, 1988, COMPUT VISION GRAPH, V42, P399, DOI 10.1016/S0734-189X(88)80048-3; KEHTARNAVAZ N, 1988, COMPUT VISION GRAPH, V42, P32, DOI 10.1016/0734-189X(88)90141-7; KEHTARNAVAZ N, 1988, P SPIE C OPTICS ELEC, P357; Lipschutz M., 1969, DIFFERENTIAL GEOMETR; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871	13	22	24	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					707	713		10.1109/34.6780	http://dx.doi.org/10.1109/34.6780			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500011
J	SIMARD, PY; MAILLOUX, GE				SIMARD, PY; MAILLOUX, GE			A PROJECTION OPERATOR FOR THE RESTORATION OF DIVERGENCE-FREE VECTOR-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SIMARD, PY (corresponding author), ECOLE POLYTECH,INST GENIE BIOMED,MONTREAL H3C 3A7,QUEBEC,CANADA.							Adams R., 2003, SOBOLEV SPACE, Vsecond; CHIN RT, 1985, IEEE T PATTERN ANAL, V7, P475, DOI 10.1109/TPAMI.1985.4767686; Girault V., 1979, FINITE ELEMENT APPRO; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Sezan M, 1984, IEEE Trans Med Imaging, V3, P91, DOI 10.1109/TMI.1984.4307661; Sezan M I, 1982, IEEE Trans Med Imaging, V1, P95, DOI 10.1109/TMI.1982.4307556; TEMAN R, 1979, NAVIER STOKES EQUATI, P17; Wilkie, 1968, MUSCLE; Youla D C, 1982, IEEE Trans Med Imaging, V1, P81, DOI 10.1109/TMI.1982.4307555; [No title captured]	11	22	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					248	256		10.1109/34.3886	http://dx.doi.org/10.1109/34.3886			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400008
J	HARA, Y; DOI, H; KARASAKI, K; IIDA, T				HARA, Y; DOI, H; KARASAKI, K; IIDA, T			A SYSTEM FOR PCB AUTOMATED INSPECTION USING FLUORESCENT LIGHT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									HITACHI LTD,KANAGAWA WORKS,HADANO,KANAGAWA 25913,JAPAN	Hitachi Limited	HARA, Y (corresponding author), HITACHI LTD,PROD ENGN RES LAB,292 YOSHIDA MACHI,TOTSUKA KU,YOKOHAMA 244,JAPAN.							BARK LS, 1982, ANAL POLYM SYSTEMS, pCH4; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; GILUTZ H, 1985, ELECTRON PACKAGI SEP, P68; HARA Y, 1983, IEEE T PATTERN ANAL, V5, P623, DOI 10.1109/TPAMI.1983.4767453; HARA Y, 1985, ELECTRONICS COMMUN 2, V68, P1; HARA Y, 1980, 5TH P INT JOINT C PA, P273; HUDSON D, ELECTRO 84; NAKASHIMA M, 1981, FUJITU SCI TECHN JUN, P105; WEST MA, 1983, IBM J RES DEV, V27, P50, DOI 10.1147/rd.271.0050	10	22	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					69	78		10.1109/34.3868	http://dx.doi.org/10.1109/34.3868			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600007
J	LEE, SY; AGGARWAL, JK				LEE, SY; AGGARWAL, JK			PARALLEL 2-D CONVOLUTION ON A MESH CONNECTED ARRAY PROCESSOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LEE, SY (corresponding author), UNIV TEXAS,COLL ENGN,COMP & VIS RES CTR,AUSTIN,TX 78712, USA.							DEO N, 1974, GRAPH THEORY APPLICA; Duff M.J.B., 1978, P NATIONAL COMPUTER, P1055; Hall E. L., 1979, COMPUTER IMAGE PROCE; KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825; KUNG HT, 1981, NOV IEEE COMP SOC WO, P159; KUNG HT, 1981, NOV P IEEE C SOC WOR, P273; LEE SY, 1985, JUN P IEEE COMP SOC, P614; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Rosenfeld A., 1982, DIGITAL PICTURE PROC; YOUNG TY, 1983, OCT P IEEE WORKSH CO, P118	10	22	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1987	9	4					590	594		10.1109/TPAMI.1987.4767947	http://dx.doi.org/10.1109/TPAMI.1987.4767947			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H9088	21869417				2022-12-18	WOS:A1987H908800013
J	FU, KS				FU, KS			A STEP TOWARDS UNIFICATION OF SYNTACTIC AND STATISTICAL PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FU, KS (corresponding author), PURDUE UNIV, SCH ELECT ENGN, W LAFAYETTE, IN 47907 USA.							Aho A.V., 1972, THEORY PARSING TRANS; [Anonymous], PATTERN RECOGNITION; BANAMINI R, 1982, PATTERN RECOGNITION; BUNKE H, 1979, GRAPH GRAMMAR APPLIC; FAN TI, 1979, COMPUT VISION GRAPH, V11, P138, DOI 10.1016/0146-664X(79)90063-7; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; FU KS, 1980, DIGITAL PATTERN RECO; FU KS, 1982, SYNTACTIC PATTERN RE; FU KS, 1980, IEEE T COMPUT, V29; FU KS, 1981, JUN WORKSH STRUCT SY; FU KS, 1982, 1982 P PRIP C LAS VE; GEORGEFF MP, 1982, ARTIF INTELL, P173; GIESE DA, 1979, IEEE T SYST MAN CYBE, V9; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; Knuth D. E., 1968, Mathematical Systems Theory, V2, P127, DOI 10.1007/BF01692511; LEDLEY RS, 1965, OPTICAL ELECTROOPTIC; Lewis PM, 1976, COMPILER DESIGN THEO; LIU HH, 1982, IEEE T PATTERN ANAL, V4; MOAYER B, 1975, PATTERN RECOGN, V7, P210; MUNDY JL, 1977, 1977 P IEEE COMP SOC; Pavlidis T., 1977, STRUCTURAL PATTERN R; PYSTER A, 1978, INFORM CONTR, V39, P320; ROSENFELD A, 1981, COMPUT GRAPHICS IMAG, V16; SANFELIU A, 1981, JUN NSF WORKSH STRUC; SANFELIU A, UNPUB DISTANCE MEASU; SANFELIU A, 1982, 2ND P INT WORKSH GRA; SHAPIRO L, 1981, ORG RELATIONAL MODEL; SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5; SHI QY, 1982, 6TH P INT C PATT REC; SHI QY, 1982, INFORM SCI, V26; STOCKMAN G, 1976, COMMUN ASS COMPUT MA, V19; TAI JW, 1982, 6TH P INT C PATT REC; THOMASON MG, 1975, IEEE T COMPUT, V24; TSAI WH, 1979, IEEE T SYST MAN CYBE, V9; TSAI WH, 1980, 5TH P INT C PATT REC; TSAI WH, 1983, IEEE T SYST MAN CYBE, V13; Winston P. H., 1975, PSYCHOL COMPUTER VIS; YOU KC, 1979, IEEE T SYST MAN CYBE, V9	38	22	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					398	404		10.1109/TPAMI.1986.4767800	http://dx.doi.org/10.1109/TPAMI.1986.4767800			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C0841	21869356				2022-12-18	WOS:A1986C084100009
J	LANSNER, A; EKEBERG, O				LANSNER, A; EKEBERG, O			RELIABILITY AND SPEED OF RECALL IN AN ASSOCIATIVE NETWORK	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LANSNER, A (corresponding author), ROYAL INST TECHNOL,DEPT NUMER ANAL & COMP SCI,S-10044 STOCKHOLM 70,SWEDEN.		Ekeberg, Örjan/F-1402-2011; Lansner, Anders/E-4824-2016	Ekeberg, Örjan/0000-0002-2792-1622; Lansner, Anders/0000-0002-2358-7815				ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3; BALLARD DH, 1983, NATURE, V306, P21, DOI 10.1038/306021a0; Hinton Geoffrey E, 1981, PARALLEL MODELS ASS; KOHONEN T, 1976, BIOL CYBERN, V22, P159, DOI 10.1007/BF00365526; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353, DOI 10.1109/TC.1972.5008975; Kohonen T., 1981, PARALLEL MODELS ASS, P105; Kohonen T., 1977, ASS MEMORY; Kohonen Teuvo, 1984, SELF ORG ASS MEMORY; LANSNER A, 1983, TRITANA8302 ROY I TE; LANSNER A, 1982, TRITANA8211 ROY I TE; LANSNER A, 1984, TRITANA8408 ROY I TE; LEGENDY C. R., 1967, MATH BIOSCI, V1, P555, DOI 10.1016/0025-5564(67)90003-X; LONGUET-HIGGINS H C, 1970, Quarterly Reviews of Biophysics, V3, P223; PALM G, 1981, BIOL CYBERN, V39, P125, DOI 10.1007/BF00336738; PALM G, 1981, BIOL CYBERN, V39, P181, DOI 10.1007/BF00342771; PALM G, 1980, BIOL CYBERN, V36, P19, DOI 10.1007/BF00337019; Palm G., 1982, NEURAL ASSEMBLIES AL; WILLSHAW DJ, 1969, MACHINE INTELLIGENCE, V5; WILLWACHER G, 1982, BIOL CYBERN, V43, P115, DOI 10.1007/BF00336974; WILLWACHER G, 1976, BIOL CYBERN, V24, P181, DOI 10.1007/BF00335979	20	22	23	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					490	498		10.1109/TPAMI.1985.4767688	http://dx.doi.org/10.1109/TPAMI.1985.4767688			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869287				2022-12-18	WOS:A1985ALB6900013
J	STENTIFORD, FWM				STENTIFORD, FWM			AUTOMATIC FEATURE DESIGN FOR OPTICAL CHARACTER-RECOGNITION USING AN EVOLUTIONARY SEARCH PROCEDURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											STENTIFORD, FWM (corresponding author), BRITISH TELECOM RES LABS,IPSWICH IP5 7RE,SUFFOLK,ENGLAND.							ADAWAY WGL, 1982, IEE C PUB, V214, P159; BAKIS R, 1968, IEEE T SYST SCI CYB, VSSC4, P119, DOI 10.1109/TSSC.1968.300138; BLEDSOE WW, 1969, P E JOINT COMPUT C, P225; BRAKKE KA, 1982, IEEE T PATTERN ANAL, V4, P291, DOI 10.1109/TPAMI.1982.4767245; CHANDRASEKARAN B, 1971, IEEE T INFORM THEORY, V17, P452, DOI 10.1109/TIT.1971.1054665; DUERR B, 1980, PATTERN RECOGN, V12, P189, DOI 10.1016/0031-3203(80)90043-6; Fleming JF, 1983, PATTERN RECOGN LETT, V1, P457, DOI 10.1016/0167-8655(83)90086-7; FLORES I, 1960, IRE T ELECTRON COM, VEC9, P54; GU YX, 1983, IEEE T PATTERN ANAL, V5, P83, DOI 10.1109/TPAMI.1983.4767349; HO YC, 1968, PR INST ELECTR ELECT, V56, P2101; Kamentsky L., 1964, COMPUTER INFORMATION, P194; KAMENTSKY LA, 1963, IBM J RES DEV, V7, P2, DOI 10.1147/rd.71.0002; LAI MTY, 1981, PATTERN RECOGN, V14, P383, DOI 10.1016/0031-3203(81)90083-2; LEVINE MD, 1969, P IEEE, V57, P1391, DOI 10.1109/PROC.1969.7277; LIU CN, 1964, IEEE T COMPUT, VEC13, P586, DOI 10.1109/PGEC.1964.263730; MALINA W, 1981, IEEE T PATTERN ANAL, V3, P611, DOI 10.1109/TPAMI.1981.4767154; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; NADLER M, 1980, 5TH P INT C PATT REC, P848; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; ROUNDS EM, 1980, PATTERN RECOGNITION, V12, P312; SHORT RD, 1982, IEEE T PATTERN ANAL, V4, P323, DOI 10.1109/TPAMI.1982.4767252; STENTIFORD FWM, 1974, THESIS SOUTHAMPTON U, P44; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; SUEN CY, 1982, SIGNAL PROCESS, V4, P193, DOI 10.1016/0165-1684(82)90021-4; UHR L, 1961, P WJCC, P555; ULLMANN JR, 1969, IEEE T COMPUT, VC 18, P1135, DOI 10.1109/T-C.1969.222599; VANSTEENIS H, 1970, 4TH C DTSCH GES KYB; YAMAMOTO K, 1980, PATTERN RECOGN, V12, P229, DOI 10.1016/0031-3203(80)90062-X; 1971, CHARACTER RECOGNITIO	29	22	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					349	355		10.1109/TPAMI.1985.4767665	http://dx.doi.org/10.1109/TPAMI.1985.4767665			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869271				2022-12-18	WOS:A1985AFM4400011
J	HONG, TH; SHNEIER, M				HONG, TH; SHNEIER, M			EXTRACTING COMPACT OBJECTS USING LINKED PYRAMIDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; DANKER AJ, 1981, IEEE T PATTERN ANAL, V3, P79, DOI 10.1109/TPAMI.1981.4767053; DYER CR, 1981, AUG P PRIP 81, P381; HARTLEY RL, 1982, IEEE T SYST MAN CYB, V12, P553; HONG TH, 1982, IEEE T SYST MAN CYB, V12, P660; HONG TH, 1982, IEEE T SYST MAN CYB, V12, P611, DOI 10.1109/TSMC.1982.4308880; HONG TH, UNPUB IEEE T PATTERN; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; LEVINE MD, 1980, STRUCTURED COMPUTER, P57; MILGRAM DL, 1979, COMPUT VISION GRAPH, V11, P1, DOI 10.1016/0146-664X(79)90073-X; SHNEIER M, 1983, IEEE T PATTERN ANAL, V5, P345, DOI 10.1109/TPAMI.1983.4767397; SHNEIER MO, 1982, IEEE T SYST MAN CYB, V12, P569; STRONG JP, 1973, COMMUN ACM, V16, P237, DOI 10.1145/362003.362030; TANIMOTO SL, 1976, COMPUT GRAPHICS IMAG, V5, P330; UHR L, 1980, STRUCTURED COMPUTER, P1	16	22	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					229	237		10.1109/TPAMI.1984.4767506	http://dx.doi.org/10.1109/TPAMI.1984.4767506			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SF591	21869186				2022-12-18	WOS:A1984SF59100009
J	KITTLER, J; DEVIJVER, PA				KITTLER, J; DEVIJVER, PA			STATISTICAL PROPERTIES OF ERROR ESTIMATORS IN PERFORMANCE ASSESSMENT OF RECOGNITION SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											KITTLER, J (corresponding author), PHILIPS RES LAB,BRUSSELS,BELGIUM.							CHEN Z, 1977, IEEE T SYST MAN CYB, V7, P651, DOI 10.1109/TSMC.1977.4309802; COVER TM, 1969, METHODOLOGIES PATTER, P111; DEVIJVER PA, 1978, PATTERN RECOGN, V10, P297, DOI 10.1016/0031-3203(78)90039-0; DEVIJVER PA, 1978, 4TH P INT C PATT REC, P217; DEVIJVER PA, 1977, P SEMINAR PATTERN RE; DEVIJVER PA, 1978, PATTERN RECOGNITION; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P434, DOI 10.1109/TIT.1973.1055049; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GARNETT JM, 1977, IEEE T COMPUT, V26, P46, DOI 10.1109/TC.1977.5009273; HIGHLEYMAN WH, 1962, AT&T TECH J, V41, P723, DOI 10.1002/j.1538-7305.1962.tb02426.x; JOHN S, 1961, ANN MATH STAT, V32, P1125, DOI 10.1214/aoms/1177704851; KANAL L, 1971, PATTERN RECOGN, V3, P225, DOI 10.1016/0031-3203(71)90013-6; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KITTLER J, 1980, IEEE T PATTERN ANAL, V2, P259, DOI 10.1109/TPAMI.1980.4767014; KITTLER J, 1978, 4TH P IJCPR KYOT JAP, P249; LACHENBRUCH PA, 1967, BIOMETRICS, V23, P639, DOI 10.2307/2528418; LISSACK T, 1974, IEEE T INFORM THEORY, V22, P34; OKAMOTO M, 1963, ANN MATH STAT, V34, P1286, DOI 10.1214/aoms/1177703864; Smith C., 1947, ANN EUGEN, V18, P272; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260	21	22	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					215	220		10.1109/TPAMI.1982.4767229	http://dx.doi.org/10.1109/TPAMI.1982.4767229			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869028				2022-12-18	WOS:A1982NE95700018
J	NAGIN, PA; HANSON, AR; RISEMAN, EM				NAGIN, PA; HANSON, AR; RISEMAN, EM			STUDIES IN GLOBAL AND LOCAL HISTOGRAM-GUIDED RELAXATION ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01002	University of Massachusetts System; University of Massachusetts Amherst	NAGIN, PA (corresponding author), TUFTS UNIV,NEW ENGLAND MED CTR,DEPT OPHTHALMOL,BOSTON,MA 02111, USA.							CHOW CK, 1971, 1971 P IFIP, P130; COLEMAN GB, 1977, USCIPI750 U SO CAL I; EKLUNDH J, 1979, IEEE T PATTERN ANAL, V1; HANSON AR, 1976, COINS769 U MASS TECH; HANSON AR, 1980, CONSISTENT LABELING; KOHLER R, THESIS U MASSACHUSET; NAGIN PA, 1979, COINS7915 U MASS TEC; OVERTON KJ, 1979, AUG P PATT REC IM PR, P498; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PRAGER JM, 1979, COINS797 U MASS TECH; RISEMAN EM, 1978, MECHANISMS PARALLEL; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1977, TR519 U MAR COMP SCI; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P117, DOI 10.1109/TPAMI.1981.4767069; ZUCKER SW, 1978, MAY IJCPR CHIC	17	22	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					263	277		10.1109/TPAMI.1982.4767243	http://dx.doi.org/10.1109/TPAMI.1982.4767243			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869033				2022-12-18	WOS:A1982NN06900004
J	DATTATREYA, GR; SARMA, VVS				DATTATREYA, GR; SARMA, VVS			BAYESIAN AND DECISION TREE APPROACHES FOR PATTERN-RECOGNITION INCLUDING FEATURE MEASUREMENT COSTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DATTATREYA, GR (corresponding author), INDIAN INST SCI,SCH AUTOMAT,BANGALORE 560012,INDIA.							ATAL BS, 1976, IEEE T ACOUST SPEECH, V24, P201, DOI 10.1109/TASSP.1976.1162800; DANTE HM, 1979, IEEE T ACOUST SPEECH, V27, P255, DOI 10.1109/TASSP.1979.1163238; DANTE HM, 1979, 1979 P IEEE INT C AC, P797; Duda R.O., 1973, J ROYAL STAT SOC SER; Fu K.-S., 1976, IEEE Transactions on Geoscience Electronics, VGE-14, P10, DOI 10.1109/TGE.1976.294459; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193, DOI 10.1109/TPAMI.1979.4766905; KULKARNI AV, 1976, THESIS U MARYLAND; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905, DOI 10.1109/TC.1977.1674938; PETERS RJ, 1977, IBM J RES DEV, V21, P449, DOI 10.1147/rd.215.0449; Rabiner L., 1978, DIGITAL PROCESSING S; SARMA VVS, 1978, 1979 P IEEE INT C AC, P1; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972; WALD A, 1950, STATISTICAL DECISION	15	22	22	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					293	298		10.1109/TPAMI.1981.4767102	http://dx.doi.org/10.1109/TPAMI.1981.4767102			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN969	21868950				2022-12-18	WOS:A1981MN96900006
J	RICHARDS, JA; LANDGREBE, DA; SWAIN, PH				RICHARDS, JA; LANDGREBE, DA; SWAIN, PH			PIXEL LABELING BY SUPERVISED PROBABILISTIC RELAXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									PURDUE UNIV,APPL REMOTE SENSING LAB,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	RICHARDS, JA (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							FAUGERAS O, 1979, 1979 P IEEE C PATT R, P318; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1979, 1979 P IEEE C PATT R, P337; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; YAMAMOTO H, 1979, COMPUT VISION GRAPH, V10, P256, DOI 10.1016/0146-664X(79)90005-4; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1978, 1978 P IEEE C PATT R, P307	7	22	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					188	191		10.1109/TPAMI.1981.4767077	http://dx.doi.org/10.1109/TPAMI.1981.4767077			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868934	Green Submitted			2022-12-18	WOS:A1981MN96800009
J	TSUJI, S; OSADA, M; YACHIDA, M				TSUJI, S; OSADA, M; YACHIDA, M			TRACKING AND SEGMENTATION OF MOVING-OBJECTS IN DYNAMIC LINE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											TSUJI, S (corresponding author), OSAKA UNIV,FAC ENGN SCI,DEPT CONTROL ENGN,OSAKA,JAPAN.							AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; ARIKI Y, 1978, 4TH P IJCPR, P681; BADLER N, 1974, 2ND P INT JOINT C PA, P157; JAIN R, 1975, 5TH P INT JOINT C AR, P612; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; NAGEL HH, 1978, 4TH P INT JOINT C PA, P186; TSUJI S, 1977, 5TH P INT JOINT C AR, P609; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; YACHIDA M, 1978, 4TH P INT JOINT C PA, P726; [No title captured]	10	22	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					516	522		10.1109/TPAMI.1980.6447698	http://dx.doi.org/10.1109/TPAMI.1980.6447698			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200004
J	CHANG, SK; KE, JS				CHANG, SK; KE, JS			TRANSLATION OF FUZZY QUERIES FOR RELATIONAL DATABASE SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CHANG, SK (corresponding author), UNIV ILLINOIS,DEPT INFORMAT SCI,KNOWLEDGE SYST LAB,CHICAGO,IL 60680, USA.							ANTONACCI F, 1977, 3RD P INT C VER LARG; BITZER DL, 1965, COMPUTER AUGMENTATIO, P90; BOYCE RF, 1975, COMMUN ASS COMPUT MA, V18; BRUCE B, 1975, ARTIFICIAL INTELLIGE, V6; Chamberlin D. D., 1976, Computing Surveys, V8, P43, DOI 10.1145/356662.356665; CHAMBERLIN DD, 1974, MAY P ACMSIGMOD WORK; Chang C C. L., 1976, PATTERN RECOGNITION; CHANG CL, 1978, RJ2147 IBM REP; CHANG CL, 1978, RJ2145 IBM RES REP; CHANG SK, 1978, IEEE T SOFTWARE ENG, V4, P31, DOI 10.1109/TSE.1978.231464; CHANG SK, 1978, IEEE T SOFTWARE ENG, V4, P18, DOI 10.1109/TSE.1978.231463; CHANG SK, 1976, JUN P NAT COMP C NEW, P277; CHANG SK, 1976, INTELLIGENT COUPLER; CHANG SK, 1977, NOV P COMPSAC; CHEN PPS, 1977, 1977 P NAT COMP C DA, V46, P77; CODD EF, 1971, COURANT S DATA BASE, V6; CODD EF, 1974, DATA BASE MANAGEMENT, P179; CODD EF, 1970, COMMUN ASS COMPUT MA, V13; CODD EF, 1971, COURNAT S DATA BASE, V6; CODD EF, 1971, NOV P ACM SIGFIDET W; CODD EF, 1978, RJ2144 IBM RES REP; DENNY GH, 1977, RA9328099 IBM TECH R; GOLDSTEIN RC, 1970, 1970 P ACMSIGFIDET W; HARRIS LR, 1977, 3RD P INT C VER LARG; HENDRIX GG, 1977, 3RD P INT C VER LARG; KAMBAYASHI Y, 1977, 3RD P INT C VER LARG; KE JS, 1978, KSL18 U ILL KNOWL SY; KE JS, 1978, THESIS U ILLINOIS; KENT W, 1976, 2ND P INT C VER LARG; KOGON R, 1976, USER SPECIALITY LANG; LACROIX M, 1977, 3RD P INT C VER LARG; LEHMANN H, 1976, USL SYSTEM DATA ANAL; MCDONALD N, 1975, 75 P ACM PAC REG C N, P127; MINSKY M, 1975, JUN P THEOR ISS NAT; MYLOPOULOS J, 1975, 4TH P INT C ART INT; NOTLEY MG, 1972, UKSC0018 IBM UK SCI; PALERMO FP, 1976, RJ1805 IBM TECH REP; PECHERER RM, 1975, THESIS UCB; PETRICK SR, 1976, IBM J RES DEV    JUL; Pin-Shan Chen P., 1976, ACM Transactions on Database Systems, V1, P9, DOI 10.1145/320434.320440; PRENNER CJ, 1977, UCBERLM7760 TECH REP; QUILLIAN MR, 1968, SEMANTIC INFORMATION; QUILLIAN MR, 1969, COMMUN ASS COMPUT MA, V12; REISNER P, 1975, AFIPS C P, V44; ROUSSOPOULOS N, 1977, 104 U TOR DEP CONP S; ROUSSOPOULOS N, 1975, 1ST P INT C VER LARG; SAGALOWICZ D, 1977, 3RD P INT C VER LARG; SCHANK R, 1972, COGNITIVE PSYCH, V3; SCHMID HA, 1975, MAY P ACM SIGMOD, P211; SENKO ME, 1976, RC6034 IBM TECH REP; SHNEIDERMAN B, 1978, 20 U MAR DEP INF SYS; SIMMONS RF, 1973, COMPUTER MODEL THOUG; SIMMONS RF, 1970, COMMUN ASS COMPUT MA, V13; Smith J. M., 1977, ACM Transactions on Database Systems, V2, P105, DOI 10.1145/320544.320546; SMITH JM, 1977, UUCS77112 U UT TECH; SOWA J, 1976, IBM J RES DEV    JUL; SZOLORITS P, 1977, OVERVIEW OWL LANGUAG; THOMAS JC, 1976, RC5866 IBM TECH REP; THOMAS JC, 1975, AFIPS C P, V44; THOMAS JC, 1977, 3RD P INT C VER LARG; THOMAS JC, 1977, RC6581 IBM TECH REP; THOMAS JC, 1976, RC5882 IBM TECH REP; WHITNEY VKM, 1972, DEC P COINS IV; Winograd Terry, 1971, PROCEDURES REPRESENT; WONG HKT, 1977, ACTA INFORMATICA, V15, P344; WOODS WA, 1968, AFIPS C P, V33; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZLOOF MM, 1975, MAY P AFIPS NAT COMP; [No title captured]	69	22	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					281	294		10.1109/TPAMI.1979.4766924	http://dx.doi.org/10.1109/TPAMI.1979.4766924			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868859				2022-12-18	WOS:A1979HC30100006
J	WONG, AKC; WANG, DCC				WONG, AKC; WANG, DCC			DECA - DISCRETE-VALUED DATA CLUSTERING ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV PITTSBURGH,SCH MED,PITTSBURGH,PA 15213	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	WONG, AKC (corresponding author), UNIV WATERLOO,DEPT SYST DESIGN,WATERLOO N2L 3G1,ONTARIO,CANADA.							BALL GH, 1965, AFIPS P, V27, P533; BOYCE AJ, 1969, NUMERICAL TAXONOMY; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHRISTENSEN R, 1973 P IEEE INT C CY, P321; DIDAY E, 1976, DIGITAL PATTERN RECO; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; Duda R.O., 1973, J ROYAL STAT SOC SER; GITMAN I, 1970, IEEE T COMPUT, VC 19, P583, DOI 10.1109/T-C.1970.222992; GOWER JC, 1969, APPL STATIST, V18, P54, DOI DOI 10.2307/2346439; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; HENRICHON EG, 1968, 7TH P S AD PROC; JARDINE N, 1971, NUMERICAL TAXONOMY; KITTLER J, 1976, PATTERN RECOGN, V8, P23, DOI 10.1016/0031-3203(76)90026-1; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171, DOI 10.1109/TC.1972.5008922; Lewis PM., 1959, INF CONTROL, V2, P214, DOI 10.1016/S0019-9958(59)90207-4; Sneath PHA, 1973, NUMERICAL TAXONOMY P; STOFFEL JC, 1974, IEEE T COMPUT, VC 23, P428, DOI 10.1109/T-C.1974.223958; WANG CC, 1977, THESIS CARNEGIE MELL; WONG AKC, 1977, IEEE T COMPUT, V26, P75, DOI 10.1109/TC.1977.5009277; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	20	22	22	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					342	349		10.1109/TPAMI.1979.4766942	http://dx.doi.org/10.1109/TPAMI.1979.4766942			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868868				2022-12-18	WOS:A1979HV22700002
J	Liu, J; Yan, M; Zeng, TY				Liu, Jun; Yan, Ming; Zeng, Tieyong			Surface-Aware Blind Image Deblurring	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Image edge detection; Estimation; Image restoration; Surface cleaning; Blind deblurring; image gradient; surface area; non-uniform blur; saturated images	MOTION; DECONVOLUTION; RECOVERY; SPARSE	Blind image deblurring is a conundrum because there are infinitely many pairs of latent image and blur kernel. To get a stable and reasonable deblurred image, proper prior knowledge of the latent image and the blur kernel is urgently required. Different from the recent works on the statistical observations of the difference between the blurred image and the clean one, our method is built on the surface-aware strategy arising from the intrinsic geometrical consideration. This approach facilitates the blur kernel estimation due to the preserved sharp edges in the intermediate latent image. Extensive experiments demonstrate that our method outperforms the state-of-the-art methods on deblurring the text and natural images. Moreover, our method can achieve attractive results in some challenging cases, such as low-illumination images with large saturated regions and impulse noise. A direct extension of our method to the non-uniform deblurring problem also validates the effectiveness of the surface-aware prior.	[Liu, Jun] Northeast Normal Univ, Sch Math & Stat, Key Lab Appl Stat MOE, Changchun 130024, Jilin, Peoples R China; [Yan, Ming] Michigan State Univ, Dept Math, Dept Computat Math Sci & Engn, E Lansing, MI 48824 USA; [Zeng, Tieyong] Chinese Univ Hong Kong, Dept Math, Shatin, Hong Kong, Peoples R China	Northeast Normal University - China; Michigan State University; Chinese University of Hong Kong	Zeng, TY (corresponding author), Chinese Univ Hong Kong, Dept Math, Shatin, Hong Kong, Peoples R China.	liuj292@nenu.edu.cn; myan@msu.edu; zeng@math.cuhk.edu.hk		ZENG, Tieyong/0000-0002-0688-202X	NSFC [11701079, 11631003, 1690012, 11671002]; Jilin Provincial Science and Technology Development Plan funded project [20180520026JH]; Jilin Provincial Department of Education [JJKH20190293KJ]; NSF [DMS-1621798, RGC 14300219]; CUHK start-up; CUHK [DAG 4053296, 4053342]	NSFC(National Natural Science Foundation of China (NSFC)); Jilin Provincial Science and Technology Development Plan funded project; Jilin Provincial Department of Education; NSF(National Science Foundation (NSF)); CUHK start-up; CUHK(Chinese University of Hong Kong)	This work was sponsored in part by NSFC (11701079, 11631003, 1690012), Jilin Provincial Science and Technology Development Plan funded project (20180520026JH), Jilin Provincial Department of Education (JJKH20190293KJ), the NSF grant DMS-1621798, RGC 14300219, NSFC 11671002, CUHK start-up and CUHK DAG 4053296, 4053342. The authors would like to thank the associate editor and the three anonymous reviewers for their professional comments and constructive suggestions. We deeply thank Prof. Faming Fang in the East China Normal University for a constructive discussion on the modeling analysis. The authors are grateful for Dr. Ning Du in Northeast Normal University who kindly performs most of the experiments in this paper. We thank Dr. Hongfei Yang in The Chinese University of Hong Kong for his helpful discussion on preparing this manuscript. We appreciate that Prof. Jinshan Pan and Prof. Whyte make their codes available.	Arrow K. J., STUDIES LINEAR NONLI; Aubert G., 2006, MATH PROBLEMS IMAGE; Blumensath T, 2008, J FOURIER ANAL APPL, V14, P629, DOI 10.1007/s00041-008-9035-z; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Courant R., 1943, B AM MATH SOC, V49, P1, DOI 10.1090/S0002-9904-1943-07818-4; Dai SY, 2008, IEEE IMAGE PROC, P661, DOI 10.1109/ICIP.2008.4711841; Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; El-Fallah AI, 1998, PATTERN RECOGN LETT, V19, P433, DOI 10.1016/S0167-8655(98)00030-0; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Graber G, 2015, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2015.7298649; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276; Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432; Huang J., 2018, UNIFIED PRIMAL DUAL; Huang YM, 2008, MULTISCALE MODEL SIM, V7, P774, DOI 10.1137/070703533; Ito K, 2014, INVERSE PROBL, V30, DOI 10.1088/0266-5611/30/1/015001; Joshi N, 2008, PROC CVPR IEEE, P3823; Kimmel R, 1997, LECT NOTES COMPUT SC, V1252, P236; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li LRH, 2019, INT J COMPUT VISION, V127, P1025, DOI 10.1007/s11263-018-01146-0; LICHNEWSKY A, 1978, J DIFFER EQUATIONS, V30, P340, DOI 10.1016/0022-0396(78)90005-0; Ma LY, 2017, J SCI COMPUT, V70, P1336, DOI 10.1007/s10915-016-0282-x; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P3005, DOI 10.1109/TIP.2007.910179; Molina R, 2001, IEEE SIGNAL PROC MAG, V18, P11, DOI 10.1109/79.916318; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pan JS, 2016, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2016.306; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Pankajakshan P, 2007, P ANN INT IEEE EMBS, P6532; Perrone D, 2016, IEEE T PATTERN ANAL, V38, P1041, DOI 10.1109/TPAMI.2015.2477819; Perrone D, 2016, INT J COMPUT VISION, V117, P159, DOI 10.1007/s11263-015-0857-2; Rameshan R.M., 2012, P 8 IND C COMP VIS G, P1; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Storath M, 2014, IEEE T SIGNAL PROCES, V62, P3654, DOI 10.1109/TSP.2014.2329263; Strekalovskiy E, 2014, LECT NOTES COMPUT SC, V8690, P127, DOI 10.1007/978-3-319-10605-2_9; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun LB, 2013, IEEE INT CONF COMPUT; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Tikhonov A.N., 1977, SOLUTION ILL POSED P; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016; Wang C., 2009, INVERSE PROB, V26; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Whyte Oliver, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P745; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738; Yezzi A, 1998, IEEE T IMAGE PROCESS, V7, P345, DOI 10.1109/83.661184; Yuan GZ, 2015, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2015.7299175; Zosso D., 2014, 1452 UCLA	68	21	22	9	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1041	1055		10.1109/TPAMI.2019.2941472	http://dx.doi.org/10.1109/TPAMI.2019.2941472			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31535982				2022-12-18	WOS:000616309900020
J	Bhattacharjee, D; Roy, H				Bhattacharjee, Debotosh; Roy, Hiranmoy			Pattern of Local Gravitational Force (PLGF): A Novel Local Image Descriptor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gravity; Face recognition; Histograms; Feature extraction; Image edge detection; Lighting; Image retrieval; Gravitational force; local gravitational force magnitude; local gravitational force angle; pattern of local gravitational force; illumination invariant face recognition; image descriptor	FACE RECOGNITION; ILLUMINATION-INVARIANT; REPRESENTATION; ROTATION; SCALE; HISTOGRAMS; DETECTORS; FEATURES; MODEL	This paper presents a novel local image descriptor called Pattern of Local Gravitational Force (PLGF). It is inspired by Law of Universal Gravitation. PLGF is a hybrid descriptor, which is a combination of two feature components: one is the Pattern of Local Gravitational Force Magnitude (PLGFM), and another is Pattern of Local Gravitational Force Angle (PLGFA). PLGFM encodes the local gravitational force magnitude, and PLGFA encodes the local gravitational force angle that the center pixel exerts on all other pixels within a local neighborhood. We propose a novel noise resistance and the edge-preserving binary pattern called neighbors to center difference binary pattern (NCDBP) for gravitational force magnitude encoding. Finally, the histograms of the two components are concatenated to construct the PLGF descriptor. Experimental results on the existing face recognition databases, texture database, and biomedical image database show that PLGF is an effective image descriptor, and it outperforms other widely used existing descriptors. Even if in complicated variations like noise, and illumination with smaller databases, a combination of PLGF and convolutional neural network (CNN) performs consistently better than other state-of-the-art techniques.	[Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India; [Roy, Hiranmoy] RCC Inst Informat Technol, Dept Informat Technol, Canal South Rd, Kolkata 700015, India	Jadavpur University; RCC Institute of Information Technology (RCCIIT)	Roy, H (corresponding author), RCC Inst Informat Technol, Dept Informat Technol, Canal South Rd, Kolkata 700015, India.	debotosh@ieee.org; hiranmoy.roy@rcciit.org	Bhattacharjee, Debotosh/Q-4065-2019	Bhattacharjee, Debotosh/0000-0002-1163-6413				Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176; Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535; Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396; Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FERRARI V, 2004, P EUR C COMP VIS, P40; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791; Heikkila M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68; Horn BKP, 2011, ROBOT VISION; Huang D, 2014, IEEE T IMAGE PROCESS, V23, P4680, DOI 10.1109/TIP.2014.2353814; Iscen A, 2015, IEEE T IMAGE PROCESS, V24, P2369, DOI 10.1109/TIP.2015.2423557; Kang WX, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2423617; Ke Y, 2004, PROC CVPR IEEE, P506; Kellman P, 2005, MAGNET RESON MED, V54, P1439, DOI 10.1002/mrm.20713; Kim S, 2017, IEEE T PATTERN ANAL, V39, P1712, DOI 10.1109/TPAMI.2016.2615619; Kim W, 2014, IEEE IMAGE PROC, P5671, DOI 10.1109/ICIP.2014.7026147; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S, 2003, PROC CVPR IEEE, P319; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mellor M, 2008, IEEE T PATTERN ANAL, V30, P52, DOI 10.1109/TPAMI.2007.1161; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Olenick R. P., 1985, MECH UNIVERSE INTRO; Roy H, 2016, IEEE T INF FOREN SEC, V11, P1412, DOI 10.1109/TIFS.2016.2530043; Schonberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Song TC, 2018, IEEE SIGNAL PROC LET, V25, P625, DOI 10.1109/LSP.2018.2809607; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961; Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294; Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397; Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255; Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324; Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749	58	21	21	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					595	607		10.1109/TPAMI.2019.2930192	http://dx.doi.org/10.1109/TPAMI.2019.2930192			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31380743				2022-12-18	WOS:000607383300014
J	Zhang, W; Wang, BR; Ma, L; Liu, W				Zhang, Wei; Wang, Bairui; Ma, Lin; Liu, Wei			Reconstruct and Represent Video Contents for Captioning via Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Decoding; Image reconstruction; Semantics; Training data; Visualization; Video sequences; Video captioning; reconstruction network (RecNet); backward information		In this paper, the problem of describing visual contents of a video sequence with natural language is addressed. Unlike previous video captioning work mainly exploiting the cues of video contents to make a language description, we propose a reconstruction network (RecNet) in a novel encoder-decoder-reconstructor architecture, which leverages both forward (video to sentence) and backward (sentence to video) flows for video captioning. Specifically, the encoder-decoder component makes use of the forward flow to produce a sentence based on the encoded video semantic features. Two types of reconstructors are subsequently proposed to employ the backward flow and reproduce the video features from local and global perspectives, respectively, capitalizing on the hidden state sequence generated by the decoder. Moreover, in order to make a comprehensive reconstruction of the video features, we propose to fuse the two types of reconstructors together. The generation loss yielded by the encoder-decoder component and the reconstruction loss introduced by the reconstructor are jointly cast into training the proposed RecNet in an end-to-end fashion. Furthermore, the RecNet is fine-tuned by CIDEr optimization via reinforcement learning, which significantly boosts the captioning performance. Experimental results on benchmark datasets demonstrate that the proposed reconstructor can boost the performance of video captioning consistently.	[Zhang, Wei; Wang, Bairui] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China; [Ma, Lin; Liu, Wei] Tencent AI Lab, Shenzhen 518052, Peoples R China	Shandong University; Tencent	Ma, L (corresponding author), Tencent AI Lab, Shenzhen 518052, Peoples R China.	davidzhang@sdu.edu.cn; bairuiwong@gmail.com; forest.linma@gmail.com; wl2223@columbia.edu		Liu, Wei/0000-0002-3865-8145	National Key Research and Development Plan of China [2017YFB1300205]; NSFC [61573222]; Major Research Program of Shandong Province [2018CXGC1503]	National Key Research and Development Plan of China; NSFC(National Natural Science Foundation of China (NSFC)); Major Research Program of Shandong Province	This work was supported by the National Key Research and Development Plan of China under Grant 2017YFB1300205, NSFC Grant no. 61573222, and Major Research Program of Shandong Province 2018CXGC1503.	[Anonymous], 2012, ARXIV PREPRINT ARXIV; Bahdanau D., 2015, P 3 INT C LEARNING R; Ballas N., 2016, P INT C LEARN REPR I, P1; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Chen David, 2011, P 49 ANN M ASS COMP, P190; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Chen X, 2015, CORR, V1504, P325; Chen XP, 2018, PROC CVPR IEEE, P7995, DOI 10.1109/CVPR.2018.00834; Cho K., 2014, P SSST 8 8 WORKSH SY, P103; Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019; Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337; He Di, 2016, NEURAL INFORM PROCES, P2; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31; Jiang WH, 2018, AAAI CONF ARTIF INTE, P6959; Jin Q., 2016, P 24 ACM INT C MULTI, P1087, DOI 10.1145/2964284.2984065; Karpathy A, 2014, ADV NEUR IN, V27; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kingma Diederik P., 2015, 3 INT C LEARN REPRES, V3; Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608; Li Y, 2018, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2018.00782; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Liu W, 2016, IEEE MULTIMEDIA, V23, P75, DOI 10.1109/MMUL.2016.39; Liu Y, 2017, AAAI CONF ARTIF INTE, P4197; Luo P, 2017, IEEE I CONF COMP VIS, P2737, DOI 10.1109/ICCV.2017.296; Ma L, 2016, AAAI CONF ARTIF INTE, P3567; Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301; Nishi H, 2016, PROC IEEE COOL CHIPS; Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117; Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111; Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pasunuru R., 2017, EMNLP; Ramanishka V., 2016, P 24 ACM INT C MULT, P1092, DOI DOI 10.1145/2964284.2984066; Ranzato M., 2016, SEQUENCE LEVEL TRAIN; Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Rohrbach A, 2014, LECT NOTES COMPUT SC, V8753, P184, DOI 10.1007/978-3-319-11752-2_15; Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6; Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548; Shetty R., 2016, P 2016 ACM MULT C, P1073, DOI DOI 10.1145/2964284.2984062; Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2737; Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tu ZP, 2017, AAAI CONF ARTIF INTE, P3097; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Voykinska V, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1584, DOI 10.1145/2818048.2820013; Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795; Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960; Wang JW, 2018, PROC CVPR IEEE, P7190, DOI 10.1109/CVPR.2018.00751; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Xia YC, 2017, PR MACH LEARN RES, V70; Xu J., 2016, P IEEE C COMP VIS PA; Xu R, 2015, AAAI CONF ARTIF INTE, P2346; Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512; Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496; Zaremba W., 2015, ARXIV150500521; Zhang CY, 2016, INT C PATT RECOG, P2924, DOI 10.1109/ICPR.2016.7900081; Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188; Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911	70	21	22	2	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					3088	3101		10.1109/TPAMI.2019.2920899	http://dx.doi.org/10.1109/TPAMI.2019.2920899			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31180887	Green Submitted			2022-12-18	WOS:000587912800009
J	Tonioni, A; Poggi, M; Mattoccia, S; Di Stefano, L				Tonioni, Alessio; Poggi, Matteo; Mattoccia, Stefano; Di Stefano, Luigi			Unsupervised Domain Adaptation for Depth Prediction from Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Reliability; Estimation; Loss measurement; Computer architecture; Prediction algorithms; Deep learning; Deep learning; depth estimation; unsupervised learning; self-supervised learning; domain adaptation	STEREO; ACCURATE	State-of-the-art approaches to infer dense depth measurements from images rely on CNNs trained end-to-end on a vast amount of data. However, these approaches suffer a drastic drop in accuracy when dealing with environments much different in appearance and/or context from those observed at training time. This domain shift issue is usually addressed by fine-tuning on smaller sets of images from the target domain annotated with depth labels. Unfortunately, relying on such supervised labeling is seldom feasible in most practical settings. Therefore, we propose an unsupervised domain adaptation technique which does not require groundtruth labels. Our method relies only on image pairs and leverages on classical stereo algorithms to produce disparity measurements alongside with confidence estimators to assess upon their reliability. We propose to fine-tune both depth-from-stereo as well as depth-from-mono architectures by a novel confidence-guided loss function that handles the measured disparities as noisy labels weighted according to the estimated confidence. Extensive experimental results based on standard datasets and evaluation protocols prove that our technique can address effectively the domain shift issue with both stereo and monocular depth prediction architectures and outperforms other state-of-the-art unsupervised loss functions that may be alternatively deployed to pursue domain adaptation.	[Tonioni, Alessio; Poggi, Matteo; Mattoccia, Stefano; Di Stefano, Luigi] Univ Bologna, Dept Comp Sci & Engn, BO-40126 Bologna, Italy	University of Bologna	Poggi, M (corresponding author), Univ Bologna, Dept Comp Sci & Engn, BO-40126 Bologna, Italy.	alessio.tonioni@unibo.it; m.poggi@unibo.it; stefano.mattoccia@unibo.it; luigi.distefano@unibo.it	Mattoccia, Stefano/C-5410-2018; Mattoccia, Stefano/AAV-6931-2021	Mattoccia, Stefano/0000-0002-3681-7704; Mattoccia, Stefano/0000-0002-3681-7704; Poggi, Matteo/0000-0002-3337-2236; Tonioni, Alessio/0000-0003-3358-9686; Di Stefano, Luigi/0000-0001-6014-6421	NVIDIA Corporation	NVIDIA Corporation	The authors gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. Thanks to Filippo Aleotti for its help with experiments on monocular depth estimation. Alessio Tonioni and Matteo Poggi are joint first authorship.	Aleotti F, 2019, LECT NOTES COMPUT SC, V11129, P337, DOI 10.1007/978-3-030-11009-3_20; [Anonymous], [No title captured]; Batsos K, 2018, PROC CVPR IEEE, P2060, DOI 10.1109/CVPR.2018.00220; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117; Cheng X., 2018, ARXIV181002695; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Eigen D, 2014, ADV NEUR IN, V27; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Fu ZH, 2018, IEEE WINT CONF APPL, P1321, DOI 10.1109/WACV.2018.00149; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gidaris S, 2017, PROC CVPR IEEE, P7187, DOI 10.1109/CVPR.2017.760; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Haeusler R, 2013, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2013.46; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293; Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56; Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46; Jiang L., 2018, ICML, P2304; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Kim S, 2017, IEEE T IMAGE PROCESS, V26, P6019, DOI 10.1109/TIP.2017.2750404; Klodt M, 2018, LECT NOTES COMPUT SC, V11214, P713, DOI 10.1007/978-3-030-01249-6_43; Kumar ACS, 2018, IEEE COMPUT SOC CONF, P413, DOI 10.1109/CVPRW.2018.00068; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Li LC, 2017, APPL OPTICS, V56, P3411, DOI 10.1364/AO.56.003411; Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614; Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Mostegel C, 2016, PROC CVPR IEEE, P4067, DOI 10.1109/CVPR.2016.441; Pang JH, 2018, PROC CVPR IEEE, P2070, DOI 10.1109/CVPR.2018.00221; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605; Poggi M., 2016, P BRIT MACH VIS C; Poggi M, 2018, IEEE INT C INT ROBOT, P5848, DOI 10.1109/IROS.2018.8593814; Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045; Poggi M, 2017, LECT NOTES COMPUT SC, V10484, P483, DOI 10.1007/978-3-319-68560-1_43; Poggi M, 2017, IEEE I CONF COMP VIS, P5238, DOI 10.1109/ICCV.2017.559; Poggi M, 2017, PROC CVPR IEEE, P4541, DOI 10.1109/CVPR.2017.483; Poggi M, 2017, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2017.54; Poggi M, 2016, INT CONF 3D VISION, P509, DOI 10.1109/3DV.2016.61; Ren MY, 2018, PR MACH LEARN RES, V80; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Seki A., 2016, P BRIT MACH VIS C; Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703; Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730; Simonyan K., 2015, INT C LEARN REPR ICL; Spangenberg R, 2014, IEEE INT VEH SYM, P190; Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210; Taniai T, 2018, IEEE T PATTERN ANAL, V40, P2725, DOI 10.1109/TPAMI.2017.2766072; Tonioni A, 2017, IEEE I CONF COMP VIS, P1614, DOI 10.1109/ICCV.2017.178; Tosi F., 2017, P 28 BRIT MACH VIS C; Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012; Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596; Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412; Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620; Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212; Yu LD, 2018, AAAI CONF ARTIF INTE, P7517; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Zbontar J, 2016, J MACH LEARN RES, V17; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhang YD, 2018, LECT NOTES COMPUT SC, V11212, P802, DOI 10.1007/978-3-030-01237-3_48; Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700	78	21	22	4	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2396	2409		10.1109/TPAMI.2019.2940948	http://dx.doi.org/10.1109/TPAMI.2019.2940948			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31514127	Green Submitted			2022-12-18	WOS:000567471300006
J	Tewari, A; Zollhofer, M; Bernard, F; Garrido, P; Kim, H; Perez, P; Theobalt, C				Tewari, Ayush; Zollhofer, Michael; Bernard, Florian; Garrido, Pablo; Kim, Hyeongwoo; Perez, Patrick; Theobalt, Christian			High-Fidelity Monocular Face Reconstruction Based on an Unsupervised Model-Based Face Autoencoder	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Image reconstruction; Three-dimensional displays; Training; Decoding; Shape; Lighting	SHAPE; RECOGNITION; REGRESSION	In this work, we propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image. To this end, we combine a convolutional encoder network with an expert-designed generative model that serves as decoder. The core innovation is the differentiable parametric decoder that encapsulates image formation analytically based on a generative model. Our decoder takes as input a code vector with exactly defined semantic meaning that encodes detailed face pose, shape, expression, skin reflectance, and scene illumination. Due to this new way of combining CNN-based with model-based face reconstruction, the CNN-based encoder learns to extract semantically meaningful parameters from a single monocular input image. For the first time, a CNN encoder and an expert-designed generative model can be trained end-to-end in an unsupervised manner, which renders training on very large (unlabeled) real world datasets feasible. The obtained reconstructions compare favorably to current state-of-the-art approaches in terms of quality and richness of representation. This work is an extended version of [1] , where we additionally present a stochastic vertex sampling technique for faster training of our networks, and moreover, we propose and evaluate analysis-by-synthesis and shape-from-shading refinement approaches to achieve a high-fidelity reconstruction.	[Tewari, Ayush; Bernard, Florian; Kim, Hyeongwoo; Theobalt, Christian] Max Planck Inst Informat, D-66123 Saarbrcken, Germany; [Zollhofer, Michael] Stanford Univ, Stanford, CA 94305 USA; [Garrido, Pablo; Perez, Patrick] Technicolor, F-92130 Issy Les Moulineaux, France	Max Planck Society; Stanford University; Technicolor SA	Tewari, A (corresponding author), Max Planck Inst Informat, D-66123 Saarbrcken, Germany.	atewari@mpi-inf.mpg.de; zollhoefer@cs.stanford.edu; f.bernardpi@gmail.com; pablo.garrido.adrian@gmail.com; hyeongwoo.kim@mpi-inf.mpg.de; Patrick.Perez@technicolor.com; theobalt@mpi-inf.mpg.de			ERC Starting Grant CapReal [335545]; Max Planck Center for Visual Computing and Communications (MPC-VCC); Technicolor	ERC Starting Grant CapReal; Max Planck Center for Visual Computing and Communications (MPC-VCC); Technicolor	The authors thank True-VisionSolutions Pty Ltd for kindly providing the 2D face tracker, Anh Tuan Tran and Aaron S. Jackson for publishing their source code, and Justus Thies, Elad Richardson, Matan Sela, and Stefanos Zafeiriou for the comparisons. This work was supported by the ERC Starting Grant CapReal (335545), the Max Planck Center for Visual Computing and Communications (MPC-VCC), and by Technicolor.	ALEXANDER O, 2009, ACM SIGGRAPH COURSES, V12; BAS A, 2017, CORR; Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777; Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970; Bhagavatula C, 2017, IEEE I CONF COMP VIS, P4000, DOI 10.1109/ICCV.2017.429; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712; Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580; Bradski G, 2000, DR DOBBS J, V25, P120; Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Delaunoy A, 2011, INT J COMPUT VISION, V95, P100, DOI 10.1007/s11263-010-0408-9; Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042; Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164; DUONG CN, 2016, CORR; Fried O, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925933; Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438; Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493; Garrido P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508380; Grant E, 2016, LECT NOTES COMPUT SC, V9915, P266, DOI 10.1007/978-3-319-49409-8_22; GULER RA, 2016, CORR; Handa A, 2016, LECT NOTES COMPUT SC, V9915, P67, DOI 10.1007/978-3-319-49409-8_9; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Vu HH, 2012, IEEE T PATTERN ANAL, V34, P889, DOI 10.1109/TPAMI.2011.172; Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129; HUBER P, 2016, CORR; Huynh L, 2018, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2018.00877; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; Jaderberg M, 2015, ADV NEUR IN, V28; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; JIN X, 2016, CORR; Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243; Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439; Kemelmacher-Shlizerman I, 2010, LECT NOTES COMPUT SC, V6311, P341, DOI 10.1007/978-3-642-15549-9_25; Kim H, 2018, PROC CVPR IEEE, P4625, DOI 10.1109/CVPR.2018.00486; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kulkarni TD, 2015, ADV NEUR IN, V28; Laine S, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099581; Li M., 2016, ARXIV161005586 CORR; Li SW, 2016, LECT NOTES COMPUT SC, V9905, P349, DOI 10.1007/978-3-319-46448-0_21; Liu F, 2017, FRONT INFORM TECH EL, V18, P1978, DOI 10.1631/FITEE.1700253; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7; Muller C., 1966, SPHERICAL HARMONICS; Nair V, 2008, LECT NOTES COMPUT SC, V5163, P971, DOI 10.1007/978-3-540-87536-9_99; *NVIDA, 2008, NVIDIA CUDA PROGR GU; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; QUACH KG, 2016, CORR; Ranjan R., 2016, ARXIV160301249; Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589; Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56; ROMDHANI S, 2005, PROC CVPR IEEE, P986, DOI DOI 10.1109/CVPR.2005.145; Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455; Saito S, 2017, PROC CVPR IEEE, P2326, DOI 10.1109/CVPR.2017.250; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Schonborn S, 2015, COMPUT VIS IMAGE UND, V136, P117, DOI 10.1016/j.cviu.2015.01.008; Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Suwajanakorn S, 2015, IEEE I CONF COMP VIS, P3952, DOI 10.1109/ICCV.2015.450; Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52; Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270; Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Trigeorgis G, 2017, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2017.44; TYLECEK R, 2010, INT J VIRTUAL REALIT, V9, P45, DOI DOI 10.20870/IJVR.2010.9.1.2761; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Wang N., 2014, CORR; Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388; Wu Y, 2015, INT J COMPUT VISION, V113, P37, DOI 10.1007/s11263-014-0775-8; Xia T, 2012, INT C PATT RECOG, P1419; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; ZHAO F, 2016, CORR; ZHMOGINOV A, 2016, CORR; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; ZHU S, 2016, CORR; Zhu Z., 2014, NIPS, P217; Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21; 2012, CUBLAS LIB USER GUID	87	21	21	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					357	370		10.1109/TPAMI.2018.2876842	http://dx.doi.org/10.1109/TPAMI.2018.2876842			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30334783	Green Submitted			2022-12-18	WOS:000508386100009
J	Sansone, E; De Natale, FGB; Zhou, ZH				Sansone, Emanuele; De Natale, Francesco G. B.; Zhou, Zhi-Hua			Efficient Training for Positive Unlabeled Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; one-class classification; positive unlabeled learning; open set recognition; kernel methods	ONE-CLASS CLASSIFICATION; SUPPORT VECTOR; NOVELTY DETECTION; ANOMALY DETECTION	Positive unlabeled (PU) learning is useful in various practical situations, where there is a need to learn a classifier for a class of interest from an unlabeled data set, which may contain anomalies as well as samples from unknown classes. The learning task can be formulated as an optimization problem under the framework of statistical learning theory. Recent studies have theoretically analyzed its properties and generalization performance, nevertheless, little effort has been made to consider the problem of scalability, especially when large sets of unlabeled data are available. In this work we propose a novel scalable PU learning algorithm that is theoretically proven to provide the optimal solution, while showing superior computational and memory performance. Experimental evaluation confirms the theoretical evidence and shows that the proposed method can be successfully applied to a large variety of real-world problems involving PU learning.	[Sansone, Emanuele; De Natale, Francesco G. B.] Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38123 Trento, Italy; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China	University of Trento; Nanjing University	Sansone, E (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38123 Trento, Italy.	e.sonsone@unitn.it; francesco.denatale@unitn.it; zhouzh@nju.edu.cn		De Natale, Francesco/0000-0003-2566-6995	National Key R&D Program of China [2018YFB1004300]; NSFC [61333014]; Collaborative Innovation Center of Novel Software Technology and Industrialization; NVIDIA Corporation	National Key R&D Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Collaborative Innovation Center of Novel Software Technology and Industrialization; NVIDIA Corporation	This research was partially supported by the National Key R&D Program of China (2018YFB1004300), NSFC (61333014) and the Collaborative Innovation Center of Novel Software Technology and Industrialization. Part of this research was conducted when E. Sansonewas visiting the LAMDA Group, Nanjing University. We gratefully acknowledge the support of NVIDIA Corporation with the donation of a Titan X Pascal machine to support this research.	Argyriou A, 2014, PR MACH LEARN RES, V32, P748; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918; Blanchard G, 2010, J MACH LEARN RES, V11, P2973; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Campbell C, 2001, ADV NEUR IN, V13, P395; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 2005, P 10 INT WORKSH ART, V2005, P57; Chapelle O., 2006, IEEE T NEURAL NETWOR, V20, P542; Chen PH, 2006, IEEE T NEURAL NETWOR, V17, P893, DOI 10.1109/TNN.2006.875973; Da Q, 2014, AAAI CONF ARTIF INTE, P1760; De Comite F, 1999, LECT NOTES ARTIF INT, V1720, P219; du Plessis MC, 2014, ADV NEUR IN, V27; du Plessis MC, 2015, PR MACH LEARN RES, V37, P1386; Elkan Charles, 2008, P 14 ACM SIGKDD INT, P213, DOI DOI 10.1145/1401890.1401920; Fergus R., 2009, ADV NEURAL INFORM PR, P522; Hanson MA, 1999, J MATH ANAL APPL, V236, P594, DOI 10.1006/jmaa.1999.6484; He J, 2010, DATA PROCESSING AND QUANTITATIVE ECONOMY MODELING, P368; Hido S, 2008, IEEE DATA MINING, P223, DOI 10.1109/ICDM.2008.49; Hsieh CJ, 2015, PR MACH LEARN RES, V37, P2445; Jumutc V, 2014, IEEE T PATTERN ANAL, V36, P2510, DOI 10.1109/TPAMI.2014.2327984; Kearns M, 1998, J ACM, V45, P983, DOI 10.1145/293347.293351; Khan SS, 2014, KNOWL ENG REV, V29, P345, DOI 10.1017/S026988891300043X; Kingma D. P, 2014, ARXIV13126114; Kittler J, 2014, IEEE T PATTERN ANAL, V36, P845, DOI 10.1109/TPAMI.2013.209; Koppel Moshe, 2004, P 21 INT C MACHINE L, DOI [DOI 10.1145/1015330.1015448, 10.1145/1015330.1015448]; Lee Wee Sun, 2003, ICML, P448, DOI DOI 10.1016/J.TCS.2005.09.007; Letouzey F, 2000, LECT NOTES ARTIF INT, V1968, P71; Li WK, 2011, IEEE T GEOSCI REMOTE, V49, P717, DOI 10.1109/TGRS.2010.2058578; Li X.-L., 2009, P 2009 SIAM INT C DA, P259, DOI DOI 10.1137/1.9781611972795.23; Li Xiaoli, 2003, IJCAI 03 P 18 INT JO, P587; Li YF, 2013, J MACH LEARN RES, V14, P2151; Liu Bing, 2002, ICML, P387; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; Mehrotra S, 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028; Miller DJ, 1997, ADV NEUR IN, V9, P571; Moya MM, 1996, NEURAL NETWORKS, V9, P463, DOI 10.1016/0893-6080(95)00120-4; Nguyen MN, 2011, P 22 INT JOINT C ART, V11, P1421; Niu G., 2016, ARXIV160303130; Onoda T, 2005, IEEE IJCNN, P552; Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16; Pekalska E., 2002, ADV NEURAL INFORM PR, V15, P761; Plessis du, 2015, P 7 AS C MACH LEARN, P221; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; Sakai T., 2016, ARXIV160506955; Sansone E, 2016, FRONT ARTIF INTEL AP, V285, P1089, DOI 10.3233/978-1-61499-672-9-1089; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 2000, MICROSOFT RES; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Shieh AD, 2009, LECT NOTES COMPUT SC, V5519, P181, DOI 10.1007/978-3-642-02326-2_19; Silva J, 2009, IEEE T PATTERN ANAL, V31, P563, DOI 10.1109/TPAMI.2008.232; Skabar A, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2127, DOI 10.1109/ICMLC.2003.1259857; Smola AJ, 1999, ADV NEUR IN, V11, P585; Tax, 2001, ONE CLASS CLASSIFICA; Tax D. M. J., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096), P299; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yu H., 2002, P 8 ACM SIGKDD INT C, P239, DOI DOI 10.1145/775047.775083; Yu HJ, 2005, MACH LEARN, V61, P49, DOI 10.1007/s10994-005-1122-7; Yuille AL, 2002, ADV NEUR IN, V14, P1033; Zhang Tong, 2000, P 17 INT C MACHINE L, P1191; Zhou Joey Tianyi, 2012, AS C MACH LEARN, V25, P555; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106; Zhou ZH, 2010, KNOWL INF SYST, V24, P415, DOI 10.1007/s10115-009-0209-z	72	21	21	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2584	2598		10.1109/TPAMI.2018.2860995	http://dx.doi.org/10.1109/TPAMI.2018.2860995			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30059293	Green Submitted			2022-12-18	WOS:000489838200004
J	Wang, HZ; Xiao, GB; Yan, Y; Suter, D				Wang, Hanzi; Xiao, Guobao; Yan, Yan; Suter, David			Searching for Representative Modes on Hypergraphs for Robust Geometric Model Fitting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geometric model fitting; hypergraph construction; mode-seeking; multi-structure data	MEAN SHIFT; CONSENSUS	In this paper, we propose a simple and effective geometric model fitting method to fit and segment multi-structure data even in the presence of severe outliers. We cast the task of geometric model fitting as a representative mode-seeking problem on hypergraphs. Specifically, a hypergraph is first constructed, where the vertices represent model hypotheses and the hyperedges denote data points. The hypergraph involves higher-order similarities (instead of pairwise similarities used on a simple graph), and it can characterize complex relationships between model hypotheses and data points. In addition, we develop a hypergraph reduction technique to remove "insignificant" vertices while retaining as many "significant" vertices as possible in the hypergraph. Based on the simplified hypergraph, we then propose a novel mode-seeking algorithm to search for representative modes within reasonable time. Finally, the proposed mode-seeking algorithm detects modes according to two key elements, i.e., the weighting scores of vertices and the similarity analysis between vertices. Overall, the proposed fitting method is able to efficiently and effectively estimate the number and the parameters of model instances in the data simultaneously. Experimental results demonstrate that the proposed method achieves significant superiority over several state-of-the-art model fitting methods on both synthetic data and real images.	[Wang, Hanzi; Yan, Yan] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Fujian, Peoples R China; [Xiao, Guobao] Xiamen Univ, Sch Aerosp Engn, Xiamen 361005, Fujian, Peoples R China; [Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Xiamen University; Xiamen University; University of Adelaide	Wang, HZ (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Fujian, Peoples R China.	hanzi.wang@ieee.org; guobaoxiao@xmu.edu.cn; yanyan@xmu.edu.cn; dsuter@cs.adelaide.edu.au	Wang, Han/GPW-9809-2022	Suter, David/0000-0001-6306-3023	National Natural Science Foundation of China [U1605252, 61472334, 61571379, 61702431]; Natural Science Foundation of Fujian Province of China [2017J01127]; China Postdoctoral Science Foundation [2017M620272, ARC DPDP130102524]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Fujian Province of China(Natural Science Foundation of Fujian Province); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	This work was supported by the National Natural Science Foundation of China under Grants U1605252, 61472334, 61571379 and 61702431, by the Natural Science Foundation of Fujian Province of China under Grant 2017J01127, and by the China Postdoctoral Science Foundation 2017M620272. David Suter acknowledged funding under ARC DPDP130102524. Hanzi Wang and Guobao Xiao contributed equally to this work.	Bul`o S. R., 2009, ADV NEURAL INFORM PR, P1571; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150; Cho MS, 2012, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2012.6247727; Cohen A, 2015, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2015.263; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Ferraz L, 2007, LECT NOTES COMPUT SC, V4478, P355; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fredriksson J, 2015, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2015.7298884; Ghoshdastidar D, 2017, ANN STAT, V45, P289, DOI 10.1214/16-AOS1453; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7; Jain S, 2013, IEEE I CONF COMP VIS, P3511, DOI 10.1109/ICCV.2013.436; Kanazawa Y., 2004, PROC BRIT MACH VIS C, P1; Li Pu, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P410, DOI 10.1007/978-3-642-33460-3_32; Li ZW, 2014, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2014.41; Litman R, 2015, PROC CVPR IEEE, P5243, DOI 10.1109/CVPR.2015.7299161; Liu HR, 2012, PROC CVPR IEEE, P574, DOI 10.1109/CVPR.2012.6247723; Magri L, 2014, PROC CVPR IEEE, P3954, DOI 10.1109/CVPR.2014.505; Mittal S, 2012, IEEE T PATTERN ANAL, V34, P2351, DOI 10.1109/TPAMI.2012.52; Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728; Purkait P, 2014, LECT NOTES COMPUT SC, V8692, P672, DOI 10.1007/978-3-319-10593-2_44; Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; TANIMOTO TT, 1958, IBM INTERNAL REPORT; Tennakoon RB, 2016, IEEE T PATTERN ANAL, V38, P350, DOI 10.1109/TPAMI.2015.2448103; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Wand MP, 1994, KERNEL SMOOTHING; Wang HZ, 2015, IEEE I CONF COMP VIS, P2902, DOI 10.1109/ICCV.2015.332; Wang HZ, 2012, IEEE T PATTERN ANAL, V34, P1177, DOI 10.1109/TPAMI.2011.216; Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; Yang Wang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P234, DOI 10.1007/978-3-319-06605-9_20; Zhou D, 2006, P 2006 C ADV NEURAL, V19, DOI 10.7551/mitpress/7503.003.0205	35	21	23	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					697	711		10.1109/TPAMI.2018.2803173	http://dx.doi.org/10.1109/TPAMI.2018.2803173			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994506	Green Submitted			2022-12-18	WOS:000458168800013
J	Soomro, K; Idrees, H; Shah, M				Soomro, Khurram; Idrees, Haroon; Shah, Mubarak			Online Localization and Prediction of Actions and Interactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action localization; action prediction; interactions; dynamic programming; structural SVM	ACTION RECOGNITION; POSE	This paper proposes a person-centric and online approach to the challenging problem of localization and prediction of actions and interactions in videos. Typically, localization or recognition is performed in an offline manner where all the frames in the video are processed together. This prevents timely localization and prediction of actions and interactions - an important consideration for many tasks including surveillance and human-machine interaction. In our approach, we estimate human poses at each frame and train discriminative appearance models using the superpixels inside the pose bounding boxes. Since the pose estimation per frame is inherently noisy, the conditional probability of pose hypotheses at current time-step (frame) is computed using pose estimations in the current frame and their consistency with poses in the previous frames. Next, both the superpixel and pose-based foreground likelihoods are used to infer the location of actors at each time through a Conditional Random Field enforcing spatio-temporal smoothness in color, optical flow, motion boundaries and edges among superpixels. The issue of visual drift is handled by updating the appearance models, and refining poses using motion smoothness on joint locations, in an online manner. For online prediction of action/interaction confidences, we propose an approach based on Structural SVM that operates on short video segments, and is trained with the objective that confidence of an action or interaction increases as time passes in a positive training clip. Lastly, we quantify the performance of both detection and prediction together, and analyze how the prediction accuracy varies as a time function of observed action/interaction at different levels of detection performance. Our experiments on several datasets suggest that despite using only a few frames to localize actions/interactions at each time instant, we are able to obtain competitive results to state-of-the-art offline methods.	[Soomro, Khurram; Shah, Mubarak] Univ Cent Florida, Ctr Res Comp Vis CRCV, Orlando, FL 32816 USA; [Idrees, Haroon] Carnegie Mellon Univ CMU, Inst Robot, Pittsburgh, PA 15213 USA	State University System of Florida; University of Central Florida	Soomro, K (corresponding author), Univ Cent Florida, Ctr Res Comp Vis CRCV, Orlando, FL 32816 USA.	ksoomro@eecs.ucf.edu; hidrees@andrew.cmu.edu; shah@eecs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572; Idrees, Haroon/0000-0002-9613-6580	National Institute of Justice, Office of Justice Programs, U.S. Department of Justice [2015-R2-CXK025]	National Institute of Justice, Office of Justice Programs, U.S. Department of Justice	K. Soomro and H. Idrees were supported in part by Award No. 2015-R2-CXK025, awarded by the National Institute of Justice, Office of Justice Programs, U.S. Department of Justice. The opinions, findings, and conclusions or recommendations expressed in this publication are those of the author(s) and do not necessarily reflect those of the Department of Justice. Most of this work was done when H. Idrees was at Center for Research in Computer Vision, UCF.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; [Anonymous], 2015, P BRIT MACH VIS C BM; [Anonymous], 2014, COMPUTER VISION SPOR, DOI DOI 10.1007/978-3-319-09396-3_9; Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Chen W, 2015, IEEE I CONF COMP VIS, P3298, DOI 10.1109/ICCV.2015.377; Chen W, 2014, PROC CVPR IEEE, P748, DOI 10.1109/CVPR.2014.101; Cheron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368; Cuzzolin F., 2016, P BRIT MACH VIS C; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; De Geest R, 2016, LECT NOTES COMPUT SC, V9909, P269, DOI 10.1007/978-3-319-46454-1_17; Dehghan A, 2014, PROC CVPR IEEE, P2585, DOI 10.1109/CVPR.2014.331; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676; Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211; Hoai M, 2014, PROC CVPR IEEE, P875, DOI 10.1109/CVPR.2014.117; Hu YX, 2009, IEEE I CONF COMP VIS, P128, DOI 10.1109/ICCV.2009.5459153; Huang DA, 2014, LECT NOTES COMPUT SC, V8695, P489, DOI 10.1007/978-3-319-10584-0_32; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; Jianzhai Wu, 2013, Intelligence Science and Big Data Engineering. 4th International Conference, IScIDE 2013. Revised Selected Papers: LNCS 8261, P216, DOI 10.1007/978-3-642-42057-3_28; Kong Y, 2014, 2014 EUR C COMP VIS, P29; Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39; Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22; Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45; Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472; Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321; Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13; Lovegrove S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.93; Ma SG, 2013, IEEE I CONF COMP VIS, P2744, DOI 10.1109/ICCV.2013.341; Maji S., 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995631; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734; Oneata D, 2014, PROC CVPR IEEE, P2545, DOI 10.1109/CVPR.2014.326; Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48; Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24; Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45; Pirsiavash H, 2014, LECT NOTES COMPUT SC, V8694, P556, DOI 10.1007/978-3-319-10599-4_36; Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342; Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Rota P, 2015, IEEE IMAGE PROC, P3456, DOI 10.1109/ICIP.2015.7351446; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Ryoo M.S., 2010, ICPR; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119; Soomro K, 2017, IEEE I CONF COMP VIS, P696, DOI 10.1109/ICCV.2017.82; Soomro K, 2016, PROC CVPR IEEE, P2648, DOI 10.1109/CVPR.2016.290; Soomro K, 2015, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2015.375; Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341; Tran D., 2012, P ADV NEUR INF PROC, P359; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vahdat A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1729, DOI 10.1109/ICCVW.2011.6130458; Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wang LM, 2014, LECT NOTES COMPUT SC, V8693, P565, DOI 10.1007/978-3-319-10602-1_37; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362; Xie YL, 2011, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2011.5995648; Xu R, 2012, LECT NOTES COMPUT SC, V7378, P114, DOI 10.1007/978-3-642-31567-1_11; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293; Yu G., 2012, P 20 ACM INT C MULT, P1049; Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735; Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; Zhao X., 2013, P 21 ACM INT C MULT, P23; Zhou Z, 2015, IEEE T MULTIMEDIA, V17, P512, DOI 10.1109/TMM.2015.2404779	73	21	22	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					459	472		10.1109/TPAMI.2018.2797266	http://dx.doi.org/10.1109/TPAMI.2018.2797266			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994600	Green Submitted			2022-12-18	WOS:000456150600014
J	Wang, L; Mao, Q				Wang, Li; Mao, Qi			Probabilistic Dimensionality Reduction via Structure Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonlinear dimensionality reduction; structure learning; probabilistic models; latent variable model	GEOMETRIC FRAMEWORK; REGULARIZATION; EIGENMAPS	We propose an alternative probabilistic dimensionality reduction framework that can naturally integrate the generative model and the locality information of data. Based on this framework, we present a new model, which is able to learn a set of embedding points in a low-dimensional space by retaining the inherent structure from high-dimensional data. The objective function of this new model can be equivalently interpreted as two coupled learning problems, i.e., structure learning and the learning of projection matrix. Inspired by this interesting interpretation, we propose another model, which finds a set of embedding points that can directly form an explicit graph structure. We proved that the model by learning explicit graphs generalizes the reversed graph embedding method, but leads to a natural interpretation from Bayesian perspective. This can greatly facilitate data visualization and scientific discovery in downstream analysis. Extensive experiments are performed that demonstrate that the proposed framework is able to retain the inherent structure of datasets and achieve competitive quantitative results in terms of various performance evaluation criteria.	[Wang, Li] Univ Texas Arlington, Dept Math, Arlington, TX 76019 USA; [Mao, Qi] HERE North Amer LLC, Chicago, IL 60606 USA	University of Texas System; University of Texas Arlington	Wang, L (corresponding author), Univ Texas Arlington, Dept Math, Arlington, TX 76019 USA.	li.wang@uta.edu; qimao.here@gmail.com		Mao, Qi/0000-0003-1822-4558				Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 1986, PRINCIPAL COMPONENT; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Boyd S., 2003, LECT NOTES EE392O; Burges CJC, 2010, FOUND TRENDS MACH LE, V2, P275, DOI 10.1561/2200000002; Cayton L., 2005, 12 U CAL, P1; Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Cheung M., 2008, MINIMUM COST SPANNIN; Curtis C, 2012, NATURE, V486, P346, DOI 10.1038/nature10983; Ding C., 2004, P 21 ST INT C MACHIN, P29, DOI DOI 10.1145/1015330.1015408; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Dudik M, 2007, J MACH LEARN RES, V8, P1217; Elhamifar Ehsan, 2011, ADV NEURAL INF PROCE, V24, P3; Filippone M, 2008, PATTERN RECOGN, V41, P176, DOI 10.1016/j.patcog.2007.05.018; Greaves M, 2012, NATURE, V481, P306, DOI 10.1038/nature10762; Gupta A. K., 1999, MATRIX VARIATE DISTR, V104; Hein, 2009, ADV NEURAL INFORM PR, P1025; Hinton GE., 2002, NIPS, V15, P833; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Lake B., 2010, P 33 ANN COGN SCI C; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lawrence ND, 2012, J MACH LEARN RES, V13, P1609; Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017; Mao Q., 2015, P 2015 SIAM INT C DA, P792, DOI [10.1137/1.9781611974010.89, DOI 10.1137/1.9781611974010.89]; Mao Q, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P765, DOI 10.1145/2783258.2783309; Mao Q, 2015, IEEE T NEUR NET LEAR, V26, P1134, DOI 10.1109/TNNLS.2014.2334137; Parker JS, 2009, J CLIN ONCOL, V27, P1160, DOI 10.1200/JCO.2008.18.1370; Qiu X, 2017, BIORXIV, DOI [10.1101/110668, DOI 10.1101/110668]; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Scholkopf B., 2001, LEARNING KERNELS SUP; Smola AJ, 2003, LECT NOTES ARTIF INT, V2777, P144, DOI 10.1007/978-3-540-45167-9_12; Song L., 2007, ICML, P815; Sun YJ, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0440-0; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Titsias MK, 2010, P 13 INT C ARTIFICIA, V9, P844; van der Maaten L., 2009, TECH REP; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang L, 2017, AAAI CONF ARTIF INTE, P2703; Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106, DOI 10.1145/1015330.1015345; Weinberger K. Q., 2006, AAAI, V6, P1683; Xiao L., 2006, P 23 INT C MACH LEAR, P1041; Yao J, 2015, PATTERN RECOGN LETT, V53, P100, DOI 10.1016/j.patrec.2014.11.006; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhu J, 2014, J MACH LEARN RES, V15, P1799	53	21	21	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					205	219		10.1109/TPAMI.2017.2785402	http://dx.doi.org/10.1109/TPAMI.2017.2785402			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990039	Green Submitted			2022-12-18	WOS:000452434800016
J	Parashar, S; Pizarro, D; Bartoli, A				Parashar, Shaifali; Pizarro, Daniel; Bartoli, Adrien			Isometric Non-Rigid Shape-from-Motion with Riemannian Geometry Solved in Linear Time	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; NRSfM; riemannian geometry; metric tensor; christoffel symbols; infinitesimal planarity		We study Isometric Non-Rigid Shape-from-Motion (Iso-NRSfM): given multiple intrinsically calibrated monocular images, we want to reconstruct the time-varying 3D shape of a thin-shell object undergoing isometric deformations. We show that Iso-NRSfM is solvable from local warps, the inter-image geometric transformations. We propose a new theoretical framework based on the Riemmanian manifold to represent the unknown 3D surfaces as embeddings of the camera's retinal plane. This allows us to use the manifold's metric tensor and Christoffel Symbol (CS) fields. These are expressed in terms of the first and second order derivatives of the inverse-depth of the 3D surfaces, which are the unknowns for Iso-NRSfM. We prove that the metric tensor and the CS are related across images by simple rules depending only on the warps. This forms a set of important theoretical results. We show that current solvers cannot solve for the first and second order derivatives of the inverse-depth simultaneously. We thus propose an iterative solution in two steps. 1) We solve for the first order derivatives assuming that the second order derivatives are known. We initialise the second order derivatives to zero, which is an infinitesimal planarity assumption. We derive a system of two cubics in two variables for each image pair. The sum-of-squares of these polynomials is independent of the number of images and can be solved globally, forming a well-posed problem for N >= 3 images. 2) We solve for the second order derivatives by initialising the first order derivatives from the previous step. We solve a linear system of 4N - 4 equations in three variables. We iterate until the first order derivatives converge. The solution for the first order derivatives gives the surfaces' normal fields which we integrate to recover the 3D surfaces. The proposed method outperforms existing work in terms of accuracy and computation cost on synthetic and real datasets.	[Parashar, Shaifali; Bartoli, Adrien] Univ dAuvergne, CNRS, ISIT, F-63000 Clermont Ferrand, France; [Pizarro, Daniel] Univ dAuvergne, CNRS, ISIT, GEINTRA, F-63000 Clermont Ferrand, France; [Pizarro, Daniel] Univ Alcala, Alcala De Henares 28801, Spain	Centre National de la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA); Centre National de la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA); Universidad de Alcala	Parashar, S (corresponding author), Univ dAuvergne, CNRS, ISIT, F-63000 Clermont Ferrand, France.	shaifali.parashar@gmail.com; Dani.Pizarro@gmail.com; adrien.bartoli@gmail.com		Pizarro, Daniel/0000-0003-0622-4884	EU's FP7 through the ERC research grant [307483 FLEXABLE]; Spanish Ministry of Economy, Industry and Competitiveness under project ARTEMISA [TIN2016-80939-R]	EU's FP7 through the ERC research grant; Spanish Ministry of Economy, Industry and Competitiveness under project ARTEMISA	This research has received funding from the EU's FP7 through the ERC research grant 307483 FLEXABLE, the Spanish Ministry of Economy, Industry and Competitiveness under project ARTEMISA (TIN2016-80939-R).	Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293; Agudo A, 2015, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2015.7298830; Akhter Ijaz, 2009, P NIPS; Bartoli A, 2015, IEEE T PATTERN ANAL, V37, P2099, DOI 10.1109/TPAMI.2015.2392759; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Chhatkuli A., 2014, P BRIT MACH VIS C; Chhatkuli A, 2016, PROC CVPR IEEE, P1719, DOI 10.1109/CVPR.2016.190; Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Hartley R, 2008, LECT NOTES COMPUT SC, V5302, P276, DOI 10.1007/978-3-540-88682-2_22; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Henrion D, 2003, ACM T MATH SOFTWARE, V29, P165, DOI 10.1145/779359.779363; Lee J.M, 2012, INTRO SMOOTH MANIFOL; Lee John M, 2018, INTRO RIEMANNIAN MAN; Ozgur E, 2017, INT J COMPUT VISION, V123, P184, DOI 10.1007/s11263-016-0968-4; Parashar S, 2016, PROC CVPR IEEE, P4679, DOI 10.1109/CVPR.2016.506; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Pizarro D, 2016, INT J COMPUT VISION, V119, P93, DOI 10.1007/s11263-016-0882-9; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; Russell C, 2014, LECT NOTES COMPUT SC, V8695, P583, DOI 10.1007/978-3-319-10584-0_38; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Sasaki T., 2002, CRM P LECT NOTES AMS, P271; TAYLOR J, 2010, PROC CVPR IEEE, P2761, DOI DOI 10.1109/CVPR.2010.5540002; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Varol A, 2009, IEEE I CONF COMP VIS, P1811, DOI 10.1109/ICCV.2009.5459403; Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31	27	21	21	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2442	2454		10.1109/TPAMI.2017.2760301	http://dx.doi.org/10.1109/TPAMI.2017.2760301			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28991733				2022-12-18	WOS:000443875500012
J	Sanchez-Lozano, E; Tzimiropoulos, G; Martinez, B; De la Torre, F; Valstar, M				Sanchez-Lozano, Enrique; Tzimiropoulos, Georgios; Martinez, Brais; De la Torre, Fernando; Valstar, Michel			A Functional Regression Approach to Facial Landmark Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Continuous regression; face tracking; functional regression; functional data analysis	ACTIVE APPEARANCE MODELS; FACE ALIGNMENT; LINEAR-REGRESSION	Linear regression is a fundamental building block in many face detection and tracking algorithms, typically used to predict shape displacements from image features through a linear mapping. This paper presents a Functional Regression solution to the least squares problem, which we coin Continuous Regression, resulting in the first real-time incremental face tracker. Contrary to prior work in Functional Regression, in which B-splines or Fourier series were used, we propose to approximate the input space by its first-order Taylor expansion, yielding a closed-form solution for the continuous domain of displacements. We then extend the continuous least squares problem to correlated variables, and demonstrate the generalisation of our approach. We incorporate Continuous Regression into the cascaded regression framework, and show its computational benefits for both training and testing. We then present a fast approach for incremental learning within Cascaded Continuous Regression, coined iCCR, and show that its complexity allows real-time face tracking, being 20 times faster than the state of the art. To the best of our knowledge, this is the first incremental face tracker that is shown to operate in real-time. We show that iCCR achieves state-of-the-art performance on the 300-VW dataset, the most recent, large-scale benchmark for face tracking.	[Sanchez-Lozano, Enrique; Tzimiropoulos, Georgios; Martinez, Brais; Valstar, Michel] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England; [De la Torre, Fernando] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA	University of Nottingham; Carnegie Mellon University	Sanchez-Lozano, E (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.	Enrique.SanchezLozano@nottingham.ac.uk; yorgos.tzimiropoulos@nottingham.ac.uk; brais.martinez@nottingham.ac.uk; ftorre@cs.cmu.edu; michel.valstar@nottingham.ac.uk		Sanchez-Lozano, Enrique/0000-0003-0196-922X; Valstar, Michel/0000-0003-2414-161X	European Union Horizon 2020 research and innovation programme [645378]; University of Nottingham; EPSRC project [EP/M02153X/1]; EPSRC [EP/M02153X/1] Funding Source: UKRI	European Union Horizon 2020 research and innovation programme; University of Nottingham; EPSRC project(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The work of Sanchez-Lozano, Martinez and Valstar was supported by the European Union Horizon 2020 research and innovation programme under grant agreement No 645378, ARIA-VALUSPA. The work of Sanchez-Lozano was also supported by the Vice-Chancellors Scholarship for Research Excellence of the University of Nottingham. The work of Tzimiropoulos was supported in part by the EPSRC project EP/M02153X/1 Facial Deformable Models of Animals. We are also grateful for access to the University of Nottingham High Performance Computing Facility. Georgios Tzimiropoulos and Brais Martinez contributed equally.	Amari S.-i., 1985, DIFFERENTIAL GEOMETR, V28; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Brookes M., 2011, MATRIX REFERENCE MAN; Bulat A., 2016, P BRIT MACH VIS C, V86, P1; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126; Cootes T. F., 2004, TECH REP; Cootes T. F., 2012, LECT NOTES COMPUT SC, P278, DOI DOI 10.1007/978-3-642-33786-4; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2006, P BRIT MACH VIS C, V3, P929; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dhall A., 2014, P 16 INT C MULTIMODA, P461, DOI [10.1145/2663204.2666275, DOI 10.1145/2663204.2666275]; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Levin A, 2002, LECT NOTES COMPUT SC, V2352, P635; Liu L., 2014, P AS C COMP VIS WORK, P71; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205; Martins P, 2016, IEEE T PATTERN ANAL, V38, P704, DOI 10.1109/TPAMI.2015.2462343; Marx BD, 1999, TECHNOMETRICS, V41, P1, DOI 10.2307/1270990; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Morris JS, 2015, ANNU REV STAT APPL, V2, P321, DOI 10.1146/annurev-statistics-010814-020413; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; QUAK E, 1993, SIAM J MATH ANAL, V24, P1043, DOI 10.1137/0524062; Ramsay J., 2005, FUNCTIONAL DATA ANAL, V2, DOI [10.1007/b98888, DOI 10.1007/B98888]; Ratliffe S. J., 2002, STAT MED, V21, P1115; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Sanchez-Lozano E, 2016, PATTERN RECOGN LETT, V73, P19, DOI 10.1016/j.patrec.2015.11.014; Sanchez-Lozano E, 2016, LECT NOTES COMPUT SC, V9912, P645, DOI 10.1007/978-3-319-46484-8_39; Sanchez-Lozano E, 2012, LECT NOTES COMPUT SC, V7578, P250, DOI 10.1007/978-3-642-33786-4_19; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Tresadern P., 2010, P BRIT MACH VIS C; Tresadern PA, 2012, INT J COMPUT VISION, V96, P280, DOI 10.1007/s11263-011-0464-9; Tzimiropoulos G, 2017, INT J COMPUT VISION, V122, P17, DOI 10.1007/s11263-016-0950-1; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; Wang JL, 2016, ANNU REV STAT APPL, V3, P257, DOI 10.1146/annurev-statistics-041715-033624; Wang XM, 2015, IEEE I CONF COMP VIS, P4337, DOI 10.1109/ICCV.2015.493; Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4; Xiao ST, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P986, DOI 10.1109/ICCVW.2015.130; Xiong X, 2014, CORR; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yan JJ, 2014, LECT NOTES COMPUT SC, V8690, P568, DOI 10.1007/978-3-319-10605-2_37; Yang J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P994, DOI 10.1109/ICCVW.2015.131; Yao F, 2005, ANN STAT, V33, P2873, DOI 10.1214/009053605000000660; Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	60	21	21	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2037	2050		10.1109/TPAMI.2017.2745568	http://dx.doi.org/10.1109/TPAMI.2017.2745568			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28858786	Green Accepted, Green Submitted			2022-12-18	WOS:000440868400001
J	Pieciak, T; Aja-Fernandez, S; Vegas-Sanchez-Ferrero, G				Pieciak, Tomasz; Aja-Fernandez, Santiago; Vegas-Sanchez-Ferrero, Gonzalo			Non-Stationary Rician Noise Estimation in Parallel MRI Using a Single Image: A Variance-Stabilizing Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MRI; parallel MRI; spatially variant noise; noise estimation; variance-stabilizing transformation; Rician distribution	CORRECTION SCHEME; PARAMETERS; ALGORITHM	Parallel magnetic resonance imaging (pMRI) techniques have gained a great importance both in research and clinical communities recently since they considerably accelerate the image acquisition process. However, the image reconstruction algorithms needed to correct the subsampling artifacts affect the nature of noise, i.e., it becomes non-stationary. Some methods have been proposed in the literature dealing with the non-stationary noise in pMRI. However, their performance depends on information not usually available such as multiple acquisitions, receiver noise matrices, sensitivity coil profiles, reconstruction coefficients, or even biophysical models of the data. Besides, some methods show an undesirable granular pattern on the estimates as a side effect of local estimation. Finally, some methods make strong assumptions that just hold in the case of high signal-to-noise ratio (SNR), which limits their usability in real scenarios. We propose a new automatic noise estimation technique for non-stationary Rician noise that overcomes the aforementioned drawbacks. Its effectiveness is due to the derivation of a variance-stabilizing transformation designed to deal with any SNR. The method was compared to the main state-of-the-art methods in synthetic and real scenarios. Numerical results confirm the robustness of the method and its better performance for the whole range of SNRs.	[Pieciak, Tomasz] AGH Univ Sci & Technol, PL-30059 Krakow, Poland; [Pieciak, Tomasz; Aja-Fernandez, Santiago] Univ Valladolid, LPI, E-47002 Valladolid, Spain; [Vegas-Sanchez-Ferrero, Gonzalo] Harvard Med Sch, Brigham & Womens Hosp, ACIL, 1249 Boylston St, Boston, MA 02115 USA; [Vegas-Sanchez-Ferrero, Gonzalo] Univ Politecn Madrid, ETSI Telecomunicac, Biomed Image Technol Lab, E-28040 Madrid, Spain; [Vegas-Sanchez-Ferrero, Gonzalo] CIBER BBN, Madrid 28040, Spain	AGH University of Science & Technology; Universidad de Valladolid; Harvard University; Brigham & Women's Hospital; Harvard Medical School; Universidad Politecnica de Madrid; CIBER - Centro de Investigacion Biomedica en Red; CIBERBBN	Pieciak, T (corresponding author), AGH Univ Sci & Technol, PL-30059 Krakow, Poland.; Pieciak, T (corresponding author), Univ Valladolid, LPI, E-47002 Valladolid, Spain.	pieciak@agh.edu.pl; sanaja@tel.uva.es; gvegas@bwh.harvard.edu	Aja-Fernández, Santiago/L-2490-2017; Sanchez-Ferrero, Gonzalo Vegas/K-7556-2017; Vegas-Sanchez-Ferrero, Gonzalo/AAD-6387-2019	Aja-Fernández, Santiago/0000-0002-5337-5071; Sanchez-Ferrero, Gonzalo Vegas/0000-0002-3803-4324; Vegas-Sanchez-Ferrero, Gonzalo/0000-0002-3803-4324; Pieciak, Tomasz/0000-0002-7543-3658	Ministerio de Ciencia e Innovacion [TEC2013-44194-P]; National Science Centre, Poland [2015/19/N/ST7/01204]; Consejeria de Educacion, Juventud y Deporte of Comunidad de Madrid; People Programme (Marie Curie Actions) of the European Unions Seventh Framework Programme [291820]	Ministerio de Ciencia e Innovacion(Ministry of Science and Innovation, Spain (MICINN)Instituto de Salud Carlos IIISpanish Government); National Science Centre, Poland(National Science Centre, Poland); Consejeria de Educacion, Juventud y Deporte of Comunidad de Madrid; People Programme (Marie Curie Actions) of the European Unions Seventh Framework Programme	The authors thank M. Maggioni and K. Tabelow for sharing the source codes of their methods and for their outstanding assistance. This work was supported by Ministerio de Ciencia e Innovacion with research grant TEC2013-44194-P. T. Pieciak acknowledges National Science Centre, Poland, for funding resource (2015/19/N/ST7/01204). Gonzalo Vegas-Sanchez-Ferrero acknowledges Consejeria de Educacion, Juventud y Deporte of Comunidad de Madrid and the People Programme (Marie Curie Actions) of the European Unions Seventh Framework Programme (FP7/2007-2013) for REA grant agreement n. 291820.	Aja-Fernandez S, 2015, I S BIOMED IMAGING, P1478, DOI 10.1109/ISBI.2015.7164156; Aja-Fernandez S, 2015, MED IMAGE ANAL, V20, P184, DOI 10.1016/j.media.2014.11.005; Aja-Fernandez S, 2014, MAGN RESON IMAGING, V32, P281, DOI 10.1016/j.mri.2013.12.001; Aja-Fernandez S, 2013, MAGN RESON IMAGING, V31, P272, DOI 10.1016/j.mri.2012.07.006; Aja-Fernandez S, 2012, MAGN RESON MED, V67, P580, DOI 10.1002/mrm.23020; Aja-Fernandez S, 2011, MAGN RESON MED, V65, P1195, DOI 10.1002/mrm.22701; Aja-Fernandez S, 2009, MAGN RESON IMAGING, V27, P1397, DOI 10.1016/j.mri.2009.05.025; BARTLETT MS, 1947, BIOMETRICS, V3, P39, DOI 10.2307/3001536; Billingsley P., 1995, WILEY SERIES PROBABI, V3rd; Borrelli Pasquale, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1230, DOI 10.1109/ICASSP.2014.6853793; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Constantinides CD, 1997, MAGNET RESON MED, V38, P852, DOI 10.1002/mrm.1910380524; Coupe P, 2010, MED IMAGE ANAL, V14, P483, DOI 10.1016/j.media.2010.03.001; Delakis I, 2007, PHYS MED BIOL, V52, P3741, DOI 10.1088/0031-9155/52/13/006; den Dekker AJ, 2014, PHYS MEDICA, V30, P725, DOI 10.1016/j.ejmp.2014.05.002; DeVore MD, 2000, P SOC PHOTO-OPT INS, V4050, P34, DOI 10.1117/12.395589; Dikaios N, 2014, MAGN RESON MED, V71, P2105, DOI 10.1002/mrm.24877; Ding Y, 2010, MAGN RESON MED, V63, P782, DOI 10.1002/mrm.22258; Foi A, 2011, I S BIOMED IMAGING, P1809, DOI 10.1109/ISBI.2011.5872758; Gahm JK, 2014, MED IMAGE ANAL, V18, P197, DOI 10.1016/j.media.2013.10.009; Glenn GR, 2015, MAGN RESON IMAGING, V33, P124, DOI 10.1016/j.mri.2014.08.028; Goossens B, 2006, IEEE IMAGE PROC, P1425, DOI 10.1109/ICIP.2006.312694; Griswold MA, 2002, MAGN RESON MED, V47, P1202, DOI 10.1002/mrm.10171; GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618; Guo WH, 2009, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2009.5192993; Hansen MS, 2015, MAGN RESON MED, V73, P1300, DOI 10.1002/mrm.25194; HENKELMAN RM, 1985, MED PHYS, V12, P232, DOI 10.1118/1.595711; Koay CG, 2006, J MAGN RESON, V179, P317, DOI 10.1016/j.jmr.2006.01.016; Koay CG, 2009, J MAGN RESON, V197, P108, DOI 10.1016/j.jmr.2008.11.015; Landman BA, 2009, MAGN RESON IMAGING, V27, P741, DOI 10.1016/j.mri.2009.01.001; Landman BA, 2009, MAGN RESON MED, V62, P500, DOI 10.1002/mrm.22013; Liu RW, 2014, MAGN RESON IMAGING, V32, P702, DOI 10.1016/j.mri.2014.03.004; Maggioni M., 2012, P IS T SPIE EL IM; Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725; Makitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693; Manjon JV, 2015, MED IMAGE ANAL, V22, P35, DOI 10.1016/j.media.2015.01.004; Manjon JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003; MARZETTA TL, 1995, INT CONF ACOUST SPEE, P3651, DOI 10.1109/ICASSP.1995.479778; Maximov II, 2012, MED IMAGE ANAL, V16, P536, DOI 10.1016/j.media.2011.12.002; Noh J, 2011, IEEE T SIGNAL PROCES, V59, P1322, DOI 10.1109/TSP.2010.2098400; Pan X., 2012, P SPIE MED IMAG; Poot DHJ, 2015, IEEE T MED IMAGING, V34, P1164, DOI 10.1109/TMI.2014.2380830; Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S; Rajan J, 2011, PHYS MED BIOL, V56, P5221, DOI 10.1088/0031-9155/56/16/009; Reichenbach A., 2014, CHOOSING TRACTOGRAPH, P115; Rohde GK, 2005, NEUROIMAGE, V26, P673, DOI 10.1016/j.neuroimage.2005.02.023; Samsonov AA, 2004, MAGN RESON MED, V52, P798, DOI 10.1002/mrm.20207; Sijbers J, 1998, MAGN RESON IMAGING, V16, P87, DOI 10.1016/S0730-725X(97)00199-9; Sijbers J, 2007, PHYS MED BIOL, V52, P1335, DOI 10.1088/0031-9155/52/5/009; Tabelow K, 2015, MED IMAGE ANAL, V20, P76, DOI 10.1016/j.media.2014.10.008; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Veraart J, 2016, MAGN RESON MED, V76, P1582, DOI 10.1002/mrm.26059; Veraart J, 2013, MAGN RESON MED, V70, P972, DOI 10.1002/mrm.24529; Walsh DO, 2000, MAGNET RESON MED, V43, P682, DOI 10.1002/(SICI)1522-2594(200005)43:5<682::AID-MRM10>3.0.CO;2-G	54	21	21	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					2015	2029		10.1109/TPAMI.2016.2625789	http://dx.doi.org/10.1109/TPAMI.2016.2625789			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27845653	Green Accepted			2022-12-18	WOS:000408807600009
J	Park, J; Sinha, SN; Matsushita, Y; Tai, YW; Kweon, IS				Park, Jaesik; Sinha, Sudipta N.; Matsushita, Yasuyuki; Tai, Yu-Wing; Kweon, In So			Robust Multiview Photometric Stereo Using Planar Mesh Parameterization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiview photometric stereo; planar mesh parametrization	HIGH-QUALITY SHAPE; RECONSTRUCTION; MINIMIZATION; ALGORITHMS; IMAGE	We propose a robust uncalibrated multiview photometric stereo method for high quality 3D shape reconstruction. In our method, a coarse initial 3D mesh obtained using a multiview stereo method is projected onto a 2D planar domain using a planar mesh parameterization technique. We describe methods for surface normal estimation that work in the parameterized 2D space that jointly incorporates all geometric and photometric cues from multiple viewpoints. Using an estimated surface normal map, a refined 3D mesh is then recovered by computing an optimal displacement map in the same 2D planar domain. Our method avoids the need of merging view-dependent surface normal maps that is often required in conventional methods. We conduct evaluation on various real-world objects containing surfaces with specular reflections, multiple albedos, and complex topologies in both controlled and uncontrolled settings and demonstrate that accurate 3D meshes with fine geometric details can be recovered by our method.	[Park, Jaesik] Intel Labs, Santa Clara, CA 95051 USA; [Sinha, Sudipta N.] Microsoft Res, Redmond, WA 98052 USA; [Matsushita, Yasuyuki] Osaka Univ, Suita, Osaka 5650871, Japan; [Tai, Yu-Wing] SenseTime Grp Ltd, Hong Kong, Hong Kong, Peoples R China; [Kweon, In So] Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea	Intel Corporation; Microsoft; Osaka University; Korea Advanced Institute of Science & Technology (KAIST)	Park, J (corresponding author), Intel Labs, Santa Clara, CA 95051 USA.	jaesik.park@intel.com; Sudipta.Sinha@microsoft.com; yasumat@ist.osaka-u.ac.jp; yuwing@gmail.com; iskweon77@kaist.ac.kr	Kweon, In So/C-2023-2011; Sinha, Sudipta/AAA-2447-2019	Matsushita, Yasuyui/0000-0002-1935-4752; PARK, JAESIK/0000-0001-5541-409X	National Research Foundation of Korea (NRF) grant - Korea government (MSIP) [2010-0028680]; JSPS KAKENHI [JP16H01732]; Grants-in-Aid for Scientific Research [16H01732] Funding Source: KAKEN	National Research Foundation of Korea (NRF) grant - Korea government (MSIP); JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); Grants-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work was partly supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680) and JSPS KAKENHI Grant Number JP16H01732. In So Kweon is the corresponding author.	Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Choe GM, 2014, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2014.501; Davis T. A., 2011, ACM T MATH SOFTWARE, V38, DOI DOI 10.1145/2049662.2049670; Fitzgibbon A. W., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P155; GUPTA UI, 1982, NETWORKS, V12, P459, DOI 10.1002/net.3230120410; Ha H, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P127, DOI 10.1109/3DV.2015.22; Han Y, 2013, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2013.204; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hernandez Carlos, 2007, ICCV, P1; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869; Horn B, 1970, THESIS; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237; Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891; Lin Z., 2010, MATH PROGRAMMING; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422; Lu Z, 2010, PROC CVPR IEEE, P1205, DOI 10.1109/CVPR.2010.5539829; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Mount D. M., 2010, ANN LIB APPROXIMATE; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Oh TH, 2013, IEEE I CONF COMP VIS, P145, DOI 10.1109/ICCV.2013.25; Okatani T, 2012, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2012.6247683; Park J, 2013, IEEE I CONF COMP VIS, P1161, DOI 10.1109/ICCV.2013.148; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011; Szirmay-Kalos L, 2008, COMPUT GRAPH FORUM, V27, P1567, DOI 10.1111/j.1467-8659.2007.01108.x; Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473; Ungar A. A., 2010, BARYCENTRIC CALCULUS; Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388; Wu CL, 2011, IEEE T VIS COMPUT GR, V17, P1082, DOI [10.1109/TVCG.2010.224, 10.1109/TPDS.2010.224]; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186; Zhang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P618, DOI 10.1109/ICCV.2003.1238405; Zhang Q, 2012, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2012.6247962; Zhou K., 2004, S GEOMETRY PROCESSIN, P45; Zhou ZL, 2013, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR.2013.195	43	21	23	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1591	1604		10.1109/TPAMI.2016.2608944	http://dx.doi.org/10.1109/TPAMI.2016.2608944			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	28113654				2022-12-18	WOS:000404606300008
J	Tang, DH; Chang, HJ; Tejani, A; Kim, TK				Tang, Danhang; Chang, Hyung Jin; Tejani, Alykhan; Kim, Tae-Kyun			Latent Regression Forest: Structured Estimation of 3D Hand Poses	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Random forest; regression forest; latent tree model; hand pose estimation; 3D; depth	TREE MODELS; TRACKING	In this paper we present the latent regression forest (LRF), a novel framework for real-time, 3D hand pose estimation from a single depth image. Prior discriminative methods often fall into two categories: holistic and patch-based. Holistic methods are efficient but less flexible due to their nearest neighbour nature. Patch-based methods can generalise to unseen samples by consider local appearance only. However, they are complex because each pixel need to be classified or regressed during testing. In contrast to these two baselines, our method can be considered as a structured coarse-to-fine search, starting from the centre of mass of a point cloud until locating all the skeletal joints. The searching process is guided by a learnt latent tree model which reflects the hierarchical topology of the hand. Our main contributions can be summarised as follows: (i) Learning the topology of the hand in an unsupervised, data-driven manner. (ii) A new forest-based, discriminative framework for structured search in images, as well as an error regression step to avoid error accumulation. (iii) A new multi-view hand pose dataset containing 180 K annotated images from 10 different subjects. Our experiments on two datasets show that the LRF outperforms baselines and prior arts in both accuracy and efficiency.	[Tang, Danhang] PerceptiveIO Inc, San Francisco, CA 94103 USA; [Chang, Hyung Jin; Kim, Tae-Kyun] Imperial Coll London, London SW7 2AZ, England; [Tejani, Alykhan] Blippar, London, England	Imperial College London	Tang, DH (corresponding author), PerceptiveIO Inc, San Francisco, CA 94103 USA.	d.tang11@imperial.ac.uk; hj.chang@imperial.ac.uk; tk.kim@imperial.ac.uk		Chang, Hyung Jin/0000-0001-7495-9677	Samsung Advanced Institute of Technology (SAIT); EPSRC [EP/J012106/1] Funding Source: UKRI	Samsung Advanced Institute of Technology (SAIT)(Samsung); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This project was in part supported by the Samsung Advanced Institute of Technology (SAIT). The authors would also like to thank Guillermo Garcia-Hernando for the help of data collection and Mang Shao for the demo. This research was done when all authors were with ICVL. Hyung Jin Chang is the corresponding author.	Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46; Boussemart Y., 2004, P ACM S VIRT REAL SO, P162; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chang HJ, 2016, COMPUT VIS IMAGE UND, V148, P87, DOI 10.1016/j.cviu.2016.01.010; Charles J., 2014, P BRIT MACH VIS C, P1; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Choi C, 2015, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2015.269; Choi MJ, 2011, J MACH LEARN RES, V12, P1771; Criminisi A., 2013, DECISION FORESTCOM; de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33; Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012; Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270; Harmeling S, 2011, IEEE T PATTERN ANAL, V33, P1087, DOI 10.1109/TPAMI.2010.145; Hirsch M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618505; Jacob Yannick, 2015, IEEE COMP SOC WORKSH; Jang Y, 2015, IEEE T VIS COMPUT GR, V21, P501, DOI 10.1109/TVCG.2015.2391860; Jung HY, 2015, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2015.7298861; Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61; Krejov Philip, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163141; Li PY, 2015, IEEE I CONF COMP VIS, P819, DOI 10.1109/ICCV.2015.100; Melax S., 2013, GRAPHICS INTERFACE 2, P63, DOI DOI 10.1145/2448196.2448232; Mourad R, 2013, J ARTIF INTELL RES, V47, P157, DOI 10.1613/jair.3879; Narasimhan S.G., 2012, ECCV; Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379; Oikonomidis I., 2011, P BMVC, P101; Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483; Poier G., 2015, P BRIT MACH VIS C; Pons-Moll G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.4; QIAN C, 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145; Romero J., 2009, P 9 IEEE RAS INT C H, P87; Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447; Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941; Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305; Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683; Supancic JS, 2015, IEEE I CONF COMP VIS, P1868, DOI 10.1109/ICCV.2015.217; Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700; Tang DH, 2015, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2015.380; Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490; Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400; Taylor J, 2014, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2014.88; Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Tzionas D, 2015, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2015.90; Tzionas D, 2014, LECT NOTES COMPUT SC, V8753, P277, DOI 10.1007/978-3-319-11752-2_22; Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83; Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369; Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429; Zafrulla Z., 2011, P 13 INT C MULT INT, P279, DOI DOI 10.1145/2070481.2070532	50	21	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1374	1387		10.1109/TPAMI.2016.2599170	http://dx.doi.org/10.1109/TPAMI.2016.2599170			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ					2022-12-18	WOS:000402744400008
J	Chhatkuli, A; Pizarro, D; Bartoli, A; Collins, T				Chhatkuli, Ajad; Pizarro, Daniel; Bartoli, Adrien; Collins, Toby			A Stable Analytical Framework for Isometric Shape-from-Template by Surface Integration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								Shape-from-Template (SfT) reconstructs the shape of a deforming surface from a single image, a 3D template and a deformation prior. For isometric deformations, this is a well-posed problem. However, previous methods which require no initialization break down when the perspective effects are small, which happens when the object is small or viewed from larger distances. That is, they do not handle all projection geometries. We propose stable SfT methods that accurately reconstruct the 3D shape for all projection geometries. We follow the existing approach of using first-order differential constraints and obtain local analytical solutions for depth and the first-order quantities: the depth-gradient or the surface normal. Previous methods use the depth solution directly to obtain the 3D shape. We prove that the depth solution is unstable when the projection geometry tends to affine, while the solution for the first-order quantities remain stable for all projection geometries. We therefore propose to solve SfT by first estimating the first-order quantities (either depth-gradient or surface normal) and integrating them to obtain shape. We validate our approach with extensive synthetic and real-world experiments and obtain significantly more accurate results compared to previous initialization-free methods. Our approach does not require any optimization, which makes it very fast.	[Chhatkuli, Ajad; Pizarro, Daniel; Bartoli, Adrien; Collins, Toby] Univ Auvergne, CNRS, ISIT, Clermont Ferrand, France; [Pizarro, Daniel] Univ Alcala, GEINTRA, Alcala De Henares, Spain	Centre National de la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA); Universidad de Alcala	Chhatkuli, A (corresponding author), Univ Auvergne, CNRS, ISIT, Clermont Ferrand, France.	ajad.chhatkuli@gmail.com; Dani.Pizarro@gmail.com; adrien.bartoli@gmail.com; Toby.Collins@gmail.com	Collins, Toby/Q-8967-2019	Collins, Toby/0000-0002-9441-8306; Pizarro, Daniel/0000-0003-0622-4884	EU's FP7 through the ERC research [307483 FLEXABLE]	EU's FP7 through the ERC research	We would like to thank the authors of [11] and [13] for sharing the implementation of their methods and the authors of [ 32] for their dataset. This research has received funding from the EU's FP7 through the ERC research grant 307483 FLEXABLE.	Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16; Bartoli A, 2015, IEEE T PATTERN ANAL, V37, P2099, DOI 10.1109/TPAMI.2015.2392759; Bartoli A, 2013, IEEE I CONF COMP VIS, P961, DOI 10.1109/ICCV.2013.123; Bartoli A, 2013, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2013.199; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brunet F, 2014, COMPUT VIS IMAGE UND, V125, P138, DOI 10.1016/j.cviu.2014.04.003; Chhatkuli A., 2014, P BRIT MACH VIS C; Chhatkuli A, 2014, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2014.96; Collins T., 2010, P INT WORKSHOP VISIO, P339; Collins T, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P116, DOI 10.1109/ISMAR.2015.35; Collins T, 2014, LECT NOTES COMPUT SC, V8692, P325, DOI 10.1007/978-3-319-10593-2_22; Collins T, 2014, LECT NOTES COMPUT SC, V8695, P138, DOI 10.1007/978-3-319-10584-0_10; Collins T, 2014, INT J COMPUT VISION, V109, P252, DOI 10.1007/s11263-014-0725-5; Ngo DT, 2016, IEEE T PATTERN ANAL, V38, P172, DOI 10.1109/TPAMI.2015.2435739; Del Bue A, 2008, P IEEE C COMP VIS PA, P1; Dierckx P., 1993, CURVE SURFACE FITTIN; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maier-Hein L, 2014, IEEE T MED IMAGING, V33, P1913, DOI 10.1109/TMI.2014.2325607; Perriollat M, 2013, COMPUT ANIMAT VIRT W, V24, P457, DOI 10.1002/cav.1478; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Pizarro D, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.104; Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0; Puerto-Souza GA, 2013, IEEE T MED IMAGING, V32, P1201, DOI 10.1109/TMI.2013.2239306; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Sorkine O., 2004, P 2004 EUR ACM SIGGR, P175, DOI [10.1145/1057432.1057456, DOI 10.1145/1057432.1057456]; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; TAYLOR J, 2010, PROC CVPR IEEE, P2761, DOI DOI 10.1109/CVPR.2010.5540002; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Varol A, 2012, PROC CVPR IEEE, P2248, DOI 10.1109/CVPR.2012.6247934; Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31	32	21	21	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					833	850		10.1109/TPAMI.2016.2562622	http://dx.doi.org/10.1109/TPAMI.2016.2562622			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	27164575				2022-12-18	WOS:000399250000001
J	Fu, YW; Hospedales, TM; Xiang, T; Xiong, JC; Gong, SG; Wang, YZ; Yao, Y				Fu, Yanwei; Hospedales, Timothy M.; Xiang, Tao; Xiong, Jiechao; Gong, Shaogang; Wang, Yizhou; Yao, Yuan			Robust Subjective Visual Property Prediction from Crowdsourced Pairwise Labels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Subjective visual properties; outlier detection; robust ranking; robust learning to rank; regularisation path	VARIABLE SELECTION; GRAPHS	The problem of estimating subjective visual properties from image and video has attracted increasing interest. A subjective visual property is useful either on its own (e.g. image and video interestingness) or as an intermediate representation for visual recognition (e.g. a relative attribute). Due to its ambiguous nature, annotating the value of a subjective visual property for learning a prediction model is challenging. To make the annotation more reliable, recent studies employ crowdsourcing tools to collect pairwise comparison labels. However, using crowdsourced data also introduces outliers. Existing methods rely on majority voting to prune the annotation outliers/errors. They thus require a large amount of pairwise labels to be collected. More importantly as a local outlier detection method, majority voting is ineffective in identifying outliers that can cause global ranking inconsistencies. In this paper, we propose a more principled way to identify annotation outliers by formulating the subjective visual property prediction task as a unified robust learning to rank problem, tackling both the outlier detection and learning to rank jointly. This differs from existing methods in that (1) the proposed method integrates local pairwise comparison labels together to minimise a cost that corresponds to global inconsistency of ranking order, and (2) the outlier detection and learning to rank problems are solved jointly. This not only leads to better detection of annotation outliers but also enables learning with extremely sparse annotations.	[Fu, Yanwei] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai 200433, Peoples R China; [Hospedales, Timothy M.; Xiang, Tao; Gong, Shaogang] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England; [Xiong, Jiechao; Yao, Yuan] Peking Univ, Sch Math Sci, Beijing, Peoples R China; [Wang, Yizhou] Peking Univ, Natl Engn Lab, Video Technol Cooperat Medianet Innovat Ctr, Key Lab Machine Percept MoE,Sch EECS, Beijing 100871, Peoples R China	Fudan University; University of London; Queen Mary University London; Peking University; Peking University	Fu, YW (corresponding author), Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai 200433, Peoples R China.; Hospedales, TM; Xiang, T; Gong, SG (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.; Xiong, JC; Yao, Y (corresponding author), Peking Univ, Sch Math Sci, Beijing, Peoples R China.; Wang, YZ (corresponding author), Peking Univ, Natl Engn Lab, Video Technol Cooperat Medianet Innovat Ctr, Key Lab Machine Percept MoE,Sch EECS, Beijing 100871, Peoples R China.	y.fu@qmul.ac.uk; t.hospedales@qmul.ac.uk; t.xiang@qmul.ac.uk; xiongjiechao@pku.edu.cn; s.gong@qmul.ac.uk; yizhou.wang@pku.edu.cn; yuany@math.pku.edu.cn		Hospedales, Timothy/0000-0003-4867-7486	National Natural Science Foundation of China [61402019]; China Postdoctoral Science Foundation [2014M550015]; National Basic Research Program of China [2012CB825501, 2015CB856000]; NSFC [61071157, 11421110001]; NSFC-Royal Society [1130360, IE110976]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); National Basic Research Program of China(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC)); NSFC-Royal Society	This research of Jiechao Xiong was supported in part by National Natural Science Foundation of China: 61402019, and China Postdoctoral Science Foundation: 2014M550015. The research of Yuan Yao was supported in part by National Basic Research Program of China under grant 2012CB825501 and 2015CB856000, as well as NSFC grant 61071157 and 11421110001. The research of Yanwei Fu and Tao Xiang was in part supported by a joint NSFC-Royal Society grant 1130360, IE110976 with Yuan Yao. Yuan Yao and Tao Xiang are the corresponding authours.	Belloni A, 2011, BIOMETRIKA, V98, P791, DOI 10.1093/biomet/asr043; Biswas A, 2013, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2013.89; Cao Z., 2007, P 24 INT C MACH LEAR, P129, DOI DOI 10.1145/1273496.1273513; Caron F, 2012, J COMPUT GRAPH STAT, V21, P174, DOI 10.1080/10618600.2012.638220; Carterette B, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P436, DOI 10.1145/1571941.1572017; Chapelle O, 2010, INFORM RETRIEVAL, V13, P201, DOI 10.1007/s10791-009-9109-9; Chen KT, 2009, MATH COMPUT SCI ENG, P491, DOI 10.1145/1631272.1631339; Chen X., 2013, WSDM, P193; Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467; Donahue J, 2011, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2011.6126394; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Fan J., 2012, ARXIV12106950; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Gannaz I, 2007, STAT COMPUT, V17, P293, DOI 10.1007/s11222-007-9019-x; GEHRLEIN WV, 1983, THEOR DECIS, V15, P161, DOI 10.1007/BF00143070; Gygli M, 2013, IEEE I CONF COMP VIS, P1633, DOI 10.1109/ICCV.2013.205; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Hirani A. N., 2010, ARXIV10111716; Huber P., 1981, ROBUST STAT; Hunter DR, 2004, ANN STAT, V32, P384; Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721; Jiang XY, 2011, MATH PROGRAM, V127, P203, DOI 10.1007/s10107-010-0419-x; Jiang Y. -G., 2013, P AAAI C ART INT, P1113; Ke Yan, 2006, 2006 IEEE COMPUTER S, V1, P419, DOI DOI 10.1109/CVPR.2006.303; Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453; Kovashka A, 2013, IEEE I CONF COMP VIS, P3432, DOI 10.1109/ICCV.2013.426; Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Liang L, 2014, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2014.34; Liu F, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2058; Liu Y., 2008, P ACM SIGIR; Long CJ, 2013, IEEE I CONF COMP VIS, P3000, DOI 10.1109/ICCV.2013.373; Ma Y., 2011, P 1 ACM INT C MULT R, P38; Maire M, 2011, IEEE I CONF COMP VIS, P2142, DOI 10.1109/ICCV.2011.6126490; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Mika S, 1999, ADV NEUR IN, V11, P536; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; PeterWelinder Steve Branson, 2010, P NIPS, V23, P1; Raykar V. C., 2009, P 26 ANN INT C MACH, P889, DOI DOI 10.1145/1553374.1553488; She YY, 2011, J AM STAT ASSOC, V106, P626, DOI 10.1198/jasa.2011.tm10390; Shrivastava A, 2012, LECT NOTES COMPUT SC, V7574, P369, DOI 10.1007/978-3-642-33712-3_27; Sorokin A, 2008, PROC CVPR IEEE, P23; Soufiani Hossein Azari, 2013, P 26 INT C NEUR INF, P2706; Sun ZY, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P259, DOI 10.1145/1571941.1571987; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wauthier Fabian L, 2013, ADV NEURAL INFORM PR, V26, P1061; Whitehill J., 2009, ADV NEURAL INFORM PR, P2035; Wu O., 2011, P 22 INT JOINT C ART, P1571; Xu, 2013, P 21 ACM INT C MULT, P43, DOI DOI 10.1145/2502081.2502083; Xu Q., 2012, P 20 ACM INT C MULTI, P359; Xu Q, 2012, IEEE T MULTIMEDIA, V14, P844, DOI 10.1109/TMM.2012.2190924; Yu SX, 2012, IEEE T PATTERN ANAL, V34, P158, DOI 10.1109/TPAMI.2011.107; Zhang Z, 2015, PATTERN ANAL APPL, V18, P157, DOI 10.1007/s10044-013-0349-3	63	21	21	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					563	577		10.1109/TPAMI.2015.2456887	http://dx.doi.org/10.1109/TPAMI.2015.2456887			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046498	Green Submitted, Green Accepted, Green Published			2022-12-18	WOS:000370738900011
J	Evangelidis, GD; Hansard, M; Horaud, R				Evangelidis, Georgios D.; Hansard, Miles; Horaud, Radu			Fusion of Range and Stereo Data for High-Resolution Scene-Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; range data; time-of-flight camera; sensor fusion; maximum a posteriori; seed-growing	ENERGY MINIMIZATION	This paper addresses the problem of range-stereo fusion, for the construction of high-resolution depth maps. In particular, we combine low-resolution depth data with high-resolution stereo data, in a maximum a posteriori ( MAP) formulation. Unlike existing schemes that build on MRF optimizers, we infer the disparity map from a series of local energy minimization problems that are solved hierarchically, by growing sparse initial disparities obtained from the depth data. The accuracy of the method is not compromised, owing to three properties of the data-term in the energy function. First, it incorporates a new correlation function that is capable of providing refined correlations and disparities, via subpixel correction. Second, the correlation scores rely on an adaptive cost aggregation step, based on the depth data. Third, the stereo and depth likelihoods are adaptively fused, based on the scene texture and camera geometry. These properties lead to a more selective growing process which, unlike previous seed-growing methods, avoids the tendency to propagate incorrect disparities. The proposed method gives rise to an intrinsically efficient algorithm, which runs at 3FPS on 2.0 MP images on a standard desktop computer. The strong performance of the new method is established both by quantitative comparisons with state-of-the-art methods, and by qualitative comparisons using real depth-stereo data-sets.	[Evangelidis, Georgios D.; Horaud, Radu] INRIA Grenoble Rhone Alpes, Percept Team, F-38330 Montbonnot St Martin, France; [Hansard, Miles] Univ London, Sch Elect Engn & Comp Sci, Vis Grp, London E1 4NS, England	University of London	Evangelidis, GD (corresponding author), INRIA Grenoble Rhone Alpes, Percept Team, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	georgios.evangelidis@inria.fr; miles.hansard@qmul.ac.uk; radu.horaud@inria.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X	Agence Nationale de la Recherche under the MIXCAM [ANR-13-BS02-0010-01]	Agence Nationale de la Recherche under the MIXCAM(French National Research Agency (ANR))	This work has received funding from Agence Nationale de la Recherche under the MIXCAM project number ANR-13-BS02-0010-01. Georgios Evangelidis is the corresponding author.	ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; BESAG J, 1986, J R STAT SOC B, V48, P259; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cech J., 2007, 2007 IEEE C COMP VIS, P1; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; Dal Mutto C, 2012, LECT NOTES COMPUT SC, V7583, P598, DOI 10.1007/978-3-642-33863-2_62; De-Maeztu L, 2011, IEEE I CONF COMP VIS, P1708, DOI 10.1109/ICCV.2011.6126434; Egnal G, 2004, IMAGE VISION COMPUT, V22, P943, DOI 10.1016/j.imavis.2004.03.018; Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42; Fischer Jan, 2011, IEEE International Conference on Robotics and Automation, P3548; Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060; Gandhi V, 2012, IEEE INT CONF ROBOT, P4742, DOI 10.1109/ICRA.2012.6224771; Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3; Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128; Guomundsson Sigurjon Arni, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P425, DOI 10.1504/IJISTA.2008.021305; Hahne Uwe, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P325, DOI 10.1504/IJISTA.2008.021295; Hansard M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3089, DOI 10.1109/CVPR.2011.5995533; Hansard M, 2015, COMPUT VIS IMAGE UND, V134, P105, DOI 10.1016/j.cviu.2014.09.001; Hansard Miles, 2012, TIME FLIGHT CAMERAS, P2; Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Kuhnert KD, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4780, DOI 10.1109/IROS.2006.282349; Liang Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3033, DOI 10.1109/CVPR.2011.5995480; Mac Aodha O, 2013, IEEE T PATTERN ANAL, V35, P1107, DOI 10.1109/TPAMI.2012.171; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; Nair Rahul, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P105, DOI 10.1007/978-3-642-44964-2_6; Nair R, 2012, LECT NOTES COMPUT SC, V7584, P1, DOI 10.1007/978-3-642-33868-7_1; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Psarakis EZ, 2005, IEEE I CONF COMP VIS, P907; Remondino F., 2013, TOF RANGE IMAGING CA; Reynolds M, 2011, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2011.5995550; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Ruhl K., 2012, P EUR CVMP, P26; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Stuckler Jorg, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4566, DOI 10.1109/IROS.2010.5654338; Sun J, 2005, PROC CVPR IEEE, P399; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Van den Bergh M, 2011, 2011 IEEE WORKSH APP, P66, DOI [10.1109/WACV.2011.5711485, DOI 10.1109/WACV.2011.5711485]; Van Meerbergen G, 2002, INT J COMPUT VISION, V47, P275, DOI 10.1023/A:1014562312225; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827; Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430; Zhu J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587761; Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172	52	21	23	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2178	2192		10.1109/TPAMI.2015.2400465	http://dx.doi.org/10.1109/TPAMI.2015.2400465			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440260	Green Submitted			2022-12-18	WOS:000362411000003
J	Fernandez, JA; Boddeti, VN; Rodriguez, A; Kumar, BVKV				Fernandez, Joseph A.; Boddeti, Vishnu Naresh; Rodriguez, Andres; Kumar, B. V. K. Vijaya			Zero-Aliasing Correlation Filters for Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Correlation filters; object recognition; object detection; object localization; discrete Fourier transform	PATTERN-RECOGNITION; AVERAGE; FRAMEWORK	Correlation filters (CFs) are a class of classifiers that are attractive for object localization and tracking applications. Traditionally, CFs have been designed in the frequency domain using the discrete Fourier transform (DFT), where correlation is efficiently implemented. However, existing CF designs do not account for the fact that the multiplication of two DFTs in the frequency domain corresponds to a circular correlation in the time/spatial domain. Because this was previously unaccounted for, prior CF designs are not truly optimal, as their optimization criteria do not accurately quantify their optimization intention. In this paper, we introduce new zero-aliasing constraints that completely eliminate this aliasing problem by ensuring that the optimization criterion for a given CF corresponds to a linear correlation rather than a circular correlation. This means that previous CF designs can be significantly improved by this reformulation. We demonstrate the benefits of this new CF design approach with several important CFs. We present experimental results on diverse data sets and present solutions to the computational challenges associated with computing these CFs. Code for the CFs described in this paper and their respective zero-aliasing versions is available at http://vishnu.boddeti.net/projects/correlation-filters.html	[Fernandez, Joseph A.; Kumar, B. V. K. Vijaya] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA; [Boddeti, Vishnu Naresh] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Rodriguez, Andres] Air Force Res Lab, Sensors Directorate, Dayton, OH USA	Carnegie Mellon University; Carnegie Mellon University	Fernandez, JA (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.	jafernan@andrew.cmu.edu; naresh@cmu.edu; andres.rodriguez.8@us.af.mil; kumar@ece.cmu.edu			Air Force Office of Scientific Research (AFOSR); National Defense Science & Engineering Graduate Fellowship (NDSEG) Program; KACST, Saudi Arabia	Air Force Office of Scientific Research (AFOSR)(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); National Defense Science & Engineering Graduate Fellowship (NDSEG) Program; KACST, Saudi Arabia	The authors would like to acknowledge the US Air Force Research Laboratory (AFRL) DoD Supercomputing Resource Center (DSRC) for providing the computational resources to quickly run many of the experiments presented. This work was supported in part by the Air Force Office of Scientific Research (AFOSR), the National Defense Science & Engineering Graduate Fellowship (NDSEG) Program, and KACST, Saudi Arabia. J. A. Fernandez is the corresponding author.	Ali S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2608, DOI 10.1109/ICPR.2010.639; [Anonymous], 2013, P 2013 AS PAC SIGN I; Anwaar-ul-Haq, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P474, DOI 10.1109/DICTA.2011.86; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boddeti V.N., 2011, INT JOINT C BIOMETRI, P1; Boddeti V. N., 2014, ARXIV1404 6031; Boddeti VN, 2013, PROC CVPR IEEE, P2291, DOI 10.1109/CVPR.2013.297; Boddeti VN, 2013, IEEE T PATTERN ANAL, V35, P2064, DOI 10.1109/TPAMI.2012.244; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Bolme DS, 2009, PROC CVPR IEEE, P2105, DOI 10.1109/CVPRW.2009.5206701; Bolme DS, 2009, 2009 12 IEEE INT WOR, P1, DOI DOI 10.1109/PETS-WINTER.2009.5399555; Boyd S, 2004, CONVEX OPTIMIZATION; Bristow H, 2013, PROC CVPR IEEE, P391, DOI 10.1109/CVPR.2013.57; CASASENT D, 1991, APPL OPTICS, V30, P5176, DOI 10.1364/AO.30.005176; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Fernandez JA, 2013, INT SYMP IMAGE SIG, P101; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381; Henriques JF, 2013, IEEE I CONF COMP VIS, P2760, DOI 10.1109/ICCV.2013.343; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Ito K, 2004, IEICE T FUND ELECTR, VE87A, P682; Kerekes R, 2009, IEEE T AERO ELEC SYS, V45, P289, DOI 10.1109/TAES.2009.4805280; Kumar BVKV, 2006, P IEEE, V94, P1963, DOI 10.1109/JPROC.2006.884094; Kumar BV., 2005, CORRELATION PATTERN, DOI 10.1017/CBO9780511541087; KUMAR BVKV, 1992, OPT ENG, V31, P915, DOI 10.1117/12.56169; KUMAR BVKV, 1994, OPT LETT, V19, P1556, DOI 10.1364/OL.19.001556; Li Y, 2004, IEEE T PATTERN ANAL, V26, P1639, DOI 10.1109/TPAMI.2004.117; MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633; Mahalanobis A., 2011, P SPIE DEF SEC SENS; Mathews M. M., 2014, P INT C LEARN REPR I, P1, DOI 10.1109/ICGCCEE.2014.6922231.s; Military Sensing Information Analysis Center, 2011, ATR ALG DEV IM DAT; Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833; Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724; Movshovitz-Attias Y., 2014, P BRIT MACH VIS C; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Proakis J., 2007, DIGIT SIGNAL PROCESS, V4th; REFREGIER P, 1990, OPT LETT, V15, P854, DOI 10.1364/OL.15.000854; Revaud J, 2013, PROC CVPR IEEE, P2459, DOI 10.1109/CVPR.2013.318; Rodriguez A., 2013, P SPIE C AUT TARG RE; Rodriguez A., 2012, THESIS CARNEGIE MELL; Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; SUDHARSANAN SI, 1990, OPT ENG, V29, P1021, DOI 10.1117/12.55698; Thornton J, 2007, IEEE T PATTERN ANAL, V29, P596, DOI 10.1109/TPAMI.2007.1006	46	21	21	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1702	1715		10.1109/TPAMI.2014.2375215	http://dx.doi.org/10.1109/TPAMI.2014.2375215			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353005	Green Submitted			2022-12-18	WOS:000357591900013
J	Bazzani, L; Zanotto, M; Cristani, M; Murino, V				Bazzani, Loris; Zanotto, Matteo; Cristani, Marco; Murino, Vittorio			Joint Individual-Group Modeling for Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Group modeling; joint individual-group tracking; decentralized particle filtering; Dirichlet process mixture model	MULTITARGET TRACKING; MOTION; ROBUST	We present a novel probabilistic framework that jointly models individuals and groups for tracking. Managing groups is challenging, primarily because of their nonlinear dynamics and complex layout which lead to repeated splitting and merging events. The proposed approach assumes a tight relation of mutual support between the modeling of individuals and groups, promoting the idea that groups are better modeled if individuals are considered and vice versa. This concept is translated in a mathematical model using a decentralized particle filtering framework which deals with a joint individual-group state space. The model factorizes the joint space into two dependent subspaces, where individuals and groups share the knowledge of the joint individual-group distribution. The assignment of people to the different groups (and thus group initialization, split and merge) is implemented by two alternative strategies: using classifiers trained beforehand on statistics of group configurations, and through online learning of a Dirichlet process mixture model, assuming that no training data is available before tracking. These strategies lead to two different methods that can be used on top of any person detector (simulated using the ground truth in our experiments). We provide convincing results on two recent challenging tracking benchmarks.	[Bazzani, Loris; Zanotto, Matteo; Cristani, Marco; Murino, Vittorio] Ist Italiano Tecnol, Pattern Anal & Comp Vis PAVIS, Genoa, Italy; [Cristani, Marco; Murino, Vittorio] Univ Verona, Dept Comp Sci, I-37100 Verona, Italy	Istituto Italiano di Tecnologia - IIT; University of Verona	Bazzani, L (corresponding author), Ist Italiano Tecnol, Pattern Anal & Comp Vis PAVIS, Genoa, Italy.	loris.bazzani@dartmouth.edu; matteo.zanotto@iit.it; marco.cristani@univr.it; vittorio.murino@iit.it		Murino, Vittorio/0000-0002-8645-2328				Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1; Arrow H., 2000, SMALL GROUPS COMPLEX; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008; Bazzani L, 2012, STUD COMPUT INTELL, V409, P271; Bazzani L, 2012, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2012.6247888; Bazzani L, 2010, IEEE IMAGE PROC, P837, DOI 10.1109/ICIP.2010.5653463; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bierlaire M., 2003, MOVING NETS PHYS SOC, P1; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Chang MC, 2011, IEEE I CONF COMP VIS, P747, DOI 10.1109/ICCV.2011.6126312; Chen TS, 2011, IEEE T SIGNAL PROCES, V59, P465, DOI 10.1109/TSP.2010.2091639; Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; Cristani M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.23; Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; De Freitas N, 2004, P IEEE, V92, P455, DOI 10.1109/JPROC.2003.823157; Doucet A., 2001, SEQUENTIAL MONTE CAR; F. Cupillard F. Bremond M. Thonnat I. S. Antipolis and O. Group, 2001, P 2 EUR WORKSH ADV V, P88; Fathi A, 2012, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2012.6247805; Feldmann M, 2011, IEEE T SIGNAL PROCES, V59, P1409, DOI 10.1109/TSP.2010.2101064; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Forsyth D.R., 2010, GROUP DYNAMICS, V5th ed.,; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; Gennari G, 2004, PROC CVPR IEEE, P876; Gilholm K., 2005, P SPIE C SIGN DAT PR; Gning A, 2011, IEEE T SIGNAL PROCES, V59, P1383, DOI 10.1109/TSP.2010.2103062; Goffman E., 1972, ENCOUNTERS 2 STUDIES; Goffman Ervin, 1966, BEHAV PUBLIC PLACES; Hall E. T, 1990, HIDDEN DIMENSION; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hung H., 2011, P 13 INT C MULTIMODA, P231; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kendon A., 1990, CUP ARCH, V7; Khamis S, 2012, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2012.6247804; Lau B, 2010, INT J SOC ROBOT, V2, P19, DOI 10.1007/s12369-009-0036-0; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Leal-Taixe Laura, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P120, DOI 10.1109/ICCVW.2011.6130233; Lin WC, 2007, IEEE T PATTERN ANAL, V29, P777, DOI 10.1109/TPAMI.2007.1053; LO AY, 1984, ANN STAT, V12, P351, DOI 10.1214/aos/1176346412; Marques J. S., 2003, P 2003 C COMP VIS PA, P101; Mauthner T., 2008, ICPR, P1; McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870; MCPHAIL C, 1982, SOCIOL METHOD RES, V10, P347, DOI 10.1177/0049124182010003007; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan A, 2013, IEEE COMPUT SOC CONF, P735, DOI 10.1109/CVPRW.2013.111; Pang SK, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P504; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pellegrini S, 2013, COMPUT VIS IMAGE UND, V117, P1215, DOI 10.1016/j.cviu.2012.09.005; Pellegrini S, 2010, LECT NOTES COMPUT SC, V6311, P452, DOI 10.1007/978-3-642-15549-9_33; Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42; Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Jacques JCS, 2007, PATTERN ANAL APPL, V10, P321, DOI 10.1007/s10044-007-0070-1; Smith K., 2005, COMP VIS PATT REC WO, P36, DOI DOI 10.1109/CVPR.2005.453; Sochman J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P830, DOI 10.1109/ICCVW.2011.6130338; Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123; Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007; Wang YD, 2006, INT C PATT RECOG, P1127; Xing E., 2008, P 2008 SIAM INT C DA, DOI DOI 10.1137/1.9781611972788.20; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892; Yousuf Mohammad Abu, 2012, Intelligent Computing Technology. Proceedings 8th International Conference, ICIC 2012, P423, DOI 10.1007/978-3-642-31588-6_55; Zanotto M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.111; Zheng WS, 2014, ADV COMPUT VIS PATT, P183, DOI 10.1007/978-1-4471-6296-4_9	74	21	22	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					746	759		10.1109/TPAMI.2014.2353641	http://dx.doi.org/10.1109/TPAMI.2014.2353641			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353291	Green Submitted			2022-12-18	WOS:000351213400004
J	Liu, MM; Hartley, R; Salzmann, M				Liu, Miaomiao; Hartley, Richard; Salzmann, Mathieu			Mirror Surface Reconstruction from a Single Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Smooth mirror surface; reconstruction; single image; partial differential equation; transparent surface reconstruction	SHAPE; POSE	This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images. We then provide a theoretical analysis of the potential degenerate cases with and without prior knowledge of the pose of the reference target. Finally we show that our theory can be similarly applied to the reconstruction of the surface of transparent object.	[Liu, Miaomiao; Hartley, Richard; Salzmann, Mathieu] NICTA, CRL, Canberra, ACT 2600, Australia; [Liu, Miaomiao; Hartley, Richard; Salzmann, Mathieu] Australian Natl Univ, Canberra, ACT 0200, Australia	Australian National University; Australian National University	Liu, MM (corresponding author), NICTA, CRL, Canberra, ACT 2600, Australia.	miaomiao.liu@nicta.com.au; richard.hartley@anu.edu.au; mathieu.salzmann@nicta.com.au		Liu, Miaomiao/0000-0001-6485-3510				Adato Y, 2007, IEEE I CONF COMP VIS, P433; Baker S., 2001, PANORAMIC VISION SEN; Balzer J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2537, DOI 10.1109/CVPR.2011.5995346; Bonfort T, 2006, LECT NOTES COMPUT SC, V3852, P872; Bonfort T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P591; Canas GD, 2009, IEEE I CONF COMP VIS, P191, DOI 10.1109/ICCV.2009.5459164; Chari V, 2013, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2013.189; Earl N. L., 1955, THEORY ORDINARY DIFF; Endre Suli D. F. M., 2003, INTRO NUMERICAL ANAL; Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10; Halstead M. A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P335, DOI 10.1145/237170.237272; Hartley R., 2004, ROBOTICA; Kutulakos KN, 2008, INT J COMPUT VISION, V76, P13, DOI 10.1007/s11263-007-0049-9; Liu MM, 2013, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2013.24; Liu MM, 2011, IEEE I CONF COMP VIS, P579, DOI 10.1109/ICCV.2011.6126291; Nehab D., 2008, P IEEE C COMP VIS PA, P1; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Roth S., 2006, P IEEE COMP SOC C CO, V2, P1869; ROZENFELD S, 2007, P IEEE C COMP VIS PA, P1; Sankaranarayanan AC, 2010, PROC CVPR IEEE, P1245, DOI 10.1109/CVPR.2010.5539826; Savarese S, 2005, INT J COMPUT VISION, V64, P31, DOI 10.1007/s11263-005-1086-x; Sturm P, 2006, LECT NOTES COMPUT SC, V3852, P21; Swaminathan R, 2006, INT J COMPUT VISION, V66, P211, DOI 10.1007/s11263-005-3220-1; Tarini M, 2005, GRAPH MODELS, V67, P233, DOI 10.1016/j.gmod.2004.11.002; Vasilyev Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2561, DOI 10.1109/CVPR.2011.5995662; ZISSERMAN A, 1989, IMAGE VISION COMPUT, V7, P38, DOI 10.1016/0262-8856(89)90018-8	26	21	21	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					760	773		10.1109/TPAMI.2014.2353622	http://dx.doi.org/10.1109/TPAMI.2014.2353622			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353292				2022-12-18	WOS:000351213400005
J	Lezama, J; Morel, JM; Randall, G; von Gioi, RG				Lezama, Jose; Morel, Jean-Michel; Randall, Gregory; von Gioi, Rafael Grompone			A Contrario 2D Point Alignment Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point alignment detection; clustering; a contrario methods; Poisson point process	STRAIGHT-LINES; DOTTED LINE; PARADIGM; IMAGES; SETS	In spite of many interesting attempts, the problem of automatically finding alignments in a 2D set of points seems to be still open. The difficulty of the problem is illustrated here by very simple examples. We then propose an elaborate solution. We show that a correct alignment detection depends on not less than four interlaced criteria, namely the amount of masking in texture, the relative bilateral local density of the alignment, its internal regularity, and finally a redundancy reduction step. Extending tools of the a contrario detection theory, we show that all of these detection criteria can be naturally embedded in a single probabilistic a contrario model with a single user parameter, the number of false alarms. Our contribution to the a contrario theory is the use of sophisticated conditional events on random point sets, for which expectation we nevertheless find easy bounds. By these bounds the mathematical consistency of our detection model receives a simple proof. Our final algorithm also includes a new formulation of the exclusion principle in Gestalt theory to avoid redundant detections. Aiming at reproducibility, a source code and an online demo open to any data point set are provided. The method is carefully compared to three state-of-the-art algorithms and an application to real data is discussed. Limitations of the final method are also illustrated and explained.	[Lezama, Jose; Morel, Jean-Michel; von Gioi, Rafael Grompone] ENS Cachan, CMLA, F-94235 Cachan, France; [Lezama, Jose; Randall, Gregory] Univ Republica, IIE, Montevideo, Uruguay	UDICE-French Research Universities; Universite Paris Saclay; Universidad de la Republica, Uruguay	Lezama, J (corresponding author), ENS Cachan, CMLA, F-94235 Cachan, France.	lezama@cmla.ens-cachan.fr; morel@cmla.ens-cachan.fr; randall@fing.edu.uy; grompone@cmla.ens-cachan.fr	Lezama, Jose/ABG-2111-2021	Morel, Jean-Michel/0000-0002-6108-897X				AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; ALBERT MK, 1995, GEOMETRIC REPRESENTATIONS OF PERCEPTUAL PHENOMENA, P95; Amorese D, 1999, B SEISMOL SOC AM, V89, P742; [Anonymous], 1985, PERCEPTUAL ORG VISUA; Arcasoy A, 2004, COMPUT GEOSCI-UK, V30, P45, DOI 10.1016/j.cageo.2003.09.004; ARP H, 1980, ASTROPHYS J, V240, P726, DOI 10.1086/158284; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; Black PE, 2004, DICT ALGORITHMS DATA; BROADBENT S, 1980, J ROY STAT SOC A STA, V143, P109, DOI 10.2307/2981985; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Crow F. C., 1984, Computers & Graphics, V18, P207; Danuser G, 1998, IEEE T PATTERN ANAL, V20, P263, DOI 10.1109/34.667884; Dave R. N., 1989, INTELLIGENT ROBOTS C, V8, P600; de la Escalera A, 2010, SENSORS-BASEL, V10, P2027, DOI 10.3390/s100302027; Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; Desolneux A., 2008, GESTALT THEORY IMAGE, V1st ed.; Dubska M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.90; Dubska M, 2011, PROC CVPR IEEE, P1489, DOI 10.1109/CVPR.2011.5995501; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; EDMUNDS MG, 1981, NATURE, V290, P481, DOI 10.1038/290481a0; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; Gerig G., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P112; GERIG G, 1986, P ICPR, V8, P498; Hall P, 2006, BERNOULLI, V12, P821, DOI 10.3150/bj/1161614948; Hammer O, 2009, COMPUT GEOSCI-UK, V35, P659, DOI 10.1016/j.cageo.2008.03.012; Hammer Oyvind, 2001, Palaeontologia Electronica, V4, pUnpaginated; Havel J, 2013, PATTERN RECOGN LETT, V34, P703, DOI 10.1016/j.patrec.2013.01.020; Herout A., 2013, J REAL-TIME IMAGE PR, P1; Hough, 1959, P INT C HIGH EN ACC, V590914, P554; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Kanizsa G., 1980, GRAMMATICA VEDERE; Kanizsa G., 1979, ORG VISION; Kanizsa G., 1991, VEDERE E PENSARE; KENDALL DG, 1980, ADV APPL PROBAB, V12, P380, DOI 10.2307/1426603; KIRYATI N, 1992, IEEE T PATTERN ANAL, V14, P496, DOI 10.1109/34.126810; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; Kiryati N, 2000, PATTERN RECOGN LETT, V21, P1157, DOI 10.1016/S0167-8655(00)00077-5; KIRYATI N, 1991, IEEE T PATTERN ANAL, V13, P602, DOI 10.1109/34.87346; Kiryati N., 1992, BIWITR137 I COMM TEC; Lezama J, 2014, PROC CVPR IEEE, P509, DOI 10.1109/CVPR.2014.72; Litton C. D., 1983, COMPUT APPL ARCHAEOL, P85; LOWE DG, 1982, P DARPARIUS WORKSHOP, P168; LUTZ TM, 1986, J GEOPHYS RES-SOLID, V91, P421, DOI 10.1029/JB091iB01p00421; MACK C, 1950, P CAMB PHILOS SOC, V46, P285; Metzger W., 1975, GESETZE SEHENS; METZGER W., 2006, LAWS OS SEEING; MILES R E, 1970, Mathematical Biosciences, V6, P85, DOI 10.1016/0025-5564(70)90061-1; MURTAGH F, 1984, PATTERN RECOGN, V17, P479, DOI 10.1016/0031-3203(84)90045-1; Mussap AJ, 2000, VISION RES, V40, P3297, DOI 10.1016/S0042-6989(00)00154-1; Preiss A. K., 2006, THESIS U ADELAIDE AD; SMALL CG, 1988, INT STAT REV, V56, P243, DOI 10.2307/1403352; SMITS J T S, 1985, Spatial Vision, V1, P163, DOI 10.1163/156856885X00170; THRIFT PR, 1983, COMPUT VISION GRAPH, V21, P383, DOI 10.1016/S0734-189X(83)80050-4; Tripathy SP, 1999, VISION RES, V39, P4161, DOI 10.1016/S0042-6989(99)00125-X; Uttal W.R., 1975, AUTOCORRELATION THEO; UTTAL WR, 1973, VISION RES, V13, P2155, DOI 10.1016/0042-6989(73)90193-4; UTTAL WR, 1970, PERCEPT PSYCHOPHYS, V8, P385, DOI 10.3758/BF03207029; UTTAL WR, 1987, PERCEPTION DOTTED FO; Vanegas MC, 2010, INT GEOSCI REMOTE SE, P464, DOI 10.1109/IGARSS.2010.5652243; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; VONGIOI RG, 2009, J PHYSIOL-PARIS, V103, P4; WADGE G, 1988, GEOLOGY, V16, P815, DOI 10.1130/0091-7613(1988)016<0815:QMFDAP>2.3.CO;2; WAGEMANS J, 1992, CAN J PSYCHOL, V46, P236, DOI 10.1037/h0084323; Witkin A. P., 1983, HUMAN MACHINE VISION, P481; Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181; Yong-Gang Zhao, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P522, DOI 10.1007/978-3-642-36669-7_64; ZHANG DZ, 1989, TECTONOPHYSICS, V159, P137, DOI 10.1016/0040-1951(89)90175-3; ZUIDERWIJK EJ, 1982, NATURE, V295, P577, DOI 10.1038/295577a0	71	21	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					499	512		10.1109/TPAMI.2014.2345389	http://dx.doi.org/10.1109/TPAMI.2014.2345389			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353257	Green Submitted			2022-12-18	WOS:000349626200002
J	Foti, NJ; Williamson, SA				Foti, Nicholas J.; Williamson, Sinead A.			A Survey of Non-Exchangeable Priors for Bayesian Nonparametric Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; non-exchangeable data; dependent stochastic processes; dependent Dirichlet processes		Dependent nonparametric processes extend distributions over measures, such as the Dirichlet process and the beta process, to give distributions over collections of measures, typically indexed by values in some covariate space. Such models are appropriate priors when exchangeability assumptions do not hold, and instead we want our model to vary fluidly with some set of covariates. Since the concept of dependent nonparametric processes was formalized by MacEachern, there have been a number of models proposed and used in the statistics and machine learning literatures. Many of these models exhibit underlying similarities, an understanding of which, we hope, will help in selecting an appropriate prior, developing new models, and leveraging inference techniques.	[Foti, Nicholas J.] Univ Washington, Dept Stat, Seattle, WA 98195 USA; [Williamson, Sinead A.] Univ Texas Austin, Dept Informat Risk & Operat Management, Austin, TX 78712 USA	University of Washington; University of Washington Seattle; University of Texas System; University of Texas Austin	Foti, NJ (corresponding author), Univ Washington, Dept Stat, Seattle, WA 98195 USA.	nfoti@uw.edu; sinead.williamson@mccombs.utexas.edu			Alfred P. Sloan Foundation; Dartmouth College Neukom Institute for Computational Science	Alfred P. Sloan Foundation(Alfred P. Sloan Foundation); Dartmouth College Neukom Institute for Computational Science	Nicholas J. Foti was partially supported by a grant from the Alfred P. Sloan Foundation and by the Dartmouth College Neukom Institute for Computational Science.	Ahmed A., 2008, P 8 SIAM INT C DAT M; Aldous D., 1983, LECT NOTES MATH, V1117, P1, DOI [10.1007/BFb0099420, DOI 10.1007/BFB0099421.1072]; An Q., 2008, P 25 ICML HELS FINL; Bartlett N., 2010, P 27 ICML HAIF ISR; Blei DM, 2011, J MACH LEARN RES, V12, P2461; Blei DM, 2006, INT C MACH LEARN ICM, V148, P113, DOI [10.1145/1143844.1143859, DOI 10.1145/1143844.1143859]; Caron F., 2007, P UNC ART INT; Chen C., 2013, P 30 ICML ATL GA US; Chen C., 2012, P 29 ICML ED UK; Chung YS, 2011, ANN I STAT MATH, V63, P59, DOI 10.1007/s10463-008-0218-9; CIFARELLI DM, 1978, QUADERNI I MATEMATIC, V3, P1; Cressie N, 2011, STAT SPATIO TEMPORAL; De Iorio M, 2004, J AM STAT ASSOC, V99, P205, DOI 10.1198/016214504000000205; De Iorio M, 2009, BIOMETRICS, V65, P762, DOI 10.1111/j.1541-0420.2008.01166.x; Duan JA, 2007, BIOMETRIKA, V94, P809, DOI 10.1093/biomet/asm071; Dunson D. B., 2010, BAYESIAN NONPARAMETR; Dunson DB, 2008, BIOMETRIKA, V95, P307, DOI 10.1093/biomet/asn012; Dunson DB, 2007, J ROY STAT SOC B, V69, P163, DOI 10.1111/j.1467-9868.2007.00582.x; Dunson DB, 2006, BIOSTATISTICS, V7, P551, DOI 10.1093/biostatistics/kxj025; DYKSTRA RL, 1981, ANN STAT, V9, P356, DOI 10.1214/aos/1176345401; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Foti N., 2012, P NIPS; Foti N. J., 2013, P INT C ART INT STAT; Fox E. B., 2008, P 25 ICML HELS FINL; Gelfand AE, 2005, J AM STAT ASSOC, V100, P1021, DOI 10.1198/016214504000002078; Gelfand AE, 2007, BAYESIAN STAT, V8, P1; Gershman S. J., IEEE T PATT IN PRESS; Griffin JE, 2013, J R STAT SOC B, V75, P499, DOI 10.1111/rssb.12002; Griffin JE, 2011, J STAT PLAN INFER, V141, P3648, DOI 10.1016/j.jspi.2011.05.019; Griffin JE, 2006, J AM STAT ASSOC, V101, P179, DOI 10.1198/016214505000000727; Griffiths T. L., 2005, P NIPS; HJORT NL, 1990, ANN STAT, V18, P1259, DOI 10.1214/aos/1176347749; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Kingman J, 1982, J APPL PROB A, V19, P27, DOI DOI 10.2307/3213548; KINGMAN JFC, 1967, PAC J MATH, V21, P59, DOI 10.2140/pjm.1967.21.59; Lijoi A., 2010, BAYESIAN NONPARAMETR, P80; Lijoi A., 2012, CLASS DEPENDENT RAND; Lijoi A., 2011, BAYESIAN INFERENCE D; Lin D., 2010, P NIPS; LO AY, 1989, ANN I STAT MATH, V41, P227, DOI 10.1007/BF00049393; MACEACHERN S., 1999, P SECT BAYES STAT SC; MacEachern S, 2000, TECHNICAL REPORT; MILES RE, 1964, P NATL ACAD SCI USA, V52, P901, DOI 10.1073/pnas.52.4.901; Orbanz P., 2011, P NIPS; PERMAN M, 1992, PROBAB THEORY REL, V92, P21, DOI 10.1007/BF01205234; Pitman J., 2002, COMBINATORIAL STOCHA; Rao V., 2009, P NIPS; Regazzini E, 2003, ANN STAT, V31, P560; Ren L., 2008, P 25 ICML HELS FINL; Ren L., 2011, P NIPS; Rodriguez A, 2010, J AM STAT ASSOC, V105, P647, DOI 10.1198/jasa.2010.tm08241; Saeedi A., 2011, P NIPS; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Sudderth E. B., 2008, P NIPS; Teh Y. W., 2010, BAYESIAN NONPARAMETR; Teh Y.W, 2007, P INT C ART INT STAT; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Thibaux R., 2007, P INT C ART INT STAT; Titsias M. K., 2007, P NIPS; Tsay R. S., 2010, ANAL FINANCIAL TIME, V3rd; Williamson S., 2010, P 13 INT C ART INT S; Williamson S. A., 2011, THESIS U CAMBRIDGE C; Xing E. P., 2006, P 23 ICML PITTSB PA; Zhou M., 2012, P INT C ART INT STAT; Zhou M., 2011, P INT C ART INT STAT; Zhu Xiaojin, 2005, TIME SENSITIVE DIRIC	66	21	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					359	371		10.1109/TPAMI.2013.224	http://dx.doi.org/10.1109/TPAMI.2013.224			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353247	Green Submitted			2022-12-18	WOS:000349625500012
J	Mitra, K; Cossairt, OS; Veeraraghavan, A				Mitra, Kaushik; Cossairt, Oliver S.; Veeraraghavan, Ashok			A Framework for Analysis of Computational Imaging Systems: Role of Signal Prior, Sensor Noise and Multiplexing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational imaging; extended depth-of-field (EDOF); motion deblurring; Gaussian mixture model (GMM)	EXTENDED DEPTH; FIELD; MIXTURE; ALGORITHM; DESIGN; SPACE	Over the last decade, a number of computational imaging (CI) systems have been proposed for tasks such as motion deblurring, defocus deblurring and multispectral imaging. These techniques increase the amount of light reaching the sensor via multiplexing and then undo the deleterious effects of multiplexing by appropriate reconstruction algorithms. Given the widespread appeal and the considerable enthusiasm generated by these techniques, a detailed performance analysis of the benefits conferred by this approach is important. Unfortunately, a detailed analysis of CI has proven to be a challenging problem because performance depends equally on three components: (1) the optical multiplexing, (2) the noise characteristics of the sensor, and (3) the reconstruction algorithm which typically uses signal priors. A few recent papers [ 12], [ 30], [ 49] have performed analysis taking multiplexing and noise characteristics into account. However, analysis of CI systems under state-of-the-art reconstruction algorithms, most of which exploit signal prior models, has proven to be unwieldy. In this paper, we present a comprehensive analysis framework incorporating all three components. In order to perform this analysis, we model the signal priors using a Gaussian Mixture Model (GMM). A GMM prior confers two unique characteristics. First, GMM satisfies the universal approximation property which says that any prior density function can be approximated to any fidelity using a GMM with appropriate number of mixtures. Second, a GMM prior lends itself to analytical tractability allowing us to derive simple expressions for the 'minimum mean square error' (MMSE) which we use as a metric to characterize the performance of CI systems. We use our framework to analyze several previously proposed CI techniques (focal sweep, flutter shutter, parabolic exposure, etc.), giving conclusive answer to the question: 'How much performance gain is due to use of a signal prior and how much is due to multiplexing? Our analysis also clearly shows that multiplexing provides significant performance gains above and beyond the gains obtained due to use of signal priors.	[Mitra, Kaushik; Veeraraghavan, Ashok] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77025 USA; [Cossairt, Oliver S.] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Rice University; Northwestern University	Mitra, K (corresponding author), Rice Univ, Dept Elect & Comp Engn, Houston, TX 77025 USA.	Kaushik.Mitra@rice.edu; ollie@eecs.northwestern.edu; vashok@rice.edu	Cossairt, Oliver/I-5647-2012	Mitra, Kaushik/0000-0001-6747-9050	US National Science Foundation (NSF) [NSF-IIS: 1116718, NSF-CCF:1117939]; Samsung Advanced Institute of Technology through the Samsung GRO program; Direct For Computer & Info Scie & Enginr [1116718] Funding Source: National Science Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Samsung Advanced Institute of Technology through the Samsung GRO program(Samsung); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	Kaushik Mitra and Ashok Veeraraghavan acknowledge support through US National Science Foundation (NSF) Grants NSF-IIS: 1116718, NSF-CCF:1117939 and a research grant from Samsung Advanced Institute of Technology through the Samsung GRO program.	Agrawal Amit, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2560, DOI 10.1109/CVPRW.2009.5206546; Agrawal A, 2010, PROC CVPR IEEE, P599, DOI 10.1109/CVPR.2010.5540161; Agrawal A, 2010, COMPUT GRAPH FORUM, V29, P763, DOI 10.1111/j.1467-8659.2009.01646.x; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2007, COMPUTER VISION PATT; Baek J. M., 2010, ICCP, P1; Baer R., 1999, P SPIE EL IM C; Castro A, 2004, APPL OPTICS, V43, P3474, DOI 10.1364/AO.43.003474; Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087; Chen MH, 2010, IEEE T SIGNAL PROCES, V58, P6140, DOI 10.1109/TSP.2010.2070796; Cho T., 2010, P INT C COMP PHOT; Cossairt O., 2011, THESIS COLUMBIA U NE; Cossairt O., 2010, P ACM SIGGRAPH; Cossairt O, 2013, IEEE T IMAGE PROCESS, V22, P447, DOI 10.1109/TIP.2012.2216538; Dabov K., 2008, P SPIE IMAGING IMAGI; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; DOWSKI ER, 1995, APPL OPTICS, V34, P1859, DOI 10.1364/AO.34.001859; Eldar YC, 2010, IEEE T SIGNAL PROCES, V58, P3042, DOI 10.1109/TSP.2010.2044837; Eldar YC, 2009, IEEE T INFORM THEORY, V55, P5302, DOI 10.1109/TIT.2009.2030471; Flam JT, 2012, IEEE T SIGNAL PROCES, V60, P3840, DOI 10.1109/TSP.2012.2192112; Garcia-Guerrero EE, 2007, OPT EXPRESS, V15, P910, DOI 10.1364/OE.15.000910; George N, 2003, J OPT A-PURE APPL OP, V5, pS157, DOI 10.1088/1464-4258/5/5/358; Guerrero-Colon JA, 2008, IEEE T IMAGE PROCESS, V17, P27, DOI 10.1109/TIP.2007.911473; Hanley QS, 1999, APPL SPECTROSC, V53, P1, DOI 10.1366/0003702991945317; Harwit M., 1979, HADAMARD TRANSFORM O; Hasinoff S., 2009, P INT C COMP VIS, P1; Hasinoff SW, 2008, LECT NOTES COMPUT SC, V5305, P45, DOI 10.1007/978-3-540-88693-8_4; Hausler G., 1972, OPT COMMUN, V6, P38; Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254; Holloway J., 2012, P IEEE INT C COMP PH, P1; Ihrke I, 2010, PROC CVPR IEEE, P483, DOI 10.1109/CVPR.2010.5540174; Kuthirummal S, 2011, IEEE T PATTERN ANAL, V33, P58, DOI 10.1109/TPAMI.2010.66; Lanman D., P ACM SIGGRAPH; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2833, DOI 10.1109/CVPR.2011.5995309; Levin A., 2008, P ACM SIGGRAPH; Levin A., 2007, P ACM SIGGRAPH; Levin A, 2008, LECT NOTES COMPUT SC, V5305, P88, DOI 10.1007/978-3-540-88693-8_7; Levin A, 2012, LECT NOTES COMPUT SC, V7576, P73, DOI 10.1007/978-3-642-33715-4_6; Levin A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531403; Liang C., 2008, P ACM SIGGRAPH; Lumsdaine A., 2009, IEEE INT C COMPUTATI, P1; Mairal J, 2010, J MACH LEARN RES, V11, P19; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914; Mitra K., 2014, ICCP; Mitra K., 2012, IEEE C COMP VIS PATT, P22; Nayar S., 2011, CUCS00111 DEP COMP S; Ng R., 2005, 200502 CSTR STANF U, V2; Ojeda-Castaneda J, 2005, OPT LETT, V30, P1647, DOI 10.1364/OL.30.001647; Plataniotis K. N., 2000, ADV SIGNAL PROCESSIN, P32; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Ratner N, 2007, OPT EXPRESS, V15, P17072, DOI 10.1364/OE.15.017072; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1339, DOI 10.1109/TPAMI.2007.1151; Shroff Nitesh, 2012, P IEEE INT C COMP PH, P1; SORENSON HW, 1971, AUTOMATICA, V7, P465, DOI 10.1016/0005-1098(71)90097-5; Tendero Y., 2012, THESIS ENS CACHAN CA; Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Wuttig A., 2005, APPL OPT, V44; Yang JB, 2013, IEEE IMAGE PROC, P19, DOI 10.1109/ICIP.2013.6738005; Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743; Zhang L, 2010, PROC CVPR IEEE, P522, DOI 10.1109/CVPR.2010.5540171; Zhou C., 2012, CUCS02112 DEP COMP S	65	21	22	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					1909	1921		10.1109/TPAMI.2014.2313118	http://dx.doi.org/10.1109/TPAMI.2014.2313118			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352624				2022-12-18	WOS:000341981300001
J	Hughes, JM; Mao, D; Rockmore, DN; Wang, Y; Wu, Q				Hughes, James M.; Mao, Dong; Rockmore, Daniel N.; Wang, Yang; Wu, Qiang			Empirical Mode Decomposition Analysis for Visual Stylometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Empirical mode decomposition; stylometry; classifier; image processing	CLASSIFICATION	In this paper, we show how the tools of empirical mode decomposition (EMD) analysis can be applied to the problem of "visual stylometry," generally defined as the development of quantitative tools for the measurement and comparisons of individual style in the visual arts. In particular, we introduce a new form of EMD analysis for images and show that it is possible to use its output as the basis for the construction of effective support vector machine (SVM)-based stylometric classifiers. We present the methodology and then test it on collections of two sets of digital captures of drawings: a set of authentic and well-known imitations of works attributed to the great Flemish artist Pieter Bruegel the Elder (1525-1569) and a set of works attributed to Dutch master Rembrandt van Rijn (1606-1669) and his pupils. Our positive results indicate that EMD-based methods may hold promise generally as a technique for visual stylometry.	[Hughes, James M.] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA; [Mao, Dong; Wang, Yang] Michigan State Univ, Dept Math, E Lansing, MI 48824 USA; [Rockmore, Daniel N.] Dartmouth Coll, Dept Math, Hanover, NH 03755 USA; [Rockmore, Daniel N.] Santa Fe Inst, Santa Fe, NM 87501 USA; [Wu, Qiang] Middle Tennessee Univ, Dept Math Sci, Murfreesboro, TN 37132 USA; [Rockmore, Daniel N.] Dartmouth Coll, Neukom Inst Computat Sci, Hanover, NH 03755 USA	Dartmouth College; Michigan State University; Dartmouth College; The Santa Fe Institute; Middle Tennessee State University; Dartmouth College	Hughes, JM (corresponding author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.	hughes@cs.dartmouth.edu; dmao@math.msu.edu; rockmore@cs.dartmouth.edu; ywang@math.msu.edu; qwu@mtsu.edu	Wu, Qiang/B-1620-2008	Wu, Qiang/0000-0002-4698-6966; Wang, Yang/0000-0002-8903-2388	Samuel H. Kress Foundation	Samuel H. Kress Foundation	Thanks to N. Foti for many useful conversations and to P. Schatborn for suggesting the Rembrandt experiments and providing the images. James M. Hughes and Daniel N. Rockmore gratefully acknowledge the partial support of the Samuel H. Kress Foundation.	Benesch Otto, 1973, DRAWINGS REMBRANDT C; Berezhnoy Igor E, 2005, P IEEE INT C MULT EX, P1586; Chen QH, 2006, ADV COMPUT MATH, V24, P171, DOI 10.1007/s10444-004-7614-3; Coddington J, 2008, PROC SPIE, V6810, DOI 10.1117/12.765015; de Morgan A., 1982, MEMOIRS A DEMORGAN S; Echeverria JC, 2001, MED BIOL ENG COMPUT, V39, P471, DOI 10.1007/BF02345370; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; GINZBURG C, 1980, HIST WORKSHOP, P6; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hendrix L., 2010, DRAWINGS REMBRANDT H; Holmes DavidI., 2003, CHANCE, V16, P5, DOI [10.1080/09332480.2003.10554842, DOI 10.1080/09332480.2003.10554842]; Huang NE, 1999, ANNU REV FLUID MECH, V31, P417, DOI 10.1146/annurev.fluid.31.1.417; Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193; Hughes J.M., 2010, P SPIE COMP VIS IM A, V7531; Hughes JM, 2010, P NATL ACAD SCI USA, V107, P1279, DOI 10.1073/pnas.0910530107; Izenman AJ, 2008, SPRINGER TEXTS STAT, P1, DOI 10.1007/978-0-387-78189-1_1; Johnson CR, 2008, IEEE SIGNAL PROC MAG, V25, P37, DOI 10.1109/MSP.2008.923513; Jones-Smith K, 2006, NATURE, V444, pE9, DOI 10.1038/nature05398; Leibon G., 2007, MATEMATICA CULTURA, P107; Li J, 2004, IEEE T IMAGE PROCESS, V13, P338, DOI 10.1109/TIP.2003.821349; Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6; Lin L, 2009, ADV DATA SCI ADAPT, V1, P543, DOI 10.1142/S179353690900028X; Liu B, 2006, MECH SYST SIGNAL PR, V20, P718, DOI 10.1016/j.ymssp.2005.02.003; Lyu S, 2004, P NATL ACAD SCI USA, V101, P17006, DOI 10.1073/pnas.0406398101; Manaris B, 2005, COMPUT MUSIC J, V29, P55, DOI 10.1162/comj.2005.29.1.55; Manaris B, 2007, P 22 NAT C ART INT, V1, P839; Mao D., 2009, INTEGER VALUED LEVY; Mureika JR, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.046101; Orenstein N, 2001, P BRUEGEL ELDER; Orenstein N.M., 2003, INT FDN ART RES J, V12-17; Pawlowski A, 2004, GLOTTOMETRICS, V8, P83; Pines D, 2002, P SOC PHOTO-OPT INS, V4701, P127, DOI 10.1117/12.474653; Platt J., 1999, ADV LARGE MARGIN CLA; Qi H., 2011, P INT C AC SPEECH SI; Sapp C.S., 2007, P 8 INT C MUS INF RE, P497, DOI DOI 10.5281/ZENODO.1417693; Taylor RP, 2006, NATURE, V444, pE10, DOI 10.1038/nature05399; Taylor RP, 1999, NATURE, V399, P422, DOI 10.1038/20833; Wang Y., INTEGER VALUED LEVY; Wollheim R., 1989, MIND ITS DEPTHS; Yang Z., INTEGER VALUED LEVY; Yang ZH, 2007, APPL NUMER HARMON AN, P543, DOI 10.1007/978-3-7643-7778-6_40; Yang ZH, 2006, PATTERN RECOGN LETT, V27, P1692, DOI 10.1016/j.patrec.2006.03.002; Yao L, 2009, IEEE IMAGE PROC, P73, DOI 10.1109/ICIP.2009.5414102; Zheng T., PATTERN REC IN PRESS	44	21	22	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2147	2157		10.1109/TPAMI.2012.16	http://dx.doi.org/10.1109/TPAMI.2012.16			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	23289129				2022-12-18	WOS:000308755000007
J	Sizintsev, M; Wildes, RP				Sizintsev, Mikhail; Wildes, Richard P.			Spatiotemporal Stereo and Scene Flow via Stequel Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; motion; spacetime; spatiotemporal; scene flow; quadric element; stequel	SPACETIME STEREO; MOTION; DEPTH; SHAPE; MAPS	This paper is concerned with the recovery of temporally coherent estimates of 3D structure and motion of a dynamic scene from a sequence of binocular stereo images. A novel approach is presented based on matching of spatiotemporal quadric elements (stequels) between views, as this primitive encapsulates both spatial and temporal image structure for 3D estimation. Match constraints are developed for bringing stequels into correspondence across binocular views. With correspondence established, temporally coherent disparity estimates are obtained without explicit motion recovery. Further, the matched stequels also will be shown to support direct recovery of scene flow estimates. Extensive algorithmic evaluation with ground truth data incorporated in both local and global correspondence paradigms shows the considerable benefit of using stequels as a matching primitive and its advantages in comparison to alternative methods of enforcing temporal coherence in disparity estimation. Additional experiments document the usefulness of stequel matching for 3D scene flow estimation.	[Sizintsev, Mikhail; Wildes, Richard P.] York Univ, Dept Comp Sci & Engn, Toronto, ON M3J 1P3, Canada; [Sizintsev, Mikhail; Wildes, Richard P.] York Univ, Ctr Vis Res, Toronto, ON M3J 1P3, Canada	York University - Canada; York University - Canada	Sizintsev, M (corresponding author), York Univ, Dept Comp Sci & Engn, 4700 Keele St, Toronto, ON M3J 1P3, Canada.	sizints@cse.yorku.ca; wildes@cse.yorku.ca			CRD; NSERC; MDA Space Missions	CRD; NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); MDA Space Missions	This work was supported by a CRD grant to R. Wildes, as funded by NSERC and MDA Space Missions.	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bigun J., 1998, VISION DIRECTION; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Cannons KJ, 2010, LECT NOTES COMPUT SC, V6314, P511, DOI 10.1007/978-3-642-15561-1_37; Chomat O, 2000, LECT NOTES COMPUT SC, V1842, P487; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; Demirdjian D, 2002, INT J COMPUT VISION, V47, P219, DOI 10.1023/A:1014502126337; Derpanis K., 2010, P IEEE C COMP VIS PA; Derpanis K., 2009, P IEEE C COMP VIS PA; Derpanis K.G., 2006, P IEEE INT VEH S; Derpanis KG, 2005, IEEE IMAGE PROC, P2777; Dollar P., 2005, P IEEE INT WORKSH VI; FAHLE M, 1981, PROC R SOC SER B-BIO, V213, P451, DOI 10.1098/rspb.1981.0075; Fiala M, 2005, PROC CVPR IEEE, P590; Franke U, 2005, LECT NOTES COMPUT SC, V3663, P216; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gong ML, 2006, LECT NOTES COMPUT SC, V3953, P564, DOI 10.1007/11744078_44; Granlund G.H., 1995, SIGNAL PROCESSING CO; Hanna K. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P357, DOI 10.1109/ICCV.1993.378192; Heeger D., 1997, J OPT SOC AM A, V4, P1455; Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000; Isard M, 2006, LECT NOTES COMPUT SC, V3852, P32; JENKIN M, 1986, COMPUT VISION GRAPH, V33, P16, DOI 10.1016/0734-189X(86)90219-7; JONES DG, 1992, LECT NOTES COMPUT SC, V588, P395; Klaser A, 2008, BMVC 2008, P271; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; KORN GA, 1976, MATH HDB SCI ENG; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Larsen E. S., 2007, ICCV, P1; Leung C, 2004, INT C PATT RECOG, P72, DOI 10.1109/ICPR.2004.1333708; Malassiotis S, 1997, COMPUT VIS IMAGE UND, V65, P79, DOI 10.1006/cviu.1996.0481; Mandelbaum R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P544, DOI 10.1109/ICCV.1999.791270; Medioni G, 2000, P 12 C FRANC AFRIF A; Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429; Pons JP, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P597; RICHARDS W, 1985, J OPT SOC AM A, V2, P343, DOI 10.1364/JOSAA.2.000343; Scharr H, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P220, DOI 10.1109/MOTION.2002.1182240; Scharr H., 2006, P VIS MOD VIS 06, P81; Scharstein D, 2003, PROC CVPR IEEE, P195; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Sizintsev M., 2009, P IEEE C COMP VIS PA; Sizintsev M., 2008, CS200804 YORK U; Sizintsev M, 2010, IMAGE VISION COMPUT, V28, P352, DOI 10.1016/j.imavis.2009.06.008; Stein GP, 1998, PROC CVPR IEEE, P211, DOI 10.1109/CVPR.1998.698611; Strang G., 1986, INTRO APPL MATH; Strecha C, 2002, LECT NOTES COMPUT SC, V2351, P170; SUDHIR G, 1995, J OPT SOC AM A, V12, P2564, DOI 10.1364/JOSAA.12.002564; Vedula S, 2000, PROC CVPR IEEE, P592, DOI 10.1109/CVPR.2000.854926; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853; WENG JY, 1992, IEEE T ROBOTIC AUTOM, V8, P362, DOI 10.1109/70.143354; Williams O, 2005, PROC CVPR IEEE, P250; Zaharescu A., 2010, P 11 EUR C COMP VIS; Zhang L, 2003, PROC CVPR IEEE, P367; Zhang Y, 2001, PROC CVPR IEEE, P778; ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394	56	21	23	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1206	1219		10.1109/TPAMI.2011.202	http://dx.doi.org/10.1109/TPAMI.2011.202			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22516652				2022-12-18	WOS:000302916600013
J	Muhlich, M; Friedrich, D; Aach, T				Muehlich, Matthias; Friedrich, David; Aach, Til			Design and Implementation of Multisteerable Matched Filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Steerable filters; feature detection; junction analysis; orientation estimation; rotated matched filtering; multi-oriented patterns; template equation; trigonometric polynomials; multivariate polynomials; camera calibration		Image analysis problems such as feature tracking, edge detection, image enhancement, or texture analysis require the detection of multi-oriented patterns which can appear at arbitrary orientations. Direct rotated matched filtering for feature detection is computationally expensive, but can be sped up with steerable filters. So far, steerable filter approaches were limited to only one direction. Many important low-level image features are, however, characterized by more than a single orientation. We therefore present here a framework for efficiently detecting specific multi-oriented patterns with arbitrary orientations in grayscale images. The core idea is to construct multisteerable filters by appropriate combinations of single-steerable filters. We exploit that steerable filters are closed under addition and multiplication. This allows to derive a design guide for multisteerable filters by means of multivariate polynomials. Furthermore, we describe an efficient implementation scheme and discuss the use of weighting functions to reduce angular oscillations. Applications in camera calibration, junction analysis of images from plant roots, and the discrimination of L, T, and X-junctions demonstrate the potential of this approach.	[Muehlich, Matthias] CanControls, D-52074 Aachen, Germany; [Friedrich, David; Aach, Til] Rhein Westfal TH Aachen, Inst Imaging & Comp Vis, D-52056 Aachen, Germany	RWTH Aachen University	Muhlich, M (corresponding author), CanControls, Vaalser Str 259, D-52074 Aachen, Germany.	muehlich@cancontrols.com; david.friedrich@lfb.rwth-aachen.de; til.aach@lfb.rwth-aachen.de			Deutsche Forschungsgemeinschaft (DFG) [AA5/3-1]	Deutsche Forschungsgemeinschaft (DFG)(German Research Foundation (DFG))	This work was funded by the Deutsche Forschungsgemeinschaft (DFG, AA5/3-1). Parts of this work were presented at IEEE ICIP 2007, San Antonio, EUSIPCO 2007, Poznan, and Mustererkennung 2007, Heidelberg.	Aach T, 2006, IEEE T IMAGE PROCESS, V15, P3690, DOI 10.1109/TIP.2006.884921; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; Bouguet J-Y, 1999, THESIS CALIFORNIA I; DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Hel-Or Y., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P337, DOI 10.1109/ISCAS.1998.694484; HelOr Y, 1996, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.1996.517165; Iso T., 1993, Proceedings of the SPIE - The International Society for Optical Engineering, V2094, P1185, DOI 10.1117/12.157875; Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Katznelson Y., 1976, INTRO HARMONIC ANAL, VCorrected; Michaelis M., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P101; MICHAELIS M, 1995, PATTERN RECOGN LETT, V16, P1165, DOI 10.1016/0167-8655(95)00066-P; Muhlich M, 2008, LECT NOTES COMPUT SC, V5096, P497, DOI 10.1007/978-3-540-69321-5_50; Muhlich M, 2007, LECT NOTES COMPUT SC, V4713, P284; Muhlich M, 2009, IEEE T IMAGE PROCESS, V18, P1424, DOI 10.1109/TIP.2009.2019307; MUHLICH M, 2007, P IEEE INT C IM PROC; Muhlich M., 2006, P EUR C COMP VIS, P69; Mulich M., 2007, P 15 EUR SIGN PROC C; Nagel KA, 2009, FUNCT PLANT BIOL, V36, P947, DOI 10.1071/FP09184; Oppenheim A.V., 1999, DISCRETE TIME SIGNAL; PERONA P, 1992, LECT NOTES COMPUT SC, V588, P3, DOI 10.1016/0262-8856(92)90011-Q; Shizawa M., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P274, DOI 10.1109/ICPR.1990.118111; Shizawa M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P289, DOI 10.1109/CVPR.1991.139704; Simoncelli EP, 1996, IEEE T IMAGE PROCESS, V5, P1377, DOI 10.1109/83.535851; SIMONCELLI EP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P189, DOI 10.1109/ICCV.1995.466787; Yu WC, 1998, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.1998.698635; Yu WC, 2001, IEEE T IMAGE PROCESS, V10, P193, DOI 10.1109/83.902274; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	32	21	22	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					279	291		10.1109/TPAMI.2011.143	http://dx.doi.org/10.1109/TPAMI.2011.143			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21768652				2022-12-18	WOS:000298105500007
J	Albanese, M; Chellappa, R; Cuntoor, N; Moscato, V; Picariello, A; Subrahmanian, VS; Udrea, O				Albanese, Massimiliano; Chellappa, Rama; Cuntoor, Naresh; Moscato, Vincenzo; Picariello, Antonio; Subrahmanian, V. S.; Udrea, Octavian			PADS: A Probabilistic Activity Detection Framework for Video Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Applications and expert knowledge-intensive systems; computer vision; vision and scene understanding; video analysis; image processing and computer vision; applications	HIDDEN MARKOV-MODELS; REPRESENTATION; RECOGNITION	There is now a growing need to identify various kinds of activities that occur in videos. In this paper, we first present a logical language called Probabilistic Activity Description Language (PADL) in which users can specify activities of interest. We then develop a probabilistic framework which assigns to any subvideo of a given video sequence a probability that the subvideo contains the given activity, and we finally develop two fast algorithms to detect activities within this framework. OffPad finds all minimal segments of a video that contain a given activity with a probability exceeding a given threshold. In contrast, the OnPad algorithm examines a video during playout (rather than afterwards as OffPad does) and computes the probability that a given activity is occurring (even if the activity is only partially complete). Our prototype Probabilistic Activity Detection System (PADS) implements the framework and the two algorithms, building on top of existing image processing algorithms. We have conducted detailed experiments and compared our approach to four different approaches presented in the literature. We show that-for complex activity definitions-our approach outperforms all the other approaches.	[Albanese, Massimiliano; Chellappa, Rama; Subrahmanian, V. S.] Univ Maryland, Inst Adv Comp Studies, Dept Comp Sci, College Pk, MD 20742 USA; [Cuntoor, Naresh] Kitware Inc, Clifton Pk, NY 12065 USA; [Moscato, Vincenzo; Picariello, Antonio] Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy; [Udrea, Octavian] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA	University System of Maryland; University of Maryland College Park; University of Naples Federico II; International Business Machines (IBM)	Albanese, M (corresponding author), Univ Maryland, Inst Adv Comp Studies, Dept Comp Sci, College Pk, MD 20742 USA.	albanese@umiacs.umd.edu; rama@umiacs.umd.edu; nareshpc@ieee.org; vmoscato@unina.it; picus@unina.it; vs@umiacs.umd.edu; oudrea@us.ibm.com	Moscato, Vincenzo/H-2526-2012; Picariello, Antonio/G-9062-2012; Picariello, Antonio/L-6820-2015; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; Subrahmanian, Venkatramanan/ABA-7399-2021	Picariello, Antonio/0000-0003-4804-1007; Moscato, Vincenzo/0000-0002-0754-7696; Albanese, Massimiliano/0000-0002-2675-5810	US Air Force Office of Scientific Research [FA95500510298]; US Army Research Office [DAAD190310202]; US National Science Foundation [IIS0329851, 0205489]	US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); US Army Research Office; US National Science Foundation(National Science Foundation (NSF))	Part of this work was supported by the US Air Force Office of Scientific Research under Grant Nr. FA95500510298, by US Army Research Office grant number DAAD190310202, and by US National Science Foundation grants IIS0329851 and 0205489.	Albanese M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1802; ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Buchanan M. C., 1993, Proceedings ACM Multimedia 93, P341, DOI 10.1145/166266.168415; Candan KS, 2000, VLDB J, V9, P131, DOI 10.1007/PL00010673; Chittaro L, 2000, ANN MATH ARTIF INTEL, V28, P47, DOI 10.1023/A:1018900105153; Cuntoor NP, 2008, IEEE T IMAGE PROCESS, V17, P594, DOI 10.1109/TIP.2008.916991; Cuntoor NP, 2006, LECT NOTES COMPUT SC, V3852, P499; DECHTER R, 1991, ARTIF INTELL, V49, P61, DOI 10.1016/0004-3702(91)90006-6; Fagin R, 1999, J COMPUT SYST SCI, V58, P83, DOI 10.1006/jcss.1998.1600; Francois ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87; Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263; Hamid R, 2005, PROC CVPR IEEE, P1031; HAMID R, 2003, P IEEE COMP VIS PATT, V4, P38; Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005; Hongeng S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P84, DOI 10.1109/ICCV.2001.937608; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; IZO T, 2004, P IEEE WORKSH MOT NO, V1, P14; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; KOWALSKI R, 1986, NEW GENERAT COMPUT, V4, P67, DOI 10.1007/BF03037383; Li XK, 2004, IEEE IMAGE PROC, P2901; Marcus S, 1996, J ACM, V43, P474, DOI 10.1145/233551.233554; NATARAJAN P, 2005, P 10 IEEE INT C COMP, P1876; Oliver N, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P3, DOI 10.1109/ICMI.2002.1166960; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Rogers Jr H., 1987, THEORY RECURSIVE FUN; Shipley T. F., 2008, UNDERSTANDING EVENTS; Shoenfield Joseph R., 1967, MATH LOGIC; SIEBEL NT, 2003, THESIS READING U; Siebel NT, 2004, P ECCV 2004 WORKSH A, P103; Starner T., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P265, DOI 10.1109/ISCV.1995.477012; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Town C, 2004, IMAGE VISION COMPUT, V22, P251, DOI 10.1016/j.imavis.2003.10.002; Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197; VU VT, 2003, P 18 INT JOINT C ART, P1295; Wang F, 2004, IEEE IMAGE PROC, P633; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Zhong H, 2004, PROC CVPR IEEE, P819	38	21	22	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2246	2261		10.1109/TPAMI.2010.33	http://dx.doi.org/10.1109/TPAMI.2010.33			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20975121				2022-12-18	WOS:000283558700010
J	Chertok, M; Keller, Y				Chertok, Michael; Keller, Yosi			Spectral Symmetry Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; symmetry detection; optimization; spectral relaxation	CLASSIFICATION; FEATURES; TEXTURE; SCALE	We present a spectral approach for detecting and analyzing rotational and reflectional symmetries in n-dimensions. Our main contribution is the derivation of a symmetry detection and analysis scheme for sets of points in R-n and its extension to image analysis by way of local features. Each object is represented by a set of points S is an element of R-n, where the symmetry is manifested by the multiple self-alignments of S. The alignment problem is formulated as a quadratic binary optimization problem, with an efficient solution via spectral relaxation. For symmetric objects, this results in a multiplicity of eigenvalues whose corresponding eigenvectors allow the detection and analysis of both types of symmetry. We improve the scheme's robustness by incorporating geometrical constraints into the spectral analysis. Our approach is experimentally verified by applying it to 2D and 3D synthetic objects as well as real images.	[Chertok, Michael; Keller, Yosi] Bar Ilan Univ, Sch Engn, Ramat Gan, Israel	Bar Ilan University	Chertok, M (corresponding author), Bar Ilan Univ, Sch Engn, Ramat Gan, Israel.	michael.chertok@gmail.com; yosi.keller@gmail.com						Arbib MA, 1995, HDB BRAIN THEORY NEU; Berg AC, 2005, PROC CVPR IEEE, P26; BioID Technology Research, 2001, BIOID FAC DAT; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Chen S, 2001, P INT C IM PROC, V3, P756; Cornelis C, 2007, IEEE T FUZZY SYST, V15, P161, DOI 10.1109/TFUZZ.2006.881444; Cour T., 2007, P ADV NEURAL INFORM, P313; Coxeter HSM., 1969, INTRO GEOMETRY; Derrode S, 2004, SIGNAL PROCESS, V84, P25, DOI 10.1016/j.sigpro.2003.07.006; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley R., 2004, ROBOTICA; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; Kazhdan M, 2002, LECT NOTES COMPUT SC, V2351, P642; Keller Y, 2006, IEEE T IMAGE PROCESS, V15, P2198, DOI 10.1109/TIP.2006.875227; Kim WY, 1999, IEEE T PATTERN ANAL, V21, P768, DOI 10.1109/34.784290; Kiryati N, 1998, INT J COMPUT VISION, V29, P29, DOI 10.1023/A:1008034529558; LEE S, 2008, P IEEE COMP VIS PATT; Lei YW, 1999, PATTERN RECOGN, V32, P167, DOI 10.1016/S0031-3203(98)00135-6; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Lucchese L, 2004, PATTERN RECOGN, V37, P2263, DOI 10.1016/j.patcog.2004.04.012; Martinet A, 2006, ACM T GRAPHIC, V25, P439, DOI 10.1145/1138450.1138462; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Miller W., 1972, SYMMETRY GROUPS THEI; Nilsback M.E., 2006, P 2006 IEEE COMP VIS; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Park M., 2008, P COMP VIS PATT REC; PRASAD LSN, 2005, P 10 IEEE INT C COMP, V2, P954; Prasad VSN, 2004, IEEE T IMAGE PROCESS, V13, P1559, DOI 10.1109/TIP.2004.837564; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; Shen DG, 2001, PATTERN RECOGN, V34, P1417, DOI 10.1016/S0031-3203(00)00079-0; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; TANG F, 2005, P 2 JOINT IEEE INT W, P25; TRUCCO E, 1998, INTRO TECHNIQUES 3D, P333; VALSTAR M, 2006, P IEEE INT C COMP VI, V3; Weyl H., 1952, SYMMETRY; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	44	21	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1227	1238		10.1109/TPAMI.2009.121	http://dx.doi.org/10.1109/TPAMI.2009.121			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489226				2022-12-18	WOS:000277649100006
J	Liu, XQ; Veksler, O; Samarabandu, J				Liu, Xiaoqing; Veksler, Olga; Samarabandu, Jagath			Order-Preserving Moves for Graph-Cut-Based Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Energy minimization; graph cuts; max-flow; SVM; geometric class labeling; shape prior	ENERGY MINIMIZATION	In the last decade, graph-cut optimization has been popular for a variety of labeling problems. Typically, graph-cut methods are used to incorporate smoothness constraints on a labeling, encouraging most nearby pixels to have equal or similar labels. In addition to smoothness, ordering constraints on labels are also useful. For example, in object segmentation, a pixel with a "car wheel" label may be prohibited above a pixel with a "car roof" label. We observe that the commonly used graph-cut alpha-expansion move algorithm is more likely to get stuck in a local minimum when ordering constraints are used. For a certain model with ordering constraints, we develop new graph-cut moves which we call order-preserving. The advantage of order-preserving moves is that they act on all labels simultaneously, unlike alpha-expansion. More importantly, for most labels alpha, the set of alpha-expansion moves is strictly smaller than the set of order-preserving moves. This helps to explain why in practice optimization with order-preserving moves performs significantly better than alpha-expansion in the presence of ordering constraints. We evaluate order-preserving moves for the geometric class scene labeling (introduced by Hoiem et al.) where the goal is to assign each pixel a label such as "sky," "ground," etc., so ordering constraints arise naturally. In addition, we use order-preserving moves for certain simple shape priors in graph-cut segmentation, which is a novel contribution in itself.	[Liu, Xiaoqing] UtopiaCompression Corp, Los Angeles, CA 90064 USA; [Veksler, Olga] Univ Western Ontario, Middlesex Coll 361, Dept Comp Sci, London, ON N6A 5B7, Canada; [Samarabandu, Jagath] Univ Western Ontario, Dept Elect & Comp Engn, London, ON N6A 5B9, Canada	Western University (University of Western Ontario); Western University (University of Western Ontario)	Liu, XQ (corresponding author), UtopiaCompression Corp, 11150 W Olymp Blvd,Suite 680, Los Angeles, CA 90064 USA.	xliu65@alumni.uwo.ca; olga@csd.uwo.ca; jagath@uwo.ca	Veksler, Olga/B-6549-2015	Veksler, Olga/0000-0002-9664-6601				[Anonymous], 2006, P 2006 IEEE COMP SOC, DOI DOI 10.1109/CVPR.2006.23; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Coughlan J.M., 1999, P INT C COMP VIS; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; Darbon J., 2008, P 12 INT WORKSH COMB; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Ford L. R. J., 1962, FLOWS NETWORKS; Freedman D, 2005, PROC CVPR IEEE, P755; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; HORRY Y, 1997, P ACM SIGGRAPH, V3, P225; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; KEUCHEL J, 2006, P EUR C COMP VIS, V2, P454; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kumar MP, 2005, PROC CVPR IEEE, P18; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; LIU X, 2008, P C COMP VIS PATT RE; Platt J., 1999, ADV LARGE MARGIN CLA; RAMALINGAM S, 2008, P IEEE CS C COMP VIS; ROUSSON M, 2002, P EUR C COMP VIS, P416; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; SCHLENKER B, 2006, EUR UROL, V6, P1; Shum HY, 1998, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.1998.698641; Stein A, 2007, IEEE I CONF COMP VIS, P110; Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VEKSLER O, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383249; Winn J., 2006, CVPR; Wu TF, 2004, J MACH LEARN RES, V5, P975; YEDIDIA J, 2001, P WORKSH STAT COMP T	38	21	23	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1182	1196		10.1109/TPAMI.2009.120	http://dx.doi.org/10.1109/TPAMI.2009.120			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489223	Green Submitted			2022-12-18	WOS:000277649100003
J	Pruteanu-Malinici, I; Ren, L; Paisley, J; Wang, E; Carin, L				Pruteanu-Malinici, Iulian; Ren, Lu; Paisley, John; Wang, Eric; Carin, Lawrence			Hierarchical Bayesian Modeling of Topics in Time-Stamped Documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchical models; variational Bayes; Dirichlet process; text modeling		We consider the problem of inferring and modeling topics in a sequence of documents with known publication dates. The documents at a given time are each characterized by a topic and the topics are drawn from a mixture model. The proposed model infers the change in the topic mixture weights as a function of time. The details of this general framework may take different forms, depending on the specifics of the model. For the examples considered here, we examine base measures based on independent multinomial-Dirichlet measures for representation of topic-dependent word counts. The form of the hierarchical model allows efficient variational Bayesian inference, of interest for large-scale problems. We demonstrate results and make comparisons to the model when the dynamic character is removed, and also compare to latent Dirichlet allocation (LDA) and Topics over Time (TOT). We consider a database of Neural Information Processing Systems papers as well as the US Presidential State of the Union addresses from 1790 to 2008.	[Pruteanu-Malinici, Iulian; Ren, Lu; Paisley, John; Wang, Eric; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Duke University	Pruteanu-Malinici, I (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	ip6@ee.duke.edu; lr@ee.duke.edu; jwp4@ee.duke.edu; ew28@ee.duke.edu; lcarin@ee.duke.edu	Paisley, John/AAF-8586-2019	Carin, Lawrence/0000-0001-6277-7948				AN Q, 2008, P 25 INT C MACH LEAR; Beal M.J., 2003, VARIATIONAL ALGORITH; Blei D.M., 2006, P 23 INT C MACH LEAR, P113, DOI [10.1145/1143844.1143859, DOI 10.1145/1143844.1143859, 10.1145/1143844.114385]; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BLEI DM, 2004, P 21 INT C MACH LEAR; CANNY JF, 2006, DYNAMIC TOPIC MODEL; Dunson DB, 2008, BIOMETRIKA, V95, P307, DOI 10.1093/biomet/asn012; Dunson DB, 2006, BIOSTATISTICS, V7, P551, DOI 10.1093/biostatistics/kxj025; Gruber A., 2007, P INT C ART INT STAT; Hofmann T., 1999, P C UNC ART INT; ISHWARAN J, 2001, J AM STAT ASSOC, V96; PARK JH, 2009, STAT SINICA; Pennell ML, 2006, BIOMETRICS, V62, P1044, DOI 10.1111/j.1541-0420.2006.00571.x; Ren L., 2008, P 25 INT C MACHINE L; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Srebro N., 2005, TIME VARYING TOPIC M; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; VANRIJSBERGEN CJ, 1979, INFORM RETRIEVAL, V6, P111; Wang X., 2006, P 12 ACM SIGKDD INT, P424; WELLING M, 2007, P INT C NEUR INF PRO; Winn J, 2005, J MACH LEARN RES, V6, P661; Zhang J., 2004, P NEUR INF PROC SYST	23	21	26	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					996	1011		10.1109/TPAMI.2009.125	http://dx.doi.org/10.1109/TPAMI.2009.125			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431127				2022-12-18	WOS:000276671900004
J	Saenko, K; Livescu, K; Glass, J; Darrell, T				Saenko, Kate; Livescu, Karen; Glass, James; Darrell, Trevor			Multistream Articulatory Feature-Based Models for Visual Speech Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual speech recognition; articulatory features; dynamic Bayesian networks; support vector machines		We study the problem of automatic visual speech recognition (VSR) using dynamic Bayesian network (DBN)-based models consisting of multiple sequences of hidden states, each corresponding to an articulatory feature (AF) such as lip opening (LO) or lip rounding (LR). A bank of discriminative articulatory feature classifiers provides input to the DBN, in the form of either virtual evidence (VE) (scaled likelihoods) or raw classifier margin outputs. We present experiments on two tasks, a medium-vocabulary word-ranking task and a small-vocabulary phrase recognition task. We show that articulatory feature-based models outperform baseline models, and we study several aspects of the models, such as the effects of allowing articulatory asynchrony, of using dictionary-based versus whole-word models, and of incorporating classifier outputs via virtual evidence versus alternative observation models.	[Saenko, Kate; Glass, James] MIT Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Livescu, Karen] Toyota Technol Inst Chicago, Chicago, IL 60637 USA; [Darrell, Trevor] Univ Calif Berkeley, CS Div, Berkeley, CA 94704 USA; [Darrell, Trevor] Int Comp Sci Inst ICSI, Berkeley, CA 94704 USA	Massachusetts Institute of Technology (MIT); Toyota Technological Institute - Chicago; University of California System; University of California Berkeley	Saenko, K (corresponding author), MIT Comp Sci & Artificial Intelligence Lab, 32 Vassar St,32-D510, Cambridge, MA 02139 USA.	saenko@csail.mit.edu; klivescu@uchicago.edu; glass@mit.edu; trevor@eecs.berkeley.edu			US Defense Advanced Research Projects Agency (DARPA); ITRI	US Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); ITRI	This work was supported by the US Defense Advanced Research Projects Agency (DARPA) and ITRI.	[Anonymous], 1998, STAT METHODS SPEECH; BILMES J, 2009, GRAPHICAL MODELS TOO; BILMES J, 2004, UWEETR200400016 U WA; Bilmes JA, 2005, IEEE SIGNAL PROC MAG, V22, P89, DOI 10.1109/MSP.2005.1511827; BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913; CETIN O, 2007, P INT C AC SPEECH SI; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Dean T., 1989, Computational Intelligence, V5, P142, DOI 10.1111/j.1467-8640.1989.tb00324.x; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deng L, 1997, SPEECH COMMUN, V22, P93, DOI 10.1016/S0167-6393(97)00018-6; Glass J. R, 2004, P 6 INT C MULT INT A, P152, DOI [10.1145/1027933.1027960, DOI 10.1145/1027933.1027960]; Gordan M, 2002, EURASIP J APPL SIG P, V2002, P1248, DOI 10.1155/S1110865702207039; GRAVIER G, 2002, P HUM LANG TECHN C, P1006; HASEGAWAJOHNSON M, 2007, P INT C PHON SCI AUG; Hazen T. J., 2004, P 6 INT C MULT INT I, P235, DOI DOI 10.1145/1027933.1027972; King S, 2000, COMPUT SPEECH LANG, V14, P333, DOI 10.1006/csla.2000.0148; King S, 2007, J ACOUST SOC AM, V121, P723, DOI 10.1121/1.2404622; Kirchhoff K, 2002, SPEECH COMMUN, V37, P303, DOI 10.1016/S0167-6393(01)00020-6; KRONE G, 1997, P EUR TUT WORKS AUD, P57; LIVESCU K, 2004, P HUM LANG TECHN C N; LIVESCU K, 2004, P ICSLP JEJ S KOR, P677; LIVESCU K, 2007, JHU SUMM WORKSH FIN; MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0; MORGANTI R, 1995, PUBL ASTRON SOC AUST, V12, P3, DOI 10.1017/S1323358000019962; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; Nefian AV, 2002, INT CONF ACOUST SPEE, P2013; NIYOGI P, 1999, P INT C AUD VIS SPEE; Nock HJ, 2002, COGNITIVE SCI, V26, P283, DOI 10.1207/s15516709cog2603_5; Pan H, 2004, IEEE T SIGNAL PROCES, V52, P573, DOI 10.1109/TSP.2003.822353; PETAJAN ED, 1984, P IEEE GLOB TEL C AT, P265; Platt JC, 2000, ADV NEUR IN, P61; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; Richardson M, 2003, SPEECH COMMUN, V41, P511, DOI 10.1016/S0167-6393(03)00031-1; Saenko K, 2005, IEEE I CONF COMP VIS, P1424, DOI 10.1109/ICCV.2005.251; SAENKO K, 2005, P INT C AC SPEECH SI; ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7; ZWEIG G, 1998, THESIS U CALIFORNIA	38	21	26	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1700	1707		10.1109/TPAMI.2008.303	http://dx.doi.org/10.1109/TPAMI.2008.303			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574628	Green Published, Green Submitted			2022-12-18	WOS:000267369800012
J	Zhong, BJ; Ma, KK; Liao, WH				Zhong, Baojiang; Ma, Kai-Kuang; Liao, Wenhe			Scale-Space Behavior of Planar-Curve Corners	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scale space; corner detection; curve evolution; CSS; digital curves; curvature; discrete curvature; shrinkage rate; evolution trajectory; dual trajectory	HEAT-EQUATION; SHAPE; MULTISCALE; DIFFUSION; RETRIEVAL	The curvature scale-space (CSS) technique is suitable for extracting curvature features from objects with noisy boundaries. To detect corner points in a multiscale framework, Rattarangsi and Chin investigated the scale-space behavior of planar-curve corners. Unfortunately, their investigation was based on an incorrect assumption, viz., that planar curves have no shrinkage under evolution. In the present paper, this mistake is corrected. First, it is demonstrated that a planar curve may shrink nonuniformly as it evolves across increasing scales. Then, by taking into account the shrinkage effect of evolved curves, the CSS trajectory maps of various corner models are investigated and their properties are summarized. The scale-space trajectory of a corner may either persist, vanish, merge with a neighboring trajectory, or split into several trajectories. The scale-space trajectories of adjacent corners may attract each other when the corners have the same concavity, or repel each other when the corners have opposite concavities. Finally, we present a standard curvature measure for computing the CSS maps of digital curves, with which it is shown that planar-curve corners have consistent scale-space behavior in the digital case as in the continuous case.	[Zhong, Baojiang] Nanjing Univ Aeronaut & Astronaut, Dept Math, Nanjing 210016, Peoples R China; [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Liao, Wenhe] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China	Nanjing University of Aeronautics & Astronautics; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanjing University of Aeronautics & Astronautics	Zhong, BJ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Math, Nanjing 210016, Peoples R China.	zhbj@nuaa.edu.cn; ekkma@ntu.edu.sg; njwho@nuaa.edu.cn		Zhong, Baojiang/0000-0002-9899-524X	US Defense Advanced Research Projects Agency (DARPA) [M48680021]; National Science Foundation of China [60705014]	US Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research was funded in part by the US Defense Advanced Research Projects Agency (DARPA) under grant M48680021 and the National Science Foundation of China under grant 60705014. The authors are grateful to the anonymous reviewers and Professor Kaleem Siddiqi for their insightful comments and helpful suggestions. The term pitchfork as described in Section 2.2 was suggested by one of the reviewers. B. Zhong was with the Temasek Laboratories, Nanyang Technological University, Singapore, when this research was conducted.	BALMASHNOVA E, 2007, P IEEE 11 INT C COMP, P1; Beau V, 2001, PATTERN RECOGN, V34, P287, DOI 10.1016/S0031-3203(99)00221-6; BLOM J, 1992, THESIS U UTRECHT; Bruce JW, 1984, CURVES SINGULARITIES; Cui M, 2007, VISUAL COMPUT, V23, P607, DOI 10.1007/s00371-007-0164-1; DAMON J, 1995, J DIFFER EQUATIONS, V115, P368, DOI 10.1006/jdeq.1995.1019; FERMULLER C, 1994, IEEE T PATTERN ANAL, V16, P748, DOI 10.1109/34.297957; Florack L, 2000, J MATH IMAGING VIS, V12, P65, DOI 10.1023/A:1008304909717; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Kimia BB, 1996, COMPUT VIS IMAGE UND, V64, P305, DOI 10.1006/cviu.1996.0062; Kuijper A, 2004, INT J COMPUT VISION, V57, P67, DOI 10.1023/B:VISI.0000013091.14851.24; Leitao HCD, 2002, IEEE T PATTERN ANAL, V24, P1239, DOI 10.1109/TPAMI.2002.1033215; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahmoudi S, 2007, PATTERN RECOGN LETT, V28, P1705, DOI 10.1016/j.patrec.2007.04.012; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F, 2004, IEEE T IMAGE PROCESS, V13, P653, DOI 10.1109/TIP.2004.826126; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; Mokhtarian F., 2003, CURVATURE SCALE SPAC; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; RAY BK, 1995, PATTERN RECOGN, V28, P1765, DOI 10.1016/0031-3203(95)00046-3; Roh MC, 2006, LECT NOTES COMPUT SC, V3954, P347; Romeny B. t. H., 2003, FRONT END VISION MUL; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193; Sporring J, 2000, IMAGE VISION COMPUT, V18, P261, DOI 10.1016/S0262-8856(99)00017-7; Super BJ, 2002, COMPUT VIS IMAGE UND, V85, P1, DOI 10.1006/cviu.2002.0959; Tissainayagam P, 2005, PATTERN RECOGN, V38, P105, DOI 10.1016/j.patcog.2004.05.011; Tu CL, 2005, IEEE T INFORM THEORY, V51, P1049, DOI 10.1109/TIT.2004.842706; WEISSTEIN EW, 2009, WOLFRAM MATHWORLD; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006; Zhang XH, 2009, PATTERN RECOGN LETT, V30, P449, DOI 10.1016/j.patrec.2008.11.002; Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50	36	21	26	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1517	1524		10.1109/TPAMI.2008.295	http://dx.doi.org/10.1109/TPAMI.2008.295			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542584				2022-12-18	WOS:000267050600014
J	Garcia-Garcia, D; Hernandez, EP; Diaz-de Maria, F				Garcia-Garcia, Dario; Parrado Hernandez, Emilio; Diaz-de Maria, Fernando			A New Distance Measure for Model-Based Sequence Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; sequential data; similarity measures		We review the existing alternatives for defining model-based distances for clustering sequences and propose a new one based on the Kullback-Leibler divergence. This distance is shown to be especially useful in combination with spectral clustering. For improved performance in real-world scenarios, a model selection scheme is also proposed.	[Garcia-Garcia, Dario; Parrado Hernandez, Emilio; Diaz-de Maria, Fernando] Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid 28911, Spain	Universidad Carlos III de Madrid	Garcia-Garcia, D (corresponding author), Univ Carlos III Madrid, Dept Signal Theory & Commun, Avda Univ 30, Madrid 28911, Spain.	dggarcia@tsc.uc3m.es; emipar@tsc.uc3m.es; fdiaz@tsc.uc3m.es	PARRADO-HERNANDEZ, EMILIO/ABH-2027-2020; de María, Fernando Díaz/E-8048-2011; Hernández, Fernando Javier Pérez/AAA-1466-2019	PARRADO-HERNANDEZ, EMILIO/0000-0003-2146-2135; de María, Fernando Díaz/0000-0002-6437-914X; Hernández, Fernando Javier Pérez/0000-0002-7249-7496	Spanish Government CICYT [TEC2008-02473, TEC2008-06382]	Spanish Government CICYT(Consejo Interinstitucional de Ciencia y Tecnologia (CICYT))	This research was conducted with support from Spanish Government CICYT grants TEC2008-02473 and TEC2008-06382. The authors would like to thank the anonymous reviewers and the associate editor for their valuable comments and suggestions that helped to improve the manuscript.	Baldi P., 1998, BIOINFORMATICS MACHI; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Jebara T., 2007, P 18 EUR C MACH LEAR; Jin GY, 2004, LECT NOTES COMPUT SC, V3211, P605; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; JUANG BH, 1985, AT&T TECH J, V64, P391, DOI 10.1002/j.1538-7305.1985.tb00439.x; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; Ng A.Y., 2002, ADV NEURAL INFORM PR; Oates T., 2001, Sequence learning. Paradigms, algorithms, and applications (Lecture Notes in Artificial Intelligence Vol.1828), P35; Ortega-Garcia J, 2000, SPEECH COMMUN, V31, P255, DOI 10.1016/S0167-6393(99)00081-3; PANUCCIO A, 2002, P JOINT IAPR INT WOR, P734; PORIKLI F, 2004, P INT WORKSH STRUCT, P352; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Smyth P, 1997, ADV NEUR IN, V9, P648; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; YIN J, 2005, P 5 IEEE INT C DAT M; [No title captured]	21	21	22	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1325	U183		10.1109/TPAMI.2008.268	http://dx.doi.org/10.1109/TPAMI.2008.268			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443928	Green Accepted			2022-12-18	WOS:000266188900014
J	Kokiopoulou, E; Frossard, P				Kokiopoulou, Effrosyni; Frossard, Pascal			Minimum Distance between Pattern Transformation Manifolds: Algorithm and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transformation invariance; pattern manifolds; sparse approximations		Transformation invariance is an important property in pattern recognition, where different observations of the same object typically receive the same label. This paper focuses on a transformation-invariant distance measure that represents the minimum distance between the transformation manifolds spanned by patterns of interest. Since these manifolds are typically nonlinear, the computation of the manifold distance (MD) becomes a nonconvex optimization problem. We propose representing a pattern of interest as a linear combination of a few geometric functions extracted from a structured and redundant basis. Transforming the pattern results in the transformation of its constituent parts. We show that, when the transformation is restricted to a synthesis of translations, rotations, and isotropic scalings, such a pattern representation results in a closed-form expression of the manifold equation with respect to the transformation parameters. The MD computation can then be formulated as a minimization problem whose objective function is expressed as the difference of convex functions (DC). This interesting property permits optimally solving the optimization problem with DC programming solvers that are globally convergent. We present experimental evidence which shows that our method is able to find the globally optimal solution, outperforming existing methods that yield suboptimal solutions.	[Kokiopoulou, Effrosyni] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, Swiss Fed Inst Technol, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Kokiopoulou, E (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, Swiss Fed Inst Technol, CH-1015 Lausanne, Switzerland.	effrosyni.kokiopoulou@epfl.ch; pascal.frossard@epfl.ch	Frossard, Pascal/AAF-2268-2019		NCCR IM2	NCCR IM2(Swiss National Science Foundation (SNSF))	The authors would like to thank Dr. Meritxell Bach Cuadra for providing the MRI brain image. This work has been partly supported by NCCR IM2.	An LTH, 2005, ANN OPER RES, V133, P23, DOI 10.1007/s10479-004-5022-1; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Boyd S, 2004, CONVEX OPTIMIZATION; Carli M, 2002, P SOC PHOTO-OPT INS, V4667, P55, DOI 10.1117/12.468017; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DECOSTE D, 2000, P IEEE INT C COMP VI; Ellis S. E., 2003, PHYLOGENETIC ANAL VI; FITZGIBBON A, 2003, P IEEE INT C COMP VI; Graepel T, 2004, ADV NEUR IN, V16, P33; Haasdonk B, 2002, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2002.1048439; Horst R, 1999, J OPTIMIZ THEORY APP, V103, P1, DOI 10.1023/A:1021765131316; HORST R., 1995, HDB GLOBAL OPTIMIZAT; Horst R., 2000, INTRO GLOBAL OPTIMIZ; Jost P, 2006, IEEE T SIGNAL PROCES, V54, P4685, DOI 10.1109/TSP.2006.882080; Keysers D, 2000, INT C PATT RECOG, P38, DOI 10.1109/ICPR.2000.906014; KOKIOPOULOU E, 2007, P IEEE INT WORKSH MU; Mallat S., 1999, WAVELET TOUR SIGNAL; Neri A, 2004, IEEE T IMAGE PROCESS, V13, P72, DOI 10.1109/TIP.2003.818021; Samaria F., 1994, P 2 IEEE WORKSH APPL; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Scholkopf B., 1996, Artificial Neural Networks - ICANN 96. 1996 International Conference Proceedings, P47; Scholkopf B., 2001, LEARNING KERNELS SUP; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; Thevenaz P, 1998, IEEE T IMAGE PROCESS, V7, P27, DOI 10.1109/83.650848; Vasconcelos N, 2005, IEEE T MULTIMEDIA, V7, P127, DOI 10.1109/TMM.2004.840596; Ventura RMFI, 2006, IEEE T IMAGE PROCESS, V15, P726, DOI 10.1109/TIP.2005.860596; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	28	21	22	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1225	1238		10.1109/TPAMI.2008.156	http://dx.doi.org/10.1109/TPAMI.2008.156			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443921	Green Submitted			2022-12-18	WOS:000266188900007
J	Gilboa, G				Gilboa, Guy			Nonlinear Scale Space with Spatially Varying Stopping Time	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image denoising; stopping time; scale space; nonlinear diffusion; SNR; spatially varying parameters	WAVELET SHRINKAGE; DIFFUSION; REGULARIZATION; REPRESENTATION; SELECTION; BV	A general scale-space algorithm is presented for denoising signals and images with spatially varying dominant scales. The process is formulated as a partial differential equation with spatially varying time. The proposed adaptivity is semilocal and is in conjunction with the classical gradient-based diffusion coefficient, designed to preserve edges. The new algorithm aims at maximizing a local SNR measure of the denoised image. It is based on a generalization of a global stopping time criterion presented recently by the author and his colleagues. Most notably, the method also works well for partially textured images and outperforms any selection of a global stopping time. Given an estimate of the noise variance, the procedure is automatic and can be applied well to most natural images.	3DB Syst Ltd, IL-20692 Yokneam, Israel		Gilboa, G (corresponding author), 3DB Syst Ltd, POB 249,2 Carmel St, IL-20692 Yokneam, Israel.	gilboa@3dvsystems.com			US National Science Foundation [DMS-0714087, ITR ACI-0321917, DMS-0312222]; US National Institutes of Health [P20 MH65166]; NATIONAL INSTITUTE OF MENTAL HEALTH [P20MH065166] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))	This work was Supported by grants from the US National Science Foundation under Contracts DMS-0714087, ITR ACI-0321917, and DMS-0312222, and the US National Institutes of Health under Contract P20 MH65166. The main part of the paper was done during the stay of the author in the Department of Mathematics at the University of California, Los Angeles.	ALVAREZ L, 1993, ARCH RATIONAL MECH A, V123, P3; Aubert G., 2002, APPL MATH SCI; Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z; AUJOL JF, 2005, J MATH IMAGING VISIO, V22; Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Black MJ, 1999, LECT NOTES COMPUT SC, V1682, P259; Burger M, 2006, COMMUN MATH SCI, V4, P179; Chambolle A, 2001, IEEE T IMAGE PROCESS, V10, P993, DOI 10.1109/83.931093; Chan TF, 2005, IMAGE PROCESSING AND ANALYSIS, P1, DOI 10.1137/1.9780898717877; Frigaard IA, 2003, SIAM J APPL MATH, V63, P1911, DOI 10.1137/S0036139902400465; Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47; Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2281, DOI 10.1109/TIP.2006.875247; Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2269, DOI 10.1109/TIP.2006.875248; HAMZA AB, 2001, IEEE T SIGNAL PROCES, V49, P3045; Iijima T., 1959, BASIC THEORY PATTERN; Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009; Kervrann C, 2004, LECT NOTES COMPUT SC, V3023, P132; *KOD, 2002, KOD IM COLL; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Meyer F, 2000, J VIS COMMUN IMAGE R, V11, P245, DOI 10.1006/jvci.1999.0447; Meyer Y, 2001, AM MATH SOC LEWIS ME, V22; Morozov V.A, 1966, SOVIET MATH DOKLADY, V7, P414; Mrazek P, 2003, INT J COMPUT VISION, V52, P189, DOI 10.1023/A:1022908225256; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Osher S., 2003, GEOMETRIC LEVEL SET; Papandreou G, 2005, PROC CVPR IEEE, P625; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; ROUSSEEUW PJ, 2006, ROBUST REGRESSION OU; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Scherzer O, 2000, J MATH IMAGING VIS, V12, P43, DOI 10.1023/A:1008344608808; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429; Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448; Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; Weickert J, 1997, COMP IMAG VIS, V8, P45; Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	46	21	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2175	2187		10.1109/TPAMI.2008.23	http://dx.doi.org/10.1109/TPAMI.2008.23			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988950				2022-12-18	WOS:000260033900008
J	Brimkov, VE; Klette, R				Brimkov, Valentin E.; Klette, Reinhard			Border and surface tracing - Theoretical foundations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digital geometry; digital topology; discrete dimension; digital manifold; digital curve; digital hypersurface; good pair	TOPOLOGICAL PROPERTIES; ADJACENCY; SPACES	In this paper, we define and study digital manifolds of arbitrary dimension, and provide (in particular) a general theoretical basis for curve or surface tracing in picture analysis. The studies involve properties such as the one-dimensionality of digital curves and (n - 1)-dimensionality of digital hypersurfaces that makes them discrete analogs of corresponding notions in continuous topology. The presented approach is fully based on the concept of adjacency relation and complements the concept of dimension, as common in combinatorial topology. This work appears to be the first one on digital manifolds based on a graph-theoretical definition of dimension. In particular, in the n-dimensional digital space, a digital curve is a one-dimensional object and a digital hypersurface is an (n - 1)-dimensional object, as it is in the case of curves and hypersurfaces in the euclidean space. Relying on the obtained properties of digital hypersurfaces, we propose a uniform approach for studying good pairs defined by separations and obtain a classification of good pairs in arbitrary dimension. We also discuss possible applications of the presented definitions and results.	[Brimkov, Valentin E.] SUNY Coll Buffalo, Dept Math, Buffalo, NY 14222 USA; [Klette, Reinhard] Univ Auckland, Dept Comp Sci, Auckland 1142, New Zealand	State University of New York (SUNY) System; Buffalo State College; University of Auckland	Brimkov, VE (corresponding author), SUNY Coll Buffalo, Dept Math, 1300 Elmwood Ave, Buffalo, NY 14222 USA.	brimkove@buffalostate.edu; r.klette@auckland.ac.nz		Klette, Reinhard/0000-0001-8818-7145				ALEXANDER JC, 1971, J ACM, V18, P105, DOI 10.1145/321623.321634; ALEXANDROFF P, 1935, TOPOLOGIE ERSTER BAN; Andres E, 1997, GRAPH MODEL IM PROC, V59, P302, DOI 10.1006/gmip.1997.0427; Bertrand G, 1999, J MATH IMAGING VIS, V11, P207, DOI 10.1023/A:1008348318797; Brimkov V, 2007, DISCRETE APPL MATH, V155, P468, DOI 10.1016/j.dam.2006.08.004; Brimkov VE, 2005, DISCRETE APPL MATH, V147, P169, DOI 10.1016/j.dam.2004.09.010; Brimkov VE, 2002, PATTERN RECOGN LETT, V23, P623, DOI 10.1016/S0167-8655(01)00139-8; BRIMKOV VE, 2004, P INT WORKSH COMB IM, P270; Chen L, 1999, INFORM SCIENCES, V115, P201, DOI 10.1016/S0020-0255(98)10072-5; CHEN L., 2004, DISCRETE SURFACES MA; CHEN L., 1993, P 2 ACM SIGGRAPH S S, P459; CHEN L, 2005, 156 CITR TR U AUCKL; COHEN-OR D., 1996, TOPOLOGICAL ALGORITH, P181; Couprie M, 2002, PATTERN RECOGN LETT, V23, P637, DOI 10.1016/S0167-8655(01)00140-4; Daragon X, 2005, J MATH IMAGING VIS, V23, P379, DOI 10.1007/s10851-005-2029-4; DOMINGUEZ E, 2001, LECT NOTES COMPUTER, V2243, P3; DUDA RO, 1967, ECOM0190126 STANF RE; Eckhardt U, 2003, COMPUT VIS IMAGE UND, V90, P295, DOI 10.1016/S1077-3142(03)00062-6; FRANCON J, 1995, GRAPH MODEL IM PROC, V57, P20, DOI 10.1006/gmip.1995.1003; HERMAN GT, 1996, TOPOLOGICAL ALGORITH, P233; Kenmochi Y, 1997, PATTERN RECOGN, V30, P1719, DOI 10.1016/S0031-3203(97)00001-0; KIM CE, 1983, IEEE T PATTERN ANAL, V5, P231, DOI 10.1109/TPAMI.1983.4767379; Klette G., 2007, THESIS GRONINGEN U; Klette G, 2006, LECT NOTES COMPUT SC, V4040, P34; Klette R., 2001, Visual Form 2001. 4th International Workshop on Visual Form IWVF4. Proceedings (Lecture Notes in Computer Science Vol.2059), P356; Klette R., 2004, DIGITAL GEOMETRY GEO; KLETTE R, 2005, LECTURE, V25; Kong T, 2001, FDN IMAGE UNDERSTAND, P33; KONG TY, 1992, TOPOL APPL, V46, P219, DOI 10.1016/0166-8641(92)90016-S; Kong TY, 2002, THEOR COMPUT SCI, V283, P3, DOI 10.1016/S0304-3975(01)00050-0; KOPPERMAN R, 1991, DISCRETE COMPUT GEOM, V6, P155, DOI 10.1007/BF02574681; Kovalevsky V, 2003, DISCRETE APPL MATH, V125, P25, DOI 10.1016/S0166-218X(02)00222-6; KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5; Lachaud JO, 2000, GRAPH MODELS, V62, P129, DOI 10.1006/gmod.2000.0522; LATECKI LJ, 1998, DISCRETE REPRESENTAT, P33018; Malgouyres R, 1997, THEOR COMPUT SCI, V186, P1, DOI 10.1016/S0304-3975(96)00213-7; Menger K., 1932, KURVENTHEORIE; MORGENTHALER DG, 1981, INFORM CONTROL, V51, P227, DOI 10.1016/S0019-9958(81)90290-4; MYLOPOULOS JP, 1971, J ACM, V18, P239, DOI 10.1145/321637.321644; Ohser J., 2006, IMAGE PROCESSING ANA; REVEILLES J, 1991, THESIS U L PASTEUR; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1974, INFORM CONTROL, V26, P24, DOI 10.1016/S0019-9958(74)90696-2; ROSENFELD A, 1991, CVGIP-GRAPH MODEL IM, V53, P305, DOI 10.1016/1049-9652(91)90034-H; ROSENFELD A, 1974, IEEE T SYST MAN CYB, VMC 4, P221, DOI 10.1109/TSMC.1974.5409121; SIGUERA M, 2005, P VISION GEOMETRY, P150; TOURLAKIS G, 1977, SIAM J APPL MATH, V33, P51, DOI 10.1137/0133005; TOURLAKIS G, 1973, J ACM, V20, P439, DOI 10.1145/321765.321776; UDUPA JK, 1996, TOPOLOGICAL ALGORITH, P205; URYSOHN P, 1923, P ANN M DTSCH MATH V; Welsh DJA, 1976, MATROID THEORY; Wyse F, 1970, AM MATH MON, V77, P1119	52	21	21	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					577	590		10.1109/TPAMI.2007.70725	http://dx.doi.org/10.1109/TPAMI.2007.70725			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276965				2022-12-18	WOS:000253135600003
J	Sagawa, R; Ikeuchi, K				Sagawa, Ryusuke; Ikeuchi, Katsushi			Hole filling of a 3D model by flipping signs of a signed distance field in adaptive resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional modeling; interpolation of a mesh model; adaptive signed distance field		When we use range finders to observe the shape of an object, many occluded areas may occur. These become holes and gaps in the model and make it undesirable for various applications. We propose a novel method to fill holes and gaps to complete this incomplete model. As an intermediate representation, we use a Signed Distance Field (SDF), which stores euclidean signed distances from a voxel to the nearest point of the mesh model. By using an SDF, we can obtain interpolating surfaces for holes and gaps. The proposed method generates an interpolating surface that becomes smoothly continuous with real surfaces by minimizing the area of the interpolating surface. Since the isosurface of an SDF can be identified as being a real or interpolating surface from the magnitude of signed distances, our method computes the area of an interpolating surface in the neighborhood of a voxel both before and after flipping the sign of the signed distance of the voxel. If the area is reduced by flipping the sign, then our method changes the sign for the voxel. Therefore, we minimize the area of the interpolating surface by iterating this computation until convergence. Unlike methods based on Partial Differential Equations (PDEs), our method does not require any boundary condition and the initial state that we use is automatically obtained by computing the distance to the closest point of the real surface. Moreover, because our method can be applied to an SDF of adaptive resolution, our method efficiently interpolates large holes and gaps of high curvature. We tested the proposed method with both synthesized and real objects and evaluated the interpolating surfaces.	[Sagawa, Ryusuke] Osaka Univ, Dept Intelligent Media, Inst Sci & Ind Res, Ibaraki, Osaka 5670047, Japan; [Ikeuchi, Katsushi] Univ Tokyo, Inst Ind Sci, Minato Ku, Tokyo 106, Japan	Osaka University; University of Tokyo	Sagawa, R (corresponding author), Osaka Univ, Dept Intelligent Media, Inst Sci & Ind Res, 8-1 Mihogaoka, Ibaraki, Osaka 5670047, Japan.	sagawa@am.sanken.osaka-u.ac.jp; ki@iis.u-tokyo.ac.jp						CARR JC, 2001, P 28 ANN C COMP GRAP, P67, DOI DOI 10.1145/383259.383266; CHEN Y, 1995, COMPUT VIS IMAGE UND, V61, P325, DOI 10.1006/cviu.1995.1026; CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092; Clarenz U, 2004, COMPUT AIDED GEOM D, V21, P427, DOI 10.1016/j.cagd.2004.02.004; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; *CYR TECHN INC, CYR 2500; Davis J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P428, DOI 10.1109/TDPVT.2002.1024098; DELINGETTE H, 1992, IMAGE VISION COMPUT, V10, P132, DOI 10.1016/0262-8856(92)90065-B; Foley J.D., 1995, COMPUTER GRAPHICS PR; Hilton A., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P117, DOI 10.1007/BFb0015528; HOPPE H, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Liepa, 2003, P 2003 EUR ACM SIGGR, P200, DOI DOI 10.2312/SGP/SGP03/200-206; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Masuda T, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1003; Masuda T, 1998, INT C PATT RECOG, P977, DOI 10.1109/ICPR.1998.711851; *MINOLTA CO, VIV 900 NONC DIG; Sagawa R, 2005, IEEE T PATTERN ANAL, V27, P392, DOI 10.1109/TPAMI.2005.46; Sagawa R, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P410, DOI 10.1109/IM.2003.1240276; SAGAWA R, 2003, THESIS U TOKYO GRADU; Sato K., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P657; Sethian J. A., 1999, LEVEL SET METHODS FA; Verdera J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P903; Wheeler MD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P917, DOI 10.1109/ICCV.1998.710826; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900	26	21	24	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					686	699		10.1109/TPAMI.2007.70726	http://dx.doi.org/10.1109/TPAMI.2007.70726			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276973				2022-12-18	WOS:000253135600011
J	Tang, F; Crabb, R; Tao, H				Tang, Feng; Crabb, Ryan; Tao, Hai			Representing images using nonorthogonal Haar-like bases	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonorthogonal subspace; image representations; principal component analysis; image reconstruction	COMPONENT ANALYSIS; VISUAL TRACKING; COMPUTATION; SET	The efficient and compact representation of images is a fundamental problem in computer vision. In this paper, we propose methods that use Haar- like binary box functions to represent a single image or a set of images. A desirable property of these box functions is that their inner product operation with an image can be computed very efficiently. We propose two closely related novel subspace methods to model images: The nonorthogonal binary subspace ( NBS) method and the binary principal component analysis ( B-PCA) algorithm. NBS is spanned directly by binary box functions and can be used for image representation, fast template matching, and many other vision applications. B- PCA is a structure subspace that inherits the merits of both NBS ( fast computation) and PCA ( modeling data structure information). B- PCA base vectors are obtained by a novel PCA- guided NBS method. We also show that B- PCA base vectors are nearly orthogonal to each other. As a result, in the nonorthogonal vector decomposition process, the computationally intensive pseudoinverse projection operator can be approximated by the direct dot product without causing significant distance distortion. Experiments on real image data sets show a promising performance in image matching, reconstruction, and recognition tasks with significant speed improvement.	Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Tang, F (corresponding author), Univ Calif Santa Cruz, Dept Comp Engn, 1156 High St, Santa Cruz, CA 95064 USA.	tang@soe.ucsc.edu; rcrabb@soe.ucsc.edu; tao@soe.ucsc.edu						Andrle M, 2006, SIGNAL PROCESS, V86, P480, DOI 10.1016/j.sigpro.2005.05.034; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; BLACK MJ, 1996, P EUR C COMP VIS, P329; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Chui CK, 1994, WAVELETS THEORY ALGO; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430; Davis HF, 1989, FOURIER SERIES ORTHO; Di Stefano L, 2003, MACH VISION APPL, V13, P213; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; ELAD M, 2006, P IEEE C COMP VIS PA, P329; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Georgiev P, 2005, IEEE T NEURAL NETWOR, V16, P992, DOI 10.1109/TNN.2005.849840; Gilbert AC, 2003, SIAM PROC S, P243; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Hazan T, 2005, IEEE I CONF COMP VIS, P50; Heiler M, 2005, IEEE I CONF COMP VIS, P1667; Hel-Or Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1486; Ho J, 2004, PROC CVPR IEEE, P782; HONG W, 2005, P 10 IEEE INT C COMP, P674; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Irani M, 2002, INT J COMPUT VISION, V48, P173, DOI 10.1023/A:1016372015744; Jollife I. T., 1986, PRINCIPAL COMPONENT; KANATANI K, 1918, P 8 IEEE INT C COMP, P586; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Kolda TG, 2000, ACM T MATH SOFTWARE, V26, P415, DOI 10.1145/358407.358424; KULTHAU S, 2002, P IEEE INT C IM PROC, P669; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee KC, 2005, COMPUT VIS IMAGE UND, V99, P303, DOI 10.1016/j.cviu.2005.02.002; Lewis JP, 1994, PROC CANAD IMAG PROC, P120; LI S, 2004, HDB FACE RECOGNITION, pCH7; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Meyer Y, 1993, WAVELETS; Mita T, 2005, IEEE I CONF COMP VIS, P1619; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; Rebollo-Neira L, 2002, IEEE SIGNAL PROC LET, V9, P137, DOI 10.1109/LSP.2002.1001652; ROSS D, 2004, P 8 EUR C COMP VIS, V2, P470; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHWEITZER H, 2002, P 7 EUR C COMP VIS, P358; SHANKS JL, 1969, IEEE T COMPUT, VC 18, P457, DOI 10.1109/T-C.1969.222685; SHASHUA A, 2002, P 16 INT C PATT REC, P11; Tao H, 2005, IEEE I CONF COMP VIS, P864; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Veksler O, 2003, PROC CVPR IEEE, P556; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517	56	21	28	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2120	2134		10.1109/TPAMI.2007.1123	http://dx.doi.org/10.1109/TPAMI.2007.1123			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934222				2022-12-18	WOS:000250087900005
J	Haindl, M; Filip, J				Haindl, Michal; Filip, Jiri			Extreme compression and modeling of Bidirectional Texture Function	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						rough texture; 3D texture; BTF; texture synthesis; texture modeling; data compression	IMAGE	The recent advanced representation for realistic real-world materials in virtual reality applications is the Bidirectional Texture Function (BTF), which describes rough texture appearance for varying illumination and viewing conditions. Such a function can be represented by thousands of measurements ( images) per material sample. The resulting BTF size excludes its direct rendering in graphical applications and some compression of these huge BTF data spaces is obviously inevitable. In this paper, we present a novel, fast probabilistic model-based algorithm for realistic BTF modeling allowing an extreme compression with the possibility of a fast hardware implementation. Its ultimate aim is to create a visual impression of the same material without a pixelwise correspondence to the original measurements. The analytical step of the algorithm starts with a BTF space segmentation and a range map estimation by photometric stereo of the BTF surface, followed by the spectral and spatial factorization of selected subspace color texture images. Single mono-spectral band-limited factors are independently modeled by their dedicated spatial probabilistic model. During rendering, the subspace images of arbitrary size are synthesized and both color ( possibly multispectral) and range information is combined in a bump-mapping filter according to the view and illumination directions. The presented model offers a huge BTF compression ratio unattainable by any alternative sampling-based BTF synthesis method. Simultaneously, this model can be used to reconstruct missing parts of the BTF measurement space.	Acad Sci Czech Republ, Inst Informat Theory & Automat, CR-18208 Prague, Czech Republic	Czech Academy of Sciences; Institute of Information Theory & Automation of the Czech Academy of Sciences	Haindl, M (corresponding author), Acad Sci Czech Republ, Inst Informat Theory & Automat, Pod Vodarenskou Vezi 4, CR-18208 Prague, Czech Republic.	haindl@utia.cz; filipj@utia.cz	Haindl, Michal/R-4909-2019; Haindl, Michal/H-4323-2014; Filip, Jiri/D-3396-2012	Haindl, Michal/0000-0001-8159-3685; Haindl, Michal/0000-0001-8159-3685; 				Bennett J, 1998, IEEE T PATTERN ANAL, V20, P327, DOI 10.1109/34.667889; Blinn J. F., 1977, P 4 ANN C COMP GRAPH, V11, P192, DOI DOI 10.1145/563858.563893; Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265; Coxeter HSM., 1969, INTRO GEOMETRY; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Filip J, 2004, INT C PATT RECOG, P80, DOI 10.1109/ICPR.2004.1334011; Haindl M, 2004, INT C PATT RECOG, P194, DOI 10.1109/ICPR.2004.1334501; Haindl M, 2004, LECT NOTES COMPUT SC, V3212, P298; Haindl M., 1991, CWI Q, V4, P305; Haindl M., 2003, TEXTURE 2003, P47; HAINDL M, 2005, TEXTURE 2005, P89; HAINDL M, 2000, P ADV PATT REC; KOUDELKA M, 2003, TEXTURE, P47; Lafortune E. P. F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P117, DOI 10.1145/258734.258801; Liu XG, 2004, IEEE T VIS COMPUT GR, V10, P278, DOI 10.1109/TVCG.2004.1272727; Liu XG, 2001, COMP GRAPH, P97; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; MCALLISTER DK, 2002, GRAPHICS HARDWARE, P77; Meseth J., 2003, P OPENSG S, P89; Muller G., 2004, EUROGRAPHICS 2004 ST, P69; NEUBECK A, 2005, TEXTURE; Nicodemus F. E., 1977, NBS MONOGR, V160, P1; SATTLER M, 2003, P EUR S REND JUN; SOMOL P, 2005, P 13 C CENTR EUR COM; Vasilescu MAO, 2004, ACM T GRAPHIC, V23, P336, DOI 10.1145/1015706.1015725; Wang J, 2004, PROC CVPR IEEE, P372; WELSCH T, 2004, PARALLAX MAPPING OFF; WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9; YACOV H, 2003, TEXTURE, P47	31	21	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1859	1865		10.1109/TPAMI.2007.1139	http://dx.doi.org/10.1109/TPAMI.2007.1139			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699929	Green Submitted			2022-12-18	WOS:000248696100014
J	Guo, YL; Hsu, S; Sawhney, HS; Kumar, R; Shan, Y				Guo, Yanlin; Hsu, Steve; Sawhney, Harpreet S.; Kumar, Rakesh; Shan, Ying			Robust object matching for persistent tracking with heterogeneous features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video object tracking and reacquisition; object matching; feature matching; image alignment and matching	IMAGES	This paper addresses the problem of matching vehicles across multiple sightings under variations in illumination and camera poses. Since multiple observations of a vehicle are separated in large temporal and/or spatial gaps, thus prohibiting the use of standard frame-to-frame data association, we employ features extracted over a sequence during one time interval as a vehicle fingerprint that is used to compute the likelihood that two or more sequence observations are from the same or different vehicles. Furthermore, since our domain is aerial video tracking, in order to deal with poor image quality and large resolution and quality variations, our approach employs robust alignment and match measures for different stages of vehicle matching. Most notably, we employ a heterogeneous collection of features such as lines, points, and regions in an integrated matching framework. Heterogeneous features are shown to be important. Line and point features provide accurate localization and are employed for robust alignment across disparate views. The challenges of change in pose, aspect, and appearances across two disparate observations are handled by combining a novel feature-based quasi-rigid alignment with flexible matching between two or more sequences. However, since lines and points are relatively sparse, they are not adequate to delineate the object and provide a comprehensive matching set that covers the complete object. Region features provide a high degree of coverage and are employed for continuous frames to provide a delineation of the vehicle region for subsequent generation of a match measure. Our approach reliably delineates objects by representing regions as robust blob features and matching multiple regions to multiple regions using Earth Mover's Distance ( EMD). Extensive experimentation under a variety of real-world scenarios and over hundreds of thousands of Confirmatory Identification ( CID) trails has demonstrated about 95 percent accuracy in vehicle reacquisition with both visible and Infrared ( IR) imaging cameras.	Sarnoff Corp, Princeton, NJ 08543 USA; Canesta Inc, Sunnyvale, CA 94085 USA	Sarnoff Corporation	Guo, YL (corresponding author), Sarnoff Corp, 201 Washington Rd,CN5300, Princeton, NJ 08543 USA.	yguo@sarnoff.com; shsu@canesta.com; hsawhney@sarnoff.com; rkumar@sarnoff.com; yshan@sarnoff.com	Kumar, Rakesh/ABG-8864-2021					Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; BEIER T, 1992, FEATURE BASED IMAGE, V26; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; FERENCZ A, 2004, NEURAL INFORM PROCES; Fergus R., 2003, P IEEE C COMP VIS PA; FORSSEN PE, 2003, P SCAND C IM ANAL; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; Ghanem M, 2005, I C COMP SYST APPLIC; GREENSPAN H, 2000, P IEEE WORKSH CONT B; Grenander U., 1991, HANDS PATTERN THEORE; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hitchcock F.L., 1941, J MATH PHYS, V20, P224, DOI DOI 10.1002/SAPM1941201224; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; Lazebnik S., 2004, P BRIT MACH VIS C, V2, P959, DOI DOI 10.5244/C.18.98; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; MIKOLAJCZK K, 2003, P IEEE C COMP VIS PA; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; SIVIC J, 2004, P 8 EUR C COMP VIS; ULLMAN S, 2001, P 4 INT WORKSH VIS F	26	21	25	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					824	839		10.1109/TPAMI.2007.1052	http://dx.doi.org/10.1109/TPAMI.2007.1052			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356202				2022-12-18	WOS:000244855700006
J	Manduchi, R				Manduchi, Roberto			Learning outdoor color classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color constancy; classification; expectation maximization	CONSTANCY; SEGMENTATION; ILLUMINATION; MODELS; SCENES	We present an algorithm for color classification with explicit illuminant estimation and compensation. A Gaussian classifier is trained with color samples from just one training image. Then, using a simple diagonal illumination model, the illuminants in a new scene that contains some of the surface classes seen in the training image are estimated in a maximum likelihood framework using the Expectation Maximization algorithm. We also show how to impose priors on the illuminants, effectively computing a maximum a posteriori estimation. Experimental results are provided to demonstrate the performance of our classification algorithm in the case of outdoor images.	Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Manduchi, R (corresponding author), Univ Calif Santa Cruz, Dept Comp Engn, 1156 High St,MS SOE3, Santa Cruz, CA 95064 USA.	manduchi@soe.ucsc.edu						Barnard K, 1997, COMPUT VIS IMAGE UND, V65, P311, DOI 10.1006/cviu.1996.0567; Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; BARNARD K, 2000, P 6 EUR C COMP VIS D, P375; BESAG J, 1986, J R STAT SOC B, V48, P259; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; Buluswar SD, 2002, COMPUT VIS IMAGE UND, V85, P71, DOI 10.1006/cviu.2001.0950; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P3011, DOI 10.1364/JOSAA.11.003011; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Forsyth DA, 2001, INT J COMPUT VISION, V41, P109, DOI 10.1023/A:1011165200654; GROSSBERG MD, 2003, P IEEE COMP VIS PATT; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; Jaynes E.T., 2003, PROBABILITY THEORY L; JIANG C, 1992, P IEEE COMPUTER VISI; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; Manduchi R, 2005, AUTON ROBOT, V18, P81, DOI 10.1023/B:AURO.0000047286.62481.1d; MANDUCHI R, 2004, P EUR C COMP VIS; MATAS J, 1994, P 5 BRIT MACH VIS C; McLachlan, 1997, EM ALGORITHM EXTENSI; Press WH, 1986, NUMERICAL RECIPES C, V818; Ripley BD., 1996; SCHAEFER G, 2004, P 2 INT C COMP VIS G; Slater D, 1998, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.1998.698595; SMITH WK, 1989, ECOLOGY, V70, P1603, DOI 10.2307/1938093; TSIN Y, 2001, P IEEE COMP VIS PATT; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; ZHANG J, 1994, IEEE T IMAGE PROCESS, V3, P404, DOI 10.1109/83.298395	28	21	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1713	1723		10.1109/TPAMI.2006.231	http://dx.doi.org/10.1109/TPAMI.2006.231			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063678				2022-12-18	WOS:000240443400001
J	Zhou, ZH; Prugel-Bennett, A; Damper, RI				Zhou, Ziheng; Prugel-Bennett, Adam; Damper, Robert I.			A Bayesian framework for extracting human gait using strong prior knowledge	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian framework; strong prior; articulated motion; human gait; hidden Markov model	RECOGNITION	Extracting full-body motion of walking people from monocular video sequences in complex, real-world environments is an important and difficult problem, going beyond simple tracking, whose satisfactory solution demands an appropriate balance between use of prior knowledge and learning from data. We propose a consistent Bayesian framework for introducing strong prior knowledge into a system for extracting human gait. In this work, the strong prior is built from a simple articulated model having both time-invariant (static) and time-variant (dynamic) parameters. The model is easily modified to cater to situations such as walkers wearing clothing that obscures the limbs. The statistics of the parameters are learned from high-quality (indoor laboratory) data and the Bayesian framework then allows us to "bootstrap" to accurate gait extraction on the noisy images typical of cluttered, outdoor scenes. To achieve automatic fitting, we use a hidden Markov model to detect the phases of images in a walking cycle. We demonstrate our approach on silhouettes extracted from fronto-parallel ("sideways on") sequences of walkers under both high-quality indoor and noisy outdoor conditions. As well as high-quality data with synthetic noise and occlusions added, we also test walkers with rucksacks, skirts, and trench coats. Results are quantified in terms of chamfer distance and average pixel error between automatically extracted body points and corresponding hand-labeled points. No one part of the system is novel in itself, but the overall framework makes it feasible to extract gait from very much poorer quality image sequences than hitherto. This is confirmed by comparing person identification by gait using our method and a well-established baseline recognition algorithm.	Univ Southampton, Sch Elect & Comp Sci, ISIS, Res Grp, Southampton SO17 1BJ, Hants, England	UK Research & Innovation (UKRI); Science & Technology Facilities Council (STFC); STFC Rutherford Appleton Laboratory; University of Southampton	Zhou, ZH (corresponding author), Univ Southampton, Sch Elect & Comp Sci, ISIS, Res Grp, Southampton SO17 1BJ, Hants, England.	zz02r@ecs.soton.ac.uk; apb@ecs.soton.ac.uk; rid@ecs.soton.ac.uk						Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Baggenstoss PM, 2003, IEEE T SIGNAL PROCES, V51, P672, DOI 10.1109/TSP.2002.808109; Baumberg A. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P194, DOI 10.1109/MNRAO.1994.346236; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K; Elgammal A, 2003, PROC CVPR IEEE, P571; ELGAMMAL A, 2004, P 2 INT WORKSH GEN M; GAVRILA DM, 2000, P EUR C COMP VIS, P37; Grant MG, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P46, DOI 10.1109/IAI.2004.1300942; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; LAN X, 2004, P IEEE C COMP VIS PA, V1, P722; Lappas P, 2002, PATTERN RECOGN LETT, V23, P253, DOI 10.1016/S0167-8655(01)00109-X; Lee L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P663; Lee Lily, 2003, 2003014 MIT ART INT; MEYER D, 1998, P BRIT MACH VIS C, P459; MINKA T, 2004, EXEMPLAR BASED LIKEL; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Murray M P, 1967, Am J Phys Med, V46, P290; Ning HZ, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P383, DOI 10.1109/ICMI.2002.1167025; Nixon M.S., 1996, BIOMETRICS, P231, DOI 10.1007/0-306-47044-6_11; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Shutler J.D., 2002, P 4 INT C REC ADV SO, P66; Sigal L, 2004, PROC CVPR IEEE, P421; SUNDARESAN A, 2003, P IEEE INT C IM PROC, V2, P85; THAYANANTHAN A, 2004, P BRIT MACH VIS C; Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014; Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0; Zhang JY, 2004, PROC CVPR IEEE, P342	32	21	24	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1738	1752		10.1109/TPAMI.2006.214	http://dx.doi.org/10.1109/TPAMI.2006.214			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063680	Green Accepted			2022-12-18	WOS:000240443400003
J	Goudail, F; Refregier, P				Goudail, F; Refregier, P			Contrast definition for optical coherent polarimetric images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; contrast definition; detection; segmentation; active contours; polarimetric imaging	SNAKE-BASED SEGMENTATION; TARGET; LIGHT; SAR	We consider polarimetric images formed with coherent waves, such as in laser-illuminated imagery or synthetic aperture radar. A definition of the contrast between regions with different polarimetric properties in such images is proposed, and it is shown that the performances of maximum likelihood-based detection and segmentation algorithms are bijective functions of this contrast parameter. This makes it possible to characterize the performance of such algorithms by simply specifying the value of the contrast parameter.	Ecole Gen Ingenieurs Marseille, Phys & Image Proc Grp, Inst Fresnel, UMR 6133, F-13397 Marseille 20, France	UDICE-French Research Universities; Aix-Marseille Universite	Goudail, F (corresponding author), Ecole Gen Ingenieurs Marseille, Phys & Image Proc Grp, Inst Fresnel, UMR 6133, Domaine Univ St-Jerome, F-13397 Marseille 20, France.	francois.goudail@fresnel.fr; philippe.refregier@fresnel.fr	goudail, françois/AAG-2372-2020					Barrett HH, 1998, J OPT SOC AM A, V15, P1520, DOI 10.1364/JOSAA.15.001520; BASSEVILLE M, 1989, SIGNAL PROCESS, V18, P349, DOI 10.1016/0165-1684(89)90079-0; Breugnot S, 1999, P SOC PHOTO-OPT INS, V3707, P449, DOI 10.1117/12.351366; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; Clemenceau P, 1998, P SOC PHOTO-OPT INS, V3380, P284, DOI 10.1117/12.327201; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; FELLER W, 1960, INTRO PROBABILITY TH; Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249; Floc'h M, 1998, PURE APPL OPT, V7, P1327, DOI 10.1088/0963-9659/7/6/011; Germain O, 1996, OPT LETT, V21, P1845, DOI 10.1364/OL.21.001845; Gleckler AD, 2000, P SOC PHOTO-OPT INS, V4035, P266, DOI 10.1117/12.397800; GOODMAN JW, 1985, STAT OPTICS, P116; HUARD S, 1997, POLARIZATION LIGHT, P00001; Jacques SL, 2002, J BIOMED OPT, V7, P329, DOI 10.1117/1.1484498; Jiao SL, 2002, OPT LETT, V27, P101, DOI 10.1364/OL.27.000101; KAY SM, 1998, FUNDAMENTALS STAT SI, V2, P186; LEE JS, 1994, INT J REMOTE SENS, V15, P2299, DOI 10.1080/01431169408954244; Muirhead R.J., 1982, ASPECTS MULTIVARIATE; Oliver CJ, 1995, P SOC PHOTO-OPT INS, V2584, P152, DOI 10.1117/12.227124; Refregier P, 2002, J OPT SOC AM A, V19, P1223, DOI 10.1364/JOSAA.19.001223; THERRIEN CW, 1989, DECISION ESTIMATION, P139; Tyo JS, 1996, APPL OPTICS, V35, P1855, DOI 10.1364/AO.35.001855; Wolff LB, 1997, IMAGE VISION COMPUT, V15, P81, DOI 10.1016/S0262-8856(96)01123-7; [No title captured]	25	21	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					947	U2		10.1109/TPAMI.2004.22	http://dx.doi.org/10.1109/TPAMI.2004.22			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579953				2022-12-18	WOS:000221323900012
J	Kamgar-Parsi, B; Kamgar-Parsi, B				Kamgar-Parsi, B; Kamgar-Parsi, B			Algorithms for matching 3D line sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line matching; motion estimation; object recognition; pose estimation; 3D registration	SEGMENTS; MOTION	Matching two sets of lines is a basic tool that has applications in many computer vision problems such as scene registration, object recognition, motion estimation, and others. Line sets may be composed of infinitely long lines or finite length line segments. Depending on line lengths, three basic cases arise in matching sets of lines: 1) finite-finite, 2) finite-infinite, and 3) infinite-infinite. Case 2 has not been treated in the literature. For Cases 1 and 3, existing algorithms for matching 3D line sets are not completely satisfactory in that they either solve special situations, or give approximate solutions, or may not converge, or are not invariant with respect to coordinate system transforms. In this paper, we present new algorithms that solve exactly all three cases for the general situation. The algorithms are provably convergent and invariant to coordinate transforms. Experiments with synthetic and real 3D image data are reported.	Off Naval Res, Arlington, VA 22217 USA; USN, Res Lab, Washington, DC 20375 USA	United States Department of Defense; United States Navy; United States Department of Defense; United States Navy; Naval Research Laboratory	Kamgar-Parsi, B (corresponding author), Off Naval Res, Code 311,800 N Quincy St, Arlington, VA 22217 USA.	kamgarb@onr.navy.mil; kamgar@aic.nrl.navy.mil						Bartoli A, 2001, PROC CVPR IEEE, P287; CHEN HH, 1990, IEEE T PATTERN ANAL, V12, P1002, DOI 10.1109/34.58872; Daniilidis K, 1999, INT J ROBOT RES, V18, P286, DOI 10.1177/02783649922066213; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Guerra C, 1999, P SOC PHOTO-OPT INS, V3811, P157, DOI 10.1117/12.364090; Heisterkamp DR, 1997, IEEE T PATTERN ANAL, V19, P68, DOI 10.1109/34.566813; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Jonas A, 1998, J MATH IMAGING VIS, V8, P215, DOI 10.1023/A:1008218517090; Kamgar-Parsi B, 2001, PROC CVPR IEEE, P651; KAMGARPARSI B, 1990, COMPUT VISION GRAPH, V52, P341, DOI 10.1016/0734-189X(90)90080-F; KamgarParsi B, 1997, IEEE T PATTERN ANAL, V19, P1090, DOI 10.1109/34.625109; KamgarParsi B, 1997, INT J IMAG SYST TECH, V8, P377, DOI 10.1002/(SICI)1098-1098(1997)8:4<377::AID-IMA4>3.0.CO;2-7; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P998, DOI 10.1109/34.35504; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O; Werman M, 2001, IEEE T PATTERN ANAL, V23, P528, DOI 10.1109/34.922710; ZHANG Z, 1992, 3D DYNAMIC SCENE ANA; ZHANG ZG, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P257; ZHANG ZY, 1991, IMAGE VISION COMPUT, V9, P10, DOI 10.1016/0262-8856(91)90043-O	22	21	23	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					582	593		10.1109/TPAMI.2004.1273930	http://dx.doi.org/10.1109/TPAMI.2004.1273930			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460280	Green Submitted			2022-12-18	WOS:000220756400004
J	Inoue, M; Ueda, N				Inoue, M; Ueda, N			Exploitation of unlabeled sequences in hidden Markov models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						unlabeled data; sequential data; hidden Markov models; extended Baum-Welch algorithm	MAXIMUM-LIKELIHOOD; CLASSIFICATION; RECOGNITION; MIXTURE	This paper presents a method for effectively using unlabeled sequential data in the learning of hidden Markov models (HMMs). With the conventional approach, class labels for unlabeled data are assigned deterministically by HMMs learned from labeled data. Such labeling often becomes unreliable when the number of labeled data is small. We propose an extended Baum-Welch (EBW) algorithm in which the labeling is undertaken probabilistically and iteratively so that the labeled and unlabeled data likelihoods are improved. Unlike the conventional approach, the EBW algorithm guarantees convergence to a local maximum of the likelihood. Experimental results on gesture data and speech data show that when labeled training data are scarce, by using unlabeled data, the EBW algorithm improves the classification performance of HMMs more robustly than the conventional naive labeling (NIL) approach.	Nara Inst Sci & Technol, Grad Sch Informat Sci, NAIST, Ikoma, Nara, Japan; NTT Corp, Commun Sci Labs, Seika, Kyoto, Japan	Nara Institute of Science & Technology; Nippon Telegraph & Telephone Corporation	Inoue, M (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, NAIST, 8916-5 Takayama Cho, Ikoma, Nara, Japan.	masash-i@is.aist-nara.ac.jp; ueda@cslab.kecl.ntt.co.jp	Inoue, Masashi/AAQ-9082-2021	Inoue, Masashi/0000-0002-9364-3114				Aversano G, 2001, PROCEEDINGS OF THE 44TH IEEE 2001 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P516, DOI 10.1109/MWSCAS.2001.986241; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BELLEGARDA JR, 1990, IEEE T ACOUST SPEECH, V38, P2033, DOI 10.1109/29.61531; Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Corduneanu A., 2002, UNC ART INT P 18 C, P111; CUTTING D, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P133; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; ELWORTHY D, 1994, P 4 C APPL NAT LANG, P53; GANESALINGAM S, 1981, BIOMETRICS, V37, P23, DOI 10.2307/2530519; Garofolo J.S., 1993, TIMIT ACOUSTIC PHONE, DOI 10.35111/17gk-bn40; Huang X., 1990, HIDDEN MARKOV MODELS; HUANG XD, 1992, IEEE T SIGNAL PROCES, V40, P1062, DOI 10.1109/78.134469; Inoue M, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P93, DOI 10.1109/NNSP.2001.943114; KEMP T, 1999, P ESCA EUR 99 BUD HU, V6, P2725; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Lamel L, 2002, COMPUT SPEECH LANG, V16, P115, DOI 10.1006/csla.2001.0186; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; MCDERMOT E, 1997, P EUROSPEECH 97, V1, P123; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; Merialdo B., 1994, Computational Linguistics, V20, P155; Miller DJ, 1997, ADV NEUR IN, V9, P571; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Seymore K., 1999, AAAI 99 WORKSHOP MAC, P37; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; STARNER T, 1995, P INT WORKSH AUT FAC, P189	29	21	22	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1570	1581		10.1109/TPAMI.2003.1251150	http://dx.doi.org/10.1109/TPAMI.2003.1251150			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000007
J	Jacob, M; Blu, T; Unser, M				Jacob, M; Blu, T; Unser, M			An exact method for computing the area moments of wavelet and spline curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						area moments; curves; splines; wavelets; Fourier; two-scale relation; box splines; wavelet-Galerkin integrals	RECOGNITION; POLYGONS; SIGNAL	We present a method for the exact computation of the moments of a region bounded by a curve represented by a scaling function or wavelet basis. Using Green's Theorem, we show that the computation of the area moments is equivalent to applying a suitable multidimensional filter on the coefficients of the curve and thereafter computing a scalar product. The multidimensional filter coefficients are precomputed exactly as the solution of a two-scale relation. To demonstrate the performance improvement of the new method, we compare it with existing methods such as pixel-based approaches and approximation of the region by a polygon. We also propose an alternate scheme when the scaling function is sinc(x).	Swiss Fed Inst Technol, Biomed Imaging Grp, EPFL, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Jacob, M (corresponding author), Swiss Fed Inst Technol, Biomed Imaging Grp, EPFL, CH-1015 Lausanne, Switzerland.	mathews.jacob@epfl.ch; thierry.blu@epfl.ch; michael.unser@epfl.ch	Jacob, Mathews/F-9205-2011; Jacob, Mathews/GZA-5643-2022; Unser, Michael/A-1550-2008; Blu, Thierry/J-9344-2012	Blu, Thierry/0000-0001-5759-0011; Jacob, Mathews/0000-0001-6196-3933				ALDROUBI A, 1992, SIGNAL PROCESS, V28, P127, DOI 10.1016/0165-1684(92)90030-Z; Antoine JP, 1997, SIGNAL PROCESS, V62, P265, DOI 10.1016/S0165-1684(97)00129-1; Bartels RH, 1987, INTRO SPLINES USE CO; Blu T, 1999, IEEE T SIGNAL PROCES, V47, P2796, DOI 10.1109/78.790660; BLU T, 1993, IEEE T SIGNAL PROCES, V41, P3232, DOI 10.1109/78.258070; BOCKMAN SF, 1989, AM MATH MON, V96, P131, DOI 10.2307/2323197; Brigger P, 2000, IEEE T IMAGE PROCESS, V9, P1484, DOI 10.1109/83.862624; Candocia F, 1998, IEEE T SIGNAL PROCES, V46, P2044, DOI 10.1109/78.700979; Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671; COHEN FS, 1994, IEEE T PATTERN ANAL, V16, P1, DOI 10.1109/34.273721; DAHMEN W, 1993, SIAM J NUMER ANAL, V30, P507, DOI 10.1137/0730024; DEBOOR C, 1998, BOX SPLINES; DESAI R, 1994, P 12 IAPR INT C PATT; FERMULLER C, 1992, P 11 IAPR INT C PATT; Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249; FLICKNER M, 1994, P 28 AS C SIGN SYST; Huang ZH, 1996, IEEE T IMAGE PROCESS, V5, P1473, DOI 10.1109/83.536895; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MCCOOL MD, 1995, GRAPH INTER, P34; Rad S., 1991, P IEEE INT C AC SPEE, V4, P2465; Restrepo JM, 1997, INT J NUMER METH ENG, V40, P3557, DOI 10.1002/(SICI)1097-0207(19971015)40:19<3557::AID-NME227>3.0.CO;2-A; SHEN LX, 1995, OPT ENG, V34, P3181, DOI 10.1117/12.213614; SINGER MH, 1993, PATTERN RECOGN, V26, P1019, DOI 10.1016/0031-3203(93)90003-F; STRACHAN NJC, 1990, PATTERN RECOGN LETT, V11, P351, DOI 10.1016/0167-8655(90)90044-3; Strang G., 1996, WAVELETS FILTER BANK; TSIRIKOLIAS K, 1993, PATTERN RECOGN, V26, P877, DOI 10.1016/0031-3203(93)90053-Y; Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930; VETTERLI M, 1995, WAVELETS SUBBAND CDI; WANG EK, 1991, ELECTROANAL, V3, P1, DOI 10.1002/elan.1140030102; Wang YP, 1999, IEEE T IMAGE PROCESS, V8, P1586, DOI 10.1109/83.799886	32	21	25	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					633	642		10.1109/34.927463	http://dx.doi.org/10.1109/34.927463			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC		Green Submitted			2022-12-18	WOS:000169037600007
J	Kundu, A; He, Y; Chen, MY				Kundu, A; He, Y; Chen, MY			Alternatives to variable duration HMM in handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variable duration HMM (VDHMM); path discriminant HMM (PD-HMM); model discriminant HMM (MD-HMM); nonergodic HMM (NEHMM); variable sequence length HMM (VSLHMM); adaptive length Viterbi algorithm (ALVA)	HIDDEN MARKOV-MODELS; WORD RECOGNITION; SEGMENTATION	A successful handwritten word recognition (HWR) system using Variable Duration Hidden Markov Model (VDHMM) and the PD-HMM strategy is easy to implement. The central theme of this paper is to show that if the duration statistics are computed, it could be utilized to implement an MD-HMM approach for better experimental results. This paper also describes a PD-HMM based HWR system where the duration statistics are not explicitly computed, but results are still comparable to VDHMM based HWR scheme [1].	US W Adv Technol, Boulder, CO 80303 USA; Xerox Imaging Syst, Peabody, MA 01960 USA; ITRI, Hsinchu, Taiwan	Industrial Technology Research Institute - Taiwan	Kundu, A (corresponding author), US W Adv Technol, Boulder, CO 80303 USA.	akundu@advtech.uswest.com						BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Vlontzos JA, 1992, IEEE T IMAGE PROCESS, V1, P539, DOI 10.1109/83.199925	5	21	23	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1275	1280		10.1109/34.730561	http://dx.doi.org/10.1109/34.730561			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100013
J	Chien, SA; Mortensen, HB				Chien, SA; Mortensen, HB			Automating image processing for scientific data analysis of a large image database	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data analysis; image processing; artificial intelligence (AI); planning; automated programming		This article describes the Multimission VICAR Planner (MVP): an Al planning system which uses knowledge about image processing steps and their requirements to construct executable image processing scripts to support high-level science requests made to the Jet Propulsion Laboratory (JPL) Multimission Image Processing Subsystem (MIPS). This article describes a general Al planning approach to automation and application of the approach to a specific area of image processing for planetary science applications involving radiometric correction, color triplet reconstruction, and mosaicing in which the MVP system significantly reduces the amount of effort required by image processing experts to fill a typical request.			Chien, SA (corresponding author), CALTECH,JET PROP LAB,4800 OAK GROVE DR,PASADENA,CA 91109, USA.							CAPDEVIELLE O, 1994, P 1 IEEE INT C IM PR, V3, P816; CHIEN S, 1996, D13463 JPL; CHIEN S, 1994, P 1 IEEE INT C IM PR, V3, P796; CLEMENT V, 1993, CVGIP-IMAG UNDERSTAN, V57, P166, DOI 10.1006/ciun.1993.1011; Erol K., 1994, AIPS, V94, P249; Grimm F., 1993, Expert Systems, V10, P61, DOI 10.1111/j.1468-0394.1993.tb00303.x; HILL R, 1995, TELECOMMUNICATIONS D; IWASAKI Y, 1985, J AUTOMATED REASONIN, V1, P161; JIAN X, 1994, VISION PLANNER INTEL; LANSKY A, 1995, P 1995 AAAI SPRING S, P67; LANSKY A, 1993, FIA9317 TR NASA AM R; LAVOIE S, 1989, D4186 CALTECH JET PR; MATSUYAMA T, 1989, COMPUT VISION GRAPH, V48, P22, DOI 10.1016/0734-189X(89)90103-5; PEMBERTHY JS, 1992, P 3 INT C KNOWL REPR; Sakaue K., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P189; STEFIK M, 1981, ARTIF INTELL, V16, P111, DOI 10.1016/0004-3702(81)90007-2; ZMUDA M, 1991, P IEEE NAT AER EL C, V3, P1054; [No title captured]	18	21	21	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					854	859		10.1109/34.531806	http://dx.doi.org/10.1109/34.531806			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VE318					2022-12-18	WOS:A1996VE31800010
J	Gu, HS; Shirai, Y; Asada, M				Gu, HS; Shirai, Y; Asada, M			MDL-based segmentation and motion modeling in a long image sequence of scene with multiple independently moving objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						long image sequence; spatiotemporal segmentation; motion estimation; MDL principle		This paper presents a method for spatiotemporal segmentation of long image sequences of scenes which include multiple independently moving objects, based on the minimum description length (MDL) principle. First, a family of motion models Is constructed, each of which corresponds to a physically meaningful motion such as translation with constant velocity or a combination of translation and rotation. Then, the motion description length is formulated. When an object changes the type of the motion or a new part of an object appears, the corresponding temporal or spatial segmentation is carried out. Ambiguous segmentation of two consecutive images can be resolved by minimizing the motion description length in a long sequence of images. Experiments on several real image sequences show the validity of our method.	OSAKA UNIV,FAC ENGN,OSAKA 565,JAPAN	Osaka University	Gu, HS (corresponding author), MATSUSHITA ELECT WORKS LTD,PROD ENGN RES LAB,SENSING TECHNOL LAB,KADOMA,OSAKA 571,JAPAN.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; Gu H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P367, DOI 10.1109/CVPR.1993.341104; GU H, 1994, THESIS OSAKA U; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Liou S.-P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P726, DOI 10.1109/CVPR.1991.139801; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; NIYOGI SA, 1985, P CVPR 94 SEATTLE, P469; RESTLE F, 1979, PSYCHOL REV, V86, P1, DOI 10.1037/0033-295X.86.1.1; RISSANEN J, 1989, WORLD SCI SERIES COM, V15; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834	11	21	21	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					58	64		10.1109/34.476012	http://dx.doi.org/10.1109/34.476012			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500007
J	WU, CH; DOERSCHUK, PC				WU, CH; DOERSCHUK, PC			TREE APPROXIMATIONS TO MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MARKOV RANDOM FIELD; BAYESIAN ESTIMATION; SPATIAL PATTERN CLASSIFICATION; IMAGE SEGMENTATION; IMAGE RESTORATION	STATISTICAL-ANALYSIS; BINARY IMAGES; OPTIMIZATION; RESTORATION; ALGORITHMS	Methods for approximately computing the marginal probability mass functions and means of a Markov random field (MRF) by approximating the lattice by a tree are described. Applied to the a posteriori MRP these methods solve Bayesian spatial pattern classification and image restoration problems. The methods are described, several theoretical results concerning fixed-point problems are proven, and four numerical examples are presented, including comparison with optimal estimators and the Iterated Conditional Mode estimator and including two agricultural optical remote sensing problems.	PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	WU, CH (corresponding author), IND TECHNOL RES INST,OPTOELECTR & SYST LAB,DEPT IMAGE PROC,HSINCHU,TAIWAN.		Doerschuk, Peter/A-3424-2016	Doerschuk, Peter/0000-0002-4517-6582				Baxter R.J., 1982, EXACTLY SOLVED MODEL; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BLANCHARD LE, 1980, IEEE T GEOSCI REMOTE, V18, P146, DOI 10.1109/TGRS.1980.350267; DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595; Devijver P. A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P259; DEVIJVER PA, 1987, PATTERN RECOGN, P141; ELFADEL IM, 1993, RLE579 MIT RES LAB E; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HIRIYANNAIAH HP, 1989, J OPT SOC AM A, V6, P1901, DOI 10.1364/JOSAA.6.001901; JEON B, 1992, IEEE T GEOSCI REMOTE, V30, P663, DOI 10.1109/36.158859; Kindermann R., 1980, MARKOV RANDOM FIELDS, DOI [10.1090/conm/001, DOI 10.1090/CONM/001]; LANDGREBE DA, 1980, PATTERN RECOGN, V12, P165, DOI 10.1016/0031-3203(80)90041-2; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Ortega J. M., 1970, ITERATIVE SOLUTION N, V30; Press WH, 1988, NUMERICAL RECIPES C; Van Laarhoven P.J., 1987, SIMULATED ANNEALING, P7; WU C, 1994, THESIS PURDUE U W LA; WU CH, 1995, IEEE T PATTERN ANAL, V17, P275, DOI 10.1109/34.368192; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297; Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863	25	21	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					391	402		10.1109/34.385979	http://dx.doi.org/10.1109/34.385979			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800006
J	VEELAERT, P				VEELAERT, P			DIGITAL PLANARITY OF RECTANGULAR SURFACE SEGMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DIGITAL PLANES; DIGITAL STRAIGHT LINES; EVENNESS; FLATNESS; FOURIER-MOTZKIN ELIMINATION METHOD; REGULAR SHAPE; STRAIGHTNESS	PLANES	We generalize the concept of evenness which has been developed for digital straight lines. Evenness is a necessary and sufficient condition for a digital are segment of be a digital straight line segment. We prove that evenness is also a necessary and sufficient condition for a rectangular surface segment to be a digital plane segment. This is not true for surface segments of arbitrary shape. To clarify the relation between shape and evenness we introduce tha notion of a regular shape and of an arbitrarily extendable even set.			VEELAERT, P (corresponding author), STATE UNIV GHENT,DEPT ELECTR & INFORMAT SYST,ST PIETERNIEUWSTR 41,B-9000 GHENT,BELGIUM.							DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DYER ME, 1984, SIAM J COMPUT, V13, P31, DOI 10.1137/0213003; HUNG SHY, 1985, IEEE T PATTERN ANAL, V7, P203, DOI 10.1109/TPAMI.1985.4767644; KIM CE, 1991, PATTERN RECOGN LETT, V12, P665, DOI 10.1016/0167-8655(91)90003-5; KIM CE, 1984, IEEE T PATTERN ANAL, V6, P639, DOI 10.1109/TPAMI.1984.4767578; KIM CE, 1982, COMPUT VISION GRAPH, V18, P369, DOI 10.1016/0146-664X(82)90005-3; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; Stoer J., 1970, CONVEXITY OPTIMIZATI, DOI 10.1007/978-3-642-46216-0; STOJMENOVIC I, 1991, CONT MATH, V119, P197; Veelaert P., 1993, Journal of Mathematical Imaging and Vision, V3, P205, DOI 10.1007/BF01250530; VEELAERT P, 1992, J MATH IMAGING VISIO; VEELAERT P, 1992, DG9203 U GHENT EL LA	12	21	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					647	652		10.1109/34.295909	http://dx.doi.org/10.1109/34.295909			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200009
J	KEREN, D; WERMAN, M				KEREN, D; WERMAN, M			PROBABILISTIC ANALYSIS OF REGULARIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FUNCTION SPACES; REGULARIZATION; SURFACE RECONSTRUCTION; UNCERTAINTY	ALGORITHMS	In order to wisely use interpolated data, it is important to have reliability and confidence measures associated with it. In this paper, we show how to compute the reliability at each point of any linear functional, for example, height or derivative, of a surface reconstructed using regularization. The proposed method is to define a probability structure on the class of possible objects (for example surfaces) and compute the variance of the corresponding random variable (for example, the height at a certain point). This variance is a natural measure for uncertainty, and experiments have shown it to correlate well with reality. The probability distribution used is based on the Boltzmann distribution. The theoretical part of the work utilizes tools from classical analysis, functional analysis, and measure theory on function spaces. The theory was tested and applied to real depth images. It was also applied to formalize a paradigm of optimal sampling, which was successfully tested on real depth images.	HEBREW UNIV JERUSALEM,DEPT COMP SCI,JERUSALEM,ISRAEL	Hebrew University of Jerusalem	KEREN, D (corresponding author), BROWN UNIV,DIV ENGN,PROVIDENCE,RI 02912, USA.							Adams R., 2003, SOBOLEV SPACE, Vsecond; AKIMA H, 1974, COMMUN ACM, V17, P26, DOI 10.1145/360767.360797; AYACHE N, 1987, 1ST P INT C COMP VIS, P73; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Chorley RJ, 1972, SPATIAL ANAL GEOMORP; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KEREN D, 1990, THESIS HEBREW U JERU; Kuo H, 1975, GAUSSIAN MEASURES BA; Larkin F. M., 1972, ROCKY MT J MATH, V2, P379; Leclerc YG, 1989, P WORKSH IM UND WORK, P1056; LEE D, 1986, ROCKY MOUNTAIN J MAT, V16, P461; MARROQUIN JL, 1987, MAY P INT C COMPUT V, P597; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MATTHIES L, 1988, JUN P IEEE COMP SOC, P366; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; POGGIO T, 1985, MIT833 MEM; Press WH., 1980, NUMERICAL RECIPES FO; RIOUX M, 1988, NRCC 3 DIMENSIONAL I; Robinson J. E., 1969, AAPG BULL, V53, P2341; SHMUEL A, 1990, JUN P INT C PATT REC, P48; Srivastava H.M., 1972, ROCKY MOUNTAIN J MAT, V2, P283, DOI [10.1216/RMJ-1972-2-2-283, DOI 10.1216/RMJ-1972-2-2-283]; SZELISKI R, 1989, BAYESIAN MODELING UN; SZELISKI R, 1987, P AAAI 87, P749; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1984, MULTIRESOLUTION IMAG; Tikhonov A., 1977, SOLUTIONS ILL POSED; WASILKOWSKI GW, 1986, ROCKY MT J MATH, V16, P727, DOI 10.1216/RMJ-1986-16-4-727; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; WHABA G, 1981, BAYESIAN C INTERVALS; Young N., 2012, INTRO HILBERT SPACE; [No title captured]	35	21	21	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					982	995		10.1109/34.254057	http://dx.doi.org/10.1109/34.254057			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775					2022-12-18	WOS:A1993MD77500002
J	MURTAGH, F				MURTAGH, F			PARALLEL ALGORITHMS FOR HIERARCHICAL-CLUSTERING AND CLUSTER VALIDITY - COMMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTATIONAL COMPLEXITY; HIERARCHICAL CLUSTERING	EFFICIENT ALGORITHM	The purpose of this correspondence is to indicate that state-of-the-art hierarchical clustering algorithms have O(n2) time complexity and should be referred to in preference to the O(n3) algorithms, which were described in many texts in the 1970's. We also point out some further references in the parallelizing of hierarchic clustering algorithms.			MURTAGH, F (corresponding author), EUROPEAN SPACE AGCY,SPACE TELESCOPE EUROPEAN COORDINATING FACIL,GARCHING,GERMANY.							BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Bruynooghe Michel., 1977, STAT ANAL DONNEES, P24; DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115; DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364; DERHAM C, 1980, CAHIERS ANAL DONNEES, V5, P135; Juan J., 1982, CAHIERS ANAL DONNEES, V7, P219; LI XB, 1990, IEEE T PATTERN ANAL, V12, P1088, DOI 10.1109/34.61708; MURTAGH F, 1983, INFORM PROCESS LETT, V16, P237, DOI 10.1016/0020-0190(83)90095-9; MURTAGH F, 1983, COMPUT J, V26, P354, DOI 10.1093/comjnl/26.4.354; Murtagh F, 1984, COMPUT STAT Q, V1, P101; MURTAGH F, 1985, COMPSTAT LECTURES, V4; ROHLF FJ, 1978, INFORM PROCESS LETT, V7, P44, DOI 10.1016/0020-0190(78)90039-X; ROHLF FJ, 1973, COMPUT J, V16, P93; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; Sneath P.H.A., 1973, NUMERICAL TAXONOMY P; WILLETT P, 1989, J DOC, V45, P1	16	21	22	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1992	14	10					1056	1057		10.1109/34.159908	http://dx.doi.org/10.1109/34.159908			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR944					2022-12-18	WOS:A1992JR94400008
J	FLECK, MM				FLECK, MM			MULTIPLE WIDTHS YIELD RELIABLE FINITE-DIFFERENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CAMERA NOISE MEASUREMENT; EDGE FINDER STABILITY EVALUATION; EDGE FINDING; MULTIPLE-WIDTH FINITE DIFFERENCE; NOISE SUPPRESSION ALGORITHMS	2ND DIRECTIONAL-DERIVATIVES; DIGITAL STEP EDGES; INTENSITY CHANGES; HUMAN-VISION; LOCALIZATION; DETECTOR; OPERATOR; IMAGES	This paper introduces a new finite difference edge finder in which each finite difference is computed at a range of widths, i.e., a range of distances between data points. Although narrow operators are best for describing detailed texture, wide operators report low-amplitude responses more reliably. Thus, if wide operators are used to fill gaps in narrow operator responses, each operator can be restricted to report only statistically reliable responses without losing many real features. This sharply reduces the noise in the final output. The paper presents theoretical bounds on spurious responses in the finite difference outputs, given only weak assumptions about the signal and noise. The expected response of the edge finder to an ideal straight step edge is also analyzed. These performance measures are compared with those of a standard algorithm based on Gaussian smoothing and those of a second new algorithm that also considers the spatial structure of noise. The new algorithms prove equally good at suppressing noise but are better able to detect faint or blurred features. These predictions are confirmed by empirical tests on real images using empirical measurements of camera noise.	UNIV OXFORD,DEPT ENGN SCI,OXFORD,ENGLAND	University of Oxford								Abramowitz M., 1964, HDB MATH FUNCTIONS; ARGYLE E, 1971, PR INST ELECTR ELECT, V59, P285, DOI 10.1109/PROC.1971.8136; Ballard D.H., 1982, COMPUTER VISION; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BINFORD TO, ARTIFICIAL INTELL, V17; BLAKE A, 1983, THSIS U EDINBURGH; Boie R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P100; Boie R. A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P450; BROOKS MJ, 1978, COMPUT VISION GRAPH, V8, P277, DOI 10.1016/0146-664X(78)90054-0; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Canny JF, 1983, TR720 AI LAB; CHATFIELD C, 1983, STATISTICS TECHNOLOG; CLARK JJ, 1989, IEEE T PATTERN ANAL, V11, P43, DOI 10.1109/34.23112; CLARK JJ, 1988, IEEE T PATTERN ANAL, V10, P720, DOI 10.1109/34.6782; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DEMICHELI E, 1989, IEEE T PATTERN ANAL, V11, P1106, DOI 10.1109/34.42841; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; Fleck M. M., 1989, Fifth Alvey Vision Conference AVC89. Proceedings of the Fifth Alvey Vision Conference, P127; FLECK MM, 1992, IEEE T PATTERN ANAL, V14, P337, DOI 10.1109/34.120328; FLECK MM, 1988, IMAGE VISION COMPUT, V6, P75, DOI 10.1016/0262-8856(88)90002-9; FLECK MM, 1985, TR1065 AI LAB; Forsyth D., 1989, Fifth Alvey Vision Conference AVC89. Proceedings of the Fifth Alvey Vision Conference, P193; FRAM JR, 1975, IEEE T COMPUT, VC 24, P616, DOI 10.1109/T-C.1975.224274; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gennert M. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P552; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P121, DOI 10.1109/TPAMI.1985.4767628; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HARALICK RM, 1985, IEEE T PATTERN ANAL, V7, P127, DOI 10.1109/TPAMI.1985.4767629; HARTLEY R, 1985, COMPUT VISION GRAPH, V30, P70, DOI 10.1016/0734-189X(85)90019-2; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; Hoff W., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P284; HORN BKP, 1978, P DARPA IMAGE UNDERS, P56; Huang K., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P225; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; HUTTENLOCHER DP, 1988, THESIS MIT; KORN AF, 1988, IEEE T PATTERN ANAL, V10, P610, DOI 10.1109/34.6770; Leclerc Y., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P34; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Lee D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P215, DOI 10.1109/CVPR.1988.196239; Lee D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P2, DOI 10.1109/CVPR.1989.37822; MACLEOD IDG, 1972, PR INST ELECTR ELECT, V60, P344, DOI 10.1109/PROC.1972.8642; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MCIVOR AM, 1989, UNPUB CAMERA NOISE M; MCKENDALL R, 1987, UNPUB MODELS SENSOR; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; Noble J. A., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P222; NOBLE JA, 1988, P INT C COMPUT VISIO, P112; NOBLE JA, 1989, THESIS U OXFORD; Parvin B., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P23; PEARSON DE, 1985, P IEEE, V73, P795, DOI 10.1109/PROC.1985.13202; Persoon E., 1976, COMPUTER GRAPHICS IM, V5, P425, DOI DOI 10.1016/S0146-664X(76)80030-5; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROSENFEL.A, 1970, PR INST ELECTR ELECT, V58, P814, DOI 10.1109/PROC.1970.7756; Schunk B. G., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P208; Sher D., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P35; SHER DB, 1987, TR232 U ROCH DEP COM; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; WATT RJ, 1985, VISION RES, V25, P1661, DOI 10.1016/0042-6989(85)90138-5; WATT RJ, 1984, VISION RES, V24, P1387, DOI 10.1016/0042-6989(84)90194-9; WILLIAMS DR, 1988, VISION RES, V28, P433, DOI 10.1016/0042-6989(88)90185-X; WILLIAMS DR, 1985, VISION RES, V25, P195, DOI 10.1016/0042-6989(85)90113-0; Yellott J., 1984, HDB PHYSL NERVOUS SY, P257; YELLOTT JI, 1983, SCIENCE, V221, P382, DOI 10.1126/science.6867716; Young R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P564	73	21	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					412	429		10.1109/34.126804	http://dx.doi.org/10.1109/34.126804			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193					2022-12-18	WOS:A1992HL19300002
J	ALOIMONOS, J; HERVE, JY				ALOIMONOS, J; HERVE, JY			CORRESPONDENCELESS STEREO AND MOTION - PLANAR SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											ALOIMONOS, J (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							ADIV G, 1984, 8407 U MASS DEP COIN; ADIV G, 1985 P CVPR, P70; ALOIMONOS J, 1984, P IEEE WORKSHOP COMP, P83; ALOIMONOS J, 1988, CARTR357 U MAR CTR A; Bandyopadhyay A., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P78; BANDYOPADHYAY A, 1985, 157 U ROCH DEP COMP; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P313, DOI 10.1016/0734-189X(83)90029-4; FANG JQ, 1984, COMPUT VISION GRAPH, V26, P183, DOI 10.1016/0734-189X(84)90182-8; Haralick R. M., 1983, P IMAGE UNDERSTANDIN, P84; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1987, 1ST P ICCV, P12; HUANG TS, 1985, P TOPICAL M COMPUTER; HUANG TS, 1985 P CVPR, P518; ITO E, 1987, IEEE J ROBOTIC AUTOM, P78; JENKIN M, 1986, COMPUT VISION GRAPH, V33, P16, DOI 10.1016/0734-189X(86)90219-7; KANADE T, 1985, MAR P ANN M OPT SOC; KANATANI K, 1985, COMPUT VISION GRAPH, V29, P1, DOI 10.1016/S0734-189X(85)90146-X; KITCHEN L, 1980, TR887 U MAR DEP COMP; KUPERMAN IB, 1971, APPROXIMATE LINEAR A; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P332; Matsushima Y., 1972, DIFFERENTIABLE MANIF; MORAVEC HP, 1977, 5TH P IJCAI; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NEGADARIPOUR S, 1985, P 9 INT JOINT C ART, P898; PRAGER JM, 1983, CVGIP, V21, P272; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P94; RICHARDS W, 1985, J OPT SOC AM A, V2; RIEGER JH, 1983, 831 U MASS DEP COINS; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SARACHAN B, 1985, TR152 U ROCH DEP COM; SUBBARAO M, 1986, CVGIP, V36, P374; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TSAI RY, 1982, MAY P IEEE C ASSP; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30; TSAI RY, 1984, UNIQUENESS ESTIMATIO, P135; ULLMAN S, 1981, COMPUTER, V14, P51; WAXMAN A, 1986, P WORKSHOP MOTION, P65; WAXMAN AM, 1985, INT J ROBOTICS RES, V4	41	21	21	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1990	12	5					504	510		10.1109/34.55111	http://dx.doi.org/10.1109/34.55111			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DA035					2022-12-18	WOS:A1990DA03500010
J	YAMADA, H; MERRITT, C; KASVAND, T				YAMADA, H; MERRITT, C; KASVAND, T			RECOGNITION OF KIDNEY GLOMERULUS BY DYNAMIC-PROGRAMMING MATCHING METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									NATL RES COUNCIL CANADA,DIV ELECT ENGN,OTTAWA K1A 0R6,ONTARIO,CANADA	National Research Council Canada	YAMADA, H (corresponding author), ELECTROTECH LAB,DIV INFORMAT SCI,TSUKUBA,IBARAKI 305,JAPAN.							Ballard D.H., 1982, COMPUTER VISION; Bellman RE, 1957, DYNAMIC PROGRAMMING; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; Kovalevsky V A, 1980, IMAGE PATTERN RECOGN; KOVALEVSKY VA, P IFIP C, V68, P1603; LEVINE MD, 1981, COMPUT VISION GRAPH, V16, P185, DOI 10.1016/0146-664X(81)90037-X; MARTELLI A, P IFIP C, V71, P173; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; NEY H, 1982, 6TH P INT C PATT REC, P1119; SAKOE H, 1974, PRL7420 IECE TECH RE; Yamada H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P95; Yamada H., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P389; YAMADA H, 1985, T IECE JAPAN JD, V68, P1649	14	21	22	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					731	737		10.1109/34.6784	http://dx.doi.org/10.1109/34.6784			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500015
J	YE, QZ; DANIELSSON, PE				YE, QZ; DANIELSSON, PE			INSPECTION OF PRINTED-CIRCUIT BOARDS BY CONNECTIVITY PRESERVING SHRINKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											YE, QZ (corresponding author), LINKOPING UNIV,DEPT ELECT ENGN,S-58183 LINKOPING,SWEDEN.							CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; DANIELSSON PE, 1979, COMPUT VISION GRAPH, V11, P349, DOI 10.1016/0146-664X(79)90070-4; DANIELSSON PE, 1979, Patent No. 4170003; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; Hilditch C.J., 1969, MACH INTELL, P403; MANDEVILLE JR, 1985, IBM J RES DEV, V29, P73, DOI 10.1147/rd.291.0073; MUDGE TN, 1982, 19TH P DES AUT C; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SANZ JLC, 1986, J OPT SOC AM A, V3, P1465, DOI 10.1364/JOSAA.3.001465; SILVEN O, 1984, IEEE P INT C PATTERN, P1355; Ye Q., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P2; YE QZ, 1985, LITHISYI0762 LINK U	13	21	27	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					737	742		10.1109/34.6785	http://dx.doi.org/10.1109/34.6785			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500016
J	KUNDU, A; MITRA, SK				KUNDU, A; MITRA, SK			A NEW ALGORITHM FOR IMAGE EDGE EXTRACTION USING A STATISTICAL CLASSIFIER APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF SANTA BARBARA,DEPT ELECT & COMP ENGN,SIGNAL PROC LAB,SANTA BARBARA,CA 93106	University of California System; University of California Santa Barbara	KUNDU, A (corresponding author), SUNY BUFFALO,DEPT ELECT ENGN,BUFFALO,NY 14260, USA.							ADBOU IE, 1979, P IEEE, V67, P753; BASSEVILLE M, 1981, IEEE T ACOUST SPEECH, V29, P24, DOI 10.1109/TASSP.1981.1163523; Duda R.O., 1973, J ROYAL STAT SOC SER; FRAM JR, 1975, IEEE T COMPUT, VC 24, P616, DOI 10.1109/T-C.1975.224274; GRAHAM RE, 1966, IRE T INFORM THEOR, V8, P129; GRIFFITH AK, 1973, IEEE T COMPUT, VC 22, P371, DOI 10.1109/T-C.1973.223724; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; KUNDU A, 1984, IEEE T ACOUST SPEECH, V32, P600, DOI 10.1109/TASSP.1984.1164364; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; MARTELLI A, 1972, COMPUTER GRAPHICS IM, V1, P169, DOI DOI 10.1016/S0146-664X(72)80013-3; MASCARENHAS N, 1978, P IJPCR, V14, P707; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; NAHI NE, 1978, IEEE T AUTOMAT CONTR, V23, P834, DOI 10.1109/TAC.1978.1101841; Parzen E., 1960, MODERN PROBABILITY T, DOI 10.1063/1.3056709; PELI T, 1982, COMPUT VISION GRAPH, V20, P1, DOI 10.1016/0146-664X(82)90070-3; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RAO CR, 1973, LINEAR STATISTICAL I; Robinson G.S., 1977, COMPUT VISION GRAPH, V6, P492, DOI 10.1016/s0146-664x(77)80024-5; ROSENFEL.A, 1970, PR INST ELECTR ELECT, V58, P814, DOI 10.1109/PROC.1970.7756; ROSENFELD A, 1982, PICTURE PROCESSING C; SHAW GB, 1979, COMPUT VISION GRAPH, V9, P135, DOI 10.1016/0146-664X(79)90053-4; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981	26	21	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1987	9	4					569	577		10.1109/TPAMI.1987.4767944	http://dx.doi.org/10.1109/TPAMI.1987.4767944			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H9088	21869414				2022-12-18	WOS:A1987H908800010
J	THOMASON, MG; GRANUM, E				THOMASON, MG; GRANUM, E			DYNAMIC-PROGRAMMING INFERENCE OF MARKOV NETWORKS FROM FINITE SETS OF SAMPLE STRINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									AALBORG UNIV,INST ELECTR SYST,DK-9000 AALBORG,DENMARK	Aalborg University	THOMASON, MG (corresponding author), UNIV TENNESSEE,DEPT COMP SCI,KNOXVILLE,TN 37996, USA.							ABRAMSON N, 1963, INFORMATION THEORY C; ANDERSON TW, 1957, ANN MATH STAT, V28, P89, DOI 10.1214/aoms/1177707039; ASH R, 1965, INFORMATION THEORY; Baum LE, 1972, INEQUALITIES, V3, P1; BAUM LE, 1966, ANN MATH STAT, V37, P1559; FU KS, 1982, SYNTACTIC PATTERN RE; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; GRANLUND GH, 1976, IEEE T BIO-MED ENG, V23, P182, DOI 10.1109/TBME.1976.324629; GRANUM E, 1980, THESIS TU DENMARK; GRANUM E, 1982, PATTERN RECOGNITION; KEMENY JG, 1972, FINITE MARKOV CHAINS; Kruskal J.B., 1983, TIME WARPS STRING ED; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; LUNDSTEEN C, 1980, CLIN GENET, V18, P355; Parzen E., 1962, STOCHASTIC PROCESSES; PIPER J, 1980, SIGNAL PROCESS, V2, P203, DOI 10.1016/0165-1684(80)90019-5; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	17	21	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					491	501		10.1109/TPAMI.1986.4767813	http://dx.doi.org/10.1109/TPAMI.1986.4767813			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000008
J	LUH, JYS; KLAASEN, JA				LUH, JYS; KLAASEN, JA			A 3-DIMENSIONAL VISION BY OFF-SHELF SYSTEM WITH MULTI-CAMERAS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									IBM CORP,BOCA RATON,FL 33432	International Business Machines (IBM)	LUH, JYS (corresponding author), CLEMSON UNIV,DEPT ELECT & COMP ENGN,CLEMSON,SC 29631, USA.							LOZANOPEREZ T, 1983, IEEE T COMPUT, V32, P108, DOI 10.1109/TC.1983.1676196; LUH JYS, 1983, IEEE T AUTOMAT CONTR, V28, P133, DOI 10.1109/TAC.1983.1103216; LUH JYS, 1984, IEEE T AUTOMAT CONTR, V29, P675, DOI 10.1109/TAC.1984.1103640; LUH JYS, 1984, J ROBOTIC SYST, V1, P5; NEVATIA R, 1982, MACHINE PERCEPTION, P158; NITZAN D, 1979, SRI9TH INT REP; THOMPSON A, 1981, ROBOTICS AGE, V3, P20; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	8	21	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					35	45		10.1109/TPAMI.1985.4767616	http://dx.doi.org/10.1109/TPAMI.1985.4767616			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869238				2022-12-18	WOS:A1985ABF0900003
J	SAMET, H; SHAFFER, CA				SAMET, H; SHAFFER, CA			A MODEL FOR THE ANALYSIS OF NEIGHBOR FINDING IN POINTER-BASED QUADTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	SAMET, H (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							Brodatz P., 1966, TEXTURES; DEMILLO RA, 1978, COMMUN ACM, V21, P228, DOI 10.1145/359361.359447; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; JACKINS CL, 1983, IEEE T PATTERN ANAL, V5, P533, DOI 10.1109/TPAMI.1983.4767433; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; KLINGER A, 1971, OPTIMIZING METHODS S, P303; SAMET H, 1982, COMPUT VISION GRAPH, V18, P37, DOI 10.1016/0146-664X(82)90098-3; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SAMET H, 1983, IEEE T SYST MAN CYB, V13, P1148, DOI 10.1109/TSMC.1983.6313192; SAMET H, 1985, IEEE T PATTERN ANAL, V7, P94, DOI 10.1109/TPAMI.1985.4767622; SAMET H, 1984, TR1432 U MAR DEP COM; [No title captured], DOI DOI 10.1145/356924.356930	14	21	22	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					717	720		10.1109/TPAMI.1985.4767729	http://dx.doi.org/10.1109/TPAMI.1985.4767729			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869311				2022-12-18	WOS:A1985ATG0500011
J	AHUJA, N; SWAMY, S				AHUJA, N; SWAMY, S			MULTIPROCESSOR PYRAMID ARCHITECTURES FOR BOTTOM-UP IMAGE-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS,DEPT ELECT ENGN,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	AHUJA, N (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; AHUJA N, 1981, AUG P PATT REC IM PR, P75; BATCHER KE, 1982, IEEE T COMPUT, V31, P377, DOI 10.1109/TC.1982.1676015; BURT PJ, 1980, TR927 U MAR COMP SCI; DUBITZKI T, 1981, IEEE T PATTERN ANAL, V3, P626, DOI 10.1109/TPAMI.1981.4767163; Duff M. J. B., 1976, 3rd International Joint Conference on Pattern Recognition, P728; DYER CR, 1981, AUG P PRIP 81, P381; DYER CR, 1978, THESIS U MARYLAND CO; DYER CR, 1979, TR769 U MAR COMP SCI; Hanson A., 1978, COMPUTER VISION SYST; KELLY MD, 1971, MACH INTELL, V6, P379; LEVINE MD, 1978, COMPUTER VISION SYST, P335; NAKAMURA A, 1978, 4TH P INT JOINT C PA, P474; PRICE K, 1977, 5TH P INT JOINT C AR, P619; REDDAWAY SF, 1983, 1ST P ANN S COMP ARC, P61; RIEGER C, 1981, NOV IEEE COMP SOC WO, P119; ROSENFELD A, 1980, 5TH P INT C PATT REC, P802; Rosenfeld A., 1979, PICTURE LANGUAGES; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SAMET H, 1980, 5TH P INT C PATT REC, P815; SCHNEIER M, 1980, TR961 U MAR COMP SCI; SIEGEL HJ, 1981, IEEE T COMPUT, V30, P934, DOI 10.1109/TC.1981.1675732; SWAMY S, UNPUB BOTTOM CONNECT; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; Tanimoto S. L., 1976, Computer Graphics and Image Processing, V5, P333, DOI 10.1016/S0146-664X(76)80012-3; UHR L, 1972, IEEE T COMPUT, VC 21, P758, DOI 10.1109/T-C.1972.223579; UHR L, 1981, P IEEE WORKSHOP COMP, P209	27	21	21	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					463	475		10.1109/TPAMI.1984.4767551	http://dx.doi.org/10.1109/TPAMI.1984.4767551			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869214				2022-12-18	WOS:A1984SY28900007
J	JERIAN, C; JAIN, R				JERIAN, C; JAIN, R			DETERMINING MOTION PARAMETERS FOR SCENES WITH TRANSLATION AND ROTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											JERIAN, C (corresponding author), UNIV MICHIGAN,DEPT ELECT & COMP ENGN,ANN ARBOR,MI 48109, USA.							DRESCHLER L, 1981, P IJCAI VANCOUVER; DRESCHLER L, 1981, P GI WORKSHOP ARTIFI; FANG JQ, P IJCAI 83, P1033; Fischler M. A., 1982, P AM ASS ART INT 82, P30; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GLAZER F, 1981, P IJCAI; HILL R, 1980, THESIS WAYNE STATE U; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jain R., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P262; JERIAN C, 1983, ACM SIGGRAPH SIGART, P71; JERIAN C, 1982, THESIS WAYNE STATE U; KITCHEN L, 1980, TR887 U MAR COMP SCI; LAWTON DT, 1983, APR P MOT REPR PERC, P33; LAWTON DT, P WORKSHOP COMPUT VI, P59; Moravec H., 1980, THESIS STANFORD U ST; Moravec H., 1977, P 5 INT JOINT C ART, VVolume 1, P584; MORAVEC HP, 1979, 6TH P INT JOINT C AR, P598; NAGEL HH, 1981, P IJCAI; NAGEL HH, 1981, P IEEE C PATTERN REC; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; PRAZDNY K, 1979, 6TH P INT JOINT C AR, P702; PRAZDNY K, 1981, P INT JOINT C ART IN, P698; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Tsai R. Y., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P112; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30, P525, DOI 10.1109/TASSP.1982.1163931; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; TSAI RY, 1982, P SPIE, V359; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, P ROYAL SOC LONDON, VB, P405	30	21	23	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					523	530		10.1109/TPAMI.1984.4767558	http://dx.doi.org/10.1109/TPAMI.1984.4767558			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869221	Green Submitted			2022-12-18	WOS:A1984SY28900014
J	JONES, LP; IYENGAR, SS				JONES, LP; IYENGAR, SS			SPACE AND TIME EFFICIENT VIRTUAL QUADTRESS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									LOUISIANA STATE UNIV,DEPT COMP SCI,BATON ROUGE,LA 70803	Louisiana State University System; Louisiana State University								ALEXANDRIDIS N, 1978, COMPUT VISION GRAPH, V8, P43, DOI 10.1016/S0146-664X(78)80030-6; DYER RC, 1980, COMMUN ASS COMPUT MA, V23, P170; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; JONES L, 1981, AUG P IEEE C PATT RE, P57; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; Knuth D. E., 1969, ART COMPUTER PROGRAM, V1; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Pavlidis T., 1976, ACM Transactions on Mathematical Software, V2, P305, DOI 10.1145/355705.355706; SAMET H, 1980, COMPUT VISION GRAPH, V13, P88, DOI 10.1016/0146-664X(80)90118-5; SAMET H, 1981, IEEE T PATTERN ANAL, V3, P93, DOI 10.1109/TPAMI.1981.4767054; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; TANIMOTO SL, 1980, IMAGE DATA STRUCTURE	13	21	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					244	247		10.1109/TPAMI.1984.4767508	http://dx.doi.org/10.1109/TPAMI.1984.4767508			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869188				2022-12-18	WOS:A1984SF59100011
J	PURDOM, PW				PURDOM, PW			SOLVING SATISFIABILITY WITH LESS SEARCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											PURDOM, PW (corresponding author), INDIANA UNIV,DEPT COMP SCI,BLOOMINGTON,IN 47405, USA.							BIBEL W, 1981, J ACM, V28, P633, DOI 10.1145/322276.322277; Bobrow D. G., 1974, Computing Surveys, V6, P153, DOI 10.1145/356631.356632; DAVIS M, 1960, J ACM, V7, P201, DOI 10.1145/321033.321034; DAVIS M, 1962, COMMUN ACM, V5, P394, DOI 10.1145/368273.368557; FREUDER EC, 1982, J ACM, V29, P24, DOI 10.1145/322290.322292; Garey M.R., 1979, COMPUTERS INTRACTABI; GASCHNIG J, 1979, THESIS CARNEGIEMELLO; GOLDBERG A, 1983, INFORM PROCESS LETT, V16, P213, DOI 10.1016/0020-0190(83)90127-8; GOLDBERG A, 1982, INFORM PROCESS LETT, V15, P72, DOI 10.1016/0020-0190(82)90110-7; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; MONIEN B, 1979, UNPUB DISCRETE MATH; PURDOM PW, 1981, ACTA INFORM, V15, P99, DOI 10.1007/BF00288958; PURDOM PW, 1982, P NAT C ARTIFICAL IN, P124; PURDOM PW, 1982, 128 IND U COMP SCI T; ROBINSON JA, 1965, J ACM, V12, P23, DOI 10.1145/321250.321253	15	21	21	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					510	513		10.1109/TPAMI.1984.4767555	http://dx.doi.org/10.1109/TPAMI.1984.4767555			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SY289	21869218				2022-12-18	WOS:A1984SY28900011
J	WANG, YF; MAGEE, MJ; AGGARWAL, JK				WANG, YF; MAGEE, MJ; AGGARWAL, JK			MATCHING 3-DIMENSIONAL OBJECTS USING SILHOUETTES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV TEXAS,AUSTIN,TX 78712; UNIV WYOMING,LARAMIE,WY 82071	University of Texas System; University of Texas Austin; University of Wyoming	WANG, YF (corresponding author), LAB IMAGE & SIGNAL ANAL,AUSTIN,TX 78712, USA.		Rohlf, F J/A-8710-2008					CHAKRAVARTY I, 1982, IPLTR034 RENSS POL I; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; LIKINS PW, 1973, ELEMENTS ENG MECHANI; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MARTIN WN, 1981, AUG P C PATT REC IM, P189; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; WALLACE TP, 1980, IEEE T PATTERN ANAL, V2, P583, DOI 10.1109/TPAMI.1980.6447707; WATSON LT, 1982, IEEE T PATTERN ANAL, V4, P469, DOI 10.1109/TPAMI.1982.4767290; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; 1979, MAY WORKSH REPR 3 DI	11	21	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					513	518		10.1109/TPAMI.1984.4767556	http://dx.doi.org/10.1109/TPAMI.1984.4767556			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SY289	21869219				2022-12-18	WOS:A1984SY28900012
J	DYER, CR				DYER, CR			GAUGE INSPECTION USING HOUGH TRANSFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									INT HARVESTER CO,SCI & TECHNOL LAB,DEPT AUTOMAT TECHNOL,HINSDALE,IL 60521		DYER, CR (corresponding author), UNIV WISCONSIN,DEPT COMP SCI,MADISON,WI 53706, USA.							BAIRD ML, 1982, 1982 WORKSH IND APPL, P108; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; KENDER JR, 1979, 6 IJCAI TOK, P475; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; TROMBLY JE, 1982, MAR P ROB DETR, V6	8	21	22	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					621	623		10.1109/TPAMI.1983.4767452	http://dx.doi.org/10.1109/TPAMI.1983.4767452			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869149				2022-12-18	WOS:A1983RV48800009
J	KAWAGUCHI, E; ENDO, T; MATSUNAGA, J				KAWAGUCHI, E; ENDO, T; MATSUNAGA, J			DEPTH-1ST PICTURE EXPRESSION VIEWED FROM DIGITAL PICTURE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									OITA UNIV,DEPT INFORMAT SCI & SYST ENGN,OITA 87011,JAPAN	Oita University	KAWAGUCHI, E (corresponding author), KYUSHU UNIV,INTERDISCIPLINARY GRAD SCH ENGN SCI,DEPT INFORMAT SYST,KASUGA,FUKUOKA 816,JAPAN.							DECOULON F, 1976, ELECTRON LETT, V12, P61, DOI 10.1049/el:19760050; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; ENDO T, 1981, ENG SCI REP KYUSHU U, V2, P1; ENDO T, 1979, T IECE JAPAN D, V62; HUANG TS, 1977, IEEE T COMMUN, V25, P1406, DOI 10.1109/TCOM.1977.1093775; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; ICHIKAWA T, 1978, 4TH IJCPR, P603; KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967; KAWAGUCHI E, 1980, 5TH P INT C PATT REC, P822; Kawaguchi E. W., 1981, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE64, P71; KLINGER A, 1971, OPTIMIZING METHODS S; KUNT M, 1977, INFORM CONTROL, V33, P333, DOI 10.1016/S0019-9958(77)90461-2; KUNT M, 1980, P IEEE, V68; TANIGUCHI R, 1982, 6TH P ICPR; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104	15	21	22	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					373	384		10.1109/TPAMI.1983.4767407	http://dx.doi.org/10.1109/TPAMI.1983.4767407			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869122				2022-12-18	WOS:A1983RA57800003
J	Dong, XY; Liu, L; Musial, K; Gabrys, B				Dong, Xuanyi; Liu, Lu; Musial, Katarzyna; Gabrys, Bogdan			NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Topology; Microprocessors; Benchmark testing; Training; Search problems; Deep learning; Neural architecture search; benchmark; deep learning		Neural architecture search (NAS) has attracted a lot of attention and has been illustrated to bring tangible benefits in a large number of applications in the past few years. Architecture topology and architecture size have been regarded as two of the most important aspects for the performance of deep learning models and the community has spawned lots of searching algorithms for both of those aspects of the neural architectures. However, the performance gain from these searching algorithms is achieved under different search spaces and training setups. This makes the overall performance of the algorithms incomparable and the improvement from a sub-module of the searching model unclear. In this paper, we propose NATS-Bench, a unified benchmark on searching for both topology and size, for (almost) any up-to-date NAS algorithm. NATS-Bench includes the search space of 15,625 neural cell candidates for architecture topology and 32,768 for architecture size on three datasets. We analyze the validity of our benchmark in terms of various criteria and performance comparison of all candidates in the search space. We also show the versatility of NATS-Bench by benchmarking 13 recent state-of-the-art NAS algorithms on it. All logs and diagnostic information trained using the same setup for each candidate are provided. This facilitates a much larger community of researchers to focus on developing better NAS algorithms in a more comparable and computationally effective environment. All codes are publicly available at: https://xuanyidong.com/assets/projects/NATS-Bench.	[Dong, Xuanyi; Liu, Lu; Musial, Katarzyna; Gabrys, Bogdan] Univ Technol Sydney, Sch Comp Sci, Ultimo, NSW 2007, Australia	University of Technology Sydney	Dong, XY (corresponding author), Univ Technol Sydney, Sch Comp Sci, Ultimo, NSW 2007, Australia.	Xuanyi.Dxy@gmail.com; Lu.Liu.Cs@icloud.com; Katarzyna.Musial-Gabrys@uts.edu.au; Bogdan.Gabrys@uts.edu.au		Musial-Gabrys, Katarzyna/0000-0001-6038-7647; Gabrys, Bogdan/0000-0002-0790-2846	Google Cloud Credits from GCP Education Programs	Google Cloud Credits from GCP Education Programs	The authors would like to thank Gabriel Bender, Pieter-Jan Kindermans, and Hanxiao Liu for their suggestions on experiments. Part of this project was supported by Google Cloud Credits from GCP Education Programs.	Baker B., 2018, ICLR; Bender Gabriel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14311, DOI 10.1109/CVPR42600.2020.01433; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Brock A., 2018, ICLR, P1; Cai H., 2020, ICLR, P1; Cai H, 2018, AAAI CONF ARTIF INTE, P2787; Chen TH, 2015, DES AUT CON, DOI 10.1145/2744769.2744837; Chrabaszcz P., 2017, ARXIV 170708819; Dong X., 2020, PROC INT C LEARN REP; Dong X., 2020, ARXIV 200603656; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Dong XY, 2017, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR.2017.205; Falkner S, 2018, PR MACH LEARN RES, V80; Ghiasi G, 2018, ADV NEUR IN, V31; Gu Y.-C., 2020, ARXIV 201000969; Han D, 2017, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR.2017.668; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; KENDALL MG, 1945, BIOMETRIKA, V33, P239, DOI 10.2307/2332303; Klein A., 2019, ARXIV 190504970; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Li L, 2019, 35 C UNC ART INT UAI, P1; Lindauer M, 2020, J MACH LEARN RES, V21; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Loshchilov I., 2017, P INT C LEARNING REP; Peng DY, 2020, UEEE INT SYM PERS IN; Pham H, 2018, PR MACH LEARN RES, V80; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shu Yao, 2020, INT C LEARN REPR; Simonyan K., 2015, ICLR; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Tan MX, 2019, PR MACH LEARN RES, V97; Vaswani A, 2017, ADV NEUR IN, V30; Wan Alvin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12962, DOI 10.1109/CVPR42600.2020.01298; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Yang Yi, 2019, ADV NEUR IN, P760; Ying C, 2019, PR MACH LEARN RES, V97; Yu JH, 2019, IEEE I CONF COMP VIS, P1803, DOI 10.1109/ICCV.2019.00189; Yu K., 2020, C LEARN REPR ICLR; Zela A., 2020, INT C LEARN REPRESEN; Zhang C, 2019, INT C LEARN REPR; Zhang Hongyi, 2017, ARXIV171009412, DOI DOI 10.1007/978-3-030-01231-1_31; Zoph B., 2017, PROC INT C LEARN REP; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	53	20	20	9	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3634	3646		10.1109/TPAMI.2021.3054824	http://dx.doi.org/10.1109/TPAMI.2021.3054824			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33497330	Green Submitted			2022-12-18	WOS:000805820500022
J	Huang, ZL; Wei, YC; Wang, XG; Liu, WY; Huang, TS; Shi, H				Huang, Zilong; Wei, Yunchao; Wang, Xinggang; Liu, Wenyu; Huang, Thomas S.; Shi, Humphrey			AlignSeg: Feature-Aligned Segmentation Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic segmentation; feature alignment; context alignment		Aggregating features in terms of different convolutional blocks or contextual embeddings has been proven to be an effective way to strengthen feature representations for semantic segmentation. However, most of the current popular network architectures tend to ignore the misalignment issues during the feature aggregation process caused by step-by-step downsampling operations and indiscriminate contextual information fusion. In this paper, we explore the principles in addressing such feature misalignment issues and inventively propose Feature-Aligned Segmentation Networks (AlignSeg). AlignSeg consists of two primary modules, i.e., the Aligned Feature Aggregation (AlignFA) module and the Aligned Context Modeling (AlignCM) module. First, AlignFA adopts a simple learnable interpolation strategy to learn transformation offsets of pixels, which can effectively relieve the feature misalignment issue caused by multi-resolution feature aggregation. Second, with the contextual embeddings in hand, AlignCM enables each pixel to choose private custom contextual information adaptively, making the contextual embeddings be better aligned. We validate the effectiveness of our AlignSeg network with extensive experiments on Cityscapes and ADE20K, achieving new state-of-the-art mIoU scores of 82.6 and 45.95 percent, respectively.	[Huang, Zilong; Wang, Xinggang; Liu, Wenyu] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China; [Wei, Yunchao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China; [Wei, Yunchao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China; [Huang, Thomas S.] Univ Illinois, Beckman Inst, Dept Elect & Comp Engn, Urbana, IL 61801 USA; [Shi, Humphrey] Univ Oregon, Comp Sci, Eugene, OR 97403 USA; [Shi, Humphrey] Univ Illinois, Elect & Informat Engn, Urbana, IL 61801 USA; [Shi, Humphrey] Picsart AI Res, San Francisco, CA 94105 USA	Huazhong University of Science & Technology; Beijing Jiaotong University; Beijing Jiaotong University; University of Illinois System; University of Illinois Urbana-Champaign; University of Oregon; University of Illinois System; University of Illinois Urbana-Champaign	Wang, XG (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.	hzl@hust.edu.cn; wychao1987@gmail.com; xgwang@hust.edu.cn; liuwy@hust.edu.cn; t-huang1@illinois.edu; hshi10@illinois.edu	Liu, Wenyu/AAG-1426-2019	Liu, Wenyu/0000-0002-4582-7488; Wang, Xinggang/0000-0001-6732-7823	NSFC [61876212, 61733007]; China Scholarship Council; IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR) -a research collaboration as part of the IBM AI Horizons Network	NSFC(National Natural Science Foundation of China (NSFC)); China Scholarship Council(China Scholarship Council); IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR) -a research collaboration as part of the IBM AI Horizons Network(International Business Machines (IBM))	This work was supported in part by the NSFC (No. 61876212 and No. 61733007), China Scholarship Council, and IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR) -a research collaboration as part of the IBM AI Horizons Network.	Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Berg A.C., 2015, ARXIV150604579; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen Yuntao, 2019, ARXIV190801570; Chiu MT, 2020, PROC CVPR IEEE, P2825, DOI 10.1109/CVPR42600.2020.00290; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Evening M., 2012, ADOBE PHOTOSHOP CS3; Fritsch J, 2013, IEEE INT C INTELL TR, P1693, DOI 10.1109/ITSC.2013.6728473; Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang Zilong, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3007032; Huang ZL, 2020, IEEE T IMAGE PROCESS, V29, P2066, DOI 10.1109/TIP.2019.2941644; Jaderberg M, 2015, ADV NEUR IN, V28; Jiao JB, 2019, PROC CVPR IEEE, P2864, DOI 10.1109/CVPR.2019.00298; Ke TW, 2018, LECT NOTES COMPUT SC, V11205, P605, DOI 10.1007/978-3-030-01246-5_36; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336; Mazzini D., 2018, P INT C LEARN REPR; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Pang YW, 2019, IEEE I CONF COMP VIS, P4229, DOI 10.1109/ICCV.2019.00433; Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189; Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163; Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26; Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388; Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20; Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199; Yu F., 2016, P ICLR 2016; Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255; Yuan Y., 2018, ARXIV180900916; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224; Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660	54	20	21	22	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					550	557		10.1109/TPAMI.2021.3062772	http://dx.doi.org/10.1109/TPAMI.2021.3062772			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	33646946	Green Submitted			2022-12-18	WOS:000728561300039
J	Peng, L; Yang, Y; Wang, Z; Huang, Z; Shen, HT				Peng, Liang; Yang, Yang; Wang, Zheng; Huang, Zi; Shen, Heng Tao			MRA-Net: Improving VQA Via Multi-Modal Relation Attention Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual question answering; visual relation; attention mechanism; relation attention		Visual Question Answering (VQA) is a task to answer natural language questions tied to the content of visual images. Most recent VQA approaches usually apply attention mechanism to focus on the relevant visual objects and/or consider the relations between objects via off-the-shelf methods in visual relation reasoning. However, they still suffer from several drawbacks. First, they mostly model the simple relations between objects, which results in many complicated questions cannot be answered correctly, because of failing to provide sufficient knowledge. Second, they seldom leverage the harmony cooperation of visual appearance feature and relation feature. To solve these problems, we propose a novel end-to-end VQA model, termed Multi-modal Relation Attention Network (MRA-Net). The proposed model explores both textual and visual relations to improve performance and interpretability. In specific, we devise 1) a self-guided word relation attention scheme, which explore the latent semantic relations between words; 2) two question-adaptive visual relation attention modules that can extract not only the fine-grained and precise binary relations between objects but also the more sophisticated trinary relations. Both kinds of question-related visual relations provide more and deeper visual semantics, thereby improving the visual reasoning ability of question answering. Furthermore, the proposed model also combines appearance feature with relation feature to reconcile the two types of features effectively. Extensive experiments on five large benchmark datasets, VQA-1.0, VQA-2.0, COCO-QA, VQA-CP v2, and TDIUC, demonstrate that our proposed model outperforms state-of-the-art approaches.	[Peng, Liang; Yang, Yang; Wang, Zheng; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Peoples R China; [Peng, Liang; Yang, Yang; Wang, Zheng; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China; [Yang, Yang] Univ Elect Sci & Technol China UESTC, Inst Elect & Informat Engn, Dongguan 523808, Guangdong, Peoples R China; [Huang, Zi] Univ Queensland, St Lucia, Qld 4072, Australia	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; University of Queensland	Yang, Y (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Peoples R China.	pliang951125@outlook.com; dlyyang@gmail.com; zh_wang@hotmail.com; huang@itee.uq.edu.au; shenhengtao@hotmail.com	yang, yang/GVT-5210-2022; yang, yang/HGT-7999-2022	Liang, Peng/0000-0002-0576-1429; WANG, Zheng/0000-0002-9318-0084	National Key Research and Development Program of China [2018AAA0102200]; Sichuan Science and Technology Program, China [2018GZDZX0032, 2020YFS0057]; Fundamental Research Funds for the Central Universities [ZYGX2019Z015]; National Natural Science Foundation of China [61632007]; Dongguan Songshan Lake Introduction Programof Leading Innovative and Entrepreneurial Talents	National Key Research and Development Program of China; Sichuan Science and Technology Program, China; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Dongguan Songshan Lake Introduction Programof Leading Innovative and Entrepreneurial Talents	This work was supported in part by National Key Research and Development Program of China under Grant No. 2018AAA0102200, the Sichuan Science and Technology Program, China, under Grant 2018GZDZX0032 and 2020YFS0057, the Fundamental Research Funds for the Central Universities under Project ZYGX2019Z015, the National Natural Science Foundation of China under Grants 61632007 and Dongguan Songshan Lake Introduction Programof Leading Innovative and Entrepreneurial Talents.	Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Ben-Younes H, 2019, AAAI CONF ARTIF INTE, P8102; Bin Y, 2019, AAAI CONF ARTIF INTE, P8110; Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447; Bin Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1345, DOI 10.1145/3123266.3123391; Bin Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P436, DOI 10.1145/2964284.2967258; Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209; Cho K., 2014, P SSST 8 8 WORKSH SY, P103; Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637; Fukui Akira, 2016, ARXIV160601847; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Han CJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P510, DOI 10.1145/3240508.3240611; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Ilievski I, 2017, ADV NEUR IN, V30; Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947; Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217; Kim JH, 2018, ADV NEUR IN, V31; Kingma D.P, P 3 INT C LEARNING R; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; LI L, 2019, P INT C COMP VIS, P322; Li R., 2016, ADV NEURAL INF PROCE, P4655; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin YT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4216; Lu JS, 2016, ADV NEUR IN, V29; Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034; Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1; Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232; Norcliffe-Brown W, 2018, ADV NEUR IN, V31; Peng L, 2022, IEEE T KNOWL DATA EN, V34, P1644, DOI 10.1109/TKDE.2020.2998805; Peng L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1202, DOI 10.1145/3343031.3350925; Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3; Santra A, 2017, ADV GEOSPAT TECH, P1, DOI 10.4018/978-1-5225-1814-3; Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI [10.1109/TNNLS.2020.2995708, 10.1109/TKDE.2020.2970050]; Shi Y, 2018, LECT NOTES COMPUT SC, V11208, P158, DOI 10.1007/978-3-030-01225-0_10; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851; Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P906; Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100; Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326; Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P519, DOI 10.1145/3240508.3240513; Wu CF, 2018, ADV NEUR IN, V31; Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446; Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340; Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644; Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202; Zhang MS, 2017, PROCEEDINGS OF THE 26TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA'17), P261, DOI [10.1145/3092703.3092731, 10.1007/978-3-319-68155-9_20]; Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415; Zhang Y., 2018, P ICLR, P1; Zhuang BH, 2017, IEEE I CONF COMP VIS, P589, DOI 10.1109/ICCV.2017.71	56	20	20	30	66	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					318	329		10.1109/TPAMI.2020.3004830	http://dx.doi.org/10.1109/TPAMI.2020.3004830			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750794				2022-12-18	WOS:000728561300023
J	Lu, G; Zhang, XY; Ouyang, WL; Chen, L; Gao, ZY; Xu, D				Lu, Guo; Zhang, Xiaoyun; Ouyang, Wanli; Chen, Li; Gao, Zhiyong; Xu, Dong			An End-to-End Learning Framework for Video Compression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image coding; Video compression; Optical imaging; Motion estimation; Optical distortion; Estimation; Adaptive optics; Video compression; neural network; end-to-end optimization; image compression	MOTION ESTIMATION	Traditional video compression approaches build upon the hybrid coding framework with motion-compensated prediction and residual transform coding. In this paper, we propose the first end-to-end deep video compression framework to take advantage of both the classical compression architecture and the powerful non-linear representation ability of neural networks. Our framework employs pixel-wise motion information, which is learned from an optical flow network and further compressed by an auto-encoder network to save bits. The other compression components are also implemented by the well-designed networks for high efficiency. All the modules are jointly optimized by using the rate-distortion trade-off and can collaborate with each other. More importantly, the proposed deep video compression framework is very flexible and can be easily extended by using lightweight or advanced networks for higher speed or better efficiency. We also propose to introduce the adaptive quantization layer to reduce the number of parameters for variable bitrate coding. Comprehensive experimental results demonstrate the effectiveness of the proposed framework on the benchmark datasets.	[Lu, Guo; Zhang, Xiaoyun; Chen, Li; Gao, Zhiyong] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China; [Ouyang, Wanli; Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia	Shanghai Jiao Tong University; University of Sydney	Zhang, XY (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.	luguo2014@sjtu.edu.cn; xiaoyun.zhang@sjtu.edu.cn; wanli.ouyang@sydney.edu.au; hilichen@sjtu.edu.cn; zhiyong.gao@sjtu.edu.cn; dong.xu@sydney.edu.au	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730	National Natural Science Foundation of China [61771306]; Natural Science Foundation of Shanghai [18ZR1418100]; 111 plan [B07022]; Shanghai Key Laboratory of Digital Media Processing and Transmissions [STCSM 18DZ2270700]; Australian Research Council (ARC) Future Fellowship [FT180100116]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Shanghai(Natural Science Foundation of Shanghai); 111 plan; Shanghai Key Laboratory of Digital Media Processing and Transmissions; Australian Research Council (ARC) Future Fellowship(Australian Research Council)	This work was supported in part by National Natural Science Foundation of China (61771306), Natural Science Foundation of Shanghai(18ZR1418100), 111 plan (B07022), Shanghai Key Laboratory of Digital Media Processing and Transmissions(STCSM 18DZ2270700). This work was also supported by the Australian Research Council (ARC) Future Fellowship under Grantd FT180100116.	Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031; Agustsson E, 2017, ADV NEUR IN, V30; Baig MH, 2017, ADV NEUR IN, V30; Ball Johannes, 2018, INT C LEARN REPR ICL; Balle Johannes, 2017, 5 INT C LEARN REPR I; Barjatya A., 2004, IEEE T EVOLUT COMPUT, V8, P225, DOI DOI 10.1109/TEVC.2004.826069; Bellard Fabrice, BPG IMAGE FORMAT; Bjontegaard Gisle, 2001, VCEGM33, P6; Blau Y, 2019, PR MACH LEARN RES, V97; C. V. networking Index, 2016, CISC VIS NETW IND GL, V1; Chen CY, 2006, IEEE T CIRCUITS-I, V53, P578, DOI 10.1109/TCSI.2005.858488; Chen T, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP); Chen ZB, 2006, J VIS COMMUN IMAGE R, V17, P264, DOI 10.1016/j.jvcir.2004.12.002; Chen ZB, 2020, IEEE T CIRC SYST VID, V30, P566, DOI 10.1109/TCSVT.2019.2892608; Cheng ZX, 2019, PROC CVPR IEEE, P10063, DOI 10.1109/CVPR.2019.01031; Choi Y, 2019, IEEE I CONF COMP VIS, P3146, DOI 10.1109/ICCV.2019.00324; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936; Hui Tak-Wai, 2019, ARXIV190307414; Jaderberg M, 2015, ADV NEUR IN, V28; Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461; Kingma D.P, P 3 INT C LEARNING R; Lee Jisoo, 2019, ICLR; Li M, 2018, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2018.00339; Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405; Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264; Lu G., 2019, IEEE C COMP VIS PATT, P11006; Lu G, 2018, LECT NOTES COMPUT SC, V11218, P591, DOI 10.1007/978-3-030-01264-9_35; Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462; Minnen D, 2017, IEEE IMAGE PROC, P2796; Minnen D, 2018, ADV NEUR IN, V31; Patel Y., 2019, HUMAN PERCEPTUAL EVA, P1; Patel Yash, 2019, ARXIV190708310; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Rippel O, 2019, IEEE I CONF COMP VIS, P3453, DOI 10.1109/ICCV.2019.00355; Rippel O, 2017, PR MACH LEARN RES, V70; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804; Song R., 2017, P IEEE VIS COMM IM P, P1, DOI DOI 10.1145/3080845.3080878; Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Theis Lucas, 2017, INT C LEARN REPR; Toderici G., 2016, 4 INT C LEARN REPR I, P2; Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577; Tsai YH, 2018, AAAI CONF ARTIF INTE, P7363; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165; Wu CY, 2018, LECT NOTES COMPUT SC, V11212, P425, DOI 10.1007/978-3-030-01237-3_26; Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2; Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697	51	20	21	4	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3292	3308		10.1109/TPAMI.2020.2988453	http://dx.doi.org/10.1109/TPAMI.2020.2988453			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32324541				2022-12-18	WOS:000692232400006
J	Morales, A; Fierrez, J; Vera-Rodriguez, R; Tolosana, R				Morales, Aythami; Fierrez, Julian; Vera-Rodriguez, Ruben; Tolosana, Ruben			SensitiveNets: Learning Agnostic Representations with Application to Face Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Face; Privacy; Face recognition; Machine learning algorithms; Neural networks; Data protection; Face recognition; face analysis; biometrics; deep learning; agnostic; algorithmic discrimination; bias; privacy		This work proposes a novel privacy-preserving neural network feature representation to suppress the sensitive information of a learned space while maintaining the utility of the data. The new international regulation for personal data protection forces data controllers to guarantee privacy and avoid discriminative hazards while managing sensitive data of users. In our approach, privacy and discrimination are related to each other. Instead of existing approaches aimed directly at fairness improvement, the proposed feature representation enforces the privacy of selected attributes. This way fairness is not the objective, but the result of a privacy-preserving learning method. This approach guarantees that sensitive information cannot be exploited by any agent who process the output of the model, ensuring both privacy and equality of opportunity. Our method is based on an adversarial regularizer that introduces a sensitive information removal function in the learning objective. The method is evaluated on three different primary tasks (identity, attractiveness, and smiling) and three publicly available benchmarks. In addition, we present a new face annotation dataset with balanced distribution between genders and ethnic origins. The experiments demonstrate that it is possible to improve the privacy and equality of opportunity while retaining competitive performance independently of the task.	[Morales, Aythami; Fierrez, Julian; Vera-Rodriguez, Ruben; Tolosana, Ruben] Univ Autonoma Madrid, Sch Engn, Biometr & Data Pattern Analyt Lab, Madrid 28049, Spain	Autonomous University of Madrid	Morales, A; Fierrez, J (corresponding author), Univ Autonoma Madrid, Sch Engn, Biometr & Data Pattern Analyt Lab, Madrid 28049, Spain.	aythami.morales@uam.es; julian.fierrez@uam.es; ruben.vera@uam.es; ruben.tolosana@uam.es	Tolosana, Ruben/ABE-9297-2021; Moreno, Aythami/ABF-8166-2021; Morales Moreno, Aythami/L-2529-2013; Vera-Rodriguez, Ruben/D-1272-2014	Tolosana, Ruben/0000-0002-9393-3066; Morales Moreno, Aythami/0000-0002-7268-4785; Vera-Rodriguez, Ruben/0000-0002-6338-8511; Fierrez, Julian/0000-0002-6343-5656	PRIMA [MSCA-ITN-2019-860315]; TRESPASS-ETN [MSCA-ITN-2019-860813]; BIBECA [RTI2018-101248-B-I00MINECO]	PRIMA; TRESPASS-ETN; BIBECA	This work was supported by projects: PRIMA (MSCA-ITN-2019-860315), TRESPASS-ETN (MSCA-ITN-2019-860813), and BIBECA (RTI2018-101248-B-I00MINECO). Aythami Morales and Julian Fierrez contributed equally to this work.	Acien A, 2018, IB C PATT REC, P584; Alvi M, 2019, LECT NOTES COMPUT SC, V11129, P556, DOI 10.1007/978-3-030-11009-3_34; [Anonymous], EU 2016/679 (GDPR); Berendt B, 2014, ARTIF INTELL LAW, V22, P175, DOI 10.1007/s10506-013-9152-0; Buolamwini J., 2018, C FAIRN ACC TRANSP, P77; Calders T, 2010, DATA MIN KNOWL DISC, V21, P277, DOI 10.1007/s10618-010-0190-x; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Chen JW, 2018, IEEE COMPUT SOC CONF, P1651, DOI 10.1109/CVPRW.2018.00207; Denton E., 2019, DETECTING BIAS GENER; Drozdowski Pawel, 2020, IEEE Transactions on Technology and Society, V1, P89, DOI 10.1109/TTS.2020.2992344; Feutry C, 2018, ARXIV PREPRINT ARXIV, P1; Gong S., 2020, ECCV, P330; Gonzalez-Sosa E, 2018, IEEE T INF FOREN SEC, V13, P2001, DOI 10.1109/TIFS.2018.2807791; Hardt M, 2016, ADV NEUR IN, V29; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hernandez-Ortega J, 2019, INT CONF BIOMETR; Kawulok M., 2016, ADV FACE DETECTION F, P189, DOI DOI 10.1007/978-3-319-25958-1_8; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Kim B, 2019, PROC CVPR IEEE, P9004, DOI 10.1109/CVPR.2019.00922; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Madras D, 2018, PR MACH LEARN RES, V80; Mirjalili V, 2019, IEEE ACCESS, V7, P99735, DOI 10.1109/ACCESS.2019.2924619; Mirjalili V, 2018, INT CONF BIOMETR, P82, DOI 10.1109/ICB2018.2018.00023; Pena A, 2020, IEEE COMPUT SOC CONF, P129, DOI 10.1109/CVPRW50498.2020.00022; Pena A, 2021, INT C PATT RECOG, P3566, DOI 10.1109/ICPR48806.2021.9412581; Proenca H, 2018, IEEE INTELL SYST, V33, P41, DOI 10.1109/MIS.2018.033001416; Quadrianto N, 2019, PROC CVPR IEEE, P8219, DOI 10.1109/CVPR.2019.00842; Raff E., 2018, ARXIV180700392; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Ranjan R, 2018, IEEE SIGNAL PROC MAG, V35, P66, DOI 10.1109/MSP.2017.2764116; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Serna I, 2020, P AAAI WORKSH ART IN, P146; Serna I., 2020, ARXIV200406592; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Vera-Rodriguez R, 2019, IEEE COMPUT SOC CONF, P2254, DOI 10.1109/CVPRW.2019.00278; Wang M, 2020, P IEEE COMP SOC C CO, P9319; Wang M, 2019, IEEE I CONF COMP VIS, P692, DOI 10.1109/ICCV.2019.00078; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419; Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P335, DOI 10.1145/3278721.3278779	40	20	20	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2158	2164		10.1109/TPAMI.2020.3015420	http://dx.doi.org/10.1109/TPAMI.2020.3015420			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	32776875	Green Submitted			2022-12-18	WOS:000649590200026
J	Wan, RJ; Shi, BX; Li, HL; Duan, LY; Tan, AH; Kot, AC				Wan, Renjie; Shi, Boxin; Li, Haoliang; Duan, Ling-Yu; Tan, Ah-Hwee; Kot, Alex C.			CoRRN: Cooperative Reflection Removal Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; Cooperative systems; Computer vision; Task analysis; Feature extraction; Pattern analysis; Reflection removal; deep learning; statistic loss; cooperative framework	USER ASSISTED SEPARATION; BLIND SEPARATION; IMAGE	Removing the undesired reflections from images taken through the glass is of broad application to various computer vision tasks. Non-learning based methods utilize different handcrafted priors such as the separable sparse gradients caused by different levels of blurs, which often fail due to their limited description capability to the properties of real-world reflections. In this paper, we propose a network with the feature-sharing strategy to tackle this problem in a cooperative and unified framework, by integrating image context information and the multi-scale gradient information. To remove the strong reflections existed in some local regions, we propose a statistic loss by considering the gradient level statistics between the background and reflections. Our network is trained on a new dataset with 3250 reflection images taken under diverse real-world scenes. Experiments on a public benchmark dataset show that the proposed method performs favorably against state-of-the-art methods.	[Wan, Renjie; Li, Haoliang; Kot, Alex C.] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Shi, Boxin; Duan, Ling-Yu] Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Wan, Renjie; Duan, Ling-Yu] Peng Cheng Lab, Shenzhen 518000, Peoples R China; [Tan, Ah-Hwee] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Peking University; Peng Cheng Laboratory; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Wan, RJ (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.; Duan, LY (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	rjwan@ntu.edu.sg; boxin.shi@gmail.com; hli016@e.ntu.edu.sg; lingyu@pku.edu.cn; asahtan@ntu.edu.sg; eackot@ntu.edu.sg	Wan, Patrick/AAL-2841-2021	Kot, Alex/0000-0001-6262-8125; Li, Haoliang/0000-0002-8723-8112; Tan, Ah Hwee/0000-0003-0378-4069; Wan, Renjie/0000-0002-0161-0367	National Research Foundation, Prime Ministers Office, Singapore, under NRF-NSFC [NRF2016NRF-NSFC001-098]; National Natural Science Foundation of China [61661146005, U1611461, 61872012]; SSIJRI Guangzhou [206_A018001]	National Research Foundation, Prime Ministers Office, Singapore, under NRF-NSFC; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); SSIJRI Guangzhou	This research was carried out at the Rapid-Rich Object Search (ROSE) Lab at the Nanyang Technological University, Singapore and is supported by the National Research Foundation, Prime Ministers Office, Singapore, under the NRF-NSFC grant NRF2016NRF-NSFC001-098. This work was supported in part by the Project Grant 206_A018001 from SSIJRI Guangzhou and National Natural Science Foundation of China under Grant 61661146005, Grant U1611461, and Grant No. 61872012.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arvanitopoulos N, 2017, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2017.190; Be'ery E, 2008, IEEE T IMAGE PROCESS, V17, P340, DOI 10.1109/TIP.2007.915548; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Chandramouli P, 2017, LECT NOTES COMPUT SC, V10113, P129, DOI 10.1007/978-3-319-54187-7_9; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Fan QN, 2017, IEEE I CONF COMP VIS, P3258, DOI 10.1109/ICCV.2017.351; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Gai K, 2012, IEEE T PATTERN ANAL, V34, P19, DOI 10.1109/TPAMI.2011.87; Gatys L A, 2016, PRESERVING COLOR NEU; Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9; Kim Y., 2017, NEW CONVOLUTIONAL NE; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Levin A, 2004, LECT NOTES COMPUT SC, V3021, P602; Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312; Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346; Li Y, 2013, IEEE I CONF COMP VIS, P2432, DOI 10.1109/ICCV.2013.302; Li YJ, 2015, PR MACH LEARN RES, V37, P1718; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu DL, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA), P406, DOI 10.1109/ICSGEA.2017.74; Ma WC, 2018, LECT NOTES COMPUT SC, V11218, P211, DOI 10.1007/978-3-030-01264-9_13; Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263; Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shi BX, 2019, IEEE T PATTERN ANAL, V41, P271, DOI 10.1109/TPAMI.2018.2799222; Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379; Shih YC, 2015, PROC CVPR IEEE, P3193, DOI 10.1109/CVPR.2015.7298939; Snell J, 2017, IEEE IMAGE PROC, P4277; Su C, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND COMPUTER APPLICATIONS (ICSCA 2019), P38, DOI 10.1145/3316615.3316715; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Wan RJ, 2018, PROC CVPR IEEE, P4777, DOI 10.1109/CVPR.2018.00502; Wan RJ, 2018, IEEE T IMAGE PROCESS, V27, P2927, DOI 10.1109/TIP.2018.2808768; Wan RJ, 2017, IEEE I CONF COMP VIS, P3942, DOI 10.1109/ICCV.2017.423; Wan RJ, 2017, IEEE INT CON MULTI, P1500, DOI 10.1109/ICME.2017.8019527; Wan RJ, 2016, IEEE IMAGE PROC, P21, DOI 10.1109/ICIP.2016.7532311; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xue TF, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766940; Yu K., 2016, DEEP CONVOLUTION NET; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865	47	20	20	3	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					2969	2982		10.1109/TPAMI.2019.2921574	http://dx.doi.org/10.1109/TPAMI.2019.2921574			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31180841	Green Accepted			2022-12-18	WOS:000587912800001
J	Schwartz, G; Nishino, K				Schwartz, Gabriel; Nishino, Ko			Recognizing Material Properties from Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Image recognition; Material properties; Shape; Face; Visual perception; Semantics; Visual material attributes; human material perception; material recognition	REPRESENTATION; OBJECTS	Humans implicitly rely on the properties of materials to guide our interactions. Grasping smooth materials, for example, requires more care than rough ones. We may even visually infer non-visual properties (e.g., softness is a physical material property). We refer to visually-recognizable material properties as visual material attributes. Recognizing these attributes in images can provide valuable information for scene understanding and material recognition. Unlike typical object and scene attributes, however, visual material attributes are local (i.e., "fuzziness" does not have a shape). Given full supervision, we may accurately recognize such attributes from purely local information (small image patches). Obtaining consistent full supervision at scale, however, is challenging. To solve this problem, we probe the human visual perception of materials. By asking simple yes/no questions comparing pairs of image patches, we obtain the weak supervision required to build a set of classifiers for attributes that, while unnamed, function similarly to the attributes with which we describe materials. Furthermore, we integrate this method in the end-to-end learning of a CNN that simultaneously recognizes materials and their visual attributes. Experiments show that visual material attributes serve as both a useful representation for known material categories and as a basis for transfer learning.	[Schwartz, Gabriel; Nishino, Ko] Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA	Drexel University	Schwartz, G (corresponding author), Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA.	gbs25@drexel.edu; kon@drexel.edu		Nishino, Ko/0000-0002-3534-3447	Office of Naval Research [N00014-16-1-2158 (N00014-14-1-0316), N00014-17-1-2406]; US National Science Foundation [IIS-1421094, IIS-1715251]	Office of Naval Research(Office of Naval Research); US National Science Foundation(National Science Foundation (NSF))	This work was supported by the Office of Naval Research grants N00014-16-1-2158 (N00014-14-1-0316) and N00014-17-1-2406, and the US National Science Foundation awards IIS-1421094 and IIS-1715251. The Titan X used for part of this research was donated by the NVIDIA Corporation.	Adelson E, 2009, J VISUAL-JAPAN, V9, P784, DOI DOI 10.1167/9.8.784; Adelson EH, 2001, PROC SPIE, V4299, P1, DOI 10.1117/12.429489; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Barla A., 2003, P INT C IM PROC; Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970; Bell S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462002; Berg T. L., 2010, EPILEPSIA, P1; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Escorcia V, 2015, PROC CVPR IEEE, P1256, DOI 10.1109/CVPR.2015.7298730; Everingham M., PASCAL VISUAL OBJECT; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Ferrari Vittorio, 2007, NIPS; Goda N, 2014, J NEUROSCI, V34, P2660, DOI 10.1523/JNEUROSCI.2593-13.2014; Hiramatsu C, 2011, NEUROIMAGE, V57, P482, DOI 10.1016/j.neuroimage.2011.04.056; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; LeCun Y., 1989, ADV NEURAL INFORM PR, V2; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C, 2010, PROC CVPR IEEE, P239, DOI 10.1109/ICCET.2010.5485248; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Ordonez V, 2013, IEEE I CONF COMP VIS, P2768, DOI 10.1109/ICCV.2013.344; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; Rastegari M, 2012, LECT NOTES COMPUT SC, V7577, P876, DOI 10.1007/978-3-642-33783-3_63; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schwartz G., 2016, BIOL ART VIS WORKSH; Schwartz G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P883, DOI 10.1109/ICCVW.2013.121; Shankar S, 2015, PROC CVPR IEEE, P3403, DOI 10.1109/CVPR.2015.7298962; Sharan Lavanya, 2013, Int J Comput Vis, V103, P348; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; von Ahn Luis, 2004, P SIGCHI C HUM FACT, DOI [10.1145/985692.985733, DOI 10.1145/985692.985733]; Xu XD, 2011, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON SYSTEMS (ICONS 2011), P48; Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111; Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105; Zbou BL, 2015, PROC CVPR IEEE, P1492, DOI 10.1109/CVPR.2015.7298756; Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2	44	20	21	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1981	1995		10.1109/TPAMI.2019.2907850	http://dx.doi.org/10.1109/TPAMI.2019.2907850			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30932831	hybrid, Green Submitted			2022-12-18	WOS:000545415400013
J	RichardWebster, B; Anthony, SE; Scheirer, WJ				RichardWebster, Brandon; Anthony, Samuel E.; Scheirer, Walter J.			PsyPhy: A Psychophysics Driven Evaluation Framework for Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; visual psychophysics; neuroscience; psychology; evaluation; deep learning	HIERARCHICAL-MODELS; PERFORMANCE	By providing substantial amounts of data and standardized evaluation protocols, datasets in computer vision have helped fuel advances across all areas of visual recognition. But even in light of breakthrough results on recent benchmarks, it is still fair to ask if our recognition algorithms are doing as well as we think they are. The vision sciences at large make use of a very different evaluation regime known as Visual Psychophysics to study visual perception. Psychophysics is the quantitative examination of the relationships between controlled stimuli and the behavioral responses they elicit in experimental test subjects. Instead of using summary statistics to gauge performance, psychophysics directs us to construct item-response curves made up of individual stimulus responses to find perceptual thresholds, thus allowing one to identify the exact point at which a subject can no longer reliably recognize the stimulus class. In this article, we introduce a comprehensive evaluation framework for visual recognition models that is underpinned by this methodology. Over millions of procedurally rendered 3D scenes and 2D images, we compare the performance of well-known convolutional neural networks. Our results bring into question recent claims of human-like performance, and provide a path forward for correcting newly surfaced algorithmic deficiencies.	[RichardWebster, Brandon; Scheirer, Walter J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; [Anthony, Samuel E.] Harvard Univ, Dept Psychol, 33 Kirkland St, Cambridge, MA 02138 USA; [Anthony, Samuel E.] Percept Automata Inc, Somerville, MA 02143 USA	University of Notre Dame; Harvard University	RichardWebster, B (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.	brichar1@nd.edu; santhony@wjh.harvard.edu; walter.scheirer@nd.edu			IARPA [D16PC00002]; NSF DGE [1313583]; NSF SBIR Award [IIP-1621689]	IARPA; NSF DGE(National Science Foundation (NSF)NSF- Directorate for Education & Human Resources (EHR)); NSF SBIR Award(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))	The authors thank Lucas Parzianello for helping import Blendswap models into PsyPhy and Brian Turnquist for providing feedback on an early draft of this work. Funding was provided under IARPA contract #D16PC00002, NSF DGE #1313583, and NSF SBIR Award #IIP-1621689. Hardware support was generously provided by the NVIDIA Corporation.	Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; [Anonymous], 2012, IMAGETNET LARGE SCAL; Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173; Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897; BOWMAKER JK, 1980, J PHYSIOL-LONDON, V298, P501, DOI 10.1113/jphysiol.1980.sp013097; Cadieu CF, 2013, INT C LEARN REP, P1; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Duchaine B, 2006, NEUROPSYCHOLOGIA, V44, P576, DOI 10.1016/j.neuropsychologia.2005.07.001; Eberhardt S., 2016, ADV NEURAL INFORM PR, P1100; Embretson S, 2000, ITEM RESPONSE THEORY; Gal Y, 2016, PR MACH LEARN RES, V48; Geirhos R., 2017, ARXIV170606969, P1; Gerhard HE, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002873; Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9; Hecht S, 1942, J GEN PHYSIOL, V25, P819, DOI 10.1085/jgp.25.6.819; Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25; Hong H, 2016, NAT NEUROSCI, V19, P613, DOI 10.1038/nn.4247; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; Kingdom FAA, 2016, PSYCHOPHYSICS PRACTI; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kulkarni TD, 2015, PROC CVPR IEEE, P4390, DOI 10.1109/CVPR.2015.7299068; Lu ZL, 2014, VISUAL PSYCHOPHYSICS: FROM LABORATORY TO THEORY, P1; O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107; O'Toole AJ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2355598.2355599; Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017; Phillips PJ, 2014, IMAGE VISION COMPUT, V32, P74, DOI 10.1016/j.imavis.2013.12.002; Pramod RT, 2016, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2016.177; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Riesenhuber M., 2000, AIM1682 MIT; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P1679, DOI 10.1109/TPAMI.2013.2297711; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Tommasi T, 2015, LECT NOTES COMPUT SC, V9358, P504, DOI 10.1007/978-3-319-24947-6_42; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Vondrick C., 2015, ADV NEURAL INFORM PR, P289; Wilber Michael J., 2016, P IEEE WINT C APPL C, P1; Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111; Yildirim MZ, 2015, ZOOKEYS, P1, DOI 10.3897/zookeys.481.8225	42	20	20	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2280	2286		10.1109/TPAMI.2018.2849989	http://dx.doi.org/10.1109/TPAMI.2018.2849989			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994469	Green Submitted, hybrid			2022-12-18	WOS:000480343900018
J	Marin, D; Tang, M; Ben Ayed, I; Boykov, Y				Marin, Dmitrii; Tang, Meng; Ben Ayed, Ismail; Boykov, Yuri			Kernel Clustering: Density Biases and solutions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel methods; kernel clustering; kernel k-means; average association; average cut; normalized cut; dominant set		Kernel methods are popular in clustering due to their generality and discriminating power. However, we show that many kernel clustering criteria have density biases theoretically explaining some practically significant artifacts empirically observed in the past. For example, we provide conditions and formally prove the density mode isolation bias in kernel K-means for a common class of kernels. We call it Breiman's bias due to its similarity to the histogram mode isolation previously discovered by Breiman in decision tree learning with Gini impurity. We also extend our analysis to other popular kernel clustering methods, e.g., average/normalized cut or dominant sets, where density biases can take different forms. For example, splitting isolated points by cut-based criteria is essentially the sparsest subset bias, which is the opposite of the density mode bias. Our findings suggest that a principled solution for density biases in kernel clustering should directly address data inhomogeneity. We show that density equalization can be implicitly achieved using either locally adaptive weights or locally adaptive kernels. Moreover, density equalization makes many popular kernel clustering objectives equivalent. Our synthetic and real data experiments illustrate density biases and proposed solutions. We anticipate that theoretical understanding of kernel clustering limitations and their principled solutions will be important for a broad spectrum of data analysis applications across the disciplines.	[Marin, Dmitrii; Tang, Meng; Boykov, Yuri] Univ Western Ontario, Dept Comp Sci, London, ON N6A 3K7, Canada; [Ben Ayed, Ismail] Univ Quebec, Ecole Technol Super, Mont Royal, PQ H3R 1K, Canada	Western University (University of Western Ontario)	Marin, D (corresponding author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 3K7, Canada.	dmitrii.a.marin@gmail.com; mtang73@csd.uwo.ca; ismail.benayed@etsmtl.ca; yuri@csd.uwo.ca		Marin, Dmitrii/0000-0002-4799-3412	RTI programs of the National Science and Engineering Research Council of Canada (NSERC)	RTI programs of the National Science and Engineering Research Council of Canada (NSERC)	The authors would like to thank Professor Kaleem Siddiqi (McGill University) for suggesting a potential link between Breiman's bias and the dominant sets. This work was generously supported by the Discovery and RTI programs of the National Science and Engineering Research Council of Canada (NSERC).	[Anonymous], 1997, P UNC ART INT AUG; Bach FR, 2004, ADV NEUR IN, V16, P305; Bishop C.M, 2006, PATTERN RECOGN; Boykov Y, 2015, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2015.206; Breiman L, 1996, MACH LEARN, V24, P41, DOI 10.1023/A:1018094028462; CHEEGER J., 1970, PROBLEMS ANAL PAPERS, P195, DOI [10.1515/9781400869312-013, DOI 10.1515/9781400869312-013]; Chitta R., 2011, P 17 ACM SIGKDD INT, P895; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CORMEN TH, 2006, INTRO ALGORITHMS; Cox T., 2000, MULTIDIMENSIONAL SCA; Criminisi A., 2013, DECISION FORESTCOM; DONATH WE, 1973, IBM J RES DEV, V17, P420, DOI 10.1147/rd.175.0420; Duda R.O., 1973, J ROYAL STAT SOC SER; Fanti C, 2004, ADV NEUR IN, V16, P1603; FIEDLER M, 1975, CZECH MATH J, V25, P619; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; LINGOES JC, 1971, PSYCHOMETRIKA, V36, P195, DOI 10.1007/BF02291398; MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshen R., 1984, CLASSIFICATION REGRE; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Roth V, 2003, IEEE T PATTERN ANAL, V25, P1540, DOI 10.1109/TPAMI.2003.1251147; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Sethian J.A., 1999, LEVEL SET METHODS FA, V3; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silverman B. W., 1986, DENSITY ESTIMATION S, V26; Tang M., 2015, ARXIV150607439; Tang M, 2016, LECT NOTES COMPUT SC, V9906, P748, DOI 10.1007/978-3-319-46475-6_46; Tang M, 2015, IEEE I CONF COMP VIS, P1555, DOI 10.1109/ICCV.2015.182; TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768; Vapnik V.N, 1998, STAT LEARNING THEORY; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Zhang R, 2002, INT C PATT RECOG, P289, DOI 10.1109/ICPR.2002.1047453	43	20	20	3	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					136	147		10.1109/TPAMI.2017.2780166	http://dx.doi.org/10.1109/TPAMI.2017.2780166			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990278	Green Submitted			2022-12-18	WOS:000452434800011
J	Chen, T; Lu, SJ; Fan, JY				Chen, Tao; Lu, Shijian; Fan, Jiayuan			S-CNN: Subcategory-Aware Convolutional Networks for Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Subcategory; object detection; convolutional neural network; ACF detector; subcategory-aware CNN		The marriage between the deep convolutional neural network (CNN) and region proposals has made breakthroughs for object detection in recent years. While the discriminative object features are learned via a deep CNN for classification, the large intra-class variation and deformation still limit the performance of the CNN based object detection. We propose a subcategory-aware CNN (S-CNN) to solve the object intra-class variation problem. In the proposed technique, the training samples are first grouped into multiple subcategories automatically through a novel instance sharing maximum margin clustering process. A multi-component Aggregated Channel Feature (ACF) detector is then trained to produce more latent training samples, where each ACF component corresponds to one clustered subcategory. The produced latent samples together with their subcategory labels are further fed into a CNN classifier to filter out false proposals for object detection. An iterative learning algorithm is designed for the joint optimization of image subcategorization, multi-component ACF detector, and subcategory-aware CNN classifier. Experiments on INRIA Person dataset, Pascal VOC 2007 dataset and MS COCO dataset show that the proposed technique clearly outperforms the state-of-the-art methods for generic object detection.	[Chen, Tao] Agcy Sci Technol & Res, Inst Infocomm Res, Visual Comp Dept, Singapore 138632, Singapore; [Fan, Jiayuan] Agcy Sci Technol & Res, Satellite Dept, Singapore 138632, Singapore; [Lu, Shijian] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Agency for Science Technology & Research (A*STAR); Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Chen, T (corresponding author), Agcy Sci Technol & Res, Inst Infocomm Res, Visual Comp Dept, Singapore 138632, Singapore.	ntuchentao@gmail.com; Shijian.Lu@ntu.edu.sg; fanj@i2r.a-star.edu.sg	Lu, Shijian/AAU-4831-2021	Lu, Shijian/0000-0002-6766-2506; Chen, Tao/0000-0002-0779-9818				Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Chen T, 2017, IEEE T CIRC SYST VID, V27, P394, DOI 10.1109/TCSVT.2015.2513677; Chen T, 2016, IEEE T VEH TECHNOL, V65, P4006, DOI 10.1109/TVT.2015.2500275; Coppi D., 2014, P INT C MULT RETR, P337; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Dong J, 2015, IEEE T CIRC SYST VID, V25, P1322, DOI 10.1109/TCSVT.2014.2355697; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Hoai M, 2013, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2013.218; Lan T, 2013, IEEE I CONF COMP VIS, P369, DOI 10.1109/ICCV.2013.53; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ohn-Bar E, 2015, IEEE T INTELL TRANSP, V16, P2511, DOI 10.1109/TITS.2015.2409889; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sapp A.S., 2008, NAT C ART INT, P1402; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang XY, 2015, IEEE T PATTERN ANAL, V37, P2071, DOI 10.1109/TPAMI.2015.2389830; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yan JJ, 2015, PROC CVPR IEEE, P5107, DOI 10.1109/CVPR.2015.7299146; Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x; Zhou G-T, 2013, ADV NEURAL INFORM PR, P28; Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	33	20	23	4	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2522	2528		10.1109/TPAMI.2017.2756936	http://dx.doi.org/10.1109/TPAMI.2017.2756936			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28961103				2022-12-18	WOS:000443875500018
J	Akbarinia, A; Parraga, CA				Akbarinia, Arash; Parraga, C. Alejandro			Colour Constancy Beyond the Classical Receptive Field	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Colour constancy; illuminant estimation; classical receptive field; surround modulation; centre-surround contrast	MACAQUE V1; CHROMATICITY; SENSITIVITY; MECHANISMS; ALGORITHM; VARIANCE; CELLS; MODEL	The problem of removing illuminant variations to preserve the colours of objects (colour constancy) has already been solved by the human brain using mechanisms that rely largely on centre-surround computations of local contrast. In this paper we adopt some of these biological solutions described by long known physiological findings into a simple, fully automatic, functional model (termed Adaptive Surround Modulation or ASM). In ASM, the size of a visual neuron's receptive field (RF) as well as the relationship with its surround varies according to the local contrast within the stimulus, which in turn determines the nature of the centre-surround normalisation of cortical neurons higher up in the processing chain. We modelled colour constancy by means of two overlapping asymmetric Gaussian kernels whose sizes are adapted based on the contrast of the surround pixels, resembling the change of RF size. We simulated the contrast-dependent surround modulation by weighting the contribution of each Gaussian according to the centre-surround contrast. In the end, we obtained an estimation of the illuminant from the set of the most activated RFs' outputs. Our results on three single-illuminant and onemulti-illuminant benchmark datasets show that ASM is highly competitive against the state-of-the-art and it even outperforms learning-based algorithms in one case. Moreover, the robustness of our model is more tangible if we consider that our results were obtained using the same parameters for all datasets, that is, mimicking how the human visual system operates. These results suggest a dynamical adaptation mechanisms contribute to achieving higher accuracy in computational colour constancy.	[Akbarinia, Arash; Parraga, C. Alejandro] Univ Autonoma Barcelona, CVC, E-08193 Barcelona, Spain	Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Akbarinia, A (corresponding author), Univ Autonoma Barcelona, CVC, E-08193 Barcelona, Spain.	arash.akbarinia@cvc.uab.es; alejandro.parraga@cvc.uab.es	Parraga, C. Alejandro/D-2329-2011	Parraga, C. Alejandro/0000-0002-3809-241X	Spanish Secretary of Research and Innovation [TIN2013-41751-P, TIN2013-49982-EXP]	Spanish Secretary of Research and Innovation	We would like to thank members of the NeuroBiT Group and anonymous reviewers of the manuscript for their thoughtful insights and comments. This work was funded by the Spanish Secretary of Research and Innovation (TIN2013-41751-P and TIN2013-49982-EXP).	Agarwal V, 2007, NEURAL NETWORKS, V20, P559, DOI 10.1016/j.neunet.2007.02.004; Akbari A., 2017, 11 INT ITG C SYSTEMS, P1; Akbari A, 2016, 2016 IEEE 18 INT WOR, P1; Akbari A, 2018, INFOR, V56, P92, DOI 10.1080/03155986.2017.1334322; ALLMAN J, 1985, ANNU REV NEUROSCI, V8, P407, DOI 10.1146/annurev.ne.08.030185.002203; Angelucci A, 2014, NEW VISUAL NEUROSCIENCES, P425; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531; Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; Barnard K., 2000, EUR C COMP VIS; Beigpour S, 2014, IEEE T IMAGE PROCESS, V23, P83, DOI 10.1109/TIP.2013.2286327; Bianco Simone, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P81, DOI 10.1109/CVPRW.2015.7301275; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; Brainard DH, 2004, VISUAL NEUROSCIENCES, P948; Brown RO, 1997, CURR BIOL, V7, P844, DOI 10.1016/S0960-9822(06)00372-1; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374; Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2530, DOI 10.1152/jn.00692.2001; Chakrabarti A, 2012, IEEE T PATTERN ANAL, V34, P1509, DOI 10.1109/TPAMI.2011.252; Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160; Conway BR, 2010, J NEUROSCI, V30, P14955, DOI 10.1523/JNEUROSCI.4348-10.2010; EBNER M., 2007, COLOR CONSTANCY, V6; ENROTHCUGELL C, 1966, J PHYSIOL-LONDON, V187, P517, DOI 10.1113/jphysiol.1966.sp008107; Finlayson G, 2000, IEEE T IMAGE PROCESS, V9, P1774, DOI 10.1109/83.869188; Finlayson G.D., 2014, PERCEPTION, V310, P1; Finlayson GD, 1996, IEEE T PATTERN ANAL, V18, P1034, DOI 10.1109/34.541413; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Foster DH, 2011, VISION RES, V51, P674, DOI 10.1016/j.visres.2010.09.006; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Funt B, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P47; Funt B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P445, DOI 10.1007/BFb0055683; Funt B, 2012, COLOR IMAG CONF, P105; FUNT BV, 1991, INT J COMPUT VISION, V6, P5, DOI 10.1007/BF00127123; Gao SB, 2015, IEEE T PATTERN ANAL, V37, P1973, DOI 10.1109/TPAMI.2015.2396053; Gao SB, 2014, LECT NOTES COMPUT SC, V8690, P158, DOI 10.1007/978-3-319-10605-2_11; Gegenfurtner KR, 2003, NAT REV NEUROSCI, V4, P563, DOI 10.1038/nrn1138; Gehler PV, 2008, PROC CVPR IEEE, P3291; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; Gijsenij A, 2012, IEEE T PATTERN ANAL, V34, P918, DOI 10.1109/TPAMI.2011.197; Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219; Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243; Hansen T, 2006, NAT NEUROSCI, V9, P1367, DOI 10.1038/nn1794; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; Hubel PM, 2000, J IMAGING SCI TECHN, V44, P371; Hurlbert A, 2003, PROG BRAIN RES, V144, P147, DOI 10.1016/S0079-6123(03)14401-0; Ichida JM, 2007, J NEUROPHYSIOL, V98, P2168, DOI 10.1152/jn.00298.2007; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Joze HRV, 2012, COLOR IMAG CONF, P41; Joze HRV, 2014, IEEE T PATTERN ANAL, V36, P860, DOI 10.1109/TPAMI.2013.169; KAPADIA MK, 1995, NEURON, V15, P843, DOI 10.1016/0896-6273(95)90175-2; Lampl I, 2004, J NEUROPHYSIOL, V92, P2704, DOI 10.1152/jn.00060.2004; Land E, 1977, RETINEX THEORY COLOR; LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; Lou Z., 2015, BMVC, P76; MacAdam D., 1970, SOURCES COLOR SCI; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Mosny M., 2010, C COL GRAPH SOC IM S, P466; Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Otazu X, 2010, J VISION, V10, DOI 10.1167/10.12.5; Parraga C. A., 2013, ENCY COMPUTATIONAL N, V10, P1; Parraga C. A., 2016, J VIS, V16, P214, DOI DOI 10.1167/16.12.214; Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575; Roca-Vila J, 2013, J VISION, V13, DOI 10.1167/13.4.3; Rosenberg Charles R., 2003, ADV NEURAL INFORM PR, P1595; Shapley R, 2011, VISION RES, V51, P701, DOI 10.1016/j.visres.2011.02.012; Shi L., 2012, RE PROCESSED VERSION; Shi LL, 2011, J OPT SOC AM A, V28, P940, DOI 10.1364/JOSAA.28.000940; Shushruth S, 2009, J NEUROPHYSIOL, V102, P2069, DOI 10.1152/jn.00512.2009; Spitzer H, 2005, VISION RES, V45, P3323, DOI 10.1016/j.visres.2005.08.002; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; Vazquez-Corral J, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.031105; Von Kries J., 1902, FESTSCHRIFT ALBRECHT, V135, P145; Walker GA, 1999, J NEUROSCI, V19, P10536; Wilson HR, 2014, NEW VISUAL NEUROSCIENCES, P617; Yang KF, 2015, PROC CVPR IEEE, P2254, DOI 10.1109/CVPR.2015.7298838; Zhang J, 2012, LECT NOTES COMPUT SC, V7576, P312, DOI 10.1007/978-3-642-33715-4_23	86	20	21	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2081	2094		10.1109/TPAMI.2017.2753239	http://dx.doi.org/10.1109/TPAMI.2017.2753239			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28922115				2022-12-18	WOS:000440868400004
J	Park, CC; Kim, Y; Kim, G				Park, Cesc Chunseong; Kim, Youngjin; Kim, Gunhee			Retrieval of Sentence Sequences for an Image Stream via Coherence Recurrent Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image captioning; bidirectional long short-term memory networks; convolutional neural networks; coherence models		We propose an approach for retrieving a sequence of natural sentences for an image stream. Since general users often take a series of pictures on their experiences, much online visual information exists in the form of image streams, for which it would better take into consideration of the whole image stream to produce natural language descriptions. While almost all previous studies have dealt with the relation between a single image and a single natural sentence, our work extends both input and output dimension to a sequence of images and a sequence of sentences. For retrieving a coherent flow of multiple sentences for a photo stream, we propose a multimodal neural architecture called coherence recurrent convolutional network (CRCN), which consists of convolutional neural networks, bidirectional long short-term memory (LSTM) networks, and an entity-based local coherence model. Our approach directly learns from vast user-generated resource of blog posts as text-image parallel training data. We collect more than 22 K unique blog posts with 170 K associated images for the travel topics of NYC, Disneyland, Australia, and Hawaii. We demonstrate that our approach outperforms other state-of-the-art image captioning methods for text sequence generation, using both quantitative measures and user studies via Amazon Mechanical Turk.	[Park, Cesc Chunseong; Kim, Youngjin; Kim, Gunhee] Seoul Natl Univ, Dept Comp Sci & Engn, Seoul 151742, South Korea	Seoul National University (SNU)	Park, CC (corresponding author), Seoul Natl Univ, Dept Comp Sci & Engn, Seoul 151742, South Korea.	park.chunseong@snu.ac.kr; youngj09@snu.ac.kr; gunhee@snu.ac.kr			National Research Foundation of Korea [2015R1C1A1A02036562]; Hancom	National Research Foundation of Korea(National Research Foundation of Korea); Hancom	This research is partially supported by Hancom and Basic Science Research Program through National Research Foundation of Korea (2015R1C1A1A02036562). Gunhee Kim is the corresponding author. The code and dataset are available at https://github.com/cesc-park/CRCN.	[Anonymous], 2015, P INT C LEARN REPR; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65; Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1; Bird S., 2009, NATURAL LANGUAGE PRO; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Choi FYY, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P109; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Huang Ting-Hao Kenneth, 2016, P 2016 C N AM CHAPT, P1233, DOI DOI 10.18653/V1/N16-1147; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kim G, 2015, PROC CVPR IEEE, P1993, DOI 10.1109/CVPR.2015.7298810; Kim G, 2015, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2015.7298927; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kuznetsova Polina, 2014, T ASSOC COMPUT LING, V2, P351, DOI DOI 10.1162/TACL_A_00188; Lan T, 2012, LECT NOTES COMPUT SC, V7577, P129, DOI 10.1007/978-3-642-33783-3_10; Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mikolov T.A., 2012, STAT LANGUAGE MODELS; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Park Cesc C, 2015, NIPS; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Quoc Le, 2014, P 31 INT C MACHINE L, V32, P1188; Ren M., 2015, P 28 INT C NEUR INF, V2, P2953, DOI [10.5555/2969442.2969570, DOI 10.5555/2969442.2969570]; Rohrbach A, 2015, LECT NOTES COMPUT SC, V9358, P209, DOI 10.1007/978-3-319-24947-6_17; Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Siddiquie B, 2014, P INT C MULT RETR, P321; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Simonyan K, 2015, 3 INT C LEARN REPR I; Socher R., 2013, TACL, V2, P207; Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI [DOI 10.1162/NEC0_A_00311, DOI 10.1109/CVPR.2013.49]; Tieleman Tijmen, 2012, LECT 6 5 RMSPROP; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; WERBOS PJ, 1988, NEURAL NETWORKS, V1, P339, DOI 10.1016/0893-6080(88)90007-X; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211	54	20	20	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					945	957		10.1109/TPAMI.2017.2700381	http://dx.doi.org/10.1109/TPAMI.2017.2700381			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28475047				2022-12-18	WOS:000426687100013
J	Li, SW; Purushotham, S; Chen, C; Ren, YZ; Kuo, CCJ				Li, Shangwen; Purushotham, Sanjay; Chen, Chen; Ren, Yuzhuo; Kuo, C. -C. Jay			Measuring and Predicting Tag Importance for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal image retrieval (MIR); image retrieval; semantic gap; tag importance; importance measure; importance prediction; cross-domain learning		Textual data such as tags, sentence descriptions are combined with visual cues to reduce the semantic gap for image retrieval applications in today's Multimodal Image Retrieval (MIR) systems. However, all tags are treated as equally important in these systems, which may result in misalignment between visual and textual modalities during MIR training. This will further lead to degenerated retrieval performance at query time. To address this issue, we investigate the problem of tag importance prediction, where the goal is to automatically predict the tag importance and use it in image retrieval. To achieve this, we first propose a method to measure the relative importance of object and scene tags from image sentence descriptions. Using this as the ground truth, we present a tag importance prediction model to jointly exploit visual, semantic and context cues. The Structural Support Vector Machine (SSVM) formulation is adopted to ensure efficient training of the prediction model. Then, the Canonical Correlation Analysis (CCA) is employed to learn the relation between the image visual feature and tag importance to obtain robust retrieval performance. Experimental results on three real-world datasets show a significant performance improvement of the proposed MIR with Tag Importance Prediction (MIR/TIP) system over other MIR systems.	[Li, Shangwen; Purushotham, Sanjay; Chen, Chen; Ren, Yuzhuo; Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA	University of Southern California	Li, SW (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.	shangwel@usc.edu; sanjayp2005@gmail.com; ohyline@gmail.com; yuzhuore@usc.edu; cckuo@sipi.usc.edu	Kuo, C.-C. Jay/A-7110-2011	Kuo, C.-C. Jay/0000-0001-9474-5035				Andrew Galen, 2013, ICML; [Anonymous], 2013, ARXIV13124894; Bakir G. H., 2007, NEURAL INFORM PROCES; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Berg AC, 2012, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2012.6248100; Bird S., 2009, NATURAL LANGUAGE PRO; Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Datta Ritendra, 2005, P MIR, P253; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Feng SH, 2015, IEEE T IMAGE PROCESS, V24, P1223, DOI 10.1109/TIP.2015.2395816; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hou X, 2007, 2007 IEEE C COMP VIS, V800, P1, DOI DOI 10.1109/CVPR.2007.383267; Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3; Hwang SY, 2011, PURE APPL CHEM, V83, P233, DOI 10.1351/PAC-CON-10-09-35; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525; Krishna R., 2016, VISUAL GENOME CONNEC; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lai PL, 2000, IEEE IJCNN, P614; Lan T, 2013, PROC CVPR IEEE, P3103, DOI 10.1109/CVPR.2013.399; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Li M., 2012, P 4 INT C INT MULT C, P153; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu D., 2009, P 18 INT C WORLD WID, P351; Liu YM, 2011, IEEE T PATTERN ANAL, V33, P1022, DOI 10.1109/TPAMI.2010.142; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Manning D. K. C. D., 2003, P C ADV NEUR INF PRO, V15; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Spain M, 2011, INT J COMPUT VISION, V91, P59, DOI 10.1007/s11263-010-0376-0; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; Turakhia N, 2013, IEEE I CONF COMP VIS, P1225, DOI 10.1109/ICCV.2013.155; Wang W., 2015, VLDB J, P1; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yun KW, 2013, PROC CVPR IEEE, P739, DOI 10.1109/CVPR.2013.101; Zbou BL, 2015, PROC CVPR IEEE, P1492, DOI 10.1109/CVPR.2015.7298756; Zhang HW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P187, DOI 10.1145/2647868.2654915; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhuang J., 2011, PROC INT C WEB SEARC, P625	55	20	21	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2423	2436		10.1109/TPAMI.2017.2651818	http://dx.doi.org/10.1109/TPAMI.2017.2651818			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28092521	Green Submitted			2022-12-18	WOS:000414395400008
J	Hofmeyr, DP				Hofmeyr, David P.			Clustering by Minimum Cut Hyperplanes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; hyperplane; normalised cut; asymptotics; maximum margin		Minimum normalised graph cuts are highly effective ways of partitioning unlabeled data, having been made popular by the success of spectral clustering. This work presents a novel method for learning hyperplane separators which minimise this graph cut objective, when data are embedded in Euclidean space. The optimisation problem associated with the proposed method can be formulated as a sequence of univariate subproblems, in which the optimal hyperplane orthogonal to a given vector is determined. These subproblems can be solved in log-linear time, by exploiting the trivial factorisation of the exponential function. Experimentation suggests that the empirical runtime of the overall algorithmis also log-linear in the number of data. Asymptotic properties of the minimum cut hyperplane, both for a finite sample, and for an increasing sample assumed to arise froman underlying probability distribution are discussed. In the finite sample case the minimum cut hyperplane converges to the maximum margin hyperplane as the scaling parameter is reduced to zero. Applying the proposed methodology, both for fixed scaling, and the largemargin asymptotes, is shown to produce high quality clusteringmodels in comparison with state-of-the-art clustering algorithms in experiments using a large collection of benchmark datasets.	[Hofmeyr, David P.] Univ Lancaster, Dept Management Sci, Lancaster LA1 4YF, England; [Hofmeyr, David P.] Univ Lancaster, Dept Math & Stat, Lancaster LA1 4YF, England	Lancaster University; Lancaster University	Hofmeyr, DP (corresponding author), Univ Lancaster, Dept Management Sci, Lancaster LA1 4YF, England.; Hofmeyr, DP (corresponding author), Univ Lancaster, Dept Math & Stat, Lancaster LA1 4YF, England.	d.hofmeyr@lancaster.ac.uk	Hofmeyr, David/AAC-4042-2021	Hofmeyr, David/0000-0003-3068-8128	EPSRC [EP/H023151/1]; Oppenheimer Memorial Trust; Engineering and Physical Sciences Research Council [EP/M507234/1] Funding Source: researchfish; EPSRC [EP/M507234/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Oppenheimer Memorial Trust; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The author acknowledges support from the EPSRC funded EP/H023151/1 STOR-i centre for doctoral training, and the Oppenheimer Memorial Trust. He would also like to thank Dr. Nicos Pavlidis and Prof. Idris Eckley for their valuable comments on this work.	Agrawal R., 1998, SIGMOD Record, V27, P94, DOI 10.1145/276305.276314; Allgower E.L., 2012, NUMERICAL CONTINUATI, V13; [Anonymous], 1998, STAT LEARNING THEORY; Boley D, 1998, DATA MIN KNOWL DISC, V2, P325, DOI 10.1023/A:1009740529316; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Franti P, 2006, PATTERN RECOGN, V39, P761, DOI 10.1016/j.patcog.2005.09.012; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Kutin S, 2002, TR200204 U CHIC DEP; Leisch F, 2006, COMPUT STAT DATA AN, V51, P526, DOI 10.1016/j.csda.2005.10.006; Lewis AS, 2013, MATH PROGRAM, V141, P135, DOI 10.1007/s10107-012-0514-2; Narayanan Hariharan, 2006, ADV NEURAL INFORM PR, P1025; Ng AY, 2002, ADV NEUR IN, V14, P849; Pavlidis NG, 2016, J MACH LEARN RES, V17; PUNJ G, 1983, J MARKETING RES, V20, P134, DOI 10.2307/3151680; Rosenberg A., 2007, P 2007 JOINT C EMP M, P410; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Steinbach M, 2000, P KDD WORKSH TEXT MI, V400, P525; Steinbach M., 2003, NEW VISTAS STAT PHYS; Stoer M, 1997, J ACM, V44, P585, DOI 10.1145/263867.263872; Sturn A, 2002, BIOINFORMATICS, V18, P207, DOI 10.1093/bioinformatics/18.1.207; Tasoulis SK, 2010, PATTERN RECOGN, V43, P3391, DOI 10.1016/j.patcog.2010.05.025; Tatiraju S., 2008, IMAGE SEGMENTATION U; Vapnik V. N., 1982, ESTIMATION DEPENDENC, V40; von Luxburg U, 2008, ANN STAT, V36, P555, DOI 10.1214/009053607000000640; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wagner D., 1993, MIN CUT GRAPH BISECT; Xu L., 2004, ADV NEURAL INFORM PR; Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zhang K, 2009, IEEE T NEURAL NETWOR, V20, P583, DOI 10.1109/TNN.2008.2010620; Zhao Y., 2001, 0104 U M INN	33	20	20	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1547	1560		10.1109/TPAMI.2016.2609929	http://dx.doi.org/10.1109/TPAMI.2016.2609929			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	27654138				2022-12-18	WOS:000404606300005
J	Andalo, FA; Taubin, G; Goldenstein, S				Andalo, Fernanda A.; Taubin, Gabriel; Goldenstein, Siome			PSQP: Puzzle Solving by Quadratic Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image puzzle; quadratic programming; constrained optimization	JIGSAW PUZZLES; CONSTRAINTS; DOCUMENTS	In this article we present the first effective method based on global optimization for the reconstruction of image puzzles comprising rectangle pieces-Puzzle Solving by Quadratic Programming (PSQP). The proposed novel mathematical formulation reduces the problem to the maximization of a constrained quadratic function, which is solved via a gradient ascent approach. The proposed method is deterministic and can deal with arbitrary identical rectangular pieces. We provide experimental results showing its effectiveness when compared to state-of-the-art approaches. Although the method was developed to solve image puzzles, we also show how to apply it to the reconstruction of simulated strip-shredded documents, broadening its applicability.	[Andalo, Fernanda A.; Goldenstein, Siome] Univ Campinas UNICAMP, Inst Comp, Campinas, SP, Brazil; [Taubin, Gabriel] Brown Univ, Div Engn, Providence, RI 02912 USA	Universidade Estadual de Campinas; Brown University	Andalo, FA (corresponding author), Univ Campinas UNICAMP, Inst Comp, Campinas, SP, Brazil.	feandalo@ic.unicamp.br; taubin@brown.edu; siome@ic.unicamp.br	Andaló, Fernanda/K-6663-2012	Andaló, Fernanda/0000-0002-5243-0921; Taubin, Gabriel/0000-0002-1983-7607	CNPq [201238/2010-1, 308882/2013-0, 454082/2014-2]; FAPERJ; CAPES [E-26/103.665/2012]; US National Science Foundation (NSF) [IIS-0808718, CCF-0915661, IIP-1330139]; FAPESP [2012/50468-6]; Directorate For Engineering [1500249] Funding Source: National Science Foundation	CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); FAPERJ(Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado do Rio De Janeiro (FAPERJ)); CAPES(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); US National Science Foundation (NSF)(National Science Foundation (NSF)); FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)); Directorate For Engineering(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))	This work was primarily supported by CNPq (grants 201238/2010-1, 308882/2013-0, and 454082/2014-2), with additional support by FAPERJ and CAPES (grant E-26/103.665/2012), US National Science Foundation (NSF) (grants IIS-0808718, CCF-0915661, and IIP-1330139), and FAPESP (grant 2012/50468-6).	[Anonymous], 2008, DARPA SHREDDER CHALL; Brown BJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360683; BURDEA GC, 1989, IEEE T ROBOTIC AUTOM, V5, P752, DOI 10.1109/70.88097; Cho TS, 2010, PROC CVPR IEEE, P183, DOI 10.1109/CVPR.2010.5540212; Cho TS, 2010, IEEE T PATTERN ANAL, V32, P1489, DOI 10.1109/TPAMI.2009.133; da Gama Leitao H. C., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P705; Demaine ED, 2007, GRAPH COMBINATOR, V23, P195, DOI 10.1007/s00373-007-0713-4; FREEMAN H, 1964, IEEE T COMPUT, VEC13, P118, DOI 10.1109/PGEC.1964.263781; Gallagher AC, 2012, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2012.6247699; Goldberg D., 2002, P 18 ANN S COMP GEOM, P82; Justino E, 2006, FORENSIC SCI INT, V160, P140, DOI 10.1016/j.forsciint.2005.09.001; KOSIBA DA, 1994, INT C PATT RECOG, P616, DOI 10.1109/ICPR.1994.576377; Marande W, 2007, SCIENCE, V318, P415, DOI 10.1126/science.1148033; McBride J. C., 2003, IEEE COMPUTER VISION, V1, P3, DOI [10.1109/CVPRW.2003.10008, DOI 10.1109/CVPRW.2003.10008]; Nartker TA, 2005, P SOC PHOTO-OPT INS, V5676, P37, DOI 10.1117/12.587293; Nielsen TR, 2008, PATTERN RECOGN LETT, V29, P1924, DOI 10.1016/j.patrec.2008.05.027; Pomeranz D, 2011, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2011.5995331; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Seneta E, 2006, SPRINGER SER STAT, P1, DOI 10.1007/0-387-32792-4; Sholomon D, 2013, PROC CVPR IEEE, P1767, DOI 10.1109/CVPR.2013.231; Son K, 2014, LECT NOTES COMPUT SC, V8694, P32, DOI 10.1007/978-3-319-10599-4_3; Zhao Y.X., 2007, WSEAS INT C COMPUTER, P171; Zhu LJ, 2008, IEEE T PATTERN ANAL, V30, P1, DOI 10.1109/TPAMI.2007.1163	24	20	20	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					385	396		10.1109/TPAMI.2016.2547394	http://dx.doi.org/10.1109/TPAMI.2016.2547394			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27046868	hybrid			2022-12-18	WOS:000395553400013
J	Biggio, B; Fumera, G; Marcialis, GL; Roli, F				Biggio, Battista; Fumera, Giorgio; Marcialis, Gian Luca; Roli, Fabio			Statistical Meta-Analysis of Presentation Attacks for Secure Multibiometric Systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical meta-analysis; uncertainty analysis; presentation attacks; security evaluation; secure multibiometric fusion	BIOMETRIC RECOGNITION	Prior work has shown that multibiometric systems are vulnerable to presentation attacks, assuming that their matching score distribution is identical to that of genuine users, without fabricating any fake trait. We have recently shown that this assumption is not representative of current fingerprint and face presentation attacks, leading one to overestimate the vulnerability of multibiometric systems, and to design less effective fusion rules. In this paper, we overcome these limitations by proposing a statistical meta-model of face and fingerprint presentation attacks that characterizes a wider family of fake score distributions, including distributions of known and, potentially, unknown attacks. This allows us to perform a thorough security evaluation of multibiometric systems against presentation attacks, quantifying how their vulnerability may vary also under attacks that are different from those considered during design, through an uncertainty analysis. We empirically show that our approach can reliably predict the performance of multibiometric systems even under never-before-seen face and fingerprint presentation attacks, and that the secure fusion rules designed using our approach can exhibit an improved trade-off between the performance in the absence and in the presence of attack. We finally argue that our method can be extended to other biometrics besides faces and fingerprints.	[Biggio, Battista; Fumera, Giorgio; Marcialis, Gian Luca; Roli, Fabio] Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy	University of Cagliari	Biggio, B (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy.	battista.biggio@diee.unica.it; fumera@diee.unica.it; marcialis@diee.unica.it; roli@diee.unica.it	Biggio, Battista/HCI-4766-2022; Marcialis, Gian Luca/ABB-3299-2020; Biggio, Battista/M-5931-2016	Biggio, Battista/0000-0001-7752-509X; Biggio, Battista/0000-0001-7752-509X; ROLI, FABIO/0000-0003-4103-9190; Marcialis, Gian Luca/0000-0002-8719-9643				Akhtar Z., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P402, DOI 10.1109/ICB.2012.6199784; Anjos A., 2011, IJCB, P1, DOI DOI 10.1109/IJCB.2011.6117503; [Anonymous], 2015, 301071 ISOIEC DIS; [Anonymous], 2015, 301073 ISOIEC DIS; [Anonymous], 2012, 2382372012 ISOIEC; Arce I., 2003, IEEE Security & Privacy, V1, P72, DOI 10.1109/MSECP.2003.1193216; Biggio B, 2012, IET BIOMETRICS, V1, P11, DOI 10.1049/iet-bmt.2011.0012; Biggio B., 2011, 2011 INT JOINT C BIO, P1; Biggio B, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2015.2426728; Biggio B, 2014, IEEE T KNOWL DATA EN, V26, P984, DOI 10.1109/TKDE.2013.57; Biggio B, 2011, IEEE SYS MAN CYBERN, P977, DOI 10.1109/ICSMC.2011.6083796; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Chakka Murali Mohan, 2011, BIOM IJCB 2011 INT J; Chingovska I, 2014, ADV COMPUT VIS PATT, P185, DOI 10.1007/978-1-4471-6524-8_10; Chingovska I, 2013, IEEE COMPUT SOC CONF, P98, DOI 10.1109/CVPRW.2013.22; Das A, 2010, PR IEEE COMP DESIGN, P17, DOI 10.1109/ICCD.2010.5647566; Erdogmus N., 2013, IEEE 6 INT C BIOM TH, P1; Fumera G, 2014, ADV COMPUT VIS PATT, P165, DOI 10.1007/978-1-4471-6524-8_9; Geller B, 1999, J FORENSIC SCI, V44, P963; Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652; Hadid A, 2014, IEEE COMPUT SOC CONF, P113, DOI 10.1109/CVPRW.2014.22; ISO, 2006, 197951 ISOIEC; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102; Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653; Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416; Johnson Peter A, 2010, 2010 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2010.5711469; Kann A, 2000, ENVIRON MODEL ASSESS, V5, P29, DOI 10.1023/A:1019041023520; Kannala J, 2012, INT C PATT RECOG, P1363; Kim YS, 2009, J OPT SOC AM A, V26, P760, DOI 10.1364/JOSAA.26.000760; Marasco E., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P418, DOI 10.1109/BTAS.2012.6374609; Marasco E, 2011, LECT NOTES COMPUT SC, V6713, P309, DOI 10.1007/978-3-642-21557-5_33; Marcialis GL, 2009, LECT NOTES COMPUT SC, V5716, P12, DOI 10.1007/978-3-642-04146-4_4; MARTIN A, 1997, DET CURVE ASSESSMENT, V4, P1895; Matsumoto T., 2002, DATENSCHUTZ DATENSIC, V26; Mura V., 2015, P 7 IEEE INT C BIOM, P1; Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796; Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393; Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223; Rodrigues RN, 2009, J VISUAL LANG COMPUT, V20, P169, DOI 10.1016/j.jvlc.2009.01.010; Ross A.A., 2006, HDB MULTIBIOMETRICS; Saltelli A, 2000, STAT SCI, V15, P377, DOI 10.1214/ss/1009213004; Saltelli A., 2000, SENSITIVITY ANAL; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137, DOI 10.1109/34.809107; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tome P, 2015, INT CONF BIOMETR, P319, DOI 10.1109/ICB.2015.7139056; Tuveri P, 2015, LECT NOTES COMPUT SC, V9280, P540, DOI 10.1007/978-3-319-23234-8_50; Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007; Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810; Yang J, 2013, SCI WORLD J, DOI [10.1155/2013/812469, 10.1155/2013/829067]; Zhang Z, 2012, J NANOMATER, V2012, DOI 10.1155/2012/238605; Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438	52	20	20	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					561	575		10.1109/TPAMI.2016.2558154	http://dx.doi.org/10.1109/TPAMI.2016.2558154			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	28182550	Green Submitted, Green Published			2022-12-18	WOS:000395555100011
J	Feichtenhofer, C; Pinz, A; Wildes, RP				Feichtenhofer, Christoph; Pinz, Axel; Wildes, Richard P.			Dynamic Scene Recognition with Complementary Spatiotemporal Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic scenes; feature representations; visual spacetime; image dynamics; spatiotemporal orientation	SPATIAL PYRAMIDS; IMAGE; REPRESENTATION; PERCEPTION; COMPACT	This paper presents Dynamically Pooled Complementary Features (DPCF), a unified approach to dynamic scene recognition that analyzes a short video clip in terms of its spatial, temporal and color properties. The complementarity of these properties is preserved through all main steps of processing, including primitive feature extraction, coding and pooling. In the feature extraction step, spatial orientations capture static appearance, spatiotemporal oriented energies capture image dynamics and color statistics capture chromatic information. Subsequently, primitive features are encoded into a mid-level representation that has been learned for the task of dynamic scene recognition. Finally, a novel dynamic spacetime pyramid is introduced. This dynamic pooling approach can handle both global as well as local motion by adapting to the temporal structure, as guided by pooling energies. The resulting system provides online recognition of dynamic scenes that is thoroughly evaluated on the two current benchmark datasets and yields best results to date on both datasets. In-depth analysis reveals the benefits of explicitly modeling feature complementarity in combination with the dynamic spacetime pyramid, indicating that this unified approach should be well-suited to many areas of video analysis.	[Feichtenhofer, Christoph; Pinz, Axel] Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Graz, Austria; [Wildes, Richard P.] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON, Canada; [Wildes, Richard P.] York Univ, Ctr Vis Res, Toronto, ON, Canada	Graz University of Technology; York University - Canada; York University - Canada	Feichtenhofer, C (corresponding author), Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Graz, Austria.	feichtenhofer@tugraz.at; axel.pinz@tugraz.at; wildes@cse.yorku.ca			Austrian Science Fund (FWF) [P27076]; Canadian NSERC Discovery grant; Austrian Science Fund (FWF) [P 27076] Funding Source: researchfish	Austrian Science Fund (FWF)(Austrian Science Fund (FWF)); Canadian NSERC Discovery grant(Natural Sciences and Engineering Research Council of Canada (NSERC)); Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	This work was supported by the Austrian Science Fund (FWF) under project P27076 "Space-Time Representation and Recognition in Computer Vision" and a Canadian NSERC Discovery grant.	Adelson Edward H., 1985, PAMI, V2, P284, DOI DOI 10.1109/TPAMI.2012.141; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Cannons KJ, 2014, IEEE T PATTERN ANAL, V36, P784, DOI 10.1109/TPAMI.2013.233; Cao LJ, 2012, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2012.6248102; Chan AB, 2005, PROC CVPR IEEE, P846; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Derpanis KG, 2012, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2012.6247815; Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Elfiky NM, 2012, IMAGE VISION COMPUT, V30, P492, DOI 10.1016/j.imavis.2012.04.002; Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Feichtenhofer C, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.56; Feichtenhofer C, 2015, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2015.7298892; Feichtenhofer C, 2014, PROC CVPR IEEE, P2681, DOI 10.1109/CVPR.2014.343; Feng J., 2011, P IEEE C COMP VIS PA, P2609; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GOREA A, 1993, VISION RES, V33, P2515, DOI 10.1016/0042-6989(93)90132-G; Granlund G.H., 1995, SIGNAL PROCESSING CO; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li FF, 2002, P NATL ACAD SCI USA, V99, P9596, DOI 10.1073/pnas.092277599; Liu JJ, 2007, PR IEEE COMP DESIGN, P17; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Nikhil R., 2008, 2008 IEEE C COMP VIS, P1; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oppenheim A. V., 1999, DISCRETE TIME SIGNAL; PAPATHOMAS TV, 1991, VISION RES, V31, P1883, DOI 10.1016/0042-6989(91)90183-6; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; POTTER MC, 1969, J EXP PSYCHOL, V81, P10, DOI 10.1037/h0027470; Rousselet GA, 2004, TRENDS COGN SCI, V8, P363, DOI 10.1016/j.tics.2004.06.003; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864; Sizintsev M, 2014, IEEE T PATTERN ANAL, V36, P2241, DOI 10.1109/TPAMI.2014.2321373; Stone J.V., 2012, VISION BRAIN WE PERC; Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871; Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032; Theriault C, 2013, PROC CVPR IEEE, P2603, DOI 10.1109/CVPR.2013.336; Tran D., 2014, ARXIV; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Watson A., 1983, P MOT WORKSH, P1; Wildes Richard P, 2000, COMPUTER VISION ECCV; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	54	20	23	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2389	2401		10.1109/TPAMI.2016.2526008	http://dx.doi.org/10.1109/TPAMI.2016.2526008			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	27824581				2022-12-18	WOS:000387984700004
J	Kalogeiton, V; Ferrari, V; Schmid, C				Kalogeiton, Vicky; Ferrari, Vittorio; Schmid, Cordelia			Analysing Domain Shift Factors between Videos and Images for Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; domain adaptation; video and image analysis	LOCALIZATION; RECOGNITION	Object detection is one of the most important challenges in computer vision. Object detectors are usually trained on bounding-boxes from still images. Recently, video has been used as an alternative source of data. Yet, for a given test domain (image or video), the performance of the detector depends on the domain it was trained on. In this paper, we examine the reasons behind this performance gap. We define and evaluate different domain shift factors: spatial location accuracy, appearance diversity, image quality and aspect distribution. We examine the impact of these factors by comparing performance before and after factoring them out. The results show that all four factors affect the performance of the detectors and their combined effect explains nearly the whole performance gap.	[Kalogeiton, Vicky; Ferrari, Vittorio] Univ Edinburgh, CALVIN Team, Edinburgh EH8 9YL, Midlothian, Scotland; [Kalogeiton, Vicky; Schmid, Cordelia] INRIA Grenoble, LJK Lab, THOTH Team, Grenoble, France	University of Edinburgh	Kalogeiton, V (corresponding author), Univ Edinburgh, CALVIN Team, Edinburgh EH8 9YL, Midlothian, Scotland.; Kalogeiton, V (corresponding author), INRIA Grenoble, LJK Lab, THOTH Team, Grenoble, France.	vicky.kalogeiton@ed.ac.uk; vferrari@staffmail.ed.ac.uk; cordelia.schmid@inria.fr	Kalogeiton, Vicky/AAP-1860-2020	Kalogeiton, Vicky/0000-0002-7368-6993				Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; [Anonymous], 2015, IMAGENET LARGE SCALE; [Anonymous], 2007, PASCAL VISUAL OBJECT; [Anonymous], 2003, KERNEL DENSITY ESTIM; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chum O., 2007, P IEEE C COMP VIS PA, P1; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Donahue J., 2013, 31 INT C MACH LEARN; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fergus R, 2003, PROC CVPR IEEE, P264; Girshick RB, 2012, DISCRIMINATIVELY TRA; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3; Jia Y., 2013, CAFFE OPEN SOURCE CO; Jia Y., P ACM MULT, P675; Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Leistner C., 2011, P IEEE C COMP VIS PA, P2753; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sharma P, 2013, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2013.418; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Tang K., 2012, ADV NEURAL INFORM PR; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang LM, 2014, LECT NOTES COMPUT SC, V8693, P565, DOI 10.1007/978-3-319-10602-1_37; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10	44	20	21	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2327	2334		10.1109/TPAMI.2016.2551239	http://dx.doi.org/10.1109/TPAMI.2016.2551239			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	27071159	Green Submitted, Green Accepted			2022-12-18	WOS:000385945000014
J	Qin, Z; Shelton, CR				Qin, Zhen; Shelton, Christian R.			Social Grouping for Multi-Target Tracking and Head Pose Estimation in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-target tracking; multi-camera tracking; head pose estimation; social grouping; video analysis; context	APPEARANCE; MODEL	Many computer vision tasks are more difficult when tackled without contextual information. For example, in multi-camera tracking, pedestrians may look very different in different cameras with varying pose and lighting conditions. Similarly, head direction estimation in high-angle surveillance video in which human head images are low resolution is challenging. Even humans can have trouble without contextual information. In this work, we couple novel contextual information, social grouping, with two important computer vision tasks: multi-target tracking and head pose/direction estimation in surveillance video. These three components are modeled in a probabilistic formulation and we provide effective solvers. We show that social grouping effectively helps to mitigate visual ambiguities in multi-camera tracking and head pose estimation. We further notice that in single-camera multi-target tracking, social grouping provides a natural high-order association cue that avoids existing complex algorithms for high-order track association. In experiments, we demonstrate improvements with our model over models without social grouping context and several state-of-art approaches on a number of publicly available datasets on tracking, head pose estimation, and group discovery.	[Qin, Zhen; Shelton, Christian R.] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	University of California System; University of California Riverside	Qin, Z (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.	zqin001@cs.ucr.edu; cshelton@cs.ucr.edu	Shelton, Christian/GQJ-1146-2022	Shelton, Christian/0000-0001-6698-7838	US Defense Advanced Research Projects Agency (DARPA) [FA8750-12-2-0010]	US Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work was supported by the US Defense Advanced Research Projects Agency (DARPA) (FA8750-12-2-0010).	Aghajanian J., 2009, P 20 BRIT MACH VIS C, V1, P1; [Anonymous], 2011, CAVIAR CAVIAR DATASE; Bazzani L, 2012, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2012.6247888; Benfold B, 2011, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2011.6126516; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Chamveha I, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.121; Chamveha I, 2013, COMPUT VIS IMAGE UND, V117, P1502, DOI 10.1016/j.cviu.2013.06.005; Chen C, 2012, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2012.6247845; Chen XJ, 2014, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2014.162; D'Orazio T, 2009, 2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P365; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Demirkus M, 2014, MULTIMED TOOLS APPL, V70, P495, DOI 10.1007/s11042-012-1352-1; Denina G., 2010, DISTRIBUTED VIDEO SE; Duchi J. C., 2006, P ADV NEUR INF PROC, P369; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532; Hou Y., 2013, P IEEE INT C MULT EX, P1; Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Kuo CH, 2010, LECT NOTES COMPUT SC, V6311, P383; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Makris D, 2004, PROC CVPR IEEE, P205; Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Orozco J., 2009, P BMVC, V1, P120, DOI DOI 10.5244/C.23.120; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pellegrini S., 2010, P EUR C COMPUT VIS; Prosser B., 2008, P BRIT MACH VIS C, P641; Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899; Robertson N, 2006, LECT NOTES COMPUT SC, V3952, P402; Schmidt Mark, 2012, MINFUNC; Sochman J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P830, DOI 10.1109/ICCVW.2011.6130338; Song B., 2010, P EUR C COMPUT VIS; Sontag D, 2012, OPTIMIZATION FOR MACHINE LEARNING, P219; Sutton Charles, 2012, FDN TRENDS MACHINE L; Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263; Wu TF, 2004, J MACH LEARN RES, V5, P975; Wu Z, 2011, PROC CVPR IEEE, P1185, DOI 10.1109/CVPR.2011.5995515; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yang B, 2014, INT J COMPUT VISION, V107, P203, DOI 10.1007/s11263-013-0666-4; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892; Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhang S, 2013, IEEE COMPUT SOC CONF, P751, DOI 10.1109/CVPRW.2013.113; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	53	20	24	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					2082	2095		10.1109/TPAMI.2015.2505292	http://dx.doi.org/10.1109/TPAMI.2015.2505292			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26660698	Green Submitted			2022-12-18	WOS:000384240600012
J	Chakraborty, A; Das, A; Roy-Chowdhury, AK				Chakraborty, Anirban; Das, Abir; Roy-Chowdhury, Amit K.			Network Consistent Data Association	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data association; network consistency; integer program; person re-identification; spatio-temporal cell tracking	TRACKING; MICROSCOPY; ALGORITHM; TIME	Existing data association techniques mostly focus on matching pairs of data-point sets and then repeating this process along space-time to achieve long term correspondences. However, in many problems such as person re-identification, a set of data-points may be observed at multiple spatio-temporal locations and/or by multiple agents in a network and simply combining the local pairwise association results between sets of data-points often leads to inconsistencies over the global space-time horizons. In this paper, we propose a Novel Network Consistent Data Association (NCDA) framework formulated as an optimization problem that not only maintains consistency in association results across the network, but also improves the pairwise data association accuracies. The proposed NCDA can be solved as a binary integer program leading to a globally optimal solution and is capable of handling the challenging data-association scenario where the number of data-points varies across different sets of instances in the network. We also present an online implementation of NCDA method that can dynamically associate new observations to already observed data-points in an iterative fashion, while maintaining network consistency. We have tested both the batch and the online NCDA in two application areas-person re-identification and spatio-temporal cell tracking and observed consistent and highly accurate data association results in all the cases.	[Chakraborty, Anirban] Natl Univ Singapore, Dept Diagnost Radiol, Singapore 119077, Singapore; [Chakraborty, Anirban] Univ Calif Riverside, Riverside, CA 92521 USA; [Das, Abir] Univ Massachusetts Lowell, Dept Comp Sci, Lowell, MA USA; [Roy-Chowdhury, Amit K.] Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA	National University of Singapore; University of California System; University of California Riverside; University of Massachusetts System; University of Massachusetts Lowell; University of California System; University of California Riverside	Chakraborty, A (corresponding author), Natl Univ Singapore, Dept Diagnost Radiol, Singapore 119077, Singapore.	anirban.chakraborty@email.ucr.edu; abir.das@email.ucr.edu; amitrc@ece.ucr.edu			NSF [IIS-1316934, CNS-1544969]	NSF(National Science Foundation (NSF))	This work was partially supported by NSF grants IIS-1316934 and CNS-1544969. The work was done when the authors A. Chakraborty and A. Das were at the University of California, Riverside, CA 92521.	Alavi A, 2013, IEEE IMAGE PROC, P3542, DOI 10.1109/ICIP.2013.6738731; Avidan S, 2007, INT J COMPUT VISION, V71, P49, DOI 10.1007/s11263-005-4888-v; Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38; Bacarian T., 2005, IEEE COMP SOC C COMP, P142; Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008; Bellet A., 2013, ARXIV E PRINTS; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bise R, 2011, I S BIOMED IMAGING, P1004, DOI 10.1109/ISBI.2011.5872571; Chakraborty A, 2014, IEEE IMAGE PROC, P451, DOI 10.1109/ICIP.2014.7025090; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22; Delibaltov D, 2012, CONF REC ASILOMAR C, P1588, DOI 10.1109/ACSSC.2012.6489297; Dikmen Mert, 2010, P AS C COMP VIS, P501; Dufour A, 2005, IEEE T IMAGE PROCESS, V14, P1396, DOI 10.1109/TIP.2005.852790; Dzyubachyk O, 2010, IEEE T MED IMAGING, V29, P852, DOI 10.1109/TMI.2009.2038693; Gilbert A, 2006, LECT NOTES COMPUT SC, V3952, P125; Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532; Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003; Kachouie NN, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/12186; Karthikeyan S, 2012, IEEE IMAGE PROC, P1349, DOI 10.1109/ICIP.2012.6467118; Kirubarajan T, 2001, IEEE T AERO ELEC SYS, V37, P2, DOI 10.1109/7.913664; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Li K., 2007, P INT WORKSH MICR IM; Li K, 2008, MED IMAGE ANAL, V12, P546, DOI 10.1016/j.media.2008.06.001; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461; Liang Liang, 2013, Inf Process Med Imaging, V23, P98, DOI 10.1007/978-3-642-38868-2_9; Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39; Liu M, 2011, MOL PLANT, V4, P922, DOI 10.1093/mp/ssr071; Liu M, 2010, PLANT J, V62, P135, DOI 10.1111/j.1365-313X.2009.04117.x; Martinel N., 2012, IEEE COMPUTER SOC C, DOI DOI 10.1109/CVPRW.2012.6239203; Martinel N, 2015, IEEE T PATTERN ANAL, V37, P1656, DOI 10.1109/TPAMI.2014.2377748; Mkrtchyan K., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2165, DOI 10.1109/ICIP.2011.6116040; Mkrtchyan K, 2013, I S BIOMED IMAGING, P672; Padfield D, 2009, MED IMAGE ANAL, V13, P143, DOI 10.1016/j.media.2008.06.018; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133; Prosser B., 2008, P BRIT MACH VIS C, P641; Schrijver A., 1998, THEORY LINEAR INTEGE; Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1; Yang L., 2006, DISTANCE METRIC LEAR; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460	44	20	21	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1859	1871		10.1109/TPAMI.2015.2491922	http://dx.doi.org/10.1109/TPAMI.2015.2491922			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26485472	Green Submitted			2022-12-18	WOS:000381432700011
J	Hauberg, S				Hauberg, Soren			Principal Curves on Riemannian Manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Principal component analysis; principal curves; differential geometry; Riemannian manifolds	GEODESIC ANALYSIS; SHAPE-ANALYSIS; STATISTICS; TRACKING; METRICS; SPACES	Euclidean statistics are often generalized to Riemannian manifolds by replacing straight-line interpolations with geodesic ones. While these Riemannian models are familiar-looking, they are restricted by the inflexibility of geodesics, and they rely on constructions which are optimal only in Euclidean domains. We consider extensions of Principal Component Analysis (PCA) to Riemannian manifolds. Classic Riemannian approaches seek a geodesic curve passing through the mean that optimizes a criteria of interest. The requirements that the solution both is geodesic and must pass through the mean tend to imply that the methods only work well when the manifold is mostly flat within the support of the generating distribution. We argue that instead of generalizing linear Euclidean models, it is more fruitful to generalize non-linear Euclidean models. Specifically, we extend the classic Principal Curves from Hastie & Stuetzle to data residing on a complete Riemannian manifold. We show that for elliptical distributions in the tangent of spaces of constant curvature, the standard principal geodesic is a principal curve. The proposed model is simple to compute and avoids many of the pitfalls of traditional geodesic approaches. We empirically demonstrate the effectiveness of the Riemannian principal curves on several manifolds and datasets.	[Hauberg, Soren] Tech Univ Denmark, Sect Cognit Syst, Lyngby, Denmark	Technical University of Denmark	Hauberg, S (corresponding author), Tech Univ Denmark, Sect Cognit Syst, Lyngby, Denmark.	sohau@dtu.dk	Hauberg, Søren/L-2104-2016	Hauberg, Søren/0000-0001-7223-877X	Danish Council for Independent Research (DFF), Natural Sciences	Danish Council for Independent Research (DFF), Natural Sciences	The author is funded in part by the Danish Council for Independent Research (DFF), Natural Sciences. He is grateful to Aasa Feragen and anonymous reviewers for helpful feedback on early drafts of the manuscript.	Amari S., 2000, METHODS INFORM GEOME; Berger M., 2007, PANORAMIC VIEW RIEMA; Cetingul HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806; DIGGLE P, 1985, J R STAT SOC C-APPL, V34, P138; Duchamp T, 1996, ANN STAT, V24, P1511; Feragen Aasa, 2013, Inf Process Med Imaging, V23, P74, DOI 10.1007/978-3-642-38868-2_7; Fletcher P.T., 2003, COMPUTER VISION PATT, V1, P1; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Freifeld O, 2014, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2014.179; Freifeld O, 2012, LECT NOTES COMPUT SC, V7572, P1, DOI 10.1007/978-3-642-33718-5_1; Gerber S, 2013, J MACH LEARN RES, V14, P1285; Gerber S, 2010, MED IMAGE ANAL, V14, P643, DOI 10.1016/j.media.2010.05.008; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hauberg S., 2012, ADV NEURAL INFORM PR, P2033; Hauberg S, 2013, J MATH IMAGING VIS, V46, P103, DOI 10.1007/s10851-012-0372-9; Hauberg S, 2012, IMAGE VISION COMPUT, V30, P453, DOI 10.1016/j.imavis.2011.11.009; Hauberg S, 2010, LECT NOTES COMPUT SC, V6311, P425, DOI 10.1007/978-3-642-15549-9_31; Hennig P, 2014, JMLR WORKSH CONF PRO, V33, P347; Huckemann S, 2010, STAT SINICA, V20, P1; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500; Jung SK, 2012, BIOMETRIKA, V99, P551, DOI 10.1093/biomet/ass022; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; KENDALL WS, 1990, P LOND MATH SOC, V61, P371; Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee J.M., 2002, INTRO SMOOTH MANIFOL; Lenglet C, 2004, LECT NOTES COMPUT SC, V2034, P127; Panaretos VM, 2014, J AM STAT ASSOC, V109, P424, DOI 10.1080/01621459.2013.849199; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Said S., 2007, P 15 EUR SIGN PROC C, P1700; Sommer S, 2014, ADV COMPUT MATH, V40, P283, DOI 10.1007/s10444-013-9308-1; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Wang HN, 2006, PATTERN RECOGN LETT, V27, P1142, DOI 10.1016/j.patrec.2005.12.005; Wang YX, 2014, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2014.390; Younes L, 2012, IMAGE VISION COMPUT, V30, P389, DOI 10.1016/j.imavis.2011.09.009; Zhang Miaomiao, 2013, ADV NEURAL INFORM PR, V26, P2	43	20	21	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1915	1921		10.1109/TPAMI.2015.2496166	http://dx.doi.org/10.1109/TPAMI.2015.2496166			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26540674	Green Published			2022-12-18	WOS:000381432700016
J	Li, SN; Ngan, KN; Paramesran, R; Sheng, L				Li, Songnan; Ngan, King Ngi; Paramesran, Raveendran; Sheng, Lu			Real-Time Head Pose Tracking with Online Face Template Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Head pose tracking; deformable face model; iterative closest point; RGB-Depth camera		We propose a real-time method to accurately track the human head pose in the 3-dimensional (3D) world. Using a RGB-Depth camera, a face template is reconstructed by fitting a 3D morphable face model, and the head pose is determined by registering this user-specific face template to the input depth video.	[Li, Songnan; Ngan, King Ngi; Sheng, Lu] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China; [Paramesran, Raveendran] Univ Malaya, Kuala Lumpur, Malaysia	Chinese University of Hong Kong; Universiti Malaya	Li, SN (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.	snli@ee.cuhk.edu.hk; knngan@ee.cuhk.edu.hk; ravee@um.edu.my; lsheng@ee.cuhk.edu.hk	Sheng, Lu/V-2526-2019; Paramesran, Raveendran/AAA-1895-2019; Ngan, N/E-8240-2014	Sheng, Lu/0000-0002-8525-9163; Ngan, N/0000-0003-1946-3235; Paramesran, Raveendran/0000-0001-5093-7027	Hong Kong Innovation and Technology Commission [ITS/070/13]; University of Malaya, Malaysia [UM.C/625/1/HIR/MOHE/ENG/42]	Hong Kong Innovation and Technology Commission; University of Malaya, Malaysia(Universiti Malaya)	This work was partially supported by the Hong Kong Innovation and Technology Commission (Project ITS/070/13) and the University of Malaya, Malaysia (Project UM.C/625/1/HIR/MOHE/ENG/42).	[Anonymous], 2012, ICT 3DHP KINECT HEAD; [Anonymous], BIWI KINECT HEAD POS; Bar T, 2012, IEEE INT C INTELL TR, P1797, DOI 10.1109/ITSC.2012.6338678; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Breitenstein M. D., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.458; Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229; Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Kaymak Sertan, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P160, DOI 10.1007/978-3-642-37484-5_14; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Movellan J., 2008, 2008 8 IEEE INT C AU, P1, DOI DOI 10.1109/AFGR.2008.4813429; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Padeleris P., 2012, 2012 IEEE COMP SOC C, P42, DOI DOI 10.1109/CVPRW.2012.6239236; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Songnan Li, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P153, DOI 10.1007/978-3-642-39402-7_16; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Zollhofer M, 2011, COMPUT ANIMAT VIRT W, V22, P195, DOI 10.1002/cav.405	23	20	20	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1922	1928		10.1109/TPAMI.2015.2500221	http://dx.doi.org/10.1109/TPAMI.2015.2500221			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26584487				2022-12-18	WOS:000381432700017
J	Haines, O; Calway, A				Haines, Osian; Calway, Andrew			Recognising Planes in a Single Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Planar structure; single images; recognition; learning		We present a novel method to recognise planar structures in a single image and estimate their 3D orientation. This is done by exploiting the relationship between image appearance and 3D structure, using machine learning methods with supervised training data. As such, the method does not require specific features or use geometric cues, such as vanishing points. We employ general feature representations based on spatiograms of gradients and colour, coupled with relevance vector machines for classification and regression. We first show that using hand-labelled training data, we are able to classify pre-segmented regions as being planar or not, and estimate their 3D orientation. We then incorporate the method into a segmentation algorithm to detect multiple planar structures from a previously unseen image.	[Haines, Osian; Calway, Andrew] Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England	University of Bristol	Haines, O (corresponding author), Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.	haines@cs.bris.ac.uk; andrew@cs.bris.ac.uk			United Kingdom Engineering and Physical Sciences Research Council	United Kingdom Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank the United Kingdom Engineering and Physical Sciences Research Council for funding this work. Osian Haines is the corresponding author.	Barinova O, 2008, LECT NOTES COMPUT SC, V5303, P100, DOI 10.1007/978-3-540-88688-4_8; BESAG J, 1986, J R STAT SOC B, V48, P259; Birchfield ST, 2005, PROC CVPR IEEE, P1158; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Choi S, 2008, IEEE IJCNN, P1828, DOI 10.1109/IJCNN.2008.4634046; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Conaire C. O, 2007, P IEEE INT C AC SPEE; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Fergus R, 2005, PROC CVPR IEEE, P380; GARDING J, 1993, IEEE T PATTERN ANAL, V15, P1202, DOI 10.1109/34.244682; Gregory RL, 1997, PHILOS T ROY SOC B, V352, P1121, DOI 10.1098/rstb.1997.0095; Guo F, 2010, IEEE T PATTERN ANAL, V32, P1329, DOI 10.1109/TPAMI.2010.26; Haines Osian, 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P289; Haines O., 2013, THESIS U BRISTOL BRI; Haines O, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.31; Haines O, 2013, IEEE INT CONF ROBOT, P2227, DOI 10.1109/ICRA.2013.6630877; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hoiem D, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.232; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; Kosecka J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez-Carranza J, 2012, IEEE INT CONF ROBOT, P5210, DOI 10.1109/ICRA.2012.6225100; Micusik B., 2008, P IEEE C COMP VIS PA, P1; Orban G., 2006, ADV NEURAL INFORM PR, P1043; Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23; Ramalingam S, 2013, IEEE I CONF COMP VIS, P497, DOI 10.1109/ICCV.2013.67; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Stein A, 2007, IEEE I CONF COMP VIS, P110; Thayananthan A, 2006, LECT NOTES COMPUT SC, V3953, P124, DOI 10.1007/11744078_10; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214	35	20	21	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1849	1861		10.1109/TPAMI.2014.2382097	http://dx.doi.org/10.1109/TPAMI.2014.2382097			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353131	hybrid			2022-12-18	WOS:000359216600009
J	Aftab, K; Hartley, R; Trumpf, J				Aftab, Khurrum; Hartley, Richard; Trumpf, Jochen			Generalized Weiszfeld Algorithms for Lq Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weiszfeld algorithm; rotation averaging; L-q mean	EIGENVECTOR SYNCHRONIZATION; CONVERGENCE	In many computer vision applications, a desired model of some type is computed by minimizing a cost function based on several measurements. Typically, one may compute the model that minimizes the L-2 cost, that is the sum of squares of measurement errors with respect to the model. However, the Lq solution which minimizes the sum of the qth power of errors usually gives more robust results in the presence of outliers for some values of q, for example, q = 1. The Weiszfeld algorithm is a classic algorithm for finding the geometric L1 mean of a set of points in Euclidean space. It is provably optimal and requires neither differentiation, nor line search. The Weiszfeld algorithm has also been generalized to find the L1 mean of a set of points on a Riemannian manifold of non-negative curvature. This paper shows that the Weiszfeld approach may be extended to a wide variety of problems to find an Lq mean for 1 <= q < 2, while maintaining simplicity and provable convergence. We apply this problem to both single-rotation averaging (under which the algorithm provably finds the global Lq optimum) and multiple rotation averaging (for which no such proof exists). Experimental results of Lq optimization for rotations show the improved reliability and robustness compared to L-2 optimization.	[Aftab, Khurrum; Hartley, Richard; Trumpf, Jochen] Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia; [Aftab, Khurrum; Hartley, Richard; Trumpf, Jochen] NICTA Natl ICT Australia, Canberra, ACT 0200, Australia	Australian National University; NICTA	Aftab, K (corresponding author), Australian Natl Univ, Res Sch Engn, GPO Box 4, Canberra, ACT 0200, Australia.	Khurrum.Aftab@anu.edu.au; Richard.Hartley@anu.edu.au; Jochen.Trumpf@anu.edu.au		Hartley, Richard/0000-0002-5005-0191	National ICT Australia; Australian Government	National ICT Australia; Australian Government(Australian GovernmentCGIAR)	This research has been funded by National ICT Australia. National ICT Australia is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.	Afsari B, 2013, SIAM J CONTROL OPTIM, V51, P2230, DOI 10.1137/12086282X; Afsari B, 2011, P AM MATH SOC, V139, P655, DOI 10.1090/S0002-9939-2010-10541-5; Aftab K., LQ CLOSEST POINT AFF; [Anonymous], 1999, NUMERICAL OPTIMIZATI; BRIMBERG J, 1993, OPER RES, V41, P1153, DOI 10.1287/opre.41.6.1153; Brimberg J, 1998, COMPUT MATH APPL, V35, P25, DOI 10.1016/S0898-1221(98)00054-6; Brimberg J., 2003, YUGOSL J OPER RES, V13, P199; Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498; Chavel I., 2006, RIEMANNIAN GEOMETRY; Cheeger J., 1975, N HOLLAND MATH LIB, V9; Cucuringu M, 2012, INF INFERENCE, V1, P21, DOI 10.1093/imaiai/ias002; Daubechies I, 2008, 2008 42ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-3, P26, DOI 10.1109/CISS.2008.4558489; Dold A., 1995, LECT ALGEBRAIC TOPOL; ECKHARDT U, 1980, MATH PROGRAM, V18, P186, DOI 10.1007/BF01588313; Eldar YC, 2009, IEEE T INFORM THEORY, V55, P5302, DOI 10.1109/TIT.2009.2030471; Fletcher P. T., 2001, P IEEE C COMP VIS PA; Fletcher PT, 2009, NEUROIMAGE, V45, pS143, DOI 10.1016/j.neuroimage.2008.10.052; Govindu VM, 2004, PROC CVPR IEEE, P684; Groisser D, 2004, ADV APPL MATH, V33, P95, DOI 10.1016/j.aam.2003.08.003; Hartley R, 2004, PROC CVPR IEEE, P504; Hartley R., 2011, P IEEE C COMP VIS PA, P3041, DOI DOI 10.1109/CVPR.2011.5995745; Hartley R., 2004, ROBOTICA; Hartley RI, 1998, PHILOS T R SOC A, V356, P1175, DOI 10.1098/rsta.1998.0216; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; Kaucic R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P420, DOI 10.1109/ICCV.2001.937548; Klingenberg W., 1982, AKSUTIKA; KUHN HW, 1962, J REGIONAL SCI, V4, P21; Lang S., 1999, FUNDAMENTALS DIFFERE; Le HL, 2001, ADV APPL PROBAB, V33, P324, DOI 10.1017/S0001867800010818; Lee John M, 2018, INTRO RIEMANNIAN MAN; Luenberger D.G., 2003, LINEAR NONLINEAR PRO; Manton JH, 2004, I C CONT AUTOMAT ROB, P2211; Martinec D., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383115; Meyer W., 1989, LECT NOTES TRIESTE; Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877; Myers S., 1945, T AM MATH SOC; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Petersen P., 2006, RIEMANNIAN GEOMETRY; Plastria F, 2008, TOP, V16, P388, DOI 10.1007/s11750-008-0056-1; Rother C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P42, DOI 10.1109/ICCV.2001.937497; Sarlette A, 2009, SIAM J CONTROL OPTIM, V48, P56, DOI 10.1137/060673400; SIM K, 2006, IEEE C COMP VIS PATT, P1230, DOI DOI 10.1109/CVPR.2006.247; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Tron R, 2009, IEEE DECIS CONTR P, P901, DOI 10.1109/CDC.2009.5400405; Wang L., 2012, ARXIV12112441; Weber A., 1909, UEBER STANDORT INDUS; Weiszfeld E, 2009, ANN OPER RES, V167, P7, DOI 10.1007/s10479-008-0352-z; Yang L, 2010, LMS J COMPUT MATH, V13, P461, DOI 10.1112/S1461157020090531; Yuchao Dai, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P335	53	20	20	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					728	745		10.1109/TPAMI.2014.2353625	http://dx.doi.org/10.1109/TPAMI.2014.2353625			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353290	Green Submitted			2022-12-18	WOS:000351213400003
J	Mumtaz, A; Coviello, E; Lanckriet, GRG; Chan, AB				Mumtaz, Adeel; Coviello, Emanuele; Lanckriet, Gert R. G.; Chan, Antoni B.			A Scalable and Accurate Descriptor for Dynamic Textures Using Bag of System Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic textures; bag of systems; video annotation; music annotation; dynamic texture recognition; efficient indexing; large codebooks	REPRESENTATION; SCENE	The bag-of-systems (BoS) representation is a descriptor of motion in a video, where dynamic texture (DT) codewords represent the typical motion patterns in spatio-temporal patches extracted from the video. The efficacy of the BoS descriptor depends on the richness of the codebook, which depends on the number of codewords in the codebook. However, for even modest sized codebooks, mapping videos onto the codebook results in a heavy computational load. In this paper we propose the BoS Tree, which constructs a bottom-up hierarchy of codewords that enables efficient mapping of videos to the BoS codebook. By leveraging the tree structure to efficiently index the codewords, the BoS Tree allows for fast look-ups in the codebook and enables the practical use of larger, richer codebooks. We demonstrate the effectiveness of BoS Trees on classification of four video datasets, as well as on annotation of a video dataset and a music dataset. Finally, we show that, although the fast look-ups of BoS Tree result in different descriptors than BoS for the same video, the overall distance (and kernel) matrices are highly correlated resulting in similar classification performance.	[Mumtaz, Adeel; Chan, Antoni B.] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Coviello, Emanuele; Lanckriet, Gert R. G.] San Diego State Univ, Dept Elect & Comp Engn, San Diego, CA 92182 USA	City University of Hong Kong; California State University System; San Diego State University	Mumtaz, A (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	adeelmumtaz@gmail.com; emanuetre@gmail.com; gert@ece.ucsd.edu; abchan@cityu.edu.hk	CHAN, Antoni B./D-7858-2013	CHAN, Antoni B./0000-0002-2886-2513	Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 110610, CityU 110513]; Google, Inc.; Qualcomm, Inc.; Yahoo! Inc.; KETI under the PHTM program; NSF [CCF-0830535, IIS-1054960]; Alfred P. Sloan Foundation; NSF Research Infrastructure Grant [EIA-0303622]; UCSD; Research Grant Council; University Grant Committee of the HKSAR; HKBU	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); Google, Inc.(Google Incorporated); Qualcomm, Inc.; Yahoo! Inc.; KETI under the PHTM program; NSF(National Science Foundation (NSF)); Alfred P. Sloan Foundation(Alfred P. Sloan Foundation); NSF Research Infrastructure Grant; UCSD; Research Grant Council(Hong Kong Research Grants Council); University Grant Committee of the HKSAR; HKBU	The authors thank R. Peteri for the DynTex dataset, and G. Doretto for the UCLA dataset. A.M. and A.B.C. were supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (CityU 110610 & CityU 110513). E.C., A.B.C. and G.R.G.L. acknowledge support from Google, Inc. EC and GRGL acknowledge support from Qualcomm, Inc., Yahoo! Inc., KETI under the PHTM program, and NSF Grants CCF-0830535 and IIS-1054960. G.R.G.L. acknowledges support from the Alfred P. Sloan Foundation. This research was supported in part by the UCSD FWGrid Project, NSF Research Infrastructure Grant Number EIA-0303622. This research was conducted in part using the resources of the HPCCC, HKBU, which receives funding from Research Grant Council, University Grant Committee of the HKSAR and HKBU.	Afsari B, 2012, PROC CVPR IEEE, P2208, DOI 10.1109/CVPR.2012.6247929; Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Cayton L., 2008, P 25 INT C MACHINE L, P112; Chan AB, 2005, PROC CVPR IEEE, P846; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; Chan AB, 2010, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2010.5539878; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Coviello E., 2013, P INT C MACH LEARN, P468; Coviello E, 2012, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2012.6247900; Coviello E, 2011, IEEE T AUDIO SPEECH, V19, P1343, DOI 10.1109/TASL.2010.2090148; Derpanis K., 2012, P COMP VIS PATT REC, P1; Derpanis KG, 2010, PROC CVPR IEEE, P191, DOI 10.1109/CVPR.2010.5540213; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Ellis K., 2011, P 12 INT SOC MUS INF, P723; Ellis K, 2013, IEEE T AUDIO SPEECH, V21, P2554, DOI 10.1109/TASL.2013.2279318; Gersho A., 1992, VECTOR QUANTIZATION; Grauman K., 2006, NIPS, P505; Grossberg S, 2009, J VISION, V9, DOI 10.1167/9.4.6; Lepetit V, 2005, PROC CVPR IEEE, P775; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; Mumtaz A, 2013, IEEE T PATTERN ANAL, V35, P1606, DOI 10.1109/TPAMI.2012.236; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Peteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009; Ravichandran A., 2012, IEEE T PATTERN ANAL, V35, P342; Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847; Saisan P, 2001, PROC CVPR IEEE, P58; Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Vasconcelos N., 2001, P COMP VIS PATT REC; Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110	39	20	21	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					697	712		10.1109/TPAMI.2014.2359432	http://dx.doi.org/10.1109/TPAMI.2014.2359432			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353288				2022-12-18	WOS:000351213400001
J	Dai, YC; Li, HD; He, MY				Dai, Yuchao; Li, Hongdong; He, Mingyi			Projective Multiview Structure and Motion from Element-Wise Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Element-wise factorization; projective structure and motion; semidefinite programming; missing data; outlier	LOW-RANK; ALGORITHM; NORM; RECONSTRUCTION; MATRICES	The Sturm-Triggs type iteration is a classic approach for solving the projective structure-from-motion (SfM) factorization problem, which iteratively solves the projective depths, scene structure, and camera motions in an alternated fashion. Like many other iterative algorithms, the Sturm-Triggs iteration suffers from common drawbacks, such as requiring a good initialization, the iteration may not converge or may only converge to a local minimum, and so on. In this paper, we formulate the projective SfM problem as a novel and original element-wise factorization (i.e., Hadamard factorization) problem, as opposed to the conventional matrix factorization. Thanks to this formulation, we are able to solve the projective depths, structure, and camera motions simultaneously by convex optimization. To address the scalability issue, we adopt a continuation-based algorithm. Our method is a global method, in the sense that it is guaranteed to obtain a globally optimal solution up to relaxation gap. Another advantage is that our method can handle challenging real-world situations such as missing data and outliers quite easily, and all in a natural and unified manner. Extensive experiments on both synthetic and real images show comparable results compared with the state-of-the-art methods.	[Dai, Yuchao; He, Mingyi] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China; [Dai, Yuchao] Australian Natl Univ, Res Sch Comp Sci, Canberra, ACT 2600, Australia; [Li, Hongdong] Australian Natl Univ, Canberra, ACT 2600, Australia; [Li, Hongdong] NICTA, Canberra, ACT 2600, Australia; [He, Mingyi] ShaanXi Key Lab Informat Acquisit & Proc, Xian 710129, Shaanxi, Peoples R China	Northwestern Polytechnical University; Australian National University; Australian National University; Australian National University	Dai, YC (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.	daiyuchao@gmail.com; hongdong.li@anu.edu.au; myhe@nwpu.edu.cn	He, Mingyi/AGX-2464-2022; He, Mingyi/B-4138-2011; Dai, Yuchao/F-7832-2015	He, Mingyi/0000-0003-2051-6955; He, Mingyi/0000-0003-2051-6955; Dai, Yuchao/0000-0002-4432-7406	NSFC [60736007, 61171154]; NSF of Shaanxi Province [2010JZ011]; Australian Research Council (ARC)	NSFC(National Natural Science Foundation of China (NSFC)); NSF of Shaanxi Province; Australian Research Council (ARC)(Australian Research Council)	The authors thank Professor Richard Hartley for his invaluable support and discussions. They also thank the anonymous reviewers of TPAMI and ECCV '10 for constructive comments that improved the manuscript. This work was supported in part by NSFC (60736007, 61171154), NSF of Shaanxi Province (2010JZ011), an Australian Research Council (ARC) discovery grant, and an ARC linkage grant.	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Angst R, 2011, IEEE I CONF COMP VIS, P2502, DOI 10.1109/ICCV.2011.6126536; Ayazoglu M, 2010, LECT NOTES COMPUT SC, V6312, P71, DOI 10.1007/978-3-642-15552-9_6; Buchanan AM, 2005, PROC CVPR IEEE, P316; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793; Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626; Dai YC, 2010, LECT NOTES COMPUT SC, V6314, P396; Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238; Ding T, 2007, IEEE I CONF COMP VIS, P817; Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139; Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27; Haldar Justin P, 2009, IEEE Signal Process Lett, V16, P584, DOI 10.1109/LSP.2009.2018223; HAN M, 1999, CMURITR9922; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5; Jia HJ, 2009, IEEE T PATTERN ANAL, V31, P841, DOI 10.1109/TPAMI.2008.122; Ke QF, 2005, PROC CVPR IEEE, P739; Lin Z, 2010, ARXIV E PRINTS; Liu RS, 2012, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2012.6247726; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; Mahamud S, 2001, PROC CVPR IEEE, P1018; Mahamud S, 2000, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2000.854872; Martinec D, 2005, PROC CVPR IEEE, P198; Martinec D, 2002, LECT NOTES COMPUT SC, V2351, P355; Mitra K., 2010, P ADV NIPS, V23, P1642; Oliensis J, 2007, IEEE T PATTERN ANAL, V29, P2217, DOI 10.1109/TPAMI.2007.1132; Olsson C, 2011, LECT NOTES COMPUT SC, V6688, P524, DOI 10.1007/978-3-642-21227-7_49; Olsson C, 2009, LECT NOTES COMPUT SC, V5575, P301, DOI 10.1007/978-3-642-02230-2_31; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Qian Chen, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P55, DOI 10.1109/CVPR.1999.784608; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; Ueshiba T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P296, DOI 10.1007/BFb0055674; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; [No title captured]	48	20	21	1	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2238	2251		10.1109/TPAMI.2013.20	http://dx.doi.org/10.1109/TPAMI.2013.20			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868782				2022-12-18	WOS:000322029000014
J	Wang, SF; Lai, SH				Wang, Shu-Fan; Lai, Shang-Hong			Reconstructing 3D Face Model with Associated Expression Deformation from a Single Face Image via Constructing a Low-Dimensional Expression Deformation Manifold	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D face reconstruction; expression modeling; manifold analysis; surface registration	REGISTRATION; RECOGNITION; GEOMETRY	Facial expression modeling is central to facial expression recognition and expression synthesis for facial animation. In this work, we propose a manifold-based 3D face reconstruction approach to estimating the 3D face model and the associated expression deformation from a single face image. With the proposed robust weighted feature map (RWF), we can obtain the dense correspondences between 3D face models and build a nonlinear 3D expression manifold from a large set of 3D facial expression models. Then a Gaussian mixture model in this manifold is learned to represent the distribution of expression deformation. By combining the merits of morphable neutral face model and the low-dimensional expression manifold, a novel algorithm is developed to reconstruct the 3D face geometry as well as the facial deformation from a single face image in an energy minimization framework. Experimental results on simulated and real images are shown to validate the effectiveness and accuracy of the proposed algorithm.	[Wang, Shu-Fan; Lai, Shang-Hong] Natl Tsing Hua Univ, Hsinchu 30013, Taiwan	National Tsing Hua University	Wang, SF (corresponding author), Natl Tsing Hua Univ, Hsinchu 30013, Taiwan.	lai@cs.nthu.edu.tw	Lai, Shang-Hong/AAS-4002-2020	Lai, Shang-Hong/0000-0002-5092-993X	National Science Council, Taiwan [98-2221-E-007-089-MY3]	National Science Council, Taiwan(Ministry of Science and Technology, Taiwan)	This research was partially supported by the National Science Council, Taiwan, under grant 98-2221-E-007-089-MY3.	Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basso C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P205, DOI 10.4304/jmm.1.4.37-45; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BLANZ V, 1999, SIGGRAPH 99; BLANZ V, 2003, P 24 ANN C EUR ASS C; Chang Y., 2003, P IEEE INT WORKSH AN; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Glocker B, 2008, MED IMAGE ANAL, V12, P731, DOI 10.1016/j.media.2008.03.006; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; He XF, 2005, IEEE I CONF COMP VIS, P1208; HU C, 2004, P IEEE WORKSH FAC PR; HU C, 2004, P IEEE CS C COMP VIS; Komodakis N, 2007, IEEE I CONF COMP VIS, P488; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Nguyen MX, 2005, VISUAL COMPUT, V21, P669, DOI 10.1007/s00371-005-0315-1; NOH JY, 2001, P ACM SIGGRAPH; Periaswamy S, 2003, IEEE T MED IMAGING, V22, P865, DOI 10.1109/TMI.2003.815069; Pfeifle R, 1996, PROC GRAPH INTERF, P186; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; ROWEIS S, 2001, NEURAL INFORM PROCES, V14, P889; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schlkopf B., 2006, ADV NEURAL INFORM PR, P1009; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Wallhoff F., 2006, FACIAL EXPRESSIONS E; WANG S, 2008, P IEEE C COMP VIS PA; Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050; Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x; Wang Y, 2008, INT J COMPUT VISION, V76, P283, DOI 10.1007/s11263-007-0063-y; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244; WEN Z, 2003, P IEEE INT C COMP VI; ZALEWSKI L, 2004, P IEEE 6 INT C AUT F; ZHANG D, 1999, P IEEE CS C COMP VIS, V2; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; ZHANG L, 2005, P COMP GRAPH INT	39	20	23	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2115	2121		10.1109/TPAMI.2011.88	http://dx.doi.org/10.1109/TPAMI.2011.88			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21576739				2022-12-18	WOS:000293969000017
J	Jiang, H				Jiang, Hao			Human Pose Estimation Using Consistent Max Covering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human pose estimation; consistent max covering; linear programming		A novel consistent max-covering method is proposed for human pose estimation. We focus on problems in which a rough foreground estimation is available. Pose estimation is formulated as a jigsaw puzzle problem in which the body part tiles maximally cover the foreground region, match local image features, and satisfy body plan and color constraints. This method explicitly imposes a global shape constraint on the body part assembly. It anchors multiple body parts simultaneously and introduces hyperedges in the part relation graph, which is essential for detecting complex poses. Using multiple cues in pose estimation, our method is resistant to cluttered foregrounds. We propose an efficient linear method to solve the consistent max-covering problem. A two-stage relaxation finds the solution in polynomial time. Our experiments on a variety of images and videos show that the proposed method is more robust than previous locally constrained methods.	Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA	Boston College	Jiang, H (corresponding author), Boston Coll, Dept Comp Sci, 140 Commonwealth Ave, Chestnut Hill, MA 02467 USA.	hjiang@cs.bc.edu			US National Science Foundation (NSF) [1018641]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This work is supported by US National Science Foundation (NSF) Grant 1018641.	Agarwal A., 2004, P IEEE C COMP VIS PA; ANDRILUKA M, 2009, P IEEE C COMP VIS PA; Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; Chvatal V., 1983, LINEAR PROGRAMMING; ELGAMMAL A, 2004, P IEEE C COMP VIS PA; Felzenszwalb P. F., 2005, INT J COMPUTER VISIO, V61; FERRARI V, 2010, P IEEE C COMP VIS PA; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; GRAUMAN K, 2003, P IEEE 9 INT C COMP; IOFFE S, 2001, INT J COMPUTER VISIO, V43; Jiang H., 2008, P IEEE C COMP VIS PA; JIANG H, 2009, P IEEE 12 INT C COMP; JOHNSON S, 2009, P IEEE INT WORKSH MA; Lee M., 2004, P IEEE C COMP VIS PA; MORI G, 2002, P 7 EUR C COMP VIS; Ning H., 2008, P IEEE C COMP VIS PA; Ramanan D., 2006, NIPS; REN X, 2005, P IEEE 10 INT C COMP; ROSALES R, 2000, P IEEE C COMP VIS PA; Sapp B., 2010, P IEEE C COMP VIS PA; SHAKHNAROVICH G, 2003, P IEEE 9 INT C COMP; SIGAL I, 2006, P IEEE C COMP VIS PA; Tian T., 2010, P IEEE C COMP VIS PA; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; 2011, HUMANEVA DATA SET; 2011, LIBDAI	26	20	23	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1911	1918		10.1109/TPAMI.2011.92	http://dx.doi.org/10.1109/TPAMI.2011.92			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21576747				2022-12-18	WOS:000292740000015
J	Ravichandran, A; Vidal, R				Ravichandran, Avinash; Vidal, Rene			Video Registration Using Dynamic Textures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic textures; video registration; nonrigid dynamical scenes	ALIGNMENT; IMAGE	We consider the problem of spatially and temporally registering multiple video sequences of dynamical scenes which contain, but are not limited to, nonrigid objects such as fireworks, flags fluttering in the wind, etc., taken from different vantage points. This problem is extremely challenging due to the presence of complex variations in the appearance of such dynamic scenes. In this paper, we propose a simple algorithm for matching such complex scenes. Our algorithm does not require the cameras to be synchronized, and is not based on frame-by-frame or volume-by-volume registration. Instead, we model each video as the output of a linear dynamical system and transform the task of registering the video sequences to that of registering the parameters of the corresponding dynamical models. As these parameters are not uniquely defined, one cannot directly compare them to perform registration. We resolve these ambiguities by jointly identifying the parameters from multiple video sequences, and converting the identified parameters to a canonical form. This reduces the video registration problem to a multiple image registration problem, which can be efficiently solved using existing image matching techniques. We test our algorithm on a wide variety of challenging video sequences and show that it matches the performance of significantly more computationally expensive existing methods.	[Ravichandran, Avinash; Vidal, Rene] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA	Johns Hopkins University	Ravichandran, A (corresponding author), Johns Hopkins Univ, Ctr Imaging Sci, 319A Clark Hall,3400 N Charles St, Baltimore, MD 21218 USA.	avinash@cis.jhu.edu; rvidal@cis.jhu.edu	Vidal, Rene/A-3367-2010		Johns Hopkins Univerity; US Office of Naval Research (ONR) [N00014-05-10836]; US National Science Foundation [0447739, N00014-09-1-0084]	Johns Hopkins Univerity; US Office of Naval Research (ONR)(Office of Naval Research); US National Science Foundation(National Science Foundation (NSF))	This work was partially supported by startup funds from the Johns Hopkins Univerity, by grants US Office of Naval Research (ONR) N00014-05-10836, the US National Science Foundation CAREER 0447739, and ONR N00014-09-1-0084.	Agarwala A, 2005, ACM T GRAPHIC, V24, P821, DOI 10.1145/1073204.1073268; Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165; Brown M, 2005, PROC CVPR IEEE, P510; Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148; Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z; Chan AB, 2005, PROC CVPR IEEE, P846; Chan AW, 2007, CHANNELS, V1, DOI 10.4161/chan.3694; Chris H., 1988, P 4 ALVEY VISION C, P189; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Doretto G., 2003, P IEEE C COMP VIS, P44; Doretto G, 2006, IEEE T PATTERN ANAL, V28, P2006, DOI 10.1109/TPAMI.2006.243; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma Y., 2003, INVITATION 3D VISION; Rav-Acha A, 2005, PROC CVPR IEEE, P58; RAVACHA A, 2005, P WORKSH DYN VIS IEE; RAVICHANDRAN A, 2007, P WORKSH DYN VIS; Rugh W. J., 1996, LINEAR SYSTEM THEORY; Saisan P, 2001, PROC CVPR IEEE, P58; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; Shi J, 1994, P IEEE C COMP VIS PA; Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009; Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871; Ukrainitz Y, 2006, LECT NOTES COMPUT SC, V3953, P538, DOI 10.1007/11744078_42; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; Vidal R, 2005, PROC CVPR IEEE, P516; Vidal R., 2007, P IEEE INT C COMP VI; Viola P. A., 1995, AITR1548; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009	32	20	21	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					158	171		10.1109/TPAMI.2010.61	http://dx.doi.org/10.1109/TPAMI.2010.61			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088325	Green Submitted			2022-12-18	WOS:000284277600012
J	Aliaga, DG; Xu, Y				Aliaga, Daniel G.; Xu, Yi			A Self-Calibrating Method for Photogeometric Acquisition of 3D Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Digitization and image capture; scene analysis; geometric modeling	SPACETIME STEREO; SHAPE; LIGHT	We present a self-calibrating photogeometric method using only off-the-shelf hardware that enables quickly and robustly obtaining multimillion point-sampled and colored models of real-world objects. Some previous efforts use a priori calibrated systems to separately acquire geometric and photometric information. Our key enabling observation is that a digital projector can be simultaneously used as either an active light source or as a virtual camera ( as opposed to a digital camera, which cannot be used for both). We present our self-calibrating and multiviewpoint 3D acquisition method, based on structured light, which simultaneously obtains mutually registered surface position and surface normal information and produces a single high-quality model. Acquisition processing freely alternates between using a geometric setup and using a photometric setup with the same hardware configuration. Further, our approach generates reconstructions at the resolution of the camera and not only the projector. We show the results of capturing several high-quality models of real-world objects.	[Aliaga, Daniel G.; Xu, Yi] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus	Aliaga, DG (corresponding author), Purdue Univ, Dept Comp Sci, Lawson Comp Sci Bldg,305 N Univ St, W Lafayette, IN 47907 USA.	aliaga@cs.purdue.edu; xu43@cs.purdue.edu	Aliaga, Daniel/AHD-1022-2022		US National Science Foundation (NSF) [CCF 0434398]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This work was supported in part by the US National Science Foundation (NSF) under grant no. CCF 0434398.	ALIAGA D, 2008, P IEEE C COMP VIS PA; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Batlle J, 1998, PATTERN RECOGN, V31, P963, DOI 10.1016/S0031-3203(97)00074-5; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Furukawa R, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P302, DOI 10.1109/3DIM.2005.80; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; Hemayed EE, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P351, DOI 10.1109/AVSS.2003.1217942; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Inokuchi S., 1984, P INT C PATT REC, P806; Koninckx TP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P293, DOI 10.1109/IM.2003.1240262; Lim J, 2005, IEEE I CONF COMP VIS, P1635; Lu JP, 1999, INT J COMPUT VISION, V32, P213, DOI 10.1023/A:1008157029424; Mallick SP, 2005, PROC CVPR IEEE, P619; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Park J, 2008, IEEE T VIS COMPUT GR, V14, P246, DOI 10.1109/TVCG.2007.1069; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; Rushmeier H., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P99, DOI 10.1109/IM.1999.805339; Scharstein D, 2003, PROC CVPR IEEE, P195; Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257; Sturm P, 2002, IMAGE VISION COMPUT, V20, P415, DOI 10.1016/S0262-8856(02)00012-4; Tan P, 2008, IEEE T PATTERN ANAL, V30, P1460, DOI 10.1109/TPAMI.2007.70789; Weise T, 2007, P IEEE C COMP VIS PA; WOODHAM R, 1991, 9118 U BRIT COL; Zhang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P618, DOI 10.1109/ICCV.2003.1238405; Zhang L, 2003, PROC CVPR IEEE, P367; Zickler T, 2002, LECT NOTES COMPUT SC, V2352, P869; Zickler T., 2006, IEEE COMP SOC C COMP, P1801; Zickler TE, 2003, PROC CVPR IEEE, P548	30	20	22	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					747	754		10.1109/TPAMI.2009.202	http://dx.doi.org/10.1109/TPAMI.2009.202			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224128				2022-12-18	WOS:000274548800014
J	Marks, TK; Hershey, JR; Movellan, JR				Marks, Tim K.; Hershey, John R.; Movellan, Javier R.			Tracking Motion, Deformation, and Texture Using Conditionally Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; generative models; motion; shape; texture; video analysis; face tracking	MODELS; FRAMEWORK	We present a generative model and inference algorithm for 3D nonrigid object tracking. The model, which we call G-flow, enables the joint inference of 3D position, orientation, and nonrigid deformations, as well as object texture and background texture. Optimal inference under G-flow reduces to a conditionally Gaussian stochastic filtering problem. The optimal solution to this problem reveals a new space of computer vision algorithms, of which classic approaches such as optic flow and template matching are special cases that are optimal only under special circumstances. We evaluate G-flow on the problem of tracking facial expressions and head motion in 3D from single-camera video. Previously, the lack of realistic video data with ground truth nonrigid position information has hampered the rigorous evaluation of nonrigid tracking. We introduce a practical method of obtaining such ground truth data and present a new face video data set that was created using this technique. Results on this data set show that G-flow is much more robust and accurate than current deterministic optic-flow-based approaches.	[Marks, Tim K.] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA; [Hershey, John R.] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; [Movellan, Javier R.] Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA	International Business Machines (IBM); University of California System; University of California San Diego	Marks, TK (corresponding author), Mitsubishi Elect Res Labs, 201 Broadway, Cambridge, MA 02139 USA.	tmarks@merl.com; jrhershe@us.ibm.com; movellan@mplab.ucsd.edu			US National Science Foundation (NSF) [IIS-0223052, DGE-0333451]; UCDIMI [D0010084]; NSF [ECCS-0622229, IIS-0808767]; Departments of Cognitive Science and Computer Science and Engineering at the University of California, San Diego	US National Science Foundation (NSF)(National Science Foundation (NSF)); UCDIMI; NSF(National Science Foundation (NSF)); Departments of Cognitive Science and Computer Science and Engineering at the University of California, San Diego	Earlier versions of this work appeared in [16], [17], [36]. Tim K. Marks was supported by US National Science Foundation (NSF) grants IIS-0223052 and DGE-0333451. John R. Hershey was supported by UCDIMI grant D0010084. Javier R. Movellan was supported by NSF grants ECCS-0622229 and IIS-0808767. Tim K. Marks performed this research at the Departments of Cognitive Science and Computer Science and Engineering at the University of California, San Diego.	Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Andrieu C, 2002, J ROY STAT SOC B, V64, P827, DOI 10.1111/1467-9868.00363; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Beal MJ, 2003, IEEE T PATTERN ANAL, V25, P828, DOI 10.1109/TPAMI.2003.1206512; BLANZ V, 1999, P 26 ANN C COMP GRAP, P187, DOI DOI 10.1145/311535.311556; BRAND M, 2005, P IEEE CS C COMP VIS; BRAND M, 2001, P IEEE CS C COMP VIS; BREGLER C, 2000, P IEEE CS C COMP VIS; CHEN HF, 1989, SYST CONTROL LETT, V13, P397, DOI 10.1016/0167-6911(89)90106-0; Chen R, 2000, J R STAT SOC B, V62, P493, DOI 10.1111/1467-9868.00246; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; De Freitas N, 2004, P IEEE, V92, P455, DOI 10.1109/JPROC.2003.823157; Dellaert F, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P2, DOI 10.1109/ACV.1998.732850; Doucet A., 2000, P 16 C UNC ART INT, P176, DOI DOI 10.1049/IET-SPR:20070075.; Fasel I, 2005, COMPUT VIS IMAGE UND, V98, P182, DOI 10.1016/j.cviu.2004.07.014; FISHMAN GS, 1996, MONTE CARLO SAMPLING; HINTON G, 2005, P INT WORKSH ART INT; Ho J, 2004, PROC CVPR IEEE, P782; Jojic N, 2001, PROC CVPR IEEE, P199; Kalman RE., 1960, J BASIC ENG-T ASME, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KHAN Z, 2004, P IEEE CS C COMP VIS; MARKS TK, 2004, P IEEE CS C COMP VIS; MARKS TK, 2005, ADV NEURAL INFORM PR, V17, P889; MARKS TK, 2006, THESIS U CALIFORNIA; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; TORRALBA A, 2003, P IEEE INT C COMP VI; Torresani L, 2001, PROC CVPR IEEE, P493; TORRESANI L, 2004, ADV NEURAL INFORM PR, V16; TORRESANI L, 2004, P EUR C COMP VIS; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; XIAO J, 2004, P IEEE CS C COMP VIS; XIAO J, 2004, P EUR C COMP VIS	35	20	24	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					348	363		10.1109/TPAMI.2008.278	http://dx.doi.org/10.1109/TPAMI.2008.278			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075463	Green Submitted			2022-12-18	WOS:000272741500012
J	Bae, KH; Belton, D; Lichti, DD				Bae, Kwang-Ho; Belton, David; Lichti, Derek D.			A Closed-Form Expression of the Positional Uncertainty for 3D Point Clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Laser range finders; uncertainty; point clouds; range image analysis; range data; eigenvalues; eigenvectors	REGISTRATION; DRIVEN	We present a novel closed-form expression of positional uncertainty measured by a near-monostatic and time-of-flight laser range finder with consideration of its measurement uncertainties. An explicit form of the angular variance of the estimated surface normal vector is also derived. This expression is useful for the precise estimation of the surface normal vector and the outlier detection for finding correspondence in order to register multiple 3D point clouds. Two practical algorithms using these expressions are presented: a method for finding optimal local neighborhood size which minimizes the variance of the estimated normal vector and a resampling method of point clouds.	[Bae, Kwang-Ho; Belton, David] Curtin Univ Technol, Dept Spatial Sci, Perth, WA 6845, Australia; [Lichti, Derek D.] Univ Calgary, Schulich Sch Engn, Dept Geomat Engn, Ctr Bioengn Res & Educ, Calgary, AB T2N 1N4, Canada	Curtin University; University of Calgary	Bae, KH (corresponding author), Curtin Univ Technol, Dept Spatial Sci, Perth, WA 6845, Australia.	K.H.Bae@curtin.edu.au; D.Belton@curtin.edu.au; ddlichti@ucalgary.ca	Belton, David/Q-5423-2016	Belton, David/0000-0002-2879-7918	Australian Research Council (ARC) [DP0342887]; Linkage-International Grant [LX0347905]; Curtin University of Technology; Australian Commonwealth Cooperative Research Centres Programme	Australian Research Council (ARC)(Australian Research Council); Linkage-International Grant(Australian Research Council); Curtin University of Technology; Australian Commonwealth Cooperative Research Centres Programme(Australian GovernmentDepartment of Industry, Innovation and ScienceCooperative Research Centres (CRC) Programme)	This project was supported by the Australian Research Council (ARC) with a Discovery Grant (DP0342887) and a Linkage-International Grant (LX0347905). This work has been supported in part by Curtin University of Technology and the Cooperative Research Centre for Spatial Information, whose activities are funded by the Australian Commonwealth Cooperative Research Centres Programme. This data set and surveying information are currently available through ISPRS Working Group V/3 Terrestrial Laser Scanning, http://www.commission5.isprs.org/wg3/. The authors would like to thank Stuart Gordon, Michael Stewart, Maria Tsakiri, and the National Technical University of Athens for supporting the collection of the Agia Sanmarina church data sets in Greece. The authors would also like to thank three anonymous reviewers for providing suggestions that led to the improvement of this paper. In addition, Kwang-Ho Bae would like to express his gratitude to Associate Professor Michael P. Stewart for suggestions on an early draft of this paper and encouragement throughout his PhD study on which this paper is based.	Bae K.H., 2006, INT ARCH PHOTOGRAM R, VXXXV, P222; BAE KH, 2007, J SPAT SCI, V52, P41; Bae KH, 2008, ISPRS J PHOTOGRAMM, V63, P36, DOI 10.1016/j.isprsjprs.2007.05.012; Ben-Israel A, 1974, GEN INVERSE THEORY A; Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351; BLAIS F, 2000, P SPIE INT S AER, P236; Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714; Devara PCS, 1998, INT J REMOTE SENS, V19, P3271, DOI 10.1080/014311698213966; Dey TK, 2006, LECT NOTES COMPUT SC, V4337, P21; Dey TK, 2006, COMP GEOM-THEOR APPL, V35, P124, DOI 10.1016/j.comgeo.2005.10.006; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Filin S, 2003, PHOTOGRAMM ENG REM S, V69, P1235, DOI 10.14358/PERS.69.11.1235; FILIN S, 2001, THESIS OHIO STATE U; GARLAND M, 1997, P SIGGRAPH 97, P209, DOI DOI 10.1145/258734.258849; Hofle B, 2007, ISPRS J PHOTOGRAMM, V62, P415, DOI 10.1016/j.isprsjprs.2007.05.008; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P234, DOI 10.1109/IM.1997.603871; Kanatani K., 1996, STAT OPTIMIZATION GE; Kay S. M., 1993, FUNDAMENTALS STAT SI; Lalonde J., 2005, CMURITR0501; Lichti D.D., 2004, INT ARCH PHOTOGRAMME, P222; Linsen Lars, 2001, POINT CLOUD REPRESEN; Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470; PAULY M, 2004, P EUR S POINT BAS GR; Pennec X, 1997, INT J COMPUT VISION, V25, P203, DOI 10.1023/A:1007976002485; STODDART AJ, 1996, P BRIT MACH VIS C; Tasdizen T, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P70, DOI 10.1109/IM.2003.1240234; Whaite P, 1997, IEEE T PATTERN ANAL, V19, P193, DOI 10.1109/34.584097; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237; 2008, LEICA            FEB	30	20	21	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					577	590		10.1109/TPAMI.2008.116	http://dx.doi.org/10.1109/TPAMI.2008.116			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229076				2022-12-18	WOS:000263396100001
J	Chesi, G				Chesi, Graziano			Camera Displacement via Constrained Minimization of the Algebraic Error	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo vision; camera displacement; essential matrix; homogeneous form; LMI	MATRIX; MOTION	This paper proposes a new approach to estimate the camera displacement of stereo vision systems via minimization of the algebraic error over the essential matrices manifold. The proposed approach is based on the use of homogeneous forms and linear matrix inequality (LMI) optimizations, and has the advantages of not presenting local minima and not introducing approximations of nonlinear terms. Numerical investigations carried out with both synthetic and real data show that the proposed approach provides significantly better results than SVD methods, as well as minimizations of the algebraic error over the essential matrices manifold via both gradient descent and simplex search algorithms.	Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Hong Kong, Peoples R China	University of Hong Kong	Chesi, G (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	chesi@eee.hku.hk	Chesi, Graziano/C-1575-2009	Chesi, Graziano/0000-0003-4214-4224				Boyd S., 1994, SIAM; Chesi G, 2004, IEEE T ROBOTIC AUTOM, V20, P908, DOI 10.1109/TRO.2004.829456; Chesi G, 2004, IEEE T PATTERN ANAL, V26, P1239, DOI 10.1109/TPAMI.2004.56; Chesi G, 2004, IEEE T ROBOTIC AUTOM, V20, P724, DOI 10.1109/TRO.2004.829465; Chesi G, 2003, INT J ROBUST NONLIN, V13, P1239, DOI 10.1002/rnc.839; Chesi G, 2003, IEEE T AUTOMAT CONTR, V48, P200, DOI 10.1109/TAC.2002.808465; Chesi G, 2002, IEEE T PATTERN ANAL, V24, P397, DOI 10.1109/34.990139; Chesi G., 1999, P 5 EUR CONTR C; Chesi G, 2007, IEEE T ROBOT, V23, P1050, DOI 10.1109/TRO.2007.903817; Chesi G, 2007, IEEE T PATTERN ANAL, V29, P1476, DOI 10.1109/TPAMI.2007.70723; DERICHE R, 1994, P 3 EUR C COMP VIS; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Hartley R., 2000, MULTIPLE VIEW COMPUT; HARTLEY R, 2007, P 11 IEEE INT C COMP; Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; Malis E, 1999, IEEE T ROBOTIC AUTOM, V15, P238, DOI 10.1109/70.760345; Mezouar Y, 2002, IEEE T ROBOTIC AUTOM, V18, P534, DOI 10.1109/TRA.2002.802218; Nesterov Y., 1994, INTERIOR POINT POLYN; Taylor C. J., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2734, DOI 10.1109/ROBOT.2000.846441; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	22	20	20	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					370	375		10.1109/TPAMI.2008.198	http://dx.doi.org/10.1109/TPAMI.2008.198			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110501				2022-12-18	WOS:000261846800014
J	Peter, AM; Rangarajan, A				Peter, Adrian M.; Rangarajan, Anand			Information Geometry for Landmark Shape Analysis: Unifying Shape Representation and Deformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Information geometry; Fisher information; Fisher-Rao metric; Havrda-Charvat entropy; Gaussian mixture models; shape analysis; shape matching; landmark shapes	ELASTIC REGISTRATION; DISTRIBUTIONS; ALGORITHM; DISTANCE; MIXTURE	Shape matching plays a prominent role in the comparison of similar structures. We present a unifying framework for shape matching that uses mixture models to couple both the shape representation and deformation. The theoretical foundation is drawn from information geometry wherein information matrices are used to establish intrinsic distances between parametric densities. When a parameterized probability density function is used to represent a landmark-based shape, the modes of deformation are automatically established through the information matrix of the density. We first show that given two shapes parameterized by Gaussian mixture models (GMMs), the well-known Fisher information matrix of the mixture model is also a Riemannian metric (actually, the Fisher-Rao Riemannian metric) and can therefore be used for computing shape geodesics. The Fisher-Rao metric has the advantage of being an intrinsic metric and invariant to reparameterization. The geodesic-computed using this metric-establishes an intrinsic deformation between the shapes, thus unifying both shape representation and deformation. A fundamental drawback of the Fisher-Rao metric is that it is not available in closed form for the GMM. Consequently, shape comparisons are computationally very expensive. To address this, we develop a new Riemannian metric based on generalized phi-entropy measures. In sharp contrast to the Fisher-Rao metric, the new metric is available in closed form. Geodesic computations using the new metric are considerably more efficient. We validate the performance and discriminative capabilities of these new information geometry-based metrics by pairwise matching of corpus callosum shapes. We also study the deformations of fish shapes that have various topological properties. A comprehensive comparative analysis is also provided using other landmark-based distances, including the Hausdorff distance, the Procrustes metric, landmark-based diffeomorphisms, and the bending energies of the thin-plate (TPS) and Wendland splines.	[Peter, Adrian M.; Rangarajan, Anand] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Peter, AM (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, E301 CSE Bldg,POB 116120, Gainesville, FL 32611 USA.	adrian.peter@gmail.com; anand@cise.ufl.edu	Rangarajan, Anand/A-8652-2009; Peter, Adrian/L-6369-2015	Rangarajan, Anand/0000-0001-8695-8436; Peter, Adrian/0000-0001-8124-5648	US National Science Foundation [IIS-0307712]; National Institutes of Health [R01NS046812]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS046812] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	This work is partially supported by US National Science Foundation grant IIS-0307712 and the National Institutes of Health grant R01NS046812. The authors acknowledge helpful conversations with Hongyu Guo, Karl Rohr, Chris Small, and Gnana Bhaskar Tenali. They thank the Department of Ichthyology, California Academy of Sciences, for providing them access to the fish images; these were used to extract the fish shapes for the experiments. A database containing 100 binary fish images is now available under the terms of the GNU General Public License [47].	AMARI SI, 2001, METHODS INFORM GEOME; Banerjee A, 2005, J MACH LEARN RES, V6, P1345; Bookstein F. L., 1991, MORPHOMETRIC TOOLS L; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Boothby W., 2002, INTRO DIFFERENTIABLE; BURBEA J, 1982, J MULTIVARIATE ANAL, V12, P575, DOI 10.1016/0047-259X(82)90065-3; *CA AC SCI DEP ICH, CAT FISH; Cencov N.N., 1982, TRANSL MATH MONOG AM, V53; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; COOTES TF, 1997, P BRIT MACH VIS C, P110; COSTA SIR, 2005, P IEEE INF THEOR WOR, P28; Courant R., 1989, METHODS MATH PHYS, V2; DAVIES RC, 2001, EMERG COMMUNICAT, V1, P3; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fornefett M, 2001, IMAGE VISION COMPUT, V19, P87, DOI 10.1016/S0262-8856(00)00057-3; Glaunes J, 2004, PROC CVPR IEEE, P712; GUO H, 2005, P INT C MED IM COMP, P984; Havrda J., 1967, KYBERNETIKA, V3, P30; Horn B., 1986, ROBOT VISION, P1; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Lebanon G., 2005, THESIS CARNEGIE MELL; Lenglet C, 2006, J MATH IMAGING VIS, V25, P423, DOI 10.1007/s10851-006-6897-z; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Maybank SJ, 2005, INT J COMPUT VISION, V63, P191, DOI 10.1007/s11263-005-6877-6; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Mio W, 2005, LECT NOTES COMPUT SC, V3757, P18, DOI 10.1007/11585978_2; Mio W, 2006, IEEE IMAGE PROC, P2113, DOI 10.1109/ICIP.2006.312825; Myung IJ, 2000, P NATL ACAD SCI USA, V97, P11170, DOI 10.1073/pnas.170283897; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; PETER A, 2006, P INT C MED IM COMP, P249; Peter A, 2006, I S BIOMED IMAGING, P1164; Petersen A., 2008, P IEEE C COMP VIS PA, P1; Rao C.R., 1945, BULL CALCUTTA MATH S, V37, P81, DOI DOI 10.1007/978-1-4612-0919-5_15; Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Small C.G., 1996, STAT THEORY SHAPE; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Srivastava A., 2007, IEEE C COMP VIS PATT, P1; Thompson P, 1996, IEEE T MED IMAGING, V15, P402, DOI 10.1109/42.511745; *U FLOR, 2008, GATORBAIT 100; Wahba G., 1990, SPLINE MODELS OBSERV; WANG F, 2006, P 9 EUR C COMP VIS E, P551; Woodlock D, 2002, BEHAV HEALTHC TOM, V11, P8	47	20	22	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					337	350		10.1109/TPAMI.2008.69	http://dx.doi.org/10.1109/TPAMI.2008.69			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110497	Green Accepted, Green Submitted			2022-12-18	WOS:000261846800010
J	Tan, P; Lin, S; Quan, L				Tan, Ping; Lin, Stephen; Quan, Long			Subpixel photometric stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						photometric stereo; superresolution; 3D textons	SHAPE	Conventional photometric stereo recovers one normal direction per pixel of the input image. This fundamentally limits the scale of recovered geometry to the resolution of the input image and does not adequately model surfaces with subpixel geometric structures. In this paper, we propose a method for recovering the subpixel surface geometry by studying the relationship between the subpixel geometry and the reflectance properties of a surface. We first describe a generalized physically based reflectance model that relates the distribution of surface normals inside each pixel area to its reflectance function. The distribution of surface normals can be computed from the reflectance functions recorded in photometric stereo images. A convexity measure of the subpixel geometric structure is also recovered at each pixel through an analysis of brightness attenuation due to shadowing. Then, we use the recovered distribution of surface normals and the surface convexity to infer subpixel geometric structures on a surface of homogeneous material by spatially arranging the normals among pixels at a higher resolution than that of the input image. We optimize the arrangement of normals by using a combination of belief propagation and Markov Chain Monte Carlo (MCMC) based on a minimum-description-length criterion on 3D textons over the surface. Experiments demonstrate the validity of our approach and show superior geometric resolution for the recovered surfaces.	[Tan, Ping; Quan, Long] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China; [Lin, Stephen] Beijing Sigma Ctr, Internet Graph Grp, Microsoft Res Asia, Beijing 100080, Peoples R China	Hong Kong University of Science & Technology; Microsoft; Microsoft Research Asia	Tan, P (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	ptan@cse.ust.hk; stevelin@microsoft.com; quan@cse.ust.hk		Tan, Ping/0000-0002-4506-6973				Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31; Ashikhmin M, 2000, COMP GRAPH, P65, DOI 10.1145/344779.344814; Ben-Ezra M, 2005, IEEE T PATTERN ANAL, V27, P977, DOI 10.1109/TPAMI.2005.129; Bilmes J., 1997, GENTLE TUTORIAL ALGO; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; COOK RL, 1981, P SIGGRAPH, P307; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DRBOHLAV O, 2002, P EUR C COMP VIS, P46; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Liu JS., 2001, MONTE CARLO STRATEGI, DOI DOI 10.1007/978-0-387-76371-2; NGAN A, 2005, P EUR S REND, P117; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Shashua A, 1992, THESIS MIT; Silver W, 1980, THESIS MIT; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; Sun J, 2003, PROC CVPR IEEE, P729; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WESTIN SH, 1992, COMP GRAPH, V26, P255, DOI 10.1145/142920.134075; Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136	29	20	20	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1460	1471		10.1109/TPAMI.2007.70789	http://dx.doi.org/10.1109/TPAMI.2007.70789			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566498				2022-12-18	WOS:000256679700011
J	Sheikh, YA; Shah, M				Sheikh, Yaser Ajmal; Shah, Mubarak			Trajectory association across multiple airborne cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						applications; scene analysis; motion; sensor fusion; registration		A camera mounted on an aerial vehicle provides an excellent means to monitor large areas of a scene. Utilizing several such cameras on different aerial vehicles allows further flexibility in terms of increased visual scope and in the pursuit of multiple targets. In this paper, we address the problem of associating trajectories across multiple moving airborne cameras. We exploit geometric constraints on the relationship between the motion of each object across cameras without assuming any prior calibration information. Since multiple cameras exist, ensuring coherency in association is an essential requirement, e. g., that transitive closure is maintained between more than two cameras. To ensure such coherency, we pose the problem of maximizing the likelihood function as a k-dimensional matching and use an approximation to find the optimal assignment of association. Using the proposed error function, canonical trajectories of each object and optimal estimates of intercamera transformations ( in a maximum likelihood sense) are computed. Finally, we show that, as a result of associating trajectories across the cameras, under special conditions, trajectories interrupted due to occlusion or missing detections can be repaired. Results are shown on a number of real and controlled scenarios with multiple objects observed by multiple cameras, validating our qualitative models, and, through simulation, quantitative performance is also reported.	[Sheikh, Yaser Ajmal] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Shah, Mubarak] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA	Carnegie Mellon University; State University System of Florida; University of Central Florida	Sheikh, YA (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	yaser@cs.cmu.edu; shah@cs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572				AZARBAYEJANI A, 1996, P INT C PATT REC; Bar-Shalom Y., 1990, MULTITARGET MULTISEN; Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119; CHANG T, 2001, P IEEE INT WORKSH MU; Chum O, 2005, COMPUT VIS IMAGE UND, V97, P86, DOI 10.1016/j.cviu.2004.03.004; COLLINS R, 1997, P IEEE INT C IM PROC; Collins R.T., 2001, P IEEE; CRIMINISI A, 1997, P BRIT MACH VIS C; DARRELL T, 2001, P IEEE INT C COMP VI; Dockstader S., 2001, P IEEE INT WORKSH MU; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HOPCROFT J, 1973, SIAM J COMPUTING; Huang T., 1997, P INT JOINT C ART IN; JAVED O, 2005, P IEEE INT C COMP VI; Javed O., 2003, ICCV; KANG J, 2003, P IEEE C COMP VIS PA; KETTNAKER V, 1999, P IEEE C COMP VIS PA; Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912; KRUMM J, 2000, P IEEE WORKSH VIS SU; Kuhn Harold W, 1955, NAVAL RES LOGISTICS; LEE L, 2000, IEEE T PATTERN MACHI, V22, P747; Makris D., 2004, P IEEE C COMP VIS PA; MATSUYAMA T, 2000, P IEEE; MITTAL A, 2003, INT J COMPUTER VISIO; Nakazawa A., 1998, P INT C PATT REC; Papadimitriou CH., 1993, COMPUT COMPLEX; RAHIMI A, 2004, P IEEE C COMP VIS PA; Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1; Shan Y., 2005, P IEEE INT C COMP VI; Stauffer C., 2003, P IEEE C COMP VIS PA; Sturm P.F., 1997, THESIS I NATL POLYTE	31	20	22	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					361	367		10.1109/TPAMI.2007.70750	http://dx.doi.org/10.1109/TPAMI.2007.70750			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084066				2022-12-18	WOS:000251580300014
J	Doretto, G; Soatto, S				Doretto, Gianfranco; Soatto, Stefano			Dynamic shape and appearance models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active appearance models; linear dynamical systems; video analysis; image motion; dynamic textures	SUBSPACE ALGORITHMS; IDENTIFICATION; IMAGE	We propose a model of the joint variation of shape and appearance of portions of an image sequence. The model is conditionally linear, and can be thought of as an extension of active appearance models to exploit the temporal correlation of adjacent image frames. Inference of the model parameters can be performed efficiently using established numerical optimization techniques borrowed from finite-element analysis and system identification techniques.	GE Co, Global Res Ctr, Visualizat & Comp Vis Lab, Niskayuna, NY 12309 USA; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	General Electric; University of California System; University of California Los Angeles	Doretto, G (corresponding author), GE Co, Global Res Ctr, Visualizat & Comp Vis Lab, 1 Res Circle,KWC208, Niskayuna, NY 12309 USA.	doretto@research.ge.com; soatto@ucla.edu						ARUN KS, 1990, SIAM J MATRIX ANAL A, V11, P42, DOI 10.1137/0611003; Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77; Baker S, 2001, PROC CVPR IEEE, P1090; BAKER S, 2004, CMURITR0414; Campbell N.W., 2002, P BMVC, P434; CARNE TK, 1990, P LOND MATH SOC, V61, P407; Cootes TF, 2004, LECT NOTES COMPUT SC, V2034, P316; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Doretto G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1236; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; DORETTO G, 2004, P EUR C COMP VIS, V2, P591; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; Hughes T.J., 2000, FINITE ELEMENT METHO; Jackson JD, 2005, LECT NOTES COMPUT SC, V3757, P427, DOI 10.1007/11585978_28; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Ma Y., 2004, INVITATION 3D VISION; Magnus J. R, 1999, MATRIX DIFFERENTIAL; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Saisan P, 2001, PROC CVPR IEEE, P58; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; Scholkopf B., 2002, LEARNING KERNELS SVM; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Wang DY, 1998, IEEE T SYST MAN CY B, V28, P583, DOI 10.1109/3477.704297; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981	28	20	20	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					2006	2019		10.1109/TPAMI.2006.243	http://dx.doi.org/10.1109/TPAMI.2006.243			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108373				2022-12-18	WOS:000241195700009
J	Lerner, R; Rivlin, E; Rotstein, HP				Lerner, Ronen; Rivlin, Ehud; Rotstein, Hector P.			Pose and motion recovery from feature correspondences and a Digital Terrain Map	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose estimation; vision-based navigation; DTM; structure from motion	STRUCTURE-FROM-MOTION; 2 PERSPECTIVE VIEWS; 3-D; PARAMETERS; ALGORITHM; LINE; 2-D	A novel algorithm for pose and motion estimation using corresponding features and a Digital Terrain Map is proposed. Using a Digital Terrain (or Digital Elevation) Map (DTM/ DEM) as a global reference enables the elimination of the ambiguity present in vision-based algorithms for motion recovery. As a consequence, the absolute position and orientation of a camera can be recovered with respect to the external reference frame. In order to do this, the DTM is used to formulate a constraint between corresponding features in two consecutive frames. Explicit reconstruction of the 3D world is not required. When considering a number of feature points, the resulting constraints can be solved using nonlinear optimization in terms of position, orientation, and motion. Such a procedure requires an initial guess of these parameters, which can be obtained from dead-reckoning or any other source. The feasibility of the algorithm is established through extensive experimentation. Performance is compared with a state-of-the-art alternative algorithm, which intermediately reconstructs the 3D structure and then registers it to the DTM. A clear advantage for the novel algorithm is demonstrated in variety of scenarios.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology; Technion Israel Institute of Technology	Lerner, R (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	ronen@cs.technion.ac.il; ehudr@cs.technion.ac.il; hector@ee.technion.ac.il						ANANDAN P, 1994, P IEEE INT C PATT A, P685; Baker W., 1977, ASPTR7761; Barron JL, 1996, PATTERN RECOGN, V29, P797, DOI 10.1016/0031-3203(95)00114-X; BOOZER D, 1988, J I NAVIGATION, V35, P161; Bouguet J.-Y., 1999, PYRAMIDAL IMPLEMENTA; Burschka D, 2004, IEEE INT CONF ROBOT, P409, DOI 10.1109/ROBOT.2004.1307184; Chellappa R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P492, DOI 10.1109/ICIP.1999.822945; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chiuso A, 2000, INT J COMPUT VISION, V39, P195, DOI 10.1023/A:1026563712076; Chiuso A, 2000, P EUR C COMP VIS; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; Hel-Or Y., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P77, DOI 10.1109/CVPR.1992.223224; Hoaglin D.C., 1983, UNDERSTANDING ROBUST; HSU S, 2000, P IEEE C COMP VIS PA, V1, P448; IRANI M, 1993, P COMP AN IM PATT, P371; Jacobs D, 1999, INT J COMPUT VISION, V34, P123, DOI 10.1023/A:1008135819955; Lerner R, 2004, PROC CVPR IEEE, P604; LERNER R, UNPUB ERROR ANAL ALG; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; Longuet-Higgins H., 1987, READINGS COMPUTER VI, P61, DOI DOI 10.1016/B978-0-08-051581-6.50012-X; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Nister D, 2004, PROC CVPR IEEE, P560; Oliensis J, 1999, INT J COMPUT VISION, V34, P163, DOI 10.1023/A:1008139920864; Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853; Oliensis J, 2000, COMPUT VIS IMAGE UND, V80, P172, DOI 10.1006/cviu.2000.0869; RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P1138, DOI 10.1109/34.62603; SEITZ SM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P330; Shimshoni I, 1999, IEEE T PATTERN ANAL, V21, P252, DOI 10.1109/34.754615; SHUM HY, 1999, P INT C COMP VIS PAT, V2, P538, DOI DOI 10.1109/CVPR.1999.784733; Sim DG, 2002, IEEE T PATTERN ANAL, V24, P1, DOI 10.1109/34.982881; Simon D., 1996, CMURITR9645; Srinivasan S, 2000, INT J COMPUT VISION, V37, P203, DOI 10.1023/A:1008111923880; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; TAKEDA H, 1994, IEEE T PATTERN ANAL, V16, P1002, DOI 10.1109/34.329009; TAN TN, 1993, IMAGE VISION COMPUT, V11, P203, DOI 10.1016/0262-8856(93)90037-H; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; WU TH, 1995, INT J COMPUT VISION, V15, P77, DOI 10.1007/BF01450850; Zhang ZY, 1997, J OPT SOC AM A, V14, P2938, DOI 10.1364/JOSAA.14.002938	44	20	22	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1404	1417		10.1109/TPAMI.2006.192	http://dx.doi.org/10.1109/TPAMI.2006.192			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929728				2022-12-18	WOS:000238950800005
J	Popovici, I; Withers, WD				Popovici, I; Withers, WD			Custom-built moments for edge location	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; moments; step edge; Radon transform; wedgelets	IMAGE-ANALYSIS	We present a general construction of functions whose moments serve to locate and parametrize step edges within an image. Previous use of moments to locate edges was limited to functions supported on a circular region, but our method allows the use of "custom-designed" functions supported on circles, rectangles, or any desired shape, and with graphs whose shape may be chosen with great freedom. We present analyses of the sensitivity of our method to pixelization errors or discrepancy between the image and an idealized edge model. The parametric edge description yielded by our method makes it especially suitable as a component of wedgelet image coding.	USN Acad, Dept Math, Annapolis, MD 21402 USA	United States Department of Defense; United States Navy; United States Naval Academy	Popovici, I (corresponding author), USN Acad, Dept Math, Annapolis, MD 21402 USA.	popovici@usna.edu; wdw@usna.edu						CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DEMARET L, QUICK GUIDE WEDGELET; Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261; FUHR H, WAVELETS NEW IMAGE R; GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X; Ghosal S, 1997, IEEE T IMAGE PROCESS, V6, P781, DOI 10.1109/83.585230; HUO X, 2004, IPAM PRES SEPT; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367; Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859; POPOVICI I, 2003, RES PROPOSAL; POPOVICI I, LOCATING EDGES REMOV; Reeves A. P., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P312; ROMBERG JK, MULTISCALE GEOMETRIC; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640	15	20	22	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					637	642		10.1109/TPAMI.2006.75	http://dx.doi.org/10.1109/TPAMI.2006.75			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566511				2022-12-18	WOS:000235253300012
J	Sun, CM; Appleton, B				Sun, CM; Appleton, B			Multiple paths extraction in images using a constrained expanded trellis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple paths extraction; constrained expanded trellis; feature extraction; object segmentation	EFFICIENT ALGORITHMS; DISJOINT PATHS; MODELS	Single shortest path extraction algorithms have been used in a number of areas such as network flow and image analysis. In image analysis, shortest path techniques can be used for object boundary detection, crack detection, or stereo disparity estimation. Sometimes one needs to find multiple paths as opposed to a single path in a network or an image where the paths must satisfy certain constraints. In this paper, we propose a new algorithm to extract multiple paths simultaneously within an image using a constrained expanded trellis (CET) for feature extraction and object segmentation. We also give a number of application examples for our multiple paths extraction algorithm.	CSIRO Math & Informat Sci, N Ryde, NSW 1670, Australia; Univ Queensland, Sch ITEE, St Lucia, Qld 4067, Australia	Commonwealth Scientific & Industrial Research Organisation (CSIRO); University of Queensland	Sun, CM (corresponding author), CSIRO Math & Informat Sci, Locked Bag 17, N Ryde, NSW 1670, Australia.	changming.sun@csiro.au; appleton@itee.uq.edu.au	Whitford, Linda M/C-2470-2009; Sun, Changming/A-3276-2008	Sun, Changming/0000-0001-5943-1989				Ahuja R. K., 1993, NETWORK FLOWS THEORY; Appleton B, 2005, J MATH IMAGING VIS, V23, P67, DOI 10.1007/s10851-005-4968-1; Appleton B, 2003, PATTERN RECOGN, V36, P2513, DOI 10.1016/S0031-3203(03)00122-5; Bamford P, 1998, SIGNAL PROCESS, V71, P203, DOI 10.1016/S0165-1684(98)00145-5; Barzohar M, 1996, IEEE T PATTERN ANAL, V18, P707, DOI 10.1109/34.506793; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Buckley M, 1997, PATTERN RECOGN LETT, V18, P621, DOI 10.1016/S0167-8655(97)00076-7; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASTANON DA, 1990, IEEE T AERO ELEC SYS, V26, P405, DOI 10.1109/7.53448; Chan WT, 2000, J ALGORITHMS, V34, P337, DOI 10.1006/jagm.1999.1054; Changming Sun, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P852; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Gu QP, 2000, J PARALLEL DISTR COM, V60, P764, DOI 10.1006/jpdc.2000.1632; LEUNG C, 2004, P BRIT MACH VIS C SE, V1, P97; LLOYD SA, 1986, PATTERN RECOGN LETT, V4, P273, DOI 10.1016/0167-8655(86)90008-5; Nikolopoulos SD, 1997, J SYST ARCHITECT, V42, P743, DOI 10.1016/S1383-7621(96)00074-4; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PERRY R, 1999, P 6 ANN WORKSH AD SE; SEDGEWICK R, 1998, ALGORITHMS CPLUSPLUS; STEGMANN MB, 2001, P 12 SCAND C IM AN S, V1, P90; Sun CM, 2002, IMAGE VISION COMPUT, V20, P981, DOI 10.1016/S0262-8856(02)00112-9; Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703; WOLF JK, 1989, IEEE T AERO ELEC SYS, V25, P287, DOI 10.1109/7.18692; Wu CS, 1999, IEICE T COMMUN, VE82B, P591; [No title captured]	25	20	20	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1923	1933		10.1109/TPAMI.2005.247	http://dx.doi.org/10.1109/TPAMI.2005.247			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355660				2022-12-18	WOS:000232532600007
J	Spratling, MW				Spratling, MW			Learning viewpoint invariant perceptual representations from cluttered images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computational models of vision; neural nets	OBJECT RECOGNITION; VISUAL-SYSTEM; FUNCTIONAL ARCHITECTURE; PATTERN-RECOGNITION; LATERAL INHIBITION; TEMPORAL CORTEX; NEURONS; MACAQUE; NEOCOGNITRON; RESPONSES	In order to perform object recognition, it is necessary to form perceptual representations that are sufficiently specific to distinguish between objects, but that are also sufficiently flexible to generalize across changes in location, rotation, and scale. A standard method for learning perceptual representations that are invariant to viewpoint is to form temporal associations across image sequences showing object transformations. However, this method requires that individual stimuli be presented in isolation and is therefore unlikely to succeed in real-world applications where multiple objects can co-occur in the visual input. This paper proposes a simple modification to the learning method that can overcome this limitation and results in more robust learning of invariant representations.	Kings Coll London, Div Engn, London WC2R 2LS, England; Univ London Birkbeck Coll, Ctr Brain & Cognit Dev, London WC1E 7HX, England	University of London; King's College London; University of London; Birkbeck University London	Spratling, MW (corresponding author), Kings Coll London, Div Engn, London WC2R 2LS, England.	michael.spratling@kcl.ac.uk	Spratling, Michael W/G-7689-2011	Spratling, Michael W/0000-0001-9531-2813	Engineering and Physical Sciences Research Council [GR/S81339/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		BARLOW H, 1990, VISION RES, V30, P1561, DOI 10.1016/0042-6989(90)90144-A; BARTLETT MS, 1998, NETW COMPUT NEURAL S, V9, P1; BARTLETT MS, 1996, COMPUTATIONAL NEUR S, V1, P317; Becker S, 1999, NEURAL COMPUT, V11, P347, DOI 10.1162/089976699300016683; BECKER S, 1993, ADV NEURAL INFORMATI, V5, P361; Booth MCA, 1998, CEREB CORTEX, V8, P510, DOI 10.1093/cercor/8.6.510; Clarkson RW, 1997, GREAT BASIN NAT, V57, P66; EBDON M, 1996, THESIS U SUSSEX; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Foldiak P, 1991, NEURAL COMPUT, V3, P194, DOI 10.1162/neco.1991.3.2.194; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gilbert CD, 1996, CURR OPIN NEUROBIOL, V6, P269, DOI 10.1016/S0959-4388(96)80083-3; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; KOBATAKE E, 1994, J NEUROPHYSIOL, V71, P856, DOI 10.1152/jn.1994.71.3.856; Kording KP, 2001, NEURAL COMPUT, V13, P2823, DOI 10.1162/089976601317098547; Logothetis N, 1998, CURR OPIN NEUROBIOL, V8, P536; Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045; MIYASHITA Y, 1988, NATURE, V335, P817, DOI 10.1038/335817a0; Mountcastle V.B., 1998, PERCEPTUAL NEUROSCIE; O'Reilly R. C., 1992, PDPCNS925 CARN MELL; Oram MW, 1996, NEUROCOMPUTING, V11, P297, DOI 10.1016/0925-2312(95)00099-2; OREILLY RC, 1994, NEURAL COMPUT, V6, P357, DOI 10.1162/neco.1994.6.3.357; Palmer S.E., 1999, VISION SCI PHOTONS P; PERRETT DI, 1992, PHILOS T ROY SOC B, V335, P23, DOI 10.1098/rstb.1992.0003; PERRETT DI, 1996, VISION MOVEMENT MECH, P142; Riesenhuber M, 1999, NEURON, V24, P87, DOI 10.1016/S0896-6273(00)80824-7; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Rolls ET, 2000, NEURON, V27, P205, DOI 10.1016/S0896-6273(00)00030-1; Rolls ET, 2000, NEURAL COMPUT, V12, P2547, DOI 10.1162/089976600300014845; Sinha P, 1996, NATURE, V384, P460, DOI 10.1038/384460a0; Spratling M. W., 2004, Cognitive Systems Research, V5, P93, DOI 10.1016/j.cogsys.2003.11.002; Spratling MW, 2002, NEURAL COMPUT, V14, P2157, DOI 10.1162/089976602320264033; STONE J, 1995, NETWORK-COMP NEURAL, V6, P429, DOI 10.1088/0954-898X/6/3/008; Stone JV, 1996, PERCEPTION, V25, P207, DOI 10.1068/p250207; Stone JV, 1998, VISION RES, V38, P947, DOI 10.1016/S0042-6989(97)00301-5; Stringer SM, 2000, NEURAL NETWORKS, V13, P305, DOI 10.1016/S0893-6080(00)00017-4; STRYKER MP, 1991, NATURE, V354, P108, DOI 10.1038/354108d0; Tanaka K, 1996, NEURAL NETWORKS, V9, P1459, DOI 10.1016/S0893-6080(96)00045-7; TEMPLEMAN JN, 1989, P INT JOINT C NEUR N, V1, P731; Thornton C., 1996, FORMS REPRESENTATION, P152; TOVEE MJ, 1994, J NEUROPHYSIOL, V72, P1049, DOI 10.1152/jn.1994.72.3.1049; Ungerleider LG, 1982, ANAL VISUAL BEHAV, P549; Wallace RW, 1998, DRUG DISCOV TODAY, V3, P299, DOI 10.1016/S1359-6446(98)01205-7; Wallis G, 1997, PROG NEUROBIOL, V51, P167, DOI 10.1016/S0301-0082(96)00054-8; Wallis G, 2002, VIS COGN, V9, P233, DOI 10.1080/13506280143000412; Wallis G, 1999, TRENDS COGN SCI, V3, P22, DOI 10.1016/S1364-6613(98)01261-3; Wallis G, 1998, NETWORK-COMP NEURAL, V9, P265, DOI 10.1088/0954-898X/9/2/007; WALLIS G, 1993, IEEE IJCNN, P1087; Wallis G, 1996, NEURAL NETWORKS, V9, P1513, DOI 10.1016/S0893-6080(96)00041-X; Wallis G, 2001, P NATL ACAD SCI USA, V98, P4800, DOI 10.1073/pnas.071028598; WALLIS G, 1994, THESIS U OXFORD; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938	56	20	20	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					753	761		10.1109/TPAMI.2005.105	http://dx.doi.org/10.1109/TPAMI.2005.105			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875796	Green Submitted, Green Accepted			2022-12-18	WOS:000227569300008
J	Guillemaut, JY; Aguado, AS; Illingworth, J				Guillemaut, JY; Aguado, AS; Illingworth, J			Using points at infinity for parameter decoupling in camera calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; camera calibration; invariants	LINE CORRESPONDENCES; 3 VIEWS; MOTION	The majority of camera calibration methods, including the Gold Standard algorithm, use point-based information and simultaneously estimate all calibration parameters. In contrast, we propose a novel calibration method that exploits line orientation information and decouples the problem into two simpler stages. We formulate the problem as minimization of the lateral displacement between single projected image lines and their vanishing points. Unlike previous vanishing point methods, parallel line pairs are not required. Additionally, the invariance properties of vanishing points mean that multiple images related by pure translation can be used to increase the calibration data set size without increasing the number of estimated parameters. We compare this method with vanishing point methods and the Gold Standard algorithm and demonstrate that it has comparable performance.	Univ Surrey, Sch Elect & Phys Sci, Surrey GU2 7XH, England; Core Tech, Elect Arts, Surrey KT16 0EU, England	University of Surrey	Guillemaut, JY (corresponding author), Univ Surrey, Sch Elect & Phys Sci, Surrey GU2 7XH, England.	jean-yves.guillemaut@surrey.ac.uk; AAguado@europe.ea.com; j.illingworth@surrey.ac.uk	Guillemaut, Jean-Yves/N-7739-2014	Guillemaut, Jean-Yves/0000-0001-8223-5505				AGUADO AS, 2000, P BRIT MACH VIS C, V2, P785; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Bartoli A, 2003, PROC CVPR IEEE, P477; BEARDSLEY P, 1992, P BRIT MACH VIS C, P416; BUCHANAN T, 1988, COMPUT VISION GRAPH, V42, P130, DOI 10.1016/0734-189X(88)90146-6; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; CHEN W, 1991, PATTERN RECOGN, V24, P57, DOI 10.1016/0031-3203(91)90116-M; Cipolla R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P25, DOI 10.1109/MMCS.1999.779115; Daniilidis K, 1996, PATTERN RECOGN LETT, V17, P1179, DOI 10.1016/0167-8655(96)00073-6; Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269; Echigo T., 1990, Machine Vision and Applications, V3, P159, DOI 10.1007/BF01214428; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Haralick RM, 1996, INT J PATTERN RECOGN, V10, P561, DOI 10.1142/S0218001496000347; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; Hartley RI, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P469, DOI 10.1109/ICCV.1998.710760; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; Liebowitz D., 1999, P EUROGRAPHICS, V18, P39; Liu K. J., 1988, Packaging Technology & Science, V1, P57, DOI 10.1002/pts.2770010203; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354; Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P282, DOI 10.1109/34.754631; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Stein GP, 1999, IEEE T PATTERN ANAL, V21, P244, DOI 10.1109/34.754590; STEVENSON DE, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P34; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; VIEVILLE T, 1998, FEW STEPS 3D ACTIVE; Wang L L, 1990, MACH VISION APPL, V3, P129; WANG LL, 1991, IEEE T PATTERN ANAL, V13, P370, DOI 10.1109/34.88572; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327	33	20	23	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					265	270		10.1109/TPAMI.2005.41	http://dx.doi.org/10.1109/TPAMI.2005.41			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688563	Green Submitted			2022-12-18	WOS:000225689300009
J	Han, M; Kanade, T				Han, M; Kanade, T			Multiple motion scene reconstruction with uncalibrated cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; motion segmentation; camera calibration; dynamic scene reconstruction; computer vision	SELF-CALIBRATION; 3D RECONSTRUCTION; SHAPE; AUTOCALIBRATION; SEQUENCES; POINTS	In this paper, we describe a reconstruction method for multiple motion scenes, which are scenes containing multiple moving objects, from uncalibrated views. Assuming that the objects are moving with constant velocities, the method recovers the scene structure, the trajectories of the moving objects, the camera motion, and the camera intrinsic parameters (except skews) simultaneously. We focus on the case where the cameras have unknown and varying focal lengths while the other intrinsic parameters are known. The number of the moving objects is automatically detected without prior motion segmentation. The method is based on a unified geometrical representation of the static scene and the moving objects. It first performs a projective reconstruction using a bilinear factorization algorithm and, then, converts the projective solution to a Euclidean one by enforcing metric constraints. Experimental results on synthetic and real images are presented.	NEC Labs Amer, Cupertino, CA 95014 USA; Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	NEC Corporation; Carnegie Mellon University	Han, M (corresponding author), NEC Labs Amer, 10080 N Wolfe Rd,SW3-350, Cupertino, CA 95014 USA.	meihan@ccrl.sj.nec.com; tk@cs.cmu.edu						Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; AVIDAN S, 1999, P IEEE C COMP VIS PA; Beardsley P., 1996, P EUR C COMP VIS, P683; Bougnoux S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P790, DOI 10.1109/ICCV.1998.710808; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; Christy S, 1996, IEEE T PATTERN ANAL, V18, P1098, DOI 10.1109/34.544079; CHRISTY S, 1996, P EUR C COMP VIS 96, P129; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; de Agapito L., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P15, DOI 10.1109/CVPR.1999.786911; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 2000, P EUR C COMP VIS; Han M, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P178, DOI 10.1109/WACV.2000.895420; Han M, 2000, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2000.854908; HAN M, 2001, P INT C COMP VIS; Hartley R. I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P510, DOI 10.1109/ICCV.1999.791264; HARTLEY RI, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P908; Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362; Kahl F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P366, DOI 10.1109/CVPR.1999.784661; Kahl F, 2000, J MATH IMAGING VIS, V13, P131, DOI 10.1023/A:1026524030731; MOHR R, 1995, INT J ROBOT RES, V14, P619, DOI 10.1177/027836499501400607; Nister D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P116, DOI 10.1109/ICCV.2001.937612; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; Quan L, 1996, INT J COMPUT VISION, V19, P93, DOI 10.1007/BF00131149; Shashua A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P330, DOI 10.1109/ICCV.1999.791238; SHASHUA A, 2000, P EUR C COMP VIS; Sparr G., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P328, DOI 10.1109/ICPR.1996.546043; Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467; STURM P, 1997, SOC CERT INF ARCH; STURM P, 1999, P BRIT MACH VIS C NO, P63; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762; Torr PHS, 1999, INT J COMPUT VISION, V32, P27, DOI 10.1023/A:1008140928553; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; TRIGGS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P338, DOI 10.1109/ICCV.1995.466920; Wexler Y, 2000, PROC CVPR IEEE, P576, DOI 10.1109/CVPR.2000.855871; Wolf L, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P412, DOI 10.1109/ICCV.2001.937547; YU H, 1996, P INT C PATT REC	44	20	21	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					884	894		10.1109/TPAMI.2003.1206517	http://dx.doi.org/10.1109/TPAMI.2003.1206517			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN					2022-12-18	WOS:000183667300010
J	Marengoni, M; Hanson, A; Zilberstein, S; Riseman, E				Marengoni, M; Hanson, A; Zilberstein, S; Riseman, E			Decision making and uncertainty management in a 3D reconstruction system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						intelligent systems; image reconstruction; learning systems; object recognition	NETWORKS; IMAGES	This paper presents a control structure for a general-purpose image understanding system. It addresses the high level of uncertainty in local hypotheses and the computational complexity of image interpretation. The control of vision algorithms is done by an independent subsystem that uses Bayesian networks and utility theory to compute marginal value of information and selects the algorithm with the highest value of information. It is shown that the knowledge base can be acquired using learning techniques and the value-driven approach to the selection of vision algorithms leads to performance gains.	Massachusetts Coll Lib Arts, Dept Comp Sci, N Adams, MA 01247 USA; Univ Massachusetts, Dept Comp Sci, Amherst, MA 01002 USA	Massachusetts System of Public Higher Education; Massachusetts College Liberal Arts; University of Massachusetts System; University of Massachusetts Amherst	Marengoni, M (corresponding author), Massachusetts Coll Lib Arts, Dept Comp Sci, 375 Church St, N Adams, MA 01247 USA.	mmarengo@mcla.edu	Marengoni, Mauricio/B-8378-2013	Marengoni, Mauricio/0000-0002-6830-1067; Zilberstein, Shlomo/0000-0001-9817-7848				ANDERSEN SK, 1989, P IJCAI, V2, P1080; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BROWN CM, 1994, P SPIE IM INF SYST A; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J., 1998, LEARNING BAYESIAN NE; Cheng J., 1997, P AI STAT 97, P83, DOI DOI 10.1016/J.PATCOG.2004.05.012; COLLINS R, 1998, COMPUTER VISION IMAG; COLLINS RT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P888, DOI 10.1109/ICCV.1995.466842; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cooper Gregory F., 1991, UNCERTAINTY ARTIFICI, V1991, P86, DOI DOI 10.1016/B978-1-55860-203-8.50015-2; Crevier D, 1997, COMPUT VIS IMAGE UND, V67, P161, DOI 10.1006/cviu.1996.0520; DRAPER BA, 1989, INT J COMPUT VISION, V2, P209, DOI 10.1007/BF00158165; Draper BA, 1996, P IEEE, V84, P1625, DOI 10.1109/5.542412; Friedman N, 1996, P 12 C UNC ART INT, P252; Hanson A., 1978, COMPUTER VISION SYST; Heckerman D, 1995, MSRTR9506; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; HOWARD RA, 1984, READINGS PRINCIPLES, P721; JAYNES C, 1998, P INT S ENG INT SYST; Jaynes C., 1998, P IASTED INT C INT S, P30; JAYNES CO, 1996, P ARP IM UND WORKSH, P479; Jensen F.V., 2007, BAYESIAN NETWORKS DE, DOI 10.1007/978-0-387-68282-2; KREBS BM, 1998, P INT C COMP VIS; Kumar VP, 1996, IEEE T PATTERN ANAL, V18, P74, DOI 10.1109/34.476423; Lindley D., 1985, MAKING DECISIONS; MANN WB, 1992, P DARPA IM UND WORKS, P793; MARENGONI M, 1999, P INT C VIS SYST; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; RIMEY R, 1992, ACTIVE VISION	29	20	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					852	858		10.1109/TPAMI.2003.1206514	http://dx.doi.org/10.1109/TPAMI.2003.1206514			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN					2022-12-18	WOS:000183667300007
J	Olson, CF				Olson, CF			Adaptive-scale filtering and feature detection using range data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						filtering; edge detection; feature detection; stereo; smoothing; scale-space	EDGE-DETECTION; SELECTION; VISION; SPACE	In edge and corner detection applications, it is typical to examine a single scale without knowing which scale is appropriate for each location in the image. However, many images contain a wide variation in the distance to the scene pixels and, thus, features of the same size can appear at greatly differing scales in the image. We present a method where the scale of the filtering and feature detection is Varied locally according to the distance to the scene pixel, which we estimate through stereoscopy. The features that are detected are, thus, at the same scale in the world. rather than at the same scale in the image. This method has been implemented efficiently by filtering the image at a discrete set of scales and performing interpolation to estimate the response at the correct scale for each pixel. The application of this technique to an ordnance recognition problem has resulted in a considerable improvement in performance.	CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA	California Institute of Technology; National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL)	Olson, CF (corresponding author), CALTECH, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.	Clark.Olson@jpl.nasa.gov						BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GENNERY DB, 1991, D8580 JPL CALTECH; Hancock E. R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P196, DOI 10.1109/CVPR.1991.139687; JEONG H, 1992, IEEE T PATTERN ANAL, V14, P579, DOI 10.1109/34.134062; Liang P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P193, DOI 10.1109/ICCV.1998.710718; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X; LU Y, 1992, IEEE T PATTERN ANAL, V14, P450, DOI 10.1109/34.126806; Marimont DH, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P207, DOI 10.1109/ICCV.1998.710720; MATTHIES L, 1992, INT J COMPUT VISION, V8, P71, DOI 10.1007/BF00126401; MATTHIES L, 1996, P INT S ROB RES, P475; MORRONE MC, 1995, PATTERN RECOGN LETT, V16, P667, DOI 10.1016/0167-8655(95)00017-B; Olson CF, 1998, PROC CVPR IEEE, P80, DOI 10.1109/CVPR.1998.698591; Olson CF, 1998, PROC SPIE, V3392, P122, DOI 10.1117/12.324184; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; Rosin PL, 1997, MACH VISION APPL, V9, P139, DOI 10.1007/s001380050036; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	24	20	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					983	991		10.1109/34.877521	http://dx.doi.org/10.1109/34.877521			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY					2022-12-18	WOS:000089741300006
J	Hasan, YMY; Karam, LJ				Hasan, YMY; Karam, LJ			Morphological reversible contour representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape analysis; binary images; mathematical morphology; shape representation; homotopy; topology; contour coding; contour filling	SHAPE REPRESENTATION; BINARY IMAGES; MATHEMATICAL MORPHOLOGY; DECOMPOSITION; COMPRESSION; ALGORITHM; SKELETON	In this paper, a novel morphological reversible contour representation of discrete binary images is proposed. A binary image is represented by a set of nonoverlapping multilevel contours and a residual image. In this proposed representation, the total number of pixels representing an image is far less than the total number of pixels obtained by the seed-based morphological contour-skeleton lossless representation. The proposed contour representation is simple, unique. and general without restrictions on the binary image to be represented. Moreover, it requires fewer number of operations to compute the proposed representation compared with other lossless morphological representation methods. The resulting multicontour image component is also robust to noise. An efficient differential chain contour coding scheme is employed to further compress the represented image. The proposed method yields very low bit rates compared to the existing morphological techniques. To exactly reconstruct an original image, an automatic filling procedure, which properly fills a proper multicontour image according to its topological structure without need of seed points, is proposed. The morphological unique contour representation and its lossless reconstruction techniques have been tested on images with varying size and complexity. Examples are presented to illustrate the performance of the proposed method.	Arizona State Univ, Dept Elect Engn, Ctr Telecommun Res, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe	Hasan, YMY (corresponding author), Arizona State Univ, Dept Elect Engn, Ctr Telecommun Res, Tempe, AZ 85287 USA.		Karam, Lina Jamil/ABD-6531-2021	Karam, Lina Jamil/0000-0003-1870-1211				ACKLAND BD, 1981, IEEE T COMPUT, V30, P41, DOI 10.1109/TC.1981.6312155; CABRELLI CA, 1990, IEEE T PATTERN ANAL, V12, P1190, DOI 10.1109/34.62608; CAI ZG, 1988, COMPUT VISION GRAPH, V41, P101, DOI 10.1016/0734-189X(88)90119-3; CHANG LW, 1990, COMPUT VISION GRAPH, V50, P296, DOI 10.1016/0734-189X(90)90149-P; CHARIF M, 1996, IEEE T IMAGE PROCESS, V15, P531; CHARIFCHEFCHAOUNI M, 1994, IEEE T IMAGE PROCESS, V3, P847, DOI 10.1109/83.336253; CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552; *ESPRIT, 1996, NOBL NONL MOD BAS AN; Foley James D, 1996, COMPUTER GRAPHICS PR, V12110; Heijmans H., 1994, MORPHOLOGICAL IMAGE; JANG BK, 1990, IEEE T PATTERN ANAL, V12, P541, DOI 10.1109/34.56190; JI LA, 1992, IEEE T PATTERN ANAL, V14, P653, DOI 10.1109/34.141555; Kasturi R., 1990, IMAGE ANAL APPL; Loui ACP, 1992, IEEE T IMAGE PROCESS, V1, P337, DOI 10.1109/83.148607; LU G, 1997, J INFORM SCI, V123, P119; MA CKW, 1986, COMPUTER VISION GRAP, V34, P282; MAHDY YB, 1996, P IEEE INT C SIGN PR, P1362; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1987, OPT ENG, V26, P623, DOI 10.1117/12.7974127; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; MARSHALL S, 1992, IEE PROC-I, V139, P1, DOI 10.1049/ip-i-2.1992.0001; MATSOPOOLOS GK, 1994, PATTERN RECOGN, P1317; MICHEL JL, 1988, IBM J RES DEV, V32, P753; OHTA K, 1996, P IEEE INT C SIGN PR, P1002; PAI TW, 1994, IEEE T PATTERN ANAL, V16, P200; PAI TW, 1991, P IEEE INT C AC SPEE, P2761; PITAS I, 1992, PATTERN RECOGN, V25, P555, DOI 10.1016/0031-3203(92)90073-R; PITAS I, 1990, IEEE T PATTERN ANAL, V12; PONG SWL, 1992, CIRCUIT SYSTEMS SIGN, V22, P455; PONG SWL, 1991, CIRCUIT SYSTEMS SIGN, V10, P293; *RACE, 1995, MORPH MORPH COD STOR; Reinhardt JM, 1996, IEEE T PATTERN ANAL, V18, P951, DOI 10.1109/34.537351; Reinhardt JM, 1996, IEEE T IMAGE PROCESS, V5, P89, DOI 10.1109/83.481673; Ritter Gerhard, 1996, HDB COMPUTER VISION; Salembier P, 1996, IEEE T IMAGE PROCESS, V5, P881, DOI 10.1109/83.503906; Serra J, 1982, IMAGE ANAL MATH MORP; STERNBERG SR, 1983, P IEEE WORKSH COMP A; TANG GY, 1988, COMPUT VISION GRAPH, V42, P297, DOI 10.1016/S0734-189X(88)80040-9; Turner MJ, 1996, COMPUT GRAPH FORUM, V15, P107, DOI 10.1111/1467-8659.1520107; XU J, 1996, PATTERN RECOGN, V29, P175; YANG R, 1993, P IEEE INT C AC SPEE, P97; ZHOU Z, 1988, P IEEE INT C AC SIGN, P984; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	43	20	21	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2000	22	3					227	240		10.1109/34.841755	http://dx.doi.org/10.1109/34.841755			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	306EJ					2022-12-18	WOS:000086584100002
J	Sato, J; Cipolla, R				Sato, J; Cipolla, R			Affine reconstruction of curved surfaces from uncalibrated views of apparent contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curved surfaces; affine reconstruction; uncalibrated reconstruction; apparent contours; epipolar geometry; time-to-contact	OCCLUDING CONTOURS; MOTION; SHAPE	In this paper, we consider uncalibrated reconstruction of curved surfaces from apparent contours. Since apparent contours are not fixed features (viewpoint independent), we cannot directly apply the recent results of the uncalibrated reconstruction from fixed features. We show that, nonetheless, curved surfaces can be reconstructed up to an affine ambiguity from their apparent contours viewed from uncalibrated cameras with unknown linear translations. Furthermore, we show that, even if the reconstruction is nonmetric (non-Euclidean), we can still extract useful information for many computer vision applications just from the apparent contours. We first show that if the camera motion is linear translation (but arbitrary direction and magnitude), the epipolar geometry can be recovered from the apparent contours without using any optimization process. The extracted epipolar geometry is next used for reconstructing curved surfaces from the deformations of the apparent contours viewed from uncalibrated cameras. The result is applied to distinguishing curved surfaces from fixed features in images. It is also shown that the time-to-contact to the curved surfaces can be computed from simple measurements of the apparent contours.	Nagoya Inst Technol, Dept Elect & Comp Engn, Nagoya, Aichi 4668555, Japan; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Nagoya Institute of Technology; University of Cambridge	Sato, J (corresponding author), Nagoya Inst Technol, Dept Elect & Comp Engn, Nagoya, Aichi 4668555, Japan.	junsato@elcom.nitech.ac.jp		Cipolla, Roberto/0000-0002-8999-2151				ASTROM K, 1996, P 4 EUR C COMP VIS C, V2, P97; BOYER E, 1996, P 4 EUR C COMP VIS, V2, P109; CHAM TJ, 1996, P BRIT MACH VIS C ED, V2, P363; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; CIPOLLA R, 1992, P 2 EUR C COMP VIS, P187; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136; GIBLIN PJ, 1994, P 3 EUR C COMP VIS S, V1, P14; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; JOSHI T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P290, DOI 10.1109/ICCV.1995.466927; Kutulakos KN, 1997, PROC CVPR IEEE, P53, DOI 10.1109/CVPR.1997.609297; KUTULAKOS KN, 1995, ARTIF INTELL, V78, P147, DOI 10.1016/0004-3702(95)00027-5; KUTULAKOS KN, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P894, DOI 10.1109/ICCV.1995.466841; KUTULAKOS KN, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P323, DOI 10.1109/CVPR.1994.323847; Moons T., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P297; Mundy J. L., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P89; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; SEALES WB, 1995, COMPUT VIS IMAGE UND, V61, P308, DOI 10.1006/cviu.1995.1025; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; VIJAYAKUMAR B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P508, DOI 10.1109/ICCV.1995.466897; Wright M, 1996, IMAGE VISION COMPUT, V14, P627, DOI 10.1016/0262-8856(96)01100-6; Zhao CS, 1996, COMPUT VIS IMAGE UND, V64, P62, DOI 10.1006/cviu.1996.0046; ZISSERMAN A, 1993, P 4 INT C COMP VIS B, P340	26	20	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1188	1198		10.1109/34.809111	http://dx.doi.org/10.1109/34.809111			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG		Green Submitted			2022-12-18	WOS:000083921100007
J	Chang, F; Lu, YC; Pavlidis, T				Chang, F; Lu, YC; Pavlidis, T			Feature analysis using line sweep thinning algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line sweep; thinning; line sweep thinning algorithm; path; junction; regular region; singular region; intersection set; feature analysis; character recognition	CHARACTER-RECOGNITION; CHINESE-CHARACTERS; RELAXATION	In this article, we propose a new thinning algorithm based on line sweep operation. A line sweep is a process where the plane figure is divided into parallel slabs by lines passing through certain "events." Assuming that the contour of the figure to be thinned has been approximated by polygons, the "events" are then the vertices of the polygons, and the line sweep algorithm searches for pairs of edges lying within each slab. The pairing of edges is useful for detecting both regular and intersection regions. The regular regions can be found at the sites where pairings between edges exist. Intersection regions are those where such relations would cease to exist. A salient feature of our approach is that it finds simultaneously the set of regular regions that attach to the same intersection region. Such a set is thus called an intersection set. The output of our algorithm consists of skeletons as well as intersection sets. Both can be used as features for subsequent character recognition. Moreover, the line sweep thinning algorithm is efficient in computation as compared with a pixel-based thinning algorithm which outputs skeletons only.	Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan; Cent Bank China, Sect 1, Taipei, Taiwan; SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Academia Sinica - Taiwan; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Chang, F (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.							Chang F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P35, DOI 10.1109/ICDAR.1993.395787; CHANG F, 1994, P INT C COMP PROC OR, P435; CHANG F, 1995, P 3 INT C DOC AN REC; CHANG F, 1997, TRIIS97011 AC SIN; CHANG F, 1995, P 3 INT C DOC AN REC, P227; CHENG FH, 1993, PATTERN RECOGN, V26, P579, DOI 10.1016/0031-3203(93)90112-A; Chouinard C., 1992, Machine Vision and Applications, V5, P185, DOI 10.1007/BF02626997; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEE S, 1992, IEEE T SYST MAN CYB, V22, P755, DOI 10.1109/21.156588; LI B, 1991, PATTERN RECOGN, V24, P1211, DOI 10.1016/0031-3203(91)90146-V; LU SW, 1992, PATTERN RECOGN LETT, V13, P745, DOI 10.1016/0167-8655(92)90104-8; LU W, 1988, P 9 ICPR, P266; MAHMOUD SA, 1991, PATTERN RECOGN, V24, P453, DOI 10.1016/0031-3203(91)90058-D; Marcelli A, 1997, COMPUT VIS IMAGE UND, V66, P330, DOI 10.1006/cviu.1996.0518; NISHIDA H, 1991, P INT WORKSH FRONT H, P27; PAVLIDIS T, 1985, IEEE COMPUT GRAPH, V5, P47, DOI 10.1109/MCG.1985.276499; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; SAKAUCHI M, 1985, IEEE COMP SOC WORKSH, P154; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646; SUEN Y, 1993, INT J PATTERN RECOGN, V7; XIE SL, 1988, PATTERN RECOGN, V21, P1, DOI 10.1016/0031-3203(88)90066-0	23	20	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					145	158		10.1109/34.748823	http://dx.doi.org/10.1109/34.748823			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL					2022-12-18	WOS:000078639900004
J	Ji, Q; Haralick, RM				Ji, Q; Haralick, RM			Breakpoint detection using covariance propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						corner detection; arc segmentation; error propagation	DIGITAL CURVES; SEGMENTATION	This paper presents a novel statistical approach for detecting breakpoints from chain encoded digital arcs. An are point is declared as a breakpoint if the estimated orientations of the two fitted lines of the two are segments immediately to the right and left of the are point are significantly statistically different. The major contributions of this research include developing a method for analytically estimating the covariance matrix of the fitted line parameters and proposing a perturbation model to characterize the perturbation associated with each are point.	Univ Washington, Dept Elect Engn, Intelligent Syst Lab, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Ji, Q (corresponding author), Univ Washington, Dept Elect Engn, Intelligent Syst Lab, Seattle, WA 98195 USA.	qiangji@george.ee.washington.edu; haralick@george.ee.washington.edu	Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GUIDUCCI R, 1990, PATTERN RECOGN, V23, P1223; HARALICK RM, 1994, INT C PATT RECOG, P493, DOI 10.1109/ICPR.1994.576335; KADONAGA T, 1995, INT WORKSH GRAPH REC; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; OGORMAN L, 1988, P 9 INT C PATT REC; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; ROSIN PL, 1996, 7 BRIT MACH VIS C ED; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; THORNTON K, 1995, IUE WORKSH; VENTURA JA, 1992, PATTERN RECOGN, V25, P1129, DOI 10.1016/0031-3203(92)90016-C; ZHANG X, 1995, IUE WORKSH; Zuniga O. A., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P30	18	20	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					845	851		10.1109/34.709604	http://dx.doi.org/10.1109/34.709604			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700007
J	Lemarechal, C; Fjortoft, R; Marthon, P; Cubero-Castan, E				Lemarechal, C; Fjortoft, R; Marthon, P; Cubero-Castan, E			Comments on "Geodesic saliency of watershed contours and hierarchical segmentation"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material						hierarchical segmentation; watershed algorithm; basin dynamics; edge dynamics		In a recent paper on morphological image segmentation [1], Najman and Schmitt introduce the powerful concept of edge dynamics. In this communication, we show that the method that they propose to compute the edge dynamics gives erroneous results for certain spatial configurations, and we propose a new algorithm which always yields correct edge dynamics.	CNRS, INP, UMR,IRIT,ENSEEIHT,LIMA, F-31071 Toulouse, France; French Space Agcy, CNES, DGA T SH QTIS, F-31401 Toulouse, France	Centre National de la Recherche Scientifique (CNRS); CNRS - Institute of Physics (INP); Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite de Toulouse; Institut National Polytechnique de Toulouse	Lemarechal, C (corresponding author), CNRS, INP, UMR,IRIT,ENSEEIHT,LIMA, 5505 UPS, F-31071 Toulouse, France.							Grimaud M., 1992, SPIE, V1769, P292; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344	3	20	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					762	763		10.1109/34.689307	http://dx.doi.org/10.1109/34.689307			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930					2022-12-18	WOS:000074677200009
J	Silva, C; SantosVictor, J				Silva, C; SantosVictor, J			Robust egomotion estimation from the normal flow using search subspaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; egomotion; optical flow; normal flow	MOTION; NAVIGATION	We address the problem of egomotion estimation for a monocular observer moving under arbitrary translation and rotation. in an unknown environment. The method we propose is uniquely based on the spatio-temporal image derivatives, or the normal flow. We introduce a search paradigm which is based on geometric properties of the normal flow field, and consists in considering a family of search subspaces to estimate the egomotion parameters. Various algorithms are proposed within this framework. In order to decrease the noise sensitivity of the estimation methods, we use statistical tools, based on robust regression theory. Finally, we present and discuss a wide variety of experiments with synthetic and real images, for various kinds of camera motion.			Silva, C (corresponding author), Univ Tecn Lisboa, INST SISTEMAS & ROBOT, VISLAB, COMP VIS LAB,INST SUPER TECN, AV ROVISCO PAIS, P-1096 LISBON, PORTUGAL.		; Santos-Victor, Jose/K-2093-2012	Silva, Cesar/0000-0001-5388-2594; Santos-Victor, Jose/0000-0002-9036-1728				ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; DANIILIDIS K, 1996, ECCV96 CAMBRIDGE APR; FERMULLER C, 1995, INT J COMPUT VISION, V15, P7, DOI 10.1007/BF01450848; FERMULLER C, 1995, INT J COMPUT VISION, V14, P147, DOI 10.1007/BF01418980; FERMULLER C, 1995, SCIENCE, V270, P1973, DOI 10.1126/science.270.5244.1973; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; LUSTMAN F, 1987, P 1 INT C COMP VIS L; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SANTOSVICTOR J, 1995, INT J COMPUT VISION, V14, P159, DOI 10.1007/BF01418981; SILVA C, 1996, P 13 INT C PATT REC; SILVA C, 1996, 696 ISR I SUP TECN V	14	20	20	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					1026	1034		10.1109/34.615451	http://dx.doi.org/10.1109/34.615451			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500008
J	Kita, Y				Kita, Y			Elastic-model driven analysis of several views of a deformable cylindrical object	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformable objects; elastic models; physics-based modeling; multiple view analysis; nonrigid motion; contour extraction; medical image processing; stomach X-ray images	IMAGES; RECOGNITION; EXTRACTION; SURFACES	This paper proposes a method to extract regions of a deformable object from several views of it while finding the correspondence of the object among the views. The method has been developed to analyze X-ray images of a stomach. Owing to the physical (not physiological) deformation oi the stomach and changes of the camera angle, the shape oi the stomach regions are fairly different among the Images. In order to collectively analyze these images, we use an elastic stomach model. Firstly, our method builds an elastic stomach model based on the stomach shape in one image. Considering each photographing condition, the deformation of the stomach in each image is simulated with the elastic model. Referring to the predicted contour which is obtained by projecting the deformed model from the camera angle of each image, the contour is robustly extracted from noisy images in a model-driven way. Since the predicted contour registered in each image corresponds with the elastic model, the position of each stomach part in the image is simultaneously obtained; corresponding parts can be found among the images through the model. Experimental results of analyzing several types of stomach X-ray images are shown and discussed.			Kita, Y (corresponding author), ELECTROTECH LAB, COMP VIS SECT, 1-1-4 UMEZONO, TSUKUBA, IBARAKI 305, JAPAN.							AKATSUKA T, 1974, P 2 INT C PATT REC, P324; ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; AMINI AA, 1992, IMAGE VISION COMPUT, V10, P418, DOI 10.1016/0262-8856(92)90027-Z; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CHEN CW, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P443, DOI 10.1109/ICPR.1992.202020; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; ETUKUSHIMA S, 1977, MED EL BIOM ENG, V15, P7; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; GIBLIN P, 1987, 1ST P INT C COMP VIS, P136; GUPTA A, 1993, COMPUT CARDIOL, P747; HADORI M, 1980, PRL7995 I EL COMM EN; HASEGAWA J, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P352, DOI 10.1109/ICPR.1992.201997; Herlin I., 1992, P EUR C COMP VIS, P43; Huang W.-C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P833, DOI 10.1109/CVPR.1992.223246; *INF PROC MED IM, 1993, P 13 INT C INF PROC; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KISE K, 1993, P AS C COMP VIS, P656; KITA Y, 1991, CVGIP-GRAPH MODEL IM, V53, P447, DOI 10.1016/1049-9652(91)90029-J; Kita Y., 1991, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ74D-II, P873; KITA Y, 1996, TR967 EL LAB; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; MARR D, 1977, 416 7IT AI; MONHEIT G, 1991, IEEE COMPUT GRAPH, V11, P29, DOI 10.1109/38.75588; MORI H, 1977, MEE ELECT BIOM ENG, V15, P457; Nakamura S., 1983, Transactions of the Information Processing Society of Japan, V24, P165; Nakamura S., 1983, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ66D, P235; NASTAR C, 1993, P 4 INT C COMP VIS I, P275; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PRESTON K, 1976, DIGITAL PROCESSING B; Pugh A, 1983, ROBOT VISION; STARK L, 1991, IEEE T PATTERN ANAL, V13, P1097, DOI 10.1109/34.99242; Tehrani S., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P342, DOI 10.1109/CVPR.1989.37870; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.20317; WATERS K, 1987, P SIGGRAPH 87, P17; Yamamoto M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P664, DOI 10.1109/CVPR.1991.139772; Young A., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P399, DOI 10.1109/CVPR.1992.223158; [No title captured]	44	20	21	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1150	1162		10.1109/34.546253	http://dx.doi.org/10.1109/34.546253			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000002
J	McReynolds, DP; Lowe, DG				McReynolds, DP; Lowe, DG			Rigidity checking of 3D point correspondences under perspective projection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						rigidity checking; point correspondences; image matching; structure-from-motion; nonlinear parameter estimation; perspective projection	MOTION; VIEWS	An algorithm is described which rapidly verifies the potential rigidity of three-dimensional point correspondences from a pair of two-dimensional views under perspective projection. The output of the algorithm is a simple yes or no answer to the question ''Could these corresponding points from two views be the projection of a rigid configuration?'' Potential applications include 3D object recognition from a single previous view and correspondence matching for stereo or motion over widely separated views. The rigidity checking problem is different from the structure-from-motion problem because it is often the case that two views cannot provide an accurate structure-from-motion estimate due to ambiguity and ill conditioning, whereas it is still possible to give an accurate yes/no answer to the rigidity question. Rigidity checking verifies point correspondences using 3D recovery equations as a matching condition. The proposed algorithm improves upon other methods that fall under this approach because it works with as few as six corresponding points under full perspective projection, handles correspondences from widely separated views, makes full use of the disparity of the correspondences, and is integrated with a linear algorithm for 3D recovery due to Kontsevich. Results are given for experiments with synthetic and real image data. A complete implementation of this algorithm is being made publicly available.			McReynolds, DP (corresponding author), UNIV BRITISH COLUMBIA,DEPT COMP SCI,2366 MAIN MALL,VANCOUVER,BC V6T 1Z4,CANADA.							BASRI R, 1991, 133 AI MIT ART INT L; BENNETT BM, 1989, J OPT SOC AM A, V6, P1052, DOI 10.1364/JOSAA.6.001052; BENNETT BM, 1993, J OPT SOC AM A, V10, P759, DOI 10.1364/JOSAA.10.000759; BRAUNSTEIN ML, 1990, PERCEPT PSYCHOPHYS, V47, P205, DOI 10.3758/BF03204996; HARRIS C, 1990, P 1 EUR C COMP VIS, P118; HARRIS CG, 1988, IMAGE VISION COMPUT, V6, P87, DOI 10.1016/0262-8856(88)90003-0; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; HU XP, 1991, IEEE T ROBOTIC AUTOM, V7, P848, DOI 10.1109/70.105394; HUTTENLOCHER DP, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KONTSEVICH LL, 1993, J OPT SOC AM A, V10, P1129, DOI 10.1364/JOSAA.10.001129; KUMAR RVR, 1989, P CVPR, P136; LEE CH, 1990, COMPUT VISION GRAPH, V52, P309, DOI 10.1016/0734-189X(90)90078-A; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; MCREYNOLDS DP, 1988, THESIS U BRIT COLUMB; MCREYNOLDS DP, 1989, IEEE P NATL AER EL C, V3, P1097; MCREYNOLDS DP, 1995, 9505 U BRIT COL DEP; Nishimura E., 1993, AS C COMP VIS OS JAP, P199; SINCLAIR D, 1993, P 4 INT C COMP VIS B, P366; SZELISKI R, 1993, IEEE CS C COMP VIS P, P752; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WEI GQ, 1990, P IEEE INT C ROB AUT, V3, P2017; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074	27	20	21	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1174	1185		10.1109/34.546255	http://dx.doi.org/10.1109/34.546255			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000004
J	Wang, ZQ; Rao, KR; BenArie, J				Wang, ZQ; Rao, KR; BenArie, J			Optimal ramp edge detection using expansion matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						canny edge detector; edge detection; optimal filters; ramp edges; step edges; Expansion Matching (EXM); Discriminative Signal-to-Noise Ratio (DSNR)		In practical images, ideal step edges are actually transformed into ramp edges, due to the general low pass filtering nature of imaging systems. This pager discusses the application of the recently developed Expansion Matching (EXM) method for optimal ramp edge detection, EXM optimizes a novel matching criterion called Discriminative Signal-to-Noise Ratio (DSNR) and has been shown to robustly recognize templates under conditions of noise, severe occlusion, and superposition. We show that our ramp edge detector performs better than the ramp detector obtained from Canny's criteria in terms oi DSNR and is relatively easier to derive for various noise levels and slopes.	UNIV ILLINOIS, DEPT ELECT ENGN & COMP SCI, CHICAGO, IL 60607 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Wang, ZQ (corresponding author), IIT, DEPT ELECT & COMP ENGN, CHICAGO, IL 60616 USA.							Ben-Arie J, 1993, IEEE T CIRC SYST VID, V3, P71, DOI 10.1109/76.180691; BENARIE J, 1995, IEEE T CIRCUITS-II, V42, P402, DOI 10.1109/82.392315; BENARIE J, 1992, NEURAL NETWORKS HUMA, P214; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; Lee D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P2, DOI 10.1109/CVPR.1989.37822; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; NANDY D, 1996, P ICASSP 96 FEB; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RAO KR, 1994, IEEE T CIRC SYST VID, V4, P490, DOI 10.1109/76.322996; RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490; RAO KR, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P547, DOI 10.1109/ISCAS.1993.393779; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7	16	20	21	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1092	1097		10.1109/34.544078	http://dx.doi.org/10.1109/34.544078			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900004
J	DeCarlo, D; Metaxas, D				DeCarlo, D; Metaxas, D			Blended deformable models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation; shape blending; shape abstraction; shape estimation; physics-based modeling	GLOBAL DEFORMATIONS; RECOGNITION; REPRESENTATION; SUPERQUADRICS; ORGANIZATION; FORM	This paper develops a new class of parameterized models based on the linear interpolation of two parameterized shapes along their main axes, using a blending function. This blending function specifies the relative contribution of each component shape on the resulting blended shape. The resulting blended shape can have aspects of each of the component shapes. Using a small number oi additional parameters, blending extends the coverage of shape primitives while also providing abstraction of shape. In particular, it offers the ability to construct shapes whose genus can change. Blended models are incorporated into a physics-based shape estimation framework which uses dynamic deformable models. Finally, we present experiments involving the extraction of complex shapes from range data including examples of dynamic genus change.			DeCarlo, D (corresponding author), UNIV PENN, DEPT COMP & INFORMAT SCI, 200 S 33RD ST, PHILADELPHIA, PA 19104 USA.							Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BINFORD TO, 1971, P IEEE C SYST CONTR; DECARLO D, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P566, DOI 10.1109/CVPR.1994.323883; Farin G, 1990, CURVES SURFACES COMP; HANSON AJ, 1988, COMPUT VISION GRAPH, V44, P191, DOI 10.1016/S0734-189X(88)80005-7; HOFFMANN C, 1988, ARTIF INTELL, V37, P357, DOI 10.1016/0004-3702(88)90060-4; Koenderink J., 1990, SOLID SHAPE; MALLADI R, 1994, IN PRESS IEEE T PATT; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MATAXAS D, 1992, THESIS U TORONTO; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; ODONNELL T, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P174, DOI 10.1109/CVPR.1994.323826; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Snyder J., 1992, GENERATIVE MODELING; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P82, DOI 10.1109/CVPR.1993.340975; TAUBIN G, 1993, P 4 INT C COMP VIS B, P658; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; VEMURI BC, 1994, ACM T GRAPHIC, V13, P177, DOI 10.1145/176579.176583	23	20	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					443	448		10.1109/34.491626	http://dx.doi.org/10.1109/34.491626			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500010
J	Kumar, VP; Desai, UB				Kumar, VP; Desai, UB			Image interpretation using Bayesian networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						artificial intelligence; Bayesian networks; expert systems; object recognition; image interpretation; decision making; inference systems; Markov random fields		The problem of image interpretation is one of inference with the help of domain knowledge. In this correspondence, we formulate the problem as the maximum a posteriori (MAP) estimate of a properly defined probability distribution function. We show that a Bayesian network can be used to represent this p.d.f. as well as the domain knowledge needed for interpretation. The Bayesian network may be relaxed to obtain the set of optimum interpretations.	INDIAN INST TECHNOL,DEPT ELECT ENGN,BOMBAY 400076,MAHARASHTRA,INDIA	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay	Kumar, VP (corresponding author), NORTHEASTERN UNIV,DEPT ELECT & COMP ENGN,BOSTON,MA 02115, USA.							GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; KIM IY, 1993, PATTERN RECOGN, V26, P1695, DOI 10.1016/0031-3203(93)90024-Q; KUMAR VP, 1994, SPANN943 IND I TECHN; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552; NEAPOLITAN RE, 1990, PROBABILITSTIC REASO; OHTA Y, 1985, KNOWLEDGE BASED INTE; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PRASANNAPPA R, 1987, CSTR1785 U MARYL DEP; VERMA T, 1988, 4TH P AAAI WORKSH UN	12	20	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					74	77		10.1109/34.476423	http://dx.doi.org/10.1109/34.476423			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500010
J	KAO, CY; KUMARA, SRT; KASTURI, R				KAO, CY; KUMARA, SRT; KASTURI, R			EXTRACTION OF 3D OBJECT FEATURES FROM CAD BOUNDARY REPRESENTATION USING THE SUPER RELATION GRAPH METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAD/CAM; MANUFACTURING FEATURE EXTRACTION; FEATURE INTERACTIONS; SUPER RELATION GRAPHS; COMPUTATIONAL GEOMETRY; GRAPH ISOMORPHISM; PATTERN RECOGNITION	MODELS	This paper presents the super relation graph (SRG) method for extracting prismatic features from the CBD boundary representation of a machined part. Using the definition of super relations and the validity of a feature volume, this method recognizes features with all three types of interactions: face splitting, face merging, and edge truncation.	PENN STATE UNIV,DEPT COMP SCI & ENGN,UNIVERSITY PK,PA 16802	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	KAO, CY (corresponding author), PENN STATE UNIV,DEPT IND & MFG ENGN,UNIVERSITY PK,PA 16802, USA.							DEFLORIANI L, 1989, IEEE T PATTERN ANAL, V11, P785, DOI 10.1109/34.31442; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; Henderson M.R., 1984, THESIS PURDUE U; JAKUBOWSKI R, 1982, CYBERNET SYST, V13, P1, DOI 10.1080/01969728208927686; KAO CY, 1992, THESIS PENNSYLVANIA; KIM YS, 1991, 1991 P C COMP ENG, V1, P61; LEE YC, 1987, IEEE COMPUT GRAPH, V7, P20, DOI 10.1109/MCG.1987.277024; MAREFAT M, 1990, IEEE T PATTERN ANAL, V12, P949, DOI 10.1109/34.58868; Nnaji B. O., 1990, (AI EDAM) Artificial Intelligence for Engineering Design, Analysis and Manufacturing, V4, P15, DOI 10.1017/S0890060400002225; VANDENBRANDE JH, 1993, DEC IEEE T PATT AN M, V15; WOO TC, 1982, MAR P C CAD CAM TECH, P76	11	20	31	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1228	1233		10.1109/34.476517	http://dx.doi.org/10.1109/34.476517			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500012
J	PANKANTI, S; JAIN, AK				PANKANTI, S; JAIN, AK			INTEGRATING VISION MODULES - STEREO, SHADING, GROUPING, AND LINE LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STEREO; SHAPE FROM SHADING; PERCEPTUAL ORGANIZATION; LINE LABELING; INTEGRATION; FUSION	FRAMEWORK	It is generally agreed that individual visual cues are fallible and often ambiguous. This has generated a lot of interest in design of integrated vision systems which are expected to give a reliable performance in practical situations. The design of such systems is challenging since each vision module works under a different and possibly conflicting set of assumptions. We have proposed and implemented a multiresolution system which integrates perceptual organization (grouping), segmentation, stereo, shape from shading, and line labeling modules. We demonstrate the efficacy of our approach using images of several different realistic scenes. The output of the integrated system is shown to be insensitive to the constraints imposed by the individual modules. The numerical accuracy of the recovered depth is assessed in case of synthetically generated data. Finally, we have qualitatively evaluated our approach by reconstructing geons from the depth data obtained from the integrated system. These results indicate that integrated vision systems are likely to produce better reconstruction of the input scene than the individual modules.			PANKANTI, S (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; BLAKE A, 1989, SHAPE SHADING, P29; BOZMA HI, 1994, IEEE T PATTERN ANAL, V16, P1074, DOI 10.1109/34.334387; BULTHOFF HH, 1988, J OPT SOC AM A, V5, P1749, DOI 10.1364/JOSAA.5.001749; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cryer J. E., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P720, DOI 10.1109/CVPR.1993.341012; GRIMSON WEL, 1984, COMPUT VISION GRAPH, V28, P19, DOI 10.1016/0734-189X(84)90137-3; GROSSBERG S, 1988, NEURAL NETWORKS NATU; Horn B. K., 1989, SHAPE SHADING, P123; JEPSON A, 1992, IEEE T SYST MAN CYB, V22, P1087, DOI 10.1109/21.179846; Kass M., 1988, INT J COMPUT VISION, V1, P321; Leclerc Y. G., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P552, DOI 10.1109/CVPR.1991.139752; LEHMANN EL, 1975, NONPARAMETRICS; LOZANOPEREZ T, 1987, IEEE T ROBOTIC AUTOM, P202; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Marr D., 1982, VISION; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; NADABAR SG, 1992, P SOC PHOTO-OPT INS, V1708, P108, DOI 10.1117/12.58565; NALWA VS, 1988, INT J COMPUT VISION, V2, P103, DOI 10.1007/BF00133696; Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071; OLIENSIS J, 1991, CVGIP-IMAG UNDERSTAN, V54, P163, DOI 10.1016/1049-9660(91)90061-S; PANKANTI S, 1994, JUN P IEEE C COMP VI, P316; PANKANTI S, 1994, INTEGRATION VISION M; POGGIO T, 1985, NATURE, V317, P638; SARKAR S, 1993, IEEE T PATTERN ANAL, V15, P256, DOI 10.1109/34.204907; TRYTTEN DA, 1992, THESIS MICHIGAN STAT; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592	28	20	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					831	842		10.1109/34.406649	http://dx.doi.org/10.1109/34.406649			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900001
J	SALZBERG, S; DELCHER, AL; HEATH, D; KASIF, S				SALZBERG, S; DELCHER, AL; HEATH, D; KASIF, S			BEST-CASE RESULTS FOR NEAREST-NEIGHBOR LEARNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MACHINE LEARNING; NEAREST-NEIGHBOR; GEOMETRIC CONCEPTS		In this paper we propose a theoretical model for analysis of classification methods, in which the teacher knows the classification algorithm and chooses examples in the best way possible. We apply this model using the nearest-neighbor learning algorithm, and develop upper and lower bounds on sample complexity for several different concept classes. For some concept classes, the sample complexity turns out to be exponential even using this best-case model, which implies that the concept class is inherently difficult for the NN algorithm. We identify several geometric properties that make learning certain concepts relatively easy. Finally we discuss the relation of our work to helpful teacher models, its application to decision tree learning algorithms, and some of its implications for current experimental work.	LOYOLA COLL,DEPT COMP SCI,BALTIMORE,MD 21210	Loyola University Maryland	SALZBERG, S (corresponding author), JOHNS HOPKINS UNIV,DEPT COMP SCI,BALTIMORE,MD 21218, USA.		Salzberg, Steven/Q-6514-2019; Salzberg, Steven L/F-6162-2011	Salzberg, Steven/0000-0002-8859-7432; Salzberg, Steven L/0000-0002-8859-7432				Aha D, 1991, MACHINE LEARNING, V6; [Anonymous], 1992, C4 5 PROGRAMS MACHIN; BAKER BS, 1988, DISCRETE COMPUT GEOM, V3, P147, DOI 10.1007/BF02187904; BERN M, 1992, LATIN 92, P46; BERN M, 1991, 7TH ACM S COMPUTATIO, P342; BERN M, 1994, 10TH P ANN ACM S COM, P221; BHATTACHARYA B, 1992, SOCS9219 TECH REP; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179, DOI 10.1109/T-C.1974.223827; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; DASARATHY BV, 1991, NN NORMS NN PATTERN; Devijver P. A., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P343; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; FIX E, 1952, USAF11 SCH AV MED RE; GOLDMAN SA, 1991, 4TH P ANN WORKSH COM, P303; HART PE, 1968, IEEE T INFORMATION T, V14; HEATH D, 1992, GEOMETRIC FRAMEWORK; Minsky M., 1969, PERCEPTRONS; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; ROMANIK K, 1995, COMP GEOM-THEOR APPL, V5, P33, DOI 10.1016/0925-7721(94)00016-O; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; SALZBERG S, 1992, 9014 J HOPK U DEP CO; SALZBERG S, 1991, 12TH P INT JOINT C A, P705; Salzberg SL, 1990, LEARNING NESTED GENE; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; Toussaint G.T., 1984, P 16 S COMP SCI STAT, P97; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	30	20	20	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					599	608		10.1109/34.387506	http://dx.doi.org/10.1109/34.387506			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000005
J	SNYDER, W; HAN, YS; BILBRO, G; WHITAKER, R; PIZER, S				SNYDER, W; HAN, YS; BILBRO, G; WHITAKER, R; PIZER, S			IMAGE RELAXATION - RESTORATION AND FEATURE-EXTRACTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						GRADUATED NONCONVEXITY; ANISOTROPIC DIFFUSION; MEAN FIELD ANNEALING; IMAGE OPTIMIZATION	STOCHASTIC RELAXATION	The techniques of a posteriori image restoration and iterative image feature extraction are described and compared. Image feature extraction methods known as Graduated Nonconvexity (GNC), Variable Conductance Diffusion (VCD), Anisotropic Diffusion, and Biased Anisotropic Diffusion (BAD), which extract edges from noisy images, are compared with a restoration/feature extraction method known as Mean Field Annealing (MFA). Ail are shown to be performing the same basic operation: image relaxation, This equivalence shows the relationship between energy minimization methods and spatial analysis methods and between their respective parameters of temperature and scale. As a result of the equivalence, VCD is demonstrated to minimize a cost function, and that cost is specified explicitly. Furthermore, operations over scale space are shown to be a method of avoiding local minima.	BOWMAN GRAY SCH MED,DEPT RADIOL,WINSTON SALEM,NC; UNIV N CAROLINA,DEPT COMP SCI,CHAPEL HILL,NC	Wake Forest University; Wake Forest Baptist Medical Center; University of North Carolina; University of North Carolina Chapel Hill	SNYDER, W (corresponding author), N CAROLINA STATE UNIV,DEPT ELECT & COMP ENGN,RALEIGH,NC 27695, USA.							BESAG J, 1986, J ROY STAT SOC B MET, V48, P271; BILBRO G, 1990, J NEURAL NETWORK FAL; BILBRO G, 1991, IEEE T NEURAL NETWOR; BILBRO G, 1991, J OPTICAL SOC AM A, V8; BILBRO GL, 1989, ADV NEURAL NETWORK I; Brezin E., 1976, PHASE TRANSITIONS CR; Ganan Stuart, 1985, P STAT COMP SECT AM, P12; GEIGER D, 1989, COMMON FRAMEWORK IMA; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GROSSBERG S, 1984, PERCEPT PSYCHOPHYS, V36, P428; HAN YS, 1992, P SPIE 92 C NEURAL S; HEBERT T, 1989, IEEE T MED IMAGI JUN; HIRINYANNAIAH H, 1989, J OPT SOC AM A, P1901; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOLMOGOROV AN, 1957, AMS TRANSLATING, V2, P55; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; Perona P., 1990, IEEE T PATTERN ANAL, V12, P429; TERHAAR RB, 1994, GEOMETRY DRIVEN DIFF; WHITAKER RT, 1991, TR91039 U N CAR DEP; WOLBERG G, 1985, PATTERN RECOGN LETT, V3, P375, DOI 10.1016/0167-8655(85)90024-8; [No title captured]	23	20	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					620	624		10.1109/34.387509	http://dx.doi.org/10.1109/34.387509			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000007
J	COHEN, E; HULL, JJ; SRIHARI, SN				COHEN, E; HULL, JJ; SRIHARI, SN			CONTROL-STRUCTURE FOR INTERPRETING HANDWRITTEN ADDRESSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						TEXT PROCESSING; HANDWRITING RECOGNITION; IMAGE PROCESSING		This correspondence describes the control structure for an intelligent handwritten address interpretation system. The system takes a grey-level address image, segments the address into lines and words, parses the address into meaningful syntactic categories, recognizes words using dynamically generated lexicons, and determines the destination code with the aid of postal directories.	SUNY BUFFALO,CTR DOCUMENT ANAL & RECOGNIT,BUFFALO,NY 14260	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	COHEN, E (corresponding author), ACCUSORT SYST INC,511 SCH HOUSE RD,TELFORD,PA 18969, USA.		Srihari, Sargur N/E-8100-2011					COHEN E, 1991, CHARACTER HANDWRITIN, P221; COHEN E, 1992, 9206 STAT U NEW YORK; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P63	3	20	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					1049	1055		10.1109/34.329003	http://dx.doi.org/10.1109/34.329003			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827		Green Submitted			2022-12-18	WOS:A1994PM82700010
J	PAGLIERONI, DW; FORD, GE; TSUJIMOTO, EM				PAGLIERONI, DW; FORD, GE; TSUJIMOTO, EM			THE POSITION-ORIENTATION MASKING APPROACH TO PARAMETRIC SEARCH FOR TEMPLATE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CORRELATION INEQUALITY; DISTANCE TRANSFORM; EDGES; OBJECT DETECTION; POSITION-ORIENTATION MASKING; TEMPLATE MATCHING; VERTICES	RELAXATION	For applications such as object detection in high altitude aerial images, the image acquisition parameters can be used to deduce image scale but the objects can still occur at arbitrary position (x, y) and orientation theta. Even when the 3-D objects are modeled compactly as 2-D templates composed of line and curve segments that correlate with salient image features, template matching over all possible combinations of (x, y, theta) is prohibitively expensive. A new search method over (x, y, theta), called position-orientation masking is introduced. It is applied to vertices that are allowed to be separated into different bands of acuteness. Position-orientation masking yields exactly one theta value for each (x, y) that it considers to be the location of a possible occurrence of an object. Detailed matching of edge segments is performed at only these candidate (x, y, theta) to determine if objects actually do occur there. Template matching is accelerated dramatically since the candidates comprise only a small fraction of all (x, y, theta). Position-orientation masking eliminates the need for exhaustive search when deriving the candidate (x, y, theta). Search is guided by correlations between template vertices and distance transforms of image vertices. When a poor correlation is encountered at a particular position and orientation, nearby positions at that orientation and nearby orientations at that position are masked out. Position and orientation traversal are by quadrant and binary decomposition.	KLA INSTRUMENTS,SAN JOSE,CA 95164; UNIV CALIF DAVIS,DEPT ELECT & COMP ENGN,DAVIS,CA 95616	KLA Corporation; University of California System; University of California Davis			Ford, Gary/AAY-6405-2020	Ford, Gary/0000-0001-8719-4968				FORD GE, 1991, P SOC PHOTO-OPT INS, V1452, P244, DOI 10.1117/12.45387; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Paglieroni D. W., 1992, Machine Vision and Applications, V5, P47, DOI 10.1007/BF01213529; PAGLIERONI DW, 1987, PATTERN RECOGN, V20, P583, DOI 10.1016/0031-3203(87)90029-X; PRAGER JM, 1980, IEEE T PATTERN ANAL, V2, P16, DOI 10.1109/TPAMI.1980.4766966; ROSENFEL.A, 1966, J ACM, V13, P471; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHIRAI Y, 1975, 4TH P INT JOINT C AR, P674; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; [No title captured]	12	20	25	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					740	747		10.1109/34.297956	http://dx.doi.org/10.1109/34.297956			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134					2022-12-18	WOS:A1994NY13400008
J	WANG, Y; MITRA, SK				WANG, Y; MITRA, SK			IMAGE REPRESENTATION USING BLOCK PATTERN MODELS AND ITS IMAGE-PROCESSING APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE CODING; IMAGE INTERPOLATION; IMAGE MODELING; IMAGE SMOOTHING	VECTOR QUANTIZATION; COMPRESSION; INTERPOLATION	An image representation scheme using a set of block pattern models (BPM's) is introduced. These models consist of three categories (constant, oriented, and irregular), with the last one consisting of two subgroups: textured and mixed. They are constructed to represent three basic types of image patterns: shade, edge, and texture. Image representation using these models requires considerably fewer bits than the original pixel-wise description and yet characterizes perceptually significant features more effectively. In particular, the parameterization of the oriented model using oriented basis functions lays a mathematical foundation for designing directional operators that are desirable in many image processing applications. Algorithms for model classification, model parameter estimation, and image reconstruction from model parameters are presented, and these provide the necessary vehicles for applying the proposed representation scheme to various image processing tasks. The applications of the proposed models in image coding, image zooming, and image smoothing are described. The coding system approximates each image block by a BPM and further quantizes the model parameters. Satisfactory coded images have been obtained at bit rates between 0.5 - 0.6 bpp (bits per pixel) with a high-rate realization and between 0.3 - 0.5 bpp with a low-rate realization. The high-rate realization has a simple structure suitable for real-time implementation. The methods for image zooming and smoothing are similar, where both adapt the processing for each pixel according to the model of its neighborhood. By using directional filters in oriented regions, edges and lines are rendered sharper in a smoother manner than with conventional linear filtering approaches, which leads to significant improvement in perceived image quality.	UNIV CALIF SANTA BARBARA, DEPT ELECT & COMP ENGN, SANTA BARBARA, CA 93106 USA	University of California System; University of California Santa Barbara	WANG, Y (corresponding author), POLYTECH INST NEW YORK, DEPT ELECT ENGN, BROOKLYN, NY 11201 USA.			Wang, Yao/0000-0003-3199-3802				CARLSSON S, 1988, SIGNAL PROCESS, V15, P57, DOI 10.1016/0165-1684(88)90028-X; CHELLAPPA R, 1985, PROGR PATTERN RECOGN; CHEN D, 1989, P SPIE VISUAL COMMUN, P1461; CHEN DP, 1990, IEEE T COMMUN, V38, P2137, DOI 10.1109/26.64656; Cheng-Tie Chen, 1991, Journal of Visual Communication and Image Representation, V2, P1, DOI 10.1016/1047-3203(91)90031-A; Cornsweet T., 1970, VISUAL PERCEPTION; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560; FORCHHEIMER R, 1989, IEEE T ACOUST SPEECH, V37, P2008, DOI 10.1109/29.45550; FORCHHEIMER R, 1989, IEEE T ACOUST SPEECH, V1, P119; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; GRISWOLD NC, 1987, IEEE T ACOUST SPEECH, V35, P1201, DOI 10.1109/TASSP.1987.1165260; HALVERSON DR, 1984, IEEE T ACOUST SPEECH, V32, P664, DOI 10.1109/TASSP.1984.1164341; HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508; Hubel D. H., 1979, Scientific American, V241, P130; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JAIN AK, 1981, P IEEE, V69, P349, DOI 10.1109/PROC.1981.11971; JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021; KOCHER M, 1982, MAY P ICASSP 82 PAR, P436; KUNT M, 1987, IEEE T CIRCUITS SYST, V34, P1306, DOI 10.1109/TCS.1987.1086071; KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184; LLOYD PS, 1982, IEEE T INFORM THEORY, V28; MARTINEZ DM, 1989, MAY P IEEE INT C AC, P1886; MUSMANN HG, 1985, P IEEE, V73, P523, DOI 10.1109/PROC.1985.13183; MUSMANN HG, 1989, SIGNAL PROCESS-IMAGE, V1, P119; NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776; NETRAVALI AN, 1980, P IEEE, V68, P366, DOI 10.1109/PROC.1980.11647; Olzak L.A., 1986, HDB PERCEPTION HUMAN; RAMAMURTHI B, 1986, IEEE T COMMUN, V34, P1105, DOI 10.1109/TCOM.1986.1096468; ROSENFIELD A, 1981, IMAGE MODELING; SCHREIBER WF, 1959, J SMPTE, V68, P525; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; VAISEY J, 1989, THESIS U CALIFORNIA; WANG Y, 1989, AUG P IEEE INT C SYS, P81; WANG Y, 1991, MAY P IEEE INT C AC, P2829; WANG Y, 1988, APR P IEEE INT C AC, P1320; WANG Y, 1991, MAY P IEEE INT C AC, P2569; WANG Y, 1990, THESIS U CALIFORNIA; WANG Y, 1988, SEP P EUR SIGN PROC, P1445	40	20	26	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1993	15	4					321	336		10.1109/34.206953	http://dx.doi.org/10.1109/34.206953			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU543					2022-12-18	WOS:A1993KU54300001
J	TAALEBINEZHAAD, MA				TAALEBINEZHAAD, MA			DIRECT RECOVERY OF MOTION AND SHAPE IN THE GENERAL-CASE BY FIXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						DIRECT METHOD; FIXATION; LEAST-SQUARES; MOTION; SHAPE	PASSIVE NAVIGATION; OPTICAL-FLOW; TRACKING	A direct method called fixation is introduced for solving the general motion vision problem: arbitrary motion relative to an arbitrary environment. This method results in a linear constraint equation that explicitly expresses the rotational velocity in terms of the translational velocity. The combination of this constraint equation with the brightness-change constraint equation (BCCE) solves the general motion vision problem. Avoiding correspondence and optical flow has been the motivation behind this direct method, which uses the image brightness information such as temporal and spatial brightness gradients directly. In contrast with previous direct methods, the fixation method does not put any severe restrictions on the motion or the environment. Moreover, the fixation method neither requires tracked images as its input nor uses tracking for obtaining fixated images. Instead, it introduces a pixel shifting process to construct fixated images for any arbitrary fixation point. This is done entirely in software without any use of camera motion for tracking.			TAALEBINEZHAAD, MA (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALOIMONOS J, 1989, INTEGRATION VISUAL M; ALOIMONOS J, 1986, JUN P IEEE C COMP VI; ALOIMONOS J, 1988, CARTR390 U MAR COMP; BAHIL AT, 1984, AM SCI, V72, P219; BAHILL AT, 1983, BIOL CYBERN, V48, P213, DOI 10.1007/BF00318089; BALLARD DH, 1983, COMPUTER VISION, V22; BANDOPADHAY A, 1986, MAY P WORKSH MOT REP, P23; BANDOPADHAY A, 1986, COMPUTATIONAL STUDY; BARRON J, 1984, RBCVTR845 U TOR; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; CORNELIUS N, 1983, CMUCS83119 CARN U; GENNERT MA, 1987, MIT AI975 ART INT LA; HALLERT B, 1960, PHOTOGRAMMETRY; Hildreth E., 1984, MEASUREMENT VISUAL M; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Moffit F.H., 1980, PHOTOGRAMMETRY, V3rd Ed.; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; NEGAHDARIPOUR S, 1989, SEP P INT C IM PROC, P806; PRAZDNY K, 1979, 6TH P INT JOINT C AR; SANDINI G, 1990, IEEE T PATTERN ANAL, V12, P13, DOI 10.1109/34.41380; TAALEBINEZHAAD M, 1980, PERCEPTION, V9, P617; TAALEBINEZHAAD M, 1979, INTERPRETATION VISUA; TAALEBINEZHAAD MA, 1991, JUN P IEEE C COMP VI; THOMPSON WB, 1989, BIOL CYBERN, V62, P113, DOI 10.1007/BF00202999; WAXMAN AM, 1988, ADV COMPUTER VISION, V1, P165	29	20	20	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1992	14	8					847	853		10.1109/34.149584	http://dx.doi.org/10.1109/34.149584			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JG613		Green Submitted			2022-12-18	WOS:A1992JG61300006
J	LIOU, SP; CHIU, AH; JAIN, RC				LIOU, SP; CHIU, AH; JAIN, RC			A PARALLEL TECHNIQUE FOR SIGNAL-LEVEL PERCEPTUAL ORGANIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ALPHA-PARTITIONING; HYPOTHESIS TESTING; IMAGE SEGMENTATION; PARALLEL ALGORITHM; PERCEPTUAL ORGANIZATION; POLYNOMIAL REGRESSION; REGION FILTERING; SURFACE FITTING	SEGMENTATION; IMAGES	Due to the potential for essentially unbounded scene complexity, it is often necessary to translate the sensor-derived signals into richer symbolic representations. A key initial stage in this abstraction process is signal-level perceptual organization (SLPO) involving the processes of partitioning and identification. We present the parallel SLPO algorithm that follows the global hypothesis testing paradigm, but breaks the iterative structure of conventional region growing through the use of alpha-partitioning and region filtering. These two techniques segment an image such that the gray-level variation within each region can be described by a regression model. Experimental results demonstrate the effectiveness of this algorithm.			LIOU, SP (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ARTIFICIAL INTELLIGENCE LAB,ANN ARBOR,MI 48109, USA.							BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; BROOK RJ, 1985, APPLIED REGRESSION A; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; ESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUNT BR, 1980, COMPUT VISION GRAPH, V12, P173, DOI 10.1016/0146-664X(80)90010-6; LIOU SP, 1989, COMPUT VISION GRAPH, V45, P227, DOI 10.1016/0734-189X(89)90134-5; MORGENTHALER DG, 1981, IEEE T PATTERN ANAL, V3, P482, DOI 10.1109/TPAMI.1981.4767134; PERKINS WA, 1980, IEEE T PATTERN ANAL, V2, P8, DOI 10.1109/TPAMI.1980.4766965; PONG TC, 1984, COMPUT VISION GRAPH, V25, P1, DOI 10.1016/0734-189X(84)90046-X; SOLINA F, 1987, THESIS U PENNSYLVANI; TERZOPOLIS D, 1987, 1ST P INT C COMP VIS, P269; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105; [No title captured]	18	20	20	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					317	325		10.1109/34.88567	http://dx.doi.org/10.1109/34.88567			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600002
J	MATTHEWS, G; HEARNE, J				MATTHEWS, G; HEARNE, J			CLUSTERING WITHOUT A METRIC	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CLUSTERING; CLUSTER VALIDITY; MULTIVARIATE DATA; PROXIMITY INDEXES; UNSUPERVISED LEARNING		We describe a methodology for clustering data in which a distance metric or similarity function is not used. Instead, clusterings are optimized based on their intended function: the accurate prediction of properties of the data. The resulting clustering methodology is applicable, without further ad hoc assumptions or transformations of the data 1) when features are heterogeneous (both discrete and continuous) and not combinable, 2) where some data points have missing feature values, and 3) where some features are irrelevant, i.e., have large variance but little correlation with other features. Further, it provides an integral measure of the quality of the resulting clustering. We have implemented a clustering program, RIFFLE, in line with this approach, and experiments with synthetic and real data show that the clustering is, in many respects, superior to traditional methods.			MATTHEWS, G (corresponding author), WESTERN WASHINGTON STATE UNIV,DEPT COMP SCI,BELLINGHAM,WA 98225, USA.							BAYNE CK, 1980, PATTERN RECOGN, V12, P51, DOI 10.1016/0031-3203(80)90002-3; CHEESEMAN P, 1988, 5TH P INT C MACH LEA; DUBES RC, 1987, PATTERN RECOGN, V20, P645, DOI 10.1016/0031-3203(87)90034-3; EHINGER WJ, 1988, THESIS W WASHINGTON; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GOODMAN LA, 1972, J AM STAT ASSOC, V67, P415, DOI 10.2307/2284396; GOODMAN LA, 1959, J AM STAT ASSOC, V54, P123, DOI 10.2307/2282143; GOODMAN LA, 1963, J AM STAT ASSOC, V58, P310, DOI 10.2307/2283271; GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536; GUTTMAN L, 1941, OUTLINE STATISTICAL; HENRICHON EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Linthurst R, 1986, CHARACTERISTICS LAKE, V1; MATTHEWS GB, 1988, ANN C INT SOC ECOLOG; MATTHEWS RA, 1990, ANN C N AM BENTH SOC; Michalski R.S., 1983, MACHINE LEARNING ART, P331; Olshen R., 1984, CLASSIFICATION REGRE; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Sonquist JA, 1973, SEARCHING STRUCTURE	20	20	23	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					175	184		10.1109/34.67646	http://dx.doi.org/10.1109/34.67646			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900006
J	GMYTRASIEWICZ, P; HASSBERGER, JA; LEE, JC				GMYTRASIEWICZ, P; HASSBERGER, JA; LEE, JC			FAULT TREE BASED DIAGNOSTICS USING FUZZY-LOGIC	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GMYTRASIEWICZ, P (corresponding author), UNIV MICHIGAN,DEPT NUCL ENGN,ANN ARBOR,MI 48109, USA.							Dubois D., 1980, FUZZY SET SYST; KOLACZKOWSKI AM, 1989, NUREGCR4550 SAND N 2, V4; McCormick N.J, 1981, RELIABILITY RISK ANA; PAPPIS CP, 1985, FUZZY SET SYST, V15, P79, DOI 10.1016/0165-0114(85)90036-3; SANCHEZ E, 1976, INFORM CONTROL, V30, P38, DOI 10.1016/S0019-9958(76)90446-0; Sanchez E., 1977, FUZZY AUTOMATA DECIS; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZIMMERMANN HJ, 1985, FUZZY SET THEORT ITS; [No title captured]	9	20	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1115	1119		10.1109/34.61713	http://dx.doi.org/10.1109/34.61713			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700011
J	NEGAHDARIPOUR, S				NEGAHDARIPOUR, S			MULTIPLE INTERPRETATIONS OF THE SHAPE AND MOTION OF OBJECTS FROM 2 PERSPECTIVE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NEGAHDARIPOUR, S (corresponding author), UNIV HAWAII MANOA,DEPT ELECT ENGN,HONOLULU,HI 96822, USA.							BRUSS AR, 1983, COMPUT VISION GRAPHI, V21; FAUGERAS O, 1989, MAR P IEEE WORKSH VI; HAY JC, 1966, PSYCHOL REV, V73; HORN BKP, 1987, INT J COMPUT VISION, V1; HORN BKP, 1987, MIT AI994 ART INT LA; LONGUETHIGGINS HC, 1984, P ROY SOC LONDON B, V223; LONGUETHIGGINS HC, 1981, NATURE, V293; LONGUETHIGGINS HC, 1980, P ROY SOC LONDON B, V208; LONGUETHIGGINS HC, 1988, P ROY SOC LONDON A, V418; MAYBANK SJ, 1989, PROJECTIVE GEOMETRY; MAYBANK SJ, 1985, P ROC SOC LONDON A, V401; NEGAHDARIPOUR S, 1989, INT J COMPUT VISION, V3; NEGAHDARIPOUR S, 1987, 1ST P INT C COMP VIS; NEGAHDARIPOUR S, 1990, J OPT SOC AM A, V7; NETRAVALI AN, 1988, ALGEBRAIC METHODS 3; PRAZDNY K, 1979, 6TH P INT C ART INT; SPAIN B, 1960, ANAL QUADRICS; TSAI RY, 1984, IEEE T PATT ANAL MAC, V6; ULLMAN S, 1983, MIT AI706 ART INT LA; WAXMAN AM, 1987, INT J COMPUT VISION, V1	20	20	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1025	1039		10.1109/34.61703	http://dx.doi.org/10.1109/34.61703			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700001
J	SHERMAN, D; PELEG, S				SHERMAN, D; PELEG, S			STEREO BY INCREMENTAL MATCHING OF CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SHERMAN, D (corresponding author), HEBREW UNIV JERUSALEM, DEPT COMP SCI, IL-91904 JERUSALEM, ISRAEL.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				Arnold R. D., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P281; AYACHE N, 1985, 3RD P WORKSH COMP VI, P27; AYACHE N, 1988, P INT C PATT REC, P11; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BAKER HH, 1983, JUN P IM UND WORKSH, P327; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; FAUGERAS OD, 1986, JUN P IEEE C COMP VI, P15; GENNERY D, 1979, P 10 IM UND WORKSH, P101; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1980, APR P DARPA IM UND W, P128; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; Wong K. W., 1980, MANUAL PHOTOGRAMMETR	21	20	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1102	1106		10.1109/34.61711	http://dx.doi.org/10.1109/34.61711			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700009
J	CHEN, HH; HUANG, TS				CHEN, HH; HUANG, TS			MATCHING 3-D LINE SEGMENTS WITH APPLICATIONS TO MULTIPLE-OBJECT MOTION ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign				Chen, Homer/0000-0002-8795-1911				ABDELAZIZ YI, 1971, JAN P ASP UI S CLOS; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BALLARD DH, 1983, IEEE T PATTERN ANAL, V5, P653, DOI 10.1109/TPAMI.1983.4767456; Binford T. O., 1982, INT J ROBOT RES, V1, P18; BOYTER BA, 1986, IEEE EXPERT, P47; BURR DJ, 1977, R805 U ILL COORD SCI; CHEN HH, 1988, PATTERN RECOGN, V21, P75, DOI 10.1016/0031-3203(88)90016-7; CHEN HH, 1989, MAR P IEEE WORKSH VI, P290; CHENG JK, 1980, 8083 PURD U SCH EL E; Clark C. S., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P217; DAVIS LS, 1982, PATTERN RECOGN, V15, P277, DOI 10.1016/0031-3203(82)90030-9; Faugeras O. D., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P218; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Foley J. D., 1982, FUNDAMENTALS INTERAC, P2; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; Hebert M., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P458; HERMAN M, 1985, JUN P C COMP VIS PAT, P585; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; Horn B., 1986, ROBOT VISION, P1; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; HUANG TS, 1986, IEEE P WORKSHOP MOTI, P45; KIM YC, 1988, IEEE J ROBOTIC AUTOM, V3, P599; LOZANOPEREZ T, 1983, IEEE T COMPUT, V32, P108, DOI 10.1109/TC.1983.1676196; MAGEE MJ, 1985, IEEE T PATTERN ANAL, V7, P629, DOI 10.1109/TPAMI.1985.4767719; MEDIONI G, 1984, IEEE T PATTERN ANAL, V6, P675, DOI 10.1109/TPAMI.1984.4767592; MURRAY DW, 1988, INT J COMPUT VISION, V2, P153, DOI 10.1007/BF00133698; OROURKE J, 1981, P IEEE C PATTERN REC, P82; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; TANAKA HT, 1985, JUN P C COMP VIS PAT, P491; [No title captured]	31	20	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1990	12	10					1002	1008		10.1109/34.58872	http://dx.doi.org/10.1109/34.58872			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EA042					2022-12-18	WOS:A1990EA04200006
J	WEISS, I				WEISS, I			SHAPE RECONSTRUCTION ON A VARYING MESH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WEISS, I (corresponding author), UNIV MARYLAND,AUTOMAT RES CTR,COLLEGE PK,MD 20742, USA.							[Anonymous], 1974, COMPUTER AIDED GEOME; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BRADY M, 1984, IEEE T PATTERN ANAL, V6; BRADY M, 1984, MIT AI757 MEM; BRADY M, 1984, 2ND P S ROB RES KYOT; COURANT R, 1953, METHODS MATH PHYSICS, V1; DAVIS L, 1982, TR1133 U MAR COMP VI; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; GRIMSON WEL, 1981, MIT AI663 MEM; HORN BKP, 1983, ACM T MATH SOFTWARE, P441; Kass M., 1987; Marr D., 1982, VISION; Pavlidis T., 1977, STRUCTURAL PATTERN R; POGGIO T, 1987, P IMAGE UNDERSTANDIN; Rosenfeld A., 1982, DIGITAL PICTURE PROC; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; Strang G., 1973, ANAL FINITE ELEMENT; TERZOPOULOS D, 1985, MIT AI800 MEM; TERZOPOULOS D, 1982, MIT AI671 MEM; WEISS I, 1988, COMPUT VISION GR JAN; WEISS I, 1986, CARTR22 U MAR COMP V; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; YOUNG DM, 1973, SURVEY NUMERICAL MAT, V2; YOUNG DM, 1973, SURVEY NUMERICAL MAT, V1	26	20	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1990	12	4					345	362		10.1109/34.50621	http://dx.doi.org/10.1109/34.50621			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CV929					2022-12-18	WOS:A1990CV92900002
J	PENNA, MA				PENNA, MA			A SHAPE FROM SHADING ANALYSIS FOR A SINGLE PERSPECTIVE IMAGE OF A POLYHEDRON	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PENNA, MA (corresponding author), PURDUE UNIV,DEPT MATH SCI,INDIANAPOLIS,IN 46223, USA.							Ballard D.H., 1982, COMPUTER VISION; BANCHOFF T, 1967, J DIFFER GEOM, V1, P245; BARNARD ST, 1982, SEP P IM UND WORKSH, P193; Burden RL, 1981, NUMERICAL ANAL; Chen S., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P452; CHEN S, 1986, 5TH P INT ROB COMP V, V726, P115; CHEN S, 1986, 4TH P ANN C INT SYST, P83; CHEN SS, 1986, COMPUT VISION GRAPH, V36, P175, DOI 10.1016/0734-189X(86)90075-7; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; HOMMA T, 1970, P C MANIFOLDS, P111; HORN B, 1977, ARTIF INTELL, V8, P203; Horn B., 1986, ROBOT VISION, P1; HORN B, 1970, AI79 MIT TECH REP; HUFFMAN DA, MACHINE INTELLIGENCE, V6; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; KANADE T, 1980, AUG P IEEE WORKSH PI, P130; MACKWORTH AK, 1976, PERCEPTION, V5, P349, DOI 10.1068/p050349; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; PENNA M, IN PRESS DETERMINING; PENNA M, IN PRESS LOCAL SEMI; PENNA M, IN PRESS IMAGE UNDER; Penna M.A., 1986, PROJECTIVE GEOMETRY; PENNA MA, 1986, IJIS, V1, P263; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; REGGE T, 1961, NUOVO CIMENTO, V19, P558, DOI 10.1007/BF02733251; RICHARDS WA, 1982, PERCEPTION, V11, P557, DOI 10.1068/p110557; ROSENFELD A, 1986, DIGITAL IMAGE PROCES; Spivak M.D., 1970, CALCULUS; SUGIHARA K, 1978, COMPUT VISION GRAPH, V8, P382, DOI 10.1016/0146-664X(78)90064-3; SUGIHARA K, 1982, PERCEPTION, V11, P65, DOI 10.1068/p110065; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; WALTZ D, 1975, MACTR271 TECH REP; WEBB JA, 1983, COMPUT VISION GRAPH, V21, P145, DOI 10.1016/S0734-189X(83)80032-2	35	20	23	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					545	554		10.1109/34.24790	http://dx.doi.org/10.1109/34.24790			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749					2022-12-18	WOS:A1989U674900001
J	NAGY, G; SETH, S; EINSPAHR, K				NAGY, G; SETH, S; EINSPAHR, K			DECODING SUBSTITUTION-CIPHERS BY MEANS OF WORD MATCHING WITH APPLICATION TO OCR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV NEBRASKA,DEPT COMP SCI,LINCOLN,NE 68588	University of Nebraska System; University of Nebraska Lincoln	NAGY, G (corresponding author), RENSSELAER POLYTECH INST,DEPT ELECT COMP & SYST ENGN,TROY,NY 12180, USA.			Nagy, George/0000-0002-0521-1443				ALBERGA CN, 1967, COMMUN ACM, V10, P302, DOI 10.1145/363282.363326; [Anonymous], 1980, PRINCIPLES ARTIFICIA; BAHL L, 1977, P IEEE INT S INFORMA; Blair CR., 1960, INF CONTROL, V3, P60; CASEY R, 1984, JUL P ICPR 7 MONTR; CASEY R, 1968, IEEE T COMPUT, V7; CASEY RG, 1971, SCI AM, V224, P56, DOI 10.1038/scientificamerican0471-56; CASEY RG, 1986, P ICPR 8 PARIS, P349; CHEN MT, 1984, COMPUTER RES REV; HUNTER DGN, 1983, COMPUT J, V26, P68, DOI 10.1093/comjnl/26.1.68; NAGY G, 1983, IEEE COMPUT, P13; Nagy G, 1982, HDB STATISTICS, V2, P621; NAGY G, 1984, P 7 INT C PATT REC M, P347; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; OMARA KS, 1980, APPLIED SYSTEMS CYBE, V5; PELEG S, 1979, COMMUN ACM, V22, P598, DOI 10.1145/359168.359174; PETERSON JL, 1980, COMMUN ACM, V23, P676, DOI 10.1145/359038.359041; Rich E., 1983, ARTIF INTELL; ROBERTS CS, 1979, P IEEE, V67; STANTON T, 1986, PC MAG, V5, P128; TANAKA E, 1986, P ICPR 8 PARIS, P340; Winston P. H., 1977, ARTIFICIAL INTELLIGE; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; [No title captured]	24	20	37	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					710	715		10.1109/TPAMI.1987.4767969	http://dx.doi.org/10.1109/TPAMI.1987.4767969			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869433	Green Published			2022-12-18	WOS:A1987J739300016
J	HO, SB; DYER, CR				HO, SB; DYER, CR			SHAPE SMOOTHING USING MEDIAL AXIS PROPERTIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											HO, SB (corresponding author), UNIV WISCONSIN,DEPT COMP SCI,MADISON,WI 53706, USA.							Badler N. I., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P286; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BRADY M, 1982, P SOC PHOTO-OPT INST, V336, P20, DOI 10.1117/12.933607; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Duda R.O., 1973, J ROYAL STAT SOC SER; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543	8	20	21	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					512	519		10.1109/TPAMI.1986.4767815	http://dx.doi.org/10.1109/TPAMI.1986.4767815			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000010
J	RADA, R				RADA, R			GRADUALNESS FACILITATES KNOWLEDGE REFINEMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											RADA, R (corresponding author), NATL LIB MED,BETHESDA,MD 20209, USA.							ACKERMAN LV, 1984, P SOC PHOTO-OPT INST, V454, P443, DOI 10.1117/12.939365; [Anonymous], 1983, DATA STRUCTURES ALGO; Austin D., 1984, PRECIS MANUAL CONCEP; BANERJI RB, 1982, P IEEE, V70, P1428, DOI 10.1109/PROC.1982.12503; Barr A, 1981, HDB ARTIFICIAL INTEL, VI; BERLINER H, 1979, P IJCAI 79 TOKYO, P53; BERNSTEIN LM, 1984, J AM SOC INFORM SCI, V35, P235, DOI 10.1002/asi.4630350407; BETHKE AD, 1980, THESIS U MICHIGAN; BRACHMAN RJ, 1983, COMPUTER, V16, P30, DOI 10.1109/MC.1983.1654194; Carbonell J.G., 1983, MACHINE LEARNING ART, P243, DOI [10.1016/B978-0-08-051054-5.50013-3, DOI 10.1016/B978-0-08-051054-5.50013-3]; CARBONELL JG, 1983, MACHINE LEARNING ART, P137; Cohen P. R., 1983, AI MAG, V4, P17; CONRAD M, 1979, BIOSYSTEMS, V11, P167, DOI 10.1016/0303-2647(79)90009-1; Conrad M, 1983, ADAPTABILITY SIGNIFI; Darden L., 1982, PSA, P147; DIETTERICH TG, 1982, HDB ARTIFICIAL INTEL, V3, P323; DOYLE J, 1983, AI MAG, V4, P39; DUDA RO, 1976, AM FEDERATION INFORM, V45, P1075; Ernst G, 1969, GPS CASE STUDY GEN P; FIDEL R, 1984, J AM SOC INFORM SCI, V35, P211, DOI 10.1002/asi.4630350404; FINKEL A, 1981, CURRENT MED INFORMAT; Holland, 1983, P 2 INT WORKSH MACH, P92; HOLLAND J, 1975, ADAPTATION NATURAL A; LENAT DB, 1982, ARTIF INTELL, V19, P189, DOI 10.1016/0004-3702(82)90036-4; MCCARN DB, 1980, J AM SOC INFORM SCI, V31, P181, DOI 10.1002/asi.4630310310; Minsky M., 1969, PERCEPTRONS; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MITCHELL TM, 1983, MACH LEARN, P163; PEARL J, 1983, AI MAG, V4, P23; POLITAKIS P, 1984, ARTIF INTELL, V22, P23, DOI 10.1016/0004-3702(84)90024-9; RADA R, 1981, BIOSYST, P211; RADA R, 1981, THESIS U ILLINOIS UR; RADA R, 1983, P INT JOINT C ARTIFI, P780; Rosenbloom P. S., 1984, Proceedings of the IEEE Workshop on Principles of Knowledge-Based Systems (Cat. No. 84CH2104-8), P65; SALTON G, 1983, INTRO MODERN INFORMA; SCHANK RC, 1981, INFORMATION RETRIEVA, P94; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; TONG R, 1983, P INT JOINT C ARTIFI, P194; van Melle W., 1979, P 6 INT JOINT C ART, V2, P923	39	20	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					523	530		10.1109/TPAMI.1985.4767700	http://dx.doi.org/10.1109/TPAMI.1985.4767700			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AQH94	21869290				2022-12-18	WOS:A1985AQH9400004
J	ROSENBLOOM, PS; LAIRD, JE; MCDERMOTT, J; NEWELL, A; ORCIUCH, E				ROSENBLOOM, PS; LAIRD, JE; MCDERMOTT, J; NEWELL, A; ORCIUCH, E			R1-SOAR - AN EXPERIMENT IN KNOWLEDGE-INTENSIVE PROGRAMMING IN A PROBLEM-SOLVING ARCHITECTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,DEPT PSYCHOL,STANFORD,CA 94305; XEROX CORP,PALO ALTO RES CTR,PALO ALTO,CA 94304; CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213; DIGITAL EQUIPMENT CORP,MAYNARD,MA 01754	Stanford University; Xerox; Carnegie Mellon University	ROSENBLOOM, PS (corresponding author), STANFORD UNIV,DEPT COMP SCI,STANFORD,CA 94305, USA.			Laird, John/0000-0001-7446-3241				BACHANT J, 1984, AI MAG, V5; BROWN JS, 1980, COGNITIVE SCI, V4, P379, DOI 10.1207/s15516709cog0404_3; CHANDRASEKARAN B, 1983, INT J MAN MACH STUD, V19, P425, DOI 10.1016/S0020-7373(83)80064-9; FORGY C, 1984, P NAT C ARTIF INTELL; FORGY CL, 1981, 81135 CARN U DEP COM; GUPTA A, 1983, 83167 CARN U DEP COM; HART PE, 1982, SIGART NEWSL, V79, P11; Hayes-Roth F, 1983, BUILDING EXPERT SYST; LAIRD JE, 1985, UNPUB SOAR ARCHITECT; LAIRD JE, 1983, 83141 CARN U DEP COM; LAIRD JE, 1984, P NAT C ARTIF INTELL; LAIRD JE, 1983, 8TH P INT JOINT C AR; LAIRD JE, 1983, 84129 CARN U DEP COM; MCDERMOTT J, 1982, ARTIF INTELL, V19; NEWELL A, 1980, 80145 CARN U DEP COM; Newell A., 1969, PROGR OPERATIONS RES; NEWELL A, 1981, COGNITIVE SKILLS THE; ROSENBLOOM PS, 1985, MACHINE LEARNING ART, V2; ROSENBLOOM PS, 1983, 83148 CARN U DEP COM; Shortliffe E.H., 2012, COMPUTER BASED MED C	20	20	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					561	569		10.1109/TPAMI.1985.4767703	http://dx.doi.org/10.1109/TPAMI.1985.4767703			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AQH94	21869293				2022-12-18	WOS:A1985AQH9400007
J	STILES, GS; DENQ, DL				STILES, GS; DENQ, DL			ON THE EFFECT OF NOISE ON THE MOORE-PENROSE GENERALIZED INVERSE ASSOCIATIVE MEMORY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											STILES, GS (corresponding author), UTAH STATE UNIV,DEPT ELECT ENGN,LOGAN,UT 84322, USA.							BENISRAEL A, 1974, GENERALIZED INVERSES; KOHONEN T, 1973, IEEE T COMPUT, VC 22, P701, DOI 10.1109/TC.1973.5009138; Kohonen T, 1977, ASS MEMORY SYSTEM TH; MURAKAMI K, 1981, IEEE T PATTERN ANAL, V3, P210, DOI 10.1109/TPAMI.1981.4767083; Noble B, 1969, APPL LINEAR ALGEBRA; RUST B, 1966, COMMUN ACM, V9, P381, DOI 10.1145/355592.365659; STILES GS, 1983, UNPUB IEEE T COMPUT	7	20	20	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					358	360		10.1109/TPAMI.1985.4767667	http://dx.doi.org/10.1109/TPAMI.1985.4767667			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869273				2022-12-18	WOS:A1985AFM4400013
J	SAMET, H; WEBBER, RE				SAMET, H; WEBBER, RE			ON ENCODING BOUNDARIES WITH QUADTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	SAMET, H (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							BALLARD DH, 1981, COMMUN ACM, V24, P310, DOI 10.1145/358645.358661; BURTON W, 1977, COMMUN ACM, V20, P166, DOI 10.1145/359436.359445; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; KLINGER A, 1971, OPTIMIZING METHODS S, P303; Knuth D.E, 1975, ART COMPUTER PROGRAM, V1; SAMET H, 1982, TR1162 U MAR DEP COM; SAMET H, 1982, TR1237 U MAR DEP COM; SHNEIER M, 1981, COMPUT VISION GRAPH, V17, P211, DOI 10.1016/0146-664X(81)90002-2; [No title captured]	12	20	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					365	369		10.1109/TPAMI.1984.4767529	http://dx.doi.org/10.1109/TPAMI.1984.4767529			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869203				2022-12-18	WOS:A1984SR54200012
J	SANKAR, PV; SKLANSKY, J				SANKAR, PV; SKLANSKY, J			A GESTALT-GUIDED HEURISTIC BOUNDARY FOLLOWER FOR X-RAY IMAGES OF LUNG NODULES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SANKAR, PV (corresponding author), UNIV CALIF IRVINE,SCH ENGN,IRVINE,CA 92717, USA.							ASHKAR GP, 1978, COMPUT VISION GRAPH, V7, P331, DOI 10.1016/S0146-664X(78)80002-1; BALLARD DH, 1976, IEEE T COMPUT, V25, P503, DOI 10.1109/TC.1976.1674638; BALLARD DH, 1974, THESIS U CALIFORNIA; JELINEK F, 1969, IBM J RES DEV, V13; KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677; Knuth D., 1973, ART COMPUTER PROGRAM, V3; LESTER JM, 1978, COMPUT BIOL MED, V8, P293, DOI 10.1016/0010-4825(78)90030-6; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; Nilsson N.J., 1971, PROBLEM SOLVING METH; Robinson G.S., 1977, COMPUT VISION GRAPH, V6, P492, DOI 10.1016/s0146-664x(77)80024-5; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1979, 6TH P C COMP APPL RA, P249; WESCHER H, 1977, PATTERN RECOG, V9, P21; Zigangirov K, 1966, PROBLEMY PEREDACHI I, V2, P13	15	20	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					326	331		10.1109/TPAMI.1982.4767253	http://dx.doi.org/10.1109/TPAMI.1982.4767253			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869043				2022-12-18	WOS:A1982NN06900014
J	WONG, AKC; GHAHRAMAN, DE				WONG, AKC; GHAHRAMAN, DE			RANDOM GRAPHS - STRUCTURAL-CONTEXTUAL DICHOTOMY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,CARNEGIE INST TECHNOL,PITTSBURGH,PA 15213	Carnegie Mellon University	WONG, AKC (corresponding author), UNIV WATERLOO,DEPT SYST DESIGN,WATERLOO N2L 3G1,ONTARIO,CANADA.							ACZEL J, 1975, MEASURES INFORMATION; Aho A., 1976, DESIGN ANAL COMPUTER; BARROW HG, 1972, FRONTIERS PATTERN RE, P1; BROWN TA, 1972, R926NSF RAND CORP RE; Duda R.O., 1973, J ROYAL STAT SOC SER; Erdos P, 1974, PROBABILISTIC METHOD; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Fu K.S., 1974, MATH SCI ENG; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FU KS, 1977, SYNTACTIC PATTERN RE; GHAHRAMAN DE, 1980, IEEE T SYST MAN CYB, V10, P181, DOI 10.1109/TSMC.1980.4308468; GHAHRAMAN DE, 1976, THESIS CARNEGIE MELL; HAYESROTH F, 1977, INFORM CONTROL, V33, P87, DOI 10.1016/S0019-9958(77)90534-4; MARSHALL CW, 1971, APPLIED GRAPH THEORY; MARUYAMA M, 1963, AM SCI, V51, P164; MONTANARI U, 1974, 1974 P IFIP C 74 AMS, P727; MOROFSKY EL, 1971, 2 P INT JOINT C ART, P248; PAVLIDIS T, 1972, PATTERN RECOGN, V4, P5, DOI 10.1016/0031-3203(72)90016-7; ROBERTS FS, 1973, ENVIRON PLANN A, V5, P199, DOI 10.1068/a050199; ROBERTS FS, 1971, ENVIRON PLANN, V3, P395, DOI 10.1068/a030395; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598; SOULE S, 1974, INFORM CONTROL, V25, P57, DOI 10.1016/S0019-9958(74)90799-2; WONG AKC, 1975, IEEE T COMPUT, VC 24, P158, DOI 10.1109/T-C.1975.224183; ZAHN CT, 1974, 1974 P IFIP C 74 AMS, P698	24	20	20	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					341	348		10.1109/TPAMI.1980.4767033	http://dx.doi.org/10.1109/TPAMI.1980.4767033			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JZ206	21868910				2022-12-18	WOS:A1980JZ20600007
J	COOPER, DB				COOPER, DB			MAXIMUM LIKELIHOOD ESTIMATION OF MARKOV-PROCESS BLOB BOUNDARIES IN NOISY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											COOPER, DB (corresponding author), BROWN UNIV,DIV ENGN,PROVIDENCE,RI 02912, USA.							BALLARD DH, 1976, IEEE T COMPUT, V25, P503, DOI 10.1109/TC.1976.1674638; Cooper D. B., 1976, 3rd International Joint Conference on Pattern Recognition, P638; COOPER DB, 1978, MAY P IEEE COMP SOC, P25; COOPER DB, 1974, 2ND P INT C PATT REC, P416; CUNNINGHAM DR, 1976, IEEE T INFORM THEORY, V22, P603, DOI 10.1109/TIT.1976.1055591; ELLIOTT HE, UNPUBLISHED; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; NAHI NE, 1977, IEEE T COMPUT, V26, P772, DOI 10.1109/TC.1977.1674915; NILSSON N, 1971, PROBLEM SOLVING METH, P54; SWERLING P, 1959, J SOC IND APPL MATH, V7, P152, DOI 10.1137/0107014; VANTREES H, 1968, DETECTION ESTIMATI 1, P275; Winston P. H., 1977, ARTIFICIAL INTELLIGE; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848	14	20	21	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					372	384		10.1109/TPAMI.1979.4766946	http://dx.doi.org/10.1109/TPAMI.1979.4766946			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868872				2022-12-18	WOS:A1979HV22700006
J	PRICE, K; REDDY, R				PRICE, K; REDDY, R			MATCHING SEGMENTS OF IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University	PRICE, K (corresponding author), UNIV SO CALIF,INST IMAGE PROCESSING,LOS ANGELES,CA 90007, USA.							AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; ALLEN GR, 1973, OCT IEEE S MACH PROC; CHOW WK, 1977, IEEE T COMPUT, V26, P179, DOI 10.1109/TC.1977.5009299; HANNAH MJ, 1974, 239 STANF U STANF AR; LEVINE MD, 1973, COMPUT GRAPHICS IMAG, P131; LILLESTRAND RL, 1972, IEEE T COMPUT, VC 21, P654, DOI 10.1109/T-C.1972.223570; MORAVEX HP, 1977, 1977 P IJCAI CAMBR, P584; OHLANDER R, UNPUBLISHED; PRICE K, 1977 P IJCAI CAMBR, P177; PRICE KE, 1976, THESIS CARNEGIE MELL; QUAM L, 1971, THESIS STANFORD U; TENENBAUM JN, 1974, 87 STANF RES I ART I; YAKIMOVSKY Y, 1973, THESIS STANFORD U	13	20	21	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					110	116		10.1109/TPAMI.1979.4766884	http://dx.doi.org/10.1109/TPAMI.1979.4766884			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868839				2022-12-18	WOS:A1979HA30300015
J	Li, JJ; Du, ZK; Zhu, L; Ding, ZM; Lu, K; Shen, HT				Li, Jingjing; Du, Zhekai; Zhu, Lei; Ding, Zhengming; Lu, Ke; Shen, Heng Tao			Divergence-Agnostic Unsupervised Domain Adaptation by Adversarial Attacks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptation models; Training; Feature extraction; Measurement; Data models; Neural networks; Semantics; Unsupervised domain adaptation; transfer learning; adversarial attacks; domain generalization; model adaptation		Conventional machine learning algorithms suffer the problem that the model trained on existing data fails to generalize well to the data sampled from other distributions. To tackle this issue, unsupervised domain adaptation (UDA) transfers the knowledge learned from a well-labeled source domain to a different but related target domain where labeled data is unavailable. The majority of existing UDA methods assume that data from the source domain and the target domain are available and complete during training. Thus, the divergence between the two domains can be formulated and minimized. In this paper, we consider a more practical yet challenging UDA setting where either the source domain data or the target domain data are unknown. Conventional UDA methods would fail this setting since the domain divergence is agnostic due to the absence of the source data or the target data. Technically, we investigate UDA from a novel view-adversarial attack-and tackle the divergence-agnostic adaptive learning problem in a unified framework. Specifically, we first report the motivation of our approach by investigating the inherent relationship between UDA and adversarial attacks. Then we elaborately design adversarial examples to attack the training model and harness these adversarial examples. We argue that the generalization ability of the model would be significantly improved if it can defend against our attack, so as to improve the performance on the target domain. Theoretically, we analyze the generalization bound for our method based on domain adaptation theories. Extensive experimental results on multiple UDA benchmarks under conventional, source-absent and target-absent UDA settings verify that our method is able to achieve a favorable performance compared with previous ones. Notably, this work extends the scope of both domain adaptation and adversarial attack, and expected to inspire more ideas in the community.	[Li, Jingjing; Du, Zhekai; Lu, Ke; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China; [Li, Jingjing; Lu, Ke] Univ Elect Sci & Technol China, Yangtze Delta Reg Inst Huzhou, Chengdu 611731, Peoples R China; [Zhu, Lei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China; [Ding, Zhengming] Tulane Univ, New Orleans, LA 70118 USA; [Shen, Heng Tao] Peng Cheng Lab, Shenzhen 518066, Peoples R China	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; Shandong Normal University; Tulane University; Peng Cheng Laboratory	Zhu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.	lijin117@yeah.net; dzk1996411@163.com; leizhu0608@gmai.com; zding1@tulane.edu; kel@uestc.edu.cn; shenhengtao@hotmail.com	Li, Jing/GYU-5036-2022	Zhu, Lei/0000-0002-2993-7142	National Natural Science Foundation of China [61806039, 62176042, 62073059]; Sichuan Science and Technology Program [2020YFG0080, 2020Y FG0481]; CCF-Tencent Open Fund [RAGR20210107]; CCF-Baidu Open Fund [2021PP15002000]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Sichuan Science and Technology Program; CCF-Tencent Open Fund; CCF-Baidu Open Fund	This work was supported in part by the National Natural Science Foundation of China under Grants 61806039, 62176042 and 62073059, and in part by Sichuan Science and Technology Program under Grants 2020YFG0080 and 2020Y FG0481, and in part by CCF-Baidu Open Fund under Grant 2021PP15002000, and in part by CCF-Tencent Open Fund under Grant RAGR20210107.	Aaron van den Oord, 2019, Arxiv, DOI arXiv:1807.03748; Adrian Vladu, 2019, Arxiv, DOI arXiv:1706.06083; Afshin Rostamizadeh, 2009, Arxiv, DOI arXiv:0902.3430; Aleksander Madry, 2019, Arxiv, DOI arXiv:1906.00945; Anirban Chakraborty, 2018, Arxiv, DOI arXiv:1810.00069; Baluja S, 2018, AAAI CONF ARTIF INTE, P2687; Belghazi MI, 2018, PR MACH LEARN RES, V80; Ben Usman, 2017, Arxiv, DOI arXiv:1710.06924; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Carlucci FM, 2019, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2019.00233; Chen Chaoqi, 2020, CVPR, P8869; Chen T, 2020, PR MACH LEARN RES, V119; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Cortes C, 2011, LECT NOTES ARTIF INT, V6925, P308, DOI 10.1007/978-3-642-24412-4_25; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400; D'Innocente Antonio, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P187, DOI 10.1007/978-3-030-12939-2_14; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dou Q, 2019, ADV NEUR IN, V32; Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Farnia F., 2019, PROC INT C LEARN REP; Ganin Y, 2017, ADV COMPUT VIS PATT, P189, DOI 10.1007/978-3-319-58347-1_10; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Goodfellow I. J., 2015, PROC INT C LEARNING; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grandvalet Yves, 2004, NIPS, P529; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heinze-Deml C, 2021, MACH LEARN, V110, P303, DOI 10.1007/s10994-020-05924-1; Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525; Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503; Kate Saenko, 2018, Arxiv, DOI arXiv:1711.01575; Kingma D.P, 2015, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1412.6980; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kundu JN, 2020, PROC CVPR IEEE, P4543, DOI 10.1109/CVPR42600.2020.00460; Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053; Li D, 2019, IEEE I CONF COMP VIS, P1446, DOI 10.1109/ICCV.2019.00153; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Li JJ, 2022, IEEE T KNOWL DATA EN, V34, P5770, DOI 10.1109/TKDE.2021.3060473; Li JJ, 2021, IEEE T PATTERN ANAL, V43, P3918, DOI 10.1109/TPAMI.2020.2991050; Li JJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P747, DOI 10.1145/3343031.3350902; Li JJ, 2019, IEEE T IMAGE PROCESS, V28, P6103, DOI 10.1109/TIP.2019.2924174; Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854; Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174; Li Rui, 2020, P IEEE CVF C COMP VI, P9641, DOI 10.1109/CVPR42600.2020.00966; Li S, 2021, AAAI CONF ARTIF INTE, V35, P8455; Li S, 2021, IEEE T PATTERN ANAL, V44, P4093, DOI 10.1109/TPAMI.2021.3062644; Li S, 2021, IEEE T PATTERN ANAL, V43, P2329, DOI 10.1109/TPAMI.2020.2964173; Liang J, 2019, PROC CVPR IEEE, P2970, DOI 10.1109/CVPR.2019.00309; Liang Jian, 2020, ICML; Liu XQ, 2019, PROC CVPR IEEE, P11226, DOI 10.1109/CVPR.2019.01149; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2016, ADV NEUR IN, V29; Matsuura T, 2020, AAAI CONF ARTIF INTE, V34, P11749; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Muandet Krikamol, 2013, ICML; Niu L, 2015, IEEE I CONF COMP VIS, P4193, DOI 10.1109/ICCV.2015.477; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Paszke A, 2019, ADV NEUR IN, V32; Ranganath R, 2014, JMLR WORKSH CONF PRO, V33, P814; Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Sarkar D, 1996, IEEE T NEURAL NETWOR, V7, P676, DOI 10.1109/72.501725; Scardapane S, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1200; Shafahi A., 2020, PROC INT C LEARN REP; Shankar Shiv, 2018, P INT C LEARN REPR I; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Shujun Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P159, DOI 10.1007/978-3-030-58545-7_10; Sinha A., 2018, ICLR; Sun SL, 2015, INFORM FUSION, V24, P84, DOI 10.1016/j.inffus.2014.12.003; Tobin J, 2017, IEEE INT C INT ROBOT, P23; Tommasi T, 2016, LECT NOTES COMPUT SC, V9915, P475, DOI 10.1007/978-3-319-49409-8_39; Tramer F., 2018, PROC INT C LEARN REP; Utrera F., 2021, PROC INT C LEARN REP; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Volpi Riccardo, 2018, ARXIV180512018; Wang Rui, 2017, P 2017 C EMP METH NA, P1482, DOI [10.18653/v1/D17-1155, DOI 10.18653/V1/D17-1155]; Wang YS, 2019, PR MACH LEARN RES, V97; Wong E., 2020, PROC INT C LEARN REP; Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905; Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151; Yang Shiqi, 2020, ARXIV; Youngeun Kim, 2021, IEEE Transactions on Artificial Intelligence, V2, P508, DOI 10.1109/TAI.2021.3110179; Zellinger W., 2017, 5 INT C LEARN REPR I; Zeyi Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P124, DOI 10.1007/978-3-030-58536-5_8; Zhao S., 2020, PROC INT C NEURAL IN, P16096; Zhihe Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9108, DOI 10.1109/CVPR42600.2020.00913; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	96	19	19	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8196	8211		10.1109/TPAMI.2021.3109287	http://dx.doi.org/10.1109/TPAMI.2021.3109287			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34478362				2022-12-18	WOS:000864325900066
J	Zhu, PF; Wen, LY; Du, DW; Bian, X; Fan, H; Hu, QH; Ling, HB				Zhu, Pengfei; Wen, Longyin; Du, Dawei; Bian, Xiao; Fan, Heng; Hu, Qinghua; Ling, Haibin			Detection and Tracking Meet Drones Challenge	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Drones; Object detection; Conferences; Benchmark testing; Surveillance; Target tracking; Computer vision; Drone; benchmark; image object detection; video object detection; single object tracking; multi-object tracking	OBJECT TRACKING; NETWORKS; MULTITARGET; DATASET	Drones, or general UAVs, equipped with cameras have been fast deployed with a wide range of applications, including agriculture, aerial photography, and surveillance. Consequently, automatic understanding of visual data collected from drones becomes highly demanding, bringing computer vision and drones more and more closely. To promote and track the developments of object detection and tracking algorithms, we have organized three challenge workshops in conjunction with ECCV 2018, ICCV 2019 and ECCV 2020, attracting more than 100 teams around the world. We provide a large-scale drone captured dataset, VisDrone, which includes four tracks, i.e., (1) image object detection, (2) video object detection, (3) single object tracking, and (4) multi-object tracking. In this paper, we first present a thorough review of object detection and tracking datasets and benchmarks, and discuss the challenges of collecting large-scale drone-based object detection and tracking datasets with fully manual annotations. After that, we describe our VisDrone dataset, which is captured over various urban/suburban areas of 14 different cities across China from North to South. Being the largest such dataset ever published, VisDrone enables extensive evaluation and investigation of visual analysis algorithms for the drone platform. We provide a detailed analysis of the current state of the field of large-scale object detection and tracking on drones, and conclude the challenge as well as propose future directions. We expect the benchmark largely boost the research and development in video analysis on drone platforms. All the datasets and experimental results can be downloaded from https://github.com/VisDrone/VisDrone-Dataset.	[Zhu, Pengfei; Hu, Qinghua] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China; [Wen, Longyin] JD Finance Amer Corp, Mountain View, CA 94043 USA; [Du, Dawei] SUNY Albany, Comp Sci Dept, Albany, NY 12222 USA; [Bian, Xiao] GE Global Res, Niskayuna, NY 12309 USA; [Fan, Heng] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA; [Ling, Haibin] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Tianjin University; State University of New York (SUNY) System; State University of New York (SUNY) Albany; General Electric; University of North Texas System; University of North Texas Denton; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Hu, QH (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.	zhupengfei@tju.edu.cn; longyin.wen@jd.com; ddu@albany.edu; xiao.bian@ge.com; heng.fan@unt.edu; huqinghua@tju.edu.cn; hling@cs.stonybrook.edu		Ling, Haibin/0000-0003-4094-8413; Wen, Longyin/0000-0001-5525-492X; Hu, Qinghua/0000-0001-7765-8095; Fan, Heng/0000-0002-7033-3690	National Key Research and Development Program of China [2019YFB2101904]; National Natural Science Foundation of China [61732011, 61876127, 61925602]; Applied Basic Research Program of Qinghai [2019-ZJ-7017]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Applied Basic Research Program of Qinghai	This work was supported by the National Key Research and Development Program of China under Grant 2019YFB2101904, the National Natural Science Foundation of China under Grants 61732011, 61876127, and 61925602, the Applied Basic Research Program of Qinghai under Grant 2019-ZJ-7017. (Corresponding author: Qinghua Hu.)	Alexey Bochkovskiy, 2020, Arxiv, DOI arXiv:2004.10934; Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Barekatain M, 2017, IEEE COMPUT SOC CONF, P2153, DOI 10.1109/CVPRW.2017.267; Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003; Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628; Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30; Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Cai YQ, 2021, AAAI CONF ARTIF INTE, V35, P947; Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246; Chao Peng, 2017, Arxiv, DOI arXiv:1711.07264; Chen L, 2018, IEEE INT CON MULTI; Chen Y., 2020, PROC INT C NEURAL IN; Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057; Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023; Collins RT, 2012, PROC CVPR IEEE, P1744, DOI 10.1109/CVPR.2012.6247870; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Dave Achal, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P436, DOI 10.1007/978-3-030-58558-7_26; Dendorfer P., 2020, ARXIV; Deng HM, 2019, IEEE I CONF COMP VIS, P6677, DOI 10.1109/ICCV.2019.00678; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Du D., 2020, PROC EUR C COMPUT VI, P692; Du DW, 2019, IEEE INT CONF COMP V, P213, DOI 10.1109/ICCVW.2019.00030; Du DW, 2019, IEEE INT CONF COMP V, P199, DOI 10.1109/ICCVW.2019.00029; Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23; Du DW, 2016, IEEE T IMAGE PROCESS, V25, P3572, DOI 10.1109/TIP.2016.2570556; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fan H., 2020, PROC EUR C COMPUT VI, P728; Fan H., 2020, PROC EUR C COMPUT VI, P713; Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; G. V. Research, 2021, COMM DRON MARK SIZ S; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI 10.1109/ICCV.2017.129; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He ZQ, 2017, IEEE INT CONF COMP V, P1992, DOI 10.1109/ICCVW.2017.233; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jian Yang, 2019, Arxiv, DOI arXiv:1905.09646; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kalra I, 2019, IEEE INT CONF AUTOMA, P207; Kang Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P355, DOI 10.1007/978-3-030-58595-2_22; Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1; Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45; Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441; Li C., 2019, CORR, P8410; Li SY, 2017, AAAI CONF ARTIF INTE, P4140; Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI 10.1007/978-3-030-01240-3_21; Liang PP, 2018, IEEE INT CONF ROBOT, P651; Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653; Lu YY, 2017, IEEE I CONF COMP VIS, P2363, DOI 10.1109/ICCV.2017.257; Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190; Lyu S, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Lyu SW, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P441; Mandal M, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2626, DOI 10.1145/3394171.3413934; Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478; Muller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19; Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152; Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27; Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48; Najibi M, 2019, IEEE I CONF COMP VIS, P9744, DOI 10.1109/ICCV.2019.00984; Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465; Jiang N, 2021, Arxiv, DOI arXiv:2101.08466; Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091; Park E, 2017, LARGE SCALE VISUAL R; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008; Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Shi XC, 2014, PROC CVPR IEEE, P3518, DOI 10.1109/CVPR.2014.450; Singh B, 2018, ADV NEUR IN, V31; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584; Tarvainen A, 2017, ADV NEUR IN, V30; Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Viola P., 2001, P 2001 IEEE COMP SOC, pI; Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661; Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813; Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853; Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552; Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308; Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310; Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142; Wang S., 2015, P BRIT MACH VIS C; Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33; Wen L., 2018, PROC EUR C COMPUT VI, P469; Wen LY, 2019, IEEE INT CONF COMP V, P189, DOI 10.1109/ICCVW.2019.00028; Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907; Wen LY, 2019, AAAI CONF ARTIF INTE, P8981; Wojke N, 2017, IEEE IMAGE PROC, P3645; Wu HP, 2019, IEEE I CONF COMP VIS, P9216, DOI 10.1109/ICCV.2019.00931; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28; Xu XW, 2021, IEEE T PATTERN ANAL, V43, P392, DOI 10.1109/TPAMI.2019.2932429; Yan Z., 2021, PROC IEEE C COMPUT V, P15139; Yang F, 2019, IEEE I CONF COMP VIS, P8310, DOI 10.1109/ICCV.2019.00840; Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975; Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356; Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199; Yu HY, 2020, INT J COMPUT VISION, V128, P1141, DOI 10.1007/s11263-019-01266-1; Zhang S., 2020, IEEE C COMP VIS PATT; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4; Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609; Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380; Zhu P., 2018, PROC EUR C COMPUT VI; Zhu PF, 2021, IEEE T CIRC SYST VID, V31, P4058, DOI 10.1109/TCSVT.2020.3045747; Zhu PF, 2019, IEEE INT CONF COMP V, P227, DOI 10.1109/ICCVW.2019.00031; Zhu PF, 2019, LECT NOTES COMPUT SC, V11133, P496, DOI 10.1007/978-3-030-11021-5_29; Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52; Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441; Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7	161	19	19	30	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7380	7399		10.1109/TPAMI.2021.3119563	http://dx.doi.org/10.1109/TPAMI.2021.3119563			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34648430	Green Submitted			2022-12-18	WOS:000864325900013
J	Zhang, P; Xue, JR; Zhang, PF; Zheng, NN; Ouyang, WL				Zhang, Pu; Xue, Jianru; Zhang, Pengfei; Zheng, Nanning; Ouyang, Wanli			Social-Aware Pedestrian Trajectory Prediction via States Refinement LSTM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory; Feature extraction; Legged locomotion; Predictive models; Neurons; Message passing; Adaptation models; Pedestrian trajectory prediction; human interaction modeling; states refinement; LSTM; message passing	BEHAVIOR; ATTENTION	In the task of pedestrian trajectory prediction, social interaction could be one of the most complicated factors since it is difficult to be interpreted through simple rules. Recent studies have shown a great ability of LSTM networks in learning social behaviors from datasets, e.g., introducing LSTM hidden states of the neighbors at the last time step into LSTM recursion. However, those methods depend on previous neighboring features which lead to a delayed observation. In this paper, we propose a data-driven states refinement LSTM network (SR-LSTM) to enable the utilization of the current intention of neighbors through a message passing framework. Moreover, the model performs in the form of self-updating by jointly refining the current states of all participants, rather than an input-output mechanism served by feature concatenation. In the process of states refinement, a social-aware information selection module consisting of an element-wise motion gate and a pedestrian-wise attention is designed to serve as the guidance of the message passing process. Considering the pedestrian walking space as a graph where each pedestrian is a node and each pedestrian pair with an edge, spatial-edge LSTMs are further exploited to enhance the model capacity, where two kinds of LSTMs interact with each other so that states of them are interactively refined. Experimental results on four widely used pedestrian trajectory datasets, ETH, UCY, PWPD, and NYGC demonstrate the effectiveness of the proposed model.	[Zhang, Pu; Xue, Jianru; Zhang, Pengfei; Zheng, Nanning] Xi An Jiao Tong Univ, Coll Artificial Intelligence, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China; [Ouyang, Wanli] Univ Sydney, SenseTime Comp Vis Res Grp SCVRG, Sydney, NSW 2006, Australia	Xi'an Jiaotong University; University of Sydney	Xue, JR (corresponding author), Xi An Jiao Tong Univ, Coll Artificial Intelligence, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.	zhangpu2016@stu.xjtu.edu.cn; jrxue@mail.xjtu.edu.cn; zpengfei@stu.xjtu.edu.cn; nnzheng@mail.xjtu.edu.cn; wanli.ouyang@sydney.edu.au			Natural Science Foundation of China [61751308, 61773311]; Australian Research Council [DP200103223]; Australian Medical Research Future Fund [MRFAI000085]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Australian Research Council(Australian Research Council); Australian Medical Research Future Fund(Medical Research Future Fund (MRFF))	The work of Jianru Xue and Pu Zhang was supported by the Natural Science Foundation of China under Grant 61751308 and Grant 61773311. The work of Wanli Ouyang was supported by Australian Research Council Grant DP200103223 and Australian Medical Research Future Fund MRFAI000085.	Al-Molegi A, 2018, PATTERN RECOGN LETT, V112, P34, DOI 10.1016/j.patrec.2018.05.015; Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Amirian J, 2019, IEEE COMPUT SOC CONF, P2964, DOI 10.1109/CVPRW.2019.00359; Antonini G, 2006, TRANSPORT RES B-METH, V40, P667, DOI 10.1016/j.trb.2005.09.006; Becker S., 2018, ECCV, P138; Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459; Bruna J., 2014, C TRACK P; Cancela B, 2014, PROC CVPR IEEE, P2553, DOI 10.1109/CVPR.2014.327; Chandra R, 2019, PROC CVPR IEEE, P8475, DOI 10.1109/CVPR.2019.00868; Choi C, 2019, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2019.00101; Chrysanthou Y., 2007, RES DOWNLOADS CROWD; Deo N, 2018, IEEE COMPUT SOC CONF, P1549, DOI 10.1109/CVPRW.2018.00196; Fernando T, 2019, LECT NOTES COMPUT SC, V11361, P314, DOI 10.1007/978-3-030-20887-5_20; Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002; Ferrer G, 2013, IEEE INT C INT ROBOT, P1688, DOI 10.1109/IROS.2013.6696576; Gorrini A., 2016, COLLECTIVE DYN, V1, P1, DOI DOI 10.17815/CD.2016.3; Gorrini A, 2015, TRAFFIC AND GRANULAR FLOW '13, P83, DOI 10.1007/978-3-319-10629-8_10; Gupta A., 2018, CIDNN; Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240; Hasan I, 2021, IEEE T PATTERN ANAL, V43, P1267, DOI 10.1109/TPAMI.2019.2949414; Hasan I, 2018, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2018.00635; Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hoogendoorn SP, 2013, TRANSPORT RES REC, P45, DOI 10.3141/2326-07; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Huang YF, 2019, IEEE I CONF COMP VIS, P6281, DOI 10.1109/ICCV.2019.00637; Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573; Kingma D.P, P 3 INT C LEARNING R; Kipf TN, 2016, P INT C LEARN REPR; Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x; Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789; Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142; Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766; Li YK, 2019, PROC CVPR IEEE, P294, DOI 10.1109/CVPR.2019.00038; Li YK, 2018, IEEE T MULTIMEDIA, V20, P3289, DOI 10.1109/TMM.2018.2834873; Liang JW, 2019, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR.2019.00587; Liang XD, 2017, PROC CVPR IEEE, P2175, DOI 10.1109/CVPR.2017.234; Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8; Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493; Ma YX, 2019, AAAI CONF ARTIF INTE, P6120; Manh H, 2018, ARXIV 180804018; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Ratsamee P, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500084; Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144; Schadschneider A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P75; Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230; Shi XD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051223; Su H., 2016, IJCAI 16 PROC 25 INT, P3469; Su H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2772; Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008; Do T, 2016, TRANSPORT RES REC, P13, DOI 10.3141/2540-02; Varshneya D, 2017, ARXIV 170509436; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Vemula A, 2018, IEEE INT CONF ROBOT, P4601; Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25; Wang Y., 2016, ARXIV160706416; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu Y., 2018, AGRIMGUPTA92; Xu YY, 2018, PROC CVPR IEEE, P5275, DOI 10.1109/CVPR.2018.00553; Xue H, 2019, LECT NOTES ARTIF INT, V11671, P439, DOI 10.1007/978-3-030-29911-8_34; Xue H, 2019, IEEE WINT CONF APPL, P2038, DOI 10.1109/WACV.2019.00221; Xue H, 2018, IEEE WINT CONF APPL, P1186, DOI 10.1109/WACV.2018.00135; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444; Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41; Yi S., 2014, P IEEE INT C MULT EX, P1; Yi S, 2016, LECT NOTES COMPUT SC, V9905, P263, DOI 10.1007/978-3-319-46448-0_16; Yi S, 2015, PROC CVPR IEEE, P3488, DOI 10.1109/CVPR.2015.7298971; Yuan Y, 2017, IEEE I CONF COMP VIS, P1819, DOI 10.1109/ICCV.2017.200; Zhang PF, 2018, LECT NOTES COMPUT SC, V11213, P136, DOI 10.1007/978-3-030-01240-3_9; Zhang P, 2019, PROC CVPR IEEE, P12077, DOI 10.1109/CVPR.2019.01236; Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453; Zhao TY, 2019, PROC CVPR IEEE, P12118, DOI 10.1109/CVPR.2019.01240; Zhou BL, 2012, LECT NOTES COMPUT SC, V7573, P857, DOI 10.1007/978-3-642-33709-3_61; Zou HS, 2018, AAAI CONF ARTIF INTE, P7648	78	19	19	11	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2742	2759		10.1109/TPAMI.2020.3038217	http://dx.doi.org/10.1109/TPAMI.2020.3038217			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33196437				2022-12-18	WOS:000792921400038
J	Zhao, B; Li, HP; Lu, XQ; Li, XL				Zhao, Bin; Li, Haopeng; Lu, Xiaoqiang; Li, Xuelong			Reconstructive Sequence-Graph Network for Video Summarization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generators; Task analysis; Streaming media; Interference; Predictive models; Optics; Diversity reception; Key-shot; video summarization; video reconstructor; summary generator		Exploiting the inner-shot and inter-shot dependencies is essential for key-shot based video summarization. Current approaches mainly devote to modeling the video as a frame sequence by recurrent neural networks. However, one potential limitation of the sequence models is that they focus on capturing local neighborhood dependencies while the high-order dependencies in long distance are not fully exploited. In general, the frames in each shot record a certain activity and vary smoothly over time, but the multi-hop relationships occur frequently among shots. In this case, both the local and global dependencies are important for understanding the video content. Motivated by this point, we propose a reconstructive sequence-graph network (RSGN) to encode the frames and shots as sequence and graph hierarchically, where the frame-level dependencies are encoded by long short-term memory (LSTM), and the shot-level dependencies are captured by the graph convolutional network (GCN). Then, the videos are summarized by exploiting both the local and global dependencies among shots. Besides, a reconstructor is developed to reward the summary generator, so that the generator can be optimized in an unsupervised manner, which can avert the lack of annotated data in video summarization. Furthermore, under the guidance of reconstruction loss, the predicted summary can better preserve the main video content and shot-level dependencies. Practically, the experimental results on three popular datasets (i.e., SumMe, TVsum and VTW) have demonstrated the superiority of our proposed approach to the summarization task.	[Zhao, Bin; Li, Haopeng; Lu, Xiaoqiang; Li, Xuelong] Northwestern Polytech Univ, Xian 710072, Peoples R China; [Zhao, Bin; Li, Haopeng; Lu, Xiaoqiang; Li, Xuelong] Northwestern Polytech Univ, Key Lab Intelligent Interact & Applicat, Minist Ind & Informat Technol, Xian 710072, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University	Zhao, B (corresponding author), Northwestern Polytech Univ, Xian 710072, Peoples R China.; Zhao, B (corresponding author), Northwestern Polytech Univ, Key Lab Intelligent Interact & Applicat, Minist Ind & Informat Technol, Xian 710072, Peoples R China.	binzhao_optimal@mail.nwpu.edu.cn; hplee@mail.nwpu.edu.cn; luxq666666@gmail.com; xuelong_li@nwpu.edu.cn	Li, Hao/GPS-9834-2022	Li, Haopeng/0000-0001-8175-5381	National Natural Science Foundation of China [61871470]; China Postdoctoral Science Foundation [2020TQ0236]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	This work was supported in part by the National Natural Science Foundation of China under Grant 61871470 and in part by the China Postdoctoral Science Foundation under Grant 2020TQ0236.	Bilkhu Manjot, 2019, ARXIV190602792; Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052; Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981; Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Fajtl J, 2019, LECT NOTES COMPUT SC, V11367, P39, DOI 10.1007/978-3-030-21074-8_4; Fernandes P., 2018, P INT C LEARN REPR; de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004; Fu TJ, 2019, IEEE WINT CONF APPL, P1579, DOI 10.1109/WACV.2019.00173; Gong BQ, 2014, ADV NEUR IN, V27; Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928; Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hussain T., 2020, PATTERN RECOGN, V109; Ji Z., 2021, IEEE T NEUR NET LEAR, V32, P1765, DOI DOI 10.1109/TNNLS.2020.2991083; Jia Robin, 2017, P 2017 C EMP METH NA, P2021, DOI DOI 10.18653/V1/D17-1215; Khan G, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106524; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Li XL, 2017, AAAI CONF ARTIF INTE, P4147; Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887; Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942; Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350; Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224; Mao F., 2018, P EUR C COMP VIS WOR, P262; Mei S., 2014, P IEEE INT C MULT EX, P1; Mei SH, 2021, IEEE T MULTIMEDIA, V23, P732, DOI 10.1109/TMM.2020.2987683; Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9; Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320; Otani M, 2019, PROC CVPR IEEE, P7579, DOI 10.1109/CVPR.2019.00778; Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117; Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35; Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22; Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229; Shemer Yair, 2019, ARXIV191203650; Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wu L., 2018, ARXIV 181102815; Xiao SW, 2020, IEEE T IMAGE PROCESS, V29, P5889, DOI 10.1109/TIP.2020.2985868; Zeng KH, 2016, LECT NOTES COMPUT SC, V9906, P609, DOI 10.1007/978-3-319-46475-6_38; Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719; Zhang K, 2018, LECT NOTES COMPUT SC, V11212, P391, DOI 10.1007/978-3-030-01237-3_24; Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120; Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47; Zhao B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P863, DOI 10.1145/3123266.3123328; Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773; Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322; Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582	51	19	19	9	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2793	2801		10.1109/TPAMI.2021.3072117	http://dx.doi.org/10.1109/TPAMI.2021.3072117			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33835915	Green Submitted			2022-12-18	WOS:000792921400041
J	Li, JN; Zhang, SL; Tian, Q; Wang, M; Gao, W				Li, Jianing; Zhang, Shiliang; Tian, Qi; Wang, Meng; Gao, Wen			Pose-Guided Representation Learning for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Training; Pose estimation; Robustness; Image segmentation; Body regions; Measurement; Person re-identification; pose variation; misalignment; pose-guided representation	ATTENTION; NETWORK	The large pose variations and misalignment errors exhibited by person images significantly increase the difficulty of person Re-Identification (ReID). Existing works commonly apply extra operations like pose estimation, part segmentation, etc., to alleviate those issues and improve the robustness of pedestrian representations. While boosting the ReID accuracy, those operations introduce considerable computational overheads and make the deep models complex and hard to tune. To chase a more efficient solution, we propose a Part-Guided Representation (PGR) composed of Pose Invariant Feature (PIF) and Local Descriptive Feature (LDF), respectively. We call PGR "Part-Guided" because it is trained and supervised by local part cues. Specifically, PIF approximates a pose invariant representation inferred by pose estimation and pose normalization. LDF focuses on discriminative body parts by approximating a representation learned with body region segmentation. In this way, extra pose extraction is only introduced during the training stage to supervise the learning of PGR, but is not required during the testing stage for feature extraction. Extensive comparisons with recent works on five widely used datasets demonstrate the competitive accuracy and efficiency of PGR.	[Li, Jianing; Zhang, Shiliang; Gao, Wen] Peking Univ, Dept Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Tian, Qi] Huawei Noahs Ark Lab, Beijing, Peoples R China; [Wang, Meng] Hefei Univ Technol, Sch Comp Sci, Hefei 230009, Anhui, Peoples R China; [Wang, Meng] Hefei Univ Technol, Sch Artificial Intelligence, Hefei 230009, Anhui, Peoples R China; [Gao, Wen] Peng Cheng Lab, Shenzhen 518000, Peoples R China	Peking University; Huawei Technologies; Hefei University of Technology; Hefei University of Technology; Peng Cheng Laboratory	Zhang, SL (corresponding author), Peking Univ, Dept Elect Engn & Comp Sci, Beijing 100871, Peoples R China.	ljn-vmc@pku.edu.cn; slzhang.jdl@pku.edu.cn; tian.qi1@huawei.com; eric.mengwang@gmail.com; wgao@pku.edu.cn			Peng Cheng Laboratory; Beijing Natural Science Foundation [JQ18012]; Natural Science Foundation of China [61620106009, 61572050, 91538111]	Peng Cheng Laboratory; Beijing Natural Science Foundation(Beijing Natural Science Foundation); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported in part by Peng Cheng Laboratory, in part by Beijing Natural Science Foundation under Grant No. JQ18012, in part by Natural Science Foundation of China under Grant No. 61620106009, 61572050, 91538111.	Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; Bai S, 2017, PROC CVPR IEEE, P3356, DOI 10.1109/CVPR.2017.358; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225; Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128; Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902; Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764; Chen H., 2018, 2018 IEEE INT C MULT, P1; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Chen YT, 2018, AAAI CONF ARTIF INTE, P2852; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Gray D., 2007, IEEE INT WORKSH PERF, V3, P1; He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53; Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782; Li JN, 2019, AAAI CONF ARTIF INTE, P8618; Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P737, DOI 10.1145/3240508.3240585; Liu JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231741; Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443; Mao SN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P883; Martinel N, 2016, LECT NOTES COMPUT SC, V9908, P858, DOI 10.1007/978-3-319-46493-0_52; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366; Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30; Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002; Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427; Su C, 2018, PATTERN RECOGN, V75, P77, DOI 10.1016/j.patcog.2017.07.005; Su C, 2017, PATTERN RECOGN, V66, P4, DOI 10.1016/j.patcog.2017.01.006; Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30; Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25; Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30; Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144; Wang HX, 2016, LECT NOTES COMPUT SC, V9908, P405, DOI 10.1007/978-3-319-46493-0_25; Wang XG, 2014, ADV COMPUT VIS PATT, P351, DOI 10.1007/978-1-4471-6296-4_17; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204; Wu Yonghui, 2016, CORR; Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226; Yao HT, 2017, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2017.8019485; Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhang Xuan, 2017, ARXIV171108184; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414; Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541	80	19	19	22	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					622	635		10.1109/TPAMI.2019.2929036	http://dx.doi.org/10.1109/TPAMI.2019.2929036			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS					2022-12-18	WOS:000740006100007
J	Chen, KA; Lin, WY; Li, JG; See, J; Wang, J; Zou, JN				Chen, Kean; Lin, Weiyao; Li, Jianguo; See, John; Wang, Ji; Zou, Junni			AP-Loss for Accurate One-Stage Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Detectors; Task analysis; Measurement; Optimization; Object detection; Training; Proposals; Computer vision; object detection; machine learning; ranking loss		One-stage object detectors are trained by optimizing classification-loss and localization-loss simultaneously, with the former suffering much from extreme foreground-background class imbalance issue due to the large number of anchors. This paper alleviates this issue by proposing a novel framework to replace the classification task in one-stage detectors with a ranking task, and adopting the average-precision loss (AP-loss) for the ranking problem. Due to its non-differentiability and non-convexity, the AP-loss cannot be optimized directly. For this purpose, we develop a novel optimization algorithm, which seamlessly combines the error-driven update scheme in perceptron learning and backpropagation algorithm in deep networks. We provide in-depth analyses on the good convergence property and computational complexity of the proposed algorithm, both theoretically and empirically. Experimental results demonstrate notable improvement in addressing the imbalance issue in object detection over existing AP-based optimization algorithms. An improved state-of-the-art performance is achieved in one-stage detectors based on AP-loss over detectors using classification-losses on various standard benchmarks. The proposed framework is also highly versatile in accommodating different network architectures. Code is available at https://github.com/cccorn/AP-loss.	[Chen, Kean; Lin, Weiyao; Zou, Junni] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China; [Li, Jianguo] Intel Labs, Beijing 100080, Peoples R China; [See, John] Multimedia Univ, Fac Comp & Informat, Cyberjaya 63100, Selangor, Malaysia; [Wang, Ji] Tencent YouTu Lab, Shanghai 200233, Peoples R China	Shanghai Jiao Tong University; Intel Corporation; Multimedia University; Tencent	Lin, WY (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.	ckadashuaige@sjtu.edu.cn; wylin@sjtu.edu.cn; jianguo.li@intel.com; johnsee@mmu.edu.my; jensenjwang@tencent.com; zou-jn@sjtu.edu.cn	See, John/C-8633-2013	See, John/0000-0003-3005-4109; Chen, Kean/0000-0002-0772-6635; Lin, Weiyao/0000-0001-8307-7107	China Major Project for New Generation of AI Grant [2018AAA0100400]; National Natural Science Foundation of China [61971277, 61931023]; CREST Malaysia [T03C1-17]; Tencent YouTu Lab; Suzhou Institute of Artificial Intelligence, SJTU	China Major Project for New Generation of AI Grant; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CREST Malaysia; Tencent YouTu Lab; Suzhou Institute of Artificial Intelligence, SJTU	The work was supported in part by China Major Project for New Generation of AI Grant (No. 2018AAA0100400), National Natural Science Foundation of China (Nos. 61971277 and 61931023), and CREST Malaysia Grant T03C1-17. The authors would like to thank the support from Tencent YouTu Lab and Suzhou Institute ofArtificial Intelligence, SJTU.	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; ANLAUF JK, 1989, EUROPHYS LETT, V10, P687, DOI 10.1209/0295-5075/10/7/014; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Brown Tom B, 2017, ARXIV171209665; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526; Cheng BW, 2018, LECT NOTES COMPUT SC, V11219, P473, DOI 10.1007/978-3-030-01267-0_28; Cortes C, 2004, ADV NEUR IN, V16, P313; Cruz R, 2017, LECT NOTES COMPUT SC, V10306, P538, DOI 10.1007/978-3-319-59147-6_46; Cruz R, 2016, IEEE IJCNN, P2182, DOI 10.1109/IJCNN.2016.7727469; Dai JF, 2016, ADV NEUR IN, V29; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fu C. -Y., 2017, ARXIV170106659; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goyal Priya, 2017, ARXIV170602677; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13; Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15; KRAUTH W, 1987, J PHYS A-MATH GEN, V20, pL745, DOI 10.1088/0305-4470/20/11/013; Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1; Li B., 2018, ARXIV180702842; Li BY, 2019, AAAI CONF ARTIF INTE, P8577; Li JG, 2013, PROC CVPR IEEE, P3468, DOI 10.1109/CVPR.2013.445; Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin W., 2018, P BRIT MACH VIS C BM; Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24; Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754; Mohapatra P., 2014, P ADV NEUR INF PROC, P2312; Mohapatra P, 2018, PROC CVPR IEEE, P3693, DOI 10.1109/CVPR.2018.00389; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Natole M. A., 2019, FRONT APPL MATH STAT, V5, DOI [10.3389/fams.2019.00030, DOI 10.3389/FAMS.2019.00030]; OKSUZ K, IN PRESS, DOI DOI 10.1109/TPAMI.2020.2981890; Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091; Qian Q., 2019, ARXIV190710156, P12164; Rao YM, 2018, PROC CVPR IEEE, P6190, DOI 10.1109/CVPR.2018.00648; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rosenblatt F., 1957, PERCEPTRON PERCEIVIN; Salton G., 1986, INTRO MODERN INFORM; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377; Song Y, 2016, PR MACH LEARN RES, V48; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; WENDEMUTH A, 1995, J PHYS A-MATH GEN, V28, P5423, DOI 10.1088/0305-4470/28/18/030; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609; Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444	67	19	19	4	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3782	3798		10.1109/TPAMI.2020.2991457	http://dx.doi.org/10.1109/TPAMI.2020.2991457			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32365016	Green Submitted			2022-12-18	WOS:000702649700008
J	Ploumpis, S; Ververas, E; O'Sullivan, E; Moschoglou, S; Wang, HY; Pears, N; Smith, WAP; Gecer, B; Zafeiriou, S				Ploumpis, Stylianos; Ververas, Evangelos; O'Sullivan, Eimear; Moschoglou, Stylianos; Wang, Haoyang; Pears, Nick; Smith, William A. P.; Gecer, Baris; Zafeiriou, Stefanos			Towards a Complete 3D Morphable Model of the Human Head	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Magnetic heads; Face; Ear; Three-dimensional displays; Shape; Computational modeling; 3DMM; morphable model combination; 3D reconstruction; craniofacial 3DMM	RECOGNITION	Three-dimensional morphable models (3DMMs) are powerful statistical tools for representing the 3D shapes and textures of an object class. Here we present the most complete 3DMM of the human head to date that includes face, cranium, ears, eyes, teeth and tongue. To achieve this, we propose two methods for combining existing 3DMMs of different overlapping head parts: (i). use a regressor to complete missing parts of one model using the other, and (ii). use the Gaussian Process framework to blend covariance matrices from multiple models. Thus, we build a new combined face-and-head shape model that blends the variability and facial detail of an existing face model (the LSFM) with the full head modelling capability of an existing head model (the LYHM). Then we construct and fuse a highly-detailed ear model to extend the variation of the ear shape. Eye and eye region models are incorporated into the head model, along with basic models of the teeth, tongue and inner mouth cavity. The new model achieves state-of-the-art performance. We use our model to reconstruct full head representations from single, unconstrained images allowing us to parameterize craniofacial shape and texture, along with the ear shape, eye gaze and eye color.	[Ploumpis, Stylianos; Ververas, Evangelos; O'Sullivan, Eimear; Moschoglou, Stylianos; Wang, Haoyang; Pears, Nick; Smith, William A. P.; Gecer, Baris; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, South Kensington Campus, London SW7 2AZ, England; [Pears, Nick; Smith, William A. P.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	Imperial College London; University of York - UK	Ploumpis, S (corresponding author), Imperial Coll London, Dept Comp, South Kensington Campus, London SW7 2AZ, England.	s.ploumpis@imperial.ac.uk; e.ververas16@imperial.ac.uk; e.o-sullivan16@imperial.ac.uk; s.moschoglou@imperial.ac.uk; haoyang.wang15@imperial.ac.uk; nick.pears@york.ac.uk; william.smith@york.ac.uk; b.gecer@imperial.ac.uk; s.zafeiriou@imperial.ac.uk		Ververas, Evangelos/0000-0003-4345-1744; Pears, Nicholas Edwin/0000-0001-9513-5634; Smith, William/0000-0002-6047-0413; Gecer, Baris/0000-0002-5684-2843; O' Sullivan, Eimear/0000-0003-0525-3341	EPSRC [EP/N007743/1, EP/S010203/1]; Google Faculty Award; Google Daydream Award; Royal Academy of Engineering under the Leverhulme Trust Senior Fellowship scheme	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Google Faculty Award(Google Incorporated); Google Daydream Award; Royal Academy of Engineering under the Leverhulme Trust Senior Fellowship scheme	The work of S. Ploumpis was suppored by EPSRC Project (EP/N007743/1) FACER2VM. The work of S. Zafeiriou was supported by Google Faculty Award, as well as from the EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans (EP/S010203/1). The work of N. Pears and W. Smith was supported by Google Daydream Award. The work of W. Smith was supported by the Royal Academy of Engineering under the Leverhulme Trust Senior Fellowship scheme. The authors would like to formally thank Vasileios Triantafyllou (computer graphics specialist at Facesoft) for all the visual content of this work, as well as for his valuable contribution to the head texture completion dataset.	Abaza A, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431221; Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1; Berard P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925962; Berard P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661285; Blackwell S., CIVILIAN AM EUROPEAN, V2; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bolkart T, 2015, IEEE I CONF COMP VIS, P3604, DOI 10.1109/ICCV.2015.411; Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62; Brunton A, 2014, COMPUT VIS IMAGE UND, V128, P1, DOI 10.1016/j.cviu.2014.05.005; Chang FJ, 2019, INT J COMPUT VISION, V127, P930, DOI 10.1007/s11263-019-01151-x; Chang FJ, 2018, IEEE INT CONF AUTOMA, P122, DOI 10.1109/FG.2018.00027; Dai H, 2018, IEEE INT CONF AUTOMA, P404, DOI 10.1109/FG.2018.00065; Dai H, 2017, IEEE I CONF COMP VIS, P3104, DOI 10.1109/ICCV.2017.335; Davies R, 2008, STAT MODELS SHAPE OP; Deng JK, 2018, IEEE INT CONF AUTOMA, P399, DOI 10.1109/FG.2018.00064; DESMET M, 2010, P AS C COMP VIS, P276; Egger B., 2019, ARXIV190901815; Funes Mora K.A., 2014, P S EYE TRACK RES AP, P255; Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125; Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021; Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30; Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x; Hu GS, 2016, LECT NOTES COMPUT SC, V9912, P73, DOI 10.1007/978-3-319-46484-8_5; Hu LW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130887; Huber P., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632; Islam SMS, 2011, INT J COMPUT VISION, V95, P52, DOI 10.1007/s11263-011-0436-0; Jin CT, 2014, IEEE T MULTIMEDIA, V16, P37, DOI 10.1109/TMM.2013.2282134; Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868; Koppen P, 2018, PATTERN RECOGN, V74, P617, DOI 10.1016/j.patcog.2017.09.006; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813; Liang S, 2016, LECT NOTES COMPUT SC, V9906, P360, DOI 10.1007/978-3-319-46475-6_23; Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123; Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767; Luthi M, 2018, IEEE T PATTERN ANAL, V40, P1860, DOI 10.1109/TPAMI.2017.2739743; Moschoglou S., 2019, ARXIV190500307; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Park S, 2018, LECT NOTES COMPUT SC, V11217, P741, DOI 10.1007/978-3-030-01261-8_44; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003; Ploumpis S, 2019, PROC CVPR IEEE, P10926, DOI 10.1109/CVPR.2019.01119; Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43; Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883; Schneider T, 2014, INT C PATT RECOG, P1167, DOI 10.1109/ICPR.2014.210; Staal FCR, 2015, J CRANIO MAXILL SURG, V43, P528, DOI 10.1016/j.jcms.2015.02.005; Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wood E, 2016, LECT NOTES COMPUT SC, V9905, P297, DOI 10.1007/978-3-319-46448-0_18; Xiangyu Zhu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163096; Yuan L., 2010, P SPIE INT DEF SEC S; Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081; Zhou YX, 2017, IEEE INT CONF AUTOMA, P626, DOI 10.1109/FG.2017.79; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679; Zolfaghari R, 2016, INT CONF ACOUST SPEE, P1771, DOI 10.1109/ICASSP.2016.7471981	62	19	20	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4142	4160		10.1109/TPAMI.2020.2991150	http://dx.doi.org/10.1109/TPAMI.2020.2991150			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32356737	Green Submitted, Green Accepted			2022-12-18	WOS:000702649700031
J	Xu, S; Wang, RS; Wang, H; Yang, RG				Xu, Sheng; Wang, Ruisheng; Wang, Hao; Yang, Ruigang			Plane Segmentation Based on the Optimal-Vector-Field in LiDAR Point Clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Image segmentation; Optimization; Estimation; Laser radar; Pipelines; Surface treatment; Plane segmentation; optimal-vector-field; point clouds; surface normals; graph-cut	SEMIAUTOMATED EXTRACTION; ENERGY MINIMIZATION; RECONSTRUCTION; ROADS	One key challenge in the point cloud segmentation is the detection and split of overlapping regions between different planes. The existing methods depend on the similarity and the dissimilarity in neighbor regions without a global constraint, which brings the 'over-' and 'under-' segmentation in the results. Hence, this paper presents a pipeline of the accurate plane segmentation for point clouds to address the shortcoming in the local optimization. There are two phases included in the proposed segmentation process. One is a local phase to calculate connectivity scores between different planes based on local variations of surface normals. In this phase, a new optimal-vector-field is formulated to detect the plane intersections. The optimal-vector-field is large in magnitude at plane intersections and vanishing at other regions. The other one is a global phase to smooth local segmentation cues to mimic leading eigenvector computation in the graph-cut. Evaluation of two datasets shows that the achieved precision and recall is 94.50 percent and 90.81 percent on the collected mobile LiDAR data and obtains an average accuracy of 75.4 percent on an open benchmark, which outperforms the state-of-the-art methods in terms of completeness and correctness.	[Xu, Sheng] Nanjing Forestry Univ, Coll Informat Sci & Technol, Coll Landscape Architecture, Nanjing 210037, Jiangsu, Peoples R China; [Wang, Ruisheng] Guangzhou Univ, Sch Geog Sci, Guangzhou 510006, Guangdong, Peoples R China; [Wang, Ruisheng] Univ Calgary, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada; [Wang, Hao] Nanjing Forestry Univ, Coll Landscape Architecture, Nanjing 210037, Jiangsu, Peoples R China; [Yang, Ruigang] Univ Kentucky, Comp Sci, Lexington, KY 40507 USA	Nanjing Forestry University; Guangzhou University; University of Calgary; Nanjing Forestry University; University of Kentucky	Xu, S (corresponding author), Nanjing Forestry Univ, Coll Informat Sci & Technol, Coll Landscape Architecture, Nanjing 210037, Jiangsu, Peoples R China.	sheng.xu2@ucalgary.ca; ruiswang@ucalgary.ca; wh9816@126.com; ryang@cs.uky.edu	Xu, Sheng/E-6451-2016	Xu, Sheng/0000-0002-9017-1510	Natural Science Foundation of the Higher Education Institutions of Jiangsu Province [19KJB520010]; National Key Research and Development Program of China [2019YFD1100404]; China Postdoctoral Science Foundation [2019M661852]; Natural Science Foundation of Jiangsu Province [BK20171453]; Central Public-interest Scientific Institution Basal Research Fund [CAFYBB2019QD003]; National Sciences and Engineering Research Council (NSERC) in Canada; Alberta Innovates Technology Futures (AITF) Scholarships	Natural Science Foundation of the Higher Education Institutions of Jiangsu Province; National Key Research and Development Program of China; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province); Central Public-interest Scientific Institution Basal Research Fund; National Sciences and Engineering Research Council (NSERC) in Canada; Alberta Innovates Technology Futures (AITF) Scholarships	This work was supported by the Natural Science Foundation of the Higher Education Institutions of Jiangsu Province (19KJB520010), the National Key Research and Development Program of China (2019YFD1100404), China Postdoctoral Science Foundation (2019M661852), the Natural Science Foundation of Jiangsu Province (BK20171453), and the Central Public-interest Scientific Institution Basal Research Fund (CAFYBB2019QD003). This work was also supported by the National Sciences and Engineering Research Council (NSERC) in Canada and the Alberta Innovates Technology Futures (AITF) Scholarships.	BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Boscaini D, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12844; Boulch A., 2017, 3DOR, V2, P7, DOI [10.2312/3dor.20171047, DOI 10.2312/3DOR.20171047]; Boyko A, 2011, ISPRS J PHOTOGRAMM, V66, pS2, DOI 10.1016/j.isprsjprs.2011.09.009; Boykov Y, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P79, DOI 10.1007/0-387-28831-7_5; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Charney J.G., 1950, TELLUS, V2, P237, DOI [10.1111/j.2153-3490.1950.tb00336.x, DOI 10.3402/TELLUSA.V2I4.8607, 10.3402/tellusa.v2i4.8607]; Chen D, 2014, IEEE J-STARS, V7, P4199, DOI 10.1109/JSTARS.2014.2349003; COURANT R, 1967, IBM J RES DEV, V11, P215, DOI 10.1147/rd.112.0215; Courant R., 1965, METHODS MATH PHYS, V1; Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Douillard B, 2011, IEEE INT CONF ROBOT; Fang W, 2015, IEEE T GEOSCI REMOTE, V53, P942, DOI 10.1109/TGRS.2014.2330852; Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946; Feng C, 2014, IEEE INT CONF ROBOT, P6218, DOI 10.1109/ICRA.2014.6907776; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Golovinskiy Aleksey, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P39, DOI 10.1109/ICCVW.2009.5457721; Golovinskiy A, 2009, IEEE I CONF COMP VIS, P2154, DOI 10.1109/ICCV.2009.5459471; Gorelick L, 2017, IEEE T PATTERN ANAL, V39, P258, DOI 10.1109/TPAMI.2016.2547399; Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345; Hackel Timo, 2017, ARXIV170403847, VIV-1-W1, P91, DOI DOI 10.5194/ISPRS-ANNALS-IV-1-W1-91-2017; Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522; Huang QX, 2009, COMPUT GRAPH FORUM, V28, P407, DOI 10.1111/j.1467-8659.2009.01380.x; Isack H, 2016, PROC CVPR IEEE, P2434, DOI 10.1109/CVPR.2016.267; Kaiser A, 2019, COMPUT GRAPH FORUM, V38, P167, DOI 10.1111/cgf.13451; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kucak RA, 2017, INT ARCH PHOTOGRAMM, V42-1, P595, DOI 10.5194/isprs-archives-XLII-1-W1-595-2017; Kumar P, 2013, ISPRS J PHOTOGRAMM, V85, P44, DOI 10.1016/j.isprsjprs.2013.08.003; Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479; Lavoue G, 2005, COMPUT AIDED DESIGN, V37, P975, DOI 10.1016/j.cad.2004.09.001; LAX PD, 1956, COMMUN PUR APPL MATH, V9, P267, DOI 10.1002/cpa.3160090206; Liang J, 2012, PROC CVPR IEEE, P214, DOI 10.1109/CVPR.2012.6247678; Lin H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461969; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Marin D, 2015, IEEE I CONF COMP VIS, P397, DOI 10.1109/ICCV.2015.53; Nan LL, 2017, IEEE I CONF COMP VIS, P2372, DOI 10.1109/ICCV.2017.258; Polewski P, 2015, ISPRS J PHOTOGRAMM, V105, P252, DOI 10.1016/j.isprsjprs.2015.01.010; Qiu RQ, 2014, LECT NOTES COMPUT SC, V8691, P17, DOI 10.1007/978-3-319-10578-9_2; Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strom J, 2010, IEEE INT C INT ROBOT, P2131, DOI 10.1109/IROS.2010.5650459; Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589; Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249; Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067; Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651; Tovari D., 2012, INT ARCH PHOTOGRAMM, V36, P79; Truong G, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P200; Wang F, 2020, IEEE T AUTOM SCI ENG, V17, P735, DOI 10.1109/TASE.2019.2942068; Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054; Xia SB, 2017, IEEE GEOSCI REMOTE S, V14, P1288, DOI 10.1109/LGRS.2017.2707467; Xu S, 2020, IEEE T INTELL TRANSP, V21, P2765, DOI 10.1109/TITS.2019.2912455; Xu S, 2017, IEEE T GEOSCI REMOTE, V55, P996, DOI 10.1109/TGRS.2016.2617819; Yang BS, 2013, ISPRS J PHOTOGRAMM, V81, P19, DOI 10.1016/j.isprsjprs.2013.04.002; Yang BS, 2013, ISPRS J PHOTOGRAMM, V79, P80, DOI 10.1016/j.isprsjprs.2013.01.016; Yu YT, 2015, IEEE T GEOSCI REMOTE, V53, P1374, DOI 10.1109/TGRS.2014.2338915; Yun T, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8110942; Zhang KQ, 2003, IEEE T GEOSCI REMOTE, V41, P872, DOI 10.1109/TGRS.2003.810682; Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169; Zheng H, 2017, IEEE T GEOSCI REMOTE, V55, P407, DOI 10.1109/TGRS.2016.2607521; Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472	62	19	19	4	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3991	4007		10.1109/TPAMI.2020.2994935	http://dx.doi.org/10.1109/TPAMI.2020.2994935			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32750765				2022-12-18	WOS:000702649700022
J	Huang, SC; Le, TH; Jaw, DW				Huang, Shih-Chia; Le, Trung-Hieu; Jaw, Da-Wei			DSNet: Joint Semantic Learning for Object Detection in Inclement Weather Conditions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Feature extraction; Atmospheric modeling; Image restoration; Task analysis; Meteorology; Detectors; Object detection; dual-subnet network; joint learning; multi-task learning; CNN		In the past half of the decade, object detection approaches based on the convolutional neural network have been widely studied and successfully applied in many computer vision applications. However, detecting objects in inclement weather conditions remains a major challenge because of poor visibility. In this article, we address the object detection problem in the presence of fog by introducing a novel dual-subnet network (DSNet) that can be trained end-to-end and jointly learn three tasks: visibility enhancement, object classification, and object localization. DSNet attains complete performance improvement by including two subnetworks: detection subnet and restoration subnet. We employ RetinaNet as a backbone network (also called detection subnet), which is responsible for learning to classify and locate objects. The restoration subnet is designed by sharing feature extraction layers with the detection subnet and adopting a feature recovery (FR) module for visibility enhancement. Experimental results show that our DSNet achieved 50.84 percent mean average precision (mAP) on a synthetic foggy dataset that we composed and 41.91 percent mAP on a public natural foggy dataset (Foggy Driving dataset), outperforming many state-of-the-art object detectors and combination models between dehazing and detection methods while maintaining a high speed.	[Huang, Shih-Chia] Natl Taipei Univ Technol, Dept Elect Engn, Taipei 10608, Taiwan; [Le, Trung-Hieu] Natl Taipei Univ Technol, Int Grad Program Elect Engn & Comp Sci, Taipei 10608, Taiwan; [Jaw, Da-Wei] Natl Taiwan Univ, Dept Elect Engn, Taipei 10617, Taiwan	National Taipei University of Technology; National Taipei University of Technology; National Taiwan University	Huang, SC (corresponding author), Natl Taipei Univ Technol, Dept Elect Engn, Taipei 10608, Taiwan.	schuang@ntut.edu.tw; hieult.ktmt@gmail.com; jdw.davidjaw@gmail.com		Jaw, David/0000-0002-9903-5910; Le, Trung-Hieu/0000-0001-5766-4199	Ministry of Science and Technology, Taiwan [MOST 108-2221-E-027-047-MY3, MOST 106-2221-E-027-017-MY3, MOST 108-2638-E-002-002-MY2, MOST 108-2218-E-009-056]	Ministry of Science and Technology, Taiwan(Ministry of Science and Technology, TaiwanMinistry of Science, ICT & Future Planning, Republic of Korea)	Thiswork was supported by the Ministry of Science and Technology, Taiwan, under Grant MOST 108-2221-E-027-047-MY3, Grant MOST 106-2221-E-027-017-MY3, Grant MOST 108-2638-E-002-002-MY2, and Grant MOST 108-2218-E-009-056.	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen BH, 2017, IEEE VEH TECHNOL MAG, V12, P20, DOI 10.1109/MVT.2016.2625331; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Everingham M., 2012, PASCAL VISUAL OBJECT; Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang SC, 2016, IEEE COMPUT INTELL M, V11, P46, DOI 10.1109/MCI.2016.2601758; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kingma D.P, P 3 INT C LEARNING R; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le Trung-Hieu, 2018, 2018 7 INT S CIV GEN, P1; Lee KKC, 2019, IEEE ACCESS, V7, P51907, DOI 10.1109/ACCESS.2019.2911541; Li BY, 2018, AAAI CONF ARTIF INTE, P7016; Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396; Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles; Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821; Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306; Rajaram RN, 2016, IEEE T INTELL VEHICL, V1, P358, DOI 10.1109/TIV.2017.2695896; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8; Sun CY, 2019, IEEE ACCESS, V7, P53103, DOI 10.1109/ACCESS.2019.2912094; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643; Teichmann M, 2018, IEEE INT VEH SYM, P1013; Le TH, 2019, IEEE SENS J, V19, P4696, DOI 10.1109/JSEN.2019.2901259; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang G, 2019, IEEE ACCESS, V7, P18840, DOI 10.1109/ACCESS.2019.2897283; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135; Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337; Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865; Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191	53	19	20	12	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2623	2633		10.1109/TPAMI.2020.2977911	http://dx.doi.org/10.1109/TPAMI.2020.2977911			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32149681				2022-12-18	WOS:000670578800008
J	Zhang, WC; Xu, D; Ouyang, WL; Li, W				Zhang, Weichen; Xu, Dong; Ouyang, Wanli; Li, Wen			Self-Paced Collaborative and Adversarial Network for Unsupervised Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Streaming media; Training; Collaboration; Object recognition; Visualization; Optical imaging; Domain adaptation; transfer learning; deep learning; adversarial learning; self-paced learning	KERNEL	This paper proposes a new unsupervised domain adaptation approach called Collaborative and Adversarial Network (CAN), which uses the domain-collaborative and domain-adversarial learning strategies for training the neural network. The domain-collaborative learning strategy aims to learn domain specific feature representation to preserve the discriminability for the target domain, while the domain adversarial learning strategy aims to learn domain invariant feature representation to reduce the domain distribution mismatch between the source and target domains. We show that these two learning strategies can be uniformly formulated as domain classifier learning with positive or negative weights on the losses. We then design a collaborative and adversarial training scheme, which automatically learns domain specific representations from lower blocks in CNNs through collaborative learning and domain invariant representations from higher blocks through adversarial learning. Moreover, to further enhance the discriminability in the target domain, we propose Self-Paced CAN (SPCAN), which progressively selects pseudo-labeled target samples for re-training the classifiers. We employ a self-paced learning strategy such that we can select pseudo-labeled target samples in an easy-to-hard fashion. Additionally, we build upon the popular two-stream approach to extend our domain adaptation approach for more challenging video action recognition task, which additionally considers the cooperation between the RGB stream and the optical flow stream. We propose the Two-stream SPCAN (TS-SPCAN) method to select and reweight the pseudo labeled target samples of one stream (RGB/Flow) based on the information from the other stream (Flow/RGB) in a cooperative way. As a result, our TS-SPCAN model is able to exchange the information between the two streams. Comprehensive experiments on different benchmark datasets, Office-31, ImageCLEF-DA and VISDA-2017 for the object recognition task, and UCF101-10 and HMDB51-10 for the video action recognition task, show our newly proposed approaches achieve the state-of-the-art performance, which clearly demonstrates the effectiveness of our proposed approaches for unsupervised domain adaptation.	[Zhang, Weichen; Xu, Dong; Ouyang, Wanli] Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia; [Li, Wen] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland	University of Sydney; Swiss Federal Institutes of Technology Domain; ETH Zurich	Xu, D (corresponding author), Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia.	weichen.zhang@sydney.edu.au; dong.xu@sydney.edu.au; wanli.ouyang@sydney.edu.au; liwen@vison.ee.ethz.ch	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730	Australian Research Council (ARC) Future Fellowship [FT180100116]; ARC [DP200103223]	Australian Research Council (ARC) Future Fellowship(Australian Research Council); ARC(Australian Research Council)	This work was supported by the Australian Research Council (ARC) Future Fellowship under Grant FT180100116 and ARC DP200103223.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2011, P 17 ACM SIGKDD INT; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Bazaraa MS., 2013, NONLINEAR PROGRAMMIN; Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bickel Steffen, 2007, P 24 INT C MACH LEAR, DOI DOI 10.1145/1273496.1273507; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; BUSTO PP, IN PRESS, DOI DOI 10.1109/TPAMI.2018.2880750; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Chen M., 2011, ADV NEURAL INFORM PR, P2456, DOI DOI 10.1016/B978-012545025-6/50150-7; Ding ZM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5434; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Yaroslav, 2015, ICML; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gulrajani I, 2017, P NIPS 2017; He K., 2017, P IEEE INT C COMP VI, P2961, DOI DOI 10.1109/ICCV.2017.322; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffman J, 2018, PR MACH LEARN RES, V80; Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629; Hu LQ, 2018, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2018.00162; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jamal Arshad, 2018, BMVC; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kang GL, 2018, LECT NOTES COMPUT SC, V11215, P420, DOI 10.1007/978-3-030-01252-6_25; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; Li W, 2018, IEEE T PATTERN ANAL, V40, P2030, DOI 10.1109/TPAMI.2017.2734890; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Ming-Yu, 2016, ADV NEURAL INFORM PR, P2; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2016, ADV NEUR IN, V29; Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397; Niu L, 2016, INT J COMPUT VISION, V118, P130, DOI 10.1007/s11263-015-0862-5; Niu L, 2015, IEEE I CONF COMP VIS, P4193, DOI 10.1109/ICCV.2015.477; Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934; Peng XC, 2018, IEEE COMPUT SOC CONF, P2102, DOI 10.1109/CVPRW.2018.00271; Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835; Rozantsev A, 2018, PROC CVPR IEEE, P4339, DOI 10.1109/CVPR.2018.00456; Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042; Russo P, 2018, PROC CVPR IEEE, P8099, DOI 10.1109/CVPR.2018.00845; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K., 2018, ICLR; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Saito K, 2017, PR MACH LEARN RES, V70; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Soomro K., 2012, ARXIV; Sugiyama M., 2008, NIPS, P1433; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tang K., 2012, ADV NEURAL INFORM PR; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; WANG L, 2016, P EUR C COMP VIS; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Yang P., 2013, INT JOINT C ARTIFICI, P1848; Yu FW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1107; Zeng XY, 2014, LECT NOTES COMPUT SC, V8691, P472, DOI 10.1007/978-3-319-10578-9_31; Zhang J, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3291124; Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400; Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	86	19	20	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2047	2061		10.1109/TPAMI.2019.2962476	http://dx.doi.org/10.1109/TPAMI.2019.2962476			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31880543				2022-12-18	WOS:000649590200016
J	Liu, G; Yu, Y; Mora, KAF; Odobez, JM				Liu, Gang; Yu, Yu; Mora, Kenneth A. Funes; Odobez, Jean-Marc			A Differential Approach for Gaze Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Head; Training; Artificial neural networks; Calibration; Robustness; Feature extraction; Gaze estimation; differential network; gaze calibration		Most non-invasive gaze estimation methods regress gaze directions directly from a single face or eye image. However, due to important variabilities in eye shapes and inner eye structures amongst individuals, universal models obtain limited accuracies and their output usually exhibit high variance as well as subject dependent biases. Thus, increasing accuracy is usually done through calibration, allowing gaze predictions for a subject to be mapped to her actual gaze. In this article, we introduce a novel approach, which works by directly training a differential convolutional neural network to predict gaze differences between two eye input images of the same subject. Then, given a set of subject specific calibration images, we can use the inferred differences to predict the gaze direction of a novel eye sample. The assumption is that by comparing eye images of the same user, annoyance factors (alignment, eyelid closing, illumination perturbations) which usually plague single image prediction methods can be much reduced, allowing better prediction altogether. Furthermore, the differential network itself can be adapted via finetuning to make predictions consistent with the available user reference pairs. Experiments on 3 public datasets validate our approach which constantly outperforms state-of-the-art methods even when using only one calibration sample or those relying on subject specific gaze adaptation.	[Liu, Gang; Yu, Yu; Odobez, Jean-Marc] Idiap Res Inst, CH-1920 Martigny, Switzerland; [Mora, Kenneth A. Funes] Eyeware Tech SA, CH-1920 Martigny, Switzerland		Odobez, JM (corresponding author), Idiap Res Inst, CH-1920 Martigny, Switzerland.	gang.liu@idiap.ch; yyu@idiap.ch; kenneth@eyeware.ch; odobez@idiap.ch			innosuisse - Swiss Innovation Agency	innosuisse - Swiss Innovation Agency	This article was supported by innosuisse - Swiss Innovation Agency, on project "Robust Eye-Gaze Estimation Deep Neural Network (REGENN)". The project was held by Idiap Research Institute, cooperated with Eyeware tech SA.	Andrist S, 2014, ACMIEEE INT CONF HUM, P25, DOI 10.1145/2559636.2559666; [Anonymous], 2017, ARXIV170303624; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Deng H, 2017, IEEE I CONF COMP VIS, P3162, DOI 10.1109/ICCV.2017.341; Funes K. A. Mora, 2014, P IEEE C COMP VIS PA; Funes Mora K.A., 2014, P S EYE TRACK RES AP, P255; Funes-Mora KA, 2016, INT J COMPUT VISION, V118, P194, DOI 10.1007/s11263-015-0863-4; Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952; Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30; Huang Q., 2015, ARXIV150801244; Ishii R, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2757284; Koch G., 2015, P 32 INT C MACH LEAR, V2; Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239; Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581; Lanata A, 2015, J EYE MOVEMENT RES, V8; Liu Gang, 2018, P BRIT MACH VIS C, V2, P6; Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123; Masko D., 2017, THESIS KTH ROYAL I T; Moon A, 2014, ACMIEEE INT CONF HUM, P334, DOI 10.1145/2559636.2559656; Mora KAF, 2014, PROC CVPR IEEE, P1773, DOI 10.1109/CVPR.2014.229; Pfeiffer T., 2008, P VIRT ERW REAL FUNF, P81; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Simonyan K., 2014, 3 INT C LEARN REPR I; Sugano Y, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P363, DOI 10.1145/2807442.2807445; Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235; Sun L, 2014, IEEE MULTIMEDIA, V21, P28, DOI 10.1109/MMUL.2014.54; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Tonsen Marc, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130971; Toser Z, 2016, LECT NOTES ARTIF INT, V9904, P200, DOI 10.1007/978-3-319-46073-4_20; Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Vidal M, 2012, COMPUT COMMUN, V35, P1306, DOI 10.1016/j.comcom.2011.11.002; Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797; Wang K, 2017, IEEE I CONF COMP VIS, P1003, DOI 10.1109/ICCV.2017.114; Wood E, 2016, LECT NOTES COMPUT SC, V9905, P297, DOI 10.1007/978-3-319-46448-0_18; Wood Erroll, 2014, ACM S EYE TRACK RES, P3; Xiong Y., 2019, P IEEE C COMP VIS PA; Yu Y., 2018, P EUR C COMP VIS WOR, P456; Yu Y, 2019, PROC CVPR IEEE, P11929, DOI 10.1109/CVPR.2019.01221; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zhang C, 2018, MULTIMED TOOLS APPL, V77, P19679, DOI 10.1007/s11042-017-5426-y; Zhang XC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174198; Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103; Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284; Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081	45	19	19	7	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1092	1099		10.1109/TPAMI.2019.2957373	http://dx.doi.org/10.1109/TPAMI.2019.2957373			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31804927	Green Submitted			2022-12-18	WOS:000616309900024
J	Xu, XW; Zhang, XY; Yu, B; Hu, XS; Rowen, C; Hu, JT; Shi, YY				Xu, Xiaowei; Zhang, Xinyi; Yu, Bei; Hu, Xiaobo Sharon; Rowen, Christopher; Hu, Jingtong; Shi, Yiyu			DAC-SDC Low Power Object Detection Challenge for UAV Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Graphics processing units; Field programmable gate arrays; Task analysis; Unmanned aerial vehicles; Hardware; Throughput; Dataset; benchmark; object detection; unmanned aerial vehicles; low power		The 55th Design Automation Conference (DAC) held its first System Design Contest (SDC) in 2018. SDC'18 features a lower power object detection challenge (LPODC) on designing and implementing novel algorithms based object detection in images taken from unmanned aerial vehicles (UAV). The dataset includes 95 categories and 150k images, and the hardware platforms include Nvidia's TX2 and Xilinx's PYNQ Z1. DAC-SDC'18 attracted more than 110 entries from 12 countries. This paper presents in detail the dataset and evaluation procedure. It further discusses the methods developed by some of the entries as well as representative results. The paper concludes with directions for future improvements.	[Xu, Xiaowei; Hu, Xiaobo Sharon; Shi, Yiyu] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; [Yu, Bei] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China; [Zhang, Xinyi; Hu, Jingtong] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA; [Rowen, Christopher] Cognite Venture, 210 Mission St, Santa Cruz, CA 95060 USA	University of Notre Dame; Chinese University of Hong Kong; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Xu, XW (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.	xxu8@nd.edu; xinyizhang@pitt.edu; byu@cse.cuhk.edu.hk; shu@nd.edu; rowen@cogniteventures.com; jthu@pitt.edu; yshi4@nd.edu	Zhang, Xinyi/ADO-0487-2022; Hu, Xiaobo/B-9367-2018	Zhang, Xinyi/0000-0002-9307-1654; Hu, Xiaobo/0000-0002-6636-9738				Chao HY, 2013, INT CONF UNMAN AIRCR, P710; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gauen K, 2018, DES AUT TEST EUROPE, P700, DOI 10.23919/DATE.2018.8342099; Gauen K, 2017, ASIA S PACIF DES AUT, P99, DOI 10.1109/ASPDAC.2017.7858303; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Howard A.G., 2017, ABS170404861 CORR; Iandola F.N., 2016, ARXIV PREPRINT ARXIV; Janssen B, 2017, 2017 INT C RECONFIGU, P1; Kragh MF, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112579; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Lu YH, 2015, ICCAD-IEEE ACM INT, P927, DOI 10.1109/ICCAD.2015.7372672; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sanmorino A., 2012, COMPUT ENG APPL J, V1, P25; Torres-Sanchez J, 2015, COMPUT ELECTRON AGR, V114, P43, DOI 10.1016/j.compag.2015.03.019; Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3	22	19	19	8	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					392	403		10.1109/TPAMI.2019.2932429	http://dx.doi.org/10.1109/TPAMI.2019.2932429			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31395535	Green Submitted			2022-12-18	WOS:000607383300002
J	Kohler, T; Batz, M; Naderi, F; Kaup, A; Maier, A; Riess, C				Kohler, Thomas; Batz, Michel; Naderi, Farzad; Kaup, Andre; Maier, Andreas; Riess, Christian			Toward Bridging the Simulated-to-Real Gap: Benchmarking Super-Resolution on Real Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Benchmark testing; Databases; Spatial resolution; Observers; Cameras; Hardware; Super-resolution; ground truth; simulated-to-real gap; benchmark; quantitative evaluation; observer study	IMAGE QUALITY ASSESSMENT; RECONSTRUCTION; ALGORITHMS; LIMITS	Capturing ground truth data to benchmark super-resolution (SR) is challenging. Therefore, current quantitative studies are mainly evaluated on simulated data artificially sampled from ground truth images. We argue that such evaluations overestimate the actual performance of SR methods compared to their behavior on real images. Toward bridging this simulated-to-real gap, we introduce the Super-Resolution Erlangen (SupER) database, the first comprehensive laboratory SR database of all-real acquisitions with pixel-wise ground truth. It consists of more than 80k images of 14 scenes combining different facets: CMOS sensor noise, real sampling at four resolution levels, nine scene motion types, two photometric conditions, and lossy video coding at five levels. As such, the database exceeds existing benchmarks by an order of magnitude in quality and quantity. This paper also benchmarks 19 popular single-image and multi-frame algorithms on our data. The benchmark comprises a quantitative study by exploiting ground truth data and qualitative evaluations in a large-scale observer study. We also rigorously investigate agreements between both evaluations from a statistical perspective. One interesting result is that top-performing methods on simulated data may be surpassed by others on real data. Our insights can spur further algorithm development, and the publicy available dataset can foster future evaluations.	[Kohler, Thomas; Naderi, Farzad; Maier, Andreas] Friedrich Alexander Univ FAU Erlangen Nurnberg, Pattern Recognit Lab, D-91058 Erlangen, Germany; [Batz, Michel; Kaup, Andre] Friedrich Alexander Univ FAU Erlangen Nurnberg, Chair Multimedia Commun & Signal Proc, D-91058 Erlangen, Germany; [Riess, Christian] FAU Erlangen Nurnberg, IT Secur Infrastruct Lab, D-91058 Erlangen, Germany	University of Erlangen Nuremberg; University of Erlangen Nuremberg; University of Erlangen Nuremberg	Kohler, T (corresponding author), Friedrich Alexander Univ FAU Erlangen Nurnberg, Pattern Recognit Lab, D-91058 Erlangen, Germany.	thomas.koehler@fau.de; michel.baetz@fau.de; farzad.naderi@fau.de; andre.kaup@fau.de; andreas.maier@fau.de; christian.riess@fau.de	Maier, Andreas/AAV-6505-2021	Maier, Andreas/0000-0002-9550-5284; Batz, Michel/0000-0002-7071-7731				Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; [Anonymous], 2016, CHIN AM EDUC RES DEV; Babacan SD, 2011, IEEE T IMAGE PROCESS, V20, P984, DOI 10.1109/TIP.2010.2080278; Bae W, 2017, IEEE COMPUT SOC CONF, P1141, DOI 10.1109/CVPRW.2017.152; Batz M, 2016, IEEE IMAGE PROC, P2822, DOI 10.1109/ICIP.2016.7532874; Batz M, 2015, IEEE IMAGE PROC, P58, DOI 10.1109/ICIP.2015.7350759; Batz M, 2014, SIGNAL PROCESS-IMAGE, V29, P191, DOI 10.1016/j.image.2013.08.016; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Basler AG, 2019, BASLER ACA2000 50GM; Batz M., 2016, P INT WORKSH MULTIME, P1; Bercea C, 2016, IEEE IMAGE PROC, P1136, DOI 10.1109/ICIP.2016.7532535; Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; Capel D, 2003, IEEE SIGNAL PROC MAG, V20, P75, DOI 10.1109/MSP.2003.1203211; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Edmund Optics Ltd, 2016, HIGH RES FIX FOC LEN; Farsiu S, 2006, IEEE T IMAGE PROCESS, V15, P141, DOI 10.1109/TIP.2005.860336; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Farsiu S., 2016, MULTIDIMENSIONAL SIG; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Geiping J., 2017, INT WORKSH EN MIN ME, P123; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Gotoh T, 2004, PROC CVPR IEEE, P600; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kim US, 2014, IEEE T CIRC SYST VID, V24, P384, DOI 10.1109/TCSVT.2013.2278142; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Kohler T, 2016, IEEE T COMPUT IMAG, V2, P42, DOI 10.1109/TCI.2016.2516909; Kohler T, 2015, MED IMAGE ANAL, V24, P220, DOI 10.1016/j.media.2015.06.011; Kohler T, 2014, LECT NOTES COMPUT SC, V8673, P650, DOI 10.1007/978-3-319-10404-1_81; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li Y, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, TECHNOLOGIES AND APPLICATIONS (ICTA 2018), P166, DOI 10.1109/CICTA.2018.8705961; Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Liu Ce, 2009, THESIS, P2; Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006; Liu YM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508391; Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009; Ma ZY, 2015, PROC CVPR IEEE, P5224, DOI 10.1109/CVPR.2015.7299159; Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x; Milanfar P., 2010, SUPER RESOLUTION IMA; Milne M, 2013, 2013 IEEE SYMPOSIUM ON INTELLIGENT AGENT (IA), P13, DOI 10.1109/IA.2013.6595184; Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726; Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; Plotz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294; Punnappurath A, 2015, IEEE I CONF COMP VIS, P558, DOI 10.1109/ICCV.2015.71; Qu CC, 2016, IEEE IMAGE PROC, P2812, DOI 10.1109/ICIP.2016.7532872; Robinson D, 2006, IEEE T IMAGE PROCESS, V15, P1413, DOI 10.1109/TIP.2006.871079; Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Salvador J, 2015, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2015.45; Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003; Schuon S, 2009, PROC CVPR IEEE, P343, DOI 10.1109/CVPRW.2009.5206804; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959; Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389; SHEIKH HR, 2016, LIVE IMAGE QUALITY A; Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206; Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8; Vandewalle P., 2016, LCAV SUPER RESOLUTIO; Vandewalle P., 2010, SUPER RESOLUTION IMA, P155; Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wirgin A, 2004, ARXIVMATHPH0401050; Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yeganeh H, 2012, IEEE IMAGE PROC, P1481, DOI 10.1109/ICIP.2012.6467151; Yuan QQ, 2012, IEEE T CIRC SYST VID, V22, P379, DOI 10.1109/TCSVT.2011.2163447; Zeng XY, 2013, DIGIT SIGNAL PROCESS, V23, P98, DOI 10.1016/j.dsp.2012.06.013; Zhang HY, 2012, SIGNAL PROCESS, V92, P2082, DOI 10.1016/j.sigpro.2012.01.020; Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344; Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang Yulun, 2018, P EUROPEAN C COMPUTE, P286	82	19	20	3	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2944	2959		10.1109/TPAMI.2019.2917037	http://dx.doi.org/10.1109/TPAMI.2019.2917037			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31095478	Green Submitted			2022-12-18	WOS:000575381000015
J	Shamwell, EJ; Lindgren, K; Leung, S; Nothwang, WD				Shamwell, E. Jared; Lindgren, Kyle; Leung, Sarah; Nothwang, William D.			Unsupervised Deep Visual-Inertial Odometry with Online Error Correction for RGB-D Imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Trajectory; Image reconstruction; Simultaneous localization and mapping; Estimation; Visualization; Jacobian matrices; Visual-inertial odometry; unsupervised deep learning; refinement; localization; neural networks	KALMAN FILTER; VISION; SLAM	While numerous deep approaches to the problem of vision-aided localization have been recently proposed, systems operating in the real world will undoubtedly experience novel sensory states previously unseen even under the most prodigious training regimens. We address the localization problem with online error correction (OEC) modules that are trained to correct a vision-aided localization network's mistakes. We demonstrate the generalizability of the OEC modules and describe our unsupervised deep neural network approach to the fusion of RGB-D imagery with inertial measurements for absolute trajectory estimation. Our network, dubbed the Visual-Inertial-Odometry Learner (VIOLearner), learns to perform visual-inertial odometry (VIO) without inertial measurement unit (IMU) intrinsic parameters or the extrinsic calibration between an IMU and camera. The network learns to integrate IMU measurements and generate hypothesis trajectories which are then corrected online according to the Jacobians of scaled image projection errors with respect to spatial grids of pixel coordinates. We evaluate our network against state-of-the-art (SoA) VIO, visual odometry (VO), and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI Odometry dataset as well as a micro aerial vehicle (MAV) dataset that we collected in the AirSim simulation environment. We demonstrate better than SoA translational localization performance against comparable SoA approaches on our evaluation sequences.	[Shamwell, E. Jared; Lindgren, Kyle; Leung, Sarah; Nothwang, William D.] US Army Res Lab, Adelphi, MD 20783 USA; [Lindgren, Kyle] Univ Washington, BioRobot Lab, Seattle, WA 98195 USA	United States Department of Defense; United States Army; US Army Research, Development & Engineering Command (RDECOM); US Army Research Laboratory (ARL); University of Washington; University of Washington Seattle	Shamwell, EJ (corresponding author), US Army Res Lab, Adelphi, MD 20783 USA.	earl.j.shamwell.civ@mail.mil; kyle.m.lindgren.ctr@mail.mil; sarah.leung.ctr@mail.mil; willaim.d.nothwang.civ@mail.mil		Lindgren, Kyle/0000-0002-8216-074X				Anandan P., 1993, MOTION ANAL IMAGE SE, P1; [Anonymous], 2018, P EUR C COMP VIS ECC; Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326; Bloesch M, 2017, INT J ROBOT RES, V36, P1053, DOI 10.1177/0278364917728574; Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033; Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638; Clark R, 2017, AAAI CONF ARTIF INTE, P3995; Dai P, 2018, ADV TOP SCI TECH CHI, P857, DOI 10.1007/978-3-662-54575-1_17; Delmerico J., 2018, MEMORY, V10, P20; Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584; Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810; Galfond M. N., 2014, THESIS; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405; Godard Clement, 2017, CVPR, V2, P7; Ji Zhang, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5051, DOI 10.1109/ICRA.2017.7989589; Kavukcuoglu K, 2015, ADV NEURAL INF PROCE, P2017; Klein George, 2007, P1; Laidlow T, 2017, IEEE INT C INT ROBOT, P6741; Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813; Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251; Li RH, 2018, IEEE INT CONF ROBOT, P7286; Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594; Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184; Majdik AL, 2017, INT J ROBOT RES, V36, P269, DOI 10.1177/0278364917702237; Moravec H. P., 1980, CMURITR3 STANF U; Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Nister D., 2004, COMP VIS PATT REC 20, V1, pI; Pang FM, 2017, IEEE INT C INT ROBOT, P1761; Pfrommer Bernd, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3847, DOI 10.1109/ICRA.2017.7989443; Pillai S, 2017, IEEE INT C INT ROBOT, P5533; Resnick R, 1966, PHYSICS; Schubert D, 2018, IEEE INT C INT ROBOT, P1680, DOI 10.1109/IROS.2018.8593419; Shah S., 2018, FIELD SERVICE ROBOTI, P621, DOI 10.1007/978-3-319-67361-5_40; Shamwell E. J., 2018, ARXIV180305850; Shamwell EJ, 2018, IEEE INT C INT ROBOT, P2524, DOI 10.1109/IROS.2018.8593573; Shamwell EJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051427; Smolyanskiy N, 2018, P IEEE C COMP VIS PA, P1007; Song SY, 2016, IEEE T PATTERN ANAL, V38, P730, DOI 10.1109/TPAMI.2015.2469274; SRINIVASAN MV, 1991, VISUAL NEUROSCI, V6, P519, DOI 10.1017/S095252380000136X; Sun K, 2018, IEEE ROBOT AUTOM LET, V3, P965, DOI 10.1109/LRA.2018.2793349; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Weiss S, 2011, J FIELD ROBOT, V28, P854, DOI 10.1002/rob.20412; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhang J, 2014, IEEE INT C INT ROBOT, P4973, DOI 10.1109/IROS.2014.6943269; Zhou T., 2017, CVPR, V2, P7; Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18	51	19	22	9	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2478	2493		10.1109/TPAMI.2019.2909895	http://dx.doi.org/10.1109/TPAMI.2019.2909895			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	30990417	Bronze			2022-12-18	WOS:000567471300012
J	Zhang, DX; Wang, L; Zhang, LM; Dai, BT; Shen, HT				Zhang, Dongxiang; Wang, Lei; Zhang, Luming; Dai, Bing Tian; Shen, Heng Tao			The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem Solvers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Feature extraction; Mathematical model; Cognition; Natural languages; Deep learning; Math word problem; semantic parser; reasoning; survey; natural language processing; machine learning	EFFICIENT; COMPUTER; TESTS; GAME; GO	Solving mathematical word problems (MWPs) automatically is challenging, primarily due to the semantic gap between human-readable words and machine-understandable logics. Despite the long history dated back to the 1960s, MWPs have regained intensive attention in the past few years with the advancement of Artificial Intelligence (AI). Solving MWPs successfully is considered as a milestone towards general AI. Many systems have claimed promising results in self-crafted and small-scale datasets. However, when applied on large and diverse datasets, none of the proposed methods in the literature achieves high precision, revealing that current MWP solvers still have much room for improvement. This motivated us to present a comprehensive survey to deliver a clear and complete picture of automatic math problem solvers. In this survey, we emphasize on algebraic word problems, summarize their extracted features and proposed techniques to bridge the semantic gap, and compare their performance in the publicly accessible datasets. We also cover automatic solvers for other types of math problems such as geometric problems that require the understanding of diagrams. Finally, we identify several emerging research directions for the readers with interests in MWPs.	[Zhang, Dongxiang; Zhang, Luming] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China; [Wang, Lei; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China; [Wang, Lei; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China; [Dai, Bing Tian] Singapore Management Univ, Sch Informat Syst, Singapore 188065, Singapore	Zhejiang University; University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; Singapore Management University	Zhang, DX (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China.	zhangdongxiang37@gmail.com; demolei@outlook.com; zglumg@gmail.com; btdai@smu.edu.sg; shenhengtao@hotmail.com	Shen, Heng Tao/ABD-5331-2021		National Natural Science Foundation of China [61602087, 61632007]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported in part by the National Natural Science Foundation of China under grants No. 61602087 and 61632007.	Alvin C., 2015, CORR; Alvin C, 2017, LECT NOTES ARTIF INT, V10331, P455, DOI 10.1007/978-3-319-61425-0_39; Alvin C, 2014, AAAI CONF ARTIF INTE, P245; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bakman Y., 2007, MATH E PRINTS; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bengio Y., 2014, ARXIV14061078; Bengtson Eric, 2008, P C EMP METH NAT LAN, P294; Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447; Bu YH, 2016, INT CONF ACOUST SPEE, P4254, DOI 10.1109/ICASSP.2016.7472479; Bulko W. C., 1988, Proceedings. The First International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems IEA/AIE - 88, P894, DOI 10.1145/55674.55704; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Chang Kai-Wei, 2013, P 2013 C EMPIRICAL M, P601; Charniak E., 1969, PROC IJCAI, P303; Chen D., 2014, P 2014 C EMPIRICAL M, P740, DOI DOI 10.3115/V1/D14-1082; Cheng G., 2016, P 25 INT JOINT C ART, P2479; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Chiang T., 2018, CORR; Clark P, 2016, AAAI CONF ARTIF INTE, P2580; Clark P, 2015, AAAI CONF ARTIF INTE, P4019; Clark P, 2016, AI MAG, V37, P5, DOI 10.1609/aimag.v37i1.2636; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; De Marneffe M.-C., 2006, P LREC, V6, P449; De Raedt L, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2468; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dries A, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3981; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; EARLEY J, 1970, COMMUN ACM, V13, P94, DOI 10.1145/362007.362035; Feigenbaum EA., 1963, COMPUTERS THOUGHT; Ferguson E, 1998, MCGH COMP C, P109; Ferguson RW, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P510; FLETCHER CR, 1985, BEHAV RES METH INSTR, V17, P565, DOI 10.3758/BF03207654; Fleuriot J., 2001, DISTINGUISHED DISSER, DOI 10.1007/978-0-85729-329-9; Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019; Gebser M., 2012, ANSWER SET SOLVING P; Gelernter Herbert, 1995, COMPUT THOUGHT, P134; Goldberg Yoav, 2010, HUMAN LANGUAGE TECHN, P742; Goldwasser D., 2011, INT JOINT C ART INT, P1794; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Guo H., 2015, ARXIV E PRINTS; Guo L, 2018, ACM T INFORM SYST, V36, DOI 10.1145/3182164; Haghighi Aria, 2009, P 2009 C EMP METH NA, P1152; Hajishirzi Hannaneh, 2013, EMNLP, P289, DOI DOI 10.1007/978-3-642-13486-921; Herbrich R, 2000, ADV NEUR IN, P115; Hernandez-Orallo J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5005; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hosseini M. J., 2014, PROC C EMPIRICAL MET, P523, DOI [10.3115/v1/D14-1058, DOI 10.3115/V1/D14-1058]; Huang DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P887; Huang Danqing, 2018, P 27 INT C COMP LING, P213; Jung CR, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P113; Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15; Knuth D. E., 1968, Mathematical Systems Theory, V2, P127, DOI 10.1007/BF01692511; Koller D., 2009, PROBABILISTIC GRAPHI; Koncel-Kedziorski R., 2016, P 2016 C N AM CHAPT, P1152, DOI 10.18653/v1/N16-1136; Koncel-Kedziorski R., 2015, T ASS COMPUTATIONAL, V3, P585; Koncel-Kedziorski Rik, 2016, P C EMP METH NAT LAN, P1617, DOI DOI 10.18653/V1/D16-1168; Kushman N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P271; Kwiatkowski T., 2013, P 2013 C EMP METH NA, P1545; Lagunovsky D, 1999, PATTERN RECOGN LETT, V20, P1005, DOI 10.1016/S0167-8655(99)00067-7; Lee H., 2011, P 15 C COMPUTATIONAL, P28; Lev Iddo, 2004, P 2 WORKSHOP TEXT ME, DOI [10.3115/1628275.1628277, DOI 10.3115/1628275.1628277]; Liang Chao-Chun, 2016, P 2016 C N AM CHAPT, P67; Lin C, 1998, COMPUT VIS IMAGE UND, V72, P101, DOI 10.1006/cviu.1998.0724; LIN XG, 1985, COMPUT VISION GRAPH, V30, P84, DOI 10.1016/0734-189X(85)90020-9; Lin Z., 2017, ARXIV E PRINTS; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luong Minh-Thang, 2015, ARXIV151106114; Ma Yuhui, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P476, DOI 10.1109/ETCS.2010.316; Mahanta N, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND ELECTRONICS SYSTEMS (ICCES), P522; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Mitra A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2144; Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220; Narasimhan K., 2015, ARXIV150608941; Narasimhan Karthik, 2016, ARXIV160307954; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Novak G. S.  Jr., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence, P465; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Polozov O, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P381; Raghunathan Karthik, 2010, P 2010 C EMP METH NA, P492; Robaidek B., 2018, DATA DRIVEN METHODS; Roy S., 2015, T ASSOC COMPUT LING, V3, P1, DOI DOI 10.1162/TACL_A_00118; Roy S., 2017, ARXIV E PRINTS; Roy S., 2015, P 2015 C EMP METH NA, P1743, DOI 10.18653/v1/D15-1202; Roy S., 2016, P 2016 C EMP METH NA, P1088; Roy S, 2017, AAAI CONF ARTIF INTE, P3082; Sachan M., 2017, P C EMP METH NAT LAN, P784; Seo M.J., 2015, P 2015 C EMPIRICAL M, P1466; Seo MJ, 2014, AAAI CONF ARTIF INTE, P2831; Shapiro L.G., 2001, COMPUTER VISION; Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887; Shi S., 2015, P 2015 C EMP METH NA, P1132, DOI 10.18653/v1/D15-1135; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Singhal Rahul, 2014, 6th International Conference on Computer-Supported Education (CSEDU 2014). Proceedings, P467; Singhal R, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MOOC, INNOVATION AND TECHNOLOGY IN EDUCATION (MITE), P148, DOI 10.1109/MITE.2014.7020259; Siyam B, 2017, PROCEDIA COMPUT SCI, V117, P153, DOI 10.1016/j.procs.2017.10.104; SLAGLE JR, 1965, COMMUN ACM, V8, P792, DOI 10.1145/365691.365960; Socher R., 2013, LONG PAPERS, V1, P455; Song J., 2019, IEEE T NEURAL NETW L, V30; Srihari R. K., 1994, Artificial Intelligence Review, V8, P349, DOI 10.1007/BF00849725; Sundaram S. S., 2015, P 12 INT C NAT LANG, P394; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Upadhyay S, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P494; Upadhyay Shyam, 2016, P 2016 C EMP METH NA, P297; Wang B, 2017, IEEE INT CONF CON AU, P805; Wang H., 2016, EMNLP 16, P541; Wang K., 2016, 25 INT JOINT C ART I, P2661; Wang L, 2019, P AAAI C ART INT; Wang L, 2018, AAAI CONF ARTIF INTE, P5545; Wang L, 2018, INT CONF SOFTW ENG, P1066, DOI 10.1109/ICSESS.2018.8663865; Wang X. J., 2017, ENV DEV SUSTAIN, V4, P1; Wang Y, 2019, TRANSPORT RES C-EMER, V99, P144, DOI 10.1016/j.trc.2018.12.004; Wang YM, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P845, DOI 10.1109/ITNEC.2017.8284854; Watanabe Y., 1998, P ANN M ASS COMP LIN, P1374; Wiseman Sam, 2016, ARXIV160602960; Wu S, 2016, PROC INT CONF DATA, P1218, DOI 10.1109/ICDE.2016.7498326; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422; Yu XG, 2016, FIFTH INTERNATIONAL CONFERENCE ON EDUCATIONAL INNOVATION THROUGH TECHNOLOGY (EITT 2016), P242, DOI 10.1109/EITT.2016.55; Yu XG, 2015, 2015 INTERNATIONAL CONFERENCE OF EDUCATIONAL INNOVATION THROUGH TECHNOLOGY - EITT 2015, P51, DOI 10.1109/EITT.2015.17; Zhang DX, 2019, INFORM FUSION, V52, P268, DOI 10.1016/j.inffus.2019.03.005; Zhang DX, 2011, PROC INT CONF DATA, P1103, DOI 10.1109/ICDE.2011.5767837; Zhang Dongxiang, 2017, ACM T INFO SYST, V35, P1; Zhou L., 2015, P 2015 C EMP METH NA, P817, DOI 10.18653/v1/D15-1096; Zhu YX, 2003, IEEE T MED IMAGING, V22, P1053, DOI 10.1109/TMI.2003.816947	129	19	19	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2287	2305		10.1109/TPAMI.2019.2914054	http://dx.doi.org/10.1109/TPAMI.2019.2914054			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	31056490	Green Accepted, Green Submitted			2022-12-18	WOS:000557354900015
J	Adeli, E; Li, XR; Kwon, D; Zhang, Y; Pohl, KM				Adeli, Ehsan; Li, Xiaorui; Kwon, Dongjin; Zhang, Yong; Pohl, Kilian M.			Logistic Regression Confined by Cardinality-Constrained Sample and Feature Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparsity; non-convex optimization; feature selection; sample selection; imbalanced classification; logistic regression	IMMUNODEFICIENCY-VIRUS-INFECTION; VARIABLE SELECTION; HIV-INFECTION; SPARSE; VOLUME; REGULARIZATION; IMPAIRMENT; ALCOHOLISM; SHRINKAGE; RELEVANCE	Many vision-based applications rely on logistic regression for embedding classification within a probabilistic context, such as recognition in images and videos or identifying disease-specific image phenotypes from neuroimages. Logistic regression, however, often performs poorly when trained on data that is noisy, has irrelevant features, or when the samples are distributed across the classes in an imbalanced setting; a common occurrence in visual recognition tasks. To deal with those issues, researchers generally rely on adhoc regularization techniques or model a subset of these issues. We instead propose a mathematically sound logistic regression model that selects a subset of (relevant) features and (informative and balanced) set of samples during the training process. The model does so by applying cardinality constraints (via l(0)-'norm' sparsity) on the features and samples. l(0) defines sparsity in mathematical settings but in practice has mostly been approximated (e.g., via l(1) or its variations) for computational simplicity. We prove that a local minimum to the non-convex optimization problems induced by cardinality constraints can be computed by combining block coordinate descent with penalty decomposition. On synthetic, image recognition, and neuroimaging datasets, we show that the accuracy of the method is higher than alternative methods and classifiers commonly used in the literature.	[Adeli, Ehsan] Stanford Univ, Stanford, CA 94305 USA; [Li, Xiaorui] Simon Fraser Univ, Dept Math, Burnaby, BC V5A 1S6, Canada; [Kwon, Dongjin; Pohl, Kilian M.] SRI Int, Ctr Hlth Sci, Menlo Pk, CA 94025 USA; [Kwon, Dongjin; Pohl, Kilian M.] Stanford Univ, Dept Psychiat & Behav Sci, Stanford, CA 94305 USA; [Zhang, Yong] Huawei, Vancouver Res Ctr, Burnaby, BC V5C 6S7, Canada	Stanford University; Simon Fraser University; SRI International; Stanford University; Huawei Technologies	Pohl, KM (corresponding author), SRI Int, Ctr Hlth Sci, Menlo Pk, CA 94025 USA.; Pohl, KM (corresponding author), Stanford Univ, Dept Psychiat & Behav Sci, Stanford, CA 94305 USA.	eadeli@stanford.edu; xla97@sfu.ca; dj0330@gmail.com; yong.zhang3@huawei.com; kilian.pohl@stanford.edu		Adeli, Ehsan/0000-0002-0579-7763; Zhang, Yong/0000-0002-0238-0719	NIH [U01-AA017347, R37-AA010723, K05-AA017168, R01-MH113406, R01-HL127661, AA005965, AA026762]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This research was supported in part by NIH grants U01-AA017347, R37-AA010723, K05-AA017168, R01-MH113406, R01-HL127661, AA005965, and AA026762. The authors also would like to thank Drs. Zirui Zhou (Hong Kong Baptist University), Bin Dong (Peking University), Qingyu Zhao (Stanford University), and Lisa M. Jack (SRI and Stanford) for proofreading and their inputs on the theoretical aspects of the paper. Ehsan Adeli and Xiaorui Li contributed equally to this work.	Adeli E, 2019, IEEE T PATTERN ANAL, V41, P515, DOI 10.1109/TPAMI.2018.2794470; Adeli E, 2017, SCI REP-UK, V7, DOI 10.1038/srep41069; Adeli E, 2016, NEUROIMAGE, V141, P206, DOI 10.1016/j.neuroimage.2016.05.054; Adeli-Mosabbeb E., 2015, ADV NEURAL INFORM PR, P658; Adeli-Mosabbeb E, 2015, IMAGE VISION COMPUT, V39, P38, DOI 10.1016/j.imavis.2015.04.006; Agresti A., 2003, CATEGORICAL DATA ANA, P211; An Le, 2016, Med Image Comput Comput Assist Interv, V9901, P79, DOI 10.1007/978-3-319-46723-8_10; [Anonymous], 2014, ADV NEURAL INFORM PR; [Anonymous], 1970, ITERATIVE SOLUTION N; Austin PC, 2015, J CLIN EPIDEMIOL, V68, P627, DOI 10.1016/j.jclinepi.2014.12.014; AYLWARD EH, 1993, NEUROLOGY, V43, P2099, DOI 10.1212/WNL.43.10.2099; Berkson J, 1944, J AM STAT ASSOC, V39, P357, DOI 10.2307/2280041; Blumensath T, 2008, J FOURIER ANAL APPL, V14, P629, DOI 10.1007/s00041-008-9035-z; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Bron E, 2014, LECT NOTES COMPUT SC, V8679, P272, DOI 10.1007/978-3-319-10581-9_34; Bursac Z, 2008, SOURCE CODE BIOL MED, V3, DOI 10.1186/1751-0473-3-17; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Coupe P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087; Djamanakova A, 2014, NEUROIMAGE, V101, P168, DOI 10.1016/j.neuroimage.2014.06.046; Ertekin S, 2013, LECT NOTES ELECTR EN, V264, P261, DOI 10.1007/978-3-319-01604-7_26; Fama R, 2014, BRAIN IMAGING BEHAV, V8, P611, DOI 10.1007/s11682-013-9286-4; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fisher RA, 1935, J R STAT SOC, V98, P39, DOI 10.2307/2342435; Forsgren A, 2002, SIAM REV, V44, P525, DOI 10.1137/S0036144502414942; Foucart S, 2009, APPL COMPUT HARMON A, V26, P395, DOI 10.1016/j.acha.2008.09.001; Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Gu Q., 2011, GEN FISHER SCORE FEA, P266; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; Hosmer D. W., 2013, APPL LOGISTIC REGRES, V398; Huber P. J, 1981, ROBUST STAT; Hwang JP, 2011, EXPERT SYST APPL, V38, P8580, DOI 10.1016/j.eswa.2011.01.061; Kallianpur KJ, 2013, NEUROLOGY, V80, P1792, DOI 10.1212/WNL.0b013e318291903f; Kallianpur KJ, 2012, CEREB CORTEX, V22, P2065, DOI 10.1093/cercor/bhr285; Kang Q, 2017, IEEE T CYBERNETICS, V47, P4263, DOI 10.1109/TCYB.2016.2606104; Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Lu ZS, 2018, MATH OPER RES, V43, P1290, DOI 10.1287/moor.2017.0905; Lu ZS, 2013, SIAM J OPTIMIZ, V23, P2448, DOI 10.1137/100808071; Maalouf M, 2011, COMPUT STAT DATA AN, V55, P168, DOI 10.1016/j.csda.2010.06.014; Madsen H., 2010, INTRO GEN GEN LINEAR; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Mohsenzadeh Y, 2013, IEEE T CYBERNETICS, V43, P2241, DOI 10.1109/TCYB.2013.2260736; Murase H, 1996, CUCS00696 COL U; Mwangi B, 2014, NEUROINFORMATICS, V12, P229, DOI 10.1007/s12021-013-9204-3; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435; Ng V, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P55; Nie F., 2010, ADV NEURAL INFORM PR, V2, P1813; Oh JH, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P464; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Pfefferbaum A, 2006, NEUROIMAGE, V33, P239, DOI 10.1016/j.neuroimage.2006.05.052; Pfefferbaum A, 2014, NEUROBIOL AGING, V35, P1755, DOI 10.1016/j.neurobiolaging.2014.01.008; Pfefferbaum A, 2012, BIOL PSYCHIAT, V72, P361, DOI 10.1016/j.biopsych.2012.02.018; PREGIBON D, 1981, ANN STAT, V9, P705, DOI 10.1214/aos/1176345513; Ragin B, 2012, NEUROLOGY, V79, P2328, DOI 10.1212/WNL.0b013e318278b5b4; Rosa MJ, 2015, NEUROIMAGE, V105, P493, DOI 10.1016/j.neuroimage.2014.11.021; Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Sanford R, 2017, JAIDS-J ACQ IMM DEF, V74, P563, DOI 10.1097/QAI.0000000000001294; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Stout JC, 1998, ARCH NEUROL-CHICAGO, V55, P161, DOI 10.1001/archneur.55.2.161; Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909; Thompson PM, 2005, P NATL ACAD SCI USA, V102, P15647, DOI 10.1073/pnas.0502548102; Thung KH, 2014, NEUROIMAGE, V91, P386, DOI 10.1016/j.neuroimage.2014.01.033; Tibshirani J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P124; Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Underwood J, 2017, CLIN INFECT DIS, V65, P422, DOI 10.1093/cid/cix301; Wade BSC, 2015, PROC SPIE, V9417, DOI 10.1117/12.2082241; Wan X, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-135; Wang JH, 2012, PATTERN RECOGN, V45, P1136, DOI 10.1016/j.patcog.2011.09.004; Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892; Xia Y, 2015, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2015.177; Yan S., 2014, ADV NEURAL INFORM PR, P253; Zellner D, 2004, COMMUN STAT-SIMUL C, V33, P787, DOI 10.1081/SAC-200033363; Zhang T, 2010, J MACH LEARN RES, V11, P1081; Zhang Y, 2017, MED IMAGE ANAL, V35, P58, DOI 10.1016/j.media.2016.05.011; Zhang Y, 2016, HUM BRAIN MAPP, V37, P4523, DOI 10.1002/hbm.23326; Zimmerman DW, 1997, J EDUC BEHAV STAT, V22, P349, DOI 10.3102/10769986022003349; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	90	19	19	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1713	1728		10.1109/TPAMI.2019.2901688	http://dx.doi.org/10.1109/TPAMI.2019.2901688			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	30835210	Green Accepted			2022-12-18	WOS:000542967200015
J	Jauer, P; Kuhlemann, I; Bruder, R; Schweikard, A; Ernst, F				Jauer, Philipp; Kuhlemann, Ivo; Bruder, Ralf; Schweikard, Achim; Ernst, Floris			Efficient Registration of High-Resolution Feature Enhanced Point Clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point cloud; registration; rigid; efficiency; high-resolution; features; graphics processors; CUDA; Monte Carlo; simulated annealing; rigid-body dynamics; many-particle systems; Newton's law; Coulomb's law	SURFACE REGISTRATION; ALGORITHMS	We present a novel framework for rigid point cloud registration. Our approach is based on the principles of mechanics and thermodynamics. We solve the registration problem by assuming point clouds as rigid bodies consisting of particles. Forces can be applied between both particle systems so that they attract or repel each other. These forces are used to cause rigid-body motion of one particle system toward the other, until both are aligned. The framework supports physics-based registration processes with arbitrary driving forces, depending on the desired behaviour. Additionally, the approach handles feature-enhanced point clouds, e.g., by colours or intensity values. Our framework is freely accessible for download. In contrast to already existing algorithms, our contribution is to precisely register high-resolution point clouds with nearly constant computational effort and without the need for pre-processing, sub-sampling or pre-alignment. At the same time, the quality is up to 28 percent higher than for state-of-the-art algorithms and up to 49 percent higher when considering feature-enhanced point clouds. Even in the presence of noise, our registration approach is one of the most robust, on par with state-of-the-art implementations.	[Jauer, Philipp; Kuhlemann, Ivo; Bruder, Ralf; Schweikard, Achim; Ernst, Floris] Univ Lubeck, Inst Robot & Cognit Syst, D-23562 Lubeck, Germany	University of Lubeck	Jauer, P (corresponding author), Univ Lubeck, Inst Robot & Cognit Syst, D-23562 Lubeck, Germany.	jauer@rob.uni-luebeck.de; kuhlemann@rob.uni-luebeck.de; bruder@rob.uni-luebeck.de; schweikard@rob.uni-luebeck.de; ernst@rob.uni-luebeck.de	Ernst, Floris/F-2915-2013	Ernst, Floris/0000-0002-0474-6673				[Anonymous], 2015, FDN TRENDS ROBOT, DOI [10.1561/9781680830255, DOI 10.1561/2300000035]; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Attia M, 2016, I C COMP GRAPH IM VI, P45, DOI 10.1109/CGiV.2016.18; Audette MA, 2000, MED IMAGE ANAL, V4, P201, DOI 10.1016/S1361-8415(00)00014-1; Bellekens B., 2014, AMBIENT 2014 4 INT C, pp 8; Bellekens B., 2015, INT, V8, P118; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Diez Y, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2692160; Douadi L, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P663, DOI 10.1109/IROS.2006.282551; Dreizler R. M., 2010, THEORETICAL MECH THE; Druon S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P249, DOI 10.1109/ICIA.2006.306004; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Golyanik V, 2016, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR.2016.625; Hansung Kim, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P202, DOI 10.1109/3DV.2014.51; Hong H., 2016, INT J COMPUT THEORY, V8; Huhle B, 2008, IEEE INT CONF ROBOT, P4025, DOI 10.1109/ROBOT.2008.4543829; Johnson AE, 1999, IMAGE VISION COMPUT, V17, P135, DOI 10.1016/S0262-8856(98)00117-6; Joung JH, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3082, DOI 10.1109/IROS.2009.5354500; KIRKPATRICK S, 1984, J STAT PHYS, V34, P975, DOI 10.1007/BF01009452; Kjer H.M., 2010, THESIS; Kjer M., 2012, ITERATIVE CLOSEST PO; Korn M, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P592; Levoy M., 2005, STANFORD 3D SCANNING; Magnusson M, 2007, J FIELD ROBOT, V24, P803, DOI 10.1002/rob.20204; Magnusson M, 2015, IEEE INT CONF ROBOT, P3631, DOI 10.1109/ICRA.2015.7139703; Men H, 2014, J COMPUT DES ENG, V1, P223, DOI 10.7315/JCDE.2014.022; Men H, 2011, IEEE INT CONF ROBOT, P1511; Myronenko A., 2009, COHERENT POINT DRIFT; Myronenko A., 2007, ADV NEURAL INFORM PR, V19, P1009, DOI DOI 10.1109/TPAMI.20; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Nolting W., 2013, GRUNDKURS THEORETISC; Park SY, 2003, PATTERN RECOGN LETT, V24, P2967, DOI 10.1016/S0167-8655(03)00157-0; Pears N, 2012, 3D IMAGING ANAL APPL; Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2; Pottmann H, 2006, INT J COMPUT VISION, V67, P277, DOI 10.1007/s11263-006-5167-2; Rangarajan A, 1997, Med Image Anal, V1, P379; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012; Santamaria J, 2011, COMPUT VIS IMAGE UND, V115, P1340, DOI 10.1016/j.cviu.2011.05.006; Spong M. W., 2006, ROBOT MODELING CONTR, V3; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; The MathWorks Inc. Natick Massachusetts USA, 2016, COMP VIS SYST TOOLB; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Turk G., 2007, LARGE GEOMETRIC MODE; Wissel T, 2016, INT J RADIAT ONCOL, V95, P810, DOI 10.1016/j.ijrobp.2016.01.041; Zanuttigh P., 2016, 3D SCENE RECONSTRUCT	51	19	22	11	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1102	1115		10.1109/TPAMI.2018.2831670	http://dx.doi.org/10.1109/TPAMI.2018.2831670			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29994022				2022-12-18	WOS:000463607400006
J	Bera, A; Klesk, P; Sychel, D				Bera, Aneta; Klesk, Przemyslaw; Sychel, Dariusz			Constant-Time Calculation of Zernike Moments for Detection with Rotational Invariance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Complex-valued integral images; Zernike moments; detection; rotational invariance; constant-time feature extraction	FOURIER-MELLIN MOMENTS; FAST COMPUTATION	We construct a set of special complex-valued integral images and an algorithm that allows to calculate Zernike moments fast, namely in constant time. The technique is suitable for dense detection procedures, where the image is scanned by a sliding window at multiple scales, and where rotational invariance is required at the level of each window. We assume no preliminary image segmentation. Owing to the proposed integral images and binomial expansions, the extraction of each feature does not depend on the number of pixels in the window and thereby is an O(1) calculation. We analyze algorithmic properties of the proposition, such as: number of needed integral images, complex-conjugacy of integral images, number of operations involved in feature extraction, speed-up possibilities based on lookup tables. We also point out connections between Zernike and orthogonal Fourier-Mellin moments in the context of computations backed with integral images. Finally, we demonstrate three examples of detection tasks of varying difficulty. Detectors are trained on the proposed features by the RealBoost algorithm. When learning, the classifiers get acquainted only with examples of target objects in their upright position or rotated within a limited range. At the testing stage, generalization onto the full 360 degrees angle takes place automatically.	[Bera, Aneta; Klesk, Przemyslaw; Sychel, Dariusz] West Pomeranian Univ Technol, Fac Comp Sci & Informat Technol, PL-70310 Szczecin, Poland	West Pomeranian University of Technology	Bera, A (corresponding author), West Pomeranian Univ Technol, Fac Comp Sci & Informat Technol, PL-70310 Szczecin, Poland.	abera@wi.zut.edu.pl; pklesk@wi.zut.edu.pl; dsychel@wi.zut.edu.pl	Sychel, Dariusz/J-2207-2016; Bera, Aneta/J-2208-2016	Sychel, Dariusz/0000-0001-9835-869X; Bera, Aneta/0000-0002-0456-9451; Klesk, Przemyslaw/0000-0002-5579-187X	National Science Centre, Poland [2016/21/B/ST6/01495]	National Science Centre, Poland(National Science Centre, Poland)	This work was financed by the National Science Centre, Poland. Research project no.: 2016/21/B/ST6/01495.	ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; [Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174265; Costea AD, 2014, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2014.307; Crow F. C., 1984, Computers & Graphics, V18, P207; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gu J, 2002, PATTERN RECOGN, V35, P2905, DOI 10.1016/S0031-3203(01)00194-7; Gueham M, 2008, PROCEEDINGS OF THE 2008 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, P487, DOI 10.1109/AHS.2008.48; Hosny KM, 2011, J REAL-TIME IMAGE PR, V6, P73, DOI 10.1007/s11554-009-0135-z; Juan L., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8; Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5; Klesk P, 2017, LECT NOTES ARTIF INT, V10245, P530, DOI 10.1007/978-3-319-59063-9_47; Liao S., 2015, FAST ACCURATE UNCONS; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; Papakostas GA, 2007, IET COMPUT VIS, V1, P11, DOI 10.1049/iet-cvi:20060130; Papakostas G. A., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P153, DOI 10.1109/IWSSIP.2007.4381176; RASOLZADEH B, 2006, IEEE INT VEH S GOLD, P344; Ren HY, 2015, IEEE I CONF COMP VIS, P46, DOI 10.1109/ICCV.2015.14; Said Y., 2011, 2011 INT C COMM COMP, P1, DOI [10.1109/CCCA.2011.6031422, DOI 10.1109/CCCA.2011.6031422]; SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748; Singh C, 2012, J MATH IMAGING VIS, V44, P411, DOI 10.1007/s10851-012-0335-1; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Terrillon JC, 2000, INT C PATT RECOG, P993, DOI 10.1109/ICPR.2000.906242; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Zernike F, 1934, PHYSICA, V1, P668	26	19	19	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					537	551		10.1109/TPAMI.2018.2803828	http://dx.doi.org/10.1109/TPAMI.2018.2803828			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993477				2022-12-18	WOS:000458168800002
J	Tzelepis, C; Mezaris, V; Patras, I				Tzelepis, Christos; Mezaris, Vasileios; Patras, Ioannis			Linear Maximum Margin Classifier for Learning from Uncertain Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification; convex optimization; Gaussian anisotropic uncertainty; large margin methods; learning with uncertainty; statistical learning theory	SUPPORT VECTOR MACHINE; REGULARIZATION PATH; ROBUSTNESS	In this paper, we propose a maximum margin classifier that deals with uncertainty in data input. More specifically, we reformulate the SVM framework such that each training example can be modeled by a multi-dimensional Gaussian distribution described by its mean vector and its covariance matrix-the latter modeling the uncertainty. We address the classification problem and define a cost function that is the expected value of the classical SVM cost when data samples are drawn from the multi-dimensional Gaussian distributions that form the set of the training examples. Our formulation approximates the classical SVM formulation when the training examples are isotropic Gaussians with variance tending to zero. We arrive at a convex optimization problem, which we solve efficiently in the primal form using a stochastic gradient descent approach. The resulting classifier, which we name SVM with Gaussian Sample Uncertainty (SVM-GSU), is tested on synthetic data and five publicly available and popular datasets; namely, the MNIST, WDBC, DEAP, TV News Channel Commercial Detection, and TRECVID MED datasets. Experimental results verify the effectiveness of the proposed method.	[Tzelepis, Christos; Patras, Ioannis] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England; [Tzelepis, Christos; Mezaris, Vasileios] Ctr Res & Technol Hellas CERTH, Informat Technol Inst, Thermi 57001, Greece	University of London; Queen Mary University London; Centre for Research & Technology Hellas	Tzelepis, C (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.; Tzelepis, C (corresponding author), Ctr Res & Technol Hellas CERTH, Informat Technol Inst, Thermi 57001, Greece.	c.tzelepis@qmul.ac.uk; bmezaris@iti.gr; i.patras@qmul.ac.uk	; Tzelepis, Christos/O-6413-2015	Patras, Ioannis/0000-0003-3913-4738; Tzelepis, Christos/0000-0002-2036-9089	EU [H2020-693092]	EU(European Commission)	This work was supported by the EU's Horizon 2020 programme H2020-693092 MOVING. We would also like to thank the authors of [13] for providing an implementation of Power SVM.	Alizadeh F, 2003, MATH PROGRAM, V95, P3, DOI 10.1007/s10107-002-0339-5; Ben-Tal A, 1998, MATH OPER RES, V23, P769, DOI 10.1287/moor.23.4.769; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bertsimas D, 2011, SIAM REV, V53, P464, DOI 10.1137/080734510; Bhattacharyya C., 2004, ADV NEURAL INFORM PR, P153; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Crammer K, 2013, MACH LEARN, V91, P155, DOI 10.1007/s10994-013-5327-x; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Deisenroth MP, 2015, IEEE T PATTERN ANAL, V37, P408, DOI 10.1109/TPAMI.2013.218; Diplaros A, 2006, IEEE T IMAGE PROCESS, V15, P1, DOI 10.1109/TIP.2005.860320; Dredze M., 2008, P 25 INT C MACHINE L, V307, P264, DOI DOI 10.1145/1390156.1390190; Ghio Alessandro, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. 22nd International Conference on Artificial Neural Networks, P156, DOI 10.1007/978-3-642-33266-1_20; Gkalelis N, 2013, IEEE T NEUR NET LEAR, V24, P8, DOI 10.1109/TNNLS.2012.2216545; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Hines W. W., 2008, PROBABILITY STAT ENG; Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068; Jiang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P27, DOI 10.1145/2671188.2749399; Joshi Ajay J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2372, DOI 10.1109/CVPRW.2009.5206627; Kakade Sham M, 2009, ADV NEURAL INFORM PR, P801; Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15; Lanckriet G. R. G., 2003, J MACHINE LEARNING R, V3, P555; Li MK, 2006, IEEE T PATTERN ANAL, V28, P1251, DOI 10.1109/TPAMI.2006.156; Li YP, 2013, IEEE T KNOWL DATA EN, V25, P2463, DOI 10.1109/TKDE.2012.179; Lichman M, 2013, UCI MACHINE LEARNING; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Liwicki S, 2012, IEEE T NEUR NET LEAR, V23, P1624, DOI 10.1109/TNNLS.2012.2208654; Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P1820, DOI 10.1109/TNN.2009.2031144; Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Over P., 2015, P TRECVID 2015 NIST; Platt JC, 2000, ADV NEUR IN, P61; Qi ZQ, 2013, PATTERN RECOGN, V46, P305, DOI 10.1016/j.patcog.2012.06.019; Rosasco L, 2004, NEURAL COMPUT, V16, P1063, DOI 10.1162/089976604773135104; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sarafis I, 2015, INT J MULTIMED INF R, V4, P129, DOI 10.1007/s13735-015-0080-5; Sentelle CG, 2016, IEEE T NEUR NET LEAR, V27, P709, DOI 10.1109/TNNLS.2015.2427333; Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4; Shivaswamy PK, 2006, J MACH LEARN RES, V7, P1283; Solera F, 2016, IEEE T PATTERN ANAL, V38, P995, DOI 10.1109/TPAMI.2015.2470658; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tsirelson B. S., 1976, NORMS GAUSSIAN SAMPL, P20, DOI [10.1007/BFb0077482, DOI 10.1007/BFB0077482]; Tzelepis C., 2013, P 21 ACM INT C MULT, P673; Tzelepis C, 2016, IMAGE VISION COMPUT, V53, P35, DOI 10.1016/j.imavis.2015.09.005; Vyas A., 2014, P 2014 IND C COMP VI; Wang J., 2012, INT C MACHINE LEARNI, P107; WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901; Xu H, 2012, MACH LEARN, V86, P391, DOI 10.1007/s10994-011-5268-1; Xu H, 2009, J MACH LEARN RES, V10, P1485; Zhang J. B. T., 2004, ADV NEURAL INF PROCE, V17, P161; Zhang T, 2004, ANN STAT, V32, P56; Zhang WY, 2012, PROC CVPR IEEE, P2144, DOI 10.1109/CVPR.2012.6247921	53	19	20	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2948	2962		10.1109/TPAMI.2017.2772235	http://dx.doi.org/10.1109/TPAMI.2017.2772235			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990153	Green Published, Green Accepted			2022-12-18	WOS:000449355500012
J	Li, CX; Zhu, J; Zhang, B				Li, Chongxuan; Zhu, Jun; Zhang, Bo			Max-Margin Deep Generative Models for (Semi-)Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep generative models; max-margin learning; variational inference; supervised and semi-supervised learning		Deep generative models (DGMs) can effectively capture the underlying distributions of complex data by learning multilayered representations and performing inference. However, it is relatively insufficient to boost the discriminative ability of DGMs. This paper presents max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs), which explore the strongly discriminative principle of max-margin learning to improve the predictive performance of DGMs in both supervised and semi-supervised learning, while retaining the generative capability. In semi-supervised learning, we use the predictions of a max-margin classifier as the missing labels instead of performing full posterior inference for efficiency; we also introduce additional max-margin and label-balance regularization terms of unlabeled data for effectiveness. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objectives in different settings. Empirical results on various datasets demonstrate that: (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; (2) in supervised learning, mmDGMs are competitive to the best fully discriminative networks when employing convolutional neural networks as the generative and recognition models; and (3) in semi-supervised learning, mmDCGMs can perform efficient inference and achieve state-of-the-art classification results on several benchmarks.	[Li, Chongxuan; Zhu, Jun; Zhang, Bo] Tsinghua Univ, Dept Comp Sci & Technol, TNList Lab, State Key Lab Intelligent Technol & Syst,Ctr Bioi, Beijing 100084, Peoples R China	Tsinghua University	Zhu, J (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, TNList Lab, State Key Lab Intelligent Technol & Syst,Ctr Bioi, Beijing 100084, Peoples R China.	chongxuanli1991@gmail.com; dcszj@tsinghua.edu.cn; dcszb@tsinghua.edu.cn			National Basic Research Program (973 Program) of China [2013CB329403]; National NSF of China [61620106010, 61621136008, 61332007]; Youth Top-notch Talent Support Program, Tsinghua Tiangong Institute for Intelligent Computing; NVIDIA NVAIL Program	National Basic Research Program (973 Program) of China(National Basic Research Program of China); National NSF of China(National Natural Science Foundation of China (NSFC)); Youth Top-notch Talent Support Program, Tsinghua Tiangong Institute for Intelligent Computing; NVIDIA NVAIL Program	The work was supported by the National Basic Research Program (973 Program) of China (No. 2013CB329403), National NSF of China (Nos. 61620106010, 61621136008, 61332007), the Youth Top-notch Talent Support Program, Tsinghua Tiangong Institute for Intelligent Computing and the NVIDIA NVAIL Program.	Al-Rfou R., 2016, ARXIV160502688; ALTUN Y, 2003, P 20 INT C MACH LEAR, P1; [Anonymous], 2016, 4 INT C LEARN REPR; Bai Y, 2014, PROC INT CONF RECON; Bengio Y., 2014, P INT C MACH LEARN; Bengio Y., 2013, P 26 INT C NEUR INF, P899; Bornschein J., 2015, INT C LEARN REPR ICL; Burda Y., 2015, P INT C LEARN REPR; Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Denton E, 2015, DEEP GENERATIVE IMAG, DOI DOI 10.5555/; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Du C., 2017, IEEE T NEURAL NETW L; Dziugaite GK, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P258; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K., 2014, P INT C MACH LEARN; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; He K., 2015, CVPR, V7, P171, DOI DOI 10.3389/FPSYG.2013.00124; Hinton G., 2012, COURSERA VIDEO LECT, V264, P66; Ioffe S, 2015, ARXIV 1502 03167, V32, P448; Kingma D.P., 2015, ICLR, P1; Kingma DP, 2014, ADV NEUR IN, P3581, DOI DOI 10.5555/2969033.2969226; Larochelle H., 2011, INT C ART INT STAT; LeCun Y, 2004, PROC CVPR IEEE, P97; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lee H, 2009, INT C MACH LEARN, P77; Li C., 2015, NIPS; Li C, 2016, PROCEEDINGS OF 2016 INTERNATIONAL SYMPOSIUM - FEMALE SURVIVAL AND DEVELOPMENT, P177; Li YJ, 2015, PR MACH LEARN RES, V37, P1718; Little R. J., 2014, J MACH LEARN RES, V539; Maaloe L, 2016, PR MACH LEARN RES, V48; Miller K., 2012, P 15 INT C ART INT S, P779; Miyato T., 2015, STAT MACH LEARN, V1050; Mnih A., 2014, P INT C MACH LEARN; Netzer Y., 2011, P INT C ADV NEUR INF; Radford A., 2015, P INT C LEARN REPR; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2857, DOI 10.1109/CVPR.2011.5995710; Rasmus A., 2015, ADV NEURAL INFORM PR, P3546; Ren Y., 2016, ADV NEURAL INFORM PR, P2928; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Salakhutdinov R., 2009, P 12 INT C ART INT S, P448; Salimans T., 2016, P INT C ADV NEUR INF; Sanjoy D., 2013, INT C MACH LEARN, P1319, DOI DOI 10.5555/3042817.3043084; Saul LK, 1996, J ARTIF INTELL RES, V4, P61, DOI 10.1613/jair.251; Sermanet P, 2012, INT C PATT RECOG, P3288; Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tang Y., 2013, P INT C MACH LEARN C; Taskar B, 2004, ADV NEUR IN, V16, P25; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vapnik V.N, 1998, STAT LEARNING THEORY; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Welling M, 2014, AUTOENCODING VARIATI; Wu Y., 2016, INT C LEARN REPR; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Zeiler M, 2013, P INT C LEARN REPR; Zhu J., 2013, ANTERIOR CRUCIATE LI; Zhu J., 2008, ADV NEURAL INFORM PR, P1977; Zhu J, 2014, J MACH LEARN RES, V15, P1799; Zhu J, 2014, J MACH LEARN RES, V15, P1073; Zhu J, 2012, J MACH LEARN RES, V13, P2237; Zhu X., 2009, SYNTHESIS LECT ARTIF, V3, P1, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]	65	19	20	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2762	2775		10.1109/TPAMI.2017.2766142	http://dx.doi.org/10.1109/TPAMI.2017.2766142			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29989965	Green Submitted, hybrid			2022-12-18	WOS:000446683700018
J	Bellavia, F; Colombo, C				Bellavia, Fabio; Colombo, Carlo			Rethinking the sGLOH Descriptor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Keypoint matching; SIFT; sGLOH; RFDs; LIOP; MIOP; MROGH; CNN descriptors; rotation invariant descriptors; histogram binarization; cascade matching	IMAGE; REPRESENTATION; PERFORMANCE; SELECTION; FEATURES	sGLOH (shifting GLOH) is a histogram-based keypoint descriptor that can be associated to multiple quantized rotations of the keypoint patch without any recomputation. This property can be exploited to define the best distance between two descriptor vectors, thus avoiding computing the dominant orientation. In addition, sGLOH can reject incongruous correspondences by adding a global constraint on the rotations either as an a priori knowledge or based on the data. This paper thoroughly reconsiders sGLOH and improves it in terms of robustness, speed and descriptor dimension. The revised sGLOH embeds more quantized rotations, thus yielding more correct matches. A novel fast matching scheme is also designed, which significantly reduces both computation time and memory usage. In addition, a new binarization technique based on comparisons inside each descriptor histogram is defined, yielding a more compact, faster, yet robust alternative. Results on an exhaustive comparative experimental evaluation show that the revised sGLOH descriptor incorporating the above ideas and combining them according to task requirements, improves in most cases the state of the art in both image matching and object recognition.	[Bellavia, Fabio; Colombo, Carlo] Univ Florence, Dept Informat Engn, Via S Marta, I-50139 Florence, Italy	University of Florence	Bellavia, F (corresponding author), Univ Florence, Dept Informat Engn, Via S Marta, I-50139 Florence, Italy.	bellavia.fabio@gmail.com; carlo.colombo@unifi.it	Colombo, Carlo/AAC-6675-2019; Bellavia, Fabio/N-6790-2018	Bellavia, Fabio/0000-0002-1688-8476; COLOMBO, CARLO/0000-0001-9234-537X	SUONO project (Safe Underwater Operations iN Oceans) [SCN_00306]	SUONO project (Safe Underwater Operations iN Oceans)	The authors would like to thank Giosue Lo Bosco, Domenico Tegolo and Cesare Valenti for granting access to the computational resources of the University of Palermo. This work was supported by the SUONO project (Safe Underwater Operations iN Oceans), SCN_00306, ranked first in the challenge on "Sea Technologies" of the competitive call named "Smart Cities and Communities" issued by the Italian Ministry of Education and Research.	Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Baber J, 2014, IMAGE VISION COMPUT, V32, P940, DOI 10.1016/j.imavis.2014.08.006; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bellavia F, 2014, IMAGE VISION COMPUT, V32, P559, DOI 10.1016/j.imavis.2014.05.002; Bellavia F, 2011, IET COMPUT VIS, V5, P87, DOI 10.1049/iet-cvi.2009.0127; Bellavia F, 2015, LECT NOTES COMPUT SC, V9279, P354, DOI 10.1007/978-3-319-23231-7_32; Bellavia F, 2013, LECT NOTES COMPUT SC, V8156, P270; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; CHENG HN, 2008, PROC WIR COMM NETW, V999, P1, DOI DOI 10.1109/ICEPT.2008.4607150; Chi-Yi Tsai, 2013, Journal of Software, V8, P2197, DOI 10.4304/jsw.8.9.2197-2201; Choi Y, 2015, LECT NOTES COMPUT SC, V9003, P569, DOI 10.1007/978-3-319-16865-4_37; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981; Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277; Fraundorfer F., 2005, P IEEE C COMP VIS PA; Gauglitz S, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.93; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hartley R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587638; Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842; Heikkila M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014; Hua G, 2007, IEEE I CONF COMP VIS, P229; Ke Y, 2004, PROC CVPR IEEE, P506; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Levi G, 2016, P IEEE WINT C APPL C, P1, DOI DOI 10.1109/WACV.2016.7477723; LING H, 2006, P IEEE C COMP VIS PA, V1, P246, DOI DOI 10.1109/CVPR.2006.99; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Miksik O, 2012, INT C PATT RECOG, P2681; Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Shao H., 260 SWISS FED I TECH; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Treen G., 2009, P WORKSH APPL COMP V, P1, DOI DOI 10.1109/WACV.2009.5403099; Trzcinski T., 2012, ADV NEURAL INFORM PR, P269, DOI DOI 10.1177/1753193411419945; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang ZH, 2016, IEEE T PATTERN ANAL, V38, P2198, DOI 10.1109/TPAMI.2015.2513396; Wang ZH, 2014, LECT NOTES COMPUT SC, V8695, P94, DOI 10.1007/978-3-319-10584-0_7; Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294; Xu XW, 2014, IEEE T IMAGE PROCESS, V23, P2983, DOI 10.1109/TIP.2014.2324824; Yang TY, 2016, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.2016.42; Yi KM, 2016, PROC CVPR IEEE, P107, DOI 10.1109/CVPR.2016.19; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263	61	19	20	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					931	944		10.1109/TPAMI.2017.2697849	http://dx.doi.org/10.1109/TPAMI.2017.2697849			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28459683	Green Submitted			2022-12-18	WOS:000426687100012
J	Balntas, V; Tang, LL; Mikolajczyk, K				Balntas, Vassileios; Tang, Lilian; Mikolajczyk, Krystian			Binary Online Learned Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Learning feature descriptors; binary descriptors; feature matching; image matching		We propose a novel approach to generate a binary descriptor optimized for each image patch independently. The approach is inspired by the linear discriminant embedding that simultaneously increases inter and decreases intra class distances. A set of discriminative and uncorrelated binary tests is established from all possible tests in an offline training process. The patch adapted descriptors are then efficiently built online from a subset of features which lead to lower intra-class distances and thus, to a more robust descriptor. We perform experiments on three widely used benchmarks and demonstrate improvements in matching performance, and illustrate that per-patch optimization outperforms global optimization.	[Balntas, Vassileios; Mikolajczyk, Krystian] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England; [Tang, Lilian] Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, Surrey, England	Imperial College London; University of Surrey	Balntas, V (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England.	v.balntas@imperial.ac.uk; h.tang@surrey.ac.uk; k.mikolajczyk@imperial.ac.uk			EPSRC [EP/K01904X/2, EP/N007743/1]; Engineering and Physical Sciences Research Council [EP/N007743/1, EP/K01904X/2] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by EPSRC EP/K01904X/2 Visen and EP/N007743/1 FACER2VM projects.	[Anonymous], [No title captured]; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bolle RM, 2004, INT C PATT RECOG, P927, DOI 10.1109/ICPR.2004.1334411; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89; Calonder M., 2010, P 11 EUR C COMM VIS; Chandrasekhar Vijay, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2504, DOI 10.1109/CVPRW.2009.5206733; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Fischer P, 2014, ARXIV14055769; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Hinz S., 2016, ARXIV161007804; Hollingsworth KP, 2009, IEEE T PATTERN ANAL, V31, P964, DOI 10.1109/TPAMI.2008.185; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; Tuytelaars T, 2007, IEEE I CONF COMP VIS, P754; Winder S., 2007, P IEEE C COMP VIS PA, P5385; Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yang TY, 2016, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.2016.42; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zhang G, 2016, IEEE INT CONF ROBOT, P765, DOI 10.1109/ICRA.2016.7487205; Zhang L, 2013, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2013.208	36	19	22	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					555	567		10.1109/TPAMI.2017.2679193	http://dx.doi.org/10.1109/TPAMI.2017.2679193			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28333620	Green Submitted			2022-12-18	WOS:000424465900004
J	Lefloch, D; Kluge, M; Sarbolandi, H; Weyrich, T; Kolb, A				Lefloch, Damien; Kluge, Markus; Sarbolandi, Hamed; Weyrich, Tim; Kolb, Andreas			Comprehensive Use of Curvature for Robust and Accurate Online Surface Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; curvature; depth fusion; camera tracking; differential geometry	REGISTRATION	Interactive real-time scene acquisition from hand-held depth cameras has recently developed much momentum, enabling applications in ad-hoc object acquisition, augmented reality and other fields. A key challenge to online reconstruction remains error accumulation in the reconstructed camera trajectory, due to drift-inducing instabilities in the range scan alignments of the underlying iterative-closest-point (ICP) algorithm. Various strategies have been proposed to mitigate that drift, including SIFT-based pre-alignment, color-based weighting of ICP pairs, stronger weighting of edge features, and so on. In our work, we focus on surface curvature as a feature that is detectable on range scans alone and hence does not depend on accurate multi-sensor alignment. In contrast to previous work that took curvature into consideration, however, we treat curvature as an independent quantity that we consistently incorporate into every stage of the real-time reconstruction pipeline, including densely curvature-weighted ICP, range image fusion, local surface reconstruction, and rendering. Using multiple benchmark sequences, and in direct comparison to other state-of-the-art online acquisition systems, we show that our approach significantly reduces drift, both when analyzing individual pipeline stages in isolation, as well as seen across the online reconstruction pipeline as a whole.	[Lefloch, Damien; Kluge, Markus; Sarbolandi, Hamed; Kolb, Andreas] Univ Siegen, Comp Graph Grp, Hoelderlinstr 3, D-57076 Siegen, Germany; [Weyrich, Tim] UCL, Dept Comp Sci, Gower St, London WC1 6BT, England	Universitat Siegen; University of London; University College London	Lefloch, D (corresponding author), Univ Siegen, Comp Graph Grp, Hoelderlinstr 3, D-57076 Siegen, Germany.	Damien.Lefloch@uni-siegen.de; Markus.Kluge@uni-siegen.de; Hamed.Sarbolandi@uni-siegen.de; t.weyrich@cs.ucl.ac.uk; Andreas.Kolb@uni-siegen.de	Kolb, Andreas/A-2067-2012; Kolb, Andreas/S-8085-2019; Kluge, Markus/X-9308-2019	Kolb, Andreas/0000-0003-4753-7801; Kolb, Andreas/0000-0003-4753-7801; Kluge, Markus/0000-0002-6815-807X; Weyrich, Tim/0000-0002-4322-8844	German Research Foundation (DFG) as part of research training group Imaging New Modalities [GRK 1564]; UK Engineering and Physical Sciences Research Council [EP/K023578/1]; EPSRC [EP/K023578/1, EP/K02339X/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/K02339X/1, EP/K023578/1] Funding Source: researchfish	German Research Foundation (DFG) as part of research training group Imaging New Modalities(German Research Foundation (DFG)); UK Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was funded by the German Research Foundation (DFG) as part of the research training group GRK 1564 Imaging New Modalities, and by the UK Engineering and Physical Sciences Research Council (grant EP/K023578/1).	[Anonymous], [No title captured]; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Botsch M., 2004, EUR S POINT BAS GRAP, P25, DOI DOI 10.2312/SPBG/SPBG04/025-032; Brown BJ, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239472; Chen JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461940; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Cheng ZL, 2009, SCI CHINA SER F, V52, P431, DOI 10.1007/s11432-009-0061-5; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Fioraio N, 2015, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2015.7299077; Gelfand N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P260, DOI 10.1109/IM.2003.1240258; Girardeau-Montaut D., 2013, CLOUDCOMPARE OPENSOU; Godin G., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2350, P279, DOI 10.1117/12.189139; Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134; Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P121, DOI 10.1109/IM.1997.603857; Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141; Kalaiah A, 2001, SPRING EUROGRAP, P139; Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650; Klein George, 2007, P1; Lo TWR, 2009, COMPUT VIS IMAGE UND, V113, P1235, DOI 10.1016/j.cviu.2009.06.005; MacKinnon D, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2955245; Magid E, 2007, COMPUT VIS IMAGE UND, V107, P139, DOI 10.1016/j.cviu.2006.09.007; Maier-Hein L, 2012, IEEE T PATTERN ANAL, V34, P1520, DOI 10.1109/TPAMI.2011.248; Mittring M., 2007, ACM SIGGRAPH 2007 CO, P97, DOI DOI 10.1145/1281500.1281671; NEWCOMBE RA, 2011, INT SYM MIX AUGMENT; Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374; Nigam S., 2013, INT J ENG SCI INNOV, V2, P330; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Roth H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.112; Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Salas-Moreno RF, 2014, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2014.6948422; Sarbolandi H, 2015, COMPUT VIS IMAGE UND, V139, P1, DOI 10.1016/j.cviu.2015.05.006; SCRAFIN J, 2015, P IEEE RSJ INT C INT, P742; Serafin J, 2014, LECT NOTES COMPUT SC, V8810, P566, DOI 10.1007/978-3-319-11900-7_48; Sofka M., P 2007 IEEE C COMP V, P1; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Wasenmuller O., 2016, P IEEE WINT C APPL C; Weik S, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P93, DOI 10.1109/IM.1997.603853; Weise Thibaut, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1630, DOI 10.1109/ICCVW.2009.5457479; Whelan T., 2012, MITCSAILTR2012031; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Zhang X., 2008, P ASIAGRAPH, P72; Zhou QY, 2015, PROC CVPR IEEE, P632, DOI 10.1109/CVPR.2015.7298662; Zhou QY, 2013, IEEE I CONF COMP VIS, P473, DOI 10.1109/ICCV.2013.65; Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919; Zwicker M, 2002, IEEE T VIS COMPUT GR, V8, P223, DOI 10.1109/TVCG.2002.1021576; [No title captured]	49	19	21	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2349	2365		10.1109/TPAMI.2017.2648803	http://dx.doi.org/10.1109/TPAMI.2017.2648803			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28103193	Green Submitted			2022-12-18	WOS:000414395400003
J	Li, B; Yuan, CF; Xiong, WH; Hu, WM; Peng, HW; Ding, XM; Maybank, S				Li, Bing; Yuan, Chunfeng; Xiong, Weihua; Hu, Weiming; Peng, Houwen; Ding, Xinmiao; Maybank, Steve			Multi-View Multi-Instance Learning Based on Joint Sparse Representation and Multi-View Dictionary Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-instance learning; multi-view; sparse representation; dictionary learning	RECOGNITION; CLASSIFICATION; ALGORITHM	In multi-instance learning (MIL), the relations among instances in a bag convey important contextual information in many applications. Previous studies on MIL either ignore such relations or simply model them with a fixed graph structure so that the overall performance inevitably degrades in complex environments. To address this problem, this paper proposes a novel multi-view multi-instance learning algorithm ((MIL)-I-2) that combines multiple context structures in a bag into a unified framework. The novel aspects are: (i) we propose a sparse epsilon-graph model that can generate different graphs with different parameters to represent various context relations in a bag, (ii) we propose a multi-view joint sparse representation that integrates these graphs into a unified framework for bag classification, and (iii) we propose a multi-view dictionary learning algorithm to obtain a multi-view graph dictionary that considers cues from all views simultaneously to improve the discrimination of the M2IL. Experiments and analyses in many practical applications prove the effectiveness of the M2IL.	[Li, Bing; Yuan, Chunfeng; Xiong, Weihua; Peng, Houwen; Ding, Xinmiao] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China; [Hu, Weiming] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Automat,Natl Lab Pattern Recognit, CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100049, Peoples R China; [Maybank, Steve] Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; University of Chinese Academy of Sciences, CAS; University of London; Birkbeck University London	Li, B (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.	bli@nlpr.ia.ac.cn; cfyuan@nlpr.ia.ac.cn; wallace.xiong@gmail.com; wmhu@nlpr.ia.ac.cn; houwen.peng@nlpr.ia.ac.cn; dingxinmiao@126.com; sjmaybank@dcs.bbk.ac.uk		yuan, chun feng/0000-0003-2219-4961; li, bing/0000-0001-6114-1411	Natural Science Foundation of China [61370038, U1636218, 61472421, 61571045]; 973 basic research program of China [2014CB349303]; CAS [XDB02070003]; Youth Innovation Promotion Association, CAS	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); 973 basic research program of China(National Basic Research Program of China); CAS(Chinese Academy of Sciences); Youth Innovation Promotion Association, CAS	This work is partly supported by the Natural Science Foundation of China (Grant Nos. 61370038, U1636218, 61472421, and 61571045), the 973 basic research program of China (Grant No. 2014CB349303), the Strategic Priority Research Program of the CAS (Grant No. XDB02070003), and the CAS External cooperation key project. Bing Li is also supported by Youth Innovation Promotion Association, CAS.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Amores J, 2013, ARTIF INTELL, V201, P81, DOI 10.1016/j.artint.2013.06.003; Andrews S., 2002, SUPPORT VECTOR MACHI, P561; Bergeron C, 2012, IEEE T PATTERN ANAL, V34, P1068, DOI 10.1109/TPAMI.2011.194; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Chen YX, 2004, J MACH LEARN RES, V5, P913; Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764; Cheung P. M., 2006, P 23 INT C MACH LEAR, P193; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DING X, 2012, COMPUTER VISION AC 3, P00599; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Foulds J, 2010, KNOWL ENG REV, V25, P1, DOI 10.1017/S026988890999035X; Fu ZY, 2011, IEEE T PATTERN ANAL, V33, P958, DOI 10.1109/TPAMI.2010.155; Grtner T., 2002, P 19 INT C MACH LEAR, P179; Nguyen HV, 2013, IEEE T IMAGE PROCESS, V22, P5123, DOI 10.1109/TIP.2013.2282078; Li B, 2015, IEEE T IMAGE PROCESS, V24, P5193, DOI 10.1109/TIP.2015.2479400; Li WJ, 2009, PROC CVPR IEEE, P1666, DOI 10.1109/CVPRW.2009.5206796; MARON O, 1998, P 1997 C ADV NEUR IN, V10, P570; Rahmani R, 2006, P 23 INT C MACH LEAR, P705, DOI DOI 10.1145/1143844.1143933; Rahmani R, 2008, IEEE T PATTERN ANAL, V30, P1902, DOI 10.1109/TPAMI.2008.112; Rahmani Rouhollah, 2005, P 7 ACM SIGMM INT WO, P227, DOI DOI 10.1145/1101826.1101863; Song H. J., 2013, P IEEE ACM C ADV SOC, P25; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Wang H, 2011, COMM COM INF SC, V136, P1; Wang J., 2000, PROC 17 INT C MACHIN, P1119; Wang J., 2010, P IEEE C COMP VIS PA, P1063; Wang JC, 2011, INT CONF ACOUST SPEE, P1325; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xu C., 2013, ARXIV; Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363; Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006; Zhang D., 2011, P 24 INT C NEURAL IN, P145; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhang Qi, 2002, P 19 INT C MACH LEAR, P682; Zhou Z.-H., 2007, P 24 INT C MACHINE L, P1167; Zhou Z.-H., 2009, ANN INT C MACH LEARN, P1249, DOI DOI 10.1145/1553374.1553534	38	19	20	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2554	2560		10.1109/TPAMI.2017.2669303	http://dx.doi.org/10.1109/TPAMI.2017.2669303			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28212079	Green Accepted			2022-12-18	WOS:000414395400017
J	Murez, Z; Treibitz, T; Ramamoorthi, R; Kriegman, DJ				Murez, Zak; Treibitz, Tali; Ramamoorthi, Ravi; Kriegman, David J.			Photometric Stereo in a Scattering Medium	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; scattering medium; fluorescence	SHAPE; LIGHT	Photometric stereo is widely used for 3D reconstruction. However, its use in scattering media such as water, biological tissue and fog has been limited until now, because of forward scattered light from both the source and object, as well as light scattered back from the medium (backscatter). Here we make three contributions to address the key modes of light propagation, under the common single scattering assumption for dilute media. First, we show through extensive simulations that single-scattered light from a source can be approximated by a point light source with a single direction. This alleviates the need to handle light source blur explicitly. Next, we model the blur due to scattering of light from the object. We measure the object point-spread function and introduce a simple deconvolution method. Finally, we show how imaging fluorescence emission where available, eliminates the backscatter component and increases the signal-to-noise ratio. Experimental results in a water tank, with different concentrations of scattering media added, show that deconvolution produces higher-quality 3D reconstructions than previous techniques, and that when combined with fluorescence, can produce results similar to that in clear water even for highly turbid media.	[Murez, Zak; Ramamoorthi, Ravi; Kriegman, David J.] Univ Calif San Diego, Dept Comp Sci & Engn, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Treibitz, Tali] Univ Haifa, Charney Sch Marine Sci, Dept Marine Technol, IL-3498838 Haifa, Israel	University of California System; University of California San Diego; University of Haifa	Murez, Z (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, 9500 Gilman Dr, La Jolla, CA 92093 USA.	zmurez@cs.ucsd.edu; ttreibitz@univ.haifa.ac.il; ravir@cs.ucsd.edu; kriegman@cs.ucsd.edu		Treibitz, Tali/0000-0002-3078-282X	US National Science Foundation [ATM-0941760]; ONR [N00014-15-1-2013]; W.M. Keck Foundation; UC San Diego Center for Visual Computing; Ministry of Science, Technology and Space [3-12487]; Technion Ollendorff Minerva Center for Vision and Image Sciences	US National Science Foundation(National Science Foundation (NSF)); ONR(Office of Naval Research); W.M. Keck Foundation(W.M. Keck Foundation); UC San Diego Center for Visual Computing; Ministry of Science, Technology and Space; Technion Ollendorff Minerva Center for Vision and Image Sciences	This work was supported in part by US National Science Foundation grant ATM-0941760, ONR grant N00014-15-1-2013, W.M. Keck Foundation, and by the UC San Diego Center for Visual Computing. Tali Treibitz was supported by the Ministry of Science, Technology and Space grant 3-12487, and the Technion Ollendorff Minerva Center for Vision and Image Sciences.	Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578; Dong B, 2014, PROC CVPR IEEE, P2299, DOI 10.1109/CVPR.2014.294; Galo M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P309, DOI 10.1109/ICIP.1996.560818; Gracias N, 2013, OCEANS-IEEE, DOI 10.1109/OCEANS-Bergen.2013.6608142; Guilbault G.G., 1990, PRACTICAL FLUORESCEN, VSecond; Henyey LG, 1941, ASTROPHYS J, V93, P70, DOI 10.1086/144246; Hullin MB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360686; Inoshita C, 2014, LECT NOTES COMPUT SC, V8690, P346, DOI 10.1007/978-3-319-10605-2_23; Iwahori Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P83, DOI 10.1109/ICPR.1990.118069; JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695; Joshi N., 2008, CVPR, P1; KIM B, 1991, CVGIP-IMAG UNDERSTAN, V54, P416, DOI 10.1016/1049-9660(91)90040-V; Kocak DM, 2008, MAR TECHNOL SOC J, V42, P52, DOI 10.4031/002533208786861209; KOLAGANI N, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1759, DOI 10.1109/ROBOT.1992.220125; Lee KM, 1996, J VIS COMMUN IMAGE R, V7, P155, DOI 10.1006/jvci.1996.0015; McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221; Murez Z, 2015, IEEE I CONF COMP VIS, P3415, DOI 10.1109/ICCV.2015.390; Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420; Narasimhan SG, 2003, PROC CVPR IEEE, P665; Narasimhan SG, 2006, ACM T GRAPHIC, V25, P1003, DOI 10.1145/1141911.1141986; Negahdaripour S, 2002, OCEANS 2002 MTS/IEEE CONFERENCE & EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS, P1010; Pintus R, 2008, IEEE T INSTRUM MEAS, V57, P989, DOI 10.1109/TIM.2007.911580; Sato I, 2012, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2012.6247685; Shashua A., 1992, THESIS; Sun B, 2005, ACM T GRAPHIC, V24, P1040, DOI 10.1145/1073204.1073309; Tanaka K, 2015, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2015.7299185; Tankus A, 2005, IEEE I CONF COMP VIS, P611; Treibitz T, 2012, LECT NOTES COMPUT SC, V7578, P292, DOI 10.1007/978-3-642-33786-4_22; Treibitz T, 2012, J OPT SOC AM A, V29, P1516, DOI 10.1364/JOSAA.29.001516; Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85; Trucco E, 2006, IEEE J OCEANIC ENG, V31, P511, DOI 10.1109/JOE.2004.836395; Tsiotsios C, 2014, PROC CVPR IEEE, P2259, DOI 10.1109/CVPR.2014.289; Tuchin V. V., 2007, TISSUE OPTICS LIGHT; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zhang SM, 2002, IEEE J OCEANIC ENG, V27, P100, DOI 10.1109/48.989895; [No title captured]	37	19	20	4	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1880	1891		10.1109/TPAMI.2016.2613862	http://dx.doi.org/10.1109/TPAMI.2016.2613862			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28114056	Green Submitted, hybrid			2022-12-18	WOS:000406840800014
J	Finlayson, GD; Zakizadeh, R; Gijsenij, A				Finlayson, Graham D.; Zakizadeh, Roshanak; Gijsenij, Arjan			The Reproduction Angular Error for Evaluating the Performance of Illuminant Estimation Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Illuminant estimation; color constancy; performance evaluation; error metric	COLOR CONSTANCY	The angle between the RGBs of the measured illuminant and estimated illuminant colors-the recovery angular error-has been used to evaluate the performance of the illuminant estimation algorithms. However we noticed that this metric is not in line with how the illuminant estimates are used. Normally, the illuminant estimates are 'divided out' from the image to, hopefully, provide image colors that are not confounded by the color of the light. However, even though the same reproduction results the same scene might have a large range of recovery errors. In this work the scale of the problem with the recovery error is quantified. Next we propose a new metric for evaluating illuminant estimation algorithms, called the reproduction angular error, which is defined as the angle between the RGB of a white surface when the actual and estimated illuminations are 'divided out'. Our new metric ties algorithm performance to how the illuminant estimates are used. For a given algorithm, adopting the new reproduction angular error leads to different optimal parameters. Further the ranked list of best to worst algorithms changes when the reproduction angular is used. The importance of using an appropriate performance metric is established.	[Finlayson, Graham D.; Zakizadeh, Roshanak] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England; [Gijsenij, Arjan] Akzo Nobel Decorat Coatings, NL-2171 AJ Sassenheim, Netherlands	University of East Anglia; AkzoNobel	Finlayson, GD (corresponding author), Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.	g.finlayson@uea.ac.uk; r.zakizadeh@uea.ac.uk; arjan.gijsenij@gmail.com	Zakizadeh, Roshanak/AAB-1950-2020	Gijsenij, Arjan/0000-0003-4926-3672	EPSRC [H022236, M001768]; EPSRC [EP/H022236/1, EP/M001768/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/H022236/1, EP/M001768/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This research was supported by EPSRC grants H022236 and M001768.	Banic N., 2015, P INT JOINT C COMP V, P1; Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; Barron JT, 2015, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2015.51; Bianco Simone, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P81, DOI 10.1109/CVPRW.2015.7301275; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Chakrabarti A, 2012, IEEE T PATTERN ANAL, V34, P1509, DOI 10.1109/TPAMI.2011.252; Cheng DL, 2015, IEEE I CONF COMP VIS, P298, DOI 10.1109/ICCV.2015.42; Cheng DL, 2014, J OPT SOC AM A, V31, P1049, DOI 10.1364/JOSAA.31.001049; Chong HY, 2007, IEEE I CONF COMP VIS, P2143; Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160; Conover W. J, 1999, PRACTICAL NONPARAMET, V350; Finlayson G., 2015, P ASS INT COUL COL I, P1; Finlayson G.D., 2014, PERCEPTION, V310, P1; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P3011, DOI 10.1364/JOSAA.11.003011; Finlayson GD, 2013, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2013.239; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359; Funt B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P445, DOI 10.1007/BFb0055683; Gehler PV, 2008, PROC CVPR IEEE, P3291; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; Hubel PM, 2005, Thirteenth Color Imaging Conference, Final Program and Proceedings, P314; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Li B, 2016, INT J COMPUT VISION, V117, P21, DOI 10.1007/s11263-015-0844-7; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; SHI L, 2010, REPROCESSED VERSION; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2, DOI 10.1109/TPAMI.1987.4767868; Zakizadeh R., 2015, P COL IM C, P196	33	19	20	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1482	1488		10.1109/TPAMI.2016.2582171	http://dx.doi.org/10.1109/TPAMI.2016.2582171			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27333601	Green Accepted			2022-12-18	WOS:000402744400018
J	Sun, W; Niessen, WJ; Klein, S				Sun, Wei; Niessen, Wiro J.; Klein, Stefan			Randomly Perturbed B-Splines for Nonrigid Image Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonrigid registration; B-splines; perturbation; transformation; free-form deformation; stochastic optimization	STOCHASTIC-APPROXIMATION; MUTUAL-INFORMATION; OPTIMIZATION; SIGNAL; MINIMIZATION; ALGORITHMS	B-splines are commonly utilized to construct the transformation model in free-form deformation (FFD) based registration. B-splines become smoother with increasing spline order. However, a higher-order B-spline requires a larger support region involving more control points, which means higher computational cost. In general, the third-order B-spline is considered as a good compromise between spline smoothness and computational cost. A lower-order function is seldom used to construct the transformation model for registration since it is less smooth. In this research, we investigated whether lower-order B-spline functions can be utilized for more efficient registration, while preserving smoothness of the deformation by using a novel random perturbation technique. With the proposed perturbation technique, the expected value of the cost function given probability density function (PDF) of the perturbation is minimized by a stochastic gradient descent optimization. Extensive experiments on 2D synthetically deformed brain images, and real 3D lung and brain scans demonstrated that the novel randomly perturbed free-form deformation (RPFFD) approach improves the registration accuracy and transformation smoothness. Meanwhile, lower-order RPFFD methods reduce the computational cost substantially.	[Sun, Wei; Niessen, Wiro J.; Klein, Stefan] Erasmus MC, Biomed Imaging Grp Rotterdam, Dept Radiol, NL-3000 CA Rotterdam, Netherlands; [Sun, Wei; Niessen, Wiro J.; Klein, Stefan] Erasmus MC, Biomed Imaging Grp Rotterdam, Dept Med Informat, NL-3000 CA Rotterdam, Netherlands; [Sun, Wei] Univ Southern Calif, Stevens Neuroimaging & Informat Inst, Lab Neuro Imaging, Los Angeles, CA 90089 USA; [Niessen, Wiro J.] Delft Univ Technol, Fac Sci Appl, Dept Image Sci & Technol, NL-2628 CD Delft, Netherlands	Erasmus University Rotterdam; Erasmus MC; Erasmus University Rotterdam; Erasmus MC; University of Southern California; Delft University of Technology	Sun, W (corresponding author), Erasmus MC, Biomed Imaging Grp Rotterdam, Dept Radiol, NL-3000 CA Rotterdam, Netherlands.; Sun, W (corresponding author), Erasmus MC, Biomed Imaging Grp Rotterdam, Dept Med Informat, NL-3000 CA Rotterdam, Netherlands.	sunweidemail@gmail.com; w.niessen@erasmusmc.nl; s.klein@erasmusmc.nl		Niessen, Wiro/0000-0002-5822-1995; Klein, Stefan/0000-0003-4449-6784; Sun, Wei/0000-0002-4385-1636	National Natural Science Foundation of China [U1301251]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Wei Sun would like to acknowledge funding from National Natural Science Foundation of China (U1301251).	Abernethy J. D., 2014, COLT, P807; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Castillo R, 2009, PHYS MED BIOL, V54, P1849, DOI 10.1088/0031-9155/54/7/001; Chun SY, 2009, IEEE J-STSP, V3, P159, DOI 10.1109/JSTSP.2008.2011116; Cocosco C. A., 1997, NEUROIMAGE, V5, P425; Crum WR, 2004, BRIT J RADIOL, V77, pS140, DOI 10.1259/bjr/25329214; De Boor C, 1978, PRACTICAL GUIDE SPLI, V27; Gao PS, 1998, VISUAL COMPUT, V14, P390, DOI 10.1007/s003710050150; GELFAND SB, 1991, SIAM J CONTROL OPTIM, V29, P999, DOI 10.1137/0329055; Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201; Holden M, 2008, IEEE T MED IMAGING, V27, P111, DOI 10.1109/TMI.2007.904691; Hollander M., 2014, NONPARAMETRIC STAT M; Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037; Klein S, 2007, IEEE T IMAGE PROCESS, V16, P2879, DOI 10.1109/TIP.2007.909412; Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616; Klein S, 2009, INT J COMPUT VISION, V81, P227, DOI 10.1007/s11263-008-0168-y; Kushner Harold, 2003, STOCHASTIC APPROXIMA, V35; KUSHNER HJ, 1987, SIAM J APPL MATH, V47, P169, DOI 10.1137/0147010; Kybic J, 2003, IEEE T IMAGE PROCESS, V12, P1427, DOI 10.1109/TIP.2003.813139; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; Maryak JL, 2001, P AMER CONTR CONF, P756, DOI 10.1109/ACC.2001.945806; Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072; Metz CT, 2011, MED IMAGE ANAL, V15, P238, DOI 10.1016/j.media.2010.10.003; Modat M, 2010, COMPUT METH PROG BIO, V98, P278, DOI 10.1016/j.cmpb.2009.09.002; Murphy K, 2011, IEEE T MED IMAGING, V30, P1901, DOI 10.1109/TMI.2011.2158349; Noblet V, 2005, IEEE T IMAGE PROCESS, V14, P553, DOI 10.1109/TIP.2005.846026; Papiez BW, 2014, MED IMAGE ANAL, V18, P1299, DOI 10.1016/j.media.2014.05.005; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Rueckert D, 2006, LECT NOTES COMPUT SC, V4191, P702; Shamonin DP, 2014, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00050; Shi WZ, 2013, MED IMAGE ANAL, V17, P779, DOI 10.1016/j.media.2013.04.010; Sorzano COS, 2005, IEEE T BIO-MED ENG, V52, P652, DOI 10.1109/TBME.2005.844030; Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603; SPALL JC, 1992, IEEE T AUTOMAT CONTR, V37, P332, DOI 10.1109/9.119632; Sun W, 2014, LECT NOTES COMPUT SC, V8545, P62, DOI 10.1007/978-3-319-08554-8_7; Sun W, 2014, LECT NOTES COMPUT SC, V8673, P194, DOI 10.1007/978-3-319-10404-1_25; Sun W, 2013, IEEE T IMAGE PROCESS, V22, P4905, DOI 10.1109/TIP.2013.2279937; Thevenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199; Tustison NJ, 2009, IEEE T IMAGE PROCESS, V18, P624, DOI 10.1109/TIP.2008.2010072; UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221; UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220; Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930	44	19	19	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1401	1413		10.1109/TPAMI.2016.2598344	http://dx.doi.org/10.1109/TPAMI.2016.2598344			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27514038				2022-12-18	WOS:000402744400010
J	Kviatkovsky, I; Gabel, M; Rivlin, E; Shimshoni, I				Kviatkovsky, Igor; Gabel, Moshe; Rivlin, Ehud; Shimshoni, Ilan			On the Equivalence of the LC-KSVD and the D-KSVD Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Discriminative dictionary learning; label consistent K-SVD; discriminative K-SVD; equivalence proof	SPARSE REPRESENTATION; FACE RECOGNITION; K-SVD; IMAGE; DICTIONARIES	Sparse and redundant representations, where signals are modeled as a combination of a few atoms from an overcomplete dictionary, is increasingly used in many image processing applications, such as denoising, super resolution, and classification. One common problem is learning a "good" dictionary for different tasks. In the classification task the aim is to learn a dictionary that also takes training labels into account, and indeed there exist several approaches to this problem. One well-known technique is D-KSVD, which jointly learns a dictionary and a linear classifier using the K-SVD algorithm. LC-KSVD is a recent variation intended to further improve on this idea by adding an explicit label consistency term to the optimization problem, so that different classes are represented by different dictionary atoms. In this work we prove that, under identical initialization conditions, LC-KSVD with uniform atom allocation is in fact a reformulation of D-KSVD: given the regularization parameters of LC-KSVD, we give a closed-form expression for the equivalent D-KSVD regularization parameter, assuming the LC-KSVD's initialization scheme is used. We confirm this by reproducing several of the original LC-KSVD experiments.	[Kviatkovsky, Igor; Gabel, Moshe; Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; [Shimshoni, Ilan] Univ Haifa, Dept Informat Syst, Rabin Bldg, IL-31905 Haifa, Israel	Technion Israel Institute of Technology; University of Haifa	Kviatkovsky, I (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	kviat@cs.technion.ac.il; mgabel@cs.technion.ac.il; ehudr@cs.technion.ac.il; ishimshoni@mis.haifa.ac.il						Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Cai S., 2014, P EUR C COMPUT VIS, pIV624; Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430; Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4; Fei-Fei L., 2004, C COMP VIS PATT REC, P178, DOI [10.1109/CVPR.2004.109, DOI 10.1109/CVPR.2004.109]; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Patel VM, 2014, J OPT SOC AM A, V31, P1090, DOI 10.1364/JOSAA.31.001090; PHAM D.-S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587408; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527; Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989	17	19	20	3	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					411	416		10.1109/TPAMI.2016.2545661	http://dx.doi.org/10.1109/TPAMI.2016.2545661			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019475				2022-12-18	WOS:000395553400015
J	Theologou, P; Pratikakis, I; Theoharis, T				Theologou, Panagiotis; Pratikakis, Ioannis; Theoharis, Theoharis			Unsupervised Spectral Mesh Segmentation Driven by Heterogeneous Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mesh processing; spectral analysis; 3D mesh segmentation	DECOMPOSITION	A fully automatic mesh segmentation scheme using heterogeneous graphs is presented. We introduce a spectral framework where local geometry affinities are coupled with surface patch affinities. A heterogeneous graph is constructed combining two distinct graphs: a weighted graph based on adjacency of patches of an initial over-segmentation, and the weighted dual mesh graph. The partitioning relies on processing each eigenvector of the heterogeneous graph Laplacian individually, taking into account the nodal set and nodal domain theory. Experiments on standard datasets show that the proposed unsupervised approach outperforms the state-of-the-art unsupervised methodologies and is comparable to the best supervised approaches.	[Theologou, Panagiotis; Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece; [Theoharis, Theoharis] Norwegian Univ Sci & Technol, Trondheim, Norway; [Theoharis, Theoharis] Univ Athens, Athens, Greece	Democritus University of Thrace; Norwegian University of Science & Technology (NTNU); National & Kapodistrian University of Athens	Theologou, P (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.	ptheolog@ee.duth.gr; ipratika@ee.duth.gr; theotheo@idi.ntnu.no	PRATIKAKIS, IOANNIS/AAD-3387-2019; Theoharis, Theoharis/AAN-2555-2020	PRATIKAKIS, IOANNIS/0000-0002-4124-3688; 	European Union (European Social Fund - ESF); Greek national funds through the Operational Program "Education and Lifelong Learning" of the National Strategic Reference Framework (NSRF)- Research Funding Program: THALES-3DOR [MIS 379516]; Investing in knowledge society through the European Social Fund	European Union (European Social Fund - ESF)(European Social Fund (ESF)); Greek national funds through the Operational Program "Education and Lifelong Learning" of the National Strategic Reference Framework (NSRF)- Research Funding Program: THALES-3DOR; Investing in knowledge society through the European Social Fund	Co-financed by the European Union (European Social Fund - ESF) and Greek national funds through the Operational Program "Education and Lifelong Learning" of the National Strategic Reference Framework (NSRF)- Research Funding Program: THALES-3DOR (MIS 379516). Investing in knowledge society through the European Social Fund.	Agathos A, 2007, COMPUT AIDED DES APP, V4, P827, DOI DOI 10.1080/16864360.2007.10738515; Agathos A, 2010, VISUAL COMPUT, V26, P63, DOI 10.1007/s00371-009-0383-8; Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x; Au OKC, 2012, IEEE T VIS COMPUT GR, V18, P1125, DOI 10.1109/TVCG.2011.131; Benhabiles H, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P36, DOI 10.1109/SMI.2009.5170161; Benhabiles H, 2011, COMPUT GRAPH FORUM, V30, P2170, DOI 10.1111/j.1467-8659.2011.01967.x; Bergamasco F, 2012, PATTERN RECOGN LETT, V33, P2057, DOI 10.1016/j.patrec.2012.03.015; Berretti S, 2009, IMAGE VISION COMPUT, V27, P1540, DOI 10.1016/j.imavis.2009.02.004; Biyikoglu T, 2007, LECT NOTES MATH, V1915, P1; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brent R.P., 1973, ALGORITHMS MINIMIZAT; Chahhou M, 2014, IEEE T PATTERN ANAL, V36, P1687, DOI 10.1109/TPAMI.2013.2297314; Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379; CHENG SY, 1976, COMMENT MATH HELV, V51, P43, DOI 10.1007/BF02568142; Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817; Cohen-Steiner D, 2003, P 19 ANN S COMP GEOM, P312, DOI DOI 10.1145/777792.777839; Golovinskiy A, 2009, COMPUT GRAPH-UK, V33, P262, DOI 10.1016/j.cag.2009.03.010; Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098; Guillaume L, 2005, ACM SIGGRAPH 2010 SI, V37, P975, DOI [DOI 10.1145/1778765.1778839, 10.1145/1778765.1778839]; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; Hu RZ, 2012, COMPUT GRAPH FORUM, V31, P1703, DOI 10.1111/j.1467-8659.2012.03175.x; Huebner K, 2008, IEEE INT CONF ROBOT, P1628, DOI 10.1109/ROBOT.2008.4543434; Julius D, 2005, COMPUT GRAPH FORUM, V24, P581, DOI 10.1111/j.1467-8659.2005.00883.x; Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369; Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237; Lai YK, 2009, COMPUT AIDED GEOM D, V26, P665, DOI 10.1016/j.cagd.2008.09.007; Lavoue G, 2005, COMPUT AIDED DESIGN, V37, P975, DOI 10.1016/j.cad.2004.09.001; Lavoue Guillaume, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P206; Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66; Liu R, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P298; Liu R, 2007, COMPUT GRAPH FORUM, V26, P385, DOI 10.1111/j.1467-8659.2007.01061.x; Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348; Mortara M., 2004, P 9 ACM S SOL MOD AP, P339; Reuter M, 2009, COMPUT GRAPH-UK, V33, P381, DOI 10.1016/j.cag.2009.03.005; Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x; Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shlafman S, 2002, COMPUT GRAPH FORUM, V21, P219, DOI 10.1111/1467-8659.00581; Sidi O, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024160; Theologou P, 2015, COMPUT VIS IMAGE UND, V135, P49, DOI 10.1016/j.cviu.2014.12.008; Tierny J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P215, DOI 10.1109/SMI.2007.38; van Kaick O, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2611811; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang H, 2014, GRAPH MODELS, V76, P440, DOI 10.1016/j.gmod.2014.04.009; Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819; Wang Yarong, 2012, ADV ENERGY MATER, V10, P1, DOI DOI 10.2514/1.46769; Xu K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866206; Yan DM, 2012, COMPUT AIDED DESIGN, V44, P1072, DOI 10.1016/j.cad.2012.04.005; Yi Fang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2145, DOI 10.1109/CVPR.2011.5995695; Zhang J, 2012, J NANOPART RES, V14, DOI 10.1007/s11051-012-0796-6	53	19	22	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					397	410		10.1109/TPAMI.2016.2544311	http://dx.doi.org/10.1109/TPAMI.2016.2544311			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019471				2022-12-18	WOS:000395553400014
J	Zhou, LP; Wang, L; Liu, LQ; Ogunbona, P; Shen, DG				Zhou, Luping; Wang, Lei; Liu, Lingqiao; Ogunbona, Philip; Shen, Dinggang			Learning Discriminative Bayesian Networks from High-Dimensional Continuous Neuroimaging Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian network; discriminative learning; Fisher kernel learning; max-margin; brain network	STRUCTURE DISCOVERY; CONNECTIVITY	Due to its causal semantics, Bayesian networks (BN) have been widely employed to discover the underlying data relationship in exploratory studies, such as brain research. Despite its success in modeling the probability distribution of variables, BN is naturally a generative model, which is not necessarily discriminative. This may cause the ignorance of subtle but critical network changes that are of investigation values across populations. In this paper, we propose to improve the discriminative power of BN models for continuous variables from two different perspectives. This brings two general discriminative learning frameworks for Gaussian Bayesian networks (GBN). In the first framework, we employ Fisher kernel to bridge the generative models of GBN and the discriminative classifiers of SVMs, and convert the GBN parameter learning to Fisher kernel learning via minimizing a generalization error bound of SVMs. In the second framework, we employ the max-margin criterion and build it directly upon GBN models to explicitly optimize the classification performance of the GBNs. The advantages and disadvantages of the two frameworks are discussed and experimentally compared. Both of them demonstrate strong power in learning discriminative parameters of GBNs for neuroimaging based brain network analysis, as well as maintaining reasonable representation capacity. The contributions of this paper also include a new Directed Acyclic Graph (DAG) constraint with theoretical guarantee to ensure the graph validity of GBN.	[Zhou, Luping; Wang, Lei; Ogunbona, Philip] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2500, Australia; [Liu, Lingqiao] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC USA; [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea	University of Wollongong; University of Adelaide; University of North Carolina; University of North Carolina Chapel Hill; Korea University	Zhou, LP (corresponding author), Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2500, Australia.	lupingz@uow.edu.au; leiw@uow.edu.au; liulq83@gmail.com; philipo@uow.edu.au; dgshen@med.unc.edu	Wang, Lei/AAL-9684-2020; Shen, Dinggang/ABF-6812-2020; Wang, Lei/D-9079-2013; Zhou, Luping/AAD-6045-2020	Shen, Dinggang/0000-0002-7934-5698; Wang, Lei/0000-0002-0961-0441; liu, lingqiao/0000-0003-3584-795X; Ogunbona, Philip O./0000-0003-4119-2873	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB006733] Funding Source: NIH RePORTER	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		Bishop C. M., 2006, J ELECT IMAG, V16, P140; Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Fast A. S., 2010, THESIS; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friston KJ, 2003, NEUROIMAGE, V19, P1273, DOI 10.1016/S1053-8119(03)00202-7; Fu F, 2013, J AM STAT ASSOC, V108, P288, DOI 10.1080/01621459.2012.754359; Gamez JA, 2011, DATA MIN KNOWL DISC, V22, P106, DOI 10.1007/s10618-010-0178-6; Gould RL, 2006, NEUROLOGY, V67, P1011, DOI 10.1212/01.wnl.0000237534.31734.1b; Guo Y., 2005, UNCERTAINTY ARTIFICI, P233; Heckerman D., 2013, CORR; Huang S, 2013, IEEE T PATTERN ANAL, V35, P1328, DOI 10.1109/TPAMI.2012.129; Jaakkola T., 1998, ADV NEURAL INFORM PR, P487; Kim J, 2007, HUM BRAIN MAPP, V28, P85, DOI 10.1002/hbm.20259; Koivisto M, 2004, J MACH LEARN RES, V5, P549; Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406; Li R, 2013, AM J NEURORADIOL, V34, P340, DOI 10.3174/ajnr.A3197; Li R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082104; Li XF, 2011, NEURORADIOLOGY, V53, P733, DOI 10.1007/s00234-010-0795-1; Liu XW, 2013, IEEE T CYBERNETICS, V43, P557, DOI 10.1109/TSMCB.2012.2212243; MACKEY D, 2003, INFORM THEORY INFERE; Margaritis D, 2000, ADV NEUR IN, V12, P505; Peharz R., 2012, P INT C MACH LEARN, P1047; Pellet JP, 2008, J MACH LEARN RES, V9, P1295; Perina A, 2012, IEEE T PATTERN ANAL, V34, P1249, DOI 10.1109/TPAMI.2011.241; Pernkopf F, 2012, IEEE T PATTERN ANAL, V34, P521, DOI 10.1109/TPAMI.2011.149; Pernkopf F, 2010, J MACH LEARN RES, V11, P2323; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Schmidt M., 2007, AAAI, V2, P1278; Scutari M., 2014, CORR; Shojaie A, 2010, BIOMETRIKA, V97, P519, DOI 10.1093/biomet/asq038; Smith SM, 2011, NEUROIMAGE, V54, P875, DOI 10.1016/j.neuroimage.2010.08.063; Spirtes P., 1991, Social Science Computer Review, V9, P62, DOI 10.1177/089443939100900106; Spirtes P., 2000, CAUSATION PREDICTION; Supekar K, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000100; Suzuki J., 1993, Uncertainty in Artificial Intelligence. Proceedings of the Ninth Conference (1993), P266; Sydorov V, 2014, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2014.182; Tijms BM, 2012, CEREB CORTEX, V22, P1530, DOI 10.1093/cercor/bhr221; Tsamardinos I., 2003, P 9 INT WORKSH ART I, V1, P300; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; van der Maaten L., 2011, P INT C MACH LEARN, P217; Verma T., 1991, P 6 UAI C UAI 90, P255; Wang K, 2007, HUM BRAIN MAPP, V28, P967, DOI 10.1002/hbm.20324; Wang L, 2008, IEEE T PATTERN ANAL, V30, P1534, DOI 10.1109/TPAMI.2007.70799; Xiang J., 2013, ADV NEURAL INFORM PR, P2418; Zhou LP, 2014, LECT NOTES COMPUT SC, V8675, P321, DOI 10.1007/978-3-319-10443-0_41; Zhou LP, 2013, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2013.291; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735	49	19	21	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2269	2283		10.1109/TPAMI.2015.2511754	http://dx.doi.org/10.1109/TPAMI.2015.2511754			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26731636	Green Submitted, Green Accepted			2022-12-18	WOS:000385945000010
J	Li, X; Shen, CH; Dick, A; Zhang, Z; Zhuang, YT				Li, Xi; Shen, Chunhua; Dick, Anthony; Zhang, Zhongfei (Mark); Zhuang, Yueting			Online Metric-Weighted Linear Representations for Robust Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; linear representation; structured metric learning; reservoir sampling	MODELS	In this paper, we propose a visual tracker based on a metric-weighted linear representation of appearance. In order to capture the interdependence of different feature dimensions, we develop two online distance metric learning methods using proximity comparison information and structured output learning. The learned metric is then incorporated into a linear representation of appearance. We show that online distance metric learning significantly improves the robustness of the tracker, especially on those sequences exhibiting drastic appearance changes. In order to bound growth in the number of training samples, we design a time-weighted reservoir sampling method. Moreover, we enable our tracker to automatically perform object identification during the process of object tracking, by introducing a collection of static template samples belonging to several object classes of interest. Object identification results for an entire video sequence are achieved by systematically combining the tracking information and visual recognition at each frame. Experimental results on challenging video sequences demonstrate the effectiveness of the method for both inter-frame tracking and object identification.	[Li, Xi; Zhuang, Yueting] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China; [Shen, Chunhua; Dick, Anthony] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Zhang, Zhongfei (Mark)] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310003, Zhejiang, Peoples R China	Zhejiang University; University of Adelaide; Zhejiang University	Li, X; Zhuang, YT (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.; Shen, CH; Dick, A (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.; Zhang, Z (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310003, Zhejiang, Peoples R China.	xilizju@zju.edu.cn; chhshen@gmail.com; ard@cs.adelaide.edu.au; zhongfei@zju.edu.cn; yzhuang@cs.zju.edu.cn	Li, Xi/L-1234-2013	Li, Xi/0000-0003-3023-1662; Dick, Anthony/0000-0001-9049-7345; Shen, Chunhua/0000-0002-8648-8718	National Natural Science Foundation of China [61472353]; National Basic Research Program of China [2012CB316400, 2015CB352300]; China Knowledge Centre for Engineering Sciences and Technology; Fundamental Research Funds for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); China Knowledge Centre for Engineering Sciences and Technology; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work is in part supported by the National Natural Science Foundation of China (Grant No. 61472353), the National Basic Research Program of China under Grants 2012CB316400 and 2015CB352300, China Knowledge Centre for Engineering Sciences and Technology, and the Fundamental Research Funds for the Central Universities. C. Shen is the corresponding author.	Adam A., 2006, IEEE C COMP VIS PATT; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884; BAO CL, 2012, PROC CVPR IEEE, P1830, DOI DOI 10.1109/CVPR.2012.6247881; Bischof H., 2006, BMVC, P47; Chechik G, 2010, J MACH LEARN RES, V11, P1109; Crammer K, 2006, J MACH LEARN RES, V7, P551; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Edwards G. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P486, DOI 10.1109/CVPR.1999.786982; Efraimidis PS, 2006, INFORM PROCESS LETT, V97, P181, DOI 10.1016/j.ipl.2005.11.003; Fan JL, 2010, LECT NOTES COMPUT SC, V6311, P480; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Hong ZB, 2012, LECT NOTES COMPUT SC, V7572, P513, DOI 10.1007/978-3-642-33718-5_37; Householder A.S., 1964, THEORY MATRICES NUME; Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549; Jennings A., 1992, MATRIX COMPUTATION; Jepson AD, 2001, PROC CVPR IEEE, P415; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Jiang N, 2011, PROC CVPR IEEE, P1161, DOI 10.1109/CVPR.2011.5995716; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kedem D., 2012, ADV NEURAL INFORM PR, P2582; Khanloo BYS, 2012, COMPUT VIS IMAGE UND, V116, P676, DOI 10.1016/j.cviu.2012.01.004; Kolonko M, 2006, ACM T MATH SOFTWARE, V32, P257, DOI 10.1145/1141885.1141891; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483; Li X, 2013, IEEE T IMAGE PROCESS, V22, P3028, DOI 10.1109/TIP.2013.2253478; Li X, 2013, IEEE T PATTERN ANAL, V35, P863, DOI 10.1109/TPAMI.2012.166; Li X, 2012, PROC CVPR IEEE, P1760, DOI 10.1109/CVPR.2012.6247872; Li XB, 2008, CAN J EDUC ADM POLIC, P1, DOI 10.1109/CVPR.2008.4587516; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35; Park DW, 2012, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR.2012.6247898; POWELL MJD, 1969, COMPUT J, V12, P288, DOI 10.1093/comjnl/12.3.288; Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Tsagkatakis G, 2011, IEEE T CIRC SYST VID, V21, P1810, DOI 10.1109/TCSVT.2011.2133970; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677; Wang XY, 2010, LECT NOTES COMPUT SC, V6313, P200; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Wu Y, 2012, IEEE T IMAGE PROCESS, V21, P2824, DOI 10.1109/TIP.2011.2182521; Ying YM, 2012, J MACH LEARN RES, V13, P1; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z; Zhao P., 2011, P 28 INT C MACHINE L, P233; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	50	19	22	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					931	950		10.1109/TPAMI.2015.2469276	http://dx.doi.org/10.1109/TPAMI.2015.2469276			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26390446	Green Submitted			2022-12-18	WOS:000374164700008
J	Shi, ZY; Hospedales, TM; Xiang, T				Shi, Zhiyuan; Hospedales, Timothy M.; Xiang, Tao			Bayesian Joint Modelling for Object Localisation in Weakly Labelled Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; topic modelling; weakly supervised learning; Bayesian domain transfer; probabilistic modelling	CLASSIFICATION; SCALE	We address the problem of localisation of objects as bounding boxes in images and videos with weak labels. This weakly supervised object localisation problem has been tackled in the past using discriminative models where each object class is localised independently from other classes. In this paper, a novel framework based on Bayesian joint topic modelling is proposed, which differs significantly from the existing ones in that: (1) All foreground object classes are modelled jointly in a single generative model that encodes multiple object co-existence so that "explaining away" inference can resolve ambiguity and lead to better learning and localisation. (2) Image backgrounds are shared across classes to better learn varying surroundings and "push out" objects of interest. (3) Our model can be learned with a mixture of weakly labelled and unlabelled data, allowing the large volume of unlabelled images on the Internet to be exploited for learning. Moreover, the Bayesian formulation enables the exploitation of various types of prior knowledge to compensate for the limited supervision offered by weakly labelled data, as well as Bayesian domain adaptation for transfer learning. Extensive experiments on the PASCAL VOC, ImageNet and YouTube-Object videos datasets demonstrate the effectiveness of our Bayesian joint model for weakly supervised object localisation.	[Shi, Zhiyuan; Hospedales, Timothy M.; Xiang, Tao] Univ London, Dept EECS, London E1 4NS, England	University of London	Shi, ZY (corresponding author), Univ London, Dept EECS, London E1 4NS, England.	z.shi@qmul.ac.uk; t.hospedales@qmul.ac.uk; t.xiang@qmul.ac.uk		Hospedales, Timothy/0000-0003-4867-7486; Shi, Zhiyuan/0000-0002-7073-2245				Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Andrews S., 2002, SUPPORT VECTOR MACHI, P561; [Anonymous], 2007, P 15 ACM INT C MULTI; [Anonymous], 2007, PASCAL VISUAL OBJECT; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Bishop C.M, 2006, PATTERN RECOGN; Blaschko M., 2010, ADV NEURAL INFORM PR; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Cabral R. S., 2011, ADV NEURAL INFORM PR, P190; Cao L, 2007, P IEEE INT C COMP VI, P1; Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Dai Wenyuan, 2007, AAAI, P540; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Dollar P, 2008, LECT NOTES COMPUT SC, V5303, P211, DOI 10.1007/978-3-540-88688-4_16; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Galleguillos C., 2008, P EUR C COMPUT VIS, P193; Gehler Peter Vincent, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2836, DOI 10.1109/CVPRW.2009.5206592; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Guillaumin M, 2012, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2012.6248055; Hartmann G, 2012, LECT NOTES COMPUT SC, V7583, P198, DOI 10.1007/978-3-642-33863-2_20; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; JIE L, 2011, P IEEE INT C COMP VI, P1863; Joulin A, 2014, LECT NOTES COMPUT SC, V8694, P253, DOI 10.1007/978-3-319-10599-4_17; Kuettel D, 2012, LECT NOTES COMPUT SC, V7578, P459, DOI 10.1007/978-3-642-33786-4_34; Kuettel D, 2012, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2012.6247721; Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718; Maron O, 1998, ADV NEUR IN, V10, P570; Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426; Nam Nguyen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P384, DOI 10.1109/ICDM.2010.109; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Orabona F, 2010, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2010.5540137; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Pedersen T., 2004, HLT NAACL 2004 STROU; Philbin J, 2011, INT J COMPUT VISION, V95, P138, DOI 10.1007/s11263-010-0363-5; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Rothe R., 2014, ICCV, DOI DOI 10.1109/ICCV.2007.4409064; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720; Shi Z., 2012, BRIT MACH VIS C GUIL; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Tang K., 2012, ADV NEURAL INFORM PR; Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Vezhnevets A, 2014, PROC CVPR IEEE, P1987, DOI 10.1109/CVPR.2014.255; Winn J, 2005, J MACH LEARN RES, V6, P661; Zha Zheng-Jun, 2008, CVPR, P1; Zhou Z.H., 2007, NIPS 19, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019; Zhu JY, 2015, IEEE T PATTERN ANAL, V37, P862, DOI 10.1109/TPAMI.2014.2353617; ZHU X, 2007, 1530 U WISC MAD DEP	72	19	20	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					1959	1972		10.1109/TPAMI.2015.2392769	http://dx.doi.org/10.1109/TPAMI.2015.2392769			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26340253	Green Submitted			2022-12-18	WOS:000360813400002
J	Kwon, J; Lee, KM				Kwon, Junseok; Lee, Kyoung Mu			A Unified Framework for Event Summarization and Rare Event Detection from Multiple Views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Event summarization; rare event detection; video structure learning; video structure editing; video structure matching		A novel approach for event summarization and rare event detection is proposed. Unlike conventional methods that deal with event summarization and rare event detection independently, our method solves them in a single framework by transforming them into a graph editing problem. In our approach, a video is represented by a graph, each node of which indicates an event obtained by segmenting the video spatially and temporally. The edges between nodes describe the relationship between events. Based on the degree of relations, edges have different weights. After learning the graph structure, our method finds subgraphs that represent event summarization and rare events in the video by editing the graph, that is, merging its subgraphs or pruning its edges. The graph is edited to minimize a predefined energy model with the Markov Chain Monte Carlo (MCMC) method. The energy model consists of several parameters that represent the causality, frequency, and significance of events. We design a specific energy model that uses these parameters to satisfy each objective of event summarization and rare event detection. The proposed method is extended to obtain event summarization and rare event detection results across multiple videos captured from multiple views. For this purpose, the proposed method independently learns and edits each graph of individual videos for event summarization or rare event detection. Then, the method matches the extracted multiple graphs to each other, and constructs a single composite graph that represents event summarization or rare events from multiple views. Experimental results show that the proposed approach accurately summarizes multiple videos in a fully unsupervised manner. Moreover, the experiments demonstrate that the approach is advantageous in detecting rare transition of events.	[Kwon, Junseok] ETH, Dept Informat Technol & Elect Engn, Zurich, Switzerland; [Lee, Kyoung Mu] Seoul Natl Univ, Automat & Syst Res Inst, Dept Elect & Comp Engn, Seoul 151744, South Korea	Swiss Federal Institutes of Technology Domain; ETH Zurich; Seoul National University (SNU)	Kwon, J (corresponding author), ETH, Dept Informat Technol & Elect Engn, Zurich, Switzerland.	kwonj@vision.ee.ethz.ch; kyoungmu@snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036	National Research Foundation of Korea (NRF) - Ministry of Science, ICT Future Planning (MSIP) [2009-0083495]; Advanced Device Team, DMC RD, Samsung Electronics	National Research Foundation of Korea (NRF) - Ministry of Science, ICT Future Planning (MSIP); Advanced Device Team, DMC RD, Samsung Electronics	This research was supported in part by the National Research Foundation of Korea (NRF) grant funded by the Ministry of Science, ICT Future Planning (MSIP) (No. 2009-0083495), and in part by the Advanced Device Team, DMC RD, Samsung Electronics. Kyoung Mu Lee is the corresponding author of the paper.	Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825; Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9; Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316; Cho M., 2012, P 11 EUR C COMP VIS, P492; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434; de Leo C., 2014, ACM T SENSOR NETWORK, V10, P1; Emonet R, 2014, IEEE T PATTERN ANAL, V36, P140, DOI 10.1109/TPAMI.2013.100; Fanti C, 2004, ADV NEUR IN, V16, P1603; Grzegorczyk M, 2008, MACH LEARN, V71, P265, DOI 10.1007/s10994-008-5057-7; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Haines TSF, 2011, IEEE I CONF COMP VIS, P2198, DOI 10.1109/ICCV.2011.6126497; Hamalainen W, 2008, IEEE DATA MINING, P203, DOI 10.1109/ICDM.2008.144; Hartmanis J., 1982, SIAM REV, V24, P90, DOI DOI 10.1137/1024022; Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; Huang YC, 2009, PROC CVPR IEEE, P1738, DOI 10.1109/CVPRW.2009.5206795; Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31; Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569; Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952; Jiang Y., 2013, P RSS; Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22; Koppula H., 2013, INT C MACHINE LEARNI, P792, DOI DOI 10.1177/0278364913478446; Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771; Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869; Kwon J, 2012, PROC CVPR IEEE, P1266, DOI 10.1109/CVPR.2012.6247810; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Pritch Y, 2007, IEEE I CONF COMP VIS, P833; Raymond JW, 2002, J COMPUT AID MOL DES, V16, P521, DOI 10.1023/A:1021271615909; Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3; Suha Kwak, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3345, DOI 10.1109/CVPR.2011.5995435; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Varadarajan J, 2012, PROC CVPR IEEE, P2096, DOI 10.1109/CVPR.2012.6247915; Wang L, 2013, IEEE I CONF COMP VIS, P3168, DOI 10.1109/ICCV.2013.393; Wang XG, 2010, IEEE T PATTERN ANAL, V32, P56, DOI 10.1109/TPAMI.2008.241; Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Yuen J, 2010, LECT NOTES COMPUT SC, V6312, P707, DOI 10.1007/978-3-642-15552-9_51; Zhong H, 2004, PROC CVPR IEEE, P819	49	19	21	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1737	1750		10.1109/TPAMI.2014.2385695	http://dx.doi.org/10.1109/TPAMI.2014.2385695			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353123				2022-12-18	WOS:000359216600001
J	Tagare, HD; Rao, M				Tagare, Hemant D.; Rao, Murali			Why Does Mutual-Information Work for Image Registration? A Deterministic Explanation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image Rregistration; medical image registration; mutual information; convexity	ENTROPY	This paper proposes a deterministic explanation for mutual-information-based image registration (MI registration). The explanation is that MI registration works because it aligns certain image partitions. This notion of aligning partitions is new, and is shown to be related to Schur- and quasi-convexity. The partition-alignment theory of this paper goes beyond explaining mutual-information. It suggests other objective functions for registering images. Some of these newer objective functions are not entropy-based. Simulations with noisy images show that the newer objective functions work well for registration, lending support to the theory. The theory proposed in this paper opens a number of directions for further research in image registration. These directions are also discussed.	[Tagare, Hemant D.] Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA; [Tagare, Hemant D.] Yale Univ, Dept Biomed Engn, New Haven, CT 06520 USA; [Tagare, Hemant D.] Yale Univ, Dept Elect Engn, New Haven, CT 06520 USA; [Rao, Murali] Univ Florida, Dept Math, Gainesville, FL 32611 USA	Yale University; Yale University; Yale University; State University System of Florida; University of Florida	Tagare, HD (corresponding author), Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA.	hemant.tagare@yale.edu; mrao@ufl.edu						Beirlant J., 1997, INT J MATH STAT SCI, V6, P17; Boyd S, 2004, CONVEX OPTIMIZATION; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; Costa JA, 2003, CONF REC ASILOMAR C, P316; GERLOTCHIRON P, 1992, CVGIP-GRAPH MODEL IM, V54, P396, DOI 10.1016/1049-9652(92)90024-R; Hajnal JV, 2001, MED IMAGE REGISTRATI; He Y, 2003, IEEE T SIGNAL PROCES, V51, P1211, DOI 10.1109/TSP.2003.810305; Loeckx D, 2010, IEEE T MED IMAGING, V29, P19, DOI 10.1109/TMI.2009.2021843; Ma B, 2000, IEEE IMAGE PROC, P481, DOI 10.1109/ICIP.2000.901000; Marshall AW, 2011, SPRINGER SER STAT, P3, DOI 10.1007/978-0-387-68276-1; Modersitzki J., 2009, FUND ALGORITHMS, P210; NEEMUCHWALA H, 2005, MULTISENSOR IMAGE FU; Neemuchwala H, 2006, INT J IMAG SYST TECH, V16, P130, DOI 10.1002/ima.20079; Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872; Rajwade A, 2009, IEEE T PATTERN ANAL, V31, P475, DOI 10.1109/TPAMI.2008.97; Rao M, 2004, IEEE T INFORM THEORY, V50, P1220, DOI 10.1109/TIT.2004.828057; Roche A, 2000, INT J IMAG SYST TECH, V11, P71, DOI 10.1002/(SICI)1098-1098(2000)11:1<71::AID-IMA8>3.0.CO;2-5; Sabuncu MR, 2005, INT CONF ACOUST SPEE, P253; Steele M. J., 2004, CAUCHY SCHWARZ MASTE; Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0; Tustison NJ, 2011, IEEE T MED IMAGING, V30, P451, DOI 10.1109/TMI.2010.2086065; van den Elsen P.A., 1994, P SOC PHOTO-OPT INS, V2359, P227; VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang F, 2007, INT J COMPUT VISION, V74, P201, DOI 10.1007/s11263-006-0011-2	25	19	20	5	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1286	1296		10.1109/TPAMI.2014.2361512	http://dx.doi.org/10.1109/TPAMI.2014.2361512			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357349				2022-12-18	WOS:000354377100013
J	Arzeno, NM; Vikalo, H				Arzeno, Natalia M.; Vikalo, Haris			Semi-Supervised Affinity Propagation with Soft Instance-Level Constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; graph algorithms; affinity propagation; semi-supervised learning; noisy pairwise constraints		Soft-constraint semi-supervised affinity propagation (SCSSAP) adds supervision to the affinity propagation (AP) clustering algorithm without strictly enforcing instance-level constraints. Constraint violations lead to an adjustment of the AP similarity matrix at every iteration of the proposed algorithm and to addition of a penalty to the objective function. This formulation is particularly advantageous in the presence of noisy labels or noisy constraints since the penalty parameter of SCSSAP can be tuned to express our confidence in instance-level constraints. When the constraints are noiseless, SCSSAP outperforms unsupervised AP and performs at least as well as the previously proposed semi-supervised AP and constrained expectation maximization. In the presence of label and constraint noise, SCSSAP results in a more accurate clustering than either of the aforementioned established algorithms. Finally, we present an extension of SCSSAP which incorporates metric learning in the optimization objective and can further improve the performance of clustering.	[Arzeno, Natalia M.; Vikalo, Haris] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Arzeno, NM (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.	narzeno@utexas.edu; hvikalo@ece.utexas.edu			National Science Foundation Graduate Research Fellowship [DGE-1110007]; Jack Kilby/Texas Instruments fellowship	National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF)); Jack Kilby/Texas Instruments fellowship	This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1110007 and Jack Kilby/Texas Instruments fellowship.	[Anonymous], 2006, P 18 INT C NEUR INF; [Anonymous], 2004, ICML, DOI [10.1145/1015330.1015376, DOI 10.1145/1015330.1015376]; Bilenko M, 2004, ICML; Bishop C.M, 2006, PATTERN RECOGN; Bouveyron C, 2009, PATTERN RECOGN, V42, P2649, DOI 10.1016/j.patcog.2009.03.027; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131, DOI 10.1613/jair.606; Conroy B, 2010, INT CONF ACOUST SPEE, P1858, DOI 10.1109/ICASSP.2010.5495368; Domeniconi C, 2007, DATA MIN KNOWL DISC, V14, P63, DOI 10.1007/s10618-006-0060-8; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Givoni I, 2009, P 12 INT C ART INT S, P161; Givoni Inmar, 2012, 12023722 ARXIV; Givoni IE, 2009, NEURAL COMPUT, V21, P1589, DOI 10.1162/neco.2009.05-08-785; Goldberger Jacob, 2005, ADV NEURAL INFORM PR, V17, P8, DOI DOI 10.1109/TCSVT.2013.2242640; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hillel A., 2003, P 20 INT C MACH LEAR, P11; Hoi S., 2006, P IEEE COMP SOC C CO, V2, P2072, DOI DOI 10.1109/CVPR.2006.167; Hoi S.C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587351; Jain P, 2012, J MACH LEARN RES, V13, P519; Jeh G, 2002, P 8 ACM SIGKDD INT C, V02, P538; Kennedy LS, 2006, P 8 ACM INT WORKSH M, P249, DOI [DOI 10.1145/1178677.1178712, 10.1145/1178677.1178712]; Kumar N, 2008, IEEE T KNOWL DATA EN, V20, P496, DOI 10.1109/TKDE.2007.190715; Lawrence N. D., 2001, 18 INT C MACHINE LEA, V1, P306; Leone M, 2008, EUR PHYS J B, V66, P125, DOI 10.1140/epjb/e2008-00381-8; Leone M, 2007, BIOINFORMATICS, V23, P2708, DOI 10.1093/bioinformatics/btm414; Li WY, 2012, LECT NOTES COMPUT SC, V7667, P437, DOI 10.1007/978-3-642-34500-5_52; Lichman M, 2013, UCI MACHINE LEARNING; Lin YLS, 2010, VLSI DESIGN FOR VIDEO CODING: H.264/AVC ENCODING FROM STANDARD SPECIFICATION TO CHIP, P11, DOI 10.1007/978-1-4419-0959-6_2; Little MA, 2007, BIOMED ENG ONLINE, V6, DOI 10.1186/1475-925X-6-23; Liu W., 2010, KDD, P1139, DOI DOI 10.1145/1835804.183594; Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809; Pechenizkiy M, 2006, COMP MED SY, P708, DOI 10.1109/CBMS.2006.65; Qi G.-J., 2009, P INT C MACH LEARN J, P841; Roth V., 2003, P ADV NEUR INF PROC, V16; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Schultz M, 2003, P NEUR INF PROC SYST; Shen XT, 2012, BIOMETRIKA, V99, P899, DOI 10.1093/biomet/ass038; Shental N, 2003, ADV NEURAL INFORM PR, V16; Shi XH, 2009, IEEE IJCNN, P2734; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wang CD, 2013, IEEE T PATTERN ANAL, V35, P2223, DOI 10.1109/TPAMI.2013.28; Wang HJ, 2012, KNOWL-BASED SYST, V36, P315, DOI 10.1016/j.knosys.2012.05.011; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Xiang SM, 2008, PATTERN RECOGN, V41, P3600, DOI 10.1016/j.patcog.2008.05.018; Yang C, 2013, IEEE T GEOSCI REMOTE, V51, P1666, DOI 10.1109/TGRS.2012.2206818; Yang L., 2006, P AAAI C ARTIFICIAL, P543; Yang L, 2007, P 23 C UNCERTAINTY A, P442; Ye J., 2007, P IEEE C COMP VIS PA, P1, DOI [10.1109/CVPR.2007.383103, DOI 10.1109/CVPR.2007.383103]; Zhu M, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/385265	49	19	23	1	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1041	1052		10.1109/TPAMI.2014.2359454	http://dx.doi.org/10.1109/TPAMI.2014.2359454			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353327				2022-12-18	WOS:000352533000011
J	Chen, N; Zhu, J; Xia, F; Zhang, B				Chen, Ning; Zhu, Jun; Xia, Fei; Zhang, Bo			Discriminative Relational Topic Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical network analysis; relational topic models; data augmentation; regularized Bayesian inference		Relational topic models (RTMs) provide a probabilistic generative process to describe both the link structure and document contents for document networks, and they have shown promise on predicting network structures and discovering latent topic representations. However, existing RTMs have limitations in both the restricted model expressiveness and incapability of dealing with imbalanced network data. To expand the scope and improve the inference accuracy of RTMs, this paper presents three extensions: 1) unlike the common link likelihood with a diagonal weight matrix that allows the-same-topic interactions only, we generalize it to use a full weight matrix that captures all pairwise topic interactions and is applicable to asymmetric networks; 2) instead of doing standard Bayesian inference, we perform regularized Bayesian inference (RegBayes) with a regularization parameter to deal with the imbalanced link structure issue in real networks and improve the discriminative ability of learned latent representations; and 3) instead of doing variational approximation with strict mean-field assumptions, we present collapsed Gibbs sampling algorithms for the generalized relational topic models by exploring data augmentation without making restricting assumptions. Under the generic RegBayes framework, we carefully investigate two popular discriminative loss functions, namely, the logistic log-loss and the max-margin hinge loss. Experimental results on several real network datasets demonstrate the significance of these extensions on improving prediction performance.	[Chen, Ning; Zhu, Jun; Xia, Fei; Zhang, Bo] Tsinghua Univ, MOE Key Lab Bioinformat, Bioinformat Div, Beijing 100084, Peoples R China; [Chen, Ning; Zhu, Jun; Xia, Fei; Zhang, Bo] Tsinghua Univ, Ctr Synthet & Syst Biol, Dept Comp Sci & Technol, CBICR,TNLIST,State Key Lab Intelligent Technol &, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University	Chen, N (corresponding author), Tsinghua Univ, MOE Key Lab Bioinformat, Bioinformat Div, Beijing 100084, Peoples R China.	ningchen@mail.tsinghua.edu.cn; dcszj@mail.tsinghua.edu.cn; xia.fei09@gmail.com; dcszb@mail.tsinghua.edu.cn			National Key Project for Basic Research of China [2013CB329403, 2012CB316301]; National Natural Science Foundation of China [61305066, 61322308, 61332007]; Tsinghua Self-innovation Project [20121088071]	National Key Project for Basic Research of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Tsinghua Self-innovation Project	This work was supported by National Key Project for Basic Research of China (Grant Nos: 2013CB329403, 2012CB316301), National Natural Science Foundation of China (Nos: 61305066, 61322308, 61332007) and Tsinghua Self-innovation Project (Grant No: 20121088071).	Airoldi E., 2008, NIPS, P33; Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7; [Anonymous], 2013, P 23 INT JOINT C ART, DOI DOI 10.5555/2540128.2540312; [Anonymous], 2008, LINK PLSA LDA NEW UN; Backstrom Lars, 2011, P 4 ACM INT C WEB SE, P635; Balasubramanyan R., 2011, SIAM INT C DATA MINI, P450, DOI DOI 10.1137/1.9781611972818.39; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chang J, 2010, ANN APPL STAT, V4, P124, DOI 10.1214/09-AOAS309; Craven M, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P509; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Devroye L., 1986, NONUNIFORM RANDOM VA, P61; Dietz L., 2007, P 24 INT C MACHINE L, P233, DOI DOI 10.1145/1273496.1273526; GEORGE A, 1986, LINEAR ALGEBRA APPL, V77, P165, DOI 10.1016/0024-3795(86)90167-9; Germain Pascal, 2009, INT C MACH LEARN; Goldenberg A, 2010, FOUND TRENDS MACH LE, V2, P129, DOI 10.1561/2200000005; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Gruber A, 2008, P 24 C UNC ART INT U, P230; Hasan M. A., 2006, P SIAM WORKSH LINK A; Hoff P. D., 2007, ADV NEURAL INFORM PR, V20, P657; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; Hoffman M., 2010, ONLINE LEARNING LATE, P856; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Jordan M. I., 1999, INTRO VARIATIONAL ME; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Lichtenwalter R.N., 2010, P 16 ACM SIGKDD INT, P243; Liu Y., 2009, P 26 ANN INT C MACH, P665, DOI DOI 10.1145/1553374.1553460; McAllester DA, 2003, MACH LEARN, V51, P5, DOI 10.1023/A:1021840411064; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; MICHAEL JR, 1976, AM STAT, V30, P88, DOI 10.2307/2683801; Miller Kurt T., 2009, NONPARAMETRIC LATENT, P1276; Nallapati R.M., 2008, SIGKDD, P542; Polson NG, 2013, J AM STAT ASSOC, V108, P1339, DOI 10.1080/01621459.2013.829001; Polson NG, 2011, BAYESIAN ANAL, V6, P1, DOI 10.1214/11-BA601; Rosasco L, 2004, NEURAL COMPUT, V16, P1063, DOI 10.1162/089976604773135104; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Smola A, 2010, PROC VLDB ENDOW, V3, P703, DOI 10.14778/1920841.1920931; TANNER MA, 1987, J AM STAT ASSOC, V82, P528, DOI 10.2307/2289457; van Dyk DA, 2001, J COMPUT GRAPH STAT, V10, P1, DOI 10.1198/10618600152418584; Zhu J., 2013, P 51 ANN M ASS COMP, P187; Zhu J., 2012, P 29 INT C MACH LEAR, P719; Zhu J., 2013, ICML J MACH LEARN RE, V28, P124; Zhu J., 2011, PROC 24 INT C NEURAL, P1620; Zhu J, 2014, J MACH LEARN RES, V15, P1799	44	19	22	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					973	986		10.1109/TPAMI.2014.2361129	http://dx.doi.org/10.1109/TPAMI.2014.2361129			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353322	Green Submitted			2022-12-18	WOS:000352533000006
J	Dai, AM; Storkey, AJ				Dai, Andrew M.; Storkey, Amos J.			The Supervised Hierarchical Dirichlet Process	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; hierarchical Dirichlet process; latent Dirichlet allocation; topic modelling	MIXTURES	We propose the supervised hierarchical Dirichlet process (sHDP), a nonparametric generative model for the joint distribution of a group of observations and a response variable directly associated with that whole group. We compare the sHDP with another leading method for regression on grouped data, the supervised latent Dirichlet allocation (sLDA) model. We evaluate our method on two real-world classification problems and two real-world regression problems. Bayesian nonparametric regression models based on the Dirichlet process, such as the Dirichlet process-generalised linear models (DP-GLM) have previously been explored; these models allow flexibility in modelling nonlinear relationships. However, until now, hierarchical Dirichlet process (HDP) mixtures have not seen significant use in supervised problems with grouped data since a straightforward application of the HDP on the grouped data results in learnt clusters that are not predictive of the responses. The sHDP solves this problem by allowing for clusters to be learnt jointly from the group structure and from the label assigned to each group.	[Dai, Andrew M.] Google Inc, Mountain View, CA 94043 USA; [Storkey, Amos J.] Univ Edinburgh, Inst Adapt & Neural Computat, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Google Incorporated; University of Edinburgh	Dai, AM (corresponding author), Google Inc, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	adai@google.com; a.storkey@ed.ac.uk	Dai, Andrew M./X-3017-2019					[Anonymous], 2003, COMP NUMERICAL OPTIM; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Asuncion A., 2009, P 25 C UNCERTAINTY A, P27, DOI DOI 10.1080/10807030390248483; Blei D., 2007, P NIPS, V1, P1; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675; CHANG J., 2012, LDA COLLAPSED GIBBS; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Cowans P. J., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P564, DOI 10.1145/1008992.1009122; Dai AM, 2011, LECT NOTES COMPUT SC, V6791, P241, DOI 10.1007/978-3-642-21735-7_30; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Gelman A, 1992, STAT SCI, V7, P136, DOI 10.1214/ss/1177011136; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Groenewald PCN, 2005, COMPUT STAT DATA AN, V48, P857, DOI 10.1016/j.csda.2004.04.009; Hannah LA, 2011, J MACH LEARN RES, V12, P1923; Li W., 2007, UAI 2007, P243; McCullagh P, 1989, MONOGRAPHS STAT APPL, V2nd; Mimno D., 2008, P NIPS WORKSH AN GRA; Mimno D.M., 2008, UAI 2008 P 24 C UNCE, P411; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Pang B., 2005, P 43 ANN M ASS COMP, V43, P115, DOI DOI 10.3115/1219840.1219855; Ramage D., 2009, P 2009 C EMP METH NA, V1, P248, DOI DOI 10.3115/1699510.1699543; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rosen-Zvi Michal, 2012, ARXIV12074169; Shahbaba B, 2009, J MACH LEARN RES, V10, P1829; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Wang C., 2009, SLDA EM IMPLEMENTATI; Zhu J, 2009, P 26 ANN INT C MACH, P1257	28	19	21	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					243	255		10.1109/TPAMI.2014.2315802	http://dx.doi.org/10.1109/TPAMI.2014.2315802			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353239	Green Submitted			2022-12-18	WOS:000349625500004
J	Bian, W; Tao, DC				Bian, Wei; Tao, Dacheng			Asymptotic Generalization Bound of Fisher's Linear Discriminant Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fisher's linear discriminant analysis; asymptotic generalization analysis; random matrix theory	RECOGNITION; PREDICTION; BAYES	Fisher's linear discriminant analysis (FLDA) is an important dimension reduction method in statistical pattern recognition. It has been shown that FLDA is asymptotically Bayes optimal under the homoscedastic Gaussian assumption. However, this classical result has the following two major limitations: 1) it holds only for a fixed dimensionality D, and thus does not apply when D and the training sample size N are proportionally large; 2) it does not provide a quantitative description on how the generalization ability of FLDA is affected by D and N. In this paper, we present an asymptotic generalization analysis of FLDA based on random matrix theory, in a setting where both D and N increase and D/N --> gamma is an element of vertical bar 0, 1). The obtained lower bound of the generalization discrimination power overcomes both limitations of the classical result, i.e., it is applicable when D and N are proportionally large and provides a quantitative description of the generalization ability of FLDA in terms of the ratio gamma = D/N and the population discrimination power. Besides, the discrimination power bound also leads to an upper bound on the generalization error of binary-classification with FLDA.	[Bian, Wei; Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Bian, Wei; Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia	University of Technology Sydney; University of Technology Sydney	Bian, W (corresponding author), Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, 235 Jones St, Ultimo, NSW 2007, Australia.	wei.bian@uts.edu.au; dacheng.tao@uts.edu.au			Australian Research Council [DP-140102164, FT-130101457]	Australian Research Council(Australian Research Council)	This study was supported by the Australian Research Council Projects DP-140102164 and FT-130101457.	Alexandre-Cortizo E, 2005, EUROCON 2005: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOL 1 AND 2 , PROCEEDINGS, P1666; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Anderson T. W, 1984, INTRO MULTIVARIATE S; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Billingsley P., 1999, WILEY SERIES PROBABI, V175; Cai, 2011, HIGH DIMENSIONAL DAT, P3; De la Torre F., 2005, PROC 22 INT C MACH L, P177; Durrant Robert J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4044, DOI 10.1109/ICPR.2010.983; Durrant R. J., 2010, P 16 ACM SIGKDD INT, P1119; Edelman A, 2005, ACT NUMERIC, V14, P233, DOI 10.1017/S0962492904000236; EDELMAN A, 1989, THESIS MIT; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717; Hoyle DC, 2011, IEEE T PATTERN ANAL, V33, P1470, DOI 10.1109/TPAMI.2010.186; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; Kumar K, 2006, REV ACCOUNT FINANC, V5, P216, DOI 10.1108/14757700610686426; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Marenko V. A., 1967, MATH USSR SB, V1, P457, DOI [10.1070/SM1967v001n04ABEH001994, DOI 10.1070/SM1967V001N04ABEH001994]; McLachlan G., 2004, WILEY SERIES PROBABI; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Potamianos G, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P221, DOI 10.1109/MMSP.1998.738938; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tao T., 2012, GRADUATE STUDIES MAT, V132; Tulino A., 2004, RANDOM MATRIX THEORY; WIGNER EP, 1955, ANN MATH, V62, P548, DOI 10.2307/1970079; WIGNER EP, 1958, ANN MATH, V67, P325, DOI 10.2307/1970008; Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929, DOI 10.1109/TPAMI.2005.110; [No title captured]	32	19	19	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2325	2337		10.1109/TPAMI.2014.2327983	http://dx.doi.org/10.1109/TPAMI.2014.2327983			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353142	Green Submitted, Green Published			2022-12-18	WOS:000344988000001
J	Hu, WM; Xie, NH; Hu, RG; Ling, HB; Chen, Q; Yan, SC; Maybank, S				Hu, Weiming; Xie, Nianhua; Hu, Ruiguang; Ling, Haibin; Chen, Qiang; Yan, Shuicheng; Maybank, Stephen			Bin Ratio-Based Histogram Distances and Their Application to Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Histogram bin ratio; histogram distance; image classification	FEATURES; TEXTURE; KERNEL; SCENE; SHAPE; REPRESENTATION; INFORMATION; MODELS	Large variations in image background may cause partial matching and normalization problems for histogram-based representations, i.e., the histograms of the same category may have bins which are significantly different, and normalization may produce large changes in the differences between corresponding bins. In this paper, we deal with this problem by using the ratios between bin values of histograms, rather than bin values' differences which are used in the traditional histogram distances. We propose a bin ratio-based histogram distance (BRD), which is an intra-cross-bin distance, in contrast with previous bin-to-bin distances and cross-bin distances. The BRD is robust to partial matching and histogram normalization, and captures correlations between bins with only a linear computational complexity. We combine the BRD with the l(1) histogram distance and the chi(2) histogram distance to generate the l(1) BRD and the chi(2) BRD, respectively. These combinations exploit and benefit from the robustness of the BRD under partial matching and the robustness of the l(1) and chi(2) distances to small noise. We propose a method for assessing the robustness of histogram distances to partial matching. The BRDs and logistic regression-based histogram fusion are applied to image classification. The experimental results on synthetic data sets show the robustness of the BRDs to partial matching, and the experiments on seven benchmark data sets demonstrate promising results of the BRDs for image classification.	[Hu, Weiming; Xie, Nianhua; Hu, Ruiguang] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Chen, Qiang] IBM Res, Carlton, Vic 3053, Australia; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Maybank, Stephen] Univ London Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, Berks, England	Chinese Academy of Sciences; Institute of Automation, CAS; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; National University of Singapore; University of London; Birkbeck University London	Hu, WM (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.	wmhu@nlpr.ia.ac.cn; nhxie@nlpr.ia.ac.cn; rghu@nlpr.ia.ac.cn; hbling@temple.edu; qiangchen@au1.ibm.com; eleyans@nus.edu.sg; sjmaybank@dcs.bbk.ac.uk	Yan, Shuicheng/HCI-1431-2022; chen, qiang/HGU-5418-2022		973 basic research program of China [2014CB349303]; National 863 High-Tech R&D Program of China [2012AA012504]; Natural Science Foundation of Beijing [4121003]; NSF [IIS-1218156, IIS-1350521]	973 basic research program of China(National Basic Research Program of China); National 863 High-Tech R&D Program of China(National High Technology Research and Development Program of China); Natural Science Foundation of Beijing(Beijing Natural Science Foundation); NSF(National Science Foundation (NSF))	This work was partly supported by the 973 basic research program of China (Grant No. 2014CB349303), the National 863 High-Tech R&D Program of China (Grant No. 2012AA012504), the Natural Science Foundation of Beijing (Grant No. 4121003), NSF Grant IIS-1218156 and NSF CAREER Award IIS-1350521.	Ablavsky V, 2011, IEEE I CONF COMP VIS, P1473, DOI 10.1109/ICCV.2011.6126404; Agarwal A, 2006, LECT NOTES COMPUT SC, V3951, P30; Berg AC, 2005, PROC CVPR IEEE, P26; Cai D, 2007, IEEE DATA MINING, P427, DOI 10.1109/ICDM.2007.88; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083; Chiang CK, 2011, IEEE I CONF COMP VIS, P1519, DOI 10.1109/ICCV.2011.6126410; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619; Everingham M, 2006, LECT NOTES ARTIF INT, V3944, P117; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Grauman K, 2007, J MACH LEARN RES, V8, P725; Griffin G., 2007, CNSTR2007001 CAL I T; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision; Nguyen HG, 2011, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2011.6116640; Huu-Giao Nguyen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2945, DOI 10.1109/CVPR.2011.5995340; Lang GK, 1997, MACH VISION APPL, V10, P123, DOI 10.1007/s001380050065; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Li FX, 2012, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2012.6247956; Li JW, 2008, PROCEEDINGS OF THE 2008 CHINESE CONFERENCE ON PATTERN RECOGNITION (CCPR 2008), P1; LING H, 2006, P IEEE C COMP VIS PA, V1, P246, DOI DOI 10.1109/CVPR.2006.99; Liu BD, 2013, PATTERN RECOGN, V46, P1879, DOI 10.1016/j.patcog.2012.11.018; Maji Subhransu, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630; Marszalek M., 2007, P VIS REC CHALL WORK, P1; Nguyen HG, 2012, IEEE T GEOSCI REMOTE, V50, P1171, DOI 10.1109/TGRS.2011.2165848; Nguyen HG, 2010, LECT NOTES COMPUT SC, V6314, P764, DOI 10.1007/978-3-642-15561-1_55; Nguyen HG, 2010, INT CONF ACOUST SPEE, P1674, DOI 10.1109/ICASSP.2010.5495506; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199; Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Savarese S., 2006, CVPR, V2, P2033, DOI DOI 10.1109/CVPR.2006.102; Schmid C, 2004, INT J COMPUT VISION, V56, P7, DOI 10.1023/B:VISI.0000004829.38247.b0; Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tahir M. A., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P178, DOI 10.1109/ICCVW.2009.5457703; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Varma M., 2007, P IEEE INT C COMP VI, V1, P1, DOI DOI 10.1109/ICCV.2007.4408875; Willamowski J., 2004, ILLUMINATION, V17, P21; Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178; Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566; Xie NH, 2010, PROC CVPR IEEE, P2313, DOI 10.1109/CVPR.2010.5539917; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	53	19	20	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2338	2352		10.1109/TPAMI.2014.2327975	http://dx.doi.org/10.1109/TPAMI.2014.2327975			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353143	Green Accepted			2022-12-18	WOS:000344988000002
J	Luo, G; Yang, S; Tian, GD; Yuan, CF; Hu, WM; Maybank, SJ				Luo, Guan; Yang, Shuang; Tian, Guodong; Yuan, Chunfeng; Hu, Weiming; Maybank, Stephen J.			Learning Human Actions by Combining Global Dynamics and Local Appearance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; linear dynamical system; local spatio-temporal feature; non-vector descriptor; distance learning	HUMAN ACTION CATEGORIES; BINET-CAUCHY KERNELS; SUBSPACE IDENTIFICATION; RECOGNITION; MODELS; CLASSIFICATION; HISTOGRAMS; SYSTEMS; DENSE; FLOW	In this paper, we address the problem of human action recognition through combining global temporal dynamics and local visual spatio-temporal appearance features. For this purpose, in the global temporal dimension, we propose to model the motion dynamics with robust linear dynamical systems (LDSs) and use the model parameters as motion descriptors. Since LDSs live in a non-euclidean space and the descriptors are in non-vector form, we propose a shift invariant subspace angles based distance to measure the similarity between LDSs. In the local visual dimension, we construct curved spatio-temporal cuboids along the trajectories of densely sampled feature points and describe them using histograms of oriented gradients (HOG). The distance between motion sequences is computed with the Chi-Squared histogram distance in the bag-of-words framework. Finally we perform classification using the maximum margin distance learning method by combining the global dynamic distances and the local visual distances. We evaluate our approach for action recognition on five short clips data sets, namely Weizmann, KTH, UCF sports, Hollywood2 and UCF50, as well as three long continuous data sets, namely VIRAT, ADL and CRIM13. We show competitive results as compared with current state-of-the-art methods.	[Luo, Guan; Yang, Shuang; Tian, Guodong; Yuan, Chunfeng; Hu, Weiming] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Maybank, Stephen J.] Univ London Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; University of London; Birkbeck University London	Luo, G (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun East Rd,POB 2728, Beijing 100190, Peoples R China.	gluo@nlpr.ia.ac.cn; syang@nlpr.ia.ac.cn; gdtian@nlpr.ia.ac.cn; cfyuan@nlpr.ia.ac.cn; wmhu@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk			NSFC [61272330, 60935002]; Beijing Natural Science Foundation [4121003]	NSFC(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work was partly supported by NSFC (Grant No. 61272330, 60935002), and Beijing Natural Science Foundation (4121003).	Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bissacco A, 2007, IEEE T PATTERN ANAL, V29, P1958, DOI 10.1109/TPAMI.2007.1101; Blake A, 1999, ADV NEUR IN, V11, P389; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boots B., 2007, ADV NEURAL INFORM PR, P1329; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779; Burgos-Artizzu XP, 2012, PROC CVPR IEEE, P1322, DOI 10.1109/CVPR.2012.6247817; Caillette F, 2008, COMPUT VIS IMAGE UND, V109, P112, DOI 10.1016/j.cviu.2007.05.005; Chakraborty B, 2013, COMPUT VIS IMAGE UND, V117, P1356, DOI 10.1016/j.cviu.2012.11.008; Chan AB, 2005, PROC CVPR IEEE, P846; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; De Cock K, 2002, SYST CONTROL LETT, V46, P265, DOI 10.1016/S0167-6911(02)00135-4; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Ghahramani Z., 1996, TECH REP, DOI DOI 10.1109/JPROC.2014.2307357; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hongeng S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1455, DOI 10.1109/ICCV.2003.1238661; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Lacy SL, 2003, IEEE T AUTOMAT CONTR, V48, P1259, DOI 10.1109/TAC.2003.814273; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60; McCallum A., 2000, P 17 INT C MACH LEAR, P591; Mikolajczyk K, 2008, PROC CVPR IEEE, P2229; Natarajan P., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587716; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864; Pavlovic V, 2000, PROC CVPR IEEE, P788, DOI 10.1109/CVPR.2000.855901; Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156; Shabani AH, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.100; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42; Turaga P. K., 2007, P IEEE C COMP VIS PA, P1; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Vail D L, 2007, P 6 INT JOINT C AUT, P235, DOI DOI 10.1145/1329125.1329409; Van Gestel T, 2001, IEEE T AUTOMAT CONTR, V46, P1416, DOI 10.1109/9.948469; VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66; Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549; Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161	66	19	19	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2466	2482		10.1109/TPAMI.2014.2329301	http://dx.doi.org/10.1109/TPAMI.2014.2329301			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353152	Green Accepted			2022-12-18	WOS:000344988000011
J	Faktor, A; Irani, M				Faktor, Alon; Irani, Michal			"Clustering by Composition"-Unsupervised Discovery of Image Categories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image clustering; image affinities; category discovery; unsupervised object recognition		We define a "good image cluster" as one in which images can be easily composed (like a puzzle) using pieces from each other, while are difficult to compose from images outside the cluster. The larger and more statistically significant the pieces are, the stronger the affinity between the images. This gives rise to unsupervised discovery of very challenging image categories. We further show how multiple images can be composed from each other simultaneously and efficiently using a collaborative randomized search algorithm. This collaborative process exploits the "wisdom of crowds of images", to obtain a sparse yet meaningful set of image affinities, and in time which is almost linear in the size of the image collection. "Clustering-by-Composition" yields state-of-the-art results on current benchmark data sets. It further yields promising results on new challenging data sets, such as data sets with very few images (where a 'cluster model' cannot be 'learned' by current methods), and a subset of the PASCAL VOC data set (with huge variability in scale and appearance).	[Faktor, Alon; Irani, Michal] Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel; [Faktor, Alon; Irani, Michal] Weizmann Inst Sci, IL-76100 Rehovot, Israel	Weizmann Institute of Science; Weizmann Institute of Science	Faktor, A (corresponding author), Weizmann Inst Sci, Dept Appl Math & Comp Sci, Ziskind Bldg, IL-76100 Rehovot, Israel.	alon.faktor@weizmann.ac.il; michal.irani@weizmann.ac.il			Israeli Science Foundation; Israeli Ministry of Science	Israeli Science Foundation(Israel Science Foundation); Israeli Ministry of Science(Ministry of Science, Technology and Space (MOST), Israel)	The authors would like to thank S. Bagon, M. Zontak, D. Glasner and O. Bartal for their helpful comments on the paper. This work was funded in part by the Israeli Science Foundation and the Israeli Ministry of Science.	Barnes C., 2011, THESIS PRINCETON U; Barnes C., 2009, P ACM SIGGRAPH; Boiman O., 2008, P IEEE C COMP VIS PA; Boiman O., 2006, P ADV NEUR INF PROC; Chum O., 2009, P IEEE C COMP VIS PA; Dalal N., 2005, HISTOGRAMS ORIENTED; Grauman K., 2006, P IEEE C COMP VIS PA; Gu C., 2009, P IEEE C COMP VIS PA; Kim G., 2008, P IEEE C COMP VIS PA; Lazebnik S., 2006, P IEEE C COMP VIS PA; Lee Y.J, 2009, P IEEE C COMP VIS PA; Lee YJ, 2009, INT J COMPUT VISION, V85, P143, DOI 10.1007/s11263-009-0252-y; PAYET N, 2010, P 11 EUR C COMP VIS, V6315, P57; Philbin J., 2008, P 6 IND C COMP VIS G; Russell B. C., 2006, P IEEE C COMP VIS PA; Shechtman E, 2007, P IEEE C COMP VIS PA; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sivic J., 2005, P IEEE 10 INT C COMP; Sivic J., 2003, P IEEE 9 INT C COMP; Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8	20	19	19	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1092	1106		10.1109/TPAMI.2013.251	http://dx.doi.org/10.1109/TPAMI.2013.251			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353273	Green Published			2022-12-18	WOS:000337124200004
J	Chia, AYS; Rajan, D; Leung, MK; Rahardja, S				Chia, Alex Yong-Sang; Rajan, Deepu; Leung, Maylor Karhang; Rahardja, Susanto			Object Recognition by Discriminative Combinations of Line Segments, Ellipses, and Appearance Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape primitives; appearance features; image classification; category-level object detection	TEXTURE; MODELS; SHAPE	We present a novel contour-based approach that recognizes object classes in real-world scenes using simple and generic shape primitives of line segments and ellipses. Compared to commonly used contour fragment features, these primitives support more efficient representation since their storage requirements are independent of object size. Additionally, these primitives are readily described by their geometrical properties and hence afford very efficient feature comparison. We pair these primitives as shape-tokens and learn discriminative combinations of shape-tokens. Here, we allow each combination to have a variable number of shape-tokens. This, coupled with the generic nature of primitives, enables a variety of class-specific shape structures to be learned. Building on the contour-based method, we propose a new hybrid recognition method that combines shape and appearance features. Each discriminative combination can vary in the number and the types of features, where these two degrees of variability empower the hybrid method with even more flexibility and discriminative potential. We evaluate our methods across a large number of challenging classes, and obtain very competitive results against other methods. These results show the proposed shape primitives are indeed sufficiently powerful to recognize object classes in complex real-world scenes.	[Chia, Alex Yong-Sang; Rahardja, Susanto] Inst Infocomm Res, Singapore 138632, Singapore; [Rajan, Deepu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Leung, Maylor Karhang] Jln Univ, Univ Tunku Abdul Rahman, Dept Comp Sci, Fac Informat & Commun Technol, Kampar 31900, Perak, Malaysia	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Universiti Tunku Abdul Rahman (UTAR)	Chia, AYS (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis South Tower, Singapore 138632, Singapore.	ysachia@i2r.a-star.edu.sg; asdrajan@ntu.edu.sg; leungkh@utar.edu.my; rsusanto@i2r.a-star.edu.sg			Institute for Infocomm Research	Institute for Infocomm Research(Agency for Science Technology & Research (A*STAR))	The authors thank the Associate Editor and all reviewers for their valuable input. This work is supported by the Institute for Infocomm Research.	Bai X., 2009, P INT C COMP VIS; Bar-Hillel A, 2008, INT J COMPUT VISION, V77, P175, DOI [10.1007/s11263-007-0091-7, 10.1007/s11263-007-0091]; Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142; Borenstein E., 2002, P EUR C COMP VIS, P639; Chen YH, 2009, IEEE T PATTERN ANAL, V31, P1747, DOI 10.1109/TPAMI.2009.95; Chia AYS, 2011, IEEE T IMAGE PROCESS, V20, P1991, DOI 10.1109/TIP.2010.2099127; Chia AYS, 2010, PROC CVPR IEEE, P2225, DOI 10.1109/CVPR.2010.5539904; Chia AYS, 2009, IEEE T MULTIMEDIA, V11, P1407, DOI 10.1109/TMM.2009.2032683; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; David P, 2005, IEEE I CONF COMP VIS, P1581; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740; Griffin G., 2007, 24 CALTECH; Jurie F, 2004, PROC CVPR IEEE, P90; Kumar P.M., 2004, P BRIT MACH VIS C, P789; Leibe B., 2003, BMVC, P759; Leordeanu M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383091; LEUNG MK, 1990, PATTERN RECOGN, V23, P69, DOI 10.1016/0031-3203(90)90049-Q; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mikolajczyk K., 2003, BRIT MACH VIS C BMVC, V2, P779; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Opelt A, 2008, INT J COMPUT VISION, V80, P16, DOI 10.1007/s11263-008-0139-3; Pons-Moll G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.4; Ren X., 2007, P CVPR, P1, DOI DOI 10.1109/CVPR.2007.383177; Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhu L, 2009, IEEE T PATTERN ANAL, V31, P114, DOI 10.1109/TPAMI.2008.67	34	19	20	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1758	1772		10.1109/TPAMI.2011.220	http://dx.doi.org/10.1109/TPAMI.2011.220			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22064799				2022-12-18	WOS:000306409100009
J	Schweitzer, H; Deng, R; Anderson, RF				Schweitzer, Haim; Deng, Rui (April); Anderson, Robert Finis			A Dual-Bound Algorithm for Very Fast and Exact Template Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Template matching; Walsh transform; pattern matching; real-time matching; priority queues		Recently proposed fast template matching techniques employ rejection schemes derived from lower bounds on the match measure. This paper generalizes that idea and shows that in addition to lower bounds, upper bounds on the match measure can be used to accelerate the search. An algorithm is proposed that utilizes both lower and upper bounds to detect the k best matches in an image. The performance of this dual-bound algorithm is guaranteed; it always detects the k best matches. Theoretical analysis and experimental results show that its runtime compares favorably with previously proposed real-time exact template-matching schemes.	[Schweitzer, Haim; Deng, Rui (April); Anderson, Robert Finis] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75080 USA	University of Texas System; University of Texas Dallas	Schweitzer, H (corresponding author), Univ Texas Dallas, Dept Comp Sci, 800 W Campbell Rd, Richardson, TX 75080 USA.	hschweitzer@utdallas.edu; rxd065000@utdallas.edu; rfa061000@utdallas.edu						Beauchamp K.G., 1984, APPL WALSH RELATED F; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; DEGRAAF JM, 1992, BIT, V32, P570, DOI 10.1007/BF01994841; DENG R, 2009, UTDCS1709; Duda R.O., 1973, J ROYAL STAT SOC SER; Gharavi-Alkhansari M, 2001, IEEE T IMAGE PROCESS, V10, P526, DOI 10.1109/83.913587; GHARAVIALKHANSA.M, 2001, P INT C IM PROC, V2, P713; GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Hoeg F., 1994, Proceedings of the Third International Workshop on Hardware/Software Codesign (Cat. No.94TH0700-5), P81, DOI 10.1109/HSC.1994.336720; KAWANISHI T, 2004, P 17 IEEE INT C PATT; LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809; Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362; Ouyang WL, 2010, IEEE T PATTERN ANAL, V32, P165, DOI 10.1109/TPAMI.2009.104; Pele O, 2008, IEEE T PATTERN ANAL, V30, P1427, DOI 10.1109/TPAMI.2007.70794; Pele O, 2007, LECT NOTES COMPUT SC, V4844, P435; Ronngren R., 1997, ACM Transactions on Modeling and Computer Simulation, V7, P157, DOI 10.1145/249204.249205; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; RUSSELL BC, 2005, AIM2005025 MIT AI LA; SCHWEITZER H, 2009, P IEEE INT C COMP VI; SCHWEITZER H, 2002, P 7 EUR C COMP VIS, P358; Smith J.O., 2007, MATH DISCRETE FOURIE; Stewart G., 1990, MATRIX PERTURBATION; Tombari F, 2009, IEEE T PATTERN ANAL, V31, P129, DOI 10.1109/TPAMI.2008.46; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb	26	19	22	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					459	470		10.1109/TPAMI.2010.105	http://dx.doi.org/10.1109/TPAMI.2010.105			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20479491				2022-12-18	WOS:000286204700003
J	Chaudhuri, P; Ghosh, AK; Oja, H				Chaudhuri, Probal; Ghosh, Anil K.; Oja, Hannu			Classification Based on Hybridization of Parametric and Nonparametric Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes risk; bandwidth; kernel density estimation; LDA; misclassification rate; multiscale smoothing; nearest neighbor; QDA	NEAREST-NEIGHBOR CLASSIFICATION; KERNEL DENSITY-ESTIMATION; PATTERN-CLASSIFICATION; DISCRIMINANT-ANALYSIS; SCALE-SPACE; REGRESSION; VISUALIZATION; VIEW	Parametric methods of classification assume specific parametric models for competing population densities (e. g., Gaussian population densities can lead to linear and quadratic discriminant analysis) and they work well when these model assumptions are valid. Violation in one or more of these parametric model assumptions often leads to a poor classifier. On the other hand, nonparametric classifiers (e. g., nearest-neighbor and kernel-based classifiers) are more flexible and free from parametric model assumptions. But, the statistical instability of these classifiers may lead to poor performance when we have small numbers of training sample observations. Nonparametric methods, however, do not use any parametric structure of population densities. Therefore, even when one has some additional information about population densities, that important information is not used to modify the nonparametric classification rule. This paper makes an attempt to overcome these limitations of parametric and nonparametric approaches and combines their strengths to develop some hybrid classification methods. We use some simulated examples and benchmark data sets to examine the performance of these hybrid discriminant analysis tools. Asymptotic results on their misclassification rates have been derived under appropriate regularity conditions.	[Chaudhuri, Probal; Ghosh, Anil K.] Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, India; [Oja, Hannu] Univ Tampere, Tampere Sch Publ Hlth, Tampere 33014, Finland	Indian Statistical Institute; Indian Statistical Institute Kolkata; Tampere University	Chaudhuri, P (corresponding author), Indian Stat Inst, Theoret Stat & Math Unit, 203 BT Rd, Kolkata 700108, India.	probal@isical.ac.in; anilkghosh@rediffmail.com; Hannu.Oja@uta.fi			Council of Scientific and Industrial Research; Department of Biotechnology, Government of India; Academy of Finland	Council of Scientific and Industrial Research(Council of Scientific & Industrial Research (CSIR) - India); Department of Biotechnology, Government of India(Department of Biotechnology (DBT) India); Academy of Finland(Academy of Finland)	The authors would like to thank the reviewers for their careful reading of the earlier version of the paper and for providing them with several helpful comments. The research of Probal Chaudhuri was partially supported by the grants of the Council of Scientific and Industrial Research and the Department of Biotechnology, Government of India. The research of Hannu Oja was partially supported by the grants of the Academy of Finland.	Bolance C, 2003, INSUR MATH ECON, V32, P19, DOI 10.1016/S0167-6687(02)00191-9; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Buch-Larsen T, 2005, STATISTICS-ABINGDON, V39, P503, DOI 10.1080/02331880500439782; Chaudhuri P, 2000, ANN STAT, V28, P408, DOI 10.1214/aos/1016218224; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fix E., 1951, JOSEPH; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J. H., 1994, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Ghosh AK, 2006, TECHNOMETRICS, V48, P120, DOI 10.1198/004017005000000391; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; Ghosh AK, 2007, INT J PATTERN RECOGN, V21, P1103, DOI 10.1142/S0218001407005855; Glad IK, 1998, SCAND J STAT, V25, P649, DOI 10.1111/1467-9469.00127; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; HAND DJ, 1982, KERNEL DISCRIMINANT; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HJORT NL, 1995, ANN STAT, V23, P882, DOI 10.1214/aos/1176324627; Hjort NL, 1996, ANN STAT, V24, P1619; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Hoti F, 2004, PATTERN RECOGN, V37, P409, DOI 10.1016/j.patcog.2003.08.004; Johnson R. A., 2014, APPL MULTIVARIATE ST, V6; JONES MC, 1995, BIOMETRIKA, V82, P327; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LAI S, 1977, THESIS U CALIFORNIA; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mahalanobis P.C., 1936, P NAT I SCI INDIA, V2, P49; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; OLKIN I, 1987, J AM STAT ASSOC, V82, P858, DOI 10.2307/2288797; Olshen R., 1984, CLASSIFICATION REGRE; Ripley BD., 1996; Schapire RE, 1998, ANN STAT, V26, P1651; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; SHALAK DB, 1996, THESIS U MASSACHUSET; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; SILVERMAN BW, 1978, ANN STAT, V6, P177, DOI 10.1214/aos/1176344076; Vapnik V.N, 1998, STAT LEARNING THEORY; Wand M.P., 1995, KERNEL SMOOTHING	45	19	20	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1153	1164		10.1109/TPAMI.2008.149	http://dx.doi.org/10.1109/TPAMI.2008.149			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443915				2022-12-18	WOS:000266188900001
J	Hirata, NST				Hirata, Nina S. T.			Multilevel Training of Binary Morphological Operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing; pattern recognition; machine learning; classifier design and evaluation; morphological operator; Boolean function; image operator learning; multilevel training; stacked generalization	MATHEMATICAL MORPHOLOGY; DESIGN; STACK; ALGORITHM; FILTERS; MAPPINGS	The design of binary morphological operators that are translation-invariant and locally defined by a finite neighborhood window corresponds to the problem of designing Boolean functions. As in any supervised classification problem, morphological operators designed from a training sample also suffer from overfitting. Large neighborhood tends to lead to performance degradation of the designed operator. This work proposes a multilevel design approach to deal with the issue of designing large neighborhood-based operators. The main idea is inspired by stacked generalization (a multilevel classifier design approach) and consists of, at each training level, combining the outcomes of the previous level operators. The final operator is a multilevel operator that ultimately depends on a larger neighborhood than of the individual operators that have been combined. Experimental results show that two-level operators obtained by combining operators designed on subwindows of a large window consistently outperform the single-level operators designed on the full window. They also show that iterating two-level operators is an effective multilevel approach to obtain better results.	Univ Sao Paulo, Dept Comp Sci, Inst Math & Stat, DCC IME USP, BR-05508090 Sao Paulo, Brazil	Universidade de Sao Paulo	Hirata, NST (corresponding author), Univ Sao Paulo, Dept Comp Sci, Inst Math & Stat, DCC IME USP, Rua Matao 1010, BR-05508090 Sao Paulo, Brazil.	nina@ime.usp.br	Hirata, Nina S. T./C-1491-2012	Hirata, Nina S. T./0000-0001-9722-5764	FAPESP [2004/11586-7]; CNPq, Brazil [312482/2006-0]	FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)); CNPq, Brazil(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ))	This work has been supported by FAPESP through process 2004/11586-7. Nina S. T. Hirata is partially supported by CNPq, Brazil, under Grant 312482/2006-0.	BANON GJF, 1993, SIGNAL PROCESS, V30, P299, DOI 10.1016/0165-1684(93)90015-3; BANON GJF, 1991, SIAM J APPL MATH, V51, P1782, DOI 10.1137/0151091; Barrera J, 1997, J ELECTRON IMAGING, V6, P54, DOI 10.1117/12.260010; Barrera J., 2000, Fundamenta Informaticae, V41, P229; Barrera J, 1996, J ELECTRON IMAGING, V5, P335, DOI 10.1117/12.240717; COYLE EJ, 1988, IEEE T ACOUST SPEECH, V36, P1244, DOI 10.1109/29.1653; Dellamonica D, 2007, IEEE T IMAGE PROCESS, V16, P453, DOI 10.1109/TIP.2006.888358; DOUGHERTY ER, 1992, CVGIP-IMAG UNDERSTAN, V55, P36, DOI 10.1016/1049-9660(92)90005-N; DOUGHERTY ER, 1998, P INT S MATH MORPH, P259; Dougherty ER., 2003, HANDS ON MORPHOLOGIC; DOUGHERTY ER, 1999, NONLINEAR FILTERS IM, P60; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HARVEY D, 1996, RETHINKING MARXISM, V8, P1; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Heijmans H., 1994, MORPHOLOGICAL IMAGE; HILL FJ, 1993, COMPUTER AIDED LOGIC; Hirata NST, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P63; Hirata NST, 2000, PATTERN RECOGN, V33, P1059, DOI 10.1016/S0031-3203(99)00165-X; Hirata NST, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P219; Hirata NST, 2000, OPT ENG, V39, P3106, DOI 10.1117/1.1327178; Hirata R, 2000, SIGNAL PROCESS, V80, P697, DOI 10.1016/S0165-1684(99)00162-0; Hirata R, 2002, J MATH IMAGING VIS, V16, P199, DOI 10.1023/A:1020377610141; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kuncheva L I, 2004, COMBINING PATTERN CL; Martins DC, 2006, PATTERN ANAL APPL, V9, P139, DOI 10.1007/s10044-006-0031-0; Matheron G., 1975, RANDOM SETS INTEGRAL; MITCHELL TOM M., 1997, MACH LEARN, P2; Quintana M. I., 2006, Genetic Programming and Evolvable Machines, V7, P81, DOI 10.1007/s10710-006-7012-3; Salembier P., 1992, Journal of Visual Communication and Image Representation, V3, P115, DOI 10.1016/1047-3203(92)90010-Q; Serra J, 1982, IMAGE ANAL MATH MORP; Soille P., 2013, MORPHOLOGICAL IMAGE; Tabus I, 1996, IEEE T IMAGE PROCESS, V5, P809, DOI 10.1109/83.503901; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yoda I, 1999, IMAGE VISION COMPUT, V17, P749, DOI 10.1016/S0262-8856(98)00151-6; Yoo J, 1999, IEEE T IMAGE PROCESS, V8, P1014, DOI 10.1109/83.777083	35	19	20	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					707	720		10.1109/TPAMI.2008.118	http://dx.doi.org/10.1109/TPAMI.2008.118			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229085				2022-12-18	WOS:000263396100010
J	Zhao, DF; Yang, L				Zhao, Dongfang; Yang, Li			Incremental Isometric Embedding of High-Dimensional Data Using Connected Neighborhood Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; incremental learning; Isomap; manifold learning; neighborhood graph	REDUCTION; LENGTH	Most nonlinear data embedding methods use bottom-up approaches for capturing the underlying structure of data distributed on a manifold in high-dimensional space. These methods often share the first step, which defines neighbor points of every data point by building a connected neighborhood graph so that all data points can be embedded into a single coordinate system. These methods are required to work incrementally for dimensionality reduction in many applications. Because the input data stream may be undersampled or skewed from time to time, building a connected neighborhood graph is crucial to the success of incremental data embedding using these methods. This paper presents algorithms for updating k-edge-connected and k-connected neighborhood graphs after a new data point is added or an old data point is deleted. It further utilizes a simple algorithm for updating all-pair shortest distances on the neighborhood graph. Together with incremental classical multidimensional scaling using iterative subspace approximation, this paper devises an incremental version of Isomap with enhancements to deal with undersampled or unevenly distributed data. Experiments on both synthetic and real-world data sets show that the algorithm is efficient and maintains low-dimensional configurations of high-dimensional data under various data distributions.	[Zhao, Dongfang] Distribut & Mkt Inc, Atlanta, GA USA; [Yang, Li] Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA	Western Michigan University	Zhao, DF (corresponding author), Distribut & Mkt Inc, Atlanta, GA USA.	dongfang.zhao@idminc.com; li.yang@wmich.edu			US National Science Foundation [IIS-0414857, EIA-0215356, EIA-0130857]	US National Science Foundation(National Science Foundation (NSF))	This work is supported in part by the US National Science Foundation under Grants IIS-0414857, EIA-0215356, and EIA-0130857. The authors are grateful to Anil K. Jain and Martin H. C. Law from Michigan State University for insightful discussions and for providing them with the software reported in [15] for incremental Isomap. This work was done while D. Zhao was a PhD student in the Department of Computer Science at Western Michigan University.	AUSIELLO G, 1992, THEOR COMPUT SCI, V95, P245, DOI 10.1016/0304-3975(92)90267-J; BLAKELEY JA, 1986, P ACM SIGMOD INT C M, P61; BUCHSBAUM AL, 1990, PROCEEDINGS OF THE FIRST ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P22; CHIN F, 1978, J COMPUT SYST SCI, V16, P333, DOI 10.1016/0022-0000(78)90022-3; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; Dong G., 1992, DATABASE THEORY ICDT, P282, DOI [10.1007/3-540-56039-4_48, DOI 10.1007/3-540-56039-4_48]; Ford L. R. J., 1962, FLOWS NETWORKS; Garey M.R., 1979, COMPUTERS INTRACTABI; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Harrison J. V., 1992, P 1992 JICLSP WORKSH, P56; KRUSKAL JB, 1971, IEEE T COMPUT, VC 20, P1614, DOI 10.1109/T-C.1971.223184; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56; Lee JH, 2000, 2000 IEEE/LEOS INTERNATIONAL CONFERENCE ON OPTICAL MEMS, P13, DOI 10.1109/OMEMS.2000.879604; MATULA DW, 1978, J COMB THEORY B, V24, P1, DOI 10.1016/0095-8956(78)90071-0; Pang CY, 2005, ACM T DATABASE SYST, V30, P698, DOI 10.1145/1093382.1093384; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Shmueli O., 1984, SIGMOD Record, V14, P240, DOI 10.1145/971697.602293; SPIRA PM, 1975, SIAM J COMPUT, V4, P2015; Tarjan RE., 1974, P 6 ANN ACM S THEOR, P185; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Yang L, 2006, IEEE T PATTERN ANAL, V28, P827, DOI 10.1109/TPAMI.2006.89; Yang L, 2005, IEEE T PATTERN ANAL, V27, P1680, DOI 10.1109/TPAMI.2005.192; Yang L, 2004, INT C PATT RECOG, P196; YANG L, 2005, PATTERN RECOGN, V26, P2015; [No title captured]	28	19	26	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					86	98		10.1109/TPAMI.2008.34	http://dx.doi.org/10.1109/TPAMI.2008.34			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029548				2022-12-18	WOS:000260889700008
J	Sung, J; Ghahramani, ZB; Bang, SY				Sung, Jaemo; Ghahramani, Zoubin; Bang, Sung-Yang			Latent-Space Variational Bayes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian inference; conjugate-exponential family; variational method; mixture of Gaussians; mixture of Bernoullis	LIKELIHOOD	Variational Bayesian Expectation-Maximization (VBEM), an approximate inference method for probabilistic models based on factorizing over latent variables and model parameters, has been a standard technique for practical Bayesian inference. In this paper, we introduce a more general approximate inference framework for conjugate-exponential family models. which we call Latent-Space Variational Bayes (LSVB). In this approach, we integrate out the model parameters in an exact way, leaving only the latent variables. It can be shown that the LSVB approach gives better estimates of the model evidence as well as the distribution over the latent variables than the VBEM approach, but, in practice, the distribution over the latent variables has to be approximated. As a practical implementation, we present a First-order LSVB (FoLSVB) algorithm to approximate the distribution over the latent variables. From this approximate distribution, one can also estimate the model evidence and the posterior over the model parameters. The FoLSVB algorithm is directly comparable to the VBEM algorithm and has the same computational complexity. We discuss how LSVB generalizes the recently proposed collapsed variational methods to general conjugate-exponential families. Examples based on mixtures of Gaussians and mixtures of Bernoullis with synthetic and real-world data sets are used to illustrate some advantages of our method over VBEM.	[Sung, Jaemo; Bang, Sung-Yang] Pohang Univ Sci & Technol, Dept Comp Sci & Engn, Pohang 790784, Kyungbuk, South Korea; [Ghahramani, Zoubin] Univ Cambridge, Informat Engn Dept Engn, Cambridge CB2 1PZ, England	Pohang University of Science & Technology (POSTECH); University of Cambridge	Sung, J (corresponding author), Pohang Univ Sci & Technol, Dept Comp Sci & Engn, San 31 Hyoja Dong, Pohang 790784, Kyungbuk, South Korea.	emtidi@postech.ac.kr; zoubin@eng.cam.ac.uk; sybang@postech.ac.kr						Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Asuncion A, 2007, UCI MACHINE LEARNING; ATTIAS H, 2000, ADV NEURAL INFORM PR, V12; Beal M.J., 2003, VARIATIONAL ALGORITH; Beal M. J., 2003, BAYESIAN STAT, V7; Bernardo J. M., 2000, BAYESIAN THEORY; Bishop C.M, 2006, PATTERN RECOGN; Chickering DM, 1997, MACH LEARN, V29, P181, DOI 10.1023/A:1007469629108; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Gelman A, 2013, BAYESIAN DATA ANAL, P16; Ghahramani Z, 2000, ADV NEURAL INFORM PR, V12; GHAHRAMANI Z, 2001, ADV NEURAL INFORM PR, V13; Jaakkola T., 2000, ADV MEAN FIELD METHO; JEFFERYS WH, 1992, AM SCI, V80, P64; JORDAN M, 1999, MACH LEARN, V72, P183; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; McLachlan G. J., 2000, FINITE MIXTURE MODEL; Neal RM, 1993, CRGTR931 U TOR DEP C; RASMUSSEN CE, 2001, ADV NEURAL INFORM PR, V13; Robert C. P., 1999, MONTE CARLO STAT MET; Svensen M, 2005, NEUROCOMPUTING, V64, P235, DOI 10.1016/j.neucom.2004.11.018; Teh Y. W., 2007, ADV NEURAL INFORM PR, V19; Teh Y. W., 2008, ADV NEURAL INFORM PR, V20; Ueda N, 2002, NEURAL NETWORKS, V15, P1223, DOI 10.1016/S0893-6080(02)00040-0; Winn J, 2005, J MACH LEARN RES, V6, P661	25	19	20	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2236	2242		10.1109/TPAMI.2008.157	http://dx.doi.org/10.1109/TPAMI.2008.157			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988955				2022-12-18	WOS:000260033900013
J	Lim, T; Medellin, H; Torres-Sanchez, C; Corney, JR; Ritchie, JM; Davies, JBC				Lim, T; Medellin, H; Torres-Sanchez, C; Corney, JR; Ritchie, JM; Davies, JBC			Edge-based identification of DP-features on free-form solids	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional geometric feature recognition; geometric modeling; CAD; CAM; CAPP	FEATURE RECOGNITION; MODEL; DECOMPOSITION; EXTRACTION	Numerous applications in mechanical CAD/CAM need robust algorithms for the identification of protrusion and depression features (DP-features) on geometric models with free-form (B-Spline) surfaces. This paper reports a partitioning algorithm that first identifies the boundary edges of DP-features and then creates a surface patch to cover the depressions or isolate the protrusions. The novelty of the method lies in the use of tangent continuity between edge segments to identify DP-feature boundaries that cross multiple faces and geometries.	Heriot Watt Univ, Scottish Mfg Inst, Dept Mech Engn, Edinburgh EH14 4AS, Midlothian, Scotland	Heriot Watt University	Lim, T (corresponding author), Heriot Watt Univ, Scottish Mfg Inst, Dept Mech Engn, Edinburgh EH14 4AS, Midlothian, Scotland.	t.lim@hw.ac.uk; him1@hw.ac.uk; mt27@hw.ac.uk; j.r.corney@hw.ac.uk; j.m.ritchie@hw.ac.uk; b.j.davies@hw.ac.uk	Medellin-Castillo, Hugo Ivan I/A-3455-2017; Torres-Sanchez, Carmen/A-8213-2010	Medellin-Castillo, Hugo Ivan I/0000-0002-2827-9547; Torres-Sanchez, Carmen/0000-0002-1649-2068; Lim, Theodore/0000-0001-8931-2745	Engineering and Physical Sciences Research Council [GR/S12395/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		BERG E, 2003, P 8 ACM S SOL MOD AP, P56; BERG E, 2002, J COMPUTERS IND, V49, P217; Bhandarkar MP, 2000, COMPUT IND, V41, P3, DOI 10.1016/S0166-3615(99)00040-8; CORNEY J, 2001, 3DMODELING ACIS; GAVANKAR P, 1990, COMPUT AIDED DESIGN, V22, P442, DOI 10.1016/0010-4485(90)90109-P; Han JH, 2000, IEEE T ROBOTIC AUTOM, V16, P782, DOI 10.1109/70.897789; JI Q, 1997, ACM COMPUT SURV, V24, P264; Joshi N, 2003, J COMPUTING INFORM S, V3, P177, DOI DOI 10.1115/1.1603307; JOSHI S, 1988, COMPUT AIDED DESIGN, V20, P58, DOI 10.1016/0010-4485(88)90050-4; KUMAR M, 2001, P 6 ACM S SOL MOD AP, P278; LEE NL, 1995, P ASME INT COMP ENG, P805; Li BF, 2002, COMPUT AIDED DESIGN, V34, P405, DOI 10.1016/S0010-4485(01)00118-X; LIM, 2002, P DETC 02 ASME; Lim T, 2001, IEEE T PATTERN ANAL, V23, P1043, DOI 10.1109/34.955117; SHAH J, 1994, ADV FEATURE BASED MA, P261; SHAH JJ, 1991, COMPUT AIDED DESIGN, V23, P331, DOI 10.1016/0010-4485(91)90027-T; Siu YK, 2002, COMPUT AIDED DESIGN, V34, P705, DOI 10.1016/S0010-4485(01)00200-7; SONTHI R, 1997, P 4 S SOL MOD APPL S, P285, DOI DOI 10.1145/267734.267805; Sundararajan V, 2004, COMPUT AIDED DESIGN, V36, P11, DOI 10.1016/S0010-4485(03)00065-4; VENTARKARAMAN S, 2001, P 6 ACM S SOL MOD AP, P99; Woo Y, 2003, COMPUT AIDED DESIGN, V35, P969, DOI 10.1016/S0010-4485(02)00144-6; Zhu H, 2002, COMPUT AIDED DESIGN, V34, P109, DOI 10.1016/S0010-4485(01)00056-2; [No title captured]; 2005, PATHTRACE ENG SYSTEM	24	19	22	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					851	860		10.1109/TPAMI.2005.118	http://dx.doi.org/10.1109/TPAMI.2005.118			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943418				2022-12-18	WOS:000228334700002
J	Aguiar, PMQ; Moura, JMF				Aguiar, PMQ; Moura, JMF			Rank 1 weighted factorization for 3D structure recovery: Algorithms and performance analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						factorization methods; structure from motion; image sequence analysis; rigid body motion; uncertainty in motion analysis; power method; weighted factorization	MOTION	The paper describes the rank 1 weighted factorization solution to the structure from motion problem. This method recovers the 3D structure from the factorization at a data matrix that is rank 1 rather than rank 3. This matrix collects the estimates of the 2D motions of a set of feature points of the rigid object. These estimates are weighted by the inverse of the estimates error standard deviation so that the 2D motion estimates for "sharper" features, which are usually well-estimated, are given more weight, white the noisier motion estimates for "smoother" features are weighted less. We analyze the performance of the rank 1 weighted factorization algorithm to determine what are the most suitable 3D shapes or the best 3D motions to recover the 3D structure of a rigid object from the 2D motions of the features. Our approach is developed for the orthographic camera model. It avoids expensive singular value decompositions by using the power method and is suitable to handle dense sets of feature points and long video sequences. Experimental studies with synthetic and real data illustrate the good performance of our approach.	Inst Super Tecn, ISR, P-1049001 Lisbon, Portugal; Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Universidade de Lisboa; Instituto Superior Tecnico; Carnegie Mellon University	Aguiar, PMQ (corresponding author), Inst Super Tecn, ISR, Torre Norte,Av Rovisco Pais, P-1049001 Lisbon, Portugal.	aguiar@isr.ist.utl.pt; moura@ece.cmu.edu	Moura, Jose M F/G-2189-2010; Aguiar, Pedro MQ/C-5523-2008	Moura, Jose M F/0000-0002-9822-8294; Aguiar, Pedro/0000-0002-3809-8416				Aguiar P. M., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P178, DOI 10.1109/CVPR.1999.786936; Aguiar PMQ, 2001, IEEE T IMAGE PROCESS, V10, P1541, DOI 10.1109/83.951539; AGUIAR PMQ, 2000, THESIS I SUPERIOR TE; Ayache N, 1991, ARTIFICIAL VISION MO; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BERGEN JR, 1992, P EUR C COMP VIS, P237; BRODSKY T, 1999, IEEE C COMPUTER VISI, V2, P146; BROIDA T, 1991, IEEE T PATTERN ANAL, V13; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Golub GH, 1989, J HOPKINS SERIES MAT; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; IRANI M, 2000, P 6 EUR C COMP VIS J, V1, P539; Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289; Morris DD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P696, DOI 10.1109/ICCV.1998.710793; Poelman C., 1995, THESIS CARNEGIE MELL; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; QUAN L, 1996, IEEE C COMPUTER VISI; SCHARF LL, 1991, ELECT COMPUTER ENG D; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; STEINHAUER LC, 1992, FUSION TECHNOL, V22, P9, DOI 10.13182/FST92-A30048; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; SZELISKI R, 1994, J VISUAL COMM IMAGE, V5; TOMASI C, 1991, THESIS CARNEGIE MELL; TOMASI C, 1990, P IEEE INT C COMPUTE; TOMASI C, 1992, INT J COMPUTER VISIO, V9; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074	29	19	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1134	1149		10.1109/TPAMI.2003.1227988	http://dx.doi.org/10.1109/TPAMI.2003.1227988			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX		Green Submitted			2022-12-18	WOS:000184977300008
J	Windridge, D; Kittler, J				Windridge, D; Kittler, J			A morphologically optimal strategy for classifier combination: Multiple expert fusion as a tomographic process	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier combination; tomography; probability theory; feature selection	HANDWRITTEN NUMERALS	We specify an analogy in which the various classifier combination methodologies are interpreted as the implicit reconstruction, by tomographic means, of the composite probability density function spanning the entirety of the pattern space, the process of feature selection in this scenario amounting to an extremely bandwidth-limited Radon transformation of the training data. This metaphor, once elaborated, immediately suggests techniques for improving the process, ultimately defining, in reconstructive terms, an optimal performance criterion for such combinatorial approaches.	Univ Surrey, Dept Elect & Elect Engn, Guildford GU2 7XH, Surrey, England	University of Surrey	Windridge, D (corresponding author), Univ Surrey, Dept Elect & Elect Engn, Guildford GU2 7XH, Surrey, England.			Windridge, David/0000-0001-5507-8516				ALI KM, 1995, 9538 ICSUCI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; CORNWELL TJ, 1985, ASTRON ASTROPHYS, V143, P77; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263; DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; Herman GT., 1980, COMPUTER SCI APPL MA; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Hogbom J. A., 1974, Astronomy and Astrophysics Supplement Series, V15, P417; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Kittler J., 2001, Pattern Recognition and Image Analysis, V11, P529; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KITTLER J, 1997, P IAPR 1 INT WORKSH, P205; LAM L, 1995, PATTERN RECOGN LETT, V16, P945, DOI 10.1016/0167-8655(95)00050-Q; NATTERER F, 1996, P STATE ART NUMERICA; Neal RM, 1993, CRGTR931 U TOR DEP C; Rahman AFR, 1997, PATTERN RECOGN LETT, V18, P781, DOI 10.1016/S0167-8655(97)00078-0; Rahman AFR, 1998, PATTERN RECOGN, V31, P1255, DOI 10.1016/S0031-3203(97)00161-1; WEBB S, 1993, PHYSICS MED IMAGING; WINDRIDGE D, UNPUB PATTERN RECOGN; WINDRIDGE D, 2000, P ADV PATTERN RECOGN, V1876; WINDRIDGE D, 2001, MULTIPLE CLASSIFIER, V2096; WINDRIDGE D, 2000, VSSPTR5 U SURR; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; XU L, 1994, IEEE T SYST MAN CYB, V22, P1539	24	19	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					343	353		10.1109/TPAMI.2003.1182097	http://dx.doi.org/10.1109/TPAMI.2003.1182097			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL					2022-12-18	WOS:000181071300006
J	Bulow, T; Klette, R				Bulow, T; Klette, R			Digital curves in 3D space and a linear-time length estimation algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digital geometry; curve length; space curves; cellular complexes		We consider simple digital curves in a 3D orthogonal grid as special polyhedrally bounded sets. These digital curves model digitized curves or arcs in three-dimensional Euclidean space. The length of such a simple digital curve is defined to be the length of the minimum-length polygonal curve fully contained and complete in the tube of this digital curve. So far, no algorithm was known for the calculation of such a shortest polygonal curve. This paper provides an iterative algorithmic solution for approximating the minimum-length polygon of a given simple digital space-curve. The theoretical foundations of this algorithm are presented as well as experimental results.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; Univ Auckland, Auckland 1005, New Zealand	University of California System; University of California Berkeley; University of Auckland	Bulow, T (corresponding author), Univ Calif Berkeley, Div Comp Sci, 485 Soda Hall 1776, Berkeley, CA 94720 USA.			Klette, Reinhard/0000-0001-8818-7145				Bulow T., 2000, P 15 INT C PATT REC, V3, P551; BUSEMANN R, 1935, ACTA MATH, V66, P27; CANNY J, 1987, IEEE FDN COMPUT SCI, V28, P49; Choi J., 1994, P 10 ANN ACM S COMP, P41; Jonas A, 1998, J MATH IMAGING VIS, V8, P215, DOI 10.1023/A:1008218517090; Klette R., 2000, Machine Graphics & Vision, V9, P673; Rosenfeld A, 1979, PICTURE LANGUAGE FOR; Sloboda F, 1998, P SOC PHOTO-OPT INS, V3454, P52, DOI 10.1117/12.323274; Sloboda F., 1998, ADV DIGITAL COMPUTAT, P113; Voss, 1993, DISCRETE IMAGES OBJE, DOI 10.1007/978-3-642-46779-0	10	19	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					962	970		10.1109/TPAMI.2002.1017622	http://dx.doi.org/10.1109/TPAMI.2002.1017622			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF					2022-12-18	WOS:000176446100008
J	Raphael, C				Raphael, C			Coarse-to-fine dynamic programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic programming; A-star; mine recognition; brachistochrone; iterated complete path; coarse to fine; global optimization	BLOCK; ALGORITHM; SEARCH	We introduce an extension of dynamic programming (DP) we call "Coarse-to-Fine Dynamic Programming" (CFDP), ideally suited to DP problems with large state space. CFDP uses dynamic programming to solve a sequence of coarse approximations which are lower bounds to the original DP problem. These approximations are developed by merging states in the original graph into "superstates" in a coarser graph which uses an optimistic arc cost between superstates. The approximations are designed so that when CFDP terminates the optimal path through the original state graph has been found. CFDP leads to significant decreases in the amount of computation necessary to solve many DID problems and can, in some instances, make otherwise infeasible computations possible, CFDP generalizes to DP problems with continuous state space and we offer a convergence result for this extension. The computation of the approximations requires that we bound the arc cost over all possible arcs associated with an adjacent pair of superstates; thus the feasibility of our proposed method requires the identification of such a lower bound. We demonstrate applications of this technique to optimization of functions and boundary estimation in mine recognition.	Univ Massachusetts, Dept Math & Stat, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Raphael, C (corresponding author), Univ Massachusetts, Dept Math & Stat, Amherst, MA 01003 USA.	raphael@math.umass.edu						AKHIEZER N, 1962, CALCULUS VARIATIONS, P180; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BARBEHENN M, 1995, IEEE T ROBOTIC AUTOM, V11, P198, DOI 10.1109/70.370502; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Chen PC, 1998, IEEE T ROBOTIC AUTOM, V14, P390, DOI 10.1109/70.678449; FUJIMURA K, 1989, IEEE T ROBOTIC AUTOM, V5, P61, DOI 10.1109/70.88018; Fujiwara T, 1998, IEEE T INFORM THEORY, V44, P714, DOI 10.1109/18.661515; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; HART P, 1968, IEEE T SYST SCI CYB, V4, P98; KAM A, 1994, IEEE INT C AC SPEECH, V5, P145; KAM A, 1993, THESIS MIT; KAMBHAMPATI S, 1986, IEEE J ROBOT AUTOM, V2, P135, DOI 10.1109/JRA.1986.1087051; KASAMI T, 1993, IEEE T INFORM THEORY, V39, P1057, DOI 10.1109/18.256515; Khaneja N, 1998, IEEE T PATTERN ANAL, V20, P1260, DOI 10.1109/34.730559; KOCKANEK K, 1998, THESIS BROWN U; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; LEE KF, 1988, THESIS CARNEGIE MELL; Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; MUDER DJ, 1988, IEEE T INFORM THEORY, V34, P1049, DOI 10.1109/18.21228; NILSSON N, 1980, PRINCIPLES ARTIFICIA, P74; PEARL J, 1984, HEURISTICS INTELLIGE, P61; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raphael C, 1997, P SOC PHOTO-OPT INS, V3079, P316, DOI 10.1117/12.280874; WOLF JK, 1978, IEEE T INFORM THEORY, V24, P76, DOI 10.1109/TIT.1978.1055821; ZHU D, 1991, IEEE T ROBOTIC AUTOM, V7, P9, DOI 10.1109/70.68066	26	19	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1379	1390		10.1109/34.977562	http://dx.doi.org/10.1109/34.977562			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700004
J	Fenster, SD; Kender, JR				Fenster, SD; Kender, JR			Sectored snakes: Evaluating learned-energy segmentations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						learning; trained deformable models; energy-minimizing shapes; snakes; segmentation evaluation; performance characterization	CONTOURS	We describe how to teach deformable models to maximize image segmentation correctness based on user-specified criteria, and we present a method for evaluating which criteria work best. A traditional deformable model ("snake" in 2D) fails to find an object's boundary when the strongest nearby image edges are not the ones sought. But models can be trained to respond to other image features instead, by learning their probability distributions. The implementor must then decide on which of many image qualities to teach the model. To this end, we show how to evaluate the efficacy of any resulting deformable model, given a sampling of ground truth, a model of the range of shapes tried during optimization, and a measure of shape closeness. In the domain of abdominal CT images, we demonstrate such evaluation on a simple "sectoring" of a snake in which intensity and perpendicular gradient are observed over equal-length segments. This specific set of qualities shows a measured improvement over an objective function that is uniform around the shape, and it follows naturally from examination of the latter's failures due to image variations around the organ boundary.	CUNY City Coll, Dept Comp Sci, New York, NY 10031 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	City University of New York (CUNY) System; City College of New York (CUNY); Columbia University	Fenster, SD (corresponding author), CUNY City Coll, Dept Comp Sci, New York, NY 10031 USA.	fenster@cs.ccny.cuny.edu; kender@cs.columbia.edu						BALDWIN B, 1997, THESIS COURANT I NEW; BOES JL, 1995, P 1 INT C COMP VIS V, P506; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BOULT TE, 1994, P ARPA IM UND WORKSH; Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755; COOTES TF, 1993, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION : PROCEEDINGS, P242; DAVATZIKOS CA, 1995, IEEE T MED IMAGING, V14, P65, DOI 10.1109/42.370403; Fenster SD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P420, DOI 10.1109/ICCV.1998.710753; Grzeszczuk RP, 1997, IEEE T PATTERN ANAL, V19, P1100, DOI 10.1109/34.625111; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; KERVRANN C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P724, DOI 10.1109/CVPR.1994.323887; LAI KF, 1995, IEEE T PATTERN ANAL, V17, P1084, DOI 10.1109/34.473235; RAMESH V, 1995, THESIS U WASHINGTON; WILLIAMS DJ, 1990, COMPUT VISION GRAPH, V51, P256, DOI 10.1016/0734-189X(90)90003-E	14	19	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2001	23	9					1028	1034		10.1109/34.955115	http://dx.doi.org/10.1109/34.955115			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	470RP					2022-12-18	WOS:000170885200008
J	Worthington, PL; Hancock, ER				Worthington, PL; Hancock, ER			Object recognition using shape-from-shading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape-from-shading; object recognition; shape-index; histograms; constant shape-index maximal patches; graph-matching	SOLID SHAPE; IMAGES; PERCEPTION; SET	This paper investigates whether surface topography information extracted from intensity images using a recently reported shape-from-shading (SFS) algorithm can be used for the purposes of 3D object recognition. We consider how curvature and shape-index information delivered by this algorithm can be used to recognize objects based on their surface topography. We explore two contrasting object recognition strategies. The first of these is based on a low-level attribute summary and uses histograms of curvature and orientation measurements. The second approach is based on the structural arrangement of constant shape-index maximal patches and their associated region attributes. We show that region curvedness and a string ordering of the regions according to size provides recognition accuracy of about 96 percent. By polling various recognition schemes. including a graph matching method. we show that a recognition rate of 98-99 percent is achievable.	Univ Manchester, Dept Computat, Manchester M60 1QD, Lancs, England; Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England	University of Manchester; University of York - UK	Worthington, PL (corresponding author), Univ Manchester, Dept Computat, Manchester M60 1QD, Lancs, England.	plw@co.unist.ac.uk; crh@cs.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				Belhumeur PN, 1996, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.1996.517085; Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150; BRUCKSTEIN AM, 1988, COMPUT VISION GRAPH, V44, P139, DOI 10.1016/S0734-189X(88)80002-1; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1139, DOI 10.1109/34.625116; Dupuis P, 1994, ANN APPL PROBAB, V4, P287, DOI 10.1214/aoap/1177005063; Gimelfarb GL, 1996, PATTERN RECOGN, V29, P1461, DOI 10.1016/0031-3203(96)00011-8; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; Huet B, 1999, IEEE T PATTERN ANAL, V21, P1363, DOI 10.1109/34.817414; Huet B, 1998, PROC CVPR IEEE, P138, DOI 10.1109/CVPR.1998.698600; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; JAIN A, 1993, 3 DIMENSIONAL OBJECT; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; KIMMEL R, 1995, INT J COMPUT VISION, V16, P107, DOI 10.1007/BF01539551; Koenderink J., 1990, SOLID SHAPE; KOENDERINK JJ, 1992, PERCEPT PSYCHOPHYS, V52, P487, DOI 10.3758/BF03206710; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; MINGOLLA E, 1986, BIOL CYBERN, V53, P137, DOI 10.1007/BF00342882; ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; Worthington PL, 2000, PROC CVPR IEEE, P643, DOI 10.1109/CVPR.2000.855880; Worthington PL, 1999, IMAGE VISION COMPUT, V17, P545, DOI 10.1016/S0262-8856(98)00173-5; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; WORTHINGTON PL, 1999, P IEEE INT C COMP VI, V2, P911; WORTHINGTON PL, 2000, P EUR C COMP VIS, P455; WORTHINGTON PL, 1999, THESIS U YORK	28	19	24	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					535	542		10.1109/34.922711	http://dx.doi.org/10.1109/34.922711			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA		Green Accepted, Green Submitted			2022-12-18	WOS:000168641000009
J	Oliensis, J				Oliensis, J			A new structure-from-motion ambiguity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure-from-motion; error sensitivity; ambiguity; bas-relief ambiguity; projective geometry; least-squares error; local minima	3-D MOTION; ALGORITHM; SHAPE	This paper demonstrates the existence of a new. approximate, intrinsic ambiguity in Euclidean structure from motion (SFM) which occurs as generically as the bas-relief ambiguity but, unlike it, strengthens for scenes with more depth variation. The ambiguity does not occur in projective SFM, but the reasons for this make projective reconstructions more likely to have large errors. Our analysis gives a semiquantitative characterization of the least-squares error surface over a domain complementary to that analyzed by Jepson, Heeger, and Maybank. As part of our analysis, we show that the least-squares error for infinitesimal motion-the optical-flow error-gives a good approximation to the least-squares error for moderate finite motions. We propose that many high-error local minima occur for epipoles in or near the image. We also establish the existence of a new local minimum in minimizing over the rotation, given the translation direction.	NEC Res Inst, Princeton, NJ 08540 USA	NEC Corporation	Oliensis, J (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.	oliensis@research.nj.nec.com						ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; Belhumeur PN, 1997, PROC CVPR IEEE, P1060, DOI 10.1109/CVPR.1997.609461; CHIUSO A, 1999, OPTIMAL STRUCTURE MO; DANIILIDIS K, 1993, VISUAL NAVIGATION; Dutta R., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P159, DOI 10.1109/CVPR.1989.37844; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; JEPSON AD, 1990, RBCVTR9036 U TOR; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Kumar R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P365, DOI 10.1109/ICCV.1990.139552; Maybank S., 1992, THEORY RECONSTRUCTIO; MAYBANK SJ, 1987, THESIS U LONDON; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P536, DOI 10.1109/ICCV.1999.791269; Oliensis J, 1999, IEEE T PATTERN ANAL, V21, P665, DOI 10.1109/34.777379; Oliensis J., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P77, DOI 10.1109/WVRS.1995.476855; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P737, DOI 10.1109/ICCV.1999.790295; Oliensis J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P185, DOI 10.1109/CVPR.1999.786937; Oliensis J, 1996, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.1996.517094; Oliensis J, 1998, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1998.698610; Oliensis J, 1999, INT J COMPUT VISION, V34, P163, DOI 10.1023/A:1008139920864; OLIENSIS J, IN PRESS COMUTER VIS; OLIENSIS J, 1996, P EUR C COMP VIS; OLIENSIS J, 1995, NECI TECHNICAL REPOR; PAPATHOMAS T, 1999, SEE THEY TURN FALSE; Soatto S, 1998, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.1998.698621; Soatto S, 1997, INT J COMPUT VISION, V22, P235, DOI 10.1023/A:1007930700152; SOATTO S, 1997, OPTIMAL SUBOPTIMAL S; Srinivasan S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P528, DOI 10.1109/ICCV.1999.791268; SRINIVASAN S, 1998, 893 CAR U MAR; Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211; Tian TY, 1996, PROC CVPR IEEE, P315, DOI 10.1109/CVPR.1996.517091; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tomasi C., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P422, DOI 10.1109/CVPR.1993.341096; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666; Zhang ZY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P772, DOI 10.1109/ICCV.1998.710805; Zhang ZY, 1998, IEEE T PATTERN ANAL, V20, P717, DOI 10.1109/34.689302	38	19	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2000	22	7					685	700		10.1109/34.865186	http://dx.doi.org/10.1109/34.865186			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347LV					2022-12-18	WOS:000088931800004
J	Zunic, J; Sladoje, N				Zunic, J; Sladoje, N			Efficiency of characterizing ellipses and ellipsoids by discrete moments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern analysis; computer vision; digital shapes; coding; parameter estimation	STRAIGHT-LINES; FITS	In this paper, our studies are focused on ellipses and problems related to their representation and reconstruction from the data resulting from their digitization. The main result of the paper is that a finite number of discrete moments, corresponded to digital ellipses, is in one-to-one correspondence with digital ellipses, which enables coding of digital ellipses with an asymptotically optimal amount of memory. In addition, the problem of reconstruction, based on the same parameters, is considered. Since the digitization of real shapes causes an inherent loss of information about the original objects. the precision of the original shape estimation from the corresponding digital data is limited. We derive a sharp upper bound for the errors in reconstruction of the center position and half-axes of the ellipse, in function of the applied picture resolution (i.e., the number of pixels per unit). An extension of these results to the 3D case is also given.	Univ Novi Sad, Fac Engn, YU-21000 Novi Sad, Yugoslavia		Zunic, J (corresponding author), Univ Novi Sad, Fac Engn, Trg D Obradovica 6, YU-21000 Novi Sad, Yugoslavia.	ftn_zunic@uns.ns.ac.yu; sladoje@uns.ns.ac.yu						DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; FISK S, 1986, IEEE T PATTERN ANAL, V8, P554, DOI 10.1109/TPAMI.1986.4767821; HUXLEY MN, 1990, P LOND MATH SOC, V60, P471; IWANIEC H, 1988, J NUMBER THEORY, V29, P60, DOI 10.1016/0022-314X(88)90093-5; KIM CE, 1984, IEEE T PATTERN ANAL, V6, P372, DOI 10.1109/TPAMI.1984.4767531; Klette R, 1996, GRAPH MODEL IM PROC, V58, P295, DOI 10.1006/gmip.1996.0024; KOPLOWITZ J, 1989, IEEE T PATTERN ANAL, V11, P611, DOI 10.1109/34.24795; Kovalevsky V. A., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P31, DOI 10.1109/ICPR.1990.119324; LINDENBAUM M, 1991, IEEE T PATTERN ANAL, V13, P847, DOI 10.1109/34.85678; MELTER RA, 1993, PATTERN RECOGN LETT, V14, P83, DOI 10.1016/0167-8655(93)90080-W; NAKAMURA A, 1984, COMPUT VISION GRAPH, V26, P242, DOI 10.1016/0734-189X(84)90187-7; Sauer P., 1993, Computational Geometry: Theory and Applications, V2, P287, DOI 10.1016/0925-7721(93)90025-2; SLADOJE N, 1997, DISCRETE GEOMETRY CO, V1347, P187; WORRING M, 1995, IEEE T PATTERN ANAL, V17, P587, DOI 10.1109/34.387505; WORRING M, 1995, THESIS U AMSTERDAM	15	19	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					407	414		10.1109/34.845384	http://dx.doi.org/10.1109/34.845384			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500011
J	Sheu, HT; Hu, WC				Sheu, HT; Hu, WC			Multiprimitive segmentation of planar curves - A two-level breakpoint classification and tuning approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiprimitive segmentation; breakpoint classification; tuning; kappa-curvature; projective height; benchmark	NONPARAMETRIC SEGMENTATION; 2-PHASE SCHEME; REPRESENTATIONS; RECOGNITION	A breakpoint classification and tuning approach is proposed for the multiprimitive segmentation of planar curves, and cockhead-like graph is suggested to evaluate the multiprimitive segmentation algorithms. The breakpoints are divided into corners and smooth joints and the types of the segments on both sides of a breakpoint are identified. Then, a joint tuning procedure is exercised to merge/split segments and adjust the joint locations. The carefully designed cockhead-like graph includes all possible combinations and parameters of line and are segments and serves as a benchmark to test the algorithms. The proposed scheme is simple, fast, threshold-free and robust to quantization and preprocessing errors, thus allowing it to be employed in a variety of applications such as matching and recognition. Test against the suggested benchmark and comparison with those in the literature assures the superiority of the method suggested herein.	Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan; Natl Penghu Inst Marine & Management Technol, Dept Comp Sci & Informat Engn, Makung, Penghu, Taiwan	National Taiwan University of Science & Technology	Sheu, HT (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Duda RO, 1973, PATTERN RECOGNITION; Farago F.T., 1982, HDB DIMENSIONAL MEAS; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; Ichoku C, 1996, PATTERN RECOGN LETT, V17, P741, DOI 10.1016/0167-8655(96)00015-3; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P1391, DOI 10.1109/34.643901; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P1393, DOI 10.1109/TPAMI.1997.643902; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8; Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253; Sheu HT, 1996, PATTERN RECOGN, V29, P819, DOI 10.1016/0031-3203(95)00121-2; SHEU HT, 1993, PATTERN RECOGN, V26, P1839, DOI 10.1016/0031-3203(93)90180-5; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; WEST GAW, 1991, PATTERN RECOGN, V24, P643, DOI 10.1016/0031-3203(91)90031-Y; WU QM, 1990, P IEEE COMPUTERS DIG, V137, P319; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	21	19	30	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					791	797		10.1109/34.784310	http://dx.doi.org/10.1109/34.784310			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000012
J	Tian, TY; Shah, M				Tian, TY; Shah, M			Recovering 3D motion of multiple objects using adaptive Hough transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple-motion analysis; segmentation; structure-from-motion; robust estimation; adaptive Hough transform	OPTICAL-FLOW; MOVING-OBJECTS; ALGORITHM	We present a method to determine 3D motion and structure of multiple objects from two perspective views, using adaptive Hough transform. In our method, segmentation is determined based on a 3D rigidity constraint. Instead of searching candidate solutions over the entire five-dimensional translation and rotation parameter space, we only examine the two-dimensional translation space. We divide the input image into overlapping patches, and, for each sample of the translation space, we compute the rotation parameters of patches using least-squares fit. Every patch votes for a sample in the five-dimensional parameter space. For a patch containing multiple motions, we use a redescending M-estimator to compute rotation parameters of a dominant motion within the patch. To reduce computational and storage burdens of standard multidimensional Hough transform, we use adaptive Hough transform to iteratively refine the relevant parameter space in a ''coarse-to-fine'' fashion. Our method can robustly recover 3D motion parameters, reject outliers of the flow estimates, and deal with multiple moving objects present in the scene. Applications of the proposed method to both synthetic and real image sequences are demonstrated with promising results.			Tian, TY (corresponding author), UNIV CENT FLORIDA,DEPT COMP SCI,ORLANDO,FL 32816, USA.			Shah, Mubarak/0000-0001-6172-5572				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AYER S, 1994, ECCV, P316; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; BLACK MJ, 1995, ICCV, P374; BOBER M, 1994, IMAGE VISION COMPUT, V12, P661, DOI 10.1016/0262-8856(94)90041-8; Costeira J., 1995, ICCV, P1071; Gear C. W., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P214, DOI 10.1109/MNRAO.1994.346233; Hampel FR., 2011, WILEY SERIES PROBABI; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HOLLAND P, 1977, COMM STAT THEORETICA, P813; ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964; IRANI M, 1992, ECCV, P282; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; LONGUETHIGGENS HC, 1980, P ROYAL SOC LONDON B, V208; LUMIA R, 1983, COMPUT VISION GRAPH, V22, P287, DOI 10.1016/0734-189X(83)90071-3; MACLEAN WJ, 1994, P 5 BRIT MACH VIS C, P13; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; THOMPSON WB, 1993, IEEE T PATTERN ANAL, V15, P162, DOI 10.1109/34.192488; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tomasi C., 1991, CMUCS91132 CARN MELL; TORR PHS, 1994, ECCV, P328; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779	23	19	23	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1178	1183		10.1109/34.625131	http://dx.doi.org/10.1109/34.625131			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800015
J	Dickinson, SJ; Metaxas, D; Pentland, A				Dickinson, SJ; Metaxas, D; Pentland, A			The role of model-based segmentation in the recovery of volumetric parts from range data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape recovery; range data; volumetric parts; model-based segmentation; object recognition; deformable superquadrics	GLOBAL DEFORMATIONS; CURVED OBJECTS; RECOGNITION; IMAGES; SHAPE; REPRESENTATION; SUPERQUADRICS; FORM	We present a method for segmenting and estimating the shape of 3D objects from range data. The technique uses model views, or aspects, to constrain the fitting of deformable models to range data. Based on an Initial region segmentation of a range image, regions are grouped into aspects corresponding to the volumetric parts that make up an object. The qualitative segmentation of the range image into a set of volumetric parts not only captures the coarse shape of the parts, but qualitatively encodes the orientation of each part through its aspect. Knowledge of a part's coarse shape, its orientation, as well as the mapping between the faces in its aspect and the surfaces on the part provides strong constraints on the fitting of a deformable model (supporting both global and local deformations) to the data. Unlike previous work in physics-based deformable model recovery from range data, the technique does not require presegmented data. Furthermore, occlusion is handled at segmentation time and does not complicate the fitting process, as only 3D points known to belong to a part participate in the fitting of a model to the part. We present the approach in detail and apply it to the recovery of objects from range data.	RUTGERS STATE UNIV,RUTGERS CTR COGNIT SCI,NEW BRUNSWICK,NJ 08903; UNIV PENN,DEPT COMP & INFORMAT SCI,PHILADELPHIA,PA 19104; MIT,MEDIA LAB,VIS & MODELING GRP,CAMBRIDGE,MA 02139	Rutgers State University New Brunswick; University of Pennsylvania; Massachusetts Institute of Technology (MIT)	Dickinson, SJ (corresponding author), RUTGERS STATE UNIV,DEPT COMP SCI,NEW BRUNSWICK,NJ 08903, USA.							AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BINFORD TO, 1971, P IEEE C SYSTEMS CON; DICKINSON S, 1994, P ECCV 94; Dickinson S., 1994, INT J COMPUT VISION, V13, P1; DICKINSON S, 1994, P 2 INT WORKSH VIS F; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; Flynn P., 1990, THESIS; GUPTA A, 1991, MSCIS9145 U PENNS DE; GUPTA A, 1992, P 11 IAPR INT C PATT, P1528; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; LEONARDIS A, 1994, LECT NOTES COMPUTER, V800, P309; LI M, 1992, CVAP114 ROYAL I TECH; Metaxas D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P337, DOI 10.1109/CVPR.1991.139712; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; METAZAS D, 1992, THESIS U TORONTO; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; RAJA NS, 1994, CVGIP-IMAG UNDERSTAN, V60, P44, DOI 10.1006/ciun.1994.1030; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; ULUPINAR F, 1993, IEEE T PATTERN ANAL, V15, P3, DOI 10.1109/34.184771; WU K, 1994, P IEEE C COMP VIS PA, P159; ZERROUG M, 1994, LECT NOTES COMPUTER, V800, P319	29	19	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					259	267		10.1109/34.584104	http://dx.doi.org/10.1109/34.584104			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582		Green Submitted			2022-12-18	WOS:A1997WR58200008
J	Zhang, ZF; Weiss, R; Hanson, AR				Zhang, ZF; Weiss, R; Hanson, AR			Obstacle detection based on qualitative and quantitative 3D reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis and stereo; qualitative vision; obstacle detection; 3D reconstruction; partial calibration		Three different algorithms for obstacle detection are presented in this paper each based on different assumptions. The first two algorithms are qualitative in that they return only yes/no answers regarding the presence of obstacles in the field of view; no 3D reconstruction is performed. They have the advantage of fast determination of the existence of obstacles in a scene based on the solvability of a linear system. The first algorithm uses information about the ground plane, while the second only assumes that the ground is planar. The third algorithm is quantitative in that it continuously estimates the ground plane and reconstructs partial 3D structures by determining the height above the ground plane of each point in the scene. Experimental results are presented for real and simulated data, and the performance of the three algorithms under different noise levels is compared in simulation. We conclude that in terms of the robustness of performance, the third algorithm is superior to the other two.	UNIV MASSACHUSETTS, DEPT COMP SCI, AMHERST, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Zhang, ZF (corresponding author), SUNY BUFFALO, CTR EXCELLENCE DOCUMENT ANAL & RECOGNIT, BUFFALO, NY 14228 USA.							ANANDAN P, 1989, INT J COMPUTER VISIO, V2; BADAL S, 1994, P 2 IEEE WORKSH APPL; DAILY MJ, 1987, P IUW M KAUFM; DAILY MJ, 1988, P IUW M KAUFM; ENKELMANN W, 1990, P 1 ECCV; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; FAUGERAS OD, 1988, INT J PATTERN RECOGN, V2, P458; FAUGERAS OD, 1992, P EUR C COMP VIS, P321; Golub G. H., 1996, MATRIX COMPUTATIONS; Grandjean P., 1993, Proceedings IEEE International Conference on Robotics and Automation (Cat. No.93CH3247-4), P20, DOI 10.1109/ROBOT.1993.292118; HANSON AR, 1993, P IUW M KAUFM APR, P39; HARTLEY RI, 1992, P CVPR; KUMAR R, 1992, THESIS U MASSACHUSET; MATTHIES LH, 1993, P CVPR JUN; MATTHIES LH, 1992, P CVPR JUN; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MOHR R, 1993, P CVPR; NELSON RC, 1989, T PATTERN ANAL MACHI, V11; PONCE J, 1993, AIRCV9307 TR U ILL; SHASHUA A, 1993, P ICCV; SOLDER U, 1990, SPIE MOBILE ROBOTS, V5, P1388; STORJOHANN K, 1990, P ICRA; YOUNG GS, 1992, SAE INTELLIGENT VEHI; ZHANG Z, 1996, 9608 CMPSCI U MASS; ZHANG Z, 1994, P CVPR; ZHENG Q, 1993, P ICCV	26	19	24	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					15	26		10.1109/34.566807	http://dx.doi.org/10.1109/34.566807			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800002
J	Taubin, G; Ronfard, R				Taubin, G; Ronfard, R			Implicit simplicial models for adaptive curve reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve fitting; topology estimation; shape recovery; geometric modeling		Parametric deformable models have been extensively and very successfully used for reconstructing free-form curves and surfaces, and for tracking nonrigid deformations, but they require previous knowledge of the topological type of the data, and good initial curve or surface estimates. With deformable models, it is also computationally expensive to check for and to prevent self-intersections while tracking deformations. The Implicit Simplicial Models that we introduce in this paper are implicit curves and surfaces defined by piece-wise linear functions. This representation allows for local deformations, control of the topological type, and prevention of self-intersections during deformations. As a first application, we also describe in this paper an algorithm for two-dimensional curve reconstruction from unorganized sets of data points. The topology, the number of connected components, and the geometry of the data are all estimated using an adaptive space subdivision approach. The main four components of the algorithm are topology estimation, curve fitting, adaptive space subdivision, and mesh relaxation.	INST NATL AUDIOVISUEL, F-94366 BRY SUR MARNE, FRANCE		Taubin, G (corresponding author), IBM CORP, THOMAS J WATSON RES CTR, POB 704, YORKTOWN HTS, NY 10598 USA.		Ronfard, Rémi P/AAW-6761-2021	Ronfard, Rémi P/0000-0003-4830-5690; Taubin, Gabriel/0000-0002-1983-7607				Farin G., 1988, CURVES SURFACES COMP; HALL M, 1990, IEEE COMPUT GRAPH, V10, P33, DOI 10.1109/38.62694; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; METAXAS D, 1992, COMP GRAPH, V26, P309, DOI 10.1145/142920.134085; MOORE D, 1990, TR90135 COMP RIC U D; SZELISKI R, 1992, COMP GRAPH, V26, P185, DOI 10.1145/142920.134037; Taubin G., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P658, DOI 10.1109/ICCV.1993.378149; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Taubin G., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P644, DOI 10.1109/ROBOT.1988.12129; Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877; TINDLE GL, 1987, MATH SURFACES, V2, P387	14	19	32	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					321	325		10.1109/34.485559	http://dx.doi.org/10.1109/34.485559			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500008
J	POVLOW, BR; DUNN, SM				POVLOW, BR; DUNN, SM			TEXTURE CLASSIFICATION USING NONCAUSAL HIDDEN MARKOV-MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						TEXTURE; TEXTURE CLASSIFICATION; TEXTURE MODELING; HIDDEN MARKOV MODEL; NONCAUSAL HIDDEN MARKOV MODEL; COMPUTER VISION; LEARNING	STATISTICAL-ANALYSIS	This paper addresses the problem of using noncausal hidden Markov models (HMMs) for texture classification, In noncausal models, the state of each pixel may be dependent on its neighbors in all directions, New algorithms are given to learn the parameters of a noncausal HMM of a texture and to classify it into one of several learned categories, Texture classification results using these algorithms are provided.	RUTGERS STATE UNIV,DEPT BIOMED ENGN,PISCATAWAY,NJ 08855	Rutgers State University New Brunswick	POVLOW, BR (corresponding author), LOCKHEED MARTIN ASTRO SPACE,MS 410-2C19,POB 800,PRINCETON,NJ 08543, USA.							ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; Brodatz P., 1966, TEXTURES; CHELLAPA R, 1985, IEEE T SYST MAN CYB, V165, P298; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DEVIJVER PA, 1988, 4TH INT C PATT REC C, P131; HALL TE, 1992, COMMUNICATION; RAO AR, 1990, IBM RC15465 RES REP; TSATSANIS MK, 1992, IEEE T PATTERN ANAL, V14, P733, DOI 10.1109/34.142910	11	19	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1995	17	10					1010	1014		10.1109/34.464564	http://dx.doi.org/10.1109/34.464564			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RX289					2022-12-18	WOS:A1995RX28900007
J	SCHONFELD, D				SCHONFELD, D			OPTIMAL STRUCTURING ELEMENTS FOR THE MORPHOLOGICAL PATTERN RESTORATION OF BINARY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MATHEMATICAL MORPHOLOGY; NONLINER FILTERING; PATTERN RESTORATION; RANDOM SET THEORY	MATHEMATICAL MORPHOLOGY; FILTERS	In this paper, we derive the optimal structuring elements of morphological filters in image restoration. The expected pattern transformation of random sets is presented. An estimation theory framework for random sets is subsequently proposed. This framework is based on the least mean difference (LMD) estimator. The least mean difference (LMD) estimator is defined to minimize the cardinality of the expected pattern transformation of the set-difference of the parameter and the estimate. Several important results for the determination of the least mean difference (LMD) estimator are derived. The least mean difference (LMD) structuring elements of morphological filters in image restoration are finally derived.			SCHONFELD, D (corresponding author), UNIV ILLINOIS,DEPT ELECT ENGN & COMP SCI,SIGNAL & IMAGE RES LAB,CHICAGO,IL 60680, USA.							ARTSTEIN Z, 1975, ANN PROBAB, V3, P879, DOI 10.1214/aop/1176996275; CHARIFCHEFCHAOU.M, IN PRESS IEEE T IMAG; CHARIFCHEFCHAOU.M, 1993, 4 P SPIE WORKSHOP IM, V2030, P24; DOUGHERTY ER, 1992, CVGIP-IMAG UNDERSTAN, V55, P55, DOI 10.1016/1049-9660(92)90006-O; DOUGHERTY ER, 1992, CVGIP-IMAG UNDERSTAN, V55, P36, DOI 10.1016/1049-9660(92)90005-N; Giardina C., 1988, MORPHOLOGICAL METHOD; Goutsias J., 1992, Journal of Mathematical Imaging and Vision, V2, P193, DOI 10.1007/BF00118590; GOUTSIAS J, 1993, MATH MORPHOLOGY THEO; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HUANG TS, 1981, 2 DIMENSIONAL DIGITA, V2; KISACANIN B, IN PRESS IEEE T IMAG; LOCE RP, 1992, OPT ENG, V31, P1008, DOI 10.1117/12.56144; LOUGHEED R, 1983, LECTURE NOTES SUMMER; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1170, DOI 10.1109/TASSP.1987.1165254; MATHERON G., 1975, RANDOM SETS INTEGRAL; Papoulis A., 1991, COMMUNICATIONS SIGNA, V3; SCHONFELD D, 1991, IEEE T PATTERN ANAL, V13, P14, DOI 10.1109/34.67627; Schonfeld D., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P579, DOI 10.1109/CVPR.1992.223132; SCHONFELD D, 1990, THESIS J HOPKIN U DE; SCHONFELD D, 1991, UICEECS9112 U ILL DE; SERRA J, 1980, COMPUT VISION GRAPH, V12, P99, DOI 10.1016/0146-664X(80)90006-4; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; SERRA J, 1989, LECTURE NOTES MORPHO; Serra J, 1988, IMAGE ANAL MATH MORP; SIDIROPOULOS ND, 1992, THESIS U MARYLAND; Stoyan D., 1987, STOCHASTIC GEOMETRY; VITALE RA, 1988, J MICROSC-OXFORD, V151, P197, DOI 10.1111/j.1365-2818.1988.tb04680.x; ZHOU Z, 1988, P INT C ACOUST SPEEC, V2, P948	30	19	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					589	601		10.1109/34.295904	http://dx.doi.org/10.1109/34.295904			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200004
J	KATZIR, N; LINDENBAUM, M; PORAT, M				KATZIR, N; LINDENBAUM, M; PORAT, M			CURVE SEGMENTATION UNDER PARTIAL OCCLUSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter							CURVATURE	2-D shape boundary segmentation is required as a fundamental and important stage in the recognition of partially occluded objects. We introduce here a new segmentation method capable of extracting a controlled number of segments along a smooth boundary curve. This new approach is invariant to similarity transformation, and partial occlusion has only marginal influence on the segmentation of the visible part. The basic concept is to transform the curve into another one which intersects itself. Points or intersection of the new curve are re-transformed to the original curve and serve as endpoints of segments. Properties of the transform are discussed, and conditions for existence of intersection points are given. Simulation results of gray level images are presented, and advantages of our method over conventional approaches relying on singular points of the curvature-are discussed.	TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL	Technion Israel Institute of Technology	KATZIR, N (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL.		Rohlf, F J/A-8710-2008					ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BENTLEY JL, 1979, IEEE T COMPUT, V28, P643, DOI 10.1109/TC.1979.1675432; Chazelle B., 1988, 29th Annual Symposium on Foundations of Computer Science (IEEE Cat. No.88CH2652-6), P590, DOI 10.1109/SFCS.1988.21975; DEGUCHI K, 1988, P INT C PATTERN  ITA, P1113; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Faux ID, 1979, COMPUTATIONAL GEOMET; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GORMAN JW, 1988, IEEE T PATTERN ANAL, V10, P257, DOI 10.1109/34.3887; HOFFMAN DD, 1982, P AAAI, P5; HONG J, 1988, NOV P ICPR ROM, P72; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KATZIR N, 1992, FAST INTERSECTION FI; KATZIR N, 1989, EEPUB730; LAMDAN Y, 1988, APR P IEEE INT C ROB, P1407; MILIOS EE, 1989, COMPUT VISION GRAPH, V47, P203, DOI 10.1016/S0734-189X(89)80007-6; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; OGORMAN L, 1988, P 9 INT C PATT REC, P1116; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; Stoker JJ, 1969, DIFFERENTIAL GEOMETR; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; [No title captured]	24	19	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					513	519		10.1109/34.291446	http://dx.doi.org/10.1109/34.291446			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100007
J	ZHANG, SJ; SULLIVAN, GD; BAKER, KD				ZHANG, SJ; SULLIVAN, GD; BAKER, KD			THE AUTOMATIC CONSTRUCTION OF A VIEW-INDEPENDENT RELATIONAL MODEL FOR 3-D OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						GEOMETRICAL REASONING; MODEL-BASED VISION; MODEL CONSTRUCTION; OBJECT RECOGNITION; RELATIONAL MODELS	TWO-DIMENSIONAL IMAGES; ROBOT VISION; COMPUTER VISION; REPRESENTATION; SYSTEM; SHAPE	This paper describes and demonstrates a view-independent relational model (VIRM) in a vision system designed for recognizing known 3-D objects from single monochromatic images of unknown scenes. The aim is to establish a model of an object, based on a CAD description, which is suitable for its recognition without invoking pose information. We show how the system can generate a VIRM automatically by a ''viewing and reasoning'' process. The system inspects the CAD model from a number of different viewpoints, and a statistical inference is applied to identify relatively view-independent relationships among component parts of the object. These relations are stored as a relational model of the object, which is represented in the form of a hypergraph. Three-dimensional component parts (model features) of the object, which can be associated with extended image features obtained by grouping of primitive 2-D features, are represented as nodes of the hypergraph. Covisibility of model features is represented by means of hyperedges of the hypergraph, and the pairwise view-independent relations form procedural constraints associated with the hypergraph edges. During the recognition phase, the covisibility measures allow a best-first search of the graph for acceptable matches.	UNIV READING,DEPT COMP SCI,READING RG6 2AH,BERKS,ENGLAND; UNIV READING,INTELLIGENT SYST RES GRP,READING RG6 2AH,BERKS,ENGLAND	University of Reading; University of Reading	ZHANG, SJ (corresponding author), UNIV BRISTOL,ADV COMP RES CTR,BRISTOL BS8 1TH,AVON,ENGLAND.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Baird H., 1984, MODEL BASED IMAGE MA; BAKER KD, 1992, NOV P IEEE WORKSH AP; Berge C., 1973, GRAPH AND HYPERGRAPH; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; BHANU B, 1987, COMPUTER, V20, P13; BHANU B, 1987, COMPUTER, V20, P19, DOI 10.1109/MC.1987.1663657; BINFORD T, 1982, INT J ROBOTICS RES, V1; BOLLES RC, 1986, INT J ROBOTICS RES, V5; BRAY AJ, 1990, THESIS U SUSSEX; BRISDON KS, 1988, 4TH P ALV VIS C MANC; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; CANNY JF, 1986, IEEE T PATTERN ANAL, V8, P179; CHEN CH, 1989, IEEE T SYST MAN CYB, V19, P1535, DOI 10.1109/21.44070; CHIEN CH, 1989, IEEE T PATTERN ANAL, V11, P372, DOI 10.1109/34.19034; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; Dickinson S. J., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P257, DOI 10.1109/ICCV.1990.139528; DRAPER BA, 1991, P IEEE CVPR91 HAWAII, P320; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; Floriani L. D., 1989, IEEE T PATTERN ANAL, V11, P785; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12, P113, DOI 10.1109/34.44399; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; IKEUCHI K, 1987, INT J COMPUT VISION, V1; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN UL, 1989, P IEEE WORKSHOP INTE, P116; Kuno Y., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P626, DOI 10.1109/ICCV.1990.139608; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MAREFAT M, 1990, IEEE T PATTERN ANAL, V12, P949, DOI 10.1109/34.58868; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; NIEMANN H, 1990, IEEE T PATTERN ANAL, V12, P883, DOI 10.1109/34.57683; SRIPRADISVARAKU.T, 1989, NOV P IEEE WORKSH IN, P109; SULLIVAN GD, 1992, PHILOS T ROY SOC B, V337, P361, DOI 10.1098/rstb.1992.0114; WONG AKC, 1990, IEEE T PATTERN ANAL, V11, P279; WORRALL AD, 1988, 4TH P ALV VIS C MANC; ZHANG S, 1990, P BRIT MACHINE VISII; [No title captured]; [No title captured]	43	19	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					531	544		10.1109/34.216723	http://dx.doi.org/10.1109/34.216723			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700002
J	STEVENSON, RL; DELP, EJ				STEVENSON, RL; DELP, EJ			VIEWPOINT INVARIANT RECOVERY OF VISUAL SURFACES FROM SPARSE DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; ILL-POSED INVERSE PROBLEMS; SURFACE RECONSTRUCTION	COMPUTATIONAL VISION; RECONSTRUCTION; REGULARIZATION; DISCONTINUITIES	This paper proposes a new algorithm for the reconstruction of visual surfaces from sparse data. An important aspect of this new algorithm is that the surface estimated from the sparse data is approximately invariant with respect to rigid transformation of the surface in 3-D space. The algorithm is based on casting the problem as an ill-posed inverse problem that must be stablized using a priori information related to the image and constraint formation. To form a surface estimate that is approximately invariant with respect to viewpoint, the stablizing information is based on invariant surface characteristics. With appropriate approximations, this results in a convex functional to minimize, which is then solved using finite element analysis. The relationship of this algorithm to several previously proposed reconstruction algorithms is discussed, and several examples that demonstrate the effectiveness of the proposed algorithm in reconstructing viewpoint invariant surface estimates are given.	PURDUE UNIV,SCH ELECT ENGN,COMP VIS & IMAGE PROC LAB,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	STEVENSON, RL (corresponding author), UNIV NOTRE DAME,DEPT ELECT ENGN,NOTRE DAME,IN 46556, USA.		Delp, Edward J/C-3616-2013	Delp, Edward J/0000-0002-2909-7323				Allen P. K, 1985, OBJECT RECOGNITION U, DOI [10.7916/D8668N6J, DOI 10.7916/D8668N6J]; BACHMAN G, 1966, FUNCTIONAL ANAL; BESL P, 1986, JUN P IEEE C COMP VI, P77; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; BLAKE A, 1989, IEEE T PATTERN ANAL, V11, P2, DOI 10.1109/34.23109; BLAKE A, 1986, 1986 P CVPR MIAM, P62; BOULT TE, 1986, 1986 P IEEE COMP VIS, P68; CHU CC, 1988, PATTERN RECOGN, V21, P303, DOI 10.1016/0031-3203(88)90043-X; CLINE AK, 1984, ROCKY MT J MATH, V14, P119, DOI 10.1216/RMJ-1984-14-1-119; COURANT R, 1953, METHODS MATH PHYSICS, V1; DAVIS L, 1987, GENETIC ALGORITHMS S; Duchon Jean, 1976, CONSTRUCTIVE THEORY, V571, P4; FAN T, 1986, JUN P IEEE C COMP VI, P86; Faux ID, 1979, COMPUTATIONAL GEOMET; FERRIE FP, 1989, NOV P WORKSH INT 3D, P170; GRIMSON WEL, 1981, IMAGES SURFACES; Guggenheimer H., 1977, DIFFERENTIAL GEOMETR; HARRIS JG, 1987, 1ST P INT C COMP VIS, P277; JOU J, 1988, 1988 P IEEE C COMP V, P138; JOU JY, 1989, COMPUT VISION GRAPH, V47, P292, DOI 10.1016/0734-189X(89)90115-1; JULESZ B, 1960, AT&T TECH J, V39, P1125, DOI 10.1002/j.1538-7305.1960.tb03954.x; KENDER JR, 1985, 3RD P WORKSH COMP VI, P157; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LEE D, 1988, IEEE T PATTERN ANAL, V10, P822, DOI 10.1109/34.9105; Lipschutz M., 1969, DIFFERENTIAL GEOMETR; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MAYHEW J, 1982, PERCEPTION, V11, P387, DOI 10.1068/p110387; Meinguet J., 1979, J APPL MATH PHYS, V30, P292; PARENT P, 1985, J OPT SOC AM A, V2, P5; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; RENKA RJ, 1982, ORNLCSD101 TECH REP; Sander P. T., 1988, THESIS MCGILL U MONT; SANDER PT, IN PRESS IEEE T PATT; SINHA SS, 1989, 1989 P IEEE C COMP V, P229; STEVENSON R, 1989, NOV P IEEE WORKSH IN, P131; STEVENSON RL, 1990, J OPT SOC AM A   MAR; SZELISKI R, 1989, JUN C COMP VIS PATT, P222; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Terzopoulos Demetri, 1984, MULTIRESOLUTION IMAG, P237; Tikhonov A., 1977, SOLUTIONS ILL POSED; Tikhonov A.N., 1987, ILL POSED PROBLEMS N; WAHBA G, 1980, APPROXIMATION THEORY, V3, P905; WAHBA G, 1987, INVERSE ILL POSED PR, V4, P37; WAHBA G, 1985, ADV REMOTE SENSING R, P385	47	19	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1992	14	9					897	909		10.1109/34.161349	http://dx.doi.org/10.1109/34.161349			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JL924					2022-12-18	WOS:A1992JL92400003
J	HOLMES, PD; JUNGERT, ERA				HOLMES, PD; JUNGERT, ERA			SYMBOLIC AND GEOMETRIC CONNECTIVITY GRAPH METHODS FOR ROUTE PLANNING IN DIGITIZED MAPS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER GEOMETRY; CONNECTIVITY GRAPH; DIGITIZED MAPS; KNOWLEDGE-BASED METHODS; PATH PLANNING; ROUTE PLANNING; SPATIAL REASONING	SIMPLE POLYGONS; VISIBILITY; TIME	This paper describes the results of a first phase of research involving spatial reasoning within digitized maps. This work focuses on techniques for 2-D route planning in the presence of obstacles. Two alternative approaches to route planning shall be discussed in this work: one involving heuristic, symbolic processing and the other employing geometric calculations. Both techniques employ A* search over a connectivity graph-a graph generated by abstracting the original map information. The type of output produced by each system is quite different. The geometric system produces a simple list of coordinate positions, whereas the symbolic system generates a symbolic description of the planned route. The symbolic system achieves this capability through the use of inference rules that can analyze and classify spatial relationships within the connectivity graph. The geometric method, on the other hand, calculates an exact path from the connectivity information in the graph. In other words, the connectivity graph acts both as a knowledge structure on which spatial reasoning may be performed and as a data structure supporting geometrical calculations. This paper also describes an extension of the methodology that exploits a hierarchical data structure; here, the hierarchy reflects different levels of map resolution.			HOLMES, PD (corresponding author), NATL DEF RES ESTAB,COMP SCI RES,LINKOPING,SWEDEN.							ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923; CHANG SK, 1990, VISUAL LANGUAGES APP, P277; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; DORST L, 1986, SIGNAL PROCESSING, V3; FOURNIER A, 1984, ACM T GRAPHIC, V3, P153, DOI 10.1145/357337.357341; GAREY MR, 1978, INFORM PROCESS LETT, V7, P175, DOI 10.1016/0020-0190(78)90062-5; GUIBAS L, 1987, ALGORITHMICA, V2, P209, DOI 10.1007/BF01840360; Hertel S., 1983, P C F COMPUTING THEO, P207; Holmes P. D., 1991, Journal of Visual Languages and Computing, V2, P143, DOI 10.1016/S1045-926X(05)80027-8; HOLMES PD, 1988, SENSOR FUSION SPATIA, V1003, P495; HOLMES PD, 1988, 3RD P INT C ENG GRAP, V1, P238; HUANG YY, 1986, MOBILE ROBOTS, V727, P344; JUNGERT E, 1988, OCT P IEEE WORKSH VI, P248; JUNGERT E, 1990, UST P EUR C GEOGR IN, P526; JUNGERT E, 1989, VISUAL DATABASE SYST; JUNGERT E, COMPUT VISION GRAPHI; JUNGERT E, 1986, AUG P IEEE WORKSH LA, P66; JUNGERT E, 1989, 2ND P INT C INT AUT, P230; JUNGERT E, 1989, OCT P IEEE WORKSH VI, P157; JUNGERT E, 1988, PATTERN RECOGNITION; KAMBHAMPATI S, 1986, IEEE J ROBOT AUTOM, V2, P135, DOI 10.1109/JRA.1986.1087051; LEE DT, 1984, NETWORKS, V14, P393, DOI 10.1002/net.3230140304; LOZANOPEREZ T, 1981, IEEE T SYST MAN CYB, V11, P681, DOI 10.1109/TSMC.1981.4308589; MENG ACC, IN PRESS ADV SPATIAL; MEYSTEL A, 1986 P IEEE INT C RO, V3, P1678; MITCHELL JSB, 1987, INT J INTELL SYST, V2, P129, DOI 10.1002/int.4550020204; NILSSON NJ, 1979, PRINCIPLES ARTIFICIA; O'Rourke J., 1987, ART GALLERY THEOREMS; ODUNLAING C, 1986, COMMUN PUR APPL MATH, V39, P423, DOI 10.1002/cpa.3160390402; OVERMARS MH, 1987, CONSTRUCTION SPARSE; Pearl J., 1984, INTELLIGENT SEARCH S; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; SHARIR M, 1989, COMPUTER, V22, P9, DOI 10.1109/2.16221; SLACK MG, 1988, SENSOR FUSION SPATIA, V1003, P350; TARJAN RE, 1988, SIAM J COMPUT, V17, P143, DOI 10.1137/0217010; TOUSSAINT GT, 1986, DEC P INT C INT AUT, P590; WELZL E, 1985, INFORM PROCESS LETT, V20, P167, DOI 10.1016/0020-0190(85)90044-4; [No title captured], DOI DOI 10.1145/356924.356930	39	19	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1992	14	5					549	565		10.1109/34.134059	http://dx.doi.org/10.1109/34.134059			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HR650					2022-12-18	WOS:A1992HR65000004
J	SANDER, PT; ZUCKER, SW				SANDER, PT; ZUCKER, SW			SINGULARITIES OF PRINCIPAL DIRECTION FIELDS FROM 3-D IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTATIONAL VISION; DIFFERENTIAL GEOMETRY; DIRECTION FIELD INDEX; GENERIC SINGULARITIES; PRINCIPAL CURVATURE AND DIRECTION FIELDS; 3-D IMAGE ANALYSIS; UMBILIC POINTS	OBJECTS	Generic singularities can provide position-independent information about the qualitative shape of surfaces. We determine the singularities of the principal direction fields of a surface (its umbilic points) from a computation of the index of the fields. We present examples both for 3-D synthetic images to which noise has been added and for clinical magnetic resonance (MR) images.	INST NATL RECH INFORMAT & AUTOMAT, UNITE RECH SOPHIA ANTIPOLIS, VALBONNE, FRANCE; MCGILL UNIV, MCGILL RES CTR INTELLIGENT MACHINES, MONTREAL H3A 2A7, QUEBEC, CANADA	McGill University								BERRY MV, 1977, J PHYS A-MATH GEN, V10, P1809, DOI 10.1088/0305-4470/10/11/009; BESL P, 1985, JUN IEEE P COMP VIS, P226; BRADY M, 1986, 2ND P INT S ROB RES, P5; DARBOUX G, 1896, LECONS THEORIE GENER; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Guillemin V., 2010, DIFFERENTIAL TOPOLOG; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; Hilbert D., 1952, GEOMETRY IMAGINATION; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; KOENDERINK JJ, 1984, SENSORY EXPERIENCE A; MAXWELL JC, 1870, LONDON EDINBURGH DEC, P421; NACKMAN LR, 1984, IEEE T PATTERN ANAL, V6, P442, DOI 10.1109/TPAMI.1984.4767549; SANDER PT, 1990, IEEE T PATTERN ANAL, V12, P833, DOI 10.1109/34.57680; SANDER PT, 1988, THESIS MCGILL U; SANDER PT, CIM881 MCGILL U MCGI; ZUCKER SW, 1987, ANNU REV COMPUT SCI, V2, P69, DOI 10.1146/annurev.cs.02.060187.000441	18	19	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1992	14	3					309	317		10.1109/34.120326	http://dx.doi.org/10.1109/34.120326			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HF732					2022-12-18	WOS:A1992HF73200001
J	BOBICK, AF; BOLLES, RC				BOBICK, AF; BOLLES, RC			THE REPRESENTATION SPACE PARADIGM OF CONCURRENT EVOLVING OBJECT DESCRIPTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTONOMOUS NAVIGATION; OBJECT REPRESENTATION; SCALE SPACE	ORGANIZATION	A representation paradigm for instantiating and refining multiple, concurrent descriptions of an object from a sequence of imagery is presented. This paradigm is designed to be used by the perception system of an autonomous robot that 1) needs to describe many types of objects, 2) initially detects objects at a distance and gradually acquires higher resolution data, and 3) continuously collects sensory input. We argue that multiple, concurrent descriptions of an object are necessary because different perceptual tasks are best performed using different representations and because different types of descriptions require different quality data to support their computation. Since the data change significantly over time, the paradigm supports the evolution of descriptions, progressing from crude 2-D "blob" descriptions to complete semantic models, such as bush, rock, and tree. To control this accumulation of new descriptions, we introduce the idea of representation space. Representation space is a lattice of representations that specifies the order in which they should be considered for describing an object. Each of the representations in the lattice is associated with an object only after the object has been described multiple times in the representation and the parameters of the representation have been judged to be "stable." We define stability in a statistical sense, enhanced by a set of explanations describing valid reasons for deviations from expected measurements. These explanations may draw on many types of knowledge, including the physics of the sensor, the performance of the segmentation procedure, and the reliability of the matching technique. To illustrate the power of these ideas, we have implemented a system, which we call TraX, that constructs and refines models of outdoor objects detected in sequences of range data.	SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025	SRI International								AYACHE N, 1987, P INT S ROBOTICS RES; BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CROWLEY JL, 1989, MAY P IEEE INT C ROB, P674; Duda R.O., 1973, J ROYAL STAT SOC SER; FISCHLER MA, 8TH P IJACI KARLSRUH, P1014; HANSON A, 1987, ADV COMPUTER VISION; JAIN RC, 1991, CVGIP-IMAG UNDERSTAN, V53, P112, DOI 10.1016/1049-9660(91)90009-E; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MATTHIES LH, 1987, P INT S ROBOTICS RES; NISHIHARA HK, 1981, J ARTIFICIAL INTELL, V17, P265; OSHIMA M, 1978, PATTERN RECOGN, V11, P9; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; PENTLAND AP, 1986, SRI406 TECH REP; PENTLAND AP, 1988, P SDF BENCHMARK S RO; POPPLESTONE RJ, 1975, 4TH P INT JOINT C AR, P664; SMITH R, 1987, P INT S ROBOTICS RES; WITKIN A, 1983, 8TH P IJCAI KARLSR, P1017; [No title captured]	19	19	20	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					146	156		10.1109/34.121786	http://dx.doi.org/10.1109/34.121786			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900005
J	SAUND, E				SAUND, E			SYMBOLIC CONSTRUCTION OF A 2-D SCALE-SPACE IMAGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SAUND, E (corresponding author), XEROX CORP,PALO ALTO RES CTR,PALO ALTO,CA 94304, USA.							ANDERSON JR, 1978, PSYCHOL REV, V85, P249, DOI 10.1037/0033-295X.85.4.249; [Anonymous], 1983, AUDUBON SOC FIELD GU; ASADA H, 1984, IEEE T PAMI, V8, P2; BOLDT M, 1984, COINS87104 U MASS TE; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CONNELL J, 1985, MIT TR853 AI LAB; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; CROWLEY JL, 1987, IEEE T PATTERN ANAL, V9, P113, DOI 10.1109/TPAMI.1987.4767876; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; FLECK M, 1985, MIT TR852 AI LAB; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; KOSSLYN SM, 1979, BEHAV BRAIN SCI, V2, P535, DOI 10.1017/S0140525X00064268; MACKWORTH A, 1988, P IEEE C CVPR; MAHONEY J, 1987, MIT TR980 AI LAB; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PARENT P, 1985, CIM863 MCGILL U; PIZER SM, 1986, INFORMATION PROCESSI, P24; PYLYSHYN ZW, 1973, PSYCHOL BULL, V80, P1, DOI 10.1037/h0034650; PYLYSHYN ZW, 1981, IMAGERY; RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483; SAMET H, 1980, 5TH P INT C PATT REC, P815; SAUND E, 1988, MIT TR1092 CAMBR; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; ULLMAN S, 1983, COGNITION, V8, P97; VOORHEES H, 1987, MIT TR968 AI LAB; WALTERS DKW, 1987, 9 ANN C COGN SCI SOC, P455; Weiss R., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P489; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019	35	19	25	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1990	12	8					817	830		10.1109/34.57672	http://dx.doi.org/10.1109/34.57672			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DQ388		Green Submitted			2022-12-18	WOS:A1990DQ38800008
J	SCHMIDT, WAC				SCHMIDT, WAC			MODIFIED MATCHED-FILTER FOR CLOUD CLUTTER SUPPRESSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SCHMIDT, WAC (corresponding author), USN,DEPT MISSION AVION TECHNOL,WARMINSTER,PA 18974, USA.							DUDA RO, 1973, PATTERN CLASSIFICATI, P276; LONGMIRE MS, 1982, APPL OPTICS, V21, P3819, DOI 10.1364/AO.21.003819; NORTH DO, 1943, PTR6C RCA LABS REP; STARK H, 1979, MODERN ELECTRICAL CO, P488; VANVLECK JH, 1946, J APPL PHYS, V17, P940	5	19	21	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					594	600		10.1109/34.56196	http://dx.doi.org/10.1109/34.56196			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003		Green Submitted			2022-12-18	WOS:A1990DE00300009
J	OLAFSSON, S; ABUMOSTAFA, YS				OLAFSSON, S; ABUMOSTAFA, YS			THE CAPACITY OF MULTILEVEL THRESHOLD FUNCTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CALTECH,DEPT ELECT ENGN,PASADENA,CA 91125	California Institute of Technology								ABUMOSTAFA YS, 1985, IEEE T INFORM THEORY, V31, P461, DOI 10.1109/TIT.1985.1057069; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Haring D., 1965, IEEE T ELECT COMPUT, V15, P45; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; KRUEGER FR, 1986, IEEE T PATTERN ANAL, V8, P760, DOI 10.1109/TPAMI.1986.4767858; Minsky M., 1969, PERCEPTRONS; MUROGA S, 1965, IEEE TRANS ELECTRON, VEC14, P136, DOI 10.1109/PGEC.1965.263958; OLAFSSON S, IN PRESS TRANSPOSITI; PEARL J, 1979, IEEE T PATTERN ANAL, V1, P350, DOI 10.1109/TPAMI.1979.4766943; TAKIYAMA R, 1978, PATTERN RECOGN, V10, P27, DOI 10.1016/0031-3203(78)90045-6; TAKIYAMA R, 1985, IEEE T PATTERN ANAL, V7, P112, DOI 10.1109/TPAMI.1985.4767626	11	19	20	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					277	281		10.1109/34.3890	http://dx.doi.org/10.1109/34.3890			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974		Green Accepted			2022-12-18	WOS:A1988M297400012
J	SHU, DB; LI, CC; MANCUSO, JF; SUN, YN				SHU, DB; LI, CC; MANCUSO, JF; SUN, YN			A LINE EXTRACTION METHOD FOR AUTOMATED SEM INSPECTION OF VLSI RESIST	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15261; WESTINGHOUSE RES & DEV CTR,DIV MAT SCI,PITTSBURGH,PA 15235	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Paramount Global								Arunkumar S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1352; BAIRD ML, 1978, IEEE T SYST MAN CYB, V8, P133; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; CHUANG HYH, 1985, P IEEE COMPUT SOC WO, P300; Duda R., 1975, COMMUN ACM, V15, P11; GOTO N, 1978, 4TH P INT JOINT C PA, P970; HARA Y, 1980, 5TH P INT JOINT C PA, P273; HARRIS H, 1983, SOLID STATE TECHNOL, V26; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HSIEH YY, 1980, COMPUT VISION GRAPH, V14, P293, DOI 10.1016/0146-664X(80)90024-6; JENSEN S, 1981, P SOC PHOTO-OPT INST, V275, P100, DOI 10.1117/12.931879; LI CC, 1985, P IEEE INT C ROBOTIC, P474; NYYSSONEN D, 1980, P SOC PHOTO-OPT INST, V221, P119; Okamoto K., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1361; Petkovic D., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P9; SIMPSON RA, 1982, P SOC PHOTO-OPT INST, V334, P230, DOI 10.1117/12.933581; Tamura S., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P285; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; YAMAJI H, 1985, SCANNING ELECTRON MI, V1, P97	19	19	20	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					117	120		10.1109/34.3875	http://dx.doi.org/10.1109/34.3875			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600012
J	LASRY, MJ; STERN, RM				LASRY, MJ; STERN, RM			A-POSTERIORI ESTIMATION OF CORRELATED JOINTLY GAUSSIAN MEAN VECTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University	LASRY, MJ (corresponding author), CARNEGIE MELLON UNIV,DEPT ELECT ENGN,PITTSBURGH,PA 15213, USA.			Stern, Richard/0000-0003-0557-7282				Cole R. A., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P731; CRAMER H, 1946, MATH METHODS STATIST; Duda R.O., 1973, J ROYAL STAT SOC SER; KEEHN DG, 1965, IEEE T INFORM THEORY, V11, P126, DOI 10.1109/TIT.1965.1053726; Stern R. M., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P734; VANTREES HL, 1973, DECTECTION ESTIMAT 1, P60	6	19	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					530	535		10.1109/TPAMI.1984.4767559	http://dx.doi.org/10.1109/TPAMI.1984.4767559			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869222	Green Submitted			2022-12-18	WOS:A1984SY28900015
J	FAIRFIELD, J				FAIRFIELD, J			SEGMENTING DOT PATTERNS BY VORONOI DIAGRAM CONCAVITY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FAIRFIELD, J (corresponding author), JAMES MADISON UNIV,DEPT MATH & COMP SCI,HARRISONBURG,VA 22807, USA.							AGIN GJ, 1972, THESIS STANFORD U ST; AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; BADLER NI, 1979, 1979 P INT C CYB SOC; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1977, 1977 P IEEE C PATT R, P203; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; DAVIS LS, 1977, IEEE T SYST MAN CYB, V7, P204; DRYSDALE RL, 1979, STANCS79705 STANF U; FAIRFIELD J, 1981, THESIS DUKE U DURHAM; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; Hartigan J.A., 1975, CLUSTERING ALGORITHM; OCALLAGH.JF, 1974, PERCEPTION, V3, P33, DOI 10.1068/p030033; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; ROSE F, 1974, Lichenologist (London), V6, P1, DOI 10.1017/S002428297400003X; SHAMOS MI, 1976, 17TH P IEEE S F COMP, P268; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; VATAN P, 1976, THESIS MIT CAMBRIDGE; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	19	19	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					104	110		10.1109/TPAMI.1983.4767353	http://dx.doi.org/10.1109/TPAMI.1983.4767353			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869092				2022-12-18	WOS:A1983PZ84400016
J	MITICHE, A; AGGARWAL, JK				MITICHE, A; AGGARWAL, JK			DETECTION OF EDGES USING RANGE INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV TEXAS,DEPT ELECT ENGN,AUSTIN,TX 78712; UNIV TEXAS,IMAGE & SIGNAL ANAL LAB,AUSTIN,TX 78712	University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin								DAVIS LS, 1980, COMPUT VISION GRAPH, V12, P25, DOI 10.1016/0146-664X(80)90002-7; Duda R. O., 1976, 3rd International Joint Conference on Pattern Recognition, P598; DUDA RO, 1975, PATTERN CLASSIFICATI; GIL B, 1983, COMPUT VISION GRAPHI, V21; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; INOKUCHI S, 1980, 5TH P INT C PATT REC, P1301; LYNCH DK, 1981, COMPUT VISION GRAPH, V15, P194, DOI 10.1016/0146-664X(81)90079-4; MILGRAM DL, 1980, 5TH P INT C PATT REC, P912; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458	9	19	20	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					174	178		10.1109/TPAMI.1983.4767369	http://dx.doi.org/10.1109/TPAMI.1983.4767369			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869098				2022-12-18	WOS:A1983QJ97400005
J	JARVIS, JF				JARVIS, JF			METHOD FOR AUTOMATING THE VISUAL INSPECTION OF PRINTED WIRING BOARDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											JARVIS, JF (corresponding author), BELL TEL LABS INC,HOLMDEL,NJ 07733, USA.							Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; HARLOW CA, 1975, COMPUTER         APR, P36; Jarvis J. F., 1976, 3rd International Joint Conference on Pattern Recognition, P189; KNUTH DE, 1973, ART COMPUTER PROGRAM, V3, P406; RESTRICK RC, 1977, AUG P SPIE SOL STAT, V116, P76; THISSEN FLAM, 1977, PHILIPS TECH REV, V37, P77	6	19	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					77	82		10.1109/TPAMI.1980.4766975	http://dx.doi.org/10.1109/TPAMI.1980.4766975			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD568	22499628				2022-12-18	WOS:A1980JD56800013
J	Furnari, A; Farinella, GM				Furnari, Antonino; Farinella, Giovanni Maria			Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Streaming media; Encoding; Three-dimensional displays; Predictive models; Containers; Cameras; Action anticipation; egocentric vision; recurrent neural networks; LSTM		In this paper, we tackle the problem of egocentric action anticipation, i.e., predicting what actions the camera wearer will perform in the near future and which objects they will interact with. Specifically, we contribute Rolling-Unrolling LSTM, a learning architecture to anticipate actions from egocentric videos. The method is based on three components: 1) an architecture comprised of two LSTMs to model the sub-tasks of summarizing the past and inferring the future, 2) a Sequence Completion Pre-Training technique which encourages the LSTMs to focus on the different sub-tasks, and 3) a Modality ATTention (MATT) mechanism to efficiently fuse multi-modal predictions performed by processing RGB frames, optical flow fields and object-based features. The proposed approach is validated on EPIC-Kitchens, EGTEA Gaze+ and ActivityNet. The experiments show that the proposed architecture is state-of-the-art in the domain of egocentric videos, achieving top performances in the 2019 EPIC-Kitchens egocentric action anticipation challenge. The approach also achieves competitive performance on ActivityNet with respect to methods not based on unsupervised pre-training and generalizes to the tasks of early action recognition and action recognition. To encourage research on this challenging topic, we made our code, trained models, and pre-extracted features available at our web page: http://iplab.dmi.unict.it/rulstm.	[Furnari, Antonino; Farinella, Giovanni Maria] Univ Catania, Dept Math & Comp Sci, I-95124 Catania, CT, Italy	University of Catania	Furnari, A (corresponding author), Univ Catania, Dept Math & Comp Sci, I-95124 Catania, CT, Italy.	furnari@dmi.unict.it; gfarinella@dmi.unict.it	; FARINELLA, Giovanni Maria/L-8555-2015	FURNARI, Antonino/0000-0001-6911-0302; FARINELLA, Giovanni Maria/0000-0002-6034-0432	Piano della Ricerca 2016-2018, linea di Intervento 2 of DMI, University of Catania; MIUR AIM -Attrazione e Mobilita Internazionale Linea 1 [AIM1893589 -CUP E64118002540007]	Piano della Ricerca 2016-2018, linea di Intervento 2 of DMI, University of Catania; MIUR AIM -Attrazione e Mobilita Internazionale Linea 1	This work was supported by Piano della Ricerca 2016-2018, linea di Intervento 2 of DMI, University of Catania and MIUR AIM -Attrazione e Mobilita Internazionale Linea 1 -AIM1893589 -CUP E64118002540007. Antonino Furnari and Giovanni Maria Farinella are co-first authors.	Abu Farha Y, 2018, PROC CVPR IEEE, P5343, DOI 10.1109/CVPR.2018.00560; Aliakbarian MS, 2017, IEEE I CONF COMP VIS, P280, DOI 10.1109/ICCV.2017.39; Bai S., 2018, ARXIV PREPRINT ARXIV; Becattini F., 2017, ARXIV170501781; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44; De Geest R, 2018, IEEE WINT CONF APPL, P1549, DOI 10.1109/WACV.2018.00173; De Geest R, 2016, LECT NOTES COMPUT SC, V9909, P269, DOI 10.1007/978-3-319-46454-1_17; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Fan C., 2017, FORECASTING HAND OBJ; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269; Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Feichtenhofer Christoph, 2016, NIPS; Felsen P, 2017, IEEE I CONF COMP VIS, P3362, DOI 10.1109/ICCV.2017.362; Furnari A, 2017, J VIS COMMUN IMAGE R, V49, P401, DOI 10.1016/j.jvcir.2017.10.004; Furnari Antonino, 2018, P EUR C COMP VIS ECC; Gao Jiyang, 2017, BRIT MACH VIS C BMVC; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Ghadiyaram Deepti, 2019, CVPR; Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Huang DA, 2014, LECT NOTES COMPUT SC, V8695, P489, DOI 10.1007/978-3-319-10584-0_32; Huang D, 2014, LECT NOTES COMPUT SC, V8691, P410, DOI 10.1007/978-3-319-10578-9_27; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jain A, 2016, IEEE INT CONF ROBOT, P3118, DOI 10.1109/ICRA.2016.7487478; Jain A, 2015, IEEE I CONF COMP VIS, P3182, DOI 10.1109/ICCV.2015.364; Kanade T, 2012, P IEEE, V100, P2442, DOI 10.1109/JPROC.2012.2200554; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kazakos E, 2019, IEEE I CONF COMP VIS, P5491, DOI 10.1109/ICCV.2019.00559; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335; Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Li Y, 2018, LECT NOTES COMPUT SC, V11209, P639, DOI 10.1007/978-3-030-01228-1_38; Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625; Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718; Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209; Ma SG, 2016, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2016.214; Ma YX, 2019, AAAI CONF ARTIF INTE, P6120; Mahmud T, 2017, IEEE I CONF COMP VIS, P5784, DOI 10.1109/ICCV.2017.616; Mees O, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P151, DOI 10.1109/IROS.2016.7759048; Miech A, 2019, IEEE COMPUT SOC CONF, P2915, DOI 10.1109/CVPRW.2019.00351; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Park HS, 2016, PROC CVPR IEEE, P4697, DOI 10.1109/CVPR.2016.508; Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010; Rhinehart N, 2017, IEEE I CONF COMP VIS, P3716, DOI 10.1109/ICCV.2017.399; Ryoo MS, 2015, ACMIEEE INT CONF HUM, P295, DOI 10.1145/2696454.2696462; Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Simonyan K, 2014, ADV NEUR IN, V27; Singh S, 2016, PROC CVPR IEEE, P2620, DOI 10.1109/CVPR.2016.287; Singh S, 2017, PATTERN RECOGN, V62, P45, DOI 10.1016/j.patcog.2016.07.031; Soran B, 2015, IEEE I CONF COMP VIS, P4669, DOI 10.1109/ICCV.2015.530; Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354; Sudhakaran S, 2019, PROC CVPR IEEE, P9946, DOI 10.1109/CVPR.2019.01019; Sudhakaran Swathikiran, 2018, ARXIV180711794; Sutskever I, 2014, ADV NEUR IN, V27; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zeng KH, 2017, IEEE I CONF COMP VIS, P3018, DOI 10.1109/ICCV.2017.326; Zhang MM, 2017, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2017.377; Zhang PF, 2018, LECT NOTES COMPUT SC, V11213, P136, DOI 10.1007/978-3-030-01240-3_9; Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49; Zhou YP, 2015, IEEE I CONF COMP VIS, P4498, DOI 10.1109/ICCV.2015.511	77	18	18	4	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4021	4036		10.1109/TPAMI.2020.2992889	http://dx.doi.org/10.1109/TPAMI.2020.2992889			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32386143	Green Submitted			2022-12-18	WOS:000702649700024
J	Dvornik, N; Mairal, J; Schmid, C				Dvornik, Nikita; Mairal, Julien; Schmid, Cordelia			On the Importance of Visual Context for Data Augmentation in Scene Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Context modeling; Object detection; Image segmentation; Semantics; Training; Visualization; Task analysis; Convolutional neural networks; data augmentation; visual context; object detection; semantic segmentation		Performing data augmentation for learning deep neural networks is known to be important for training visual recognition systems. By artificially increasing the number of training examples, it helps reducing overfitting and improves generalization. While simple image transformations can already improve predictive performance in most vision tasks, larger gains can be obtained by leveraging task-specific prior knowledge. In this work, we consider object detection, semantic and instance segmentation and augment the training images by blending objects in existing scenes, using instance segmentation annotations. We observe that randomly pasting objects on images hurts the performance, unless the object is placed in the right context. To resolve this issue, we propose an explicit context model by using a convolutional neural network, which predicts whether an image region is suitable for placing a given object or not. In our experiments, we show that our approach is able to improve object detection, semantic and instance segmentation on the PASCAL VOC12 and COCO datasets, with significant gains in a limited annotation scenario, i.e., when only one category is annotated. We also show that the method is not limited to datasets that come with expensive pixel-wise instance annotations and can be used when only bounding boxes are available, by employing weakly-supervised learning for instance masks approximation.	[Dvornik, Nikita; Mairal, Julien; Schmid, Cordelia] Univ Grenoble Alpes, CNRS, Inria, Grenoble INP,LJK, Grenoble, France	Centre National de la Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; UDICE-French Research Universities; Universite Grenoble Alpes (UGA); Inria	Dvornik, N (corresponding author), Univ Grenoble Alpes, CNRS, Inria, Grenoble INP,LJK, Grenoble, France.	nikita.dvornik@inria.fr; julien.mairal@inria.fr; cordelia.schmid@inria.fr		Dvornik, Nikita/0000-0003-4770-3427	ERC [714381]; ANR [3IA MIAI@GrenobleAlpes]	ERC(European Research Council (ERC)European Commission); ANR(French National Research Agency (ANR))	This work was supported by the ERC grant number 714381 (SOLARIS project) and by ANR 3IA MIAI@GrenobleAlpes.	Ba J., 2017, P 3 INT C LEARN REPR; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Barth R., 2018, ARXIV180306301; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Ben-Shahar O., 2017, ARXIV171105471; Burges, 1998, MNIST DATABASE HANDW; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chu WQ, 2018, NEUROCOMPUTING, V275, P1035, DOI 10.1016/j.neucom.2017.09.048; Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532; Dvornik N, 2018, LECT NOTES COMPUT SC, V11216, P375, DOI 10.1007/978-3-030-01258-8_23; Dvornik N, 2017, IEEE I CONF COMP VIS, P4174, DOI 10.1109/ICCV.2017.447; Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Frid-Adar M, 2018, I S BIOMED IMAGING, P289; Fu C. -Y., 2017, ARXIV170106659; Georgakis G, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; Handa A, 2016, PROC CVPR IEEE, P4077, DOI 10.1109/CVPR.2016.442; He K., 2017, P IEEE INT C COMP VI, P2961, DOI DOI 10.1109/ICCV.2017.322; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He XM, 2006, LECT NOTES COMPUT SC, V3951, P338; Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191; Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Liao ZC, 2012, PROC CVPR IEEE, P3442, DOI 10.1109/CVPR.2012.6248085; Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; McCormac J, 2017, IEEE I CONF COMP VIS, P2697, DOI 10.1109/ICCV.2017.292; Movshovitz-Attias Y, 2016, LECT NOTES COMPUT SC, V9915, P202, DOI 10.1007/978-3-319-49409-8_18; Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8; Sankaranarayanan S, 2018, PROC CVPR IEEE, P3752, DOI 10.1109/CVPR.2018.00395; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Sixt L, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00066; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P763, DOI 10.1109/ICCV.2001.937604; Yang J., 2017, FASTER PYTORCH IMPLE; Yang JM, 2014, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2014.415; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235; Yu F., 2016, ABS151107122 CORR; Yu R, 2016, ARXIV160902948; Zhou YZ, 2018, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2018.00399	62	18	19	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2014	2028		10.1109/TPAMI.2019.2961896	http://dx.doi.org/10.1109/TPAMI.2019.2961896			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31880540	Green Submitted			2022-12-18	WOS:000649590200014
J	Okuda, M; Satoh, S; Sato, Y; Kidawara, Y				Okuda, Makoto; Satoh, Shinichi; Sato, Yoichi; Kidawara, Yutaka			Community Detection Using Restrained Random-Walk Similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Community detection; graph; normalized mutual information; random walk	NETWORKS; OPTIMIZATION; ALGORITHM	In this paper, we propose a restrained random-walk similarity method for detecting the community structures of graphs. The basic premise of our method is that the starting vertices of finite-length random walks are judged to be in the same community if the walkers pass similar sets of vertices. This idea is based on our consideration that a random walker tends to move in the community including the walker's starting vertex for some time after starting the walk. Therefore, the sets of vertices passed by random walkers starting from vertices in the same community must be similar. The idea is reinforced with two conditions. First, we exclude abnormal random walks. Random walks that depart from each vertex are executed many times, and vertices that are rarely passed by the walkers are excluded from the set of vertices that the walkers may pass. Second, we forcibly restrain random walks to an appropriate length. In our method, a random walk is terminated when the walker repeatedly visits vertices that they have already passed. Experiments on real-world networks demonstrate that our method outperforms previous techniques in terms of accuracy.	[Okuda, Makoto] Natl Inst Informat & Commun Technol NICT, Universal Commun Res Inst, Koganei, Tokyo 1840015, Japan; [Satoh, Shinichi] Natl Inst Informat NII, Digital Content & Media Sci Res Div, Chiyoda Ku, Tokyo 1000003, Japan; [Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Meguro Ku, Okyo 1138654, Japan; [Kidawara, Yutaka] Natl Inst Informat & Commun Technol NICT, Universal Commun Res Inst, Kyoto 6190289, Japan	National Institute of Information & Communications Technology (NICT) - Japan; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; University of Tokyo; National Institute of Information & Communications Technology (NICT) - Japan	Okuda, M (corresponding author), Natl Inst Informat & Commun Technol NICT, Universal Commun Res Inst, Koganei, Tokyo 1840015, Japan.	m-okuda@nict.go.jp; satoh@nii.ac.jp; ysato@iis.u-tokyo.ac.jp; kidawara@nict.go.jp						Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Andersen R, 2007, INTERNET MATH, V4, P35, DOI 10.1080/15427951.2007.10129139; Audet C, 2003, SIAM J OPTIMIZ, V13, P889, DOI 10.1137/S1052623400378742; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Boettcher S, 2001, PHYS REV LETT, V86, P5211, DOI 10.1103/PhysRevLett.86.5211; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Clauset A, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026132; Csardi G., 2006, INTERJOURNAL COMPLEX, V1695, P5; Csardi G., 2015, IGRAPH NETWORK ANAL; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; Danon L, 2006, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2006/11/P11010; De Meo P, 2014, J COMPUT SYST SCI, V80, P72, DOI 10.1016/j.jcss.2013.03.012; Duch J, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.027104; Fan Y, 2007, PHYSICA A, V377, P363, DOI 10.1016/j.physa.2006.11.036; Ferrara E., COMMUNITY DETECTION; Fortunato S., INTHEPRESS2 SANTOFOR; Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104; Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; FRIGGE M, 1989, AM STAT, V43, P50, DOI 10.2307/2685173; Gao C, 2017, J MACH LEARN RES, V18, P1; GOLDBERG AV, 1988, J ACM, V35, P921, DOI 10.1145/48014.61051; Guimera R, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.025101; Guimera R, 2005, NATURE, V433, P895, DOI 10.1038/nature03288; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Harenberg S, 2014, WIRES COMPUT STAT, V6, P426, DOI 10.1002/wics.1319; Harenverg S., 2017, HARENBERGSD COMMUNIT; Hastings MB, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.035102; Holland J.H, 1975, INTRO ANAL APPL BIOL; Hughes B. D., 1995, RANDOM WALKS RANDOM, DOI [10.1079/PNS19950063, DOI 10.1079/PNS19950063]; Jierui Xie, 2012, Advances in Knowledge Discovery and Data Mining. Proceedings 16th Pacific-Asia Conference (PAKDD 2012), P25, DOI 10.1007/978-3-642-30220-6_3; Karrer B, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.016107; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LANCICHINETTI A, 2009, PHYS REV E 2, V80, DOI DOI 10.1103/PHYSREVE.80.056117; Leibe B., COMPUTER VISION; Leskovec J, 2014, SNAP DATASETS STANFO; Liu X, 2007, LECT NOTES COMPUT SC, V4488, P657; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Medus A, 2005, PHYSICA A, V358, P593, DOI 10.1016/j.physa.2005.04.022; Newman MEJ, 2013, PHYS REV E, V88, DOI 10.1103/PhysRevE.88.042822; Newman MEJ, 2004, PHYS REV E, V70, DOI [10.1103/PhysRevE.70.056131, 10.1103/PhysRevE.69.026113]; Okuda M, 2017, IEEE IMAGE PROC, P1292; Pearl J., 1982, AAAI 82 P 2 AAAI C A, P133; Pons P, 2005, LECT NOTES COMPUT SC, V3733, P284; Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106; Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110; Richardson T, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.036111; Rosvall M, 2009, EUR PHYS J-SPEC TOP, V178, P13, DOI 10.1140/epjst/e2010-01179-1; Ruan J, 2007, IEEE DATA MINING, P643, DOI 10.1109/ICDM.2007.72; Schuetz P, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.026112; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Snijders TAB, 1997, J CLASSIF, V14, P75, DOI 10.1007/s003579900004; Sun Y, 2009, EPL-EUROPHYS LETT, V86, DOI 10.1209/0295-5075/86/28004; Wang GX, 2008, COMPUT MATH APPL, V55, P2746, DOI 10.1016/j.camwa.2007.10.028; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weyand T, 2015, COMPUT VIS IMAGE UND, V135, P1, DOI 10.1016/j.cviu.2015.02.002; Weyand T, 2011, IEEE I CONF COMP VIS, P1132, DOI 10.1109/ICCV.2011.6126361; Whang JJ, 2016, IEEE T KNOWL DATA EN, V28, P1272, DOI 10.1109/TKDE.2016.2518687; White S., 2009, SIAM INT C DATA MINI, P504; Xianghua Fu, 2013, Journal of Software, V8, P286, DOI 10.4304/jsw.8.2.286-295; Yang JW, 2012, IEEE DATA MINING, P745, DOI 10.1109/ICDM.2012.138; Yang YY, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P587	65	18	18	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					89	103		10.1109/TPAMI.2019.2926033	http://dx.doi.org/10.1109/TPAMI.2019.2926033			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31265385				2022-12-18	WOS:000597206900007
J	Yu, X; Fernando, B; Hartley, R; Porikli, F				Yu, Xin; Fernando, Basura; Hartley, Richard; Porikli, Fatih			Semantic Face Hallucination: Super-Resolving Very Low-Resolution Face Images with Supplementary Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Spatial resolution; Image reconstruction; Semantics; Facial features; Feature extraction; Face; super-resolution; hallucination; attribute	SUPERRESOLUTION; MODELS	Given a tiny face image, existing face hallucination methods aim at super-resolving its high-resolution (HR) counterpart by learning a mapping from an exemplary dataset. Since a low-resolution (LR) input patch may correspond to many HR candidate patches, this ambiguity may lead to distorted HR facial details and wrong attributes such as gender reversal and rejuvenation. An LR input contains low-frequency facial components of its HR version while its residual face image, defined as the difference between the HR ground-truth and interpolated LR images, contains the missing high-frequency facial details. We demonstrate that supplementing residual images or feature maps with additional facial attribute information can significantly reduce the ambiguity in face super-resolution. To explore this idea, we develop an attribute-embedded upsampling network, which consists of an upsampling network and a discriminative network. The upsampling network is composed of an autoencoder with skip-connections, which incorporates facial attribute vectors into the residual features of LR inputs at the bottleneck of the autoencoder, and deconvolutional layers used for upsampling. The discriminative network is designed to examine whether super-resolved faces contain the desired attributes or not and then its loss is used for updating the upsampling network. In this manner, we can super-resolve tiny (16x16 pixels) unaligned face images with a large upscaling factor of 8x while reducing the uncertainty of one-to-many mappings remarkably. By conducting extensive evaluations on a large-scale dataset, we demonstrate that our method achieves superior face hallucination results and outperforms the state-of-the-art.	[Yu, Xin; Hartley, Richard; Porikli, Fatih] Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia; [Fernando, Basura] ASTAR, Artificial Intelligence Initiat, Singapore 138632, Singapore	Australian National University; Agency for Science Technology & Research (A*STAR)	Yu, X (corresponding author), Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia.	xin.yu@anu.edu.au; basura.fernando@anu.edu.au; richard.hartley@anu.edu.au; fatih.porikli@anu.edu.au		Yu, Xin/0000-0002-0269-5649; Fernando, Basura/0000-0002-6920-9916	Australian Research Council [DP150104645]; Australian Research Council Centre of Excellence for Robotic Vision [CE140100016]	Australian Research Council(Australian Research Council); Australian Research Council Centre of Excellence for Robotic Vision(Australian Research Council)	This work was supported under the Australian Research Council's Discovery Projects funding scheme (project DP150104645) and Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arjovsky M, 2017, PR MACH LEARN RES, V70; Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Berthelot D., 2017, BEGAN BOUNDARY EQUIL; Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019; Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180; Chang XX, 2018, ADVANCED FUNCTIONAL MATERIALS (CMC 2017), P293, DOI 10.1007/978-981-13-0110-0_33; Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581; Farrugia RA, 2017, IEEE T IMAGE PROCESS, V26, P4562, DOI 10.1109/TIP.2017.2717181; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Goncalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grm K., 2018, ARXIV180510938; Hinton G., NEURAL NETWORKS MACH; Hsu C.-C., 2018, ARXIV180708370; Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jaderberg M, 2015, ADV NEUR IN, V28; Jiang JJ, 2020, IEEE T CYBERNETICS, V50, P324, DOI [10.1109/TCYB.2018.2868891, 10.1007/978-3-319-95957-3_1]; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee C.-H., 2018, P C COMP VIS PATT RE, P721; Li YC, 2014, PATTERN RECOGN, V47, P1261, DOI 10.1016/j.patcog.2013.09.012; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019; Mirza M., 2014, ARXIV PREPRINT ARXIV; Perarnau G, 2016, ARXIV161106355; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Reed S., 2016, ARXIV160505396; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135; Shi JG, 2018, IEEE T IMAGE PROCESS, V27, P2980, DOI 10.1109/TIP.2018.2813163; Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578; Tappen MF, 2012, LECT NOTES COMPUT SC, V7578, P236, DOI 10.1007/978-3-642-33786-4_18; van den Oord A, 2016, PR MACH LEARN RES, V48; Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9; Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171; Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828; Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36; Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47; Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yu XH, 2020, IEEE GEOSCI REMOTE S, V17, P978, DOI 10.1109/LGRS.2019.2939264; Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14; Yu X, 2018, PROC CVPR IEEE, P908, DOI 10.1109/CVPR.2018.00101; Yu X, 2017, AAAI CONF ARTIF INTE, P4327; Yu X, 2018, IEEE T IMAGE PROCESS, V27, P2747, DOI 10.1109/TIP.2018.2808840; Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhao Junbo, 2016, P INT C LEARN REPR T, DOI DOI 10.48550/ARXIV.1609.03126; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37	65	18	18	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2926	2943		10.1109/TPAMI.2019.2916881	http://dx.doi.org/10.1109/TPAMI.2019.2916881			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NX0AD	31095477				2022-12-18	WOS:000575381000014
J	Zabatani, A; Surazhsky, V; Sperling, E; Ben Moshe, S; Menashe, O; Silver, DH; Karni, Z; Bronstein, AM; Bronstein, MM; Kimmel, R				Zabatani, Aviad; Surazhsky, Vitaly; Sperling, Erez; Ben Moshe, Sagi; Menashe, Ohad; Silver, David H.; Karni, Zachi; Bronstein, Alexander M.; Bronstein, Michael M.; Kimmel, Ron			Intel (R) RealSense (TM) SR300 Coded Light Depth Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Three-dimensional displays; Image reconstruction; Pipelines; Optical imaging; Optical sensors; Reflective binary codes; Intel; RealSense; 3D camera; SR300; coded light; depth reconstruction	SURFACE MEASUREMENT; MINIMAL-SURFACES; MOVIES; IMAGES; COLOR; MAPS	Intel (R) RealSense (TM) SR300 is a depth camera capable of providing a VGA-size depth map at 60 fps and 0.125mm depth resolution. In addition, it outputs an infrared VGA-resolution image and a 1080p color texture image at 30 fps. SR300 form-factor enables it to be integrated into small consumer products and as a front facing camera in laptops and Ultrabooks (TM). The SR300 depth camera is based on a coded-light technology where triangulation between projected patterns and images captured by a dedicated sensor is used to produce the depth map. Each projected line is coded by a special temporal optical code, that enables a dense depth map reconstruction from its reflection. The solid mechanical assembly of the camera allows it to stay calibrated throughout temperature and pressure changes, drops, and hits. In addition, active dynamic control maintains a calibrated depth output. An extended API LibRS released with the camera allows developers to integrate the camera in various applications. Algorithms for 3D scanning, facial analysis, hand gesture recognition, and tracking are within reach for applications using the SR300. In this paper, we describe the underlying technology, hardware, and algorithms of the SR300, as well as its calibration procedure, and outline some use cases. We believe that this paper will provide a full case study of a mass-produced depth sensing product and technology.	[Zabatani, Aviad; Surazhsky, Vitaly; Sperling, Erez; Ben Moshe, Sagi; Menashe, Ohad; Silver, David H.; Karni, Zachi] Intel Corp Ltd, RealSense, IL-31015 Haifa, Israel; [Bronstein, Alexander M.; Kimmel, Ron] Technion, Comp Sci Dept, Haifa, Israel; [Bronstein, Michael M.] Imperial Coll London, Dept Comp, London, England; [Bronstein, Michael M.] Univ Svizzera Italiana, Inst Computat Sci, CH-6900 Lugano, Switzerland	Technion Israel Institute of Technology; Imperial College London; Universita della Svizzera Italiana	Zabatani, A (corresponding author), Intel Corp Ltd, RealSense, IL-31015 Haifa, Israel.	aviad.zabatani@intel.com; vitaly.surazhsky@intel.com; erez.sperling@intel.com; sagi.benmoshe@intel.com; ohad.menashe@intel.com; david.silver@intel.com; tzachi.karni@intel.com; alex.bronstein@intel.com; michael.bronstein@imperial.ac.uk; ron.kimmel@intel.com		Silver, David/0000-0002-3071-304X				Audras C., 2011, AUSTR C ROB AUT, V2, P2; Bronstein A., 2017, U.S. Patent, Patent No. [9,824,461, 9824461]; Bronstein A., 2017, U.S. Patent, Patent No. [9,794,545, 9794545]; Bronstein A., 2018, U.S. Patent, Patent No. [9,952,036, 9952036]; Bronstein A. M., 2003, TECH REP; Bronstein M., 2018, U.S. Patent, Patent No. [9,940,701, 9940701]; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Burbano A, 2016, ICDSC 2016: 10TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERA, P76, DOI 10.1145/2967413.2967431; Carfagni M, 2017, IEEE SENS J, V17, P4508, DOI 10.1109/JSEN.2017.2703829; Gray F., 1953, U.S. Patent no, Patent No. [2 632 058, 2632058, 2, 632, 058, 2,632,058]; Guler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280; Hartley R., 2003, MULTIPLE VIEW GEOMET; House R, 2017, PROC SPIE, V10135, DOI 10.1117/12.2255899; Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; Kimmel R, 1997, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.1997.609348; Kimmel R., 2010, US Patent, Patent No. [7,756,323, 7756323]; Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939; Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; Remondino F., 2013, TOF RANGE IMAGING CA, V68121; Rubinstein O., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1505, DOI 10.1109/ICCVW.2009.5457433; SATO K, 1985, J ROBOTIC SYST, V2, P27; Scharstein D, 2003, PROC CVPR IEEE, P195; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Silver D. H., 2017, U.S. Patent, Patent No. [9,852,495, 9852495]; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Sochen N, 2001, J MATH IMAGING VIS, V14, P195, DOI 10.1023/A:1011277827470; Steinbrucker F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P719, DOI 10.1109/ICCVW.2011.6130321; Surazhsky V., 2017, U.S. Patent, Patent No. [9,792,673, 9792673]; Surazhsky V., 2017, U.S. Patent, Patent No. [9,792,671, 9792671]; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972; Wetzler A., 2015, P BRIT MACH VIS C; Zabatani A., 2017, U.S. Patent, Patent No. [9,813,692, 9813692]; Zabatani A., 2017, U.S. Patent, Patent No. [9,800,795, 9800795]; Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289	37	18	20	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2333	2345		10.1109/TPAMI.2019.2915841	http://dx.doi.org/10.1109/TPAMI.2019.2915841			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31094683				2022-12-18	WOS:000567471300002
